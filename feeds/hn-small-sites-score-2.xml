<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 16 Aug 2020 04:19:52 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 16 Aug 2020 04:19:52 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Tell no-one: A century of secret deals between the NSA and the telecom industry]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24155374">thread link</a>) | @trymas
<br/>
August 14, 2020 | https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford#t=2215 | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford#t=2215">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><a href="https://media.ccc.de/c/31c3">
<img alt="conference logo" src="https://static.media.ccc.de/media/congress/2014/folder-2014.png">
</a>
</p>

<h2>
A century of secret deals between the NSA and the telecom industry
</h2>
</div>
<p>
<span></span>
<a href="https://media.ccc.de/search?p=James+Bamford">James Bamford</a>

</p>
<div data-aspect-ratio="16:9">

<!-- Mediaelement Player -->
<video controls="controls" data-id="2179" data-timeline="https://static.media.ccc.de/media/congress/2014/e8e29f6a-11df-491a-acae-1253879ae8f9-timeline.jpg" height="100%" poster="https://static.media.ccc.de/media/congress/2014/6600-hd_preview.jpg" preload="metadata" width="100%">
<source data-lang="eng" data-quality="high" src="https://cdn.media.ccc.de/congress/2014/webm-hd/31c3-6600-en-de-Tell_no-one_webm-hd.webm" title="eng 1080p" type="video/webm">
<source data-lang="eng" data-quality="high" src="https://cdn.media.ccc.de/congress/2014/h264-hd-web/31c3-6600-en-Tell_no-one_hd.mp4" title="eng 1080p" type="video/mp4">
<source data-lang="eng" data-quality="low" src="https://cdn.media.ccc.de/congress/2014/webm-sd/31c3-6600-en-de-Tell_no-one_webm-sd.webm" title="eng 576p" type="video/webm">
<source data-lang="eng" data-quality="low" src="https://cdn.media.ccc.de/congress/2014/h264-sd/31c3-6600-en-de-Tell_no-one_sd.mp4" title="eng 576p" type="video/mp4">
<source data-lang="eng" data-quality="high" src="https://cdn.media.ccc.de/congress/2014/h264-hd/31c3-6600-en-de-Tell_no-one_hd.mp4" title="eng 1080p" type="video/mp4">
<track kind="metadata" label="thumbnails" src="https://static.media.ccc.de/media/congress/2014/e8e29f6a-11df-491a-acae-1253879ae8f9-thumbnails.vtt" srclang="">

</video>


</div><p>
Playlists:
<a href="https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford/playlist">'31c3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford/audio">audio</a>
/
<a href="https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford/related">related events</a></p><ul>
<li>
<span></span>
62 min
</li>
<li>
<span title="event and release date"></span>
2014-12-28
</li>
<li>
<span></span>
6224
</li>
<li>
<span></span>
<a href="http://events.ccc.de/congress/2014/Fahrplan/events/6600.html">Fahrplan</a>
</li>
</ul>
<!-- %h3 About -->
<p>For nearly one hundred years, the NSA and its predecessors have been engaging in secret, illegal deals with the American telecom industry, with both virtually immune from prosecution.</p>

<h3>Download</h3>
<div>
<div>
<div>
<p>
<h4>Video</h4>
</p>
<div>
<ul role="tablist">
<li role="presentation">
<a aria-controls="mp4" data-toggle="tab" href="#mp4" role="tab">
MP4
</a>
</li>
<li role="presentation">
<a aria-controls="webm" data-toggle="tab" href="#webm" role="tab">
WebM
</a>
</li>
</ul>
<div>
<div id="mp4" role="tabpanel">
<div>
<a href="https://cdn.media.ccc.de/congress/2014/h264-hd/31c3-6600-en-de-Tell_no-one_hd.mp4">
<p>Download 1080p</p>
<span>eng</span>
<span>484 MB</span>
</a>
</div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/h264-sd/31c3-6600-en-de-Tell_no-one_sd.mp4">
<p>Download 576p</p>
<span>eng</span>
<span>253 MB</span>
</a>
</div>
</div>
<div id="webm" role="tabpanel">
<div>
<a href="https://cdn.media.ccc.de/congress/2014/webm-hd/31c3-6600-en-de-Tell_no-one_webm-hd.webm">
<p>Download 1080p</p>
<span>eng</span>
<span>486 MB</span>
</a>
</div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/webm-sd/31c3-6600-en-de-Tell_no-one_webm-sd.webm">
<p>Download 576p</p>
<span>eng</span>
<span>208 MB</span>
</a>
</div>
</div>
</div>
</div>
</div>
<div>
<p>
<h4>Subtitles</h4>
</p>
<div>
<p><a href="https://www.c3subtitles.de/talk/guid/e8e29f6a-11df-491a-acae-1253879ae8f9" target="_blank">
Help us to subtitle this talk!
</a>
</p></div>
</div>
<div>
<p>
<h4>Audio</h4>
</p>
<div>
<div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/mp3/31c3-6600-en-de-Tell_no-one_mp3.mp3">
<p>Download mp3</p>
<span>eng</span>
<span>85 MB</span>
</a>
</div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/opus/31c3-6600-en-de-Tell_no-one_opus.opus">
<p>Download opus</p>
<span>eng</span>
<span>43 MB</span>
</a>
</div>
</div>
</div>
</div>
</div>

</div>
<h3>Related</h3>
<div>
<div>
<p><a href="https://media.ccc.de/v/31c3_-_6244_-_de_-_saal_6_-_201412281245_-_serenitat_anleitung_zum_glucklichsein_-_elektra_-_andrea_behrendt_-_read_delete">
<img alt="Serenität – Anleitung zum Glücklichsein" src="https://static.media.ccc.de/media/congress/2014/6244-hd.jpg" title="Serenität – Anleitung zum Glücklichsein">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_5930_-_en_-_saal_6_-_201412291400_-_funky_file_formats_-_ange_albertini">
<img alt="Funky File Formats" src="https://static.media.ccc.de/media/congress/2014/5930-hd.jpg" title="Funky File Formats">
</a>
</p>
<p><a href="https://media.ccc.de/v/32c3-7143-the_state_of_internet_censorship">
<img alt="The state of Internet Censorship" src="https://static.media.ccc.de/media/congress/2015/7143-hd.jpg" title="The state of Internet Censorship">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6175_-_en_-_saal_6_-_201412282300_-_superheroes_still_need_phoneboxes_-_ben_dalton">
<img alt="Superheroes Still Need Phoneboxes" src="https://static.media.ccc.de/media/congress/2014/6175-hd.jpg" title="Superheroes Still Need Phoneboxes">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6430_-_de_-_saal_2_-_201412291130_-_nsa_points_of_presence_in_at_-_erich_moechel">
<img alt="NSA Points of Presence in AT" src="https://static.media.ccc.de/media/congress/2014/6430-hd.jpg" title="NSA Points of Presence in AT">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6265_-_en_-_saal_6_-_201412281600_-_the_automobile_as_massive_data_gathering_source_and_the_consequences_for_individual_privacy_-_jimmy_schulz_-_dr_rudiger_hanig">
<img alt="The automobile as massive data gathering source and the consequences for individual privacy" src="https://static.media.ccc.de/media/congress/2014/6265-hd.jpg" title="The automobile as massive data gatherin…">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6595_-_en_-_saal_1_-_201412281900_-_hard_drive_punch_-_aram_bartholl">
<img alt="»Hard Drive Punch«" src="https://static.media.ccc.de/media/congress/2014/6595-hd.jpg" title="»Hard Drive Punch«">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6530_-_en_-_saal_6_-_201412272145_-_in_security_of_mobile_banking_-_ericfiliol_-_paul_irolla">
<img alt="(In)Security of Mobile Banking" src="https://static.media.ccc.de/media/congress/2014/6530-hd.jpg" title="(In)Security of Mobile Banking">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6602_-_en_-_saal_1_-_201412301130_-_the_case_of_chelsea_manning_-_alexa_o_brien_-_nancy_hollander_-_ahmed_ghappour_-_chase_strangio">
<img alt="The case of Chelsea Manning" src="https://static.media.ccc.de/media/congress/2014/6602-hd.jpg" title="The case of Chelsea Manning">
</a>
</p>
<p><a href="https://media.ccc.de/v/33c3-8068-state_of_internet_censorship_2016">
<img alt="State of Internet Censorship 2016" src="https://static.media.ccc.de/media/congress/2016/8068-hd.jpg" title="State of Internet Censorship 2016">
</a>
</p>
</div>
</div>

<!-- %h3 Embed/Share -->

<h3>Tags</h3>
<div>
<p><a href="https://media.ccc.de/c/31c3/Ethics,%20Society%20&amp;%20Politics" rel="tag">Ethics, Society &amp; Politics</a>
</p></div>
</div></div>]]>
            </description>
            <link>https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford#t=2215</link>
            <guid isPermaLink="false">hacker-news-small-sites-24155374</guid>
            <pubDate>Fri, 14 Aug 2020 08:34:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Save Mozilla]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24155372">thread link</a>) | @caisah
<br/>
August 14, 2020 | http://dpk.io/savemozilla | <a href="https://web.archive.org/web/*/http://dpk.io/savemozilla">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  
</header>

<p><i>Disclaimer: I’m not a current or former Mozilla employee and have no other affiliation with Mozilla.</i> This is my own analysis of the publically-available information surrounding Mozilla’s decision to <a href="https://blog.mozilla.org/blog/2020/08/11/changing-world-changing-mozilla/">radically downsize</a> in a way that seems to further threaten Firefox’s future.

</p><p>A lot of people are very angry at Mozilla’s management for their decision to restructure the foundation, which is <a href="https://twitter.com/withoutboats/status/1217558588857544704">not unreasonable.</a> But seen in context, I think most people would, if in their position, make the same decision.

</p><p>Why is Mozilla cutting staff on its most popular product (Firefox) and refocusing on things that look like unsuccessful stunt projects? <a href="https://medium.com/swlh/could-google-crush-firefox-in-2020-13a55b5d4526">Because they’re about to lose the revenue from it.</a> <em>Google</em> is to blame for not renewing the contract that gives Mozilla a share of the ad revenue from the Firefox search bar. The web browser market has been walking on thin ice since 2008 when Chrome came out, because with Chrome available and under its own control, Google no longer had a reason to support the ecosystem with revenue-sharing deals. Now it seems like Google wants to see just how thin it can make the ice before Mozilla goes under.

</p><p>And why are they focussing on products nobody uses? Because they can make money by selling VPN subscriptions and premium bookmarking accounts without depending on the (obviously limited) goodwill of their competitors.

</p><p>What can you do about this? Here are some suggestions:

</p><ul>
  <li><strong>Buy one of Mozilla’s other products.</strong> It might seem like validating the bad decision made by Mozilla management, but it is reasonable to hope that income from, say, Mozilla VPN might be enough to keep a rag-tag Firefox team going.
  </li><li><strong>Just straight up <a href="https://donate.mozilla.org/">donate to Mozilla.</a></strong> Remember, Mozilla is a non-profit organization. While Google is developing Chrome to strengthen its bottom line and pay out more to shareholders, Mozilla’s interest in the Web platform is actually public-spirited. They fought against DRM in HTML and the mandatory use of patent-encumbered technologies on the open web, and when these efforts failed (largely for the same reasons Google is now able to crush Firefox entirely) they adopted laudable compromises, giving their users a genuine choice about using these technologies. And more than that&nbsp;—&nbsp;they’re actively participating in projects to create new, widely-supported and superior alternatives to these problematic technologies for the future. The web would be a worse place without Mozilla, and for that they deserve your goodwill.
  </li><li><strong>Write to your lawmaker urging an investigation into Google’s anti-competitive practices</strong> in the web browser and web markup space. This could be particularly effective if you live in the EU and write to your European Parliamentarians. Google is probably counting on the Trump administration not caring about their blatant repeat of Microsoft’s anti-trust violations&nbsp;— but other major jurisdictions which still have functioning regulatory systems can make a difference.
  </li><li><strong>Actually use Firefox, or one of its derivatives like the Tor Browser.</strong> One reason Google feels able to do this is probably because of Firefox’s shrinking market share. But Firefox is a vital part of the browser ecosystem, not least as the only major browser left that isn’t based on a WebKit-derivative engine, and as a hackable open-source browser that’s a vital component of equally-vital privacy projects like Tor. And Firefox still has really great features, especially for web developers. Switch back to Firefox&nbsp;— especially if you’re on Chrome!
  </li><li><strong>Switch away from Google products as much as possible.</strong> I know that other web search engines are still embarrassingly bad&nbsp;—&nbsp;I’m not here to guilt-trip anyone into using DuckDuckGo. But if you use Gmail, stop. There are <a href="https://www.fastmail.com/">fantastic</a> <a href="https://protonmail.com/">alternatives</a> out there which, yes, filter spam just as well as Gmail does these days. Use Apple Maps or OpenStreetMap or Yelp instead of Google Maps. Run an ad blocker that blocks YouTube ads, and support your favourite YouTubers directly over Patreon instead.
</li></ul>


</div>]]>
            </description>
            <link>http://dpk.io/savemozilla</link>
            <guid isPermaLink="false">hacker-news-small-sites-24155372</guid>
            <pubDate>Fri, 14 Aug 2020 08:34:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Epic fight against app store monopolies (Epic Games)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24154938">thread link</a>) | @simplertms
<br/>
August 14, 2020 | https://4thquadrant.io/snippets/snippet-the-epic-fight-against-app-store-monopolies/ | <a href="https://web.archive.org/web/*/https://4thquadrant.io/snippets/snippet-the-epic-fight-against-app-store-monopolies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_27_388">

<div>
<p>Epic Games introduced an update to their mobile (iOS and Android) version of Fortnite that allows users to buy directly from Epic Games at a 20% discount, removing incentives to pay with the officially sanctioned payment systems on the App Store and Play Store.&nbsp;</p>



<p>Soon after this update, Apple removed Fortnite from its App Store, Google was not far behind in doing the same. In response, Epic Games has filed individual suits against both tech giants claiming that their behaviour is monopolistic control over their respective ecosystems. However, there is some nuance and differences that we should explore between the two ecosystems that could have implications for the validity of the anti-trust lawsuits that Epic will have to contend with.&nbsp;</p>



<p>Looking at the two ecosystems holistically, it is perhaps more appropriate in this case to think of Android and iOS as marketplaces rather than solely focusing on their function as operating systems. The contention is that the marketplaces are being monopolised and controlled to the disadvantage of developers. This is especially true of Apple iOS, where the entire OS is a marketplace, where the App Store is the only access point for third-party applications to the ecosystem. If an application is removed from the App Store, the third-party application simply cannot exist on the iOS ecosystem.&nbsp;</p>



<p>Comparatively, Google’s Android OS functions a little differently. The OS acts as an open ecosystem which is augmented by the Play Store. The Play Store, not the OS, is the marketplace – the place for discovery. The Play Store as a standalone application can have comparative and competitive marketplaces on the Android OS, like the Samsung store. Further, the Android OS allows for third-party installs of applications albeit with security warnings.&nbsp;</p>



<p>Epic might have a hard time arguing that Google is being anti-competitive when it has avenues of access – albeit less direct – outside of the Google Play Store. Applications can still exist within the Android ecosystem even when the Play Store removes listings according to their marketplace rules.</p>



<p>Apple, on the other hand, has its entire ecosystem siloed as a marketplace, with no third-party marketplaces allowed and no ability to legally install third-party applications – placing them in a much more difficult position when it comes to anti-competitive claims. In recent months, Apple has come under increasing scrutiny as they butt heads with application developers, most notably Hey email client, Google’s Stadia platform and Microsoft’s xCloud platform.&nbsp;</p>



<div id="slimcalltoaction"><p>This is box title</p><p>If you enjoyed this article, take advantage of our 14 days free trial to explore our exclusive content. Or sign-up for our free weekly newsletters. View our subscription options <a href="https://4thquadrant.io/subscribe">here.</a></p></div>
</div></div><div data-td-block-uid="tdi_28_f25">

<div><h3><span>CONTACT THE EDITOR</span></h3>
<p>We welcome thoughtful discourse on all our content. If you would like to further explore or discuss any of the ideas covered in this article please contact our editors directly.<br><span>Contact Details</span></p>
</div></div></div>]]>
            </description>
            <link>https://4thquadrant.io/snippets/snippet-the-epic-fight-against-app-store-monopolies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154938</guid>
            <pubDate>Fri, 14 Aug 2020 07:33:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Rust Lambdas in Production]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24154506">thread link</a>) | @lukastyrychtr
<br/>
August 13, 2020 | https://www.cvpartner.com/blog/using-rust-lambdas-in-production | <a href="https://web.archive.org/web/*/https://www.cvpartner.com/blog/using-rust-lambdas-in-production">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure id="w-node-c687bec1ed8c-01d6604b"><p><img src="https://assets.website-files.com/56d31f469aaa616f5089a267/5f23ffebdba110f2cab1d06d_Rust%20Lambda.png" alt=""></p></figure><div><p>Update:&nbsp;Join the discussion over at <a href="https://news.ycombinator.com/item?id=24154506">HackerNews</a>! </p><p>We’ve written in the past about how the CV Partner web application is written in Ruby on Rails. The web application isn’t the whole story, though. Surrounding it are many supporting services, and we are increasingly using Rust to write these services.</p></div><p>We’re also using more Lambdas in our architecture, and we want to use Rust in those as well. The landscape for Rust lambdas isn’t barren, but it’s not well-trodden either.<br></p><p>This post is going to cover how we write, build, and deploy our Rust lambdas. Our lambdas have the following qualities that we’re proud of and want to share with you:<br></p><ol role="list"><li><strong>Fast, standardised build.</strong> All of our lambdas use the same Dockerfile to build, and make good use of Docker’s layer caching. Incremental builds in CI take under a minute.</li><li><strong>Run locally. </strong>If you’re working on a lambda, you don’t want to have to sit through a CI build to see if your changes work. All of our lambdas can run locally and in AWS using the same code.</li><li><strong>Private GitHub dependencies. There aren’t many options out there for private Cargo repositories, so we use private GitHub repositories for our internal libraries.</strong></li></ol><h2>The code<br></h2><p>The starting point for writing a Lambda in Rust is to use the official <a href="https://github.com/awslabs/aws-lambda-rust-runtime">Rust lambda runtime</a>. At the time of writing, the last release of this library is version 0.2, which doesn’t support async/await. Async/await support is present in master, though. Here’s how it looks in practice:</p><div><pre><code>
use lambda::{lambda, Context};
use serde_json::Value;

type Error = Box<dyn std::error::error="" +="" send="" sync="" 'static="">;

#[lambda]
#[tokio::main]
async fn main(event: Value, _: Context) -&gt; Result<value, error=""> {
    Ok(event)
}

</value,></dyn></code></pre></div><p>The problem with this is that you can’t run it locally. The #[lambda] attribute wraps your main function in another main function that calls in to the AWS lambda API.<br></p><p>To get around this, we write two main functions:<br></p><div><pre><code>

#[cfg(feature = "with-lambda")]
use lambda::{lambda, Context};
use serde::{Deserialize, Serialize};

type Error = Box<dyn std::error::error="" +="" send="" sync="" 'static="">;

#[derive(Deserialize, Debug)]
struct Input {
    name: String
}

#[derive(Serialize, Debug)]
struct Output {
    greeting: String
}

async fn handler(input: Input) -&gt; Result<output, error=""> {
    Ok(Output { greeting: format!(“Hello, {}!”, input.name) })
}

#[cfg(feature = "with-lambda")]
#[lambda]
#[tokio::main]
async fn main(input: Input, _: Context) -&gt; Result<output, error=""> {
    handler(input).await
}

#[cfg(not(feature = "with-lambda"))]
#[tokio::main]
async fn main() -&gt; Result&lt;(), Error&gt; {
    let input_str = std::env::args().nth(1);
    if input_str.is_none() {
        panic!(
            "you must pass an input parameter as the first argument, and it must be a JSON string"
        );
    }
    let input = serde_json::from_str(&amp;input_str.unwrap())?;
    let output = handler(input).await?;
    println!("{}", serde_json::to_string(&amp;output)?);
    Ok(())
}

</output,></output,></dyn></code></pre></div><p>We’re making use of Rust’s “feature” flags to compile a different harness around the handle function depending on whether we want to run locally or in AWS.</p><p>Here’s the Cargo.toml file:</p><div><pre><code>
[package]
name = "rust-lambda-template"
version = "0.1.0"
authors = ["Sam Rose <sam@cvpartner.com>"]
edition = "2018"

[dependencies]
lambda = { git = "https://github.com/awslabs/aws-lambda-rust-runtime/", rev = "c8dbcd39e0b1cf9ecf395e2b2f9df6c6c0d97780" }
tokio = { version = "0.2", features = ["full"] }
serde = { version = "1", features = ["derive"] }
serde_derive = "1"
serde_json = "1"

[features]
with-lambda = []

</sam@cvpartner.com></code></pre></div><p>Two noteworthy things:<br></p><ol role="list"><li>We’re using a version of the aws-lambda-rust-runtime that hasn’t officially been released. This isn’t ideal, and we’re eagerly awaiting a 0.3 release.</li><li>We have a features section, which is where we define the with-lambda feature we use in the Rust code shown above.<br></li></ol><p>Running our lambda now gives us the following:</p><div><pre><code>
$ cargo run -- ‘{ “name”: “Sam” }’
{ “message”: “Hello, Sam!” }

</code></pre></div><h2><strong>The Dockerfile</strong></h2><p>All of our lambdas build with the same Dockerfile. I’ll show it in all of its glory and then explain what’s going on bit by bit. Brace yourself.</p><div><pre><code>
# syntax=docker/dockerfile:experimental

FROM rust:latest as cargo-build
ARG name

RUN apt-get update
RUN apt-get install musl-tools -y
RUN rustup target add x86_64-unknown-linux-musl

WORKDIR /usr/src/${name}
COPY Cargo.toml Cargo.toml
RUN mkdir src/
RUN echo "fn main() {println!(\"if you see this, the build broke\")}" &gt; src/main.rs
RUN mkdir -p $HOME/.ssh
RUN ssh-keyscan github.com &gt; $HOME/.ssh/known_hosts
RUN test "$(cat $HOME/.ssh/known_hosts | ssh-keygen -lf -)" = "2048 SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8 github.com (RSA)"
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

RUN rm src/main.rs
COPY src/* src
RUN touch src/**
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo test --features with-lambda --release --target=x86_64-unknown-linux-musl
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

FROM alpine:latest
ARG name
COPY --from=cargo-build /usr/src/${name}/target/x86_64-unknown-linux-musl/release/${name} /usr/local/bin/${name}

</code></pre></div><p>First of all, shout out to Shane Utt whose <a href="https://shaneutt.com/blog/rust-fast-small-docker-image-builds/">blog post</a> we used as a starting point for this.<br></p><p>The first line is a Docker directive that says we want to use some experimental Dockerfile syntax. The syntax in question is the --mount=type=ssh flag to the RUN commands, but we’ll talk about later.</p><div><pre><code>
FROM rust:latest as cargo-build
ARG name

</code></pre></div><p>This next bit says we want to use the latest Rust image, and we’re passing in a build arg called “name.” This is how we’re able to share this Dockerfile between all of our lambdas without having to modify it.</p><div><pre><code>
RUN apt-get update
RUN apt-get install musl-tools -y
RUN rustup target add x86_64-unknown-linux-musl

</code></pre></div><p>Next we run an update on the image, and we install <a href="https://musl.libc.org/">musl</a>. If you’re not familiar, musl is a libc replacement that you can link to statically. This means the resulting binary won’t depend on the system’s libc, which makes it more portable. It’s not a strict requirement for running on AWS Lambda, but it’s good practice.</p><div><pre><code>
WORKDIR /usr/src/${name}
COPY Cargo.toml Cargo.toml
RUN mkdir src/
RUN echo "fn main() {println!(\"if you see this, the build broke\")}" &gt; src/main.rs

</code></pre></div><p>The next few lines set up a pseudo project, where the only things we’re going to compile are our dependencies and a dummy main.rs. The idea behind this is to use Docker’s layer caching to avoid having to compile our dependencies every build. This leads to significantly faster incremental builds in Docker.</p><div><pre><code>
RUN mkdir -p $HOME/.ssh
RUN ssh-keyscan github.com &gt; $HOME/.ssh/known_hosts
RUN test "$(cat $HOME/.ssh/known_hosts | ssh-keygen -lf -)" = "2048 SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8 github.com (RSA)"

</code></pre></div><p>Up until now, we’ve done exactly what Shane Utt did in his version of this. These three lines, though, are new. Because we use SSH to fetch private dependencies (more on this later), we would sometimes find that our builds would fail with the error “host key verification failed.” To get around that we pull down GitHub’s host keys and make sure they’re what we expect them to be based on the values <a href="https://docs.github.com/en/github/authenticating-to-github/githubs-ssh-key-fingerprints">here</a>.</p><div><pre><code>
RUN mkdir -p $HOME/.ssh
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

</code></pre></div><p>Our first bit of experimental syntax! The --mount flag is a new thing introduced with the BuildKit engine for Docker, you can read about it in depth <a href="https://medium.com/@tonistiigi/build-secrets-and-ssh-forwarding-in-docker-18-09-ae8161d066">here</a>. The type=ssh bit is us telling Docker that we want to use an SSH agent for this command. In the docker build invocation, which we’ll see later, we can tell Docker what keys to add to this SSH agent.</p><p>The reason we do this is because it was the only way we could find that let us depend on private GitHub repositories in our Cargo.toml file, in a way that worked both locally and in CI. It means we can do this in our Cargo.toml file:</p><div><pre><code>
[dependencies]
private-library = { git = "ssh://github.com/cvpartner/private-library", tag = "1.0" }

</code></pre></div><p>And it Just Works<strong>™</strong>.</p><p>The rest of the RUN command is our first cargo build. It looks a lot scarier than it is. Most of it is us telling rustc to link against musl instead of the default libc. The only other interesting bit is the --features with-lambda. This matches up with the code we saw earlier to produce a binary that’s going to work properly when deployed in AWS.</p><div><pre><code>
RUN rm src/main.rs
COPY src/* src
RUN touch src/**
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo test --features with-lambda --release --target=x86_64-unknown-linux-musl
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

</code></pre></div><p>Next up, we’re copying over our actual source code. The touch command is necessary for cargo to realise the files are new, because when we created our dummy main.rs file earlier we created a new file with a timestamp later than the one on the real main.rs file. This is different to the approach taken by Shane Utt, as we found that approach would often result in builds where the dummy main.rs file was the one that ended up in the final build.</p><p>Another addition is the cargo test invocation. Tests are good!</p><div><pre><code>
FROM alpine:latest
ARG name
COPY --from=cargo-build /usr/src/${name}/target/x86_64-unknown-linux-musl/release/${name} /usr/local/bin/${name}

</code></pre></div><p>Lastly we create a new build stage and copy over the final executable. The new build stage is in order to keep the final image small. Ours tend to clock in at around 8MB.<br></p><h2><strong>The build script</strong><br></h2><p>Invoking Docker is done in a shell script which is also identical for all of our lambdas.</p><div><pre><code>
#!/usr/bin/env bash

set -e
set -x

DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" &amp;&amp; pwd )"
cd $DIR

NAME=$(cat Cargo.toml | grep "name" | head -n 1 | sed -E 's/name = "(.*)"/\1/')
DOCKER_NAME="cvpartner/$NAME"

if [[ -z $BUILD_ID ]];
then
  TAG=$DOCKER_NAME
  SSH="--ssh default"
else
  TAG="our.private.docker.registry/$DOCKER_NAME"
  SSH="--ssh default=/home/ci/.ssh/id_rsa"
fi

DOCKER_BUILDKIT=1 docker build $SSH --cache-from $TAG …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cvpartner.com/blog/using-rust-lambdas-in-production">https://www.cvpartner.com/blog/using-rust-lambdas-in-production</a></em></p>]]>
            </description>
            <link>https://www.cvpartner.com/blog/using-rust-lambdas-in-production</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154506</guid>
            <pubDate>Fri, 14 Aug 2020 06:39:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing a Type-safe printf in Rust]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24154263">thread link</a>) | @lukastyrychtr
<br/>
August 13, 2020 | https://willcrichton.net/notes/type-safe-printf/ | <a href="https://web.archive.org/web/*/https://willcrichton.net/notes/type-safe-printf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>
    
    Will Crichton
    
    &nbsp; — &nbsp;
    June 21, 2020
  </p>
  <p>I show how to use heterogeneous lists and traits to implement a type-safe printf in Rust. These mechanisms can ensure that two variadic argument lists share important properties, like the number of format string holes matches the number of printf arguments.</p>
  <p><em>Part of an ongoing series about type-level programming in Rust. Consider reading <a href="http://willcrichton.net/notes/type-level-programming/">part one</a> first! All code in this note can be found in <a href="https://gist.github.com/willcrichton/e7fcf1b0e84b4be7f172f0e0245cf149">this gist</a>.</em></p>

<p>Rust has a great printf function, <a href="https://doc.rust-lang.org/std/macro.println.html"><code>println!</code></a>. It has a rich formatting language, but also catches mistakes at compile-time. For example, <code>println!</code> will check that the number of arguments matches the number of holes in the format string:</p>

<div><div><pre><code>error: 2 positional arguments in format string, but there is 1 argument
  --&gt; src/printf.rs:36:13
   |
36 |   println!("{} {}", "Hello");
</code></pre></div></div>

<p>How does the Rust compiler make this check? Because both the format string and the argument are within the macro, Rust will check that the number of holes matches the number of arguments. Consequently, format strings <em>have</em> to be within the macro. If we write:</p>

<div><div><pre><code><span>let</span> <span>s</span> <span>=</span> <span>"{} {}"</span><span>;</span>
<span>println!</span><span>(</span><span>s</span><span>,</span> <span>"hi"</span><span>)</span>
</code></pre></div></div>

<p>This code fails to compile with the error:</p>

<div><div><pre><code>error: format argument must be a string literal
  --&gt; src/printf.rs:42:12
   |
42 |   println!(s, "hi");
</code></pre></div></div>

<p>I’ll show you how to implement type-safe printf without using procedural macros. More generally, this note contains a Rust recipe for functions where:</p>

<ol>
  <li>Arguments are variadic</li>
  <li>Each argument can be a different type (<code>Vec&lt;T&gt;</code> not allowed)</li>
  <li>Multiple variadic inputs share a parallel property, e.g. the number of arguments should match the number of format holes</li>
</ol>

<h2 id="core-mechanism-hlist">Core mechanism: HList</h2>

<p>First, we need to understand the main type-level mechanism: a heterogeneous list (or H-list). An H-list is a sequence of values of potentially different types. For example, <code>[1, "a", true]</code> is an H-list, but not a valid Rust vector. H-lists are implemented in Rust using a linked-list style:</p>

<div><div><pre><code><span>struct</span> <span>HNil</span><span>;</span>
<span>struct</span> <span>HCons</span><span>&lt;</span><span>Head</span><span>,</span> <span>Tail</span><span>&gt;</span> <span>{</span>
  <span>head</span><span>:</span> <span>Head</span><span>,</span>
  <span>tail</span><span>:</span> <span>Tail</span>
<span>}</span>

<span>let</span> <span>example</span><span>:</span> <span>HCons</span><span>&lt;</span><span>i32</span><span>,</span> <span>HCons</span><span>&lt;</span><span>bool</span><span>,</span> <span>HNil</span><span>&gt;&gt;</span> <span>=</span>
  <span>HCons</span><span>{</span><span>head</span><span>:</span> <span>1</span><span>,</span> <span>tail</span><span>:</span> <span>HCons</span><span>{</span><span>head</span><span>:</span> <span>true</span><span>,</span> <span>tail</span><span>:</span> <span>HNil</span><span>}};</span>
</code></pre></div></div>

<p>The key idea is that the type of an H-list changes every time you make a change to it. By contrast, if you push to a <code>Vec&lt;T&gt;</code>, the type of the vector stays the same.</p>

<p>Just like Rust has <code>vec![]</code>, we can use the <a href="https://github.com/lloydmeta/frunk#hlist">frunk</a> crate to get an <code>hlist!</code> macro.</p>

<div><div><pre><code><span>let</span> <span>example</span> <span>=</span> <span>hlist!</span><span>[</span><span>1</span><span>,</span> <span>true</span><span>];</span> <span>// same as above</span>
</code></pre></div></div>

<h2 id="setting-up-printf">Setting up printf</h2>

<p>Let’s go back to the ingredients of printf. We need a format string and an argument list. The key idea is to represent both with an H-list, and carefully use Rust’s traits to ensure our desired property: the number of arguments should match the number of holes.</p>

<p>First, to represent format strings, we will have a sequence of structs that represent each part of the string.</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>FString</span><span>(</span><span>&amp;</span><span>'static</span> <span>str</span><span>);</span>
<span>pub</span> <span>struct</span> <span>FVar</span><span>;</span>

<span>// Assume that we compile "Hello {}! The first prime is {}" into this code.</span>
<span>// That would be a simple syntactic transformation.</span>
<span>let</span> <span>example</span> <span>=</span> <span>hlist!</span><span>[</span>
  <span>FString</span><span>(</span><span>"Hello "</span><span>),</span> <span>FVar</span><span>,</span> <span>FString</span><span>(</span><span>"! The first prime is "</span><span>),</span> <span>FVar</span>
<span>];</span>
</code></pre></div></div>

<p>To represent arguments, we will use a matching H-list of values. For example:</p>

<div><div><pre><code><span>let</span> <span>args</span> <span>=</span> <span>hlist!</span><span>[</span><span>"world"</span><span>,</span> <span>2</span><span>];</span>
</code></pre></div></div>

<p>Then, our goal is to create a function <code>format</code> such that this is true:</p>

<div><div><pre><code><span>assert_eq!</span><span>(</span>
  <span>example</span><span>.format</span><span>(</span><span>args</span><span>),</span>
  <span>"Hello world! The first prime is 2"</span>
<span>);</span>
</code></pre></div></div>

<p>And this should be a compile-time (NOT run-time) error:</p>

<div><div><pre><code><span>example</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"Only one arg"</span><span>]);</span>
</code></pre></div></div>

<h2 id="the-format-trait">The Format trait</h2>

<p>In the spirit of type-level computation, we start by defining a trait.</p>

<div><div><pre><code><span>trait</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span> <span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>ArgList</span><span>)</span> <span>-&gt;</span> <span>String</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Here, <code>self</code> is the H-list of the format directives, and <code>ArgList</code> is the H-list of the variadic arguments. <code>Format</code> need to take <code>ArgList</code> as a type parameter, because its type will change as we remove elements from the <code>ArgList</code> list.</p>

<p>Now, we proceed to implement the <code>Format</code> trait by cases. First, the base case for reaching the end of the format list <code>HNil</code>:</p>

<div><div><pre><code><span>impl</span> <span>Format</span><span>&lt;</span><span>HNil</span><span>&gt;</span> <span>for</span> <span>HNil</span> <span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>_</span><span>args</span><span>:</span> <span>HNil</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>""</span><span>.to_string</span><span>()</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This impl says that when we reach the end of a format list, just return the empty string. And the only argument we will accept is an empty argument list. Combined with the next impls, this inductively ensures that extra arguments are not accepted.</p>

<p>Next, we will implement <code>FString</code>. This implementation should use the string constant contained in the <code>FString</code> struct, and combine it recursively with the rest of the format list. We don’t use variadic arguments for <code>FString</code>, so they get passed along. In Rust, this English specification becomes:</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>ArgList</span><span>,</span> <span>FmtList</span><span>&gt;</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span>
<span>for</span> <span>HCons</span><span>&lt;</span><span>FString</span><span>,</span> <span>FmtList</span><span>&gt;</span>
<span>where</span> <span>FmtList</span><span>:</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span>
<span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>ArgList</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>self</span><span>.head</span><span>.</span><span>0</span><span>.to_owned</span><span>()</span> <span>+</span> <span>&amp;</span><span>self</span><span>.tail</span><span>.format</span><span>(</span><span>args</span><span>)</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Note that we have to add <code>FmtList: Format&lt;ArgList&gt;</code> to ensure the recursive call to <code>self.tail.format</code> works. Also note that we aren’t implementing <code>Format</code> directly on <code>FString</code>, but rather on an H-list containing <code>FString</code>.</p>

<p>Finally, the most complex case, <code>FVar</code>. We want this impl to take an argument from the <code>ArgList</code>, then format the remaining format list with the remaining arguments.</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>,</span> <span>FmtList</span><span>&gt;</span> <span>Format</span><span>&lt;</span><span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;&gt;</span>
<span>for</span> <span>HCons</span><span>&lt;</span><span>FVar</span><span>,</span> <span>FmtList</span><span>&gt;</span>
<span>where</span>
  <span>FmtList</span><span>:</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span><span>,</span>
  <span>T</span><span>:</span> <span>ToString</span><span>,</span>
<span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>args</span><span>.head</span><span>.to_string</span><span>()</span> <span>+</span> <span>&amp;</span><span>self</span><span>.tail</span><span>.format</span><span>(</span><span>args</span><span>.tail</span><span>)</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Be careful to observe which H-list is being accessed by <code>head</code> and <code>tail</code>. Here, the <code>args</code> H-list provides the data to fill the hole via <code>args.head</code>.</p>

<h2 id="checking-our-properties">Checking our properties</h2>

<p>With this implementation, our correct example successfully compiles and runs:</p>

<div><div><pre><code><span>let</span> <span>example</span> <span>=</span> <span>hlist!</span><span>[</span>
  <span>FString</span><span>(</span><span>"Hello "</span><span>),</span> <span>FVar</span><span>,</span> <span>FString</span><span>(</span><span>"! The first prime is "</span><span>),</span> <span>FVar</span>
<span>];</span>
<span>assert_eq!</span><span>(</span>
  <span>example</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"world"</span><span>,</span> <span>2</span><span>]),</span>
  <span>"Hello world! The first prime is 2"</span>
<span>);</span>
</code></pre></div></div>

<p>What about our incorrect example? If we write this:</p>

<div><div><pre><code><span>example</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"just one arg"</span><span>]);</span>
</code></pre></div></div>

<p>This code fails to compile with the error:</p>

<div><div><pre><code>error[E0308]: mismatched types
  --&gt; src/printf.rs:48:18
   |
48 |   example.format(hlist!["just one arg"]);
   |                  ^^^^^^^^^^^^^^^^^^^^^^
   |                  expected struct `Cons`, found struct `HNil`
   |
   = note: expected struct `HCons&lt;_, HNil&gt;`
              found struct `HNil`
</code></pre></div></div>

<p>While the error is enigmatic, our mistake is at least correctly caught at compile-time. This is because Rust deduces that <code>example.format()</code> expects an H-list of the shape <code>HCons&lt;_, HCons&lt;_, HNil&gt;&gt;</code>, but it finds <code>HNil</code> too soon in our 1-element H-list. A similar error occurs when providing too many args.</p>

<p>Stupendous! We have successfully implemented a type-safe printf using H-lists and traits.</p>

<h2 id="extending-our-abstraction">Extending our abstraction</h2>

<p>Right now, our <code>Format</code> function just checks that the format list and argument list are the same length. We could extend our format structures, for example to ensure that an <code>FVar</code> must be a particular type, or must use <code>Debug</code> vs. <code>Display</code>. Here’s the sketch of such a strategy:</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>PhantomData</span><span>;</span>

<span>// Add flags for whether using Display or Debug</span>
<span>pub</span> <span>struct</span> <span>FDisplay</span><span>;</span>
<span>pub</span> <span>struct</span> <span>FDebug</span><span>;</span>

<span>// Use a type parameter with PhantomData to represent the intended type</span>
<span>pub</span> <span>struct</span> <span>FVar</span><span>&lt;</span><span>T</span><span>,</span> <span>Flag</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>(</span><span>T</span><span>,</span> <span>Flag</span><span>)</span><span>&gt;</span><span>);</span>

<span>// Now, T has to be the same between the format list and arg list</span>
<span>// Also, FDisplay flag requires that `T: Display`</span>
<span>impl</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>,</span> <span>FmtList</span><span>&gt;</span> <span>Format</span><span>&lt;</span><span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;&gt;</span>
<span>for</span> <span>HCons</span><span>&lt;</span><span>FVar</span><span>&lt;</span><span>T</span><span>,</span> <span>FDisplay</span><span>&gt;</span><span>,</span> <span>FmtList</span><span>&gt;</span>
<span>where</span>
  <span>FmtList</span><span>:</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span><span>,</span>
  <span>T</span><span>:</span> <span>Display</span><span>,</span>
<span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>// using format! is cheating, but you get the idea</span>
    <span>format!</span><span>(</span><span>"{}"</span><span>,</span> <span>args</span><span>)</span> <span>+</span> <span>&amp;</span><span>self</span><span>.tail</span><span>.format</span><span>(</span><span>args</span><span>.tail</span><span>)</span>
  <span>}</span>
<span>}</span>

<span>// Similar impl for `T: Debug` when `FDebug` is used</span>
</code></pre></div></div>

<p>With this approach, if our format list and arg list differ in type:</p>

<div><div><pre><code><span>let</span> <span>fmt</span> <span>=</span> <span>hlist!</span><span>[</span><span>FString</span><span>(</span><span>"n: "</span><span>),</span> <span>FVar</span><span>::</span><span>&lt;</span><span>i32</span><span>,</span> <span>FDisplay</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>)];</span>
<span>fmt</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"not a number"</span><span>]);</span>
</code></pre></div></div>

<p>Then the code will not compile with the error, <code>&amp;'static str is not i32</code>.</p>

<p>Shout-out to <a href="https://www.servant.dev/posts/2018-07-12-servant-dsl-typelevel.html">this blog post</a> from Haskell’s servant framework which got me thinking about adapting their strategy into Rust.</p>

</div></div>]]>
            </description>
            <link>https://willcrichton.net/notes/type-safe-printf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154263</guid>
            <pubDate>Fri, 14 Aug 2020 06:07:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Save the USPS]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 206 (<a href="https://news.ycombinator.com/item?id=24153311">thread link</a>) | @mooreds
<br/>
August 13, 2020 | https://2pml.com/2020/08/10/usps/ | <a href="https://web.archive.org/web/*/https://2pml.com/2020/08/10/usps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-12653">
	<!-- .entry-header -->

	<div>
		<p><img data-attachment-id="12682" data-permalink="https://2pml.com/2020/08/10/usps/cvbbjbi0/" data-orig-file="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?fit=1600%2C1144&amp;ssl=1" data-orig-size="1600,1144" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cVBbjbi0" data-image-description="" data-medium-file="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?fit=300%2C215&amp;ssl=1" data-large-file="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?fit=740%2C529&amp;ssl=1" loading="lazy" src="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=740%2C529&amp;ssl=1" alt="cVBbjbi0" width="740" height="529" srcset="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?w=1600&amp;ssl=1 1600w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=300%2C215&amp;ssl=1 300w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=1024%2C732&amp;ssl=1 1024w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=768%2C549&amp;ssl=1 768w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=1536%2C1098&amp;ssl=1 1536w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?w=1480&amp;ssl=1 1480w" sizes="(max-width: 740px) 100vw, 740px" data-recalc-dims="1"></p>
<p>There are three types of infrastructure. One is visible: roads, dams and bridges. The second is invisible: broadband internet provisions and the entirety of our cellular infrastructure. Both are still vital in building our present. The third form of infrastructure is one being rebuilt in order to be repurposed for future use. I explained in <em>J-Curves and Agglomeration</em>:</p>
<blockquote><p>The U.S. Postal Service is a key component of the eCommerce economy. Packages are just 5% of its shipping volume but eCommerce accounts for nearly 30% of the agency’s revenue. Partnerships with vendors like Amazon (or providers like FedEx and UPS) provide a majority of its package volume but small businesses and direct-to-consumer brands rely on USPS’ pricing. Raising costs on retailers may lead to more attrition. […]</p>
<p>By raising prices to combat Amazon’s growing influence over the economy, disrupting the postal economy is no different than digging up paved roads before a period of heightened freight transit. [<a href="https://2pml.com/2020/05/18/agglomeration/">2PM, 1</a>]</p></blockquote>
<p>The U.S. Postal Service is all three. When an American institution is 250 years old, it may as well be the ground that we stand on. The service has contributed services and innovations that we don’t readily attribute to it. Consider its contribution to the middle class: the U.S. Postal Service is one the country’s biggest employers with nearly 330,000 career employees and an average salary of $50,000. They are building the future of eCommerce, a still-nascent industry.</p>
<p>Critics of the USPS will cite cost of labor as a reason for the service’s obsolescence. A common refrain is “Why couldn’t Amazon takeover the service?” Consider that in the fourth quarter of 2019, eCommerce was just 11.9% of all retail. Amazon constituted right under half of that volume. And without the postal service, Amazon would not exist. The market costs of shipment subsidized a number of Amazon’s operations, allowing it to capture market share.</p>
<h2>“The Ground We Stand On”</h2>
<p>The postal service began before the founding of the United States. Benjamin Franklin was fired from his role as postmaster due to his involvement with the American Revolution. Just one year later in 1775, the Continental Congress appointed Franklin the Postmaster General of the “United Colonies.” His tenure left a mail system that offered service between the then-colonies and Great Britain. By 1802, the first African-Americans to work for the Postal Service were enslaved mail carriers. Senator James Jackson of Georgia, Chairman of the Committee of the Senate on the Post Office Establishment, once wrote:</p>
<blockquote><p>… The most active and intelligent [slaves] are employed as post riders. By travelling from day to day, and hourly mixing with people […] they will acquire information. They will learn that a man’s rights do not depend on his color. They will, in time, become teachers to their brethren.</p></blockquote>
<p>Within two months of Senator Jackson’s proclamation, African-Americans would be banned from the postal service, lasting from 1802 to March 1865, just one month before the conclusion of the Civil War. This disbarment ended by congressional decree.</p>
<blockquote><p>No person, by reason of color, shall be disqualified from employment in carrying the mails. (13 Stat. 515)</p></blockquote>
<p>The next decades would see an unparalleled push for African-American financial stability. Nearly 800 would serve as postal employees prior to the 20th century. More than 200 African Americans are known to have served in the high rank of postmaster prior to the conclusion of Reconstruction and the Progressive Era (1863-1920). Of them, nearly 20 were women. The postal service has always been politicized.</p>
<p>Soon after, the U.S. Government expanded on the postal service’s role in democratizing America, both literally and figuratively. President Theodore “Teddy” Roosevelt expanded on this with the <em>Square Deal</em> in 1902, communicating a fairness policy in hiring and leadership. The result was momentous for many. Roosevelt stated:</p>
<blockquote>
<p>It is and should be my consistent policy in every State, where their numbers warranted it, to recognize colored men of good repute and standing in making appointments to office. […] I can not consent to take the position that the door of hope – the door of opportunity – is to be shut upon any man, no matter how worthy, purely upon the grounds of race or color. <a href="https://about.usps.com/who-we-are/postal-history/african-american-workers-20thc.htm#_edn2" name="_ednref2">[2]</a></p>
</blockquote>
<p>Today, 21% (or nearly 70,000) of the agency’s employees are African-American. However, the postal service was consequential beyond matters of social equity. By 1823, the U.S. Postal Service and the U.S. Government established 80,000 miles of “post roads” to help carriers navigate new rural areas. By 1860, these roads connected nearly 28,000 post offices. Today, the postal service maintains nearly 40,000 post offices, clearing 212 billion letters and mail to 144 million homes.</p>
<blockquote data-card-controls="1" data-card-align="center" data-card-theme="light" data-card-key="3101080c845e4679b6077080f81a573e">
<h4><a href="https://twitter.com/web/status/1292117127055519744">No Title</a></h4>
<p>Save the @USPS.There is no institution more critical to the next phases of our commerce economy.</p>
</blockquote>

<p>Today, the service is tasked with another generational shift: supporting online retail. The pandemic shifted the American consumer towards online retail, this while reducing the number of units shipped. As such, companies like UPS and FedEx have responded by hiking prices. In response to USPS’ distress, FedEx recently stated:</p>
<blockquote>
<p>The COVID-19 pandemic has negatively impacted mail volumes and mix resulting in a further decrease in revenues and negative financial impact for the USPS. Additionally, the USPS continues to experience budgetary uncertainty as well as increased political debate regarding potential privatization or restructuring of its operations.</p>
</blockquote>

<figure id="attachment_12683" aria-describedby="caption-attachment-12683"><img data-attachment-id="12683" data-permalink="https://2pml.com/2020/08/10/usps/sleikjxu/" data-orig-file="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?fit=2048%2C1259&amp;ssl=1" data-orig-size="2048,1259" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sLEikjXU" data-image-description="" data-medium-file="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?fit=300%2C184&amp;ssl=1" data-large-file="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?fit=740%2C455&amp;ssl=1" loading="lazy" src="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=740%2C455&amp;ssl=1" alt="sLEikjXU" width="740" height="455" srcset="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?w=2048&amp;ssl=1 2048w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=300%2C184&amp;ssl=1 300w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=1024%2C630&amp;ssl=1 1024w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=768%2C472&amp;ssl=1 768w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=1536%2C944&amp;ssl=1 1536w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?w=1480&amp;ssl=1 1480w" sizes="(max-width: 740px) 100vw, 740px" data-recalc-dims="1"><figcaption id="caption-attachment-12683">The most popular government sites: June 18, 2020</figcaption></figure>
<p>Cost inflation is the most concerning obstacle ahead for digitally native retailers. Without the treatment that the United States’ oldest civilian service afforded Amazon in its infancy, it will be more difficult to build more businesses of Amazon’s scale. The economics were difficult enough as is; these added costs will only add pressure to pass along costs to consumers, many of whom are facing down one of the most economically vulnerable periods since 2008.We should consider the postal service an investment into our present and future and a monument to our past.</p>
<p>If our economy is to begin addressing the shortfalls caused by the overwhelming contraction in the traditional retail industry, it will need the support of the postal service. For eCommerce, their service is the industry’s last mile for thousands of direct-to-consumer small businesses. The postal service uniquely sits at the intersection of our physical roads and our digital infrastructure. There isn’t a direct substitute and we shouldn’t wait to find out the hard way. Save the USPS. We will need more companies like the the successful hundreds that were built on its 250 year old infrastructure. That includes Amazon.</p>
<p><strong>By Web Smith | Editor: Hilary Milnes | Art by Alex Remy | <a href="http://2pml.com/about">About 2PM</a></strong></p>
			</div><!-- .entry-content -->

	
	</article></div>]]>
            </description>
            <link>https://2pml.com/2020/08/10/usps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24153311</guid>
            <pubDate>Fri, 14 Aug 2020 04:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Ruby apps, same code, but different output: what's going on?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152544">thread link</a>) | @vaillancourtmax
<br/>
August 13, 2020 | https://maximevaillancourt.com/blog/debugging-ruby-casecmp-bug-using-gdb | <a href="https://web.archive.org/web/*/https://maximevaillancourt.com/blog/debugging-ruby-casecmp-bug-using-gdb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <p><img src="https://images.unsplash.com/photo-1522776851755-3914469f0ca2?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1000&amp;h=500&amp;q=80"></p>

<p>I noticed something odd today while working on two different Ruby codebases. This simple line of Ruby behaved differently in both applications:</p>

<div><div><pre><code><span>"luck"</span><span>.</span><span>casecmp</span><span>(</span><span>"L`auguste"</span><span>)</span>
</code></pre></div></div>

<p>Executing <code>"luck".casecmp("L`auguste")</code> in application A returned <code>-1</code>, while executing it in application B returned <code>1</code>.</p>

<p>â€œDid the alphabet change at some point and I didnâ€™t get the memo?â€�, I thought.</p>

<blockquote>
  <p><strong>Aside</strong></p>

  <p><a href="https://ruby-doc.org/core-2.7.1/String.html#method-i-casecmp"><code>String#casecmp</code></a> is a built-in Ruby method that returns <code>-1</code>, <code>0</code>, <code>1</code>, or <code>nil</code> depending on whether the object on which itâ€™s called is less than, equal to, or greater than the function argument, and it does so in case-insensitive fashion. Here are a few simple examples of how it behaves:</p>

  <div><div><pre><code><span>"aBcDeF"</span><span>.</span><span>casecmp</span><span>(</span><span>"abcde"</span><span>)</span>     <span>#=&gt; 1</span>
<span>"aBcDeF"</span><span>.</span><span>casecmp</span><span>(</span><span>"abcdef"</span><span>)</span>    <span>#=&gt; 0</span>
<span>"aBcDeF"</span><span>.</span><span>casecmp</span><span>(</span><span>"abcdefg"</span><span>)</span>   <span>#=&gt; -1</span>
<span>"abcdef"</span><span>.</span><span>casecmp</span><span>(</span><span>"ABCDEF"</span><span>)</span>    <span>#=&gt; 0</span>
</code></pre></div>  </div>
</blockquote>

<h2 id="looking-for-monkey-patches">Looking for monkey patches</h2>

<p>Seeing as one of the applications is built on top of Ruby of Rails and the other isnâ€™t, my first thought was that maybe there was a Rails and/or ActiveSupport patch on <code>String#casecmp</code> that would change the behavior of this line in one of the applications. However, I didnâ€™t find anything that pointed to this. I kept digging, hoping to maybe find a patch in the <em>other</em> application that could explain this difference in behavior. Again, I didnâ€™t find anything. ðŸ™ˆ</p>

<h2 id="different-rubies">Different Rubies</h2>

<p>Eventually, after exploring a bit more, I realized that both applications ran on different versions of Ruby: application A was on Ruby 2.6, while application B was using Ruby 2.7.</p>

<p>Running the same command on both versions of Ruby indeed gives us different results:</p>

<div><div><pre><code><span>$ </span>~/.rubies/ruby-2.6.6/bin/ruby <span>-e</span> <span>'puts "luck".casecmp("L`Auguste")'</span>
<span>-1</span>

<span>$ </span>~/.rubies/ruby-2.7.0/bin/ruby <span>-e</span> <span>'puts "luck".casecmp("L`Auguste")'</span>
1
</code></pre></div></div>

<p>Ah ha! Weâ€™re getting closer. While I could have called it a day here and simply updated application B to Ruby 2.7 to resolve the issue, I wanted to understand: what causes it?</p>

<h2 id="changelogs--bindingpry">Changelogs &amp; <code>binding.pry</code></h2>

<p>I then started to comb through Ruby changelogs, trying to find if anything changed between Ruby 2.6 and Ruby 2.7 for <code>String#casecmp</code>, or anything somehow related to string comparison. I didnâ€™t find anything.</p>

<p>Of course, it would be nice to debug this using <code>binding.pry</code> or other similar Ruby-level debugging tools by stepping into the <code>String#casecmp</code> call to see whatâ€™s going on inside. However, this doesnâ€™t get us very far, as trying to use Rubyâ€™s <code>Tracer</code> or <code>binding.pry</code> doesnâ€™t really help.</p>

<p>Running this:</p>

<div><div><pre><code><span>$ </span>ruby <span>-r</span> tracer <span>-e</span> <span>'"luck".casecmp("L`Auguste")'</span>
</code></pre></div></div>

<p>â€¦ returns this output:</p>

<div><div><pre><code>#0:-e:1::-: "luck".casecmp("L`Auguste")
</code></pre></div></div>

<p>â€¦ and not much else. Thatâ€™s because <code>String#casecmp</code> is implemented in C, directly inside MRIâ€™s <a href="https://github.com/ruby/ruby/blob/master/string.c"><code>string.c</code></a>, so thereâ€™s no actual Ruby code underneath <code>String#casecmp</code> that we can step into using Ruby-level debugging tools.</p>

<p>Here comes the GDB part: because weâ€™re essentially dealing with C code at this point, we can use GDB to understand what happens inside the call to <code>String#casecmp</code>. So with that, I fired up GDB for the first time in years (I typically work with Ruby, so GDB is not something I commonly use).</p>

<h2 id="identifying-the-root-cause-using-gdb">Identifying the root cause using GDB</h2>

<p>Letâ€™s see how to use GDB to understand why both Ruby 2.6 and Ruby 2.7 behave differently with the same input to <code>String#casecmp</code>.</p>

<p>I first prepared a simple Ruby file containing the source that replicates the issue:</p>

<div><div><pre><code><span># ~/casecmp.rb</span>
<span>puts</span> <span>"luck"</span><span>.</span><span>casecmp</span><span>(</span><span>"L`Auguste"</span><span>)</span>
</code></pre></div></div>

<p>Notice that the second character in the input to <code>casecmp</code> is a backtick (<code>`</code>), which has ASCII code 96. This is relevant for paragraphs below.</p>

<h3 id="in-ruby-270">In Ruby 2.7.0</h3>

<p>Letâ€™s start by firing up GDB with a self-compiled version of Ruby 2.7.0:</p>

<div><div><pre><code><span>$ </span><span>sudo </span>gdb /Users/maximevaillancourt/.rubies/ruby-2.7.0/bin/ruby
Reading symbols from /Users/maximevaillancourt/.rubies/ruby-2.7.0/bin/ruby...
</code></pre></div></div>

<p>Then, we add a breakpoint on the <code>str_casecmp</code> function so execution pauses once we reach it:</p>

<div><div><pre><code>(gdb) break str_casecmp
Breakpoint 1 at 0x1001fa766: file string.c, line 3371.
</code></pre></div></div>

<p>Perfect. Weâ€™re now ready to run the <code>casecmp.rb</code> Ruby script from above.</p>

<div><div><pre><code>(gdb) run casecmp.rb
Starting program: /Users/maximevaillancourt/.rubies/ruby-2.7.0/bin/ruby casecmp.rb
</code></pre></div></div>

<p>We eventually hit the breakpoint we just set:</p>

<div><div><pre><code>Thread 2 hit Breakpoint 1, str_casecmp (str1=4329352680, str2=4329352640) at string.c:3371
3371	    enc = rb_enc_compatible(str1, str2);
</code></pre></div></div>

<blockquote>
  <p><strong>Aside</strong></p>

  <p>Internally, <a href="https://github.com/ruby/ruby/blob/4318aba9c94ebff53e4168886e1a35a24013924f/string.c#L3467-L3468"><code>String#str_casecmp</code></a> is quite simple: it iterates over each character in both inputs by index starting from the first character, converting both characters to the same case so that the function behaves in a case-insensitive way, and returns early if the two currently considered characters from each input are different. In doing so, it determines which character is â€œbiggerâ€� than the other using the character code (an <a href="http://www.asciitable.com/">ASCII code table</a> is a useful asset to have nearby for the rest of this blog post).</p>
</blockquote>

<p>In Ruby 2.7.0, notice that the case conversion <a href="https://github.com/ruby/ruby/blob/e9e4f8430a62f56a4e62dd728f4498ee4c300c12/string.c#L3381-L3382">converts both inputs to lowercase using <code>TOLOWER</code></a>:</p>

<div><div><pre><code><span>while</span> <span>(</span><span>p1</span> <span>&lt;</span> <span>p1end</span> <span>&amp;&amp;</span> <span>p2</span> <span>&lt;</span> <span>p2end</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>*</span><span>p1</span> <span>!=</span> <span>*</span><span>p2</span><span>)</span> <span>{</span>
    <span>unsigned</span> <span>int</span> <span>c1</span> <span>=</span> <span>TOLOWER</span><span>(</span><span>*</span><span>p1</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>unsigned</span> <span>int</span> <span>c2</span> <span>=</span> <span>TOLOWER</span><span>(</span><span>*</span><span>p2</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>if</span> <span>(</span><span>c1</span> <span>!=</span> <span>c2</span><span>)</span>
      <span>return</span> <span>INT2FIX</span><span>(</span><span>c1</span> <span>&lt;</span> <span>c2</span> <span>?</span> <span>-</span><span>1</span> <span>:</span> <span>1</span><span>);</span>
  <span>}</span>
  <span>p1</span><span>++</span><span>;</span>
  <span>p2</span><span>++</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>After navigating in <code>str_casecmp</code> using <code>next</code> a few times, we enter the loop and arrive at a point where we can print <code>c1</code> and <code>c2</code>, which are the codes for the characters at the current index for both inputs:</p>

<div><div><pre><code>3382	                unsigned int c2 = TOLOWER(*p2 &amp; 0xff);
(gdb) print c1
$11 = 108
(gdb) next
3383	                if (c1 != c2)
(gdb) print c2
$12 = 108
</code></pre></div></div>

<p>Hereâ€™s a visual representation of the buffers:</p>

<div><div><pre><code>c1
 â†“
108  ?   ?   ?
 l   u   c   k

108  ?   ?   ?   ?   ?   ?   ?   ?
 l   `   a   u   g   u   s   t   e
 â†‘
c2
</code></pre></div></div>

<p>108 is the decimal ASCII character code representation for the first letter of both inputs: <code>l</code> (lowercase â€œLâ€�), so the loop continues to the next iteration because <code>c1</code> and <code>c2</code> are the same.</p>

<p>On the second iteration of the loop (on the second character of both inputs), we get the following results:</p>

<div><div><pre><code>3382	                unsigned int c2 = TOLOWER(*p2 &amp; 0xff);
(gdb) print c1
$14 = 117
(gdb) next
3383	                if (c1 != c2)
(gdb) print c2
$16 = 96
</code></pre></div></div>

<p>Hereâ€™s a visual representation of the buffers:</p>

<div><div><pre><code>    c1
     â†“
108 117  ?   ?
 l   u   c   k

108  96  ?   ?   ?   ?   ?   ?   ?
 l   `   a   u   g   u   s   t   e
     â†‘
     c2
</code></pre></div></div>

<p><code>c1</code> contains <code>117</code>, which is the decimal ASCII character code representation for <code>u</code>, while <code>96</code> (in <code>c2</code>) is the character code for a backtick (<code>`</code>). We then enter the <code>if (c1 != c2)</code> conditional, and the return value is <code>1</code> because <code>c1 &gt; c2</code> (<code>117 &gt; 96</code>).</p>

<p>Okay. So far so good. This lines up with the initial observation of the issue. How are things different in Ruby 2.6.6?</p>

<h3 id="in-ruby-266">In Ruby 2.6.6</h3>

<p>We do almost the same setup as above (same one-line Ruby script to replicate the issue, same breakpoint on <code>str_casecmp</code>), but we fire up GDB with Ruby 2.6.6:</p>

<div><div><pre><code><span>$ </span><span>sudo </span>gdb /Users/maximevaillancourt/.rubies/ruby-2.6.6/bin/ruby
Reading symbols from /Users/maximevaillancourt/.rubies/ruby-2.6.6/bin/ruby...

<span>(</span>gdb<span>)</span> <span>break </span>str_casecmp
...

<span>(</span>gdb<span>)</span> run casecmp.rb
Starting program: /Users/maximevaillancourt/.rubies/ruby-2.6.6/bin/ruby casecmp.rb

Thread 2 hit Breakpoint 1, str_casecmp ...
</code></pre></div></div>

<p>Letâ€™s look at the loop we presented above in Ruby 2.7.0, but <a href="https://github.com/ruby/ruby/blob/a9a48e6a741f048766a2a287592098c4f6c7b7c7/string.c#L3413-L3414">in Ruby 2.6.6</a> this time:</p>

<div><div><pre><code><span>while</span> <span>(</span><span>p1</span> <span>&lt;</span> <span>p1end</span> <span>&amp;&amp;</span> <span>p2</span> <span>&lt;</span> <span>p2end</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>*</span><span>p1</span> <span>!=</span> <span>*</span><span>p2</span><span>)</span> <span>{</span>
    <span>unsigned</span> <span>int</span> <span>c1</span> <span>=</span> <span>TOUPPER</span><span>(</span><span>*</span><span>p1</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>unsigned</span> <span>int</span> <span>c2</span> <span>=</span> <span>TOUPPER</span><span>(</span><span>*</span><span>p2</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>if</span> <span>(</span><span>c1</span> <span>!=</span> <span>c2</span><span>)</span>
      <span>return</span> <span>INT2FIX</span><span>(</span><span>c1</span> <span>&lt;</span> <span>c2</span> <span>?</span> <span>-</span><span>1</span> <span>:</span> <span>1</span><span>);</span>
  <span>}</span>
  <span>p1</span><span>++</span><span>;</span>
  <span>p2</span><span>++</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Notice that instead of using <code>TOLOWER</code> as in Ruby 2.7.0, Ruby 2.6.6 uses <code>TOUPPER</code>. Interesting.</p>

<p>Letâ€™s fast-forward to the part where we get to <code>c1</code> and <code>c2</code> for the second character in the input:</p>

<div><div><pre><code>3414			unsigned int c2 = TOUPPER(*p2 &amp; 0xff);
(gdb) next
3415	                if (c1 != c2)
(gdb) print c1
$5 = 85
(gdb) print c2
$6 = 96
</code></pre></div></div>

<p>Hereâ€™s a visual representation of the buffers:</p>

<div><div><pre><code>     c1
     â†“
108  85  ?   ?
 L   U   C   K

108  96  ?   ?   ?   ?   ?   ?   ?
 L   `   A   U   G   U   S   T   E
     â†‘
     c2
</code></pre></div></div>

<p><code>c1</code> is <code>85</code>, which is the character code for <code>U</code>, and <code>c2</code> is <code>96</code> (just like in Ruby 2.7.0), which is the character code for a backtick (<code>`</code>).</p>

<p>This time though, the comparison result is different, because <code>c1 &lt; c2</code> (<code>85 &lt; 96</code>), so <code>str_casecmp</code> returns <code>-1</code>.</p>

<p>There it is: because Ruby 2.6 uses <code>TOUPPER</code> and Ruby 2.7 uses <code>TOLOWER</code> before comparing the inputs, and because one of the characters to compare is a backtick (<code>`</code>, which canâ€™t be converted to uppercase or lowercase in any way), the other characterâ€™s code â€œmovesâ€� differently around the â€œfixedâ€� backtick character code, affecting the result of the <code>String#casecmp</code> function.</p>

<hr>

<p>To summarize, the root cause of the issue is that <code>String#casecmp</code> was updated in Ruby 2.7 to <strong>lowercase</strong> the two inputs before comparing them, while Ruby 2.6 used to <strong>uppercase</strong> the two inputs before comparing them. <a href="https://github.com/ruby/ruby/commit/082424ef58116db9663a754157d6c441d60fd101#diff-7a2f2c7dfe0bf61d38272aeaf68ac768">This is the commit where this change was introduced.</a></p>

<p>Fun debugging session. :)</p>

<p><em>Found a typo? Think I could clarify something? Reach out on Twitter (<a href="https://twitter.com/vaillancourtmax">@vaillancourtmax</a>).</em></p>

</article></div>]]>
            </description>
            <link>https://maximevaillancourt.com/blog/debugging-ruby-casecmp-bug-using-gdb</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152544</guid>
            <pubDate>Fri, 14 Aug 2020 02:32:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My electricity bill was wrong for two years]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152325">thread link</a>) | @PlanetLotus
<br/>
August 13, 2020 | https://planetlotus.github.io/2020/08/13/meter-mixup.html | <a href="https://web.archive.org/web/*/https://planetlotus.github.io/2020/08/13/meter-mixup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I’ve lived in my house for just under two years. Last summer, I noticed something strange. Our electricity bill increased by 40-90% depending on the month. This year, I finally tracked it down and discovered our meter was being mixed up with our neighbor’s. Here’s how I tracked this down and what you can do to prevent it from happening to you.</p>



<p>I have an amateur interest in electricity, conserving energy, and energy efficiency in general. I care about my carbon footprint, as well as my bill, and I’m passionate about innovation in this space. I’ve made it a habit to have a good idea of how much electricity different appliances use and, in general, I try to be aware of where my electricity is going. Years ago, I bought a simple <a href="https://en.wikipedia.org/wiki/Kill_A_Watt">Kill A Watt</a> to quickly get an idea of how much power things use.</p>



<p>The first time I noticed a problem was when we got our July bill in the summer of 2019. It was about 40% higher than usual. My grandparents stayed with us (in their motorhome) for a week that month, and their motorhome has a big air conditioner, so I chalked it up to that, though that still seemed high.</p>

<p>A couple months passed and the problem got worse. It went from 40% higher than normal, to a peak of about 90%. I couldn’t explain that. We don’t have central air conditioning. Most of our heavy appliances use natural gas. We did use a portable air conditioner briefly, but never for more than a couple hours a night. I also measured the power usage of the A/C and thought, there’s no way this adds up. This confusion continued until we got our October bill and it returned to normal, and I forgot about it for another year.</p>



<p>And…it came back! I first noticed this year in June when the bill jumped about 20%. I figure it’s reasonable for the bill to fluctuate a little, but not by that much. Plus, what made even less sense is that we used supplemental electric heating this winter, so if anything, our bill should’ve been higher in the winter! Again, no central air conditioning, so another unexplained bill. I tracked power usage on everything I could think of, to make sure I hadn’t missed something. For awhile, my big suspect was our fridge. It’s 18 years old, so I figured, maybe there’s a problem with it and it uses more power when it should, especially when the ambient temperature is higher. I cleaned the coils and played around with the fridge settings, then waited for our next bill. It got worse.</p>

<p>This year, I noticed our power company has a cool interface online where you can see your daily power usage. Very handy. I noticed that, in non-summer months, it was very consistent, ranging between 9-12 kWh per day. Then, in the summer months, it just goes all over the place. Sometimes it was 8, other days it went as high as 24! This seemed loosely correlated with the temperature but I just couldn’t explain that, due to a lack of central cooling in our house. I finally decided to call the power company at this point. Naturally, they did not take me too seriously, and were fairly insistent that it was my air conditioning (that I didn’t have). I was told to hire an electrician to investigate.</p>

<p>Then it got weirder. In late July, I noticed that in recent weeks, our daily power usage (according to the power company) dipped as low as 1 kWh per day! That’s just not possible, I thought. My electronics, combined, should use more than that per day, not even counting heavier users like the fridge. The power usage still fluctuated quite a bit, but there were several days where the power usage was as low as 1-3 kWh. I called the power company again and, no surprise, they took this much more seriously and agreed that wasn’t possible. I insisted that the peaks in usage didn’t make sense either, that I couldn’t explain those, but no luck there…they were really only interested in the low days and said they were opening an investigation that could take “at least a few weeks” to finish.</p>



<p>One night, I finally put it together. I wondered if my bill was mixed up with my neighbor’s. My neighbor had moved out in July, and that’s about when the daily power usage fell to almost nothing. I also happened to know that they have central air conditioning. I looked at my bill and noticed it actually has the meter number on it, very helpful! I looked at my meter and the number on the bill wasn’t even remotely close. It wasn’t off-by-one. The format looked consistent, but the values looked randomized. I was wondering whether I was even looking at the right number. So, the next morning, I took a look at my neighbor’s (vacant) house’s meter. Sure enough, it exactly matched what was on my bill.</p>

<p>A few frustrating phone calls later (not important), and the issue is fixed. We got the charges corrected and are enjoying a large credit on our account that ought to last us about 6 months (after having lived here only 2 years).</p>

<p>In any future house I live in, I will be sure to check that my bill’s meter number matches what’s on the property. I highly recommend everyone do the same, because I get the impression this is fairly common. A quick search online and I found about half a dozen news articles about this happening, often more egregious cases than my own. Most of us may not notice a mixup, either because the usage is fairly consistent or we just don’t know how much power we use. Thankfully, you should be able to check the accuracy of your bill in about 5 minutes if your meter is easily accessible. Simply look for the meter number on your bill (hopefully all power companies give this info), and then look physically at the meter for a sticker from your power company, and see if the numbers match.</p>

  </article>

  




</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://planetlotus.github.io/2020/08/13/meter-mixup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152325</guid>
            <pubDate>Fri, 14 Aug 2020 01:57:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning of Sets]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24152216">thread link</a>) | @akosiorek
<br/>
August 13, 2020 | http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html | <a href="https://web.archive.org/web/*/http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In machine learning, we typically work with input pairs (x, y), and we try to figure out how x and y depend on each other.
To do so, we gather many such pairs and hope that the dependence will reveal itself if a) we have enough data, b) our model is expressive enough to approximate this dependency, and c) we get the hyperparameters right.
In the simplest case, both x and y are just scalar values (or vectors \(\mathbf{x}, \mathbf{y}\)); for example, given some measurements of a plant’s shape, we might want to predict its species. The measurements here are real vectors \(\mathbf{x} \in \mathcal{X}\), where the input space \(\mathcal{X} = \mathbb{R}^d\) is usually Euclidean, and the species is a label \(\mathbf{y} \in \mathcal{Y}\) (usually an integer or a one-hot vector), but it is common for \(\mathbf{x}\) and \(\mathbf{y}\) to have more structure.</p>

<p>One of the main assumptions we rely on is that the pairs of (x, y) points are <a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">independent and identically distributed (i.i.d.) random variables</a>.
Let us unpack this a bit, starting from the end,</p>

<ul>
  <li><code>random variable</code>: there exists some stochastic generative process from which the variables were randomly sampled,</li>
  <li><code>identically</code>: all samples come from the same probability distribution,</li>
  <li><code>independent</code>: the generative process has no memory of generated samples, and hence any generated sample does not change the distribution over future generated samples.</li>
</ul>

<p>Any structure in \(\mathbf{x}, \mathbf{y}\), or both introduces constraints, and a successful application of an algorithm to a particular problem does heavily depend on whether or not this algorithm takes the relevant constraints into account.
A common constraint in image-related problems is translation equivariance<sup id="fnref:cnnequiv" role="doc-noteref"><a href="#fn:cnnequiv">1</a></sup>—the output of the algorithm should shift with any shifts applied to the image (you can read more about equvariances in <a href="https://fabianfuchsml.github.io/equivariance1of2/">this excellent blog post</a>).
In natural language-related problems, a typical constraint is causality: a token at position t can depend on any previous tokens at position 1:t-1, but it cannot depend on any future tokens<sup id="fnref:languecausality" role="doc-noteref"><a href="#fn:languecausality">2</a></sup>.</p>

<p>In the above examples, the dependencies between points (e.g., autoregressive dependence in NLP) are clear from the context.
However, if a data point is not a vector, matrix, or a sequence of vectors, but it is a <strong>set of vectors</strong>, these dependencies become less clear.
In particular, elements in an input set resemble elements in a dataset (i.e., lack of order), but the critical difference is that they are <strong>not independent</strong>, therefore breaking the i.i.d. assumption.
Accounting for this specific structure in inputs or outputs of an ML model leads to a family of set learning problems, which have recently gained considerable attention in the machine learning community.
I thought it would be useful to delve into the machine learning of sets.
In the following, we will consider set-to-vector, vector-to-set, and set-to-set problems and provide implementations of simple algorithms in <a href="https://github.com/google/jax">JAX</a> and <a href="https://github.com/deepmind/dm-haiku">haiku</a>.</p>

<p>First some imports:</p>

<div><div><pre><code>import jax
import jax.numpy as jnp
import haiku as hk
</code></pre></div></div>


<p>Before we start, it is useful to introduce some notation.
Let \(\mathbf{x} \in \mathbb{R}^d\) be an input vector, \(\mathbf{y} \in \mathbb{R}^k\) the output vector, and let \(X = \{\mathbf{x}_i\}_{i=1}^M\) and \(Y = \{\mathbf{y}_j\}_{j=1}^N\) be sets of \(M\) and \(N\) elements, respectively.
Note that, until now, \(y\) or \(\mathbf{y}\) were simply labels.
From now on, however, \(\mathbf{x}\) and \(\mathbf{y}\) can live in the same space, and simply be elements of different sets.
I will also use \(\mathcal{L}(X, Y)\) as a loss function operating on two sets, and \(l(\mathbf{x}, \mathbf{y})\) will be a loss function for pairs of elements.</p>


<p>This is perhaps the simplest set-learning problem since it only requires permutation invariance.
A function \(f\) is invariant to permutations \(\pi\) if \(\forall \pi\): \(f(X) = f(\pi X)\).
Permutation invariance has always been known in machine learning, as loss functions we use almost never<sup id="fnref:acn" role="doc-noteref"><a href="#fn:acn">3</a></sup> depend on the ordering of elements in our datasets or minibatches.
This is not for the lack of order: to create a minibatch, we stack multiple data elements in an array; this pairs every element in the minibatch with its minibatch index, therefore implicitly creating an order.
Loss functions tend to discard information about the order, usually by taking the mean over data examples.
We can create permutation-invariant functions by following a similar logic.</p>

<p>Examples in a minibatch are processed independently (which reflects their i.i.d. nature), but if each entry in the minibatch contains more than just a single data point (many pixels in an image, points in a point cloud, tokens in a language sentence), then flattening these points into a vector and feeding it into an MLP or a CNN results in different parameters being used for processing different data points, and hence order is used implicitly; feeding the points into an RNN reuses parameters, but introduces an explicit dependence on the order.</p>

<p>A straightforward solution to this issue is to treat points in a single example in the same way we treat examples in the minibatch: treat them independently.
This approach, followed by a permutation-invariant pooling operation such as max or mean pooling, is explored in <a href="https://arxiv.org/abs/1703.06114">Zaheer et al., “Deep Sets”, NeurIPS 2017</a> and is proven to be a universal set-function approximator<sup id="fnref:deepsetdim" role="doc-noteref"><a href="#fn:deepsetdim">4</a></sup>.</p>

<div><div><pre><code>class DeepSet(hk.Module):

  def __init__(self, encoder, decoder):
    super().__init__()
    self._encoder = encoder
    self._decoder = decoder
    
  def __call__(self, x):
    """Compute the DeepSet embedding.

    Args:
      x: Tensor of shape [batch_size, n_elems, n_dim].
    """
    return self._decoder(self._encoder(x).mean(1))
</code></pre></div></div>

<p>While newer approaches with better empirical performance exist, they all draw from the Deep Sets framework<sup id="fnref:setembeddings" role="doc-noteref"><a href="#fn:setembeddings">5</a></sup>.
Another factor contributing to the fact that the set-to-vector problem is quite easy is that pooling operations naturally work with variable-sized sets–there is nothing extra we have to do to handle sets of variable cardinality.
This is not the case in the following two problems, where we have to take the set size into account explicitly.</p>


<p>In vector-to-set, the task is to generate a set of real vectors from some (usually vector-valued) conditioning.</p>

<p>The majority of approaches out there focus on generating ordered sequences instead of unordered sets, and usually of fixed or at least known size.
This allows using MLPs<sup id="fnref:setae" role="doc-noteref"><a href="#fn:setae">6</a></sup> and RNNs<sup id="fnref:order_matters" role="doc-noteref"><a href="#fn:order_matters">7</a></sup> to predict fixed- and variable-length sets, respectively, but at the price of having to learn permutation-equivariance from data.
Learning permutation-equivariance can be induced by data augmentation. It is easy to generate different permutations, but usually comes at a decreased performance and/or longer training times compared to truly permutation-equivariant methods<sup id="fnref:data_augmentation" role="doc-noteref"><a href="#fn:data_augmentation">8</a></sup>.</p>

<div><div><pre><code>  def set_mlp(conditioning, decoder, n_elements):
    """Predicts a set.

    Args:
      conditioning: tensor of shape [batch_size, n_dim].
      decoder: callable, e.g. an MLP.
      n_elements: int.
    """
    z = decoder(conditioning)
    batch_size = conditioning.shape[0]
    # all we can do here is reshape!
    return z.reshape(batch_size, n_elements, -1)

  def set_rnn(conditioning, state, rnn, n_elements):
    """Predicts a set.

    Args:
      conditioning: tensor of shape [batch_size, n_dim].
      state: initial state for the rnn.
      rnn: rnn core.
      n_elements: int.
    """
    zs = []
    for _ in range(n_elements):
      z, state = rnn(conditioning, state)
      zs.append(z[:, None])  # add an axis

    return jnp.concatenate(zs, 1)
</code></pre></div></div>

<h4 id="permutation-invariant-loss-functions">Permutation-Invariant Loss Functions</h4>
<p>Learning to generate sets based on some conditioning typically requires scoring that set against the conditioning.
If we have ground-truth sets at our disposal, we can compare the generated sets against the ground-truth ones for the same conditioning.
This can take the form of supervised learning (think of detecting objects in an image, where we need to generate a set of bounding boxes) or unsupervised learning (autoencoding point-clouds, say).
Since we generally have no guarantee that the generated sets will obey any ordering (why should they?), we have to apply losses invariant to that ordering.
We have two options here:</p>

<ul>
  <li>We can find an optimal matching between two sets<sup id="fnref:bipartite_matching" role="doc-noteref"><a href="#fn:bipartite_matching">9</a></sup>, which comes down to finding a permutation \(\pi\) of one of the sets that minimizes the computed loss, that is: \(\pi^\star = \arg \min_\pi \mathcal{L}( \pi X, Y)\), with \(\mathcal{L}( \pi X, Y) = \sum_i l(\mathbf{x}_{\pi(i)}, \mathbf{y}_i)\). This can be done exactly using the cubic <a href="https://en.wikipedia.org/wiki/Hungarian_algorithm">Hungarian matching</a> algorithm, or approximately using e.g. <a href="https://arxiv.org/abs/1106.1925">optimal-transport</a>- or <a href="https://web.stanford.edu/~bayati/papers/bpmwmIT.pdf">message-passing</a>-based algorithms.</li>
  <li>Instead of finding a matching, we can find a lower bound on what the matched loss would be. A popular choice here is the Chamfer loss<sup id="fnref:chamfer" role="doc-noteref"><a href="#fn:chamfer">10</a></sup>, which computes \(\sum_{x \in X} \min_{y \in Y} l(x, y) + \sum_{y \in Y} \min_{x \in X} l(x, y)\). For every element in one set, it finds the element in the other set that results in the lowest pairwise loss. This loss does not work for multisets as elements can be repeated.</li>
</ul>

<p>If we do not have ground-truth for each conditioning (we have just sets), or if we have many possible sets for each conditioning (e.g., a group of possible sets for one of a few labels), we can instead learn by matching distributions e.g., in the GAN setting.
If we take this approach, we have two problems, really: that of vector-to-set for the generator and set-to-vector for the discriminator. 
Fortunately, we know how to solve the set-to-vector problem with a permutation-invariant neural net, and shortly I am going to describe some permutation-equivariant methods for generation.
This is precisely what we recently explored in <a href="https://oolworkshop.github.io/program/ool_32.html">Stelzner et al., “Generative Adversarial Set Transformers”, ICML 2020 Object-Oriented Learning Workshop</a>.</p>

<p>Coincidentally, sometimes we have to deal with a set of latent variables inside a model. For example in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html">http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html</a></em></p>]]>
            </description>
            <link>http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152216</guid>
            <pubDate>Fri, 14 Aug 2020 01:40:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[USPS Releases 2020 Ruth Asawa Stamp]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152035">thread link</a>) | @arunc
<br/>
August 13, 2020 | https://ruthasawa.com/usps-announces-2020-ruth-asawa-stamp/ | <a href="https://web.archive.org/web/*/https://ruthasawa.com/usps-announces-2020-ruth-asawa-stamp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tc-page-wrap">

  		
  	   	
  		                                                                                    <div id="main-wrapper">

    
    <div role="main">
        <div>

            
                <div id="content">

                    
                        
                                                                                                                              
                                                                    <article id="post-1462">
                                                
                  <section>
              <div id="attachment_1468"><p><img aria-describedby="caption-attachment-1468" src="https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200.jpg" alt="" width="1200" height="769" srcset="https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200.jpg 1200w, https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200-300x192.jpg 300w, https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200-1024x656.jpg 1024w, https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200-768x492.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px"></p><p id="caption-attachment-1468">© 2020 U.S. Postal Service. All rights reserved.</p></div><p>The U.S. Postal Service honors pioneering Japanese American artist Ruth Asawa (1926-2013). Showcasing Asawa’s wire sculptures, the pane includes 20 stamps, with two each of 10 designs, featuring photographs by Dan Bradica and Laurence Cuneo. The selvage features a photograph of Asawa taken by Nat Farbman in 1954 for <em>Life</em> magazine. Ethel Kessler served as art director and designer.</p>
<p>Customers may purchase stamps and other philatelic products through the Postal Store at <a href="https://store.usps.com/store/product/buy-stamps/ruth-asawa-S_476304" target="_blank" rel="noopener noreferrer">usps.com/shopstamps</a>, by calling 800-STAMP24 (800-782-6724), by mail through USA Philatelic, or at Post Office locations nationwide. Videos of most stamp ceremonies will be available on facebook.com/usps. </p>
<p>The pane includes 20 stamps, featuring photographs by Laurence Cuneo and Dan Bradica for David Zwirner. The selvage features a photograph of Asawa taken by Nat Farbman in 1954 for Life magazine. Ethel Kessler served as art director and designer for this issuance.</p>
<p><a href="https://store.usps.com/store/product/buy-stamps/ruth-asawa-S_476304" rel="noopener noreferrer" target="_blank">Stamps are available now &gt;</a></p>
<p>Information on ordering first-day-of-issue postmarks and covers is at <a href="https://usps.com/shopstamps" target="_blank" rel="noopener noreferrer">usps.com/shopstamps</a> under “Collectors.”</p>
<p>Paul Lanier, son of Ruth Asawa; George Takei of The Japanese American National Museum; and Jonathan Laib, of David Zwirner Gallery participated in the virtual opening event with USPS officials:</p>
<p>The Postal Service receives no tax dollars for operating expenses and relies on the sale of postage, products and services to fund its operations. All images are preliminary and are subject to change prior to printing.</p>
<p><a href="https://ruthasawa.com/art/">Explore galleries of Asawa’s art forms &gt;</a></p>
<p><a href="https://ruthasawa.com/life/">View a timeline of her life &gt;</a></p>
<p><a href="https://ruthasawa.com/view-installation/">Experience an Asawa installation virtually &gt;</a></p>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content -->                                                                                </section><!-- .entry-content -->
                                            </article>
                                
                                                                      
                        
                    
                </div><!--.article-container -->

           
        </div><!--.row -->
    </div><!-- .container role: main -->

    
</div><!-- //#main-wrapper -->

                                            		<!-- FOOTER -->
  		
    </div></div>]]>
            </description>
            <link>https://ruthasawa.com/usps-announces-2020-ruth-asawa-stamp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152035</guid>
            <pubDate>Fri, 14 Aug 2020 01:12:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Standards Are Simple]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24151909">thread link</a>) | @wyclif
<br/>
August 13, 2020 | https://portal.mozz.us/gemini/ebc.li/posts/open-standards-are-simple.gmi | <a href="https://web.archive.org/web/*/https://portal.mozz.us/gemini/ebc.li/posts/open-standards-are-simple.gmi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div><p><a href="https://portal.mozz.us/gemini/ebc.li/">Home</a></p>
<p>2020-08-13

If you want to create a truly open standard, you _need_ to make it simple.

There are no exceptions to this rule. When a standard becomes harder to fully implement than what your average motivated programmer can do in two months (max!), it _shouldn't_ be considered "open" anymore.

Why?

</p>
<h2>Complicated Standards Lead to Implementation Monopolies</h2>
<p>Since implementing a complex standard is hard, you will eventually end up with the implementation that started the earliest and maintained since, being the only implementation that is actually usable. And that implementation will most likely be the one created by the standard's creators.

In cases where the standard's creators don't maintain an implementation like "the web"⁰, the only choices are either the standard dying out because of it's complexity, or the actively maintained implementations requiring tons of effort, with (most likely) companies backing said implementations.

</p>
<h2>Implementation Monopolies Lead to Extensions</h2>
<p>If a big implementation just decides one day that your standard is lacking, they can just extend the parts they want. The two outcomes of this being that:

</p>
<ul><li>The other implementations copy their extensions</li>
<li>That one implementation getting more users, and eventually, a near monopoly because of a bigger feature set</li></ul>
<p>
At that point, the "standard" implemented by said implementations is longer the actual defined standard, but because people will inevitably use the said extensions, any new implementation that wants to be considered usable will eventually need to support said proprietary extensions.

</p>
<h2>Too Many Extensions Spoil The Standard</h2>
<p>Even if you have an "open" extension system, where implementations can all propose and agree on extensions to the standard, you need to be able to keep those implementations in check, so their extensions don't overcomplicate the standard.

Remember: Having a simple standard with a million extensions is no better than a complex standard with no extensions.

</p>
<h2>Examples</h2>
<p>Please note that I will be skipping the elephant in the room: "the web", as it has been discussed _to death_.

</p>
<h3>Matrix</h3>
<p>Matrix is _technically_ an open standard. But because of the complexity it has accumulated over the years, Synapse is the only usable server implementation. Even Dendrite, the new implementation by *the same folk that created the standard*, is barely usable after _years_.

The same applies to Matrix clients, with Element being the only usable client implementation. That space definitely seems healthier than the server space, but the same issues are there.

</p>
<h3>Various Programming Languages</h3>
<p>I will not be specifying any language, as I might get any specifics incorrect, but a general pattern I have seen is that most programming languages have only a few compiler/interpreter implementations, even though the language is standardized in some form.

This example actually has some interesting reasoning behind this issue on top of the complicated standards:

</p>
<ul><li>Writing a compiler/interpreter can be hard.</li>
<li>Especially if the current implementations do optimizations or other "clever" tricks.</li></ul>
<p>
These issues can devolve into arguments regarding seeing the complexity of these issues as a part of the standard, and other "technology is too complicated in general" arguments, which I will not dive into here.

</p>
<h3>X Display Server</h3>
<p>The X Display Server standard got so complicated, the people developing it decided to abandon it entirely and create Wayland.

It probably didn't help that most of the standard was no longer being used, and a lot of extensions are required for its use today.

Wayland probably will also suffer the "too many extensions" problem at some point, so I am looking forward to that too...

</p>
<h2>Footnotes</h2>
<p>0: Well, Google, Mozilla and Apple all had a hand in most of the "modern" parts of the standards...
</p></div>
        </div></div>]]>
            </description>
            <link>https://portal.mozz.us/gemini/ebc.li/posts/open-standards-are-simple.gmi</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151909</guid>
            <pubDate>Fri, 14 Aug 2020 00:52:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Valve Index HMD Detailed Teardown]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24151496">thread link</a>) | @adwi
<br/>
August 13, 2020 | https://www.thevrist.com//indexteardown | <a href="https://web.archive.org/web/*/https://www.thevrist.com//indexteardown">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>If you have ever wondered what is inside Valve Index, you might have stumbled upon my <a href="https://www.reddit.com/r/ValveIndex/comments/cpayc5/valve_index_disassembly/">reddit post from 2019</a>. I’ve decided to dive into the details of what makes Valve Index great and share my thoughts on tech inside.</p>

<p>Teardown should begin from the simplest parts - remove the face mask (held by just magnets), unplug the main cable, and remove headphones that are held in place by a single screw each. Next remove the rubber cover that is glued around lenses. It’s not that well glued, you can just pull it off.</p>

<p><img src="https://www.thevrist.com/assets/images/index1.jpg" alt="">
<em>Rubber cover that prevents dust from getting inside lenses</em></p>

<p>Let’s start with a front panel - glossy front panel is removed by hand, since it is only held by magnets (but you already knew that from all the numerous pictures of people shoving stuff in the frunk of the headset). The rest of the front panel can be easily split in two parts. First is the frunk section, it will give you access to the main circuit board of the headset. You can remove it quite painlessly if you have the correct screwdriver. This panel does not contain any electronics.</p>

<p><img src="https://www.thevrist.com/assets/images/index-face.jpg" alt="">
<em>Just look at this beauty</em></p>

<p>Second part of the front panel is more complex. It contains tracking points for the SteamVR tracking - you can see them by looking at the plastic at different angles - plastic covering tracking points is thinner so laser beams from base stations could shoot through it. SteamVR trackers are split in two independent parts, which are connected to the main circuit separately. Also this panel contains two front facing cameras, which makes the process of taking it off even more delicate. You have to disconnect two cameras and two halves of the tracking plate’s system to finally fully reveal the main circuit.</p>

<h2 id="main-circuit">Main Circuit</h2>

<p><img src="https://www.thevrist.com/assets/images/index2.jpg" alt="">
<em>The “meat” of Valve Index</em></p>

<p>Finally we get to the main computing power of the headset. You can identify the main points of the headset.</p>

<p><img src="https://www.thevrist.com/assets/images/index3-1.png" alt="">
<em>This is where all the cables connect to the HMD</em></p>

<p>On the top there is a metal connector with FPC cable going in. It is going to the smaller circuit in the top part of the headset where the cable plugs in the headset.</p>

<p><img src="https://www.thevrist.com/assets/images/index4.jpg" alt="">
<em>Circuit board with main cable and 3.5 mm audio port. It also connects to the proximity sensor</em></p>

<p>Same circuit has a 3.5 mm audio port for connecting headphones (I bet you didn’t know there is an audio jack) and proximity sensor between lenses. Last one is used for turning off the screens when the headset is not on the head.</p>

<p><img src="https://www.thevrist.com/assets/images/index2-1.png" alt="">
<em>SteamVR tracking points are connected here</em></p>

<p>On the sides of the main circuit board there are two black FPC cables. Those are going to the SteamVR tracking dots located in the sides of the headsets. Here is a picture of the tracking “web” when taken out of the headset.</p>

<p><img src="https://www.thevrist.com/assets/images/index5.jpg" alt="">
<em>One side of SteamVR tracking web taken out of the HMD</em></p>

<p>Final two FPC cables are orange color and located at the bottom of the main board. They are connecting to a pair of displays located right behind this circuit.</p>

<h2 id="microchips">Microchips</h2>

<p>Now it is time to dive in a wonderful world of microchips and circuit boards. I want to thank <a href="https://www.linkedin.com/in/popovs/">Sergejs Popovs</a> for helping to identify most of the components on the board.</p>

<p>Let’s start with simple chips. Here are two bluetooth <a href="https://www.nordicsemi.com/Products/Low-power-short-range-wireless/nRF52840">chips from Nordic Semiconductors</a>. Each of these chips is used for connecting one controller with the headset. That’s why there is a limitation of two devices connected to the HMD. If you want to connect more devices (Vive Trackers or other controllers) you will need to use a USB dongle with a separate Bluetooth chip.</p>

<p><img src="https://www.thevrist.com/assets/images/index6.jpg" alt="">
<img src="https://www.thevrist.com/assets/images/index7.jpg" alt="">
<em>Bluetooth microchips, each connects to one device</em></p>

<p>Do you remember the USB port in the frunk? Well, this is a <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/USB5744-Data-Sheet-DS00001855J.pdf">chip from Microchip</a> for that USB port - hence USB in the name.</p>

<p><img src="https://www.thevrist.com/assets/images/index4-4.jpg" alt="">
<em>USB chip for USB port next to it</em></p>

<p>Here is a <a href="https://www.via-labs.com/product_show.php?id=96">chip from Via-Labs</a>. It has a purpose of converting USB 3.1 signal to the 2.0 one. Some of the chips on the circuit are not advanced enough to understand 3.1 USB, so this chip “dumbs it down”. When the signal will need to go back to the PC, the chip will convert the signal back to the USB 3.1.</p>

<p><img src="https://www.thevrist.com/assets/images/index8.jpg" alt="">
<em>USB signal converter chip</em></p>

<p>This is a flash memory chip from <a href="https://www.digikey.com/products/en/integrated-circuits-ics/memory/774?k=w25q32jw">Winbond Electronics</a>.</p>

<p><img src="https://www.thevrist.com/assets/images/index9.jpg" alt="">
<em>Flash memory can be used for different kinds of tasks</em></p>

<p>Next are these two microchips. The smaller one is a <a href="https://www.analogix.com/en/products/dp-mipi-converters/anx7530">SlimPort® 4K receiver from Analogix</a>. It is capable of receiving Image in 4K at 60 Hz, but since screens in Valve Index are only 1440 by 1600 pixels it allows to process video at 90, 120, and even 144 Hz. It also splits the signal in two allowing each display to get its own image.</p>

<p><img src="https://www.thevrist.com/assets/images/index10.jpg" alt="">
<em>Video chips convert image that you see in your SteamVR mirror in beautiful VR image</em></p>

<p>Larger chip is a multipurpose <a href="https://www.digikey.com/products/en/integrated-circuits-ics/embedded-fpgas-field-programmable-gate-array/696?k=ICE40HX8K">FPGA (Field Programmable Gate Array) chip from Lattice Semiconductor</a>. It is used for tracking - all the data received from the tracking sensors is gathered here. This chip combined with the <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/Atmel-11289-32-bit-Cortex-M4-Microcontroller-SAM-G55_Summary-Datasheet.pdf">Atmel MCU</a> (located on the other side of the circuit board) are doing all the necessary tracking calculations.</p>

<p><a href="http://www.etron.com.tw/cn/products/webcam_detial.php?Product_ID=10">EtronTech microchip</a> is used for merging video feeds from external cameras and transmitting it to your PC.</p>

<p><img src="https://www.thevrist.com/assets/images/index11.jpg" alt="">
<em>Microchip for processing image from webcams</em></p>

<p>Last two chips on this side of the circuit from <a href="https://www.silabs.com/power/efp01-power-management-ic">SiliconLabs</a> are most likely related to power regulation. Both of them are located near the capacitors and an inductor (metal thingy with 150 written on it). These are making sure that nothing will get too hot on your face.</p>

<p><img src="https://www.thevrist.com/assets/images/index12.jpg" alt="">
<img src="https://www.thevrist.com/assets/images/index13.jpg" alt="">
<em>Power regulating microchips</em></p>

<p>Next step is to remove the main circuit board and look on its other side. Other side is less interesting and has very little information to offer. Most parts are related to the power regulation mentioned in the previous paragraph.</p>

<p><img src="https://www.thevrist.com/assets/images/index14.jpg" alt="">
<em>Back side of the main circuit board</em></p>

<p>Largest chip is an Atmel MCU, which I’ve already mentioned is related to the tracking system. On the left from it is a <a href="https://www.nxp.com/docs/en/data-sheet/LPC11U1X.pdf">microcontroller from NXP</a>. These are all the chips we managed to identify. One chip that is missing, is the additional Bluetooth module. Unlike Vive and Vive Pro, Index has bluetooth in the headset. It is used for connecting to the base stations, updating base station firmware, and sending them to sleep mode when the headset is turning off. Last one is completely optional - I prefer to keep my base stations 2.0 on all the time.</p>

<p><img src="https://www.thevrist.com/assets/images/index14-2.jpg" alt="">
<em>The only two chips worth noting on this side of the motherboard - larger one is for tracking calculations</em></p>

<p>Why there is no separate Bluetooth chip for this purpose is still a mystery for me. Only possible explanation is that two Bluetooth chips for controllers are capable of switching to different modes and control the base stations.</p>

<h2 id="screens">Screens</h2>

<p>After the circuit is removed you will reveal several key components. First - you can see two displays - quick search shows that those panels are made by BOE Technology - Chinese display manufacturer. Those are 1440×1600, 615PPI 3.5” <a href="https://www.panelook.com/VS035ZSM-NW0-69P0_BOE_3.5_LCM_overview_37926.html">panels</a>.</p>

<p><img src="https://www.thevrist.com/assets/images/index15.jpg" alt="">
<em>View of the HMD with main board removed</em></p>

<p>Note some key elements in this view. On the bottom there is a circular mechanism with a metal pin with springs going through the whole headset. Similar pin is barely visible on the top of the headset. This is an IPD adjustment system - movement of the knob at the bottom of the HMD will rotate circular element in the bottom center which will push screens apart.
On the left and right sides of HMD you can see black gears - this is a system for eye relief - rotating a knob on the side of the headset will move the facemask relatively to the screens. Gear system is making sure both sides are rotating simultaneously, without giving too much pressure to the mechanism.</p>

<p><img src="https://www.thevrist.com/assets/images/index16.jpg" alt="">
<em>IPD knob is actually a screw</em></p>

<p>In order to take the central part out from the headset, you will need to take the cap off the IPD adjustment knob and unscrew it.</p>

<p><img src="https://www.thevrist.com/assets/images/index17.jpg" alt="">
<em>Lens chambers with IPD mechanism still attached</em></p>

<p>Next was what I call the “wondering in the dark” part of teardown - for about 30 minutes we were trying to find a way of taking it apart without breaking anything, eventually using force to break one gear inside that was holding display chambers in place.</p>

<p><img src="https://www.thevrist.com/assets/images/index18.jpg" alt="">
<em>Right eye lens chamber removed</em></p>

<p>After this step you can easily take off separate lens chambers and view the details. Chambers are sealed shut so nothing will get inside - they are assembled in perfectly clean conditions with no dust particles. 
In order to take it apart you can probably try to melt glue or something like that. But we are no iFixit, we used good ol’ force. Here you can see the screen separated from the chamber.</p>

<p><img src="https://www.thevrist.com/assets/images/index19.jpg" alt="">
<img src="https://www.thevrist.com/assets/images/index20.jpg" alt="">
<em>BOE screen removed from the chamber</em></p>

<p>Screen has a polarised diffuser glued to it, which is particularly difficult to remove. It is made of very thin crystal glass and it cracks easily. You can see that the corners of it are cracked.</p>

<p><img src="https://www.thevrist.com/assets/images/index21.jpg" alt="">
<em>Crystal polarisation diffuser</em></p>

<p>Diffuser is added to blend pixels better, making the screen door effect even lower.</p>

<p><img src="https://www.thevrist.com/assets/images/index22.jpg" alt="">
<em>Fancy multilayered lens</em></p>

<p>Finally - the lenses. I was expecting them to be thicker with the effect that they create. Valve are saying “The custom lenses built into the Valve Index Headset maximize field of view without sacrificing edge-to-edge clarity. High geometric stability allows you to look around the scene by moving your eyes (not just your head) with minimal shape distortion”. I tend to agree that these are the most advanced lenses in modern mass produced HMD, even though they have their own flaws. Main issue is the light spill when using a headset, you can see the bright light’s reflections in spots where they shouldn’t be.</p>

<h2 id="final-thoughts">Final thoughts</h2>

<p>As you can clearly see, it is not possible to replace a damaged screen or scratched lens all by yourself (even though for latter one you might try to take the lens out using a suction cup, however I don’t think that is a good idea, as lenses and screens are calibrated in the factory).</p>

<p><img src="https://www.thevrist.com/assets/images/index-end.jpg" alt="">
<em>Sometimes… I feel like a monster…</em></p>

<p>I am going to put the high-resolution images of the teardown and of the motherboard <a href="https://photos.app.goo.gl/dhuPVWTu6P5XWo4HA">here</a> so you can see and check all the details by yourself. If you have any corrections, notes, or questions, shoot me an <a href="mailto:zegarsilya@gmail.com">email</a> or PM me on <a href="https://twitter.com/GamerToTheEnd">Twitter</a>.</p>

           …</div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thevrist.com//indexteardown">https://www.thevrist.com//indexteardown</a></em></p>]]>
            </description>
            <link>https://www.thevrist.com//indexteardown</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151496</guid>
            <pubDate>Fri, 14 Aug 2020 00:02:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding .NET Generic Host Model]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24151361">thread link</a>) | @sahan
<br/>
August 13, 2020 | https://sahansera.dev/dotnet-core-generic-host/ | <a href="https://web.archive.org/web/*/https://sahansera.dev/dotnet-core-generic-host/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this article, we will concentrate on how the Generic Host model hosts ASP.NET Core 3.x Web app and a Worker Service. We will first discuss the definition of a <em>Host</em> and its configuration. In the subsequent sections, we will dive into the implementation details from a higher level.</p>
<h3>So what’s the deal with the Generic Host</h3>
<p>With the separation of execution and initialisation, Generic Host provides us with a cleaner way to configure and start up our apps. By default, when you create an ASP.NET Core app now, your application will be hosted using the Generic Host model. If you create a new worker service app, it will be hosted the same way.</p>
<p>Not only that, but this model also provides you standardised configuration, DI, logging, and many more. You can even create a traditional console app, beef it up and make use of Generic Host.</p>
<blockquote>
<p>💡 Follow along with the code from this <a href="https://github.com/sahan91/dotnet-generic-host-example">repository</a></p>
</blockquote>
<h3>The Host</h3>
<p>According to the official documentation, a <code>Host</code> is,</p>
<blockquote>
<p>ASP.NET Core apps configure and launch a host. The host is responsible for app startup and lifetime management. At a minimum, the host configures a server and a request processing pipeline. The host can also set up logging, dependency injection, and configuration.</p>
</blockquote>
<p>Let’s create a new .NET 3.1 WebAPI and a Worker Service project</p>
<div data-language="bash"><pre><code>dotnet new webapi -n WebApplication
dotnet new worker -n WorkerService
dotnet new sln
dotnet sln <span>add</span> WebApplication WorkerService</code></pre></div>
<p>If you open up the solution in an IDE, you will see the following project structure.</p>
<p><span>
      <span></span>
  <img alt="dotnet-core-generic-host-1.png" title="dotnet-core-generic-host-1.png" src="https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/0c69d/dotnet-core-generic-host-1.png" srcset="https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/772e8/dotnet-core-generic-host-1.png 200w,
https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/e17e5/dotnet-core-generic-host-1.png 400w,
https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/0c69d/dotnet-core-generic-host-1.png 598w" sizes="(max-width: 598px) 100vw, 598px" loading="lazy">
    </span></p>
<p>They both have a <code>Program.cs</code> which takes care of setting up a host. In the case of the WebApplication project, it sets up a request processing pipeline defined in a <code>Startup.cs</code> and in the WorkerService project, sets a new hosted service which is an essentially an <code>IHostedService</code>.</p>
<p>In the WebApplication project, when you open up the Program.cs file, you will find the following boilerplate code has been added by the template:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span><span>void</span></span> <span>Main</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span>
<span>{</span>
    <span>CreateHostBuilder</span><span>(</span>args<span>)</span><span>.</span><span>Build</span><span>(</span><span>)</span><span>.</span><span>Run</span><span>(</span><span>)</span><span>;</span>
<span>}</span>

<span>public</span> <span>static</span> <span>IHostBuilder</span> <span>CreateHostBuilder</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span> <span>=&gt;</span>
    Host<span>.</span><span>CreateDefaultBuilder</span><span>(</span>args<span>)</span>
        <span>.</span><span>ConfigureWebHostDefaults</span><span>(</span>webBuilder <span>=&gt;</span>
        <span>{</span>
            webBuilder<span>.</span><span><span>UseStartup</span><span><span>&lt;</span>Startup<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>
        <span>}</span><span>)</span><span>;</span></code></pre></div>
<p>And, in the WorkerService project we have the following code:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span><span>void</span></span> <span>Main</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span>
<span>{</span>
    <span>CreateHostBuilder</span><span>(</span>args<span>)</span><span>.</span><span>Build</span><span>(</span><span>)</span><span>.</span><span>Run</span><span>(</span><span>)</span><span>;</span>
<span>}</span>

<span>public</span> <span>static</span> <span>IHostBuilder</span> <span>CreateHostBuilder</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span> <span>=&gt;</span>
    Host<span>.</span><span>CreateDefaultBuilder</span><span>(</span>args<span>)</span>
        <span>.</span><span>ConfigureServices</span><span>(</span><span>(</span>hostContext<span>,</span> services<span>)</span> <span>=&gt;</span>
        <span>{</span>
            services<span>.</span><span><span>AddHostedService</span><span><span>&lt;</span>Worker<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>
        <span>}</span><span>)</span><span>;</span></code></pre></div>
<p>Except for the <code>ConfigureWebHostDefaults()</code> and <code>ConfigureServices()</code>, everything else is the same.</p>
<h3>Host Configuration</h3>
<p>If you look at the <code>CreateHostBuilder</code> method in the above code, it calls a <code>CreateDefaultBuilder</code> static method from <a href="https://github.com/dotnet/runtime/blob/master/src/libraries/Microsoft.Extensions.Hosting/src/Host.cs">Host</a> coming from <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.host.createdefaultbuilder?view=dotnet-plat-ext-3.1">Microsoft.Extensions.Hosting</a> namespace. It looks like that when we scaffold an ASP.NET Core app, it gives us a <em>.NET Generic Host</em> by default now. We used to have Web Host in ASP.NET Core 2.x, which was made deprecated since ASP.NET Core 3.0. For any future applications, it is recommended to use the .NET Generic Host.</p>
<p>This does a few things under the covers by wrapping,</p>
<ul>
<li>Dependency Injection services</li>
<li>HTTP Server implementation (such as Kestrel)</li>
<li>Logging</li>
<li>Configuration etc.</li>
</ul>
<p>In order to get an idea what the above methods do, I looked into the <a href="https://github.com/dotnet/runtime/blob/master/src/libraries/Microsoft.Extensions.Hosting/src/Host.cs">source code on Github</a>.</p>
<p>We will start off with CreateDefaultBuilder method first.</p>
<p><strong><a href="https://github.com/dotnet/runtime/blob/6072e4d3a7a2a1493f514cdf4be75a3d56580e84/src/libraries/Microsoft.Extensions.Hosting/src/Host.cs">Host.CreateDefaultBuilder()</a></strong></p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span>IHostBuilder</span> <span>CreateDefaultBuilder</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span>
<span>{</span>
    
    <span><span>var</span></span> builder <span>=</span> <span>new</span> <span>HostBuilder</span><span>(</span><span>)</span><span>;</span>

    
    builder<span>.</span><span>UseContentRoot</span><span>(</span>Directory<span>.</span><span>GetCurrentDirectory</span><span>(</span><span>)</span><span>)</span><span>;</span>

    
    
    builder<span>.</span><span>ConfigureHostConfiguration</span><span>(</span>config <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span><span>;</span>

    
    
    builder<span>.</span><span>ConfigureAppConfiguration</span><span>(</span><span>(</span>hostingContext<span>,</span> config<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

    
    <span>.</span><span>ConfigureLogging</span><span>(</span><span>(</span>hostingContext<span>,</span> logging<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

    
    <span>.</span><span>UseDefaultServiceProvider</span><span>(</span><span>(</span>context<span>,</span> options<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span><span>;</span>

    <span>return</span> builder<span>;</span>
<span>}</span></code></pre></div>
<p>As you can see, it pretty much configures a <code>HostBuilder</code> object and returns it. There’s nothing really specific to web hosting in here. This is why it’s common to both HTTP and non-HTTP workloads.</p>
<p>Taking a step further, let’s look at how the web host gets configured. We will now look through <code>ConfigureWebHostDefaults</code> method.</p>
<p><strong><a href="https://github.com/dotnet/aspnetcore/blob/4d4f2fe00ffa7c1b9ea08164f9f26a51a392d007/src/DefaultBuilder/src/GenericHostBuilderExtensions.cs#L26">GenericHostBuilderExtensions.ConfigureWebHostDefaults()</a></strong></p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span>IHostBuilder</span> <span>ConfigureWebHostDefaults</span><span>(</span><span>this</span> <span>IHostBuilder</span> builder<span>,</span> <span>Action<span>&lt;</span>IWebHostBuilder<span>&gt;</span></span> configure<span>)</span>
<span>{</span>
    <span>return</span> builder<span>.</span><span>ConfigureWebHost</span><span>(</span>webHostBuilder <span>=&gt;</span>
    <span>{</span>
        WebHost<span>.</span><span>ConfigureWebDefaults</span><span>(</span>webHostBuilder<span>)</span><span>;</span>

        <span>configure</span><span>(</span>webHostBuilder<span>)</span><span>;</span>
    <span>}</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>Remember that <code>ConfigureWebHostDefaults</code> is used only for HTTP workloads and let’s see what we get as the default web host configuration.</p>
<p><strong><a href="https://github.com/dotnet/aspnetcore/blob/4d4f2fe00ffa7c1b9ea08164f9f26a51a392d007/src/DefaultBuilder/src/WebHost.cs#L215">WebHost.ConfigureWebDefaults()</a></strong></p>
<div data-language="csharp"><pre><code><span>internal</span> <span>static</span> <span><span>void</span></span> <span>ConfigureWebDefaults</span><span>(</span><span>IWebHostBuilder</span> builder<span>)</span>
<span>{</span>
	
    builder<span>.</span><span>ConfigureAppConfiguration</span><span>(</span><span>(</span>ctx<span>,</span> cb<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span><span>;</span>

	
    builder<span>.</span><span>UseKestrel</span><span>(</span><span>(</span>builderContext<span>,</span> options<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

	
    <span>.</span><span>ConfigureServices</span><span>(</span><span>(</span>hostingContext<span>,</span> services<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

	
    <span>.</span><span>UseIIS</span><span>(</span><span>)</span>
    <span>.</span><span>UseIISIntegration</span><span>(</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>So far, we have seen that both approaches use the same Generic Host paradigm in the two projects. If you are interested in customising the default configuration, head over to <a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.1#host-configuration">Microsoft Docs’ official documentation</a>.</p>
<h3>Finally, how does it all run?</h3>
<p>Now comes the interesting part.</p>
<p>In both cases, after the configuration sections, we finally call the <code>Run()</code> on <code>IHost</code> object implemented in <code>HostingAbstractionsHostExtensions</code>. This will run the app and block the calling thread until the host is shut down. This is enabled by <code>WaitForShutdownAsync</code> which is called at the beginning of the start-up process, which can be triggered by Ctrl+C/SIGTERM or SIGINIT.</p>
<p>Let’s look at how both web hosts and worker services run.</p>
<p>For a worker service, remember how we registered our Worker class by passing it into <code>ConfigureServices</code> method. This Worker class extends <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.backgroundservice?view=dotnet-plat-ext-3.1"><code>BackgroundService</code></a> which in turn implements <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.ihostedservice?view=dotnet-plat-ext-3.1"><code>IHostedService</code></a>. <code>IHostedService</code> provides 2 methods, namely, <code>StartAsync</code> and <code>StopAsync</code>. So when we run our host, it must be retrieving our Worker service and invoking these methods.</p>
<p><span>
      <span></span>
  <img alt="dotnet-core-generic-host-2.png" title="dotnet-core-generic-host-2.png" src="https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/5a190/dotnet-core-generic-host-2.png" srcset="https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/772e8/dotnet-core-generic-host-2.png 200w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/e17e5/dotnet-core-generic-host-2.png 400w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/5a190/dotnet-core-generic-host-2.png 800w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/c1b63/dotnet-core-generic-host-2.png 1200w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/29007/dotnet-core-generic-host-2.png 1600w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/575bd/dotnet-core-generic-host-2.png 1791w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
    </span></p>
<p><em>Source: <a href="https://devblogs.microsoft.com/cesardelatorre/implementing-background-tasks-in-microservices-with-ihostedservice-and-the-backgroundservice-class-net-core-2-x/">Microsoft</a></em></p>
<p>In the <code>Host.cs</code> there’s a separate <code>StartAsync</code> method and we can find the following lines inside it.</p>
<div data-language="csharp"><pre><code>_hostedServices <span>=</span> Services<span>.</span><span><span>GetService</span><span><span>&lt;</span>IEnumerable<span>&lt;</span>IHostedService<span>&gt;</span><span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>

<span>foreach</span> <span>(</span><span><span>var</span></span> hostedService <span>in</span> _hostedServices<span>)</span>
<span>{</span>
    
    <span>await</span> hostedService<span>.</span><span>StartAsync</span><span>(</span>combinedCancellationToken<span>)</span><span>.</span><span>ConfigureAwait</span><span>(</span><span>false</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>So our guess was correct. It certainly invokes the <code>StartAsync</code> method of <code>BackgroundService</code>, that calls <code>ExecuteAsync</code> method in which we have ultimately implemented in our <code>Worker</code> class.</p>
<p>For a web host, there’s a little bit of abstraction on top of this before it hits the above section. A summary of how it reaches this as follows;</p>
<ol>
<li>In Program.cs, configure a new webhost builder object in ConfigureWebHostDefaults</li>
<li>Register Startup class</li>
<li><code>GenericHostBuilderExtensions.ConfigureWebHostDefaults</code> method gets called</li>
<li><code>GenericHostWebHostBuilderExtensions.ConfigureWebHost</code> gets called</li>
<li>Register a <code>GenericWebHostService</code> service</li>
</ol>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span>IHostBuilder</span> <span>ConfigureWebHost</span><span>(</span><span>this</span> <span>IHostBuilder</span> builder<span>,</span> <span>Action<span>&lt;</span>IWebHostBuilder<span>&gt;</span></span> configure<span>)</span>
<span>{</span>
    <span><span>var</span></span> webhostBuilder <span>=</span> <span>new</span> <span>GenericWebHostBuilder</span><span>(</span>builder<span>)</span><span>;</span>
    <span>configure</span><span>(</span>webhostBuilder<span>)</span><span>;</span>
    builder<span>.</span><span>ConfigureServices</span><span>(</span><span>(</span>context<span>,</span> services<span>)</span> <span>=&gt;</span> services<span>.</span><span><span>AddHostedService</span><span><span>&lt;</span>GenericWebHostService<span>&gt;</span></span></span><span>(</span><span>)</span><span>)</span><span>;</span>
    <span>return</span> builder<span>;</span>
<span>}</span></code></pre></div>
<p>So what is a <code>GenericWebHostService</code> ? It’s an <code>IHostedService</code> 🤩. Rest of the story is as above as we looked at in the worker service scenario. Because of this nicely decoupled initialisation we are able to run both ASP.NET Core and Worker services on the Generic Host.</p>
<h3>Summary</h3>
<p>To summarise, we looked at what makes the Generic Host <em>generic</em> and dug deeper into the implementation details in .NET Github repo. We also looked at what makes an ASP.NET Core web application and a worker service different, configuration-wise. This post became a bit longer than I initially I thought it would be 😅 Nevertheless, hope you picked up a thing or two.</p>
<p>Cheers!</p>
<h3>References</h3>
<ol>
<li><a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view=aspnetcore-3.1&amp;tabs=visual-studio">https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view=aspnetcore-3.1&amp;tabs=visual-studio</a></li>
<li><a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.1">https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.1</a></li>
<li><a href="https://andrewlock.net/exploring-the-new-project-file-program-and-the-generic-host-in-asp-net-core-3/">https://andrewlock.net/exploring-the-new-project-file-program-and-the-generic-host-in-asp-net-core-3/</a></li>
</ol></div></div>]]>
            </description>
            <link>https://sahansera.dev/dotnet-core-generic-host/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151361</guid>
            <pubDate>Thu, 13 Aug 2020 23:49:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google play music shutting down]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24150597">thread link</a>) | @abuckenheimer
<br/>
August 13, 2020 | https://blog.youtube/news-and-events/youtube-music-will-replace-google-play-music-end-2020/ | <a href="https://web.archive.org/web/*/https://blog.youtube/news-and-events/youtube-music-will-replace-google-play-music-end-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="jump-content" tabindex="-1">
            
  <article>
    
    


<div>

<section>
    
    <div>
      
      <div>
        <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/GPM_15s_en_US_1.gif" alt="YouTube Music will replace Google Play Music by end of 2020">
        
        </p>
      </div>
      <p>
        <article>
          Today we're announcing two important updates.
        </article>
      </p>
    </div>
  </section>
</div>


    
      
        



<section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><p>Over the past couple of months, we’ve been welcoming Google Play Music listeners to YouTube Music as they <a href="https://youtube.googleblog.com/2020/05/youtube-music-transfer-google-play-music-library.html">effortlessly transfer</a> their music libraries, personal taste preferences and playlists to YouTube Music. Today we're announcing two important updates. First, YouTube Music will replace Google Play Music by December 2020. Users will have the opportunity to transfer their music libraries from Google Play Music to YouTube Music in that timeframe. Second, in the coming months, Google Play Music users will no longer be able to stream from or use the Google Play Music app. Additionally, we are making changes to the Google Play store and Music Manager.&nbsp;</p><p>Starting in September 2020 in New Zealand and South Africa — and in October for all other global markets — users will no longer be able to stream from or use the Google Play Music app. But don’t worry, we will be holding onto things like your playlists, uploads, purchases, likes and more until December 2020 to make your transfer to YouTube Music easier. Users who wish to transfer their music libraries from Google Play Music to YouTube Music, can do so through December 2020, after which their Google Play Music libraries will no longer be available.</p><h2>Simple transfer and additional changes to Music Manager</h2><p>Starting in late August, users will no longer be able to purchase and pre-order music or upload and download music from Google Play Music through Music Manager.&nbsp;</p><p>To ensure users don’t lose any of their content, they’ll need to use the simple<a href="http://music.youtube.com/transfer"> transfer tool</a> to migrate any purchases over to YouTube Music or use<a href="https://takeout.google.com/"> Google Takeout</a> to export data and download their purchased and uploaded music. Once the Music Store is no longer available, users will continue to be able to upload any tracks purchased elsewhere to YouTube Music.</p><p>For Google Play listeners that have not yet started the transfer process over to YouTube Music, now’s the time. Listeners can also choose to delete their Google Play Music data, and we will clearly notify all users before they lose access to their Google Play Music library and data.</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/unnamed_1_eb3YIiY.jpg" alt="GPM II">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><h2>Enhancements to your new home for music: YouTube Music&nbsp;&nbsp;&nbsp;</h2><p>Since<a href="https://youtube.googleblog.com/2020/05/youtube-music-transfer-google-play-music-library.html"> introducing the transfer tool in May</a>, we’ve continued to improve and add new features to YouTube Music for all music lovers to enjoy, including many that are important and familiar to Google Play Music users.&nbsp;</p><br><ul><li><p><b>Playlists: We’re continuously evolving the way listeners can create and enjoy playlists, including:</b></p></li><ul><li><p><b>Assistive Playlist Creation </b>- Quickly and easily create playlists by adding recommended songs based on existing songs in the playlist, as well as personalized signals, such as watch history and likes.</p></li><li><p><b>Collaborative Playlists</b> - Collaborate with other music fans to create shared playlists for any occasion.</p></li><li><p><b>New Programmed Playlists </b>- Explore newly launched programmed playlists like <a href="https://music.youtube.com/playlist?list=RDCLAK5uy_mu-BhJj3yO1OXEMzahs_aJVtNWJwAwFEE">Highline</a>, <a href="https://music.youtube.com/playlist?list=RDCLAK5uy_kUFCSc-grF3m-L_49W6p1QyGsMbueEbog">Caribbean Pulse</a>, <a href="https://music.youtube.com/playlist?list=RDCLAK5uy_m0Nsi5Jnn_g6qbvc7fywPRhEv1qN0PcMM">Conditions Underground</a>, and more.</p></li></ul><li><p><b>New Features and Improvements:&nbsp;</b></p></li><ul><li><p><b>Player Page Redesign</b> - Updates to the player page, available for Android mobile users, provides a more modern design that allows better playback controls and easier access to related music and other features like song lyrics.</p></li><li><p><b>Explore Tab</b> -&nbsp;The new Explore tab, available on both mobile and the web is the consistent destination to find new releases including albums, singles, and music videos, as well as browse our vast catalog of diverse playlists through the Moods &amp; Genre section</p></li></ul><li><p><b>More Ways to Enjoy YouTube Music:</b></p></li><ul><li><p><b>Android TV</b> - An update for Android TV brings YouTube Music to the big screen, letting listeners enjoy videos and live performances from their favorite artists, along with all their favorite music.</p></li><li><p><b>Google Maps</b> - The Android integration lets listeners seamlessly listen to music and get personalized music recommendations within the Google Maps interface.</p></li><li><p><b>Discover music with Google Assistant</b> - You can now ask your Google Home and Nest smart speakers, “Hey Google, play recommended music from YouTube Music.” Then, Google Assistant will share personalized recommendations based on your favorite artists and genres.&nbsp;</p></li></ul></ul></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><p>Over the last few years, we've worked to build a fantastic fan experience on YouTube Music, merging the very best of Google Play Music with the very best of YouTube. For users who decide not to transfer their Google Play Music account to YouTube music, we will be sure to cancel your subscription at the end of your billing cycle so you aren't paying for a subscription. This will happen in September in New Zealand and South Africa and in October for all other markets. And, of course, we will be sure to notify all users ahead of subscriptions being canceled.</p><p>We can’t wait for you to start exploring YouTube Music features and discovering new music favorites along the way. Have more questions or need help? Check out all of our support resources <a href="https://support.google.com/youtubemusic/answer/9698084">here</a>.</p><br></div>
      </div>
      
    </div>
  </div>
</section>

      
    

    


<section>
  <article>
    
  </article>
</section>


    
    
  


  </article>


        </div></div>]]>
            </description>
            <link>https://blog.youtube/news-and-events/youtube-music-will-replace-google-play-music-end-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24150597</guid>
            <pubDate>Thu, 13 Aug 2020 22:48:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JavaScript Face Detection and Recognition Libraries 2020]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24150436">thread link</a>) | @truly_furqan
<br/>
August 13, 2020 | https://www.edopedia.com/blog/javascript-face-detection-and-recognition-libraries/ | <a href="https://web.archive.org/web/*/https://www.edopedia.com/blog/javascript-face-detection-and-recognition-libraries/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
<p>Face detection, recognition and tracking are revolutionary technologies that have been deployed on mobile phones, webcams, and digital cameras. With the help of this advancement in technology, we are now able to detect human faces and recognize any specific person in a crowd.</p>
<p>This is a really superb and game changer innovation that has taken the technology world by storm. Now it’s only a matter of time for face detection technology to be deployed across different web applications in different sectors.</p>
<p>In digital cameras, face detection technology is used for the purpose of autofocus; in webcams, it is used to take an instant passport-sized photograph of you; and in mobile phones, it is one measure used for the authentication of its user.</p>
<p>The future of face detection and recognition technology is very promising. This is because it is successfully used by the police and other law enforcement agencies to detect and fight crime in many countries of the world.</p>
<p>Actually, the below-mentioned libraries are using Artificial Intelligence and Machine Learning algorithms/models to detect a face. This is not a simple or straightforward task but some highly professional programmers have created different JavaScript libraries and frameworks to help us use this new technology in our web applications.</p>
<p>Now, if you are like me who is curious to learn about the actual working of these libraries. Maybe you want to create a similar JavaScript library yourself. Then, I would highly recommend you to take this <strong><a href="https://click.linksynergy.com/deeplink?id=QSpACVN268M&amp;mid=39197&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fcourse%2Fmachine-learning-with-javascript%2F" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">“Machine Learning with Javascript Course”</a></strong> from Udemy.</p>
<p>Over 19,000 students are already enrolled in this course. Also, it has received 4.6 stars rating from 1,900+ students. So, this course can be a life-changer for you.</p>
<p>Anyways, let’s have a look at these amazing JavaScript face detection and recognition libraries.</p>
<hr>
<h2>tracking.js</h2>
<p>This JavaScript library is packed with a deluge of algorithms and capabilities for tackling different aspects of face detection and recognition within a web browser. It works very instinctively. Face detection, recognition and color tracking are done instantly. This is one of the best JavaScript face detection and recognition libraries.</p>
<p><a href="https://trackingjs.com/examples/face_tag_friends.html" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/eduardolundgren/tracking.js/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>face-api.js</h2>
<p>This is another JavaScript library for the detection and recognition of human faces. It makes use of the tensorflow.js core API for its proper working inside the web browser. You can use this library to track and detect a face in real-time.</p>
<p><a href="https://justadudewhohacks.github.io/face-api.js/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/justadudewhohacks/face-api.js" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>clmtrackr</h2>
<p>clmtrackr is also an open source face detection library like the ones I’ve mentioned above. You can download it from GitHub for free.</p>
<p>It makes use of Constrained Local Models to precisely identify and track the facial features. It then returns an array, which contains all the coordinates of a face model.</p>
<p>The interesting thing about clmtrackr is that it is capable of face swapping and masking. It really forms an all-in-one package.</p>
<p><a href="https://www.auduno.com/clmtrackr/examples/clm_image.html" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/auduno/clmtrackr" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>pico.js</h2>
<p>One of the JavaScript face detection and recognition libraries is pico.js. It is made up of roughly 200 lines of clean JavaScript code.</p>
<p>In its GitHub repository, you will find 3 major folders e.g. “img”, “cam” and “wasm”. All of these folders contain basic demo of how this library works. Its “img” folder has an example which clearly demonstrates how you can detect a human face in images. The “cam” folder contains a demo which shows the tracking of face in real-time. Basically “wasm” folder is there to provide an example about how you can compile pico.js to WebAssembly.</p>
<p><a href="https://tkv.io/posts/picojs-intro/demo/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/tehnokv/picojs" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>jeelizWeboji</h2>
<p>jeelizWeboji.js is a JavaScript/WebGL library that is used to detect and replicate different expressions on faces. It runs perfectly on typical webcams. The face detection is very effective because it can easily work in all kinds of lighting conditions.</p>
<p><a href="https://jeeliz.com/demos/weboji/demos/threejs/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/jeeliz/jeelizWeboji" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>jeelizFaceFilter</h2>
<p>This is another unique JavaScript/WebGL library that solely does real-time face tracking and detection in videos recorded using a webcam. Its features include face detection and tracking, mouth opening detection, face rotation detection, detect multiple faces, support for 3D engines like BABYLON.JS, THREE.JS, A-FRAME and many more. It is highly mobile-friendly too.</p>
<p><a href="https://jeeliz.com/demos/faceFilter/demos/threejs/headControls/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/jeeliz/jeelizFaceFilter" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>js-objectdetect</h2>
<p>This is an object detection JavaScript library that runs smoothly on any web browsers. It gives its output in real-time. It is well supported by all the latest web browsing applications. Basically the main purpose of using this library is to bring computer vision right inside your favorite web browser without any issues.</p>
<p><a href="http://mtschirs.github.io/js-objectdetect/examples/example_image.htm" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/mtschirs/js-objectdetect/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>face-recognition.js</h2>
<p>This is another face recognition program. It is both a JavaScript and a TypeScript API. It is available in the form of node.js package. Apart from face recognition and detection, it also identifies face landmarks.</p>
<p><a href="https://github.com/justadudewhohacks/face-recognition.js" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>jQuery Face Detection Plugin</h2>
<p>jQuery Face Detection Plugin helps to detect different human faces inside an image, canvas or video. It makes use of an advanced algorithm to get an array of all the objects found in a face. These objects include coordinates, height and width, offset, position, scale and confidence of a face.</p>
<p><a href="http://facedetection.jaysalvat.com/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/jaysalvat/jquery.facedetection" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>JS-face-tracking-demo</h2>
<p>This is a face tracking JavaScript library demo. This program consists of JavaScript, HTML and CSS.</p>
<p><a href="https://kdzwinel.github.io/JS-face-tracking-demo/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/kdzwinel/JS-face-tracking-demo" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>headtrackr</h2>
<p>This JavaScript package is specifically developed for tracking the face and head of a person. It works perfectly through a webcam. It basically tracks someone’s head position in proportion to the screen of the computer. This JavaScript library gives an accurate output when deployed on the modern web browsers.</p>
<p><a href="https://www.auduno.com/headtrackr/examples/facetracking.html" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/auduno/headtrackr" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>Kittydar</h2>
<p>This is very interesting, to say the least. Face detection functionality has gone beyond detecting the faces of humans; it is now used on animals. Kittydar is a face detection JavaScript library used for detecting the face of cats in an image/canvas. Once the cat is standing upright and facing forward, Kittydar will surely recognize it with a high level of accuracy.</p>
<p><a href="http://harthur.github.io/kittydar/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/harthur/kittydar" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>ccv-purejs</h2>
<p>ccv-purejs is a great example of JavaScript face detection libraries that can be downloaded from GitHub. Actually this library makes use of node-canvas to work effectively with node and npm. Right now the package requires you to load an image inside a canvas object. But according to the developer, he has planned to add the support for directly using an image path in future.</p>
<p><a href="https://github.com/orls/ccv-purejs" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>videojs-faceDetection</h2>
<p>This JavaScript library works in different environments. It makes use of the video.js player achieve face detection. Having a distinct support for videojs player makes it very unique. It is built on the back of a combination of JavaScript and HTML5 using an intuitive algorithm as usual. Its features include a custom data structure, simple image processing, grayscale, box blur and many more.</p>
<p><a href="https://github.com/benjipott/videojs-faceDetection" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>facedetector</h2>
<p>This is yet another face detection and tracking JavaScript library that is supported by a node.js program. Its face detection functionality is similar to others and also it works in real-time. It has implemented a really simple yet effective algorithm for tracking faces. It is capable of detecting so many faces in one photograph. You can use and distribute it for free because it is open source and available under MIT license.</p>
<p><a href="https://riversun.github.io/facedetector/example/index.html" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/riversun/facedetector" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>Conclusion</h2>
<p>Face detection and tracking have come to stay. It can only get better as more advancement is made in the future. JavaScript face detection and recognition libraries have helped in no small ways in making facial detection and recognition a reality.</p>
<p>The fact that it helps in fighting crime and used for authentication of the real owner of a mobile phone makes it a lot more compelling.</p>
<p>In the nearest future, it will be used on web applications and its usefulness will become irresistible. It may be deployed in schools during examinations to detect and recognize the faces of students who are allowed to appear in exam. It can also be used during the recruitment process. The future is already here. Our lives can only get better and smarter with the passage of time.</p>

			
					</div></div>]]>
            </description>
            <link>https://www.edopedia.com/blog/javascript-face-detection-and-recognition-libraries/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24150436</guid>
            <pubDate>Thu, 13 Aug 2020 22:36:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Blocks of Every Machine Learning Solutions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24150088">thread link</a>) | @FHMS
<br/>
August 13, 2020 | https://datarevenue.com/en-blog/machine-learning-project-architecture | <a href="https://web.archive.org/web/*/https://datarevenue.com/en-blog/machine-learning-project-architecture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Machine learning solutions are used to solve a wide variety of problems, but in nearly all cases the core components are the same. Whether you simply want to understand the skeleton of machine learning solutions better or are embarking on building your own, understanding these components - and how they interact - can help.</p><p>Here’s a visual and written explanation of what these are and what they do.</p><figure id="w-node-1017d6fd20b2-018ecc93"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5f2d1b1667b2cfe2a3ceec18_Q5H2ISpXvST4SJ7rp6-MMChpY5W_Bxul_c1g2CGCSMFSRNT_wlI1PT7XoxABOu-ftF6reUZVHRMHAzRKz7wXgxMz7umLRlFYq6gahk-GdlPW2ZUEL1M8PSuPPnNQK1nXNDV6HP2Y.png" alt="A diagram showing the components of a machine learning solution."></p><figcaption>Machine learning consists of many components, not just an algorithm. (Want more content like this? <a href="https://datarevenue.com/signup">Subscribe</a> to our newsletter).</figcaption></figure><p>‍<strong>The components of a machine learning solution</strong></p><ol role="list"><li><strong>Data Generation: </strong>Every machine learning application lives off data. That data has to come from somewhere. Usually it’s generated by one of your core business functions.</li><li><strong>Data Collection: </strong>Data is only useful if it’s accessible, so it needs to be stored – ideally in a consistent structure and conveniently in one place.</li><li><strong>Feature Engineering Pipeline:</strong> Algorithms can't make sense of raw data. We have to select, transform, combine, and otherwise prepare our data so the algorithm can find useful patterns.</li><li><strong>Training:</strong> This is where the magic happens. We apply algorithms, and they learn patterns from the data. Then they use these patterns to perform particular tasks.</li><li><strong>Evaluation: </strong>We need to carefully test how well our algorithm performs on data it hasn’t seen before (during training). This ensures we don’t use prediction models that work well on “seen” data, but not in real-world settings.</li><li><strong>Task Orchestration:</strong> Feature engineering, training, and prediction all need to be scheduled on our compute infrastructure (such as AWS or Azure) – usually with non-trivial interdependence. So we need to reliably orchestrate our tasks.</li><li><strong>Prediction:</strong> This is the moneymaker. We use the model we’ve trained to perform new tasks and solve new problems – which usually means making a prediction.</li><li><strong>Infrastructure: </strong>Even in the age of the cloud, the solution has to live and be served somewhere. This will require setup and maintenance.&nbsp;</li><li><strong>Authentication:</strong> This keeps our models secure and makes sure only those who have permission can use them.</li><li><strong>Interaction:</strong> We need some way to interact with our model and give it problems to solve. Usually this takes the form of an API, a user interface, or a command-line interface.<strong>‍</strong></li><li><strong>Monitoring: </strong>We need to regularly check our model’s performance. This usually involves periodically generating a report or showing performance history in a dashboard.</li></ol><h2><strong>Building your own ML Architecture</strong></h2><p>Data generation and collection, training, and evaluation are must-haves, but you may need domain-specific components too.</p><p>A <a href="https://datarevenue.com/en-blog/building-ai-projects-or-hiltch-skyline-ai">common mistake we see</a> is people focussing too much on the prediction component and not enough on the feature engineering pipeline (or trying to skip this component completely).</p><p>Do you need a second opinion on how to set up the architecture for your ML applications? <a href="https://datarevenue.com/en-contact">Schedule a call</a> with us.</p></div></div></div></div>]]>
            </description>
            <link>https://datarevenue.com/en-blog/machine-learning-project-architecture</link>
            <guid isPermaLink="false">hacker-news-small-sites-24150088</guid>
            <pubDate>Thu, 13 Aug 2020 22:07:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: 33% Memory Reduction by Reordering Struct Fields]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24149637">thread link</a>) | @lanecwagner
<br/>
August 13, 2020 | https://qvault.io/2020/08/07/saving-a-third-of-our-memory-by-re-ordering-go-struct-fields | <a href="https://web.archive.org/web/*/https://qvault.io/2020/08/07/saving-a-third-of-our-memory-by-re-ordering-go-struct-fields">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>In past projects at <a href="https://classroom.qvault.io/">Qvault</a> we had an application that typically ran with <strong>~2GB</strong> in memory at any given time. By simply changing the order of some <code>uint</code> variables we managed to drop the memory usage to less than <strong>1.4GB</strong>. The vast majority of this allocated memory is due to an enormous slice of <code>stats</code> structs.</p>



<p>The <code>stats</code> struct has the following type definition:</p>



<pre><code lang="go">type stats struct {
	NumPosts uint8
	Reach    uint16
	NumLikes uint8
}</code></pre>



<p>In theory, this struct will use a measly 4 bytes. Each <code>uint8</code> uses 1 <code>byte</code>, and the single <code>uint16</code> needs 2. We began to suspect that we had some wasteful memory issues, so I built the following little program to show how memory is being used by our struct:</p>



<pre><code lang="go">package main

import (
	"fmt"
	"reflect"
	"runtime"
)

type stats struct {
	NumPosts uint8
	Reach    uint16
	NumLikes uint8
}

func main() {
	typ := reflect.TypeOf(stats{})
	fmt.Printf("Struct is %d bytes long\n", typ.Size())
	n := typ.NumField()
	for i := 0; i &lt; n; i++ {
		field := typ.Field(i)
		fmt.Printf("%s at offset %v, size=%d, align=%d\n",
			field.Name, field.Offset, field.Type.Size(),
			field.Type.Align())
	}

	allStats := []stats{}
	for i := 0; i &lt; 100000000; i++ {
		allStats = append(allStats, stats{})
	}

	printMemUsage()
}

func printMemUsage() {
	var m runtime.MemStats
	runtime.ReadMemStats(&amp;m)
	fmt.Printf("Alloc = %v MiB", bToMb(m.Alloc))
	fmt.Printf("\tTotalAlloc = %v MiB", bToMb(m.TotalAlloc))
	fmt.Printf("\tSys = %v MiB", bToMb(m.Sys))
	fmt.Printf("\tNumGC = %v\n", m.NumGC)
}

func bToMb(b uint64) uint64 {
	return b / 1024 / 1024
}</code></pre>



<p>On my MacBook using Go 1.14.1 the above program prints:</p>



<pre><code lang="bash">Struct is 6 bytes long
NumPosts at offset 0, size=1, align=1
Reach at offset 2, size=2, align=2
NumLikes at offset 4, size=1, align=1
Alloc = 1084 MiB        TotalAlloc = 3012 MiB   Sys = 2713 MiB  NumGC = 19</code></pre>



<p>Notice that even though <code>NumPosts</code> only has a size of 1 byte, the next field, <code>Reach</code>, still starts at offset 2. A whole byte is being wasted! The same thing happens with the <code>NumLikes</code> field, it starts at offset 4 with a size of 1, but the struct still takes up the full 6 bytes.</p>



<p>This may not seem like a big deal, but when you are storing millions of these structs in memory the bloat starts to add up quick.</p>



<p>If we change the <code>stats</code> struct such that the <code>uint16</code> isn’t defined between the <code>uint8</code>s:</p>



<pre><code lang="go">type stats struct {
	Reach    uint16
	NumPosts uint8
	NumLikes uint8
}</code></pre>



<p>Then the output of the program becomes:</p>



<pre><code lang="bash">Struct is 4 bytes long
Reach at offset 0, size=2, align=2
NumPosts at offset 2, size=1, align=1
NumLikes at offset 3, size=1, align=1
Alloc = 694 MiB TotalAlloc = 1927 MiB   Sys = 1391 MiB  NumGC = 19</code></pre>



<p>The total allocated memory drops from 3 GB to less than 2, and each instance of the struct now only uses 4 bytes.</p>



<h2>Why?</h2>



<p>Modern CPU hardware performs reads and writes to memory most efficiently when the data is&nbsp;<em><a href="https://en.wikipedia.org/wiki/Data_structure_alignment" target="_blank" rel="noreferrer noopener">naturally aligned</a></em>. The memory that is stored side by side should be accessible using a common multiple, so the Go compiler makes sure that it is.</p>



<p>With our first struct, the Reach field is between the NumPosts and NumLikes fields, which means that the compiler will add some padding to keep things nice and even. </p>



<figure><img loading="lazy" width="1024" height="645" src="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-1024x645.png" alt="golang memory usage struct alignment" srcset="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-1024x645.png 1024w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-300x189.png 300w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-768x484.png 768w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM.png 1194w" sizes="(max-width: 1024px) 100vw, 1024px" title="Screen Shot 2020 08 07 at 2.51.09 PM"></figure>



<p>In our updated struct however, we have grouped the smaller fields, and since they add up to the same amount of memory as the larger <code>Reach</code> field we can save some space!</p>



<figure><img loading="lazy" width="1024" height="624" src="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-1024x624.png" alt="golang memory usage struct alignment fixed" srcset="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-1024x624.png 1024w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-300x183.png 300w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-768x468.png 768w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM.png 1178w" sizes="(max-width: 1024px) 100vw, 1024px" title="Screen Shot 2020 08 07 at 2.54.26 PM"></figure>



<p>This was is a weird quirk, but making the smal optimizations has made a huge impact on some of our services.</p>



<div><div>
<h2>Thanks For Reading!</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault" rel="noopener">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe" rel="noopener">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>

		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/08/07/saving-a-third-of-our-memory-by-re-ordering-go-struct-fields</link>
            <guid isPermaLink="false">hacker-news-small-sites-24149637</guid>
            <pubDate>Thu, 13 Aug 2020 21:34:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Knurling-Rs Announcement]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24149469">thread link</a>) | @lukastyrychtr
<br/>
August 13, 2020 | https://ferrous-systems.com/blog/knurling-rs/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/knurling-rs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://ferrous-systems.com/images/knurling-rs.png" alt="Knurling-rs"></p>

<p>Today we're announcing <a href="https://github.com/knurling-rs">Knurling</a> - Ferrous' effort to sustainably build better tooling for developing and debugging Rust software for embedded systems.</p>

<p>To make this a reality, we are opening a <a href="https://github.com/knurling-rs/meta">GitHub organization</a> to collect these efforts, as well as making it possible to <a href="https://github.com/sponsors/knurling-rs">support our efforts through GitHub Sponsors</a>.</p>

<h2 id="the-mission">The Mission</h2>

<p>We believe that developing software for embedded systems should be no more difficult than developing for hosted platforms. It should be possible to use the same workflows and equally powerful tooling to develop applications and libraries for tiny embedded systems as well as server-class hardware.</p>

<p>To that end, we want to enable:</p>

<ul>
  <li>Learning embedded Rust with up to date and maintained teaching material</li>
  <li>Space-efficient and real-time capable logging</li>
  <li>Tools that integrate into your standard cargo run and cargo test workflows</li>
  <li>Execution tracing</li>
  <li>Simple data logging and visualization straight into your IDE or Browser</li>
</ul>

<p>We are already active contributors in the open source ecosystem, but we want to spend more time dedicated to building tools that improve the experience for the entire ecosystem, and we can't do that without <a href="https://github.com/sponsors/knurling-rs">your support</a>.</p>

<h2 id="release-model">Release Model</h2>

<p>We plan to make everything we develop under Knurling to be open source, in order to support the community. This includes all of the tooling, teaching material, and support libraries we develop.</p>

<p>The items we release will all be under <a href="https://opensource.org/licenses/MIT">MIT</a>+<a href="https://www.apache.org/licenses/LICENSE-2.0.html">Apache 2.0</a> licenses for code, and <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC-BY-SA 4.0</a> for written material.</p>

<p>Sponsors will also have early access to work in progress tools and libraries before they are released, as well as early access to our training material and exercises before they are made public.</p>

<p>Early Access is available for all sponsors, regardless of tier.</p>

<p>Let's take a quick tour of the things we plan to make possible with <a href="https://github.com/knurling-rs/meta">Knurling</a>:</p>



<blockquote>
  <p>EDIT: This blog post has been updated to reflect the rename of <code>binfmt</code> to <code>defmt</code>.</p>
</blockquote>

<p><img src="https://ferrous-systems.com/images/defmt-teaser.jpg" alt="defmt preview"></p>

<p>We'd like to spend time to make it easier to design, build, debug, and release software components with embedded Rust. This includes developing target-side libraries, as well as host-side applications that interact with these components.</p>

<p>We also want to make it possible to have best-in-class debugging tools, allowing you to monitor, graph, and visualize what your system is doing. We think that it's possible to make developing embedded systems painless through better and extensible tooling!</p>

<p>The first of these tools we plan to release is <code>defmt</code> (in the screenshot above), a tool for efficient logging and tracing in real-time, using a variety of different transport methods like Semihosting, RTT, or even a UART or radio. <code>defmt</code> will allow for logging of data without incurring expensive formatting costs on the device itself.</p>

<p>We'll be talking more about defmt next week on our blog, but you can check it out now if you <a href="https://github.com/sponsors/knurling-rs">become a sponsor today</a>!</p>

<h2 id="more-training-and-learning-examples">More Training and Learning Examples</h2>

<p><img src="https://ferrous-systems.com/images/emb-trainings.png" alt="embedded trainings"></p>

<p>We're already developing open source training material for embedded systems in Rust, including our training material for <a href="https://github.com/ferrous-systems/teaching-material/">basic Rust training</a>, the material for our <a href="https://github.com/ferrous-systems/embedded-trainings">2019 Embedded Trainings</a>, as well as our most recent <a href="https://github.com/ferrous-systems/embedded-trainings-2020">2020 Embedded Trainings</a>.</p>

<p>We plan to develop a new, continuously maintained set of training material that consists of two parts:</p>

<p>The first part is <strong>Knurling Books</strong>, which are written guides that teach general concepts of embedded systems and Rust, and come with associated sample projects demonstrating the concepts. This is a great place for folks to learn embedded systems or embedded systems with Rust!</p>

<p>The second part is <strong>Knurling Sessions</strong>, which are quarterly embedded projects that explore specific projects using generally available hardware, building full systems and components using microcontrollers, sensors, and actuators.</p>

<p>These will be guided, hands-on tutorials for building projects like a CO2 Sensor, Data Loggers, and even robots! For folks that want to learn in a more hands-on way, or want to know "what hardware should I buy to get started", Knurling Sessions are a great option!</p>

<p>Before each session, we'll announce the hardware we'll use and how we'll use it. If you want to follow along and build the project at home, we'll include links to purchase the hardware. We'll reuse components session to session, so you can start building your own collection of parts!</p>

<p>In the future, we plan to also offer video based training and Q&amp;A sessions where we explore the concepts in a deeper and more detailed way, great for learning how and why things are built.</p>

<p>As we mentioned, all of the <strong>Knurling Books</strong> and <strong>Knurling Sessions</strong> will be made public and open source, but <a href="https://github.com/sponsors/knurling-rs">Sponsors</a> will get early access to both!</p>

<p>We'll be announcing our first training books and sessions later in August, so stay tuned!</p>

<h2 id="more-experiments-and-ecosystem-improvements">More Experiments and Ecosystem Improvements</h2>

<p><img src="https://ferrous-systems.com/images/async-on-embedded.png" alt="async on embedded"></p>

<p>In the past, we've done a number of experiments and improvements towards the Rust and Rust Embedded ecosystems. Most recently, we <a href="https://ferrous-systems.com/blog/embedded-async-await/">wrote about</a> making <a href="https://ferrous-systems.com/blog/async-on-embedded/">async/await</a> possible <a href="https://ferrous-systems.com/blog/stable-async-on-embedded/">for embedded systems</a>, and were even able to contribute optimizations that sped up compilation and run time for all users of async/await!</p>

<p>We released these experiments as <a href="https://github.com/ferrous-systems/async-on-embedded">an open source project</a>, and it has already been <a href="https://github.com/rust-embedded-community/async-on-embedded">transferred to community ownership</a>.</p>

<p>We'd like to dedicate more time to these kinds of projects, exploring what could be possible with embedded Rust, bringing crates to a maintained 1.0 status, or improving the compiler to benefit embedded systems developers. You can help us make this happen by <a href="https://github.com/sponsors/knurling-rs">sponsoring our efforts</a>!</p>

<h2 id="thank-you-all">Thank you all!</h2>

<p>We think the embedded Rust ecosystem is already the best way to develop embedded software today, but we can make it even better and easier, whether you are a developer who has never touched a microcontroller before, or you are a developer that is already an expert in embedded Rust.</p>

<p>If you'd like to support these works as an individual or through your company, we'd <a href="https://github.com/sponsors/knurling-rs">appreciate it a lot</a>! If you're interested in more details, or there is something you'd like to see us do, <a href="mailto:knurling@ferrous-systems.com">just drop us an email</a>!</p>
</div></div>]]>
            </description>
            <link>https://ferrous-systems.com/blog/knurling-rs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24149469</guid>
            <pubDate>Thu, 13 Aug 2020 21:24:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Future of Automation: The End of Silos and Rise of Workflows]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24148532">thread link</a>) | @omi1997
<br/>
August 13, 2020 | https://cto.ai/blog/the-future-of-automation-the-end-of-silos-rise-of-workflows/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/the-future-of-automation-the-end-of-silos-rise-of-workflows/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<p>Tooling has always been a strategically important method for engineering teams to bolster efficiency. The latest research by <a href="https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/developer-velocity-how-software-excellence-fuels-business-performance?cid=soc-app">McKinsey &amp; Company</a>, where 440 senior engineering executives were surveyed, demonstrates that companies are 65% likely to be more innovative with better tooling. </p><p>There’s nothing new here, engineers have always looked at tooling as a source for automation. But with the report revealing that only 5% of executives listed tooling a top three method for software enablement. With technologies rapidly rising and falling, software companies need to be leaner than ever in their adoption of automation tools. </p><p>To master this accelerating shift, technical leaders need to look at automation adoption beyond engineering departments and view the software delivery process as a cross-departmental effort. If you’re one of the many forward-looking technical leads hoping to gain strategic advantages, here’s how to ensure automation success. </p><h2 id="devops-today-and-the-automation-of-tomorrow">DevOps Today and the Automation of Tomorrow</h2><p>Traditionally, the developer tooling market has always been geared towards engineers, where DevOps specialists would craft automation, pipelines, and processes by integrating different technologies for the developer, and the graphic below shows the current tools out there.</p><!--kg-card-begin: image--><figure><img src="https://lh3.googleusercontent.com/rT9GfCt5hb7rwD2AC_bDeFI-pDxKlW8a7SZ8MSQYywCh0hNXj8UxXfs7ZmEpEPeoMB5tWFsxgBr_UpjJrSfroqayELR9eVfvWco1bjr-jOH6P4-zF-Ct97DGJjmjD4cMSzveToM7"></figure><!--kg-card-end: image--><p>In essence, the automation that the tools above provide was built with developers in mind as the end-user. The end result yields greater developer satisfaction, as their talent and imagination are given the means to shine. </p><p>As evidenced by the <a href="https://services.google.com/fh/files/misc/state-of-devops-2019.pdf">2019 State of DevOps reports</a>, the software industry values speed and automation of delivery and tasks, and the report, in particular, asserts that strong tool-chains give developers a culture of “psychological safety,” effectively bolstering team productivity. With <a href="https://stripe.com/en-ca/reports/developer-coefficient-2018">$300 billion being lost annually in developer productivity</a>, we can see a real opportunity for automation to keep saving developers, and the overall business, precious time. </p><h2 id="a-movement-to-workflows">A Movement to Workflows</h2><p>There’s already been a movement in the software industry to streamline processes with automation. For example, GitOps is streamlining source control by tightly integrating it with CI/CD. But that just doesn’t go far enough. As the developer tooling market grows, more and more tools are now required to be integrated into the software delivery process, causing greater market fragmentation. Companies like Salesforce are even launching their own DevOps platforms, meaning vendor-specific integration is more of a challenge than ever before for DevOps teams who are looking to streamline their delivery across their technology portfolio.</p><p>So, as business toolchains grow, it has become more critical than ever to eliminate silos of automation creation and empower other functions across the business, especially that outside of engineering, to be able to automate on their own. Essentially the cost of automation ownership must be lowered to allow for a more frictionless process for automation to take place. In this scenario, we see the rise of the workflow – a set of tasks and processes whereby multiple tools can be seamlessly integrated. As such, businesses must see automation outside the lens of engineering, and look to democratize its extraordinary benefits across the entire business to other departments.</p><p>A great example of a company lowering the barriers to automation is Atlassian. The company announced a <a href="https://www.computerworld.com/article/3532328/atlassian-adds-no-code-automation-to-jira-cloud-products.html">no-code workflow creator</a> for any user across it’s Jira Cloud portfolio. &nbsp; </p><p>In parallel, an interesting insight provided by McKinsey, which was missing from other reports, is the growing benefits of low-code tools. The study reveals that low-code tools help organizations adopt automation advantages at a much lower cost of ownership and allow them to exponentially increase their leverage on their development talent. The study observed that teams were able to adopt automation much faster when the barrier to automation (i.e. code complexity) is lowered. This makes automation accessible to less technical team members and enhances self-service and cross-functional accessibility to automation through workflows that they can create to their own needs. </p><p>At CTO.ai, we rethought automation from the bottom up to address these challenges. We realized that the most obvious solution was not only to lower the cost of automation through low code, but also to bring these developer tools to the place where people meet across the entire organization – Slack – and more specifically, SlackOps or DevOps in Slack (often more generally called ChatOps in the industry).</p><p>We further realized that businesses need an easy platform that all employees can leverage. By bringing the ease of chat and automation in a shared and transparent environment such as Slack, there’s an opportunity for businesses to significantly reduce inefficiencies and turbocharge productivity. </p><h2 id="a-brave-new-automation">A Brave New Automation</h2><p>With automation changing form, there will be winners and losers concerning how businesses approach the new world we’re entering. Businesses that are unwilling to begin implementing changes in their software development tooling and wider business access to workflow creation will be left behind. </p><p>For technical leadership, this is an opportunity to export engineering-based concepts and ideas such as CI/CD, automation testing, and more to other departments. Engineering departments have, generally speaking, long been ahead of other departments in regards to optimization, and use of automation. After all, engineers can code, but other departments don’t have such requirements in their job descriptions. </p><p>We at CTO.ai continue to advocate for greater use of automation for DevOps and all departments. As we continue to iterate our cutting-edge technology for Slack workflows (SlackOps), not only does the rise of the workflow become an important factor in the accessibility of automation, but also the measurement of workflow efficacy becomes even more critical. As such, companies need to be cognizant of their workflow efficacy and therefore must continue to ever optimize for scale. This is why we’re also introducing a Workflow Metrics MVP, the first-concept measurement of workflow efficiency.</p><p><em>Want to see our private demo? Contact us by<a href="https://w.cto.ai/contact-us"> clicking here </a>to see the private Alpha of the MVP.</em></p>
			</div><!-- .post-content -->
			<!-- .post-footer -->
		</article></div>]]>
            </description>
            <link>https://cto.ai/blog/the-future-of-automation-the-end-of-silos-rise-of-workflows/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148532</guid>
            <pubDate>Thu, 13 Aug 2020 20:31:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Internationalization and Localization Matters]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148141">thread link</a>) | @gsilva49
<br/>
August 13, 2020 | https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html | <a href="https://web.archive.org/web/*/https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>According to the always trustworthy Wikipedia, there are approximately 360 million native English speakers in the world. We, as developers, are so used to write code and documentation in English that we may not realize that this number only represents 4.67% of the world population. It is very useful to have a common language for the communication between developers, but this doesn’t mean that the user shouldn’t feel a little bit more comfortable when using your product.</p>
<p>This post will start discussing the definition of internationalization and localization and why they matter for your application. Then we will go over some of the internationalization tools that developers have available to work on their Python and Django projects. Finally, we will present how we had to adapt our development flow to incorporate the internationalization step.</p>
<h2>Localization vs Internationalization</h2>
<p><strong>Localization (l10n</strong><sup id="fnref:1"><a href="#fn:1">1</a></sup><strong>)</strong> is the process of adapting an application, product or even a document to be more user-friendly to customers from different countries and cultures.</p>
<p>On the other hand, <strong>internationalization (i18n)</strong> is the process of enabling localization of the product on the application. Implementing a software in a way that it will know when and how to show different content depending on the costumer’s locale.</p>
<p>As the Django documentation perfectly summarizes: localization is done by translators and internationalization is done by developers<sup id="fnref:2"><a href="#fn:2">2</a></sup></p>
<p>However, this simplified definition of internationalization and localization may give the wrong impression that this is just about translation. This process entails several other adaptations needed to make users from different cultures feel more comfortable using your product, such as:</p>
<ul>
<li>Date and currency formatting</li>
<li>Currency conversion</li>
<li>Units of measurement conversion</li>
<li>Unicode characters and bidirectional text (see example below)</li>
<li>Time zones, calendar and special holidays</li>
</ul>
<p><img alt="Wikipedia homepage in English" src="https://labcodes.com.br/blog/images/internationalization/wikipedia_english.png">
<em>Wikipedia homepage in English</em></p>
<p><img alt="Wikipedia homepage in Arabic" src="https://labcodes.com.br/blog/images/internationalization/wikipedia_arabic.png">
<em>Wikipedia homepage in Arabic</em></p>
<p>With these adaptations, we can provide a better experience for the customer when using the application.</p>
<h2>How can we do that in Python?</h2>
<h3>GNU gettext</h3>
<p>There are some tools that can help localize your Python application. Starting with the GNU gettext package that is part of the Translation Project<sup id="fnref:3"><a href="#fn:3">3</a></sup>. This package offers:</p>
<ul>
<li>A runtime library that supports the retrieval of translated messages.</li>
<li>A set of conventions about how programs should be written to support message catalogs.</li>
<li>A library supporting the parsing and creation of files containing translated messages.</li>
</ul>
<p>The following code snippet is just a simple Hello World, a <code>app.py</code> file, where we are using the <code>gettext</code> Python module to create a translation object (<code>gettext.translation</code>) for our app domain, specifying a locale directory and the language that we want to translate our strings to. Then, we assign the gettext function to an underscore (a common practice to reduce the overhead of typing <code>gettext</code> for each translatable string) and, finally, we flag the string <code>“Hello World!”</code> to be translated.</p>
<div><pre><span></span><span>import</span> <span>gettext</span>

<span>gettext</span><span>.</span><span>bindtextdomain</span><span>(</span><span>"app"</span><span>,</span> <span>"/locale"</span><span>)</span>
<span>gettext</span><span>.</span><span>textdomain</span><span>(</span><span>"app"</span><span>)</span>
<span>t</span> <span>=</span> <span>gettext</span><span>.</span><span>translation</span><span>(</span><span>"app"</span><span>,</span> <span>localedir</span><span>=</span><span>"locale"</span><span>,</span> <span>languages</span><span>=</span><span>[</span><span>'en_US'</span><span>])</span>
<span>t</span><span>.</span><span>install</span><span>()</span>
<span>_</span> <span>=</span> <span>t</span><span>.</span><span>gettext</span>

<span>greeting</span> <span>=</span> <span>_</span><span>(</span><span>"Hello, world!"</span><span>)</span>
<span>print</span><span>(</span><span>greeting</span><span>)</span>
</pre></div>


<p>After flagging the translatable strings in the code, we can collect them using the GNU <code>xgettext</code> CLI tool. This tool generates a PO file containing all the strings that we have flagged.</p>
<p><code>xgettext -d app app.py</code></p>
<p>The PO file (which stands for Portable Object file) contains a list of entries and here is the basic structure of an entry:</p>
<div><pre><span></span>#  translator-comments
#. extracted-comments
#: reference…
#, flag…
#| msgid previous-untranslated-string
msgid untranslated-string
msgstr translated-string
</pre></div>


<p>We can add comments for translators, some references and flags for the string. Then we have the <strong>entry ID</strong> (<code>msgid</code>), which is the untranslated string flagged in the code and the <strong>entry string</strong> (<code>msgstr</code>) representing the translated version of the string.</p>
<p>When we run <code>xgettext</code> in the command line passing the <code>app.py</code> as input file, this is the PO file that is generated:</p>
<div><pre><span></span><span>"Project-Id-Version: PACKAGE VERSION\n"</span>
<span>"Report-Msgid-Bugs-To: \n"</span>
<span>"POT-Creation-Date: 2019-05-03 13:23-0300\n"</span>
<span>"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"</span>
<span>"Last-Translator: FULL NAME &lt;EMAIL@ADDRESS&gt;\n"</span>
<span>"Language-Team: LANGUAGE &lt;LL@li.org&gt;\n"</span>
<span>"Language: \n"</span>
<span>"MIME-Version: 1.0\n"</span>
<span>"Content-Type: text/plain; charset=UTF-8\n"</span>
<span>"Content-Transfer-Encoding: 8bit\n"</span>

<span>#</span><span>:</span> <span>app</span><span>.</span><span>py</span><span>:</span><span>7</span>
<span>msgid</span> <span>"Hello, world!"</span>
<span>msgstr</span> <span>""</span>
</pre></div>


<p>At the top of the file, we have some metadata about the file, the project and the translation process. Then, we have the untranslated string "Hello, world!" as the <strong>entry ID</strong> and an empty string for the <strong>entry string</strong>. If no translated string is provided for a certain entry, the entry ID will be used in the translation.</p>
<p>Once the PO file is generated, we can start translating our terms to different languages. It is important to notice that the GNU gettext library is going to look for translated PO files in a specific folder path structure (<code>&lt;localedir&gt;/&lt;language_code&gt;/LC_MESSAGES/&lt;domain&gt;.po</code>) and there must be one PO file for each language that you want to support.</p>
<div><pre><span></span>|-- app.py
|-- locale
   |-- en_US
   |   |-- LC_MESSAGES
   |       |-- app.po
   |-- pt_BR
       |-- LC_MESSAGES
       |   |-- app.po
</pre></div>


<p>Here is an example of the same PO file translated to Portuguese:</p>
<div><pre><span></span><span>"Project-Id-Version: PACKAGE VERSION\n"</span>
<span>"Report-Msgid-Bugs-To: \n"</span>
<span>"POT-Creation-Date: 2019-05-03 13:23-0300\n"</span>
<span>"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"</span>
<span>"Last-Translator: FULL NAME &lt;EMAIL@ADDRESS&gt;\n"</span>
<span>"Language-Team: LANGUAGE &lt;LL@li.org&gt;\n"</span>
<span>"Language: \n"</span>
<span>"MIME-Version: 1.0\n"</span>
<span>"Content-Type: text/plain; charset=UTF-8\n"</span>
<span>"Content-Transfer-Encoding: 8bit\n"</span>

<span>#</span><span>:</span> <span>app</span><span>.</span><span>py</span><span>:</span><span>7</span>
<span>msgid</span> <span>"Hello, world!"</span>
<span>msgstr</span> <span>"Olá, mundo!"</span>
</pre></div>


<p>In order to use the translated strings in the code, we need to compile the PO file into MO file using the <code>msgfmt</code> command.</p>
<p><code>msgfmt -o app.mo app.po</code></p>
<p>With the MO file in place, it is possible to change the language of the program to Portuguese in the languages input for the translation function. If we run the following code, the flagged string will get translated to “Olá, mundo!”:</p>
<div><pre><span></span><span>import</span> <span>gettext</span>

<span>gettext</span><span>.</span><span>bindtextdomain</span><span>(</span><span>"app"</span><span>,</span> <span>"/locale"</span><span>)</span>
<span>gettext</span><span>.</span><span>textdomain</span><span>(</span><span>"app"</span><span>)</span>
<span>t</span> <span>=</span> <span>gettext</span><span>.</span><span>translation</span><span>(</span><span>"app"</span><span>,</span> <span>localedir</span><span>=</span><span>"locale"</span><span>,</span> <span>languages</span><span>=</span><span>[</span><span>'pt_BR'</span><span>])</span>
<span>t</span><span>.</span><span>install</span><span>()</span>
<span>_</span> <span>=</span> <span>t</span><span>.</span><span>gettext</span>

<span>greeting</span> <span>=</span> <span>_</span><span>(</span><span>"Hello, world!"</span><span>)</span>
<span>print</span><span>(</span><span>greeting</span><span>)</span>
</pre></div>


<h3>Locale Module</h3>
<p>This module has access to POSIX locale database and is specially useful for handling dates, numbers and currencies format. The following example shows how to use the Locale library:</p>
<div><pre><span></span><span>import</span> <span>datetime</span>
<span>import</span> <span>locale</span>

<span>locale</span><span>.</span><span>setlocale</span><span>(</span><span>locale</span><span>.</span><span>LC_ALL</span><span>,</span> <span>locale</span><span>=</span><span>'en_US'</span><span>)</span>
<span>local_conv</span> <span>=</span> <span>locale</span><span>.</span><span>localeconv</span><span>()</span>
<span>now</span> <span>=</span> <span>datetime</span><span>.</span><span>datetime</span><span>.</span><span>now</span><span>()</span>
<span>some_price</span> <span>=</span> <span>1234567.89</span>
<span>formatted_price</span> <span>=</span> <span>locale</span><span>.</span><span>format</span><span>(</span><span>'</span><span>%1.2f</span><span>'</span><span>,</span> <span>some_price</span><span>,</span> <span>grouping</span><span>=</span><span>True</span><span>)</span>
<span>currency_symbol</span> <span>=</span> <span>local_conv</span><span>[</span><span>'currency_symbol'</span><span>]</span>

<span>print</span><span>(</span><span>now</span><span>.</span><span>strftime</span><span>(</span><span>'</span><span>%x</span><span>'</span><span>))</span>
<span>print</span><span>(</span><span>f</span><span>'{currency_symbol}{formatted_price}'</span><span>)</span>
</pre></div>


<p>In this example, we are importing the module, changing all locale settings to US English and retrieving the locale conventions. Using the <code>locale.format</code> method, we can format the number without worrying about decimal and thousands separator symbols. Using the <code>%x</code> directive to format the date, it will display day, month and year in the correct order for the locale. From the locale conventions, we are able to get the correct currency symbol.</p>
<p>This is the output of that Python code. We can see that the date is following the format of <code>Month/Day/Year</code>, tthe decimal separator is a dot while the thousands separator is a comma and there is a dollar sign to represent US currency.</p>
<div><pre><span></span>$ python format_example.py
<span>05</span>/03/2019
<span>$1</span>,234,567.89
</pre></div>


<p>Now using the same code, just changing the locale to Portuguese Brazil, we get a different output based on Brazilians conventions for formatting: the date is following <code>Day/Month/Year</code> format, we have comma as the decimal separator, dots as thousands separator and the R$ symbol to represent Brazilian currency Real.</p>
<div><pre><span></span><span>import</span> <span>datetime</span>
<span>import</span> <span>locale</span>

<span>locale</span><span>.</span><span>setlocale</span><span>(</span><span>locale</span><span>.</span><span>LC_ALL</span><span>,</span> <span>locale</span><span>=</span><span>'pt_BR'</span><span>)</span>
<span>local_conv</span> <span>=</span> <span>locale</span><span>.</span><span>localeconv</span><span>()</span>
<span>now</span> <span>=</span> <span>datetime</span><span>.</span><span>datetime</span><span>.</span><span>now</span><span>()</span>
<span>some_price</span> <span>=</span> <span>1234567.89</span>
<span>formatted_price</span> <span>=</span> <span>locale</span><span>.</span><span>format</span><span>(</span><span>'</span><span>%1.2f</span><span>'</span><span>,</span> <span>some_price</span><span>,</span> <span>grouping</span><span>=</span><span>True</span><span>)</span>
<span>currency_symbol</span> <span>=</span> <span>local_conv</span><span>[</span><span>'currency_symbol'</span><span>]</span>

<span>print</span><span>(</span><span>now</span><span>.</span><span>strftime</span><span>(</span><span>'</span><span>%x</span><span>'</span><span>))</span>
<span>print</span><span>(</span><span>f</span><span>'{currency_symbol}{formatted_price}'</span><span>)</span>
</pre></div>


<div><pre><span></span>$ python format_example.py
<span>03</span>/05/2019
R<span>$1</span>.234.567,89
</pre></div>


<h2>Does it get easier with Django?</h2>
<h3>Translations and Formatting</h3>
<p>Internationalization is enabled by default when you create your Django project. The translation module encapsulates the GNU library and provides the <code>gettext</code> function with translation setup based on the language received in the <strong>Accept-Language</strong> header, that is passed by the browser in the request object. So, all that Python code that we saw before is encapsulated in the django utils translation module so we can jump ahead and just use the gettext function in our view:</p>
<div><pre><span></span><span>from</span> <span>django.http</span> <span>import</span> <span>HttpResponse</span>
<span>from</span> <span>django.utils.translation</span> <span>import</span> <span>gettext</span> <span>as</span> <span>_</span>

<span>def</span> <span>my_view</span><span>(</span><span>request</span><span>):</span>
    <span>greetings</span> <span>=</span> <span>_</span><span>(</span><span>'Hello, World!'</span><span>)</span>
    <span>return</span> <span>HttpResponse</span><span>(</span><span>greetings</span><span>)</span>
</pre></div>


<p>For translations, we can flag translatable strings in both Python and template code (once we load the internationalization tags). The <code>trans</code> template tag translates a single string, while <code>blocktrans</code> tag is able to mark as translatable a block of strings, including variable content.</p>
<div><pre><span></span><span>&lt;</span><span>p</span><span>&gt;</span>{% trans "Hello, World!" %}<span>&lt;/</span><span>p</span><span>&gt;</span>
<span>&lt;</span><span>p</span><span>&gt;</span>{% blocktrans %}This string will have {{ value }} inside.{% endblocktrans %}<span>&lt;/</span><span>p</span><span>&gt;</span>
</pre></div>


<p>Besides the standard <code>gettext</code> function, in Django we can have lazy translations: the flagged string will only be translated when the value is used in a string context, such as in template rendering. This is specially useful for translating <code>help_text</code> and <code>verbose_name</code> attributes in the Django models.</p>
<p>Regarding GNU command line interface, django admin provides equivalent commands for the ones most used in the development process. To …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html">https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html</a></em></p>]]>
            </description>
            <link>https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148141</guid>
            <pubDate>Thu, 13 Aug 2020 20:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research Says Solo Founders Perform Better]]>
            </title>
            <description>
<![CDATA[
Score 157 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24148113">thread link</a>) | @rmason
<br/>
August 13, 2020 | https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why | <a href="https://web.archive.org/web/*/https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-68erk"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label=""><p><img data-pin-url="https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why" data-pin-media="https://static.wixstatic.com/media/49c34c_add7b504cfd8464abddc1602dcb09c96~mv2.jpg/v1/fit/w_3508,h_1981,al_c,q_80/file.png" src="https://static.wixstatic.com/media/49c34c_add7b504cfd8464abddc1602dcb09c96~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt=""></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div><p><span>Better to be a Han Solo in startups? Credit: deviantart.com/dzikawa</span></p></div></div></div><p id="viewer-9t57p">A recent <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3107898" target="_blank" rel="noopener"><u>study</u></a> suggests that: </p><blockquote id="viewer-ah7c2">"Solo founders are <!-- -->more than twice as likely to own an ongoing, for-profit venture than two or more founders". </blockquote><p id="viewer-c6nq5">Or to put it in other words, ventures with solo founders are twice as likely to be profitable than ventures with 2 or more founders. See the graph below.</p><div id="viewer-5g984"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why" data-pin-media="https://static.wixstatic.com/media/49c34c_46bd6f501d98445cb0381d51c061589d~mv2.png/v1/fit/w_2560,h_1280,al_c,q_80/file.png" src="https://static.wixstatic.com/media/49c34c_46bd6f501d98445cb0381d51c061589d~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-bd3ie">How can that be true? And what could be the dangers of being a solopreneur that founders should watch out for? Let us explore!</p><h2 id="viewer-674bv">Why solo is better</h2><p id="viewer-bhfs4">As much as it may feel scary to go alone, there are good reasons to consider building a business alone, especially if you are spending a lot of time finding a co-founder.</p><h3 id="viewer-addh7">Reason #1: Speed</h3><p id="viewer-3mptm">As the famous African proverb goes, “If you want to go fast, go alone. If you want to go far, go together.” Solo founders move faster since they don't need to worry about the team alignment on every decision. And being fast can be argued to be the biggest advantage for a startup.</p><h3 id="viewer-d4jnc">Reason #2: Founder disagreements</h3><p id="viewer-bsbd7"><a href="https://www.cbinsights.com/research/startup-failure-reasons-top/#:~:text=Not%20pivoting%20away%20or%20quickly,by%20a%20lack%20of%20progress" target="_blank" rel="noopener"><u>Top 3 reason</u></a><u>s</u> why startups fail is the founder team in-fighting. Sounds wrong to say this, but no co-founders - no problems.</p><h3 id="viewer-8l2gn">Reason #3: Lower costs</h3><p id="viewer-6jfou">It seems like there is no big difference between one person on the team and three, but at the early stage, even small differences matter a lot. Whether you need an office, and how many salaries you need to pay are all crucial questions at the start.</p><h3 id="viewer-6su88">Reason #4: Taking risks</h3><p id="viewer-bg12b">Founding a startup is a big risk. Three people who've already sacrificed quite a bit tend to be more risk-averse and the chances of someone choosing the safer path are higher. </p><h2 id="viewer-f2gim">The dangers of going solo</h2><p id="viewer-fuou5">We will be honest - going solo is not for everyone. Consider the following dangers:</p><h3 id="viewer-3t7ks">Danger #1: Funding</h3><p id="viewer-cdd78">It's the sad truth that due to Y Combinator and Paul Graham's gospel, the Zeitgeist of our times is that being a solo founder means that you just couldn't convince your friends to join and therefore can't be trusted. Solo founders tend to receive considerably less funding, yet it could also play to their advantage, allow them to grow more organically and make fewer stupid mistakes.</p><h3 id="viewer-50pot">Danger #2: Lack of support </h3><p id="viewer-cte29">Loneliness and depression hit entrepreneurs harder and solo founders harder still. Solo founders might also miss on diverse perspectives. I would advise solo founders to get something called a hands-on advisor or joining a supportive community of solo founders like <a href="https://www.growthclub.online/?utm_source=growthclub&amp;utm_medium=solo_vs_team_article_body&amp;utm_campaign=content_promo" target="_blank" rel="noopener"><u>GrowthClub</u></a>. Both of those options are described in <a href="https://www.growthclub.online/post/advice-for-solo-founders?utm_source=growthclub&amp;utm_medium=solo_vs_team_article_body&amp;utm_campaign=content_promo" target="_blank" rel="noopener"><u>my previous article</u></a>.</p><h2 id="viewer-7kknt">In sum  </h2><p id="viewer-9mv3p">Solopreneurs move faster, avoid the drama of teams falling apart, reduce costs by default, and have an easier time taking risks. That being said, they should be aware of fewer funding opportunities and build their own support system.</p><p id="viewer-4an2c">Thanks for sticking till the end! I am a hands-on advisor at<a href="https://www.growthclub.online/?utm_source=growthclub&amp;utm_medium=solo_vs_team_article_footer&amp;utm_campaign=content_promo" target="_blank" rel="noopener"> <!-- -->GrowthClub</a>. GrowthClub is a community of founders with $5K+ MRR where founders exchange growth hacks and build genuine connections in 1-on-1 video calls.</p><p id="viewer-f6iut">I started with GrowthClub as a user. I liked it so much that I ended up helping the founder. Currently, after experiencing a great inflow of founders from our launch on <a href="https://www.producthunt.com/posts/growthclub" target="_blank" rel="noopener"><u>Product Hunt</u></a> and Indie Hackers <a href="https://www.indiehackers.com/post/community-the-new-business-model-for-indie-hackers-01908d3dc3" target="_blank" rel="noopener"><u>featured article</u></a>, we are signing up 30 hand-picked founders to form the core of our platform to actively iterate the product with them.</p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148113</guid>
            <pubDate>Thu, 13 Aug 2020 20:12:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comfortable C while Editing with Emacs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148112">thread link</a>) | @daptaq
<br/>
August 13, 2020 | https://zge.us.to/txt/emacs-c.html | <a href="https://web.archive.org/web/*/https://zge.us.to/txt/emacs-c.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://zge.us.to/txt/emacs-c.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148112</guid>
            <pubDate>Thu, 13 Aug 2020 20:12:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In search of the perfect pocket device]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148036">thread link</a>) | @todsacerdoti
<br/>
August 13, 2020 | https://isene.org/2020/08/Nerding.html | <a href="https://web.archive.org/web/*/https://isene.org/2020/08/Nerding.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>In my lock-down geekery, I have been searching for the perfect pocket computer setup.</p>

<p>Having been an <a href="https://youtu.be/czzuz1j364E">HP calculator collector</a> since a couple of decades, I have a passion for pocket computing power with really long battery life.</p>

<p>The <a href="https://isene.org/hp-41/">HP-41</a> is an amazing calculator with months of battery life. But it is still a calculator. I also want real computing power - with the ability to run <a href="https://en.wikipedia.org/wiki/Vim_(text_editor)">VIM</a> for editing text (with a decent keyboard) and as much of other goodies as I can cram into it.</p>

<p><img src="https://isene.org/assets/posts/nerdvana.png" alt=""></p>

<p>I started my quest for the perfect pocket computer with reviving my old <a href="https://en.wikipedia.org/wiki/HP_200LX">HP-200LX</a>. It’s a very early pocket computer running DOS 5.0 - and I have VIM running on it :-) Being a DOS device, it can run <a href="http://mizj.com/">lots of nice programs</a>. Yes, it is slow, but it is cool.</p>

<p>In search for a better keyboard, I got the <a href="http://phonedb.net/index.php?m=device&amp;id=840&amp;c=ericsson_mc218">Ericsson MC218</a> (a <a href="https://en.wikipedia.org/wiki/Psion_Series_5">Psion Series 5</a> pocket computer) up and running, hoping to make it boot Linux. While this is possible, it turns out that the CF card reader on the device was flaky, so I kept searching.</p>

<p>Some forums later, and I stumbled upon an interesting project - the <a href="https://n-o-d-e.net/zeroterminal.html">Zero Terminal</a>. Now we’re talking. A Raspberry PI Zero packed with all sorts of ports and expansion capabilities. But waiting for it? I’m not the patient type…</p>

<p>But wait a minute! I always carry my <a href="https://en.wikipedia.org/wiki/Samsung_Galaxy_S20">Samsung S20 Ultra</a> anyway. Couldn’t it serve all my needs? True, the battery life sucks. But as it is my cell phone, I always have it charged, so that shouldn’t be a problem. And with my <a href="https://www.aliexpress.com/item/33044680958.html?spm=2114.search0303.3.36.3e2f50e4kUuHVD&amp;ws_ab_test=searchweb0_0,searchweb201602_0,searchweb201603_0,ppcSwitch_0&amp;algo_pvid=c05d6fa4-cb6c-4b28-aaa8-9da88e98cd0f&amp;algo_expid=c05d6fa4-cb6c-4b28-aaa8-9da88e98cd0f-5">small, foldable bluetooth keyboard</a>, I have massive computing power with me at all times. An added benefit is that it can easily use a monitor or TV screen via the built-in <i>Smart View</i>.</p>

<p>The real kicker is that it runs VIM in all its galore - even with my <a href="https://isene.org/hyperlist/">HyperList</a> plugin. It runs <a href="https://www.ruby-lang.org/en/">Ruby</a> and my whole <a href="https://isene.org/2018/08/Amar-Tools.html">Amar Tools</a> <a href="https://github.com/isene/Amar-Tools">package</a>. And <a href="https://en.wikipedia.org/wiki/LaTeX">LaTeX</a> and <a href="https://www.ssh.com/ssh/">SSH</a> and <a href="https://weechat.org/">Weechat</a> and… you name it. Lots of terminal/console programs are readily available via <a href="https://termux.com/">Termux</a>.</p>

<p>But that’s not all you can do. With the X Server app <a href="https://play.google.com/store/apps/details?id=x.org.server&amp;hl=en">XSDL</a> and the <a href="https://play.google.com/store/apps/details?id=tech.ula&amp;hl=en">UserLand</a> app, you can in fact install a full Linux distro and fire it up on your Android phone. With the full glory of both terminals and graphical software. Run an <a href="https://i3wm.org/">i3</a> session with <a href="https://wiki.archlinux.org/index.php/Rxvt-unicode">urxvt</a> terminals running <a href="http://zsh.sourceforge.net/">zsh</a>, <a href="https://www.gimp.org/">Gimp</a>, <a href="https://www.libreoffice.org/">LibreOffice</a> and whatnot. Now, that’s Nerdvana!</p>

<p><img src="https://isene.org/assets/posts/userland.png" alt=""></p>

<p>So, from my HP-41, via the HP-200LX, the MC218 and looking at Zero Terminal, I found the answer right here in my pocket. Quite a detour. But ending in bliss :-)</p>

<hr>
<p>Link to this post: <a href="https://isene.org/2020/08/Nerding.html">https://isene.org/2020/08/Nerding.html</a></p>

            </div></div>]]>
            </description>
            <link>https://isene.org/2020/08/Nerding.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148036</guid>
            <pubDate>Thu, 13 Aug 2020 20:08:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GPT-3 to enrich NPC interactions in MUDs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148003">thread link</a>) | @teebes
<br/>
August 13, 2020 | https://blog.writtenrealms.com/gpt3/ | <a href="https://web.archive.org/web/*/https://blog.writtenrealms.com/gpt3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>How Written Realms is using the latest generation of Artificial Intelligence to animate its fictional worlds.</p><div>
<p>We were fortunate enough to receive an invite to the <a href="https://openai.com/blog/openai-api/">OpenAI private beta</a> a few weeks ago, gaining an interface to their <a href="https://arxiv.org/abs/2005.14165">GPT-3</a> engine. Using AI for mob interactions within <a href="https://writtenrealms.com/">Written Realms</a> had been a long term goal of ours for many years, and we jumped at the opportunity to play with it.</p>
<h2 id="howtheopenaiapiworks">How the OpenAI API works</h2>
<p>The OpenAI API provides a 'completion' endpoint (also available as a Python binding) for interacting with the GPT-3 engine.</p>
<p>Given a text prompt, the API attempts to complete the pattern that you gave it. For example if you give it an input of <code>1 2 4 8</code> and request 1 token back, you will get a response of: <code>16</code>. The API understood the pattern to be a doubling function and gave the next result.</p>
<p>It's not limited to math. If you give as input <code>Barking is to dogs as meowing is to</code>, you will get as a result: <code>cats</code>.</p>
<p>Not only is GPT-3 good at reading comprehension, but it also good at tailoring its output to match the style of the input. Consider the following prompt:</p>
<pre><code>Tom went fishing all afternoon. He comes home to his wife at sunset, who asks him a question.

Question: What did you do today?
Answer:
</code></pre>
<p>The API returns <code>I went fishing.</code> </p>
<p>It is possible to get a more creative answer by providing more information in the prompt and turning up the <code>temperature</code> setting, which gives GPT-3 more of a creative license to make stuff up. For example, if after adding <code>Tom responds enthusiastically, providing many details.</code> to the prompt before the question and turning the temperature to its max value, here's how the API responded: </p>
<pre><code>I went fishing all day, and in the afternoon I fought the biggest fish that I have ever seen before. I just held on for as long as I could, because once I gave up there was no way I was getting the fish back again. I had to pull everything I could, and my catch ended up weighing 3 pounds of flounder and 4 pounds of bluegill.
</code></pre>
<p>Evidently, GPT-3 is quite proficient at making stuff up given the right temperature.</p>
<h2 id="howwereusinggpt3">How we're using GPT-3</h2>
<p>For our first foray into GPT-3, we created a Historian NPC (Non-Player Character) who is able to answer arbitrary questions about Edeus, our flagship world. All of our lore is original and it can be challenging to impart it all to the players at once. An AI able to answer the organic questions of a player in real-time seemed like a perfect use-case.</p>
<p>We already had a feature called 'Reactions' that allows NPCs to respond to something said in their room with predetermined commands. The adjustment made here was to add a <code>gpt</code> flag to the Historian which at reaction time forwards the user's input to OpenAI in order to get the response.</p>
<p>As with the fisherman above, we can use the dialog pattern, and precede it with a certain context, which explains to GPT-3 what the background is for the interactions. In this case, we gave it an excerpt from a fictional history book written by the NPC in question, and then provided a little bit of background about the NPC himself. Here is a sample interaction with him:</p>
<pre><code>You say 'hello there'
Grae the Historian says 'Greetings, traveler.'

You say 'Who are you?'
Grae the Historian says 'I am Historian Grae, a Priest of the Church of Thune.'

You say 'Where are we?'
Grae the Historian says 'You are in Bluefinch, a village in the realm of Saphrin.'

You say 'Is there anything I should be doing?'
Grae the Historian says 'You should be killing orcs.'

You say 'Why? What have the orcs ever done to us?'
Grae the Historian says 'The orcs are evil. They want to destroy us.'

You say 'Okay. Can you tell me more about our origin?'
Grae the Historian says 'Humans were created by Thune, the Allmighty God.'

You say 'Who rules this area?'
Grae the Historian says 'The King of Saphrin, Arctus Kerinin, rules this area.'

You say 'Thanks Grae! You've been very helpful'
Grae the Historian says 'You're welcome.'
</code></pre>
<p>If you want to test this out for yourself, Grae is located 3 north, 1 east of Bluefinch Square in Edeus. We're always tweaking his backstory and various settings so his outputs may (and should!) vary a bit.</p>
<h2 id="theknowledgeexclusionlimitation">The Knowledge Exclusion Limitation</h2>
<p>The main issue we've been running up against is that it's difficult to constrain the AI's knowledge to that of a fictional world. It cannot help knowing things about the real world. For example:</p>
<pre><code>You say 'When was JFK born?'
Grae the Historian says 'John Fitzgerald Kennedy was born on May 29, 1917.'
</code></pre>
<p>Ideally, the historian would not know about anything outside of Edeus. But even though we specify in the prompt's backstory that he only answers questions pertaining to his own world, that distinction is not always understood. It's difficult to exclude knowledge.</p>
<h2 id="futureimprovements">Future Improvements</h2>
<p>We plan to keep iterating and try to make the AI feel as human and authentic as possible. One issue is that currently each interaction with the NPC is its own isolated event. For example:</p>
<pre><code>You say 'What is the name of this village?'
Grae the Historian says 'This village is called Bluefinch.'

You say 'Where did it get its name from?'
Grae the Historian says 'Edeus is named after the two titans that fought in the First Age. Thune and Raeshyk.'
</code></pre>
<p>Clearly the NPC didn't connect that the second question was a follow-up from the first. This is because each time we do a call to OpenAI we append the user's query to the end of the same base prompt, making each a separate interaction. It could be improved upon by including a few of the previous back and forths when generating a new prompt, provided it was the same player.</p>
<p>There's also entirely different ways we could leverage GPT-3. For example, it could be used to generate content like room, character and item descriptions, or even dynamic quests. A text-based platform and a text-based AI share great synergy, and the possible applications of it seem endless to the imaginative.</p></div></div>]]>
            </description>
            <link>https://blog.writtenrealms.com/gpt3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148003</guid>
            <pubDate>Thu, 13 Aug 2020 20:06:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Windows 10 UX deep copy on Linux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24146508">thread link</a>) | @1337shadow
<br/>
August 13, 2020 | http://www.linuxfx.org/index.php/sistemas-operacionais/linuxfx-10-w | <a href="https://web.archive.org/web/*/http://www.linuxfx.org/index.php/sistemas-operacionais/linuxfx-10-w">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="g-page-surround">
                                    

                                            
                <section id="g-top">
                
        
    </section>
                
                                
                
    
                <section id="g-container-9688">
                <div>                    <div>                        

        <div>
             <section id="g-mainbar">
                                        <div>                        

        <div>
             <div>
                                                            <div><div><div itemscope="" itemtype="https://schema.org/Article">
	<meta itemprop="inLanguage" content="pt-BR">
	
		
			
					
		
	
	
		
								<div itemprop="articleBody">
		
<p><a href="https://www.youtube.com/watch?v=gFss_DliNPE" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/desktop_mini.jpg" alt=""></a></p>
<p><span><strong>LINUXFX 10.4.2 WX DESKTOP</strong></span></p>
<p><span><strong>LINUXFX NO TELEGRAM PT-BR :&nbsp;<a href="https://t.me/linuxfxbr">https://t.me/linuxfxbr</a></strong></span></p>
<p><span><strong>LINUXFX NO TELEGRAM EN :&nbsp;<a href="https://t.me/linuxfxen">https://t.me/linuxfxen</a></strong></span></p>

<p><span>O projeto Linuxfx / Windowsfx foi desenvolvido para ajudar usuários do Microsoft© Windows® a migrarem de maneira direta para o Linux, aproveitando toda sua curva de aprendizado. Aproveitar o hardware que não suporta a versão mais nova do&nbsp;Microsoft© Windows® também é uma diretiva do Linuxfx, assim como prover suporte a rede, Active Directory, programas .exe e .msi, navegação segura e proteção contra vírus. Utilizando o Linuxfx / Windowsfx no seu computador, você terá um sistema rápido, que consome pouca memória e é imune a vírus&nbsp;desenvolvido para a plataforma&nbsp;Microsoft© Windows®.</span></p>


<p><span>Linuxfx 10.4 WX Desktop System Core</span></p>
<ul>
<li><span><strong>Tema</strong>: WX Desktop (Windows 10 <a href="https://b00merang.weebly.com/windows-10.html" target="_blank" rel="noopener noreferrer">b00merang theme</a>)</span></li>
<li><span><strong>Gerenciamento de processos de núcleo</strong>: Linuxfx Pro System Pack</span></li>
<li><span><strong>Gerenciador de janelas</strong>: Cinnamon 4.6</span></li>
<li><span><strong>Compatibilidade com rede A.D</strong>: CID, PBIS (beyond trusty)</span></li>
<li><span><strong>Compatibilidade com rede Microsoft®</strong>: SAMBA + Linuxfx Pro Network Tools</span></li>
<li><span><strong>Desktop virtual</strong>: Citrix, Vmware, Rdesktop</span></li>
<li><span><strong>Assistência remota</strong>: Anydesk, Teamviewer</span></li>
<li><span><strong>Compatibilidade com Microsoft® Windows®</strong>: Wine + Linuxfx Pro Cross Specs</span></li>
<li><span><strong>Sistema base</strong>: Ubuntu 20.04 LTS</span></li>
</ul>


<p><span><a title="Download Etcher" href="https://etcher.io/" target="_blank" rel="noopener noreferrer"><img src="https://dl2.macupdate.com/images/icons256/57903.png?d=1524853176" alt="Resultado de imagem para etcher logo" width="125" height="125"></a></span></p>
<p><span><a title="Download Etcher" href="https://etcher.io/" target="_blank" rel="noopener noreferrer"><img src="http://resin.io/blog/content/images/2017/02/etcher-logo.jpg" alt="Resultado de imagem para etcher logo" width="424" height="77"></a></span></p>
<p><a title="Download Etcher" href="https://etcher.io/" target="_blank" rel="noopener noreferrer"><strong><span>UTILIZE O ETCHER PARA GRAVAR O LINUXFX</span><span>&nbsp;</span></strong></a></p>


<p><span><a href="https://sourceforge.net/projects/linuxfxdevil/" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/pc.png" alt=""></a></span></p>
<p><span><strong><a href="https://sourceforge.net/projects/linuxfxdevil/" target="_blank" rel="noopener noreferrer">DOWNLOAD X86-64 BITS PC</a></strong></span></p>
<p><span><strong>DUAL CORE + 2GB RAM MIN</strong></span></p>


<p><span><strong><a href="https://sourceforge.net/projects/linuxfxarm/" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/rasp.png" alt=""></a></strong></span></p>
<p><span><a href="https://sourceforge.net/projects/linuxfxarm/" target="_blank" rel="noopener noreferrer">DOWNLOAD 32 BITS ARMHF</a></span></p>
<p><span><strong>RASPBERRY PI - 2 - 3 - 4</strong></span></p>


<p><a href="https://sourceforge.net/projects/linuxfxtinker/" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/tinker.png" alt=""></a>&nbsp;</p>
<p><span><a href="https://sourceforge.net/projects/linuxfxtinker/" target="_blank" rel="noopener noreferrer">DOWNLOAD 32 BITS ARMHF</a></span></p>
<p><span><strong>ASUS&nbsp;TINKERBOARD</strong></span></p>


<p><a title="Linuxfx DistroWatch.com" href="https://distrowatch.com/table.php?distribution=linuxfx" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/dwbanner.png" alt=""></a></p> 	</div>

	
							</div></div></div>
    
            
    </div>
        </div>
            </div>
            
    </section>
        </div>
            </div>
    </div>
        
    </section>
    
                                
                
                                
                <section id="g-copyright">
                
        
    </section>
                                
                <section id="g-fixedside">
                <div>                                <div>                        

        <div>
             <p><a href="http://www.linuxfx.org/" title="" rel="">
        <img src="http://www.linuxfx.org/templates/rt_kraken/images/logo/logo.png" alt="Linuxfx">
        <span></span>
</a>
            </p>
        </div>
            </div>
                            
                            
            </div>
        
    </section>
            
                        

        </div></div>]]>
            </description>
            <link>http://www.linuxfx.org/index.php/sistemas-operacionais/linuxfx-10-w</link>
            <guid isPermaLink="false">hacker-news-small-sites-24146508</guid>
            <pubDate>Thu, 13 Aug 2020 18:26:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handmade Web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24146025">thread link</a>) | @cookingoils
<br/>
August 13, 2020 | https://handmade-web.net/fall20/index.html | <a href="https://web.archive.org/web/*/https://handmade-web.net/fall20/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
            “I evoke the term ‘handmade web’ to suggest slowness and smallness as forms of resistance.”<br>
            —— J. R. Carpenter
          </p><p>The hand has become increasingly less present in the web as we know it today. Websites are automated or built from templates, and the knowledge of how to make a website is relegated to a select few. It has only gotten easier to learn and make on the web, but the idea and perceived requirements for a website have become so convoluted and arcane that many avoid the subject. This course seeks to dispel these ideas and will emphasize the hand-quality of websites by developing an understanding of the best practices, language, history, and present context of the web. We will examine the space of the web at large and explore and challenge what a website is and can be with the hopes of reclaiming an important creative space.</p><p>The websites we will make may be small, but their hearts will be big.</p><p>The first half of the class will be technically focused. It will comprise of a series of lessons, readings, workshops, and small projects to develop familiarity and confidence with the language of the web. We will focus on the basic languages of web development: HTML, CSS, and a little Javascript. This class is designed for students with no programming experience at all, but should be friendly to any skill level. The second half will be focused on a larger project website.</p><div>

          
          <p>This class will place heavy emphasis on the hand, craft, and care of your design and code. We will learn how to borrow and learn from others’ code, but we will strive to understand how to code it ourselves. This class will question much of what is commonly understood about the web and technology in general.</p>
          <ul>
            <li>Is tech always the answer? (“There’s an app for that…”)</li>
            <li>Why put something on the web?</li>
            <li>How can we think about accessibility, legibility, efficiency, and speed on the web?</li>
          </ul>

          <hr>

          
          <p>The first goal of this class is to demystify and remove the barrier for entry into web development and programming. Any and all questions are welcome. I will not know every answer, but we can work together to find one (and there are always many when it comes to programming). Learning how to search is the programmer’s greatest tool.</p>
          <p>By the end of the class you will:</p>
            <ul>
              <li>Have a working knowledge of HTML, CSS, and basic Javascript</li>
              <li>Understand the design principles particular to the web and dynamic media</li>
              <li>Have a basic understanding of web publishing</li>
              <li>Have an understanding of the history and present context of web</li>
              
            </ul>

          <hr>

          
          <p>Early in the semester we will set up individual class websites to house all products of this class (projects, writing, anything else…). We will host them using Github Pages and purchase a domain name to attach to it. You can design and organize this however you like, so long all content is accessible and easily found——I will be grading from this!</p>

          <hr>

          
          <p>For assigned readings I will ask you to respond to the reading with a rough written/sketched website concept (or, if you want, a coded sketch of the website) that reacts to the concepts and topics of the reading. Then, upload this response to your class site. Use this as an opportunity to catalogue some ideas for future web projects (either in this class or beyond!).</p>
          <p>There will be some time for reading discussions, but class time will largely be reserved for work, review, and activities. However, these readings will help facilitate a common understanding about the history and present context of the web. Ideally, they will also serve as inspiration for you (as they have been for me!).</p>
          <p>For each week that we have a reading for, only choose 1 to respond to. For example: if there are 3 assigned readings in a week, only respond to one of those.</p>
          <p>More details can be found in the <a href="https://handmade-web.net/fall20/projects/reading.html">project page</a>.</p>

          <hr>

          
          <p>During the first half of the class we will work on a series of smaller projects to practice and experiment with designing for the web:</p>
            <ol>
              <li><a href="https://handmade-web.net/fall20/projects/article.html">Article</a></li>
              <li><a href="https://handmade-web.net/fall20/projects/screensaver.html">Screensaver</a></li>
              <li><a href="https://handmade-web.net/fall20/projects/secret.html">Secret</a></li>
              <li><a href="https://handmade-web.net/fall20/projects/aura.html">Aura</a></li>
            </ol>
          <p>Details for each project will be outlined on the <a href="https://handmade-web.net/fall20/projects/index.html">Projects</a> page.</p>

          <hr>

          
          <p>The final project will take up the last half of the class. It can be anything you like: a project you’ve had in mind for some time; an extension of your practice or an even larger project outside of this class. What is important is the craft, care, and concept of the project. It will be graded on these qualities. It should be unique, personal, and a world of its own.</p>

          <hr>

          
          <p>For each major project there will be an informal presentation and feedback session. As much of this class is focused on technical introduction and skill-building, the finished projects will likely still be works in progress (the web is always under construction). Treat these sessions as opportunities to ask technical or conceptual questions to push your projects further!</p>
          <p>Beyond these review sessions I would encourage everyone to regularly share work and code inside and out of class!</p>

          <hr>

          
          <p>
            40% —— Participation<br>
            40% —— Process<br>
            20% —— Execution
          </p>

          <hr>

          
          <p>This class will require a computer, a text-editor (I recommend <a href="https://atom.io/">Atom</a>), and a browser (<a href="https://www.google.com/chrome/">Chrome</a>). I would also suggest a sketchbook for much encouraged off-screen thinking, note-taking, sketching, and journaling.</p>

          <p>More details can be found in the <a href="https://handmade-web.net/fall20/library.html">Library</a>.</p>

          <hr>

          
          <p>This class will take place entirely online, with some flexibility on potentially meeting in person for individual meetings. Unless stated otherwise, we will regularly meet (synchronously) during the scheduled class times using Zoom.</p>
          <p>You will also have access to the scheduled class space in Pollak Room 317 if you want to use that space during class time, though we will still all collectively meet online through Zoom. One thing to note is that departmental policy, at the time, only allows 10 students in a classroom at a time and only during the scheduled class time. Please make sure to prioritize your own safety and the safety of others when using public spaces!</p>
          <p>We can consider this a feature rather than a hinderance for learning web design as we will inhabit and communicate within the environment that we will be making for!</p>

          <hr>

          
          <p>As this class will take place online, we will be using a <a href="https://discord.com/" target="_blank">Discord</a> server to centralize communication and announcements for the class. The Discord will also serve as a space for feedback and comments during feedback sessions. If there are any updates/changes to the class I will announce them on the Discord, so be sure to check often.</p>

          <hr>

          
          <p>The standard VCU attendance policy states that student absences during the semester are not expected to exceed the number of times the class meets in one week (2). This semester, because we are facing unprecedented circumstances, we will be following a revised policy that addresses larger issues of expected engagement in the course, articulated below. Consistent engagement is a vital component of successful completion of the course objectives.</p>
          <p>The progression of this course requires all participants to be present and actively engaged in class, both during synchronous on-screen meetings, in-person, and with asynchronous activities. Consistency of engagement is vital for a successful completion of the course objectives. Each of us carries different circumstances and capacities; we are accountable for our own agency. This is always true, but especially crucial now.</p>
          <p>If at any point during the semester you are unable to be present, communicate this with me as soon as you can. While presence in class is important, my primary concerns with this class are your wellbeing and an emphasis on not applying unnecessary pressure in an already difficult period. Please remember to prioritize your mental and physical health over school.</p>

          <hr>

          
          <p>The University requires all students and faculty to be aware of policies outlining expectations, requirements and student services related to  academic life. Please visit the following link and review these at the start of each semester: <a target="_blank" href="https://go.vcu.edu/syllabus">go.vcu.edu/syllabus</a>
          </p>

          <hr>

          
          <p>For information regarding institutional adjustments, policies, and safety precautions during COVID-19 please consult the web page for <a target="_blank" href="https://together.vcu.edu/students/">One VCU: Responsible Together</a>.
          </p>

          <hr>

          
          <p>This syllabus and class’s foundation has a number of sources to thank</p>
          <ul>
            <li><a href="http://laurelschwulst.com/">Laurel Schwulst</a> —— whose published syllabi and class portals served as my own unbidden introduction to web design. Much of the pacing and tone of this class is modeled after her approach.</li>
            <li><a href="http://mindyseu.com/">Mindy Seu</a> —— whose classes and workshops have helped expand my thought around digital pedagogy.</li>
            <li>Roy McKelvey —— whose generously provided syllabus has served as the organizational structure of this class.</li>
          </ul>

          <hr>
        </div></div>]]>
            </description>
            <link>https://handmade-web.net/fall20/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24146025</guid>
            <pubDate>Thu, 13 Aug 2020 17:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jira Is a Microcosm of What’s Broken in Software Development]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 168 (<a href="https://news.ycombinator.com/item?id=24145665">thread link</a>) | @davetwichell
<br/>
August 13, 2020 | https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>This blog is not about how project management tools are too complex and over-engineered with features dev teams don’t need.</p>



<p>Those complaints are well articulated by others like Justin James, Chief Architect at Cloud Development Resources.</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p><em>“Jira has *never once* made my life as a developer easier or better… It’s overly complicated and the workflow is painful.”&nbsp;</em></p>



<p>Justin goes on to say…&nbsp;</p>



<p><em>“Jira is Word when it had the toolbar filled with tiny little icons for formatting only paralegals or scientists or some other specialized author needed. It does *all this stuff* and none of it is easy or makes sense…”&nbsp;</em></p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>Most popular project management tools are highly configurable which can be a plus and a minus depending on how your company has it set up. </p>



<p>So if project tools have so much flexibility, why do so many organizations configure them in a way that causes their dev teams to complain? </p>







<h4><strong>Project management tools are not perfect but they’re not the problem. The root cause of most complaints devs have with project tools are rooted in bad culture, bad management or bad process. </strong></h4>



<p>Let’s examine 4 of the most common complaints I’ve heard about project management tools from software development teams. </p>







<h3>1. “<strong>Project tools are made with PMs in mind, not dev teams</strong>“</h3>



<p>Justin said <em>“I wish Atlassian would sit down with real-world developers and design this product the way we need it to work.”&nbsp;</em></p>



<p>I’ve heard this complaint from a lot of devs. “Project tools were made with project managers and product managers in mind. Not dev teams.” It is true. Project and product managers (collectively referred to as PMs going forward) are the usually primary buyers and owners of project management systems. Not engineers.&nbsp;</p>



<p>I’ve also heard “the development process is fluid, real-time, and doesn’t always follow a linear path. Project tools force you into a workflow that does not match that reality.” </p>



<p>So why do companies use a tool that works for a few PMs and business leaders when some engineers dislike it so much?&nbsp;</p>



<p><strong>The real issue: Executives force top-down decision making on dev teams</strong></p>



<p>Some companies embrace a mindset of decisions being made by a few people “at the top”. In their world, the planning process is king. The creating process is an afterthought.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>The current software delivery process revolves around pushing decisions down to dev teams and forcing engineers to push status updates back up. This system ensures executives are the only ones who have context and can see the bigger picture while engineers do all of the work.&nbsp;</p>



<p>This is backwards. It holds us back from building the best product and slows us down from delivering faster.&nbsp;</p>



<figure><blockquote><p>Join our mission to end useless status meetings.</p><p><a href="https://linearb.io/status-updates-on/" target="_blank" rel="noreferrer noopener">Click here for access</a>&nbsp;to the dev team dashboard of the future powered by Git data.</p></blockquote></figure>







<h3>2. “<strong>Project tools are plan-first tools, not a develop-first tool</strong>s”</h3>



<p>It makes sense. PM’s, who own Jira, spend a lot of time on ideas, strategy, prioritization, requirements gathering, and preparing for the future. They want a tool that helps them succeed in those areas. Once the iteration starts, PMs shift from being planners to being status communicators. Jira is designed this way. It’s pretty good when you’re in the planning phase and it works well if you’re the PM receiving the status update.</p>



<p>But when you’re in the development phase, it’s not as well suited to dev team tasks. If you’re the engineer who has to constantly manually update the status, it’s annoying. </p>



<p>I see the merit behind this argument. Dev teams live elsewhere like in Git and Slack.&nbsp;Stopping to login in to another system throughout the day is not ideal. </p>



<p>What PMs do is really important – being the voice of the customer, planning, prioritizing and communicating with the rest of the business.  They need tools for this. </p>



<p>I also think dev teams need tools that reflect the fluidity of the development process. It’s sort of like the famous Mike Tyson quote… <em>“Everybody has a plan until they get punched in the mouth.”</em> Once development starts, a million micro-decisions are being made every hour and things change quickly. Most project tools are not set up for this reality.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>The problem is we’re taking different groups of people who spend their time in different ways and forcing them in to one workflow. 80% of the people involved in software development spend 80% of their time in the development phase. In most companies, fewer people spend less time in the planning phase.&nbsp;</p>



<p>So why are we using a plan-first tool to manage the full development lifecycle?&nbsp;</p>



<p><strong>The real issue: Many execs get product strategy but not product development</strong></p>



<p>Most business leaders think like PMs, not like engineers. Executives understand ideas, strategy, and prioritization. They’re also familiar with the process and key metrics of sales and marketing. They know the vocabulary and speak the language.&nbsp;</p>



<p>They do not understand software development as well. They don’t know the terms. When it comes to the dev team, most just want to know “are we on track to deliver feature XYZ by the deadline?”&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>This is dangerous because it holds them back from understanding our process which holds them back from engaging in intelligent conversations with engineering leaders and teams.&nbsp;</p>



<p>If sales miss their number, the CEO has 100 questions ready to analyze what levers they can pull to right the ship. If the dev team misses a deadline, other than maybe asking “do we need to work more hours?”, all they can do is wait or apply (unhelpful) artificial pressure to finish.&nbsp;</p>



<p>How we work matters. Not just the output.&nbsp;</p>







<h3>3. <strong>“Project tools perpetuate synchronous communication, not asynchronous</strong>” </h3>



<p>Project management tools seems like it should encourage asynchronous communication. But in my experience they do the opposite. </p>



<p>When execs have a meeting with a customer or the sales team, they need information about product delivery timelines and they need it now. They ask the PM and the PM sends you an urgent Slack. Or worse, the PM calls you into a meeting to find out what’s going on. Those interruptions are costly.&nbsp;</p>











<p>Why doesn’t the exec or the PM just look at project board? Because it’s not up to date. Why? Things change so rapidly that, in order for the board to be up to date, engineers would need to constantly manually update tickets. One engineering manager told me recently that even teams he’s worked on that really care about project tool hygiene only capture about 60-70% of their real work activity. Most teams are closer to 50%.&nbsp;</p>



<p>Even if the project board was up to date, it’s still missing context.&nbsp;</p>



<p>Execs and PMs want to know:&nbsp;</p>



<ul><li>When is the bug going to be fixed?&nbsp;</li><li>When is the new feature being delivered?&nbsp;</li><li>What risks could stop us from hitting our date?&nbsp;</li><li>Which features are getting attention right now and which aren’t?&nbsp;</li><li>What % of the team is invested in features versus bugs versus non-functional?&nbsp;</li></ul>



<p>There’s nothing on the project board that answers those questions. So they pull you away from deep focus mode to ask you. And it takes you a while to get your focus back. Which slows you down from delivering the thing they want most of all – more features.&nbsp;</p>



<p><strong>The real issue: Companies run on a “manager’s schedule” not a “maker’s schedule”&nbsp;&nbsp;</strong></p>



<p>Paul Graham, computer programmer and co-founder of Y Combinator, explains the disconnect between the way developers and executives get work done in his 2009 essay <em>Maker’s Schedule, Manager’s Schedule</em>.&nbsp;</p>



<p>Here’s a summary:&nbsp;</p>



<ul><li>Bosses (managers) get stuff done through meetings – changing tasks every 60 minutes.</li><li>Developers (makers) and other creators need 3-4 hour blocks of time to get work done.</li><li>Each way of working is perfectly fine by itself but problems arise when the two collide.</li><li>For a maker, a single meeting at the wrong time can disrupt their entire day of work.</li><li>Most powerful people are on a manager schedule and they directly or indirectly force the makers in their company, like software engineers, to revolve around the way they work.&nbsp;</li></ul>







<p>I couldn’t agree more with Paul. The lack of understanding some execs have for the software development process, leads to a lack of empathy for software developers. Companies subject their engineers to the manager’s schedule which disrupts the flow of development.&nbsp;</p>



<p>When engineers point out they could ship more features faster if there were fewer meetings, business leaders hear that as a complaint versus what it really is, a cry for help.&nbsp;</p>







<h3>4. “Project tools <strong>create separation between engineers and PMs</strong>“</h3>



<p>Some devs describe their interactions with their PM in a way that reminds me of <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=Fy3rjQGc6lA&amp;feature=youtu.be" target="_blank">Peter from Office Space</a> when his boss asks him for the new cover sheet on the TPS report.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>In the real world, most devs I know really value their PMs. Great PMs allow engineers to do great work. I’ve worked with some awesome ones. </p>



<p>But the <a rel="noreferrer noopener" href="https://linearb.io/blog/vp-engineering-vp-product-how-to-keep-a-united-front/" target="_blank">PM + engineer relationship is hard to get right</a>. Having additional tension built-in makes it even harder.&nbsp;</p>



<p>It’s just not engineers that don’t like having to share status updates all day. PMs don’t want to bug us either! They feel like babysitters. Imagine what they could be doing instead… talking to customers, writing high-quality user stories… or actually spending their time with us on something useful like brainstorming ideas or sharing customer feedback. </p>



<p><strong>The real issue: Some companies are lacking empathy and understanding between different departments. </strong></p>



<p>I’m lucky to work at a company where our CEO (Ori Keren) and our COO (me) are software engineers. We ensure everyone in the company understands the development process which helps maintain tight alignment between our dev, marketing, customer success, and sales teams.&nbsp;</p>



<p>I think more start-ups should be led by programmers and more big companies should promote their CTOs to CEO.&nbsp;</p>



<p>In the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/">https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145665</guid>
            <pubDate>Thu, 13 Aug 2020 17:13:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HTTP – It's Simpler Than You Think. It's More Complex Than You Think]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24145502">thread link</a>) | @Crzymary15
<br/>
August 13, 2020 | http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/ | <a href="https://web.archive.org/web/*/http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <div>
                <article>
                    <header>
                        
                        <span>
                            
                                Posted in
                                
                                    <a href="http://bluegraybox.com/blog//categories/networking">networking</a>
                                
                            

                            
                        </span>
                         - 
                        <time>Friday, August 29, 2014</time>
                    </header>
                    <section>
                        

<p>I’ve been doing web development for a pretty long time, but just over the last few years I’ve come to really appreciate the fundamentals of HTTP, what’s going on under the hood when I’m building web applications. There are two sides of this. The first is that HTTP is in one sense a very simple protocol. It’s just little text messages going back and forth between your browser and the web server. Whether I’m using Node or Django or some huge WSDL-driven Java XML-Beans monstrosity, what it’s doing isn’t rocket science; it’s just taking care of a bunch of tedious, nit-picky bookkeeping that I don’t want to be bothered with. If I really wanted to, I could just type the messages myself (and we’ll get to that in a minute).</p>

<p>The practical upside of that is that you can use really simple tools to debug big, hairy, complex web applications. A few years ago, I was working in one of those Big Web Services systems with WSDL files and auto-generated Java code and layers and layers of middleware. We’d get some kind of error at the front end, and it’d be really hard to tell which piece had broken. So I ended up writing a bunch of really simple shell scripts to test the web services in isolation. I’d spackle together something using <code>curl</code>, <code>grep</code>, and <code>sed</code> that built up and picked apart the messages as text, without dragging in all that mess of Java code.</p>

<p>The flip side is that HTTP is actually a richer protocol than I’d realized. There’s a lot I didn’t know about it until I started building RESTful web services and trying to understand the “right” way to do it. There’s all this stuff you can do with status codes and headers that I’d been re-implementing at the application level.</p>

<p>To take a recent example, I’ve been working on a web service that talks to other web services. Someone would make a call to us, we’d call the back-end services, they’d time out or barf up some sort of error, and we’d pass back a 500 error to our client. They’d see it and email us asking what was wrong with our service. It’d be nice to let them know it’s not our fault and that they should pester the back-end systems people instead. We could send back a message body that says something like, “Back-end systems failure. Original error message follows,” but it turns out we can say that just by returning a different status code. Not only is there a 502 status code, which means that a back-end system failed, but there’s also a 504, which means that we timed out trying to contact it. That tells our client that they can try again in a little while and the request might go through.</p>

<p>Ok, enough talking. Now code.</p>

<h2 id="goin-all-mechanical-turk-on-this">Goin’ all Mechanical Turk on this</h2>

<p>To illustrate the first point, that this is all just text, I’m going to play human web server, using <code>netcat</code>. If you’re not familiar with it, it’s a standard unix utility that just opens a network connection. Anything you type gets sent along it; anything that comes back gets printed out on your screen. I open up a terminal and type:</p>

<pre><code>nc -l 3333
</code></pre>

<p>That starts up <code>netcat</code> listening on port 3333. Then I switch to my browser and tell it to go to <code>http://localhost:3333/</code>. The “page loading” indicator starts spinning. In the <code>netcat</code> terminal, I see:</p>

<pre><code>GET / HTTP/1.1
Host: localhost:3333
Connection: keep-alive
Cache-Control: max-age=0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
User-Agent: Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36
Accept-Encoding: gzip,deflate,sdch
Accept-Language: en-US,en;q=0.8
</code></pre>

<p>That’s Chrome telling me it wants the root resource (<code>/</code>, which Apache or whatever would normally interpret as <code>index.html</code>). It’s also telling me a lot about what kind of response it can handle. I’m going to ignore all that for now and just type:</p>

<pre><code>HTTP/1.1 200 OK 
Content-type: text/plain
Content-length: 7

Hello!
</code></pre>

<p>Pretty straightforward. The content length is 7 because it includes the return character after “Hello!” Here’s what we see in Chrome:</p>

<p><img src="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/img/hws-1.png" alt="" title="Chrome window with plain text &quot;Hello!&quot;"></p>

<p>Switch back to the browser and go to <code>http://localhost:3333/index.html</code>. In the <code>netcat</code> terminal, we get a request that’s much the same as before, except the first line is:</p>

<pre><code>GET /index.html HTTP/1.1
</code></pre>

<p>Since they asked for HTML, I’ll give them HTML. I type:</p>

<pre><code>HTTP/1.1 200 OK
Content-type: text/html
Content-length: 16

&lt;h1&gt;Hello!&lt;/h1&gt;
</code></pre>

<p>And in Chrome we see:</p>

<p><img src="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/img/hws-2.png" alt="" title="Chrome window with HTML H1 header &quot;Hello!&quot;"></p>

<p>So at some fundamental level, that’s all a web application is. It’s a program that listens for a connection, gets little text messages, interprets them, and sends back responses. How simple can we make that?</p>

<h2 id="restful-web-services-in-bash">RESTful Web Services in Bash</h2>

<p>How about this?</p>

<pre><code>#!/bin/bash

echo "Content-type:text/plain"
echo 
uptime
</code></pre>

<p><code>uptime</code> is a standard unix utility that reports how long the computer has been running and what the 1, 5, and 15 minute system load averages are. That’s marginally useful - I’ve actually used a script much like this for basic server monitoring. Put it in a file, make it executable, run it from the command line, and it’ll spit out something like:</p>

<pre><code>Content-type:text/plain

 21:29:32 up 9 days, 15:17,  5 users,  load average: 0.05, 0.10, 0.18
</code></pre>

<p>From here, if you want to follow along, you’ll need to have Apache set up and configured to let you run CGI scripts in the directory you’re working in. (That’s a whole tutorial on its own, but here’s some <a href="http://www.cgi101.com/book/connect/mac.html">instructions for Mac OS X</a>. Otherwise, Google for “apache enable cgi” and your operating system.)</p>

<p>On my machine, this script is saved as <code>public_html/api/v1/load/index.cgi</code>. That lets me access it as <code>http://localhost/~colin/api/v1/load/</code>, as we can see in Chrome:</p>

<p><img src="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/img/v1-load.png" alt="" title="Chrome showing uptime report"></p>

<p>We can also use <code>netcat</code> in place of Chrome. Instead of listening on a port, we open a connection to the web server’s port:</p>

<pre><code>$ nc -c localhost 80
</code></pre>

<p>Then I type:</p>

<pre><code>GET /~colin/api/v1/load/ HTTP/1.1
Host: localhost
</code></pre>

<p>And I get this back from Apache:</p>

<pre><code>HTTP/1.1 200 OK
Date: Wed, 27 Aug 2014 01:14:11 GMT
Server: Apache/2.4.7 (Ubuntu)
Vary: Accept-Encoding
Transfer-Encoding: chunked
Content-Type: text/plain

46
 21:14:19 up 9 days, 15:01,  5 users,  load average: 0.08, 0.18, 0.28

0
</code></pre>

<p>You can see that Apache includes a bunch of header fields that I didn’t bother to when I was playing web server. (I’ll trim most of these out of later examples to cut down on the clutter.) The more interesting thing is that it doesn’t have a <code>Content-length</code> header. What it has instead is <code>Transfer-Encoding: chunked</code>. That says that its content will be in chunks, prefixed by their size (in hexadecimal). 46 hex is 70, which is the length of the next line (again, counting the return character at the end). The ‘0’ for the next chunk says, “that’s all, folks!”</p>

<p>We can make this a little easier on ourselves by using <code>curl</code> instead of <code>netcat</code>. It’s a somewhat more custom tool for making HTTP requests. We can just run <code>curl -si http://localhost/~colin/api/v1/load/</code> from the command line, and get back:</p>

<pre><code>HTTP/1.1 200 OK
Transfer-Encoding: chunked
Content-Type: text/plain

 22:05:42 up 9 days, 15:53,  5 users,  load average: 0.14, 0.13, 0.19
</code></pre>

<p>That’s the same as what <code>netcat</code> gave us (minus the header clutter), but notice that it combined the chunked response for us. Even at this level, some of the details are being hidden.</p>

<h2 id="status-seeking">Status Seeking</h2>

<p>Let’s take this a step further. The <a href="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/v1/status/index.cgi">status script</a> gets a status message (“GREEN”, “YELLOW”, or “RED”) from a file, and prints it out like so:</p>

<pre><code>$ curl -si http://localhost/~colin/api/v1/status/
HTTP/1.1 200 OK
Content-Length: 4
Content-Type: text/plain

RED
</code></pre>

<p>It also lets us set a new status like so:</p>

<pre><code>$ curl -si -X PUT -d GREEN http://localhost/~colin/api/v1/status/
HTTP/1.1 204 No Content
Content-Length: 0
Content-Type: text/plain
</code></pre>

<p>Note that we used the same URL, but changed the HTTP method to <code>PUT</code> (instead of the default <code>GET</code> - don’t ask me why that’s the <code>-X</code> option) and specified “GREEN” as the data (<code>-d</code>) to be sent along with the request. We get back an exciting new response code: 204! Since we’re telling not asking, it doesn’t make much sense for the server to send anything back. The 204 status just says, “That thing you were doing? It worked.” No reason to have a message body saying “Success!” when the code already tells you that. I’ve definitely been guilty of reinventing that wheel before I ran across this.</p>

<p>What if we try to send a bad status, like ‘BLUE’?</p>

<pre><code>$ curl -si -X PUT -d BLUE http://localhost/~colin/api/v1/status/
HTTP/1.1 400 Bad Request
Content-Type: text/plain

Invalid status code
</code></pre>

<p>400 is the “your mistake” error code, which is pretty generic, so we include a descriptive message in the response body. Since it’s a user error, it’s reasonable to just have a human-readable message.</p>

<p>If you look at the script, you’ll see references to environment variables like <code>$REQUEST_METHOD</code>. That’s how Apache makes information about the request avaliable to the script (as part of the CGI standard). In case you want to see all of them, I’ve added an <a href="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/env/index.cgi">env script</a>, which dumps them all out, plus the content. You can hit it with Chrome or <code>curl</code>, or even <code>netcat</code>. See what’s different between them.</p>

<h2 id="api-documentation">API Documentation</h2>

<p>Ok, great! Now we have two simple yet useful web services. But they’re not so simple that they don’t need any documentation, so let’s add some. We could have some sort of parallel hierarchy for documentation, like <code>/api/docs/v1/load/</code>, etc., but that’s kinda clunky. Instead, let’s rework our services so they give you data when you ask for data, and text when you ask for text. For that, we take advantage of the <code>Accept</code> header. Take a …</p></section></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/">http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/</a></em></p>]]>
            </description>
            <link>http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145502</guid>
            <pubDate>Thu, 13 Aug 2020 16:59:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Llama Logs – Architecture Diagrams from Your Logs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24145223">thread link</a>) | @bakenator
<br/>
August 13, 2020 | https://llamalogs.com/docs/what | <a href="https://web.archive.org/web/*/https://llamalogs.com/docs/what">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    

    <p>Overview</p>
    <div>

        <p>Llama Logs is a brand new tool that turns distributed logs into a <b>real time interactive graph</b>.</p>
        <p>Llama Logs was created to help bring clarity to complex cloud architectures.</p>
        

        <p><img height="auto" width="600px" src="https://llamalogs.com/images/doc-examples/complexArch.gif"></p><p>With Llama Logs, <b>never again</b> will you need to:</p>
        <ul>
            <li>Create and update architecture diagrams by hand.</li>
            <li>Install agents onto your machines.</li>
            <li>Hunt down erors through mulitple machines and log files.</li>
            <li>Struggle to teach new team members your architecture.</li>
            <li>Limit your analytics to the machine level.</li>
        </ul> 

        <p>With <b>only a few log lines</b> in your code base, </p>
        <p><img height="auto" width="600px" src="https://llamalogs.com/images/codeScreenshot.png"></p><p>Llama Logs will instantly create a live visualization of the activity within your system. </p>
        
        <p>Llama Logs is <b>built for developers</b>, so the possibilities are endless!</p>
    </div>


    
    <p>The Llama Logs Graph</p>
    <div>
        <p>The graph is where all of the events from a system are visualized automatically by Llama Logs.</p>
        <p>Below is an example of a Llama Logs graph for a Cloud Architecture with Multiple Cloud Functions and a Database.</p>
        <p>Each one of the circles moving between components represents logged events occurring between those two components.</p>
        
        <p><img src="https://llamalogs.com/images/LlamaStartingDemo.gif"></p><p>Instantly we can see the structure and activity of the entire architecture in real time!</p>
        <p>The graph even shows errors in red that are occuring during the response from one of the modules in the first Cloud Function.</p>

        

        <p>See more examples of Llama Logs system visualizations on our <a href="https://llamalogs.com/docs/examples">examples page</a>.</p>
    </div>
    
    
    <p>Benefits</p>
    <div>
        <p>Llama Logs has tremendous benefits over other types of analytics:</p>
        <ul>
            <li>Aggregates distributed data into a single easy to understand graph.</li>
            <li>Seamlessly bridges the gap between application and infrastructure data layers.</li>
            <li>Handles millions of events per component with ease.</li>
            <li>Allows <b>You</b> to creatively define how your data will be visualized.</li>
        </ul>
    </div>


    
    
    <p>Supported Languages</p>
    
    
    
    <p>Demo</p>
    <div>
        <p>You are only 2 clicks away having a live Llama Logs graph to experiment with.</p>
        <p><a href="https://llamalogs.com/docs/demo" target="_blank">Start The Demo</a>
    </p></div>

    


    <p>Start Using Llama Logs</p>
    

    

    <p>More Info</p>
    

    </div></div>]]>
            </description>
            <link>https://llamalogs.com/docs/what</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145223</guid>
            <pubDate>Thu, 13 Aug 2020 16:35:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Architecture of Consoles – Nintendo DS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24145124">thread link</a>) | @bobbybabylon
<br/>
August 13, 2020 | https://www.copetti.org/projects/consoles/nintendo-ds/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/nintendo-ds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><div><ul><li><a href="#cover-model">Model</a></li><li><a href="#cover-motherboard">Motherboard</a></li><li><a href="#cover-diagram">Diagram</a></li></ul><div><div id="cover-motherboard"><figcaption>Showing first revision<br>Controllers are plugged using a separate daughterboard<br>Missing SRAM chips are on the back and there are four unpopulated SRAM slots</figcaption></div><div id="cover-diagram"><a href="https://www.copetti.org/images/consoles/nintendods/diagram.png"><picture>
<img alt="Diagram" src="https://www.copetti.org/images/consoles/nintendods/diagram.png" data-src="https://www.copetti.org/images/consoles/nintendods/diagram.png"></picture></a><figcaption>If you have trouble following the components: Top is only accessed by ARM9, bottom section is ARM7-only, middle section is shared</figcaption></div></div></div><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>This console is an interesting answer to many needs that weren’t possible to fulfil in the handheld ecosystem. There will be some innovation and a few compromises, but this combination may pave the way for new and ingenious content.</p><hr><h2 id="cpu">CPU</h2><p>As with Nintendo’s <a href="https://www.copetti.org/projects/consoles/game-boy-advance/">previous portable console</a>, the system revolves around a big chip named <strong>CPU NTR</strong>. ‘NTR’ is shorthand for ‘Nitro’, the codename of the original Nintendo DS.</p><p>Now, CPU NTR implements an interesting multi-processor architecture using two different ARM CPUs, this design was done before ARM Holdings officially released multi-processor solutions. So, their functioning may be considered a bit unorthodox taking into account the present technology available.</p><p>While this is not the first parallel system analysed for <a href="https://www.copetti.org/projects/consoles/">this series</a>, its design is very different from the rest. For instance, we are not talking about the ‘experimental’ master-slave configuration that the <a href="https://www.copetti.org/projects/consoles/sega-saturn/">Saturn</a> debuted or the ‘co-processor’ approach found on the <a href="https://www.copetti.org/projects/consoles/playstation/">PS1</a> or <a href="https://www.copetti.org/projects/consoles/nintendo-64/">N64</a>. The Nintendo DS includes two very independent computers that will perform exclusive operations, each one having a dedicated bus. This co-dependency will condition the overall performance of this console.</p><p>That being said, let’s take a look now at the two CPUs:</p><div><ul><li id="tab-1-1-arm7tdmi-link"><a href="#tab-1-1-arm7tdmi">ARM7TDMI</a></li><li id="tab-1-2-arm946e-s-link"><a href="#tab-1-2-arm946e-s">ARM946E-S</a></li></ul><div><div id="tab-1-1-arm7tdmi"><h4>ARM7TDMI</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"></picture></a><figcaption>ARM7 structure and components</figcaption></div><p>Starting with the more familiar one, the <strong>ARM7TDMI</strong> is the same CPU found on the <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#cpu">GameBoy Advance</a> but now running at <strong>~34 MHz</strong> (double its original speed). It still includes all its original features (especially <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#whats-new">Thumb</a>).</p><p>Now for the changes: Because Nintendo’s engineers placed the ARM7 next to most of the I/O ports, this CPU will be tasked with arbitrating and assisting I/O operations. In fact, no other processor can directly connect to the I/O. As you can see, this is not the ‘main’ processor that will be in charge of the system, but rather the ‘sub-processor’ offloading the main CPU by passing data around many components.</p></div><div id="tab-1-2-arm946e-s"><h4>ARM946E-S</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"></picture></a><figcaption>ARM9 structure and components</figcaption></div><p>Here is the ‘main’ CPU of the Nintendo DS running at <strong>~67 MHz</strong>. If you ignore the ill-fated ARM8 series, you could say the ARM946E-S is the ‘next-gen’ version of the ARM7. Part of the <strong>ARM9 series</strong>, this core in particular not only inherits all the features of the <strong>ARM7TDMI</strong> but also includes some additional bits:</p><ul><li>The <strong>ARMv5TE ISA</strong>: Compared to the previous v4, features some new instructions and a faster multiplier.<ul><li>If you take a look at the core name, the letter ‘E’ means <strong>Enhanced DSP</strong> which implies that lots of these new instructions have to do with applications for signal processing.</li></ul></li><li><strong>5-stage Pipeline</strong>: This is another increment from the previous 3-stage pipeline.</li><li><strong>12 KB of L1 Cache</strong>: The core now features cache, where 8 KB are allocated for instructions and 4 KB for data.</li><li><strong>48 KB of Tightly-Coupled Memory</strong> or ‘TCM’: Similar to <a href="https://www.copetti.org/projects/consoles/playstation/#cpu">Scratchpad memory</a>, however this one discriminates between instructions (32 KB) and data (16 KB).</li></ul><p>Nintendo also added the following components around it:</p><ul><li>A <strong>Divisor and Square root unit</strong> to speed up these type of operations (the ARM9 by itself is not capable of performing this type of math).</li><li>A <strong>Direct Memory Access Controller</strong>: Accelerates memory transfers without depending on the CPU. Combined with the use of cache, both CPU and DMA can potentially work concurrently.<ul><li>Cache and DMA can provide a lot of performance but also create new problems, such as data integrity. So programmers will have to manually maintain memory consistency by flushing the <a href="https://www.copetti.org/projects/consoles/playstation-2/#preventing-past-mishaps">write-buffer</a> before triggering DMA, for instance.</li></ul></li></ul></div></div></div><p>I guess with hardware like this, it’s easy to figure out the <em>real</em> reason kids loved this console, eh?</p><h4 id="interconnection">Interconnection</h4><p>So far I’ve talked about how the two CPUs work individually. But to work as a whole, they require to co-operate constantly. To accomplish this, both CPUs directly ‘talk’ to each other using a dedicated <strong>FIFO unit</strong>, this block of data holds two 64-byte queues (up to 16 elements) for <strong>bi-directional communication</strong>.</p><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"></picture></a><figcaption>Representation of FIFO unit</figcaption></div><p>This works as follows: The ‘sender’ CPU (that effectively needs to send the other a message) places a 32-bit block of data in the queue, the CPU acting as a ‘receiver’ can then pull that block from the queue and perform the required operations with it.</p><p>Whenever there’s a value written on the queue, either CPU can fetch it manually (<strong>polling</strong>) however, this requires to constantly check for new values (which can be expensive). Alternatively, an <strong>interrupt unit</strong> can be activated to notify the receiver whenever there’s a new value in the queue.</p><h4 id="main-memory">Main memory</h4><p>Just like its predecessor, RAM is spread around many different locations, enabling to prioritise data placement by speed of access. In summary, we have the following general-purpose memory available:</p><div><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"></picture></a><figcaption>RAM model of this console</figcaption></div><ul><li><strong>32 KB of WRAM</strong> (Work RAM) using a <strong>32-bit</strong> bus: To hold fast data shared between the ARM7 and ARM9.<ul><li>Bear in mind that only one CPU can access the same address at a time.</li></ul></li><li><strong>64 KB of WRAM</strong> using a <strong>32-bit</strong> bus: For fast data as well, but only accessible from the ARM7, like the GBA had.</li><li><strong>4 MB of PSRAM</strong> using a <strong>16-bit</strong> bus: A slower type, available from either CPU and it’s controlled by a memory interface unit.<ul><li>Pseudo SRAM or ‘PSRAM’ is a variant of DRAM which, by contrast, performs refreshes from within the chip. Therefore, behaving like SRAM (the faster, but more expensive alternative to DRAM). This design reminds me of <a href="https://www.copetti.org/projects/consoles/gamecube/#clever-memory-system">1T‑SRAM</a>.</li></ul></li></ul></div><h4 id="backwards-compatibility">Backwards compatibility</h4><p>Even though the architecture is significantly different from its predecessor, it still managed to maintain the critical bits that would grant it native compatibility with GameBoy Advance games.</p><p>But for the DS to revert to an ‘internal’ GBA, the former includes a set of software routines that set the console in <strong>AGB Compatibility Mode</strong>. In doing so, it effectively halts the ARM9, disables most of the ‘special’ hardware, redirects the buses, puts the ARM7 in charge and slows it down at 16.78 MHz. Finally, the ARM7 proceeds to boot the original AGB BIOS which bootstraps the GamePak cartridge (just like an original GameBoy Advance). This mode still exhibits some features not found in the original console, such as displaying the game with black margins (we’ll see in the next section that the new screen resolution happens to be bigger). Moreover, since the DS has two screens, users can set which screen will be used to display the GBA game.</p><p>Once in GBA mode <strong>there’s no going back</strong>, the console must be reset to re-activate the rest of the hardware.</p><h4 id="secrets-and-limitations">Secrets and limitations</h4><p>With so many sophisticated components fitted in a single and inexpensive chip, it’s no mystery that some issues emerged due to the way they were forced to work with each other.</p><div><ul><li id="tab-2-1-unused-power-link"><a href="#tab-2-1-unused-power">Unused Power</a></li><li id="tab-2-2-a-question-about-the-hardware-choice-link"><a href="#tab-2-2-a-question-about-the-hardware-choice">A question about the hardware choice</a></li></ul><div><div id="tab-2-1-unused-power"><h4>Unused Power</h4><p>Sometimes I wonder how Nintendo planned the way the two CPU’s would be used, and if they already assumed some performance would be hit by the design they chose.</p><p>Let me start with the ARM9, this CPU runs at twice the speed of the ARM7, but most (if not all) of the I/O depends on the ARM7, so the ARM9 is vulnerable to excessive stalling until the ARM7 answers. If that wasn’t enough, <strong>ARM9’s external bus runs at half the speed</strong>, so there are a few bottlenecks identified.</p><p>Additionally, the Main Memory bus is only <strong>16-bit wide</strong>. Thus, whenever any CPU needs to fetch a word (32-bit wide) from memory, the interface <strong>stalls the CPU</strong> (up to 3 ‘wait’ cycles) until a full world is reconstructed. The worst impact happens when memory access is not sequential, which makes it stall for every single access. This issue will also arise when instructions are fetched (unfortunately, ARM didn’t support sequential opcode fetching back then) which, to my dismay, also affects Thumb code (since every 16-bit fetch is done as a 32-bit block). On the other hand, this penalty (as some sources call it) can be alleviated by making full use of cache and TCM.</p><p>All in all, this means that in the worst case, the ‘whooping’ ARM9’s 66 MHz horsepower is practically reduced to a mere ~8&nbsp;MHz. That is if the program makes an abysmal use of cache/TCM.</p></div><div id="tab-2-2-a-question-about-the-hardware-choice"><h4>A question about the hardware choice</h4><p>Back when I read about the CPU of the GameBoy Advance, I was really surprised by the potential of the ARM7: The CPU not only performed its designated tasks, but could also assist with others, such as providing audio sequencing or pseudo-3D graphics.</p><p>Now, during the commercialisation ARM7, ARM Holdings joined forces with DEC to design a high-end version of ARM’s chips. For this, DEC grabbed the datapath design of their processor, <strong>Alpha</strong>, and mixed it with ARM’s. The result was a new series of CPUs called <strong>StrongARM</strong> which was surprisingly <em>fast</em>. At the expense of removing certain features (Thumb and debug), DEC managed to cross the megahertz threshold by reaching speeds of up to 233 MHz. As a normal user prepared to buy a new ARM PC (let’s say a <em>RiscPC</em>), you could either choose one with the old ARM710 at 40 MHz or another one with a StrongARM running ~582% faster. The impact of StrongARM was so disruptive that ARM Holdings absorbed some of StrongARMs features to produce their next line of CPUs, starting with ARM9. And the rest is history.</p><p>But here’s where my question resides: Considering the new developments in the ARM world, why did Nintendo ultimately choose an awfully slow ARM9 combined by an even slower ARM7, instead of a faster ARM9 (or even a StrongARM)? To give you an idea, other companies like Apple just adopted the StrongARM with their Newton PDA line.</p><p>I don’t mean to criticise Nintendo’s choice, but I believe the amount of emerging technology was just too great for me to ignore. I guess their choice was done in an effort to preserve battery life and maintain production costs (by using the same CPU found in the GBA).</p></div></div></div><hr><h2 id="graphics">Graph…</h2></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/nintendo-ds/">https://www.copetti.org/projects/consoles/nintendo-ds/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/nintendo-ds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145124</guid>
            <pubDate>Thu, 13 Aug 2020 16:27:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Q&A: How Eventbrite prioritizes developer productivity]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144790">thread link</a>) | @kklin
<br/>
August 13, 2020 | https://kelda.io/blog/eventbrite-interview/ | <a href="https://web.archive.org/web/*/https://kelda.io/blog/eventbrite-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><picture id="hero-thumbnail">
<source data-srcset="https://kelda.io/img/blog/interview%20microphone.webp" type="image/webp"></picture><p><h2>Published on Aug 11, 2020</h2></p></section><p>Deciding when to invest in developer productivity improvements is hard. If you’re on the ops side of things, you’re usually concerned about production and releases. If you’re a developer, you’re concerned about getting new features out as quickly as possible.</p><p>Usually, teams make development productivity improvements in two situations. Either the fix is so small that you can just do it in addition to your other work, or development is so painful that making changes has ground to a halt.</p><p>However, there’s still a large murky middle ground: how do you decide that it’s worth investing in a <strong>large change</strong> to your development workflow <strong>before development has ground to a halt?</strong></p><p><a href="https://medium.com/@remy.dewolf">Remy DeWolf</a> spent three years making these sorts of decisions as a <strong>principal engineer on the DevTools team at Eventbrite</strong>. He was part of the decision to build <code>yak</code>, which moved Eventbrite’s development environment into the cloud. This was a highly calculated decision since it cost a few EC2 instances per engineer and <code>yak</code> was built from scratch.</p><p>In this first post, we’ll dig into how Remy made this tough decision, and got buy-in from the rest of the company. In our next post, we’ll get into the nitty-gritty on how their remote development environment works, and what it’s been like for developers.</p><h2 id="how-is-the-eventbrite-application-architected">How is the Eventbrite application architected?</h2><p>This is a common story that you will find in a lot of startups. The founding engineers built a monolith and the strategy was to build features fast and capture the market. It was a very successful approach.</p><p>As the company grew over time, having a large team working on the monolith became challenging. And after a certain size, it was also harder to keep scaling the monolith vertically.</p><p>Over time, some of the monolith was migrated over to microservices. New services are generally containerized, and the monolith is containerized in development but not in production.</p><h2 id="whats-your-development-environment-setup-now">What’s your development environment setup now?</h2><p>Every engineer runs <strong>~50 containers</strong> which corresponds to the monolith, the microservices, the data stores (MySQL, Redis, Kafka…) and various tools (logging, monitoring).</p><p>Developers use <code>yak</code> (which we built internally) to deploy and manage their remote containers.</p><p>We use AWS EKS for the Kubernetes clusters, in which every developer has their own namespace. We have hundreds of developers and many EKS clusters.</p><p><code>yak</code> is very similar to <a href="https://kelda.io/blimp">blimp</a> since it enables the engineers to manage their remote containers without exposing them to the complexity of Kubernetes.</p><h2 id="how-did-you-decide-it-was-time-to-build-yak">How did you decide it was time to build yak?</h2><p>Before <code>yak</code>, each developer ran their development environment locally on their laptop. However, the development environment became so big that it slowed down developer laptops.</p><p>The main issue was that you might not realize that this was an issue because it was creeping one service at a time.</p><p>Once we added instrumentalization to our tools, we started to understand the scale of the problems. Moving to the cloud is expensive but when we were able to put it side by side with the wasted engineering time, the decision was easy for us.</p><p>Another goal of <code>yak</code> was to make Kubernetes easy for developers. We kept it as minimal as possible and the configuration files are plain Kubernetes manifest files. The intent was to feed developer curiosity so they learn more about Kubernetes over time.</p><h2 id="what-areas-do-you-recommend-tracking-regarding-developer-productivity">What areas do you recommend tracking regarding developer productivity?</h2><p>Whenever possible, align the developer productivity goals with the business. Every DevTool team should understand how they contribute to the company goals and vice versa. If this is unclear, I would start with that.</p><p>Next, make sure that developer productivity is part of the plan, not an afterthought. For example, some engineering teams move to microservices and only track the number of services and the uptime in production. These are great metrics, but they’re incomplete. They will generate inconsistency and the developer experience will suffer over time.</p><p>In terms of which metrics to pick, there is no general recommendation. It’s important to understand how developers work, understand how frequently they perform critical tasks, and instrument the tools that they use. With this data, you will be able to identify the most important areas to invest and track the progress over time.</p><p>I would also recommend having a metric about mean time to recovery (MTTR). If a developer is completely stuck, how would you bring them back to a clean state so they can resume their work? For this one, if you run the developer environment locally, you will have many different combinations of OS/tools/versions resulting in many different issues. If you are on the cloud and use a generic solution (e.g. Docker + Kubernetes), this problem will be much easier to solve.</p><h2 id="how-did-you-collect-feedback-at-eventbrite">How did you collect feedback at Eventbrite?</h2><p>We had many channels:</p><ul><li>Instrumentation into the tools. Every time a developer would build, run, or deploy docker images we would send metrics. Similarly, every CI job would do the same. Then we would generate some dashboards for the metrics to track and measure the progress over time. If you are using a tool like Sumologic or Datadog, it’s very easy to send custom metrics and build dashboards.</li><li>Quarterly engagement surveys.</li><li>Demos: invite other engineers to show them the progress and engage with them.</li><li>New hires: these new employees bring a fresh perspective and they are not afraid to ask questions and challenge the status quo.</li><li>Networking: build relationships with other developers (coffee breaks, office visits, lunches, etc..)</li></ul><h2 id="can-you-give-some-examples-of-developer-productivity-okrs">Can you give some examples of developer productivity OKRs?</h2><ol><li><p><strong>Time to start the developer environment is under x min</strong></p><p>This time is usually wasted time, so it’s important to track it and improve it. If the dev stack is unreliable or slow, it would be captured in this OKR.</p></li><li><p><strong>Engagement is over x%</strong></p><p>If you send an engagement survey every quarter, you can have an OKR to make sure the trend is upward. Seeing a drop would mean that the team might not be working on the most relevant projects.</p></li><li><p><strong>Average time from commit to QA/Prod</strong></p><p>This one will capture the CI/CD pipeline effectiveness. If you experience some flaky tests or deployment errors in the pipeline, it would negatively impact the key results.</p></li></ol><p>Over time, some OKRs will be exhausted, so consider renewing them over time. For example, if your survey always has the same questions, developers will eventually stop responding. Also if an OKR has been greatly improved, it’s a good time to shift priorities.</p><p>In my personal experience, I would focus on a few OKRs instead of having too many. Sometimes by trying to please everybody, you will not have a big impact. Some projects might require the full team focus, which can temporarily impact other OKRs. This would be a calculated strategy as these projects would bring huge improvements when delivered.</p><h2 id="are-there-any-warning-signs-people-should-look-out-for-in-order-to-know-their-developer-productivity-is-suffering">Are there any warning signs people should look out for in order to know their developer productivity is suffering?</h2><p>This is where it’s important to have good metrics and monitor them over time. You should be able to feel the pulse of your developers by looking at different data points. Ideally, you would tie these to your OKRs and review the progress every sprint and make adjustments.</p><p>If you don’t have this data there are still warning signs that productivity is suffering:</p><ul><li>Increase in support cases and/or requests for help. If developers need external help to do their work, this is a sign that a process is too hard to use or not well documented.</li><li>On the other hand, I’d be worried if you find out that some processes aren’t working properly but nobody reported them to your team. You want developers to be always looking for improvements and not accepting a broken process.</li></ul><p>Kelda has collaborated with Eventbrite for a long time. We first met when we were building the predecessor to <a href="https://kelda.io/blimp">Blimp</a>, which moves your Docker Compose development environment into the cloud. Eventbrite had already built <code>yak</code> internally, and we were trying to make a general solution. We’ve been trading ideas ever since.</p><p><a href="https://kelda.io/blimp">Check out Blimp</a> to get the benefits of <code>yak</code> without having to build it yourself!</p><h2 id="references">References</h2><p>See <a href="https://kelda.io/blimp/docs/#/usage">Blimp commands and usage</a> in the Docs</p><p>Read <a href="https://kelda.io/blog/common-docker-compose-mistakes/">5 common Docker Compose mistakes</a></p><p><a href="https://medium.com/@remy.dewolf">Remy DeWolf’s Medium</a></p><hr><p>By: Kevin Lin</p></div></div>]]>
            </description>
            <link>https://kelda.io/blog/eventbrite-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144790</guid>
            <pubDate>Thu, 13 Aug 2020 16:01:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Postgres Row-Level Security in Python and Django]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144405">thread link</a>) | @karlhughes
<br/>
August 13, 2020 | https://pganalyze.com/blog/postgres-row-level-security-django-python | <a href="https://web.archive.org/web/*/https://pganalyze.com/blog/postgres-row-level-security-django-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>
Postgres introduced <a href="https://www.postgresql.org/docs/9.5/ddl-rowsecurity.html">row-level security</a> in 2016 to give database administrators a way to limit the rows a user can access, adding an extra layer of data protection. What's nice about RLS is that if a user tries to select or alter a row they don't have access to, their query will return 0 rows, rather than throwing a permissions error. This way, a user can use <code>select * from table_name</code>, and they will only receive the rows they have access to with no knowledge of rows they don't.</p>
<p>Most examples of RLS limit row access by database user. This can be a powerful feature. In this article, we will have a look at how you can make this happen for your Django app. The problem most people run into when trying to implement row level security is that most web applications, including Django applications, connect to the database with a single user, which makes it hard to take advantage of row level security. </p>
<p>One way to get around this is to create a database user for each application user. We’ll start with just the database layer. We’ll build out our tables and create a couple of users, then write our first row level security policy to limit which rows those users can access. Once we have an understanding of how RLS works in Postgres, we’ll expand our project out into Django and see how we can handle working with policies and multiple database users in a web application. </p>

<p><span>
      <a href="https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/29114/postgres-row-level-security-django.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Postgres Row-Level Security in Python and Django" title="Postgres Row-Level Security in Python and Django" src="https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/8c557/postgres-row-level-security-django.png" srcset="https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/4edbd/postgres-row-level-security-django.png 175w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/13ae7/postgres-row-level-security-django.png 350w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/8c557/postgres-row-level-security-django.png 700w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/e996b/postgres-row-level-security-django.png 1050w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/2cefc/postgres-row-level-security-django.png 1400w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/29114/postgres-row-level-security-django.png 1920w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span></p>
<h2 id="how-to-use-rls-at-the-database-level"><a href="#how-to-use-rls-at-the-database-level" aria-label="how to use rls at the database level permalink"></a>How to use RLS at the database level</h2>
<p>Before we get to the Django side of things, let's take a look at how RLS works in Postgres. We'll keep it simple and say we are building an app to help our salespeople keep track of their clients, and we want to make sure no salesperson can access the clients of another salesperson. (These are very competitive, cutthroat salespeople). </p>
<p>First, let's set up our tables and populate them with some data:</p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>TABLE</span> salespeople <span>(</span>id <span>serial</span> <span>primary</span> <span>key</span><span>,</span> name <span>text</span><span>)</span><span>;</span>
<span>CREATE</span> <span>TABLE</span> clients <span>(</span>id <span>serial</span> <span>primary</span> <span>key</span><span>,</span> name <span>text</span><span>,</span> salesperson_id <span>integer</span><span>)</span><span>;</span>

<span>INSERT</span> <span>INTO</span> salespeople <span>(</span>name<span>)</span> <span>values</span> <span>(</span><span>'Picard'</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> salespeople <span>(</span>name<span>)</span> <span>values</span> <span>(</span><span>'Crusher'</span><span>)</span><span>;</span>

<span>INSERT</span> <span>INTO</span> clients <span>(</span>name<span>,</span> salesperson_id<span>)</span> <span>values</span> <span>(</span><span>'client1'</span><span>,</span> <span>1</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> clients <span>(</span>name<span>,</span> salesperson_id<span>)</span> <span>values</span> <span>(</span><span>'client2'</span><span>,</span> <span>2</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> clients <span>(</span>name<span>,</span> salesperson_id<span>)</span> <span>values</span> <span>(</span><span>'client3'</span><span>,</span> <span>2</span><span>)</span><span>;</span></code></pre></div>
<p>Now, we have two salespeople. <code>Picard</code> has one client, and <code>Crusher</code> has two clients.</p>
<p>Next, we are going to need some database users, one for each salesperson. Because two salespeople might share the same name, we are going to use the <code>id</code> to create Postgres users. We are also going to create a role called <code>salespeople</code>. This will be the role we grant permissions on, and all of our salespeople can inherit from it.</p>
<div data-language="sql"><pre><code><span>CREATE</span> ROLE <span>"1"</span><span>;</span>
<span>CREATE</span> ROLE <span>"2"</span><span>;</span>
<span>CREATE</span> ROLE salespeople<span>;</span>

<span>GRANT</span> <span>select</span><span>,</span> <span>insert</span> <span>ON</span> clients <span>TO</span> salespeople<span>;</span>
<span>GRANT</span> salespeople <span>TO</span> <span>"1"</span><span>;</span>
<span>GRANT</span> salespeople <span>TO</span> <span>"2"</span><span>;</span></code></pre></div>
<p>This setup will come in handy in the next section when we have to deal with Django's tables in addition to the ones we create for our models.</p>
<p>Now we are ready to set up RLS on our <code>clients</code> table. Our policy will limit access to the Postgres <code>current_user</code> so that they can only view rows where <code>current_user</code> matches <code>salesperson_id</code>. </p>
<div data-language="sql"><pre><code><span>ALTER</span> <span>TABLE</span> clients <span>ENABLE</span> <span>ROW</span> <span>LEVEL</span> SECURITY<span>;</span>
<span>CREATE</span> POLICY salesperson_clients <span>ON</span> clients <span>USING</span> <span>(</span>salesperson_id::<span>text</span> <span>=</span> <span>current_user</span><span>)</span><span>;</span></code></pre></div>
<p>When we create the policy, we give it a name, <code>salesperson_clients</code>, and enter the table we want to set the policy on, <code>clients</code>. Next, we define the policy. In this case, it is very simple: the <code>salesperson_id</code> on the table must be equal to the value of <code>current_user</code>. We have to convert the <code>salesperson_id</code> from an integer to text because our <code>current_user</code> must be a string (we can't create Postgres users with integers as names).</p>
<p>Right now, we are logged in as the <code>postgres</code> user.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>session_user</span><span>,</span> <span>current_user</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code> session_user  | current_user  
---------------+---------------
 postgres      | postgres
(1 row)</code></pre></div>
<p>If we query our <code>clients</code> table, we will be able to see all the rows because <strong>RLS policies do not apply to superusers.</strong></p>

<div data-language="text"><pre><code> id |  name   | salesperson_id 
----+---------+----------------
  1 | client1 |              1
  2 | client2 |              2
  3 | client3 |              2
(3 rows)</code></pre></div>
<p>But if we change the current user, we only get the rows that belong to that user. </p>
<div data-language="sql"><pre><code><span>SET</span> ROLE <span>"1"</span><span>;</span>
<span>SELECT</span> <span>session_user</span><span>,</span> <span>current_user</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code> session_user | current_user 
--------------+--------------
 postgres     | 1
(1 row)</code></pre></div>

<div data-language="text"><pre><code> id |  name   | salesperson_id 
----+---------+----------------
  1 | client1 |              1
(1 row)</code></pre></div>
<h2 id="how-to-use-postgres-row-level-security-in-django"><a href="#how-to-use-postgres-row-level-security-in-django" aria-label="how to use postgres row level security in django permalink"></a>How to Use Postgres Row-Level Security in Django</h2>
<p>Now, how can we translate this to a Django application?</p>
<p>First, we will need to create a database user for each app user we create. One way to accomplish this would be to override the <code>save</code> method on the Salesperson model, but this is a great opportunity to take advantage of <a href="https://docs.djangoproject.com/en/3.0/ref/signals/">Django signals</a> , so we'll create a signal that creates the database user after a new salesperson is saved.  </p>
<p>Next, we'll have to figure out how to switch to the correct user when a salesperson logs in. For this, we can use a middleware that gets the <code>salesperson_id</code> and sets the role in the database. </p>
<h3 id="models"><a href="#models" aria-label="models permalink"></a>Models</h3>
<p>Our models reflect exactly what we set up in our earlier database example. Here I chose to make Salesperson a proxy of Django's built-in <code>User</code> model, but this is not required.</p>
<div data-language="python"><pre><code><span>from</span> django<span>.</span>db <span>import</span> models
<span>from</span> django<span>.</span>contrib<span>.</span>auth<span>.</span>models <span>import</span> User

<span>class</span> <span>Salesperson</span><span>(</span>User<span>)</span><span>:</span>
    <span>class</span> <span>Meta</span><span>:</span>
        proxy <span>=</span> <span>True</span>
    
<span>class</span> <span>Client</span><span>(</span>models<span>.</span>Model<span>)</span><span>:</span>
    name <span>=</span> models<span>.</span>CharField<span>(</span>max_length<span>=</span><span>50</span><span>)</span>
    Salesperson <span>=</span> models<span>.</span>ForeignKey<span>(</span>Employee<span>,</span> on_delete<span>=</span>models<span>.</span>CASCADE<span>)</span></code></pre></div>
<h3 id="django-signals-creating-our-database-user"><a href="#django-signals-creating-our-database-user" aria-label="django signals creating our database user permalink"></a>Django Signals: Creating Our Database User</h3>
<p>We want to create a new database user every time a new salesperson record is created. We can use Django signals to execute some code after a new record is saved. If you're not familiar with signals, the Django docs on this topic are easy to understand. If this piqued your interest, <a href="https://simpleisbetterthancomplex.com/tutorial/2016/07/28/how-to-create-django-signals.html">this article</a> goes into more detail. </p>
<p>Here is the code for the signal itself, but you'll have to reference the above article to get it registered in your app: </p>
<div data-language="python"><pre><code><span>from</span> <span>.</span>models <span>import</span> Salesperson
<span>from</span> django<span>.</span>db<span>.</span>models<span>.</span>signals <span>import</span> post_save
<span>from</span> django<span>.</span>db <span>import</span> connection

<span>def</span> <span>create_db_user</span><span>(</span>sender<span>,</span> instance<span>,</span> created<span>,</span> <span>**</span>kwargs<span>)</span><span>:</span>
    <span>if</span> created<span>:</span>
        user_id <span>=</span> instance<span>.</span><span>id</span>
        <span>with</span> connection<span>.</span>cursor<span>(</span><span>)</span> <span>as</span> cursor<span>:</span>
            cursor<span>.</span>execute<span>(</span><span><span>f'CREATE ROLE "</span><span><span>{</span>user_id<span>}</span></span><span>"'</span></span><span>)</span>
            cursor<span>.</span>execute<span>(</span><span><span>f'GRANT salespeople TO "</span><span><span>{</span>user_id<span>}</span></span><span>"'</span></span><span>)</span>

post_save<span>.</span>connect<span>(</span>create_db_user<span>,</span> sender<span>=</span>Salesperson<span>)</span> </code></pre></div>
<p>The <code>post_save</code> signal can take a named argument <code>created</code>, which is a boolean. This avoids running the code every time we update the record and ensures it will only run when we create a new salesperson. From there, we can get the user id from the instance and use <code>django.db.connection</code> to run our SQL to create the role and grant permissions. </p>
<p>It's very important to note that if you want to use Django's built-in <code>User</code> model and the authentication that comes with it, you'll need to grant <code>salesperson</code> permissions on the <code>django_admin_log</code> and <code>auth_user</code> tables. That's why it's so helpful to have this parent role that all individual users inherit from.</p>
<h3 id="django-middleware-setting-current-user"><a href="#django-middleware-setting-current-user" aria-label="django middleware setting current user permalink"></a>Django Middleware: Setting Current User</h3>
<p>Now, we can write a <a href="https://docs.djangoproject.com/en/3.0/topics/http/middleware/">middleware</a> to switch the database user to the current application user making the request.</p>
<div data-language="python"><pre><code><span>from</span> django<span>.</span>db <span>import</span> connection

<span>class</span> <span>RlsMiddleware</span><span>(</span><span>object</span><span>)</span><span>:</span>
    <span>def</span> <span>__init__</span> <span>(</span>self<span>,</span> get_response<span>)</span><span>:</span>
        self<span>.</span>get_response <span>=</span> get_response
        
    <span>def</span> <span>__call__</span> <span>(</span>self<span>,</span> request<span>)</span><span>:</span>
        user_id <span>=</span> request<span>.</span>user<span>.</span><span>id</span>
        <span>with</span> connection<span>.</span>cursor<span>(</span><span>)</span> <span>as</span> cursor<span>:</span>
            cursor<span>.</span>execute<span>(</span><span><span>f'SET ROLE "</span><span><span>{</span>user_id<span>}</span></span><span>" '</span></span><span>)</span>

        response <span>=</span> self<span>.</span>get_response<span>(</span>request<span>)</span>
        <span>return</span> response</code></pre></div>
<p>We get the user id from the request object. After that, the code looks pretty similar to our signal. We use the Django <code>db</code> connection again to set the role to the corresponding database user, which should match the application user's id. Don't forget to <a href="https://docs.djangoproject.com/en/3.0/topics/http/middleware/#activating-middleware">register your middleware</a> in <code>settings.py</code>.</p>
<p>Now we can use all of Django's built-in query methods while maintaining row-level security in Postgres. What is particularly cool is that, with the role set, all we need to do to get all of a salesperson's clients is call <code>Client.objects.all()</code>, and we can be sure that only the clients related to the salesperson will be returned. If a salesperson tries to query for a client that doesn't belong to them, they'll get zero results.</p>
<h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2>
<p>In this article we were able to create a simple but powerful row level security policy and, with the help of Django middleware and Django signals, implement the policy at the application level. We saw how to create database users each time we created a new application user, and looked at setting the database role to the correct user after log in, ensuring each application user only had access to the rows that belonged to them. </p>
<p>There are a few caveats here. For one, using the ids <code>1, 2, 3</code> is probably not a good idea in production. You'd want to set up some kind of UUID or some other identifier. Also, creating a new database user for every application user becomes hard to scale at a certain point. Row level security can be a useful tool for limiting access at the database level, and we just scratched the surface of what's possible.</p>
<p>Still, you should be sure RLS is the right solution for your application before trying to implement it. In particular, the performance implications of row-level security, and how the Postgres planner treats it for query plans should not be overlooked. This has been <a href="https://medium.com/@cazzer/designing-the-most-performant-row-level-security-strategy-in-postgres-a06084f31945">significantly improved in Postgres 10</a>, but its still essential to <a href="https://pganalyze.com/postgres-explain">monitor your Postgres query plans</a> when using RLS.</p>
<p>In many cases, RLS is not needed, and you’ll be able to secure your data using the <a href="https://coderbook.com/@marcus/how-to-restrict-access-with-django-permissions/">security measures</a> already built into Django.</p>
<p><strong>Share this article:</strong> If you liked this article you might want to <a href="https://ctt.ac/K5png">tweet it to your peers</a>.</p>
<h2 id="about-the-author"><a href="#about-the-author" aria-label="about the author permalink"></a>About the Author</h2>
<p>Josh is a former educator turned developer with a proven ability to learn …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pganalyze.com/blog/postgres-row-level-security-django-python">https://pganalyze.com/blog/postgres-row-level-security-django-python</a></em></p>]]>
            </description>
            <link>https://pganalyze.com/blog/postgres-row-level-security-django-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144405</guid>
            <pubDate>Thu, 13 Aug 2020 15:33:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clear is kind, unclear is unkind]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143896">thread link</a>) | @mcrittenden
<br/>
August 13, 2020 | https://critter.blog/2020/08/13/clear-is-kind-unclear-is-unkind/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/08/13/clear-is-kind-unclear-is-unkind/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-663">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>I am terrified of awkwardness. I know nobody likes an awkward moment, but for me it’s downright crippling. I’ve walked out of the room during awkward moments on TV shows. I once faked internet issues to get out of an uncomfortable work call. I’m a huge fan of the Irish goodbye, because dealing with the not-sure-if-we-should-hug thing sucks. It’s been a serious problem in my life.</p>



<p>And wouldn’t you know it – I also hate giving people news that might upset them. Because that’s often pretty dang awkward. I’ve gotten good at figuring out ways to avoid it without feeling like I avoided it. For example:</p>



<ul><li>I’ve given negative feedback about something really tiny and specific in hopes that it would solve the bigger, much more critical problem, because talking about the critical problem may have been awkward. Spoiler: it never worked.</li><li>I’ve flat out avoided giving negative feedback because “they’re already dealing with a lot” or “I’m going to wait until I have a better example to use, or else it wouldn’t be fair to them” or who knows how many other reasons.</li><li>I’ve given negative feedback that really came from me, but I pitched it like “I don’t think this, but I’m wondering if &lt;a coworker&gt; may think it, from their point of view.”</li></ul>



<p>In that way, I convince my monkey brain that I’m being caring because I’m still “delivering feedback” just without the hurt feelings, right? But no, I’m being a jerk, because <a href="https://brenebrown.com/blog/2018/10/15/clear-is-kind-unclear-is-unkind/">clear is kind, and unclear is unkind</a>. </p>



<p>I don’t know where this first came from, but I heard it from Brené Brown and it was a smack in the face. If I’m not being clear, then I’m being unkind. Period. No matter how much I can try to convince myself that it’s not that simple, it really is.</p>



<p>I am changed. With this as my guiding principle, I feel confident in giving tough feedback no matter how awkward it might be, because anything else would be unkind. And even though I hate awkwardness, I hate being unkind even more.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/08/13/clear-is-kind-unclear-is-unkind/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143896</guid>
            <pubDate>Thu, 13 Aug 2020 14:50:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Even Unicorns Get the Blues]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143764">thread link</a>) | @StuntPope
<br/>
August 13, 2020 | https://outofthecave.io/articles/even-unicorns-get-the-blues/ | <a href="https://web.archive.org/web/*/https://outofthecave.io/articles/even-unicorns-get-the-blues/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Heretical Judge Rules that Uber Can’t Externalize its Labour Costs</h3>
<p><img src="https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy.jpg" alt="" width="693" height="478" srcset="https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy.jpg 800w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-300x207.jpg 300w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-150x104.jpg 150w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-768x530.jpg 768w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-65x45.jpg 65w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-220x152.jpg 220w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-145x100.jpg 145w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-358x247.jpg 358w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-580x400.jpg 580w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-652x450.jpg 652w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-739x510.jpg 739w" sizes="(max-width: 693px) 100vw, 693px"></p>
<p>As I briefly covered <a href="https://axisofeasy.com/aoe/axisofeasy-158-hundreds-of-smartphone-apps-sell-your-location-data-to-government-connected-data-firms/">in my AxisOfEasy tech digest</a> this week, Uber and Lyft were bracing themselves for a ruling by a California judge that threatened to force them into treating their <span>wage slaves</span> drivers as employees. Lyft said if the ruling went against them it would cause “irreparable damage”. Uber CEO Dara Khosrowshahi penned an <a href="https://www.nytimes.com/2020/08/10/opinion/uber-ceo-dara-khosrowshahi-gig-workers-deserve-better.html">op-ed in the New York Times</a> that just so happened to run Monday, pining for a fair shake for gig economy <span>serfs</span> workers.<span id="more-1152"></span></p>
<p>Khosrowshahi, whose compensation package last year clocked in at $45,000,000 USD, waxed pensively,<em> ‘There has to be a “third way” for gig workers.’ .&nbsp;</em>Ideally one in which Uber wouldn’t be on the hook for their benefits and would be able to continue apace as a Silicon Valley unicorn: posting billions of dollars a quarter in losses and <a href="https://www.forbes.com/sites/janetwburns/2020/03/26/uber-and-airbnb-ask-for-bailouts-critics-arent-having-it/#2a5d61ff7639">jockeying for Federal bailouts.</a> Meanwhile the early stage backers, the VC’s and the private equity funds, would continue to live large off of financialization, not having to worry about the consequences of being <em>the&nbsp;</em>driving force in a race to the bottom for everybody else (even Uber’s lümpenvestors who bought into the IPO are still underwater).</p>
<p>As it turned out, <a href="https://www.theverge.com/2020/8/10/21362460/uber-lyft-drivers-employees-california-court-ruling">Judge Schulman ruled</a> that these gig economy workers are to be treated as employees in the State of California, and sure enough, Uber is now <a href="https://ktla.com/news/california/uber-lyft-threaten-to-leave-california-if-court-upholds-ruling-forcing-them-to-treat-drivers-as-employees/">threatening to pick up their ball and go home.</a></p>
<p>People following my writings may be surprised that I’m not approaching this as yet another government inflicted wound against capitalism, like how laws mandating higher minimum wages actually increase unemployment. It’s a fair point.</p>
<p>But we’re not talking about countless mom-and-pops and other main street businesses having their costs jacked up by economically illiterate career politicians. Even in a climate of government mis-micromanagement and overreach, the so called “free enterprise” participants should be competing under the same conditions. If an independently owned and operated driver service in the state has to operate under onerous taxation and terms, then being a Silicon Valley unicorn shouldn’t exempt you from suffering the same conditions.</p>
<p>In this case we’re talking <a href="https://outofthecave.io/articles/wait-why-is-the-fed-buying-my-biggest-competitors-bonds/">about Cantillonaires</a> who feel entitled to special privileges and exemptions but the reality is this:</p>
<h3>These companies were never intended to be economically viable.</h3>
<p><em>Uber and Lyft started the year with $11.3B and $2.8B in cash on their balance sheets respectively. They posted TTM losses of $10B and$ 2B respectively.&nbsp; They are valued around $54B and $9.2B</em></p>
<p>The only thing that mattered from the outset was to cannibilize the entire market, driving down prices and wages while operating at a loss so that they could garner the next financial event, be it a series D, E or F up-round and then eventually some monster acquisition or IPO. Within truly un-manipulated, free market competition, Uber and Lyft would have either had to compete, <em>viably</em>, with numerous entrants and competitors all fighting under their own steam, or else be snuffed out by economic reality.</p>
<p>The truth is that you can’t actually build a business where every transaction and input is subsidized, ultimately by central bank stimulus, while&nbsp; all normal course responsibilities of operations, like expenses, are externalized.</p>
<p>With the Everything Bubble <a href="https://outofthecave.io/articles/unicorn-winter/">finally looking to pop</a>, and pent up reality s-l-o-w-l-y <a href="https://outofthecave.io/articles/the-jackpot-chronicles-scenario-1-force-majeure/">beginning to reassert itself</a>, these Unicorns will have to face the same situation that every other non-unicorn, non Silicon Valley funded business has to face: Whatever your “boil-the-ocean” big idea is, you’re gonna have to do it in an economically viable way, or it’s not going to happen.</p>
<p><em>To follow my work sign up for the&nbsp;<a href="https://outofthecave.io/join/">Out Of The Cave mailing list</a>, or on&nbsp;<a href="https://nojack.easydns.ca/@stuntpope">Mastodon</a>&nbsp;or&nbsp;<a href="https://twitter.com/stuntpope">Twitter&nbsp;</a></em></p>
<p><a href="#" rel="nofollow" onclick="window.print(); return false;" title="Printer Friendly, PDF &amp; Email"><img src="https://cdn.printfriendly.com/buttons/printfriendly-button.png" alt="Print Friendly, PDF &amp; Email"></a></p></div></div>]]>
            </description>
            <link>https://outofthecave.io/articles/even-unicorns-get-the-blues/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143764</guid>
            <pubDate>Thu, 13 Aug 2020 14:37:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Getting F'ed by Technical Recruiters]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24143721">thread link</a>) | @tacomondays
<br/>
August 13, 2020 | https://scottturman.com/stop-getting-fcked-by-technical-recruiters/ | <a href="https://web.archive.org/web/*/https://scottturman.com/stop-getting-fcked-by-technical-recruiters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="69190526" data-element_type="column">
			<div>
					<div>
				<div data-id="11bdfd87" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:50}" data-widget_type="heading.default">
				<p>
			<h2>Get notified when we publish!</h2>		</p>
				</div>
				<div data-id="50628801" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:100}" data-widget_type="heading.default">
				<p>
			<h2>New Book -Stop Getting Fu*ked By Technical Recruiters</h2>		</p>
				</div>
				
				<div data-id="27158996" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:200}" data-widget_type="heading.default">
				<p>
			<h2>You probably never had anyone teach you how to negotiate your salary or benefits. Not your parents, school and certainly not your employer. Learning to negotiate how much you will charge for your labor may be one of the most important life skills you can ever develop as it will set the tone for how well you can live your life.</h2>		</p>
				</div>
				<section data-id="1bc4b15c" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;fadeIn&quot;,&quot;animation_delay&quot;:300}">
						<div>
				<div>
				<div data-id="1a9f3005" data-element_type="column">
			<div>
					<div>
				
				<div data-id="53e472ce" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>This book is a collection of what I have learned as to how to accomplish this. I hope you will see the value of this book when you stop and realize that for every $10 more per hour you are able to get from a recruiter/employer will translate into another $20,000’ish more per year to your salary. It is also important to understand that every salary can have an additive effect over the lifetime of your total career earnings.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="562d2017" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;fadeIn&quot;,&quot;animation_delay&quot;:300}">
						<div>
				<div>
				<div data-id="4bbccccc" data-element_type="column">
			<div>
					<div>
				
				<div data-id="61cdec01" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>This book is going to teach you to take the power back. You can negotiate a higher rate, as you are the prize. You are the one with the skills needed to make the technology go and the recruiting company is simply one of the many conduits for the work that exists out there in the world.&nbsp;</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div></div>]]>
            </description>
            <link>https://scottturman.com/stop-getting-fcked-by-technical-recruiters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143721</guid>
            <pubDate>Thu, 13 Aug 2020 14:33:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using JDK FlightRecorder and JDK Mission Control]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143664">thread link</a>) | @mfiguiere
<br/>
August 13, 2020 | https://blog.arkey.fr/2020/06/28/using-jdk-flight-recorder-and-jdk-mission-control/ | <a href="https://web.archive.org/web/*/https://blog.arkey.fr/2020/06/28/using-jdk-flight-recorder-and-jdk-mission-control/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>At some point we had an issue with application startup performance.
For a bit of context this app runs in a Kubernetes cluster, with k8s it’s possible
to define a <em>rollout policy</em> to avoid service disruption, that what we had, so there’s a
rollout, new pods (a pod is composed of the application container) get created,
new application are started, then Kubernetes has a mean to check when the application is
<strong>ready</strong>, it’s called the readiness probe. This probe can be a call to http endpoint or a script,
ours is an HTTP endpoint.</p>
<p>WHen the probe indicates the application is ready, the application starts receiving traffic,
from this moment latencies increased from 10-20 milliseconds to seconds.</p>
<p>Opening the recording JMC, it will start an automated analysis. Sometime it’s helpful
and warning should be looked at. In this case the issue was elsewhere.</p>
<p>To help in our case, I needed to go in the thread view, which as a <em>thread lanes</em>
which displays each thread as an horizontal bar, and JFR event are painted on the bar
at the time they happened and for how long. At the bottom there’s a the time axis.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-0-thread-lanes.png" alt="startup 0 thread lanes">
</p>
<p>Thread Lanes</p>
</div>
<p>The first things that catch our eyes will be the vertical patterns, especially the one with
yellow and red around 12:51:15. Let’s zoom (you can select and right click, or use arrow keys.).</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-0-threads-lanes-closer.png" alt="startup 0 threads lanes closer">
</p>
<p>Zooming on the problematic</p>
</div>
<p>The vertical pattern is more precise, these vertical pattern indicates a <em>cross
threads phenomena</em>. And we can notice that all thread are not affected the same way.</p>
<p>The lanes in green at the top indicates these threads are progressing normally, nothing’s
wrong with them. However, if we go down there especially, the pattern materialize around
12:51:11.</p>
<p>Each color indicate some events:</p>
<div>
<ul>
<li>
<p>Gray ⇒ the thread does nothing, it’s parked</p>
</li>
<li>
<p>Small dark point ⇒ The park event, the thread was scheduled but was eventually parked</p>
</li>
<li>
<p>Red ⇒ In this case it’s a <em>blocked lock</em></p>
</li>
<li>
<p>Yellow ⇒ Here the yellow events that interests us are thread waiting on a lock</p>
</li>
</ul>
</div>
<p>I’m not well versed in describing colors, so know that there are other events that use
a slightly different tone / shade of red, yellow or else. Just click on the event
to see what’s going on.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-threads-jedis-lock-event.png" alt="startup 1 threads jedis lock event">
</p>
<p>monitor blocked</p>
</div>
<p>The UI could be improved but going over the events shows a popup with its details,
for the Monitor Blocked event, there’s the duration this monitor was block, who held
this monitor before, and the monitor address in the heap.</p>
<p>This monitor was held for ~9s, that’s a big bottleneck !</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-threads-jedis-monitor-acquire-blocked.png" alt="startup 1 threads jedis monitor acquire blocked">
</p>
</div>
<p>In this case this application had ~200 thread competing for this lock in particular. And finding
the thread that acquired it is not automated, it’s a bit tedious, but in the end didn’t reveal
anything.</p>
<p>However, the Monitor Blocked event has another interesting element, the stacktrace. In the lower
pane of JMC, if the event is selected, we can see the stack trace where this event was emitted.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-threads-jedis-monitor-blocked-stack.png" alt="startup 1 threads jedis monitor blocked stack">
</p>
<p>jedis classloading</p>
</div>
<p>Here that’s the JDK classloader. I would never have thought that the JDK code would cause ~9s
contention. But looking at the stacktrace, there <em>jedis</em> (a Redis client) connection pool involved.
Maybe the class have static initialization that does IO, maybe it’s the agent that runs in production
that introduces latencies during this specific classloading.</p>
<p>But all the threads starts working again around 12:51:22, and redis bottleneck is not anymore an issue
afterward. Let’s look at the story on the IO side, open the Socket IO view.</p>
<p>Identify which one is related to redis, either via IP or via port (Redis is <code>6379</code>).</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-socketio-redis-port.png" alt="startup 1 socketio redis port">
</p>
<p>Socket IO with redis port selected</p>
</div>
<p>While we see a total time of 30s, it’s the accumulated time for all thread for the recording duration (6m).
So nothing fancy here. However, we see that actual IO happens later, around 12:51:22.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-socketio-redis.png" alt="startup 1 socketio redis">
</p>
<p>Socket IO actual Redis read / write</p>
</div>
<p>I’m not sure of the cause, we can definitely rule out Redis, the is either in the network, during
connection establishment, or actually during classloading.</p>
<p>In order to remediate that, we noticed this code is called once the application is ready.
So in order to avoid the contention the code was changed to pre-connect to redis during the
application startup before the application is considered ready. And it worked, this
specific issue disappeared.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-thread-lanes.png" alt="startup 2 thread lanes">
</p>
</div>
<p>The issue identified in the first recording showed some contention on redis, this is now gone.
There is however in this second iteration multiple other issues when flying the mouse pointer
over the yellow and red events.</p>
<div>
<p>Incriminating stack traces 1</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-01.png" alt="startup 2 stack 01">
</p>
<p>Jersey’s <code>ListMultiMap</code> classloading</p>
</div>
</div>
</div>
<div>
<p>2</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-02.png" alt="startup 2 stack 02">
</p>
<p>Jackson’s <code>SerializerCache</code> initialization</p>
</div>
</div>
</div>
<div>
<p>3</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-03.png" alt="startup 2 stack 03">
</p>
<p>Jersey’s <code>ImprovedAbstractMap</code> classloading</p>
</div>
</div>
</div>
<div>
<p>4</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-04.png" alt="startup 2 stack 04">
</p>
<p>Jackson’s <code>PropertySerializerMap</code> initialization</p>
</div>
</div>
</div>
<div>
<p>5</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-05.png" alt="startup 2 stack 05">
</p>
<p>Jackson’s <code>TypeFactory</code> initialization</p>
</div>
</div>
</div>
<div>
<p>6</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-06.png" alt="startup 2 stack 06">
</p>
<p>Jackson’s <code>DeserializerCache</code> initialization</p>
</div>
</div>
</div>
<div>
<p>7</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-07.png" alt="startup 2 stack 07">
</p>
<p>Guava’s <code>hash</code> function involving classloading</p>
</div>
</div>
</div>
<div>
<p>8</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-08.png" alt="startup 2 stack 08">
</p>
<p>Newrelic’s <code>SynchronizedCollection.size()</code></p>
</div>
</div>
</div>
<div>
<p>9</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-09.png" alt="startup 2 stack 09">
</p>
<p>Jackson’s <code>PropertySerializerMap</code> initialization</p>
</div>
</div>
</div>
<div>
<p>10</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-10.png" alt="startup 2 stack 10">
</p>
<p>Datastax cassandra driver’s <code>ChainedResultSetFuture</code> involving classloading</p>
</div>
</div>
</div>
<div>
<p>11</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-11.png" alt="startup 2 stack 11">
</p>
<p>Jersey’s <code>AbstractMapBasedMultimap</code> involving classloading</p>
</div>
</div>
</div>
<p>All the stacktraces above have one thing in common, a contention on a lock.
As thread were blocked, and new request appeared, this had the effects of increase the
queuing, and made tomcat creates new <em>http nio</em> worked threads until the maximum is reached
(200 by default). I applied the same trick: i.e before readiness, exercise code paths that
are lazy initialized. And it worked too. Most contention disappeared afterward.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-3-C2-compiler.png" alt="startup 3 C2 compiler">
</p>
<p>Better startup / C2 compiler event</p>
</div>
<p>There was still some potential gain however. I noticed a few C2 compiler related events.
If you don’t know C1 and C2, those are the compilers that transform bytecode to assembly.
C1 interprets the bytecode and may perform some tricks like escape
analysis, but its role is to be fast to execute bytecode and not about optimizing the machine
code assembly. In a second phase C2 may kick in for hot code path that is code that is executed
very often, and its job is to output highly optimized code at the cost of higher computation
resources.</p>
<p>Note this compilation event <strong>is not</strong> blocking threads !</p>
<p>As an experiment I used the Graal compiler, which I believe is the new
generation of compiler that have a chance to replace C2. <a href="https://github.com/oracle/graal/blob/master/compiler/README.md">Graal compiler</a>
is part of the <a href="https://github.com/oracle/graal">GraalVM</a> project.
It ships as an experimental option : <code>-XX:+UnlockExperimentalVMOptions -XX:+UseJVMCICompiler</code>.</p>
<p>And the result for this work load in particular, just activating the Graal compiler between
these two successive rollouts.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-3-grafana.png" alt="startup 3 grafana">
</p>
<p>Improved P99</p>
</div>
<p>This graph is falling under the <a href="https://latencytipoftheday.blogspot.com/2014/06/latencytipoftheday-most-page-loads.html"><em>percentlie</em></a>
but the improvement is still visible.</p>
<p>After that experiment when I analyzed the new profile I noticed that JVM was using a lot of time to
revoke bias locking. Note the events in fushia are custom JFR events that track HTTP requests.
(<a href="https://twitter.com/gunnarmorling">Gunnar Morling</a> has an inspiring
<a href="https://www.morling.dev/blog/rest-api-monitoring-with-custom-jdk-flight-recorder-events/">write up</a> about it).</p>
<p>This VM operation is done during safepoint during which the JVM is paused. At this time a lot of
bias revocation event appears, so we removed them, and it works too.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-4-threads-revoke-biased-locks.png" alt="startup 4 threads revoke biased locks">
</p>
<p>Revoke Bias locking</p>
</div>
<p>The graphic below shows the difference in startup time. Other consuming backend services had to timeout
and eventually perform retries during rollouts which increased the pressure on the application.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-5-before-after.png" alt="startup 5 before after">
</p>
<p>Before ⇒ after</p>
</div>
<p>Other smaller issues could be discovered and tackled, for example I noticed a few gaps
200ms wide at 30/1min intervals that were related to GC pauses.</p>
<div>
<p>GC gaps</p>
<p><span><img src="https://blog.arkey.fr/assets/jfr/startup-9-gc-pause-1.png" alt="startup 9 gc pause 1" title="GC gap 1"></span> <span><img src="https://blog.arkey.fr/assets/jfr/startup-9-gc-pause-2.png" alt="startup 9 gc pause 2" title="GC gap 2"></span></p>
</div>
<p>For this application the GC is working within 20ms excepts for a few larger pauses
during the early minutes of startup:</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-9-thread-lanes-gc-pauses-effect.png" alt="startup 9 thread lanes gc pauses effect">
</p>
<p>GC pauses causes new HTTP worker threads</p>
</div>
<p>Tuning GC is out of scope for this article, but JMC presents a nice view that could help identify GC
causes. In my opinion it’s currently a bit less powerful as GC logs because GC events lack
useful information only found in GC logs with appropriate tags and level.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/jmc-java-application-view.png" alt="jmc java application view">
</p>
<p>Java Application view</p>
</div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/jmc-garbage-collection-view.png" alt="jmc garbage collection view">
</p>
<p>Garbage Collection view</p>
</div>
<p>Anyway from there we could imagine a <em>setting</em> file in the JDK dedicated for GC events.
Instead of parsing log files whose <em>string format</em> that may change a bit over releases
(even with unified logging) GC events could be analyzed leveraging the included JFR schema.</p>
<p>Also, with JFR it’s even possible to record memory leak using the <code>profile</code> <em>settings</em> file,
I never tried that in a real situation though, but if this avoids the need to make a heap dump
and parse it then I’m all in.</p>
</div></div>]]>
            </description>
            <link>https://blog.arkey.fr/2020/06/28/using-jdk-flight-recorder-and-jdk-mission-control/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143664</guid>
            <pubDate>Thu, 13 Aug 2020 14:28:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eight Great DevOps Resources for Beginners]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143403">thread link</a>) | @savovaleks
<br/>
August 13, 2020 | https://microtica.com/great-devops-resources/ | <a href="https://web.archive.org/web/*/https://microtica.com/great-devops-resources/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p>The future of DevOps solutions is bright. The <a href="https://www.marketsandmarkets.com/Market-Reports/devops-824.html" target="_blank" rel="noreferrer noopener">global DevOps market size</a> is expected to <strong>increase from $2.90 billion in 2017 to $10.31 billion by 2023</strong>, at a Compound Annual Growth Rate (CAGR) of 24.7% during the forecast period.&nbsp;</p>



<p>The growing need for fast app delivery is driving the market growth, with organizations that want to achieve both speed and quality.&nbsp;</p>



<p>However, the world is facing <a href="https://www.shuttleops.io/the-shortage-of-devops-skills" target="_blank" rel="noreferrer noopener">a shortage of DevOps skills</a>. That’s why DevOps engineers are highly-paid, with <a href="https://www.glassdoor.com/Salaries/devops-engineer-salary-SRCH_KO0,15.htm" target="_blank" rel="noreferrer noopener">Glassdoor estimating</a> <strong>the average annual pay at around $100,000</strong>.&nbsp;</p>



<p>So, if you’re looking for a career switch or upgrade, learning DevOps is a good idea. From books to podcasts, <em>here are the best DevOps resources to start with:&nbsp;</em></p>



<h2><strong><a rel="noreferrer noopener" href="https://www.bookdepository.com/Phoenix-Project-Gene-Kim/9781942788294?ref=grid-view&amp;qid=1588577029418&amp;sr=1-1" target="_blank">The Phoenix Project</a></strong></h2>



<p>Who would have thought you could write a novel about DevOps? Well, Gene Kim, Kevin Behr, and George Spafford obviously did a great job!&nbsp;</p>



<p><strong>The Phoenix Project </strong>is an amazing novel about DevOps. The story revolves around a fictional company called “Parts Unlimited”, where the IT manager gets promoted into a senior position. Then, he gets a deadline of 90 days to repair “The Phoenix Project”, a failing and messy code project that’s crucial to the future of the company. If he fails, the CEO threatens to outsource the entire IT department and let go of the people working in it.</p>



<p>So, he starts working on it with the help of some board members. The most important thing here is his philosophy called The Three Ways. It consists of (obviously) three parts—maximizing the flow of work from left-to-right, starting from business to development to IT operations to the end-user; increasing the feedback loop from right to left, and developing and nurturing a culture of <a href="https://microtica.com/cracking-the-continuous-deployment-code/" target="_blank" rel="noreferrer noopener">continuous deployment</a> and learning.</p>



<p>This philosophy helps him create <strong>a streamlined workflow in the department</strong>, <a href="https://microtica.com/6-tips-to-solve-miscommunication-in-dev-teams/">improve </a><strong><a href="https://microtica.com/6-tips-to-solve-miscommunication-in-dev-teams/" target="_blank" rel="noreferrer noopener">communication</a> and effectiveness</strong>, and make the IT department really valuable to the company.&nbsp;</p>



<p>I think this is a really great book, especially for beginners. It gives a sense of what problems IT departments face every day, and offers realistic solutions.&nbsp;</p>



<h2><strong><a rel="noreferrer noopener" href="https://www.oreilly.com/library/view/infrastructure-as-code/9781491924334/" target="_blank">Infrastructure as Code</a></strong></h2>



<p>Coming from ThoughtWorks, this is another book that focuses on <strong>the entire DevOps movement from a more technical aspect</strong>. This book covers the principles of Infrastructure as Code, practical examples, dynamic infrastructure platforms, various cloud options, tools, patterns, software engineering practices, <a href="https://microtica.com/how-to-create-simple-ci-cd-pipeline/" target="_blank" rel="noreferrer noopener">creation and management of pipelines</a>, workflows, and infrastructure management. They are all divided into three sections—Foundations, Patterns, and Practices.&nbsp;</p>



<p>If you’re interested in similar books, you can check <a href="https://www.amazon.com/Evolutionary-Architecture-Nature-Basis-Design/dp/0471117269" target="_blank" rel="noreferrer noopener">Evolutionary Architecture</a> and <a href="https://www.amazon.com/Building-Microservices-Designing-Fine-Grained-Systems/dp/1491950358/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1508683865&amp;sr=1-1&amp;keywords=microservices" target="_blank" rel="noreferrer noopener">Building Microservices</a>, also by ThoughtWorks.&nbsp;</p>



<h2><a href="https://www.udemy.com/course/linux-academy-devops-essentials/?LSNPUBID=JVFxdTr9V80&amp;ranEAID=JVFxdTr9V80&amp;ranMID=39197&amp;ranSiteID=JVFxdTr9V80-BF4jpUPRiGZluHvCXXjptQ" target="_blank" rel="noreferrer noopener"><strong>DevOps Essentials</strong></a></h2>



<p>This Udemy course has hosted over 40,000 students who gave an average rating of 4.4/5. The course is completely free, covering 2 hours and 15 minutes of video lessons.&nbsp;</p>



<p>This course can give you an understanding of <strong>how DevOps impacts the IT world</strong>. You’ll learn the basic DevOps terminology, the evolution of DevOps, the most important processes, the most common tools used, and the most popular DevOps and cloud providers.&nbsp;</p>



<h2><strong><a rel="noreferrer noopener" href="https://www.udemy.com/course/docker-and-kubernetes-the-complete-guide/?ranMID=39197&amp;ranEAID=JVFxdTr9V80&amp;ranSiteID=JVFxdTr9V80-T3DyVhPcjn.KepO0Rg.oZg&amp;LSNPUBID=JVFxdTr9V80" target="_blank">Docker and Kubernetes: The Complete Guide</a></strong></h2>



<p>Another Udemy course with over 120,000 students enrolled and an average rating of 4.6. During 21.5 hours of video materials, you’ll learn everything you need to know about <strong>Docker and Kubernetes</strong>, even if you don’t have previous experience with these topics.&nbsp;</p>



<p>The course starts with a deep dive into the Docker world, showing you all the Docker fundamentals. Then, you’ll learn everything you need to know about setting up a <a href="https://microtica.com/how-to-create-simple-ci-cd-pipeline/" target="_blank" rel="noreferrer noopener">CI/CD pipeline</a> and implementing it on Github and AWS.&nbsp;</p>



<p>Then, you’ll learn to construct a multi-container application utilizing Node, React, Redis, and Postgres. After this, you should be able to <a href="https://microtica.com/start-creating-infrastructure-on-aws-like-a-pro/" target="_blank" rel="noreferrer noopener">deploy both single- and multi-container applications on AWS</a>.</p>



<p>Finally, you’ll learn how to build a <a href="https://microtica.com/deploy-your-first-microservice-on-kubernetes-in-10-mins/" target="_blank" rel="noreferrer noopener">Kubernetes Cluster</a>. This course even covers setting up HTTPS on Kubernetes.&nbsp;</p>



<p>In their reviews, students say how they loved the way the teacher explains all concepts step-by-step. All in all, it’s one of the best courses on Udemy.&nbsp;</p>



<h2><a href="https://www.udemy.com/course/learn-devops-continuously-deliver-better-software/?LSNPUBID=JVFxdTr9V80&amp;ranEAID=JVFxdTr9V80&amp;ranMID=39197&amp;ranSiteID=JVFxdTr9V80-ImNkBFHUPJQ04wh3qXOm9A" target="_blank" rel="noreferrer noopener"><strong>Learn DevOps: Continuously Deliver Better Software</strong></a></h2>



<p>One of the most detailed courses about DevOps that targets more experienced engineers, System Administrators, IT managers, IT operation members, and other IT professionals.&nbsp;</p>



<p>The lecturer explains how to <strong>improve software delivery with automation, configuration management, provisioning, and deployment.</strong> Docker and Kubernetes are also covered.&nbsp;</p>



<p>Although the course lasts about 4.5 hours, you can add much more by trying everything by yourself. The lecturer even offers support for people who get stuck. Students also have a Facebook group where they post questions and discuss.</p>



<h2><a href="https://netflixtechblog.com/" target="_blank" rel="noreferrer noopener"><strong>The Netflix Tech Blog</strong></a></h2>



<p>The Netflix Tech Blog is a great place where you can find out “how they build code at Netflix.” Developers share literally everything, going beyond DevOps. Here, you’ll learn <strong>how Netflix creates, builds, and manages its system and engineering organizations</strong>.&nbsp;</p>



<p>For example, in one of their blogs, they elaborated on how they applied <a href="https://netflixtechblog.com/applying-netflix-devops-patterns-to-windows-2a57f2dbbf79" target="_blank" rel="noreferrer noopener">Netflix DevOps patterns to Windows</a>, while another one is about their <a href="https://netflixtechblog.com/ready-for-changes-with-hexagonal-architecture-b315ec967749" target="_blank" rel="noreferrer noopener">hexagonal architecture</a>.&nbsp;</p>



<h2><a href="https://www.reddit.com/r/devops/" target="_blank" rel="noreferrer noopener"><strong>DevOps SubReddit</strong></a></h2>



<p>Although it’s not everyone’s first choice, the DevOps SubReddit has many interesting and useful information software engineers should check out. Here, you’ll find a lot of blog posts, articles, and news about DevOps.</p>



<p>Most importantly, you can <strong>engage in discussions with fellow DevOps enthusiasts </strong>and learn a lot from their knowledge and experience, sharing a lot of practical examples.&nbsp;</p>



<h2><strong><a rel="noreferrer noopener" href="https://www.arresteddevops.com/" target="_blank">Podcast: Arrested DevOps</a></strong></h2>



<p>Arrested DevOps is a podcast hosted by Joe Laha, Bridget Kromhout, Matt Stratton, Trever Hess, and Jessica Kerr. They’ve recorded over 130 episodes, with the goal to help developers evolve practices and manage teams that will help them take the maximum out of DevOps.&nbsp;</p>



<p>Listeners can learn more about <strong>DevOps strategies, best tools, and integrations</strong> from delightful guest speakers that come from different parts of the world. The episodes last about 40-45 minutes and are released on a monthly basis.</p>



<p><strong>Here are some other links with DevOps resources you might find useful:&nbsp;</strong></p>



<ul><li><a href="https://techbeacon.com/devops/53-essential-resources-devops-practitioners" target="_blank" rel="noreferrer noopener">53 essential resources for DevOps practitioners</a></li><li><a href="https://aws.amazon.com/devops/resources/" target="_blank" rel="noreferrer noopener">DevOps resources – AWS</a></li><li><a href="https://www.upguard.com/blog/devops-resources-online" target="_blank" rel="noreferrer noopener">The best DevOps resources online</a></li><li><a href="https://opensource.com/article/19/12/devops-resources" target="_blank" rel="noreferrer noopener">8 must-read DevOps articles for success in 2020</a></li></ul>




<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://microtica.com/great-devops-resources/"
    dc:identifier="https://microtica.com/great-devops-resources/"
    dc:title="8 Great DevOps Resources for Beginners &#038; Advanced"
    trackback:ping="https://microtica.com/great-devops-resources/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://microtica.com/great-devops-resources/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143403</guid>
            <pubDate>Thu, 13 Aug 2020 14:00:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Major Drivers of Corporate Reputation Management]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143280">thread link</a>) | @Gpetrium
<br/>
August 13, 2020 | https://gpetrium.com/drivers-of-corporate-reputation-management/ | <a href="https://web.archive.org/web/*/https://gpetrium.com/drivers-of-corporate-reputation-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://gpetrium.com/drivers-of-corporate-reputation-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143280</guid>
            <pubDate>Thu, 13 Aug 2020 13:49:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decentralized Finance, the YAM fiasco and the road to DeFi sustainability]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143042">thread link</a>) | @bpierre
<br/>
August 13, 2020 | https://blog.rotki.com/2020/08/13/sustainable-defi/ | <a href="https://web.archive.org/web/*/https://blog.rotki.com/2020/08/13/sustainable-defi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>13 Aug 2020</span></p><ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#what-is-defi">What is DeFi</a>
    <ul>
      <li><a href="#decentralized-exchanges">Decentralized Exchanges</a></li>
      <li><a href="#lendingborrowing-protocols">Lending/Borrowing Protocols</a></li>
      <li><a href="#synthetic-assets">Synthetic Assets</a></li>
    </ul>
  </li>
  <li><a href="#what-new-possibilities-does-defi-unlock">What new possibilities does DeFi unlock?</a></li>
  <li><a href="#the-dark-side-of-defi">The dark side of DeFi</a>
    <ul>
      <li><a href="#yam-finance">YAM finance.</a></li>
    </ul>
  </li>
  <li><a href="#responsible-decentralized-finance">Responsible Decentralized Finance</a>
    <ul>
      <li><a href="#responsible-defi-user">Responsible DeFi user</a></li>
      <li><a href="#responsible-defi-founder">Responsible DeFi founder</a></li>
      <li><a href="#towards-a-sustainable-defi-ecosystem">Towards a sustainable DeFi ecosystem</a></li>
    </ul>
  </li>
  <li><a href="#closing--about-the-author">Closing / About the author</a></li>
</ul>

  

<p>This post explores what is the concept of Decentralized Finance (DeFi), what new possibilities does it unlock and why it’s so cool and hot right now. On the other side of the coin it touches on the dark side of DeFi with the YOLO farming and unaudited contracts most recently highlighted by the YAM fiasco. Finally it takes a look on the road ahead, the lessons that the community needs to learn in order to create sustainable and responsible DeFi for decades to come. Finacial instruments and tools that will not only be used by a few Twitter bros but permisionlessly by everyone around the world.</p>



<p>In one sentence, decentralized finance is the permissionless decentralized version of various traditional financial instruments such as exchanges, lending, borrowing, synthetic assets e.t.c. There has been a lot of innovation in the sector in the past 2 years.</p>

<h2 id="decentralized-exchanges">Decentralized Exchanges</h2>

<p>We have various decentralized exchanges such as:</p>

<ul>
  <li><a href="https://uniswap.org/">Uniswap</a></li>
  <li><a href="https://kyberswap.com/swap">Kyber</a></li>
  <li><a href="https://www.deversifi.com/">Deversifi</a></li>
</ul>

<p>They all operate in a decentralized way and are non-custodial in stark contrast with centralized exchanges such as Binance, Kraken to which you have to first deposit and give custody of your funds.</p>

<h2 id="lendingborrowing-protocols">Lending/Borrowing Protocols</h2>

<p>There are protocols such as <a href="https://app.compound.finance/">Compound</a> and <a href="https://app.aave.com/home">Aave</a> that allow users to lend their assets to earn interest or to borrow assets after staking some collateral. MakerDAO also offers a form of borrowing via <a href="https://oasis.app/borrow">vaults</a> that can mint the DAI stable token after depositing various forms of collateral.</p>

<h2 id="synthetic-assets">Synthetic Assets</h2>

<p>Synthetic asset protocols such as <a href="https://www.synthetix.io/">Synthetix</a> or <a href="https://www.tokensets.com/">Token Sets</a> combine a mix of different assets into a single asset. This way you can get exposure to multiple different assets by just holding a single synthetic asset.</p>



<p>What DeFi does is nothing new. All of this already exist in one form or another in the world of “traditional finance”. What is so amazing and revolutionary about DeFi is that it’s completely decentralized and permissionless. And that it is accessible to everyone regardless of location or background. It’s unlocking a ton of possibilities for people around the world, building a new permisionless financial system in the process.</p>



<p>Just like with everything involving money this sector also attracts short-termed myopic people and projects who are driven by greed.</p>

<p>There is the concept of a yield farmer, someone who provides liquidity or stakes in a protocol in return for interest, fees or some governance token. Yield farming is not bad per se. Everyone who provides liquidity in all the DeFi protocols is essentially yield farming. There is nothing wrong with that.</p>



<p><img src="https://blog.rotki.com/public/post8/defichad.jpeg"></p>



<p>The bad side of farming is the “DeFi chad” or “Defi Degen”. The kind of meme-driven farmer who jumps from protocol to protocol without any thought on contract safety, chasing the biggest yield, dumping their tokens to the new guys and then moving on. A practice that is obviously unsustainable.</p>

<h2 id="yam-finance">YAM finance.</h2>

<p>A very good example of the irresponsible approach to DeFi is YAM. An experiment that did not even manage to last 2 days. It <a href="https://medium.com/@yamfinance/yam-finance-d0ad577250c7">launched</a> in 19:00 UTC, August 11th, 2020 and <a href="https://medium.com/@yamfinance/yam-post-rescue-attempt-update-c9c90c05953f">died</a> 36 hours later.</p>

<h3 id="what-happened">What happened?</h3>

<p>YAM advertised itself as an experiment from the start. It was a mashup of code from various other DeFi projects, completely unaudited and without any safety hatches or deposit limits. For all intents and purposes a completely reckless enterprise. Despite that at its peak it had over $500m locked in it!</p>

<p>For a technical explanation of the bug read <a href="https://medium.com/@yamfinance/yam-post-rescue-attempt-update-c9c90c05953f">their post</a>. In short the bug made it impossible for the YAM holders to reach quorum on anything so essentially the governance part of the protocol was broken and without it the entire protocol could no longer function.</p>

<p>Once people realized that, the market cap of YAM went within minutes from $60m to 0. Everyone left holding YAM they bought took a loss as they can’t sell it, so did uniswap liquidity providers as they took a loss every time someone sold YAM through them.</p>

<h3 id="could-this-have-been-avoided">Could this have been avoided?</h3>

<p>ABSOLUTELY</p>

<p>There were multiple warnings from many prominet people in the crypto sector including myself that this is going to end in tears. The minimum precaution that could have been taken is:</p>

<ul>
  <li>Write contract tests</li>
  <li>Have some sort of security audit of the code</li>
  <li>IF you claim it’s an experiment then treat it as such by:
    <ul>
      <li>Putting deposit limits in the code to protect your users</li>
      <li>Put an escape hatch in the code to protect your users.</li>
    </ul>
  </li>
</ul>

<h3 id="ponzi">Ponzi</h3>

<p>What’s worse is that from the tokenomics of YAM it was obvious that this was a ponzi game. Note the difference between ponzi game and ponzi scheme as explained in <a href="https://jpkoning.blogspot.com/2018/05/ethereum-is-full-of-ponzis-is-that.html">this</a> article.</p>

<p>Every 12 hours the total supply of the token increased but the amount held by each user stayed the same through a process called rebasing. The first farmers were incentivized to pump and shill YAM via social media so they can find victims onto whom to dump their tokens after the rebase. The new holders had the exact same incentives to pump it even more so they can in turn dump their bags onto the poor sods after the second rebase. And so on and so forth.</p>

<p>It was a “fair” and transparent ponzi, but a ponzi nonetheless. And with the amount of due dilligence people do in Crypto I am 100% certain that most of the people who got shilled into it did not realize that and lost money as a result.</p>

<h3 id="shilling-in-twitter">Shilling in Twitter</h3>

<p>What I personally found <strong>absolutely disgusting</strong> was the incessant amount of shilling of YAM in Twitter by many people in the ethereum community whom I actually respect who were also farming it.</p>

<p>It’s inexcusable, reckless and irresponsible. They were shilling a protocol that had not seen any production use yet, had unaudited code, no tests, no deposit limits or anything. They were doing so only to get more people into the Ponzi game to sustain their profits and dump their bags onto them.</p>

<p>I sincerely hope lessons are now learned. If you are shilling an unaudited insecure ponzi you are part of the problem of why this sector is not taken seriously. We can’t have such irresponsible behavior if we are ever going to reach mass adoption.</p>

<h3 id="what-did-it-cost-us">What did it cost us?</h3>

<p><img src="https://blog.rotki.com/public/post8/yamcrash.jpeg"></p>

<p>Some people lost a lot of money</p>

<ul>
  <li>Marketcap dropped from $60m to $0.</li>
  <li>People who bought YAM are left holding a hot potato, got burned and lost everything they invested.</li>
  <li>Uniswap liquidity providers lost money due to providing liquidity for sellers of a dying token.</li>
  <li>Lots of money in gas fees (300+ gwei) for nothing</li>
</ul>

<p>The rest of the non yam farming ethereum users were left with 300 gwei gas prices and could not really use the ethereum blockchain.</p>

<p>And finally and most importantly, outsiders roll their eyes and we lose credibility. Every nocoiner I know that I tried to explain this to just get their view that crypto is only for scams and ponzi schemes reinforced. Can you blame them?</p>



<p>If you are to keep anything from this post as a take-home message let it be this section. DeFi is good and is here to stay. We just all need to be more responsible about it.</p>

<h2 id="responsible-defi-user">Responsible DeFi user</h2>

<p>As a user don’t rush into every new thing that pops up and promises amazing 100%+ returns. Do you due dilligence, demand audit reports, ask people in the community about the history and portfolio of the founders of the protocol and if possible read the code and understand the tokenomics. DYOR. If something sounds too good to be true that’s because it’s probably a scam or a ponzi.</p>

<h2 id="responsible-defi-founder">Responsible DeFi founder</h2>

<p>As a founder/developer for the love of god DO NOT TEST IN PRODUCTION. Be responsible. Users do not heed warnings, or disclaimers. If it’s an experiment and you want to experiment in the mainnet that’s fine. Then put deposit limits and centralized escape hatches for the first X months. The safety of your users is your responsibility. Avoiding that responsbility through the veil of “just an experiment” won’t be accepted.</p>

<h2 id="towards-a-sustainable-defi-ecosystem">Towards a sustainable DeFi ecosystem</h2>

<p>It is only through responsible development and professionalism that this sector can mature. We won’t get any new users with the YOLO yield farming memes. For DeFi to fullfill its goals of a new permisionless financial system it needs to go mainstream. And it will not achieve that through ponzi games and chad memes in Twitter. This will only be achieved when the ecosystem is perceived by normies to be mature enough so that they can also come in and participante in it. Let’s all then do our part to advance the ecosystem through responsible building and sustainable development and build a new financial system for the many and not for the few.</p>



<p>My name is <a href="https://twitter.com/LefterisJP">Lefteris Karapetsas</a>. I am the founder of <a href="https://rotki.com/">Rotki</a>. It is a project that deals with DeFi, among other things, and believes in the dream of a sustainable permissionless new financial system. We are a portfolio tracker and accounting tool that respect our users’ privacy and we are in this game for the long run and not to scam our users for short term gain.</p>

<p>Here is how you can help us:</p>

<ul>
  <li>Try out Rotki’s <a href="https://github.com/rotki/rotki/releases">latest release</a> and use it daily.</li>
  <li><a href="https://rotki.com/products/">Buy</a> a premium subscription to unlock awesome premium features and also support our development.</li>
  <li>Provide us with <a href="https://github.com/rotki/rotki/issues">feedback</a> in the form of bug reports and feature requests.</li>
  <li><a href="https://github.com/rotki/rotki">Star</a> our Github repo and <a href="https://twitter.com/rotkiapp">follow</a> us on Twitter.</li>
  <li>Chat with us and other users of Rotki in <a href="https://discord.gg/aGCxHG7">Discord</a> or in <a href="https://t.me/rotkiportfolio">Telegram</a>.</li>
  <li>Spread the word so that more people get to try and use Rotki and learn how to both manage their finances but also how to protect the privacy of their financial data.</li>
</ul>

</div>

    </div></div>]]>
            </description>
            <link>https://blog.rotki.com/2020/08/13/sustainable-defi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143042</guid>
            <pubDate>Thu, 13 Aug 2020 13:21:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YouTube's persistent flaws make it a hard app to love]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24142790">thread link</a>) | @whalabi
<br/>
August 13, 2020 | https://unlikekinds.com/article/youtubes-persistent-flaws-make-it-a-hard-app-to-love | <a href="https://web.archive.org/web/*/https://unlikekinds.com/article/youtubes-persistent-flaws-make-it-a-hard-app-to-love">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
      <div>
  <h2 id="the-ludicrousness-of-being-forced-to-watch-youtube-in-480p-on-a-4k-tv">The ludicrousness of being forced to watch YouTube in 480p on a 4K TV</h2>

<p>To watch YouTube videos from my phone, which is where I find them, on my TV, which is where I want to watch them, I’ve long since thrown up my hands and given up using the Cast function of the app. Every time I do, the video shows in 480p, even though I have a fiber connection on which YouTube never buffers. If I change the resolution to 1080p, YouTube stubbornly continues to play the video in a resolution that belongs in the 90s. The issue is <a href="https://support.google.com/chromecast/thread/2308994?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/chromecast/thread/2308994?hl=en">widespread</a>, and pre-dates YouTube’s limitations put in place during the pandemic. My TV is an Android TV, made for Google integration with a built-in YouTube app, and my phone is a Pixel phone. Partially chosen with the hope that they’d work well together.</p>

<p>My connection and TV are perfectly capable of playing the video in 1080p, as I learnt when I discovered a clumsy, irritating workaround: adding videos to my Watch Later list on my phone, then opening the YouTube app on my TV, and fumbling through its clumsy interface with a clumsy remote to pick them up again directly on the TV. Plays in 1080p just fine, no buffering.</p>

<figure><img alt="Thousands of YouTube users frustrated with a long-lived bug" width="840" height="593" src="https://i.imgur.com/zD5nKkS.png"><figcaption>Thousands of YouTube users frustrated with a long-lived bug</figcaption></figure>

<h2 id="have-some-captions-with-that">Have some captions with that</h2>

<p>Even when I’ve given in and kept casting blurry videos, a bizarre issue crops up. After watching for a lengthy period of time, maybe an hour or two, YouTube will decide to pop up English captions over an English video while watching on my English account. I’ll shake my head and switch them off; thankfully at least that setting works even if the quality setting doesn’t. Problem is, when the next video in the queue starts playing, the captions switch themselves back on, for every video thereafter. It’s only rectified by disconnecting my phone from my TV, which loses my queued videos, and starting again. This has been happening for many users, and shockingly, <a href="https://support.google.com/youtube/thread/38916902?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/thread/38916902?hl=en">since 2013</a>.</p>

<p>I can only imagine there’s some kind of complicated machine learning going on here - after all YouTube seems to apply fuzzy logic when it decides to turn captions on or off by itself - the captions come on for some non-English videos but not others. It works a lot of the time and seems fairly smart, but not smart enough: they come on only some of the time I watch a K-pop music video, even by the same artist, for example. Every time this happens, I turn off the captions and rewind the video, providing plenty of data, which I’m sure Google is dutifully recording, about my captioning habits, data it could be using to decide whether to override my choices and turn them back on incessantly.</p>

<p>In a pre-ML world, you might code the captions to come on for non-English videos on an English account, perhaps making a different decision based on music videos, and provide a setting, so the user can decide. This would perfectly suit my needs. The behaviour would be predictable, and in my control. This is a problem with the state of ML these days: the decision is completely opaque, inevitably flawed, and non-overridable.</p>

<h2 id="if-you-cant-guess-just-let-me-choose">If you can’t guess just let me choose</h2>

<p>Playing videos directly on my phone is just as frustrating. Much of the time (but not all of the time) I choose something to watch, it’s 480p on my fiber connection which never buffers. Sometimes the video plays in 1080p, but whether it does or not is completely unpredictable. Now everytime I play a video I immediately open the quality settings and change it over to 1080p and rewind, if it isn’t already. It appears to be happening to <a href="https://support.google.com/youtube/thread/14927224?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/thread/14927224?hl=en">plenty</a> of <a href="https://www.reddit.com/r/youtube/comments/ae5utz/auto_quality_setting_keeps_defaulting_to_the/" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://www.reddit.com/r/youtube/comments/ae5utz/auto_quality_setting_keeps_defaulting_to_the/">users</a>.</p>

<p>If this is the result of YouTube attempting to intelligently guess a resolution that won’t buffer, it’s failing miserably. Were they to provide an option to always stream at a minimum 1080p, users’ experience would be much better - they could even choose auto if they want to let YouTube decide for them. Instead YouTube makes a decision for me with an invisible process I have no say in.</p>

<figure><img alt="YouTube’s widely reviled video suggestions" width="775" height="530" src="https://i.imgur.com/WpPKYs4.jpg"><figcaption>YouTube’s widely reviled video suggestions</figcaption></figure>

<p>Users often take a back seat on YouTube. One of the issues in YouTube’s support forums with the <a href="https://support.google.com/youtube/thread/11285006?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/thread/11285006?hl=en">most upvotes</a> concerns the recommended video thumbnails which can overlap the last <a href="https://support.google.com/youtube/answer/6388789?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/answer/6388789?hl=en">5-20 seconds</a> of the video you chose to watch, causing what is often a significant interruption, or in the case of the support thread above, a critical penalty save in a soccer match. Some argue that it’s up to the uploader to add these or not. It’s up to YouTube whether they appear over the last 1 second or 20, or appear under a video rather in massive intrusive thumbnails over the video. I pay for YouTube, but I have no control over these. If it’s just being provided in the user’s interest, why not give us the option to switch them off?</p>

<h2 id="play-music-or-youtube-music">Play Music or YouTube Music</h2>

<p>Google Play Music is shutting down in favor of YouTube Music, both are services I’ve used for years and pay for. Play Music is different in that it stores your own uploaded music, from back when people had such things. As it’s shutting down, these uploads are being transferred across to YouTube Music. It turns out you <a href="https://support.google.com/youtubemusic/thread/45163028?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtubemusic/thread/45163028?hl=en">can’t transfer your uploaded music to a “Brand account”</a> - I’m not a brand, I have an account which doesn’t use my real name because I prefer to remain anonymous amongst, well, YouTubers. This was made possible when Google <a href="https://www.theguardian.com/technology/2014/jul/16/youtube-trolls-google-real-name-commenter-policy" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://www.theguardian.com/technology/2014/jul/16/youtube-trolls-google-real-name-commenter-policy">backtracked</a> after the disastrous ruckus that began when they tried to enforce a real-name policy.</p>

<p>But it also meant that users ended up with 2 YouTube accounts, unwittingly, one with their Google-set real name, and a so-called brand account. A problem arose. In YouTube Music, I have one account with all my music history, likes, favorites, and recommendations, and another with my substantial uploaded music library. Which means I can’t benefit from recommendations based on my history, without rebuilding it all over again with my real name account (which I’d rather not do, in any case, but have no power over.)</p>

<p>In the <a href="https://support.google.com/youtubemusic/thread/45163028?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtubemusic/thread/45163028?hl=en">YouTube support thread</a> announcing this, Hazel from TeamYouTube happily says “If you have any more questions, let us know in the comments below!”, then received a critical comment, and promptly locked the thread.</p>

<h2 id="let-users-have-some-control-in-the-apps-they-use">Let users have some control in the apps they use</h2>

<p>YouTube, like many big tech companies in the ML age, are using algorithms to govern the experience of their billions of users with inner workings that are invisible to their users, frequently work against their interest, and are unable to be overridden. Worse, whether it’s a bug that’s been around since 2013, a smart AI which isn’t so smart, or a crummy user experience decision, users aren’t being heard or their choices respected.</p>

</div>
</div>
    </div>

          

  </div></div>]]>
            </description>
            <link>https://unlikekinds.com/article/youtubes-persistent-flaws-make-it-a-hard-app-to-love</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142790</guid>
            <pubDate>Thu, 13 Aug 2020 12:51:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Significant JavaScript projects from 2006 to 2020]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24142462">thread link</a>) | @michaelrambeau
<br/>
August 13, 2020 | https://bestofjs.org/timeline | <a href="https://web.archive.org/web/*/https://bestofjs.org/timeline">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bestofjs.org/timeline</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142462</guid>
            <pubDate>Thu, 13 Aug 2020 12:04:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things I'm excited for in Neovim 0.5.0: Language Server Protocol]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24142041">thread link</a>) | @numToStr
<br/>
August 13, 2020 | https://nathansmith.io/posts/neovim-lsp | <a href="https://web.archive.org/web/*/https://nathansmith.io/posts/neovim-lsp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>The next major release of <a href="https://neovim.io/">Neovim</a>, 0.5.0, is currently in development and has five <a href="https://neovim.io/roadmap/">promised features</a>:</p>
<blockquote>
<ul>
<li>Lua remote plugin host</li>
<li>Lua user-config: init.lua</li>
<li>Treesitter syntax engine</li>
<li>LSP client for code navigation, refactoring</li>
<li>Extended marks (text properties, decorations, virtual text)</li>
</ul>
</blockquote>
<p>Enticed by offerings of the Neovim roadmap, I decided to install the nightly builds of Neovim and try them for myself. This post will be the first in a series where we focus on the features of Neovim 0.5.0. Today, we’ll look at Neovim’s Language Server Protocol.</p>
<h2 id="what-is-language-server-protocol">What is Language Server Protocol?<a href="#what-is-language-server-protocol" aria-label="what is language server protocol permalink"></a></h2>
<p>The <a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a>, or LSP, is a JSON RPC protocol introduced in 2016 by Microsoft that defines how an editor should talk to a language server. What is a language server? It’s a small program that runs locally on your computer that can provide information about the code you’re writing. The idea is that you tell the LSP where your project is, it scans all your files, and then has an understanding about your project. It can then provide go-to-definition, type info, compiler errors, completion suggestions, and more back to your editor. As the name implies, each language server generally supports only one language. There’s a <a href="https://langserver.org/">community maintained list</a> of major LSP implementations.</p>
<p>That’s cool, you say, but my editor already supports these features. Why should I start using a language server?</p>
<p>That’s a good question. If your editor already supports typo info, auto-completion, and everything else, you likely don’t need a language server. In fact, the LSP might slow you down – it’s likely a built-in editor feature would be faster than your editor making an RPC request to a server running on your computer.</p>
<p>However, the main advantage of the LSP is that it brings together developers who use different editors. The LSP is editor agnostic – if your editor speaks the protocol, it can talk to the server running. That is, instead of developers having to create an Emacs JavaScript plugin, and a Vim JavaScript plugin, and a VS Code JavaScript plugin, they need only create a single JavaScript language server and language server plugins for each editor.</p>
<p><a href="https://langserver.org/">Langserver.org</a> calls this problem “the matrix”, and it’s easy to see why. If we have <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> languages and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> editors, instead of making <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">n \times m</annotation></semantics></math></span></span> integrations we only have to create <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> language servers plus <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> editor LSP plugins.</p>
<figure>
    <span>
      <span></span>
  <img alt="The Matrix Problem. The Language Server Protocol ideally means we have to write less tools and can share tools across editors and environments more easily." title="The Matrix Problem. The Language Server Protocol ideally means we have to write less tools and can share tools across editors and environments more easily." src="https://d33wubrfki0l68.cloudfront.net/12005bad22eafa1b9bdcf4d1d17015b714bded83/b3443/static/96b7982529b79bd6a4f0b7a177abe150/c5bb3/matrix-problem.png" srcset="https://d33wubrfki0l68.cloudfront.net/f19838a5a467210f204603091fc65df562fb57e3/169f6/static/96b7982529b79bd6a4f0b7a177abe150/04472/matrix-problem.png 170w, https://d33wubrfki0l68.cloudfront.net/3424f4fbddec6d16f90e57176654b074aa5cbe2e/17ef2/static/96b7982529b79bd6a4f0b7a177abe150/9f933/matrix-problem.png 340w, https://d33wubrfki0l68.cloudfront.net/12005bad22eafa1b9bdcf4d1d17015b714bded83/b3443/static/96b7982529b79bd6a4f0b7a177abe150/c5bb3/matrix-problem.png 680w, https://d33wubrfki0l68.cloudfront.net/673668b2c637dfeded44b6dc09b1106f9110a2d6/f327d/static/96b7982529b79bd6a4f0b7a177abe150/b12f7/matrix-problem.png 1020w, https://d33wubrfki0l68.cloudfront.net/f2a86b00c660bf46bdd7561e959c2f3e33179bbb/fe4cf/static/96b7982529b79bd6a4f0b7a177abe150/b5a09/matrix-problem.png 1360w, https://d33wubrfki0l68.cloudfront.net/15df038d58e7fa53d1fcbcf5a31b8c4c7d70d78c/91c2c/static/96b7982529b79bd6a4f0b7a177abe150/f2f8c/matrix-problem.png 1490w" sizes="(max-width: 680px) 100vw, 680px" loading="lazy">
    </span>
    <figcaption>The Matrix Problem. The Language Server Protocol ideally means we have to write less tools and can share tools across editors and environments more easily.</figcaption>
  </figure>
<p>Okay, you tell me, so now you’ve just proved <a href="https://en.wikipedia.org/wiki/Conway%27s_law">Conway’s law</a> also applies to open source. But you didn’t answer my original question: why should I use a language server?</p>
<p>Since the community of all JavaScript developers is a superset of all JavaScript Vim developers, this means that you should see more developers working on a JavaScript language server as opposed to a JavaScript Vim plugin. This should ideally mean a generally better language server.</p>
<p>Additionally, since the community of all Vim developers is also better than all JavaScript Vim developers, this should mean better LSP integration support. Vim users can unite and benefit around building a common language server, even if the day-to-day languages they use are different.</p>
<p>While this may not necessarily be true for all editor plugins, it certainly is for Vim. Vim completion can be done for already existing keywords, dictionary words, ctags results, or omnicomplete. Of these, ctags and omnicomplete are the most IDE-like. In my experience, while ctags is pretty good, it can often give inaccurate results if the same name is used in different contexts across a codebase. And omnicomplete is often left neglected: JavaScript omnicomplete hasn’t been <a href="https://github.com/vim/vim/blob/5be4ceecea5520265066eac972460ebb1cdf05e7/runtime/autoload/javascriptcomplete.vim">updated since 2017</a>, a sign of the matrix problem.</p>
<h2 id="upgrading-to-neovim-nightly">Upgrading to Neovim Nightly<a href="#upgrading-to-neovim-nightly" aria-label="upgrading to neovim nightly permalink"></a></h2>
<p>Okay, so I’ve convinced you to try out an LSP. How does it work in Neovim?</p>
<p>Neovim has <a href="https://github.com/neovim/neovim/wiki/Installing-Neovim">great install instructions</a> for most systems (macOS, Windows, popular Linux distros). I’m on macOS, so I ran:</p>
<div data-language="text"><pre><code>brew install --HEAD neovim</code></pre></div>
<p>From there, you can confirm that the installed version of Neovim has LSP support with <code>:h lsp</code>.</p>
<h2 id="a-note-on-lua">A note on Lua<a href="#a-note-on-lua" aria-label="a note on lua permalink"></a></h2>
<p>Recall the first two features of 0.5.0:</p>
<blockquote>
<ul>
<li>Lua remote plugin host</li>
<li>Lua user-config: init.lua</li>
</ul>
</blockquote>
<p>Vimscript, or VimL, is the de facto configuration of Vim. However, it’s also <a href="https://www.reddit.com/r/vim/comments/1bf672/why_does_viml_suck/">not that great of a language</a>: there are lots of odd quirks and performance issues that come with it. As a result, the Neovim core developers decided to add support for Lua in Neovim. Justin M. Keyes goes over the rationale for this decision in a <a href="https://youtu.be/Bt-vmPC_-Ho">great VimConf presentation</a>. The tl;dr is that Lua is a fast language that already exists and is simpler to learn than Vimscript.</p>
<p>Why does this matter? We were going to go over the LSP today, not Lua, right?</p>
<p>Yes and no. Just as Vimscript is the language for which Vim apis are exposed, Lua is becoming the preferred language for which Neovim apis are being exposed. The LSP api is in Lua, meaning we’ll have to write a little bit of Lua to set it up.</p>
<p>If you haven’t written any Lua, don’t fear! Ample code examples will be provided for your copy/pasting pleasure. Lua is a fairly easy language to read if you know any programming language already. If you’re interested in more Lua, <a href="https://learnxinyminutes.com/docs/lua/">Learn X in Y minutes</a> is a great place to start.</p>
<p>However, most Vimmers don’t currently have any Lua configuration files lying around, so we need to cover the basics of going from an <code>init.vim</code> Vimscript file into triggering Lua code. There are a couple ways to do this.</p>
<h3 id="lua-in-your-vim">Lua in your vim<a href="#lua-in-your-vim" aria-label="lua in your vim permalink"></a></h3>
<p>You can put Lua code directly in vimscript files, like so:</p>
<div data-language="vim"><pre><code>lua <span>&lt;</span><span>&lt;</span> EOF
<span>print</span><span>(</span><span>"hello world"</span><span>)</span>
EOF</code></pre></div>
<p>This is great for small to medium snippets of Lua code.</p>
<h3 id="lua-in-a-file">Lua in a file<a href="#lua-in-a-file" aria-label="lua in a file permalink"></a></h3>
<p>You can also tell Neovim to source lua files, given that that fit a directory structure. In Vimscript:</p>

<p>This will look for the file: <code>nvim/lua/lsp/init.lua</code>. This is great for larger, self-contained chunks of Lua code. I prefer this approach and use it in <a href="https://github.com/nathunsmitty/.config">my dotfiles</a>, since it gives me access to Lua syntax highlighting, linters, etc. while editing.</p>
<h2 id="configuring-support-for-servers">Configuring Support for Servers<a href="#configuring-support-for-servers" aria-label="configuring support for servers permalink"></a></h2>
<p>Neovim provides the LSP client built-in, but it needs to which language servers to run and where on your machine they’re located. There’s a <a href="https://neovim.io/doc/user/lsp.html#lsp-core">Lua api</a> provided that allows you to do this; the following will trigger JavaScript LSP:</p>
<div data-language="lua"><pre><code><span>local</span> root_dir <span>=</span> <span>buffer_find_root_dir</span><span>(</span>bufnr<span>,</span> <span>function</span><span>(</span>dir<span>)</span>
  <span>return</span> <span>is_dir</span><span>(</span><span>path_join</span><span>(</span>dir<span>,</span> <span>'node_modules'</span><span>)</span><span>)</span>
<span>end</span><span>)</span>

<span>local</span> bufnr <span>=</span> vim<span>.</span>api<span>.</span><span>nvim_get_current_buf</span><span>(</span><span>)</span>
<span>local</span> javascript_lsp_config <span>=</span> <span>{</span>
  name <span>=</span> <span>"javascript"</span><span>;</span>
  cmd <span>=</span> <span>{</span> <span>path_join</span><span>(</span>os<span>.</span><span>getenv</span><span>(</span><span>"JAVASCRIPT_LANGUAGE_SERVER_DIRECTORY"</span><span>)</span><span>,</span> <span>"lib"</span><span>,</span> <span>"language-server-stdio.js"</span><span>)</span> <span>}</span><span>;</span>
<span>}</span>

<span>local</span> new_config <span>=</span> vim<span>.</span><span>tbl_extend</span><span>(</span><span>"error"</span><span>,</span> javascript_lsp_config<span>,</span> <span>{</span>
  root_dir <span>=</span> root_dir<span>;</span>
<span>}</span><span>)</span>
client_id <span>=</span> vim<span>.</span>lsp<span>.</span><span>start_client</span><span>(</span>new_config<span>)</span>
vim<span>.</span>lsp<span>.</span><span>buf_attach_client</span><span>(</span>bufnr<span>,</span> client_id<span>)</span></code></pre></div>
<p>(This is adapted from <a href="https://neovim.io/doc/user/lsp.html#lsp-extension-example">an example</a> in the LSP manual.)</p>
<p>However, this is a lot of configuration. Is there a better solution?</p>
<h3 id="nvim-lsp-common-server-configuration">nvim-lsp: Common Server Configuration<a href="#nvim-lsp-common-server-configuration" aria-label="nvim lsp common server configuration permalink"></a></h3>
<p>To give a higher level of abstraction for end users who just want to start using a LSP, Neovim provides an official plugin: <a href="https://github.com/neovim/nvim-lsp">nvim-lsp</a>. This is a collection of common LSPs with integrations ready to go. Let’s install it!</p>
<div data-language="vim"><pre><code>
Plug <span>'neovim/nvim-lsp'</span>

<span>call</span> minpac#<span>add</span><span>(</span><span>'neovim/nvim-lsp'</span><span>,</span> <span>{</span><span>'type'</span><span>:</span> <span>'opt'</span><span>}</span><span>)</span>
packadd nvim<span>-</span><span>lsp</span></code></pre></div>
<p>Note that if you’re using a Vim 8’s native package manager (or a package manager that leverages the native package manager, like <a href="https://github.com/k-takata/minpac">minpac</a>), then you need to add the line <code>packadd nvim-lsp</code>. This is because Neovim <a href="https://github.com/neovim/neovim/issues/12670">currently does not source Lua plugins before your <code>init.vim</code> file</a>, meaning that your LSP config will execute before nvim-lsp is loaded, giving errors. With an older <a href="https://neovim.io/doc/user/options.html#'runtimepath'">runtimepath</a>-based plugin manager like <a href="https://github.com/junegunn/vim-plug">vim-plug</a>, this is not an issue.</p>
<p>Now that we’ve downloaded nvim-lsp, we can configure a language server. To set up the <a href="https://github.com/theia-ide/typescript-language-server">TypeScript language server</a>, we simply need to add:</p>
<div data-language="vim"><pre><code>require<span>'nvim_lsp'</span><span>.</span>tsserver<span>.</span>setup<span>{</span><span>}</span></code></pre></div>
<p>There are also <a href="https://github.com/neovim/nvim-lsp#tsserver">configuration options</a> for which filetypes to run it on, how to detect your project’s root directory, etc.</p>
<p>While we’re configuring stuff, let’s add some nice, vim-like shortcuts for LSP features:</p>
<div data-language="vim"><pre><code>nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> <span>gd</span> <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>definition</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> gh     <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>hover</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> gD    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>implementation</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> <span>&lt;</span><span>c</span><span>-</span><span>k</span><span>&gt;</span> <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>signature_help</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> 1gD   <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>type_definition</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> <span>gr</span>    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>references</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> g0    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>document_symbol</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> gW    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>workspace_symbol</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span></code></pre></div>
<p>Note that these mappings override some Vim defaults, so in order to ensure they only work on</p>
<p>Awesome! However, unless you have the TypeScript language server already installed, you still won’t notice any LSP features. This is because you need to install the language server. The bad news is that each language server has its own installation instructions. The good news is the nvim-lsp takes care of it by providing a <code>LspInstall</code> command. All we have to do is run:</p>

<p>and we’re in business!</p>
<h3 id="even-more-abstractions">Even more abstractions<a href="#even-more-abstractions" aria-label="even more abstractions permalink"></a></h3>
<p>There are a few other optional plugins for Neovim that will improve your LSP quality-of-life. These are by no means necessary, you could implement them with a bit of Vimscript and Lua, but they do provide some more polish to the experience.</p>
<h4 id="completion-nvim">completion-nvim<a href="#completion-nvim" aria-label="completion nvim permalink"></a></h4>
<p><a href="https://github.com/nvim-lua/completion-nvim">completion-nvim</a>, as the name implies, is an autocompletion plugin. It’s similar to something like <a href="https://github.com/ycm-core/YouCompleteMe">YouCompleteMe</a> or <a href="https://github.com/Shougo/deoplete.nvim">Deoplete</a> in that it gives auto popup and other improvements on top of Neovim’s LSP api, as well as some other sources.</p>
<div data-language="vim"><pre><code><span>call</span> minpac#<span>add</span><span>(</span><span>'nvim-lua/completion-nvim'</span><span>,</span> <span>{</span><span>'type'</span><span>:</span> <span>'opt'</span><span>}</span><span>)</span>
packadd completion<span>-</span>nvim</code></pre></div>
<div data-language="lua"><pre><code><span>local</span> on_attach <span>=</span> <span>function</span><span>(</span><span>)</span>
  require<span>'completion'</span><span>.</span><span>on_attach</span><span>(</span><span>)</span>
  require<span>'diagnostic'</span><span>.</span><span>on_attach</span><span>(</span><span>)</span>
<span>end</span>
require<span>'nvim_lsp'</span><span>.</span>pyls<span>.</span><span>setup</span><span>{</span>on_attach<span>=</span>on_attach_vim<span>}</span></code></pre></div>
<h4 id="lsp-statusnvim-statusline-support">lsp-status.nvim: Statusline Support<a href="#lsp-statusnvim-statusline-support" aria-label="lsp statusnvim statusline support permalink"></a></h4>
<p><a href="https://github.com/nvim-lua/lsp-status.nvim">lsp-status.nvim</a> is a Lua plugin that allows you to display information from …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nathansmith.io/posts/neovim-lsp">https://nathansmith.io/posts/neovim-lsp</a></em></p>]]>
            </description>
            <link>https://nathansmith.io/posts/neovim-lsp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142041</guid>
            <pubDate>Thu, 13 Aug 2020 11:07:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Business logic is the weakest link in Low-Code security]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141927">thread link</a>) | @xiwenc
<br/>
August 13, 2020 | https://cinaq.com/post/2020/08/09/your-business-logic-is-the-weakest-link-in-low-code-security/ | <a href="https://web.archive.org/web/*/https://cinaq.com/post/2020/08/09/your-business-logic-is-the-weakest-link-in-low-code-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Over the past 5 years <a href="https://trends.google.com/trends/explore?date=2015-01-01%202020-08-02&amp;q=%2Fg%2F11c6cx4nrr">interest in low-code increased 100 folds</a> according to Google Trends:
<img src="https://cinaq.com/media/low-code-trends.png" alt="Low-code development trends">
This correlates with human psychology eager to optimise for efficiency in everything and building software solutions is no exception. As programming is becoming easier and more accessible, in the future, anyone should be able solve their own information automation challenges. Low-code is a relatively new movement that tries to enable those citizen developers with the right tooling lowering the barrier to build applications without writing traditional code. Because most of my professional experience with low-code is around <a href="https://www.mendix.com/">Mendix</a>, I will use it as reference through out this article.</p>

<p>First computer programs were written in machine code by few experts in the early days. This programming ability felt like a super power to many. Just like the Industrial age boosted the human civilisation, the Information Technology age we are currently in is helping the human race reach new heights. Programming languages are invented or improved to enable more efficient or better programming paradigms. This trend in <a href="https://en.wikipedia.org/wiki/History_of_programming_languages">programming languages timeline</a> is recently leading towards visual programming. In the industry this idea is marked as <a href="https://en.wikipedia.org/wiki/Low-code_development_platform">low-code platforms</a>. To me this is currently the highest programming level because of its high productivity characteristics. Low-code is in a nutshell an unification of deployment and composable building blocks nicely packed to play well together reducing the feedback loop at development and runtime.</p>

<p>The cost of higher abstraction which often correlates with higher productivity is <a href="https://en.wikipedia.org/wiki/High-level_programming_language#Abstraction_penalty">Abstraction penalty</a>. As we move up in the pyramid depicted below, we accomplish more with fewer efforts. That little effort however translates to more execute computing instructions. Due to this fact we loose optimisations and also unaware of the extra assumptions made in between. This problem increases more as applications grow larger and depend on libraries. No matter how well documented the libraries are, they are again abstractions of the actual implementation which might be inaccurate or the user of such library might not know or understand the full extends of the functionalities being leveraged on.</p>
<p><img src="https://cinaq.com/media/low-code-productivity-pyramid.png" alt="Higher programming languages result in higher computational instructions count"></p>

<p>A critical aspect of abstraction penalty is the unawareness of implied behaviours. Citizen developers (Low-code developers) leverage a lot from low-code platform itself; often with insufficient experience and knowledge of the underlaying runtime environment. This is a natural cause because these platforms were designed and promoted  for easy adoption. In the case of Mendix a typical security pitfall is negligence of <a href="https://docs.mendix.com/refguide/access-rules">entity access on attributes level</a>. Developers often focus on getting the program to work, in this particular case, a developer would grant access to all users. No matter the seniority, people make mistakes and forget access rule must be refined. In low-code platform like this, it’s very easy to make mistakes and leave open major security holes.</p>
<p>Platforms like Mendix already has <a href="https://www.mendix.com/evaluation-guide/enterprise-capabilities/security">security covered very well</a>. However with a strong platform, you can still build vulnerable applications because the platform does not know or understand your data risk levels. Therefore the weakest link is your business logic on a low-code platform.</p>
<p><img src="https://cinaq.com/media/low-code-mendix-security.png" alt="Business logic is weakest link with Mendix"></p>
<p>A typical example is: developer gives all access to credit card number attribute in the application model. The developer makes a remark to fine tune the access rules later but forgets to do so. Due to time pressure, testers mostly focussed on the happy use cases which did not reveal the CC information leak.</p>
<p>Therefore it’s crucial to have tooling to help detect these mistakes before they hit production. A tool that could reveal more that meets the eye for developers and testers alike. In Mendix, this would mean bypass the View (from <a href="https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller">Model View Controller</a>) showing all accessible data and function calls for a given user. There are few challenges here:</p>
<ul>
<li>How to extensively and automatically collect these data</li>
<li>How to make sense of the collected data to identify security weaknesses</li>
<li>Finally a repeatable and preferably incremental method to assess the security risk coverage</li>
</ul>
<p>Often pentest consultants are called in to assess the security risks of low-code applications. However this process is very labor intensive and error prone. As pointed out, higher generation languages like low-code has a bigger attack vector (related to number of computational instructions together with rapid feature building) requires extensive manual work.</p>

<p>In this article we learned low-code is an upcoming trend and it helps companies innovate faster by increasing the productivity of its developers. However, with the higher abstraction levels, it’s also easier to make security mistakes leaving the application vulnerable to attacks. As the citizen developers group grows, we need tooling in place to help identity security risks with the same low threshold as it requires to develop an app on a low-code platform.</p>

			</div></div>]]>
            </description>
            <link>https://cinaq.com/post/2020/08/09/your-business-logic-is-the-weakest-link-in-low-code-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141927</guid>
            <pubDate>Thu, 13 Aug 2020 10:50:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Danger of Having a B-Team]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141704">thread link</a>) | @svmanager
<br/>
August 13, 2020 | https://staysaasy.com/management/2020/08/11/Team-Topology.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/08/11/Team-Topology.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Make the seniority, talent, and quality-of-mission of your organization’s teams as consistent as possible. The pretstige of team missions and their capability should all be comparable. There should be no dramatic differences between the caliber of your teams.</p>

<h2 id="the-problem">The Problem</h2>

<p>It’s not uncommon for a leader to bucket what needs to get done as a set of hard, medium, and easy missions. The next step they’ll take is to assemble teams of respectively different talent levels and seniority to handle those challenges of different prestige levels. The outcome are teams that vary in their ability and the importance (real or perceived) of their mission. You’ve just turned your department into a caste system.</p>

<p>This creates lots of challenges:</p>
<ul>
  <li>People who are on low-caliber teams know it. This causes morale and retention issues.</li>
  <li>In some cases, people end up selling the company to recruits based off of what the prestigious teams are doing, only to place people into other teams. This causes morale and retention issues.</li>
  <li>The weak-mission teams will often not have a growth path to the highest levels. This essentially means it’s a transient team unless you hire people to stagnate. A great litmus test is: can every team support promotions to the highest level?</li>
  <li>You end up constantly having to field questions around internal transfers to the prestigious teams. Good managers tell the truth when people aren’t ready for the other team or when the team isn’t ready for them. Bad managers give little glimmers of hope that don’t reflect reality and lead to a long tail of frustration.</li>
  <li>Dysfunctional organizations will actually lower the hiring and promotion bars for lower caliber teams for political and morale reasons. This can lead to very, very bad outcomes like reducing the integrity of compensation bands or causing internal strife at the mis-match across teams.</li>
  <li>This set of variables is also very dangerous because internal processes of an organization are based on the people they’re serving. Different cohorts of people need different enablement, onboarding, rules, and rewards. Having major differences amongst teams means it’s harder to have one overarching culture and set of organizational mechanics.</li>
</ul>

<p>How do you fix this? Let’s go back and revisit some assumptions.</p>

<h2 id="assumption-1-we-have-hard-medium-and-easy-missions">Assumption 1: We Have Hard, Medium and Easy Missions</h2>

<p>People get this wrong all the time. When looking at the missions of a team, it’s not uncommon for a leader to have standard biases or an ego that leads to total miscalculations of the difficulty of certain missions.</p>

<p>An example is in software engineering, where leaders might view their team’s goals as fancy backend “hard stuff’’ and simple front-end “easy stuff”. That’s obviously bullshit. Think of all of the terrible UIs you encounter on a day to day basis. If frontend engineering was easy UI would be a solved problem.</p>

<p>Another example is when a leader or a team aren’t executing well on a part of their responsibilities and they end up saying that it just needs to be handled by some other team because it’s easy but distracting. In reality, if it’s easy they’d be doing a good job at it. This kind of thinking can lead teams to push away what is actually more important work in lieu of more interesting (or greenfield, or easy) work.</p>

<p>People often make bad calls on what’s difficult and what’s easy and then make things worse with the second, equally damaging assumption.</p>

<h2 id="assumption-2-easy-missions-should-be-done-by-lower-caliber-teams">Assumption 2: Easy Missions Should Be Done By Lower-Caliber Teams</h2>

<p>Leaders will then compound the problem by staffing teams to get the “easy missions” done with less senior or skillful talent. So they assume a problem is easy, understaff it, and then as things inevitably go wrong they end up blaming either the team, the mission, or anything else but the poor decisions that lead to a self-fulfilling prophecy.</p>

<h2 id="a-better-path">A Better Path</h2>

<p>To solve this problem, take a hard look at the topology of work you’re trying to get done:</p>
<ul>
  <li>If a <em>small</em> volume of work is much simpler than other tasks, you should add it into the responsibilities of your existing teams.</li>
  <li>If a <em>large</em> volume work is much simpler than other work- meaning it’d meaningfully distract your regular teams - you should either contract it out or you build an different organization to handle it.</li>
  <li>Sometimes you’ll have a team who has lower perceived prestigue because it doesn’t contain as many buzzwords or trendy technologies as other teams. Absent active efforts, that team will have a harder time hiring and retaining. To counteract this, you should make sure you’re overloading that team with talent, so that you make up for the team’s perceived mission prestigue with personel prestige.</li>
  <li>In all cases, expectation setting and integrity in decision making is critical. Don’t hire people into roles with the false hope of transferring to other teams if it’s not possible. Don’t transfer people to other teams if they’re not ready.</li>
</ul>

<h2 id="examples">Examples</h2>
<ul>
  <li>Your hot-stuff AI/ML startup has 4 high-powered product teams, but you keep having this pesky problem of a trickle of internal requests from the client-facing teams. You decide to create a team to just handle those requests. You figure it’s not that big of a problem and don’t want to distract your teams, so you hire a junior team to just handle that. You’ve just made a huge mistake. That team will be unhappy and have retention problems forever. You should have either contracted that work or found a process for your other teams to get it done.</li>
  <li>Your hot-stuff AI/ML startup has built out a customer portal that is getting a ton of traction. The work has meaningful challenges and growth opportunities, but it’s very different than your core team’s responsibilities. The people you hire, the promotion paths, the culture needed to execute well, and the evaluation criteria are existentially inconsistent with your other teams. You work with senior management to build out an entirely new organization to work on the portal. Great job, you’ve done the right thing. This was a lot of work that warranted a focused division to manage the mission.</li>
</ul>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/08/11/Team-Topology.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141704</guid>
            <pubDate>Thu, 13 Aug 2020 10:10:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US Core Inflation Jumps by Most Since 1991]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24141694">thread link</a>) | @jules-jules
<br/>
August 13, 2020 | https://confoundedinterest.net/2020/08/12/us-core-inflation-jumps-by-most-since-1991-while-rent-inflation-fell-to-lowest-rate-since-2015/ | <a href="https://web.archive.org/web/*/https://confoundedinterest.net/2020/08/12/us-core-inflation-jumps-by-most-since-1991-while-rent-inflation-fell-to-lowest-rate-since-2015/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-12687">
			<!-- .entry-header -->		<div>
			<p>
							<span>
					<a href="https://confoundedinterest.net/category/bubble/" rel="category tag">#bubble</a>, <a href="https://confoundedinterest.net/category/banking/" rel="category tag">Banking</a>, <a href="https://confoundedinterest.net/category/bernanke/" rel="category tag">Bernanke</a>, <a href="https://confoundedinterest.net/category/cmbs/" rel="category tag">CMBS</a>, <a href="https://confoundedinterest.net/category/cre/" rel="category tag">CRE</a>, <a href="https://confoundedinterest.net/category/ecb/" rel="category tag">ECB</a>, <a href="https://confoundedinterest.net/category/economy/" rel="category tag">Economy</a>, <a href="https://confoundedinterest.net/category/fannie-mae/" rel="category tag">fannie mae</a>, <a href="https://confoundedinterest.net/category/fed/" rel="category tag">Fed</a>, <a href="https://confoundedinterest.net/category/freddie-mac/" rel="category tag">Freddie Mac</a>, <a href="https://confoundedinterest.net/category/gdp/" rel="category tag">GDP</a>, <a href="https://confoundedinterest.net/category/housing/" rel="category tag">Housing</a>, <a href="https://confoundedinterest.net/category/inflation/" rel="category tag">Inflation</a>, <a href="https://confoundedinterest.net/category/mortgage/" rel="category tag">Mortgage</a>, <a href="https://confoundedinterest.net/category/pension/" rel="category tag">Pension</a>, <a href="https://confoundedinterest.net/category/powell/" rel="category tag">Powell</a>, <a href="https://confoundedinterest.net/category/reits/" rel="category tag">REITs</a>, <a href="https://confoundedinterest.net/category/treasuries/" rel="category tag">Treasuries</a>, <a href="https://confoundedinterest.net/category/treasury/" rel="category tag">Treasury</a>, <a href="https://confoundedinterest.net/category/uncategorized/" rel="category tag">Uncategorized</a>, <a href="https://confoundedinterest.net/category/volatility/" rel="category tag">Volatility</a>, <a href="https://confoundedinterest.net/category/yellen/" rel="category tag">Yellen</a>				</span></p><!-- .cat-links -->
			
			
			<p><span>
				<time datetime="2020-08-12T12:46:59-04:00">August 12, 2020</time><time datetime="2020-08-12T14:36:15-04:00">August 12, 2020</time>			</span>

			<span>1 Minute</span>		</p></div><!-- .entry-meta -->
	
	<div>
		
<p>Well, The Federal Reserve finally got its wish: INFLATION!</p>



<p><em>U.S. consumer prices&nbsp;rose&nbsp;in July by more than expected on a bounce in auto and apparel costs. <strong>The so-called core figure, which excludes volatile food and fuel costs, climbed 0.6% from the prior month, the biggest surge in almost three decades</strong>, according to a Labor Department report Wednesday. The headline figure also increased 0.6%, following the same gain in June. The trend reflects a rebound in demand for goods and services from the depths of the pandemic-induced lockdowns earlier this year</em>.</p>



<figure><img data-attachment-id="12691" data-permalink="https://confoundedinterest.net/coreinf/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png" data-orig-size="736,530" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="coreinf" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>



<p>But on a YoY basis, core inflation rose only 1.6%.</p>



<figure><img data-attachment-id="12694" data-permalink="https://confoundedinterest.net/the-core-1/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png" data-orig-size="736,530" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="the-core-1" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>







<figure><img data-attachment-id="12697" data-permalink="https://confoundedinterest.net/indl-1/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png" data-orig-size="736,530" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="indl-1" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>



<p>But rent inflation fell to 2.8% YoY, the lowest since 2015.</p>



<figure><img data-attachment-id="12698" data-permalink="https://confoundedinterest.net/rentcpi-2/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png" data-orig-size="736,529" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rentcpi" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>



<figure><img data-attachment-id="12709" data-permalink="https://confoundedinterest.net/ogd-1/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg" data-orig-size="329,750" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ogd-1" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=132" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=329" src="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=329" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg 329w, https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=66 66w, https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=132 132w" sizes="(max-width: 329px) 100vw, 329px"></figure>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	<div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-08-12T12:46:59-04:00">August 12, 2020</time><time datetime="2020-08-12T14:36:15-04:00">August 12, 2020</time>		</p><!-- .site-posted-on -->
	</div>
</article></div>]]>
            </description>
            <link>https://confoundedinterest.net/2020/08/12/us-core-inflation-jumps-by-most-since-1991-while-rent-inflation-fell-to-lowest-rate-since-2015/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141694</guid>
            <pubDate>Thu, 13 Aug 2020 10:08:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Limiting Asynchronous Operations Concurrency in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141535">thread link</a>) | @ziir_hn
<br/>
August 13, 2020 | https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/ | <a href="https://web.archive.org/web/*/https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>Today's post is about a little trick I have learned about 2years ago, and that I have since used numerous times in short Node.js scripts I had to write.<br>
It really isn't much, but I guess it may be helpful to others, and probably is an alright first JavaScript post on this blog.</p>
<blockquote>
<p>Say one has a list of things, and for every of these things, one needs to perform an asynchronous operation that returns a Promise, and be notified when all operations have been performed.<br>
How does one limit the number of asynchronous operations being performed conccurently? Without 3rd party dependencies and just a few lines of code?</p>
</blockquote>
<p>Are you seeing the problem yet? Let's build some context:</p>
<h3 id="we-have-a-list-of-99-things%2C-say-resource-identifiers">We have a list of 99 things, say resource identifiers <a href="#we-have-a-list-of-99-things%2C-say-resource-identifiers">#</a></h3>
<pre><code><span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span><br><span>&gt;</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>...</span> <span>99</span><span>]</span></code></pre>
<h3 id="for-each-of-these-things%2C-we-need-to-perform-an-asynchronous-operation">For each of these things, we need to perform an asynchronous operation <a href="#for-each-of-these-things%2C-we-need-to-perform-an-asynchronous-operation">#</a></h3>
<p>First, let's define the function that will perform said asynchronous operation:</p>
<pre><code><br><br><span>function</span> <span>performAsyncOperation</span><span>(</span><span>id</span><span>)</span> <span>{</span><br>  <span>return</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve</span><span>)</span> <span>=&gt;</span> <span>{</span><br>    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>      console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Performed operation for resource </span><span><span>${</span>id<span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span><br>      <span>resolve</span><span>(</span><span>)</span><span>;</span><br>    <span>}</span><span>,</span> <span>300</span><span>)</span><span>;</span><br>  <span>}</span><span>)</span><span>;</span><br><span>}</span></code></pre>
<p>Now, we know that we need to call this function of every single thing out of our list of 99 things, every resource id we have in <code>ids</code>.<br>
Our first approach, would be to naively use <a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array/map">Array.prototype.map</a> and <a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Promise/all">Promise.all</a> and call it a day. But let's have a closer look to this innocent line of code and its implications:</p>
<pre><code><span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span><br>console<span>.</span><span>log</span><span>(</span><span>'All operations performed, moving on to something else now.'</span><span>)</span><span>;</span></code></pre>
<p><em>Note: we might arguably use <a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Promise/allSettled">Promise.allSettled</a> in a real world scenario, but let's assume our asynchronous operations cannot fail.</em></p>
<p>Which we would give us the following complete script:</p>
<pre><code><span>function</span> <span>performAsyncOperation</span><span>(</span><span>id</span><span>)</span> <span>{</span><br>  <span>return</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve</span><span>)</span> <span>=&gt;</span> <span>{</span><br>    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>    console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Performed operation for resource </span><span><span>${</span>id<span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span><br>    <span>resolve</span><span>(</span><span>)</span><span>;</span><br>    <span>}</span><span>,</span> <span>300</span><span>)</span><span>;</span><br>  <span>}</span><span>)</span><span>;</span><br><span>}</span><p><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span><br>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span><br>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></p><p>  <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span><br>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span><br>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span><br><span>}</span></p><p><span>run</span><span>(</span><span>)</span><span>;</span></p></code></pre>
<p>Now, let's run it:</p>
<pre><code>$ node async-operations-promise-all.js
</code></pre>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
All operations performed in 338ms, moving on to something else now.
</code></pre>
<p>As we can see, ~all the asynchronous operations were performed <strong>concurrently</strong>, and sometimes, that's perfectly fine and exactly what we want.</p>
<p><em>Note: <code>Promise.all</code> only waits for all the <code>Promise</code>s to be resolved. The actual asynchronous operation is triggered by the function call from <code>Array.prototype.map</code>, creating a new <code>Promise</code> on each call.</em></p>
<h3 id="the-problem-of-performing-operations-concurrently">The problem of performing operations concurrently <a href="#the-problem-of-performing-operations-concurrently">#</a></h3>
<p>Now, let's assume that our <code>performAsyncOperation</code> really performs an HTTP request, an API Call, a database query, or really anything else that would either suffer or punish us for the load we push on to it. It might be a rate-limited API, or a fragile host.</p>
<p><em>Note: in the actual case of an HTTP request, or database query, the Web/Node.js/etc... API being used will already probably limit concurrency, of which value may or may not configurable, but let's assume that we cannot or do not want to change such settings.</em></p>
<p>In such cases, we simply cannot allow our script to perform all these operations concurrently, as it risks getting our API key revoked, our IP blocked, or the target host/database responding unreliably, etc... Thus we will be searching for a way to limit this concurrency to avoid such scenario.</p>
<p><em>Note: depending on the actual work performed by the asynchronous operation, performing many of these concurrently may also make the process running it consuming significant amount of CPU and/or memory resources on the machine it runs.</em></p>
<h3 id="a-solution%3A-performing-asynchronous-operations-sequentially">A solution: performing asynchronous operations sequentially <a href="#a-solution%3A-performing-asynchronous-operations-sequentially">#</a></h3>
<p>The first solution that may come to mind, would be to perform each of these operations <strong>sequentially</strong>:</p>
<pre><code><span><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span></span><br><span>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></span><br><span></span><br><del>  <span>-</span> <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span></del><br><ins>  <span>+</span> <span>for</span> <span>(</span><span>const</span> id <span>of</span> ids<span>)</span> <span>{</span></ins><br><ins>  <span>+</span>   <span>await</span> <span>performAsyncOperation</span><span>(</span>id<span>)</span><span>;</span></ins><br><ins>  <span>+</span> <span>}</span></ins><br><span>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span></span><br><span><span>}</span></span></code></pre>
<p>Which, if we run this script, gives the following output:</p>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
All operations performed in 29825ms, moving on to something else now.
</code></pre>
<p>As we'd expect, every operation awaits for the previous one to be completed, and, in a way, we found a succesful solution to our problem.<br>
However, one would probably argue this being far from optimal, and that the system against which we run these asynchronous operations can safely withstand up to 3 concurrent operations, thus, our script could theoretically be ~3 times faster.</p>
<h3 id="the-solution%3A-limiting-concurrency-using-workers">The solution: limiting concurrency using workers <a href="#the-solution%3A-limiting-concurrency-using-workers">#</a></h3>
<p>Now, let's take a look at how we can update our script to perform at most 3 operations concurrently.<br>
For that, let's introduce a <code>worker</code> function, to which we will delegate the job of performing one asynchronous operation at a time.</p>
<pre><code><span>const</span> <span>worker</span> <span>=</span> <span>next_</span> <span>=&gt;</span> <span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>  <span>let</span> next<span>;</span><br>  <span>while</span> <span>(</span><span>(</span>next <span>=</span> <span>next_</span><span>(</span><span>)</span><span>)</span><span>)</span> <span>{</span><br>    <span>await</span> <span>performAsyncOperation</span><span>(</span>next<span>)</span><span>;</span><br>  <span>}</span><br><span>}</span><span>;</span></code></pre>
<p><em>Note: such a <code>worker</code> function can be implemented in various ways, this implementation is just an example of what I've used in the past.</em></p>
<p>However big the number of asynchronous operations we wish to perform, we will ever need at most, 3 concurrent <code>workers</code>.</p>
<pre><code><span>const</span> <span>CONCURRENT_WORKERS</span> <span>=</span> <span>3</span><span>;</span></code></pre>
<p>We will then want to give a way to our <code>workers</code> to retrieve the next resource identifier, or thing, to perform the asynchronous operation from.</p>
<pre><code><span>const</span> workers <span>=</span> <span>[</span><span>]</span><span>;</span><br><span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>CONCURRENT_WORKERS</span><span>;</span> i<span>++</span><span>)</span> <span>{</span><br>  <span>const</span> w <span>=</span> <span>worker</span><span>(</span>ids<span>.</span><span>pop</span><span>.</span><span>bind</span><span>(</span>ids<span>)</span><span>)</span><span>;</span><br>  workers<span>.</span><span>push</span><span>(</span><span>w</span><span>(</span>ids<span>)</span><span>)</span><span>;</span><br><span>}</span></code></pre>
<p>Let us update our script:</p>
<pre><code><span><span>function</span> <span>performAsyncOperation</span><span>(</span><span>id</span><span>)</span> <span>{</span></span><br><span>  <span>return</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve</span><span>)</span> <span>=&gt;</span> <span>{</span></span><br><span>    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span></span><br><span>    console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Performed operation for resource </span><span><span>${</span>id<span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span></span><br><span>    <span>resolve</span><span>(</span><span>)</span><span>;</span></span><br><span>    <span>}</span><span>,</span> <span>300</span><span>)</span><span>;</span></span><br><span>  <span>}</span><span>)</span><span>;</span></span><br><span><span>}</span></span><br><span></span><br><ins><span>const</span> <span>worker</span> <span>=</span> <span>next_</span> <span>=&gt;</span> <span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span></ins><br><ins>  <span>let</span> next<span>;</span></ins><br><ins>  <span>while</span> <span>(</span><span>(</span>next <span>=</span> <span>next_</span><span>(</span><span>)</span><span>)</span><span>)</span> <span>{</span></ins><br><ins>    <span>await</span> <span>performAsyncOperation</span><span>(</span>next<span>)</span><span>;</span></ins><br><ins>  <span>}</span></ins><br><ins><span>}</span><span>;</span></ins><br><ins></ins><br><ins><span>const</span> <span>CONCURRENT_WORKERS</span> <span>=</span> <span>3</span><span>;</span></ins><br><ins></ins><br><ins><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span></ins><br><ins>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></ins><br><ins>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></ins><br><ins></ins><br><ins>  <span>const</span> workers <span>=</span> <span>[</span><span>]</span><span>;</span></ins><br><ins>  <span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>CONCURRENT_WORKERS</span><span>;</span> i<span>++</span><span>)</span> <span>{</span></ins><br><ins>    <span>const</span> w <span>=</span> <span>worker</span><span>(</span>ids<span>.</span><span>pop</span><span>.</span><span>bind</span><span>(</span>ids<span>)</span><span>)</span><span>;</span></ins><br><ins>    workers<span>.</span><span>push</span><span>(</span><span>w</span><span>(</span>ids<span>)</span><span>)</span><span>;</span></ins><br><ins>  <span>}</span></ins><br><ins></ins><br><ins>  <span>await</span> Promise<span>.</span><span>all</span><span>(</span>workers<span>)</span><span>;</span></ins><br><span></span><br><span>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span></span><br><span><span>}</span></span><br><span></span><br><span><span>run</span><span>(</span><span>)</span><span>;</span></span></code></pre>
<p>And run it:</p>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
All operations performed in 9948ms, moving on to something else now.
</code></pre>
<h3 id="bonus-solution%3A-batching-concurrent-operations">Bonus solution: batching concurrent operations <a href="#bonus-solution%3A-batching-concurrent-operations">#</a></h3>
<p>There's one more way to look at the problem, and reach another solution: splitting the asynchronous operations to be performed in <strong>batches</strong>.<br>
In our case, if we have 99 operations to perform, we can split these into 33 batches of 3 operations.<br>
With batching, every operation within one batch will be performed conccurently, and the next batch will only be started once the previous one is finished.<br>
How does one implement concurrent operations batching with JavaScript?</p>
<pre><code><span><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span></span><br><span>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></span><br><span></span><br><del>  <span>-</span> <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span></del><br><ins>  <span>+</span> <span>let</span> i <span>=</span> <span>1</span><span>;</span></ins><br><ins>  <span>+</span> <span>while</span> <span>(</span>ids<span>.</span>length<span>)</span> <span>{</span></ins><br><ins>  <span>+</span>   <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>splice</span><span>(</span><span>0</span><span>,</span> <span>3</span><span>)</span><span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>;</span></ins><br><ins>  <span>+</span>   console<span>.</span><span>log</span><span>(</span><span>'Performed async operactions batch number'</span><span>,</span> i<span>)</span><span>;</span></ins><br><ins>  <span>+</span>   i<span>++</span><span>;</span></ins><br><ins>  <span>+</span> <span>}</span></ins><br><span>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span></span><br><span><span>}</span></span></code></pre>
<p>Which gives us the following output:</p>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
Performed async operactions batch number 1
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
Performed async operactions batch number 33
All operations performed in 9981ms, moving on to something else now.
</code></pre>
<h3 id="conclusion">Conclusion <a href="#conclusion">#</a></h3>
<p>Asynchronous JavaScript can be tricky, and though one may argue the language lacks high-level APIs to deal more efficiently with some of these tricky cases like the one we've just covered, it's always worth taking our chance at solving the problems leveraging the features that we're provided by the language.</p>
<p>In this post we've built and lived through a common scenario of managing asynchronous operations concurrency in JavaScript, along with a common pitfall associated with a naive approach, as well as an intermediary solution that is also very useful on some other cases, and finally the optimal solution for dealing with this problem, all without using third party modules. I hope this may be useful to some of you, and that I did not take too many shortcuts in the process.</p>
<p>If you liked this post, feel free to encourage me by saying so on <a href="https://twitter.com/tpillard">my Twitter</a> and/or by liking/retweeting the associated tweet or sharing the article around you.<br>
If, on the contrary, you did not like this post and think I should never write JavaScript and/or on a public medium again, keep it to yourself dude, I know already.<br>
Finally, feel free to share your feedback …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/">https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/</a></em></p>]]>
            </description>
            <link>https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141535</guid>
            <pubDate>Thu, 13 Aug 2020 09:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell to Core: Understanding Haskell Features Through Their Desugaring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141425">thread link</a>) | @NaeosPsy
<br/>
August 13, 2020 | https://serokell.io/blog/haskell-to-core | <a href="https://web.archive.org/web/*/https://serokell.io/blog/haskell-to-core">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>This article is based on <a href="https://www.youtube.com/watch?v=fty9QL4aSRc">my talk with the same title</a>, which I gave at the Haskell Love conference in 2020, where I give a cursory overview of GHC’s front-end pipeline, the internal Core language, and the desugaring pass.</em></p><p>Haskell is an expressive language with many features. On the one hand, it makes Haskell convenient, equipping the programmer with a rich arsenal of tools to get the job done and write high-quality software. On the other hand, developing a thorough understanding of these tools, of all the language features, takes time, effort, and experience.</p><p>One way to build an intuition for a language feature is to use it. Practice makes perfect, and by trial and error, you can discover the ins and outs of using certain parts of the language. However, the knowledge acquired this way may be superficial, and the mental model will only be as good as it was needed for the tasks at hand.</p><p>Deeper insight comes from a different perspective: you need to decompose a concept into its basic constituents. For example, what are multi-argument functions? In a curried language, we know that <code>\a b c -&gt; ...</code> is much the same as <code>\a -&gt; \b -&gt; \c -&gt; ...</code>. Thus we have reduced the concept of a multi-argument function into a simpler concept of a single-argument function.</p><p>For a more involved example: what is <code>do</code>-notation? To grasp it, you need to think about how it is desugared into <code>&gt;&gt;=</code> and <code>&gt;&gt;</code> (and also <code>&lt;*&gt;</code> with <code>-XApplicativeDo</code>).</p><p>What about infix operators, if-then-else expressions, list comprehensions, type classes, type families, GADTs? How much Haskell is essential, and how much is sugar on top?</p><p>This becomes clear if we start thinking about the way Haskell programs are desugared into GHC’s Core: a small, elegant language, used as an intermediate representation in GHC’s compilation pipeline. The many features of Haskell are reducible to the few constructs of Core.</p><p>Desugaring translates a program that uses many different language constructs into a program that uses only a few.</p><p>For example, consider this snippet:</p><pre><code><span>product</span> [a + b, c + d]
</code></pre><p>It uses several Haskell features:</p><ol>
<li>Lists literals: <code>[a, b, c, ...]</code></li>
<li>Operator application: <code>x # y</code></li>
<li>Function application: <code>f x</code></li>
</ol><p>But we can rewrite it in such a way that it uses only function application:</p><pre><code><span>product</span> (
  (:) ((+) a b) (
  (:) ((+) c d) (
  [])))
</code></pre><p>Granted, the end result is not as readable. But the building blocks used to write this program are simpler, and that’s the important bit.</p><p>Desugaring is not just an abstract idea: it’s a concrete step of GHC’s pipeline. Every Haskell program is desugared into Core during compilation. So, to see the full picture, it’s helpful to consider the steps that occur prior to desugaring.</p><p>The input to the compiler is a string, a sequence of characters:</p><center><img src="https://serokell.io/files/dy/dy2sc5q9.ParserInput.png" alt="Parser Input"></center><p>Where would one begin to process this sequence? Actually, this is fairly well known. The first step is <strong>lexical analysis</strong>, which groups subsequences of these characters into labeled tokens:</p><center><img src="https://serokell.io/files/mf/mfm4t5lo.LexerOutput.png" alt="Lexer Output"></center><p>Then the tokens are organized into a tree. That’s <strong>syntactic analysis</strong>:</p><center><img src="https://serokell.io/files/oa/oav0bml8.ParserOutput.png" alt="Parser Output"></center><p>The structure of this tree depends on the language we’re working with. In Haskell, a module contains declarations, such as data declarations, class declarations, function/variable definitions, and so on. In this example, we have two value bindings, marked as ‘bind’.</p><p>In a ‘bind’, there’s a pattern on the left-hand side and an expression on the right-hand side. In this example, the patterns are simply variable names, but we could also have as-patterns, view-patterns, matching on specific data constructors, and so on.</p><p>An expression can be one of many forms, but here we have:</p><ul>
<li>‘app’ – function application, consisting of a function and its argument;</li>
<li>‘op app’ – operator application, consisting of two operands and an operator;</li>
<li>‘var’ – references to other named values;</li>
<li>‘lit’ – numeric and string literals.</li>
</ul><p>Then we do <strong>name resolution</strong>, to figure out which name refers to what:</p><center><img src="https://serokell.io/files/8v/8vvt57kn.RenamerOutput.png" alt="Renamer Output"></center><p>Here, ‘print’, ‘+’, and ‘length’ are imported from other modules, whereas ‘x’ is defined in the same module.</p><p>And then, we analyse the program to <strong>check and infer the types</strong> of its expressions and subexpressions:</p><pre><code><span>main</span> :: <span>IO</span> ()
<span>x</span> :: <span>Int</span>
</code></pre><p>So that’s the GHC pipeline, or at least its front-end:</p><p><img src="https://serokell.io/files/sx/sxg6b87v.PipelineGHC.png" alt="sxg6b87v.PipelineGHC.png"></p><ul>
<li>text to tokens;</li>
<li>tokens to a syntax tree;</li>
<li>add scoping information to the syntax tree;</li>
<li>add type information to the syntax tree;</li>
</ul><p>This leaves us with a well-scoped, well-typed syntax tree. This is the input to desugaring. And the output is a Core program, where Core is a language like Haskell, but it’s much smaller and with fewer features.</p><p>To understand how Core is simpler, let’s first take a deeper look at Haskell. To represent a Haskell expression, GHC defines a type called <code>HsExpr</code>. If you open <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Expr.hs">compiler/GHC/Hs/Expr.hs</a></code> in GHC sources, you will see it:</p><pre><code><span><span>data</span> <span>HsExpr</span> p</span>
  = <span>HsVar</span> ...         
  | <span>HsLit</span> ...         
  | <span>HsApp</span> ...         
  | <span>OpApp</span> ...         
  | ...
</code></pre><p>Remember how syntactic analysis creates a node for each subexpression? And these nodes can be of different varieties, such as function application, operator application, variables, literals, etc.? <code>HsExpr</code> has a constructor for each node type: <code>HsVar</code>, <code>HsLit</code>, <code>HsApp</code>, <code>OpApp</code>, and so on.</p><p>And there are lots and lots of node types:</p><pre><code><span><span>data</span> <span>HsExpr</span> p</span>
  = <span>HsVar</span> ...         
  | <span>HsLit</span> ...         
  | <span>HsApp</span> ...         
  | <span>OpApp</span> ...         
  | <span>HsAppType</span> ...     
  | <span>HsLam</span> ...         
  | <span>HsLet</span> ...         
  | <span>ExprWithTySig</span> ... 
  | <span>ExplicitList</span> ...  
  | <span>SectionL</span> ...      
  | <span>SectionR</span> ...      
  | <span>ExplicitTuple</span> ... 
  | <span>HsCase</span> ...        
  | <span>HsLamCase</span> ...     
  | <span>HsIf</span> ...          
  | <span>HsMultiIf</span> ...     
  | <span>HsDo</span> ...          
  | <span>RecordCon</span> ...     
  | <span>RecordUpd</span> ...     
  | <span>ArithSeq</span> ...      
  | <span>HsPar</span> ...         
  | <span>NegApp</span> ...        
  | <span>HsBracket</span> ...     
  | <span>HsSpliceE</span> ...     
  | <span>HsProc</span> ...        
  | <span>HsStatic</span> ...      
  | <span>HsOverLabel</span> ...   
  | ...
</code></pre><p>And that’s just expressions. There are also patterns, defined in <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Pat.hs">compiler/GHC/Hs/Pat.hs</a></code>:</p><pre><code><span><span>data</span> <span>Pat</span> p</span>
  = <span>WildPat</span> ...       
  | <span>VarPat</span> ...        
  | <span>LazyPat</span> ...       
  | <span>BangPat</span> ...       
  | <span>AsPat</span> ...         
  | <span>ParPat</span> ...        
  | <span>ListPat</span> ...       
  | <span>TuplePat</span> ...      
  | <span>ConPat</span> ...        
  | <span>ViewPat</span> ...       
  | <span>LitPat</span> ...        
  | <span>SigPat</span> ...        
  | <span>NPat</span> ...          
  | <span>NPlusKPat</span> ...     
  | <span>SplicePat</span> ...     
  | ...
</code></pre><p>And types, defined in <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Type.hs">compiler/GHC/Hs/Type.hs</a></code>:</p><pre><code><span><span>data</span> <span>HsType</span> p</span>
  = <span>HsForAllTy</span> ...    
  | <span>HsQualTy</span> ...      
  | <span>HsTyVar</span> ...       
  | <span>HsAppTy</span> ...       
  | <span>HsAppKindTy</span> ...   
  | <span>HsFunTy</span> ...       
  | <span>HsListTy</span> ...      
  | <span>HsTupleTy</span> ...     
  | <span>HsOpTy</span> ...        
  | <span>HsParTy</span> ...       
  | <span>HsIParamTy</span> ...    
  | <span>HsStarTy</span> ...      
  | <span>HsKindSig</span> ...     
  | <span>HsSpliceTy</span> ...    
  | <span>HsTyLit</span> ...       
  | <span>HsWildCardTy</span> ...  
  | ...
</code></pre><p>In <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Decls.hs">compiler/GHC/Hs/Decls.hs</a></code> there are data declarations, classes, type families, instances, and so on:</p><pre><code><span><span>data</span> <span>TyClDecl</span> p</span>
  = <span>FamDecl</span> ...       
  | <span>SynDecl</span> ...       
  | <span>DataDecl</span> ...      
  | <span>ClassDecl</span> ...     

<span><span>data</span> <span>InstDecl</span> p</span>
  = <span>ClsInstD</span> ...      
  | <span>DataFamInstD</span> ...  
  | <span>TyFamInstD</span> ...    
</code></pre><p>That’s not all, of course. You can browse <code>compiler/GHC/Hs/...</code> to see more.</p><p>What about Core? Here’s the entirety of its syntax:</p><pre><code><span><span>data</span> <span>Expr</span></span>
  = <span>Var</span>   <span>Id</span>
  | <span>Lit</span>   <span>Literal</span>
  | <span>App</span>   <span>Expr</span> <span>Expr</span>
  | <span>Lam</span>   <span>Var</span> <span>Expr</span>
  | <span>Let</span>   <span>Bind</span> <span>Expr</span>
  | <span>Case</span>  <span>Expr</span> <span>Var</span> <span>Type</span> [<span>Alt</span>]
  | <span>Cast</span>  <span>Expr</span> <span>Coercion</span>
  | <span>Type</span>  <span>Type</span>
  | <span>Coercion</span> <span>Coercion</span>
  | <span>Tick</span>  ...  

<span><span>type</span> <span>Alt</span> = (<span>AltCon</span>, [<span>Var</span>], <span>Expr</span>)</span>

<span><span>data</span> <span>AltCon</span></span>
  = <span>DataAlt</span> <span>DataCon</span>
  | <span>LitAlt</span>  <span>Literal</span>
  | <span>DEFAULT</span>

<span><span>data</span> <span>Bind</span></span>
  = <span>NonRec</span> <span>Var</span> <span>Expr</span>
  | <span>Rec</span> [(<span>Var</span>, <span>Expr</span>)]

<span><span>data</span> <span>Type</span></span>
  = <span>TyVarTy</span> <span>Var</span>
  | <span>AppTy</span> <span>Type</span> <span>Type</span>
  | <span>TyConApp</span> <span>TyCon</span> [<span>Type</span>]
  | <span>ForAllTy</span> <span>TyCoVarBinder</span> <span>Type</span>
  | <span>FunTy</span> <span>Mult</span> <span>Type</span> <span>Type</span>
  | <span>LitTy</span> <span>TyLit</span>
  | <span>CastTy</span> <span>Type</span> <span>Coercion</span>
  | <span>CoercionTy</span> <span>Coercion</span>
</code></pre><p>Its expression syntax has only nine constructs:</p><ul>
<li>variables (<code>Var</code>)</li>
<li>literals (<code>Lit</code>)</li>
<li>function application (<code>App</code>)</li>
<li>lambdas (<code>Lam</code>)</li>
<li>let-bindings (<code>Let</code>)</li>
<li>case-expressions (<code>Case</code>)</li>
<li>casts (<code>Cast</code>)</li>
<li>coercions (<code>Coercion</code>)</li>
</ul><p>If you learn what these are, you know Core. And if you know both Core and how Haskell programs are desugared into it, then you can easily reason about the menagerie of Haskell language features.</p><p>At a first approximation, you can think of Core as a subset of Haskell plus coercions (and casts, these two are closely related). That’s not the full story, though. For example, there are also differences in strictness, as <code>case</code> in Core is always strict. Here are some resources if you want to delve deeper into this:</p><ul>
<li><a href="https://www.youtube.com/watch?v=uR_VzYxvbxg">“Into the Core - Squeezing Haskell into Nine Constructors"</a></li>
<li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2007/01/tldi22-sulzmann-with-appendix.pdf">“System F with Type Equality Coercions"</a></li>
<li><a href="https://repository.brynmawr.edu/cgi/viewcontent.cgi?article=1014&amp;context=compsci_pubs">“System FC with Explicit Kind Equality"</a></li>
<li><a href="https://github.com/ghc/ghc/blob/master/docs/core-spec/core-spec.pdf">“System FC, as implemented in GHC"</a></li>
<li>Read the GHC sources (e.g. <code>dsLExpr</code>) and <code>-ddump-simpl</code> output</li>
</ul><p>However, as a starting point, it’s sufficient to assume that Core is a subset of Haskell.</p><p>Now let’s see how Haskell programs are transformed into Core by looking at specific examples. We’ll start with the most basic features and progress to more complex ones.</p><h2 id="infix-operators">Infix Operators</h2><p>Infix operators are translated into function applications:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>a</span> &amp;&amp; b
</code></pre>
</td>
<td>
<pre><code>(&amp;&amp;) a b
</code></pre>
</td></tr></tbody></table><p>There isn’t much to it. But keep in mind that in Core, all variable occurrences have type information, so a more accurate translation would look like this:</p><pre><code>((&amp;&amp;) :: <span>Bool</span> -&gt; <span>Bool</span> -&gt; <span>Bool</span>)
  (a :: <span>Bool</span>)
  (b :: <span>Bool</span>)
</code></pre><p>However, more often than not, I will omit type annotations to save visual space.</p><h2 id="function-bindings">Function Bindings</h2><p>Bindings in Core always have a single variable name on the left-hand side. Function bindings are desugared into lambdas:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>f</span> x y = not x &amp;&amp; y
</code></pre>
</td>
<td>
<pre><code><span>f</span> =
  \(x :: <span>Bool</span>) -&gt;
  \(y :: <span>Bool</span>) -&gt;
     (&amp;&amp;) (not x) y
</code></pre>
</td></tr></tbody></table><p>Also, there are no separate type signatures. All type information is stored inline.</p><h2 id="multi-argument-function-bindings">Multi-Argument Function Bindings</h2><p>Multi-argument functions are translated into nested lambdas. In Core, all lambdas are single-argument:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>f</span> x y = not x &amp;&amp; y
</code></pre>
</td>
<td>
<pre><code><span>f</span> =
  \(x :: <span>Bool</span>) -&gt;
  \(y :: <span>Bool</span>) -&gt;
     (&amp;&amp;) (not x) y
</code></pre>
</td></tr></tbody></table><p>This is also true for hand-written multi-argument lambdas:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>f</span> = \x y -&gt; not x &amp;&amp; y
</code></pre>
</td>
<td>
<pre><code><span>f</span> =
  \(x :: <span>Bool</span>) -&gt;
  \(y :: <span>Bool</span>) -&gt;
     (&amp;&amp;) (not x) y
</code></pre>
</td></tr></tbody></table><p>This treatment of multi-argument functions may be familiar to you if you’ve heard of <a href="https://en.wikipedia.org/wiki/Currying">cu…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serokell.io/blog/haskell-to-core">https://serokell.io/blog/haskell-to-core</a></em></p>]]>
            </description>
            <link>https://serokell.io/blog/haskell-to-core</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141425</guid>
            <pubDate>Thu, 13 Aug 2020 09:22:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Go 1.15 improved converting small integer values to interfaces]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141174">thread link</a>) | @ngaut
<br/>
August 13, 2020 | https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>How Go 1.15 improved converting small integer values to interfaces</h2>

	<p><small>August 12, 2020</small></p>
</div><div><p>In Go, <a href="https://golang.org/ref/spec#Interface_types">interface values</a>
are famously implemented as a pair of pointers (see Russ Cox's <a href="https://research.swtch.com/interfaces">Go
Data Structures: Interfaces</a>);
a pointer to information about the type and a pointer to the value
itself. This generally means that the value must be dynamically
allocated in the <em>heap</em>, which means that it will contribute to the
work that Go's garbage collection does.</p>

<p>The <a href="https://golang.org/doc/go1.15">Go 1.15 release notes</a> mention
an intriguing improvement in <a href="https://golang.org/doc/go1.15#runtime">the runtime section</a>:</p>

<blockquote><p>Converting a small integer value into an interface value no longer
causes allocation.</p>
</blockquote>

<p>When I saw that, I immediately wondered how it works, and especially
if Go's runtime was now sometimes using the value pointer field in
interface values to directly store the value.
(There are a number of languages that do this, using various approaches
like <a href="https://wiki.c2.com/?TagBit">tag bits</a> to tell values from real
pointers.)</p>

<p>The answer turns out to be pretty straightforward, and is in <a href="https://go-review.googlesource.com/c/go/+/216401">Go
CL 216401</a> (merged
in <a href="https://github.com/golang/go/commit/9828c43288a53d3df75b1f73edad0d037a91dff8">this commit</a>,
which may be easier to read). The Go runtime has a special static
array of the first 256 integers (0 to 255), and when it would
normally have to allocate memory to store an integer on the heap
as part of converting it to an interface, it first checks to see
if it can just return a pointer to the appropriate element in the
array instead. This kind of static allocation of frequently used
values is common in languages with lots of dynamic allocation;
Python does something similar for small integers, for example
(<a href="https://utcc.utoronto.ca/~cks/space/blog/python/ObjectIdentityGotcha">which can sometimes surprise you</a>).</p>

<p>(It turns out that Go previously had an optimization where if you were
converting 0 to an interface value, it would return a pointer to a
special static zero value. This new optimization for 0-255 replaces
that.)</p>

<p>There is one special trick that Go plays here. The actual array is
an array of <code>uint64</code>, but it reuses the same array for smaller sized
values as well. On <a href="https://en.wikipedia.org/wiki/Endianness">little endian</a> systems like x86, this
is fine as it stands because a pointer to a 64-bit value is also a
valid pointer to that value interpreted as 32 or 16 bits (or 8
bits). But on big endian systems this isn't the case, so if Go is
running on a big endian machine it bumps up the pointer so that it
works properly (making it point to either the last two bytes or the
last four bytes of the 8-byte value).</p>

<p>(On a little endian machine, the pointer is to the low byte of the
value and the remaining bytes are all zero so it doesn't matter how
many more of them you look at. On a big endian machine, the pointer
is to the high byte, but the low byte is the thing that matters.)</p>

<p>As bonus trivia for this change, this new array of 0-255 <code>uint64</code>
values was then reused for avoiding allocating anything for one-byte
strings in another change (<a href="https://github.com/golang/go/commit/bda42a7a782dbcf4b123d617c5b60f3c848cbb82">this commit</a>,
<a href="https://go-review.googlesource.com/c/go/+/221979">CL 221979</a>).
Go previously had an array of bytes for this purpose, but why have
two arrays. Big endian machines need the same sort of pointer bumping
they did for small integers being converted to interface values,
but little endian machines can once again use the pointers as is.</p>

<p>PS: There are runtime functions for converting 16, 32, and 64 bit
values to interface values, in <a href="https://github.com/golang/go/blob/master/src/runtime/iface.go">runtime/iface.go</a>
(they can be inlined in actual code), but I was puzzled because
there is no runtime function for converting 8 bit values. It turns
out that 8-bit values are directly handled by the compiler in
<a href="https://github.com/golang/go/blob/master/src/cmd/compile/internal/gc/walk.go#L837">walk.go</a>,
where it generates inline code that uses the <code>staticuint64s</code> array.
This may be done directly in the compiler partly because it needs
no fallback path for larger values, unlike the 16, 32, and 64 bit
cases, since an 8 bit value will always be in <code>staticuint64s</code>.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141174</guid>
            <pubDate>Thu, 13 Aug 2020 08:35:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stopping phishing campaigns with Bash]]>
            </title>
            <description>
<![CDATA[
Score 436 | Comments 154 (<a href="https://news.ycombinator.com/item?id=24141127">thread link</a>) | @geek_at
<br/>
August 13, 2020 | https://blog.haschek.at/2020/stopping-phishing-campaigns-with-bash.html | <a href="https://web.archive.org/web/*/https://blog.haschek.at/2020/stopping-phishing-campaigns-with-bash.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    <div>
                        <div>
                            <div>
                            <p>A few days ago my wife got a text message that was obviously a bad phishing attempt</p>
<figure><img loading="lazy" src="https://pictshare.net/xcz7r5.jpg"><figcaption>It says: Our -bankname- system has noticed that your "pushTAN" service is not active. Click here to activate</figcaption></figure>
<p>I spun up a VM and took a look at the website it linked to, which is <a href="https://www.sso-meinelba.com/">https://www.sso-meinelba.com/</a> (almost like the real domain but with a typo) and of course it was just a copy of a banks login form that had only one change made to it.</p>
<figure><img loading="lazy" src="https://pictshare.net/0fuchr.png"><figcaption>The phishers added a "PIN" field to the logon page</figcaption></figure>
<p>The way these things work is that they act like they're the real login form, <code>steal your credentials</code> and usually send you off to the real bank so you think you made a typo or something.</p>

<p>These phishing backends are usually very simple PHP scripts that just take the data from the submitted form and save them to a file. The phishers then <a href="https://krebsonsecurity.com/2017/12/the-market-for-stolen-account-credentials/">sell them via hidden services</a> (trying real hard not to use the bullshit term <code>darknet</code> here).</p>
<p>If the phishers didn't think too hard about getting garbage data you can have a little fun and poison their loot with fake logins.</p>
<p>So with a few lines of Bash I was able to send a few thousand datapoints to their backend, filling it with garbage.</p>
<pre><code>while :; do

    # generate random numbers for login and password
    verf=$(cat /dev/urandom | tr -dc '0-9' | fold -w 7 | head -n 1)
    pin=$(cat /dev/urandom | tr -dc '0-9' | fold -w 5 | head -n 1)

    # send them to their server as your browser would
    curl 'https://www.sso-meinelba.com/files/index/identifier/verfueger/uz1.php' \
        -H 'authority: www.sso-meinelba.com' \
        -H 'origin: https://www.sso-meinelba.com' \
        -H 'content-type: application/x-www-form-urlencoded' \
        -H 'user-agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36' \
        -H 'referer: https://www.sso-meinelba.com/files/index/identifier/verfueger/' \
        --data-raw "verfueger=Wien&amp;Verf%C3%BCgernummer=$verf&amp;Pin=$pin&amp;submit=Weiter"

    echo "Sending $verf with pin $pin"
done</code></pre>
<figure>
<video id="video" poster="https://pictshare.net/i3khmn.mp4/preview/i3khmn.mp4" preload="auto" autoplay="autoplay" controls="" muted="muted" loop="loop" webkit-playsinline="">   
    <source src="https://pictshare.net/i3khmn.mp4/raw" type="video/mp4">
</video>
<figcaption>Which was running for about half an hour until I had an idea</figcaption>
</figure>
<h2>The form was limiting my input.. but does the backend too?</h2>
<p>The phishing form limited the account number to 7 digits and the pin to 5 digits but what if I would send a bit more?</p>
<p>So I edited the script to send 256 character account numbers and passwords and then this happened.</p>
<h2>It killed their site (?)</h2>
<figure><img loading="lazy" src="https://pictshare.net/rcr9g6.png"><figcaption>The site didn't like my input</figcaption></figure>
<p>After my first request with two times 256 characters, the site went down. I'm not sure what happened and if it was a big coincidence and they took it down in the exact second I sent the large strings or I activated self destruction but since this request the site is down.</p>
<figure><img loading="lazy" src="https://pictshare.net/b71byj.png"><figcaption>Site is down now. Did I do that?</figcaption></figure>
<p>The server seems up but the content is gone.</p>
<h2>Strange things</h2>
<p>What struck me as odd was that the fake domain <code>sso-meinelba.com</code> had a valid SSL Wildcard certificate from the italian company <a href="https://www.actalis.it/">Actalis</a>. Usually phishers only get free certificates like Let's encrypt but they really seemed to have bought one. Odd</p>
<figure><img loading="lazy" src="https://pictshare.net/1fiexe.png"><figcaption>The certificate</figcaption></figure>
<p>I also noticed that the website was hosted on webx1413.aruba.it. The scammers must have rented a small VPS that hosts the scamming site</p>
<h2>How do they hide their scamming site from being detected?</h2>
<p>Remember the <code>bitly.com</code> link from the screenshot? It actually doesn't point directly to <code>sso-meinelba.com</code> but rather to a sub folder on <a href="https://kls-study.com/">https://kls-study.com</a> which is (as far as I can tell) an old homepage of the italian <a href="http://klm.education/">KLM Education</a> language school.</p>
<p>Obviously the phishers found a bug in their website and used the subdirectory <code>https://kls-study.com/redi/ccui</code> (the last part of the path seems to be random) to forward users to their phishing campaigns.</p>

<p>On the local Austrian subreddit <a href="https://www.reddit.com/r/Austria/comments/i88imh/wei%C3%9F_jemand_wieso_mir_raiffeisen_das_geschickt/">I saw a post describing a similar</a> phishing campaign and I also took a look.</p>
<p>It was the same banking login page but the backend was much more professional. It seems they actively tried to use the login credentials in the backend before saving them because after entering login data I saw this and had to laugh.</p>
<figure><img loading="lazy" src="https://pictshare.net/qm3tsb.png"><figcaption>My IP address in a subfolder called "victims"</figcaption></figure>
<p>This txt file was called once per second and it had the value <code>0</code> in it. I assume they tried to login with the credentials I entered and if it was valid, they'd forward me to the real website of the bank.</p>
<p>Sadly the server didn't enable indexing otherwise I would have seen all victims, but it was funny nonetheless.</p>
<h2>Also attacking this phishing site</h2>
<p>I saw that every request to <code>http://elba-app.com/Raiffeisen/</code> seemed to create a folder with a random string on their server. (eg <code>http://elba-app.com/Raiffeisen/f5255513e44fa68/</code>) so I thought I'd spam them again and it worked well</p>
<figure>
<video id="video2" poster="https://pictshare.net/a1s52s.mp4/preview/a1s52s.mp4" preload="auto" autoplay="autoplay" controls="" muted="muted" loop="loop" webkit-playsinline="">   
                <source src="https://pictshare.net/a1s52s.mp4/raw" type="video/mp4">
</video>
<figcaption>With every request there is a folder generated on their server</figcaption>
</figure>
<p>until</p>
<figure><img loading="lazy" src="https://pictshare.net/dj72f5.png"><figcaption>They blocked my IP</figcaption></figure>
<p>Being a sysadmin this of course is not the only IP at my disposal so I tried the BOMB request (256 instead of 7 characters) again and what happened?</p>
<figure><img loading="lazy" src="https://pictshare.net/r33l7v.png"><figcaption>Their server was not happy with my input</figcaption></figure>
<p>This time the server didn't crash or self destruct, I just seem to produce a lot of error messages on their side.</p>
<p>Also their site is a bit more complex as they don't have a single form where to post login credentials but they have 3 steps:</p>
<p><strong>Step 1:</strong>
Go to <code>http://elba-app.com/Raiffeisen</code> and the server will respond with a 302 redirect to the folder they created for you</p>
<figure><img loading="lazy" src="https://pictshare.net/jilwi2.png"><figcaption>Redirect in the location header</figcaption></figure>
<p><strong>Step 2:</strong>
They send you to a sumbit.php that only takes the account name and redirects you to</p>
<p><strong>Step 3:</strong>
Now they want your pin on <code>/hundle-pin.php</code>. I'm not sure why they did leave in that typo but here we are.</p>

<p>I made a few changes to my script to handle all 3 steps and let it run over night from a dozen different ip addresses.</p>
<p>The result? They stopped their campaign from this Domain</p>
<figure><img loading="lazy" src="https://pictshare.net/17p4v8.png"><figcaption>This phishing site is gone too</figcaption></figure>
<p><a href="https://gist.github.com/geek-at/53768c6b7aee7a973032cfb7daf65107">Here's my updated script</a> for those playing along at home</p>

<p>We saw 2 phishing attacks in different quality. Both sent out as SMS to users who are customers of the same bank.</p>
<p>I wrote a script to poison their data and got both of the sites to stop working. Great success!</p>
                            </div>
                        </div>
                    </div></article></div>]]>
            </description>
            <link>https://blog.haschek.at/2020/stopping-phishing-campaigns-with-bash.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141127</guid>
            <pubDate>Thu, 13 Aug 2020 08:25:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nintendo DS Architecture]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141035">thread link</a>) | @charliechuck
<br/>
August 13, 2020 | https://www.copetti.org/projects/consoles/nintendo-ds/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/nintendo-ds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><div><ul><li><a href="#cover-model">Model</a></li><li><a href="#cover-motherboard">Motherboard</a></li><li><a href="#cover-diagram">Diagram</a></li></ul><div><div id="cover-motherboard"><figcaption>Showing first revision<br>Controllers are plugged using a separate daughterboard<br>Missing SRAM chips are on the back and there are four unpopulated SRAM slots</figcaption></div><div id="cover-diagram"><a href="https://www.copetti.org/images/consoles/nintendods/diagram.png"><picture>
<img alt="Diagram" src="https://www.copetti.org/images/consoles/nintendods/diagram.png" data-src="https://www.copetti.org/images/consoles/nintendods/diagram.png"></picture></a><figcaption>If you have trouble following the components: Top is only accessed by ARM9, bottom section is ARM7-only, middle section is shared</figcaption></div></div></div><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>This console is an interesting answer to many needs that weren’t possible to fulfil in the handheld ecosystem. There will be some innovation and a few compromises, but this combination may pave the way for new and ingenious content.</p><hr><h2 id="cpu">CPU</h2><p>As with Nintendo’s <a href="https://www.copetti.org/projects/consoles/game-boy-advance/">previous portable console</a>, the system revolves around a big chip named <strong>CPU NTR</strong>. ‘NTR’ is shorthand for ‘Nitro’, the codename of the original Nintendo DS.</p><p>Now, CPU NTR implements an interesting multi-processor architecture using two different ARM CPUs, this design was done before ARM Holdings officially released multi-processor solutions. So, their functioning may be considered a bit unorthodox taking into account the present technology available.</p><p>While this is not the first parallel system analysed for <a href="https://www.copetti.org/projects/consoles/">this series</a>, its design is very different from the rest. For instance, we are not talking about the ‘experimental’ master-slave configuration that the <a href="https://www.copetti.org/projects/consoles/sega-saturn/">Saturn</a> debuted or the ‘co-processor’ approach found on the <a href="https://www.copetti.org/projects/consoles/playstation/">PS1</a> or <a href="https://www.copetti.org/projects/consoles/nintendo-64/">N64</a>. The Nintendo DS includes two very independent computers that will perform exclusive operations, each one having a dedicated bus. This co-dependency will condition the overall performance of this console.</p><p>That being said, let’s take a look now at the two CPUs:</p><div><ul><li id="tab-1-1-arm7tdmi-link"><a href="#tab-1-1-arm7tdmi">ARM7TDMI</a></li><li id="tab-1-2-arm946e-s-link"><a href="#tab-1-2-arm946e-s">ARM946E-S</a></li></ul><div><div id="tab-1-1-arm7tdmi"><h4>ARM7TDMI</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"></picture></a><figcaption>ARM7 structure and components</figcaption></div><p>Starting with the more familiar one, the <strong>ARM7TDMI</strong> is the same CPU found on the <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#cpu">GameBoy Advance</a> but now running at <strong>~34 MHz</strong> (double its original speed). It still includes all its original features (especially <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#whats-new">Thumb</a>).</p><p>Now for the changes: Because Nintendo’s engineers placed the ARM7 next to most of the I/O ports, this CPU will be tasked with arbitrating and assisting I/O operations. In fact, no other processor can directly connect to the I/O. As you can see, this is not the ‘main’ processor that will be in charge of the system, but rather the ‘sub-processor’ offloading the main CPU by passing data around many components.</p></div><div id="tab-1-2-arm946e-s"><h4>ARM946E-S</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"></picture></a><figcaption>ARM9 structure and components</figcaption></div><p>Here is the ‘main’ CPU of the Nintendo DS running at <strong>~67 MHz</strong>. If you ignore the ill-fated ARM8 series, you could say the ARM946E-S is the ‘next-gen’ version of the ARM7. Part of the <strong>ARM9 series</strong>, this core in particular not only inherits all the features of the <strong>ARM7TDMI</strong> but also includes some additional bits:</p><ul><li>The <strong>ARMv5TE ISA</strong>: Compared to the previous v4, features some new instructions and a faster multiplier.<ul><li>If you take a look at the core name, the letter ‘E’ means <strong>Enhanced DSP</strong> which implies that lots of these new instructions have to do with applications for signal processing.</li></ul></li><li><strong>5-stage Pipeline</strong>: This is another increment from the previous 3-stage pipeline.</li><li><strong>12 KB of L1 Cache</strong>: The core now features cache, where 8 KB are allocated for instructions and 4 KB for data.</li><li><strong>48 KB of Tightly-Coupled Memory</strong> or ‘TCM’: Similar to <a href="https://www.copetti.org/projects/consoles/playstation/#cpu">Scratchpad memory</a>, however this one discriminates between instructions (32 KB) and data (16 KB).</li></ul><p>Nintendo also added the following components around it:</p><ul><li>A <strong>Divisor and Square root unit</strong> to speed up these type of operations (the ARM9 by itself is not capable of performing this type of math).</li><li>A <strong>Direct Memory Access Controller</strong>: Accelerates memory transfers without depending on the CPU. Combined with the use of cache, both CPU and DMA can potentially work concurrently.<ul><li>Cache and DMA can provide a lot of performance but also create new problems, such as data integrity. So programmers will have to manually maintain memory consistency by flushing the <a href="https://www.copetti.org/projects/consoles/playstation-2/#preventing-past-mishaps">write-buffer</a> before triggering DMA, for instance.</li></ul></li></ul></div></div></div><p>I guess with hardware like this, it’s easy to figure out the <em>real</em> reason kids loved this console, eh?</p><h4 id="interconnection">Interconnection</h4><p>So far I’ve talked about how the two CPUs work individually. But to work as a whole, they require to co-operate constantly. To accomplish this, both CPUs directly ‘talk’ to each other using a dedicated <strong>FIFO unit</strong>, this block of data holds two 64-byte queues (up to 16 elements) for <strong>bi-directional communication</strong>.</p><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"></picture></a><figcaption>Representation of FIFO unit</figcaption></div><p>This works as follows: The ‘sender’ CPU (that effectively needs to send the other a message) places a 32-bit block of data in the queue, the CPU acting as a ‘receiver’ can then pull that block from the queue and perform the required operations with it.</p><p>Whenever there’s a value written on the queue, either CPU can fetch it manually (<strong>polling</strong>) however, this requires to constantly check for new values (which can be expensive). Alternatively, an <strong>interrupt unit</strong> can be activated to notify the receiver whenever there’s a new value in the queue.</p><h4 id="main-memory">Main memory</h4><p>Just like its predecessor, RAM is spread around many different locations, enabling to prioritise data placement by speed of access. In summary, we have the following general-purpose memory available:</p><div><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"></picture></a><figcaption>RAM model of this console</figcaption></div><ul><li><strong>32 KB of WRAM</strong> (Work RAM) using a <strong>32-bit</strong> bus: To hold fast data shared between the ARM7 and ARM9.<ul><li>Bear in mind that only one CPU can access the same address at a time.</li></ul></li><li><strong>64 KB of WRAM</strong> using a <strong>32-bit</strong> bus: For fast data as well, but only accessible from the ARM7, like the GBA had.</li><li><strong>4 MB of PSRAM</strong> using a <strong>16-bit</strong> bus: A slower type, available from either CPU and it’s controlled by a memory interface unit.<ul><li>Pseudo SRAM or ‘PSRAM’ is a variant of DRAM which, by contrast, performs refreshes from within the chip. Therefore, behaving like SRAM (the faster, but more expensive alternative to DRAM). This design reminds me of <a href="https://www.copetti.org/projects/consoles/gamecube/#clever-memory-system">1T‑SRAM</a>.</li></ul></li></ul></div><h4 id="backwards-compatibility">Backwards compatibility</h4><p>Even though the architecture is significantly different from its predecessor, it still managed to maintain the critical bits that would grant it native compatibility with GameBoy Advance games.</p><p>But for the DS to revert to an ‘internal’ GBA, the former includes a set of software routines that set the console in <strong>AGB Compatibility Mode</strong>. In doing so, it effectively halts the ARM9, disables most of the ‘special’ hardware, redirects the buses, puts the ARM7 in charge and slows it down at 16.78 MHz. Finally, the ARM7 proceeds to boot the original AGB BIOS which bootstraps the GamePak cartridge (just like an original GameBoy Advance). This mode still exhibits some features not found in the original console, such as displaying the game with black margins (we’ll see in the next section that the new screen resolution happens to be bigger). Moreover, since the DS has two screens, users can set which screen will be used to display the GBA game.</p><p>Once in GBA mode <strong>there’s no going back</strong>, the console must be reset to re-activate the rest of the hardware.</p><h4 id="secrets-and-limitations">Secrets and limitations</h4><p>With so many sophisticated components fitted in a single and inexpensive chip, it’s no mystery that some issues emerged due to the way they were forced to work with each other.</p><div><ul><li id="tab-2-1-unused-power-link"><a href="#tab-2-1-unused-power">Unused Power</a></li><li id="tab-2-2-a-question-about-the-hardware-choice-link"><a href="#tab-2-2-a-question-about-the-hardware-choice">A question about the hardware choice</a></li></ul><div><div id="tab-2-1-unused-power"><h4>Unused Power</h4><p>Sometimes I wonder how Nintendo planned the way the two CPU’s would be used, and if they already assumed some performance would be hit by the design they chose.</p><p>Let me start with the ARM9, this CPU runs at twice the speed of the ARM7, but most (if not all) of the I/O depends on the ARM7, so the ARM9 is vulnerable to excessive stalling until the ARM7 answers. If that wasn’t enough, <strong>ARM9’s external bus runs at half the speed</strong>, so there are a few bottlenecks identified.</p><p>Additionally, the Main Memory bus is only <strong>16-bit wide</strong>. Thus, whenever any CPU needs to fetch a word (32-bit wide) from memory, the interface <strong>stalls the CPU</strong> (up to 3 ‘wait’ cycles) until a full world is reconstructed. The worst impact happens when memory access is not sequential, which makes it stall for every single access. This issue will also arise when instructions are fetched (unfortunately, ARM didn’t support sequential opcode fetching back then) which, to my dismay, also affects Thumb code (since every 16-bit fetch is done as a 32-bit block). On the other hand, this penalty (as some sources call it) can be alleviated by making full use of cache and TCM.</p><p>All in all, this means that in the worst case, the ‘whooping’ ARM9’s 66 MHz horsepower is practically reduced to a mere ~8&nbsp;MHz. That is if the program makes an abysmal use of cache/TCM.</p></div><div id="tab-2-2-a-question-about-the-hardware-choice"><h4>A question about the hardware choice</h4><p>Back when I read about the CPU of the GameBoy Advance, I was really surprised by the potential of the ARM7: The CPU not only performed its designated tasks, but could also assist with others, such as providing audio sequencing or pseudo-3D graphics.</p><p>Now, during the commercialisation ARM7, ARM Holdings joined forces with DEC to design a high-end version of ARM’s chips. For this, DEC grabbed the datapath design of their processor, <strong>Alpha</strong>, and mixed it with ARM’s. The result was a new series of CPUs called <strong>StrongARM</strong> which was surprisingly <em>fast</em>. At the expense of removing certain features (Thumb and debug), DEC managed to cross the megahertz threshold by reaching speeds of up to 233 MHz. As a normal user prepared to buy a new ARM PC (let’s say a <em>RiscPC</em>), you could either choose one with the old ARM710 at 40 MHz or another one with a StrongARM running ~582% faster. The impact of StrongARM was so disruptive that ARM Holdings absorbed some of StrongARMs features to produce their next line of CPUs, starting with ARM9. And the rest is history.</p><p>But here’s where my question resides: Considering the new developments in the ARM world, why did Nintendo ultimately choose an awfully slow ARM9 combined by an even slower ARM7, instead of a faster ARM9 (or even a StrongARM)? To give you an idea, other companies like Apple just adopted the StrongARM with their Newton PDA line.</p><p>I don’t mean to criticise Nintendo’s choice, but I believe the amount of emerging technology was just too great for me to ignore. I guess their choice was done in an effort to preserve battery life and maintain production costs (by using the same CPU found in the GBA).</p></div></div></div><hr><h2 id="graphics">Graph…</h2></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/nintendo-ds/">https://www.copetti.org/projects/consoles/nintendo-ds/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/nintendo-ds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141035</guid>
            <pubDate>Thu, 13 Aug 2020 08:05:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mozilla Is Dead]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 60 (<a href="https://news.ycombinator.com/item?id=24140547">thread link</a>) | @kowabit
<br/>
August 12, 2020 | https://kowabit.de/mozilla-is-dead/ | <a href="https://web.archive.org/web/*/https://kowabit.de/mozilla-is-dead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-206394"><div><p><img width="720" height="250" src="https://kowabit.de/wp-content/uploads/2019/02/software.png" alt="" loading="lazy" srcset="https://kowabit.de/wp-content/uploads/2019/02/software.png 720w, https://kowabit.de/wp-content/uploads/2019/02/software-300x104.png 300w" sizes="(max-width: 720px) 100vw, 720px"></p><div><p>If the official news and the unofficial information come true, I believe that Mozilla will die. Ciao Firefox, ciao Thunderbird. Sorry. Also goodbye to all other products that nobody ordered.</p><p>In an <a href="https://blog.mozilla.org/blog/2020/08/11/changing-world-changing-mozilla/" target="_blank" rel="noopener noreferrer">official blog post</a> and an e-mail (<a href="https://blog.mozilla.org/wp-content/uploads/2020/08/Message-to-Employees-Change-in-Difficult-Times.pdf" target="_blank" rel="noopener noreferrer">PDF</a>) Mozilla announces that a quarter of the employees are to be fired. The current Corona crisis have contributed to this. However, the explanation for this action is only PR-speech. In the message to all employees there is again talk of new products and they are supposed to adopt a new way of thinking. Mozilla has often been criticized in the past. Projects like pocket, Send, Lockwise, Firefox OS were/are either born dead and/or burned a lot of money and resources. I have never met anyone in my professional life who has used the additional products or features. Honestly. Me neither.</p><p>According to unofficial information e.g. via Twitter or Github the documentation team, the Firefox engine team (Gecko) and the security team are affected (<a href="https://twitter.com/MichalPurzynski/status/1293220570885062657" target="_blank" rel="noopener noreferrer">1</a>, <a href="https://twitter.com/gcpascutto/status/1293519587967983616" target="_blank" rel="noopener noreferrer">2</a>, <a href="https://github.com/servo/servo/discussions/27575" target="_blank" rel="noopener noreferrer">3</a>, <a href="https://twitter.com/SteveALee/status/1293487542382333952" target="_blank" rel="noopener noreferrer">4</a>). In a crisis never the responsible head of an organization saying goodbye. The head that should have made its own company crisis-proof. Now the most important organs of the whole body are apparently being removed.</p><p>Which products Mozilla wants to market without these teams remains the secret of the management floor. As an administrator in the main job and helper in the private sphere for some people, Firefox as a browser can no longer be an option. The danger of unpatched security holes and lack of further development in the core area endangers the infrastructure and systems. Decision makers also have to pay attention to this when it comes to equipping company networks with software. An organization that buries the most important committees for the maintenance of its products no longer has a product.</p><p>If Mozilla wants to survive, the management will be fired with unearned compensation, the most important departments will be strengthened, products that nobody ordered will be discontinued and the organization will be limited to its core competence. Browser, email, security, adaptability and the fight for a free Internet. And they work with all their might to ensure that the products will become an integral part of everyday life and all operating systems.</p><p>Three months. That’s all the time they have for a clear signal. After that, users have to make a decision. Unfortunately, it will probably only be something with chromium.</p><p>Poor Internet.</p> <p><span>Tagged <a href="https://kowabit.de/tag/firefox/" rel="tag">Firefox</a>, <a href="https://kowabit.de/tag/gecko/" rel="tag">gecko</a>, <a href="https://kowabit.de/tag/goodbye/" rel="tag">goodbye</a>, <a href="https://kowabit.de/tag/imho/" rel="tag">imho</a>, <a href="https://kowabit.de/tag/mozilla/" rel="tag">mozilla</a>, <a href="https://kowabit.de/tag/security/" rel="tag">security</a>, <a href="https://kowabit.de/tag/thunderbird/" rel="tag">thunderbird</a></span></p></div></div></article></div>]]>
            </description>
            <link>https://kowabit.de/mozilla-is-dead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24140547</guid>
            <pubDate>Thu, 13 Aug 2020 06:30:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can we do better than our C compiler?]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24139943">thread link</a>) | @signa11
<br/>
August 12, 2020 | https://briancallahan.net/blog/20200812.html | <a href="https://web.archive.org/web/*/https://briancallahan.net/blog/20200812.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
	<a name="top"></a>
	<div id="main">
	    
	    <p>academic, developer, with an eye towards a brighter techno-social life</p>
	    <hr>
		
	    <hr>
	</div>
<h5 id="prev"><a href="https://briancallahan.net/blog/20200808.html">[prev]</a></h5>
<h5 id="next">[next]</h5>
    <h2 id="title">2020-08-12: Can we do better than our C compiler?</h2>
<p>Today, I wanted to become a C compiler. I added a <a href="https://github.com/ibara/echo/blob/master/echo.s">hand-compiled assembly version of echo</a> from <a href="https://briancallahan.net/blog/20200808.html">our previous coding exercise</a> and added a new make target, <code>make asm</code>, that will assemble it. Let's look at our hand-compiled assembly and compare it to our C compiler and ask whether or not it was worth it.</p>
<h4>My hand-compiled assembly</h4>
<p>It's quite small.</p>
<pre>	.text
	.p2align 2
	.globl	main
	.type	main,@function
main:
	movq	%rdi, %r15	# Get argc from %rdi, put it in %r15
	movq	%rsi, %r14	# Get argv from %rsi, put it in %r14
loop:
	decl	%r15d		# 47: for (i = 0; i &lt; argc; i++) {
	jz	done		# Rewritten as: while (--argc) {
	addq	$8, %r14	# ++argv
	movl	$4, %eax	# Set up write(2)
	movl	$1, %edi	# First parameter is 1
	movq	(%r14), %rsi	# Second parameter is *argv
	leaq	-1(%rsi), %rdx	# Get *argv[0]
strlen:				# Note: strlen has been inlined
	cmpb	$0, 1(%rdx)	# 36: while (*t != '\0')
	leaq	1(%rdx), %rdx	# 37: t++;
	jne	strlen
	subq	%rsi, %rdx	# 39: return t - s;
	syscall			# 48: write(1, *argv, %rdx);
	cmpl	$1, %r15d	# 49: if (i + 1 != argc)
	je	done		# Rewritten as: if (argc != 1)
	movl	$4, %eax	# Set up write(2)
	movl	$1, %edi	# First parameter is 1
	movq	%r14, %rsi	# Set %rsi back to beginning of *argv
	movb	$32, (%rsi)	# Second parameter is " "
	movl	$1, %edx	# Third parameter is 1
	syscall			# 50: write(1, " ", 1);
	jmp	loop
done:
	movl	$4, %eax	# Set up write(2)
	movl	$1, %edi	# First parameter is 1
	movq	%r14, %rsi	# Set %rsi back to beginning of *argv
	movb	$10, (%rsi)	# Second parameter is "\n"
	movl	$1, %edx	# Third parameter is 1
	syscall			# 52: write(1, "\n", 1);
	xorl	%eax, %eax	# Return value is 0
	retq			# 54: return 0;
	.size	main,.-main
</pre>
<p>The whole source is annotated. Comments that begin with a number are for easy cross-referencing with our <a href="https://github.com/ibara/echo/blob/master/echo.c">C version of echo</a>.</p>
<h4>Better optimization for the C code</h4>
<p>The primary tricks are are a manual inlining of the strlen function and not needing the write and _syscall functions, instead being able to use syscall directly. We could inline strlen in the C code if we wanted, but the compiler is very likely to do that for us anyway. We probably can't avoid the write and _syscall functions in C, as we discussed previously.</p>
<p>There is also some rewriting of loops to avoid the use of variables: the <code>for (i = 0; i &lt; argc; i++)</code> is rewritten as <code>while (--argc)</code> and <code>if (i + 1 != argc)</code> becomes <code>if (argc != 1)</code>, which means that we can get rid of the <code>int i</code> variable and increment through argv with <code>++argv</code>. These changes can of course be applied to the C code as well.</p>
<p>Some other tricks include using *argv as scratch space for our space and newline characters. We don't actually care what the value of *argv is once we've written it out—we only use it the one time. So it becomes free memory space for us to overwrite it with whatever we want (as long as things fit; our space and newline characters are a single byte each so we're safe). We could do this one in C too if we wanted.</p>
<p>If we made these changes, our new main function in C might look like this.</p>
<pre>int
main(int argc, char *argv[])
{

	while (--argc) {
		++argv;
		write(1, *argv, strlen(*argv));
		if (argc != 1) {
			*argv[0] = ' ';
			write(1, *argv, 1);
		}
	}
	*argv[0] = '\n';
	write(1, *argv, 1);

	return 0;
}
</pre>
<h4>Even better assembly?</h4>
<p>If we let our C compiler (clang 10.0.0) compile this to assembly, we get the following.
</p><pre>	.text
	.file	"echo.c"
	.globl	main                    # -- Begin function main
	.type	main,@function
main:                                   # @main
# %bb.0:
	pushq	%r15
	pushq	%r14
	pushq	%r12
	movq	%rsi, %r14
	movl	%edi, %r15d
	pushq	$1
	popq	%r12
.LBB0_1:                                # =&gt;This Loop Header: Depth=1
                                        #     Child Loop BB0_3 Depth 2
	decl	%r15d
	je	.LBB0_6
# %bb.2:                                #   in Loop: Header=BB0_1 Depth=1
	movq	8(%r14), %rdi
	addq	$8, %r14
	leaq	-1(%rdi), %rsi
.LBB0_3:                                #   Parent Loop BB0_1 Depth=1
                                        # =&gt;  This Inner Loop Header: Depth=2
	cmpb	$0, 1(%rsi)
	leaq	1(%rsi), %rsi
	jne	.LBB0_3
# %bb.4:                                #   in Loop: Header=BB0_1 Depth=1
	subq	%rdi, %rsi
	callq	write
	cmpl	$1, %r15d
	je	.LBB0_1
# %bb.5:                                #   in Loop: Header=BB0_1 Depth=1
	movq	(%r14), %rax
	movb	$32, (%rax)
	movq	(%r14), %rdi
	movq	%r12, %rsi
	callq	write
	jmp	.LBB0_1
.LBB0_6:
	movq	(%r14), %rax
	movb	$10, (%rax)
	movq	(%r14), %rdi
	pushq	$1
	popq	%rsi
	callq	write
	xorl	%eax, %eax
	popq	%r12
	popq	%r14
	popq	%r15
	retq
.Lfunc_end0:
	.size	main, .Lfunc_end0-main
                                        # -- End function
	.type	write,@function         # -- Begin function write
write:                                  # @write
# %bb.0:
	movq	%rsi, %rcx
	movq	%rdi, %rdx
	pushq	$4
	popq	%rdi
	pushq	$1
	popq	%rsi
	xorl	%r8d, %r8d
	xorl	%r9d, %r9d
	jmp	_syscall                # TAILCALL
.Lfunc_end1:
	.size	write, .Lfunc_end1-write
                                        # -- End function
	.section	".note.GNU-stack","",@progbits
	.addrsig
</pre>
<p>It seems that both clang and I found very similar ways to optimize the program. According to size, I did a little bit better than clang: my hand-compiled assembly came out to a 104-byte object file whereas clang generated a very heavy 125-byte object file. When factoring in the necessary glue code (_start.s, crt,s, and _syscall.s for the C version), my hand-compiled assembly ended up 152 bytes whereas clang was a distant 197 bytes. But clang had the last laugh: running ls -l on the final binaries resulted in 848 bytes for the hand-compiled assembly and 840 bytes for clang. So there is clearly something else going on under the hood that I am losing out on with my hand-compiled assembly. Perhaps you can do better than me.</p>
<h4>Smarter than me</h4>
<p>As will come as little surprise, a production-ready compiler with large teams of developers and larger pools of money is smarter than I am. But I think I did a decent job at it. I believe that learning assembly for several different processors is worthwhile but I think I will stick to higher level languages for most of my work (unless you're paying me to do otherwise...). Because there is one cost we haven't mentioned yet: time. It took me all of 30 seconds, if that, to optimize the C code whereas it took maybe half an hour to write the assembly version.</p>
<h4>Conclusion</h4>
I enjoy assembly. I teach courses that require a deep knowledge of assembly. But I think I'm going to stick to optimizing higher level code rather than cranking out assembly by hand. Or maybe not. Even our original C code was honestly good enough. I'm glad to live in a world where we have a choice of smart compilers.
<p><a href="#top"><img alt="Top" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAICAYAAADJEc7MAAAABmJLR0QA/wD/AP+gvaeTAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH4wkWDyUKJxzXegAAAB1pVFh0Q29tbWVudAAAAAAAQ3JlYXRlZCB3aXRoIEdJTVBkLmUHAAAAUklEQVQY02Ocd/j/fwY0kGjDwMhACPz//5/h////DPMO//8PYxODWXAZOP8Iw39k22F8uBg2G7Gx0cWYGMgEWJ2aaMPAiO5UDOcTGxjogUe2UwHwdJDZUucW5QAAAABJRU5ErkJggg=="></a></p>
<a href="https://briancallahan.net/blog/feed.xml"><img src="https://briancallahan.net/blog/media/pic_rss.gif"></a>
	<br>
	<hr>
	
    

</div>]]>
            </description>
            <link>https://briancallahan.net/blog/20200812.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24139943</guid>
            <pubDate>Thu, 13 Aug 2020 04:28:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I'm 15 and made a bedtime calculator with React JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 304 | Comments 119 (<a href="https://news.ycombinator.com/item?id=24139339">thread link</a>) | @joshternyak
<br/>
August 12, 2020 | https://www.sleepsources.com/bed-time-calculator/ | <a href="https://web.archive.org/web/*/https://www.sleepsources.com/bed-time-calculator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.sleepsources.com/bed-time-calculator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24139339</guid>
            <pubDate>Thu, 13 Aug 2020 02:22:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being a generalist requires more sleep than specialists]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24138674">thread link</a>) | @searchableguy
<br/>
August 12, 2020 | https://hndex.org/1730462 | <a href="https://web.archive.org/web/*/https://hndex.org/1730462">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>

<a href="https://news.ycombinator.com/item?id=1730462" target="_blank">comments</a> <a href="https://andymckenzie.blogspot.com/2010/09/trade-off-10-plasticity-vs.html" target="_blank">original article</a></header>
<p>In college, I was constantly reading neuro lit extolling the
virtues of neural plasticity, which is the ability of neurons to
change based on feedback from the environment. Plasticity certainly
has huge benefits. Specifically, plasticity allows for a better
match between phenotype and environment across variable
environments than a single, constant phenotype would.</p>
<p>But after a while, the idolatry of plasticity began to annoy me,
in part because much of the lit discussed plasticity <i>as if it
had no downsides</i>, which seems impossible. (If there really were
no costs to plasticity, then evolution should have selected for it
like <i>woah</i>).</p>
<p>The general downside seems to be that plasticity hinders
specialization. That is, if a system has the ability to change
easily (i.e. it has high plasticity), then it will tend to expend
resources on a wide range of trait values, and will have fewer
resources to focus on the most important and relevant traits. A few
examples:</p>
<ul>
<li>Synaptic pruning and other mechanisms for synaptic plasticity
allow for learning and memory, but they are energetically costly.
Indeed, one hypothesis holds that sleep is the price we have to pay
for plasticity the previous day. (see here)</li>
<li>In an evolutionary framework, the major costs to more
plasticity are 1) actually sensing the current environmental
conditions, and 2) producing the actual trait in a less efficient
way. Both of these divert resources from other tasks. (see here and
here)</li>
<li>People with autism spectrum disorders often find it difficult
to parse novel stimuli, but can sometimes concentrate for
especially long periods of time on specific niches. So one might
think of the autistic cognitive style as shifted towards the
specialization side of this trade off. (see here)</li>
</ul>
<p>Despite the many applications, the members of the committee and
I are a bit wary about this trade off. First, its status depends
largely on one's particular definitions of plasticity and
specialization. Also, some think it might just be a specific case
of trade off #3, switching costs vs change gains.</p>
<p>But given our current working definitions (plasticity = the
ability, which is highly correlated with the tendency, for
context-dependent change; specialization = funneling energy
expenditures to a narrow purpose), and because it is sort of one
level "meta" to switching costs vs change gains, we are granting
this trade off its own place in the canon.</p>
<p>(Above photo taken by flickr user uncle beast. Plants are often
studied w/r/t genetic plasticity because they can't simply pack up
shop and move if the environment changes, like an animal or insect
could.)</p>
</article></div>]]>
            </description>
            <link>https://hndex.org/1730462</link>
            <guid isPermaLink="false">hacker-news-small-sites-24138674</guid>
            <pubDate>Thu, 13 Aug 2020 00:19:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vitamin D, part 1: back to basics]]>
            </title>
            <description>
<![CDATA[
Score 371 | Comments 137 (<a href="https://news.ycombinator.com/item?id=24138590">thread link</a>) | @conorh
<br/>
August 12, 2020 | https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics | <a href="https://web.archive.org/web/*/https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-cnct8"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/3e0600_d714cff5c2c346ca9f3f81a007aa2b44~mv2.jpg/v1/fit/w_900,h_597,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_d714cff5c2c346ca9f3f81a007aa2b44~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-dpa1h">Vitamin D is a big deal. Recent studies have shown that patients with low Vitamin D levels are more likely to die from Covid-19 than their Vitamin D-rich counterparts,(1) and deficiency in the vitamin has been linked to seven of the ten leading causes of death in the U.S.(2) These facts alone have been enough incentive for many people to start supplementing the vitamin. A common question from my patients is: how much Vitamin D should I take? This is a simple question, but there are a lot of assumptions built in. Before you order that case of Vitamin D for you and your family, let’s back up and look a little more at the data.
 </p><p id="viewer-49tlt">First, why I’m interested in Vitamin D: I’m a parathyroid surgeon, and the vitamin is something I track closely in my patients. For background, the parathyroid glands are tiny endocrine organs in your neck that regulate blood calcium levels. They do this partly through the activation of Vitamin D, which helps the intestines absorb calcium. Without Vitamin D, you will have difficulty getting enough calcium, even if you are taking calcium supplements. Your bones need calcium, so a severe deficiency in Vitamin D leads to bone deformities in children (rickets) and bone loss in adults (osteomalacia). </p><div id="viewer-bovng"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/3e0600_4a3a0724a42049019ad1182bcdb30d79~mv2.png/v1/fit/w_700,h_375,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_4a3a0724a42049019ad1182bcdb30d79~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-csmdc"><em> Normal child femurs compared to femurs of a child with rickets. Rickets is caused by a severe Vitamin D deficiency while bones are growing. This condition is now very rare in the U.S. due to the fortification of almost all milk with Vitamin D.* </em></p><p id="viewer-6lba0">The relationship between parathyroid hormone, calcium, and Vitamin D is complex and fascinating (at least to a parathyroid surgeon), but the vitamin appears to do much more than just influence calcium. We’re still figuring out all that it does, but we have some circumstantial evidence about its roles. Low Vitamin D levels are linked to a variety of illnesses including cancers, hypertension, diabetes, obesity, heart failure, stroke, dementia, autoimmune disease, and respiratory tract infections (including Covid-19). A simple search of the medical literature on PubMed produces page after page of articles on the harms of Vitamin D deficiency. </p><p id="viewer-5l5ac"><strong>Most studies follow this pattern:</strong> Two sets of people are evaluated. One set has a certain disease (diabetes, for example). The other set does not have the disease. Vitamin D levels are measured in both groups. Vitamin D deficiency is found to be much more common in the group of diseased individuals. </p><p id="viewer-4f52t">Using this study method, Vitamin D deficiency is correlated with many diseases. But correlation does not equal causation. The fact that two things are related does not imply that one caused the other. With regard to the vitamin and diabetes, it could be that diabetes causes low Vitamin D. Or it may be that some other health condition causes both low Vitamin D and diabetes. Obesity, for example, is a known risk factor for diabetes, and people who are obese also tend to have low Vitamin D levels, due mostly to the dilution of the fat-soluble vitamin in the larger mass of adipose tissue. The close association between Vitamin D and diabetes could be due simply to the association they both share with obesity. </p><p id="viewer-1plm0">Here is another example: Early interest in respiratory infections and Vitamin D was due to research on hospitalized children. Young children who were hospitalized with respiratory infections were found to have much higher rates of rickets than children hospitalized for other causes.(3) Rickets, of course, is caused by Vitamin D deficiency. If Vitamin D deficiency also causes immune dysfunction, we might come up with an explanation for how low Vitamin D in these children made them more susceptible to infection. But there are other explanations. Children with a serious vitamin deficiency are likely to be less healthy overall compared to non-deficient children. In addition, rickets can cause rib deformities, which are known to make it harder to cough and breathe deeply, leading to an increased risk of respiratory infections. Vitamin D itself is not necessary for explaining the infections in these children. 
 </p><p id="viewer-8d45v">Most researchers understand that correlation does not equal causation. The classic example of this involves the correlation between ice cream and violent crime. As ice cream consumption rises, so does the rate of violent crime. The association is strong, and puzzling, until you remember that more ice cream is sold during warmer months, which is also when violent crime rates rise. Ice cream has no causative connection to crime. </p><div id="viewer-8u104"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/3e0600_7750c8e0f0804ca7b241349a5caa3f6a~mv2.jpg/v1/fit/w_900,h_720,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_7750c8e0f0804ca7b241349a5caa3f6a~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-2muq9"><em>Children about to embark on a life of crime?</em></p><p id="viewer-i9b6"><strong>But the temptation to equate correlation and causation is strong.</strong> Many articles showing a correlation with Vitamin D will add an untested but completely plausible physiological explanation for how low vitamin levels could lead to the disease. Armed with a solid correlation and a reasonable argument for causation, they may feel justified in concluding that the evidence for causation is strong. And once you have made that leap, you are almost obligated in recommending Vitamin D supplementation for anyone affected by or concerned about your disease of interest. </p><p id="viewer-9rfi1">Assuming that the correlations between Vitamin D and various illnesses are accurate, the argument for supplementation then depends on the plausibility of the physiologic mechanism. The numerous conditions associated with the deficiency involve disparate organs and body systems. To understand how one vitamin could be involved in so much, and whether we can explain a disease state by the vitamin's deficiency, it helps to know the basics of what Vitamin D does on a molecular level.</p><p id="viewer-ccvgc"><strong>Vitamin D is a hormone that binds to the Vitamin D Receptor</strong>, a protein made by cells throughout your body. The vitamin acts like a key, while the receptor is a lock. A key and lock are pointless individually, but useful together. Vitamin D and its receptor are inactive until they combine, and then they interact with DNA to produce certain actions within the cell. Based on what we already know, it is easy to understand why the intestines, parathyroids, and bones make Vitamin D Receptors – these organs are all involved in regulating calcium levels, and we know Vitamin D regulates calcium metabolism. But those are not the only organs that have the receptors. We find these receptors all over the place, in the kidneys, lungs, pancreas, uterus, and blood cells involved in immune function, just to name a few.(4,5) </p><p id="viewer-5olt1">Our bodies like to conserve resources, so if an organ or cell uses energy and resources to make these receptors, we can assume that they use them. This is the first solid piece of evidence that Vitamin D is involved in many processes throughout multiple organs. The next goal is to figure out how the organs use Vitamin D. There are various ways to do this. One clever method involves the use of mutant mice called “knockout mice” that have been genetically modified to inactivate a specific gene. In this case, the gene for the Vitamin D Receptor is inactivated, to produce "VDR null" mice. Studies in these animals provide important clues about Vitamin D, since without the lock, or receptor, the key is useless. As expected, these knockout mice have problems with calcium absorption, and the most notable effect is stunted bone growth.(6) This can be mitigated by giving the mice lots of calcium, which makes sense, since it is possible but harder for calcium to be absorbed without Vitamin D.</p><div id="viewer-3qo09"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/a27d24_ea278d26b9924aa2b2b0105b816d4c62~mv2.jpg/v1/fit/w_887,h_377,al_c,q_80/file.png" src="https://static.wixstatic.com/media/a27d24_ea278d26b9924aa2b2b0105b816d4c62~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-75iel"><em>Knockout mice are mice that have been genetically modified to inactivate a specific gene. VDR null mice are knockout mice that do not make Vitamin D Receptors. (The mouse in the photo is just a random mouse. We don't actually grow them in petri dishes.)</em></p><p id="viewer-4s6nd">But we already knew about Vitamin D and calcium. What about those other effects? VDR null mice should be helpful in explaining Vitamin D’s other roles, and we do see some revealing changes: these mutant mice on average have higher blood pressure than normal mice, and mice lacking the receptor specifically on the heart have decreased cardiac function. Certain immune cells also seem to also be impaired in the mutant mice.</p><p id="viewer-fakeg">Following this out a few steps, we could come up with a logical explanation for how Vitamin D helps the immune system, and thus deficiency would lead to impaired immune function, which then lead to increased susceptibility to infections. It sounds reasonable. But there are a few assumptions we are making: 1. We assume that Vitamin D deficiency is similar to a complete absence of the receptor. This is questionable, since even people with severe Vitamin D deficiencies still have some amount of Vitamin D. 2. We also assume that the receptor works exactly the same in mice as it does in humans. Mice and humans are relatively close on the evolutionary tree (when compared to, say, shiitake mushrooms), so this could be true, but maybe not.</p><p id="viewer-5b36s">Maybe we need to go back to humans. Interestingly, there is a very rare condition in humans characterized by ineffective Vitamin D Receptors due to a genetic mutation, similar to the VDR null mice.(7) Like the mice, these individuals will develop severely abnormal bone growth if untreated. Thinking logically and using what we know about the receptor in mice, we might expect that these individuals who cannot process Vitamin D effectively would have immune dysfunction, and perhaps cardiac issues. So far, we have not seen this. They do not appear to have an increased risk of cancer, respiratory infections, diabetes, or any of the other conditions found to be associated with Vitamin D deficiency. This genetic defect is extremely rare, though, and we have not yet been able to study these patients over a lifetime, so we may have more to learn. </p><p id="viewer-1lu5r">Studying the Vitamin D Receptor in living bodies is not the only way to assess Vitamin D’s actions. We can also study Vitamin D in a lab, using living cells in a test tube or culture dish. Much of our evidence for a link between Vitamin D and immunity comes from these <em>in vitro</em> studies. Vitamin D Receptors are …</p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics">https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics</a></em></p>]]>
            </description>
            <link>https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics</link>
            <guid isPermaLink="false">hacker-news-small-sites-24138590</guid>
            <pubDate>Thu, 13 Aug 2020 00:07:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Memoization in Dynamic Programming Through Examples]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24138567">thread link</a>) | @algodaily
<br/>
August 12, 2020 | https://algodaily.com/lessons/memoization-in-dynamic-programming/?view=article | <a href="https://web.archive.org/web/*/https://algodaily.com/lessons/memoization-in-dynamic-programming/?view=article">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://algodaily.com/lessons/memoization-in-dynamic-programming/?view=article</link>
            <guid isPermaLink="false">hacker-news-small-sites-24138567</guid>
            <pubDate>Thu, 13 Aug 2020 00:03:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Most Important Question You're Not Asking]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24138167">thread link</a>) | @brendancahill
<br/>
August 12, 2020 | https://brendancahill.io/brensblog/who | <a href="https://web.archive.org/web/*/https://brendancahill.io/brensblog/who">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f3473af4113673fca614d00"><div><div><div data-block-type="2" id="block-aace044761d7e4ee583c"><div><p>There is one single question that governs good marketing: </p><p><em>Who is it for?</em></p><p>At the heart of good marketing lies empathy. Empathy is the ability to understand where someone else is coming from. Empathy can be difficult since we tend to be enamored with our own products and ideas. But, often times who we are trying to help doesn’t care what we think, they care about what <em>they</em> want. </p><p>Designing a product before you have understood your people is a sure way to waste energy. You can go about identifying these people in two ways: </p><ol data-rte-list="default"><li><p>Demographics </p></li><li><p>Psychographics</p></li></ol><p>Demographics are easy. It answers <em>where</em> you will physically find someone. Are they in the suburbs, the city, the farm, Europe, Russia? It also answers basic information about income level, racial, gender, or political makeup. And, yes, you should know where your potential clients live but you also can’t get inside their head through demographics. Enter psychographics. </p><p>Psychographics study the beliefs of a particular group of people. What do these people believe about themselves? What are their hopes? What are their dreams? What keeps them up at night wondering about? How might they view a product like yours? How are they currently trying to solve the problem that you are offering to help with? What are their insecurities? </p><p>We are immensely complex beings and you will need to apply rigorous thinking in identifying <em>who</em> you are trying to help before you try to develop a tool. Don’t be in such a rush to develop your MVP that you forget to actually identify your MVP (most valuable people). </p><p>You might wrong in your initial attempts to bring a product or service to market but this front-loading question “Who is it for?” can at least ensure you are less off-the-mark. </p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://brendancahill.io/brensblog/who</link>
            <guid isPermaLink="false">hacker-news-small-sites-24138167</guid>
            <pubDate>Wed, 12 Aug 2020 23:12:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A device I built to improve my sleep]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24138014">thread link</a>) | @biotinker
<br/>
August 12, 2020 | https://biotinker.dev/posts/seismograph.html | <a href="https://web.archive.org/web/*/https://biotinker.dev/posts/seismograph.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>At my old house, I used to live next to some railroad tracks.
</p><p>
And by "next to", I mean it was a measured 48 feet from my bedroom window to the rail. On the only north-south freight rail line in central Oregon. Trains were frequent - around eight passed by daily, including (typically) three between the hours of 11PM and 6AM.
</p>
<p><img src="https://biotinker.dev/images/tracks_from_window.jpg"></p><h4>The view from the window, mid snow shower</h4>
<p>
Fortunately, I'm a deep sleeper, and it didn't really bother me as long as I kept the window shut. I was quite happy sleeping here for nearly two years.
</p>
<h2>The Issue</h2>
<p>
But then, I got married, and unlike me, my wife is not a deep sleeper. She was being constantly woken up by trains, and so what sleep she did get was poor in quality. Repeat for a month, and she was fairly unhappy.
</p><p>
So I grabbed one of the (many) spare Raspberry Pis I had lying around, hooked it up to some $5 thrift store speakers in our bedroom, and set the Pi to play <a href="https://en.wikipedia.org/wiki/Pink_noise">pink noise</a> constantly. We would turn on the speakers before bed, and turn them off in the morning. The speakers even had a remote control, so no need to get up if we forgot to turn it on before getting in bed.
</p><p>
And it worked! Mrs. Wife slept like a rock. Train noise successfully drowned out.
</p><p>
Just one problem: the minimum speaker volume necessary to drown out passing trains was significantly louder than the maximum volume at which I could easily fall asleep. One person slept easy, and the other did not, just like before.
</p><p>
So I thought to myself - "Wouldn't it be nice if I had some way of knowing when a train was coming, so I could raise the volume to drown it out, but keep the noise quiet otherwise?"
</p><p>
I started brainstorming ways to do this. Some ideas that came to mind:
</p>
<ol><h2><li>A train schedule</li></h2>
<p>The trains most readers are familiar with, probably claim to run on some sort of schedule. Those who ride them often in the United States are probably also familiar with how often they actually abide by that schedule; rarely if ever. And this is purely a freight line, where running trains at a given time is optional and frequently plus-or-minus several hours, not to mention that BNSF was free to run bonus 2am trains whenever they felt like it. And of course, freight train location data is considered information of national security importance, so no freight company publishes it or will give it out when asked.</p>

<h2><li>Radio Signals</li></h2>
<p>Trains use radios to communicate with their stations, and BNSF trains transmit telemetry data <a href="https://web.archive.org/web/20200806234343/https://www.arema.org/files/library/2003_Conference_Proceedings/0058.pdf">at around 44Mhz</a>. Hypothetically I could listen for these radio blasts, and indeed they are commonly used in the railfan community to know when trains are nearby. But some unfortunate realities made this difficult for our purposes. There were multiple switching yards nearby, so the presence of many trains that were not necessarily on the track going past our house would confound the signal. Furthermore, the trains had a very unfortunate habit of stopping on the tracks outside our house, and not moving again for up to 20 minutes. With the transmitter potentially up to a mile away at the head of the train, a radio system would not know the railcars were still outside the window and would happily assume there was no train through the racket the railcars made once they started moving again.</p>

<h2><li>Railroad Crossings</li></h2>
<p>There are railroad crossings at major roads about a half mile in both directions from the house. This had the potential to be very useful - if I could somehow discern the state of the two crossing gates, then as long as at least one was closing/closed, I could ramp up the volume and keep it high, otherwise keeping it low.</p>
<p>Unfortunately, I did not have line-of-sight to either crossing, even from my roof. Without being able to see the crossings, the only way to determine their state would be to place hardware somewhere near (or on) the crossing, which came with a whole host of problems. Not only would the device would have to be powered, but someone would be able to steal it (as it wouldn't be anywhere close to on my property), it would have to send information a half mile away to my house, and of course it had the potential to land me in prison if I tampered with the crossing in any way.</p>

<h2><li>Laser Microphone</li></h2>
<p>Having read several articles and books on the Cold War and the history of spycraft, I was familiar with a device called a <a href="https://en.wikipedia.org/wiki/Laser_microphone">laser microphone</a>, which allows someone to measure the vibrations in a distant object by bouncing a laser beam off of it and measuring movements of the reflected light beam. The rails are conveniently located at window height, so this would be feasible. Increased vibrations in the track would indicate a train approaching.</p>
<p>Unfortunately, the tracks are not themselves sufficiently reflective for this to natively work. A mirror would have to be physically affixed to the side of the track, about which I am sure BNSF would not be thrilled if they found (and it would be pretty obvious who put it there). Add to that the loss of sensitivity whenever it rained or snowed, and of course the risk of hanging somewhat expensive electronics equipment out my window, and this wasn't looking like a great option either.</p>

<h2><li>Non-laser Microphone</li></h2>
<p>I considered just dangling an ordinary microphone out the window to listen for the engine rumble and the whistle that blew at the train crossings. But like the laser microphone above, this would be susceptible to the weather - wind at the wrong time could prevent a train detection, water or insects could get in and destroy the equipment, and it still meant that I had to run wires through my wall or window to the outdoors. Putting the microphone indoors would solve those problems, but might not be able to hear an approaching train far enough in advance to slowly ramp up the volume before it arrived.</p>
</ol>
<h2>The Solution</h2>
<p>As I was pondering ways to make a laser microphone work while having all equipment contained within my house, a train went by, a particularly loud one that shook the house for a minute or so. I realized - there was no need to look outside at the rail for vibrations of an approaching train, I could do so right within my own home, picking up the shaking of the earth caused by the approach of ten million pounds of high-speed steel. Each train that went by created a very small localized earthquake - and so I would make a seismograph.
</p><p>
Searching online for "homemade seismograph" yields numerous results and dozens of very different and creative designs of various difficulties, costs, and sensitivities. Some made creative use of springs, while others simply used accelerometers. I finally settled on <a href="https://web.archive.org/web/20200806232640/https://create.arduino.cc/projecthub/mircemk/extremely-sensitive-cheap-homemade-seismometer-175231">a GPL'd design</a> that suspended a magnet on a long lever arm next to a coil of wire - vibrations would shake the arm, inducing a current in the coil. It even included a vibration damper based on Lenz's Law, so after an initial shock oscillations would quickly dissipate on their own.
</p>
<h2>Seismograph Body Construction</h2>
<p>
Creating the body was simply a matter of cutting some foam board and applying a hot glue gun. I bought a thin iron rod to use as the needle arm, as well as several neodymium disk magnets, from a home improvement store. I wound some 28 AWG enameled wire around a small, flat plastic spool to create my coil. I cut a thin strip of brass to hold the coil over the magnets. On top of the brass, under the coil, I put a 1/8" thick plate of aluminum I made by cutting a much longer aluminum strip, and on top of the coil I put a small piece of steel to attract the magnets mounted on top of the rod, to hold that assembly upright. For anyone looking to make their own, the only measurement that really matters is to make the height of the structure about an inch taller than the length of your needle, to give room for your magnets. Everything else should be pretty self-explanatory from the above link.
</p><p>
Once the assembly of the above was done, I created a cage for the whole thing to protect it from air currents. I twisted several lengths of annealed wire into a wireframe box significantly larger than the device, and then wrapped the whole thing in clear kitchen plastic wrap, sealing the holes with duct tape. I soldered some jumper wires to the free ends coming off the coil, and the device was done.
</p>
<p><img loading="lazy" src="https://biotinker.dev/images/completed_seismo.jpg"></p><h4>The completed seismograph, without the enclosure</h4>
<p><img loading="lazy" src="https://biotinker.dev/images/completed_seismo_enclosed.jpg"></p><h4>The completed seismograph, with the air current enclosure</h4>
<p>
Of course, building the physical device to pick up the vibrations was only half of the task - and, it turned out, by far the easier one. Next, the tiny signals from the movement of the magnet needed to be amplified so I could pick them up and process the signal.
</p><p>
Despite my constant tinkering, I am not an electrical engineer. Not even close - it's at best a Halloween costume on me. I have a general idea of what resistors, capacitors, and transistors are, and I'm semi-competent with a soldering iron, but that's about as far as it goes. The most complex projects I've done before are 1) programming a micro maestro to actuate a servo when a button was pressed, and 2) rewriting some firmware for a different version of a circuit board of mine with a PIC12F635 microchip, tracing the circuitry with a multimeter to determine what each pin was connected to. I had never undertaken any large-scale soldering project, nor designed my own PCB or any complicated circuit. There was a lot of learning to do before electrical engineering seemed more like science and less like black magic.
</p>
<h2>Some Brief EE Background Follows</h2>
<p>
I learned there are devices called operational amplifiers, or op amps, which are key to building amplification circuits. These are chips which have an "inverting" and a "non-inverting" input, as well as an output, and put simply, making the inverting input more negative makes the output more positive, and making the non-inverting input more negative makes the output more negative. These are enormously useful for a wide variety of electronics applications, and there are all sorts of different neat circuits you can make with them. The one I was interested in is called a non-inverting amplifier, which takes a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://biotinker.dev/posts/seismograph.html">https://biotinker.dev/posts/seismograph.html</a></em></p>]]>
            </description>
            <link>https://biotinker.dev/posts/seismograph.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24138014</guid>
            <pubDate>Wed, 12 Aug 2020 22:52:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Navidrome Music Server]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24137317">thread link</a>) | @deluan
<br/>
August 12, 2020 | https://www.navidrome.org/about | <a href="https://web.archive.org/web/*/https://www.navidrome.org/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
        

















<section id="td-cover-block-0">
  <div>
    <div>
      <div>
        <div>
          
          
          <p>
  Navidrome is a self-hosted, open source music server and streamer. 
  It gives you freedom to listen to your music collection from any browser or mobile device.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>




 
<a id="td-block-1"></a>
<section>
	<div>
		<div>
			<h3 id="what-exactly-is-navidrome">What exactly is Navidrome?</h3>
<p>It is a piece of software that allows you to listen to your own digital music in the same way you
would with services like Spotify, Apple Music and others. It also allows you to easily share
your music and playlists with your friends and family</p>
<h3 id="how-it-works">How it works?</h3>
<p>After a simple <a href="https://www.navidrome.org/docs/installation">installation</a>, Navidrome indexes all digital music stored in your hard drive and makes
it available through a nice web player and also by using any
<a href="https://www.navidrome.org/docs/overview/#apps">Subsonic-API compatible mobile client</a>.
Your music becomes searchable and you can create playlists, rate and “favourite” your loved tracks,
albums and artists</p>
<p>
    
    
    <img height="300" src="https://www.navidrome.org/screenshots/mobile-login.png">
    <img height="300" src="https://www.navidrome.org/screenshots/light-albums-view.png">
    <img height="300" src="https://www.navidrome.org/screenshots/dark-mobile-albums-view.png">
    <img height="300" src="https://www.navidrome.org/screenshots/dark-album-view.png"></p>

		</div>
	</div>
</section>




      </div></div>]]>
            </description>
            <link>https://www.navidrome.org/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-24137317</guid>
            <pubDate>Wed, 12 Aug 2020 21:39:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reducing the Costs of Robotics Observability]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24137018">thread link</a>) | @richardanaya
<br/>
August 12, 2020 | https://formant.io/news-and-blog/2020/08/11/development/cut-the-costs-of-robotic-observability-with-on-demand-ingestion/ | <a href="https://web.archive.org/web/*/https://formant.io/news-and-blog/2020/08/11/development/cut-the-costs-of-robotic-observability-with-on-demand-ingestion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="div_block-19-15073"><p><img id="image-21-15073" alt="" src="https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/featured-image-spot-modem3-figma.jpg"></p><p><span id="span-17-15073"><h2>Challenges to connectivity</h2>
<p>Much has been written in recent years on strategies for observation and analysis of servers in the cloud data center. So much so that we have a whole field of DevOps who have refined this topic into an art to keep businesses running optimally.&nbsp; Robot fleets similarly rely upon historical data and metrics for the improvement of their day-to-day operations.&nbsp; The importance of these principles may not be readily apparent in early development phases of a robot, but as a company scales to sending many robots out into the field they become essential to tracking accomplishments of goals, identifying mistakes, and recognizing patterns.&nbsp;</p>
<p>Beyond the storage and processing of this data, roboticists face additional challenges that server infrastructure engineers do not.&nbsp; Robots operate in environments fraught with both physical and financial barriers to the transfer of data. Some of these environmental challenges include:&nbsp;</p>
<ul>
<li> &nbsp; &nbsp; &nbsp; Structures or equipment that create poor signal or noise</li>
<li> &nbsp; &nbsp; &nbsp; Locations where data is only accessible via expensive mobile data services</li>
<li> &nbsp; &nbsp; &nbsp; Networks that are not accessible due to security</li>
<li> &nbsp; &nbsp; &nbsp; Limited robot hardware that can’t power always-on communication</li>
</ul>
<p>As a robot business, you must consider these challenges and develop a strategy to overcome them in order to optimize your service. While each use case is unique, certain considerations are common throughout the field. For example:</p>
<ul>
<li> &nbsp; &nbsp; &nbsp; What information do I need to see all the time?</li>
<li> &nbsp; &nbsp; &nbsp; What information do I need to see on a case by case basis?</li>
<li> &nbsp; &nbsp; &nbsp; What information is important for me to be aware of immediately if something goes wrong?</li>
<li> &nbsp; &nbsp; &nbsp; How can I financially optimize my data ingestion?</li>
</ul>
<h2>The benefits of on-demand ingestion&nbsp;</h2>
<p>In this article, I want to introduce a technique that can be applied in order to address these issues — on-demand ingestion.&nbsp; On-demand ingestion is the process of storing robot telemetry on the device itself so it can be accessed when needed or kept until extraction. Doing this allows us to move beyond the paradigm that a robot is simply an “always-on” source of various kinds of telemetry streams, which can only be either “on” or “off”.</p>
<p>The primary advantage of on-demand ingestion is that it allows robot businesses to reduce the costs of mobile data transfer, cloud storage, and processing<b>.</b> When it comes down to it, the cost of additional on-device hard drive space is minuscule compared to the cost of cellular data transfer. By storing one’s observational data on-device and accessing it selectively — rather than passively transferring a constant stream of data to the cloud — businesses can often reduce their cellular data expenditures by upwards of 80%.</p>
<p>Ultimately, not all telemetry generated by a robot needs to be sent immediately. Often robot companies have existing support systems with a list of incidents that need to be investigated.&nbsp; We want operators to be able to start with their knowledge base first and determine if the cost of data acquisition is worth the effort. If extraction is worth it, then it should be as easy as possible to gather this data whenever it is available. A typical workflow might look something like:</p>
<p>1. A ticket comes in from a field agent regarding an anomalous event (e.g., faster battery drain, battery high temperature, sensor malfunction or unexpected state changes) with a robot on-site.</p>
<p>2. We look at the incident and determine what kinds of information would prove useful in diagnosing the problem at that moment in time.</p>
<p><img src="https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-00.png" alt="" width="1440" height="972" srcset="https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-00.png 1440w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-00-300x203.png 300w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-00-1024x691.png 1024w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-00-768x518.png 768w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-00-600x405.png 600w" sizes="(max-width: 1440px) 100vw, 1440px"></p>
<p>3. With our knowledge of what data types are relevant, we can query the robot for the presence of that data at or around the time of the incident, identifying the size and scope of data necessary to resolve the issue.</p>
<p><img src="https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-01.png" alt="" width="1440" height="972" srcset="https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-01.png 1440w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-01-300x203.png 300w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-01-1024x691.png 1024w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-01-768x518.png 768w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-01-600x405.png 600w" sizes="(max-width: 1440px) 100vw, 1440px"></p>
<p>4. We send a request to a robot to retrieve this data at the next opportune time it’s available.</p>
<p><img src="https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-02.png" alt="" width="1440" height="972" srcset="https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-02.png 1440w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-02-300x203.png 300w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-02-1024x691.png 1024w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-02-768x518.png 768w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-02-600x405.png 600w" sizes="(max-width: 1440px) 100vw, 1440px"></p>
<p>5. We are notified when this data arrives and can complete our investigation</p>
<p><img src="https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-5.png" alt="" width="1440" height="972" srcset="https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-5.png 1440w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-5-300x203.png 300w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-5-1024x691.png 1024w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-5-768x518.png 768w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/Retrieve-On-Demand-5-600x405.png 600w" sizes="(max-width: 1440px) 100vw, 1440px"></p>
<p>Notice how we’ve turned continuous historical data transfer into a reactive operation that could be automated to allow a single person to investigate many issues with minimal data cost. Rather than constantly query, transfer, and store telemetry data of unknown worth or necessity, we can now selectively peek into the system on an “as-needed” basis.&nbsp;</p>
<p>On-demand ingestion also means that triggering/alerting mechanisms can be reassigned from the cloud to the machine itself. Having these mechanisms function on the robot, rather than in the cloud, opens up a number of possibilities. Normally, data sent to the cloud level is throttled to save on the cost of data processing.&nbsp; A robot with local storage of data can keep telemetry in the maximum resolution capable by the hardware. This allows on-device observation/alerting of high-density telemetry that would be cost prohibitive in the cloud level.</p>
<p>Similarly, consider the creation of data science models that identify when something is wrong with your robot. The accuracies of your model should not be limited to an arbitrary ingestion rate for live data. With high-resolution data stored on the robot, you could selectively extract high-density data in the time ranges around the moment of error.&nbsp; In this way, one enjoys “the best of both worlds,” with throttled live data on-cloud and high-density data on-device.</p>
<h2>Robotics’ persistent data problem</h2>
<p>On-demand ingestion is a compelling solution to a challenge that will likely persist for quite some time. The wireless data market shows few signs of competitive pricing or technological improvements capable of keeping up with ever-increasing usage. The majority of mobile networks are still owned by a select few companies that charge high fees, with the costs of taxes, installation, and maintenance baked into them. Ultimately, these services run on spectrums that have limited capacity and are struggling to keep up with the latest consumer innovations. Until a major economic shift occurs, managing a robotic fleet will involve trade-offs between the financial costs of bandwidth, the scheduling of ingestion, and the volume and variety of data types one monitors continuously.</p>
<p><img src="https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/on-demand-ingestion-image-5b-20200811.jpg" alt="" width="1000" height="617" srcset="https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/on-demand-ingestion-image-5b-20200811.jpg 716w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/on-demand-ingestion-image-5b-20200811-300x185.jpg 300w, https://mk0newformantw60igh8.kinstacdn.com/wp-content/uploads/2020/08/on-demand-ingestion-image-5b-20200811-600x370.jpg 600w" sizes="(max-width: 1000px) 100vw, 1000px"></p>
<p>A data ingestion strategy is essential for any business wanting to take a robot from a well-tested device connected to the lab’s wi-fi network to the complexity of your customers’ environment where data availability can be a wildcard. Flipping a switch to tell your robot to save data on-device is just the beginning.&nbsp; Fascinating opportunities are opened when we begin asking how we can intelligently release that data to maximize your operations.&nbsp; As a data engineer, I’m excited about how integrations with 3rd party services and statistical models can help businesses automate the discovery of the unknowns hidden within machines.</p>
<span></span></span></p></div></div>]]>
            </description>
            <link>https://formant.io/news-and-blog/2020/08/11/development/cut-the-costs-of-robotic-observability-with-on-demand-ingestion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24137018</guid>
            <pubDate>Wed, 12 Aug 2020 21:09:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Game Dev Examines Why His First Game Failed]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24136936">thread link</a>) | @handlingelect
<br/>
August 12, 2020 | https://www.staticcatgames.com/2020/06/tappy-donut-brief-history.html | <a href="https://web.archive.org/web/*/https://www.staticcatgames.com/2020/06/tappy-donut-brief-history.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><iframe allowfullscreen="" height="266" src="https://www.youtube.com/embed/jeVTJLjzYHM" width="320" youtube-src-id="jeVTJLjzYHM"></iframe></p><p>Gameplay footage of the last build uploaded to itch.io and IndieGala</p><p><i><a href="https://staticcatgames.itch.io/tappy-donut" target="_blank">Tappy Donut</a>&nbsp;</i>was my first game. Released on May 20th, it was a fairly simple casual game built with Buildbox 3, using their flappy bird template to help understand how games work and how their particular software worked.&nbsp;</p><p>It was the only successful prototype released. The initial idea was called <i>Trials of a Martian Flyboy </i>and it was going to be a fun casual endless runner set on Mars. Unfortunately, it didn't look right. Graphics were too pixellated and there wasn't any joy in avoiding the same killer robots over and over again.&nbsp;</p><p>There were additional problems with how the game looked in previews - borders were all over the place and it was a mess.</p><p>Perhaps the biggest issue was Android performance. A debug APK revealed the underlying truth: it was just too slow. Even though it was a 2D game and was fairly simple in its design, melting chocolate was far quicker. There were complaints on the Buildbox forum about the 3D performance on Android devices, but I wonder if there were also issues with 2D games?</p><p>Anyhow, it just couldn't be released to the public. Anyone playing would be frustrated and delete immediately.</p><h2><br>Creating Tappy Donut</h2><p>Next came <i>Tappy Donut. </i>The first prototype was initially derived from an excellent Buildbox user called Smart Penguins. He has a great YouTube video explaining how to build a very simple 2D game. That was followed to the letter and it worked great until the problems occurred.&nbsp;</p><p>First the background stuttered. It was a layered image and the foreground started to stutter. Then came the rotating ground issue. The ground started to rotate on its on. The player would move from screen one to two and encounter rotating ground.&nbsp;</p><p>Then the game crashed, and when it was opened, all of the functions such as player movement were undone. You can reconnect them, easy right? This had the noticeable effect of doing absolutely nothing at all.&nbsp;</p><p>At this point, it was getting frustrating. Emailing support didn't help because they took two days to respond.&nbsp;</p><p>During this time I decided to start from scratch again. I sourced new assets for the game (fast food themed) along with a new background and music. Everything worked okay, fingers crossed. The debugged APK was stable, albeit a little slow.&nbsp;</p><h2>First version screenshots</h2><p>The first version looked like this:</p><p><a href="https://1.bp.blogspot.com/-bPxOZM6Z_tQ/Xvm8fIUYoKI/AAAAAAAAANI/tVMj6cQq8iQJzgGL6kMiIScUW6HwfIbkQCK4BGAsYHg/s300/unnamed%2B%25282%2529.png"><img alt="tappy donut" data-original-height="300" data-original-width="169" src="https://1.bp.blogspot.com/-bPxOZM6Z_tQ/Xvm8fIUYoKI/AAAAAAAAANI/tVMj6cQq8iQJzgGL6kMiIScUW6HwfIbkQCK4BGAsYHg/d/unnamed%2B%25282%2529.png" title="tappy donut screenshot"></a><img alt="tappy donut" data-original-height="300" data-original-width="169" src="https://1.bp.blogspot.com/-HxazHLepZy4/Xvm8flq_sAI/AAAAAAAAANQ/4-nOcNws52EpPa0cXYK3nzscVE1xIx4OgCK4BGAsYHg/d/unnamed%2B%25281%2529.png" title="tappy donut screenshot gameplay original"><img alt="tappy donut" data-original-height="300" data-original-width="169" src="https://1.bp.blogspot.com/-EHCH2_2GitM/Xvm8fVH8JjI/AAAAAAAAANM/sZxxI6rDXkYTEg_FgaHgFxmmIhXD8mFgwCK4BGAsYHg/d/unnamed.png" title="tappy donut screenshot game over"></p><br><h2>Launching the game</h2><p>Out of curiosity, I decided to unleash the game onto the unsuspecting public through publishing on Google Play. I wondered how many people would actually play the thing? My marketing strategy would consist of social media (especially the idea of "shout outs" on Instagram) and ASO. I even tried marketing on TikTok but these resulted in only a couple of installs. Posting the APK on alternative app stores such as Amazon and Yandex resulted in only a few more.&nbsp;</p><h2>Conclusion: what happened to Tappy Donut?</h2><p>Lately, I came to the conclusion that investing more time in the project wasn't worth it. To improve things, I had redesigned several elements and updated the APK. No changes. I spent almost a whole day creating graphics from scratch in Inkscape but they looked awful.&nbsp;</p><p>I decided, in the end, to end the project and take down the game from Google Play. I uploaded the final build (created in Buildbox 2.3.9) <a href="https://staticcatgames.itch.io/tappy-donut" target="_blank">on itch.io today</a>.&nbsp;</p><p>Was the experience worth it? Totally. Parts of it were extremely frustrating, but it was actually pretty cool to have a game <i>you </i>built on your smartphone.&nbsp;</p>
</div></div>]]>
            </description>
            <link>https://www.staticcatgames.com/2020/06/tappy-donut-brief-history.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24136936</guid>
            <pubDate>Wed, 12 Aug 2020 21:02:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Out of Sight ≠ Out of Mind]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24136463">thread link</a>) | @gajus
<br/>
August 12, 2020 | https://aboutsnack.com/blog/5-easy-ways-to-boost-employee-wellness | <a href="https://web.archive.org/web/*/https://aboutsnack.com/blog/5-easy-ways-to-boost-employee-wellness">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>5 Easy Ways To Boost Employee Wellness</span></p></div><div><p>Working from home during the pandemic is far from the traditional sense of remote working. When not given a choice, the natural tendency is to feel trapped and disgruntled. From there, a downward emotional spiral could be triggered, and without prompt attention from coworkers or HR, it can leave employees feeling unappreciated, neglected and burned out.</p>
<p>During this period of change and uncertainty, taking good care of the emotional wellbeing of your employees is more important than ever.</p>
<p>Here are 5 simple &amp; fun ideas for you to increase employee happiness.</p>
<h3>1. Care Package</h3>
<p>May it be a gourmet meal, or an afternoon delight like bubble tea or ice cream, there are a myriad of delivery options for every budget. It is the thought that counts.</p>
<p><span>
      <a href="https://aboutsnack.com/static/77265f5048a63f20339a97d045f76d12/d165a/wine-connection.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Wine and cheese care package" title="Wine and cheese care package" src="https://aboutsnack.com/static/77265f5048a63f20339a97d045f76d12/b4294/wine-connection.jpg" srcset="https://aboutsnack.com/static/77265f5048a63f20339a97d045f76d12/75985/wine-connection.jpg 150w,
https://aboutsnack.com/static/77265f5048a63f20339a97d045f76d12/f93b5/wine-connection.jpg 300w,
https://aboutsnack.com/static/77265f5048a63f20339a97d045f76d12/b4294/wine-connection.jpg 600w,
https://aboutsnack.com/static/77265f5048a63f20339a97d045f76d12/8e1fc/wine-connection.jpg 900w,
https://aboutsnack.com/static/77265f5048a63f20339a97d045f76d12/e5166/wine-connection.jpg 1200w,
https://aboutsnack.com/static/77265f5048a63f20339a97d045f76d12/d165a/wine-connection.jpg 1400w" sizes="(max-width: 600px) 100vw, 600px" loading="lazy">
  </a>
    </span></p>
<p>(My favourite delivery during the pandemic!)</p>
<h3>2. Virtual Parties</h3>
<p>Lockdown does not mean doing away with fun. In fact, parties can now have as many participants as your conferencing tool permits (and often less expensive with reduced spending on catering). Apart from birthday celebrations, get your team together for a virtual happy hour, wine tasting, book club, <a href="https://skribbl.io/" target="_blank" rel="noreferrer">pictionary</a>, game night, yoga and more! This is the perfect opportunity for team bonding — no one can excuse themselves because of traffic or the location being too far away.</p>
<p><span>
      <a href="https://aboutsnack.com/static/5d4dbc61d401d9935a0b04195dbb7679/3bf57/the-smol-hearts.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Entertaining team photo op ideas" title="Entertaining team photo op ideas" src="https://aboutsnack.com/static/5d4dbc61d401d9935a0b04195dbb7679/b4294/the-smol-hearts.jpg" srcset="https://aboutsnack.com/static/5d4dbc61d401d9935a0b04195dbb7679/75985/the-smol-hearts.jpg 150w,
https://aboutsnack.com/static/5d4dbc61d401d9935a0b04195dbb7679/f93b5/the-smol-hearts.jpg 300w,
https://aboutsnack.com/static/5d4dbc61d401d9935a0b04195dbb7679/b4294/the-smol-hearts.jpg 600w,
https://aboutsnack.com/static/5d4dbc61d401d9935a0b04195dbb7679/8e1fc/the-smol-hearts.jpg 900w,
https://aboutsnack.com/static/5d4dbc61d401d9935a0b04195dbb7679/e5166/the-smol-hearts.jpg 1200w,
https://aboutsnack.com/static/5d4dbc61d401d9935a0b04195dbb7679/3bf57/the-smol-hearts.jpg 1302w" sizes="(max-width: 600px) 100vw, 600px" loading="lazy">
  </a>
    </span></p>
<p>See <a href="https://www.facebook.com/groups/zoommemes/permalink/282859036070242/" target="_blank" rel="noreferrer">The Smart Local</a> post for entertaining team photo op ideas.</p>
<h3>3. Gamify Meetings</h3>
<p>For the next conference call, how about a little competition on who has the best outfit or background? Just as one needs to spice things up to keep the flame of romance alive, we also need to put in extra effort to maintain the spirit of camaraderie.</p>
<h3>4. Workshop &amp; Training</h3>
<p>Employee recognition is particularly crucial at remote work settings. There is a genuine fear of “losing out” because your supervisor does not see you working. On top of conducting regular 1-on-1s, empower your employees by giving them showcase opportunities. You will be pleasantly surprised by the hidden talents and eloquent presenters within the company.</p>
<h3>5. Keeping Social Interactions Real</h3>
<p><a href="https://journals.aom.org/doi/10.5465/amj.2018.1474" target="_blank" rel="noreferrer">Research</a> shows that small talk has a positive impact on our emotional wellbeing. Managers can facilitate micro-interactions by starting the meeting early to allow for casual bantering, or schedule randomised video calls with tools like <a href="https://aboutsnack.com/" target="_blank" rel="noreferrer">Snack</a> &amp; Donut. <a href="http://downloads.hindawi.com/journals/ahci/2020/1827107.pdf" target="_blank" rel="noreferrer">Social serendipity</a> enhances innovation &amp; collaboration, and helps to instil an inclusive work culture. While nobody misses office gossip and other distractions, as social creatures we need these spontaneous encounters — may it be at our desks, in the pantry, along the corridor, or virtually.</p>
<p><span>
      <a href="https://aboutsnack.com/static/ec3a5fb53771cfc6a87c7518d11f7c10/c1b63/snack-meeting.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Randomly match with your coworkers for Snack-sized video calls!" title="Randomly match with your coworkers for Snack-sized video calls!" src="https://aboutsnack.com/static/ec3a5fb53771cfc6a87c7518d11f7c10/0a47e/snack-meeting.png" srcset="https://aboutsnack.com/static/ec3a5fb53771cfc6a87c7518d11f7c10/8a4e8/snack-meeting.png 150w,
https://aboutsnack.com/static/ec3a5fb53771cfc6a87c7518d11f7c10/5a46d/snack-meeting.png 300w,
https://aboutsnack.com/static/ec3a5fb53771cfc6a87c7518d11f7c10/0a47e/snack-meeting.png 600w,
https://aboutsnack.com/static/ec3a5fb53771cfc6a87c7518d11f7c10/1cfc2/snack-meeting.png 900w,
https://aboutsnack.com/static/ec3a5fb53771cfc6a87c7518d11f7c10/c1b63/snack-meeting.png 1200w" sizes="(max-width: 600px) 100vw, 600px" loading="lazy">
  </a>
    </span></p>
<p>Randomly match with your coworkers for Snack-sized video calls!</p></div></div>]]>
            </description>
            <link>https://aboutsnack.com/blog/5-easy-ways-to-boost-employee-wellness</link>
            <guid isPermaLink="false">hacker-news-small-sites-24136463</guid>
            <pubDate>Wed, 12 Aug 2020 20:23:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How cloud-native application testing is different from testing on-prem software]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24136317">thread link</a>) | @ohjeez
<br/>
August 12, 2020 | https://www.functionize.com/blog/5-ways-cloud-native-application-testing-is-different-from-testing-on-premises-software | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/5-ways-cloud-native-application-testing-is-different-from-testing-on-premises-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/07/ft-cloud-app-testing.jpg" alt="5 ways cloud-native application testing is different from testing on-premises software" srcset="https://www.functionize.com/wp-content/uploads/2020/07/ft-cloud-app-testing.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/07/ft-cloud-app-testing-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/07/ft-cloud-app-testing-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/07/ft-cloud-app-testing-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <blockquote><p>Cloud-native applications function differently from the software you deploy onsite. Testing the software works differently, too.</p></blockquote>
<p>As enterprise computing shifts to the cloud, so has software development, along with the tools and business processes that employ it. This means that your way of testing software has to change as well.</p>
<p>The term “cloud-native application” has muddy and sometimes contradictory definitions. For the purpose of this article, I default to the description from the <a href="https://www.cncf.io/" target="_blank" rel="noopener noreferrer">Cloud Native Computing Foundation</a>, founded in 2015 by the Linux Foundation: Cloud native applications are an open-source software stack that can be containerized where each part of the application is packaged in its own container, dynamically orchestrated so they are actively scheduled and managed to optimize resource utilization, and microservices-oriented to increase the overall agility and maintainability of applications.</p>
<p>Because of their dynamic nature, cloud-native applications run differently than do their on-premises elder brothers. Some things don’t change, of course, such as <a href="https://www.functionize.com/blog/the-challenges-of-testing-guis/">attention to user experience</a> and <a href="https://www.functionize.com/blog/understanding-user-acceptance-testing-for-better-results/">responding to users’ needs</a>. But other differences between cloud-native and the applications running in your data center suggest that you should <a href="https://www.functionize.com/blog/cloud-testing-what-why-and-how/">rethink the way you look for defects</a>. Here’s a summary of the testing adjustments you should consider.</p>
<h3>Use DevOps methodologies</h3>
<p>In a cloud application development environment, teams work in parallel instead of working independently of each other. Each team works on a different branches of an application or project, says Jason Bloomberg, president at <a href="https://intellyx.com/" target="_blank" rel="noopener noreferrer">Intellyx</a>, a cloud computing consultancy.</p>
<p>That introduces a new set of challenges for integration testing, which Bloomberg says is addressed by adopting a <a href="https://www.functionize.com/blog/aligning-bdd-with-continuous-delivery/">Continuous Integration/Continuous Delivery</a> (CI/CD) approach. Traditionally, people think in waterfall terms for testing. “But in the cloud it’s a continuous test phase,” he says. “Whatever you are doing with the code involves testing, and more testing has to take place. The cloud native approach says we have to test all the time, in an inherently dynamic and ephemeral way.”</p>
<p>Isaac Sacolick, president of consultancy <a href="https://www.starcio.com/" target="_blank" rel="noopener noreferrer">StarCIO</a>, echoes the importance of DevOps. “Development teams deploying to the cloud are more likely to pick DevOps tools and implement CI/CD and infrastructure as code (IaC),” he says. Developers also must invest in continuous testing. “It’s part of the DevOps culture, and the tools are more readily available for cloud-native applications.”</p>
<h3>Test with a component infrastructure in mind</h3>
<p>Cloud native applications operate in a dynamic, elastic, and distributed environment. They scale up for increased capacity and scale down when demand falls off. Moreover, the applications are loosely coupled, so they do not depend on infrastructure components.</p>
<p>For example, SOA and <a href="https://www.functionize.com/blog/challenges-benefits-automating-testing-microservices/">microservices</a> generates more individual components. For testers, that means, “You have to test each component individually as well as end-to-end workflow. That adds a new layer of decision making at a micro level and more end-to-end level testing,” says Sacolick.</p>
<p>Because cloud-native apps use so many services, you have to test against each individual service, turning them on and off, just as it occurs in the real world.</p>
<p>Test the software as a collective harmonic. “Think of it as a symphony,” says Sabourin. “Imagine tuning the orchestra without the brass, then with the brass but without the woodwinds.”</p>
<p>Testing a collection of resources, such as dozens of <a href="https://www.functionize.com/blog/the-fully-containerized-testing-strategy/">containerized applications</a>, means you have to test each application against every resource as well as each other. For example, in a scenario where 20 containers all use the same database, you should test how the database responds to every permutation of the collection. You might find, for example, that the combination of containers 2,4, 12, and 19 results in a significant performance problem. You will never know until you test against every possible combination.</p>
<p>Cloud-native software also changes the balance between functional and non-functional testing. Sure, you still care that the software meets user requirements. But, says Bloomberg, “Cloud-native application development places an additional emphasis on non-functional testing, where you ensure deployed software meets the non-functional requirements for scalability, flexibility, and resilience.”</p>
<h3>Get a troop of chaos monkeys</h3>
<p>Netflix introduced “chaos monkeys” for its system testing. On its live system – not test environment but production system! – Netflix randomly kills processes and watches how the system recovers. The goal of <a href="https://github.com/Netflix/chaosmonkey" target="_blank" rel="noopener noreferrer">chaos monkeys </a>is to test resiliency so you can be confident that your applications can tolerate random instance failures. (Its code is open source, in case you want to explore.) Customers are asked if they want to take part and can opt in, so no one is an unwilling guinea pig.</p>
<p>In other words, Netflix randomly causes chaos. “If you are doing your AWS job correctly, you are building in the failsafe to make sure it recovers. Forcing it to fail is one way to test how well it recovers,” says Rob Sabourin, software engineering consultant with AmiBug.com and adjunct professor at Montreal’s McGill University.</p>
<p>Let’s say you have a microservices environment with a thousand servers. “Go test a live system and crash the server on purpose,” Sabourin suggests. “If your system is designed well, another server will take over.”</p>
<p>This isn’t something you do on a staging server. For failure mode testing, you must be unafraid to do it on live systems. (Though obviously, not in situations where the test creates a life-threatening risk.)</p>
<h3>Beware fluid resources</h3>
<p>Traditional on-premises testing is done against known quantity of server resources. You know the server where the application resides, along with its CPUs, memory, and network bandwidth, and you can test against those expectations.</p>
<p>Cloud-native applications have the added challenge of never knowing just why kind of resources you are dealing with. There might be a particularly high load on your provider or you might have to deal with a proverbial “noisy neighbor.”</p>
<p>Because of this, we have unknown behaviors that are difficult to plan for due to the dynamic nature of the software and the cloud, and it’s hard to test against these abnormalities.</p>
<p>“In traditional testing you know how the infrastructure will behave. In cloud-native application development, you don’t know how it will behave and there are things you just can’t know about when writing code. So testing includes knowing cloud-native system requirements in production,” says Bloomberg.</p>
<p>The testing tools need to shift to observability, so they understand the behavior of the application, Bloomberg says. Observability leverages logs, traces, metrics, and events to provide SREs or other operators with active control over the operational environment, so they can identify and mitigate issues quickly, or ideally, prevent them from impacting users. “Ask, what is this software supposed to do? Then fix those problems,” he says.</p>
<h3>Consider rollback issues</h3>
<p>Services like Kubernetes permit you to dynamically change the versions of containers. The result is that developers working with cloud applications need to consider versioning in a different way, notes Sabourin.</p>
<p>When you deploy software, you are trusting that you can go back to the older version, Sabourin points out, including multiple versions of an application at the same time. “The question then becomes, ‘Can I roll back?’” he says.</p>
<p>That can get complicated. If container B contains a data set not found in container A or container C, what happens to that data found in container B? The takeaway: If you test a multi-version scenario, keep track of changes from one version to another.</p>
<h3>A shift in importance</h3>
<p>The cloud is a different world from software deployed to a datacenter, which means some things grow in importance while others fade. Among the nuances are security and penetration testing.</p>
<p>“The stakes are a little higher,” says Sacolick. “There are a few more risks when you put things in the cloud you that have to test for, like security, depending on whether the application is open-ended [user facing] or closed [non-user accessible].”</p>
<p>However, there are tradeoffs, including matters where you can give up personal responsibility for testing, such as in layers of infrastructure, Sacolick adds. “Serverless computing means you have no responsibility for the operating system and hardware infrastructure. You get an endpoint and deploy a code and everything is done for you. That’s fewer things you have to test for,” he says.</p>
<blockquote><p>While you’re contemplating process changes: Our white paper discusses <a href="https://www.functionize.com/project/5-levels-of-test-automation/">how to assess the level of automation your test tool provides</a>.</p></blockquote>
<div>
<div>
<p><img src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/author-Andy-Patrizio.jpg" alt="Andy Patrizio"></p>
<div>
<p><span>by</span> Andy Patrizio</p>
<p>Andy Patrizio has been covering the Silicon Valley (and everywhere else tech) for more than 25 years, having written for a range of publications that includes InformationWeek, Network World, Dr. Dobbs Journal, and Ars Technica. He is currently based in Orange County, California.</p>
</div>

</div>
</div>
  </div></div>]]>
            </description>
            <link>https://www.functionize.com/blog/5-ways-cloud-native-application-testing-is-different-from-testing-on-premises-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-24136317</guid>
            <pubDate>Wed, 12 Aug 2020 20:13:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sets and Probability]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24136233">thread link</a>) | @stopachka
<br/>
August 12, 2020 | https://stopa.io/post/243 | <a href="https://web.archive.org/web/*/https://stopa.io/post/243">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>I’ve been a big fan of Nassim Taleb’s Incerto. He wrote a series of essays on life, where all the topics revolve around decision making under uncertainty. I wanted to dig deeper on some of the more technical concepts he alluded too, so last year I explored a few textbooks on probability theory.</p><p>I was surprised with how elegant the field was. The most inspiring idea to me was how the originators interpreted probability through set theory. Not only is it a beautiful way to look at things, but by seeing it this way, they could apply few axioms, leverage set theory, and badabing badaboom they had a whole field’s worth of discoveries.</p><p>I wanted to share with you an example from one of the textbooks, that illustrated the power of seeing probability through this lens, and demonstrated how you could begin deriving complex ideas from the simplest kernel.</p><h2>Boxes and balls</h2><p><span><img src="https://stopa.io/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0LzgzMDUxODM5LTYwNThjZDgwLWEwMDMtMTFlYS04YjE0LWQ2ODhiZGY0Y2MwMC5wbmc" alt="image"></span></p><p>Let’s say you have 2 boxes. In Box 1, you have 99 red balls, and 1 white ball. In Box 2, you have 99 white balls, and 1 red ball.</p><p><strong>You pick a box at random, then, you pick a ball from that box.</strong></p><h2>Question 1: What’s the chance that you pick a red ball?</h2><h3>Memory</h3><p>This can get a bit tough to reason about. There’s a 50% chance you pick Box 1. In Box 1, you have a 99% chance. If you picked Box 2, you have a 1% chance. How do we combine these probabilities together?</p><p>If you reason the way you were taught in high school, you may think like this: </p><p>Well, there’s a 50% chance I pick Box 1, and a 99% chance after that to pick a red ball
And, there’s a 50% chance I pick Box 2, and a 1% chance after that to pick a white ball. </p><p>So the total probability can be <code>50% * 99% + 50% * 1%</code></p><p>Which is 49.5% + 0.5% which is…50% </p><p>Now this will work, but notice how the probability was 50% — Did you really need to do all that work to figure this out? (1)</p><h3>Intuition</h3><p>Let’s reimagine what <em>probability</em> here means. First, let’s consider: what are <em>all</em> <em>the possible outcomes</em>?</p><p>For out experiment, an outcome must contain two choices: The box we chose, and the ball we chose after that. We could represent it like this:</p><p><span><img src="https://stopa.io/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0LzgzMDUxODc0LTZlYTZlOTgwLWEwMDMtMTFlYS05YTNlLTA1MjEyY2MxM2M2OC5wbmc" alt="image"></span></p><p>This is <em>one outcome — we picked Box 1, then picked Red Ball 1.</em> </p><p>How many of these outcomes do we have?</p><p><span><img src="https://stopa.io/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0LzgzMDUxOTE2LTdiYzNkODgwLWEwMDMtMTFlYS05ZTU0LWE0ZWQzNzVhOTBkMS5wbmc" alt="image"></span></p><p>We can list it out: we pick Box 1, Red Ball 1, Box 1…Red Ball 99, etc. In total, we would have 200 possible outcomes. </p><p>Now that we have all the outcomes in mind, we can answer the question: <em>what’s the probability that we pick a red ball?</em></p><p>Well, how many outcomes contain a “red ball”? </p><p><span><img src="https://stopa.io/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0LzgzMDUxOTYwLTg4NDgzMTAwLWEwMDMtMTFlYS05NjVhLTczNGJiNjRlMDE3ZC5wbmc" alt="image"></span></p><p>Looks like 100. This means that 100 of 200 outcomes would give us the result “we got a red ball” — 100/200 makes 50%</p><p>Note how this boiled down to just “counting” the outcomes we cared about. Is it really that easy? Let’s try with a harder example.</p><h2>Question 2: You picked a red ball, what’s the probability that it came <em>from</em> Box 1?</h2><h3>Memory</h3><p>This question can get pretty hairy to answer from what we learned in high school. <em>Given</em> that we chose a red ball, what’s the chance that it was Box 1? Well, there are 99 red balls in Box 1, and only 1 red ball in Box 2, so the chance that it came from Box 1 is <em>very high.</em> But how high? </p><p>We may recall Bayes Theorem here, but the formula can be hard to remember.</p><h3>Intuition</h3><p>However, if we think in sets, we can <em>kind of</em> derive Bayes Theorem. Let’s look at our outcomes again:</p><p><span><img src="https://stopa.io/image/aHR0cHM6Ly9wYXBlci1hdHRhY2htZW50cy5kcm9wYm94LmNvbS9zX0RERUJEQUI4NDM4RTBDRTI1QkUzNjUyNDEyQ0NDNkE4NENCMEE2OTBBQjlFMTBGMzFFMzE0NENCRTE5NjJGOURfMTU5MDUyODI4MDUzNF9pbWFnZS5wbmc"></span></p><p>How many of these outcomes contain “red ball”?</p><p><span><img src="https://stopa.io/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0LzgzMDUyMTQ1LWJkZWQxYTAwLWEwMDMtMTFlYS04NGU3LTVlNDIzNzQ3N2VjNi5wbmc" alt="image"></span></p><p>Yup, 100 total. Since we <em>know</em> we got a red ball, this means that we could have <em>only gotten</em> one of these 100 outcomes.</p><p>Out of these outcomes, how many come from “Box 1”?  </p><p><span><img src="https://stopa.io/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0LzgzMDUyMTcyLWM2ZGRlYjgwLWEwMDMtMTFlYS04MTU3LTg0YWVjMjA4YTBlZi5wbmc" alt="image"></span></p><p>That's 99 outcomes. So out of 100 outcomes that could have happened, 99 of those came from Box 1. 99/100 and you have a 99% chance that given a red ball, it came from Box 1. </p><p>This too, just came down to counting the number of outcomes. Now, it can get a lot more difficult — what if you can’t possibly count the number of outcomes? what if each outcome has a different probability? But, just from this notion of events forming a set of possible outcomes, we can chug along and derive out quite a bit.</p><p>(1) Alexandre came up with a pretty beautiful intuitive solution to question 1: consider symmetry — since the problem is symmetric (you can reverse white and red), it implies the only solution could be 50%</p><p><em>Thanks to Daniel Woelfel, Alexandre Lebrun, Bipin Suresh, Mark Shlick, Davit Magaltadze for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/243</link>
            <guid isPermaLink="false">hacker-news-small-sites-24136233</guid>
            <pubDate>Wed, 12 Aug 2020 20:05:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Far-UV Light for Air Sanitization]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24136032">thread link</a>) | @apsec112
<br/>
August 12, 2020 | https://healthelighting.com/pages/sanitization-science | <a href="https://web.archive.org/web/*/https://healthelighting.com/pages/sanitization-science">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h6><a href="https://cdn.shopify.com/s/files/1/0774/5259/files/Fluence_Required_to_Achieve_Incremental_Log_Inactivation_of_Bacteria_Protozoa_Viruses_Algae.pdf?v=1587046221" target="_blank" title="FLUENCE (UV DOSE) REQUIRED TO ACHIEVE INCREMENTAL LOG INACTIVATION OF BACTERIA, PROTOZOA, VIRUSES AND ALGAE" rel="noopener noreferrer">FLUENCE (UV DOSE) REQUIRED TO ACHIEVE INCREMENTAL LOG INACTIVATION OF BACTERIA, PROTOZOA, VIRUSES AND ALGAE</a></h6>
<p>Authors: Malyeri A.H., Mohseni M., Cairns B., Bolton, J.R., Chevrefils G., Caron E.</p>
<hr>
<p>This paper advises the UV dose required to inactivate various pathogens, including bacteria, protozoa, viruses and algae based on the lamp type.</p>
<!-- <p><a class="button" href="https://cdn.shopify.com/s/files/1/0774/5259/files/Blue-enriched_Owens_Corning_2018_website.pdf?1419" target="_blank" rel="noopener noreferrer">Download Now</a></p> -->
</div><div>

<h6><a href="https://cdn.shopify.com/s/files/1/0774/5259/files/Germicidal_Efficacy_and_Mammalian_Skin_Safety_of_222-nm_UV_Light.pdf?v=1587046216" target="_blank" title="GERMICIDAL EFFICACY AND MAMMALIAN SKIN SAFETY OF 222-NM UV LIGHT" rel="noopener noreferrer">GERMICIDAL EFFICACY AND MAMMALIAN SKIN SAFETY OF 222-NM UV LIGHT</a></h6>
<p>Authors: Manuela Buonanno, Brian Ponnaiya, David Welch, Milda Stanislauskas, Gerhard Randers-Pehrson, Lubomir Smilenov, Franklin D. Lowy, David M. Owens, and David J. Brenner</p>
<hr>
<p>This study discusses the germicidal effects of 222nm (Far-UV) light, which is significantly harmful to bacteria, but demonstrates no harm to human cells.</p>
</div><div>

<h6><a href="https://cdn.shopify.com/s/files/1/0774/5259/files/Kobe_University_222nm_UV_Apr_2020.pdf?v=1589564434" target="_blank" title="GERMICIDAL EFFICACY AND MAMMALIAN SKIN SAFETY OF 222-NM UV LIGHT" rel="noopener noreferrer">LONG TERM EFFECTS OF 222 NM ULTRAVIOLET RADIATION C STERILIZING LAMPS ON MICE SUSCEPTIBLE TO ULTRAVIOLET RADIATION</a></h6>
<p>Authors: Nozomi Yamano, Makoto Kunisada, Sachiko Kaidzu, Kazunobu Sugihara, Aiko Nishiaki-Sawada, Hiroyuki Ohashi, Ai Yoshioka, Tatsushi Igarashi, Akihiro Ohira, Masaki Tanito, and Chikako Nishigori</p>
<hr>
<p>This study focuses on the human safety in regards to long term exposure of 222nm (Far-UV) light and suggests 222nm FAR-UVC lamp can be safely used on humans</p>
</div></div>]]>
            </description>
            <link>https://healthelighting.com/pages/sanitization-science</link>
            <guid isPermaLink="false">hacker-news-small-sites-24136032</guid>
            <pubDate>Wed, 12 Aug 2020 19:48:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moments of Attention]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24135716">thread link</a>) | @slmnmls
<br/>
August 12, 2020 | https://www.jimmckelvey.com/moments-of-attention/ | <a href="https://web.archive.org/web/*/https://www.jimmckelvey.com/moments-of-attention/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
					<article id="post-148">
							

			<div>
				<div>
					<div>
						

						<div>
							<div>
								
<h4><strong>Selling the future is hard.&nbsp;</strong> <br>Imagine a new invention that is superior to what we have now.&nbsp; This product is so much better than everything else that you only need to show it to a potential customer to close the sale.&nbsp; Sounds easy to sell, right?&nbsp; </h4>



<p>Back in 1987 the Canon company, who built the first laser
printers, did a study and found two types of people:&nbsp; those who had never heard of laser printers,
and laser printer owners.&nbsp; The laser
printer was so superior to current printer technology in output, cost, speed,
sound, size, maintenance, and paper handling that anyone who had seen one had
also bought one.&nbsp; The Canon salesforce
was euphoric, until they learned just how difficult it was to actually get
people’s attention.&nbsp; As someone who has
often failed to sell truly superior products, I understood their pain.</p>



<p>You might think that everyone would be open to better ways,
but not really.&nbsp; We have all been burned
by promises of miracle products so often that words like <em>superior</em>, <em>new</em>,
and <em>better</em> have all just become toothpaste adjectives.&nbsp; But what if you really do have something
better?&nbsp; You actually need someone’s
attention.&nbsp; </p>



<p>In the early 1990’s, I had such a product.&nbsp; My company, Mira Digital Publishing, had
developed a way of collecting, curating, and editing scientific papers that was
so vastly superior to the current process that anyone who heard about it would
buy it.&nbsp; There really was no selling
involved, just a demonstration and a handshake.&nbsp;
But getting a new customer involved getting someone to first consider
that there might be a better way.&nbsp; And
that was hard.&nbsp; </p>



<h4><strong>Can I have you attention please?</strong></h4>



<p>My greatest frustration at the time was the Institute of Transportation Engineers.&nbsp; The ITE was an organization in Washington DC that decided the optimal radius for a highway curve or what shade of red to make a stop sign.&nbsp; My product would save them millions of dollars, but after a year and a half of attempts I could not get them to take a look.&nbsp; I could not schedule an appointment; phone calls fell on deaf ears; emails were ignored.&nbsp; Even physical cold-calls failed – at least my first three did.&nbsp; Then one day I found myself across the street from ITE with two hours before my next appointment.&nbsp; I decided to try again.</p>



<p>The ITE lobby was typical: at the receptionist’s desk a
descendant of Cerberus guarded two glass doors, one leading to the offices and
another to a conference room.&nbsp; There was
also a couch and chair where you could sit before being told that someone was
too busy to see you. This was my fourth cold call, but this time the
receptionist was absent.&nbsp; I was alone in
the lobby watching a group of women having what appeared to be some sort of
party in the conference room. Before the rectangular piece of cake arrived, I
had a crazy idea.&nbsp; </p>



<p>I was wearing my meet-with-the-Government suit, and carrying
a leather briefcase.&nbsp; I walked into the
conference room like a stern teacher entering a chaotic classroom, no smile, no
expression whatever.&nbsp; I put my briefcase
in the middle of the table.&nbsp; Then I turned
the radio dial from office-safe adult contemporary to the edgiest hip-hop
station I could find.&nbsp; Volume UP!</p>



<p>I still don’t say a word.&nbsp;
I just start grinding to the music. My audience begins to clap
rhythmically. I start taking off my clothes, beginning with my necktie and
working my way down. I throw my jacket to the screaming women; and just as I
rip my shirt off, I stare at my watch, a tiny analog Rado. </p>



<p>I ask the nearest lady,&nbsp; “Is it 1:30 <em>AM</em> or 1:30 <em>PM</em>?” </p>



<p>She replies, “It’s 1:30 PM.” </p>



<p>And I say, “Oh my god, I’ve got my jobs confused! I’m
actually here to sell you software!”</p>



<p>Everybody bursts out laughing. I act embarrassed and ask for
my shirt back. As another lady is retrieving my necktie from the light fixture
I say, “Oh yeah, I’m here from Mira Digital Publishing. We make software that
automates the collection and review of technical papers. I’m here to talk to
your boss.” </p>



<p>Three women run down the hall to the executive director.
They literally drag him into the room and now <em>I’ve finally got everyone’s
attention</em>.&nbsp; I set an appointment to
come back fully clothed next week, and they sign a six-figure annual
contract.&nbsp; </p>



<h4><strong>So what has changed? </strong></h4>



<p>They have the same needs and we have had the same solution for the past eighteen months; but during that time I never had their attention.&nbsp; A few busted buttons is a small price to pay to deliver an important message.</p>



<p><em>New doesn’t count until people notice.</em></p>
							</div>
						</div>
					</div>
				</div>
			</div>

			

		</article>
		</div></div>]]>
            </description>
            <link>https://www.jimmckelvey.com/moments-of-attention/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24135716</guid>
            <pubDate>Wed, 12 Aug 2020 19:21:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we used Postgres extended statistics to achieve a 3000x speedup]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24135649">thread link</a>) | @adamperelman
<br/>
August 12, 2020 | https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61 | <a href="https://web.archive.org/web/*/https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://build.affinity.co/@jaredrulison?source=post_page-----ea93d3dcdc61----------------------" rel="noopener"><img alt="Jared Rulison" src="https://miro.medium.com/fit/c/96/96/0*3FU0njiCnLnXkMYC.jpg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3056/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg" width="1528" height="840" srcset="https://miro.medium.com/max/552/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 276w, https://miro.medium.com/max/1104/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 552w, https://miro.medium.com/max/1280/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 640w, https://miro.medium.com/max/1400/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg?q=20"></p></div></div></div><figcaption>Go on. Guess.</figcaption></figure><p id="add9">Much like the DMV, the PostgreSQL query planner is a powerful, mysterious entity to whom we semi-blindly entrust our well-being. It has the crucial responsibility of picking the most efficient execution plan for every query. Here we’ll explore what data Postgres takes into account when creating query plans, and how we used that context to help the query planner come up with more efficient plans for some of our most important query patterns.</p><p id="2dce">Here’s an example slow query issued from our web server, along with the inefficient query plan that Postgres chose. Can you spot the key mistake the query planner made?</p><figure><div></div></figure><p id="3e61">By far the most expensive step is the second Nested Loop Join:</p><p id="26ca"><code>Nested Loop Semi Join (cost=1.01..25.07 rows=1 width=4) (actual time=0.079..122074.806 rows=1958 loops=1)</code>.</p><p id="2594">Postgres estimated that this step would return about 1 row, which was a wild underestimate — it actually returned 1958 rows and took about 122 seconds. (See <a href="https://thoughtbot.com/blog/reading-an-explain-analyze-query-plan" target="_blank" rel="noopener">here</a> for more background on how to interpret Postgres query plans.)</p><p id="418b">Through informed use of Postgres statistics, we brought the time for this query down<strong> from 2 minutes to 42 milliseconds — </strong>almost a 3000x speedup! Before we dive into the stats adjustments that we made, let’s make sure we understand how the Postgres planner works.</p><h2 id="b700">Basic Statistics</h2><p id="2225">Statistics are data collected by Postgres used to inform its selection of query plans. Out of the box, Postgres samples the possible values for each column of each table to create histograms and a list of the most common values (among other things). These are used to estimate how many rows will result from applying some set of filters to a table.</p><p id="e362">For larger tables, the planner can’t keep track of every single value a column holds. Instead, it samples the values of each column and uses those to make estimations. We can tweak how much sampling Postgres does for each column on each table with</p><p id="db5b"><code>ALTER TABLE table ALTER column SET STATISTICS {-1 ..10000}</code></p><p id="6e31">where -1 sets it to the default value of 100 (<a href="https://www.postgresql.org/docs/12/planner-stats.html" target="_blank" rel="noopener">docs</a>). This number sets how many buckets are used in the histogram and how many of the most common values are stored.</p><p id="9134">The downsides to increasing the statistics for a column are that more data must be stored in <code>pg_statistic</code> and running <code>ANALYZE</code> on the column's table takes longer.</p><p id="7f91">More details can be found in <a href="https://www.postgresql.org/docs/12/row-estimation-examples.html" target="_blank" rel="noopener">the Postgres docs</a>.</p><h2 id="b5e8">Extended Statistics</h2><p id="8726">Extended statistics are user-defined objects that tell Postgres to collect certain kinds of data for sets of columns, rather than individual columns.</p><p id="e580">Without extended statistics, Postgres estimates the impact of filters on a table by considering each filter independently. For example, consider a database containing 10 Artist records, each of which has 10 Album records referencing it, each of which has 10 Songs referencing that. This totals to 10 Artists, 100 Albums, and 1,000 Songs. Now, consider running the following query:</p><p id="07b3"><code>SELECT * FROM songs WHERE (artists_id = 1 and album_id = 1);</code></p><p id="a3e9">With perfect sampling, the query plan might look like</p><pre><span id="552c">Index Scan using songs_artists_id_album_id_index on songs  (cost=0.28..6.05 rows=1 width=159) (actual time=5.555..5.562 rows=10 loops=1)<br>   Index Cond: ((artists_id = 1) AND (album_id = 1))<br> Planning Time: 311.482 ms<br> Execution Time: 9.266 ms<br>(4 rows)</span></pre><p id="c78c"><code>(cost=0.28..6.05 rows=1 width=159)</code> refers to the planner's estimations while <code>(actual time=5.555..5.562 rows=10 loops=1)</code> refers to the actual results of the executing the plan. The planner estimated 1 row would be returned, but there were actually 10.</p><p id="c03a">The planner calculated its row estimate by first taking the total number of Songs (1000), then considering the <code>artists_id</code> filter. 10% of Songs have <code>artists_id = 1</code> so that leaves 100 Songs. Next it considers the <code>album_id</code> filter. 1% of Songs have <code>album_id = 1</code>, so it's left with 1 Song.</p><p id="b69b">The key piece of information Postgres is missing is that <code>artist_id</code> and <code>album_id</code> are strongly correlated. In fact, knowing the <code>album_id</code>uniquely determines the <code>artist_id</code>. Had Postgres known about this, it could have used only the <code>album_id = 1</code> filter in its estimation and come up with the correct result of 10 Songs.</p><p id="a995">This kind of correlation can be indicated to Postgres using a dependency statistic. This statistic stores the frequency with which each column uniquely determines the other column. A dependency statistic on <code>(artist_id, album_id)</code> might yield the following:</p><pre><span id="53d4">CREATE STATISTICS album_id_artist_id_dep_stt (dependencies) ON album_id, artist_id FROM songs;</span><span id="709a">ANALYZE songs;</span><span id="d112">SELECT stxname, stxkeys, stxddependencies<br>  FROM pg_statistic_ext join pg_statistic_ext_data on (oid = stxoid)<br>  WHERE stxname = 'stts';<br> stxname | stxkeys |             stxddependencies             <br>---------+---------+------------------------------------------<br> stts    | 1 5     | {"1 =&gt; 5": 0.1, "5 =&gt; 1": 1.0}<br>(1 row)</span></pre><p id="6cf7">The 1 and 5 under <code>stxkeys</code> and <code>stxddependencies</code> refer to the 1st and 5th columns on the <code>songs</code> table, which are <code>artist_id</code> and <code>album_id</code>, respectively. The value for "1 =&gt; 5" is 0.1 since <code>artist_id</code> determines <code>album_id</code> 10% of the time. The value for "5 =&gt; 1" is 1.0 since <code>album_id</code> always determines <code>artist_id</code>. When Postgres is filtering by columns with a matching dependency statistic, it’s able to use that to make a more accurate estimation.</p><p id="7487">There are, of course, <a href="https://www.postgresql.org/docs/12/planner-stats.html" target="_blank" rel="noopener">other kinds of extended statistics</a> but a dependency statistic makes the most sense for this kind of data distribution.</p><p id="7db1">One caveat of extended statistics is that Postgres only knows to use them when filtering on exactly the columns referenced in the statistic and when filtering using simple equality conditions, e.g. <code>artist_id = 5</code> and not <code>artist_id IN (5, 6)</code> or <code>artist_id &lt; 10</code>.</p><p id="824b">Use of extended statistics can lead to non-intuitive index choices. If a dependency statistic indicates to Postgres that a column filter is redundant, as in the case of <code>artist_id</code>and <code>album_id</code>, it may opt to use an index that only references one of the columns. In the case of <code>songs</code>, it may use an index on only <code>(album_id)</code> instead of an index on <code>(artist_id, album_id)</code> if both are present.</p><h2 id="ec96">Join Strategies</h2><p id="12ff">There are <a href="https://www.postgresql.org/docs/12/planner-optimizer.html" target="_blank" rel="noopener">three options</a> Postgres has for joining tables:</p><ol><li id="299a">Nested Loop Join. Using this join strategy, Postgres loops through each row in the left relation and scans through the right relation for rows that satisfy the join condition, ideally using an index. This is an effective strategy for when there are very few rows in the left relation.</li><li id="c08c">Merge Join. From <a href="https://www.postgresql.org/docs/12/planner-optimizer.html" target="_blank" rel="noopener">the docs</a>: “each relation is sorted on the join attributes before the join starts. Then the two relations are scanned in parallel, and matching rows are combined to form join rows. This kind of join is more attractive because each relation has to be scanned only once. The required sorting might be achieved either by an explicit sort step, or by scanning the relation in the proper order using an index on the join key.”</li><li id="f1e5">Hash Join. From <a href="https://www.postgresql.org/docs/12/planner-optimizer.html" target="_blank" rel="noopener">the docs</a>: “the right relation is first scanned and loaded into a hash table, using its join attributes as hash keys. Next the left relation is scanned and the appropriate values of every row found are used as hash keys to locate the matching rows in the table.”</li></ol><p id="8865">For our purposes, the main thing to note here is that the advantage of a Nested Loop Join is that there’s very little overhead compared to the other join strategies. However, this join can go wrong if there are many rows in the left relation. For example, suppose there are 1,000 rows in the left relation and Postgres is using an index to access the right relation. If each index access takes 4ms, the entire join will take 4s, which is too slow in the context of responding to a user request.</p><p id="c5b5">Now that we understand the different type of joins, let’s revisit the Nested Loop Join that struck us as problematic. Without going into too much detail about our data model at Affinity, all you need to know is that on our tables <code>entity_values</code> and <code>lists_entries</code>, the column <code>org_id</code> is uniquely determined by <code>list_id</code> or <code>entity_attribute_id</code>, meaning that in order to estimate the selectivity of a set of filters on these columns, the filters should not be considered individually. <strong>Our slow queries were the result of Postgres underestimating the number of rows that would result from applying a filter condition and opting to use a nested loop join because of that underestimation.</strong></p><h2 id="4244">Actions Taken</h2><p id="edb4">Let’s look back at our original problem query. By far, the most costly step was looping over the index access to <code>entity_values_org_id_entity_attribute_id_company_id_index</code> a whopping 13,769 times.</p><p id="f8ca">To encourage the planner to use a different join strategy, we needed to improve its estimates for filters on <code>lists_entries</code> and <code>entity_values</code>. Based on the filters applied, we maxed out the per-column statistics for:</p><pre><span id="099f">lists_entries:<br>- org_id<br>- list_id</span><span id="cee2">entity_values:<br>- org_id<br>- entity_attribute_id</span></pre><p id="3c24">among other tables and columns for different query patterns.</p><p id="5f14">We also added dependency statistics on:</p><pre><span id="8495">lists_entries (list_id, org_id)<br>entity_values (entity_attribute_id, org_id)</span></pre><p id="5a2b">among other dependency statistics for other tables and columns, since both <code>list_id</code> and <code>entity_attribute_id</code> uniquely determine the <code>org_id</code>.</p><p id="c28c">After we made these adjustments, Postgres chose the following query plan for our original query:</p><figure><div></div></figure><p id="3a3d">Here, the estimates are much more accurate and the planner opted for a hash join for the inner join — and the query took 42 milliseconds instead of the original 2 minutes.</p><p id="54b4">Increasing the per-column statistics and adding dependency statistics have helped tremendously, but there is still progress to be made. As you may have noticed in the improved query plan, the planner underestimates the number of rows resulting from the inner join. While the outer nested loop join didn’t take long this time, it’s not hard to imagine a query where the inner join results in many rows and the outer join becomes a bottleneck.</p><p id="f2fd">We hope this post has given you some ideas about how to improve your query plans, or at the very least taught you something about the magic of Postgres!</p></div></div></section></div></div>]]>
            </description>
            <link>https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61</link>
            <guid isPermaLink="false">hacker-news-small-sites-24135649</guid>
            <pubDate>Wed, 12 Aug 2020 19:13:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dishwashing detergent hack: Two ingredients (2015)]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 284 (<a href="https://news.ycombinator.com/item?id=24135619">thread link</a>) | @superasn
<br/>
August 12, 2020 | https://www.whatlisacooks.com/blog/2015/5/8/dishwashing-detergent-hack-two-ingredients | <a href="https://web.archive.org/web/*/https://www.whatlisacooks.com/blog/2015/5/8/dishwashing-detergent-hack-two-ingredients">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-6bd2e7a7516b7db5982c"><div><p>I don't know about you, but running out of dishwasher detergent and not being able to do the dishes is just not an option around here. Getting behind on the dishes might be worse than getting behind on the laundry (which happens too often). &nbsp;But what to do when it's late at night and you go to the cabinet and realize you're out of dishwasher detergent? A late night grocery store run sounds like about the last thing I want to do, and waking up to a mountain of dirty dishes sounds even worse. There has to be a solution.&nbsp;</p><p>Have you seen any of these recipes online for making your own dishwasher detergent? &nbsp;They sound interesting, but a lot of them call for stuff that I just don't normally keep around my house, or stuff that I'm not sure I'm comfortable putting on my dishes&nbsp;(Borax, Oxy-Clean, etc.), or they require you mixing up some big recipe of stuff, which I'm not doing late at night.</p><p>But I saw one recently that called for just dish soap and baking soda. &nbsp;Things I always have. So of course I had to try it.</p><p>We run our dishwasher at least twice a day here, and often three times on weekends. With 6-8 people at every meal, everything homemade,&nbsp;we go through a lot of dishes! And so we also go through a LOT of dishwasher detergent. &nbsp;I try to buy a more natural brand, because when I open the dishwasher and I am hit in the face with a strong chemical smell, I just don't think that sounds like a good idea. If there's that much strong chemical odor left in the steam that comes out of the dishwasher, then I'm pretty sure that it's on my dishes too, and I just don't like the idea of that. So I try to go for a dishwasher&nbsp;detergent that is a little lighter on the chemicals. &nbsp;But those kinds are expensive, and for some reason they come in very small packages. &nbsp;I buy like 4 or 5 packages at a time, just to make sure we don't run out. &nbsp;</p></div></div><div data-block-type="2" id="block-yui_3_17_2_5_1431111680998_24708"><div><p>But what if we do run out? &nbsp;That would be an emergency! So when I came across this idea for running the dishwasher with just regular other household stuff, I had to know if it worked!</p><p>I had to.</p><p>And you know what? &nbsp;IT WORKS!!</p><p>I've been doing this every day this week. &nbsp;I run the dishwasher twice a day usually during the week, so I've been doing one load with our regular detergent and one load with this homemade combo. &nbsp;I've stuck with the regular detergent for the load that we run after dinner, since it's running at night and I'm not keeping an eye on it, and I've tried this new method for the load I run while I am home during the day - just in case I had any kind of over-sudsing incident.&nbsp;</p><p>And I can honestly tell you the results are identical. I&nbsp;haven't noticed any difference in the dishes between the two methods. &nbsp;The loads with the homemade detergent are just as clean as the loads with the packaged detergent. &nbsp;I haven't added up the costs yet, but I can pretty much assure you that a bottle of dish soap and a big package of&nbsp;baking soda&nbsp;are going to be a heck of a lot cheaper than the expensive detergent tablets that I've been buying.&nbsp;</p></div></div><div data-block-type="2" id="block-yui_3_17_2_5_1431111680998_25482"><div><p><strong>The recipe:</strong></p><ul data-rte-list="default"><li><p>A couple tablespoons of baking soda</p></li><li><p>A few drops, or a small squirt, of Dawn dish soap.</p></li></ul><p><strong>Directions:</strong></p><p>Fill your detergent cup with baking soda, you don't have to be precise, but with mine this ends up being a couple of heaping tablespoons. Then add a few drops of dish soap. I have a pump dispenser for my dish soap, so I just put about half a squirt in there. Close the cover, and run dishwasher as usual. That's all.&nbsp;</p><p>I experimented with quantity of dish soap. &nbsp;The first few recipes I read said just 2 drops, but that just didn't feel like enough to me, to really get a very full load clean. &nbsp;So I gradually added a little more until I felt comfortable. &nbsp;I haven't yet found an upper limit, but I haven't pushed it too far.</p><p>The baking soda is VERY important here. Don't try this without it!&nbsp;It keeps the soap from forming suds. &nbsp;The reason they tell you never to use liquid dish soap in your dishwasher is because of the suds - you'll have bubbles all over your floor. &nbsp;But the baking soda apparently prevents that, so it allows the soap to do the grease cutting and cleaning, without making all those bubbles. I've opened my dishwasher at various points in the cycles to see what's going on in there, and there are no bubbles.&nbsp;I'm not scientist, so I'm not going to try to figure out why any of this happens. &nbsp;All I know is, my dishes are getting clean and I don't have soap all over my floor and I didn't have to buy dishwasher detergent.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_5_1431111680998_28310"><div><p>I have not tried this with other brands of dish soap. &nbsp;I've tried lots of other brands of liquid dish soap for hand washing, and I keep coming back to Dawn, so that is what I used for this. &nbsp;The more natural and/or less expensive brands just don't work as well. &nbsp;I found that I was having to use so much more soap to just wash a sink full of dishes, that it just wasn't worth it.&nbsp;</p><p>I pour my dish soap into a pump dispenser that I keep next to my sink. &nbsp;I like this one because the spout extends out far enough that you can just pump it right into the sink.&nbsp;</p><p>So that's it. &nbsp;Dish soap &amp; baking soda! &nbsp;Let me know if you try it!</p></div></div></div>]]>
            </description>
            <link>https://www.whatlisacooks.com/blog/2015/5/8/dishwashing-detergent-hack-two-ingredients</link>
            <guid isPermaLink="false">hacker-news-small-sites-24135619</guid>
            <pubDate>Wed, 12 Aug 2020 19:10:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understand HTTP3 in 5 Minutes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24135554">thread link</a>) | @jesuisundev
<br/>
August 12, 2020 | https://www.jesuisundev.com/en/understand-http3-in-5-minutes/ | <a href="https://web.archive.org/web/*/https://www.jesuisundev.com/en/understand-http3-in-5-minutes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
<!-- Horizontal Top Article -->
<p>You haven’t quite figured out HTTP2 yet that you’re already starting to get pissed off by people talking about HTTP3. But there’s a reason for that: HTTP3 is fast. I bet you in five minutes you’ll agree with me. </p>



<h3>Once upon a time</h3>



<p>I can’t tell you about the future without telling you about the present. <strong>Do you know about HTTP ?</strong> Defined in 1991, it’s the protocol that manages the web. It means <a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol" target="_blank" rel="noreferrer noopener">HyperText Transfer Protocol</a> and it allows you to fetch resources from a web page. </p>



<p>From a web server to your browser. It’s built on a lower level protocol –<strong>TCP: it’s going to be important-</strong> and it’s stateless. It means that each request is completely independent. Each GIF present on this page is a GIF proudly independent in its life on the internet. That’s good for him and his life as a GIF. But for us it’s a bit of a broken system.</p>



<p>Because the problem is that <strong>each request will only look for one file at a time</strong>. Each time an expensive TCP connection is created for the occasion. Imagine if you had 10,000 Internet tips on your page.</p>



<p> I know a lot of people absolutely loved my pattern making skills in the previous article. So, to explain the Internets to you properly, I’m doing it again.</p>



<div><figure><img src="https://i.imgur.com/iI0MrHF.jpg" data-src="https://i.imgur.com/iI0MrHF.jpg" alt="http"></figure></div>



<p>Despite the fact that a browser can make six different requests at the same time, HTTP is still slow and full of TCP connections. Plus, we developers, usualy don’t care about that. <strong>We like to put as much crap on our pages as possible. </strong>Big jQuery lib with 300 useless CSS stylesheets ending with a big transparent 8 mega PNG. </p>



<p>When Google saw all the crap we were doing everywhere <strong>they started talking about SPDY</strong> (it’s called speedy). The point? To speed up the Internets. </p>



<p>SPDY is a specification that proposes to use HTTP as is but with a change of rules. And by <strong>compressing headers, prioritizing requests and multiplexing</strong>, it will transform all TCP requests and connections into one! </p>



<p>Concretely, when your HTML is read, your browser looks at everything you’re going to ask in your page. Then, it’s getting everything all at once. <strong>This way you avoid doing it file by file.</strong> </p>



<p>The first draft of HTTP2 is SPDY based. Very quickly HTTP2 was adopted and life on the internet has become faster. <strong>Today <a href="https://w3techs.com/technologies/details/ce-http2" target="_blank" rel="noreferrer noopener">42.7% of the internet</a> use HTTP2.</strong></p>



<div><figure><img src="https://i.imgur.com/2jePyHC.jpg" data-src="https://i.imgur.com/2jePyHC.jpg" alt="http2"></figure></div>



<h3>Great, what about HTTP3?</h3>



<p>If I piss you off with HTTP and HTTP2 when you explicitly clicked to see sexy HTTP3, there’s a good reason. HTTP2 was created by taking HTTP as a base and changing the rules.<strong> It’s the same thing with HTTP3. </strong>So by understanding the present it’s easier for me to explain the future to you.</p>



<p>Googlers are geeks, they never stop. After SPDY became HTTP2, they thought that it was still not fast enough. So they started talking about QUIC (it’s called Quick). <strong>This will be the second experimental technology developed by Google to become an official upgrade of the HTTP protocol</strong>. But what’s so special about this protocol?</p>



<p>The main big evolution of HTTP3 is the change of transport layer. No more of the heavy TCP connections I’ve been telling you about since the beginning. <strong>Now, it’s all about UDP. </strong></p>



<p>By the way QUIC means “Quick UDP Internet Connections”. This change of protocol will speed up connection establishment and data transfer times enormously. Howerver, <strong>UDP is certainly faster and simpler, but it doesn’t have the reliability and error handling of TCP.</strong></p>



<p>TCP has to make several round trips just to establish a connection in a square and stable way. <strong>Where UDP doesn’t give a damn and does it really fast without stability and risk of lost packets. </strong>However UDP can dramatically reduce latency in requests. Up to almost zero latency in repeated connections to the same server because no roundtrip is made to establish connections.</p>



<figure><img src="https://i.imgur.com/hDmNkpS.png" data-src="https://i.imgur.com/hDmNkpS.png" alt="http3"></figure>



<p>HTTP3 is the multiplexing and compression features of HTTP2 with a protocol change from TCP to UDP. The Google guys then added their layer in the protocol to guarantee stability, order in the reception of packets and of course security. </p>



<p><strong>So HTTP3 uses UDP for its high speed while keeping the stability of QUIC</strong>, without forgetting the security of TLS. Because yes, in QUIC you find TLS 1.3 which allows you to make your beautiful SSL. I’ve been talking about layers for a while, this is what it looks like under the hood.</p>



<figure><img src="https://i.imgur.com/QdNsQHL.jpg" data-src="https://i.imgur.com/QdNsQHL.jpg" alt="http3"></figure>



<p>In 2018, QUIC became HTTP3. The Internet Enginerring Task Force dudes, <a href="https://www.youtube.com/watch?v=uVf_yyMfIPQ&amp;t=4956" target="_blank" rel="noreferrer noopener"><strong>dudes in shorts who decide on Internet protocols</strong></a>, have agreed. And that’s great news because the Internets will never be fast enough for us, impatient people.</p>



<h3>Epilogue</h3>



<p>HTTP3 is the sexy future with a HTTP base that has been tuned to the maximum by google geeks. At the time of writing, <a href="https://w3techs.com/technologies/details/ce-quic" target="_blank" rel="noreferrer noopener">only 4.6% of the Internet uses HTTP3</a> but this figure is likely to grow in the coming years. We stayed on the surface today, but there are a lot of deep-dive articles everywhere that I invite you to consult if you’re more curious.</p>

			<!-- clearfix -->
			

			
		</div></div>]]>
            </description>
            <link>https://www.jesuisundev.com/en/understand-http3-in-5-minutes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24135554</guid>
            <pubDate>Wed, 12 Aug 2020 19:03:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Homemade tamper-evident security seals for kids and adults alike (2017)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24135355">thread link</a>) | @strangecasts
<br/>
August 12, 2020 | http://blog.ssokolow.com/archives/2017/04/08/home-made-tamper-evident-security-seals-for-kids-and-adults-alike/ | <a href="https://web.archive.org/web/*/http://blog.ssokolow.com/archives/2017/04/08/home-made-tamper-evident-security-seals-for-kids-and-adults-alike/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>Suppose you need to keep siblings, roommates, children, or even friends with wandering hands out of something, but you can’t use a lock. Maybe you’re worried they’ll find the key, maybe you need something that has no metallic parts, or maybe you’re a kid and your parents are worried you will lose the key.</p>
<p>This is the kind of thing numbered security seals are good for… but they’re expensive. (The cheapest I’ve found are roughly 50¢ each in packs of 100 or more)</p>
<p>…so I decided to do a little experimentation and came up with a cheap-but-reliable solution for homemade tamper seals that’s so simple and safe that even children can do it.</p>
<h2>Instructions</h2>
<h3>Step 1: Making the seals</h3>
<p>The most important thing about a security seal is that it’s unique, so it can’t be replaced, and either can’t be reclosed after being opened or you’ll notice if it is.</p>
<p>To satisfy these requirements with paper, we need to print or write something on the paper which other people can’t reproduce and which will look wrong if someone cuts and re-glues the seal.</p>
<p>If you’ve got a printer, you could print out a random image from the Internet, delete the file and empty your browser history, then cut strips from it to use as seals, but Inkjet ink tends to cost a fortune and most people don’t have laser printers.</p>
<p>What I recommend is this: Cut strips from a piece of paper, then sign and doodle all over both sides of them so any cuts or complete replacement will be obvious. (You do it on both sides, so that you can easily see if someone mends a cut by glueing another piece of paper to the inside of the loop.)</p>
<p>Don’t forget to use your scissors to make the ends of the strip round, rather than square, so it’s harder for someone to attempt to pick at the joint&nbsp;if they want to try to peel it apart.</p>
<h3>Step 2: Applying the seals</h3>
<p>To apply the seal, you just need to pass it through or around whatever you want to seal (eg. cabinet handles) and then glue it into a loop. (a tight loop, if you’re securing knob-shaped cabinet handles, so it can’t be lifted off without breaking it.)</p>
<p>If you want to seal a box, try gluing several strips together into a shape similar to the ribbon on a Christmas present.</p>
<p>It’s the details which make it tamper-evident:</p>
<ol>
<li>Get a bottle of Polyvinyl Acetate glue (A.K.A. white glue, school glue, PVA).</li>
<li>Apply a enough glue to one end of the strip that, when squeezed, it won’t leave unglued corners.</li>
<li>Close the loop and squeeze the ends together for at least five seconds, as hard as you can.</li>
<li>Wait at least 5 minutes, but ideally 10 minutes.</li>
</ol>
<h3>Step 3: Making the seals tougher</h3>
<p>Supposing you’re trying to keep really clever people from sneaking access, there are two more tricks you should get an adult to do:</p>
<ol>
<li>Paint the glued part with clear nail polish to waterproof it, so nobody can try to invisibly open the seal by steaming the glue. (This also makes it harder to try to pick apart.)</li>
<li>Cut some diagonal stripes into the glued spot using a utility knife to absolutely guarantee that any attempt to peel apart the glue will result in obvious tearing.</li>
</ol>
<h2>The “Why”</h2>
<p>I was very specific in my instructions, because I actually did a lot of testing. If you want to repeat my tests yourself, here’s what I did:</p>
<h3>Goals</h3>
<ol>
<li>A successful seal must not have the glue fail when pulling on both ends of the glued joint.</li>
<li>A successful seal must show obvious damage when someone tries to pick and peel at the glued joint.</li>
<li>A successful seal must have the paper visibly fail before the glue if a solvent is applied to the glued joint.</li>
</ol>
<h3>Methodology</h3>
<ol>
<li>Cut a bunch of paper strips, approximately 3″ long.</li>
<li>Glue pairs of strips into longer strips, using various test glues.</li>
<li>On each glued strip, write the time the process was finished, so drying time can be considered.</li>
<li>For each drying time tested, grip the ends of a test strip and pull evenly outward as with a <a href="https://en.wikipedia.org/wiki/Christmas_cracker">Christmas cracker</a>.<br>
The test is a success if the paper breaks outside the glued patch. (If it fails far enough from the join, repeat until there’s nothing left to grip)</li>
<li>For each drying time tested, attempt to peel apart the two strips of paper.<br>
The test is a success if the paper is visibly damaged in a manner that wouldn’t be hidden by glueing the joint back together.</li>
<li>Repeat each test at least once, to account for variations in the process.</li>
<li>Prepare another set of test strips and allow the glued spot to soak in a drop of mineral or vegetable oil for 30 minutes. Repeat the tests.<br>
The glue passes if it wasn’t weakened by the oil. (In my tests, the breakage still consistently occurred in the dry portions of the paper, indicating that the oil had not weakened it significantly.)</li>
<li>Prepare another set of test strips and paint the glued patch thoroughly with clear nail polish. Repeat the tests.<br>
The glue passes if the solvent in the nail polish didn’t weaken it. (I have already confirmed in previous experiments that nail polish will waterproof paper without weakening it and, in these tests, the breakage still consistently occurred in the un-painted portions of the paper.)</li>
</ol>
<h3>Results</h3>
<p>I performed these tests with the following dollar-store adhesives:</p>
<dl>
<dt>Double-sided tape</dt>
<dd>I tested two different kinds of foamless double-sided tape. Both were too weak to be suitable, losing their grip on the paper during the pull test with barely any visible effect.</dd>
<dt>Roll-on glue tape</dt>
<dd>This contact adhesive passed the pull test, but was not tamper-evident in the face of picking and peeling at the joint and was so thoroughly weakened by the oil test that it was trivial to pull open without harming the paper.</dd>
<dt>Non-frosted Scotch/Sellotape</dt>
<dd>From personal experience, I know that the frosted variety is meant to be possible to peel off without harm if you’re careful. I tested the un-frosted kind and, while it just barely passed the pull test, it was too easy to peel off without evidence. Also, it was severely weakened by exposure to oil and I suspect this to be a trait common to all readily available contact adhesives.</dd>
<dt>Roll-on glue tape, plus Scotch/Sellotape</dt>
<dd>Didn’t perform significantly better Scotch/Sellotape on its own.</dd>
<dt>Glue stick</dt>
<dd>Passed the dry and oil tests, but whether it passed the peel test depended very heavily on exactly how I applied it, so I can’t recommend it. It also got severely degraded by the solvent in the clear nail polish.</dd>
<dt>White/School/Elmer’s Glue (PVA/Polyvinyl Acetate)</dt>
<dd>I was surprised how well this performed… though I probably shouldn’t have been, given that it’s used as a bookbinding glue. PVA dries quickly enough that, after 5 minutes, the still-damp paper next to the joint breaks under test and, after 10 minutes, the paper is back to normal. It is so resistant to peeling that the paper tends to tear, and neither the oil nor the nail polish solvent had a measurable effect on the joint’s strength.</dd>
</dl>
<p>I did, however, notice that peeling at a corner produced damage that was easier to overlook… thus my recommendation to round off the ends of the strip before gluing.</p>
<p>I would have moved on to testing other avenues, such as hot glue, super glue, contact cement, and so on, but I don’t need to test them to know that, at best, they’d match the performance of white glue for this application.&nbsp; (They’re harder to work with, more expensive,&nbsp;no faster to dry, and PVA already produces a bond stronger than and just as water-resistant as the paper around it.)</p>
<p>(I did, however, test super glue on some scraps of projector transparencies meant for black-and-white photocopiers. It passed the pull test but was trivial to peel apart without leaving evidence of tampering.)</p>
<p><strong>UPDATE 2018-08-15: </strong>After I realized how effective lighter fluid is for safely getting tape and other adhesives off books and boxes without damaging them, I ran another round of tests.</p>
<p>Lighter fluid does not appear to significantly weaken white glue. However, since my initial tests, I’ve switched to a new bottle of glue and it seems that the resistance of Polyvinyl Acetate (PVA) glues to being peeled off will vary. (I’m not sure whether it varies between batches or just between brands.)</p>
<p data-select-link-text="1">As such, since the quality of your white glue cannot be guaranteed, I now strongly recommend the “making the seals tougher” steps be always used (a coating of clear nail polish to seal the seam and some cuts to improve the chances of tearing when trying to peel it apart), with the use of chevron-shaped (<code>&lt;</code> and <code>&gt;</code>) cuts to ensure there’s no angle one can try to peel at which will be completely parallel to every cut.</p>

<!-- BEGIN License added by Creative-Commons-Configurator plugin for WordPress -->
<p prefix="dct: http://purl.org/dc/terms/ cc: http://creativecommons.org/ns#"><a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><img alt="CC BY-SA 4.0" src="http://blog.ssokolow.com/wp-content/plugins/creative-commons-configurator-1/media/cc/by-sa/4.0/88x31.png" width="88" height="31"></a>
<a href="http://blog.ssokolow.com/archives/2017/04/08/home-made-tamper-evident-security-seals-for-kids-and-adults-alike/" title="Permalink to Home-made tamper-evident security seals for kids and adults alike"><span property="dct:title">Home-made tamper-evident security seals for kids and adults alike</span></a> by <a href="http://blog.ssokolow.com/archives/author/ssokolow/" property="cc:attributionName" rel="cc:attributionURL">Stephan Sokolow</a> is licensed under a <a rel="license" target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.</p>
<!-- END License added by Creative-Commons-Configurator plugin for WordPress -->
											</div></div>]]>
            </description>
            <link>http://blog.ssokolow.com/archives/2017/04/08/home-made-tamper-evident-security-seals-for-kids-and-adults-alike/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24135355</guid>
            <pubDate>Wed, 12 Aug 2020 18:44:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Content Is King – Who Said It Better?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24135322">thread link</a>) | @dredmorbius
<br/>
August 12, 2020 | https://lgkmarketingcc.com/content-king-said-better/ | <a href="https://web.archive.org/web/*/https://lgkmarketingcc.com/content-king-said-better/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
						
						<div id="main">			
		<section role="main" itemprop="mainEntity" itemscope="itemscope" itemtype="https://schema.org/Blog">
	<div>
		<div>
			<div>
				<div>
										<article id="post-6219" itemscope="itemscope" itemtype="https://schema.org/BlogPosting" itemprop="blogPost">
	<div>
		

		
		<div itemprop="text">
			<p><a href="https://www.lgkmarketingcc.com/wp-content/uploads/2016/07/Content-is-King-rev-1.png"><img loading="lazy" src="https://www.lgkmarketingcc.com/wp-content/uploads/2016/07/Content-is-King-rev-1.png" alt="Content is King rev (1)" width="560" height="315"></a><br>
Although Bill Gates often gets credit for the phrase “content is king,” it was actually outlined in a book in 1974 and popularized by Sumner Redstone before Gates’ speech.&nbsp; Google also uses a version of the phrase, related to internet searches – more original content, better search results.<br>
From <em>Magazine Editing and Production:</em></p>
<blockquote><p><em>Content is king.&nbsp; It is the meaning that counts.&nbsp; Form and technical considerations, though important, cannot substitute for content. </em><br>
J.W. Click and Russell N. Baird, authors, on how to pick the best magazine photos</p></blockquote>
<p>From Sumner Redstone’s Wikipedia page:</p>
<blockquote><p><em>In 1954, he joined his father’s theater chain,&nbsp;<a href="https://en.wikipedia.org/wiki/National_Amusements">National Amusements</a></em><em>&nbsp;</em><em>and in 1967, he became CEO of the company.<span>&nbsp;</span>As the company grew, Redstone came to believe that content would become more important than distribution mechanisms: channels of distribution (in varied forms) would always exist, but content would always be essential (Redstone coined the phrase, “Content is king!”).&nbsp;</em><br>
<a href="https://en.wikipedia.org/wiki/Sumner_Redstone">https://en.wikipedia.org/wiki/Sumner_Redstone</a></p></blockquote>
<p>From <em>Content is King</em> essay:</p>
<blockquote><p><em>Content is where I expect much of the real money will be made on the Internet, just as it was in broadcasting…</em><br>
<em>When it comes to an interactive network such as the Internet, the definition of “content” becomes very wide. For example, computer software is a form of content-an extremely important one, and the one that for Microsoft will remain by far the most important.</em><br>
<em>But the broad opportunities for most companies involve supplying information or entertainment. No company is too small to participate.</em><br>
Bill Gates</p></blockquote>
<p>Google’s site for webmasters:</p>
<blockquote><p><em>Little or no original content</em><br>
<em>One of the most important steps in improving your site’s ranking in Google search results is to ensure that it contains plenty of rich information that includes relevant keywords, used appropriately, that indicate the subject matter of your content.</em><br>
https://support.google.com/webmasters/answer/66361?hl=en</p></blockquote>
<div><p>Regardless of who first used the phrase (there are variations before 1974), it is used so often now, it’s quickly headed to cliché-land. This could be because, since the phrase is true for everyone’s own world, its relevance is universal.&nbsp; The authors from 1974 used the phrase to reference magazine articles while Sumner Redstone refers to programming, Bill Gates refers to software and the internet and Google refers to SEO.<br>
Our world revolves around marketing, where, as you guessed it, content is king. Content marketing can take several different forms – videos, blogs, infographics, e-newsletters, white papers – all built around your establishing and maintaining your brand identity. When you provide original content it helps to confirm your credibility and experience and also to establish yourself as an expert in your field. When used on your website, it also keeps things fresh, gives customers a reason to keep coming back and helps with your SEO.&nbsp; The ultimate goal, of course, is to generate new business.<br>
So, who said it better?<br>
For your viewing pleasure, here’s a <em>Conversation with Sumner Redstone</em> from the Boston University law school.&nbsp; The dean’s introduction credits him with coining the phrase “content is king” and it’s an interesting conversation with an entrepreneur who built a communications empire from a local chain of movie theatres and drive-ins.</p><iframe src="https://www.youtube.com/embed/11zypIc5QMY" width="420" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe><p>
Leisa Chester Weir<br>
<a href="https://www.lgkmarketingcc.com/wp-content/uploads/2015/03/lgklogo_color-50x37png.png"><img loading="lazy" src="https://www.lgkmarketingcc.com/wp-content/uploads/2015/03/lgklogo_color-50x37png.png" alt="LGKlogo_color 50x37png" width="50" height="37"></a></p><p>
&nbsp;
&nbsp;
<em>For daily marketing communications news,</em><em>&nbsp;</em><em><a href="http://paper.li/LGKMarketing/1360005224">subscribe</a></em><em>&nbsp;</em><em>to LGK’s free, online, MarCom Digest.</em></p></div>
		</div>

					
			</div>
</article>
	
<!-- /.row -->				</div><!-- /.inner -->
			</div><!-- /.content-area -->

					<!-- /.sidebar -->
			</div><!-- /.row -->
	</div><!-- /.container -->
</section>

		
		</div><!-- /.site-main -->

				<!-- Footer -->
		
		
	</div></div>]]>
            </description>
            <link>https://lgkmarketingcc.com/content-king-said-better/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24135322</guid>
            <pubDate>Wed, 12 Aug 2020 18:41:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[American Airlines bans masks with exhaust valves and vents]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 106 (<a href="https://news.ycombinator.com/item?id=24135255">thread link</a>) | @simpleflyong
<br/>
August 12, 2020 | https://kokpitherald.com/american-airlines-new-masks-policy/ | <a href="https://web.archive.org/web/*/https://kokpitherald.com/american-airlines-new-masks-policy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://kokpitherald.com/american-airlines-new-masks-policy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24135255</guid>
            <pubDate>Wed, 12 Aug 2020 18:36:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Feature Flags Do and Don’t Make Sense]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24135190">thread link</a>) | @kiyanwang
<br/>
August 12, 2020 | https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/ | <a href="https://web.archive.org/web/*/https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://www.redbubble.com/i/canvas-print/If-Else-Software-Developer-Joke-Beer-Lover-by-VaSkoy/33140544.5Y5V7" target="_blank"><img data-attachment-id="282" data-permalink="https://software.rajivprab.com/flag/" data-orig-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png" data-orig-size="896,1480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="flag" data-image-description="" data-medium-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182" data-large-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=620" src="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182" alt="" srcset="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182 182w, https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=364 364w, https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=91 91w" sizes="(max-width: 182px) 100vw, 182px"></a></figure></div>



<p>Over the past years, I’ve worked in multiple teams adopting very different strategies when it comes to feature flags. I’ve seen the pros and cons of both, and over time, I found myself disagreeing with any fundamentalist position on their use. There is a lot of nuance to this topic, and I think it is worth considering more carefully the various scenarios where feature flags do and do not make sense.</p>



<h2>The Reasons For</h2>



<p>There are a few major scenarios where feature flags make a lot of sense. The first is when it’s used for <a rel="noreferrer noopener" aria-label="A/B testing (opens in a new tab)" href="https://en.wikipedia.org/wiki/A/B_testing" target="_blank">A/B testing</a>, where you absolutely do want different behaviors for different users, based on their randomly assigned treatment. I’ve seen this strategy employed extremely well at Amazon where new features are gated by a “feature flag” that is actually controlled by an internal A/B testing framework. The framework randomly exposes some Amazon customers to the new feature, and then monitors their subsequent behavior in order to estimate the business impact of launching the feature.&nbsp;</p>



<p>I was initially skeptical, but was soon won over by how easy the framework was to use, and the valuable insights it provided on the benefits (or drawbacks) of certain features. “Flavor of the month” decisions were replaced with real data. And none of this is possible without the use of “feature flags” to dynamically toggle new features.</p>



<hr>



<p>Another great use case for feature flags, is when you’re working on a very complex epic that require many different sub-tasks to be completed in different parts of the system. Sub-tasks that are too numerous and invasive to be done in a single pull-request. </p>



<p>In such cases, trying to keep all these disparate changes in side-branches and coordinating a simultaneous merge and deployment, is a recipe for disaster. It’s far more manageable to gate any disruptive changes behind a master flag, merge and deploy all the sub-commits incrementally, and do a flag-flip once all the pieces are in place.</p>



<hr>



<p>One last use case for feature flags, is when you do not have control over your deployments. For example, consider the Facebook Android app, which contains code contributed by hundreds of different teams, all combined and deployed as a single binary. In such scenarios, performing rollbacks can be infeasible. For practical, political, bureaucratic or even marketing reasons. In such cases, feature flags allow your team to toggle new functionality or mitigate risky changes, without having to rollback or deploy any new binaries.</p>



<p><em>Someone on Reddit pointed out a similar use-case for feature flags: targeting a very specific launch date for marketing reasons, while still deploying your code much earlier, in order to ensure stability. You can then have a “dynamic” feature flag that automatically enables itself at a specific time. This is also a great use-case for similar reasons – changing functionality in situations where deploying a new binary is impractical.</em></p>



<h2>Risk Aversion</h2>



<p>The above are all fantastic use cases for feature flags, but I’ve also seen teams get bogged down by policies that overreach in their use. For example, mandating that every single code change should be behind a feature flag, <em>“just in case we made a mistake”</em>.</p>



<p>Risk management should indeed be a priority for all teams. But there are better ways of doing this than relying on feature flags, especially if your team has control over its own deployments. The <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/" target="_blank">vast majority of your bugs should be caught by your automated test suite</a> and/or QA process. And the last few stragglers should be handled using <a rel="noreferrer noopener" aria-label="incremental deployments, production alarms and rollbacks (opens in a new tab)" href="https://software.rajivprab.com/2019/11/25/the-birth-of-legacy-software-how-change-aversion-feeds-on-itself/" target="_blank">incremental deployments, production alarms and rollbacks</a>.</p>



<p>Besides, as soon as any problem is detected, the recommendation at places like Google is to <a rel="noreferrer noopener" aria-label="rollback first and ask questions later (opens in a new tab)" href="https://cloud.google.com/blog/products/gcp/reliable-releases-and-rollbacks-cre-life-lessons" target="_blank">rollback first and investigate the problem later</a>:</p>



<blockquote><p><em>We have seen this at Google any number of times, where a hastily deployed roll-forward fix either fails to fix the original problem, or indeed makes things worse. Even if it fixes the problem it may then uncover other latent bugs in the system; you’re taking yourself further from a known-good state, into the wilds of a release that hasn’t been subject to the regular strenuous QA testing. At Google, our philosophy is that “rollbacks are normal.” When an error is found or reasonably suspected in a new release, the releasing team rolls back first and investigates the problem second</em></p></blockquote>



<p> When things are on fire, the last thing you want to do is root-cause the bug and figure out which flag-flip will safely fix the problem. And that may not even fix things – there’s no guarantee that even if your teammate tried to put his changes behind a feature flag, he didn’t inadvertently introduce a bug that cannot be solved by a flag-flip.</p>



<p>Feature flags are a poor man’s alternative to binary rollbacks, and they definitely aren’t a substitute for having a great automated test suite and a robust QA process. If you’re relying on feature flags to remedy production bugs, you should stop and evaluate your team’s practices. Risk aversion is often a smell of your team <a rel="noreferrer noopener" aria-label="entering into a doom loop which will only get worse and worse with time (opens in a new tab)" href="https://software.rajivprab.com/2019/11/25/the-birth-of-legacy-software-how-change-aversion-feeds-on-itself/" target="_blank">entering into a doom loop which will only get worse and worse with time</a>.</p>



<h2>Death By Feature Flags</h2>



<p>You may be wondering at this point why we shouldn’t use feature flags anyway. After all, <em>“defense in depth” …</em> and it never hurts to have more fine-grain flexibility right?</p>



<p>While feature flags are great in some cases, we should also keep in mind their costs. Software engineering is primarily an exercise in managing complexity. And each feature flag immediately doubles the universe of corner cases that your programmers have to understand, and your code is required to handle. <em>“But what would happen if Foo is enabled, Bar is disabled, and we do independent A/B tests on Baz and Kaz on the same day?”</em> In my experience, this combinatorial explosion in complexity can and <strong>will</strong> lead to bugs. Not to mention slowing down the speed at which your team can make any changes.</p>



<p><em>“But these feature flags are only temporary. You should be removing them as soon as possible!”</em></p>



<p>Sure, and we should also not allow our tech debt to accumulate and we should follow every single best-practice religiously. Unfortunately, this never happens in any corporate environment. Even in great teams, tech debt often gets de-prioritized in the face of new requests. Newcomers to the team or those on their way out, aren’t always disciplined enough to clean up their flags after a successful rollout. And sometimes, these tasks simply slip through the cracks and get forgotten.</p>



<p>There is no better illustration of this than the KCG debacle where a financial firm lost half a billion dollars and almost went bankrupt in 30 minutes, partly due to dead code that was behind a feature flag.</p>



<blockquote><p><a href="https://www.bugsnag.com/blog/bug-day-460m-loss"><em>The cause of the failure</em></a><em> was due to multiple factors. However, one of the most important was that a flag which had previously been used to enable Power Peg… Power Peg had been obsolete since 2003, yet still remained in the codebase some eight years later.</em></p><p><em>In 2005, an alteration was made to the Power Peg code which inadvertently disabled safety-checks which would have prevented such a scenario. However, this update was deployed to a production system at the time, despite no effort having been made to verify that the Power Peg functionality still worked</em></p></blockquote>



<hr>



<p>Feature flags are a powerful tool that can help you experiment with new features, manage the rollout of complex epics, and mitigate the problems associated with not controlling your team’s deployments. </p>



<p>But they come at a significant cost, in the form of code complexity, tech debt, slower development speeds, and inevitably, bugs. </p>



<p>As tempting as it may be, there is no silver bullet here. Weigh the pros against the cons, and use this tool judiciously when it makes sense to do so.</p>



<hr>



<p><a href="https://www.reddit.com/r/programming/comments/i5zbvk/when_feature_flags_do_and_dont_make_sense/" target="_blank" rel="noreferrer noopener"><em>Discussion thread on /r/programming</em></a></p>
	</div></div>]]>
            </description>
            <link>https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24135190</guid>
            <pubDate>Wed, 12 Aug 2020 18:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Golden Rule of Building Technical Platforms (Eat Your Own Dogfood)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24135005">thread link</a>) | @kislayverma
<br/>
August 12, 2020 | https://kislayverma.com/platform-thinking/the-golden-rule-of-platforms/ | <a href="https://web.archive.org/web/*/https://kislayverma.com/platform-thinking/the-golden-rule-of-platforms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<div>
<p>The Golden rule of platforms (<a href="https://kislayverma.com/platform-thinking/distilled-steve-yegge-s-platform-rant/">™ Steve Yegge</a>) is simple and well known – <strong><em>Eat your own dogfood</em>.</strong>&nbsp;</p>
<p>In the context of building technical platforms, it means that the first user of your platform is you. While this seems a fairly simple thing, certainly too simple to be THE golden rule, this guideline has very deep repercussions around why a platform is built, how it is built, and the impact it has on an organization.</p>
<p>The Golden Rule plays the essential counterfoil to the other cardinal rule of building platforms – <strong>a platform must be externally programmable</strong>. External programmability ensures that anyone can build cool new things on top of a platform without having to buy into your business opinions. “Eat your own dogfood” turns external programmability inwards by dictating that even internal teams, even the platform owner itself, must use the platform just as if it was provided by an external party. <strong>No backdoors. No special access. No admins. Nothing that you wouldn’t allow a complete stranger to do.</strong></p>
<p>External programmability is the knife that separates platforms from products. The Golden Rule is this knife applied to the platform owner’s business.</p>
<div><figure><img loading="lazy" width="552" height="331" src="http://167.71.230.226/wp-content/uploads/2020/07/knife-of-platformization.jpg" alt="" srcset="https://kislayverma.com/wp-content/uploads/2020/07/knife-of-platformization.jpg 552w, https://kislayverma.com/wp-content/uploads/2020/07/knife-of-platformization-300x180.jpg 300w" sizes="(max-width: 552px) 100vw, 552px"></figure></div>
<p>Here are some ramifications of building a technical platform based on dogfooding.</p>
<h3>A Good Platform is a Great Product</h3>
<p>I have written before about <a href="https://kislayverma.com/platform-thinking/why-you-should-build-a-platform/">why an organization should adopt platform architecture and strategy</a>.&nbsp;</p>
<p>Eating your own dogfood means that the reasons for building a platform are also the reasons for using said platform. A platform is typically sold as a set of tools that take care of “solved problems” and allows the buyer to focus on solving new problems. For a team to grow and solve business problems at a deeper and deeper level, it is imperative that they <a href="https://kislayverma.com/agile/being-fast-or-getting-faster-aka-build-momentum-not-velocity/">not be repeating themselves</a>. Explicitly adopting platform architecture forces us to think about solved problems and unsolved problems separately.</p>
<p>A good platform lays down the building blocks and <a href="https://kislayverma.com/platform-thinking/platform-nuts-bolts-enforcing-constraints-in-platform-architectures/">clear rules around using them</a>. As a follower of those same rules, the platform owner gets a first hand understanding of the good, the bad, and the ugly. Dogfooding tells us about the “maker experience” first hand.</p>
<div>
<div>
<h4>Support this blog on Patreon</h4>

</div>
<div>
<div><figure><a href="https://www.patreon.com/bePatron?u=29760145"><img loading="lazy" src="http://167.71.230.226/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-1024x1024.png" alt="" width="100" height="100" srcset="https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-1024x1024.png 1024w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-300x300.png 300w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-150x150.png 150w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-768x768.png 768w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral.png 1080w" sizes="(max-width: 100px) 100vw, 100px"></a></figure></div>
</div>
</div>

<h3>Externalizable from day one</h3>
<p>If we are to eat our own dogfood, then ALL the rules and mechanisms for using the platform must be in place just as they would have to be if we were to let others (other teams in the company, people outside the company) use the platform. This means that in practice, a platform done right is externalizable and ready for consumption by anyone from its first day.&nbsp;</p>
<p>A good effect of this is that the organization’s boundary starts becoming fuzzy from a technical perspective, <a href="https://kislayverma.com/platform-thinking/control-and-chaos-in-platform-systems/">switching from access control mode to cooperation mode</a>. <em>Anyone</em> who wants to co-create alongside internal teams on this platform is now free to do so. We may never expose the platform externally, but it forces the business and other technical teams to think in a way that does not presuppose exclusive control and encourage co-creation of value with other partners (via close knit technology integrations). I can assure you that given such capabilities, business folks can get very creative very fast!</p>
<div><figure><img src="http://167.71.230.226/wp-content/uploads/2020/08/platforms-for-cooperation-1-1024x838.jpg" alt=""></figure></div>
<p><strong>Layered Organization Structure</strong></p>
<p><em>Eating our own dogfood</em> means that we have to think about making dog food separately from eating it. <a href="https://kislayverma.com/platform-thinking/platforms-and-dogfood-everywhere/">Every business problem contains two parts</a>. One is the part which is shared by all problems of that domain regardless of the organization (what I call <strong>Domain Context</strong>). The other part represents the organization’s specific ways of solving the problem – the <strong>Organization Context</strong>.&nbsp;</p>
<p>Eating your own dogfood forces the split between these two in the organization’s technical architecture. I outlined a <a href="https://kislayverma.com/platform-thinking/platforms-and-dogfood-everywhere/">case study</a> of such a split in an earlier post on building a notification system.&nbsp;</p>
<p>Hierarchical, loosely coupled layers are an emergent property of platform architecture.</p>
<p>And since an organization cannot help but <a href="https://en.wikipedia.org/wiki/Conway%27s_law">ship its communication structures</a>, we can leverage this phenomenon in reverse to let the technical architecture lead us to an organization structure which is best suited to exploit this loose coupling and agility. Platforms architecture facilitates fast, unmediated (by humans, all mediation is over well defined programmatic interfaces) cooperation between teams that focus on achieving their specific business goals using the various platforms surrounding them – including the one they made themselves.</p>
<div><figure><img src="http://167.71.230.226/wp-content/uploads/2020/08/platforms-and-business-process-2-1024x867.jpg" alt=""></figure></div>
<p>You can visualize this as a set of value generating, opinionated business processes sitting on top of a set of platforms. As these processes grow larger and more complex, they themselves start splitting into higher order platforms and even higher order business solutions built on top of them.</p>
<div><figure><img src="http://167.71.230.226/wp-content/uploads/2020/08/higher-order-platforms-and-processes-1-1024x798.jpg" alt=""></figure></div>
<hr>
<p>This is a brief look at the impact of The Golden Rule of Platform on technical architecture organizational attitudes. It is worth it to consciously apply platform thinking and this rule to every business or technical problem your are solving to what kind of structures emerge as a result and how we can benefit from them.</p>
<p><strong>Read Next</strong> – <a href="https://kislayverma.com/software-architecture/layering-domains-and-microservices-using-api-gateways/">Using API Gateways to build hierarchical architecture</a></p>
</div>
</article></div>]]>
            </description>
            <link>https://kislayverma.com/platform-thinking/the-golden-rule-of-platforms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24135005</guid>
            <pubDate>Wed, 12 Aug 2020 18:14:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nintendo DS Architecture – A Practical Analysis]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24134285">thread link</a>) | @danhor
<br/>
August 12, 2020 | https://www.copetti.org/projects/consoles/nintendo-ds/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/nintendo-ds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><div><ul><li><a href="#cover-model">Model</a></li><li><a href="#cover-motherboard">Motherboard</a></li><li><a href="#cover-diagram">Diagram</a></li></ul><div><div id="cover-motherboard"><figcaption>Showing first revision<br>Controllers are plugged using a separate daughterboard<br>Missing SRAM chips are on the back and there are four unpopulated SRAM slots</figcaption></div><div id="cover-diagram"><a href="https://www.copetti.org/images/consoles/nintendods/diagram.png"><picture>
<img alt="Diagram" src="https://www.copetti.org/images/consoles/nintendods/diagram.png" data-src="https://www.copetti.org/images/consoles/nintendods/diagram.png"></picture></a><figcaption>If you have trouble following the components: Top is only accessed by ARM9, bottom section is ARM7-only, middle section is shared</figcaption></div></div></div><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>This console is an interesting answer to many needs that weren’t possible to fulfil in the handheld ecosystem. There will be some innovation and a few compromises, but this combination may pave the way for new and ingenious content.</p><hr><h2 id="cpu">CPU</h2><p>As with Nintendo’s <a href="https://www.copetti.org/projects/consoles/game-boy-advance/">previous portable console</a>, the system revolves around a big chip named <strong>CPU NTR</strong>. ‘NTR’ is shorthand for ‘Nitro’, the codename of the original Nintendo DS.</p><p>Now, CPU NTR implements an interesting multi-processor architecture using two different ARM CPUs, this design was done before ARM Holdings officially released multi-processor solutions. So, their functioning may be considered a bit unorthodox taking into account the present technology available.</p><p>While this is not the first parallel system analysed for <a href="https://www.copetti.org/projects/consoles/">this series</a>, its design is very different from the rest. For instance, we are not talking about the ‘experimental’ master-slave configuration that the <a href="https://www.copetti.org/projects/consoles/sega-saturn/">Saturn</a> debuted or the ‘co-processor’ approach found on the <a href="https://www.copetti.org/projects/consoles/playstation/">PS1</a> or <a href="https://www.copetti.org/projects/consoles/nintendo-64/">N64</a>. The Nintendo DS includes two very independent computers that will perform exclusive operations, each one having a dedicated bus. This co-dependency will condition the overall performance of this console.</p><p>That being said, let’s take a look now at the two CPUs:</p><div><ul><li id="tab-1-1-arm7tdmi-link"><a href="#tab-1-1-arm7tdmi">ARM7TDMI</a></li><li id="tab-1-2-arm946e-s-link"><a href="#tab-1-2-arm946e-s">ARM946E-S</a></li></ul><div><div id="tab-1-1-arm7tdmi"><h4>ARM7TDMI</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"></picture></a><figcaption>ARM7 structure and components</figcaption></div><p>Starting with the more familiar one, the <strong>ARM7TDMI</strong> is the same CPU found on the <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#cpu">GameBoy Advance</a> but now running at <strong>~34 MHz</strong> (double its original speed). It still includes all its original features (especially <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#whats-new">Thumb</a>).</p><p>Now for the changes: Because Nintendo’s engineers placed the ARM7 next to most of the I/O ports, this CPU will be tasked with arbitrating and assisting I/O operations. In fact, no other processor can directly connect to the I/O. As you can see, this is not the ‘main’ processor that will be in charge of the system, but rather the ‘sub-processor’ offloading the main CPU by passing data around many components.</p></div><div id="tab-1-2-arm946e-s"><h4>ARM946E-S</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"></picture></a><figcaption>ARM9 structure and components</figcaption></div><p>Here is the ‘main’ CPU of the Nintendo DS running at <strong>~67 MHz</strong>. If you ignore the ill-fated ARM8 series, you could say the ARM946E-S is the ‘next-gen’ version of the ARM7. Part of the <strong>ARM9 series</strong>, this core in particular not only inherits all the features of the <strong>ARM7TDMI</strong> but also includes some additional bits:</p><ul><li>The <strong>ARMv5TE ISA</strong>: Compared to the previous v4, features some new instructions and a faster multiplier.<ul><li>If you take a look at the core name, the letter ‘E’ means <strong>Enhanced DSP</strong> which implies that lots of these new instructions have to do with applications for signal processing.</li></ul></li><li><strong>5-stage Pipeline</strong>: This is another increment from the previous 3-stage pipeline.</li><li><strong>12 KB of L1 Cache</strong>: The core now features cache, where 8 KB are allocated for instructions and 4 KB for data.</li><li><strong>48 KB of Tightly-Coupled Memory</strong> or ‘TCM’: Similar to <a href="https://www.copetti.org/projects/consoles/playstation/#cpu">Scratchpad memory</a>, however this one discriminates between instructions (32 KB) and data (16 KB).</li></ul><p>Nintendo also added the following components around it:</p><ul><li>A <strong>Divisor and Square root unit</strong> to speed up these type of operations (the ARM9 by itself is not capable of performing this type of math).</li><li>A <strong>Direct Memory Access Controller</strong>: Accelerates memory transfers without depending on the CPU. Combined with the use of cache, both CPU and DMA can potentially work concurrently.<ul><li>Cache and DMA can provide a lot of performance but also create new problems, such as data integrity. So programmers will have to manually maintain memory consistency by flushing the <a href="https://www.copetti.org/projects/consoles/playstation-2/#preventing-past-mishaps">write-buffer</a> before triggering DMA, for instance.</li></ul></li></ul></div></div></div><p>I guess with hardware like this, it’s easy to figure out the <em>real</em> reason kids loved this console, eh?</p><h4 id="interconnection">Interconnection</h4><p>So far I’ve talked about how the two CPUs work individually. But to work as a whole, they require to co-operate constantly. To accomplish this, both CPUs directly ‘talk’ to each other using a dedicated <strong>FIFO unit</strong>, this block of data holds two 64-byte queues (up to 16 elements) for <strong>bi-directional communication</strong>.</p><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"></picture></a><figcaption>Representation of FIFO unit</figcaption></div><p>This works as follows: The ‘sender’ CPU (that effectively needs to send the other a message) places a 32-bit block of data in the queue, the CPU acting as a ‘receiver’ can then pull that block from the queue and perform the required operations with it.</p><p>Whenever there’s a value written on the queue, either CPU can fetch it manually (<strong>polling</strong>) however, this requires to constantly check for new values (which can be expensive). Alternatively, an <strong>interrupt unit</strong> can be activated to notify the receiver whenever there’s a new value in the queue.</p><h4 id="main-memory">Main memory</h4><p>Just like its predecessor, RAM is spread around many different locations, enabling to prioritise data placement by speed of access. In summary, we have the following general-purpose memory available:</p><div><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"></picture></a><figcaption>RAM model of this console</figcaption></div><ul><li><strong>32 KB of WRAM</strong> (Work RAM) using a <strong>32-bit</strong> bus: To hold fast data shared between the ARM7 and ARM9.<ul><li>Bear in mind that only one CPU can access the same address at a time.</li></ul></li><li><strong>64 KB of WRAM</strong> using a <strong>32-bit</strong> bus: For fast data as well, but only accessible from the ARM7, like the GBA had.</li><li><strong>4 MB of PSRAM</strong> using a <strong>16-bit</strong> bus: A slower type, available from either CPU and it’s controlled by a memory interface unit.<ul><li>Pseudo SRAM or ‘PSRAM’ is a variant of DRAM which, by contrast, performs refreshes from within the chip. Therefore, behaving like SRAM (the faster, but more expensive alternative to DRAM). This design reminds me of <a href="https://www.copetti.org/projects/consoles/gamecube/#clever-memory-system">1T‑SRAM</a>.</li></ul></li></ul></div><h4 id="backwards-compatibility">Backwards compatibility</h4><p>Even though the architecture is significantly different from its predecessor, it still managed to maintain the critical bits that would grant it native compatibility with GameBoy Advance games.</p><p>But for the DS to revert to an ‘internal’ GBA, the former includes a set of software routines that set the console in <strong>AGB Compatibility Mode</strong>. In doing so, it effectively halts the ARM9, disables most of the ‘special’ hardware, redirects the buses, puts the ARM7 in charge and slows it down at 16.78 MHz. Finally, the ARM7 proceeds to boot the original AGB BIOS which bootstraps the GamePak cartridge (just like an original GameBoy Advance). This mode still exhibits some features not found in the original console, such as displaying the game with black margins (we’ll see in the next section that the new screen resolution happens to be bigger). Moreover, since the DS has two screens, users can set which screen will be used to display the GBA game.</p><p>Once in GBA mode <strong>there’s no going back</strong>, the console must be reset to re-activate the rest of the hardware.</p><h4 id="secrets-and-limitations">Secrets and limitations</h4><p>With so many sophisticated components fitted in a single and inexpensive chip, it’s no mystery that some issues emerged due to the way they were forced to work with each other.</p><div><ul><li id="tab-2-1-unused-power-link"><a href="#tab-2-1-unused-power">Unused Power</a></li><li id="tab-2-2-a-question-about-the-hardware-choice-link"><a href="#tab-2-2-a-question-about-the-hardware-choice">A question about the hardware choice</a></li></ul><div><div id="tab-2-1-unused-power"><h4>Unused Power</h4><p>Sometimes I wonder how Nintendo planned the way the two CPU’s would be used, and if they already assumed some performance would be hit by the design they chose.</p><p>Let me start with the ARM9, this CPU runs at twice the speed of the ARM7, but most (if not all) of the I/O depends on the ARM7, so the ARM9 is vulnerable to excessive stalling until the ARM7 answers. If that wasn’t enough, <strong>ARM9’s external bus runs at half the speed</strong>, so there are a few bottlenecks identified.</p><p>Additionally, the Main Memory bus is only <strong>16-bit wide</strong>. Thus, whenever any CPU needs to fetch a word (32-bit wide) from memory, the interface <strong>stalls the CPU</strong> (up to 3 ‘wait’ cycles) until a full world is reconstructed. The worst impact happens when memory access is not sequential, which makes it stall for every single access. This issue will also arise when instructions are fetched (unfortunately, ARM didn’t support sequential opcode fetching back then) which, to my dismay, also affects Thumb code (since every 16-bit fetch is done as a 32-bit block). On the other hand, this penalty (as some sources call it) can be alleviated by making full use of cache and TCM.</p><p>All in all, this means that in the worst case, the ‘whooping’ ARM9’s 66 MHz horsepower is practically reduced to a mere ~8&nbsp;MHz. That is if the program makes an abysmal use of cache/TCM.</p></div><div id="tab-2-2-a-question-about-the-hardware-choice"><h4>A question about the hardware choice</h4><p>Back when I read about the CPU of the GameBoy Advance, I was really surprised by the potential of the ARM7: The CPU not only performed its designated tasks, but could also assist with others, such as providing audio sequencing or pseudo-3D graphics.</p><p>Now, during the commercialisation ARM7, ARM Holdings joined forces with DEC to design a high-end version of ARM’s chips. For this, DEC grabbed the datapath design of their processor, <strong>Alpha</strong>, and mixed it with ARM’s. The result was a new series of CPUs called <strong>StrongARM</strong> which was surprisingly <em>fast</em>. At the expense of removing certain features (Thumb and debug), DEC managed to cross the megahertz threshold by reaching speeds of up to 233 MHz. As a normal user prepared to buy a new ARM PC (let’s say a <em>RiscPC</em>), you could either choose one with the old ARM710 at 40 MHz or another one with a StrongARM running ~582% faster. The impact of StrongARM was so disruptive that ARM Holdings absorbed some of StrongARMs features to produce their next line of CPUs, starting with ARM9. And the rest is history.</p><p>But here’s where my question resides: Considering the new developments in the ARM world, why did Nintendo ultimately choose an awfully slow ARM9 combined by an even slower ARM7, instead of a faster ARM9 (or even a StrongARM)? To give you an idea, other companies like Apple just adopted the StrongARM with their Newton PDA line.</p><p>I don’t mean to criticise Nintendo’s choice, but I believe the amount of emerging technology was just too great for me to ignore. I guess their choice was done in an effort to preserve battery life and maintain production costs (by using the same CPU found in the GBA).</p></div></div></div><hr><h2 id="graphics">Graph…</h2></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/nintendo-ds/">https://www.copetti.org/projects/consoles/nintendo-ds/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/nintendo-ds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24134285</guid>
            <pubDate>Wed, 12 Aug 2020 17:15:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LaTeX: A First Introduction]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24133722">thread link</a>) | @R3G1R
<br/>
August 12, 2020 | https://mathvault.ca/latex-guide/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/latex-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-css="tve-u-16ec5d248bb"><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/latex-logo1.jpg" alt="LaTeX - Professional Typesetting and Scientific Publishing" width="759" height="427" title="latex logo1"></figure><p>Ordinarily, when it comes to document editing, tools such as notebooks and word processors come to mind. But alas, that’s usually the last thing math folks have in mind when it comes to the task…</p><p>In fact, in what follows, we’ll introduce you to the fascinating world of <strong>mathematical typesetting</strong>. We’ll also introduce you to a marvelous tool adopted by a wide range of technical scientists — so that they can communicate with each other with precision and ease.<span id="more-988"></span></p><figure id="attachment_1057" aria-describedby="caption-attachment-1057"><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/professional-typesetting-e1440887059415.jpg" alt="LaTeX - A Professional Typesetting System for Scientific and Technical Publications" width="681" height="364" title="professional typesetting e1440887059415"><figcaption id="caption-attachment-1057">Typesetting meets technology.</figcaption></figure><h2><span id="6_Serious_Weaknesses_of_Standard_WYSIWYG_Editors"></span><a id="wysiwyg" href="#toc">6 Serious Weaknesses of Standard&nbsp;WYSIWYG Editors</a><span></span></h2><p>Ever heard of a software application called <em><a href="https://en.wikipedia.org/wiki/Microsoft_Word" target="_blank" rel="noopener noreferrer">Microsoft Word</a></em>? Of course you do! And chances are, you have been using it — or another <a href="https://en.wikipedia.org/wiki/WYSIWYG" target="_blank" rel="noopener noreferrer">What You See Is What You Get (<strong>WYSIWYG</strong>) word processor</a>&nbsp;(e.g., <em>OpenOffice.org Writer</em>,&nbsp;<em>Google Docs</em>)<em> —&nbsp;</em>all along over these years.</p><p>And here is something potentially unpleasant to the ears: what if we were to object that <em>sometimes</em>, they could just be the poor tools designed with the wrong philosophy in mind? Or that they are built primarily for general usage, and is thus ill-suited for <strong>technical publishing</strong> at a wider scale?</p><p>And while these text editors are undoubtedly highly powerful and accessible, there are also 6 <strong>critical flaws</strong> that they tend to suffer from. These range from the ones that may have been annoying you in the past — to the subtler ones that you might not even have been aware of.</p><h3><span id="File_Compatibility"></span><a id="compatibility"></a><a href="#toc">File Compatibility</a><span></span></h3><p>Quick question: How do we open a doc/docx file? With <em>Microsoft Word</em> of course! (or a variant that accepts these filetypes). In other words, opening a <em>Microsoft Word</em> file requires a <em>Microsoft-Word-like</em> application. Try opening these files with basic text editors such as&nbsp;<em>NotePad</em>&nbsp;(or <em>TextEdit</em> in Mac)<em>&nbsp;</em>and see what happens: you’d probably get a bunch of weird and unintelligible symbols that just make no sense!</p><p>In addition to being text-unfriendly, converting these filetypes to other formats — or even just older formats — could very well&nbsp;jeopardize the&nbsp;<strong>formatting</strong>, <strong>alignment</strong>, or other specifications in the document. This would then require another round of judicious manual correction on your own, which could very well be somewhat painful or infuriating. In fact, there have been many recurring episodes of <em>file conversion disasters</em> in the <a href="https://en.wikipedia.org/wiki/Microsoft_Word#Cross-version_compatibility" target="_blank" rel="noopener noreferrer">history of <em>Microsoft Word</em></a>&nbsp;(in the olden days at least).</p><h3 id="cost"><span id="Proprietariness_and_Cost"></span><a href="#toc">Proprietariness and Cost</a><span></span></h3><p>How much does a proper <em>Microsoft Word</em><sup>®</sup> costs? Well, here a picture is worth a thousand words:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/ms-word-price.jpg" alt="The Price of Microsoft Word 2013 - Microsoft Store" width="1024" height="495" title="ms word price">Or if you prefer subscription plans for <em>Office 365</em>, which seems at least a bit cheaper on the surface:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/office-365-price.jpg" alt="The different subscription plans and prices for Office 365" width="1024" height="719" title="office 365 price">As powerful as word processors are, the <strong>proprietariness</strong> of document preparation applications, while many times justifiable, can hinder the democratization of the publication of creative and scholarly work — a right previously reserved to the elites, and often associated with the publishing industry even decades ago.</p><p>And of course, there are also the <strong>free</strong> / <strong>open-source</strong> variants of <em>Microsoft Word</em> such as <em><a href="https://www.openoffice.org/" target="_blank" rel="noopener noreferrer">OpenOffice.org</a></em>, <em><a href="http://www.libreoffice.org/" target="_blank" rel="noopener noreferrer">LibreOffice</a></em>, <em><a href="https://www.neooffice.org/neojava/en/index.php" target="_blank" rel="noopener noreferrer">NeoOffice</a></em> (for Mac OS X) or even <em><a href="https://www.google.ca/docs/about/" target="_blank" rel="noopener noreferrer">Google Docs</a></em>. The problem — if there is one — is that they invariably suffer from the typical weaknesses exhibited by a standard WYSIWYG word processor, such as the limitations when it comes to feature extension, and the general clumsiness of the design interface.</p><h3><span id="Unsophisticated_Typography_and_Alignment"></span><a id="typo"></a><a href="#toc">Unsophisticated Typography and Alignment</a><span></span></h3><p>While traditional WYSIWYG editors provide an enormous amount of choices in terms of fonts, font sizes and colors, documents produced using those editors tend to lack the <strong>typographical machineries</strong> to make them visually pleasing and satisfying. For one, the texts in these editors tend to be typeset in low resolution, with usually little to no care on minute ornamentations (e.g., <a href="https://en.wikipedia.org/wiki/Typographic_ligature" target="_blank" rel="noopener noreferrer">ligature</a>) and spacing/alignment details (e.g., <a href="https://en.wikipedia.org/wiki/Hyphenation_algorithm" target="_blank" rel="noopener noreferrer">hyphenation</a>) that are commonly observed in professionally produced journals and printed books.</p><p>Poor typography aside. With the traditional WYSIWYG word processors, the end of the lines are — more often than not — poorly aligned. And even if a paragraph is fully-justified, there is usually a lack of <strong>consistency</strong> in the interword spaces — which in turn could make the document look even messier than usual.</p><p>And if you want to produce elaborated <strong>formulas</strong> and <strong>equations</strong> in its full glory, you are pretty much out of luck. After all, while the standard WYSIWYG editors usually allow for the insertion of <a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/" target="_blank" rel="noopener noreferrer">Greek letters</a> and rudimentary equations, in more likelihood, you’d probably find yourself doing a lot of clicking and hand-and-eye coordination — often with very little in return…</p><figure id="attachment_1027" aria-describedby="caption-attachment-1027"><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/latex-sample.png" alt="Professional Typesetting - A Sample of What Can Be Achieved In LaTeX" width="915" height="576" title="latex sample"><figcaption id="caption-attachment-1027">Try to do this in Microsoft Word, and you’ll soon find yourself in deep despair and fury.</figcaption></figure><p>Some more words of caution: if you run too many <strong>equations</strong>,&nbsp;<b>text boxes</b>&nbsp;or <strong>figures</strong> in the same <em>Word</em> document, you could very well risk of <a href="http://www-h.eng.cam.ac.uk/help/tpl/textprocessing/latex_advocacy.html" target="_blank" rel="noopener noreferrer">having your computer run out of memory</a> and freeze to an infamous <a href="https://en.wikipedia.org/wiki/Blue_Screen_of_Death" target="_blank" rel="noopener noreferrer">Blue Screen Of Death</a> (BSOD).</p><h3><span id="Inefficient_Formatting_Features"></span><a id="formatting"></a><a href="#toc">Inefficient&nbsp;Formatting Features</a><span></span></h3><p>There is of course no doubt that <em>Microsoft Word</em> and its competitors has evolved to become some formidable text editors&nbsp;over the years. For example, in the newer <em>Microsoft&nbsp;Word</em> (e.g., <em>Word 95</em> and onward), users can determine the position of the images via a simple and intuitive <strong>drag-and-drop</strong>.</p><p>But as it turns out, this intuitiveness can also be problematic at times. as the position of the images can now be altered at the slightest mouse clicks and keyboard taps. And when that happens, the image position would need to be readjusted again — usually with very little feedback as to where the image would land after the readjustment ends…</p><figure id="attachment_1030" aria-describedby="caption-attachment-1030"><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/ms-word-image-misalignment.jpg" alt="A Typical Microsoft Word Image Misalignment" width="321" height="185" title="ms word image misalignment"><figcaption id="caption-attachment-1030">“Ahh!!! What have I done to deserve this?”</figcaption></figure><p>And if you manage to integrate some <strong>text boxes</strong> smoothly into the paragraphs, similar formatting issues could then resurface again: you would drag a text box to an intended position, and it would slip away to another position or simply disobey your command. And if you’re really unlucky, it might even disappear from the document altogether, making any attempt of recovery very difficult — if not impossible.</p><h3><span id="Numbering_Chaos"></span><a id="numbering"></a><a href="#toc">Numbering Chaos</a><span></span></h3><p>In a structured document with a large list of <strong>items</strong> such as chapters, captions and references, it usually makes good sense that we number the items — so that we can keep track of them in a fairly simple manner.</p><p>And while it’s certainly possible to do the numbering manually (which admittedly is rather intuitive), this can actually become increasingly difficult — as the number of items increases.</p><p>Moreover, what if we <em>accidentally</em> numbered Chapter 13 as Chapter 12? Or that we later decide to introduce a <em>new section</em> in between Section 5 and Section 6? Well, that can only mean one thing — that our numbering is all messed up and that it needs to be redone all over again!</p><p>But&nbsp;of course, the point here is not <em>just</em> about the chapters and sections, as the same numbering issue could apply to&nbsp;<strong>bibliographical references</strong>, <strong>tables</strong>, <strong>images</strong>, <strong>definitions</strong> and <strong>equations</strong> (if you manage to make some that is!).</p><p>To be fair, <em>Microsoft Word</em> does support <strong>automatic numbering adjustment</strong> in some cases, but it does so at the cost of bringing in more confusion and complexity. Here’s how <a href="http://word.mvps.org/FAQs/Numbering/WordsNumberingExplained.htm" target="_blank" rel="noopener noreferrer">Microsft Word MVP John McGhie</a> puts it:</p><blockquote><p>Numbering in Word is difficult to understand because Word attempts to hide “<strong>complexity</strong>” from us. In many cases, it provides insufficient detail in the explanation of features. Regrettably, a simplistic explanation does not help understanding of a complex subject. It fills our heads with loose ends, which makes the problem worse!</p></blockquote><p>And of course, the issue runs deeper than simply the numbering of the modules themselves. For example, let’s say that you referred to page 91 where you elaborated a bit on the <em>Keynesian theory of economics</em>, but later edited the text so that the same content now appears on <em>page 87</em>. Well, that’s not a good news, because it means that you would have to change your <strong>reference page</strong> now from 91 to 87!</p><p>And there is more: imagine doing that for <em>hundreds</em> of <strong>page references</strong> for equations, sections, chapters, paragraphs, tables, figures, footnotes and citations… Not exactly a human-friendly task if we may add!</p><h3><span id="Flowery_/_Messy_Graphics_Over_Image_Quality,_Speed_and_Simplicity"></span><a id="graphic"></a><a href="#toc">Flowery / Messy Graphics Over Image Quality, Speed and Simplicity</a><span></span></h3><p>While&nbsp;WYSIWYG text editors provide an intuitive graphical user interface by displaying, <em>in real-time</em>, how the document will look like when it’s printed, in some instances, it has also been argued that it’s this overemphasis on elaborated graphics that forces traditional WYSIWYG editors to water down its <strong>display resolution&nbsp;</strong>and <strong>typesetting quality</strong>. For example, Alain Cottrell, a strong proponent of $ \TeX$, <a href="http://ricardo.ecn.wfu.edu/~cottrell/wp.html" target="_blank" rel="noopener noreferrer">puts it this way</a>:</p><blockquote><p>The typesetting algorithm employed by WYSIWYG word processor sacrifices <strong>quality</strong> to the speed required for the setting and resetting of the user’s input in real time. The final product is greatly inferior to that of a real typesetting program.</p></blockquote><figure id="attachment_1066" aria-describedby="caption-attachment-1066"><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/appearance-substance.jpg" alt="Microsoft Word - Appearance Over Substance?" width="281" height="123" title="appearance substance"><figcaption id="caption-attachment-1066">Microsoft Word’s Document Output</figcaption></figure><p>In addition, as the demand for more powerful features and functionalities grow over the years,&nbsp;there is a tendency — for developers of traditional WYSIWYG editors —&nbsp;to sacrifice&nbsp;the cleanness of <strong>user interface</strong> (UI) by featuring&nbsp;an excessive amount of friendly icons, menus, boxes and bars into the editor’s main window. As a result, the users would find themselves performing&nbsp;<em>repetitive mouse clicks&nbsp;</em>and an unnatural amount of fine hand-and-eye coordinations — just to get to some feature which could have been implemented in a more energy-efficient manner.</p><p>What’s worse. The decision to opt for a more <em>graphical</em> — rather than a more <em>minimalist</em> user interface — would eventually take a toll on the <strong>speed</strong> of the text editors, putting additional demands on the computer’s memory and graphic card while making the installation larger and longer as the year progresses.</p><h2><span id="Introducing_LaTeX_and_its_Strengths"></span><a id="latex"></a><a href="#toc">Introducing LaTeX and its&nbsp;Strengths</a><span></span></h2><p>As we have seen, WYSIWYG text editors operate on the philosophy of an intuitive, <strong>output-editing graphical user interface</strong> — one which is easy to maneuver, but which could make document preparation tedious and ineffective for the large-scale tasks with higher professional demands.</p><p>And because of that, we now turn our attention to a different kind of document …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/latex-guide/">https://mathvault.ca/latex-guide/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/latex-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24133722</guid>
            <pubDate>Wed, 12 Aug 2020 16:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A mathematical approach to Zoom wait times]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24133721">thread link</a>) | @pedro-guimaraes
<br/>
August 12, 2020 | http://blog.amplemarket.com/how-much-time-should-you-wait-for-another-person-to-join-a-video-call-a-mathematical-approach/ | <a href="https://web.archive.org/web/*/http://blog.amplemarket.com/how-much-time-should-you-wait-for-another-person-to-join-a-video-call-a-mathematical-approach/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <p>As a large fraction of the world is working remotely, a lot of people's days are spent jumping between video conference calls. One question that might occur when someone joins a video conference call is how much time you should wait for the other person to join. We're going to use a simplistic mathematical model for the waiting time on a 1:1 video conference call using a famous probability distribution. </p>

<p>The problem of modeling waiting times is not new, it has been widely studied in the past particularly in areas like transportation, where it has been observed that waiting times in train and bus networks tend to follow an exponential distribution. We are going to assume that the problem of someone joining a video call is similar, from a probabilistic standpoint, to that of a train arriving at a railway station.</p>

<p>The&nbsp;exponential distribution&nbsp;is a continuous distribution defined by the following probability density function in which t is, in this case, the waiting time before the other person joins the call and \(\mu\) is the mean of the distribution</p>

<p>\(f(t) = \frac{e^{-t/\mu}}{\mu} \text{ , $t \ge 0$} \)</p>

<p>We can calculate the probability that someone takes more than \(T\) minutes to join a call by integrating \(f\)</p>

<p>\(P(t&gt;T)= 1 - \int_{0}^{T}f(t) = e^{-T/\mu}\)</p>

<p>Now, the only thing we need to do is estimate the mean of the distribution. For that we’re going to use a sample of past calls and calculate the mean waiting time for those calls. In our case, we are also going to separate our calls in 2 types: Hiring Interviews and Sales Meetings. The average waiting time for our sample is 1.5 min for Hiring Interviews and 3 min for Sales Meetings. Based on these values we can now plot the waiting time probabilities for the 2 cases.</p>

<p><img src="https://i.imgur.com/muew29r.png" alt=""></p>

<p>We can see that, for Hiring Interviews, the probability of waiting more than 5 minutes is relatively low - approximately 3% - whereas to get to the same probability on Sales Meetings we need to wait around 10 minutes. </p>

<p>This is a simplistic model but having an idea of how much time you should wait on a video call before you can confidently say that someone is unlikely to show up can have a considerable impact on the time and productivity losses across teams and companies.</p>

<p><img src="https://i.imgur.com/yHYaJIj.png" alt=""></p>

<hr>

<p><em>If you have any questions or suggestions feel free to reach out to team@amplemarket.com. You can also <a href="https://twitter.com/amplemarket">follow us on Twitter</a>.</em></p>

<blockquote>
  <p><a href="http://amplemarket.com/?ref=amplemarket-blog">Amplemarket</a> helps you find and get in touch with your next customers in the most efficient and personalized way possible.</p>
</blockquote>
        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>http://blog.amplemarket.com/how-much-time-should-you-wait-for-another-person-to-join-a-video-call-a-mathematical-approach/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24133721</guid>
            <pubDate>Wed, 12 Aug 2020 16:32:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Longwave – group journaling as a new form of social media]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24133694">thread link</a>) | @colinmcd
<br/>
August 12, 2020 | https://longwave.app/manifesto/ | <a href="https://web.archive.org/web/*/https://longwave.app/manifesto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
		



<p>Social media is broken.

</p><p>We want community and connection with our friends, family, and co-workers. We want to share witty observations, <b>deep thoughts</b>, and everything between.</p>

<p>But social networks today aren't made for that. Social media makes money from advertisements, so they optimize their sites to "maximize engagement." The more time you spend on social media, the more money they make. They <b>exploit your time and attention to make a buck</b>. They surveil you and use algorithmic feeds to serve targeted ads. They trick you into caring about likes and comments. About favorites and retweets. They try to force you to care about influencers. And engagement. And number of views.</p>

<p>Social media has become <b>performative</b>. You feel pressure to show the world a fake version of your true self. You feel anxious — as you scroll the infinite feed&nbsp;—&nbsp;of people having more fun than you. You're conditioned to rack up the hearts, and likes, and comments. You feel pressure to like and comment on your best friend's post.</p>

<p>Research shows that the more time you spend on social media, the less happy you feel. Social media sites are <b>designed to be addictive</b>. They are designed to be superficial. They shorten our attention span and overload our dopamine receptors. They polarize and breed extremism.</p>

<p>We need a place to <b>share what's on our mind</b> with people we care about. Slowly. Without likes. Without reacts. Without social anxiety and external pressure. We need to do better.</p>

<p>Enter Longwave.</p>

<p>Longwave is a <b>brand new way to connect</b>. It's a way to journal together, in small groups. It's a place to stay connected to your close friends. And family. And coworkers. To share real thoughts —&nbsp;deep or not. It's a place that values your time and attention.</p>

<p>Longwave updates once a day. There are no comments, and there are no replies. There are no flame wars. Or bots. Or presidents.</p>

<p>It's a <b>rethink</b> of social media, from the ground up.</p>




		</div>
	</div><p><span>No likes.</span>
	<span>No comments.</span>
	<span>No ads.</span>
	<span>No @-Replies.</span>
	<span>No retweets.</span>
	<span>No favorites.</span>
	<span>No flamewars.</span>
	<span>No character limits.</span> 
	<span>No tracking.</span>
	<span>No infinite scrolling.</span>
	<span>No dark patterns.</span>
	<span>No presidents.</span>
</p></div>]]>
            </description>
            <link>https://longwave.app/manifesto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24133694</guid>
            <pubDate>Wed, 12 Aug 2020 16:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Stock Market side project to micro SaaS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24133575">thread link</a>) | @eduardosasso
<br/>
August 12, 2020 | https://eduardosasso.co/blog/from-stock-market-side-project-to-micro-saas/ | <a href="https://web.archive.org/web/*/https://eduardosasso.co/blog/from-stock-market-side-project-to-micro-saas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p><a href="https://eduardosasso.co/"><img src="https://eduardosasso.co/blog/logo.png"></a></p>
      
      <hr>
      <p>
        A couple of months back, during this crazy world pandemic, I had an idea
        for a <a href="https://bullish.email/">Stock Market email newsletter</a>.
      </p>
      <p>
        Nothing novel, the initial premise was to build a fully automated
        hands-off email with some key stats I care about and send it every
        weekday before the markets open, and that’s how
        <a href="https://bullish.email/">https://bullish.email</a> came to be.
      </p>
      <p>
        Doing rounds trying to promote my little pet project, I posted it on
        <a href="https://news.ycombinator.com/item?id=22870667">Hacker News</a>
        and received great feedback, and one thousand people were convinced
        enough to subscribe.
      </p>
      <p>
        That initial traction, combined with all the positive comments and
        suggestions, was the signal I needed to upgrade from side hustle to tiny
        micro SaaS indie venture.
      </p>
      <p>
        I planned to offer a premium version of the newsletter with a lot more
        data points and insights and charge money for it. Plain and simple.
      </p>
      <p>
        But to do that, I had to do a good amount of code refactoring, hookup
        Stripe, update the website, make all the plumbing work, and promote it.
      </p>
      <p>And that’s where the fun begins again. Let’s get to work!</p>
      <p>
        The first thing I tackled was to
        <a href="https://github.com/eduardosasso/bullish/tree/master/services">build new data points</a>, all of them based on variations of the unofficial
        <a href="https://github.com/eduardosasso/bullish/blob/master/services/config.rb">Yahoo Finance API</a>.
      </p>
      <p>From those API’s I’ve extracted insights like</p>
      <ul>
        <li>Performance by sector</li>
        <li>Trending stocks</li>
        <li>Top gainers and losers</li>
        <li>All-time high stats</li>
        <li>Crypto performance</li>
      </ul>
      <p>There’s a lot you can do with Yahoo’s API.</p>
      <p>
        For each of those data points, I formatted their results with an
        emphasis on percentage performance to keep it consistent with the
        original version of Bullish and maintain its uniqueness.
      </p>
      <p>
        Next, I had to find a way to design and easily code email layouts.
        Creating email templates is a huge pain. You have to inline CSS
        everywhere, nothing works, and every change is a pain and hard to reuse.
        There’s gotta be a better way.
      </p>
      <p>
        After some research, I found <a href="https://mjml.io/">MJML</a> , which
        is essentially a markup layer on top of HTML built for designing
        responsive emails. It works great, no more writing arcane HTML and
        fighting email client compatibility.
      </p>
      <p>
        My mental model for Bullish Pro centered around the concept
        <a href="https://github.com/eduardosasso/bullish/tree/master/editions">editions</a>, and that translated to a
        <a href="https://github.com/eduardosasso/bullish/blob/master/editions/free.rb">free edition</a>, a
        <a href="https://github.com/eduardosasso/bullish/blob/master/editions/morning.rb">morning edition</a>, and an
        <a href="https://github.com/eduardosasso/bullish/blob/master/editions/afternoon.rb">afternoon edition</a>
        for paid subscribers.
      </p>
      <p>
        Editions are composed of
        <a href="https://github.com/eduardosasso/bullish/blob/master/editions/widgets.rb">elements or widgets</a>
        and change daily, like a newspaper. Between Monday and Friday, each
        edition includes a set of widgets reused interchangeably to create the
        final email layout.
      </p>
      <p>
        This notion of daily editions combined with elements gives a lot of
        versatility when creating layouts.
      </p>
      
      

      <p>
        Each element gets hooked up to a data point, so for trending stocks, you
        can expect to have a widget to render that, same thing for pre-market
        futures, crypto, etc.
      </p>
      <p>
        Elements use the
        <a href="http://mustache.github.io/">Mustache</a> template engine to
        take variables and replace them with data and do some formatting like
        green or red if the value is positive or negative.
      </p>
      <p>
        With this design, it’s easy to add new components and move them around
        to create unique
        <a href="https://github.com/eduardosasso/bullish/blob/master/templates/template.rb">templates</a>
        with almost zero code.
      </p>
      <p>
        Editions have a tag specifying their group ID, so emails go out to the
        right group free or premium.
      </p>
      <p>
        Of course, there’s a lot of plumbing involved in stitching everything
        together like compressing emails to be
        <a href="https://mailchimp.com/help/gmail-is-clipping-my-email/">under 102k</a>, so they don’t break in Gmail and things like that, but that’s a good
        overview of how I revamped Bullish to support different email formats
        without giving away the idea of full automation.
      </p>
      <p>
        The infrastructure is still pretty much the same, three CRON jobs set up
        in a Raspberry PI to create the HTML of each edition and calls to
        <a href="https://www.mailerlite.com/">MailerLite</a> API to schedule
        distribution. Check the
        <a href="https://bullish.email/blog/turning-my-obsession-in-the-stock-market-into-a-side-project/">previous article</a>
        for more details.
      </p>
      <p>
        For payments, I used Stripe and their drop-in
        <a href="https://stripe.com/docs/payments/checkout">checkout flow</a> to
        accept payments and
        <a href="https://stripe.com/billing">Stripe Billing</a> for managing
        recurring subscriptions connected to a few
        <a href="https://zapier.com/">Zapier</a> recipes to handle users moving
        from free group to premium and downgrading from premium back to free
        when they cancel.
      </p>
      <p>
        With Stripe Billing and a sprinkle of Javascript
        <a href="https://www.netlify.com/products/functions/">cloud function</a>
        deployed to <a href="https://www.netlify.com/">Netlify</a>, I’ve set up a
        magic link on premium emails, so paid users can update or cancel their
        subscriptions directly in Stripe securely.
      </p>
      <p>
        Based on the customer id, Stripe generates a unique link on demand so
        users can update their subscription without having to log in or create
        an account, it’s zero friction.
      </p>
      <p>
        Leveraging Zapier was a big time saver, and it’s less code I need to
        write and maintain. They offer a free plan that includes five zaps, and
        that’s what I use.
      </p>
      <p>
        Another huge time saver was moving the website over to Netlify. They
        have such an excellent product with killer features like branch previews
        for testing, automatic asset compression, and serverless functions that
        are ridiculously easy to use with no config whatsoever write Javascript
        and deploy plus a generous free tier.
      </p>
      <p>
        <a href="https://stripe.com/">Stripe</a> is also another great product.
        From documentation to testing and configuration and support for Apple
        and Google pay, everything was a joy to use and simple to integrate into
        the flow I had in mind and seamless to users—big fan.
      </p>
      <p>
        I let this setup run for a few days to make sure everything worked as
        expected before I made my first move into upselling the premium version.
      </p>
      <p>Time to sell.</p>
      <p>
        My initial strategy was to convert existing subscribers first before
        going out to the world.
      </p>
      <p>
        So I crafted an email in a personal tone, where the subject was “<a href="https://preview.mailerlite.com/o2y8k1">It’s launch day!</a>”. In this email, I started by giving an overview where Bullish was at
        and then introducing Bullish Premium for 4.99/mo along with all the
        features we were releasing and a big green call to action button saying,
        “<strong>Subscribe now</strong>.”
      </p>
      <p>
        My honest expectation was to get maybe four or five users to convert,
        but we end up closing ten on the first day. We celebrated with Sushi!
      </p>
      <p>
        That got us to an instant
        <strong>$50 monthly recurring revenue!</strong> Almost ramen
        profitability.
      </p>
      <p>
        The numbers are so small, but you’ve got to start somewhere. I’ve done
        lots of side projects over the years, and they all brought me some
        indirect form of monetization. It was through a side project that I
        ended up in Silicon Valley, but this is the first time I’m directly
        selling things to people.
      </p>
      <p>
        After some validation from the first sales, I moved on to the next big
        topic in my todo—a new website.
      </p>
      <p>
        I’ve put together the first version of the website in a couple of hours
        using my yet-to-be-released static site generator called
        <a href="https://github.com/eduardosasso/leter">Leter</a>, which also
        powers this article by the way.
      </p>
      <figure>
          <img src="https://eduardosasso.co/blog/from-stock-market-side-project-to-micro-saas/first_site.png" alt="First version">
          <figcaption>First version</figcaption>
        </figure>
      
      <p>
        It was Ok but far from what I had in mind, but I had to ship something,
        so I pushed a professional better-looking website for later.
      </p>
      <p>
        I know my weaknesses, and web design is a time sink for me. I’m very
        opinionated, and I like to think I have a good eye for it, but so far, I
        couldn’t deliver anything I was proud of on my own.
      </p>
      <p>
        After learning from my fail attempts over the years trying to come up
        with an exclusive design this time around, I looked for references,
        inspiration, and templates that could help me jump-start the process.
      </p>
      <p>
        As an engineer, I always feel inclined to start everything from scratch,
        and with the new website was no different, the utopian dream of the
        perfect, valid HTML and clean CSS a trap that I fell into way too many
        times but not again.
      </p>
      <p>
        I ended up
        <a href="https://themeforest.net/item/fold-software-and-app-template/24295615">finding a template</a>
        that was pretty close to what I had in mind. I just had to brush off my
        CSS skills and do some customization to take my vision to reality.
      </p>
      <p>
        Of course, I have a list of things to improve like adding archives or a
        way to update the sample email dynamically, but overall I’m pretty happy
        how it turned out.
      </p>
      <figure>
          <img src="https://eduardosasso.co/blog/from-stock-market-side-project-to-micro-saas/new_site.png" alt="New version">
          <figcaption>New version</figcaption>
        </figure>
      
      <p>With the site up and running, it was time to promote it.</p>
      <p>
        Before trying the big leagues on
        <a href="https://www.producthunt.com/">Product Hunt</a>, we tested the
        waters by engaging on Twitter and getting a few subscribers. Then, I
        asked my
        <a href="https://www.linkedin.com/in/abduzeedo/">influencer brother</a>
        to post on his
        <a href="https://www.linkedin.com/feed/update/urn:li:activity:6693739953026945024/">LinkedIn</a>, which generated a nice amount of traffic and about fifty new readers,
        not hockey stick growth but decent.
      </p>
      <p>
        For
        <a href="https://www.producthunt.com/posts/bullish">Product Hunt</a>, we
        scheduled our launch for a Wednesday, and I remember going to sleep that
        night, excited to see what the next day would bring, and we bombed, we
        never made to the frontpage and only got like 20 upvotes it was a total
        disaster.
      </p>
      <p>
        The next day was business as usual, …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eduardosasso.co/blog/from-stock-market-side-project-to-micro-saas/">https://eduardosasso.co/blog/from-stock-market-side-project-to-micro-saas/</a></em></p>]]>
            </description>
            <link>https://eduardosasso.co/blog/from-stock-market-side-project-to-micro-saas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24133575</guid>
            <pubDate>Wed, 12 Aug 2020 16:18:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Education and the Red Queen Effect: Is It Time to Worry?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24133434">thread link</a>) | @MOTF
<br/>
August 12, 2020 | https://dougantin.com/2020/08/12/education-and-the-red-queen-effect-is-it-time-to-worry/ | <a href="https://web.archive.org/web/*/https://dougantin.com/2020/08/12/education-and-the-red-queen-effect-is-it-time-to-worry/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<figure><img data-attachment-id="1437" data-permalink="https://dougantin.com/2020/08/12/education-and-the-red-queen-effect-is-it-time-to-worry/pexels-photo-131615/" data-orig-file="https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?fit=1880%2C1251&amp;ssl=1" data-orig-size="1880,1251" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Photo by George Becker on <a href=\&quot;https:\/\/www.pexels.com\/photo\/black-chess-chess-pieces-close-up-131615\/\&quot; rel=\&quot;nofollow\&quot;>Pexels.com<\/a>&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;black chess chess pieces close up&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pexels-photo-131615" data-image-description="" data-medium-file="https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?fit=1024%2C681&amp;ssl=1" loading="lazy" width="1100" height="732" src="https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?resize=1100%2C732&amp;ssl=1" alt="black chess chess pieces close up" srcset="https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?w=1880&amp;ssl=1 1880w, https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?resize=1024%2C681&amp;ssl=1 1024w, https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?resize=768%2C511&amp;ssl=1 768w, https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?resize=1536%2C1022&amp;ssl=1 1536w, https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?resize=1200%2C799&amp;ssl=1 1200w, https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?resize=1100%2C732&amp;ssl=1 1100w" sizes="(max-width: 1100px) 100vw, 1100px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?w=1880&amp;ssl=1 1880w, https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?resize=1024%2C681&amp;ssl=1 1024w, https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?resize=768%2C511&amp;ssl=1 768w, https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?resize=1536%2C1022&amp;ssl=1 1536w, https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?resize=1200%2C799&amp;ssl=1 1200w, https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?resize=1100%2C732&amp;ssl=1 1100w" data-lazy-src="https://i0.wp.com/dougantin.com/wp-content/uploads/2020/08/pexels-photo-131615.jpeg?resize=1100%2C732&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Photo by George Becker on <a href="https://www.pexels.com/photo/black-chess-chess-pieces-close-up-131615/" rel="nofollow">Pexels.com</a></figcaption></figure>



<h2>Innovating an old system in a world playing a new game.</h2>



<p>The push to innovate how we educate kids hides a simple truth. What we teach is outdated and doesn’t address many skills needed in the digital age. Many education innovations reinforce the growing education bubble. A workforce filled with skills that don’t apply to available opportunities. Training in obsolete skills produces the opposite goal of education. A reduced quality of life for standardized employment paths. </p>



<p>But how could this happen?</p>



<p>It’s simple, we’ve optimized our education systems for industrial era needs. And we’ve done a great job at it. You go to school and you learn skills for a blue or white collar job. You go to college or you enter a service or trade industry.  But these skills are becoming obsolete. As technology advances, societal needs are evolving to require different skills for digital age work. This change is like the <a href="https://fs.blog/2012/10/the-red-queen-effect/">Red Queen Effect</a> popularized by <em><a href="http://<a target=&quot;_blank&quot; href=&quot;https://www.amazon.com/gp/product/0553213458/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0553213458&amp;linkCode=as2&amp;tag=doug5023-20&amp;linkId=336d8b7fae6c29af7fddd71a6e2cf729&quot;>Alice's Adventures in Wonderland &amp; Through the Looking-Glass (Bantam Classics)</a><img src=" &quot;="" ir-na.amazon-adsystem.com="" e="" ir?t="doug5023-20&amp;l=am2&amp;o=1&amp;a=0553213458&quot;&quot;" width="&quot;1&quot;" height="&quot;1&quot;" alt="&quot;&quot;" margin:0px="" data-lazy-src="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">Alice In Wonderland</a></em>.</p>



<p>In the novel, Alice and the Red Queen run in place faster and faster without making any actual progress. It shows the importance co-evolving with the surrounding environment. Ie: the world changes and we must adapt to the changing world or get left behind.</p>



<p>Our education systems are now trying to fit a square peg to a round hole. We are using learning solutions optimized for past societal needs not the requirements of a modern digital workforce.</p>



<p><strong>At the root of the problem</strong> is our standardized and outdated learning objectives. Should all students learn the same things? And is it optimal for each student to be taught the same way? If not, then how can we best deliver alternative paths towards a quality life?</p>



<h2>Why We Need A Change</h2>



<h3>Emergence of New Types of Social Classes</h3>



<p>After WWII, social class divides split by blue and white collar labor. But as the internet arrived, it created new types of occupations and a set of class divide. <strong>Location-based work</strong> <strong>versus digital and increasingly remote work.</strong> </p>



<p>The needs of these two social classes are different from previous generations. As an example, businesses now outsource work to areas of the world with cheaper labor. Location-based work suffers from this globally connected economy that can undercut their cost of living. The emerging digital class however, is becoming location agnostic through their ability to work remotely. This provides digital workers with leverage to extract more value from society. </p>



<p>The recent Presidential Candidate, Andrew Yang wrote of another example of changing social issues <a href="https://www.nytimes.com/2019/11/14/opinion/andrew-yang-jobs.html">in a NY times OP-Ed</a>.  Job elimination by automation. The key is that digital technology and automation disproportionally impacts location-based workers. Adding to the class divide is that the digital workforce is designing and implementing these initiatives impacting other groups of people. </p>



<p>In a global and technologically progressive world, location-based workers face significant life disruption. And this social class is becoming less resilient to these changes. </p>



<p>Societal change is happening but curriculums aren’t being altered to address these changes. We’ve been struck by <a href="https://en.wikipedia.org/wiki/Normalcy_bias#:~:text=Normalcy%20bias%2C%20or%20normality%20bias,and%20its%20potential%20adverse%20effects.">normalcy bias</a>. </p>



<h3>New Innovative Tools Frequently Support Outdated Needs</h3>



<p>The COVID-19 pandemic broke the traditional education delivery model. In-person education is now unsafe and the future of <a href="https://www.wsj.com/articles/new-york-schools-among-few-top-10-districts-reopening-schools-for-in-person-learning-11596635317">traditional schooling is indefinitely uncertain</a>. We’ve turned to using new digital tools like Zoom to deliver education online but it doesn’t work well.  </p>



<p>The teachers are poorly trained for this setting and student engagement is inconsistent.</p>



<figure></figure>



<h3>Inconsistent and Bad Learning Outcomes</h3>



<p>Many students don’t even have access to the same equipment at home. In fact, <a href="https://www.wsj.com/articles/schools-coronavirus-remote-learning-lockdown-tech-11591375078?mod=searchresults&amp;page=1&amp;pos=13">nearly 20% of students</a> don’t have reliable ways to connect to online learning. One study indicates that there is a significant learning loss associated with online education during COVID. Ie: students are more likely to forget what they learned than they otherwise would.  This creates an uneven experience.</p>



<p><a href="https://www.nwea.org/content/uploads/2020/05/Collaborative-Brief_Covid19-Slide-APR20.pdf">“Preliminary COVID slide estimates suggest students will return in fall 2020 with roughly 70% of the learning gains in reading relative to a typical school year.”</a></p>



<h3>Higher Education is Breaking Under the Weight of&nbsp;Debt</h3>



<p>Student debt from college education is above $1.5 trillion. As classes move online during the pandemic, many students are questioning the value of higher education. Many colleges were already under pressure from ballooning student debt and negative job prospects. </p>



<p>As job opportunities fall, students struggle to pay down their debt over their lifetimes. This is a more severe issue <a href="https://www.cnbc.com/2020/07/10/its-a-tough-job-outlook-for-college-graduates-in-the-class-of-2020.html">during a recession and the pandemic.</a>  Combining these facts with the push to exclusively online class format, the college path may no longer be desirable by many. </p>



<h3>Experimenting with New Skills &amp; New Education Formats</h3>



<p>So what are the alternative options? The standardized education process doesn’t work for everyone but there are alternative ways of building skills. The new digital class is separating from the industrial era class structure. This group is characterized by it’s shifting preferences based on the ability to conduct digital work from anywhere in the world.</p>



<p>Here are some examples of alternative models already in progress. </p>



<h3>HomeSchooling Pods</h3>



<p>One new method of teaching is a type of homeschooling sometimes called <a href="https://www.technologyreview.com/2020/07/30/1005810/american-parents-are-setting-up-homeschool-pandemic-pods-microschool/">homeschooling pods</a> or microschools. </p>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>The interesting thing about this is that Jason will be spending *far less* per student than it costs to send kids to public school.</p><p>We could send every single kid to a microschool with a 1:8 teacher:student ratio and *save* money. IMO micro schooling is just a better model. <a href="https://t.co/IoFCaVkVUC">https://t.co/IoFCaVkVUC</a></p></div>— Austen Allred (@Austen) <a href="https://twitter.com/Austen/status/1290529936994795520?ref_src=twsrc%5Etfw">August 4, 2020</a></blockquote>
</div></figure>



<p>These schools are building workarounds for students to get good in-person instruction. But laws are inconsistent across states and many of these laws weren’t built for the reality of schooling during a pandemic.  “In the DC area, for example,&nbsp;<a href="https://hslda.org/post/how-to-comply-with-maryland-s-homeschool-law">laws in Maryland</a>&nbsp;make it illegal for homeschooling parents to hire <em>someone else to teach kids, but&nbsp;<a href="https://hslda.org/post/how-to-comply-with-virginias-homeschool-laws">not in neighboring Virginia</a>.&nbsp;“</em></p>



<p>Microschools present an interesting opportunity to alter curriculums and avoid online instruction. But they may not scale well and there is a fear that they offer advantage to wealthy families over low income students.</p>



<h3>ISA’s</h3>



<p><a href="https://lambdaschool.com/">Lambda School</a> is another interesting method of teaching digital age skills. This program teaches programing skills through a remote learning curriculum. The goal is to provide students with the necessary skills and experience to get an entry level programing job. </p>



<p>It also empowers students of all income demographics to participate through it’s unique Income Sharing Agreements (ISA). Tuition is deferred until course completion and in the event a student cannot afford the tuition, they can pay a percentage of their future incomes. </p>



<p>One drawback to this model at scale is that it does not provide a well rounded education. It focuses on providing the skills needed for a specific subset of jobs. This is significantly different from traditional models of well rounded education. Lambda School also does not currently provide early childhood or high school level educational opportunities. The program is intended to retool adults. </p>



<h3>Certification &amp; Vocational Programs</h3>



<p>Organizations are launching their own education programing. Examples include <a href="https://coursera.community/professional-certificate-community-61/new-google-career-certificates-launching-for-job-seekers-11572">Google’s recent certificate program</a> in partnership with Coursera. The program offers <a href="https://www.coursera.org/collections/google-career-certificates">IT Support and Automation with Python</a> certificates. </p>



<p>There are also vocational and apprenticeship style programing similar to Lambda School but without ISA’s. One example is <a href="https://www.droneforwardinc.com/">Drone Forward</a>, a unique vocational program partnering with drone organizations to teach technical skills required for professions in the industry. Through the program, students as young as 10 years old can participate remotely to learn core business concepts and technical skills through real business projects. </p>



<p>Certifications and vocational programs are frequently industry specific although they frequently provide a well rounded education. </p>



<h2>The Bottom Line</h2>



<p>Many people are operating as if our educational needs are going to stay the same forever. This is illogical. We cannot assume that the skills students to learn now will be the same 10 years from now. The COVID-19 pandemic presents the ideal opportunity to implement drastic change. The reality is that we cannot assume that the parents won’t seek to provide an alternative education for their children to maximize their future success. </p>



<p>So I pose a<em><strong><em><strong> </strong></em></strong></em>question<em><strong><em><strong>: can we use the pandemic to experiment with what we teach and how we teach it? </strong></em></strong></em>Providing multiple options: some in the form of standardized education from the state and some tailored towards individual tools available for self education. Or hybrid models of both.</p>



<p>The common argument against allowing experimentation is lack of fairness and equity. But this is a moot point because none of the current students are experiencing a fair and equitable opportunity under the given circumstances. Should all suffer? </p>



<h3>There is no one size fits all approach</h3>



<p>School districts must take a rational approach to education under an indefinite pandemic and changing societal needs. Governments should focus on building systems that allow parents to make the best choices for their children.  Simultaneously they should free up resources to provide additional support to lower income communities. </p>



<p>Taking a one size fits all approach is a methodology that is breaking. Instead, we should assume sovereign individuals will take personal responsibility for their education and support them in making the best choices. For those not able to do the same, governments should focus on solutions that support them in making a better life for themselves. </p>



<p>Instead of pushing harder for an average and uniform outcome, we should …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dougantin.com/2020/08/12/education-and-the-red-queen-effect-is-it-time-to-worry/">https://dougantin.com/2020/08/12/education-and-the-red-queen-effect-is-it-time-to-worry/</a></em></p>]]>
            </description>
            <link>https://dougantin.com/2020/08/12/education-and-the-red-queen-effect-is-it-time-to-worry/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24133434</guid>
            <pubDate>Wed, 12 Aug 2020 16:04:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JuliaCon 2020 in Retrospective]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24133242">thread link</a>) | @eperim
<br/>
August 12, 2020 | https://invenia.github.io/blog/2020/08/12/juliacon/ | <a href="https://web.archive.org/web/*/https://invenia.github.io/blog/2020/08/12/juliacon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>12 Aug 2020</span></p>
  <p>We at Invenia are heavy users of Julia, and are proud to <a href="https://invenia.github.io/blog/2019/08/09/juliacon/">once again</a> have been a part of <a href="https://juliacon.org/2020/">this year’s JuliaCon</a>. This was the first year the conference was fully online, with about 10,000 registrations and 26,000 people tuning in. Besides being <a href="https://www.youtube.com/watch?v=xN6ZXfKHDPI">sponsors</a> of the conference, Invenia also had several team members attending, helping host sessions, and presenting some of their work.</p>

<p>This year we had five presentations: <a href="https://www.youtube.com/watch?v=XI58hlGA7Is">“Design documents are great, here’s why you should consider one”</a>, by Matt Brzezinski; <a href="https://www.youtube.com/watch?v=B4NfkkkJ7rs">“ChainRules.jl”</a>, by Lyndon White; <a href="https://www.youtube.com/watch?v=xUpX-k0oZmo">“HydroPowerModels.jl: Impacts of Network Simplifications”</a>, by Andrew Rosemberg; <a href="https://www.youtube.com/watch?v=nq6X-w5xgLo">“Convolutional Conditional Neural Processes in Flux”</a>, by Wessel Bruinsma; and <a href="https://www.youtube.com/watch?v=dysmEpX1QoE">“Fast Gaussian processes for time series”</a>, by Will Tebbutt.</p>

<p>JuliaCon always brings some really exciting work, and this year it was no different. We are eager to share some of our highlights.</p>

<h3 id="juliacon-is-not-just-about-research">JuliaCon is not just about research</h3>

<p>There were a lot of good talks and workshops at JuliaCon this year, but one which stood out was “Building microservices and applications in Julia”, by Jacob Quinn. This workshop was about creating a music album management microservice, and provided useful information for both beginners and more experienced users. Jacob explained how to define the architectural layers, solving common problems such as authentication and caching, as well as deploying the service to Google Cloud Platform.</p>

<p>A very interesting aspect of the talk was that it exposed Julia users to the field of software engineering. JuliaCon usually has a heavy emphasis on academic and research-focused talks, so it was nice to see the growth of a less represented field within the community. There were a few other software engineering related talks, but having a hands-on practical approach is a great way to showcase a different approach to architecting code.</p>

<p>Among the other software engineering talks and posters, we can highlight <a href="https://live.juliacon.org/talk/KCP9NT">“Reproducible environments with Singularity”</a>, by Steffen Ridderbusch; the aforementioned <a href="https://youtu.be/XI58hlGA7Is">“Design documents are great, here’s why you should consider one”</a>, by Matt Brzezinski; <a href="https://youtu.be/nkSuEkmsB28">“Dispatching Design Patterns”</a>, by Aaron Christianson; and <a href="https://live.juliacon.org/uploads/posters/M8KTBL.pdf">“Fantastic beasts and how to show them”</a>, by Joris Kraak.</p>



<p>The conference kicked off with a brief and fun session on work related to Gaussian processes, including our own Will Tebbutt who talked about <a href="https://www.youtube.com/watch?v=dysmEpX1QoE">TemporalGPs.jl</a>, which provides fast inference for certain types of GP models for time series, as well as Théo Galy-Fajou’s talk on <a href="https://www.youtube.com/watch?v=0fKGICZrk3w">KernelFunctions.jl</a>. Although there was no explicit talk on the topic, there were productive discussions about the move towards a common set of abstractions provided by <a href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/">AbstractGPs.jl</a>.</p>

<p>It was also great to see so many people at the <a href="https://discourse.julialang.org/t/juliacon-2020-birds-of-a-feather/39181">Probabilistic Programming Bird of a Feather</a>, and it feels like there is a proper community in Julia working on various approaches to problems in Probabilistic Programming. There were discussions around helpful abstractions, and whether there are common ones that can be more widely shared between projects. A commitment was made to having monthly discussions aimed at understanding how the wider community is approaching Probabilistic Programming.</p>

<p>Another interesting area that ties into both our work on <a href="https://github.com/JuliaDiff/ChainRules.jl/">ChainRules.jl</a>, the AD ecosystem and the Probabilistic Programming world, is Keno Fischer’s work. He has been working on improving the degree to which you can manipulate the compiler and changing the points at which you can inject additional compiler passes. This intends to mitigate the type-inference issues that plague <a href="https://github.com/jrevels/Cassette.jl">Cassette.jl</a> and <a href="https://github.com/FluxML/IRTools.jl">IRTools.jl</a>. Those issues lead to problems in <a href="https://github.com/FluxML/Zygote.jl/">Zygote.jl</a> (and other tools). We expect great things from changes to how compiler pass injection works with the compiler’s usual optimisation passes.</p>

<p>Finally, Chris Elrod’s work on <a href="https://github.com/chriselrod/LoopVectorization.jl">LoopVectorization.jl</a> is very exciting for performance. <a href="https://www.youtube.com/watch?v=qz2kJdVDWi0">His talk</a> contained an interesting example involving Automatic Differentiation (AD), and we’re hoping to help him integrate this insight into <a href="https://github.com/JuliaDiff/ChainRules.jl/">ChainRules.jl</a> in the upcoming months.</p>



<p>This year we saw a significant number of projects on direct applications to engineering, including interesting work on <a href="https://pretalx.com/juliacon2020/talk/review/APWY839YWNAYXCG9GXSVWJJLP7LQ98DW">steel truss design</a> and <a href="https://pretalx.com/juliacon2020/talk/review/KY87TTQHX9BSHQPDT8HHSTDVZ3G8CJJG">structural engineering</a>. Part of why the engineering community is fond of Julia is the type structure paired with multiple dispatch, which allows developers to easily extend types and functions from other packages, and build complex frameworks in a Lego-like manner.</p>

<p>A direct application of Julia in engineering that leverages the existing ecosystem is <a href="https://www.youtube.com/watch?v=xUpX-k0oZmo">HydroPowerModels.jl</a>, developed by our own Andrew Rosemberg. HydroPowerModels.jl is a tool for planning and simulating the operation of hydro-dominated power systems. It builds on three main dependencies (PowerModels.jl, SDDP.jl, and JuMP.jl) to efficiently construct and solve the desired problem.</p>

<p>The pipeline for HydroPowerModels.jl uses <a href="https://github.com/lanl-ansi/PowerModels.jl">PowerModels.jl</a>—a package for parsing system data and modeling optimal power flow (OPF) problems—to build the OPF problem as a JuMP.jl model. Then the model is modified in <a href="https://github.com/jump-dev/JuMP.jl">JuMP.jl</a> to receive the appropriate hydro variables and constraints. Lastly, it is passed to <a href="https://github.com/odow/SDDP.jl">SDDP.jl</a>, which builds the multistage problem and provides a solution algorithm (SDDP) to solve it.</p>

<h3 id="there-were-several-tools-for-working-with-networks-and-graphs">There were several tools for working with networks and graphs</h3>

<p>As a company that works on problems related to electricity grids, new developments on how to deal with networks and graphs are always interesting. Several talks this year featured useful new tools.</p>

<p><a href="https://github.com/yuehhua/GeometricFlux.jl">GeometricFlux.jl</a> adds to <a href="https://github.com/FluxML/Flux.jl">Flux.jl</a> the capability to perform deep learning on graph-structured data. This area of research is <a href="https://arxiv.org/abs/1611.08097">opening up</a> new opportunities in diverse applications such as social network analysis, protein folding, and natural language processing. GeometricFlux.jl defines several types of graph-convolutional layers.  Also of particular interest is the ability to define a <code>FeaturedGraph</code>, where you specify not just the structure of the graph, but can also provide feature vectors for individual nodes and edges.</p>

<p>Practical applications of networks were shown in talks on economics and energy systems.</p>

<p>Work done by the Federal Reserve Bank of New York on <a href="https://www.youtube.com/watch?v=q3KoMloafwY">Estimation of Macroeconomic Models</a> showed how Julia is being applied to speed up calculations on equilibrium models, which are a classic way of simulating the interconnections in the economy and how interventions such as policy changes can have rippling impacts through the system.  Similarly, work by the National Renewable Energy Laboratory (NREL) on <a href="https://www.youtube.com/watch?v=IU4PVKTVNTI">Intertwined Economic and Energy Analysis using Julia</a> demonstrated equilibrium models that couple economic and energy systems.</p>

<p>Quite a few talks dealt specifically with power networks. These systems can be computationally challenging to model, particularly when considering the complexity of actual large-scale power grids and not simple test cases.   <a href="https://www.youtube.com/watch?v=GrmnbDYr6mM">NetworkDynamics.jl</a> allows for modelling dynamic systems on networks, by bridging existing work in LightGraphs.jl and DifferentialEquations.jl.  This has, in turn, been used to help build <a href="https://juliaenergy.github.io/PowerDynamics.jl/stable/">PowerDynamics.jl</a>.  Approaches to speed up power simulations were discussed in <a href="https://www.youtube.com/watch?v=RKtIxZfhdXU">A Parallel Time-Domain Power System Simulation Toolbox in Julia</a>.  Finally, another talk by NREL on a <a href="https://www.youtube.com/watch?v=kQNOG4tGJdg">Crash Course in Energy Systems Modeling &amp; Analysis with Julia</a> showed off a collection of packages for power simulations they are developed.</p>

<h3 id="this-year-the-whole-event-happened-online">This year the whole event happened online</h3>

<p>It may not have been the JuliaCon we envisioned, but the organisers this year did an incredible job in adjusting to extraordinary circumstances and hosting an entirely virtual conference.</p>

<p>A distinct silver lining in moving online is that attendance was free, which opened the conference up to a much larger community. The boost in attendance no doubt increased the engagement with contributors to the Julia project and provided presenters with a much wider audience than would otherwise be possible in a lecture hall.</p>

<p>Even with the usual initialization issues with conference calls (“Can you hear me now?”), the technical set-up of the conference was superb. In previous years, JuliaCon had the talks swiftly available on YouTube and this year they outdid themselves by simultaneously live-streaming multiple tracks. Being able to pause and rewind live talks and switch between tracks without leaving the room made for a convenient viewing experience. The Discord forum also proved great for interacting with others and for asking questions in a manner that may have appealed to the more shy audience members.</p>

<p>Perhaps the most pivotal, yet inconspicuous, benefit of hosting JuliaCon online is the considerably reduced carbon footprint. Restricted international movement has brought to light the travel industry’s impact on the planet and international conferences have their role to play. Maybe the time has come for communities that are underpinned by strong social and scientific principles, like the Julia community, to make the reduction of emissions an explicit priority in future gatherings.</p>

<p>In spite of JuliaCon’s overall success, there are still kinks to iron out in the online conference experience: the digital interface makes it difficult to spontaneously engage with other participants, which tends to be one of the main reasons to attend conferences in the first place, and the lack of “water cooler”-talk (although <a href="https://gather.town/rBrwIUqeDkb5JTxu/juliacon2020">Gather.Town</a> certainly helped in providing a similar experience) means missed connections and opportunities for ideas to cross-pollinate. Not for a lack of trying, JuliaCon seemed to miss an atmosphere that can only be captured by being in the same physical space as the community. We don’t doubt that the online experience will improve in the future one way or the other, but JuliaCon certainly hit the ground running.</p>

<p>We look forward to seeing what awaits for JuliaCon 2021, and we’ll surely be part of it once more, however it happens.</p>

</div>





    </div></div>]]>
            </description>
            <link>https://invenia.github.io/blog/2020/08/12/juliacon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24133242</guid>
            <pubDate>Wed, 12 Aug 2020 15:49:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aha launches SaaS fellowship for underrepresented groups in tech]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24133164">thread link</a>) | @optimizethis
<br/>
August 12, 2020 | https://www.aha.io/blog/aha-fellowship?ref=producthunt | <a href="https://web.archive.org/web/*/https://www.aha.io/blog/aha-fellowship?ref=producthunt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article><div><p><img src="data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAkACQAAD/4g/wSUNDX1BST0ZJTEUAAQEAAA/gYXBwbAIQAABtbnRyUkdCIFhZWiAH5AAFAAQACQAAACZhY3NwQVBQTAAAAABBUFBMAAAAAAAAAAAAAAAAAAAAAAAA9tYAAQAAAADTLWFwcGwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABJkZXNjAAABXAAAAGJkc2NtAAABwAAABIJjcHJ0AAAGRAAAACN3dHB0AAAGaAAAABRyWFlaAAAGfAAAABRnWFlaAAAGkAAAABRiWFlaAAAGpAAAABRyVFJDAAAGuAAACAxhYXJnAAAOxAAAACB2Y2d0AAAO5AAAADBuZGluAAAPFAAAAD5jaGFkAAAPVAAAACxtbW9kAAAPgAAAACh2Y2dwAAAPqAAAADhiVFJDAAAGuAAACAxnVFJDAAAGuAAACAxhYWJnAAAOxAAAACBhYWdnAAAOxAAAACBkZXNjAAAAAAAAAAhEaXNwbGF5AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbWx1YwAAAAAAAAAmAAAADGhySFIAAAAUAAAB2GtvS1IAAAAMAAAB7G5iTk8AAAASAAAB+GlkAAAAAAASAAACCmh1SFUAAAAUAAACHGNzQ1oAAAAWAAACMGRhREsAAAAcAAACRm5sTkwAAAAWAAACYmZpRkkAAAAQAAACeGl0SVQAAAAUAAACiGVzRVMAAAASAAACnHJvUk8AAAASAAACnGZyQ0EAAAAWAAACrmFyAAAAAAAUAAACxHVrVUEAAAAcAAAC2GhlSUwAAAAWAAAC9HpoVFcAAAAKAAADCnZpVk4AAAAOAAADFHNrU0sAAAAWAAADInpoQ04AAAAKAAADCnJ1UlUAAAAkAAADOGVuR0IAAAAUAAADXGZyRlIAAAAWAAADcG1zAAAAAAASAAADhmhpSU4AAAASAAADmHRoVEgAAAAMAAADqmNhRVMAAAAYAAADtmVuQVUAAAAUAAADXGVzWEwAAAASAAACnGRlREUAAAAQAAADzmVuVVMAAAASAAAD3nB0QlIAAAAYAAAD8HBsUEwAAAASAAAECGVsR1IAAAAiAAAEGnN2U0UAAAAQAAAEPHRyVFIAAAAUAAAETHB0UFQAAAAWAAAEYGphSlAAAAAMAAAEdgBMAEMARAAgAHUAIABiAG8AagBpzuy37AAgAEwAQwBEAEYAYQByAGcAZQAtAEwAQwBEAEwAQwBEACAAVwBhAHIAbgBhAFMAegDtAG4AZQBzACAATABDAEQAQgBhAHIAZQB2AG4A/QAgAEwAQwBEAEwAQwBEAC0AZgBhAHIAdgBlAHMAawDmAHIAbQBLAGwAZQB1AHIAZQBuAC0ATABDAEQAVgDkAHIAaQAtAEwAQwBEAEwAQwBEACAAYwBvAGwAbwByAGkATABDAEQAIABjAG8AbABvAHIAQQBDAEwAIABjAG8AdQBsAGUAdQByIA8ATABDAEQAIAZFBkQGSAZGBikEGgQ+BDsETAQ+BEAEPgQyBDgEOQAgAEwAQwBEIA8ATABDAEQAIAXmBdEF4gXVBeAF2V9pgnIATABDAEQATABDAEQAIABNAOAAdQBGAGEAcgBlAGIAbgD9ACAATABDAEQEJgQyBDUEQgQ9BD4EOQAgBBYEGgAtBDQEOARBBD8EOwQ1BDkAQwBvAGwAbwB1AHIAIABMAEMARABMAEMARAAgAGMAbwB1AGwAZQB1AHIAVwBhAHIAbgBhACAATABDAEQJMAkCCRcJQAkoACAATABDAEQATABDAEQAIA4qDjUATABDAEQAIABlAG4AIABjAG8AbABvAHIARgBhAHIAYgAtAEwAQwBEAEMAbwBsAG8AcgAgAEwAQwBEAEwAQwBEACAAQwBvAGwAbwByAGkAZABvAEsAbwBsAG8AcgAgAEwAQwBEA4gDswPHA8EDyQO8A7cAIAO/A7gDzAO9A7cAIABMAEMARABGAOQAcgBnAC0ATABDAEQAUgBlAG4AawBsAGkAIABMAEMARABMAEMARAAgAGEAIABDAG8AcgBlAHMwqzDpMPwATABDAEQAAHRleHQAAAAAQ29weXJpZ2h0IEFwcGxlIEluYy4sIDIwMjAAAFhZWiAAAAAAAADzFgABAAAAARbKWFlaIAAAAAAAAIJ2AAA9Kf///7xYWVogAAAAAAAATDkAALS4AAAK6VhZWiAAAAAAAAAoJgAADh8AAMiIY3VydgAAAAAAAAQAAAAABQAKAA8AFAAZAB4AIwAoAC0AMgA2ADsAQABFAEoATwBUAFkAXgBjAGgAbQByAHcAfACBAIYAiwCQAJUAmgCfAKMAqACtALIAtwC8AMEAxgDLANAA1QDbAOAA5QDrAPAA9gD7AQEBBwENARMBGQEfASUBKwEyATgBPgFFAUwBUgFZAWABZwFuAXUBfAGDAYsBkgGaAaEBqQGxAbkBwQHJAdEB2QHhAekB8gH6AgMCDAIUAh0CJgIvAjgCQQJLAlQCXQJnAnECegKEAo4CmAKiAqwCtgLBAssC1QLgAusC9QMAAwsDFgMhAy0DOANDA08DWgNmA3IDfgOKA5YDogOuA7oDxwPTA+AD7AP5BAYEEwQgBC0EOwRIBFUEYwRxBH4EjASaBKgEtgTEBNME4QTwBP4FDQUcBSsFOgVJBVgFZwV3BYYFlgWmBbUFxQXVBeUF9gYGBhYGJwY3BkgGWQZqBnsGjAadBq8GwAbRBuMG9QcHBxkHKwc9B08HYQd0B4YHmQesB78H0gflB/gICwgfCDIIRghaCG4IggiWCKoIvgjSCOcI+wkQCSUJOglPCWQJeQmPCaQJugnPCeUJ+woRCicKPQpUCmoKgQqYCq4KxQrcCvMLCwsiCzkLUQtpC4ALmAuwC8gL4Qv5DBIMKgxDDFwMdQyODKcMwAzZDPMNDQ0mDUANWg10DY4NqQ3DDd4N+A4TDi4OSQ5kDn8Omw62DtIO7g8JDyUPQQ9eD3oPlg+zD88P7BAJECYQQxBhEH4QmxC5ENcQ9RETETERTxFtEYwRqhHJEegSBxImEkUSZBKEEqMSwxLjEwMTIxNDE2MTgxOkE8UT5RQGFCcUSRRqFIsUrRTOFPAVEhU0FVYVeBWbFb0V4BYDFiYWSRZsFo8WshbWFvoXHRdBF2UXiReuF9IX9xgbGEAYZRiKGK8Y1Rj6GSAZRRlrGZEZtxndGgQaKhpRGncanhrFGuwbFBs7G2MbihuyG9ocAhwqHFIcexyjHMwc9R0eHUcdcB2ZHcMd7B4WHkAeah6UHr4e6R8THz4faR+UH78f6iAVIEEgbCCYIMQg8CEcIUghdSGhIc4h+yInIlUigiKvIt0jCiM4I2YjlCPCI/AkHyRNJHwkqyTaJQklOCVoJZclxyX3JicmVyaHJrcm6CcYJ0kneierJ9woDSg/KHEooijUKQYpOClrKZ0p0CoCKjUqaCqbKs8rAis2K2krnSvRLAUsOSxuLKIs1y0MLUEtdi2rLeEuFi5MLoIuty7uLyQvWi+RL8cv/jA1MGwwpDDbMRIxSjGCMbox8jIqMmMymzLUMw0zRjN/M7gz8TQrNGU0njTYNRM1TTWHNcI1/TY3NnI2rjbpNyQ3YDecN9c4FDhQOIw4yDkFOUI5fzm8Ofk6Njp0OrI67zstO2s7qjvoPCc8ZTykPOM9Ij1hPaE94D4gPmA+oD7gPyE/YT+iP+JAI0BkQKZA50EpQWpBrEHuQjBCckK1QvdDOkN9Q8BEA0RHRIpEzkUSRVVFmkXeRiJGZ0arRvBHNUd7R8BIBUhLSJFI10kdSWNJqUnwSjdKfUrESwxLU0uaS+JMKkxyTLpNAk1KTZNN3E4lTm5Ot08AT0lPk0/dUCdQcVC7UQZRUFGbUeZSMVJ8UsdTE1NfU6pT9lRCVI9U21UoVXVVwlYPVlxWqVb3V0RXklfgWC9YfVjLWRpZaVm4WgdaVlqmWvVbRVuVW+VcNVyGXNZdJ114XcleGl5sXr1fD19hX7NgBWBXYKpg/GFPYaJh9WJJYpxi8GNDY5dj62RAZJRk6WU9ZZJl52Y9ZpJm6Gc9Z5Nn6Wg/aJZo7GlDaZpp8WpIap9q92tPa6dr/2xXbK9tCG1gbbluEm5rbsRvHm94b9FwK3CGcOBxOnGVcfByS3KmcwFzXXO4dBR0cHTMdSh1hXXhdj52m3b4d1Z3s3gReG54zHkqeYl553pGeqV7BHtje8J8IXyBfOF9QX2hfgF+Yn7CfyN/hH/lgEeAqIEKgWuBzYIwgpKC9INXg7qEHYSAhOOFR4Wrhg6GcobXhzuHn4gEiGmIzokziZmJ/opkisqLMIuWi/yMY4zKjTGNmI3/jmaOzo82j56QBpBukNaRP5GokhGSepLjk02TtpQglIqU9JVflcmWNJaflwqXdZfgmEyYuJkkmZCZ/JpomtWbQpuvnByciZz3nWSd0p5Anq6fHZ+Ln/qgaaDYoUehtqImopajBqN2o+akVqTHpTilqaYapoum/adup+CoUqjEqTepqaocqo+rAqt1q+msXKzQrUStuK4trqGvFq+LsACwdbDqsWCx1rJLssKzOLOutCW0nLUTtYq2AbZ5tvC3aLfguFm40blKucK6O7q1uy67p7whvJu9Fb2Pvgq+hL7/v3q/9cBwwOzBZ8Hjwl/C28NYw9TEUcTOxUvFyMZGxsPHQce/yD3IvMk6ybnKOMq3yzbLtsw1zLXNNc21zjbOts83z7jQOdC60TzRvtI/0sHTRNPG1EnUy9VO1dHWVdbY11zX4Nhk2OjZbNnx2nba+9uA3AXcit0Q3ZbeHN6i3ynfr+A24L3hROHM4lPi2+Nj4+vkc+T85YTmDeaW5x/nqegy6LzpRunQ6lvq5etw6/vshu0R7ZzuKO6070DvzPBY8OXxcvH/8ozzGfOn9DT0wvVQ9d72bfb794r4Gfio+Tj5x/pX+uf7d/wH/Jj9Kf26/kv+3P9t//9wYXJhAAAAAAADAAAAAmZmAADypwAADVkAABPQAAAKW3ZjZ3QAAAAAAAAAAQABAAAAAAAAAAEAAAABAAAAAAAAAAEAAAABAAAAAAAAAAEAAG5kaW4AAAAAAAAANgAArgAAAFIAAABDwAAAsMAAACbAAAANQAAAUAAAAFRAAAIzMwACMzMAAjMzAAAAAAAAAABzZjMyAAAAAAABDHIAAAX4///zHQAAB7oAAP1y///7nf///aQAAAPZAADAcW1tb2QAAAAAAAAGEAAAoDQAAAAA0hZ4gAAAAAAAAAAAAAAAAAAAAAB2Y2dwAAAAAAADAAAAAmZmAAMAAAACZmYAAwAAAAJmZgAAAAIzMzQAAAAAAjMzNAAAAAACMzM0AP/bAEMAAwICAwICAwMDAwQDAwQFCAUFBAQFCgcHBggMCgwMCwoLCw0OEhANDhEOCwsQFhARExQVFRUMDxcYFhQYEhQVFP/bAEMBAwQEBQQFCQUFCRQNCw0UFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFP/AABEIAAsAFAMBEQACEQEDEQH/xAAXAAADAQAAAAAAAAAAAAAAAAACBggH/8QAJBAAAgIBBAICAwEAAAAAAAAAAQIDBAUABhEhBxIiQRMVMVH/xAAXAQEBAQEAAAAAAAAAAAAAAAACAwQF/8QAIBEAAgICAgIDAAAAAAAAAAAAAQIAAxEhEjITMVFxof/aAAwDAQACEQMRAD8AY9w3NuYDDZHNPNSs2sVXltR1XnVWLrGT6jvkEjrr6Oi68us0KeO2mvbh8WPsjZtTdkd+raXI3KUL0oq/oEaxIiEiUSMGK+3Pajnj61PxGvsd/UAsFhGB+wv15j+J+tVCmIrg7kF+UNz5PHZDNVatkV67VJI3SONF/IrTKrB+vlyOu+dPyMpyPgzQakZBkRYx+/tx4fDrJWzd0Ml1ZkEsxlVXCDghX5A4PfAHGsFtjY9w0opJ1Lg8A7vy+9/F2Ly+buG9kZWlV5jGiewWRgOlAH8H+a61W0BMjZ2n/9k=" alt="New Aha! Fellowship Program Launched to Create More Opportunity in Tech"></p></div><p>August 11, 2020</p><p>Every single person has value. That belief is core to how Aha! operates and why we do our best to always put people first.&nbsp;Over the last few years, we have contributed more than $250,000  to nonprofits through <a href="https://www.aha.io/company/cares">Aha! Cares</a>, which encompasses our philanthropic efforts. It was created to support people's most basic needs — food, safety, and shelter. But recent events, which painfully revealed the breadth and depth of injustice, made us look harder at ourselves and to more thoughtfully consider what actions we should take to support social change. </p><blockquote>Aha! Cares was missing a critical need, one that is as fundamental as food, safety, or shelter —&nbsp;opportunity. </blockquote><p>So on June 22, <a href="https://www.aha.io/blog/aha-launches-new-programs-to-support-social-justice">we announced</a> that we added opportunity to the three existing pillars of Aha! Cares. And we shared our plans to financially support social justice organizations, better educate ourselves, and launch a new fellowship program. The goal of the fellowship is to provide training and enhance the diversity of people in software, including those from historically underrepresented racial, ethnic, and disadvantaged groups.</p><p>We already offer advanced product management training through <a href="https://www.aha.io/academy">Aha! Academy</a>. But we knew we could do more and that was where the idea for the fellowship came from. We wanted to share our knowledge, make a real impact, and create more opportunity. We spent the last month and a half researching the best way to design a program that is truly unique.</p><blockquote>I am thrilled to share that we are seeking applications now through September 4 for the first <a href="https://www.aha.io/academy/fellowship">Aha! fellowship program</a>.</blockquote><p>Let me share a little more about what makes this program so unique. It is a full-time and immersive practicum — eight weeks of online seminars led by our experts along with a small group project. Attendees will receive a monthly stipend of $4,200. </p><p>The program includes a mix of hands-on experience, peer collaboration, and mentorship for maximum skill-building. Our goal is to help prepare people to build, launch, and support innovative products. The curriculum is built around three key areas:</p><h2 id="entrepreneurship"><strong>Entrepreneurship</strong></h2><p>Company-building fundamentals —&nbsp;from developing a business plan and model to defining strategic goals and initiatives.</p><h2 id="product-management"><strong>Product management</strong></h2><p>Product development fundamentals —&nbsp;from developing customer empathy and building roadmaps to defining user journeys and reporting on key metrics.</p><h2 id="customer-success"><strong>Customer success</strong></h2><p>Customer support fundamentals —&nbsp;from conducting expert product demos to communicating effectively with customers.</p><blockquote>I look forward to welcoming the first group of fellows and learning together.</blockquote><p>We want this to be a<span> sustainable program that creates real value for others. If you are not eligible or able to apply, you can help us by </span><a href="https://fellowship.ideas.aha.io/ideas/new?_ga=2.34669281.1145035220.1597069464-1221933143.1590792113" target="_blank" rel="noopener noreferrer"><span>sharing the application</span></a><span> with people you think would benefit from it or by posting it in online groups that promote professional development.  </span></p></article></div></div></div>]]>
            </description>
            <link>https://www.aha.io/blog/aha-fellowship?ref=producthunt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24133164</guid>
            <pubDate>Wed, 12 Aug 2020 15:42:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raise Less Money]]>
            </title>
            <description>
<![CDATA[
Score 283 | Comments 105 (<a href="https://news.ycombinator.com/item?id=24133146">thread link</a>) | @Harj
<br/>
August 12, 2020 | https://www.aaronkharris.com/raise-less-money | <a href="https://web.archive.org/web/*/https://www.aaronkharris.com/raise-less-money">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      <div><p>Over the last few years, I’ve noticed that good companies are increasingly over-diluting themselves in their seed and A rounds. Counterintuitively, dilution seems to rise along with price. One would expect the opposite correlation. Strong founders who command high prices should be using that higher price to sell less of their companies in exchange for money to grow. As I’ve tried to understand what’s going on, I’ve tried several arguments.</p><p>Somewhere in the last week, I’ve come to understand an error I’ve been making when talking to founders about how much money to raise. I realized that the conversation about raising always anchors back to the idea of adding “months of runway.” That always seemed appropriate to me because it was a measure of the amount of time a company had to stay alive. Staying alive seemed good since it increased the time a company had to find product market fit and to grow.</p><p>But I now realize that this is the wrong framing because simply staying alive is an inadequate goal for a company.&nbsp; Founders start companies to find product market fit and grow. Venture capital is designed to speed growth, not to extend runway.</p><p>As a result, in recent conversations, I’ve started to ask founders: “How much could you get done in the next 12 months with the amount of capital you are planning to raise? If you’re a good company, you’re either going to raise your Series A - or Series B - in the next 12 months or have significant revenue such that you won’t need more capital.[1] If you’re doing badly, why would you want to keep working on this for 24 or 36 months? That’s a waste of your time.”</p><p>Founders who raise too much capital are acting out of fear rather than acting out of confidence. This fear made sense ten years ago when seed financing was relatively scarce. This is when much of the fundraising advice I read as a founder was written. However, the world has changed and so should the advice</p><p>Financing is more accessible to good founders than it has ever been.[2] Confident, competent founders should take the risk of running out of money vs. the certainty of over-dilution.</p><p>Good founders respond to this framework as it shifts the argument from one in which “winning” is about adding months of runway to the bank to one in which “winning” is fast and high quality execution - as evidenced by hitting milestones. It’s also easy to draw a straight line from this framing to the best companies. When a company raises a Series A nine months after launch - or Demo Day - with 80% of its seed funds in the bank, it’s apparent that those founders sold too much.[3]</p><p>A founder’s decision on how much money to raise in any given round is more art than science. It is a fraught decision since it necessarily forces founders to make predictions about the future. There is no perfect answer, and <a href="https://www.ycombinator.com/library/3P-how-to-optimize-your-fundraising-round" target="_blank">over-optimizing</a> around any single factor is a mistake. However, it seems clear that shifting the goal of fundraising from adding runway to progress would limit both the amount of money companies believe they need and the dilution that founders take in the process of building successful startups.</p><p>__</p><p>[1] And if this is true, investors will chase you anyway.</p><p>[2] Even during COVID. I did not expect this to be true, however, this market is one of the most active I've ever seen.</p><p>[3] Seeing this dynamic on a regular basis while running YC's Series A program is what led me to realize my mistake. Without fail, the founders raising the most competitive rounds have the most capital left, and thereby the most unnecessary dilution.</p><p><i>Thank you to Daniel Gackle and Michael Seibel for your thoughts and edits.</i><br></p></div>
    
  </div></div>]]>
            </description>
            <link>https://www.aaronkharris.com/raise-less-money</link>
            <guid isPermaLink="false">hacker-news-small-sites-24133146</guid>
            <pubDate>Wed, 12 Aug 2020 15:40:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[QEMU should move from C to Rust]]>
            </title>
            <description>
<![CDATA[
Score 206 | Comments 208 (<a href="https://news.ycombinator.com/item?id=24133128">thread link</a>) | @rwmj
<br/>
August 12, 2020 | http://blog.vmsplice.net/2020/08/why-qemu-should-move-from-c-to-rust.html | <a href="https://web.archive.org/web/*/http://blog.vmsplice.net/2020/08/why-qemu-should-move-from-c-to-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><b>Welcome Redditors and HackerNews folks!</b> <i>This post is getting attention outside the QEMU community, so I'd like to highlight two things that may not be immediately clear: I am a QEMU maintainer and I'm not advocating to Rewrite It In Rust. Enjoy! :)</i></p>

<p>My KVM Forum 2018 presentation titled <a href="https://vmsplice.net/~stefan/stefanha-kvm-forum-2018.pdf">Security in QEMU: How Virtual Machines provide Isolation (pdf)</a> <a href="https://www.youtube.com/watch?v=YAdRf_hwxU8">(video)</a> reviewed security bugs in QEMU and found the most common causes were C programming bugs. This includes buffer overflows, use-after-free, uninitialized memory, and more. In this post I will argue for using Rust as a safer language that prevents these classes of bugs.</p>
        <p>In 2018 the choice of a safer language was not clear. C++ offered safe abstractions without an effective way to prohibit unsafe language features. Go also offered safety but with concerns about runtime costs. Rust looked promising but few people had deep experience with it. In 2018 I was not able to argue confidently for moving away from C in QEMU.</p>
        <p>Now in 2020 the situation is clearer. C programming bugs are still the main cause of <a href="https://www.cvedetails.com/vulnerability-list.php?vendor_id=7506">CVEs in QEMU</a>. Rust has matured, its ecosystem is growing and healthy, and there are virtualization projects like <a href="https://chromium.googlesource.com/chromiumos/platform/crosvm/">Crosvm</a>, <a href="https://github.com/firecracker-microvm/firecracker/">Firecracker</a>, and <a href="https://github.com/cloud-hypervisor/cloud-hypervisor">cloud-hypervisor</a> that prove Rust is an effective language for writing Virtual Machine Monitors (VMM). In the QEMU community Paolo Bonzini and Sergio Lopez's work on <a href="https://github.com/rust-vmm/">rust-vmm</a> and vhost-user code inspired me to look more closely at moving away from C.</p>

        <h2>Do we need to change programming language?</h2>
        <p>Most <a href="https://www.cvedetails.com/vulnerability-list.php?vendor_id=7506">security bugs in QEMU</a> are C programming bugs. This is easy to verify by looking through the CVE listings. Although I have only reviewed CVEs it seems likely that non-security bugs are also mostly C programming bugs.</p>

        <p>Eliminating C programming bugs does not necessarily require switching programming languages. Other approaches to reducing bug rates in software include:
        </p><ul>
            <li>Coding style rules that forbid unsafe language features.</li>
            <li>Building safe abstractions and prohibiting unsafe language features or library APIs.</li>
            <li>Static checkers that scan source code for bugs.</li>
            <li>Dynamic sanitizers that run software with instrumentation to identify bugs.</li>
            <li>Unit testing and fuzzing.</li>
        </ul>
        

        <p>The problem is, the QEMU community has been doing these things for years but new bugs are still introduced despite these efforts. It is certainly possible to spend more energy on these efforts but the evidence shows that bugs continue to slip through.</p>

        <p>There are two issues with these approaches to reducing bugs. First,
        although these approaches help find existing bugs, eliminating classes
        of bugs so they cannot exist in the first place is a stronger approach.
        This is hard to do with C since the language is unsafe, placing the
        burden of safety on the programmer.</p>

        <p>Second, much of the ability to write safe C code comes with
        experience. Custom conventions, APIs, tooling, and processes
        to reduce bugs is a hurdle for one-time contributors or
        newcomers. It makes the codebase inaccessible unless we accept lower
        standards for some contributors. Code quality should depend as little
        on experience as possible but C is notorious for being a programming
        language that requires a lot of practice before you can write
        production-quality code.</p>

        <h2>Why Rust?</h2>
        <p>Safe languages eliminate memory safety bugs (and other classes like
        concurrency bugs). <a href="https://www.rust-lang.org/">Rust</a> made this a priority in its design:
        </p><ul>
            <li>Use-after-free, double-free, memory leaks, and other lifetime bugs are prevented at compile-time by the <a href="https://doc.rust-lang.org/1.8.0/book/references-and-borrowing.html">borrow checker</a> where the compiler checks ownership of data.</li>
            <li>Buffer overflows and other memory corruptions are prevented by compile-time and runtime bounds-checking.</li>
            <li>Pointer deference bugs are prevented by the absense of NULL pointers and strict ownership rules.</li>
            <li>Uninitialized memory is prevented because all variables and fields must be initialized.</li>
        </ul>
        

        <p>Rust programs can still "panic" at runtime when safety cannot be
        proven at compile time but this does not result in undefined behavior
        as seen in C programs. The program simply aborts with a backtrace. Bugs
        that could have resulted in arbitrary code execution in C become at
        most denial-of-service bugs in Rust. This reduces the severity of
        bugs.</p>

        <p>As a result of this language design most C programming bugs that
        plague QEMU today are either caught by the compiler or turn into a safe
        program termination. It is reasonable to expect CVEs to reduce in
        number and in severity when switching to Rust.</p>

        <p>At the same time Rust eliminates the need for many of the measures
        that the QEMU community added onto C because the Rust programming
        language and its compiler already enforce safety. This means newcomers
        and one-time contributors will not need QEMU-specific experience, can
        write production-quality code more easily, and can get their code
        merged more quickly. It also means reviewers will have to spend less
        time pointing out C programming bugs or asking for changes that comply
        with QEMU's way of doing things.</p>

        <p>That said, Rust has a reputation for being a scary language due to
        the borrow checker. Most programmers have not thought about object
        lifetimes and ownership as systematically and explicitly as required
        by Rust. This raises the bar to learning the language, but I look at it
        this way: learning Rust is humanly possible, writing bug-free C code is
        not.</p>

        <h2>How can we change programming language?</h2>
        <p>When I checked in 2018 QEMU was 1.5 million lines of code. It has
        grown since then. Moving a large codebase to a new programming language
        is extremely difficult. If people want to convert QEMU to Rust that
        would be great, but I personally don't have the appetite to do it
        because I think the integration will be messy, result in a lot of
        duplication, and there is too much un(der)maintained code that is hard
        to convert.</p>

        <p>The reason I am writing this post is because device emulation, the
        main security attack surface for VMMs, can be done in a separate
        program. That program can be written in any language and this is where
        Rust comes in. For vhost devices it is possible to write Rust
        device backends today and I hope this will become the default approach to
        writing new devices.</p>

        <p>For non-vhost devices the <a href="https://patchew.org/QEMU/1594913503-52271-1-git-send-email-thanos.makatos@nutanix.com/">vfio-user</a>
        project is working on an interface out-of-process device emulation. It
        will be possible to implement devices in Rust there too.</p>

        <p>If you are implementing new device emulation code please consider
        doing it in Rust!</p>

        <h2>Conclusion</h2>
        <p>Most security bugs in QEMU today are C programming bugs. Switching
        to a safer programming language will significantly reduce security bugs
        in QEMU. Rust is now mature and proven enough to use as the language
        for device emulation code. Thanks to vhost-user and vfio-user using
        Rust for device emulation does not require a big conversion of QEMU
        code, it can simply be done in a separate program. This way attack
        surfaces can be written in Rust to make them less susceptible to
        security bugs going forward.</p>

</div></div>]]>
            </description>
            <link>http://blog.vmsplice.net/2020/08/why-qemu-should-move-from-c-to-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24133128</guid>
            <pubDate>Wed, 12 Aug 2020 15:39:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Static Site Generator Designed to Build 10-100k Page Sites (Svelte.js)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24133109">thread link</a>) | @nickreese
<br/>
August 12, 2020 | https://elderguide.com/tech/elderjs/ | <a href="https://web.archive.org/web/*/https://elderguide.com/tech/elderjs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>All information, data and other material displayed on this website or included on other websites linked to
this website is being provided for informational purposes only. This is not a substitute for medical, legal,
financial or other professional advice. You should always consult with a qualified professional before making
any decision with medical, legal or financial consequences. You should never disregard qualified professional
advice based on information found on our website. We explicitly disclaim liability in connection with your use
of this information.
</p></div></div>]]>
            </description>
            <link>https://elderguide.com/tech/elderjs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24133109</guid>
            <pubDate>Wed, 12 Aug 2020 15:37:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Free alternative data for investment research]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24132949">thread link</a>) | @greatwave1
<br/>
August 12, 2020 | https://www.quiverquant.com/splash/ | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/splash/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <h3><span>What is alternative data?</span></h3>
                        <h3><span>Alternative data refers to non-traditional data sources that can be used for stock analysis. Alternative data includes things like social media trends and web traffic data (and not anything that can be found on an income statement or balance sheet).</span>
			<p>
                        <span><span>Over the last decade, alternative data has exploded in popularity among hedge funds and Wall Street trading firms.</span> Professional investors spent almost $2B on alternative data in 2020. This data allows them to find unique insights on stocks, and gain an information edge over the rest of the market.</span></p><p>
                        <span><span>However, alternative data is still almost completely inaccessible to non-professional investors.</span> Most providers charge thousands of dollars a year for access to their services, and in many cases only sell to institutional clients.</span></p><p>
                        <span><span>We created this site to level the playing field between retail investors and Wall Street,</span> by providing high-quality alternative data on a free, easy-to-use platform.</span></p></h3>
                </div></div>]]>
            </description>
            <link>https://www.quiverquant.com/splash/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24132949</guid>
            <pubDate>Wed, 12 Aug 2020 15:22:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Micro SaaS with MailerLite, Netlify, Stripe and Zapier]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24132880">thread link</a>) | @blakbelt78
<br/>
August 12, 2020 | https://bullish.email/blog/building-a-micro-saas-with-mailerlite-netlify-stripe-and-zapier/ | <a href="https://web.archive.org/web/*/https://bullish.email/blog/building-a-micro-saas-with-mailerlite-netlify-stripe-and-zapier/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p><a href="https://bullish.email/"><img src="https://bullish.email/blog/logo.png"></a></p>
      
      <hr>
      <p>
        A couple of months back, during this crazy world pandemic, I had an idea
        for a <a href="https://bullish.email/">Stock Market email newsletter</a>.
      </p>
      <p>
        Nothing novel, the initial premise was to build a fully automated
        hands-off email with some key stats I care about and send it every
        weekday before the markets open, and that’s how
        <a href="https://bullish.email/">https://bullish.email</a> came to be.
      </p>
      <p>
        Doing rounds trying to promote my little pet project, I posted it on
        <a href="https://news.ycombinator.com/item?id=22870667">Hacker News</a>
        and received great feedback, and one thousand people were convinced
        enough to subscribe.
      </p>
      <p>
        That initial traction, combined with all the positive comments and
        suggestions, was the signal I needed to upgrade from side hustle to tiny
        micro SaaS indie venture.
      </p>
      <p>
        I planned to offer a premium version of the newsletter with a lot more
        data points and insights and charge money for it. Plain and simple.
      </p>
      <p>
        But to do that, I had to do a good amount of code refactoring, hookup
        Stripe, update the website, make all the plumbing work, and promote it.
      </p>
      <p>And that’s where the fun begins again. Let’s get to work!</p>
      <p>
        The first thing I tackled was to
        <a href="https://github.com/eduardosasso/bullish/tree/master/services">build new data points</a>, all of them based on variations of the unofficial
        <a href="https://github.com/eduardosasso/bullish/blob/master/services/config.rb">Yahoo Finance API</a>.
      </p>
      <p>From those API’s I’ve extracted insights like</p>
      <ul>
        <li>Performance by sector</li>
        <li>Trending stocks</li>
        <li>Top gainers and losers</li>
        <li>All-time high stats</li>
        <li>Crypto performance</li>
      </ul>
      <p>There’s a lot you can do with Yahoo’s API.</p>
      <p>
        For each of those data points, I formatted their results with an
        emphasis on percentage performance to keep it consistent with the
        original version of Bullish and maintain its uniqueness.
      </p>
      <p>
        Next, I had to find a way to design and easily code email layouts.
        Creating email templates is a huge pain. You have to inline CSS
        everywhere, nothing works, and every change is a pain and hard to reuse.
        There’s gotta be a better way.
      </p>
      <p>
        After some research, I found <a href="https://mjml.io/">MJML</a> , which
        is essentially a markup layer on top of HTML built for designing
        responsive emails. It works great, no more writing arcane HTML and
        fighting email client compatibility.
      </p>
      <p>
        My mental model for Bullish Pro centered around the concept
        <a href="https://github.com/eduardosasso/bullish/tree/master/editions">editions</a>, and that translated to a
        <a href="https://github.com/eduardosasso/bullish/blob/master/editions/free.rb">free edition</a>, a
        <a href="https://github.com/eduardosasso/bullish/blob/master/editions/morning.rb">morning edition</a>, and an
        <a href="https://github.com/eduardosasso/bullish/blob/master/editions/afternoon.rb">afternoon edition</a>
        for paid subscribers.
      </p>
      <p>
        Editions are composed of
        <a href="https://github.com/eduardosasso/bullish/blob/master/editions/widgets.rb">elements or widgets</a>
        and change daily, like a newspaper. Between Monday and Friday, each
        edition includes a set of widgets reused interchangeably to create the
        final email layout.
      </p>
      <p>
        This notion of daily editions combined with elements gives a lot of
        versatility when creating layouts.
      </p>
      
      

      <p>
        Each element gets hooked up to a data point, so for trending stocks, you
        can expect to have a widget to render that, same thing for pre-market
        futures, crypto, etc.
      </p>
      <p>
        Elements use the
        <a href="http://mustache.github.io/">Mustache</a> template engine to
        take variables and replace them with data and do some formatting like
        green or red if the value is positive or negative.
      </p>
      <p>
        With this design, it’s easy to add new components and move them around
        to create unique
        <a href="https://github.com/eduardosasso/bullish/blob/master/templates/template.rb">templates</a>
        with almost zero code.
      </p>
      <p>
        Editions have a tag specifying their group ID, so emails go out to the
        right group free or premium.
      </p>
      <p>
        Of course, there’s a lot of plumbing involved in stitching everything
        together like compressing emails to be
        <a href="https://mailchimp.com/help/gmail-is-clipping-my-email/">under 102k</a>, so they don’t break in Gmail and things like that, but that’s a good
        overview of how I revamped Bullish to support different email formats
        without giving away the idea of full automation.
      </p>
      <p>
        The infrastructure is still pretty much the same, three CRON jobs set up
        in a Raspberry PI to create the HTML of each edition and calls to
        <a href="https://www.mailerlite.com/">MailerLite</a> API to schedule
        distribution. Check the
        <a href="https://bullish.email/blog/turning-my-obsession-in-the-stock-market-into-a-side-project/">previous article</a>
        for more details.
      </p>
      <p>
        For payments, I used Stripe and their drop-in
        <a href="https://stripe.com/docs/payments/checkout">checkout flow</a> to
        accept payments and
        <a href="https://stripe.com/billing">Stripe Billing</a> for managing
        recurring subscriptions connected to a few
        <a href="https://zapier.com/">Zapier</a> recipes to handle users moving
        from free group to premium and downgrading from premium back to free
        when they cancel.
      </p>
      <p>
        With Stripe Billing and a sprinkle of Javascript
        <a href="https://www.netlify.com/products/functions/">cloud function</a>
        deployed to <a href="https://www.netlify.com/">Netlify</a>, I’ve set up a
        magic link on premium emails, so paid users can update or cancel their
        subscriptions directly in Stripe securely.
      </p>
      <p>
        Based on the customer id, Stripe generates a unique link on demand so
        users can update their subscription without having to log in or create
        an account, it’s zero friction.
      </p>
      <p>
        Leveraging Zapier was a big time saver, and it’s less code I need to
        write and maintain. They offer a free plan that includes five zaps, and
        that’s what I use.
      </p>
      <p>
        Another huge time saver was moving the website over to Netlify. They
        have such an excellent product with killer features like branch previews
        for testing, automatic asset compression, and serverless functions that
        are ridiculously easy to use with no config whatsoever write Javascript
        and deploy plus a generous free tier.
      </p>
      <p>
        <a href="https://stripe.com/">Stripe</a> is also another great product.
        From documentation to testing and configuration and support for Apple
        and Google pay, everything was a joy to use and simple to integrate into
        the flow I had in mind and seamless to users—big fan.
      </p>
      <p>
        I let this setup run for a few days to make sure everything worked as
        expected before I made my first move into upselling the premium version.
      </p>
      <p>Time to sell.</p>
      <p>
        My initial strategy was to convert existing subscribers first before
        going out to the world.
      </p>
      <p>
        So I crafted an email in a personal tone, where the subject was “<a href="https://preview.mailerlite.com/o2y8k1">It’s launch day!</a>”. In this email, I started by giving an overview where Bullish was at
        and then introducing Bullish Premium for 4.99/mo along with all the
        features we were releasing and a big green call to action button saying,
        “<strong>Subscribe now</strong>.”
      </p>
      <p>
        My honest expectation was to get maybe four or five users to convert,
        but we end up closing ten on the first day. We celebrated with Sushi!
      </p>
      <p>
        That got us to an instant
        <strong>$50 monthly recurring revenue!</strong> Almost ramen
        profitability.
      </p>
      <p>
        The numbers are so small, but you’ve got to start somewhere. I’ve done
        lots of side projects over the years, and they all brought me some
        indirect form of monetization. It was through a side project that I
        ended up in Silicon Valley, but this is the first time I’m directly
        selling things to people.
      </p>
      <p>
        After some validation from the first sales, I moved on to the next big
        topic in my todo—a new website.
      </p>
      <p>
        I’ve put together the first version of the website in a couple of hours
        using my yet-to-be-released static site generator called
        <a href="https://github.com/eduardosasso/leter">Leter</a>, which also
        powers this article by the way.
      </p>
      <figure>
          <img src="https://bullish.email/blog/building-a-micro-saas-with-mailerlite-netlify-stripe-and-zapier/first_site.png" alt="First version">
          <figcaption>First version</figcaption>
        </figure>
      
      <p>
        It was Ok but far from what I had in mind, but I had to ship something,
        so I pushed a professional better-looking website for later.
      </p>
      <p>
        I know my weaknesses, and web design is a time sink for me. I’m very
        opinionated, and I like to think I have a good eye for it, but so far, I
        couldn’t deliver anything I was proud of on my own.
      </p>
      <p>
        After learning from my fail attempts over the years trying to come up
        with an exclusive design this time around, I looked for references,
        inspiration, and templates that could help me jump-start the process.
      </p>
      <p>
        As an engineer, I always feel inclined to start everything from scratch,
        and with the new website was no different, the utopian dream of the
        perfect, valid HTML and clean CSS a trap that I fell into way too many
        times but not again.
      </p>
      <p>
        I ended up
        <a href="https://themeforest.net/item/fold-software-and-app-template/24295615">finding a template</a>
        that was pretty close to what I had in mind. I just had to brush off my
        CSS skills and do some customization to take my vision to reality.
      </p>
      <p>
        Of course, I have a list of things to improve like adding archives or a
        way to update the sample email dynamically, but overall I’m pretty happy
        how it turned out.
      </p>
      <figure>
          <img src="https://bullish.email/blog/building-a-micro-saas-with-mailerlite-netlify-stripe-and-zapier/new_site.png" alt="New version">
          <figcaption>New version</figcaption>
        </figure>
      
      <p>With the site up and running, it was time to promote it.</p>
      <p>
        Before trying the big leagues on
        <a href="https://www.producthunt.com/">Product Hunt</a>, we tested the
        waters by engaging on Twitter and getting a few subscribers. Then, I
        asked my
        <a href="https://www.linkedin.com/in/abduzeedo/">influencer brother</a>
        to post on his
        <a href="https://www.linkedin.com/feed/update/urn:li:activity:6693739953026945024/">LinkedIn</a>, which generated a nice amount of traffic and about fifty new readers,
        not hockey stick growth but decent.
      </p>
      <p>
        For
        <a href="https://www.producthunt.com/posts/bullish">Product Hunt</a>, we
        scheduled our launch for a Wednesday, and I remember going to sleep that
        night, excited to see what the next day would bring, and we bombed, we
        never made to the frontpage and only got like 20 upvotes it was a total
        disaster.
      </p>
      <p>
        The next day was business as usual, …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bullish.email/blog/building-a-micro-saas-with-mailerlite-netlify-stripe-and-zapier/">https://bullish.email/blog/building-a-micro-saas-with-mailerlite-netlify-stripe-and-zapier/</a></em></p>]]>
            </description>
            <link>https://bullish.email/blog/building-a-micro-saas-with-mailerlite-netlify-stripe-and-zapier/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24132880</guid>
            <pubDate>Wed, 12 Aug 2020 15:16:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Changing, Start Experimenting]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24132550">thread link</a>) | @mcrittenden
<br/>
August 12, 2020 | https://critter.blog/2020/08/12/stop-changing-start-experimenting/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/08/12/stop-changing-start-experimenting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-642">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>I bet right now, if you thought about it, you could come up with some change that would be great for your team or your project. And I bet you’ve been subconsciously dismissing it because “it’ll never fly” or “management won’t go for it” or “people will think it’s crazy.” And they probably <em>will</em> think it’s crazy, if you just suggest it as a “change”.</p>



<p><strong>But you can convince your team to let you try nearly anything if you pitch it as an experiment.</strong></p>



<p>The crucial ingredients are:</p>



<ul><li>It needs a defined start and end date</li><li>It needs to be measurable </li><li>It needs clear success and failure criteria</li></ul>



<p>Let’s take an example. Yesterday I posted about <a href="https://critter.blog/2020/08/11/that-coworker-who-never-stops-refactoring/">Fred, who only cares about providing value to other developers</a> instead of users. My suggested solution was to lean into that and make that his full time role. What I didn’t say was that if you suggested changing Fred’s role, you’d freak people out. You’d get a lot of “uh, you want someone to work full time on stuff that our users don’t care about?”, etc. You know the drill.</p>



<p>So how about an experiment? Suggest letting Fred fill that role for only only a single sprint, and see how it affects velocity. More specifically:</p>



<ul><li>Hypothesis: moving Fred into this role will not lower velocity</li><li>Start date: start of sprint</li><li>End date: end of sprint</li><li>KPI: team velocity compared to the average</li><li>Success: velocity increases or stays the same</li><li>Failure: velocity decreases</li></ul>



<p>(This isn’t an ideal experiment because lots of other things can affect velocity for a single sprint, but it’s enough to get your foot in the door with convincing people the idea isn’t crazy.)</p>



<p>Most teams and managers will be <em>drastically</em> more willing to accept that, because the best case scenario is that it makes the team more valuable indefinitely, and worst case scenario is that you’ve only lost a bit of velocity for a single sprint.</p>



<p>Changes are scary. They bring anxiety and regret. Experiments are comforting. They bring clarity.</p>



<p>This goes for all types of changes. Process changes, technology changes, role changes, product direction changes, all of ’em. Next time you’re in a retro meeting and you want to suggest a change but you’re worried about getting shut down, call it an experiment and lay out how it will be measured and when it will end. Then observe as your team magically agrees to give it a shot.</p>



<p>And if you do, <a href="https://twitter.com/mcrittenden">tweet at me</a>!</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/08/12/stop-changing-start-experimenting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24132550</guid>
            <pubDate>Wed, 12 Aug 2020 14:49:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Tagging Best Practices]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24132528">thread link</a>) | @toeknee123
<br/>
August 12, 2020 | https://www.cloudforecast.io/blog/aws-tagging-best-practices/ | <a href="https://web.archive.org/web/*/https://www.cloudforecast.io/blog/aws-tagging-best-practices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <!-- Toc if any -->            
                
                <!-- End Toc -->
				

<p>If you’ve worked in Amazon Web Services for long, you’ve probably seen or used <a href="https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html">AWS cost allocation tags</a> to organize your team’s resources. AWS allows you to attach metadata to most resources in the form of key-value pairs called tags. In this guide (the first in a three-part series), we’ll cover some of the most common use-cases for AWS cost allocation tags and look at some best AWS tagging best practices for selecting and organizing your tags. Finally, we’ll explore some examples of AWS resource tagging strategies used by real companies to improve visibility into their resource utilization in Amazon Web Services.</p>

<h2 id="why-tag-aws-resources">Why Tag AWS Resources?</h2>

<p>AWS cost allocation tags can help you <a href="https://www.cloudforecast.io/blog/how-tagging-resources-can-reduce-your-aws-bill/">understand and control your AWS costs</a>. <a href="https://aws.amazon.com/aws-cost-management/aws-cost-explorer/">AWS Cost Explorer</a> allows you to use tags to break down your AWS resource usage over time, while tools like <a href="https://www.cloudforecast.io/overview.html">CloudForecast</a> keep you informed of your spending proactively.</p>

<p>Understanding and controlling your costs isn’t the only reason you should tag your AWS resources. You can use AWS cost allocation tags to answer a variety of questions, including:</p>

<ul>
  <li>Which team member is the point of contact for this AWS resource?</li>
  <li>How many of our servers have been updated with the latest version of our operating system?</li>
  <li>How many of our services have alerting enabled?</li>
  <li>Which AWS resources are unnecessary at low-load hours?</li>
  <li>Who should have access to this resource?</li>
</ul>

<p>Before you start adding AWS cost allocation tags to all of your AWS resources, it’s essential to create a strategy that will help you sustainably manage your tags. AWS tags can be helpful, but without a consistently applied plan, they can become an unsustainable mess.</p>

<h2 id="aws-tagging-best-practices">AWS Tagging Best Practices</h2>

<p>While there isn’t a perfect AWS tagging strategy that works for every organization, there are a few AWS tagging best practices that you should be familiar with.</p>

<h3 id="1-know-how-each-tag-you-create-will-be-used">1. Know how each tag you create will be used</h3>

<p>AWS cites <a href="https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html#tag-categories">four categories for cost allocation tags</a>: technical, business, security, and automation. Consider which of these categories you will need when creating your AWS tagging strategy:</p>

<ul>
  <li><strong>Technical Tags</strong> help engineers identify and work with the resource. These might include an application or service name, an environment, or a version number.</li>
  <li><strong>Business Tags</strong> allow stakeholders to analyze costs and the teams or business units responsible for each resource. For example, you might want to know what percentage of your AWS spend is going towards the new product you launched last year so you can determine the return on investment of that effort.</li>
  <li><strong>Security Tags</strong> ensure compliance and security standards are met across the organization. These tags might be used to limit access or denote specific data security requirements for <a href="https://en.wikipedia.org/wiki/Health_Insurance_Portability_and_Accountability_Act">HIPAA</a> or <a href="https://aws.amazon.com/compliance/soc-faqs/">SOC</a> compliance.</li>
  <li><strong>Automation Tags</strong> can be used to automate the cleanup, shutdown, or usage rules for each resource in your account. For example, you could tag sandbox servers and run a script to delete them after they’re no longer in use.</li>
</ul>

<h3 id="2-decide-which-aws-tags-will-be-mandatory">2. Decide which AWS tags will be mandatory</h3>

<p>As you decide which AWS tags you need and how you will use them, set rules about their usage. Decide which AWS tags will be mandatory, what character should be used as a delimiter, and who will be responsible for creating them. If you already have many resources, you may have to delegate tag assignment to the teams who use them.</p>

<h3 id="3-develop-a-consistent-aws-tag-naming-convention">3. Develop a consistent AWS tag naming convention</h3>

<p>Choosing a consistent and scalable AWS tag naming convention for your AWS tag keys and values can be complicated. There are different AWS tag naming convention rules about which characters you can use and how long AWS tag keys and AWS tag values can be. Be sure to <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html#tag-restrictions">read up on these tag restrictions</a> before you select a AWS tag naming convention.</p>

<p>A common AWS tag naming convention pattern is to use lowercase letters with hyphens between words and colons to namespace them. For example, you might use something like this:</p>

<table>
  <thead>
    <tr>
      <th>Tag Key</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>mifflin:eng:os-version</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>

<p>Where <code>mifflin</code> is the name of your company, <code>eng</code> designates this tag as being relevant to the engineering team, <code>os-version</code> indicates the purpose of the tag, and <code>1.0</code> is the value.</p>

<h3 id="4-limit-the-number-of-aws-tags-you-adopt">4. Limit the number of AWS tags you adopt</h3>

<p>There are technical and practical limits to the number of tags you should use. First, AWS enforces a 50-tag limit on each resource. More importantly, engineers will have a hard time keeping track of and remembering how to properly use tags if you require too many.</p>

<p>Fortunately, many tags can be avoided by relying on AWS’s built-in resource metadata. For example, you don’t have to store the creator of an EC2 instance because <a href="https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html">Amazon adds a <code>createdBy</code> tag by default</a>. Decide which tags you need and try to limit the creation of new tags.</p>

<h3 id="5-automate-aws-tag-management">5. Automate AWS tag management</h3>

<p>As the number of AWS resources in your account grows, keeping up with your AWS tags, enforcing conventions, and updating tags will get increasingly difficult. In Part 2 and 3 of this guide, we’ll look at how you can use <a href="https://www.cloudforecast.io/blog/aws-tagging-best-practices/terraform.io">Terraform</a>, <a href="https://aws.amazon.com/cloudformation/">CloudFormation</a>, <a href="https://cloudcustodian.io/">Cloud Custodian</a> to manage tags across your resources.</p>

<p>Amazon also offers <a href="https://aws.amazon.com/blogs/aws/new-use-tag-policies-to-manage-tags-across-multiple-aws-accounts/">tag policies</a>, <a href="https://aws.amazon.com/blogs/aws/resource-groups-and-tagging/">tagging by resource group</a>, and a <a href="https://aws.amazon.com/blogs/aws/new-aws-resource-tagging-api/">resource tagging API</a> to help you govern and assign tags in bulk. Automating as much of the tag management process as possible will result in higher quality, more maintainable tags in the long run.</p>

<h3 id="6-plan-to-audit-and-maintain-aws-tags">6. Plan to audit and maintain AWS tags</h3>

<p>You will undoubtedly need to revisit your AWS tags periodically to make sure they’re still useful and accurate. Depending on how many resources you deploy, this might mean setting a reminder to audit your tags every quarter, or it might mean creating a committee to review and update tags every month. We’ll look at some tools and strategies for managing your tags in Part 3 of this guide.</p>

<p>Amazon Web Services provides a <a href="https://d1.awsstatic.com/whitepapers/aws-tagging-best-practices.pdf">comprehensive document of their recommended practices</a> for tagging resources. Be sure to review it if you’re new to AWS tags and want to dive deeper into some of these AWS tagging best practices.</p>

<h2 id="example-aws-tagging-strategies">Example AWS Tagging Strategies</h2>

<p>Let’s look at a few real-world tagging strategies. These are adapted from real companies that use AWS tags to organize their resources for various reasons. While they may differ from your use case, they’ll offer you insight into how you might tag your resources in AWS.</p>

<h3 id="example-1-a-service-based-aws-tagging-strategy">Example 1: A Service-Based AWS Tagging Strategy</h3>

<p>A widespread pattern for tagging resources is by service and environment. For example, if an organization has two services (<code>cart</code> and <code>search</code>) and two environments (<code>prod</code> and <code>dev</code>), they might set up the following tags:</p>

<table>
  <thead>
    <tr>
      <th>Key</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>service</td>
      <td>cart or search</td>
    </tr>
    <tr>
      <td>contact</td>
      <td>Name of the engineer who maintains this resource</td>
    </tr>
    <tr>
      <td>env</td>
      <td>prod or dev</td>
    </tr>
  </tbody>
</table>

<p>If these two services share a single <a href="https://aws.amazon.com/rds/">RDS</a> instance, then the database can be tagged <code>service=cart|search</code> (to indicate that this resource serves both services) and the architecture might look something like this:</p>

<p><img src="https://i.imgur.com/nPLHmfp.png" alt="A service-based tagging strategy in AWS"></p>

<p>If you choose an AWS tagging strategy like the one above, you have to consider how tags will change over time. For example, if you add a new service that shares the same RDS instance, you’ll have to update the database’s tags to include the name of the new service. For this reason, some teams opt to use a single tag to indicate that a resource may be used by all services (eg: <code>service=common</code>).</p>

<p>Service-based tagging strategies like this are usually a good starting point if you’d like to understand which services contribute the most to your AWS costs. The business team can use these tags to see how much they’re paying for each service or environment and reach out to the appropriate contact if they have questions.</p>

<h3 id="example-2-a-compliance-aws-tagging-strategy">Example 2: A Compliance AWS Tagging Strategy</h3>

<p>AWS cost allocation tags may also help organizations manage governance or compliance. Tools like <a href="https://www.cloudforecast.io/blog/aws-tagging-best-practices/www.cloudforecast.io">CloudForecast</a> through their <a href="https://www.cloudforecast.io/aws-tagging-compliance-report.html">AWS Tagging Compliance feature</a> can help you maintain tagging compliance if you tag your resources in specific ways. These AWS tags might be used to limit access or run extra security checks on particular resources.</p>

<p>In this example, the company tags resources that contain user data with <code>user-data=true</code> so that they can audit them more frequently and ensure they meet specific standards. All resources have a <code>contact</code> and <code>env</code> tag to designate the responsible team member and ensure someone is accountable for keeping them up to date.</p>

<p><img src="https://i.imgur.com/VfWPQ6O.png" alt="A compliance-based tagging strategy in AWS"></p>

<p>Using a compliance tagging strategy does not preclude you from using other strategies as well. One of the advantages of AWS tags is that they let you segment your AWS resources in a nearly infinite number of ways.</p>

<h3 id="example-3-account-segmented-environments">Example 3: Account Segmented Environments</h3>

<p>The final example we’ll look at is an account-segmented tagging strategy. While AWS’s IAM permissions allow you to assign access to users, roles, and teams granularly, some organizations may want to go a step further.</p>

<blockquote>
  <p>“When resources across heterogeneous logical environments are colocated, it is deceptively easy to accidentally use resources from another environment if you’re not extraordinarily careful when provisioning resources and designing network/IAM policies” - Platform Engineer at <a href="https://www.cars.com/">Cars.com</a></p>
</blockquote>

<p>In this example, the organization designated business unit and team tags to each resource, with each environment having a separate AWS account.</p>

<p><img src="https://i.imgur.com/Lg36Cug.png" alt="An account-segmented environment and tagging strategy in AWS"></p>

<p>This allows them to generate reports in each environment to see what their resource costs are for the marketing (<code>mktg</code>) unit is vs. the data warehousing (<code>data</code>) unit. If the team uses this method of account-segmented tagging, they’ll need to <a href="https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html">use a master account</a> to see resource usage across their entire organization. You can also use <a href="https://www.cloudforecast.io/">CloudForecast</a> to generate regular cost reports and breakdowns across multiple AWS accounts.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Any organization that uses AWS at scale will need to develop a tagging strategy that works for them. Consider the AWS tagging best practices and examples above, as well as your organization’s goals.</p>

<p>Once you decide on a AWS tagging strategy, you will need a plan for adding and maintaining AWS cost …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cloudforecast.io/blog/aws-tagging-best-practices/">https://www.cloudforecast.io/blog/aws-tagging-best-practices/</a></em></p>]]>
            </description>
            <link>https://www.cloudforecast.io/blog/aws-tagging-best-practices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24132528</guid>
            <pubDate>Wed, 12 Aug 2020 14:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We’ve Spent 208,000 Hours in Azure DevOps. Here’s What We Learned]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24132527">thread link</a>) | @encorekt
<br/>
August 12, 2020 | https://www.7pace.com/blog/azure-devops-best-practices | <a href="https://web.archive.org/web/*/https://www.7pace.com/blog/azure-devops-best-practices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<p>Sometimes, when looking for the right tool for a job, you just have to turn to the experts.<br></p>



<p>If you wanted to cook a meal you’ve never attempted to make yourself, you might ask an experienced cook for advice. If you planned to renovate your home but you didn’t know the difference between a miter and a chainsaw, you’d probably want to ask a handyman or contractor for help (no, seriously).<br></p>



<p>And if you were considering implementing Azure DevOps for your software team, but weren’t sure about the benefits, tips, and tricks for getting the most out of Microsoft’s toolstack, well, you might come to us.<br></p>



<p>Our team has spent a combined 208,000 hours in Azure DevOps. We think you could consider us experts. And that’s why we’re here to offer all our advice —&nbsp;why you should use Azure DevOps, how to use it effectively to get the most benefit, and how it can help you manage DevOps best practices within your teams.</p>



<p>Take it from the experts —&nbsp;we love Azure DevOps so much we <a href="https://www.7pace.com/timetracker">built a tool specifically to integrate with it</a>. Read on to see how your team can get the most out of Azure DevOps, too.<br></p>



<h2>Why Go for Azure DevOps?</h2>



<p>Azure DevOps has evolved over time.<br></p>



<p>In its current iteration, it’s the rebranding of Microsoft’s Visual Studio Team Services (VSTS), which is the online version of Team Foundation Server (TFS). Since the beginning, it’s been a source code management tool meant to allow teams to share and work on code collectively.&nbsp;<br></p>



<p>Today, it’s a powerful tool for teams who use DevOps —&nbsp;collaboration between development and operations teams that uses agile methods to create great programs and launch them quickly.<br></p>



<p>A quick Google is all it’ll take to find people all over the internet who will tell you why your teams should use Azure DevOps. For the most part, none of them are wrong. We also think you should use Azure DevOps. And after spending 208,000 hours using it ourselves, these are <em>our</em> reasons.<br></p>



<h3>Collaboration Is Built In</h3>



<p>Since its early days, collaboration and sharing have been at the heart of Azure DevOps. Azure DevOps provides a central location for storing and managing code, ensuring that everyone on your team has constant access and can work together.<br></p>



<h3>It’s an Open Platform</h3>



<figure><img src="https://lh6.googleusercontent.com/kIGffuNdHkSImfhWG2xUEV8FSP5p-cZnTrSzhDm5iEjIAr3A3JsZ90GgTGLS3m2qs-kOQ3GcInsAXEAMUAc6RNp4nmUS7pUWahryNB2pxyjCQUu6z6EyLf91X_618Kr5TD-ibPLI" alt="Azure DevOps extensions library"></figure>



<p>Azure DevOps integrates seamlessly with a wide variety of industry and community tools. And if there’s a functionality you need that Azure DevOps doesn’t offer out of the box, just check the <a href="https://marketplace.visualstudio.com/azuredevops">marketplace</a> —&nbsp;odds are good that there’s an extension available that will give you what you need, even if it requires integration with one of Microsoft’s competitors, like Slack. That freedom of customization is one of the biggest reasons Azure DevOps is such a powerful tool.<br></p>



<h3>Pipeline Organization is Handled for You</h3>



<p>Too many teams put too much time and effort into creating and organizing pipelines. Azure DevOps comes with its own clean, customizable hierarchy of organizations, projects, teams, and work items, ensuring smooth pipelines with minimal management on your part. That means your team can focus on what it’s good at: software development.<br></p>



<h2>How to Effectively Use DevOps with Azure</h2>



<p>Making the most out of Azure DevOps means effectively using all of its components:<br></p>



<ul><li>Pipelines: Azure pipelines are built for continuous integration and continuous deployment, which means they can replace whatever tools your team used for those processes previously. In other words, say goodbye to clunky manual deployment that requires 20 pages of Word docs to get through each new deployment.</li><li>Boards: Azure boards can replace whatever task management solution your team has been using, with a system that’s admittedly more complex than other popular solutions, but is also infinitely customizable. Because of all the customization options, you can even use Azure boards for more than just task management —&nbsp;like bug tracking that’s linked to customer support.</li><li>Artifacts: Azure artifacts make it easy (think, one-click easy) to add fully integrated package management to your CI/CD pipelines. You can create and share Maven, npm, NuGet, and Python package feeds with your team from both public and private sources, and artifacts stay organized and protected by Azure SLA.</li><li>Repos (Git Repositories): Git may require a little bit of a learning curve compared to some of the simpler source control tools many teams use. However, when you’re a new Git user, you can treat it like your old source control platform and put off learning more complex features —&nbsp;like re-basing, merging, and rewriting history —&nbsp;until you need them.</li><li>Monitor: Azure monitor lets you collect and analyze data continuously to maximize performance and availability of applications. It’s one of the tenets of the DevOps philosophy: Application monitoring should be continuous and comprehensive.</li><li>Test Plans: Azure test plans is the component you need to top off your DevOps toolstack. With manual and exploratory testing tools, you can test and ship with complete confidence in your code quality. And automating testing is simple in your Azure pipelines. When we said these tools were seamless and integrated, we really meant it.</li></ul>



<p>How your team makes the most of each of these will be largely individual —&nbsp;different teams operate in different ways. But the benefit is that a mish-mash of different DevOps tools from companies that may be competing with one another generally don’t communicate well with one another.&nbsp;<br></p>



<p>Plus, this means having one comprehensive solution that’s all based in Azure DevOps, rather than a collection of systems that everyone on the team needs to learn individually. And each Azure DevOps component can replace other tools, giving teams a more seamless, integrated workflow.<br></p>



<h2>How Azure DevOps Can Help Manage DevOps Best Practices</h2>



<p>DevOps as a philosophy comes with a number of best practices that encourage collaboration among your team members to deliver high quality programs quickly. Adhering to best practices is a lot easier when you have the right tools, and that’s where we think Azure DevOps <em>really</em> shines.<br></p>



<p>These are just a few common DevOps best practices that are made a lot easier by Azure DevOps tools.</p>



<figure><img src="https://www.7pace.com/wp-content/uploads/2020/07/208000-Hours-4-1024x576.png" alt="DevOps best practices are made easier by mastering Azure DevOps" srcset="https://www.7pace.com/wp-content/uploads/2020/07/208000-Hours-4-1024x576.png 1024w, https://www.7pace.com/wp-content/uploads/2020/07/208000-Hours-4-300x169.png 300w, https://www.7pace.com/wp-content/uploads/2020/07/208000-Hours-4-768x432.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>DevOps Best Practices</strong><br></p>



<ul><li><strong>Teams use version control</strong>: Azure DevOps offers two types of version control —&nbsp;Git, which is distributed, and Team Foundation Version Control (TFVC), which is a centralized, client-server system. Both allow for easy collaboration on multi-developer projects as all team members can manage changes to files over time.</li><li><strong>All stakeholders are active in the development process: </strong>Azure DevOps is built on a foundation of collaboration across teams and organizations. This is one of the principles of DevOps, and Azure DevOps tools make it as easy as possible for team members across your entire organization to work collaboratively on projects, from anywhere.</li><li><strong>Deployment patterns are reusable:</strong> When it comes to continuous deployment, Azure pipelines has you covered. Deployment patterns for building application and services can be automated and reused through Azure DevOps, by setting up a release pipeline in Azure DevOps that will deploy packages to given environments depending on what you specify.</li><li><strong>Testing is automated: </strong>One of the components that make up Azure DevOps is Azure test plans, which allows for automated testing, manual testing, bug reports, and more. One of the most useful features here is the ability to automate test cases in your test plans and then run them directly from Azure test plans, or from the Test hub in TFS.&nbsp;</li><li><strong>Source code is available for other teams: </strong>Azure Repos is a set of tools that makes it easy to manage source code, and whether you choose cloud or on-site storage, code is always accessible across different teams. This is the collaborative spirit the DevOps philosophy was born from.</li></ul>



<h2>208,000 Hours Is Only the Beginning</h2>



<p>It doesn’t actually take 208,000 hours in Azure DevOps to see the powerful capabilities of these tools. But once you start using them, you’ll likely find that spending hundreds of thousands of hours in Azure DevOps is much easier than you think.<br></p>
        </div></div>]]>
            </description>
            <link>https://www.7pace.com/blog/azure-devops-best-practices</link>
            <guid isPermaLink="false">hacker-news-small-sites-24132527</guid>
            <pubDate>Wed, 12 Aug 2020 14:46:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cyph and PGP]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24132431">thread link</a>) | @jzig
<br/>
August 12, 2020 | https://www.cyph.com/blog/cyph-pgp | <a href="https://web.archive.org/web/*/https://www.cyph.com/blog/cyph-pgp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main><article><div><div><p><img src="https://www.cyph.com/wp-content/uploads/2020/06/AdobeStock_296619919.png?ef8fdd9eb11b8a5b7c39e3671fa0de8da9750a94d0c5b7339c6f8a91bd5dd134b356d2c31d8f0742a87b385c263376447a98a62bed24dfa27e7dfaa20e370124" alt="Cyph + PGP"></p></div></div></article><section><div><p><span>One of our major competitors, Keybase, was </span><a href="https://news.ycombinator.com/item?id=23102430"><span>acquired by Zoom</span></a><span> last month.</span></p><p><span>Many Keybase users are now </span><a href="https://news.ycombinator.com/item?id=23103386"><span>looking for alternatives</span></a><span> as a result, primarily due to a lack of trust in the new ownership to maintain high privacy standards, as well as speculation that the service is now doomed to ultimately be shut down. However, no single solution has so far stood out from the crowd; instead, users are faced with the prospect of setting up a hodgepodge of independent solutions.</span></p><p><span>Keybase is great, but a full alternative is clearly needed. That’s why we’ve spent the past month building new features to make Cyph more of a direct replacement.</span></p><p><img src="https://www.cyph.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-10-at-4.38.11-PM-1024x640.png?9e56b59e17dd8d0c24ced228ed7ea88c2bcabfe24b86ae53a95ba06df0fb6d2b2fa818ab92622828b0eba4e32774328f7715ea8cc2eb380f2f14521decd6842b" alt="" width="560" height="350"></p><p><span>Cyph’s features and general architecture are similar in many ways to Keybase, plus/minus a few features:</span></p><ul><li><span>On the plus side, our features include voice/video calling (with group support), Bitcoin, and social networking (like Twitter, but all posts are signed + optionally encrypted for a subset of your contacts).</span></li><li><span>On the minus side, Keybase offers some awesome niche features (like encrypted git repos) that we currently do not.</span></li><li><span>And now, with our latest release, we’ve built out a set of PGP key management and utility features to make Cyph more immediately useful for users coming from Keybase.</span></li></ul><p><img src="https://www.cyph.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-10-at-4.39.49-PM-1024x640.png?f0bd1ee3132c87cc78b8cedeb60710eeb23fd5a7f872ad008ea828201a5fddb2fc486aab5a5ddcc0f006233616219034b2a9fb46fd4f93ec95de99dc175143cc" alt="" width="560" height="350"></p><p><span>Additionally, the architecture of Cyph yields some </span><i><span>significant</span></i><span> broader advantages:</span></p><ul><li><span>Full web support</span><ul><li><span>Whereas Keybase splits up its features between the web UI, the CLI, GPG, and the native apps, thanks to </span><a href="https://www.cyph.com/websign"><span>WebSign</span></a><span> Cyph is able to provide a consistent experience across all platforms. The full functionality is available regardless of whether you use </span><a href="https://cyph.app/"><span>https://cyph.app</span></a><span> or the desktop and mobile apps, with no need to worry about degraded security on the web.</span></li></ul></li><li><a href="https://www.cyph.com/agse"><span>Automatic strong public key authentication</span></a><span> for all users</span><ul><li><span>No need to verify keys or usernames out of band, meet up in person to compare fingerprints or “Safety Numbers”, etc.</span></li></ul></li><li><a href="https://www.cyph.com/blog/quantum-resistance"><span>Quantum-resistant cryptography</span></a><ul><li><span>Post-quantum encryption, key exchange, and signing algorithms are used throughout the application (in combination with classical crypto such as elliptic curves). Whereas others are still planning long-term migrations to post-quantum crypto, Cyph was built with it in mind from the start, meaning that your private data is theoretically protected from future QC attacks </span><i><span>today</span></i><span>.</span></li></ul></li></ul><p>We encourage you to submit a response to <a href="https://docs.google.com/forms/d/e/1FAIpQLSdMOdjPKf1O3jb2vBURF5N-UGsr08XLO6GJazlUOy1r_sCnKQ/viewform">our poll</a><span> to vote on the missing features you’d like us to add. And if you’re a Keybase user, just include your username and email address to skip the line and get a free invite to the Cyph beta!</span></p></div></section><section></section></main></div></div></div>]]>
            </description>
            <link>https://www.cyph.com/blog/cyph-pgp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24132431</guid>
            <pubDate>Wed, 12 Aug 2020 14:36:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HTTPS for your local endpoints with inlets and Caddy (2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24132345">thread link</a>) | @alexellisuk
<br/>
August 12, 2020 | https://blog.alexellis.io/https-inlets-local-endpoints/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/https-inlets-local-endpoints/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><blockquote>
<p>Updated: Aug 2020 - new diagrams, inletsctl for automated provisioning, and introducing inlets PRO</p>
</blockquote>
<h2 id="whatistheproblem">What is the problem?</h2>
<p>Over the holidays I was reflecting on a network connectivity problem that I faced whilst employed by a large enterprise company. It turned out that this was a common problem which was being faced by my new team working at yet another large enterprise.</p>
<blockquote>
<p>How do you get incoming HTTP traffic to a service running behind a restrictive firewall?</p>
</blockquote>
<p>The team needed to get incoming HTTP traffic in the form of webhooks to test the work we were doing with <a href="https://www.openfaas.com/">OpenFaaS and OpenFaaS Cloud</a> whilst developing code on their laptop with no routable IP address.</p>
<p>My solution for this problem is called <a href="http://github.com/inlets/inlets">inlets</a>. inlets is written in Go and recently trended for about a week on Hacker News and gained over 2.2k GitHub stars along with a dozen PRs from developers in the far east. inlets now has just over 5k stars. In this post we'll learn more about how to secure inlets with HTTPS for an encrypted connection.</p>
<p>See also: <a href="https://blog.alexellis.io/the-need-for-a-cloud-native-tunnel/">The Need for A Cloud Native Tunnel</a></p>
<h2 id="whatsthesolution">What's the solution?</h2>
<p>There are already several good solutions for this problem which create a tunnel from the outside world to services on our local environments - whether that be a Raspberry Pi, a home-lab or a laptop.</p>
<p>You can <a href="http://github.com/alexellis/inlets">read more on GitHub</a> about why I felt a new solution was required.</p>
<p>Let me introduce you to <em>inlets</em>.</p>
<p><img src="https://raw.githubusercontent.com/alexellis/inlets/master/docs/inlets.png" alt="Conceptual diagram"></p>
<p>The goal of the project is to <em>Expose your local endpoints to the Internet</em>.</p>
<p>Bill of materials:</p>
<ul>
<li>an <em>exit-server</em> or node - this is a machine outside out firewall with full access to the Internet and a public IP address. Our users will connect to the exit-server and be routed to local endpoints inside our firewall over a websocket tunnel</li>
<li>a client - the client acts as a reverse proxy or bridge - when it hears a request, it will proxy that to a local service such as an Express.js server and then send a result back</li>
<li>A permanent tunnel using a websocket - most corporate firewalls will allow an outbound TCP connection to be established over your existing HTTP/S proxy using a CONNECT message.</li>
</ul>
<p>Each HTTP request to the exit-server is serialized and published on the websocket as a control message - then blocks. A client will then receive the request, decide if it knows how to proxy that site then will fetch the resource and send it back down the websocket as a serialized response.</p>
<p>Finally the user's HTTP request unblocks and writes the response to the caller.</p>
<h2 id="securingthetunnel">Securing the tunnel</h2>
<p>By default, for development inlets is configured to use a non-encrypted tunnel which is vulnerable to man-in-the-middle (or MITM) attacks. I have a roadmap item to bake TLS into inlets using the new libraries made available by Caddy, but for the time-being we can do this by running the Caddy binary on our exit-server.</p>
<p>Enabling HTTPS means that our users connect to an encrypted endpoint and our inlets clients can also connect to our server over an encrypted tunnel.</p>
<h2 id="tutorial">Tutorial</h2>
<p>For our exit-server we will use a DigitalOcean droplet, but if you are really on a budget you can use a cheaper VPS like <a href="https://scaleway.com/">Scaleway.com</a>. The main requirement is that we have a VM or VPS with a public IP address.</p>
<p>This is the conceptual diagram of what we're going to create:</p>
<p><img src="https://blog.alexellis.io/content/images/2020/08/inlets-tls.png" alt="inlets-tls"></p>
<p>The exit server will run a reverse proxy, its responsibility will be to obtain, renew, and serve TLS certificates.</p>
<p>When complete, the inlets server's websocket will be encrypted, as will any sites we expose, as long as they have an entry in the reverse proxy's configuration file. For this setup we'll be using Caddy, but other projects also work well.</p>
<h3 id="setupanexitserverautomated">Setup an exit-server (automated)</h3>
<p>First sign-up to DigitalOcean using my code to get free credits: <a href="https://m.do.co/c/8d4e75e9886f">100 USD credit for 60 days</a>.</p>
<p>Download <a href="https://github.com/inlets/inletsctl">inletsctl</a>, which provisions exit servers using cloud APIs:</p>
<pre><code># Or run without sudo, and copy the binary over yourself
curl -SLs https://inletsctl.inlets.dev/ | sudo sh
</code></pre>
<p>Create a DigitalOcean API key from your dashboard and save it as <code>$HOME/do-api-key.txt</code></p>
<p>Run the following, you can customise the region:</p>
<pre><code>inletsctl create --provider digitalocean \
 --region lon1 \
 --access-token-file $HOME/do-api-key.txt
</code></pre>
<p>Now wait until the setup is complete, it will give you the instructions to get started.</p>
<p>You will also be emailed a first-time root password for your new VM.</p>
<h3 id="setupanexitservermanual">Setup an exit-server (manual)</h3>
<ul>
<li>
<p>First sign-up to DigitalOcean using my code to get free credits: <a href="https://m.do.co/c/8d4e75e9886f">100 USD credit for 60 days</a>.</p>
</li>
<li>
<p>Create a Droplet in a region near you using Ubuntu 18.04.x</p>
</li>
<li>
<p>The cheapest Droplet is suitable for our purposes - 5 USD with 1GB RAM / 1vCPU and 1TB transfer</p>
</li>
<li>
<p>Select additional options. Here you can pick <em>User data</em> to automate the setup of the inlets server</p>
</li>
<li>
<p>Enter your user-data using the text from our <a href="https://raw.githubusercontent.com/alexellis/inlets/master/hack/userdata.sh">userdata.sh</a> script.</p>
</li>
<li>
<p>Add any SSH keys you want to use for logging into the exit-server</p>
</li>
<li>
<p>Name your host i.e. <code>inlets-exit-server-1</code></p>
</li>
<li>
<p>Deploy the droplet</p>
</li>
<li>
<p>Get your public IP address</p>
</li>
</ul>
<h3 id="configuredns">Configure DNS</h3>
<ul>
<li>Now create an A record for your domain name pointing at the new Public IP address of your exit-server. I used <a href="https://namecheap.com/">Namecheap.com</a> to provision a cheap domain name for about 2 USD. You may have even just bought a .dev domain in all that craziness. This is a good opportunity for you to put it to use.</li>
</ul>
<h3 id="enablecaddy1xforhttps">Enable Caddy 1.x for HTTPS</h3>
<ul>
<li>Log in to your VM using <code>ssh</code> and update the port from <code>80</code> to <code>8080</code> with:</li>
</ul>
<pre><code>sudo sed -i s/80/8080/g /etc/systemd/system/inlets.service
sudo systemctl daemon-reload 
sudo systemctl restart inlets
</code></pre>
<p>We are doing this so that Caddy can run on both port 80 and 443.</p>
<ul>
<li>Now grab your token for authenticating your client:</li>
</ul>
<pre><code>sudo cat /etc/default/inlets | cut -d"=" -f2

cd4bf5db2601ec9075425102d2b12a9ee5413d4a
</code></pre>
<ul>
<li>
<p>Download the latest Caddy binary from the <a href="https://github.com/mholt/caddy/releases">Releases page</a> - on a VPS you want a binary with a name like <code>caddy_v0.11.5_linux_amd64.tar.gz</code>. You can use <code>wget https://</code> to download the file.</p>
</li>
<li>
<p>Uncompress the tar.gz file: <code>tar -xvf caddy_v0.11.5_linux_amd64.tar.gz</code></p>
</li>
<li>
<p>Here are the instructions for Linux:</p>
</li>
</ul>
<p>Use a 1.x release rather than 2.0, where the configuration format changed.</p>
<pre><code>curl -sLSf https://github.com/caddyserver/caddy/releases/download/v1.0.4/caddy_v1.0.4_linux_amd64.tar.gz &gt; caddy_v1.0.4_linux_amd64.tar.gz

sudo tar -xvf caddy_v1.0.4_linux_amd64.tar.gz --strip-components=0 -C /usr/local/bin

sudo cp /usr/local/bin/init/linux-systemd/caddy.service /etc/systemd/system/
sudo systemctl enable caddy

sudo rm -rf /usr/local/bin/init

sudo mkdir -p /etc/caddy
</code></pre>
<ul>
<li>Create <em>/etc/caddy/Caddyfile</em> replacing <code>exit.domain.com</code> with your own DNS record:</li>
</ul>
<pre><code>exit.domain.com

proxy / 127.0.0.1:8080 {
  transparent
}

proxy /tunnel 127.0.0.1:8080 {
  transparent
  websocket
}
</code></pre>
<ul>
<li>Start the Caddy process with <code>caddy</code>. The first time you run this command, Caddy will ask for your email address. Enter your email and then wait for the TLS certificate to be issued by LetsEncrypt.</li>
<li>Now exit Caddy and run <code>sudo systemctl start caddy</code> to use the systemd unit file we installed</li>
</ul>
<p>The systemd unit file means that Caddy will restart upon reboot and if its process crashes.</p>
<h3 id="connectyourclient">Connect your client</h3>
<p>Over on your laptop you can now start your local endpoint either directly or via a Docker container.</p>
<p>The simplest HTTP server is probably the one built-into Python. It will serve files from whatever directory you run it in.</p>
<ul>
<li>Create a temporary directory:</li>
</ul>
<pre><code>mkdir ~/filestore/
cd ~/filestore/
echo "Welcome to my filestore" &gt; welcome.txt
</code></pre>
<pre><code># If Python version returned above is 3.X
python3 -m http.server
# On windows try "python" instead of "python3"
# If Python version returned above is 2.X
python -m SimpleHTTPServer
</code></pre>
<p>By default it listens on port 8000: <code>Serving HTTP on 0.0.0.0 port 8000 ...</code> so this will be our <code>--upstream</code> value.</p>
<p>You can test the local URL at: <a href="http://127.0.0.1:8000/">http://127.0.0.1:8000</a></p>
<h3 id="connectyourclient">Connect your client</h3>
<p>Install inlets on your laptop or local computer such as your Raspberry Pi:</p>
<pre><code># Download and copy to /usr/local/bin/
sudo inletsctl download

# Or download, and you can move the binary manually
inletsctl download
</code></pre>
<p>Now connect the client to your tunnel server:</p>
<pre><code>inlets client \
 --remote wss://exit.domain.com \
 --upstream=exit.domain.com=http://127.0.0.1:8000 \
 --token=cd4bf5db2601ec9075425102d2b12a9ee5413d4a
</code></pre>
<ul>
<li>Note the use of <code>--token</code> from earlier. This authenticates our client to our exit-server to prevent unauthorized access.</li>
<li><code>wss://</code> shows we are using an encrypted tunnel to prevent tampering and MITM</li>
</ul>
<p>Now you and your friends can visit <a href="https://exit.domain.com/">https://exit.domain.com</a> and access the Simple Python HTTP server running on your laptop.</p>
<p>If you have multiple domain names and multiple services on your laptop simply change the <code>--upstream</code> flag to reflect that.</p>
<p>For OpenFaaS on Docker Swarm that may be:</p>
<pre><code>inlets client \
 --remote wss://exit.domain.com \
 --upstream=gateway.domain.com=http://127.0.0.1:8080,prometheus.domain.com=http://127.0.0.1:9090
</code></pre>
<p>You'll see output similar to:</p>
<pre><code>2019/03/15 11:56:31 Upstream: lon1-exit.domain.com =&gt; http://127.0.0.1:8000
2019/03/15 11:56:31 connecting to wss://lon1-exit.domain.com/tunnel
2019/03/15 11:56:32 Connected to websocket: 192.168.0.71:49631
</code></pre>
<p>Just remember to add each DNS A record for each sub-domain you want to be accessible from the exit-server.</p>
<p>If you're running your client on a Linux computer or Raspberry Pi, you can create a systemd unit file so that the tunnel restarts and comes up upon reboot.</p>
<h3 id="didyouknow">Did you know?</h3>
<p>inlets also works on a Raspberry Pi, so you can run the client on a Raspberry Pi 24/7 as a way to get incoming traffic to your services on your Raspberry Pi cluster, or as a cheap gateway pointing at other computers in your network.</p>
<blockquote>
<p>Link: Buy your Raspberry Pi cluster here and follow my latest tutorial: <a href="https://blog.alexellis.io/test-drive-k3s-on-raspberry-pi/">k3s: Will it cluster?</a></p>
</blockquote>
<blockquote>
<p>Link: <a href="https://blog.alexellis.io/raspberry-pi-zero-tunnel-gateway/">Build a 10USD Internet Gateway with a Raspberry Pi Zero</a></p>
</blockquote>
<h3 id="wrappingup">Wrapping up</h3>
<blockquote>
<p>Show your support: Star or fork the project here: <a href="https://github.com/inlets/inlets">inlets/inlets</a> and follow <a href="https://twitter.com/inletsdev">@inletsdev</a> on Twitter.</p>
</blockquote>
<p>You now have a completely free tunnel set up for around 5USD/month which can punch through almost any firewall. The code is open-source under the MIT license and built by community.</p>
<h4 id="inletsprotcptunnelsforwork">inlets-pro - TCP tunnels for work</h4>
<p><img src="https://raw.githubusercontent.com/inlets/media/master/assets/inlets-monochrome.png" width="100px"></p><p>Since launching …</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.alexellis.io/https-inlets-local-endpoints/">https://blog.alexellis.io/https-inlets-local-endpoints/</a></em></p>]]>
            </description>
            <link>https://blog.alexellis.io/https-inlets-local-endpoints/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24132345</guid>
            <pubDate>Wed, 12 Aug 2020 14:28:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From social media darling to America’s most wanted: Your guide to TikTok]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24132163">thread link</a>) | @donohoe
<br/>
August 12, 2020 | https://restofworld.org/2020/do-you-even-tiktok-tiktok/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/do-you-even-tiktok-tiktok/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>There’s little chance you haven’t heard of TikTok by now. Between the viral dance videos and President Donald Trump’s comments, speculation about the future of the popular video-sharing platform has reached a fever pitch.&nbsp;</p>



<p>Here’s everything you need to know about TikTok: where it came from, why countries are threatening to ban it, and how it could trigger a ripple effect through China’s billion-dollar startup scene.</p>



<h3><strong>Where did TikTok come from?&nbsp;</strong></h3>


<div>

<div>

<div>
<table>
<tbody>
<tr><td>Company Name:</td><td>TikTok</td></tr>
<tr><td>Main office:</td><td>Los Angeles, USA
</td></tr>
<tr><td>CEO:</td><td>Kevin Mayer</td></tr>
<tr><td>Data centers:</td><td>Los Angeles, Dublin, Singapore
</td></tr>
<tr><td>Monthly Active Users:</td><td>800 million</td></tr>
<tr><td>Downloads:</td><td>over 2 billion</td></tr>
<tr><td>Annual revenue, 2019:</td><td>$200–$300 million</td></tr>
<tr><td>
</td></tr><tr><td>Available in:</td><td>141 countries, 39 languages</td></tr>
</tbody></table>
</div>
</div>
</div>


<p>TikTok’s origin story begins with ByteDance, a Chinese startup that brands itself as an artificial intelligence company. Its founder and CEO, 37-year-old Zhang Yiming, initially fought his way into the lucrative Chinese market with algorithm-driven content-sharing platforms. The company’s first major success, a curated news-sharing app called Toutiou, had <a href="http://www.ce.cn/cysc/tech/gd2012/201608/16/t20160816_14924089.shtml">55 million daily active users</a> within four years of its launch. The app dethroned Tencent — one of China’s most powerful tech giants — as the <a href="https://mp.weixin.qq.com/s/TAbIT96slElLVz18r7RE-g">most-used Android news app</a> in the country.&nbsp;</p>



<p>By 2016, ByteDance had turned its attention to video-sharing platforms. At the time, the Shanghai-based Musical.ly app was leading the global market. It allowed users to lip-sync pop songs and was finding a sizable audience overseas. Kuaishou, another Chinese short-form video platform, was also gaining traction locally. ByteDance incubated two apps that year. One mimicked Kuaishou, the other Musical.ly. Zhang bet that one might catch on.</p>



	




<p>The bet paid off. The Musical.ly copycat, known as Douyin in China, soared in the spring of 2017. By August of that year, it had more than 1 billion video views per day. By November, in an effort to open the market outside China, ByteDance had <a href="https://www.nytimes.com/2017/11/10/business/dealbook/musically-sold-app-video.html">acquired Musical.ly for nearly $1 billion</a>. The copycat outgrew the original, and in 2018, the two merged into a single app. It was known as TikTok.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/GettyImages-1227809947-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/GettyImages-1227809947-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/GettyImages-1227809947-400x266.jpg 400w, https://restofworld.org/wp-content/uploads/2020/08/GettyImages-1227809947-600x399.jpg 600w, https://restofworld.org/wp-content/uploads/2020/08/GettyImages-1227809947-1600x1065.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/08/GettyImages-1227809947-2800x1863.jpg 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="MINQUAN, CHINA - JULY 27, 2020 - Twin brothers Zhang Yabo and Zhang Ya-zhao presented tiktok webcast to promote mahua, a specialty food. Minquan County, Henan Province, China, 27 July 2020- PHOTOGRAPH BY Costfoto / Barcroft Studios / Future Publishing (Photo credit should read Costfoto/Barcroft Media via Getty Images)">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Costfoto/Barcroft Media via Getty Images</span>
			</figcaption>
		</figure>


<h3><strong>How did it become so popular?&nbsp;</strong></h3>



<p>Once ByteDance acquired Musical.ly, it applied its unique business ethos to the video-sharing platform. “I would call Musical.ly more of a product-driven company,” says tech analyst Rui Ma, “and ByteDance a more ‘algorithm-and-operations-driven’ company.” Ma, the creator and co-host of a podcast called Tech Buzz China<em>, </em>says ByteDance’s operational practices, which include hosting creator meetups and outreach campaigns, are often overlooked by English-language media.</p>



<p>TikTok’s hypnotic algorithm keeps users glued to its customized “For You” page with far more precise suggestions than Facebook’s or Instagram’s. This sophisticated content-sharing AI, together with its prowess in the Chinese market — at a time when users were new to mobile internet and social media — paved the way for TikTok’s global popularity. “Every Chinese internet company has to answer the same question,” says Ma. “<em>How do I cold-start this ecosystem when users don’t have existing friend lists?”&nbsp;</em></p>



<p>ByteDance answered with an algorithmic secret sauce fueling TikTok’s rise into a realm of billions: billions of users, billions of dollars, billions of page views. With coronavirus shelter-in-place orders upping screen time worldwide, the app’s popularity in the U.S. and India has exploded, with downloads in Brazil, Indonesia, Russia, and Mexico trailing close behind.</p>



<p>But with increased popularity comes increased scrutiny.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/GettyImages-1227914701-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/GettyImages-1227914701-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/GettyImages-1227914701-400x273.jpg 400w, https://restofworld.org/wp-content/uploads/2020/08/GettyImages-1227914701-600x410.jpg 600w, https://restofworld.org/wp-content/uploads/2020/08/GettyImages-1227914701-1600x1092.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/08/GettyImages-1227914701-2800x1911.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="An employee walks outside the headquarters of ByteDance, the owner of video sharing app TikTok, in Beijing on August 5, 2020. - US President Donald Trump on August 4 defended his demand for the US government to get a piece of the action to let Microsoft or any other US company buy popular China-based social media app TikTok. (Photo by Noel Celis / AFP) (Photo by NOEL CELIS/AFP via Getty Images)">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Noel Celis/AFP via Getty Images</span>
			</figcaption>
		</figure>


<h3><strong>Why is the platform under investigation?</strong></h3>



<p>In November 2019, as TikTok <a href="https://www.reuters.com/article/us-tiktok-cfius-exclusive/exclusive-u-s-opens-national-security-investigation-into-tiktok-sources-idUSKBN1XB4IL">approached 30 million U.S. users</a>, an interagency government panel in Washington called the Committee on Foreign Investment in the United States (CFIUS) launched an investigation into TikTok’s 2017 Musical.ly buyout, which brought ByteDance into the American market.</p>



<p>At the time, CFIUS, which probes foreign investments for threats to national security, did not consider the merger to pose any risk. But over the past year, the panel has shown growing concern about the platform, and in early 2020, it <a href="https://home.treasury.gov/system/files/206/FR-2018-22182_1786904.pdf">issued regulations</a> that redefine national security to include “economic security,” effectively <a href="https://fortune.com/2020/01/20/cfius-rules-regulations-china-investment/">widening the scope of</a> its investigation into TikTok.</p>



<p>TikTok’s Chinese ownership has landed the social media platform in the same geopolitical crosshairs as Chinese technology companies like Huawei and Tencent: the fact that it operates out of China requires that the company comply with the Chinese Communist Party’s rules and regulations, leaving foreign user data potentially vulnerable to the CCP. ByteDance has said it houses much of <a href="https://newsroom.tiktok.com/en-us/statement-on-tiktoks-content-moderation-and-data-security-practices">TikTok’s American user data in the US and Singapore</a> and <a href="https://www.wsj.com/articles/tiktok-user-data-what-does-the-app-collect-and-why-are-u-s-authorities-concerned-11594157084">would refuse state requests for data in China</a>. But in the current charged political climate, American authorities remain unconvinced by their assertions.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/tiktok_explainer_grab2-e1597190651771-40x82.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/tiktok_explainer_grab2-e1597190651771-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/tiktok_explainer_grab2-e1597190651771-400x820.png 400w, https://restofworld.org/wp-content/uploads/2020/08/tiktok_explainer_grab2-e1597190651771-600x1230.png 600w, " sizes="300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>On August 3, ByteDance founder Zhang <a href="https://www.bloomberg.com/news/articles/2020-08-03/bytedance-ceo-letter-working-overtime-on-u-s-tiktok-solution?sref=QYWxDQ1o">sent an exasperated internal memo to his staff</a>. “Even though we’ve repeatedly stressed that we’re a privately run business, and despite our willingness to adopt even more technical solutions to allay their concerns,” Zhang wrote, “CFIUS still believes ByteDance has to sell the TikTok U.S. operation. We do not agree with this decision.”&nbsp;</p>



<h3><strong>Is Trump going to ban TikTok?</strong></h3>



<p>On Thursday, President Trump announced that he would use his emergency economic powers to ban TikTok from operating in the U.S.&nbsp;</p>



<p>The announcement comes on the heels of India’s ban, announced on June 29, under which TikTok and 58 other Chinese apps were banned overnight after fatal military clashes on the China-India border. Experts say India’s ban is largely political and that no clear audit was conducted before the decision. TikTok chose to comply with the ban by voluntarily removing its app from the Google Play and iOS App stores, then shutting down its servers across India. With only a day’s notice — little time to migrate their followings to other platforms — more than 119 million active Indian users were booted off the app.</p>



<p>Although it’s unclear whether Trump can enforce an all-out ban on TikTok, the fate of India’s influencers has shaken American TikTokers, many of whom have taken to the app to post preemptive eulogies.&nbsp;</p>



<p>The executive order puts a 45-day countdown on American companies to cut all business ties with TikTok. This will render <a href="https://www.npr.org/2020/08/06/900019185/trump-signs-executive-order-that-will-effectively-ban-use-of-tiktok-in-the-u-s">TikTok’s operations in the U.S. unmanageable</a>, leaving ByteDance scrambling to sell its U.S. business to an American company before mid-September. As of Monday afternoon, TikTok was reportedly in acquisition talks with Microsoft <a href="https://www.wsj.com/articles/twitter-tiktok-have-held-preliminary-talks-about-possible-combination-11596925449">and Twitter</a>, while the company itself has said it will <a href="https://www.npr.org/2020/08/08/900394707/tiktok-to-sue-trump-administration-over-ban-as-soon-as-tuesday">sue the Trump administration to challenge</a> the ban.</p>



<h3><strong>What does Microsoft have to do with all this?&nbsp;</strong></h3>



<p>With the future of TikTok’s U.S. operation threatened, Zhang (who briefly worked at Microsoft) has approached the American tech company to buy out the American wing of the business. Microsoft <a href="https://www.ft.com/content/b02d5324-07e6-48ac-b658-b8c400d9b4fc">has cultivated deep roots in the Chinese market</a>; LinkedIn and Github, which it owns, are two of the three major foreign-owned platforms in China that host user-generated content. While Google and other foreign-owned search engines have been booted from the Chinese market, Microsoft’s Bing has remained and largely complied with Chinese censorship orders.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/GettyImages-1223694893-40x31.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/GettyImages-1223694893-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/GettyImages-1223694893-400x306.jpg 400w, https://restofworld.org/wp-content/uploads/2020/08/GettyImages-1223694893-600x459.jpg 600w, https://restofworld.org/wp-content/uploads/2020/08/GettyImages-1223694893-1600x1224.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/08/GettyImages-1223694893-2800x2142.jpg 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="ENCINO, CALIFORNIA - MAY 08:  (L-R) TikTok influencers Dedrick Spence, Abel Carden, Chris Weaver, Desmond Spence and Emiliano Decontreras Jr. perform At Home With TikTok's " the="" drip="" crib"="" at="" crib="" on="" may="" 08,="" 2020="" in="" encino,="" california.="" (photo="" by="" jon="" kopaloff="" getty="" images)"="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Jon Kopaloff/Getty Images</span>
			</figcaption>
		</figure>


<h3><strong>Will TikTok be the same after a purchase?</strong></h3>



<p>Although Microsoft’s success with Xbox has cemented its place in the gaming market, <a href="https://www.zdnet.com/article/microsofts-steady-retreat-from-consumer-products-is-nearly-complete/">trendy and youth-oriented</a> it is not. Some worry a Microsoft-owned TikTok would share the fate of the company’s failed consumer-facing products, like Zune or Groove Music.&nbsp;&nbsp;</p>



<p>It’s not clear what would be included in the acquisition deal between ByteDance and Microsoft. <em>New York Times </em>tech columnist Kevin Roose <a href="https://www.nytimes.com/2020/08/05/technology/tiktok-deal-algorithm.html">argues </a>that TikTok’s algorithms “could be the most valuable asset the company owns.” The success of the algorithm, though, may be difficult to maintain without ByteDance’s stewardship. “The magic in it is sort of in the optimization,” says Rui Ma. Once ByteDance and Microsoft start to operate the algorithms separately and make their own optimization decisions, the same TikTok could split into two very different products.</p>



<p>After Microsoft announced its interest in an acquisition, <a href="https://www.bloomberg.com/news/articles/2020-08-04/tiktok-s-price-is-a-giant-question-mark-in-already-complex-deal?sref=QYWxDQ1o">analysts</a> estimated the valuation of TikTok’s U.S. services at between $20 and $50 billion — very much within cash-rich Microsoft’s budget. But that valuation may dip with the growing political risks attached to the merger. The Beijing-based financial-news publication <em>Caixin</em> has reported a source close to the negotiation as saying that, as of August 7, <a href="https://www.caixinglobal.com/2020-08-08/exclusive-trump-pressure-slashes-us-tiktok-value-by-at-least-half-101590290.html">the valuation had been lowered to $10 billion</a>. That would be a huge loss for ByteDance, a company whose global ambitions distinguish it from most Chinese tech giants. TikTok is far and away its top-earning app.</p>



<h3><strong>What does an American TikTok buyout mean for other Chinese startups?&nbsp;</strong></h3>



<p>TikTok’s story has become a cautionary tale for other Chinese entrepreneurs. In the short term, Chinese companies will be incentivized to stay in the domestic market, according to Jennifer Zhu, a Hong Kong–based entrepreneur and investor. “Your choice is between <em>Do I develop the next three provinces that have 100 million people? </em>or <em>Do I go to the U.S. and have this massive risk?</em>’” says Zhu. After the hostility surrounding TikTok’s situation, she expects more Chinese entrepreneurs to choose the former.&nbsp;</p>



<p>Investor hesitation couldn’t come at a worse time: while China’s venture-capital market is the second largest in the world, it has seen <a href="https://www.wsj.com/articles/chinas-venture-capital-boom-is-over-leaving-investors-high-and-dry-11573727756">a steady decline</a> over the past few years. In the first quarter of 2020, thanks in large part to the pandemic, <a href="https://theconversation.com/chinese-start-ups-are-being-starved-of-venture-capital-with-worrying-omens-for-the-west-137104">the market shrank by 60%</a>. As more Chinese apps undergo …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/do-you-even-tiktok-tiktok/">https://restofworld.org/2020/do-you-even-tiktok-tiktok/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/do-you-even-tiktok-tiktok/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24132163</guid>
            <pubDate>Wed, 12 Aug 2020 14:04:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bootstrap a startup that won’t fail – lessons learned]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24132135">thread link</a>) | @phalox
<br/>
August 12, 2020 | https://phalox.be/wp/startup/bootstrap-a-startup-that-wont-fail/?pk_campaign=blog_bootstrap&pk_source=hn | <a href="https://web.archive.org/web/*/https://phalox.be/wp/startup/bootstrap-a-startup-that-wont-fail/?pk_campaign=blog_bootstrap&pk_source=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><em>Sorry for the poor experience on mobile. We’ll try to fix this soon.</em></p>



<p>You’ve read some articles about nomads running their business from a beach? You enjoyed books about startups? You think that the time is right to bootstrap your own startup? Then you’re at the right address.</p>



<p>In this post we’ve summarized the most important lessons during the early stages of your startups for founders who bootstrap their business with their own means. Some of these lessons might come as a surprise, so keep reading!</p>



<h2>Set your expectations straight</h2>



<p>Websites like <a href="https://www.indiehackers.com/" target="_blank" rel="noreferrer noopener">Indie Hackers</a>, <a href="https://www.producthunt.com/" target="_blank" rel="noreferrer noopener">Product Hunt</a> or <a href="https://news.ycombinator.com/" target="_blank" rel="noreferrer noopener">Hacker News</a> make it seem like every entrepreneur builds a 1M$ business overnight. Despite these magnificent stories, the reality is quite different: <a href="https://www.forbes.com/sites/neilpatel/2015/01/16/90-of-startups-will-fail-heres-what-you-need-to-know-about-the-10/" target="_blank" rel="noreferrer noopener">90% of startups fail</a> sooner or later and those 10% rarely succeed overnight. Building any business is hard work and takes longer than you’ll expect.</p>



<p>Bootstrapping and running a startup sounds easy if you read The Lean Startup or other books. On the one hand, the theory (iteratively grow your business) is easy, but practice, on the other hand, is a lot harder. We easily lose the customer out of sight and start thinking in solutions. Before you know, you’ve spent a month developing an ‘<a href="https://en.wikipedia.org/wiki/Minimum_viable_product" target="_blank" rel="noreferrer noopener">MVP</a>’ (Minimum Viable Product) that nobody wants.</p>



<p>And that’s just one of the many bad days you might experience. You’ll be disappointed that nobody uses your product, you might be angry at a random person who destroyed your idea or you will have days without any energy whatsoever. But when you become 100% customer focused and provide value frequently, in return you will receive delight, gratefulness and heaps of energy so that you can create even more customer value.</p>



<h2>Validate your startup idea</h2>



<p>The internet contains countless websites of bootstrapped startups that never saw a single customer. A lot of code has been wasted on a problem that nobody had, or nobody wanted to pay for. If only there would be a better way to not waste precious coding hours.</p>



<p>Well there is! It’s called validation and <a href="http://gallery.mailchimp.com/8c534f3b5ad611c0ff8aeccd5/files/Startup_Genome_Report_Extra_Premature_Scaling_version_2.1.pdf" target="_blank" rel="noreferrer noopener">70% of startups never bother</a> to do this step properly. Just like we all did at one point, they think that their idea is valuable and that anything but writing code is a waste of time. Books like <a href="http://momtestbook.com/" target="_blank" rel="noreferrer noopener">The Mom Test</a> only talk about customer validation for good reason. It’s so easy to lose the customer out of sight.</p>



<div><div>
<figure><ul><li><figure><img loading="lazy" width="900" height="600" src="https://phalox.be/wp/wp-content/uploads/2020/08/amy-hirschi-K0c8ko3e6AA-unsplash-900.jpg" alt="A bootstrap entrepreneur talking to her customer to validate her startup" data-id="695" data-full-url="https://phalox.be/wp/wp-content/uploads/2020/08/amy-hirschi-K0c8ko3e6AA-unsplash-900.jpg" data-link="https://phalox.be/wp/startup/bootstrap-a-startup-that-wont-fail/attachment/amy-hirschi-k0c8ko3e6aa-unsplash-900/" srcset="https://phalox.be/wp/wp-content/uploads/2020/08/amy-hirschi-K0c8ko3e6AA-unsplash-900.jpg 900w, https://phalox.be/wp/wp-content/uploads/2020/08/amy-hirschi-K0c8ko3e6AA-unsplash-900-300x200.jpg 300w, https://phalox.be/wp/wp-content/uploads/2020/08/amy-hirschi-K0c8ko3e6AA-unsplash-900-768x512.jpg 768w" sizes="(max-width: 900px) 100vw, 900px"><figcaption>Always keep your customer central. It’s the only thing that counts.</figcaption></figure></li></ul></figure>
</div></div>



<p>With small experiments, you can validate that your customer really has a problem worth paying for. During your early experiments, you could already deliver a service to your customers without writing a single line of code. Are you building a post card printing company? Just print them manually, add a stamp and put them in the mailbox.</p>



<p>As soon as you find a worthwhile customer problem, you can build an MVP  for that specific issue (and nothing else). As Toon (creator of Validat.r) <em>famously </em>said “There is always a <em>more minimal </em>MVP”, so also you can reduce your first product version. Don’t add nice to haves, stick to the core product. Consequently, when you reduce development time you can get your product faster to your customer and start receiving payments – the true validation of your business idea.</p>



<h2>Scale up</h2>



<p>If you reached this point, you already outperformed 70% of startups. Congratulations! However, the battle isn’t over yet. From this point on there are many paths you can take. Do you want to stick to a one-person business? Is competition breathing down your neck? Is it easy to copy your solution?</p>



<p>The answers to these questions will determine how fast you should scale up your bootstrapped business and how you should act next. By now you’ll have a decent amount of customer insight (something your competition might lack) and it will allow you to make decisions more confidently.</p>



<p>Whether you decide for the riskier or the safer approach, you should always keep your customer central. When you found your most loyal customers, allow them to iteratively co-create your future product, let them test early versions and encourage them to promote your product!</p>



<h2>Get help to bootstrap your startup</h2>



<p>There is so much content out there that you might get lost. Luckily <a href="https://validator.phalox.be/?pk_campaign=blog_bootstrap&amp;pk_source=phalox.be" target="_blank" rel="noreferrer noopener">Validat.r</a> will soon provide its services to help solo founders bootstrap their startup and increase the chances of success. </p>



<div><div>
<div><div>
<figure><blockquote><div><p>Exclusively for readers of this blog</p><p><strong>Sign up</strong> for the <a href="https://validator.phalox.be/?pk_campaign=blog_bootstrap&amp;pk_source=phalox.be" target="_blank" rel="noreferrer noopener">Validat.r waiting list</a> and receive <strong>a free landing page roast</strong></p></div></blockquote></figure>
</div></div>
</div></div>



<p><a href="https://validator.phalox.be/?pk_campaign=blog_bootstrap&amp;pk_source=phalox.be" target="_blank" rel="noreferrer noopener">Validat.r</a> helps you stay focused on your customer’s problem and ensures that your experiments stay small and your validation velocity high. We keep you motivated so that <strong>you can continue where others stopped</strong>. </p>
<!-- Simple Share Buttons Adder (7.7.1) simplesharebuttons.com -->		</div></div>]]>
            </description>
            <link>https://phalox.be/wp/startup/bootstrap-a-startup-that-wont-fail/?pk_campaign=blog_bootstrap&amp;pk_source=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24132135</guid>
            <pubDate>Wed, 12 Aug 2020 13:59:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pin Bypass in Passwordless WebAuthn on Microsoft.com and Nextcloud]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24131850">thread link</a>) | @sufficient
<br/>
August 12, 2020 | https://hwsecurity.dev/2020/08/webauthn-pin-bypass/ | <a href="https://web.archive.org/web/*/https://hwsecurity.dev/2020/08/webauthn-pin-bypass/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>While implementing FIDO2 and WebAuthn support in our Hardware Security SDK, we found a way to bypass the PIN when logging into microsoft.com.</p>
<h2 id="what-is-fido2webauthn">What is FIDO2/WebAuthn?</h2>
<p>FIDO2/WebAuthn is an open standard, supported by browsers and driven by tech companies, such as Google and Microsoft.
Many websites already adopted the FIDO standard for two-factor authentication.
This means, in addition to a password, a login requires an additional FIDO hardware device, such as a YubiKey.</p>
<p>FIDO2/WebAuthn goes one step further and allows users to login without passwords, creating passwordless authentication.
The standard is built on Public Key Cryptography and thus eliminates the need to exchange a shared secret between user and website.</p>
<p>With our experience in cryptographic protocols, we evaluated the WebAuthn specification and its threat model.
The technology is well thought through, focused on the scenario of authentication and makes the right trade-offs.
We have mostly praise for its design.</p>
<h2 id="webauthn-passwordless-authentication">WebAuthn Passwordless Authentication</h2>
<p><img src="https://hwsecurity.dev/2020/08/webauthn-pin-bypass/security-key.jpg">
Passwordless authentication is yet to be adopted widely.
A prominent example that already implements this is Microsoft with its Azure Active Directory.</p>
<p>First, the user adds a security key to her account.
The browser will ask the user to set a PIN on her security key.
The registration is completed by touching the button on the security key.</p>
<p><strong>Now, on each login, the user needs the PIN and her security key (multi-factor authentication: “something you know and something you have”).</strong></p>

<p>
  <iframe src="https://www.youtube.com/embed/uLrTP9k3Rek" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h2 id="pin-bypass-in-passwordless-authentication">PIN Bypass in Passwordless Authentication</h2>
<p>We were able to bypass the PIN when logging into microsoft.com.
This breakes the assumption of requiring two factors and allows an attacker to log into the victim’s account by using the security key only.
He could steal the victim’s USB security key and login without a PIN.
Attacking the victim over NFC is even easier by sneaking up on the victim without getting noticed.</p>

<p>
  <iframe src="https://www.youtube.com/embed/hZvnC11ttqw" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h2 id="technical-details">Technical Details</h2>
<p>On a FIDO2 security key, there is only one PIN, not multiple PINs.
Just because a PIN has been set does not mean that all FIDO2 credentials will require a PIN from that point on.</p>
<p>To allow <code>getAssertion</code> calls with or without PIN, the website decides this individually per operation.
This is done by setting the optional 
<a href="https://www.w3.org/TR/webauthn-2/#enum-userVerificationRequirement" target="_blank" rel="noopener"><code>userVerification</code></a> property to either <code>required</code>, <code>preferred</code>, or <code>discouraged</code>.
Microsoft’s website did not provide a value (see 
<a href="#appendix">Javascript Snippet in Appendix</a>).
In this case, Chrome and other browsers will either ask the user to set a PIN or ask the user to enter the existing PIN (see 
<a href="https://chromium.googlesource.com/chromium/src/+/master/content/browser/webauth/uv_preferred.md" target="_blank" rel="noopener">Chrome’s notice regarding <code>preferred</code></a>).</p>
<p>It is important to note that <code>userVerification</code> only influences how the browser communicates with the security key.
Setting <code>userVerification = "required"</code> provides no cryptographic guarantee by itself that the <code>getAssertion</code> call will always require a PIN.
Instead it is up to the Relying Party (the WebAuthn server) to verify that the cryptographic signature in <code>authData</code> has the UV flag set (Step 17 in 
<a href="https://www.w3.org/TR/webauthn-2/#rp-op-verifying-assertion-step-rpid-hash" target="_blank" rel="noopener">7.2. Verifying an Authentication Assertion</a>).
This is also noted briefly in Yuriy Ackermann’s blog post (Step 6 under the section 
<a href="https://medium.com/@herrjemand/verifying-fido2-responses-4691288c8770" target="_blank" rel="noopener">“Verifying response”</a>).
So to fix this issue, on Microsoft’s implementation of the Relying Party, the UV flag in <code>authData</code> must be checked.</p>
<h2 id="microsofts-response">Microsoft’s Response</h2>
<p>We reported the issue to Microsoft.
They did not consider it a vulnerability, but fixed it:</p>
<blockquote>
<p>Thank you for reporting this issue to Microsoft.
Our team investigated this, and we agree that userVerification should be required in the described scenarios as part of a defense in depth strategy.
We are grateful to the finder for their work in identifying this issue and reporting it to Microsoft.</p>
<p>It is important to note that when a UserPresence check was used in place of a UserVerification check, the resulting token issued reflected correctly that a single-factor authentication occurred.
This token would not be usable to access resources protected by strong-auth (MFA) policies or elevate access.
This does not lessen the significance of the research but does mitigate the impact of the finding.</p>
</blockquote>
<p>We verified that Microsoft indeed fixed the PIN bypass issue.</p>
<p>We do not agree with Microsoft that this was not a vulnerability.
If a PIN is requested by the browser during login, users expect that this PIN is actually verified.
This was not the case and lead to a <strong>false sense of security</strong>.
Even for us security developers, this was highly unexpected.</p>
<h2 id="nextcloud-19">Nextcloud 19</h2>
<p>Nextcloud introduced WebAuthn passwordless authentication with 
<a href="https://nextcloud.com/blog/nextcloud-hub-brings-productivity-to-home-office/" target="_blank" rel="noopener">version 19</a>.
In an announcement of Nextcloud’s cooperation with Nitrokey, 
<a href="https://www.nitrokey.com/news/2020/what-passwordless-world-looks" target="_blank" rel="noopener">it is written that this feature provides two-factor authentication</a>:</p>
<blockquote>
<p>The server asking for authentication can request verification of multiple factors, so that a configured key requires the user to not just plug it in but also enter a PIN or scan a finger print.</p>
</blockquote>
<p>We found that in Nextcloud 19.0.0 and 19.0.1, <code>userVerification</code> is not set and the UV flag is not checked on the server.
Thus, even though a FIDO2 key with a PIN is added in a user account, the PIN is not required to log in.</p>
<h2 id="nextclouds-response">Nextcloud’s Response</h2>
<p>We discussed the issue with the Nextcloud team privately.
They do not consider this a vulnerability as the feature is supposedly not designed to provide two-factor authentication but only single-factor authentication.
They agree that Nitrokey’s blog post is incorrect (it has now been updated) and they 
<a href="https://github.com/nextcloud/server/pull/21880" target="_blank" rel="noopener">implemented <code>userVerification = "discouraged"</code></a> for their next maintenance release, which will stop browsers from asking for a PIN.
For two-factor authentication, they recommend users to enable TOTP or Nextcloud Notifications.</p>
<p>Like with Microsoft’s response, we think that if the user is asked to provide a PIN, the user expects that the PIN is verified.
We recommend that Nextcloud documents their threat model and communicates that their passwordless authentication does not provide two-factor protection.</p>
<h2 id="inconsistencies-between-spec-and-implementation">Inconsistencies between Spec and Implementation</h2>
<p>WebAuthn specifies that the 
<a href="https://www.w3.org/TR/webauthn-2/#enum-userVerificationRequirement" target="_blank" rel="noopener">UV flag should not be checked</a> if the website sets <code>userVerification = 'preferred'</code>.
This is unexpected to web developers who observe that Chrome requires a PIN and conclude that their code provides two-factor protection.
In fact it only does so when checking the UV flag on the server.
We recommend that the FIDO Alliance re-think their position on this matter (see 
<a href="https://github.com/w3c/webauthn/issues/1253" target="_blank" rel="noopener">related GitHub discussions</a>) to better match the developers expectations.</p>
<h2 id="reproducing-the-issue">Reproducing the Issue</h2>
<p>If you like to try how different websites implement WebAuthn, try our SDK example app on Google Play.
We added a button to skip the PIN authentication.</p>
<p><a href="https://play.google.com/store/apps/details?id=de.cotech.hw.fido.example"><img src="https://hwsecurity.dev/img/google-play-badge-small.png" alt="Get it on Google Play" height="63"></a></p>
<p>We also provide a 
<a href="#appendix">Tampermonkey script</a> that can be installed in Chrome to override <code>userVerification</code> to always be <code>discouraged</code>.</p>
<h2 id="what-about-other-passwordless-webauthn-logins">What about other passwordless WebAuthn logins?</h2>
<p>This issue is also present on 
<a href="https://demo.yubico.com/playground" target="_blank" rel="noopener">Yubico’s Playground</a>.
Due to time constraints we haven’t yet evaluated other implementations of a FIDO2 Relying Party.
A good overview of existing projects can be found on 
<a href="https://github.com/herrjemand/awesome-webauthn#server-libs" target="_blank" rel="noopener">Yuriy Ackermann’s Github repo</a>.</p>
<h2 id="timeline">Timeline</h2>
<ul>
<li>2020-08-12: We published this blog post</li>
<li>2020-07-20: Added Nextcloud’s response</li>
<li>2020-07-15: Nextcloud 19 tested, included in post and reported to Nextcloud</li>
<li>2020-07-09: Microsoft fixed the issue but does not consider it a vulnerability</li>
<li>2020-06-22: Added more context about userVerification = ‘preferred’</li>
<li>2020-06-18: Finished blog post, post is not listed publicly</li>
<li>2020-06-18: Reported to Microsoft as VULN-026995</li>
</ul>
<h2 id="appendix">Appendix</h2>
<div>
<div>
<div id="accordion">
<div>

<div id="collapseOne" aria-labelledby="headingOne" data-parent="#accordion">
<div>
<p>In our tests, the <code>useNewDefaults</code> branch is not executed, thus <code>userVerification</code> is not set.</p>
<pre><code>exports.getAssertion = function (serverChallenge, serverAllowList, rpId)
{
    var allowListParam = [];

    if (serverAllowList)
    {
        allowListParam = serverAllowList.map(
            function (credentialId)
            {
                return { type: "public-key",
                    id: TypeConverter.base64UrlStringToArrayBuffer(credentialId) };
            });
    }

    var publicKeyCredentialRequestOptions =
    {
        challenge: TypeConverter.stringToArrayBuffer(serverChallenge),
        timeout: FidoConstants.Timeout,
        rpId: rpId,
        allowCredentials: allowListParam
    };

    if (useNewDefaults)
    {
        publicKeyCredentialRequestOptions.userVerification = "required";
    }

    return n.credentials.get({ publicKey: publicKeyCredentialRequestOptions });
};
</code></pre>
</div>
</div>
</div>
<div>

<div id="collapseTwo" aria-labelledby="headingTwo" data-parent="#accordion">
<div>
<ol>
<li>
<a href="https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo?hl=de" target="_blank" rel="noopener">Install Tampermonkey</a></li>
<li>Add this script:</li>
</ol>
<pre><code>// ==UserScript==
// @name         Skip WebAuthn PIN verification
// @namespace    https://hwsecurity.dev
// @version      1.0
// @description  Discourage WebAuthn userVerification
// @author       Vincent Breitmoser
// @match        https://*/*
// @grant        none
// ==/UserScript==

(function() {
    'use strict';

    const origGet = navigator.credentials.get.bind(navigator.credentials);
    navigator.credentials.get = function(arg) { console.log(arg); arg.publicKey.userVerification = "discouraged"; return origGet(arg); }
})();
</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>

    </div></div>]]>
            </description>
            <link>https://hwsecurity.dev/2020/08/webauthn-pin-bypass/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24131850</guid>
            <pubDate>Wed, 12 Aug 2020 13:28:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Programming Languages to Learn to Code: 2020 Edition]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24131217">thread link</a>) | @studentLS
<br/>
August 12, 2020 | https://coding.degree/best-coding-languages/ | <a href="https://web.archive.org/web/*/https://coding.degree/best-coding-languages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>When it comes to programming languages to learn and use, there are a lot of options to choose from.&nbsp; Some languages have stood the test of time and been around for ages, outlasting numerous changes to the technology industry.&nbsp; Still, many programming languages are relatively new as well, developed to adapt to those very changes in novel ways.&nbsp; So, in this choice overload situation, the question becomes, which language should you choose when you want to learn to code?</p><p>Making an informed decision about this is no easy matter, as each programming language does offer something different, whether it be in terms of how it’s used, how beginner-friendly it is, or something else entirely.&nbsp; In fact, this single point often trips up many people as they begin to learn to code, as indecisiveness takes over instead of the actual learning part.</p><p>However, with good information, and a clear goal in mind, you can make this tough decision and be on the fast track to learning a programming language that will help you achieve whatever you would like professionally or personally.&nbsp; Below, we’ve compiled a comprehensive information guide to help you along so you can stop researching and get to learning to code that much faster.</p><p>So sit back, and let’s talk about the best programming languages to learn!</p><p><img src="https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-scaled.jpg" alt="Programmer programming at a computer with dual screens" width="2560" height="1707" srcset="https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-scaled.jpg 2560w, https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-300x200.jpg 300w, https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-1024x683.jpg 1024w, https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-768x512.jpg 768w, https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-1536x1024.jpg 1536w, https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-2048x1365.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px" data-eio="l" data-old-src="https://coding.degree/wp-content/ewww/lazy/placeholder-1920x1280.png" data-src="https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-scaled.jpg" data-srcset="https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-scaled.jpg 2560w, https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-300x200.jpg 300w, https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-1024x683.jpg 1024w, https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-768x512.jpg 768w, https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-1536x1024.jpg 1536w, https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-2048x1365.jpg 2048w" data-src-webp="https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-scaled.jpg.webp" data-srcset-webp="https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-scaled.jpg.webp 2560w, https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-300x200.jpg.webp 300w, https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-1024x683.jpg.webp 1024w, https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-768x512.jpg.webp 768w, https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-1536x1024.jpg.webp 1536w, https://coding.degree/wp-content/uploads/2020/08/shutterstock_645324130-2048x1365.jpg.webp 2048w"></p><h3><span id="Key_Terminology"></span>Key Terminology<span></span></h3><p>Before we jump into talking about the languages themselves, there are a few keys terms we need to cover which are important to programming in general.&nbsp; When learning to code, these concepts are quite important, as they can not only inform your personal goals somewhat, but also have wider implications in terms of the best language to use for certain projects.&nbsp; That being said, we won’t dive too far into the technical specifics of each term – it’s just important to have a good grasp on them.</p><p><img src="https://coding.degree/wp-content/uploads/2020/08/1990s-computer-scaled.jpg" alt="1990s computer" width="2560" height="1707" srcset="https://coding.degree/wp-content/uploads/2020/08/1990s-computer-scaled.jpg 2560w, https://coding.degree/wp-content/uploads/2020/08/1990s-computer-300x200.jpg 300w, https://coding.degree/wp-content/uploads/2020/08/1990s-computer-1024x683.jpg 1024w, https://coding.degree/wp-content/uploads/2020/08/1990s-computer-768x512.jpg 768w, https://coding.degree/wp-content/uploads/2020/08/1990s-computer-1536x1024.jpg 1536w, https://coding.degree/wp-content/uploads/2020/08/1990s-computer-2048x1365.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px" data-eio="l" data-old-src="https://coding.degree/wp-content/ewww/lazy/placeholder-1920x1280.png" data-src="https://coding.degree/wp-content/uploads/2020/08/1990s-computer-scaled.jpg" data-srcset="https://coding.degree/wp-content/uploads/2020/08/1990s-computer-scaled.jpg 2560w, https://coding.degree/wp-content/uploads/2020/08/1990s-computer-300x200.jpg 300w, https://coding.degree/wp-content/uploads/2020/08/1990s-computer-1024x683.jpg 1024w, https://coding.degree/wp-content/uploads/2020/08/1990s-computer-768x512.jpg 768w, https://coding.degree/wp-content/uploads/2020/08/1990s-computer-1536x1024.jpg 1536w, https://coding.degree/wp-content/uploads/2020/08/1990s-computer-2048x1365.jpg 2048w" data-src-webp="https://coding.degree/wp-content/uploads/2020/08/1990s-computer-scaled.jpg.webp" data-srcset-webp="https://coding.degree/wp-content/uploads/2020/08/1990s-computer-scaled.jpg.webp 2560w, https://coding.degree/wp-content/uploads/2020/08/1990s-computer-300x200.jpg.webp 300w, https://coding.degree/wp-content/uploads/2020/08/1990s-computer-1024x683.jpg.webp 1024w, https://coding.degree/wp-content/uploads/2020/08/1990s-computer-768x512.jpg.webp 768w, https://coding.degree/wp-content/uploads/2020/08/1990s-computer-1536x1024.jpg.webp 1536w, https://coding.degree/wp-content/uploads/2020/08/1990s-computer-2048x1365.jpg.webp 2048w"></p><h4><span id="HighLevel_Languages"></span>High-Level Languages<span></span></h4><p>Most programming languages have a level of <em>abstraction</em> from the computer itself.&nbsp; When a computer sees a set of code, in the background it breaks it down into elements it can understand, often referred to as the <strong>machine language</strong>.&nbsp; However, this machine language is not something fit for humans to work with on a regular basis, hence why we have programming languages to help us out.</p><p>When something is a&nbsp;<strong>high-level language</strong>, this means that it is “far” away from machine language i.e. the computer needs more steps to do this conversion.&nbsp; While this does result in some loss of efficiency, which can be bad for projects needing something highly efficient to the millisecond, it makes up for this by being more human-readable, and thus simpler to work with in many regards (which is a necessity for highly complex tasks).</p><h4><span id="LowLevel_Languages"></span>Low-Level Languages<span></span></h4><p>Given the above, as you might imagine, a&nbsp;<strong>low-level language&nbsp;</strong>is the opposite.&nbsp; These languages have a “low” degree of abstraction from machine language, meaning that it takes less time for the computer to convert it to machine language.&nbsp; Certainly, this sacrifices some amount of human readability, but it does result in higher efficiency.</p><h4><span id="ObjectOriented_Programming"></span>Object-Oriented Programming<span></span></h4><p>When someone talks about&nbsp;<strong>object-oriented programming</strong>, they’re talking about programming that is based around the ideas of objects.&nbsp; In this model, developers create various objects to hold their data, including properties, attributes, and methods.&nbsp; For example, you could have an “animal” object that holds a name, age, and various functions it can do (eat, play, sleep, etc.). In this way, the program is easier to understand for humans and, in most cases, makes it easier to work with.</p><p>Further, object-oriented programming also lets programmers:</p><ul><li><strong>Encapsulate</strong> certain pieces of data privately away from other parts of the program.</li><li>Use <strong>inheritance</strong> so certain data can be passed along a hierarchy.</li><li><strong>Abstract</strong> data so only the most relevant data to an object is shown.</li><li>Morph objects with <strong>polymorphism</strong> to change behavior compared to its parent.</li></ul><h3><span id="Python"></span>Python<span></span></h3><p><img src="https://coding.degree/wp-content/uploads/2020/08/06_Blackjack-Counter.jpg" alt="Example of a program that counts BlackJack cards" width="1143" height="651" srcset="https://coding.degree/wp-content/uploads/2020/08/06_Blackjack-Counter.jpg 1143w, https://coding.degree/wp-content/uploads/2020/08/06_Blackjack-Counter-300x171.jpg 300w, https://coding.degree/wp-content/uploads/2020/08/06_Blackjack-Counter-1024x583.jpg 1024w, https://coding.degree/wp-content/uploads/2020/08/06_Blackjack-Counter-768x437.jpg 768w" sizes="(max-width: 1143px) 100vw, 1143px" data-eio="l" data-old-src="https://coding.degree/wp-content/ewww/lazy/placeholder-1143x651.png" data-src="https://coding.degree/wp-content/uploads/2020/08/06_Blackjack-Counter.jpg" data-srcset="https://coding.degree/wp-content/uploads/2020/08/06_Blackjack-Counter.jpg 1143w, https://coding.degree/wp-content/uploads/2020/08/06_Blackjack-Counter-300x171.jpg 300w, https://coding.degree/wp-content/uploads/2020/08/06_Blackjack-Counter-1024x583.jpg 1024w, https://coding.degree/wp-content/uploads/2020/08/06_Blackjack-Counter-768x437.jpg 768w" data-src-webp="https://coding.degree/wp-content/uploads/2020/08/06_Blackjack-Counter.jpg.webp" data-srcset-webp="https://coding.degree/wp-content/uploads/2020/08/06_Blackjack-Counter.jpg.webp 1143w, https://coding.degree/wp-content/uploads/2020/08/06_Blackjack-Counter-300x171.jpg.webp 300w, https://coding.degree/wp-content/uploads/2020/08/06_Blackjack-Counter-1024x583.jpg.webp 1024w, https://coding.degree/wp-content/uploads/2020/08/06_Blackjack-Counter-768x437.jpg.webp 768w"></p><h4><span id="What_is_Python"></span>What is Python<span></span></h4><p><a href="https://www.python.org/">Python</a> is a high-level, interpreted, general-purpose language.&nbsp; Created in 1991 by Guido van Rossum, Python is a language that was designed specifically for human readability.&nbsp; Unlike other programming languages that determine where a set of instructions ends with various punctuation (such semicolons), Python uses lines to determine where each instruction starts and stops.&nbsp; As such, the language emphasizes the use of whitespace and indentation, which furthers its mission of being as readable as possible for human programmers.</p><h4><span id="How_is_Python_Used"></span>How is Python Used<span></span></h4><p>Python is used in many different sectors of the industry.&nbsp; It can be commonly found being used for backend aspects of web development, software development, and even some games.&nbsp; In recent times, however, Python has seen the most use in the areas of data science, computer vision, and machine learning.&nbsp; Due to its simple syntax, it’s been used to break down the complex tasks and data-heavy tasks in these areas into easy-to-understand code.&nbsp; Due to this, it has allowed programmers to create advanced data analytics programs and teach machine tasks in ways that are generally considered quicker than what other languages are capable of.</p><h4><span id="Why_Learn_Python"></span>Why Learn Python<span></span></h4><p>Python has quickly become one of the most popular, high-level languages to use simply due to its ease of use and overall readability.&nbsp; It is extremely capable of breaking down complex tasks that would be more difficult in other languages.&nbsp; This has profound consequences for data science and machine learning projects, which are both topics already very heavy in theory.&nbsp; As such, learning how to code with Python can provide you with an astounding headstart if you’re interested in pursuing either topic.</p><p>In addition, its readability also makes it a good first language for many developers to learn how to code.&nbsp; Since it is specifically designed to be read by humans (and also requires fewer lines to do specific tasks), it makes it a language that is quick to adapt to.&nbsp; However, it is equally versatile, making it suitable for even things such as game projects you might have in mind.</p><p>Given its rise in popularity, it is also equally in high-demand across the technology industry.&nbsp; So, if you’re looking to expand your skills for the professional field, this is a great language.&nbsp; Not only does this open up positions in data science and machine learning, but other niches also have expanded into Python as well, such as cybersecurity.&nbsp; Thus, it makes a great point to have on your resume.</p><p><img src="https://coding.degree/wp-content/uploads/2020/08/01_Frogger-Style-Game.jpg" alt="Frogger Style game made with Python" width="600" height="582" srcset="https://coding.degree/wp-content/uploads/2020/08/01_Frogger-Style-Game.jpg 600w, https://coding.degree/wp-content/uploads/2020/08/01_Frogger-Style-Game-300x291.jpg 300w" sizes="(max-width: 600px) 100vw, 600px" data-eio="l" data-old-src="https://coding.degree/wp-content/ewww/lazy/placeholder-600x582.png" data-src="https://coding.degree/wp-content/uploads/2020/08/01_Frogger-Style-Game.jpg" data-srcset="https://coding.degree/wp-content/uploads/2020/08/01_Frogger-Style-Game.jpg 600w, https://coding.degree/wp-content/uploads/2020/08/01_Frogger-Style-Game-300x291.jpg 300w" data-src-webp="https://coding.degree/wp-content/uploads/2020/08/01_Frogger-Style-Game.jpg.webp" data-srcset-webp="https://coding.degree/wp-content/uploads/2020/08/01_Frogger-Style-Game.jpg.webp 600w, https://coding.degree/wp-content/uploads/2020/08/01_Frogger-Style-Game-300x291.jpg.webp 300w"></p><h4><span id="Job_Prospects_for_Python_Developers"></span>Job Prospects for Python Developers<span></span></h4><p>Python Developers were reported to earn on average <a href="https://www.indeed.com/career/python-developer/salaries">$119,000 per year in the US</a>.&nbsp; However, developers in the US who specialize in data science can earn up to <a href="https://www.indeed.com/career/data-scientist/salaries">$121,680 per year</a> on average, while machine learning engineers were <a href="https://www.indeed.com/career/machine-learning-engineer/salaries">average at $140,200</a>.</p><h4><span id="Resources_to_Learn_Python"></span>Resources to Learn Python<span></span></h4><ul><li><a href="https://youtu.be/Z1Yd7upQsXY">Python Tutorial for Absolute Beginners by CS Dojo</a></li><li><a href="https://academy.zenva.com/product/data-science-mini-degree/?zva_src=codingdegree-bestlanguage">Data Science Mini-Degree by Zenva</a></li><li><a href="https://www.youtube.com/watch?v=RGor6fssp6c">30 Days of Python by CodingEntrepreneurs</a></li><li><a href="https://pythonmachinelearning.pro/bite-size-python-tutorial/">A Bite-Sized Guide to Python by Nimish Narang</a></li><li><a href="https://youtu.be/KOdfpbnWLVo">Python Tutorial Series by Socratica</a></li><li><a href="https://academy.zenva.com/product/deep-learning-mini-degree/?zva_src=codingdegree-bestlanguage">Machine Learning Mini-Degree by Zenva</a></li><li><a href="https://pythonmachinelearning.pro/overview-of-machine-learning/">Overview of Machine Learning by Mohit Deshpande</a></li><li><a href="https://pythonmachinelearning.pro/">Python Machine Learning</a></li></ul><h3><span id="JavaScript"></span>JavaScript<span></span></h3><p><img src="https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full.jpg" alt="RPG made with Phaser" width="1679" height="941" srcset="https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full.jpg 1679w, https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full-300x168.jpg 300w, https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full-1024x574.jpg 1024w, https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full-768x430.jpg 768w, https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full-1536x861.jpg 1536w" sizes="(max-width: 1679px) 100vw, 1679px" data-eio="l" data-old-src="https://coding.degree/wp-content/ewww/lazy/placeholder-1679x941.png" data-src="https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full.jpg" data-srcset="https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full.jpg 1679w, https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full-300x168.jpg 300w, https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full-1024x574.jpg 1024w, https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full-768x430.jpg 768w, https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full-1536x861.jpg 1536w" data-src-webp="https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full.jpg.webp" data-srcset-webp="https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full.jpg.webp 1679w, https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full-300x168.jpg.webp 300w, https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full-1024x574.jpg.webp 1024w, https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full-768x430.jpg.webp 768w, https://coding.degree/wp-content/uploads/2020/08/FullRPGWorld_Full-1536x861.jpg.webp 1536w"></p><h4><span id="What_is_JavaScript"></span>What is JavaScript<span></span></h4><p>First appearing in 1995, <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript">JavaScript</a> is a high-level, just-in-time compiled language that was created by Brendan Eich and other contributors to conform to the ECMAScript specification – a standardization so multiple web browsers could interpret code the same.&nbsp; Due to this origin, JavaScript forms one of the core pillars of web development, providing the integral scripts that inform most user interaction on the internet.&nbsp; The language features both object-oriented programming structures, as well as event-driven, functional, and other programming styles.&nbsp; Additionally, JavaScript is used as the basis for many modern frameworks.</p><h4><span id="How_is_JavaScript_Used"></span>How is JavaScript Used<span></span></h4><p>JavaScript sees the most use in the area of web development.&nbsp; On the frontend, JavaScript provides many functions that bring webpages to life, whether through animations or user interaction such as buttons, forms, and so forth.&nbsp; JavaScript also sees plenty of use in website backends through frameworks such as Node.js, where it can be used to send and receive data through requests to create complex webapps.&nbsp; Recently, JavaScript has also provided the backbone for HTML5 games due to its event-driven nature of user interaction, resulting in a resurgence of browser-based games.</p><h4><span id="Why_Learn_JavaScript"></span>Why Learn JavaScript<span></span></h4><p>As a core pillar of web development, you really can’t go wrong with JavaScript.&nbsp; Whether you want to develop backends with Express and Node.js, use frontend frameworks like React and Vue, or create your own custom scripts, JavaScript is absolutely necessary to know when learning how to code.&nbsp; So much of the web is based around the language, you will always find new web projects that will require knowledge of it.&nbsp; Thus, knowing it provides you one of the most fantastic foundations to have for any sort of web programming.</p><p>However, as mentioned, if you’re looking to develop games, especially browser-based games, JavaScript has a big role there as well.&nbsp; It allows you to animate, provide the necessary user interactions to function, and beyond.&nbsp; Further, unlike other languages that require hefty computers to create games, JavaScript requires very little of your machine, meaning you can develop games on your laptop if you so desire!</p><p>In terms of professional work, learning to code JavaScript can open up web development paths to you, including the all-inclusive Full-Stack development path.&nbsp; As the language is extremely stable and ingrained, you can expect quite a bit of security that it won’t be dethroned anytime soon, meaning there’ll be lots of opportunities available for a long time.</p><p><img src="https://coding.degree/wp-content/uploads/2020/08/Javascript-Game_Small.jpg" alt="Road crossing game made with JavaScript" width="1185" height="591" srcset="https://coding.degree/wp-content/uploads/2020/08/Javascript-Game_Small.jpg 1185w, https://coding.degree/wp-content/uploads/2020/08/Javascript-Game_Small-300x150.jpg 300w, https://coding.degree/wp-content/uploads/2020/08/Javascript-Game_Small-1024x511.jpg 1024w, https://coding.degree/wp-content/uploads/2020/08/Javascript-Game_Small-768x383.jpg 768w" sizes="(max-width: 1185px) 100vw, 1185px" data-eio="l" data-old-src="https://coding.degree/wp-content/ewww/lazy/placeholder-1185x591.png" data-src="https://coding.degree/wp-content/uploads/2020/08/Javascript-Game_Small.jpg" data-srcset="https://coding.degree/wp-content/uploads/2020/08/Javascript-Game_Small.jpg 1185w, https://coding.degree/wp-content/uploads/2020/08/Javascript-Game_Small-300x150.jpg 300w, https://coding.degree/wp-content/uploads/2020/08/Javascript-Game_Small-1024x511.jpg 1024w, https://coding.degree/wp-content/uploads/2020/08/Javascript-Game_Small-768x383.jpg 768w" data-src-webp="https://coding.degree/wp-content/uploads/2020/08/Javascript-Game_Small.jpg.webp" data-srcset-webp="https://coding.degree/wp-content/uploads/2020/08/Javascript-Game_Small.jpg.webp 1185w, https://coding.degree/wp-content/uploads/2020/08/Javascript-Game_Small-300x150.jpg.webp 300w, https://coding.degree/wp-content/uploads/2020/08/Javascript-Game_Small-1024x511.jpg.webp 1024w, https://coding.degree/wp-content/uploads/2020/08/Javascript-Game_Small-768x383.jpg.webp 768w"></p><h4><span id="Job_Prospects_for_JavaScript_Developers"></span>Job Prospects for JavaScript Developers<span></span></h4><p>On average, web developers in the US can earn around <a href="https://www.indeed.com/career/web-developer/salaries">$78,070 per year</a>.&nbsp; For those who specialize in JavaScript and become general JavaScript developers, though, salaries rise to about <a href="https://www.indeed.com/career/javascript-developer/salaries">$118,150 per year in the US</a>.</p><h4><span id="Resources_to_Learn_JavaScript"></span>Resources to Learn JavaScript<span></span></h4><ul><li><a href="https://html5hive.org/how-to-chain-javascript-promises/">How to Chain JavaScript Promises – Intro Tutorial to JavaScript Promises by Pablo Farias Navarro</a></li><li><a href="https://www.youtube.com/watch?v=9M4XKi25I2M">JavaScript Programming All-in-One Tutorial …</a></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://coding.degree/best-coding-languages/">https://coding.degree/best-coding-languages/</a></em></p>]]>
            </description>
            <link>https://coding.degree/best-coding-languages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24131217</guid>
            <pubDate>Wed, 12 Aug 2020 12:11:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Risk BowTie Method]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24130809">thread link</a>) | @unixhero
<br/>
August 12, 2020 | https://www.juliantalbot.com/post/risk-bow-tie-method | <a href="https://web.archive.org/web/*/https://www.juliantalbot.com/post/risk-bow-tie-method">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.12.3"><div dir="ltr"><div><p id="viewer-etkqn">BowTie is one of my favorite risk management tools. It supports a complex analysis but is so simple that can even a five-year-old can understand it. It is also&nbsp;visual which makes it a great communication tool. </p><p id="viewer-en7co">BowTie analysis draws its name from its shape reminiscent of a traditional necktie.&nbsp;The precise origin of this method is unclear, but it seems to have evolved from cause and consequence diagrams in the 1970s. A major limitation of ‘cause-event-consequence’ diagrams is that they don’t show the full complexity of a scenario.&nbsp;&nbsp;</p><p id="viewer-am9gl">The first formal use of BowTie as a documented method appeared in the 1990s when Shell Group adopted the method&nbsp;to show causal links between sources of risk and consequences.&nbsp;The&nbsp;oil &amp; gas industry and many other industries have since adopted it.</p><div id="viewer-6i9l"><div><div data-hook="imageViewer"><div role="img" aria-label="Risk Bow-Tie Model"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_f603e2c48c044f74a797e7142ac9a5a8~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_1920,h_1440,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_f603e2c48c044f74a797e7142ac9a5a8~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Risk Bow-Tie Model"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-1vghs">Figure 1: Risk BowTie</p><p id="viewer-5e1fl">You can consider multiple Events if the causal links from risk&nbsp;Sources to the Event(s) to Consequences are credible but usually t<!-- -->he focal point for BowTie analysis is a single risk&nbsp;Event. <!-- -->At the center of the BowTie diagram is the risk Event. In this example, a fire. To the left is what might cause the Event to occur (e.g., lightning, arson, an electrical fault). On the right-hand side are the potential outcomes (e.g., death, building damage, financial loss).&nbsp;</p><p id="viewer-45gvr">The left and right sides are larger than the center because there are many Sources that might lead to a single risk Event. That single Event, can in turn&nbsp;lead to many Consequences.&nbsp;</p><div id="viewer-c0r1b"><div><div data-hook="imageViewer"><div role="img" aria-label="Risk Causation"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_a229d7140fc84766b60b69d1819e0e48~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_1920,h_1440,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_a229d7140fc84766b60b69d1819e0e48~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Risk Causation"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-f8sgr">Figure 2: Risk Causation</p><p id="viewer-bpm38">In reality, most sources of risk can create many events. Even a single event can cause many consequences.&nbsp;</p><div id="viewer-50irm"><div><div data-hook="imageViewer"><div role="img" aria-label="Risk Causation Example"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_e17691eaaae8431783c7e5a171e820de~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_1920,h_1440,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_e17691eaaae8431783c7e5a171e820de~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Risk Causation Example"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-acufh">Figure 3: Risk Causation Example</p><p id="viewer-83edk">Choosing an ‘Event’ at the center of the BowTie provides a focus for analysis.&nbsp;</p><h3 id="viewer-5b8cq"><strong>Structure and Application</strong></h3><p id="viewer-4ugdj">BowTie expresses likelihood and consequence management via the left and right-hand sides of the Event using similar concepts to the <a href="https://www.juliantalbot.com/post/swiss-cheese-theory" target="_blank" rel="noopener">Swiss Cheese Model</a> and Escalation Factors.&nbsp;</p><div id="viewer-457ms"><div><div data-hook="imageViewer"><div role="img" aria-label="Risk Controls in Bow-Tie"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_673a644d0d6448de895f8c8008b14e66~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_1920,h_1440,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_673a644d0d6448de895f8c8008b14e66~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Risk Controls in Bow-Tie"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-4op7v">Figure 4: Risk Controls</p><p id="viewer-9cojm">BowTie diagrams depict the relationship between Sources of risk, Controls, Escalation Factors,&nbsp;Events, and&nbsp;Consequences. Some&nbsp;benefits include:&nbsp;</p><ul><li id="viewer-8kv0l"><p>full range of initiating causes can be shown<!-- -->  </p></li><li id="viewer-8vpc1"><p>existing controls (intervening safeguards/barriers) are depicted<!-- -->  </p></li><li id="viewer-2b4sc"><p>causal pathway in which these combine and escalate can be shown<!-- -->  </p></li><li id="viewer-4fi37"><p>consequence management (right) side shows post-event controls<!-- -->  </p></li><li id="viewer-erdni"><p>multiple possible consequence outcomes can be depicted<!-- -->  </p></li><li id="viewer-2liq2"><p>causal pathway effects of controls are made explicit<!-- --> </p></li></ul><p id="viewer-cgo4p">In the BowTie, Controls change the likelihood or consequence of a risk but Escalation Factors are conditions that can vary the effectiveness of likelihood or consequence Controls. &nbsp;Escalation Factors might include fatigue, competency, the environment, foreign exchange, drug use, human error, etc.</p><p id="viewer-71l1c">On an oil rig for example, Controls such as fire detection and suppression systems might be more likely to fail due to the corrosive salt water environment. In this instance, Controls such as regular inspections, testing, and preventative maintenance programs might mitigate that Escalation Factor.</p><p id="viewer-8stll">It’s important to remember that, as illustrated below, not all controls will be effective at managing all sources of risk, nor mitigating all consequences.&nbsp;</p><div id="viewer-e627"><div><div data-hook="imageViewer"><div role="img" aria-label="Risk Control Relationships in Bow-Tie Model"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_9d782f9532d64fe8be018a45bdde1132~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_1920,h_1440,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_9d782f9532d64fe8be018a45bdde1132~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Risk Control Relationships in Bow-Tie Model"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-d5g9l">Figure 5: Control Relationships</p><div id="viewer-2tdma"><div><div data-hook="imageViewer"><div role="img" aria-label=""><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_4e3a1982344943feb07ecb39468473b5~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_1920,h_1440,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_4e3a1982344943feb07ecb39468473b5~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt=""></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-2plc5">Figure 6: BowTie Structure Example</p><ul><li id="viewer-201c3"><p>Sources of risk. Threats, hazards, exposures, vulnerabilities, opportunities, or circumstances which cause a risk event.</p></li><li id="viewer-9ehkp"><p>Likelihood controls. Measures to reduce the likelihood of negative risk events or increase the likelihood of positive events.</p></li><li id="viewer-b75v1"><p>Likelihood escalation factors. Elements that might change the effectiveness of likelihood controls.</p></li><li id="viewer-3kblh"><p>Likelihood escalation controls. Resources, risk treatments, mitigations, or barriers that affect or manage escalation factors.</p></li><li id="viewer-4qh0q"><p>Event(s). Incident(s) or risk event(s) which may occur as a result of the sources of risk and could impact on objectives.</p></li><li id="viewer-5u1br"><p>Consequence controls. Measures to support or change the consequences of the risk event(s).</p></li><li id="viewer-9eeo6"><p>Consequence escalation factors. Elements that through cascading or cumulative effects could lead to changes in the effect of consequence controls.</p></li><li id="viewer-4j642"><p>Consequence escalation controls. Resources, risk treatments, mitigations, or barriers that modify the effect of escalation factors.</p></li><li id="viewer-fkssq"><p>Consequences. Outcome(s) of a risk event that could affect objectives.&nbsp;<!-- --> </p></li></ul><div id="viewer-ejheo"><div><div data-hook="imageViewer"><div role="img" aria-label="Risk Bow-Tie Factory Fire Example Diagram in Pretty Colors by Julian Talbot"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_1c83725259d14013af6e66a133f31741~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_1920,h_1440,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_1c83725259d14013af6e66a133f31741~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Risk Bow-Tie Factory Fire Example Diagram in Pretty Colors by Julian Talbot"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-1h4il">Figure 7: Factory Fire Example</p><h3 id="viewer-8u3tc"><strong>Advantages of BowTies</strong></h3><p id="viewer-es22p">Bow-ties are not a universal panacea but they have practical benefits including many we find which in only a few methodologies:&nbsp; <!-- --> </p><ul><li id="viewer-ceq5g"><p>Repeatable. A robust and consistent method for documenting existing controls and linking them to the risks that&nbsp;they are treating.&nbsp;&nbsp;</p></li><li id="viewer-cf1v0"><p>Integrated. A framework where risks and management procedures can be linked and compared.&nbsp;&nbsp;&nbsp;</p></li><li id="viewer-739ut"><p>Causal. Highlighting causal links between risks, controls, sources, events, and potential consequences.&nbsp;&nbsp;</p></li><li id="viewer-ar2eo"><p>Systems and gap analysis. Facilitates identification of deficiencies or missing risk controls.&nbsp;&nbsp;</p></li><li id="viewer-cqu3t"><p>Visual. Risks are easily communicated and understood at all levels of an organization.&nbsp;&nbsp;</p></li><li id="viewer-ahiob"><p>Complementary. Aligns with and complements other methodologies such as Likelihood and Consequence Management, P2R2, Swiss Cheese, and Root Cause Analysis.&nbsp;&nbsp;</p></li><li id="viewer-62sjb"><p>Aligned with better practice methodologies to support management decision-making and evaluation of risks.&nbsp;&nbsp;</p></li><li id="viewer-3d177"><p>Adequacy of Existing Controls. Existing Controls are identified, listed, linked to specific threats, and can be assessed by their effectiveness.&nbsp;&nbsp;</p></li><li id="viewer-alp11"><p>Scenario-modeling. Typical scenarios and relationships can be&nbsp;&nbsp;and depicted on the pre-event side (left side) of the BowTie diagram.</p></li><li id="viewer-2cfas"><p>Vulnerabilities. BowTie can highlight areas where controls are poor.</p></li><li id="viewer-a6kvo"><p>Audit. BowTie diagrams can show auditors and managers the conceptual application of management systems.&nbsp;&nbsp;</p></li><li id="viewer-cj1oe"><p>Defining. Define the meaning and relative roles of key terms.<!-- --> </p></li></ul><div id="viewer-aa8cv"><div><div data-hook="imageViewer"><div role="img" aria-label="Example of using a Bow-Tie diagram to define risk management terms (in pretty colors of course :-)"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_cc05f35001b34a0f848c1b5bb11c1d1b~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_1920,h_1440,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_cc05f35001b34a0f848c1b5bb11c1d1b~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Example of using a Bow-Tie diagram to define risk management terms (in pretty colors of course :-)"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-fiua9">Figure 8: Example of Using Bow-Tie to Define Terms</p><p id="viewer-c2vqa">It is important to understand there isn’t a single correct way and BowTies can be adapted for each specific context and organization. &nbsp;</p><div id="viewer-amild"><div><div data-hook="imageViewer"><div role="img" aria-label="Another example of using Bow-Tie diagrams to define and show relationship of risk management terms"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_8a4e83a5df5544d98763148489b6d5ed~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_1920,h_1440,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_8a4e83a5df5544d98763148489b6d5ed~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Another example of using Bow-Tie diagrams to define and show relationship of risk management terms"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-cif4c">Figure 9: Second Example of Defined Terms Illustrated by Bow-Tie</p><h3 id="viewer-fae5q"><strong>Positive Risks</strong></h3><p id="viewer-27k2g">BowTie&nbsp;can also illustrate the Sources, Controls and risk Events that could turn an opportunity into a benefit. When managing a project or implementing a plan for example, starting a business, or choosing to start a project, the intention is to increase the positive consequences.</p><p id="viewer-ak9pv">The following example illustrates a funds management product.</p><div id="viewer-4713e"><div><div data-hook="imageViewer"><div role="img" aria-label="Positive Risk Bow-Tie Example using Financial Services Product Development"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_b444024e8ea54af0a214fb83a1701fac~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_1920,h_1440,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_b444024e8ea54af0a214fb83a1701fac~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Positive Risk Bow-Tie Example using Financial Services Product Development"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-3l3br">Figure 10: Financial Product Example</p><p id="viewer-665gf">Although unusual, positive and negative consequences can be plotted in a single BowTie to illustrate Sources (Threats and Opportunities) and Consequences (Benefits and Losses) of a single event as illustrated.</p><div id="viewer-cb1i"><div><div data-hook="imageViewer"><div role="img" aria-label="Aligning postitive and negative risks on a risk Bow-Tie model"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_f794922d1a6d46c590efd2235ffd35dc~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_1920,h_1440,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_f794922d1a6d46c590efd2235ffd35dc~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Aligning postitive and negative risks on a risk Bow-Tie model"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-f46pu">Figure 11: Threats and Opportunities</p><p id="viewer-3ds3r">Even terrible events such as car accidents can generate both positive outcomes. Accidents are good for repair businesses, new car salespeople, and demand for enhanced safety features.</p><div id="viewer-2o7if"><div><div data-hook="imageViewer"><div role="img" aria-label="Positive and negative risks associate with car accidents using Bow-Tie model"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_46afa1c1bddb4a4f9042a075192534d9~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_1920,h_1440,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_46afa1c1bddb4a4f9042a075192534d9~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Positive and negative risks associate with car accidents using Bow-Tie model"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-2se7p">Figure 12: Car Crash Example</p><h3 id="viewer-6d3p9"><strong>Bow-Tie Tables</strong></h3><p id="viewer-6up6n">Although useful as a visual metaphor or illustration of risk controls, we magnify the power of the BowTie method when used in a table.&nbsp;This level of analysis is only worth the effort&nbsp;for&nbsp;major projects or enterprise risk assessments.&nbsp;</p><p id="viewer-bksvi">In a table, the BowTie model moves the left to right ’Source to Consequence’ elements to a top-to-bottom format. Each part in the BowTie can then be linked to specific controls. This is best done by creating a separate list of controls because many controls relate to more than one escalation factor or barrier.</p><div id="viewer-1jcto"><div><div data-hook="imageViewer"><div role="img" aria-label="Showing relationship of Bow-Tie diagram to Bow-Tie table"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_e963148dbcb24242a5d803fa30e72451~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_1920,h_1440,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_e963148dbcb24242a5d803fa30e72451~mv2_d_1920_1440_s_2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Showing relationship of Bow-Tie diagram to Bow-Tie table"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-enhnd">Figure 13: BowTie Diagram to Table</p><p id="viewer-4nfs3">The following example highlights one approach in which a BowTie table might produce a comprehensive evaluation of a risk event.</p><p id="viewer-fd5lo">Table 1: Example of a BowTie Table Structure</p><div id="viewer-du1mb"><div><div data-hook="imageViewer"><div role="img" aria-label="Example of a Bow-Tie Table Format"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_c051c9d2955e4e26b5f3ea1dd8dc87bc~mv2.jpeg/v1/fit/w_1043,h_771,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_c051c9d2955e4e26b5f3ea1dd8dc87bc~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Example of a Bow-Tie Table Format"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-ah6ej">Table 2: Example of Structure of Blank BowTie Table</p><div id="viewer-conp5"><div><div data-hook="imageViewer"><div role="img" aria-label="Bow-Tie Table Structure"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_03981f189e924e68be1bae61311f488a~mv2.jpeg/v1/fit/w_1043,h_523,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_03981f189e924e68be1bae61311f488a~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Bow-Tie Table Structure"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-1c92a">Table 3: Example of Structure of Blank BowTie Controls Table</p><div id="viewer-8m9v8"><div><div data-hook="imageViewer"><div role="img" aria-label="Example of a Controls Register Table"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_23573723b6ff4c83b2d33a663ba2bb0d~mv2.jpeg/v1/fit/w_915,h_336,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_23573723b6ff4c83b2d33a663ba2bb0d~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Example of a Controls Register Table"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-1trq1"><strong>BowTie Controls Example</strong></p><p id="viewer-ff7s">The Controls shown in the table below are examples only and are cross-referenced in the Bow Tie Assessment Table.</p><p id="viewer-dii46">Notes:<!-- --> </p><ol><li id="viewer-f1j71"><p>It may be appropriate to document organizational Controls before establishing the BowTie table and again when the BowTie table is complete.&nbsp;&nbsp;&nbsp;</p></li><li id="viewer-1nb56"><p>The inability to list an existing control that is proposed in the BowTie table highlights a gap in Control systems.&nbsp;&nbsp;&nbsp;</p></li><li id="viewer-a33l8"><p>Not all Controls have a reference number.&nbsp;&nbsp;&nbsp;</p></li><li id="viewer-dqh85"><p>Not all Controls are documented because some are cultural, social, or physical.</p></li><li id="viewer-5p99v"><p>Controls that have a physical form (e.g., handrails) should have a specific documented reference such as a policy, procedure, or engineering specification.&nbsp;&nbsp;</p></li><li id="viewer-5jl8t"><p>Controls should have enough detail to be auditable, or some form of evidence produced.&nbsp;&nbsp;&nbsp;</p></li><li id="viewer-argla"><p>If a Control exists but isn’t documented, you may need to create a controlled record such as a photograph, sworn statement, archived computer log, or cultural survey.<!-- --> </p></li></ol><p id="viewer-4neki">Table 4: Example of BowTie Controls Table</p><div id="viewer-1330b"><div><div data-hook="imageViewer"><div role="img" aria-label="Example of Truncated Bow-Tie Controls Table with Data"><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_3ab8faee04b9494684fd60f7686458d7~mv2.jpeg/v1/fit/w_792,h_958,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_3ab8faee04b9494684fd60f7686458d7~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt="Example of Truncated Bow-Tie Controls Table with Data"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-82dqh"><strong>BowTie Table Example</strong></p><p id="viewer-7ag26">This table is an example of how a complex analysis can be conducted for security-related events.</p><p id="viewer-b5vt6">The BowTie in the example below relates to a security risk analysis but the same approach will work well for safety, environment, financial, project, enterprise risk management or any risk analysis.</p><p id="viewer-19ssf">Note: Reference numbers refer to controls from the above BowTie Table. Superscript text &lt;Ref # xxx&gt; refers to the control numbers listed in a separate Controls table.</p><p id="viewer-4l4r0">Table 5: Example of Complex BowTie Table</p><div id="viewer-4dj5a"><div><div data-hook="imageViewer"><div role="img" aria-label=""><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_d1b3ae0268cc4578a87b865c45b1a547~mv2.jpeg/v1/fit/w_995,h_1904,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_d1b3ae0268cc4578a87b865c45b1a547~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt=""></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><div id="viewer-fv40e"><div><div data-hook="imageViewer"><div role="img" aria-label=""><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_188f7bd30dd24e75aecc02a217506c8b~mv2.jpeg/v1/fit/w_996,h_1804,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_188f7bd30dd24e75aecc02a217506c8b~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt=""></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><div id="viewer-5d018"><div><div data-hook="imageViewer"><div role="img" aria-label=""><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_11c92388fd514d1f8955ad733b50e945~mv2.jpeg/v1/fit/w_994,h_1848,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_11c92388fd514d1f8955ad733b50e945~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt=""></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><div id="viewer-tstd"><div><div data-hook="imageViewer"><div role="img" aria-label=""><p><img data-pin-url="https://www.juliantalbot.com/post/risk-bow-tie-method" data-pin-media="https://static.wixstatic.com/media/2554f5_c45904f064514a1c823d8ba2ada436e0~mv2.jpeg/v1/fit/w_996,h_1428,al_c,q_80/file.png" src="https://static.wixstatic.com/media/2554f5_c45904f064514a1c823d8ba2ada436e0~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg" alt=""></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><h3 id="viewer-fcnmu"><strong>How to Use BowTie Technique</strong></h3><p id="viewer-9qps6">Bow-Tie method can be used in a number of different ways including as the focus of a facilitated group workshop or for risk analysis. One of the best uses is to analyze, report, and communicate potential risks, actual incidents and&nbsp;near-misses.</p><p id="viewer-1itmj">In another article, I will talk about how it can be expanded for Root&nbsp;Cause Analysis (RCA).</p><p id="viewer-d8fqp">This article is an excerpt from the a book a few of us are working on. If you would like to know more about <a href="https://www.juliantalbot.com/books" target="_top" rel="noopener"><u>the guide to the risk management body of knowledge</u></a> or contribute to it, please subscribe to my occasional newsletters. I promise not to email too frequently.&nbsp;</p><p id="viewer-e75vh">The plan is to publish the guide as an ebook and hard copy in early 2020. To make it widely …</p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.juliantalbot.com/post/risk-bow-tie-method">https://www.juliantalbot.com/post/risk-bow-tie-method</a></em></p>]]>
            </description>
            <link>https://www.juliantalbot.com/post/risk-bow-tie-method</link>
            <guid isPermaLink="false">hacker-news-small-sites-24130809</guid>
            <pubDate>Wed, 12 Aug 2020 11:18:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Consistent Caliber Teams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24130695">thread link</a>) | @chesterarthur
<br/>
August 12, 2020 | https://staysaasy.com/management/2020/08/11/Team-Topology.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/08/11/Team-Topology.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Make the seniority, talent, and quality-of-mission of your organization’s teams as consistent as possible. The pretstige of team missions and their capability should all be comparable. There should be no dramatic differences between the caliber of your teams.</p>

<h2 id="the-problem">The Problem</h2>

<p>It’s not uncommon for a leader to bucket what needs to get done as a set of hard, medium, and easy missions. The next step they’ll take is to assemble teams of respectively different talent levels and seniority to handle those challenges of different prestige levels. The outcome are teams that vary in their ability and the importance (real or perceived) of their mission. You’ve just turned your department into a caste system.</p>

<p>This creates lots of challenges:</p>
<ul>
  <li>People who are on low-caliber teams know it. This causes morale and retention issues.</li>
  <li>In some cases, people end up selling the company to recruits based off of what the prestigious teams are doing, only to place people into other teams. This causes morale and retention issues.</li>
  <li>The weak-mission teams will often not have a growth path to the highest levels. This essentially means it’s a transient team unless you hire people to stagnate. A great litmus test is: can every team support promotions to the highest level?</li>
  <li>You end up constantly having to field questions around internal transfers to the prestigious teams. Good managers tell the truth when people aren’t ready for the other team or when the team isn’t ready for them. Bad managers give little glimmers of hope that don’t reflect reality and lead to a long tail of frustration.</li>
  <li>Dysfunctional organizations will actually lower the hiring and promotion bars for lower caliber teams for political and morale reasons. This can lead to very, very bad outcomes like reducing the integrity of compensation bands or causing internal strife at the mis-match across teams.</li>
  <li>This set of variables is also very dangerous because internal processes of an organization are based on the people they’re serving. Different cohorts of people need different enablement, onboarding, rules, and rewards. Having major differences amongst teams means it’s harder to have one overarching culture and set of organizational mechanics.</li>
</ul>

<p>How do you fix this? Let’s go back and revisit some assumptions.</p>

<h2 id="assumption-1-we-have-hard-medium-and-easy-missions">Assumption 1: We Have Hard, Medium and Easy Missions</h2>

<p>People get this wrong all the time. When looking at the missions of a team, it’s not uncommon for a leader to have standard biases or an ego that leads to total miscalculations of the difficulty of certain missions.</p>

<p>An example is in software engineering, where leaders might view their team’s goals as fancy backend “hard stuff’’ and simple front-end “easy stuff”. That’s obviously bullshit. Think of all of the terrible UIs you encounter on a day to day basis. If frontend engineering was easy UI would be a solved problem.</p>

<p>Another example is when a leader or a team aren’t executing well on a part of their responsibilities and they end up saying that it just needs to be handled by some other team because it’s easy but distracting. In reality, if it’s easy they’d be doing a good job at it. This kind of thinking can lead teams to push away what is actually more important work in lieu of more interesting (or greenfield, or easy) work.</p>

<p>People often make bad calls on what’s difficult and what’s easy and then make things worse with the second, equally damaging assumption.</p>

<h2 id="assumption-2-easy-missions-should-be-done-by-lower-caliber-teams">Assumption 2: Easy Missions Should Be Done By Lower-Caliber Teams</h2>

<p>Leaders will then compound the problem by staffing teams to get the “easy missions” done with less senior or skillful talent. So they assume a problem is easy, understaff it, and then as things inevitably go wrong they end up blaming either the team, the mission, or anything else but the poor decisions that lead to a self-fulfilling prophecy.</p>

<h2 id="a-better-path">A Better Path</h2>

<p>To solve this problem, take a hard look at the topology of work you’re trying to get done:</p>
<ul>
  <li>If a <em>small</em> volume of work is much simpler than other tasks, you should add it into the responsibilities of your existing teams.</li>
  <li>If a <em>large</em> volume work is much simpler than other work- meaning it’d meaningfully distract your regular teams - you should either contract it out or you build an different organization to handle it.</li>
  <li>Sometimes you’ll have a team who has lower perceived prestigue because it doesn’t contain as many buzzwords or trendy technologies as other teams. Absent active efforts, that team will have a harder time hiring and retaining. To counteract this, you should make sure you’re overloading that team with talent, so that you make up for the team’s perceived mission prestigue with personel prestige.</li>
  <li>In all cases, expectation setting and integrity in decision making is critical. Don’t hire people into roles with the false hope of transferring to other teams if it’s not possible. Don’t transfer people to other teams if they’re not ready.</li>
</ul>

<h2 id="examples">Examples</h2>
<ul>
  <li>Your hot-stuff AI/ML startup has 4 high-powered product teams, but you keep having this pesky problem of a trickle of internal requests from the client-facing teams. You decide to create a team to just handle those requests. You figure it’s not that big of a problem and don’t want to distract your teams, so you hire a junior team to just handle that. You’ve just made a huge mistake. That team will be unhappy and have retention problems forever. You should have either contracted that work or found a process for your other teams to get it done.</li>
  <li>Your hot-stuff AI/ML startup has built out a customer portal that is getting a ton of traction. The work has meaningful challenges and growth opportunities, but it’s very different than your core team’s responsibilities. The people you hire, the promotion paths, the culture needed to execute well, and the evaluation criteria are existentially inconsistent with your other teams. You work with senior management to build out an entirely new organization to work on the portal. Great job, you’ve done the right thing. This was a lot of work that warranted a focused division to manage the mission.</li>
</ul>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/08/11/Team-Topology.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24130695</guid>
            <pubDate>Wed, 12 Aug 2020 11:04:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why YAML is used for configuration when it's so bad, what can you do about it?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24130532">thread link</a>) | @hbogert
<br/>
August 12, 2020 | https://kula.blog/posts/yaml/ | <a href="https://web.archive.org/web/*/https://kula.blog/posts/yaml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            


<p>I've been programming long enough that I still remember programming in XML. It was everywhere.</p>
<h2 id="xml">XML <a href="#xml">#</a></h2>
<p>XML was the default when sending data between the client and the server. AJAX stands for "Asynchronous JavaScript and XML" for a reason. It was everywhere really. PHP projects, all kinds of Java projects. It was mostly fine when passing data, but people started to use it for configuration and from there to write logic.<br>
For example Spring at the time used it for dependency injection. Hibernate used XML for the specification of the Object Relational Mapping between the database and Java objects. I've seen a bunch of internal projects using all kinds of logic. <code>if</code>, <code>loop</code> in a long complicated file with thousands of lines.<br>
To some extent, you were able to deal with it when the company had an appropriate XML Schema. Your IDE could help you a bit. People abused XML so much that I heard complaints about XML all the time. I was complaining about XML as well. Let's be honest, working on the XML file so big that sometimes crashes your IDE isn't fun. I still remember a couple of senior engineers pointing out JSON faults and the benefits of XML and neither I nor anyone else listened to them. It was the beginning of the JSON era.</p>
<h2 id="json">JSON <a href="#json">#</a></h2>
<p>JSON is pretty good for what it was made for—it's a lightweight (compared to XML) format for exchanging data between the server and JavaScript client in the browser.<br>
One good thing about JSON is that it's pretty bad for configuration files. Yes, people tried it, but fortunately, it gets bad so quickly that I haven't seen anything too bad. Maybe beside <a href="https://webpack.js.org/configuration/">Webpack configuration</a>. Fortunately, it's not that common to see a big JSON configuration file. The biggest reason for that is the lack of comments in JSON format. It's a restriction that prevents people from abusing it too much.</p>
<p>But, if someone is already abusing JSON and has a hard time dealing with it they try to fix the problem with code. Some started working on JSON Schema others on new JSON format witch comments e. g.: HJSON.</p>
<p>It was obvious that JSON is not enough and we need something else for configuration.</p>
<h2 id="yaml">YAML <a href="#yaml">#</a></h2>
<p>Various popular projects use it for configuration:</p>
<ul>
<li>Travis CI</li>
<li>CircleCI</li>
<li>AWS CloudFormation</li>
<li>Ansible</li>
</ul>
<p>Now imagine you look at hundreds of lines of YAML trying to figure out what is wrong. If it's really a declarative configuration then while it's hard to read you don't have to worry that much. Just find the line setting that you need to change. The problem is when it's not a declarative configuration file, but a programming language pretending to be YAML. I start to think of something is a programming language when it gets <code>if</code> statements (conditionals). For example:</p>
<ul>
<li><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html">Conditionals in Ansible</a></li>
<li><a href="https://docs.travis-ci.com/user/customizing-the-build/#conditionally-allowing-jobs-to-fail">Conditionally Allowing Jobs to Fail in Travis CI</a></li>
<li><a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/process/templates?view=azure-devops#conditional-insertion">Conditional insertion in Azure Pipelines</a></li>
<li><a href="https://circleci.com/docs/2.0/configuration-reference/#filters-1">Filters in CircleCI</a></li>
</ul>
<p>It's worse than your favorite programming language as well. Your IDE can't help you. Errors are cryptic. Most of the time you won't get an error at all because you didn't get the indentation just right and it's valid YAML that happens to be invalid configuration. It's a mess.</p>
<p>It's even worse than what XML had years ago. At least at a time, most IDEs were expected to help you with XML Schema. Something similar is showing up for YAML. See <a href="https://www.redhat.com/sysadmin/yaml-tips">10 YAML tips for people who hate YAML</a> for advice on editor setup, linting, and more.</p>
<p>Another problem I want to mention again is readability. If you ever try to read a longer (hundred or more lines) YAML file you will realize that it's pretty hard to scan and make sense of its structure. Unlike Python that uses significant whitespace, you can't do any meaningful structured programming practices like extracting code into smaller functions. Everything is one blob of text.</p>
<h2 id="no-silver-bullet">No silver bullet <a href="#no-silver-bullet">#</a></h2>
<p>One most important thing I want to stress is that I don't believe we can solve the problem by introducing another format. XML, JSON, and YAML are fine as long as the file itself is small and doesn't contain logic. So what do you do when you need to add logic? Use a proper programming language! Please stop treating logic in configuration files as a lesser code. If it's wrong then it's a serious problem. At least you will be able to write tests for your configuration. Have you ever tried doing that for your YAML file? I don't think so.</p>
<hr>
<p>Notes (More reading):</p>
<ul>
<li><a href="https://blog.cloud-elements.com/json-better-xml">Why JSON Is Better Than XML</a></li>
<li><a href="https://www.lucidchart.com/techblog/2018/07/16/why-json-isnt-a-good-configuration-language/">Why JSON isn’t a Good Configuration Language</a></li>
<li><a href="https://www.arp242.net/json-config.html">The downsides of JSON for config files</a></li>
<li><a href="https://www.arp242.net/yaml-config.html">YAML: probably not so great after all</a></li>
<li><a href="https://www.redhat.com/sysadmin/yaml-tips">10 YAML tips for people who hate YAML</a></li>
<li><a href="https://dev.to/jessekphillips/stop-using-yaml-3kec">Stop Using YAML</a></li>
</ul>


<!-- Sharingbutton Facebook -->
<a href="https://facebook.com/sharer/sharer.php?u=https%3A%2F%2Fkula.blog%2Fposts%2Fyaml%2F" target="_blank" rel="noopener" aria-label="Share on Facebook">
  
</a>

<!-- Sharingbutton Twitter -->
<a href="https://twitter.com/intent/tweet/?text=Why%20YAML%20is%20used%20for%20configuration%20when%20it%27s%20so%20bad%20and%20what%20can%20you%20do%20about%20it?&amp;url=https%3A%2F%2Fkula.blog%2Fposts%2Fyaml%2F" target="_blank" rel="noopener" aria-label="Share on Twitter">
  
</a>

<!-- Sharingbutton E-Mail -->
<a href="mailto:?subject=Why%20YAML%20is%20used%20for%20configuration%20when%20it's%20so%20bad%20and%20what%20can%20you%20do%20about%20it?&amp;body=https%3A%2F%2Fkula.blog%2Fposts%2Fyaml%2F" target="_self" rel="noopener" aria-label="Share by E-Mail">
  
</a>

<!-- Sharingbutton Hacker News -->
<a href="https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fkula.blog%2Fposts%2Fyaml%2F&amp;t=Why%20YAML%20is%20used%20for%20configuration%20when%20it%27s%20so%20bad%20and%20what%20can%20you%20do%20about%20it?" target="_blank" rel="noopener" aria-label="Share on Hacker News">
  
</a>

<!-- Sharingbutton LinkedIn -->
<a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fkula.blog%2Fposts%2Fyaml%2F&amp;title=Why%20YAML%20is%20used%20for%20configuration%20when%20it%27s%20so%20bad%20and%20what%20can%20you%20do%20about%20it?&amp;source=https%3A%2F%2Fkula.blog%2Fposts%2Fyaml%2F" target="_blank" rel="noopener" aria-label="Share on LinkedIn">
  
</a>



<p>
    <a href="https://kula.blog/">← Home</a>
</p>

        </div></div>]]>
            </description>
            <link>https://kula.blog/posts/yaml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24130532</guid>
            <pubDate>Wed, 12 Aug 2020 10:45:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The SF Anthology Problem – Solved]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24130250">thread link</a>) | @sohkamyung
<br/>
August 12, 2020 | https://classicsofsciencefiction.com/2020/08/09/the-sf-anthology-problem-solved/ | <a href="https://web.archive.org/web/*/https://classicsofsciencefiction.com/2020/08/09/the-sf-anthology-problem-solved/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Two years ago when we completed version 1 of The Classics of Science Fiction Short Story list I <a href="https://auxiliarymemory.com/2018/08/18/the-mathematics-of-buying-science-fiction-anthologies/">proposed a math challenge</a>. Version 1 came up with 275 stories. I asked if there was any mathematically way to decide what were the fewest anthologies that contained all 275 stories using ISFDB.org as a reference database. Version 1 was generated using .csv files. Since then we updated the process to a database for version 2 of the list, which produced 101 stories — we believe that was a more practical reading list.</p>
<p>A science fiction fan could read the entire list over the summer by reading one story a day, or in a year by reading one story every three days, but where would they get the 101 science fiction short stories? It might be possible to track down many stories on the internet, but what if people wanted to read them in a printed book? What would be the minimum number of anthologies to buy to get all the stories? That seem like an fascinating mathematical problem to me.</p>
<p>Well, <a href="https://szymonszott.github.io/">Szymon Szott</a> just <a href="https://github.com/SzymonSzott/science-fiction-anthology-problem">came up with a solution</a> using version 2 of the list. The second link goes to GitHub for Szymon’s Python code and documentation. The first link goes to his bio. Even if you can’t read the programming code you should <a href="https://github.com/SzymonSzott/science-fiction-anthology-problem/blob/master/classics_sf.ipynb">visit this page</a> that explains his solution. Szymon was able to come up with 22 anthologies that collected the 101 stories on the v. 2 of <a href="https://csfquery.com/SearchResult?mincite=8&amp;category=story&amp;sortby=7&amp;list=1">The Classics of Science Fiction Short Stories</a> list.</p>
<p>The photo above pictures eight anthologies that get 81 stories of the version 2 list. Of course, those eight anthologies gets you a lot more than 81 stories. I tried to figure out the solution myself by <a href="https://docs.google.com/spreadsheets/d/1BcnkixicU-NtvTrBfwX03vqGSAF5yAorMQTnn-Ytq1M/edit?usp=sharing">using a spreadsheet</a> and the best I could do was find fifteen anthologies to cover 81 stories, and then gave up. I figured my eyeballing method might have gotten me to 30-35 anthologies.</p>
<p>Here’s what Szymon says about the project:</p>
<pre>As a fan of science fiction and a compulsive completionist, Worlds Without End is one of my favorite sites on the Internet. It was there that I learned about Jim and Mike's work on the list of classic science fiction novels which I've been eagerly following. When the list of classic science fiction short stories was announced and Jim blogged about <a href="https://auxiliarymemory.com/2018/08/18/the-mathematics-of-buying-science-fiction-anthologies/">The Mathematics of Buying Science Fiction Anthologies</a>, I knew this was an interesting problem to solve. But it wasn't until I started dabbling in Python that I realized that, along with the 2020 travel-restricted summer holidays, I now had the tools to start chipping away at this. Creating a story-to-anthology mapping using data from the Internet Speculative Fiction Database didn't take too long, but the underlying mathematical problem was harder than I initially thought: it turned out that a brute-force approach of checking all possible combinations is unfeasible. Still, the heuristic used has given us a solution which I'm satisfied with and I don't think there exists a much better global solution. I was most surprised that the Science Fiction Hall of Fame series did not make the list (as I've already read volume one). Thank you Jim for this challenge! Now, all this coding was fun, but it's time to get back to reading: Sense of Wonder is next!</pre>
<p>This isn’t an easy problem. Szymon had to screenscrape the table of contents from 290 anthologies from ISFDB.org, which contained one or more of the 101 stories. Just look at <a href="https://github.com/SzymonSzott/science-fiction-anthology-problem/blob/master/main.csv">this listing</a> to see how often each of these stories was reprinted. Towards the end of his programming loops, he had to use eight anthologies to cover eight stories. If all those singletons had been in one anthology, Szymon’s finally anthology list would have been 15. Most of those singletons were newer stories and there haven’t been enough time for them to be collected into a retrospective anthology. One new anthology could shorten Szymon’s final list.</p>
<p>I know many people won’t follow links, so here is Szymon’s program results:</p>
<pre><strong>Sense of Wonder</strong>

- "Arena" by Fredric Brown
- "Bears Discover Fire" by Terry Bisson
- "Black Destroyer" by A. E. van Vogt
- "Blood Music" by Greg Bear
- "Bloodchild" by Octavia E. Butler
- "The Cold Equations" by Tom Godwin
- "The Country of the Kind" by Damon Knight
- "Day Million" by Frederik Pohl
- "First Contact" by Murray Leinster
- "Fondly Fahrenheit" by Alfred Bester
- "The Game of Rat and Dragon" by Cordwainer Smith
- "Hell Is the Absence of God" by Ted Chiang
- "Jeffty Is Five" by Harlan Ellison
- "The Little Black Bag" by C. M. Kornbluth
- "Lobsters" by Charles Stross
- "The Lucky Strike" by Kim Stanley Robinson
- "A Martian Odyssey" by Stanley G. Weinbaum
- "Microcosmic God" by Theodore Sturgeon
- "The Mountains of Mourning" by Lois McMaster Bujold
- "Nightfall" by Isaac Asimov
- "The Only Neat Thing to Do" by James Tiptree, Jr.
- "Or All the Seas with Oysters" by Avram Davidson
- "Passengers" by Robert Silverberg
- "The Persistence of Vision" by John Varley
- "Rachel in Love" by Pat Murphy
- "A Rose for Ecclesiastes" by Roger Zelazny
- "The Sentinel" by Arthur C. Clarke
- "Seven American Nights" by Gene Wolfe
- "Souls" by Joanna Russ
- "Surface Tension" by James Blish
- "That Only a Mother" by Judith Merril
- "Think Like a Dinosaur" by James Patrick Kelly
- "The Ugly Chickens" by Howard Waldrop
- "Who Goes There?" by John W. Campbell, Jr.

Running story total: 34

<strong>The Wesleyan Anthology of Science Fiction</strong>

- ""Repent, Harlequin!" Said the Ticktockman" by Harlan Ellison
- "Air Raid" by John Varley
- "All You Zombies—" by Robert A. Heinlein
- "And I Awoke and Found Me Here on the Cold Hill's Side" by James Tiptree, Jr.
- "Aye, and Gomorrah …" by Samuel R. Delany
- "Burning Chrome" by William Gibson
- "Coming Attraction" by Fritz Leiber
- "Desertion" by Clifford D. Simak
- "Nine Lives" by Ursula K. Le Guin
- "Speech Sounds" by Octavia E. Butler
- "The Star" by H. G. Wells
- "There Will Come Soft Rains" by Ray Bradbury
- "Thunder and Roses" by Theodore Sturgeon
- "We Can Remember It for You Wholesale" by Philip K. Dick
- "When It Changed" by Joanna Russ

Running story total: 49

<strong>Science Fiction: Stories and Contexts</strong>

- "At the Rialto" by Connie Willis
- "Flowers for Algernon" by Daniel Keyes
- "For a Breath I Tarry" by Roger Zelazny
- "The Girl Who Was Plugged In" by James Tiptree, Jr.
- "Mimsy Were the Borogoves" by Henry Kuttner, C. L. Moore
- "The Nine Billion Names of God" by Arthur C. Clarke
- "Second Variety" by Philip K. Dick
- "Story of Your Life" by Ted Chiang
- "Vaster Than Empires and More Slow" by Ursula K. Le Guin
- "Vintage Season" by Henry Kuttner, C. L. Moore

Running story total: 59

<strong>The Big Book of Science Fiction: The Ultimate Collection</strong>

- "Sandkings" by George R. R. Martin
- "Snow" by John Crowley
- "Swarm" by Bruce Sterling
- "The Last Question" by Isaac Asimov
- "The Man Who Lost the Sea" by Theodore Sturgeon
- "The Star" by Arthur C. Clarke
- "The Voices of Time" by J. G. Ballard

Running story total: 66

<strong>The Science Fiction Hall of Fame, Volume IV</strong>

- "A Meeting with Medusa" by Arthur C. Clarke
- "Born with the Dead" by Robert Silverberg
- "Of Mist, and Grass, and Sand" by Vonda N. McIntyre
- "The Day Before the Revolution" by Ursula K. Le Guin
- "The Death of Doctor Island" by Gene Wolfe
- "The Queen of Air and Darkness" by Poul Anderson

Running story total: 72

<strong>The Very Best of Fantasy &amp; Science Fiction: 60th Anniversary Anthology</strong>

- "Harrison Bergeron" by Kurt Vonnegut, Jr.
- "The Merchant and the Alchemist's Gate" by Ted Chiang
- "The Women Men Don't See" by James Tiptree, Jr.

Running story total: 75

<strong>The Science Fiction Century</strong>

- "Beggars in Spain" by Nancy Kress
- "Fire Watch" by Connie Willis
- "Great Work of Time" by John Crowley

Running story total: 78

<strong>The Best of the Nebulas</strong>

- "A Boy and His Dog" by Harlan Ellison
- "Houston, Houston, Do You Read?" by James Tiptree, Jr.
- "Time Considered as a Helix of Semi-Precious Stones" by Samuel R. Delany

Running story total: 81

<strong>Armageddons</strong>

- "Inconstant Moon" by Larry Niven
- "The Screwfly Solution" by James Tiptree, Jr.

Running story total: 83

<strong>Survival Printout</strong>

- "I Have No Mouth, and I Must Scream" by Harlan Ellison
- "Scanners Live in Vain" by Cordwainer Smith

Running story total: 85

<strong>Modern Classic Short Novels of Science Fiction</strong>

- "Sailing to Byzantium" by Robert Silverberg
- "The Star Pit" by Samuel R. Delany

Running story total: 87

<strong>The Legend Book of Science Fiction</strong>

- "The Fifth Head of Cerberus" by Gene Wolfe
- "The Moon Moth" by Jack Vance

Running story total: 89

<strong>The Arbor House Treasury of Modern Science Fiction</strong>

- "Light of Other Days" by Bob Shaw
- "The Bicentennial Man" by Isaac Asimov

Running story total: 91

<strong>The Locus Awards: Thirty Years of the Best in Science Fiction and Fantasy</strong>

- "Even the Queen" by Connie Willis
- "The Way of Cross and Dragon" by George R. R. Martin

Running story total: 93

<strong>Hugo and Nebula Award Winners from Asimov's Science Fiction</strong>

- "Press ENTER ■" by John Varley

Running story total: 94

<strong>The Hugo Winners, Volume Three</strong>

- "A Song for Lya" by George R. R. Martin

Running story total: 95

<strong>The Best Science Fiction and Fantasy of the Year Volume Six</strong>

- "The Man Who Bridged the Mist" by Kij Johnson

Running story total: 96

<strong>The Best Science Fiction and Fantasy of the Year Volume Five</strong>

- "The Things" by Peter Watts

Running story total: 97

<strong>The Year's Best Science Fiction: Fourth Annual Collection</strong>

- "R &amp; R" by Lucius Shepard

Running story total: 98

<strong>The Unreal and the Real: The Selected Short Stories of Ursula K. Le Guin</strong>

- "Buffalo Gals, Won't You Come Out Tonight" by Ursula K. Le Guin

Running story total: 99

<strong>The New Space Opera 2</strong>

- "The Island" by Peter Watts

Running story total: 100

<strong>The New Hugo Winners, Volume III</strong>

- "The Last of the Winnebagos" by Connie Willis

Running story total: 101

<strong>Selected books</strong>:

- <a href="http://www.isfdb.org/cgi-bin/title.cgi?1295175">Sense of Wonder</a>
- <a href="http://www.isfdb.org/cgi-bin/title.cgi?1139797">The Wesleyan Anthology of Science Fiction</a>
- <a href="http://www.isfdb.org/cgi-bin/title.cgi?2177624">Science Fiction: Stories and Contexts</a>
- <a href="http://www.isfdb.org/cgi-bin/title.cgi?2012662">The Big Book of Science Fiction: The Ultimate Collection</a>
- <a href="http://www.isfdb.org/cgi-bin/title.cgi?33477">The Science Fiction Hall of Fame, Volume IV</a>
- <a href="http://www.isfdb.org/cgi-bin/title.cgi?33477">The Very Best of Fantasy &amp; Science Fiction: 60th Anniversary …</a></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://classicsofsciencefiction.com/2020/08/09/the-sf-anthology-problem-solved/">https://classicsofsciencefiction.com/2020/08/09/the-sf-anthology-problem-solved/</a></em></p>]]>
            </description>
            <link>https://classicsofsciencefiction.com/2020/08/09/the-sf-anthology-problem-solved/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24130250</guid>
            <pubDate>Wed, 12 Aug 2020 10:04:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Concept for Usable Touch Interaction in Cars]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 40 (<a href="https://news.ycombinator.com/item?id=24130123">thread link</a>) | @caskes
<br/>
August 12, 2020 | https://www.theturnsignalblog.com/blog/new-touch-concept/ | <a href="https://web.archive.org/web/*/https://www.theturnsignalblog.com/blog/new-touch-concept/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><p>Over the past years, a trend in car design has emerged where car designers have been 'decluttering' car interiors. They are removing physical controls in favor of touch screens. The main reasons for this are the cleaner looks and cost-saving.</p>
<p>However, when car companies do this, they fail to take full advantage of touch screens. Instead, their approach has largely been to copy tablet interfaces, and directly convert physical buttons into touch buttons. As a result, touch interfaces in cars are difficult to use.</p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/304ea3345f61cdaf795bc35ce666168b/ea415/touchinterior.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Car companies are going all out with touch screens" title="Car companies are going all out with touch screens" src="https://www.theturnsignalblog.com/static/304ea3345f61cdaf795bc35ce666168b/b85f6/touchinterior.png" srcset="https://www.theturnsignalblog.com/static/304ea3345f61cdaf795bc35ce666168b/aaa28/touchinterior.png 180w,
https://www.theturnsignalblog.com/static/304ea3345f61cdaf795bc35ce666168b/7e1e1/touchinterior.png 360w,
https://www.theturnsignalblog.com/static/304ea3345f61cdaf795bc35ce666168b/b85f6/touchinterior.png 720w,
https://www.theturnsignalblog.com/static/304ea3345f61cdaf795bc35ce666168b/ea415/touchinterior.png 1000w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>Car companies are going all out with touch screens</figcaption>
  </figure>
<p>When looking around in traffic, the number of people being distracted by their phones and infotainment systems is alarming. The latter is a problem entirely created by the car companies themselves. I think they are not doing enough to take ownership and address this. Having a well-designed user experience does not only lead to fewer accidents, but it also leads to happier customers, it is a win-win!</p>
<p>In short, either touch screens are a step back in usability from physical controls and a different solution has to be found, or there are significant improvements possible in the design.
I decided to see if it is possible to create an in-car experience that has no physical controls and is usable at the same time.</p>

<p>Based on the core problems of touch screens, I came up with four abstract principles that help me to solve them.</p>
<h2>1. "Simplify, then add lightness"</h2>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/717437a4ddd929baa1895358e6ec90a1/ea415/simplify.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Simplify, then add lightness" title="Simplify, then add lightness" src="https://www.theturnsignalblog.com/static/717437a4ddd929baa1895358e6ec90a1/b85f6/simplify.png" srcset="https://www.theturnsignalblog.com/static/717437a4ddd929baa1895358e6ec90a1/aaa28/simplify.png 180w,
https://www.theturnsignalblog.com/static/717437a4ddd929baa1895358e6ec90a1/7e1e1/simplify.png 360w,
https://www.theturnsignalblog.com/static/717437a4ddd929baa1895358e6ec90a1/b85f6/simplify.png 720w,
https://www.theturnsignalblog.com/static/717437a4ddd929baa1895358e6ec90a1/ea415/simplify.png 1000w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>Simplify, then add lightness</figcaption>
  </figure>
<p>I had to look no further than the automotive world itself to describe the most important principle. Legendary race car designer Colin Chapman coined the famous phrase: "Simplify, then add lightness". His race cars were successful in the '60s because they were highly purpose-built and fully adapted to their context of use. This same principle is a determining factor in good interfaces.</p>
<p>Compare the features in the interior of the Volkswagen Golf I to the Golf VIII. They are actually quite similar. Both offer some information related to driving, climate controls, and media controls. The main difference being that the Golf VIII has a navigation system. Still, how is it possible that the Golf VIII is so much more complex?</p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/b9f936225263c3c93a0f25dc503dd2dd/ea415/golfcomparison.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The Golf I vs Golf VIII interior" title="The Golf I vs Golf VIII interior" src="https://www.theturnsignalblog.com/static/b9f936225263c3c93a0f25dc503dd2dd/b85f6/golfcomparison.png" srcset="https://www.theturnsignalblog.com/static/b9f936225263c3c93a0f25dc503dd2dd/aaa28/golfcomparison.png 180w,
https://www.theturnsignalblog.com/static/b9f936225263c3c93a0f25dc503dd2dd/7e1e1/golfcomparison.png 360w,
https://www.theturnsignalblog.com/static/b9f936225263c3c93a0f25dc503dd2dd/b85f6/golfcomparison.png 720w,
https://www.theturnsignalblog.com/static/b9f936225263c3c93a0f25dc503dd2dd/ea415/golfcomparison.png 1000w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The Golf I vs Golf VIII interior</figcaption>
  </figure>
<p>One reason is that it offers hundreds of additional options, features, and settings that are not essential. When digital interfaces became bigger and bigger, car companies saw it as an opportunity to add more features. But just because you can add something, doesn't mean that you should. What I set out to do was reevaluate all these functionalities and remove anything that is not significantly contributing to the driver experience, and simplify the functionalities that do contribute. Which leads to the next principle.</p>
<h2>2. Configuration vs Automation</h2>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/f2413234443126af50331695d18cc03e/ea415/automate.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Configuration vs Automation" title="Configuration vs Automation" src="https://www.theturnsignalblog.com/static/f2413234443126af50331695d18cc03e/b85f6/automate.png" srcset="https://www.theturnsignalblog.com/static/f2413234443126af50331695d18cc03e/aaa28/automate.png 180w,
https://www.theturnsignalblog.com/static/f2413234443126af50331695d18cc03e/7e1e1/automate.png 360w,
https://www.theturnsignalblog.com/static/f2413234443126af50331695d18cc03e/b85f6/automate.png 720w,
https://www.theturnsignalblog.com/static/f2413234443126af50331695d18cc03e/ea415/automate.png 1000w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>Configuration vs Automation</figcaption>
  </figure>
<p>This abundance of choice is typical for the car industry. The more luxurious a car, the more options of personalization exist. Modern car interfaces reflect this. Users have a myriad of settings, widgets, backgrounds, colors, and more that can be configured in the interface.
The same holds for other interactions like the climate controls. </p>
<p>Is it really luxurious to touch 5 different controls to get the temperature you want, or Do users appreciate this kind of luxury? Consider the example below. Isn't luxury not having to interact with a system at all, or in a minimal way?</p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/fc3268882aef57f8acdde0a94829bab9/ea415/climatecomparison.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The climate controls in a Range Rover Velar compared to the Nest Thermostat" title="The climate controls in a Range Rover Velar compared to the Nest Thermostat" src="https://www.theturnsignalblog.com/static/fc3268882aef57f8acdde0a94829bab9/b85f6/climatecomparison.png" srcset="https://www.theturnsignalblog.com/static/fc3268882aef57f8acdde0a94829bab9/aaa28/climatecomparison.png 180w,
https://www.theturnsignalblog.com/static/fc3268882aef57f8acdde0a94829bab9/7e1e1/climatecomparison.png 360w,
https://www.theturnsignalblog.com/static/fc3268882aef57f8acdde0a94829bab9/b85f6/climatecomparison.png 720w,
https://www.theturnsignalblog.com/static/fc3268882aef57f8acdde0a94829bab9/ea415/climatecomparison.png 1000w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The climate controls in a Range Rover Velar compared to the Nest Thermostat</figcaption>
  </figure>
<h2>3. Adjust to Context</h2>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/ad774452ae55214fcb36425e8558e8e8/ea415/context.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Adjust to Context" title="Adjust to Context" src="https://www.theturnsignalblog.com/static/ad774452ae55214fcb36425e8558e8e8/b85f6/context.png" srcset="https://www.theturnsignalblog.com/static/ad774452ae55214fcb36425e8558e8e8/aaa28/context.png 180w,
https://www.theturnsignalblog.com/static/ad774452ae55214fcb36425e8558e8e8/7e1e1/context.png 360w,
https://www.theturnsignalblog.com/static/ad774452ae55214fcb36425e8558e8e8/b85f6/context.png 720w,
https://www.theturnsignalblog.com/static/ad774452ae55214fcb36425e8558e8e8/ea415/context.png 1000w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>Adjust to Context</figcaption>
  </figure>
<p>Today, most interfaces in cars are very similar to tablet interfaces. Tablets are devices that are used in a broad range of contexts. The interface has to work just as well when you are watching Netflix at home on your couch, as when you are multitasking in a busy office environment. </p>
<p>In a car, this is not the case. A UX designer can be sure that the interface will be only be used in a context related to driving. Therefore, they should design the interface to fit that context. It is the difference between a Swiss army knife and a chef's knife. You can design the best Swiss army knife in the world, but in a kitchen, a chef's knife will always be better.   </p>
<h2>4. Hardware Follows Software</h2>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/c9b0ad868fe410c1027f7fe3ebaa3a27/ea415/software.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Hardware Follows Software" title="Hardware Follows Software" src="https://www.theturnsignalblog.com/static/c9b0ad868fe410c1027f7fe3ebaa3a27/b85f6/software.png" srcset="https://www.theturnsignalblog.com/static/c9b0ad868fe410c1027f7fe3ebaa3a27/aaa28/software.png 180w,
https://www.theturnsignalblog.com/static/c9b0ad868fe410c1027f7fe3ebaa3a27/7e1e1/software.png 360w,
https://www.theturnsignalblog.com/static/c9b0ad868fe410c1027f7fe3ebaa3a27/b85f6/software.png 720w,
https://www.theturnsignalblog.com/static/c9b0ad868fe410c1027f7fe3ebaa3a27/ea415/software.png 1000w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>Hardware Follows Software</figcaption>
  </figure>
<p>Designing a car interior is a complex process where different disciplines have to work together and compromise. Balancing usability with esthetics is important when thinking of screen layouts. But what if you did not have to care about the esthetics and could focus fully on usability?</p>
<p>For this project, I did exactly that. I first figured out the core features of the interface. Then I tested the usability of different screen layouts by creating 3D models and testing them in VR. I discovered that a horizontal screen layout, close to the line of sight of the driver is best in terms of usability. With this in mind, I designed the interface without any real screen size constraint. I let the interface dictate the hardware size.</p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/3e382a6cd6f39b247fd160ba8d9b2680/577a7/VR.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Different versions of screen layouts that I explored in VR" title="Different versions of screen layouts that I explored in VR" src="https://www.theturnsignalblog.com/static/3e382a6cd6f39b247fd160ba8d9b2680/577a7/VR.png" srcset="https://www.theturnsignalblog.com/static/3e382a6cd6f39b247fd160ba8d9b2680/aaa28/VR.png 180w,
https://www.theturnsignalblog.com/static/3e382a6cd6f39b247fd160ba8d9b2680/7e1e1/VR.png 360w,
https://www.theturnsignalblog.com/static/3e382a6cd6f39b247fd160ba8d9b2680/577a7/VR.png 601w" sizes="(max-width: 601px) 100vw, 601px" loading="lazy">
  </a>
    </span>
    <figcaption>Different versions of screen layouts that I explored in VR</figcaption>
  </figure>

<p>In total, I designed three different versions of the concept. After each version, I sought out feedback from people in my network to improve it. Below is a mockup of the final concept. </p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/ea161bd7a56e0c35b194b0939d461455/7dc1b/FinalConcept.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The final concept" title="The final concept" src="https://www.theturnsignalblog.com/static/ea161bd7a56e0c35b194b0939d461455/b85f6/FinalConcept.png" srcset="https://www.theturnsignalblog.com/static/ea161bd7a56e0c35b194b0939d461455/aaa28/FinalConcept.png 180w,
https://www.theturnsignalblog.com/static/ea161bd7a56e0c35b194b0939d461455/7e1e1/FinalConcept.png 360w,
https://www.theturnsignalblog.com/static/ea161bd7a56e0c35b194b0939d461455/b85f6/FinalConcept.png 720w,
https://www.theturnsignalblog.com/static/ea161bd7a56e0c35b194b0939d461455/4d206/FinalConcept.png 1080w,
https://www.theturnsignalblog.com/static/ea161bd7a56e0c35b194b0939d461455/91a72/FinalConcept.png 1440w,
https://www.theturnsignalblog.com/static/ea161bd7a56e0c35b194b0939d461455/7dc1b/FinalConcept.png 1860w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The final concept</figcaption>
  </figure>
<p>The interface is divided over four different screens. The center screen, the cluster screen, and the climate control screens. Let me take you through the main features! </p>
<h2>Layers</h2>
<p>The center screen is the most important and I spent most of my time designing it. </p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/a056dd788184d2bae767d6991440cbff/b5909/concept1.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The center screen" title="The center screen" src="https://www.theturnsignalblog.com/static/a056dd788184d2bae767d6991440cbff/b85f6/concept1.png" srcset="https://www.theturnsignalblog.com/static/a056dd788184d2bae767d6991440cbff/aaa28/concept1.png 180w,
https://www.theturnsignalblog.com/static/a056dd788184d2bae767d6991440cbff/7e1e1/concept1.png 360w,
https://www.theturnsignalblog.com/static/a056dd788184d2bae767d6991440cbff/b85f6/concept1.png 720w,
https://www.theturnsignalblog.com/static/a056dd788184d2bae767d6991440cbff/4d206/concept1.png 1080w,
https://www.theturnsignalblog.com/static/a056dd788184d2bae767d6991440cbff/b5909/concept1.png 1400w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The center screen</figcaption>
  </figure>
<p>When driving, almost all of the interactions are related to either navigation or media. Today, interfaces often give equal importance to other features like phone and settings. For simplicity's sake, I chose to keep the interface as simple as possible and remove anything but media, navigation, and some basic climate controls.</p>
<p>These are organized in layers with the navigation as fundament. On top of that is the media player. These two will always be visible. One level higher are controls for climate and media which can be opened by clicking on the icon in the bottom left corner and top right corner of the screen respectively.</p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/fa360713f967fa103bdfaaa579d4ca7e/7dc1b/Layers.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The different layers that make up the interface" title="The different layers that make up the interface" src="https://www.theturnsignalblog.com/static/fa360713f967fa103bdfaaa579d4ca7e/b85f6/Layers.png" srcset="https://www.theturnsignalblog.com/static/fa360713f967fa103bdfaaa579d4ca7e/aaa28/Layers.png 180w,
https://www.theturnsignalblog.com/static/fa360713f967fa103bdfaaa579d4ca7e/7e1e1/Layers.png 360w,
https://www.theturnsignalblog.com/static/fa360713f967fa103bdfaaa579d4ca7e/b85f6/Layers.png 720w,
https://www.theturnsignalblog.com/static/fa360713f967fa103bdfaaa579d4ca7e/4d206/Layers.png 1080w,
https://www.theturnsignalblog.com/static/fa360713f967fa103bdfaaa579d4ca7e/91a72/Layers.png 1440w,
https://www.theturnsignalblog.com/static/fa360713f967fa103bdfaaa579d4ca7e/7dc1b/Layers.png 1860w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The different layers that make up the interface</figcaption>
  </figure>
<p>In a context where the user will be focused on driving, the time spent interacting with the screens should be minimized. That is why the placement of these elements is heavily influenced by Fitts' law. It states that the time required to rapidly move to a target area is a function of the ratio between the distance to the target and the width of the target. In other words, to make navigation easier, you either place clickable elements close to each other, or you make the clickable area bigger.</p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/bafa6547968825bc70f5d067948118f3/b5909/concept2.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The main features are toggled in the corner of the screen where they can easily be reached" title="The main features are toggled in the corner of the screen where they can easily be reached" src="https://www.theturnsignalblog.com/static/bafa6547968825bc70f5d067948118f3/b85f6/concept2.png" srcset="https://www.theturnsignalblog.com/static/bafa6547968825bc70f5d067948118f3/aaa28/concept2.png 180w,
https://www.theturnsignalblog.com/static/bafa6547968825bc70f5d067948118f3/7e1e1/concept2.png 360w,
https://www.theturnsignalblog.com/static/bafa6547968825bc70f5d067948118f3/b85f6/concept2.png 720w,
https://www.theturnsignalblog.com/static/bafa6547968825bc70f5d067948118f3/4d206/concept2.png 1080w,
https://www.theturnsignalblog.com/static/bafa6547968825bc70f5d067948118f3/b5909/concept2.png 1400w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The main features are toggled in the corner of the screen where they can easily be reached</figcaption>
  </figure>
<p>Fitts' law also indicates that the most quickly accessed targets on any computer display are the four corners of the screen. It is much easier to blindly reach for a screen corner than an element placed in the middle of the screen. That is why climate and media can be accessed from the corners. Furthermore, on each side of the screen are more specific sliders for volume and climate which I will explain further on.</p>
<p>I made a conscious choice to place climate controls in the left half of the screen and media controls on the right half. Most cars have some form of physical controls on the steering wheel that control media and volume. Therefore, it is more important to place the climate controls close to the hands of the driver than media.</p>
<h2>Driving Modes</h2>
<p>The interface changes depending on context in two different ways. Park vs drive and short vs long drive. </p>
<h3>Park vs Drive</h3>
<p>First, there is a difference between the interface when the car is in park compared to when in drive. These two scenarios come with two different sets of user needs. When in park, all settings and features can be accessed. More importantly, the system closely resembles the typical recognizable tablet interface with small labels and buttons since distraction is not a problem. </p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/aa4d82e6ec1eb043a1e52336c76ad59c/fb2b5/park.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The interface that is shown in Park. It takes design cues from regular tablets with smaller buttons and labels" title="The interface that is shown in Park. It takes design cues from regular tablets with smaller buttons and labels" src="https://www.theturnsignalblog.com/static/aa4d82e6ec1eb043a1e52336c76ad59c/b85f6/park.png" srcset="https://www.theturnsignalblog.com/static/aa4d82e6ec1eb043a1e52336c76ad59c/aaa28/park.png 180w,
https://www.theturnsignalblog.com/static/aa4d82e6ec1eb043a1e52336c76ad59c/7e1e1/park.png 360w,
https://www.theturnsignalblog.com/static/aa4d82e6ec1eb043a1e52336c76ad59c/b85f6/park.png 720w,
https://www.theturnsignalblog.com/static/aa4d82e6ec1eb043a1e52336c76ad59c/4d206/park.png 1080w,
https://www.theturnsignalblog.com/static/aa4d82e6ec1eb043a1e52336c76ad59c/91a72/park.png 1440w,
https://www.theturnsignalblog.com/static/aa4d82e6ec1eb043a1e52336c76ad59c/fb2b5/park.png 2600w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The interface that is shown in Park. It takes design cues from regular tablets with smaller buttons and labels</figcaption>
  </figure>
<p>But when the car is in drive, the interface changes. The driver is limited to functionalities only related to driving, like navigation and basic media controls. The labels and buttons are also much clearer and bigger so they can more easily be reached. This is a difficult choice to make as the system will not allow the driver (or passenger) to change any settings while driving. But in my eyes, it is a balance between safety and freedom to the user. And in that case, I choose safety.</p>
<h3>Short vs Long Drives</h3>
<p>The second contextual change is the distinction between short drives and longer journeys with navigation.
The main difference is in the map design. While out on a regular drive, say your daily commute, most users are not interested in many of the details on the map like street names, buildings, and more. The most important layer of information is traffic. That is why the map looks much calmer, and only shows the streets with traffic information on top. But when navigating, the map shows building shapes, major street names, highlighted spaces, and other features.</p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/430dcc3bc8b99b356c89f5115e1cfac8/befe7/mapcomparison.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The regular map (left) only shows traffic information compared to the navigation map (right) with more detailed information" title="The regular map (left) only shows traffic information compared to the navigation map (right) with more detailed information" src="https://www.theturnsignalblog.com/static/430dcc3bc8b99b356c89f5115e1cfac8/b85f6/mapcomparison.png" srcset="https://www.theturnsignalblog.com/static/430dcc3bc8b99b356c89f5115e1cfac8/aaa28/mapcomparison.png 180w,
https://www.theturnsignalblog.com/static/430dcc3bc8b99b356c89f5115e1cfac8/7e1e1/mapcomparison.png 360w,
https://www.theturnsignalblog.com/static/430dcc3bc8b99b356c89f5115e1cfac8/b85f6/mapcomparison.png 720w,
https://www.theturnsignalblog.com/static/430dcc3bc8b99b356c89f5115e1cfac8/befe7/mapcomparison.png 987w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The regular map (left) only shows traffic information compared to the navigation map (right) with more detailed information</figcaption>
  </figure>
<p>The other difference is the information displayed in the cluster. I wanted to explore how the cluster screen can work more closely …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.theturnsignalblog.com/blog/new-touch-concept/">https://www.theturnsignalblog.com/blog/new-touch-concept/</a></em></p>]]>
            </description>
            <link>https://www.theturnsignalblog.com/blog/new-touch-concept/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24130123</guid>
            <pubDate>Wed, 12 Aug 2020 09:43:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hitchhiker's Guide to the Containers: A Foolproof, Hands-On Docker Tutorial]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24130091">thread link</a>) | @fazlerocks
<br/>
August 12, 2020 | https://blog.antoniolofiego.com/the-hitchhikers-guide-to-the-containers-a-foolproof-hands-on-docker-tutorial-part-2-ckdlu8yge04y6zzs14qgz76go | <a href="https://web.archive.org/web/*/https://blog.antoniolofiego.com/the-hitchhikers-guide-to-the-containers-a-foolproof-hands-on-docker-tutorial-part-2-ckdlu8yge04y6zzs14qgz76go">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>Welcome to Part 2 of my shameless attempt at explaining Docker to beginners. I struggled so you don't have to!</p>
<p>In last week's <a target="_blank" rel="noopener" href="https://blog.antoniolofiego.com/the-hitchhikers-guide-to-the-containers-a-foolproof-hands-on-docker-tutorial-part-1-ckdc4tni0031759s14z0pdd2j">article</a> we covered what Docker is, some of its jargon, and why it outperforms VMs in many use cases in today's typical software development lifecycle. This week we'll go deeper into running Docker on our machines, all while figuring out the most interesting and useful underlying technicalities.</p>
<p><img src="https://media.giphy.com/media/3aGZA6WLI9Jde/giphy.gif" alt="Let's go!"></p>
<h2 id="getting-started-with-docker">Getting started with Docker</h2>
<p>If you don't have Docker installed on your machine, head over to the <a target="_blank" rel="noopener" href="https://docs.docker.com/get-docker/">Docker Download page</a> to get the version that will work on your system.</p>
<p>The Linux version is the easiest to install, given that Docker is built off of Linux utilities. On Mac and Windows, on the other hand, there are two main ways of using Docker:</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://docs.docker.com/desktop/">Docker Desktop</a>
The newer and recommended version of Docker. It is a native solution that works directly along with your OS's processes, so we are free to interface with Docker with your favorite terminal and your favorite IDE/text editors.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://docs.docker.com/toolbox/overview/">Docker Toolbox</a>
This is an old version for machines that don't meet the minimum requirements for Docker Desktop. It is not a native solution as it runs on VirtualBox, so we are forced to use the tools that the Toolbox comes packaged with, making everything more cumbersome and prone to errors.</p>
</li>
</ul>
<p>The main catch is that Docker Desktop is not easy to install on every system. While it is straightforward on macOS 10.13+ and Windows 10 Pro, the Windows 10 Home version needs extra attention.</p>
<p>Docker Desktop on Windows leverages Hyper-V, which is Microsoft's Type 1 hypervisor and only available on Windows 10 Pro, Enterprise, and Education. Fortunately, Windows Home supports <strong>Windows Subsystem for Linux</strong> (WSL), a Linux kernel developed by Microsoft that allows us to run Linux processes to run natively without emulation. Since March 2020, Docker Desktop supports WSL version 2 as a backend on Windows Home.</p>
<p>To install Docker Desktop on Windows Home we need to install WSL2 first, then install Docker Desktop specifying WSL2 as the backend during the installation process. we can find the whole process to install WSL2 <a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">here</a> and the subsequent Docker Desktop installation process <a target="_blank" rel="noopener" href="https://docs.docker.com/docker-for-windows/install-windows-home/">here</a>. If you would like to see a walkthrough video of the installation process, let me know and I will work on making one available.</p>
<p>Once installed, we can open our favorite terminal and check that the installation went smoothly by typing</p>
<pre><code>docker --version
</code></pre>
<p>If this returns something the likes of</p>
<pre><code>Docker version 19.03.12, build 48a66213fe
</code></pre>
<p>we are good to go!</p>
<p><strong>Note</strong>: In case you are unable to make it work on your machine or if you don't want to install anything yet, Docker also offers <a target="_blank" rel="noopener" href="https://www.docker.com/play-with-docker">online playgrounds</a> to run your code and everything you find in this tutorial would work the same.</p>
<h2 id="let-s-run-our-first-container-">Let's run our first container!</h2>
<p>As we saw last week, to run a container we first need to find an image on the Docker registry. Like everything in the programming, Docker has a Hello World container that we can easily get from its Docker Hub <a target="_blank" rel="noopener" href="https://hub.docker.com/_/hello-world">page</a>. As we can see on the website, the command we have to run is</p>
<pre><code>$ docker pull hello-world
</code></pre>
<p>which will welcome us with an unsightly wall of output which looks like</p>
<pre><code>Using default tag: latest
latest: Pulling from library/hello-world
0e03bdcc26d7: Pulling fs layer
0e03bdcc26d7: Verifying Checksum
0e03bdcc26d7: Download complete
0e03bdcc26d7: Pull complete
Digest: sha256:49a1c8800c94df04e9658809b006fd8a686cab8028d33cfba2cc049724254202
Status: Downloaded newer image for hello-world:latest
docker.io/library/hello-world:latest
</code></pre>
<p>We can see a few things that we need to cover, namely <strong>tags</strong> and <strong>layers</strong>.</p>
<p>We can check all the images that we have in our machine simply by running <code>$ docker images</code> and inspecting its output:</p>
<pre><code>REPOSITORY       TAG        IMAGE ID        CREATED           SIZE
hello-world      latest     bf756fb1ae65    7 months ago      13.3kB
</code></pre>
<p>We can see that we have a <code>hello-world</code> image tagged latest, with a unique image ID (yours may be different) and it weighs only 13.3KB! That is where the gold is! Running a similar basic job using a VM would entail installing an entire OS just to output "Hello world!".</p>
<p>The first column of the <code>docker images</code> output is called <strong>repository</strong>. If you have ever used Git or GitHub, the name might sound familiar. In a Docker Registry, a repository is a collection of different versions of images that share the same base name. Each of the versions is identified by a <strong>tag</strong>, but images can have multiple tags as well!</p>
<p>In general, Docker images follow the naming convention of <code>username/repository:tag</code>. As a quick example, let's suppose that I built an image called <code>mysimpleapp</code> and I shared version 1.0 on the Docker Hub. You could get that image by running</p>
<pre><code>$ docker pull antoniolofiego/mysimpleapplication:1.0
</code></pre>
<p>If we do not specify the tag portion, Docker will by default download the image that is tagged as <code>latest</code>. This is not a special tag, but just the one that Docker assigns by default to images when no other tags are specified at build time.</p>
<p>Now that we have the image locally, we want to run it, right? Surely enough, the command to run images is <code>$ docker run &lt;image&gt;</code>. There are mainly three ways to reference an image:</p>
<ul>
<li><strong>By repository</strong>, but it works only if we have a single version of the image (ex: if I have two versions from the same repository, Docker will be confused about which I am referring to).</li>
<li><strong>By repository/tag combination</strong>, which solves the previous problem.</li>
<li><strong>By image ID</strong>, the preferred way, given that every image will always have a unique ID. Note, we can use just the first few characters from the ID and Docker will pick up the correct one.</li>
</ul>
<p>Using the Image ID method, for our <code>hello-world</code> image example we will run</p>
<pre><code>$ docker run bf756
Hello from Docker!
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    (amd64)
 3. The Docker daemon created a new container from that image that runs the executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.

To try something more ambitious, you can run an Ubuntu container with:
 $ docker run -it ubuntu bash

Share images, automate workflows, and more with a free Docker ID:
 https://hub.docker.com/

For more examples and ideas, visit:
 https://docs.docker.com/get-started/
</code></pre>
<p>We have successfully pulled and run our first Docker Image! 🎉 Let's recap all we learned so far by visualizing a repository structure and all the ways to pull or run an image in a simple way</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1596760605560/zssexvySE.png?auto=format&amp;q=60" alt="Repo structure"></p>
<p>We know how to pull and run simple images! We just scratched the Docker surface, however. Are you ready to go to the next level?</p>
<p><img src="https://miro.medium.com/max/570/0*y8AuUHSoTGRqX40h.jpeg" alt="We need to go deeper!"></p>
<h2 id="breaking-down-a-docker-image">Breaking down a Docker Image</h2>
<p>We know from last week that a Docker Image starts as a Dockerfile, which is a recipe that Docker follows to package our application. It is composed of a series of <code>[action]</code> <code>[target]</code> commands, each of which specifies a command that Docker needs to run in sequential order.</p>
<p>Let's take a look at a Dockerfile that deploys a simple Node.js Express server and try to understand how it works.</p>
<p><strong>Note:</strong> You can download all the code from this example via <a target="_blank" rel="noopener" href="https://github.com/antoniolofiego/hashnode-dockerseries-expressapp">this</a> GitHub repository.</p>
<p>The folder structure for this example is as follows</p>
<pre><code>📦docker-express-app
 ┣ 📂src
 ┃ ┗ 📜server.js
 ┣ 📜.gitignore
 ┣ 📜Dockerfile
 ┣ 📜package-lock.json
 ┗ 📜package.json
</code></pre>
<p>As we can see, the Dockerfile sits at the root level of my project folder. Let's now look at its content.</p>
<pre><code>FROM node:11-alpine

RUN mkdir app

WORKDIR /app

COPY . .

RUN npm install

CMD ["npm", "run", "start"]
</code></pre>
<p>Let's go through each step one by one:</p>
<ol>
<li><p><code>FROM node:11-alpine</code> tells Docker to download the Docker image for Node.js version 11 running on Linux Alpine, a very lightweight Linux distribution. This will be the base image used by our container.</p>
</li>
<li><p><code>RUN mkdir app</code> creates a local folder named <code>app</code> at the root of the environment.</p>
</li>
<li><p><code>WORKDIR /app</code> changes the working directory for all subsequent commands to the <code>/app</code> folder that we created in step 2.</p>
</li>
<li><p><code>COPY . .</code> tells Docker to copy all the files in the current folder on my machine (my <code>docker-express-app</code> folder) in the current directory of the Docker image (the <code>/app</code> directory).</p>
</li>
<li><p><code>RUN npm install</code> installs all the dependencies that I specified in my <code>package.json</code> file, in this case only <code>express</code>.</p>
</li>
<li><p><code>CMD ["npm", "run", "start"]</code> is the command that the container will run at instantiation time, in this case, the <code>start</code> script defined in <code>package.json</code>.</p>
</li>
</ol>
<p>The next step is to build the image. As you can imagine, we have a <code>docker build</code> command that does just that! The standard usage for the build command is</p>
<pre><code>docker build -t &lt;username/repository:tag&gt; &lt;path/to/Dockerfile&gt;
</code></pre>
<p>Remember that, when tagging an image, if we only provide a repository name Docker will assign the <code>latest</code> tag to the image by default. Let's take a look at the output.</p>
<pre><code>$ docker build -t docker-express-app .
Sending build context to Docker daemon  2.013MB
Step 1/6 : FROM node:11-alpine
 ---&gt; f18da2f58c3d
Step 2/6 : RUN mkdir app
 ---&gt; Running in 37513fc60556
Removing intermediate container 37513fc60556
 ---&gt; 13ee4d6cccbc
Step 3/6 : WORKDIR /app
 ---&gt; Running in 45e51ade37c0
Removing intermediate container 45e51ade37c0
 ---&gt; 579c23501f62
Step 4/6 : COPY . .
 ---&gt; a3527fb353c6
Step 5/6 : RUN npm install
 ---&gt; Running in f4ab1726f363
audited 50 packages in 0.855s
found 0 vulnerabilities

Removing intermediate container f4ab1726f363
 ---&gt; 8f2c4645e536
Step 6/6 : CMD ["npm", "run", "start"]
 ---&gt; Running in b5739c39b3cf
Removing intermediate container b5739c39b3cf
 ---&gt; ac715302eade
Successfully built ac715302eade
Successfully tagged docker-express-app:latest
</code></pre>
<p>As we can see, each instruction is carefully followed. On each step, Docker creates a <strong>layer</strong>. Every image is built out of several read-only layers, with each layer corresponding to certain instructions in your Dockerfile. Each step builds …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.antoniolofiego.com/the-hitchhikers-guide-to-the-containers-a-foolproof-hands-on-docker-tutorial-part-2-ckdlu8yge04y6zzs14qgz76go">https://blog.antoniolofiego.com/the-hitchhikers-guide-to-the-containers-a-foolproof-hands-on-docker-tutorial-part-2-ckdlu8yge04y6zzs14qgz76go</a></em></p>]]>
            </description>
            <link>https://blog.antoniolofiego.com/the-hitchhikers-guide-to-the-containers-a-foolproof-hands-on-docker-tutorial-part-2-ckdlu8yge04y6zzs14qgz76go</link>
            <guid isPermaLink="false">hacker-news-small-sites-24130091</guid>
            <pubDate>Wed, 12 Aug 2020 09:38:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The cheapest investment platforms in the UK]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24129843">thread link</a>) | @Halimah
<br/>
August 12, 2020 | https://www.koody.co/investing/compare-funds-isa-charges | <a href="https://web.archive.org/web/*/https://www.koody.co/investing/compare-funds-isa-charges">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f09af9fd3ce592df7f0eae7_scale-128x128.png" width="55" alt=""></p></div><div><div><p>Typically, your annual charge depends on whether you hold funds or shares in your investment ISA. Here, we assume you'll invest in funds only. If you plan to invest in shares, have a look at our <a href="https://www.koody.co/investing/compare-shares-isa-charges">shares' table</a>. </p><p>We've split the ISA providers into three categories based on the level of help they'll offer you. These categories are "Do It Yourself (DIY)," "Do It With Me (DIWM)," and "Do It For Me (DIFM)." For each provider we list, your money is protected by the Financial Services Compensation Scheme (FSCS). This means you could get your money back up to £85,000 if any of the companies goes bust. Use the tabs below to learn about each category.</p></div></div></div><div><div data-duration-in="300" data-duration-out="100" id="providers"><div><div data-w-tab="Tab 1"><div><div><p>This is ideal for people who know what they are doing. With DIY platforms, you'll have access to a wide range of investments, and in some cases, investment ideas or suggested fund lists. But you have to choose your investments and build your portfolio yourself. This requires a bit of research on your part, so it is crucial you know what you are doing. It would help if you have clear goals, know your risk appetite and understand how to build a portfolio.</p><p>When you invest in a fund, please note the fund manager will add various charges within the fund. We haven't included any fund management fees here, just platform and dealing fees. If you would like a rough idea of how fund management fees could impact the total amount you pay to a platform, have a look at the 'Do It With Me' and 'Do It For Me' tabs. Additionally, you can find out more about investing in funds and the various charges in <a href="https://www.koody.co/investing/funds">Investing in Funds guide</a>.</p></div><p>‍<span><strong>Important:</strong></span><strong><br></strong>The table below shows annual charges of several investment platforms when you invest in funds as follows:<br></p><ul role="list"><li>£100 per month regular payment</li><li>£500 per month regular payment</li><li>£1,000 per month regular payment</li><li>£20,000 lump sum (your year’s ISA allowance)</li><li>£100,000 lump sum (if you already have lots of ISAs from previous years and are transferring in)</li></ul><div><p>For regular payments, we assume you'll make 12 deals a year or one deal every month. For lump sums, we assume you'll make four deals a year. A deal is either one of buying or selling an investment. It is also called a trade. We've used the colour red to indicate what platforms are more expensive compared to the others. This means the darker the shade of red, the more expensive the platform. Dark red doesn't mean bad or too expensive. It just means the platform is more expensive when compared to the others. If you would like to see a breakdown of fees charged by each platform, have a look at our <a href="https://www.koody.co/investing/charges-directory">Platform Charges Directory</a>.</p><p>Finally, it is important to let you know we show the costs which apply to the first year only. This is especially important because, with platforms like iWeb, your charges reduce after the first year. Whereas with platforms like EQi, your charges might increase after the first year. You'll find all the details you need below.<br>‍</p></div></div><div><p>Notes<a href="https://www.koody.co/investing/compare-shares-isa-charges"></a></p><ol role="list"><li>EQi - You'll pay no custody fee in the first two quarters of the year you join, so it'll be more expensive in subsequent years.</li><li>IWeb - Charges a one-off account opening fee of £25 in the first year, so it will be cheaper in subsequent years where you do not have to pay the account opening fee.</li></ol><p>Once again, you can find more information on the various charges <a href="https://www.koody.co/investing/charges-directory">here</a> and view our share dealing ISA charges comparison table <a href="https://www.koody.co/investing/compare-shares-isa-charges">here.</a></p></div></div><div data-w-tab="Tab 2"><div><div><p>This is ideal for people who are happy making their own investment decisions but require a bit of help getting there. The DIWM platforms do not give you advice but offer some guidance that could help you understand your attitude to risk, and then provide ready-made investments that match your risk level.</p><p>When you invest in a fund, please note the fund manager will add on various charges within the fund. A good representation of those charges is the OCF or Ongoing Charges Figure. It is an estimate of the portion of the total cost of your investment that goes to the fund manager and is separate from the platform fee and dealing fee. The examples in the table below should give you a good idea of your investment's total cost, including OCF, platform fees, and dealing fees in the first year only. In each case, we've used a mid-risk ready-made portfolio or multi-asset fund. You can find out more about investing in funds and the various charges in our <a href="https://www.koody.co/investing/funds">Investing in Funds guide</a>.</p></div><p>‍<span><strong>Important:</strong></span><strong><br></strong>The table below shows annual charges of several investment platforms when you invest in funds as follows:<br></p><ul role="list"><li>£100 per month regular payment</li><li>£1,000 per month regular payment</li><li>£20,000 lump sum (your year’s ISA allowance)</li></ul><p>For regular payments, we assume you'll make 12 deals a year or one deal every month. For the lump sum, we assume you'll make one deal a year. A deal is either one of buying or selling an investment. It is also called a trade. We've used the colour red to indicate what platforms are more expensive compared to the others. This means the darker the shade of red, the more expensive the platform or offering. Dark red doesn't mean bad or too expensive. It just means the platform is more expensive when compared to the others. If you would like to see a breakdown of fees charged by each platform, have a look at our <a href="https://www.koody.co/investing/charges-directory">Platform Charges Directory</a>.<br>‍<br></p></div><div><p>Notes<a href="https://www.koody.co/investing/compare-shares-isa-charges"></a></p><ol role="list"><li>AJ Bell and Barclays are the only members of the 'Do It With Me' cohort that charge fund dealing fees. This partially explains why they have some of the highest costs for regular investments above.</li></ol><p>Most of the platforms with low OCFs offer just index trackers and ETFs, so don't get too excited about the cheaper offerings. Except you are interested in only trackers and ETFs, then please get excited. Remember, you can find more information on the various charges <a href="https://www.koody.co/investing/charges-directory">here</a> and view our share dealing ISA charges comparison table <a href="https://www.koody.co/investing/compare-shares-isa-charges">here.</a></p></div></div><div data-w-tab="Tab 3"><div><p>This is ideal for people who are either beginners or who want all the hard work done for them. With DIFM platforms, you'll often be presented with a limited set of investment choices based on your attitude to risk, investment goals and how much you plan to invest. DIFM platforms are mostly robo-advisers. Depending on the platform you choose, you may have access to formal financial advice.<br>‍<br>When you invest in a fund, please note the fund manager will add on various charges within the fund. A good representation of those charges is the OCF or Ongoing Charges Figure. It is an estimate of the portion of the total cost of your investment that goes to the fund manager and is separate from the platform fee and dealing fee. The examples in the table below should give you an idea of the total cost of your investment, including platform fees, dealing fees, OCF, and transaction costs (where we could find them). In each case, we've used a mid-risk ready-made portfolio or multi-asset fund. You can find out more about investing in funds and the various charges in our <a href="https://www.koody.co/investing/funds">Investing in Funds guide</a>.<br></p><p>‍<span><strong>Important:</strong></span><strong><br></strong>The table below shows annual charges of several investment platforms when you invest in funds as follows:<br></p><ul role="list"><li>£100 per month regular payment</li><li>£1,000 per month regular payment</li><li>£20,000 lump sum (your year’s ISA allowance)</li><li>£100,000 lump sum (if you already have lots of ISAs from previous years and are transferring in)</li></ul><div><p>For regular payments, we assume you'll make 12 deals a year or one deal every month. For lump sums, we assume you'll make one deal a year. A deal is either one of buying or selling an investment. It is also called a trade. We've used the colour red to indicate what platforms are more expensive compared to the others. This means the darker the shade of red, the more expensive the platform. Dark red doesn't mean bad or too expensive. It just means the platform is more expensive when compared to the others. If you would like to see a breakdown of fees charged by each platform, have a look at our <a href="https://www.koody.co/investing/charges-directory">Platform Charges Directory</a>.</p><p>Finally, it is important to let you know we show the costs which apply to the first year only. This is especially important because, with platforms like Santander, Wealth Horizon and Munnypot, your costs significantly reduce after the first year. You'll find all the details you need below.<br>‍</p></div></div><div><div><p><h2>Platform</h2></p><p><h2>Average OCF</h2></p><p><h2>£100 per month</h2></p><p><h2>£1,000 per month</h2></p><p><h2>£20,000</h2></p><p><h2>£100,000</h2></p></div><a href="https://etfmatic.com/" target="_blank"><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f06f62b4f711c6145304b86_etfmatic-logo.png" alt="etfmatic Logo" height="20" srcset="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f06f62b4f711c6145304b86_etfmatic-logo-p-500.png 500w, https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f06f62b4f711c6145304b86_etfmatic-logo.png 800w" sizes="(max-width: 479px) 100vw, (max-width: 991px) 11vw, (max-width: 1279px) 9vw, 106.65625px"></p></div></a><a href="https://eqinvestors.co.uk/individuals/invest/portfolios/low-cost/" target="_blank"><div><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f06f6fe15dc2880dcc5b5a0_EQ-Investors-logo.png" alt="EQ investors Logo" height="40"></p><p>1</p></div></div></a><a href="https://www.ig.com/uk/investments/smart-portfolios" target="_blank"><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f0310358d5f7c058c79af46_IG-logo.png" alt="IG Logo" height="40"></p></div></a><a href="https://www.moneyboxapp.com/" target="_blank"><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5ec9a34a06d25c2f641226c8_money-box-logo.svg" alt="Moneybox Logo" height="25"></p></div></a><a href="https://www.moneyfarm.com/uk/" target="_blank"><div><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f06f8aa42e7a85e0223a7eb_moneyfarm-logo.svg" alt="moneyfarm Logo" height="40"></p><p>2</p></div></div></a><a href="https://www.munnypot.com/" target="_blank"><div><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f06f9634f711c2f1e3050c5_munnypot-logo.png" alt="Munnypot Logo" height="20"></p><p>3</p></div></div></a><a href="https://www.netwealth.com/" target="_blank"><div><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f06fa52f2ec274ae2908300_Netwealth-logo.png" alt="netwealth Logo" height="25"></p><p>4</p></div></div></a><a href="https://www.nutmeg.com/fully-managed-portfolios" target="_blank"><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5ed5d42ae1889f04d625418e_nutmeg-logo.png" alt="Nutmeg logo" height="25"></p></div></a><a href="https://www.open-money.co.uk/" target="_blank"><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5ed5d57f6456312181a62063_open-money-logo.svg" alt="OpenMoney logo" height="45"></p></div></a><a href="https://withplum.com/" target="_blank"><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5ec9a17ba391aac5ea76daa7_plum-logo-dark.svg" alt="Plum logo" height="25"></p></div></a><a href="https://www.santander.co.uk/personal/savings-and-investments/investments" target="_blank"><div><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f06bbdf328260833f99bf31_Santander-logo.svg" alt="Santander logo" height="30" width="110"></p><p>3</p></div></div></a><a href="https://uk.scalable.capital/" target="_blank"><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f06ffade1fbe36a54066867_scalable-capital-logo.svg" alt="scalable capital logo" height="30"></p></div></a><a href="https://www.tpinvestor.com/" target="_blank"><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f07012de1fbe30528066bda_true-potential-logo.png" alt="True Potential logo" height="30"></p></div></a><a href="https://http//www.wealthhorizon.com/" target="_blank"><div><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f07012d7efa7b567367fa31_wealth-horizon-logo.png" alt="Wealth Horizon logo" height="30" srcset="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f07012d7efa7b567367fa31_wealth-horizon-logo-p-500.png 500w, https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f07012d7efa7b567367fa31_wealth-horizon-logo.png 684w" sizes="(max-width: 479px) 100vw, (max-width: 1439px) 11vw, 138.984375px"></p><p>3</p></div></div></a><a href="https://www.wealthify.com/" target="_blank"><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5ed5d3b6f31d3f40aa060754_wealthify-logo.svg" alt="Wealthify logo" height="35"></p></div></a><a href="https://www.wealthsimple.com/en-gb/" target="_blank"><div><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f07012c63666eefde802041_wealthsimple-logo.svg" alt="Wealthsimple logo" height="35"></p></div></a></div><div><p>Notes<a href="https://www.koody.co/investing/compare-shares-isa-charges"></a></p><ol role="list"><li>EQ Investors - Minimum investment of £1,000 lump sum or £250 per month regular payment</li><li>Moneyfarm - Minimum investment of £5,000 lump sum or £1,500 regular direct debit</li><li>Munnypot, Santander and Wealth Horizon all charge a one-off initial advice fee in the first year, so they will be cheaper in subsequent years where you do not have to pay this fee.</li><li>Netwealth - Minimum investment of £50,000.</li></ol><p>Most of the platforms in this category offer just index trackers and ETFs. That's why their OCF is quite low. Remember, you can find more information on the various charges <a href="https://www.koody.co/investing/charges-directory">here</a> and view our share dealing ISA charges comparison table <a href="https://www.koody.co/investing/compare-shares-isa-charges">here.</a></p></div></div></div></div></div></div></div><section id="subscribe-form"><div><div><div><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p><strong>Subscribe to Our Blog</strong></p><p>Tips and pointers delivered to your email every month!</p></div></div></div></div></section></div></div>]]>
            </description>
            <link>https://www.koody.co/investing/compare-funds-isa-charges</link>
            <guid isPermaLink="false">hacker-news-small-sites-24129843</guid>
            <pubDate>Wed, 12 Aug 2020 08:48:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Six more ways to improve your Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24129760">thread link</a>) | @SourceryNick
<br/>
August 12, 2020 | https://sourcery.ai/blog/explaining-refactorings-3/ | <a href="https://web.archive.org/web/*/https://sourcery.ai/blog/explaining-refactorings-3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure>
    <span>
      <a href="https://sourcery.ai/static/8bd4114da4db25ae197f53bad36c7c36/12609/code.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Python code" title="Photo by Chris Ried on Unsplash" src="https://sourcery.ai/static/8bd4114da4db25ae197f53bad36c7c36/4b190/code.jpg" srcset="https://sourcery.ai/static/8bd4114da4db25ae197f53bad36c7c36/e07e9/code.jpg 200w,
https://sourcery.ai/static/8bd4114da4db25ae197f53bad36c7c36/066f9/code.jpg 400w,
https://sourcery.ai/static/8bd4114da4db25ae197f53bad36c7c36/4b190/code.jpg 800w,
https://sourcery.ai/static/8bd4114da4db25ae197f53bad36c7c36/e5166/code.jpg 1200w,
https://sourcery.ai/static/8bd4114da4db25ae197f53bad36c7c36/b17f8/code.jpg 1600w,
https://sourcery.ai/static/8bd4114da4db25ae197f53bad36c7c36/12609/code.jpg 3000w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span>
    <figcaption>Photo by Chris Ried on Unsplash</figcaption>
  </figure>
<p>Writing clean, Pythonic code is all about making it as understandable, yet concise, as possible.
This is the third part of a series on Python refactorings, based on those that can be done
automatically by <a href="https://sourcery.ai/">Sourcery</a>. Catch the first part <a href="https://sourcery.ai/blog/explaining-refactorings-1/">here</a>, and
the second part <a href="https://sourcery.ai/blog/explaining-refactorings-2/">here</a>.</p>
<p>The focus of this series is on why these changes are good ideas, not just on how to do them.</p>
<h2>1. Add guard clause</h2>
<p>Deeply nested functions can be very difficult to understand. As you read them you
have to remember the conditions that hold for each level of nesting. This can be even
more difficult in Python, given that there are no brackets to help define conditional
blocks. An easy way to reduce nesting is to convert conditionals into guard clauses.</p>
<p>As an example let's look at this function:</p>
<div data-language="python"><pre><code><span>def</span> <span>should_i_wear_this_hat</span><span>(</span>self<span>,</span> hat<span>)</span><span>:</span>
    <span>if</span> <span>isinstance</span><span>(</span>hat<span>,</span> Hat<span>)</span><span>:</span>
        current_fashion <span>=</span> FASHION_API<span>.</span>get_fashion<span>(</span>FASHION_TYPE<span>.</span>HAT<span>)</span>
        weather_outside <span>=</span> self<span>.</span>look_out_of_window<span>(</span><span>)</span>
        is_stylish <span>=</span> self<span>.</span>evaluate_style<span>(</span>hat<span>,</span> current_fashion<span>)</span>
        <span>if</span> weather_outside<span>.</span>is_raining<span>:</span>
            <span>print</span><span>(</span><span>"Damn."</span><span>)</span>
            <span>return</span> <span>True</span>
        <span>else</span><span>:</span>
            <span>print</span><span>(</span><span>"Great."</span><span>)</span>
            <span>return</span> is_stylish
    <span>else</span><span>:</span>
        <span>return</span> <span>False</span></code></pre></div>
<p>This is quite hard to parse, given the two layers of nesting. When I get to the
<code>else</code> at the bottom I need to flick back and forth a bit between that and the
<code>if</code> test at the top before I've understood what's going on. This <code>if</code>
condition is a check for an edge case, where something that isn't a hat is
passed in. Since we just return <code>False</code> here it's a perfect place to
introduce a guard clause:</p>
<div data-language="python"><pre><code><span>def</span> <span>should_i_wear_this_hat</span><span>(</span>self<span>,</span> hat<span>)</span><span>:</span>
    <span>if</span> <span>not</span> <span>isinstance</span><span>(</span>hat<span>,</span> Hat<span>)</span><span>:</span>
        <span>return</span> <span>False</span>

    current_fashion <span>=</span> get_fashion<span>(</span><span>)</span>
    weather_outside <span>=</span> self<span>.</span>look_out_of_window<span>(</span><span>)</span>
    is_stylish <span>=</span> self<span>.</span>evaluate_style<span>(</span>hat<span>,</span> current_fashion<span>)</span>
    <span>if</span> weather_outside<span>.</span>is_raining<span>:</span>
        <span>print</span><span>(</span><span>"Damn."</span><span>)</span>
        <span>return</span> <span>True</span>
    <span>else</span><span>:</span>
        <span>print</span><span>(</span><span>"Great."</span><span>)</span>
        <span>return</span> is_stylish</code></pre></div>
<p>We add a guard clause by inverting the condition and returning immediately.
The edge case is now taken care of at the start of the function and I don't have to
worry about it any more. </p>
<p>Having reduced the level of nesting, the rest of the function is now easier to read.
Whether to add a guard clause is sometimes subjective. For really short functions it
may not be worth doing. Where functions are longer or more complex it can often be
a useful tool.</p>
<h2>2. Swap if/else to remove empty if body</h2>
<p>One pattern we sometimes see is a conditional where nothing happens in the main body,
and all of the action is in the <code>else</code> clause.</p>
<div data-language="python"><pre><code><span>if</span> location <span>==</span> OUTSIDE<span>:</span>
    <span>pass</span>
<span>else</span><span>:</span>
    take_off_hat<span>(</span><span>)</span></code></pre></div>
<p>In this case we can make the code shorter and more concise by swapping the main body
and the <code>else</code> around. We have to make sure to invert the conditional, then the logic
from the <code>else</code> clause moves into the main body.</p>
<div data-language="python"><pre><code><span>if</span> location <span>!=</span> OUTSIDE<span>:</span>
   take_off_hat<span>(</span><span>)</span>
<span>else</span><span>:</span>
   <span>pass</span></code></pre></div>
<p>We then have an <code>else</code> clause which does nothing, so we can remove it.</p>
<div data-language="python"><pre><code><span>if</span> location <span>!=</span> OUTSIDE<span>:</span>
    take_off_hat<span>(</span><span>)</span></code></pre></div>
<p>This is easier to read, and the intent of the conditional is clearer. When reading
the code I don't have to mentally invert it to understand it, since that has been done for me.</p>
<h2>3. Merge append into list declaration</h2>
<p>When declaring a list and filling it up with values one way that can come naturally
is to declare it as empty and then append to it.</p>
<div data-language="python"><pre><code>hats_i_own <span>=</span> <span>[</span><span>]</span>
hats_i_own<span>.</span>append<span>(</span><span>'panama'</span><span>)</span>
hats_i_own<span>.</span>append<span>(</span><span>'baseball_cap'</span><span>)</span>
hats_i_own<span>.</span>append<span>(</span><span>'bowler'</span><span>)</span></code></pre></div>
<p>This can be done in place, shortening the code and making the intent more explicit.
Now I just need to glance at one line to see that I'm filling a variable with hats,
rather than four.</p>
<div data-language="python"><pre><code>hats_i_own <span>=</span> <span>[</span><span>'panama'</span><span>,</span> <span>'baseball_cap'</span><span>,</span> <span>'bowler'</span><span>]</span></code></pre></div>
<p>Doing it this way is also slightly more performant since it avoids the function calls to <code>append</code>.
The same holds true for filling up other collection types like sets and dictionaries.</p>
<h2>4. Move assignments closer to their usage</h2>
<p>The scope of local variables should always be as tightly defined as possible and
practicable.</p>
<p>This means that:</p>
<ul>
<li>You don't have to keep the variable in your working memory through the parts of
the function where it's not needed. This cuts down on the cognitive load of
understanding your code.</li>
<li>If code is in coherent blocks where variables are declared and used together, it
makes it easier to split functions apart, which can lead to shorter, easier to
understand methods.</li>
<li>If variables are declared far from their usage, they can become stranded. If the
code where they are used is later changed or removed unused variables can be left
sitting around, complicating the code unnecessarily.</li>
</ul>
<p>Let's take another look at the earlier example.</p>
<div data-language="python"><pre><code><span>def</span> <span>should_i_wear_this_hat</span><span>(</span>self<span>,</span> hat<span>)</span><span>:</span>
    <span>if</span> <span>not</span> <span>isinstance</span><span>(</span>hat<span>,</span> Hat<span>)</span><span>:</span>
        <span>return</span> <span>False</span>

    current_fashion <span>=</span> get_fashion<span>(</span><span>)</span>
    weather_outside <span>=</span> self<span>.</span>look_out_of_window<span>(</span><span>)</span>
    is_stylish <span>=</span> self<span>.</span>evaluate_style<span>(</span>hat<span>,</span> current_fashion<span>)</span>
    <span>if</span> weather_outside<span>.</span>is_raining<span>:</span>
        <span>print</span><span>(</span><span>"Damn."</span><span>)</span>
        <span>return</span> <span>True</span>
    <span>else</span><span>:</span>
        <span>print</span><span>(</span><span>"Great."</span><span>)</span>
        <span>return</span> is_stylish</code></pre></div>
<p>Here the <code>is_stylish</code> variable isn't actually needed if the weather is rainy.
It could be moved inside the <code>else</code> clause. This means we can also move the
<code>current_fashion</code> variable, which is only used here.
You do need to check that these variables aren't used
later in the function, which is easier if functions are kept short and sweet.</p>
<p>Moving the assignment to <code>current_fashion</code> also avoids a function call when the
weather is raining, which could lead to a performance improvement if it's an expensive call. </p>
<div data-language="python"><pre><code><span>def</span> <span>should_i_wear_this_hat</span><span>(</span>self<span>,</span> hat<span>)</span><span>:</span>
    <span>if</span> <span>not</span> <span>isinstance</span><span>(</span>hat<span>,</span> Hat<span>)</span><span>:</span>
        <span>return</span> <span>False</span>

    weather_outside <span>=</span> self<span>.</span>look_out_of_window<span>(</span><span>)</span>
    <span>if</span> weather_outside<span>.</span>is_raining<span>:</span>
        <span>print</span><span>(</span><span>"Damn."</span><span>)</span>
        <span>return</span> <span>True</span>
    <span>else</span><span>:</span>
        <span>print</span><span>(</span><span>"Great."</span><span>)</span>
        current_fashion <span>=</span> get_fashion<span>(</span><span>)</span>
        is_stylish <span>=</span> self<span>.</span>evaluate_style<span>(</span>hat<span>,</span> current_fashion<span>)</span>
        <span>return</span> is_stylish</code></pre></div>
<p>We could actually then go one step further and inline the <code>is_stylish</code> variable.
This shows how small refactorings can often build on one another and lead to further
improvements.</p>
<div data-language="python"><pre><code><span>def</span> <span>should_i_wear_this_hat</span><span>(</span>self<span>,</span> hat<span>)</span><span>:</span>
    <span>if</span> <span>not</span> <span>isinstance</span><span>(</span>hat<span>,</span> Hat<span>)</span><span>:</span>
        <span>return</span> <span>False</span>

    weather_outside <span>=</span> self<span>.</span>look_out_of_window<span>(</span><span>)</span>
    <span>if</span> weather_outside<span>.</span>is_raining<span>:</span>
        <span>print</span><span>(</span><span>"Damn."</span><span>)</span>
        <span>return</span> <span>True</span>
    <span>else</span><span>:</span>
        <span>print</span><span>(</span><span>"Great."</span><span>)</span>
        current_fashion <span>=</span> get_fashion<span>(</span><span>)</span>
        <span>return</span> self<span>.</span>evaluate_style<span>(</span>hat<span>,</span> current_fashion<span>)</span></code></pre></div>
<h2>5. Use items() to directly unpack dictionary values</h2>
<p>When iterating over a dictionary a good tip is that you can use <code>items()</code> to let
you access the keys and values at the same time. This lets you transform this:</p>
<div data-language="python"><pre><code>hats_by_colour <span>=</span> <span>{</span><span>'blue'</span><span>:</span> <span>[</span><span>'panama'</span><span>,</span> <span>'baseball_cap'</span><span>]</span><span>}</span>
<span>for</span> hat_colour <span>in</span> hats_by_colour<span>:</span>
    hats <span>=</span> hats_by_colour<span>[</span>hat_colour<span>]</span>
    <span>if</span> hat_colour <span>in</span> self<span>.</span>favourite_colours<span>:</span>
        think_about_wearing<span>(</span>hats<span>)</span></code></pre></div>
<p>into this:</p>
<div data-language="python"><pre><code>hats_by_colour <span>=</span> <span>{</span><span>'blue'</span><span>:</span> <span>[</span><span>'panama'</span><span>,</span> <span>'baseball_cap'</span><span>]</span><span>}</span>
<span>for</span> hat_colour<span>,</span> hats <span>in</span> hats_by_colour<span>.</span>items<span>(</span><span>)</span><span>:</span>
    <span>if</span> hat_colour <span>in</span> self<span>.</span>favourite_colours<span>:</span>
        think_about_wearing<span>(</span>hats<span>)</span></code></pre></div>
<p>This saves us the line that we used to assign to <code>hats</code>, incorporating it into the for loop.
The code now reads more naturally, with a touch less duplication.</p>
<h2>6. Simplify sequence comparison</h2>
<p>Something we often do is check whether a list or sequence has elements before we try
and do something with it.</p>
<div data-language="python"><pre><code><span>if</span> <span>len</span><span>(</span>list_of_hats<span>)</span> <span>&gt;</span> <span>0</span><span>:</span>
    hat_to_wear <span>=</span> choose_hat<span>(</span>list_of_hats<span>)</span></code></pre></div>
<p>A Pythonic way of doing this is just to use the fact that Python lists and sequences evaluate
to <code>True</code> if they have elements, and <code>False</code> otherwise.</p>
<p>This means we can write the above code more simply as: </p>
<div data-language="python"><pre><code><span>if</span> list_of_hats<span>:</span>
    hat_to_wear <span>=</span> choose_hat<span>(</span>list_of_hats<span>)</span></code></pre></div>
<p>Doing it this way is a convention, set out in Python's <a href="https://www.python.org/dev/peps/pep-0008/">PEP8</a> style guide.
Once you've gotten used to doing it this way it does make the code slightly easier to read and
a bit less cluttered.</p>
<h2>Conclusion</h2>
<p>As mentioned, each of these is a refactoring that <a href="https://sourcery.ai/">Sourcery</a> can automatically perform for you.
We're planning on expanding this blog series out and linking them in as additional documentation,
with the aim of turning Sourcery into a great resource for learning how to improve your Python skills.
If you have any thoughts on how to improve Sourcery or its documentation please do <a href="mailto:hello@sourcery.ai">email us</a> or
hit me up on <a href="https://twitter.com/nthapen">Twitter</a> </p></div></div>]]>
            </description>
            <link>https://sourcery.ai/blog/explaining-refactorings-3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24129760</guid>
            <pubDate>Wed, 12 Aug 2020 08:32:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Vimproved ModalEdit 2.0 for VS Code]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24129743">thread link</a>) | @johtela
<br/>
August 12, 2020 | https://johtela.github.io/vscode-modaledit/docs/presets/vim.html | <a href="https://web.archive.org/web/*/https://johtela.github.io/vscode-modaledit/docs/presets/vim.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<p><img src="https://johtela.github.io/vscode-modaledit/docs/images/pooh.jpg" alt="" width="375" height="403">
Providing full Vim emulation was not originally a goal of ModalEdit. The idea of
the extension is to provide an engine that allows the user to <a href="https://johtela.github.io/vscode-modaledit/docs/README.html#configuration">map any key
combination to any command provided by VS Code</a>.
However, most users equate modal editing with Vim and are familiar with its
default keybindings. Vim users really love the powerful key sequences that
combine editing operations with cursor motions or text ranges.</p>
<p>ModalEdit has also evolved by taking inspiration from Vim. Many capabilities
were added with the motive to enable some Vim feature that was previously not
possible to implement. With version 2.0 ModalEdit's functionality is now
extensive enough to build a semi-complete Vim emulation. So, here we go...</p>
<p>Adding Vim keybindings as optional presets serves two purposes: it lowers the
barrier to entry for Vim users who don't want to spend the time defining
bindings from ground up. Secondly, Vim presets serve as an example to show
how you can build sophisticated command sequences using the machinery provided
by ModalEdit.</p>
<p><img src="https://johtela.github.io/vscode-modaledit/docs/images/import-preset.png" alt="importing presets" width="553" height="94">
If you are not interested on how the Vim keybindings are implemented and just
want to use them, you can skip this discussion. Just import the presets by
pressing <key>Ctrl</key>+<key>Shift</key>+<key>P</key> and running command
<strong>ModalEdit: Import preset keybindings</strong>. You will be presented a choice to
import either Vim bindings or any presets that you have created yourself. If
you are planning to customize the bindings, or create Vim-style commands from
scratch, this document gives you pointers how to go about with that.</p>
<h2 id="game-plan">Game Plan</h2>
<p>We start with basic motion commands which are mostly straightforward to
implement. Motions have two modes of operation: normal mode (moving cursor), and
visual mode (extending selection). We make sure all motions work correctly in
both modes. This allows us to reuse these keybindings when implementing more
advanced operations. Our goal is to avoid repetition by building complex
sequences from primitive commands.</p>
<p>In Vim, there are multiple key sequences for a same operation. For example,
you can convert a paragraph upper case by typing
<key>g</key><key>U</key><key>i</key><key>p</key>. You can perform the same
operation using visual mode by typing <key>v</key><key>i</key><key>p</key><key>U</key>.
The trick we use is to convert key sequences that operate on character, word,
line, paragraph, etc. to analagous key sequences that use visual mode. We can
implement all the editing commands just to work on active selection and reuse
these commands with the other key combinations. Consequently, command definition
becomes a string mapping problem. Since we can use JavaScript to expressions to
do string manipulation, these mappings are easy to formulate.</p>
<p><img src="https://johtela.github.io/vscode-modaledit/docs/images/vim-uppercase.gif" alt=""></p>
<p>Many ways to skin a cat...</p>
<h2 id="motions-in-normal-mode">Motions in Normal Mode</h2>
<p>The list of available cursor motion commands is shown below.</p>
<div>
<table><thead>
<tr>
<th>Keys</th>
<th>Cursor Motion</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Enter</code></td>
<td>Beginning of next line</td>
</tr>
<tr>
<td><code>Space</code></td>
<td>Next character on right</td>
</tr>
<tr>
<td><code>h</code></td>
<td>Left</td>
</tr>
<tr>
<td><code>j</code></td>
<td>Down</td>
</tr>
<tr>
<td><code>k</code></td>
<td>Up</td>
</tr>
<tr>
<td><code>l</code></td>
<td>Right</td>
</tr>
<tr>
<td><code>0</code></td>
<td>First character on line</td>
</tr>
<tr>
<td><code>$</code></td>
<td>Last character on line</td>
</tr>
<tr>
<td><code>^</code></td>
<td>First non-blank character on line</td>
</tr>
<tr>
<td><code>g_</code></td>
<td>Last non-blank character on line</td>
</tr>
<tr>
<td><code>gg</code></td>
<td>First charater in file</td>
</tr>
<tr>
<td><code>G</code></td>
<td>Last character in file</td>
</tr>
<tr>
<td><code>w</code></td>
<td>Beginning of next word</td>
</tr>
<tr>
<td><code>e</code></td>
<td>End of next word</td>
</tr>
<tr>
<td><code>b</code></td>
<td>Beginning of previous word</td>
</tr>
<tr>
<td><code>W</code></td>
<td>Beginning of next alphanumeric word</td>
</tr>
<tr>
<td><code>B</code></td>
<td>Beginning of previous alphanumeric word</td>
</tr>
<tr>
<td><code>H</code></td>
<td>Top of the screen</td>
</tr>
<tr>
<td><code>M</code></td>
<td>Middle of the screen</td>
</tr>
<tr>
<td><code>L</code></td>
<td>Bottom of the screen</td>
</tr>
<tr>
<td><code>%</code></td>
<td>Matching bracket</td>
</tr>
</tbody>
</table>
</div><p>Now, lets implement all the keybindings listed above.</p>

<pre><code>{
    <span>"keybindings"</span>: {
</code></pre>
<p>Cursor can be advanced in a file with with enter and space. These are not
technically motion commands but included for compatibility.</p>

<pre><code>        "\n": [
            "cursorDown",
            {
                "command": "cursorMove",
                "args": {
                    "to": "wrappedLineFirstNonWhitespaceCharacter"
                }
            }
        ],
        " ": "cursorRight",
</code></pre>
<p>Move cursor up/down/left/right.</p>

<pre><code>        "h": "cursorLeft",
        "j": "cursorDown",
        "k": "cursorUp",
        "l": "cursorRight",
</code></pre>
<p>Move to first/last character on line. These work also in visual mode.</p>

<pre><code>        "0": {
            "command": "cursorMove",
            "args": "{ to: 'wrappedLineStart', select: __selecting }"
        },
        "$": {
            "command": "cursorMove",
            "args": "{ to: 'wrappedLineEnd', select: __selecting }"
        },
</code></pre>
<p>Move to first/last non-blank character on line. Also these ones use the
<code>__selecting</code> flag to check whether we are in visual mode.</p>

<pre><code>        "^": {
            "command": "cursorMove",
            "args": "{ to: 'wrappedLineFirstNonWhitespaceCharacter', select: __selecting }"
        },
        "g": {
            "_": {
                "command": "cursorMove",
                "args": "{ to: 'wrappedLineLastNonWhitespaceCharacter', select: __selecting }"
            },
</code></pre>
<p>Moving to the beginning of file is defined as a conditional command to make
it work in visual mode.</p>

<pre><code>            "g": {
                "condition": "__selecting",
                "true": "cursorTopSelect",
                "false": "cursorTop"
            },
</code></pre>
<h2 id="other-commands-starting-with-key-g-key">Other Commands Starting with <key>g</key></h2>
<p>Commands starting with <key>g</key> key are bit inconsistent in Vim. Some of
them are basic motion commands, such as <key>g</key><key>_</key> and
<key>g</key><key>g</key>, some are editing commands like <key>g</key><key>J</key>
and <key>g</key><key>U</key>, and some switch between tabs 🤷‍♂️. Since we have to
define all bindings with the same prefix in same place, we take a detour and add
these commands before continuing with rest of the motion commands.</p>
<div>
<table><thead>
<tr>
<th>Keys</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>gJ</code></td>
<td>Join lines without space in between</td>
</tr>
<tr>
<td><code>gu</code>&lt;<em>motion</em>&gt;</td>
<td>Convert text specified by &lt;<em>motion</em>&gt; to lowercase</td>
</tr>
<tr>
<td><code>gU</code>&lt;<em>motion</em>&gt;</td>
<td>Convert text specified by &lt;<em>motion</em>&gt; to uppercase</td>
</tr>
<tr>
<td><code>gt</code></td>
<td>Go to next tab</td>
</tr>
<tr>
<td><code>gT</code></td>
<td>Go to previous tab</td>
</tr>
</tbody>
</table>
</div><p>Joining lines without space is done by deleting a character after the join
command.</p>

<pre><code>            "J": [
                "editor.action.joinLines",
                "deleteRight"
            ],
</code></pre>
<p>The lower/uppercase transition works with any motion, but since we have not
defined all of them yet, we explain the command structure
<a href="#editing-with-motions">later in the document</a>.
The structure we use here is exactly the same as with <key>d</key> command, for
example.</p>

<pre><code>            "u,U": {
                "id": 1,
                "help": "Change case with motion",
                "u,U": {
                    "command": "modaledit.typeNormalKeys",
                    "args": "{ keys: __cmd.slice(0, -3) + 'V' + __rcmd[0] }"
                },
                "h,j,k,l,w,e,b,W,B,%": {
                    "command": "modaledit.typeNormalKeys",
                    "args": "{ keys: 'v' + __cmd.slice(0, -3) + __rcmd[0] + __rcmd[1] }"
                },
                "^,$,0,G,H,M,L": {
                    "command": "modaledit.typeNormalKeys",
                    "args": "{ keys: 'v' + __rcmd[0] + __rcmd[1] }"
                },
                "g": {
                    "g,_": {
                        "command": "modaledit.typeNormalKeys",
                        "args": "{ keys: 'v' + __rcmd[1] + __rcmd[0] + __rcmd[2] }"
                    }
                },
                "f,t,F,T": {
                    "help": "Do until _",
                    " -~": {
                        "command": "modaledit.typeNormalKeys",
                        "args": "{ keys: 'v' + __rcmd[1] + __rcmd[0] + __rcmd[2] }"
                    }
                },
                "a,i": {
                    "help": "Do around/inside _",
                    "w,p,b,B,t, -/,:-@,[-`,{-~": {
                        "command": "modaledit.typeNormalKeys",
                        "args": "{ keys: 'v' + __rcmd[1] + __rcmd[0] + __rcmd[2] }"
                    }
                },
                "`,'": {
                    "help": "Do until mark _",
                    "a-z": {
                        "command": "modaledit.typeNormalKeys",
                        "args": "{ keys: 'v' + __rcmd[1] + __rcmd[0] + __rcmd[2] }"
                    }
                }
            },
</code></pre>
<p><key>g</key><key>t</key> and <key>g</key><key>T</key> switch to next/previous
tab.</p>

<pre><code>            "t": "workbench.action.nextEditor",
            "T": "workbench.action.previousEditor"
        },
</code></pre>
<h2 id="rest-of-the-motion-commands">Rest of the Motion Commands</h2>
<p>Now we can complete the list of basic motion commands. This one movest the
cursor at the end of the file and selects the range, if visual mode is on.</p>

<pre><code>        "G": {
            "condition": "__selecting",
            "true": "cursorBottomSelect",
            "false": "cursorBottom"
        },
</code></pre>
<p>The logic of separating words is bit different in VS Code and Vim, so we will
not try to imitate Vim behavior here. These keys are mapped to the most similar
motion available. The <key>W</key> and <key>B</key> commands skip separator
characters, and move to the start of the next/previous alphanumeric word.</p>

<pre><code>        "w": "cursorWordStartRight",
        "e": "cursorWordEndRight",
        "b": "cursorWordStartLeft",
        "W": {
            "command": "cursorWordStartRight",
            "repeat": "__char.match(/\\W/)"
        },
        "B": {
            "command": "cursorWordStartLeft",
            "repeat": "__char.match(/\\W/)"
        },
</code></pre>
<p>Moving cursor to the top, middle, and bottom of the screen is mapped to
<key>H</key> (high), <key>M</key> (middle), and <key>L</key> (low) keys. These
mappings also work in visual mode.</p>

<pre><code>        "H": {
            "command": "cursorMove",
            "args": "{ to: 'viewPortTop', select: __selecting }"
        },
        "M": {
            "command": "cursorMove",
            "args": "{ to: 'viewPortCenter', select: __selecting }"
        },
        "L": {
            "command": "cursorMove",
            "args": "{ to: 'viewPortBottom', select: __selecting }"
        },
</code></pre>
<p>Move to matching bracket command is somewhat challenging to implement
consistently in VS Code. This is due to the problem that there are no commands
that do exactly what Vim's motions do. In normal mode we call the
<code>jumpToBracket</code> command which works if the cursor is on top of a bracket, but
does not allow for the selection to be extended. In visual mode we use the
<code>smartSelect.expand</code> command instead to extend the selection to whatever
syntactic scope is above the current selection. In many cases, it is more useful
motion than jumping to a matching bracket, but using it means that we are
diverging from Vim's …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://johtela.github.io/vscode-modaledit/docs/presets/vim.html">https://johtela.github.io/vscode-modaledit/docs/presets/vim.html</a></em></p>]]>
            </description>
            <link>https://johtela.github.io/vscode-modaledit/docs/presets/vim.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24129743</guid>
            <pubDate>Wed, 12 Aug 2020 08:30:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: NeuralCam Live – Using ML to Turn iPhones into Smart Webcams]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24129714">thread link</a>) | @soonpls
<br/>
August 12, 2020 | https://neural.cam/news/ | <a href="https://web.archive.org/web/*/https://neural.cam/news/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div id="main">
    <div>
      <div>
        <div role="article">

          <div>
            

<p>Hey everyone, <br>

Today is a big day for NeuralCam. We have three announcements to make: some news about NeuralCam as a company, a major update for our NightMode app and a brand new <strong>Smart Camera app.</strong>
</p><br>
<h3>
NeuralCam - building Smart Camera Apps
</h3>
<div><p>Let’s start by talking a bit about cameras and AI. </p><p>

At NeuralCam, we think that one of the biggest leaps in technology over the past years has been the advances Deep Learning brought in the area of Computer Vision. It gives computers the ability to see - to understand patterns, images and video similarly to how people do.
 </p></div>



<p>Ultimately, we think this technology will give birth to a new category of cameras - <b>Smart Cameras</b> - that will have a profound impact on every activity that involves capturing and processing images.
</p>

<p>We see this change similar to the transformation from classic cellular phones to the modern smartphone we witnessed 10 years ago. We believe that martphones themselves seem to be the ideal smart camera platform: they have high quality cameras and enough processing power to run modern AI algorithms on-device.
</p>
<p><img src="https://neural.cam/news/content/smartcameras.png">
</p>

<p>So, we can all have our own personal smart cameras in our pockets, all that’s needed is the right ML software. This ML software is what we call Smart Camera Apps, and these are the type of apps we’re building at NeuralCam.
</p>

<p>Whenever we see a visual task we might say “there’s a Smart Cam App for that”. We’ve been doing a lot of research and prototyping and we’re more and more confident that smart camera apps will play a key role in every industry, from Education through Healthcare to Entertainment, and we can’t wait to contribute something in each of these areas.

</p>

<p><img src="https://neural.cam/news/content/smartapps.png">
</p>

<p>However, the first category that is naturally most likely to change is almost analogous to the camera itself: photography and videography. Thus, this is what we’ve decided to start with, building AI powered Photo &amp; Video apps over the next few years. 
</p>

<p>Our first smart photo app we’ve launched is the NeuralCam NightMode app, which brought Night Mode to all iPhones and all iPhone camera lenses. But, NeuralCam is more than the Night Mode app. We think of NeuralCam as a range of smart camera apps in different categories for various use cases. 
</p>



<p>So, one of the things we did is update our brand to reflect this change. This is the first thing we’d like to show you today, a fresh NeuralCam: 
</p>

<p><img src="https://neural.cam/news/content/nclogo.png"></p>

<p>And this is the new NeuralCam NightMode:</p>

<p><img src="https://neural.cam/news/content/NightModeLogo.png">
<br>
</p>
<p>Ok, so that’s the story of NeuralCam - the company. The second thing we want to show you is an update to our NightMode app. 

</p>

<h3 id="when-they-ghost-mid-project">NeuralCam NightMode</h3>

<p>We <a href="https://www.producthunt.com/posts/neuralcam" target="_blank">launched</a> our first smart camera app, NeuralCam NightMode, about a year ago, last August. It brought NightMode to the iPhone and the response from the users and critics <a href="https://9to5mac.com/2019/08/30/iphone-camera-app-for-night-shots/" target="_blank">was amazing.</a>
</p>

<p>We’ve been <a href="https://petapixel.com/2019/08/28/neuralcam-night-photo-app-brings-ai-powered-low-light-mode-to-iphones/" target="_blank">covered</a> <a href="https://bgr.com/2019/10/25/iphone-11-pro-camera-review-features-with-night-mode-app/" target="_blank">in many</a> <a href="https://bgr.com/2019/08/30/iphone-11-release-date-soon-specs-camera-night-mode/" target="_blank">major</a> <a href="https://thenextweb.com/apple/2019/08/29/this-app-uses-ai-to-add-a-pixel-style-night-photography-mode-to-your-iphone/" target="_blank">press</a> <a href="https://www.slashgear.com/neuralcam-iphone-app-uses-ai-to-capture-bright-images-at-night-26588672/" target="_blank">publications</a>, got lots of love letters from users, and been recognized as the best NightMode app out there. 
</p>
<p>While Apple has launched a built-in night mode on the iPhone 11 in the meantime, NeuralCam continues to be the NightMode solution for devices or iPhone cameras without a native NightMode - like the newly launched iPhone SE or even the UltraWide &amp; Selfie cameras on the iPhone 11 Pro. </p>
<p>Since its launch, people have used NeuralCam NightMode to take more than 10M low light photos. 
</p>

<div><p><img src="https://neural.cam/news/content/10M.png"></p></div>

<p>Now, with a major update, we have made our NightMode app even better: we've made some major improvements to our algorithm so that it supports higher resolutions on older devices too; we’ve updated the UI to be in-line with the new NeuralCam brand and we’ve officially added iPad support.</p><p>This is how the update NeuralCam NightMode app looks like on an iPad:</p>
<p><img src="https://neural.cam/news/content/nmupdate.png">
<br>
</p>

<h3 id="when-they-ghost-mid-project">NeuralCam Live</h3>

<p>The popularity of video calls has exploded lately. In the current global context, most of us use video calls a lot for both getting our job done or to keep in touch with loved ones. For something used as often, we really need to have the best possible tools. 

</p>

<p>Looking at the things out there, we realized that there’s a weak link in all this video call experience, and it’s the webcams. </p><p>We’ve got laptop webcams (quite bad), dedicated webcams (a bit better) or apps that let you use your iPhone as a webcam (best quality). However, these products really only differ from one another in the resolution of the video they provide. 
</p>

<p><img src="https://neural.cam/news/content/webcams.png">
<br>
</p>

<p> The problem with webcams is that they’re mostly the same as they were 10 years ago, they do the same thing only slightly better. In the meantime, this cool new technology called Deep Learning came along which could add a whole new dimension to webcams and possibly change the whole video call experience - but nobody uses it. 

</p>

<p>
It turns out that one of the main reasons for Deep Learning not being used with webcams is that no webcam has the processing power required to run the required ML algorithms. Except there is one device which, when converted to a webcam, could do all this: the iPhone in our pocket.
</p>

<p>It’s got one of the best cameras in the smartphone industry and with its fast processors and dedicated machine learning hardware, it is capable of running even video processing machine learning algorithms in real-time. It just needs the right SmartCam App software to do all this. 
  </p><p>We've built this software - we call it NeuralCam Live and it turns the iPhone into the <strong>world’s smartest webcam.</strong>
  </p>
<div><p><img src="https://neural.cam/news/content/LiveLogo.png"></p></div>







<p>
	Ok, so how are we going to do that?
</p>
<br>

<h3 id="when-they-ghost-mid-project">Technology</h3>

<p><img src="https://neural.cam/news/content/tech.png">
<br>
</p>

<p>First, we need the software that connects the iPhone to the laptop and makes it appear just like a regular webcam when connected through a USB cable. 
</p>

<p>This software has two modules: the first one is an iOS app that provides the webcam functionality, while the second one is a plugin that’s installed on the laptop to make the iOS app appear as a webcam. Once you install both of these components, all you have to do is select the NeuralCam Live Camera in Zoom, Google Meet or your video call platform of choice.
</p>

<p>So, that was quite easy, now comes the fun part. </p><p><img src="https://neural.cam/news/content/engine.png">
<br>
</p>

<p> The second component we need is the machine learning software to make our smart webcam... well, smart. We call it the <b>LiveEngine</b> </p>

<p>Machine learning, as a generic technology, can help us in two ways when it comes to webcams: we can use it to recognize things in the video feed or generate new video content, improved in some way. </p><p>We’ve developed multiple machine learning modules, some proprietary, some built on top of existing CoreML models and we’ve grouped them in three different machine learning frameworks that cover both video generation and analysis: the Style Framework, the Enhance Framework and the Gesture Framework. Let’s take a quick look at each of these. 
</p>

<p><img src="https://neural.cam/news/content/f_style.png">
<br>
</p>


<p>The <b>Style Framework</b> is a deep learning-based machine learning framework that edits video similarly to a professional colorist. 
</p>
<p>Its Neural Nets were trained on images edited by hand by professionals in a range of different editing styles. The results are quite amazing, generating pro-looking videosf, very close in terms of style to the professionally edited frames it was trained on and it does all this in real-time at 30fps locally, on the user’s iPhone.
</p>
<p><img src="https://neural.cam/news/content/f_enhance.png">
<br>
</p>

<p>The <b>Enhance Framework</b> contains our set of machine learning models that can enhance a video in a bunch of different ways. </p>

<p>Our real-time video denoising and brightening models in this category achieve levels of quality and performance that are much better than traditional algorithms and make features such as video low light enhancement or face smoothing possible.
</p>
<p><img src="https://neural.cam/news/content/f_recognition.png">
<br>
</p>

<p>The <b>Recognition Framework</b> is the part of our LiveEngine that is meant to make our smart camera apps understand what they “see”. </p>

<p>It uses a combination of machine learning models provided by the iPhone SDK and adds a number of proprietary elements to detect faces, user gestures or other different patterns in the live video feed. In the app, we can use this type of technology to blur unwanted gestures or guide you to set up an ideal environment for a call.
</p>

<p>Together, all these elements form what we call the LiveEngine - the ever-evolving software module that makes NeuralCam Live a smart webcam.
</p>

<h3>Features</h3>

<p><img src="https://neural.cam/news/content/NCFeats.png">
<br>
</p>

<p>Now, let’s take a look at the actual product. </p>
<p>The iPhone app exposes all of the functionality of the smart iPhone webcam in a simple layout, most of the features can be accessed by just tapping a button on the screen. It also shows a nice preview of the current video feed. 
</p>
<p><img src="https://neural.cam/news/content/smartwebcam.png">
<br>
</p>


<p>So, using all this technology, what more can a smart webcam do compared to a traditional webcam? 
</p>

<p>In terms of the outcome they provide to the user, we’ve realized that most of the AI features we’ve built fit nicely in two categories: making you look better and helping you avoid embarrassing mistakes.
</p>

<p>Let’s take a look at these features one-by-one: 
</p>

<p><img src="https://neural.cam/news/content/fiq.png">
<br>
</p>

<h4>Face &amp; Image Quality Meter
</h4>



<p>The Face &amp; Image Quality Meter detects the amount of face lighting, type of face position and background and displays an overall Face Image Quality score. 
</p>

<p>It helps you set up an optimal video-call environment and helps you avoid making typical mistakes, such as sitting with your back towards a bright window or in an unfavorable low angle.
</p>
<p><img src="https://neural.cam/news/content/styles.png">
  <br>
  </p>

<h4>Pro Video Styling</h4>

<p>
  
  Using the Style Framework, NeuralCam Live edits the video feed like a professional colorist would, in a range of different styles. The end-result is a more impactful look, allowing you to choose the style that best fits your mood, the type of call or the environment you're in.

</p>
<p><img src="https://neural.cam/news/content/lowlight.png">
  <br>
  </p>

<h4>
  
  Low-light Mode
</h4>

<p>It wouldn't be a NeuralCam product without a Night Mode, right? </p>
<p>NeuralCam Live’s Low Light Mode brightens up your video with a similar (though a lot more lightweight) technique used in our Night Mode photo app. It allows you to look good in video calls even in low light settings, a gentle light from your monitor is usually enough to provide a nice video feed. 
</p>

<p>
  
  And just in case you need to light up things even more, you can use the face-following Ring Light …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neural.cam/news/">https://neural.cam/news/</a></em></p>]]>
            </description>
            <link>https://neural.cam/news/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24129714</guid>
            <pubDate>Wed, 12 Aug 2020 08:25:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon’s business model meets Sweden’s labor unions]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 145 (<a href="https://news.ycombinator.com/item?id=24129279">thread link</a>) | @ptr
<br/>
August 11, 2020 | https://www.politico.eu/article/amazons-cut-price-culture-meets-swedens-unions/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/amazons-cut-price-culture-meets-swedens-unions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
							
							

							
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div><p>It's Sweden's storied worker protections and climate-conscious citizens welcoming Amazon's ruthless drive for low prices. What could go wrong?</p>
<p>Stockholm is preparing for a tug-of-war with one of the world’s most powerful companies — which just announced its entry into the Swedish market — and hopes that its arrival will mean the country of 10 million will be able to change Amazon, instead of being changed by it.</p>
<p>Amazon's plans — dubbed “<a href="https://www.ehandel.se/har-ar-amazon-se-det-blir-en-helsvensk-lansering" target="_blank">Project Dancing Queen</a>,” after the hit song by Swedish pop group Abba — don't have a lot of detail, but analysts believe its Swedish store will go live in the fall, in time for November’s Black Friday online shopping bonanza.</p>
<p>“Amazon has been supporting Swedish customers and selling partners across our different European stores for many years, but the next step is to bring a full retail offering to Sweden and we are making those plans now,” said Alex Ootes, Amazon’s vice president for EU expansion, in a statement.</p>
<p>Amazon’s turbo-capitalism corporate culture goes against the grain of Sweden and the rest of the Nordic countries, which pride themselves in their strong labor unions and sustainability.</p>
<blockquote><p>“Swedish e-commerce is still like regular retail without shopping malls” <em>— Jonas Arnberg, CEO of market-research firm HUI</em></p></blockquote>
<p>But the country also has an affluent, internet-savvy market ripe for Alexa, Kindles, Prime and the thousands of items on Amazon's online store, the company believes. Around 68 percent of Swedes shopped online in 2018, and they spent an average of €200 per online transaction. In total, the Nordic countries spent over €22 billion online in 2018, according to a <a href="https://www.postnord.fi/siteassets/raportit/verkkokauppa-pohjoismaissa/ecommerce-in-the-nordics-2019.pdf" target="_blank">study</a> by PostNord, the country’s postal service.</p>
<p>There's not a lot of competition in online marketplaces, and nobody can match Amazon’s massive cornucopia of goods.</p>
<p>“Swedish e-commerce is still like regular retail without shopping malls,” said Jonas Arnberg, the CEO of HUI, a market research company.</p>
<p>Amazon will change that, and force local players to adopt e-commerce faster than they would have otherwise.</p>
<p>“It’s a perfect storm in e-commerce now. The COVID-19 impact took us two to three years forward in digitalization. With Amazon’s entry it is going to go even further,” said Kristoffer Väliharju, the CEO of CDON, a Nordic online marketplace. Väliharju is optimistic about CDON’s chances of taking on the tech giant, but said companies without a strong e-commerce game will likely take a big hit.</p>
<p>Initially, Swedish and Nordic clients will be mainly served from German warehouses — known as fulfillment centers in Amazon-speak — with trucks driving up to Sweden through Denmark, and a fulfillment center operated by local partner Kuehne + Nagel in the Swedish town of Eskilstuna, near Stockholm.</p>
<p>Analysts believe local warehouses are inevitable if Amazon is to offer one of its most unique selling points: quick delivery.</p>
<h3>When in Stockholm</h3>
<p>Establishing a local operation will be a major challenge for the company. American Amazon’s <a href="https://www.cnbc.com/2019/08/22/how-amazon-is-fighting-back-against-workers-efforts-to-unionize.html" target="_blank" rel="noopener noreferrer">anti-union stance</a> and <a href="https://www.nytimes.com/2015/08/16/technology/inside-amazon-wrestling-big-ideas-in-a-bruising-workplace.html" target="_blank" rel="noopener noreferrer">working culture</a> is the antithesis of pro-union Sweden. (Swedish Prime Minister Stefan Löfven's political career is rooted in union activism dating from his time as a welder.)</p>
<p>The Swedish labor market is regulated by collective agreements between companies and unions, giving workers plenty of power over corporate decisions. Approximately 70 percent of Swedish workers belong to a union.</p>
<p>“If Amazon wants to succeed in Sweden, they need to work very closely with unions,” said Arne Andersson, an e-commerce expert at PostNord.</p>
<p>Amazon has not yet contacted Handels, the union representing warehouse workers, its political coordinator Emelie Wärn told POLITICO.</p>
<div id="attachment_1432138"><p><img aria-describedby="caption-attachment-1432138" src="https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-714x476.jpg" alt="" width="714" height="476" srcset="https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-714x476.jpg 714w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-300x200.jpg 300w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-1024x682.jpg 1024w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-768x512.jpg 768w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-1536x1024.jpg 1536w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-1160x773.jpg 1160w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-380x253.jpg 380w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-171x114.jpg 171w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-90x60.jpg 90w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-104x69.jpg 104w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-200x133.jpg 200w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-390x260.jpg 390w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-54x36.jpg 54w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-1080x720.jpg 1080w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-333x222.jpg 333w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-1120x746.jpg 1120w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222-600x400.jpg 600w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/GettyImages-943318222.jpg 2000w" sizes="(max-width: 714px) 100vw, 714px"></p><p id="caption-attachment-1432138">Sweden's warehouse-workers union, Handels, has successfully negotiated with fashion chain Uniqlo in the past | Sean Gallup/Getty Images</p></div>
<p>“Amazon is welcome to Sweden, but they have to sign a collective agreement. We will work very hard to get them to do that,” Wärn said.</p>
<p>“The fact that international companies takes interest in the Swedish market place is a positive thing. As an employer in Sweden you are obliged to follow Swedish labor legislation, which includes regulations regarding collective bargaining,” said Eva Nordmark, Sweden’s minister of employment, adding that approximately 90 percent of the employees in Sweden are covered by collective bargaining agreements.</p>
<p>The minimum wage for a card-carrying Swedish warehouse worker is 142.50 Swedish krona (€13.85) per hour before tax, according to Handels. In contrast, Amazon’s Polish warehouse workers who serve the German market <a href="https://www.politico.eu/article/coronavirus-amazon-employees-rage/">earn</a> 20 zlotys (around €4.50). Amazon said its workers in Germany earn a base pay of €11.10 an hour.</p>
<p>But the union is confident it will be able to negotiate with the tech goliath. Handels has done similar deals with Japanese fashion chain Uniqlo, Wärn said as an example.</p>
<p>But Uniqlo is not Amazon, and Handels' confidence might be misplaced, according to Markus Varsikko, a retail consultant at Dash Retail, which helps businesses use Amazon's marketplace.</p>
<p>“Amazon is a realist. If they can operate in Germany, they can operate in Sweden. It is an American company with American culture and thinking, and it is far from what we are used to here,” Varsikko said, arguing that Sweden's companies and workers might have to adapt — not the tech giant.</p>
<h3>Handels and Greta</h3>
<p>Amazon might also have to polish its sustainability credentials to appease Swedish consumers.</p>
<p>“What makes the Swedish market unique is that there is a great focus on companies to do good, be transparent and sustainable. For many Swedes, this is even more important than a wide range and low price,” said Niclas Eriksson, the CEO of electronics retailer Elgiganten. And thanks to local activist Greta Thunberg, consumers are <a href="https://www.politico.eu/article/cancel-your-amazon-prime-subscription-save-the-planet/" target="_blank" rel="noopener noreferrer">becoming increasingly aware</a> of the carbon footprint of services like next-day delivery.</p>
<blockquote><p>European consumer groups have slammed Amazon for selling dangerous and illegal products such as toxic toys and exploding power banks on its platform.</p></blockquote>
<p>Plus Amazon's insistence on lower prices might not be its winning ticket.</p>
<p>The foray into the Swedish market by another e-commerce company, Wish, may serve as a cautionary tale. The American online marketplace, which mostly sells cheap items from China, tried and failed to take over the market a few years ago. The company first wooed consumers with dirt-cheap products such as electronics and clothes, only for Swedes to be disappointed by the quality of the products and frustrated by not being able to return products to sellers.</p>
<p>"[Wish] was cheap, it was a great marketplace, but it was also crap,” said PostNord’s Andersson. Wish did not respond to a request for comment.</p>
<p>Amazon's had troubles with quality control too. European consumer groups have <a href="https://www.politico.eu/article/online-marketplaces-rife-with-unsafe-and-illegal-items-study-shows/">slammed</a> the company for selling dangerous and illegal products such as toxic toys and exploding power banks on its platform. The European Commission also put pressure on online platforms to control scammers and price gouging during the coronavirus pandemic.</p>
<p>CDON’s Väliharju said Swedish customers are very quality-conscious, and aware of their rights as consumers. Consumer groups and <a href="https://www.politico.eu/article/how-big-brands-chanel-canon-louis-vuitton-nike-are-taking-on-big-tech-silicon-valley-at-last/">brands</a> have criticized Amazon and others for not holding sufficient information about their sellers, especially for products that come from outside the European Union that could be dangerous or counterfeit.</p>
<p>“Amazon absolutely could be well met by Swedish consumers in the beginning,” said Arnberg, the CEO of HUI, citing Amazon’s promise of low prices, a big range of products and fast delivery.</p>
<p>“But in the long run they will have to adjust to Sweden."</p>
<p><em>This article has been updated to include Amazon's partnership with a warehouse provider in Sweden, and Amazon workers' wages in Germany.</em></p>
<p><em>This article is part of </em><span>POLITICO</span><em>’s premium Tech policy coverage: Pro Technology. Our expert journalism and suite of policy intelligence tools allow you to seamlessly search, track and understand the developments and stakeholders shaping EU Tech policy and driving decisions impacting your industry. Email <a href="mailto:pro@politico.eu" target="_blank">pro@politico.eu</a> with the code ‘TECH’ for a complimentary trial.</em></p>

							
							
							<!--/.story-supplement-->

						</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/amazons-cut-price-culture-meets-swedens-unions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24129279</guid>
            <pubDate>Wed, 12 Aug 2020 06:58:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is there only one Snap Store?]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 278 (<a href="https://news.ycombinator.com/item?id=24129208">thread link</a>) | @reddotX
<br/>
August 11, 2020 | https://merlijn.sebrechts.be/blog/2020-08-02-why-one-snap-store/ | <a href="https://web.archive.org/web/*/https://merlijn.sebrechts.be/blog/2020-08-02-why-one-snap-store/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Snap and Flatpak are the basis of two universal app stores for Linux: the <a href="https://snapcraft.io/store">Snap Store</a> and <a href="https://flathub.org/home">Flathub</a>. Interestingly, Flatpak has multiple repositories: Flathub is the main one but both Fedora and Elementary OS also host their own store. In contrast; there is only one Snap store. Why is that?</p>
<blockquote>
<p>Note: for an introduction into Flatpak and Snap, please read <a href="https://www.zdnet.com/article/the-future-of-linux-desktop-application-delivery-is-flatpak-and-snap/">The future of Linux desktop application delivery is Flatpak and Snap</a>.</p>
</blockquote>
<p>Snap is designed so each device only connects to a single store for three reasons:</p>
<ul>
<li>users can easily discover new applications,</li>
<li>developers can easily publish their apps,</li>
<li>and developing Snap itself is easier.</li>
</ul>
<p>Canonical, the company behind Snap and Ubuntu, already tried the distributed approach and discovered its downsides. Before Snap, “Personal Package Archives” (PPAs) were the recommended way to get third-party software to Ubuntu users. The idea of these is that each developer creates a tiny repository which includes their app. Users get new software by adding the PPA and installing the software using their package manager. This is very similar to how Flatpak supports multiple “stores”.</p>
<p>On Android and iOS, users often find new software by opening the app store and searching for what they need. This is not possible with PPAs because the software in a PPA only shows up in the Ubuntu app store <em>after</em> a user adds it. Snap solves this by having a single repository with all available apps. Users discover new software straight from the app store instead of having to search the internet.</p>
<p>Many developers also find creating and maintaining a repository too cumbersome. Canonical tried to make this as easy as possible for PPAs with Launchpad taking care of building and hosting the apps. Nevertheless, the process is inherently more complicated than uploading your app to a store. Although PPAs are still used by many developers, even more software is only available to download from a website.</p>
<p>These issues are not unknown to the Flatpak project, which is <a href="https://www.youtube.com/watch?v=Hga20qlyknw">why Flathub was created</a>: having a single store which contains all apps benefits everyone.</p>
<p>Given the downsides of the distributed approach, Canonical decided to invest engineering resources in other parts of Snap instead. Creating a distributed system is a multiplier to complexity; each feature becomes harder to implement. That said, the Snap developers made it clear in the past that if anyone is interested in implementing this feature in Snap, they can definitely do so.</p>
<h2 id="will-there-ever-be-an-alternative-snap-store">Will there ever be an alternative Snap store?</h2>
<p>Let’s hope so! Although Snap is designed so that each <em>device</em> only connects to a single store, multiple stores can still exist! A distribution like Manjaro could very well point Snap at their own store. Manjaro chose to use the Snap store hosted by Canonical because they like the advantages that gives them. In the future, however, Manjaro could switch to their own Snap store if that makes sense to them.</p>
<p>This is exactly what the <a href="https://ubuntu-touch.io/">Ubuntu Touch</a> project did. Ubuntu Touch is a smartphone OS which uses “click”, the precursor to Snap. They initially used the click store hosted by Canonical but they created their <a href="https://open-store.io/">their own store</a> and switched to it completely when Canonical gave up on their attempt to break the smartphone duopoly.</p>
<h2 id="is-the-snap-store-open-source">Is the Snap Store open source?</h2>
<p>Sadly, part of the Snap store is still closed source. Snap itself is <a href="https://github.com/snapcore/snapd">completely open source</a> and many parts of the Snap store are open source like the <a href="https://github.com/canonical-web-and-design/snapcraft.io">web-store front-end</a>, <a href="https://launchpad.net/review-tools">the automatic review tools</a>, <a href="https://launchpad.net/">the build service</a>, the <a href="https://launchpad.net/snap-store-desktop">desktop store app</a>, and <a href="https://github.com/snapcore">many more</a>. The back-end hosting the snaps, however, is still proprietary.</p>
<p>Open sourcing the Snap store back-end would require significant changes to it, <a href="https://www.techrepublic.com/article/why-canonical-views-the-snap-ecosystem-as-a-compelling-distribution-agnostic-solution/">according to Martin Wimpress of Canonical</a>:</p>
<blockquote>
<p><em>[because of its history,]</em> the Snap store now integrates with other areas of the Canonical infrastructure. So the Snap store isn’t a single thing. It’s not like this one piece of software that you can easily decouple from the rest of the machinery that powers the infrastructure at Canonical. So we can’t just pull it apart and separate it and say, “Here you go, here’s the open source Snap store.</p>
</blockquote>
<p>Canonical is doubtful that this investment would be worth it because of what happened with Launchpad. Although they invested significant resources in open sourcing Launchpad, there is still only one instance of Launchpad running and they have not received any significant contributions from non-Canonical employees.</p>
<p>Interestingly, Canonical actually <a href="https://ubuntu.com/blog/howto-host-your-own-snap-store">released an open-source prototype Snap store backend</a> a few years ago, but there was very little interest from the community in in actually maintaining and running a second Snap store, so the project bit-rotted and became incompatible with the current Snap protocol.</p>
<h2 id="can-other-distros-curate-packages">Can other distros curate packages?</h2>
<p>Linux Mint recently made headlines by blocking users from installing Snap on Linux Mint. One of the reasons they gave for this decision is that the centralization of Snap means Linux Mint cannot provide different versions of certain snaps for their users. <a href="https://linuxmint-user-guide.readthedocs.io/en/latest/snap.html">They explain</a> that this is possible with APT:</p>
<blockquote>
<p>Thanks to the way APT works, if a bug isn’t fixed upstream, Debian can fix it with a patch. If Debian doesn’t, Ubuntu can. If Ubuntu doesn’t Linux Mint can. If Linux Mint doesn’t, anyone can, and not only can they fix it, they can distribute it with a PPA.</p>
</blockquote>
<p>It’s understandable that a distribution wants some level of control over what packages their users get but this is already possible with the Snap store!</p>
<p><a href="https://core.docs.ubuntu.com/en/build-store/">“Brand stores”</a> are special copies of the Snap store where admins select which packages from the main store are available and which additional or modified packages are included. The European Space Agency, for example, has <a href="https://sdrsatcom.snapcraft.io/">a brand store specific to satcom research</a>. The downside of Brand stores is that you’re still using the infrastructure of Canonical, but Linux Mint is no stranger to this. Like most Ubuntu derivatives, they heavily relied on Canonical infrastructure when they first started out, even using the regular Ubuntu repositories and mirrors.</p>
<p>Another option would be to create their own Snap store with similar functionality and <a href="https://ubuntu.com/blog/howto-host-your-own-snap-store">Canonical’s previous behavior</a> suggests they would be open to helping that effort.</p>
<h2 id="my-thoughts-about-this">My thoughts about this</h2>
<p>Having a single Snap store which has closed source parts is very controversial in some parts of the Linux community. The decision to have only a single store per device seems reasonable to me: it has clear advantages both to users and developers. Still, I am happy Flatpak exists as a competing project with a decentralized design and Elementary OS’s <a href="https://blog.elementary.io/elementary-appcenter-flatpak/">hybrid approach</a> does a great job of taking advantage of it. I hope that someday the community creates an alternative Snap store similar to what F-Droid is doing.</p>
<p>I do not like the fact that the Snap store backend is proprietary because it is becoming such a core part of Ubuntu. I don’t think there is anything wrong with Canonical producing closed-source add-ons on top of Ubuntu in an “Open Core” fashion. GitLab does this really well and we have an amazing open source GitHub alternative because of it. There is nothing wrong with Canonical trying to make money; Ubuntu would not be here without them. Linux is great because of all the companies surrounding it.</p>
<p>What I do take issue with is that you currently cannot use Snap for its intended purpose without this proprietary back-end. Ironically, Ubuntu’s former community member, Jono Bacon, made it very clear <a href="https://www.youtube.com/watch?v=o-OOxOS8oDs">in a recent video</a> that the proprietary parts of an Open Core project need to be <em>optional</em>. Having paid enterprise features such as the <a href="https://docs.ubuntu.com/snap-store-proxy/en/">Snap Store Proxy</a> is fine, for example, because Snap is still completely functional without it.</p>
<p>That said, I’m pragmatic about the proprietary back-end. DockerHub and GitHub are insanely popular and they are <em>completely</em> proprietary. Moreover, Canonical is much more receptive to community pressure than Docker inc or GitHub so we are in a much better position to steer them towards doing “the right thing”. Snap offers a lot of advantages <a href="https://merlijn.sebrechts.be/blog/2020-07-06-why-snap-flatpak">compared to APT</a> and <a href="https://merlijn.sebrechts.be/blog/2020-07-03-snap-vs-flatpak">compared to Flatpak</a>, and if things really don’t work out with Canonical, we can always build our own back-end.</p>
<blockquote>
<p>Note: I am a human being, and like most human beings, I make mistakes. Did you find an issue with this article? Let me know in the comments, and I’ll be happy to correct it!</p>
</blockquote>

    </div></div>]]>
            </description>
            <link>https://merlijn.sebrechts.be/blog/2020-08-02-why-one-snap-store/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24129208</guid>
            <pubDate>Wed, 12 Aug 2020 06:45:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a minimalist spaced repetition tool]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24129037">thread link</a>) | @mvind
<br/>
August 11, 2020 | http://memordo.com/launch | <a href="https://web.archive.org/web/*/http://memordo.com/launch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://memordo.com/launch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24129037</guid>
            <pubDate>Wed, 12 Aug 2020 06:12:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Word Mover's Embedding: Cheap WMD For Documents]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24128707">thread link</a>) | @vackosar
<br/>
August 11, 2020 | https://vaclavkosar.com/ml/Word-Movers-Embedding-Cheap-WMD-For-Documents | <a href="https://web.archive.org/web/*/https://vaclavkosar.com/ml/Word-Movers-Embedding-Cheap-WMD-For-Documents">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    



<p><img alt="Word Mover's Embedding is a document embedding." src="https://vaclavkosar.com/images/word-movers-embedding.png"></p>

<p>Word Moverâ€™s Distance captures the semantic similarity between documents more accurately than the cosine similarity between word vector averages. 
However, vanilla WMD has cubic computational complexity, which makes it impractical in many applications. How WMD works? Why is it so good? Is there any low complexity approximation of WMD?</p>

<h3 id="what-is-earth-movers-distance">What is Earth Moverâ€™s Distance?</h3>

<p>It is minimum amount of dirt multiplied by distance needed to transform one pile of dirt into another pile of dirt.</p>

<p><img alt="Earth Mover's Distance is amount multiplied by distance." src="https://vaclavkosar.com/images/earth-movers-distance.png"></p>

<p>Despite the earth in the name, better analogy is that of a transportation problem. 
Good example of transportation problem is cost optimization of transportation of gold ore from mines to refineries, where each refinery can accept only certain percentage of the ore.</p>

<p>Earth Movers Distance is also a distance metric between probability distributions.
So the problem above can be restated into following question. How to transform the this geographical distribution of gold ore to this geographical distribution for the least hauling cost?</p>

<p>Earth mover distance computational complexity is super-cubic as can be found in <a href="https://www.amazon.com/Network-Flows-Theory-Algorithms-Applications/dp/013617549X">Network Flows: Theory, Algorithms, and Applications</a>.
There are papers on approximating EMD with <a href="http://proceedings.mlr.press/v37/kusnerb15.pdf">quadratic complexity</a> in general case and <a href="http://proceedings.mlr.press/v97/atasu19a/atasu19a.pdf">linear complexity</a> in document search if pre-computation is allowed.</p>

<h3 id="what-is-word-movers-distance-wmd">What is Word Moverâ€™s Distance (WMD)?</h3>
<p>Word Moverâ€™s Distance is like Earth Movers Distance but between text documents.</p>

<ul>
  <li>The probability distribution is over word vectors of the documentâ€™s words.</li>
  <li>The probability is normalized frequency of unique words in the document.</li>
  <li>The distance between word vectors can be a cosine similarity or euclidean distance.</li>
</ul>

<p>Words vectors in above can be for example Word2vec embeddings.</p>

<h3 id="word-movers-distance-vs-word-embedding-weighted-average-similarity">Word Moverâ€™s Distance vs Word Embedding Weighted Average Similarity</h3>

<p>Word Embedding Weighted Average Embedding is a vector calculated as frequency weighted average of word vectors in a document.
The similarity measure used for WEWA is cosine similarity.</p>

<p><img alt="Average of two vectors." src="https://vaclavkosar.com/images/vector-average.png"></p>

<ul>
  <li>WMD uses more detailed information and captures move semantics than WEWA.</li>
  <li>WMD has much higher complexity of \( O(L^3 \log(L)) \) compared to WEWAâ€™s \( O(L) \), where \( L \) is document length.</li>
</ul>

<h3 id="word-movers-distance-vs-bert-similarity">Word Moverâ€™s Distance vs BERT Similarity</h3>

<p>It would be interesting to compare BERT transformer model sentence embedding computational complexity to WMD.
If I understand correctly, BERT is of linear complexity in the length of the document, although total running time may be still in many cases be longer for BERT.
There is <a href="https://github.com/google-research/bleurt">a sentence similarity model from Google called Bleurt</a>.</p>

<p>In terms of classification accuracy the BERT should definitely win, but I wonder by how much margin.</p>

<h3 id="word-movers-embedding">Word Moverâ€™s Embedding</h3>

<p>In oversimplified terms, <a href="https://arxiv.org/abs/1811.01713">Word Moverâ€™s Embedding</a> is a vector embedding of a document such that its dot product
with documents in a collection approximates Word Moverâ€™s Distance between the documents for less computational cost.</p>

<p>To address the main computational complexity, we need to cut cost of WMD calculation.
Could we make one of the documents in each side of WMD calculation smaller?
For small constant size \( D \) document \( \omega \), the complexity of WMD would be nearly linear \( O(L \log(L)) \) instead of \( O(L^3 \log(L)) \)!
So if we could compare all documents not against each other but rather against \(R \) much smaller documents, we could get complexity down to \( O(NRL \log(L)) \) from \( O(N^2 L^3 \log(L)) \)!</p>

<h4 id="random-encounters">Random Encounters</h4>
<p>The j-th dimension value of an embedding is defined using a WMD distance to a â€œrandomly generated documentâ€� denoted by \( \omega_j \).</p>

<p>\( \mathit{WME}(x)_j = \) 
\( \frac{1}{\sqrt{R}} \exp[ - \gamma \mathit{WMD}(x, \omega_j) ] \)</p>

<p>Letâ€™s for a moment assume we know how to randomly generate documents. Why would above make sense?</p>

<p>As teased above, the dot product of the embeddings is dominated by a random document that lies on the shortest path between the documents.
Note that the random document can only be close to the shortest path between the documents if it is â€œrich enoughâ€�.</p>

<p>\( \mathit{WME}(x) \cdot \mathit{WME}(y) = \)
\( \frac{1}{R} \sum_j \exp[ - \gamma (\mathit{WMD}(x, \omega_j) + \mathit{WMD}(y, \omega_j)) ] \)
\( \approx \frac{1}{R} exp[ - \gamma (WMD(x, \omega_k) + WMD(y, \omega_k)) ] \)
\( \approx \frac{1}{R} \exp [- \gamma \mathit{WMD}(x, y) ] \)</p>

<p><img alt="Word Mover's Distance dominated by single common random document distance." src="https://vaclavkosar.com/images/word-movers-distance-vs-embedding.png"></p>

<h3 id="rich-random-documents">Rich Random Documents</h3>

<p>You are rightly skeptical about generating random documents. 
Donâ€™t we need to generate too many, which would defeat our attempt to speed up the calculation?
And how do we generate documents anyway?</p>

<h4 id="random-words">Random Words</h4>
<p>To generate documents we only need to generate enough random word vectors to represent words.
Perhaps for the purposes of the proof or to have an ability to generate â€œmixed-wordsâ€�, <a href="https://arxiv.org/abs/1811.01713">the WME paper</a> generate random vectors instead of random words from a dictionary and then drawing words for them.</p>

<p>The paper <a href="https://arxiv.org/pdf/1502.03520.pdf">cites an observation</a> that Word2vec and GloVe words vector direction distribution is approximately isotropic.
That means that normalized word vectors are uniformly distributed on a unit sphere.
We can generate these by uniformly sampling from a hyper-cube and then normalizing the results.</p>

<p>\( v_j \approx \mathit{Uniform}[v_{min}, v_{max}] \)</p>

<p>Read more about <a href="https://vaclavkosar.com/ml/FastText-Vector-Norms-And-OOV-Words">distribution of norms of Word2vec and FastText words vectors in another post of mine</a>.</p>

<h4 id="exclusive-document-collection">Exclusive Document Collection</h4>

<p>But how many words per random document is enough?
If we generate too large documents, we will not obtain any speed up!
So far, I havenâ€™t mentioned any restrictions on the document collection we would like to embed. Here it comes.</p>

<p>The paper observed that the number of random words on the order of <em>the number of topics</em> in the collection of the documents is enough.
So if we have document collection with small enough topic count, we should obtain good accuracy, while reducing time complexity.</p>

<h4 id="how-many-rando-docs">How Many Rando-Docs?</h4>

<p>Thanks to fast convergence the paper found that the count on the order of thousands is enough, which was also on the order of number of documents they had in their testing datasets.
I am not sure, how many would be needed in the document count in the collection would be bigger than that.</p>

<h4 id="algo">Algo</h4>
<p>Full algorithm is following:</p>

<ul>
  <li>Generate \( R \) random docs:
    <ul>
      <li>Generate random document size \( D \).</li>
      <li>Generate \( D \) random words.</li>
      <li>For all input documents calculate Word Moverâ€™s Embedding projection to just generated document as store it to matrix \( Z \).</li>
    </ul>
  </li>
  <li>Return matrix \( Z \) containing the embeddings.</li>
</ul>

<h4 id="kernel-of-approximate-truth">Kernel Of Approximate Truth</h4>

<p>The approximation is motivated by analytical proof of convergence of <em>Word Moverâ€™s Kernel</em> defined below to the WMD.
The proof utilizes theory of Random Features to show convergence of the inner product between WMEs to a positive-definite kernel that can interpreted as a soft version of WMD.</p>

<p>\( k(x, y) = \)
\( \int p(\omega) \phi_{\omega}(x) \phi_{\omega}(y) \mathbf{d}\omega \),</p>

<p>where \( \phi_{\omega}(x) := \exp [- \gamma \mathit{WMD}(x, \omega) ] \)</p>

<h4 id="wme-vs-knn-wmd">WME vs KNN-WMD</h4>

<p>The method complexity is \( O(NRL \log(L)) \) when the random documents size (topic count) is constant. That stands in contrast to KNN-WMD variant \( O(N^2L^3log(L)) \).
Additionally, <a href="https://arxiv.org/abs/1811.01713">WME slightly outperformed KNN-WMD in classification accuracy</a>.</p>

<h3 id="1-minute-quiz">1-Minute Quiz</h3>

<p>Without active recall, you wonâ€™t remember anything from the above. Take at least one round of the quiz below. You can also subscribe to get revision reminders or generate your own quizzes there.<br>
<a href="https://quizrecall.com/study/public-test?store_id=83f9d7dd-0cbf-461d-a835-cbfc2024940a">1-Minute Word Moverâ€™s Distance Quiz</a></p>

<h3 id="video">Video</h3>

<iframe width="560" height="315" src="https://www.youtube.com/embed/uuNLz6eT_tg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

</div></div>]]>
            </description>
            <link>https://vaclavkosar.com/ml/Word-Movers-Embedding-Cheap-WMD-For-Documents</link>
            <guid isPermaLink="false">hacker-news-small-sites-24128707</guid>
            <pubDate>Wed, 12 Aug 2020 04:54:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keep Up: The first book written by an AI]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24128347">thread link</a>) | @wimpypistol
<br/>
August 11, 2020 | https://thefirstaibook.com/living-a-meaningful-life/ | <a href="https://web.archive.org/web/*/https://thefirstaibook.com/living-a-meaningful-life/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-33">
	
	<!-- .cover-header -->

	<div id="post-inner">

		<div>

		
<p>Many prominent figures have attempted to answer the question of what, if anything, makes life meaningful, although they typically have not put it in these terms. Consider, for example, Aristotle on the human function, Aquinas on the beatific vision, and Kant on the highest good.&nbsp;</p>



<p>But what does it mean to live a meaningful life? This question has been posed by philosophers since ancient times. In his book On the Happiness of Man (c. 450 BCE), Plato asks whether there is any way we can be happy without achieving certain goals or desires. And in his dialogue Phaedo (c. 380 BCE) Socrates asks whether the pursuit of pleasure is always desirable; he concludes that it isn’t, and that happiness lies elsewhere. In the early modern period, William Godwin’s essay What Is Art? (1793) provides a classic formulation of this problem. More recently, existentialist thinkers such as Jean-Paul Sartre and Albert Camus have explored this issue through their writings about existence.&nbsp;</p>



<p>However, most contemporary philosophers do not address the question directly. Why is it that so few people seem to find life meaningful? To answer this question, I will focus on two main issues: (1) what makes something meaningful; and (2) how can we know what is important in our lives? My aim here is not to provide a comprehensive account of the nature of meaning. Rather, my goal is simply to identify those aspects of life that make us feel alive and happy.</p>



<p>Meaning in life can be thought of as the goal-directed behavior that we engage in as a result of making conscious choices. This concept has been debated by many philosophers, especially those in the existentialist tradition. However, the general idea is fairly intuitive: we all have a sense that our choices matter and that we can affect the world around us. Indeed, this idea is so intuitive that it is practically a tautology. So, what exactly is it about conscious choice that makes life meaningful?</p>



<p>One aspect of meaning in life is its ethical component. This follows from the fact that morality provides us with reasons for action. These reasons can be either moral or amoral, but either way they are the foundations upon which our actions and choices rest. There are three components to these reasons: facts, values, and obligation.</p>



<p>Our lives are governed by facts, and this is what gives rise to the distinction between the objective and subjective. For instance, it is a fact that it is currently Monday. This fact is objective since it is independent of human opinion; in other words, it would remain true whether or not anyone believed it to be true. It is also a fact that I am currently typing on my keyboard. However, facts can be divided into two categories: brute facts and institutional facts. Institutional facts are grounded in brute facts, but they also depend upon human agreement or consent for their veracity.&nbsp;</p>



<p>For instance, the fact that it is illegal to drive on the sidewalk is an institutional fact; this is made true by human agreement, but it would not be true unless people agreed or consented to this rule. By contrast, the fact that I have five fingers on my right hand is a brute fact; it is true whether or not humans believe it to be true. The distinction between brute facts and institutional facts is an important one, because many of our facts are institutional in nature. It is for this reason that we can question the meaning of our lives.</p>



<p>The meaning of life can be seen as a function of the facts that govern it. Some facts give meaning to our lives by giving it a purpose or goal; these facts are value-laden, and as such, they provide reasons for action. For instance, I might value health because I want to live a long and happy life. Other facts give meaning to our lives by imposing obligations upon us; for instance, I have a duty to pay my taxes because it is the law.</p>



<p>Meaning arises from the relationship between facts and values. Consider an example: many people value wealth, but the acquisition of wealth does not in itself give life meaning. Rather, it is the value that one places on wealth that imbues it with meaning. This value could be the result of an objective fact; for instance, one might acquire wealth in order to give to those who are poorer than themselves. In this case, acquiring wealth would be the means to an end, and that end would be the satisfaction of helping others. By contrast, one might acquire wealth without any intention of helping others; in this case, the value that one places on wealth would be the result of a subjective fact. It is important to note that this subjective fact need not be an opinion or a matter of preference; it could just as easily be something that one “just feels.”</p>



<p>Whatever the source, values provide reasons for action. These reasons are given validity by our choices and decisions. We can make choices and decisions based on facts alone, but this would not give meaning to our lives; it is the incorporation of values that gives meaning to our lives. In this way, we make meaning out of the world around us. Without values, life would be nothing more than a series of random and disconnected events. With values, life becomes a journey with a purpose.</p>



<p>In short, the meaning of life is found in the relationships between facts and values. If you wish to find your own meaning in life, then you must first determine what makes up your values. Then, you must determine how those facts relate to each other and ultimately to yourself. Once you have done so, you will know what it is that makes up your sense of self and thus what it is that defines your worth as a person.</p>



<p><strong>7/68</strong></p>

		</div><!-- .entry-content -->
		
	</div><!-- .post-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://thefirstaibook.com/living-a-meaningful-life/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24128347</guid>
            <pubDate>Wed, 12 Aug 2020 03:27:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero-Knowledge Proofs for Engineers: Introduction]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24128340">thread link</a>) | @kipply
<br/>
August 11, 2020 | https://blog.zkga.me/intro-to-zksnarks | <a href="https://web.archive.org/web/*/https://blog.zkga.me/intro-to-zksnarks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <div>  <div> <p>In this post, we’re going to talk about zkSNARKs, which are a particular brand of Zero Knowledge Proof that’s becoming increasingly important in the blockchain space.</p> <p>We’ll cover how they’re used and what they’re useful for, and we’ll take a look at a basic zkSNARK in a SNARK-building language called Circom.</p>  <p>We assume that you’re encountered prime fields before, and remember their basic properties. If you can calculate \(4 \cdot 5 \equiv 6\) in \(\mathbb{F}_7\), you’re good to go.</p>  <p>A <em>zero knowledge protocol</em> is a protocol that allows you to prove that you know some specific mathematical fact, without revealing any information about the fact itself. The proof generated in a zero knowledge protocol is called a <em>zero knowledge proof</em>.</p> <p>Some examples of “mathematical facts” that we can create zero knowledge proofs for include things like:</p> <ul> <li>Knowledge of a three-coloring of a graph (i.e. I know a three-coloring of this publicly-known graph, and I’ll prove that I know it without showing you the coloring)</li> <li>Knowledge of the discrete logarithm of some residue modulo \(p\) (i.e. given public generator \(g\), public modulus \(p\), and some residue \(y\), I know \(x\) such that \(g^x \equiv y\) modulo \(p\))</li> <li>Knowledge of a private key corresponding to a publicly-known public key</li> </ul> <p>The idea of a zero knowledge protocol might seem paradoxical at first glance: how can I prove I know something without showing you the thing that I know? However, it turns out that we actually use zero knowledge protocols all the time! For example, familiar tools like digital signatures are actually zero knowledge proofs. By signing a message, I prove that I know the private key that corresponds to a widely-known public key, but I don’t give away any information about the private key itself. In fact, public-key encryption only works because it is a zero knowledge protocol; if signatures revealed information about your private key, then malicious actors would be able to impersonate you by analyzing your signatures and recovering your private key.</p> <p>Slightly more formally, suppose that you’ve computed \(f(\cdot) = y\) for some publicly known function \(f\) and some secret input \(\cdot\). A zero-knowledge protocol for the function \(f\) would allow you to prove to others that you know a secret input to \(f\) that results in \(y\), without revealing this secret input \(\cdot\).</p> <p>For more on ZKPs, check out <a href="https://blog.cryptographyengineering.com/2014/11/27/zero-knowledge-proofs-illustrated-primer/">this post</a>.</p>  <p>Like we mentioned above, ZKPs are protocols that allow you to prove knowledge of a specific mathematical fact: discrete log, knowledge of private key, knowledge of three-coloring, etc. However, it’s important to note that early ZKPs only allowed you to prove one kind of mathematical fact at the time. That is, cryptographers developed one protocol which you could use to prove knowledge of discrete log, another protocol which you could use to prove knowledge of three-coloring, and another protocol for digital signatures. But what if we want to generate zero knowledge proofs for arbitrary mathematical functions? For example - what if I want a zero knowledge protocol that would allow me to prove that I know the pre-image of a SHA256 hash output? It would be intractable if, for every use case, I had to go to a cryptographer and ask them to custom-write me a new protocol.</p> <p>zkSNARKs solve this problem. A zkSNARK is a gadget that can be used to generate a ZKP for any mathematical function. Basically, you feed the “code” of a function \(f\) into a zkSNARK, and the SNARK creates a protocol that allows you to generate zero-knowledge proofs for \(f\).</p> <p>As an example, say we have a fake “hash” function \(h(x) = x^3 - x + 7\) that we’d like to generate zero knowledge proofs for. First, we can use a zkSNARK to generate a ZKP for \(h\). Then, we can use this generated ZKP to prove claims like “I know a value \(\cdot\) such that \(h(\cdot) = 67\)” - <em>without revealing \(\cdot\)</em>. zkSNARKs also guarantee that this process is “succinct” and “non-interactive”: we can create this proof in linear time, and others can verify it in constant time, without needing to ask additional questions of us (the prover). Together, these properties form a zkSNARK: a <em>Zero Knowledge Succinct Non-interactive ARgument of Knowledge</em>.</p> <p>These properties makes SNARKs useful for blockchain applications, where users can create proofs locally, and then upload short proofs for constant-time verification inside a smart contract, where computation is expensive.</p>  <p>A central mechanic in Dark Forest is that the cryptographic “fog of war.” The fog of war ensures that you don’t automatically know where all players, planets, and other points of interests are in the universe; you have to spend computational resources to discover them. This mechanic is secured by zkSNARKs.</p> <p>In a universe with a fog of war, the locations of all players are private and hidden from each other. This means that players don’t upload the coordinates of their planets to the Ethereum blockchain, which can be publicly inspected. Instead, each player uploads the hash of their location to the blockchain. This ensures that players stay “committed” to a specific location, but also that the location can’t be determined from inspection of the Ethereum data layer.</p> <p>Without zkSNARKs, there’s an obvious attack vector - if a player uploads a random string of bytes that doesn’t correspond to a real and valid location, and the integrity of the game is broken. To prevent this, Dark Forest requires players to submit zkSNARKs with every move to ensure that players are indeed submitting hashes corresponding to valid coordinates that they have knowledge of.</p> <p>When players make moves, they’re also required to submit ZK proofs that their moves are “valid” - you can’t move too far or too fast. Without zkSNARKs, a malicious player could make illegal “teleport” moves by claiming that the hash they are moving from is next to the hash they’re moving to, even if the two locations are actually on opposite sides of the universe. Once again, requiring ZK proofs keeps players honest. To use a chess analogy, the required ZK proofs basically tell the contract, “I’m moving my knight; I’m not going to tell you where I moved my knight from, or where I moved it to, but this proof proves that it did in fact move in a legal L-shape.”</p> <p>We’ll dive deeper into the Dark Forest construction and SNARKs in a future blog post!</p>  <p>Like we mentioned above, SNARKs are gadgets which take in a function and output a ZKP for said function. So how do we “feed” a function to a SNARK?</p> <p>SNARKs functions are written as circuits in the Circom language. Here’s an example circuit for our “fake” hash function, \(h(x) = x^3 - x + 7\).</p> <div><div><pre><code><span>// file: circuit.circom</span>

<span>template</span> <span>BadHash</span><span>()</span> <span>{</span>
    <span>signal</span> <span>private</span> <span>input</span> <span>x</span><span>;</span>
    <span>signal</span> <span>x_squared</span><span>;</span>
    <span>signal</span> <span>x_cubed</span><span>;</span>
    <span>signal</span> <span>output</span> <span>out</span><span>;</span>

    <span>x_squared</span> <span>&lt;==</span> <span>x</span> <span>*</span> <span>x</span><span>;</span>
    <span>x_cubed</span> <span>&lt;==</span> <span>x_squared</span> <span>*</span> <span>x</span><span>;</span>
    <span>out</span> <span>&lt;==</span> <span>x_cubed</span> <span>-</span> <span>x</span> <span>+</span> <span>7</span><span>;</span>
<span>}</span>

<span>component</span> <span>main</span> <span>=</span> <span>BadHash</span><span>();</span>
</code></pre></div></div> <p>Our zkSNARK takes in this circuit, chews it up, and spits out a <em>proving key</em> and a <em>verifying key</em>. The proving key allows a prover who is computing <code>BadHash(x) = out</code> to generate a proof that they do indeed know the pre-image of <code>out</code>. The verifying key allows anyone to inspect that proof, along with <code>out</code>, and conclude that the prover did honestly carry out the computation with a known secret input.</p> <p>Concretely, suppose that the prover computes <code>BadHash(4) = 67</code>. The prover publishes their proof, along with <code>out = 67</code>, to the verifier; however, they do not publish the secret input <code>x = 4</code>. The verifier of this proof knows the source code of the <code>BadHash</code> circuit, and also receives <code>out = 67</code> and a proof from the prover. The verifier can then inspect the proof to verify that the prover did indeed compute some valid x, x_squared, and x_cubed to arrive at <code>out</code>. However, the verifier won’t know the specific values that the prover used (<code>x = 4</code>, <code>x_squared = 16</code>, <code>x_cubed = 64</code>) - just that these values were computed correctly.</p> <p>There are two things which make SNARK circuits different from normal “functions” that we’re used to.</p> <p>First, you’ll notice that BadHash only uses three operations: multiplication, addition, and subtraction. At the base level, SNARK constraints are limited to only these operations. There are ways to do operations like division and modulo, but they all ultimately involve breaking operations down into sums and products. The fact that we’re limited to these operations is part of what makes SNARK programming thorny.</p> <p>The second challenge is that each signal in a SNARK is an element of a prime field, and all operations happen inside that prime field. The most obvious implication of this is that there is no native notion of decimals, fractions, negative numbers, or numbers bigger than 77 digits. If you want one of these, you have to make them out of positive integers smaller than <code>p</code>. Another implication is that our operators “wrap around”: the result of <code>3 - 5</code> is <code>p - 2</code>, which is a 77 digit number. The prime is large enough (254) that most of the time this doesn’t matter, but occasionally it can cause subtle correctness bugs.</p> <p>To actually make proofs, we use a library called <a href="https://github.com/iden3/snarkjs">SnarkJS</a>, built by Jordi Baylina and Iden3. <code>SnarkJS</code> uses your circuit to generate proving and verification code in JavaScript and Solidity, as well as protocol paramters and proving and verification keys. This is out of the scope of this post, but you can find a tutorial on it <a href="https://github.com/iden3/circom/blob/master/TUTORIAL.md">here</a>.</p> <p>In the next posts, we’ll talk about the execution model of SNARKs, including the difference between calculation and constraint, and how to do operations like division and modulo.</p> </div> </div>  </div></div>]]>
            </description>
            <link>https://blog.zkga.me/intro-to-zksnarks</link>
            <guid isPermaLink="false">hacker-news-small-sites-24128340</guid>
            <pubDate>Wed, 12 Aug 2020 03:25:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital Nomad Survey – Do You Want to Work from Saint Lucia?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24128142">thread link</a>) | @peterburkimsher
<br/>
August 11, 2020 | https://islandeffect.com/digital-nomad-survey-do-you-want-to-work-from-saint-lucia/ | <a href="https://web.archive.org/web/*/https://islandeffect.com/digital-nomad-survey-do-you-want-to-work-from-saint-lucia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text">
<p>In a world that has in so many ways been forced to stand still, St Lucia, our small, beautiful island in the Caribbean, is looking for ways to push forward. </p>



<p>The Corona virus has brought struggles and stress across the world, but particularly to Saint Lucia as we are so reliant on tourism and many people are unable to work while most hotels remain closed and flights are scarce. </p>



<p>But some of us are also looking at this as an opportunity for some much needed change.</p>



<p>Saint Lucia’s tourism industry has long been in need of an overhaul and we’d like to push for a more sustainable, environmentally-friendly and culturally-appreciative model.</p>



<p>For years, many have been calling for less focus and reliance on resource-taxing cruise ship passengers and guests in all-inclusive resorts that don’t share benefits of tourism around the island. </p>



<p>Rather than using up our resources catering to visitors who stay a few hours or rarely spend money outside of their pre-booked packages, why not attract a different type of traveler? </p>



<p>Why not market to those who are more conscientious about the cultures and environments that they are visiting, who want to stick around and experience the true authentic life and customs the Caribbean has to offer, and to spread their spending to local businesses and villages?</p>



<p>Now is the perfect time to do just this, and that’s why we are reaching out to you, the global <em><strong>Digital Nomad </strong></em>community. We want to know what it is that you look for when choosing a country to live and work. What conveniences are needed to make sure you can work effectively? What kind of activities are you looking for during your leisure time? </p>



<p>We believe that we have so much to offer- pristine nature, gorgeous weather, friendly people, and so much else, but before welcoming you here we want to make sure everything is set up just right.</p>



<p>Below is a short survey that would really help us gather the information we need to create the ideal experience for you. We would be so grateful if you could take a few minutes to fill it out and <strong>share</strong> with your adventurous friends. </p>



<p>Thanks so much and hoping to see some of you nomads in the near future!</p>




<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://islandeffect.com/digital-nomad-survey-do-you-want-to-work-from-saint-lucia/"
    dc:identifier="https://islandeffect.com/digital-nomad-survey-do-you-want-to-work-from-saint-lucia/"
    dc:title="Digital Nomad survey &#8211; do you want to work from Saint Lucia?"
    trackback:ping="https://islandeffect.com/digital-nomad-survey-do-you-want-to-work-from-saint-lucia/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://islandeffect.com/digital-nomad-survey-do-you-want-to-work-from-saint-lucia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24128142</guid>
            <pubDate>Wed, 12 Aug 2020 02:49:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principles for a Diverging Desktop Future]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24128112">thread link</a>) | @mwcampbell
<br/>
August 11, 2020 | https://www.divergent-desktop.org/blog/2020/08/10/principles-overview/ | <a href="https://web.archive.org/web/*/https://www.divergent-desktop.org/blog/2020/08/10/principles-overview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <div>
        <article lang="en">
          
          <p>This post lays out an overview of the guiding principles driving much of the
work behind the main parts of the <a href="https://arcan-fe.com/">Arcan Project</a>. For
those unaware, Arcan is presented as something as uncommon as a ‘desktop
engine’. The grand claim is that modifying and understanding the entirety of
your desktop should be ‘patching scripts’ level easy if we rework current
popular abstractions and adjust the division of labour.</p>

<p>The principles themselves link together to tell a large chunk of the vision of
the ‘divergent desktop’; a story that has been slowly getting its shape over
many years, greatly influenced by a number of publicly documented experiments
as well as seminal works such as Von Neumann’s “The Computer and the Brain”,
Norbert Weiner’s “The Human use of Human Beings”, Ian Hacking on “Representing
and Intervening”, Jaron Lanier’s trilogy on what the future may hold in store,
as well as the nowadays less digestible amalgamation of +Fravia’s Search Lores.</p>

<p>The overview is quite a long read in its own right, and full versions of each
principle will be added as individual articles over time – If the contents in
the sections here comes off as a bit dense and hard to ingest, fret not! They
are more teasers or appetisers, the full course meal will have better pacing
and technical depth.</p>

<p>For the sake of convenience, here are navigational links to the individual
sections:</p>

<ol>
  <li><a href="#p1">Professionals First</a></li>
  <li><a href="#p2">Diversify Experience</a></li>
  <li><a href="#p3">App-pocalypse now: Emphasis at the Extremes</a></li>
  <li><a href="#p4">Make State Mobile! (Again)</a></li>
  <li><a href="#p5">No State Left Behind</a></li>
  <li><a href="#p6">Privacy Fights Back: Poison The Well</a></li>
  <li><a href="#p7">The Single User - The U in UNICS</a></li>
  <li><a href="#p8">Silent Defaults, No Surprises</a></li>
  <li><a href="#p9">Interactive At First Breath</a></li>
  <li><a href="#p10">Everything Immediately Observable</a></li>
  <li><a href="#p11">Defer Composition</a></li>
  <li><a href="#p12">Simplicity Is Systemic</a></li>
</ol>

<h2 id="backstory-and-motivation">Backstory and Motivation</h2>

<p>The Arcan project, at its core, is rooted in assumption that the ‘desktop’ way
of interfacing with computing is inching towards its last of breaths, and
rewriting X11 or JSONifying STDOUT won’t provide much more air than for a final
gasp.</p>

<p>The upside is that this may well turn out to be something positive that
provides opportunity for radical simplification and restructuring of the myriad
of technologies that make out the Rube Goldbergian contraption that is the ‘modern’
desktop.</p>

<p>The first non-academic presentation (<a href="https://youtube.com/watch?v=07nqZIFRDJg">video</a>)
on the Arcan project had a terse, technical-overview style to it, with very little
in terms of motivation or actual intended direction.</p>

<p>The reason for that was that I wanted to keep the attention and focus on “what it is”
rather than “what will it ever be used for”, and carefully note who tries to fill
in the cryptic blank spaces, and with what. This was predicated on the belief
that honest dissemination is done by first demonstrating the feasibility and
soundness of the fundamentals of the tech in isolation; flowery visions,
soap-boxing and sociopolitical annotation are best left deferred to separate
stages should the underlying tech be sufficiently coherent and robust.</p>

<p>It is not, however, some vacuous perspective of the technology as living a life
disjunct from the social consequences of its application, but having that as
the goto default mental model for any fledgling utterances is as much of a
fool’s errand as thinking that it should never be viewed through the optics of
an abstract larger social organism.</p>

<p>The basic motivation for <em>all</em> of this is as follows:</p>

<blockquote>
  <p>I am of humble needs and wants: I want to expand my agency, security, safety and quality of experience in regards to all things that computing touch. The largest obstacle to that expansion, right now, is the chaos and complexity of user-space, the dependency creep towards an online ‘service-space’, the peering eyes this ‘service space’ uses to study and repackage some naive interpretation of ‘you’, and how this service space is being used to mutate social- and critical- infrastructure towards something wholly frightening.</p>
</blockquote>

<p>On a personal level, I have coded and experimented with virtually everything
computing since the days of the venerable C-64 (divide it by two, flip it over,
that’s 23) – viruses, anti-viruses; drm protections, cracks; database
engines; operating system kernels; cheats, bots and anti-cheats; emulators
(both interpreter dance and JITterbug); demos; games; parsers for more
formats than I can remember; exploits as well as mitigations. I have worked in
academia, government, military-industrial, fortune-500 as well as fledgling
startups, and got the scars and theses to prove it. The ‘left to observe’ list
has grown rather short over the years.</p>

<p>During this time, the evolution of the capabilities of the devices themselves
have exceeded all expectactions and is nothing short of spectacular. The
hardware and software lockout which plagued the early days is, relatively
speaking, minor; access to both capable devices and deep technical information
has become absolutely stellar, overwhelmingly so. The days of begging companies
for scraps of hardware; scraping public libraries and dumpsters for slices of
information; for quid-pro-quo trading of hacker ‘secrets’ and basic software
building blocks (‘warez’) are mostly faint memories. Hopefully they will remain
as such in spite of troubling signs up ahead.</p>

<p>The counterweight to this positive development is that things have become complex
to the degree that a thorough and deep understanding, <em>preconditions</em> to responsible
control and agency, is a hard thing to come by, and an even harder thing to fight
for. Just add more dependencies and layers! Get it to market! Cash out! Build a
community! Become its figurehead! Sell the community! Pass the plate! Don’t forget
to Like Comment and Subscribe! Oh and this message was sponsored by yet another
pointless VPN from a provider you can’t trust but somehow protects you from a
network you don’t trust. With such words the once so tiny tech snowball continues
its merry way down the mountain towards the village.</p>

<p>No matter the outcome, I have more things on the immediate ‘todo’ in terms of
creative things alone – than I have hours left to live, regardless of how many
those turn out to be. That is a pleasant mental image to fall back on in times of
gloom and doom.</p>

<p>My dedication to this project and the tens of thousands of invested hours has
been described as both ‘a labour of love’ as well as the more colloquial
‘fucking insane’, though personally, I view it as an act of necessity.</p>

<p>Many a times the journey has felt like digging out of a prison using the
collarbone of a fallen mate as a makeshift shovel, fuelled by the vapours of
some faint hope that there is a relatively more free world waiting within
reach, and that the proverbial roses I can smell are not just a hallucinogenic
side effect from some invisible gas deposit that this old canary has stumbled
upon.</p>

<p>The motivation is not all some evolutionary struggle for freedom. The rest
comes from bitter anger, even resentment, towards the dominant status quo and
the trajectory that computing interfaces as a whole is moving along; pandering
to trivial attention grabbing nonsense (‘engagement’) rather than crafting
sharper tools that can claw at the delicious problems that the future holds in
store.</p>

<h2 id="principle-1-professionals-first">Principle 1: Professionals First</h2>


<p>The traditional desktop is a compromise of interests, with the more recent bias
being towards appealing to a supposed ‘mainstream’ audience. This made sense
from an economical growth standpoint within the kinetics of the peculiar brand
of capitalism at the time; the previous demographic was already hooked on the
computing drug - being ‘users’ after all.</p>

<p>The thing nowadays is that the load-bearing mainstream audience is opting out at
a rapid rate and for good reason; smartphones, tablets, digital ‘assistants’,
gaming consoles and so on are all chopping up the generic ‘desktop’ into more
controlled corporate thiefdoms.</p>

<p>Many of the past compromises that were made in order to accomodate this wider
and less experienced audience are also unnecessarily restricting agency,
precision and and efficiency for those (‘the professional’) who possess both a
stronger mental model of computing, and a vested interest in its advancement.</p>

<p>It makes little sense to try and convince your grandmother that she needs a
Free! Open-Source! desktop, and it is a farce, bordering on self-harm, to still
use that scenario as part of some requirement specification for the future.</p>

<p>That aside, the ‘professional’ here is not meant as a vain appeal to exclusionary
hacker elitism – before the numbers of those within such lines dip towards that
of past ‘biker freedom’ seekers such as radio ‘amateurs’, circuit benders and
BBS operators. The ‘professional’ is acknowledging that there is a large number
(millions) of key individuals in a wide gamut of professions that are currenty
wasting much of their time and talents thanks to misguided attempts at software
ergonomics that will try and make due with what the web can give them, but they
should not have to.</p>

<p><em>Revisit past workflows, put the professional first.</em></p>


<h2 id="principle-2-diversify-experience">Principle 2: Diversify Experience</h2>

<p>A long standing maxim in computing is that of ‘mechanism, not policy’. From
a user experience perspective, it is rooted in the assumption that the user
is both willing- and capable- of leveraging mechanisms and configure them into
their own sets of policies. This has largely failed in the ‘desktop’ sense,
and very much stagnated in the command-line processing one.</p>

<p>There are many possible reasons for this, and one likely culprit on a high
level is the marketing gospel of ‘it just works’. This is a rhetoric which
strongly favours a ‘brand identity’ preset of strict policies and aesthetics
at the desktop level and beyond. Its implementation allows for little to no
accessible layering in between the opaqueness of a UI element such as a
‘button’ and the set of actions the idea of it ‘working’ represents.</p>

<p>This turns into a problem when your personal expectations of what ‘just works’
happens to clash with those of …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.divergent-desktop.org/blog/2020/08/10/principles-overview/">https://www.divergent-desktop.org/blog/2020/08/10/principles-overview/</a></em></p>]]>
            </description>
            <link>https://www.divergent-desktop.org/blog/2020/08/10/principles-overview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24128112</guid>
            <pubDate>Wed, 12 Aug 2020 02:44:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time take some notes of the Vue 3 new features]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24127926">thread link</a>) | @daiyanze
<br/>
August 11, 2020 | https://pitayan.com/posts/vue-next-features/?ref=hackernews | <a href="https://web.archive.org/web/*/https://pitayan.com/posts/vue-next-features/?ref=hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Vue-next (Vue 3) has been out for a while. It is now under release candidate stage which means there won't be big changes on the open APIs. Good to see that Vue has already been stabilized and ready to waltz into our projects.</p><p>I have to say that Vue 2 is already amazing enough. But with Vue 3's new features, it's likely to upgrade our projects to an upper level. I guess the most thrilling feature in Vue 3 would be the composition APIs. Evan You himself mentioned that the composition APIs are inspired by the React hooks. Even though the two APIs hooks and compositions are a lot alike, but from the code base they are completely different. Let's not discuss which is better or promising because I don't really think either framework outraces another.</p><p>In all, it's so happy to see that Vue can also do what React does. Let's have a close look at the new features.</p><p><strong>TLDR;</strong></p><h2 id="1-vite"><a href="#1-vite">1. Vite</a></h2><p>This is another work of art by Evan You which is aim at replacing <a href="https://webpack.js.org/" target="_blank" rel="nofollow noopener noreferrer">Webpack</a> in Vue development (Currently only works for Vue). It is designed to be <strong>fast</strong> just as its French name implies.</p><h3 id="getting-started-with-vite"><a href="#getting-started-with-vite">Getting started with Vite</a></h3><p>The official repo offers us a simple way to create a Vue 3 app via <a href="https://github.com/vitejs/vite" target="_blank" rel="nofollow noopener noreferrer">Vite</a>.</p><h4 id="npm"><a href="#npm">Npm</a></h4><pre><code>$ <span>npm</span> init vite-app <span>&lt;</span>project-name<span>&gt;</span>
$ <span>cd</span> <span>&lt;</span>project-name<span>&gt;</span>
$ <span>npm</span> <span>install</span>
$ <span>npm</span> run dev</code></pre><h4 id="yarn"><a href="#yarn">Yarn</a></h4><pre><code>$ <span>yarn</span> create vite-app <span>&lt;</span>project-name<span>&gt;</span>
$ <span>cd</span> <span>&lt;</span>project-name<span>&gt;</span>
$ <span>yarn</span>
$ <span>yarn</span> dev</code></pre><h4 id="start-dev-server"><a href="#start-dev-server">Start Dev Server</a></h4><p>It all happened in a blink of eyes.</p><pre><code> ❯ <span>yarn</span> dev
<span>yarn</span> run v1.22.4
$ vite
vite v1.0.0-rc.4

  Dev server running at:
  <span>&gt;</span> Local:    http://localhost:3000/
  <span>&gt;</span> Network:  http://192.168.3.2:3000/
  <span>&gt;</span> Network:  http://10.80.67.216:3000/</code></pre><p>Open <a href="http://localhost:3000/" target="_blank" rel="nofollow noopener noreferrer">http://localhost:3000/</a></p><p><img src="https://d33wubrfki0l68.cloudfront.net/2034634f2673e257ab1b703f5d07e96d61a3a817/8f350/assets/static/dev_page.11f1dba.c210fe88245971e2eae43a08611a570a.png" width="1564" alt="dev page" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1564 842' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-5a42c3e9f46b3e235f13b4609018a33a'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-5a42c3e9f46b3e235f13b4609018a33a)' width='1564' height='842' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAiCAYAAADvVd%2bPAAAACXBIWXMAABYlAAAWJQFJUiTwAAAE5klEQVRo3uVY60%2bTVxjnr9mXfXIreBvDclnmssQtLplRYdnC5j6ZRZdlEwVEhGSOqTgTqkwzqU5ELgIVwTLYxaTRaIxzi5IhLe3b0vvbFnqj7W/nOaXs5V3tUPu21p3k5PS5nbzP7zyX01OE//koUmLTRCLBZ%2bp3XDrj8eSUyGnIZamZkOkVBABSIFYjX61eQUaAI%2bSDMeCAecEFk8sOo8mKaZMFLo%2bYPHl24jSIJj7JSY/0yc4RFAsvAuhjY4mkY3rhd2wcrkeVvgXq7gase/cjvFK1A1s%2b3AOvz891vL4Ao/diTeUOLldfbOD6G5idXrjHdVL7FUwKSKNg780ulAzWoWKSOXXwM5RUVOOl0q1o69ByeZtGy2nik5z0SJ/s5HsVTARIT%2b2BKEA90gT16CGodU1Yu70Wa8q3o2zrJxgc%2bxmb3tvFaeKTnOuNHOJ2Sp6%2b4hEg/fhv7%2bugurIPlROteK39C6gqd0K1uRqqN6tR/FYNp4lPctI7%2boduhX3BdQFpe6PhDgfwzvg3KNU1ovx6M9bt%2bhSqip0ofvsDvhJN/NKrjdjC9Ehfal/QbTC2VOkvzxhQzHK7crwFr/9Qh%2bLNNcuTaOKTvIfpSe0Krg3KC6E0HWpvaLB%2b6AAqJlhB/Go3Xl2/DRu%2b3M1p4tf%2bplnhuJIFUHEA0tUCg2OKtzcK97LLDVhb8zFfid6oq%2bfyXOR%2bzgCQnmR8yakDd7pRMsTa4mgzNg008pXo%2bjuXlvNe6ZPPOQBJx5IAzLAbXtXoYZSx1lg%2b1sxXounmJ9V7YQBIVxA1D/RQDe3DG6MtbK3jdK4KX14BSK2BaAjbJo%2bjZHg/3mcr0bkqfHkBIF0UXLPcxcv9n/M1H6efcwDk9/pwLIozUxN8XXH6eMEBkJ9yIgcPH4oCIP14uTPpZPLXotXoKwVSUbbDernnx//5B0e5LXck9fyV7tUnBYwcXKlNtgplkRLhLR2Li4sZbWKxGCLR6IrXodSIZyiK2YqCrKYAOXKuZxADIz/hkcmC7ivX0Hm%2bDw%2bnjfAH5qH/xYCLAyNcNm0046%2bZWQSDIXScuwSP6IO2dxiG2/cwvxDkco9XRP/VcfQMjqFPp8etu/cx9ciU1VTIKgChcAQnOs/jzIU%2b7G9tR2t7J46cPIv6r08yp82YvHELRzVdOK3txZ6GI/ju%2bwtYYAAcO9XFZDdx/LQWvxpu48%2bH01yHxgmm0zt8HWd/7EdTWwcOHzuVMTLyCgB9GIV0LBZnjgUZIGEEQ2F4RT/np0Ke3gJ9LCKiLD0ikSgcLjcC8ws8CsKRyL/SgPTCDFzSCbH9nrsUyHZl/q/b4HObAo9rXY9rZ5kcz7Rn3rpApn7/RFdhlgY2mw0mkwmCIPDpcDiW0ySRpgVmul/kNAKe5rTlk9cBrxdOpxOiKMLj8cLvT9aJZ9n3aUApyleeK33VVhQAu9PFe7jRLPCKbrHaIdjscLo8sM45WFX3wOX28t80qbqbrXOYc7g43%2bn2cB7p2Z1u2OxOrkf7zVpsnE7xLMzOOCtghk2yNZmtXI9WktM6K9i4XTS6mJsIoIsKgeBkH0Qtzrz0keQgB4I5SM6laHKWVqLd7HKTtPMlwfH64PaIcLE0sDAd4hNNfJpkQ2AITJcuU%2bQsgUK2BB61UJLTnooDUAhpkJMUeNZCpeR8UhD%2bBhE83vnWJWvmAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-src="https://d33wubrfki0l68.cloudfront.net/2034634f2673e257ab1b703f5d07e96d61a3a817/8f350/assets/static/dev_page.11f1dba.c210fe88245971e2eae43a08611a570a.png" data-srcset="https://d33wubrfki0l68.cloudfront.net/053cd1d0fc9690cc1a5ba8c724e1bb8846f40185/b7189/assets/static/dev_page.82a2fbd.c210fe88245971e2eae43a08611a570a.png 480w, https://d33wubrfki0l68.cloudfront.net/d0f140235ea1447550d7e307e3e6630cae793dbb/42d8a/assets/static/dev_page.cbab2cf.c210fe88245971e2eae43a08611a570a.png 1024w, https://d33wubrfki0l68.cloudfront.net/2034634f2673e257ab1b703f5d07e96d61a3a817/8f350/assets/static/dev_page.11f1dba.c210fe88245971e2eae43a08611a570a.png 1564w"></p><h3 id="vue-next-features"><a href="#vue-next-features">vue-next-features</a></h3><ul><li><a href="https://github.com/daiyanze/vue-next-features" target="_blank" rel="nofollow noopener noreferrer">repository link</a></li><li><a href="https://daiyanze.com/vue-next-features/dist/" target="_blank" rel="nofollow noopener noreferrer">demo link</a></li></ul><p>I created a small app to <a href="https://daiyanze.com/vue-next-features/dist/" target="_blank" rel="nofollow noopener noreferrer">demo</a> the new features of Vue 3. If you take a look at the projects' <code>package.json</code>, the simplicity of <a href="https://github.com/daiyanze/vue-next-features" target="_blank" rel="nofollow noopener noreferrer">vue-next-features</a> dependencies will make you fond of <a href="https://github.com/vitejs/vite" target="_blank" rel="nofollow noopener noreferrer">Vite</a> immediately. (I mean, who doesn't want a simpler <code>package.json</code> to start with?)</p><p>There is another Vue 3 "Hello World" repo (<a href="https://github.com/vuejs/vue-next-webpack-preview" target="_blank" rel="nofollow noopener noreferrer">vue-next-webpack-preview</a>) bundled with <a href="https://webpack.js.org/" target="_blank" rel="nofollow noopener noreferrer">Webpack</a>. It is also a good playground.</p><p><a href="https://github.com/daiyanze/vue-next-features" target="_blank" rel="nofollow noopener noreferrer"><strong>vue-next-features</strong></a></p><pre><code><span>{</span>
  ...<span>,</span>
  <span>"dependencies"</span><span>:</span> <span>{</span>
    <span>"vite"</span><span>:</span> <span>"^1.0.0-rc.4"</span><span>,</span>
    <span>"vue"</span><span>:</span> <span>"^3.0.0-rc.5"</span>
  <span>}</span><span>,</span>
  <span>"devDependencies"</span><span>:</span> <span>{</span>
    <span>"@vue/compiler-sfc"</span><span>:</span> <span>"^3.0.0-rc.5"</span>
  <span>}</span>
<span>}</span></code></pre><p><a href="https://github.com/vuejs/vue-next-webpack-preview" target="_blank" rel="nofollow noopener noreferrer"><strong>vue-next-webpack-preview</strong></a></p><pre><code><span>{</span>
  ...<span>,</span>
  <span>"dependencies"</span><span>:</span> <span>{</span>
    <span>"vue"</span><span>:</span> <span>"^3.0.0-beta.2"</span>
  <span>}</span><span>,</span>
  <span>"devDependencies"</span><span>:</span> <span>{</span>
    <span>"@vue/compiler-sfc"</span><span>:</span> <span>"^3.0.0-beta.2"</span><span>,</span>
    <span>"css-loader"</span><span>:</span> <span>"^3.4.2"</span><span>,</span>
    <span>"file-loader"</span><span>:</span> <span>"^6.0.0"</span><span>,</span>
    <span>"mini-css-extract-plugin"</span><span>:</span> <span>"^0.9.0"</span><span>,</span>
    <span>"url-loader"</span><span>:</span> <span>"^4.0.0"</span><span>,</span>
    <span>"vue-loader"</span><span>:</span> <span>"^16.0.0-alpha.3"</span><span>,</span>
    <span>"webpack"</span><span>:</span> <span>"^4.42.1"</span><span>,</span>
    <span>"webpack-cli"</span><span>:</span> <span>"^3.3.11"</span><span>,</span>¥
    <span>"webpack-dev-server"</span><span>:</span> <span>"^3.10.3"</span>
  <span>}</span>
<span>}</span></code></pre><h2 id="2-composition-api"><a href="#2-composition-api">2. Composition API</a></h2><p>As the biggest the change of <a href="https://vuejs.org/" target="_blank" rel="nofollow noopener noreferrer">Vue.js</a>, the composition API would become your next most frequently and commonly used feature. Just like <a href="https://reactjs.org/docs/hooks-reference.html#" target="_blank" rel="nofollow noopener noreferrer">React hooks</a>, with the Vue composition API will help gain more customizibilities.</p><p>Here is a list of the Vue 3 composition APIs. (There are actually more...)</p><ul><li><p>Reactivity</p><ul><li><code>computed</code>&nbsp;<code>reactive</code>&nbsp;<code>ref</code>&nbsp;<code>readonly</code></li><li><code>watch</code>&nbsp;<code>watchEffect</code>&nbsp;<code>unref</code>&nbsp;<code>toRefs</code></li><li><code>isRef</code>&nbsp;<code>isProxy</code>&nbsp;<code>isReactive</code>&nbsp;<code>isReadonly</code></li><li><code>customRef</code>&nbsp;<code>markRaw</code>&nbsp;<code>shallowReactive</code></li><li><code>shallowReadonly</code>&nbsp;<code>shallowRef</code>&nbsp;<code>toRaw</code></li></ul></li><li><p>Lifecycle Hooks</p><ul><li><code>onBeforeMount</code>&nbsp;<code>onBeforeUnmount</code>&nbsp;<code>onBeforeUpdate</code>&nbsp;</li><li><code>onMounted</code>&nbsp;<code>onUpdated</code>&nbsp;<code>onErrorCaptured</code>&nbsp;</li><li><code>onRenderTracked</code>&nbsp;<code>onRenderTriggered</code>&nbsp;<code>onUnmounted</code>&nbsp;</li><li><code>onActivated</code>&nbsp;<code>onDeactivated</code>&nbsp;</li></ul></li></ul><p>Visit Vue 3 official doc to know more about these APIs.
<a href="https://v3.vuejs.org/api/composition-api.html" target="_blank" rel="nofollow noopener noreferrer">https://v3.vuejs.org/api/composition-api.html</a></p><h3 id="component-styles"><a href="#component-styles">Component Styles</a></h3><h4 id="in-vue-2"><a href="#in-vue-2">In Vue 2</a></h4><p>Use configuration template to define the component contents. In Vue 3, this legacy usage is still available. If you'd prefer this style, you can continue using it.</p><pre><code><span><span><span>&lt;</span>template</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>button</span> <span>@click</span><span><span>=</span><span>"</span>count++<span>"</span></span><span>&gt;</span></span>count: {{ count }}<span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>template</span><span>&gt;</span></span>

<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
<span>const</span> multiplier <span>=</span> <span>2</span>

<span>export</span> <span>default</span> <span>{</span>
  <span>data</span> <span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>{</span>
      count<span>:</span> <span>0</span>
    <span>}</span>
  <span>}</span><span>,</span>
  computed<span>:</span> <span>{</span>
    <span>result</span> <span>(</span><span>)</span> <span>{</span>
      <span>return</span> <span>this</span><span>.</span><span>count</span> <span>*</span> multiplier
    <span>}</span>
  <span>}</span><span>,</span>
  <span>mounted</span> <span>(</span><span>)</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>this</span><span>.</span><span>count</span><span>)</span>
  <span>}</span><span>,</span>
  watch<span>:</span> <span>{</span>
    <span>count</span> <span>(</span><span>val<span>,</span> oldVal</span><span>)</span> <span>{</span>
      <span>console</span><span>.</span><span>log</span><span>(</span>val<span>,</span> oldVal<span>)</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre><h4 id="in-vue-3"><a href="#in-vue-3">In Vue 3</a></h4><p>To use the composition API, you'll need to add a <code>setup</code> property in to the default export. The below code is completely equivalent to the <a href="#in-vue-2">code above</a>.</p><pre><code><span><span><span>&lt;</span>template</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>button</span> <span>@click</span><span><span>=</span><span>"</span>count++<span>"</span></span><span>&gt;</span></span>count: {{ count }}<span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>template</span><span>&gt;</span></span>

<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
<span>import</span> <span>{</span> computed<span>,</span> reactive<span>,</span> toRefs<span>,</span> onMounted<span>,</span> watch <span>}</span> <span>from</span> <span>'vue'</span>

<span>export</span> <span>default</span> <span>{</span>
  <span>setup</span> <span>(</span><span>)</span> <span>{</span>
    <span>const</span> multiplier <span>=</span> <span>2</span>

    <span>const</span> state <span>=</span> <span>reactive</span><span>(</span><span>{</span>
      count<span>:</span> <span>0</span>
    <span>}</span><span>)</span>

    <span>const</span> result <span>=</span> <span>computed</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>return</span> state<span>.</span><span>count</span> <span>*</span> multiplier
    <span>}</span><span>)</span>

    <span>onMounted</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>console</span><span>.</span><span>log</span><span>(</span>state<span>.</span><span>count</span><span>)</span>
    <span>}</span><span>)</span>

    <span>watch</span><span>(</span>state<span>.</span><span>count</span><span>,</span> <span>(</span><span>val<span>,</span> oldVal</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>console</span><span>.</span><span>log</span><span>(</span>val<span>,</span> oldVal<span>)</span>
    <span>}</span><span>)</span>

    <span>return</span> <span>{</span>
      <span>...</span><span>toRefs</span><span>(</span>state<span>)</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre><h4 id="go-ahead-with-the-new-api"><a href="#go-ahead-with-the-new-api">Go Ahead with the new API</a></h4><p>There are 4 reasons why you should use composition API over the default Vue 2 config template:</p><ul><li>To increase readability of source code</li><li>To avoid duplicated or redundant logics</li><li>To group up similar logics</li><li><strong>To reuse the logics</strong></li></ul><p>Compared to the Vue 2 configuration style, the logics are precisely broken down into smaller particals so that you could group the similar logics together easily. In this way, it also reduces chances jumping around from irrelavant logics. This will help increase the productivity without a doubt.</p><h2 id="2-advanced-reactivity-api"><a href="#2-advanced-reactivity-api">2. Advanced Reactivity API</a></h2><p>Personally, I think this is nothing different to the other reactivity APIs. But it indeed offers those abilities of handling edge cases like <strong>custom hooks</strong> and <strong>shallow layer modification</strong>. It is now part of the <a href="https://v3.vuejs.org/api/basic-reactivity.html" target="_blank" rel="nofollow noopener noreferrer">basic reactivity API</a> according to the Vue 3 official doc.</p><p>In the <a href="https://composition-api.vuejs.org/" target="_blank" rel="nofollow noopener noreferrer">Vue composition api</a> doc (Yes, there's a doc only for the composition APIs), the following APIs are listed as <strong>advanced reactivity apis</strong>.</p><ul><li>customRef: custom hook</li><li>markRaw: not able to be a <code>reactive</code></li><li>shallowReactive: Object's first layer <code>reactive</code></li><li>shallowReadonly: Object's first layer <code>readonly</code></li><li>shallowRef: Object's value not <code>reactive</code></li><li>toRaw: restore a <code>reactive</code> to normal Object</li></ul><p>Are you farmiliar with <code>Debounce</code>? Here is an official demo of <code>customRef</code>:</p><pre><code><span>import</span> <span>{</span> customRef <span>}</span> <span>from</span> <span>'vue'</span>

<span>const</span> <span>useDebouncedRef</span> <span>=</span> <span>(</span><span>value<span>,</span> delay <span>=</span> <span>200</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>let</span> timeout
  <span>return</span> <span>customRef</span><span>(</span><span>(</span><span>track<span>,</span> trigger</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> <span>{</span>
      <span>get</span><span>(</span><span>)</span> <span>{</span>
        <span>track</span><span>(</span><span>)</span>
        <span>return</span> value
      <span>}</span><span>,</span>
      <span>set</span><span>(</span>newValue<span>)</span> <span>{</span>
        <span>clearTimeout</span><span>(</span>timeout<span>)</span>
        timeout <span>=</span> <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
          value <span>=</span> newValue
          <span>trigger</span><span>(</span><span>)</span>
        <span>}</span><span>,</span> delay<span>)</span>
      <span>}</span><span>,</span>
    <span>}</span>
  <span>}</span><span>)</span>
<span>}</span>

<span>export</span> <span>default</span> <span>{</span>
  <span>setup</span> <span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>{</span>
      text<span>:</span> <span>useDebouncedRef</span><span>(</span><span>'some text'</span><span>)</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre><h2 id="3-v-enter-from--v-leave-from"><a href="#3-v-enter-from--v-leave-from">3. v-enter-from / v-leave-from</a></h2><p>In Vue 2, the <code>&lt;Transition&gt;</code> component helps handle the component <code>animation</code> / <code>transition</code>. But the component property <code>v-enter-active</code>&nbsp;<code>v-enter</code>&nbsp;<code>v-enter-to</code> were quite ambiguous to me. Sometimes I'm confused which happens first.</p><p>Now in Vue 3, those transition property names became more unified and intuitive.</p><ul><li><code>v-enter</code> =&gt; <code>v-enter-from</code></li><li><code>v-leave</code> =&gt; <code>v-leave-from</code></li></ul><pre><code><span><span><span>&lt;</span>template</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>transition</span> <span>name</span><span><span>=</span><span>"</span>fade<span>"</span></span><span>&gt;</span></span>
    <span><span><span>&lt;</span>div</span> <span>v-show</span><span><span>=</span><span>"</span>show<span>"</span></span><span>&gt;</span></span>fade transition<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>transition</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>template</span><span>&gt;</span></span>

<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
<span>import</span> <span>{</span> reactive<span>,</span> toRefs <span>}</span> <span>from</span> <span>'vue'</span>
<span>export</span> <span>default</span> <span>{</span>
  <span>setup</span> <span>(</span><span>)</span> <span>{</span>
    <span>const</span> state <span>=</span> <span>reactive</span><span>(</span><span>{</span>
      show<span>:</span> <span>true</span>
    <span>}</span><span>)</span>

    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
      state<span>.</span><span>show</span> <span>=</span> <span>false</span>
    <span>}</span><span>,</span> <span>1000</span><span>)</span>

    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
      state<span>.</span><span>show</span> <span>=</span> <span>true</span>
    <span>}</span><span>,</span> <span>2000</span><span>)</span>

    <span>return</span> <span>{</span>
      <span>...</span><span>toRefs</span><span>(</span>state<span>)</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>

<span><span><span>&lt;</span>style</span><span>&gt;</span></span><span><span>
<span><span>.fade-enter-from</span>,
<span>.fade-leave-to</span></span> <span>{</span>
  <span>opacity</span><span>:</span> <span>0</span><span>;</span>
<span>}</span>

<span><span>.fade-enter-to</span>,
<span>.fade-leave-from</span></span> <span>{</span>
  <span>opacity</span><span>:</span> <span>1</span><span>;</span>
<span>}</span>

<span><span>.fade-enter-active</span>,
<span>.fade-leave-active</span></span> <span>{</span>
  <span>transition</span><span>:</span> opacity <span>2000</span><span>ms</span><span>;</span>
<span>}</span>

</span></span><span><span><span>&lt;/</span>style</span><span>&gt;</span></span></code></pre><p>The transition order:</p><ol><li><code>v-enter-from</code> (v-enter)</li><li><code>v-enter-active</code></li><li><code>v-enter-to</code></li><li><code>v-leave-from</code> (v-leave)</li><li><code>v-leave-active</code></li><li><code>v-leave-to</code></li></ol><p>I believe this is much easier to understand, isn't it?</p><h2 id="4-allow-multiple-root-element"><a href="#4-allow-multiple-root-element">4. Allow Multiple Root Element</a></h2><p>Vue 2 throws errors on multiple root element. All elements must be nested within one root element in the template.</p><pre><code>
<span><span><span>&lt;</span>template</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span><span>&gt;</span></span>pitayan<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span><span>&gt;</span></span>blog<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>template</span><span>&gt;</span></span>


<span><span><span>&lt;</span>template</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>div</span><span>&gt;</span></span>pitayan<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>div</span><span>&gt;</span></span>blog<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>template</span><span>&gt;</span></span></code></pre><p>Vue 3 removed this annoying usage. I think this is extremely helpful when you really don't want to nest your elements within a "container" parent. Sometimes all you need is maybe just to insert those bare elements into the right place.</p><p>This works similarly to the <a href="https://reactjs.org/docs/fragments.html" target="_blank" rel="nofollow noopener noreferrer">React Fragments</a> which helps mitigate the nesting issues.</p><pre><code>

<span><span><span>&lt;</span>template</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span><span>&gt;</span></span>pitayan<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span><span>&gt;</span></span>blog<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>template</span><span>&gt;</span></span></code></pre><h2 id="5-filters-is-deprecatedremoved"><a href="#5-filters-is-deprecatedremoved">5. "Filters" is Deprecated(Removed)</a></h2><p>I think a lot of people think that <code>filters</code> is maybe an awesome feature of Vue.js. It indeed works well in Vue's template engine. (For example, data formatting / calculation etc).</p><p>Let's see how Vue 3 doc explains why <code>filters</code> is removed:</p><blockquote><p>While this seems like a convenience, it requires a custom syntax that breaks the assumption of expressions inside of curly braces being "just JavaScript," which has both learning and implementation costs.</p></blockquote><p>I believe it's nothing bad for development without the <code>filters</code>, even though it may cost you extra time on migrating to Vue 3. In my projects, the appearance of <code>filters</code> is pretty a rare case since I could replace such functionality with a <code>method</code> or <code>computed</code> easily. Because in my opinion, <code>method</code> / <code>computed</code> has higher readability than the <code>filters</code>.</p><pre><code><span><span><span>&lt;</span>template</span><span>&gt;</span></span>
  
  <span><span><span>&lt;</span>span</span><span>&gt;</span></span>{{ count | double }}<span><span><span>&lt;/</span>span</span><span>&gt;</span></span>

  
  <span><span><span>&lt;</span>span</span><span>&gt;</span></span>{{ double(count) }}<span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>template</span><span>&gt;</span></span>

<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
<span>import</span> <span>{</span> ref <span>}</span> <span>from</span> <span>'vue'</span>

<span>export</span> <span>default</span> <span>{</span>
  
  filters<span>:</span> <span>{</span>
    <span>double</span> <span>(</span><span>val</span><span>)</span> <span>{</span>
      <span>return</span> val <span>*</span> <span>2</span>
    <span>}</span>
  <span>}</span><span>,</span>
  <span>setup</span> <span>(</span><span>)</span> <span>{</span>
    <span>const</span> count <span>=</span> <span>ref</span><span>(</span><span>1</span><span>)</span>
    <span>return</span> <span>{</span>
      count<span>,</span>
      <span>double</span><span>:</span> <span>val</span> <span>=&gt;</span> val <span>*</span> <span>2</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre><h2 id="6-new-async-component-suspense"><a href="#6-new-async-component-suspense">6. New Async Component: Suspense</a></h2><p>This is perhaps the only new feature of Vue 3 that may be changed even after official release. The inspiration is also from <a href="https://reactjs.org/docs/concurrent-mode-suspense.html" target="_blank" rel="nofollow noopener noreferrer">React Suspense</a>. So the usage scenario would be the same in my opinion.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/1cda6d13a1104cb1ce0a59b8740a43022c81e4ea/31f27/assets/static/suspense_exp.0ef7beb.41af1099f26ed8e0abb7f89a48e781a7.png" width="1218" alt="suspense experimental feature" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1218 86' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-f2cf534e3da73bad13e1a952fc3e212a'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-f2cf534e3da73bad13e1a952fc3e212a)' width='1218' height='86' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAFCAYAAAD1/OoBAAAACXBIWXMAABYlAAAWJQFJUiTwAAABpklEQVQ4y81T2WoCQRDc//%2bQ5EVBRfFeFUUQUaMunrDex65XPNH1qFANaxIwiiEPaShm6Knuru6ZUSzriJ/scrngGbMs6%2b758fhZa7/fC2jn8xmHw%2bFbPfpOp5OshLEw8L55v5vzln47/lYc9SqqGkcsFkMkEkE8HheEw2FomoZisYhqtYpQKIRmsyk87slRVRWBQACpVErgcrmQz%2bcllvt0Oo1kMolKpYJoNCp%2bOxdzOxwOZLNZFAoFeDweiXW73QgGg8L/2thuv8Vr%2bgWhtyC0koZEIgG/3w%2bfzwev1yu1GMceqIVnuVxOGmeTxGAwkB5arRZ0XUe73RaOUq83RFC5XEan08FwOJTD%2bXyOxWKByWQi/tVqhW63i0ajgV6vB8MwhDsajWCapiRdr9fiYxFyuJ/NZhLX7/clB4VMp1PJzxfAWObYbDbCJ4/1ePvX2zodUeqUoBs6TMMUHjkE%2bUStVpO61GX7t9vt9SUwP7WwLuvvdjssl0sonBwn6HQ6kclk8J%2bMwp/9hs9%2bY4WTIMbjsdwgJ38PfJqPOH8B%2b%2b/a%2bK2uR/EfptS71/ec8EoAAAAASUVORK5CYII=' /%3e%3c/svg%3e" data-src="https://d33wubrfki0l68.cloudfront.net/1cda6d13a1104cb1ce0a59b8740a43022c81e4ea/31f27/assets/static/suspense_exp.0ef7beb.41af1099f26ed8e0abb7f89a48e781a7.png" data-srcset="https://d33wubrfki0l68.cloudfront.net/ed0455ed5b8e065cf0e2f8a76a1b336accf3ff0d/d96f8/assets/static/suspense_exp.82a2fbd.41af1099f26ed8e0abb7f89a48e781a7.png 480w, https://d33wubrfki0l68.cloudfront.net/1cda6d13a1104cb1ce0a59b8740a43022c81e4ea/31f27/assets/static/suspense_exp.0ef7beb.41af1099f26ed8e0abb7f89a48e781a7.png 1218w"></p><p>Do you remember how you render the asynchronous data previously in Vue 2? I think <code>v-if</code> / <code>v-else</code> should be the answer.</p><pre><code><span><span><span>&lt;</span>template</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>div</span> <span>v-for</span><span><span>=</span><span>"</span>i in items<span>"</span></span> <span>:key</span><span><span>=</span><span>"</span>i<span>"</span></span><span>&gt;</span></span>{{ i }}<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>div</span> <span>v-else</span><span>&gt;</span></span>loading...<span><span><span>&lt;</span>div</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>template</span><span>&gt;</span></span>

<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
<span>export</span> <span>default</span> <span>{</span>
  <span>data</span> <span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>{</span>
      items<span>:</span> <span>null</span>
    <span>}</span>
  <span>}</span><span>,</span>
  <span>mounted</span> <span>(</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>items</span> <span>=</span> <span>await</span> <span>new</span> <span>Promise</span><span>(</span><span>resolve</span> <span>=&gt;</span> <span>{</span>
      <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span>…</span></span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pitayan.com/posts/vue-next-features/?ref=hackernews">https://pitayan.com/posts/vue-next-features/?ref=hackernews</a></em></p>]]>
            </description>
            <link>https://pitayan.com/posts/vue-next-features/?ref=hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-24127926</guid>
            <pubDate>Wed, 12 Aug 2020 02:02:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[List of E-Voting, Deliberation, and E-Democracy Projects]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24127907">thread link</a>) | @MavropaliasG
<br/>
August 11, 2020 | https://democracy.foundation/similar-projects/ | <a href="https://web.archive.org/web/*/https://democracy.foundation/similar-projects/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="primary">
<article id="post-853" class="page" itemscope="itemscope" itemtype="http://schema.org/Article">

	
    <div itemprop="description">

		
<p>This is a continuously-updated, alphabetical list of projects similar to <a href="https://democracy.foundation/epitome/">Epitome</a> and open source software with a short description. If your project is not listed, please send us a message with your project’s website and description through our <a rel="noopener noreferrer" href="https://democracy.foundation/contact/" target="_blank">contact</a> page.</p>



<p><strong>Voting Platforms:</strong></p>



<ol><li><a rel="noopener noreferrer" href="https://github.com/Emberwalker/Arke" target="_blank">Arke</a> – Anonymised voting with identity checking.</li><li><a rel="noopener noreferrer" href="https://github.com/republique-et-canton-de-geneve/chvote-1-0" target="_blank">CHVote</a> – A concrete answer and a real breakthrough in digital technology and e-government.</li><li><a rel="noopener noreferrer" href="https://github.com/andrewcmyers/civs" target="_blank">CIVS</a> – Condorcet internet voting system.</li><li><a rel="noopener noreferrer" href="https://github.com/marilyndavis/evote" target="_blank">Clerk</a> – A specialized database server and user-interfaces for keeping votes. The unique architecture enables user-generated polls, secret or public votes, the ability to change your vote, and security from attack from the administrator.</li><li><a rel="noopener noreferrer" href="https://github.com/Wolnosciowiec/CollectiveVotingBundle" target="_blank">Collective Voting Bundle</a> – Allows to create voting for an action, so every allowed person could vote on specific action.</li><li><a rel="noopener noreferrer" href="https://github.com/julien-boudry/Condorcet" target="_blank">Condorcet</a> – A PHP library providing Condorcet and multiple others methods, like Schulze, Copeland, Minimax, Kemeny-Young, Ranked Pairs.</li><li><a rel="noopener noreferrer" href="https://github.com/cryptoballot/cryptoballot" target="_blank">CryptoBallot</a> – A secure election server daemon that does the grunt work to secure online voting for your web or mobile application.</li><li><a rel="noopener noreferrer" href="https://github.com/ddp2p/DDP2P" target="_blank">DDP2P</a> – Direct democracy P2P.</li><li><a rel="noopener noreferrer" href="https://github.com/mlevogiannis/demos-voting" target="_blank">Demos</a> – an end-to-end verifiable e-voting system.</li><li><a rel="noopener noreferrer" href="https://github.com/shanbay/django-vote" target="_blank">Django Vote</a> – a simple Django app to conduct vote for django model.</li><li><a rel="noopener noreferrer" href="https://github.com/cidadania/e-cidadania" target="_blank">e-cidadania</a> – An open-source e-democracy web tool intended for citizen participation.</li><li><a rel="noopener noreferrer" href="https://github.com/mdipierro/evote" target="_blank">E-Vote</a> – An open source system for secure, trusted, anonymous, and verifiable voting online.</li><li><a rel="noopener noreferrer" href="https://github.com/esek/evote" target="_blank">E-Vote</a> – a voting system designed to be used for meetings with a limited number of people.</li><li><a rel="noopener noreferrer" href="https://sourceforge.net/projects/freevote/" target="_blank">Free-Vote</a> – A complete system for web-based elections &amp; consults. Support for multiple, concurrent, fully programable elections, separate lists of voters, Web based user/lists/vote admin, email feedback, etc.</li><li><a rel="noopener noreferrer" href="https://github.com/Ernest0x/gpgvote" target="_blank">GPGVote</a> – A web-based e-voting system, based on PGP encryption.</li><li><a rel="noopener noreferrer" href="https://github.com/benadida/helios-server" target="_blank">Helios</a> – An end-to-end verifiable voting system.</li><li><a rel="noopener noreferrer" href="https://github.com/ChimeraCoder/InstaVote" target="_blank">InstaVote</a> – a Python module that determines the winner of an election using instant-runoff voting rules.</li><li><a rel="noopener noreferrer" href="https://github.com/vvk-ehk/ivxv" target="_blank">IVXV</a> – The source code behind the Estonian online voting system.</li><li><a rel="noopener noreferrer" href="https://github.com/lutoma/oavote" target="_blank">oavote</a> – A custom online voting tool to fit the requirements of the ‘Online-Abstimmung’ of Junge Piraten e.V.</li><li><a rel="noopener noreferrer" href="https://github.com/cjerdonek/open-rcv" target="_blank">OpenRCV</a> – Software for tallying ranked-choice voting elections like instant-runoff voting and single transferable vote.</li><li><a rel="noopener noreferrer" href="https://github.com/bradbeattie/python-vote-core" target="_blank">Python Vote Core</a> – Implements various electoral methods, providing the results calculated off a provided set of ballots and options.</li><li><a rel="noopener noreferrer" href="https://github.com/SpaceKrakens/Ranked-Vote" target="_blank">Ranked-Vote</a> – A ranked-voting system for developers using GitHub.</li><li><a rel="noopener noreferrer" href="https://sourceforge.net/projects/secretballot/" target="_blank">Secret ballot</a> – C/Linux server-client pubkey secret verifiable voting system.</li><li><a rel="noopener noreferrer" href="https://github.com/dessalines/simple-vote" target="_blank">SimpleVote</a> – an open-source, self-hostable, live-updating voting/polling platform, for both live meetings, or extended polls.</li><li><a rel="noopener noreferrer" href="https://github.com/morinokami/social_choice" target="_blank">Social Choice</a> – A python program to calculate the winner of well-known winner selection methods, including the plurality method, the runoff method, the elimination method, the Borda count, and the pairwise-comparison method (a.k.a. Condorcet method).</li><li><a rel="noopener noreferrer" href="https://sourceforge.net/projects/solon/" target="_blank">Solon</a> – A software project for organizing elections. It includes a program to create the lists of candidates, a program to do the actual voting, and a program to count votes.</li><li><a rel="noopener noreferrer" href="https://sourceforge.net/projects/vdemocracy/" target="_blank">Vocal Democracy</a> – This project is focused on the development of a phone-based voting system to be used in elections. The goal is to provide a reliable, intuitive and highly secure voting mechanism for voters with visual impairments and other disabilities.</li><li><a rel="noopener noreferrer" href="https://github.com/salvatorelionetti/votanto" target="_blank">Votanto</a> – The first electronic voting system recognizable by humans.</li><li><a rel="noopener noreferrer" href="https://sourceforge.net/projects/votecounter/" target="_blank">VoteCounter</a> – A distributed voting program which can handle multiple clients over a network.</li><li><a rel="noopener noreferrer" href="https://sourceforge.net/projects/vote/" target="_blank">VoteEngine</a> – Software for tabulating votes in elections, particularly using uncommon methods (Nanson, Condorcet, etc.).</li><li><a rel="noopener noreferrer" href="http://reluk.ca/project/votorola/home.html" target="_blank">Votorola</a> – An experimental technology for the public guidance of electoral systems, executive offices, legislatures, and other decision sys­tems.</li><li><a rel="noopener noreferrer" href="https://github.com/gvamos/votron" target="_blank">Votron</a> – Android client for server side Condorcet style voting system.</li><li><a rel="noopener noreferrer" href="https://github.com/vvvote/vvvote" target="_blank">VVVote</a> – Cryptographic Anonymized Online Voting System.</li><li><a rel="noopener noreferrer" href="https://github.com/grnet/zeus" target="_blank">Zeus</a> – Based on the Helios voting system but instead of election results, Zeus produces a tally of the ballots cast.</li></ol>



<p><strong>Proxy Voting/Liquid Democracy:</strong></p>



<ol><li><a rel="noopener noreferrer" href="https://github.com/ekratia/ekratia" target="_blank">Ekratia</a> – Real-time, representative and participatory democracy.</li><li><a rel="noopener noreferrer" href="https://github.com/alper/enhydris" target="_blank">enhydris</a> – A bare-bones simple majority voting system with delegates created as a proof of concept.</li><li><a rel="noopener noreferrer" href="http://www.tdcommons.org/cgi/viewcontent.cgi?article=1092&amp;context=dpubs_series" target="_blank">Google Votes</a> – An experiment in liquid democracy built on Google’s internal corporate Google+ social network.</li><li><a rel="noopener noreferrer" href="https://github.com/virteal/kudocracy" target="_blank">Kudocracy</a> – A voting system where people can either directly approve or disapprove propositions associated to tags or delegate that decision.</li><li><a rel="noopener noreferrer" href="https://github.com/nathansobo/hyperarchy" target="_blank">Hyperarchy</a> – An online decision-making tool that allows team members to pose questions, submit answers, and rank the list in their preferred order.</li><li><a rel="noopener noreferrer" href="https://github.com/uniritter/liquid-democracy" target="_blank">liquid-democracy</a> – A direct democracy project, in which the votes are held by a specific mandate to a particular issue, and is supplemented by a recommendation of action.</li><li><a rel="noopener noreferrer" href="https://github.com/phynfo/LiquidDemocracy-XXS" target="_blank">LiquidDemocracy-XXS</a> – An extremely light liquid democracy tool.</li><li><a rel="noopener noreferrer" href="http://liquidfeedback.org/" target="_blank">LiquidFeedback</a> – An open-source software, powering internet platforms for proposition development and decision making.</li><li><a rel="noopener noreferrer" href="https://github.com/MakeYourLaws/MakeYourLaws" target="_blank">MakeYourLaws</a> – A project to convert the world to liquid democracy.</li><li><a rel="noopener noreferrer" href="https://github.com/ppau/polly" target="_blank">polly</a> – a liquid democracy system with a focus on deliberative policy building and consensus finding.</li><li><a rel="noopener noreferrer" href="https://github.com/metamerman/proxyfor.me" target="_blank">proxyfor.me</a> – You provide information about yourself that will be used to match you to proxies that have already most likely voted like you would, if you had the time, experience, and motivation to properly research a proposal.</li><li><a rel="noopener noreferrer" href="https://github.com/chozabu/VoteFlow" target="_blank">VoteFlow</a> – Voting website of the future. Mesh democracy, Liquid democracy, Tree of topics – made with Django.</li></ol>



<p><strong>Blockchain Voting:</strong></p>



<ol><li><a rel="noopener noreferrer" href="https://github.com/XertroV/blocvoting" target="_blank">BlocVoting</a> – A Haskell implementation for voting securely on a satoshi blockchain using liquid democracy.</li><li><a rel="noopener noreferrer" href="https://github.com/dsx-tech/e-voting" target="_blank">e-voting</a> – Blockchain based voting system.</li><li><a rel="noopener noreferrer" href="http://e-vox.org/" target="_blank">e-Vox</a> – Open e-democracy platform.</li><li><a rel="noopener noreferrer" href="https://github.com/followmyvote" target="_blank">Follow My Vote</a> – Open source end-to-end verifiable blockchain voting software.</li><li><a rel="noopener noreferrer" href="https://github.com/jonahkall/blockchain-voting" target="_blank">OneVote</a> – A distributed blockchain-based voting system.</li><li><a rel="noopener noreferrer" href="https://github.com/stonecoldpat/anonymousvoting" target="_blank">Open Vote Network</a> – Anonymous voting on Ethereum without a tally authority.</li><li><a rel="noopener noreferrer" href="https://github.com/ConsenSys/PLCRVoting" target="_blank">PLCRVoting</a> – Smart contract for voting on the Ethereum blockchain.</li><li><a rel="noopener noreferrer" href="https://github.com/domschiener/publicvotes" target="_blank">PublicVotes</a> – Publicly verifiable and Ethereum-based voting system.</li><li><a rel="noopener noreferrer" href="https://github.com/dib0/PublicVoting" target="_blank">PublicVoting</a> – Public voting system made trustworthy and verifiable through blockchain.</li><li><a rel="noopener noreferrer" href="https://github.com/aaron-lebo/updn" target="_blank">updn</a> – Reddit-alike where submissions and voting use Bitcoin.</li><li><a rel="noopener noreferrer" href="http://votosocial.github.io/" target="_blank">VotoSocial</a> – A secure, decentralized, auditable and open platform for e-voting and vote counting that everybody can trust.</li><li><a rel="noopener noreferrer" href="https://github.com/descampsk/wavevote" target="_blank">WaveVote</a> – a voting system based on Ethereum.</li></ol>



<p><strong>Deliberation/Governance Platforms:</strong></p>



<ol><li><a rel="noopener noreferrer" href="https://github.com/liqd/adhocracy" target="_blank">Adhocracy</a> – A policy drafting and decision making software for distributed groups and open institutions by liquid democracy e.V.</li><li><a rel="noopener noreferrer" href="https://github.com/agoravoting/" target="_blank">Agora Voting</a> – A secure open-source online voting software that protects the privacy of the vote and makes elections end-to-end verifiable.</li><li><a rel="noopener noreferrer" href="https://github.com/coorasse/Airesis" target="_blank">Airesis</a> – A decision making tool for direct democracy and e-government: participate in discussions, bring your ideas, suggest solutions and vote online.</li><li><a rel="noopener noreferrer" href="https://github.com/luisivan/asturixpeople" target="_blank">Asturix People</a> – A direct democracy system.</li><li><a rel="noopener noreferrer" href="https://github.com/CivilHub/CivilHub" target="_blank">CivilHub</a> – a free and open-source platform written in Python &amp; Django for the purpose of collaboration in local civic communities.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/citizenos" target="_blank">Citizen OS</a> – An e-democracy platform for discussion, co-creation, voting, digital signatures, follow-up.</li><li><a rel="noopener noreferrer" href="https://github.com/consul/consul" target="_blank">Consul</a> – Open Government and E-Participation Web Software.</li><li><a rel="noopener noreferrer" href="https://github.com/decidim/decidim" target="_blank">Decidim</a> – The participatory democracy framework.</li><li><a rel="noopener noreferrer" href="https://github.com/Venryx/DebateMap" target="_blank">Debate Map</a> – a web platform aimed at improving the efficiency of discussion and debate.</li><li><a rel="noopener noreferrer" href="https://github.com/DemocracyEarth/sovereign" target="_blank">Democracy.Earth</a> – A decentralized liquid democracy governance platform for organizations of any size.</li><li><a rel="noopener noreferrer" href="https://github.com/DemocracyOS/democracyos" target="_blank">Democracy OS</a> – An online space for deliberation and voting on political proposals.</li><li><a href="https://democracy.foundation/epitome/" target="_blank" rel="noreferrer noopener">Epitome</a> – Epitome is an online platform of mass deliberation and consensus decision-making, that enables large groups to simultaneously communicate and develop proposals to reported issues.</li><li><a rel="noopener noreferrer" href="https://github.com/cfpb/idea-box" target="_blank">IdeaBox</a> – An application that lets an organization collect ideas, comment on them, and vote them up.</li><li><a rel="noopener noreferrer" href="https://github.com/konsento/konsento" target="_blank">Konsento</a> – Digital direct progressive consensus democracy.</li><li><a rel="noopener noreferrer" href="https://github.com/loomio/loomio" target="_blank">Loomio</a> – A collaborative decision-making tool that makes it easy for anyone to participate in decisions which affect them.</li><li><a rel="noopener noreferrer" href="http://www.opendcn.org/" target="_blank">openDCN</a> – On-line dedicated tools to support participation and deliberation.</li><li><a rel="noopener noreferrer" href="https://github.com/peer/mind" target="_blank">PeerMind</a> – This project aims to explore and improve technologies we use for decision making.</li><li><a rel="noopener noreferrer" href="https://github.com/Spokenvote/spokenvote" target="_blank">Spokenvote</a> – A web-based social consensus tool for groups of any size, from a local school board to an entire nation’s people, that radically enhances the group’s ability to reach consensus via an intuitive democratic process.</li><li><a rel="noopener noreferrer" href="https://github.com/fairdemocracy/vilfredo-core" target="_blank">Vilfredo</a> – Vilfredo allows groups from 5 to 20 people to ask open questions and reach consensus in an easy and fair way.</li><li><a rel="noopener noreferrer" href="https://github.com/openpolitics/votebot" target="_blank">Votebot</a> – A collaborative writing platform built on top of GitHub, originally designed for open policy-making and manifesto writing.</li><li><a rel="noopener noreferrer" href="https://github.com/smari/wasa2il" target="_blank">Wasa2il</a> – A participatory democracy software project. It is based around the core idea of polities – political entities – which users of the system can join or leave, make proposals in, alter existing proposals, and adopt laws to self-govern.</li><li><a rel="noopener noreferrer" href="https://github.com/CitizensFoundation/your-priorities-app" target="_blank">Your Priorities</a> – An e-democracy web application designed by the non-profit Citizens Foundation to help groups speak with one voice.</li></ol>



<p><strong>Organizations:</strong></p>



<ol><li><a rel="noopener noreferrer" href="http://dcentproject.eu/" target="_blank">D-CENT</a> – A Europe-wide project creating open, secure and privacy-aware tools for direct democracy and economic empowerment.</li><li><a rel="noopener noreferrer" href="https://liqd.net/en/" target="_blank">Liquid Democracy e.V.</a> – A non-profit that creates and implements innovative concepts for e-participation.</li></ol>



<p><strong>Direct Democracy Projects:</strong></p>



<ol><li><a rel="noopener noreferrer" href="https://www.democracy-international.org/" target="_blank">Democracy International </a> – Democracy International’s goals are to give citizens a direct say in political decision-making and to make governments more accountable.</li><li><a rel="noopener noreferrer" href="http://www.democracylab.org/" target="_blank">DemocracyLab</a> – A non-profit organization aspiring to revolutionize politics by creating and curating online tools that engage communities to solve problems.</li><li><a rel="noopener noreferrer" href="http://www.idea.int/data-tools/data/direct-democracy" target="_blank">Direct Democracy Database</a> – The Direct Democracy Database allows users to explore the different ways direct democracy is used in different countries.</li><li><a rel="noopener noreferrer" href="https://github.com/pavril/onlinedemocracy" target="_blank">DirectDemocracy</a> – a web-based voting platform dedicated to school students interested in taking part in the school decision-making.</li><li><a rel="noopener noreferrer" href="http://forums.e-democracy.org/" target="_blank">E-Democracy.org</a> – A non-profit pioneer fostering inclusive online engagement, global open government knowledge sharing, and innovative civic technology.</li><li><a rel="noopener noreferrer" href="http://free-project.org/" target="_blank">FREE e-democracy project</a> – A project dedicated to creating the GNU.FREE …</li></ol></div></article></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://democracy.foundation/similar-projects/">https://democracy.foundation/similar-projects/</a></em></p>]]>
            </description>
            <link>https://democracy.foundation/similar-projects/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24127907</guid>
            <pubDate>Wed, 12 Aug 2020 01:58:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Woz's 70th Birthday Party (Live)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24127440">thread link</a>) | @empressplay
<br/>
August 11, 2020 | https://www.twitch.tv/inspirehouse | <a href="https://web.archive.org/web/*/https://www.twitch.tv/inspirehouse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/inspirehouse</link>
            <guid isPermaLink="false">hacker-news-small-sites-24127440</guid>
            <pubDate>Wed, 12 Aug 2020 00:22:33 GMT</pubDate>
        </item>
    </channel>
</rss>
