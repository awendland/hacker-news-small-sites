<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 12 Dec 2020 01:11:55 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 12 Dec 2020 01:11:55 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Building a Web Service to Manage Scientific Simulation Data Using GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25371580">thread link</a>) | @felipez
<br/>
December 10, 2020 | https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9 | <a href="https://web.archive.org/web/*/https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://medium.com/@f.zapata?source=post_page-----a0bbf1c3f6e9--------------------------------" rel="noopener"><img alt="Felipe" src="https://miro.medium.com/fit/c/96/96/1*f7WZ93VZ5pv2qgIxOhxJUA.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="77c2">Scientific simulations generate large volume of data that needs to be stored and processed by multidisciplinary teams across different geographical locations. Distributing computational expensive simulations among the available resources, avoiding duplication and keeping the data safe are challenges that scientists face every day.</p><p id="8d66">In this post we present our web service <a href="https://insilico-server.readthedocs.io/en/latest/" rel="noopener">Insilico</a> and its command line interface <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a>. Insilico solves the problem of <em>computing</em>, <em>storing</em> and <em>securely sharing</em> computationally <em>expensive</em> simulation results. Researchers can save significant time and resources by easily computing new data and reusing existing simulation data to answer their questions.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/9856/0*bI9DbwobcmYvOYyk" width="4928" height="3280" srcset="https://miro.medium.com/max/552/0*bI9DbwobcmYvOYyk 276w, https://miro.medium.com/max/1104/0*bI9DbwobcmYvOYyk 552w, https://miro.medium.com/max/1280/0*bI9DbwobcmYvOYyk 640w, https://miro.medium.com/max/1400/0*bI9DbwobcmYvOYyk 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*bI9DbwobcmYvOYyk?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@publicpowerorg?utm_source=medium&amp;utm_medium=referral" rel="noopener">American Public Power Association</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><blockquote><p id="71c5">At the <a href="https://www.esciencecenter.nl/" rel="noopener">Netherlands eScience Center</a> we empower academic researchers by building together simulation tools, data pipelines, etc. A common goal among several tools that we develop for projects in different scientific fields, is to reduce the calculation time of computationally expensive physical simulations (e.g. molecular processes) by applying statistical methods to previously simulated data.</p></blockquote><p id="204c">The aforementioned methodology can potentially save us significant human and computational resources by easily generating high value data using previous computations. But before we are ready to apply any statistical method we of course need the data and for doing so, we need to ask ourselves questions like:</p><blockquote><p id="7c69">What input is required?</p><p id="75eb">Who is going to perform the simulation?</p><p id="a35c">What facilities are going to be used?</p><p id="93ec">Where is the resulting data going to be stored?</p><p id="6091">How to access the available data?</p></blockquote><p id="6fb9">Physical simulations usually require intricate input that takes into consideration several aspects and parameters used by different models to approximate the phenomena under consideration. Also, scientific simulations are computationally demanding tasks, so they are usually run in (inter)national supercomputers or very specialized facilities. We also want to maximize the impact of the data in the scientific community, therefore we want other scientists to be able to access the data and even add their own, but we need some security layers to protect such valuable data.</p><p id="bcb8">There is no silver bullet to address all the previous questions, but there are amazing initiatives like the <a href="https://foldingathome.org/" rel="noopener">folding at home project</a> that distributes some computational tasks among volunteers around the world who give away some time in their computers to simulate protein dynamics.</p><p id="6858">It seems that if we want to collaborate on the distribution of computational tasks and the assemblage of the resulting data, we need a central ‚Äúentity‚Äù that (1) allows users to request new tasks, (2) receives the task‚Äôs results to be stored and (3) returns some available data when requested. It sounds like we need a web service!</p><blockquote><p id="6a2b">Writing a web service is a nontrivial task, you need to be aware of different technologies, libraries, etc. while making sure that your data is going to be safe and of course you need some infrastructure to host your service. This post goal is to give you some hints about building a web service for scientific applications and it is by no means a complete guide to writing web applications.</p></blockquote><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/9662/0*HnAn4y-BQGmvGjGZ" width="4831" height="3221" srcset="https://miro.medium.com/max/552/0*HnAn4y-BQGmvGjGZ 276w, https://miro.medium.com/max/1104/0*HnAn4y-BQGmvGjGZ 552w, https://miro.medium.com/max/1280/0*HnAn4y-BQGmvGjGZ 640w, https://miro.medium.com/max/1400/0*HnAn4y-BQGmvGjGZ 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*HnAn4y-BQGmvGjGZ?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@johnschno?utm_source=medium&amp;utm_medium=referral" rel="noopener">John Schnobrich</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="a44e">Before entering into the web service technical details, let‚Äôs explore what its behavior should be.</p><p id="74cc">So, once it has been decided what are the best approximations and models to perform the simulations, we can compile all the simulation metadata into different jobs. For instance, a job can be a single molecular simulation under some specific conditions. We would like to make all these jobs available to the users, in such a way that they can run one or more jobs at a time but avoiding that the same job is run by more than one user.</p><p id="2b33">It would be great that when the simulation is done a user can send the results to the web service or ask for already available results. We also want to be able to call the web service from our local computer, specialized infrastructure or wherever we want to perform the computation, without worrying about where the service is running.</p><p id="be30">It seems, that we want a <a href="https://en.wikipedia.org/wiki/Git" rel="noopener">Git</a>-like behavior where we can pull jobs (or available data) and push results.</p><p id="ba78">With these requirements in mind, I have developed an open source web service called <a href="https://github.com/nlesc-nano/insilico-server" rel="noopener">Insilico-server</a>. Let‚Äôs see how it works!</p></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7296/0*P4hHvh84YZQLPGgi" width="3648" height="2432" srcset="https://miro.medium.com/max/552/0*P4hHvh84YZQLPGgi 276w, https://miro.medium.com/max/1104/0*P4hHvh84YZQLPGgi 552w, https://miro.medium.com/max/1280/0*P4hHvh84YZQLPGgi 640w, https://miro.medium.com/max/1400/0*P4hHvh84YZQLPGgi 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*P4hHvh84YZQLPGgi?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@andrew_gook?utm_source=medium&amp;utm_medium=referral" rel="noopener">Andrew Gook</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="773a">The web service consists of two parts: a small command line interface (CLI) that communicates with the service and the <a href="https://insilico-server.readthedocs.io/en/latest/" rel="noopener">Insilico web service</a> that handles all the data.</p><p id="0fa0">Our CLI is called <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a> and it offers several actions to interact with the service, like logging in, computing, querying, etc. as shown in the following snippet:</p><pre><span id="4e44">&gt;&gt;&gt; moka --help<br>usage: moka [-h] [--version] {login,compute,report,query,add,manage} ...</span><span id="84c2">positional arguments:<br>  {login,compute,report,query,add,manage}<br>                        Interact with the properties web service<br>    login               Log in to the Insilico web service<br>    compute             Compute available jobs<br>    report              Report the results back to the server<br>    query               Query some properties from the database<br>    add                 Add new jobs to the database<br>    manage              Change jobs status</span><span id="6b00">optional arguments:<br>  -h, --help            show this help message and exit<br>  --version             show program's version number and exit</span></pre><p id="b5c4">Using <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a> we can compute some jobs using a command like:</p><pre><span id="f521">moka compute -c collection_name -j number_of_jobs_to_compute</span></pre><p id="8e50">The previous command handles the communication with the web service, fetches the requested jobs from a given collection (or dataset) and runs them directly or invokes a <a href="https://en.wikipedia.org/wiki/Job_scheduler" rel="noopener">job scheduler</a> like <a href="https://slurm.schedmd.com/documentation.html" rel="noopener">Slurm</a>. To communicate with the service, <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a> invokes the <a href="https://requests.readthedocs.io/en/master/" rel="noopener">Python Requests library</a> that handles the communication.</p><p id="54f9">Once the jobs are done we can report the computed data like:</p><pre><span id="2183">moka report</span></pre><p id="eafc">You may be wondering how does the client know what data it needs to send/receive. Well, that is the subject of the next section!</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/8064/0*o_Zzwgbaexr6Fz8y" width="4032" height="3024" srcset="https://miro.medium.com/max/552/0*o_Zzwgbaexr6Fz8y 276w, https://miro.medium.com/max/1104/0*o_Zzwgbaexr6Fz8y 552w, https://miro.medium.com/max/1280/0*o_Zzwgbaexr6Fz8y 640w, https://miro.medium.com/max/1400/0*o_Zzwgbaexr6Fz8y 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*o_Zzwgbaexr6Fz8y?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@tofi?utm_source=medium&amp;utm_medium=referral" rel="noopener">Tobias Fischer</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="e270">The main goal of the web service is to minimize the interaction between the users and the data. If the client requests some read-only action you just return the data (if available) and if the client wants to change something, you need to ensure that (1) the client has permissions to mutate the data (2) only the mutations specified by the client are carried out but nothing more. I will skip authentication in this post.</p><p id="2b72">Therefore, the <a href="https://insilico-server.readthedocs.io/en/latest/" rel="noopener">Insilico</a> web service needs to handle two kinds of requests by the client: read-only queries and mutations on the datasets. These ‚Äúqueries‚Äù and ‚Äúmutations‚Äù can be easily describe with <a href="https://graphql.org/" rel="noopener">GraphQL</a>.</p><p id="0dbe">In a nutshell, <a href="https://graphql.org/" rel="noopener">GraphQL</a> defines a contract (known as a schema) between the actions that a client can perform with the web service and the possible outcomes of those actions. More formally, <a href="https://graphql.org/" rel="noopener">GraphQL</a> is a query language that allows you to specify an application Programming interface (API) using different programming languages. If you have previous experience with <a href="https://en.wikipedia.org/wiki/Representational_state_transfer" rel="noopener">RESTful API</a> have a look at a comparison between <a href="https://www.howtographql.com/basics/1-graphql-is-the-better-rest/" rel="noopener">GraphQL and REST</a>.</p><p id="ecf0">But how does GraphQL work? First, you need to define a schema using the <a href="https://graphql.org/" rel="noopener">GraphQL</a> schema language. The following code snippet defines a schema to query a job using its status,</p><figure><div></div><figcaption>Schema definition for job query</figcaption></figure><p id="2045">The <strong>Query</strong> schema specifies that in order to request some <strong><em>jobs</em></strong> you need to provide a <em>Status</em> argument, where <em>Status</em> can be one of four possibilities: <em>AVAILABLE, DONE, FAILED</em> and <em>RUNNING. </em>The exclamation mark (!) indicates that the argument cannot be <em>Null</em> (a.k.a <em>None</em> in Python).</p><p id="5870">The following <strong>Mutation</strong> schema defines the required arguments to update a given job status.</p><figure><div></div><figcaption>Schema definitation for Job status mutation</figcaption></figure><p id="9dd2">The <strong><em>updateJob</em></strong> action specifies that you must provide an <em>id</em> and a <em>new_status</em> in order to be able to update a job. You will receive a <em>Reply</em> specifying whether the update action has succeeded.</p><p id="54d3">Have a look at the Insilico <a href="https://github.com/nlesc-nano/insilico-server/blob/master/insilicoserver/sdl/Query.graphql" rel="noopener">queries</a> and <a href="https://github.com/nlesc-nano/insilico-server/blob/master/insilicoserver/sdl/Mutation.graphql" rel="noopener">mutations</a> schemas. They are slightly more complex than the aforementioned schemas but follow the same rationale as the previous examples. You can also have a look at the official <a href="https://graphql.org/learn/" rel="noopener">introduction to GraphQL</a>.</p><p id="33f0">We have just defined the schemas that specify the actions that we want to perform. We still need to implement the actions and for doing so, we need a GraphQL engine: a library that takes the schemas together with the code that implements the actions and generates an API.</p><p id="39ea">We have chosen the <a href="https://tartiflette.io/" rel="noopener">Tartiflette GraphQL engine</a> to implement our web service mostly because it is easy to use and open source. The following snippet shows a possible implementation for querying jobs based on their status using <a href="https://tartiflette.io/" rel="noopener">Tartiflette</a>.</p><figure><div></div></figure><p id="affa">the <strong><em>Resolver</em></strong> decorator indicates that the <strong><em>resolver_query_jobs</em></strong> function corresponds to the implementation of the <strong><em>query jobs</em></strong> schema. The function takes 4 arguments of which I only use <strong><em>args</em></strong> and <strong><em>ctx</em></strong><em> </em>(You can refer to <a href="https://tartiflette.io/" rel="noopener">Tartiflette</a> for further details). <strong><em>args </em></strong>contains the arguments given by the client code, while <strong><em>ctx </em></strong>contains the context for running the current function, for example the handler to access the database that is called <strong><em>mongodb</em></strong> in this code snippet.</p><p id="9242">Notice that the definition of the aforementioned function starts with the <em>async</em> keyword. <a href="https://docs.python.org/3/library/asyncio.html" rel="noopener">Asyncio</a> is a popular built-in Python library to write concurrent code. It is extensively used to write high performance web services.</p><p id="fb0a">In the Insilico web service implementation of the <a href="https://github.com/nlesc-nano/insilico-server/tree/master/provisioning" rel="noopener"><strong>queries</strong></a> and <a href="https://github.com/nlesc-nano/insilico-server/blob/master/insilicoserver/mutation_resolvers.py" rel="noopener"><strong>mutations</strong></a>, there are definitions for all the Python functions that perform the actions specified in the GraphQL schemas. For each query and mutation, there is a corresponding function.</p><p id="632b">We need a database not only for storing the interesting data but also to store the jobs metadata, like what jobs are available. For the Insilico web service we use <a href="https://www.mongodb.com/" rel="noopener">MongoDB</a>.</p><p id="1b90">My personal opinion is that a <a href="https://en.wikipedia.org/wiki/NoSQL" rel="noopener">NoSQL database</a> like <a href="https://www.mongodb.com/" rel="noopener">MongoDB</a> gives a significant advantage over traditional SQL databases on research projects where up-front design of the schemas to store data is unfeasible. The research priorities can change as the project evolves and having dynamic ‚Ä¶</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9">https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9</a></em></p>]]>
            </description>
            <link>https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371580</guid>
            <pubDate>Thu, 10 Dec 2020 09:19:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ProtoPie 5.2: Turn Figma designs into realistic, conditional prototypes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25371555">thread link</a>) | @heytmt
<br/>
December 10, 2020 | https://blog.protopie.io/protopie-plugin-for-figma-a-revamped-import-experience-to-boost-productivity-5758892c4c58 | <a href="https://web.archive.org/web/*/https://blog.protopie.io/protopie-plugin-for-figma-a-revamped-import-experience-to-boost-productivity-5758892c4c58">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="72bc">A far better Figma import for ProtoPie. Lightning speed and flexibility at your fingertips.</h2><div><div><div><p><a href="https://medium.com/@fredotan?source=post_page-----5758892c4c58--------------------------------" rel="noopener"><img alt="Fredo Tan" src="https://miro.medium.com/fit/c/96/96/1*6aaH5nx9yHmC7KcdczcZTg@2x.jpeg" width="48" height="48"></a></p></div></div></div><blockquote><p id="e08d">We are on <a href="https://www.producthunt.com/posts/protopie-for-figma" rel="noopener"><strong>Product Hunt</strong></a> today! We‚Äôd love to receive your feedback and support there :)</p></blockquote></div></div><div><div><p id="ebd5">We are beyond excited that today we can finally introduce the <a href="https://www.figma.com/community/plugin/908870217222043020/ProtoPie-Plugin" rel="noopener"><strong>ProtoPie plugin for Figma</strong></a>‚Äîa far better Figma import for ProtoPie.</p><p id="7ead">The introduction of this plugin goes hand-in-hand with the <a href="https://protopie.io/?utm_source=medium&amp;utm_medium=social&amp;utm_campaign=standard-article&amp;utm_content=figma-plugin" rel="noopener"><strong>ProtoPie 5.2</strong></a> release.</p><p id="f675">ProtoPie plugins for Adobe XD and Sketch are coming soon.</p><p id="95c4">A lot of you have been using the Figma integration we introduced in early 2019. Many designers, since then, rely on a Figma + ProtoPie workflow on a daily basis‚Äîdesigning, prototyping, iterating, and anything in between.</p><p id="588e">As this workflow became essential for many rapidly, we received tons of feedback on how we could make this particular workflow better.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2616/1*35ZGJ7gZQN-LKqgbRZZj9Q.png" width="1308" height="262" srcset="https://miro.medium.com/max/552/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 276w, https://miro.medium.com/max/1104/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 552w, https://miro.medium.com/max/1280/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 640w, https://miro.medium.com/max/1400/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*35ZGJ7gZQN-LKqgbRZZj9Q.png?q=20"></p></div></div></div><figcaption>A better Figma import was one of the top <a href="https://protopie.canny.io/" rel="noopener">feature requests</a>.</figcaption></figure><p id="2208">Quickly we realized that we needed to provide a better workflow in which designers can merely focus on what they need ProtoPie for: making realistic, highly interactive prototypes.</p><p id="e4fd">So, we decided to build something new, entirely from scratch.</p><p id="1618">The new import experience is completely different from the previous one, which we now call the legacy Figma import.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3840/1*rINB-qGSruwy8te26r1hlA.gif" width="1920" height="1080" srcset="https://miro.medium.com/max/552/1*rINB-qGSruwy8te26r1hlA.gif 276w, https://miro.medium.com/max/1104/1*rINB-qGSruwy8te26r1hlA.gif 552w, https://miro.medium.com/max/1280/1*rINB-qGSruwy8te26r1hlA.gif 640w, https://miro.medium.com/max/1400/1*rINB-qGSruwy8te26r1hlA.gif 700w" sizes="700px" data-old-src="https://miro.medium.com/freeze/max/60/1*rINB-qGSruwy8te26r1hlA.gif?q=20"></p></div></div></div><figcaption>ProtoPie plugin for Figma: a revamped import experience to boost productivity.</figcaption></figure><p id="ffdc">With the new <a href="https://www.figma.com/community/plugin/908870217222043020/ProtoPie-Plugin" rel="noopener"><strong>ProtoPie plugin for Figma</strong></a>, you have lightning speed and flexibility at your fingertips. Import your designs from Figma into ProtoPie, all done locally‚Äîwithout any latency.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1280/1*xLg44E8hgKI01r3ML45Jjg.gif" width="640" height="360" srcset="https://miro.medium.com/max/552/1*xLg44E8hgKI01r3ML45Jjg.gif 276w, https://miro.medium.com/max/1104/1*xLg44E8hgKI01r3ML45Jjg.gif 552w, https://miro.medium.com/max/1280/1*xLg44E8hgKI01r3ML45Jjg.gif 640w" sizes="640px" data-old-src="https://miro.medium.com/freeze/max/60/1*xLg44E8hgKI01r3ML45Jjg.gif?q=20"></p></div></div><figcaption>Control what you import. At lightning speed.</figcaption></figure><p id="29cc">Control what you import. Import top-level frames as scenes, and objects with the same layer hierarchy, positioning, and constraints as in Figma.</p><p id="9ce9">The ProtoPie plugin for Figma requires ProtoPie 5.2 or higher.</p><h2 id="d98b">Differences with the legacy Figma import?</h2><p id="6d13">Spend less time on bringing your designs from Figma into ProtoPie. With the new plugin, you save time and can spend more time on prototyping.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3200/1*P_QobAhiTx_KYU4fFHnwUw.png" width="1600" height="1006" srcset="https://miro.medium.com/max/552/1*P_QobAhiTx_KYU4fFHnwUw.png 276w, https://miro.medium.com/max/1104/1*P_QobAhiTx_KYU4fFHnwUw.png 552w, https://miro.medium.com/max/1280/1*P_QobAhiTx_KYU4fFHnwUw.png 640w, https://miro.medium.com/max/1400/1*P_QobAhiTx_KYU4fFHnwUw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*P_QobAhiTx_KYU4fFHnwUw.png?q=20"></p></div></div></div><figcaption>The legacy Figma import on the left, the new ProtoPie plugin for Figma on the right.</figcaption></figure><ul><li id="b8f3">Import one or multiple frames and objects.</li><li id="9195">Import top-level frames as scenes.</li><li id="5eed">Import what you selected.</li><li id="e346">Import vector layers as SVG.</li><li id="ea4c">Import text layers as SVG that can be converted to text layers.</li><li id="7d1e">Import constraints as constraints.</li></ul><p id="9549"><a href="https://protopie.io/learn/docs/basic-features/import#import?utm_source=medium&amp;utm_medium=social&amp;utm_campaign=standard-article&amp;utm_content=figma-plugin" rel="noopener"><strong>Learn more</strong></a> about the ProtoPie plugin for Figma.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1200/1*6R6YL9UkyU9bwS3PBqaSag.jpeg" width="600" height="300" srcset="https://miro.medium.com/max/552/1*6R6YL9UkyU9bwS3PBqaSag.jpeg 276w, https://miro.medium.com/max/1104/1*6R6YL9UkyU9bwS3PBqaSag.jpeg 552w, https://miro.medium.com/max/1200/1*6R6YL9UkyU9bwS3PBqaSag.jpeg 600w" sizes="600px" data-old-src="https://miro.medium.com/max/60/1*6R6YL9UkyU9bwS3PBqaSag.jpeg?q=20"></p></div></div></figure><p id="f67c">ProtoPie is the tool that helps you to bring your Figma designs come to life, indistinguishable from the end product.</p><p id="feec">It‚Äôs simply a matter of adding powerful interactions to your designs. Think of dynamic interactions involving conditions, formulas, and variables. Add another level of realism by including text input, camera, voice, media playback to your prototypes. Or even make prototypes that can communicate with each other. The possibilities are endless.</p><h2 id="9d2a">New to ProtoPie?</h2><p id="45a6">Try the ProtoPie plugin for Figma with this <a href="https://r.protopie.io/en/figma-plugin/marketing-file/" rel="noopener"><strong>example file</strong></a>.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2160/1*4kJjwUMw6iXIJVcYmy7Asw.png" width="1080" height="540" srcset="https://miro.medium.com/max/552/1*4kJjwUMw6iXIJVcYmy7Asw.png 276w, https://miro.medium.com/max/1104/1*4kJjwUMw6iXIJVcYmy7Asw.png 552w, https://miro.medium.com/max/1280/1*4kJjwUMw6iXIJVcYmy7Asw.png 640w, https://miro.medium.com/max/1400/1*4kJjwUMw6iXIJVcYmy7Asw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*4kJjwUMw6iXIJVcYmy7Asw.png?q=20"></p></div></div></div></figure><p id="0d0d">Join our live event as our Head of Product Design, David Lee shares the journey of how we revamped the Figma import experience.</p><p id="6329">üëâ <a href="https://www.eventbrite.com/e/protopies-journey-behind-revamping-the-figma-import-tickets-130748563473" rel="noopener"><strong>Register now</strong></a>.</p><ul><li id="f42c">Single sign-on (SSO) for ProtoPie Enterprise</li><li id="2c31">Auto line height</li><li id="6898">Duplicate with same distance</li><li id="2993">App icon for macOS Big Sur</li><li id="74e3">Trigger &amp; response names for voice prototyping</li></ul><figure><a href="https://protopie.io/?utm_source=medium&amp;utm_medium=social&amp;utm_campaign=standard-article&amp;utm_content=figma-plugin"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3336/0*PwpFUw9I5BCcmPr0.png" width="1668" height="390" srcset="https://miro.medium.com/max/552/0*PwpFUw9I5BCcmPr0.png 276w, https://miro.medium.com/max/1104/0*PwpFUw9I5BCcmPr0.png 552w, https://miro.medium.com/max/1280/0*PwpFUw9I5BCcmPr0.png 640w, https://miro.medium.com/max/1400/0*PwpFUw9I5BCcmPr0.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*PwpFUw9I5BCcmPr0.png?q=20"></p></div></div></a></figure><p id="cdbd"><em>Thanks for reading! :) If you enjoyed this article, hit that clap button below </em>üëè<em>. Feel free to </em><a href="https://protopie.io/support" rel="noopener"><em>contact us</em></a><em> with your feedback and/or questions.</em></p></div></div></div>]]>
            </description>
            <link>https://blog.protopie.io/protopie-plugin-for-figma-a-revamped-import-experience-to-boost-productivity-5758892c4c58</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371555</guid>
            <pubDate>Thu, 10 Dec 2020 09:14:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital Twins, a Requirement for Industrial AI]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25371343">thread link</a>) | @MorganeR
<br/>
December 10, 2020 | https://blog.senx.io/digital-twins-requirement-for-industrial-ai/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/digital-twins-requirement-for-industrial-ai/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Using AI to make industrial assets more efficient and reduce their downtime is on many agendas. Learn how digital twins and time series data play a major role in this plan.</p><article>
      
<p><strong>When interviewed, CEOs across industries all state that AI is part of their top priorities.</strong> But when it comes to actual implementation AI projects are not very glamorous. Past simple proofs of concept and the hiring of a team of data scientists, there is usually no sign of the highly anticipated digital transformation wished by the CEOs.</p>



<p>There are multiple reasons for this disenchantment, far too many to list here. But among those, some are directly related to what we focus on at <a href="https://senx.io/" target="_blank" rel="noreferrer noopener">SenX</a>, data, and the way industries introduce them in their environment.</p>



<h2>No digital transformation without data</h2>



<p>The willingness to transform is genuine in many organizations, driven by ambitious visions or just the consciousness that the competitive landscape is evolving.</p>



<p>The next step is usually for those businesses to pick some quick wins to prove that the transformation can be initiated and comfort everyone that it does not mean changing teams or radically modifying their way of working.</p>



<p>Those short projects aim at demonstrating the methodology for transforming limited operational perimeters. They often involve solving a problem with approaches to leveraging new technologies. Those technologies, 100% digital, need fuel to work, and that fuel is data. <strong>So the first step is to ensure data are available</strong>.</p>



<p>The firms hired to help in building those quick wins will then wander among departments. They will harvest datasets here and there until they have sufficient matter for implementing their solutions.</p>



<p>This step can sometimes take time if the data is not well identified and distributed across the organization. But it is a mandatory path to follow as without data no digital transformation will happen.</p>



<figure></figure>



<h2>No AI without big data</h2>



<p>Past the simple quick wins done to bootstrap the transformation comes a time when more ambitious projects are brought on the table, and that is when AI (Artificial Intelligence) comes into the conversation. The hype around AI is so strong that projects around AI and ML (Machine Learning) cannot be neglected.</p>



<p>The problem with the current hype is that very few people really understand what AI actually implies. <strong>For many</strong>,<strong> you buy an AI like you buy a Microsoft Office 365 subscription</strong>, this is just not true. The promise of AI is to bring new, automatic, ways to use data to help in or even completely assume the decision process. This promise can only be fulfilled if the actual AI put to work, otherwise called the model, is actually trained on the data in your very own organization, and this requires once again the same digital transformation fuel, data. The difference is that this time you need more of it. You are no longer trying to light a fondue burner but a rocket engine!</p>



<p>Training a model does indeed require a lot of data covering the various aspects of your business operations you want the model to focus on, also covering a long period of time so trend and seasonality can be modeled. </p>



<h4>This has several impacts</h4>



<ul><li>The first is that you cannot expect to train a model and efficiently introduce AI in your operations until you actually have collected enough meaningful data. And if your organization has not done so so far you need to start as soon as possible. </li><li>The second impact is that this data collection process is not a one time job. It does not stop once you have enough data for training a model. It needs to go on and on so you keep on accumulating signals on how your business operates to retrain your models in the future if their performance starts to degrade. This means that prior to your journey into the core of AI you need to plan for big data to be collected, stored and made available to teams across your organization so they can start looking at the data and imagine possible uses and models.</li></ul>



<h2>No industrial AI without Digital Twins</h2>



<p>Among verticals, industrial organizations face the hardest problems of data collection. Industries whose data mainly relates to users using their services are lucky. In the end, their data are not that massive. Sure we have all heard stories of banks or retailers hoarding piles of data. But we are talking about a few thousand interactions per year per user. So even with a billion users, which not that many banks or retailers have, we are talking a few trillion events per year.</p>



<p>In the industrial world, things are different, the assets producing data do not eat or sleep. They work day and night and sometimes produce thousands of measurements per second.</p>



<h3>For example...</h3>



<p>Take for example the CERN experiments at the LHC. They produced 600 million events per second during the campaigns for the quest of the Higgs boson. That is 51 trillion events per day. Luckily for the CERN, not all events needed to be retained. With highly efficient AI-based detectors, which needed to be trained with massive data themselves, they were able to limit the production to 100 000 events per second sent for digital reconstruction and ultimately 200 events persisted per second. </p>



<p>But other sectors need to retain more data. Synchro phasors (or PMUs, phase monitoring units) monitoring electrical grids, for example. They each produce several 1000s measures per second, and there are thousands of those at the scale of a country like France. This means millions of C37.118.2 messages sent every second, not to mention the IEC61850 messages sent to supervise the substations. </p>



<p>Same thing in aeronautics where aircraft typically produce 5 000 to 15 000 data points per second they are operating, or industrial assets whose PLC (Programmable Logic Controllers) track the state of many sensors and actuators.</p>



<p>The use of AI in those verticals requires that those truly massive data be collected and organized. Since they are data related to physical assets, it is wise to use an approach which mimics these assets in a digital form, this approach is called Digital Twins. </p>



<figure></figure>



<h3>What are Digital Twins?</h3>



<p>The Digital Twin of an asset is the set of measures coming from its sensors and actuators. Those measures need to be tracked in time to catch the dynamics of the assets' operations. And the technology of choice to do so is a <a href="https://blog.senx.io/which-time-series-database-suited-to-your-needs/" target="_blank" rel="noreferrer noopener">Time Series Database</a>. Indeed Digital Twins are nothing else than time series, some for the sensors, some for the actuators with their states. And if you want more advanced digital twins, some with the control commands sent to the assets to modify how it behaves.</p>



<p>Once you start collecting the data from your assets in a Time Series Database, you can easily access the state of those assets at any point in time. More importantly, you can start extracting features to train models to detect anomalies and perform predictive maintenance.</p>



<h2>Takeaways</h2>



<p>AI is on every business' agenda, but the importance of data is too often overlooked. <strong>When it comes to industrial AI, the first step towards a successful implementation is the collection of all sensor data to build Digital Twins of the physical assets involved.</strong> This approach needs to leverage a Time Series Database, the kind of database SenX offers with the <a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp 10 Time Series Platform</a>.</p>



<p><a href="mailto:contact@senx.io" target="_blank" rel="noreferrer noopener">Contact us</a> to learn how SenX and its technologies can help you master your industrial AI adventure.</p>








<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/digital-twins-requirement-for-industrial-ai/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371343</guid>
            <pubDate>Thu, 10 Dec 2020 08:45:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts about Mapbox GL JS moving to a NON-OS License]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25371037">thread link</a>) | @D_Guidi
<br/>
December 9, 2020 | http://blog.cleverelephant.ca/2020/12/mapbox-morrison.html | <a href="https://web.archive.org/web/*/http://blog.cleverelephant.ca/2020/12/mapbox-morrison.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>09 Dec 2020</span></p><p>Yesterday, Mapbox announced that they were moving their <a href="https://github.com/mapbox/mapbox-gl-js">Mapbox GL JS</a> library from a standard BSD license to a new very much <a href="https://github.com/mapbox/mapbox-gl-js/blob/main/LICENSE.txt">non-open source license</a>.</p>

<p><a href="https://joemorrison.medium.com/death-of-an-open-source-business-model-62bc227a7e9b">Joe Morrison said</a> the news ‚Äúshook‚Äù him (and also the readers of the Hacker News front page, well done Joe). It did me as well. Although apparently for completely different reasons.</p>

<blockquote>
  <p>Mapbox is the protagonist of a story I‚Äôve told myself and others countless times. It‚Äôs a seductive tale about the incredible, counterintuitive concept of the ‚Äúopen core‚Äù business model for software companies.
<br>‚Äì Joe Morrison</p>
</blockquote>

<p>There‚Äôs a couple things wrong with Joe‚Äôs encomium to Mapbox and ‚Äúopen core‚Äù:</p>

<ul>
  <li>first, Mapbox was <strong>never</strong> an open core business;</li>
  <li>second, open core is a <strong>pretty ugly model</strong> that has very little to do with the open source ethos of shared intellectual pursuit.</li>
</ul>

<p><img src="http://blog.cleverelephant.ca/images//2020/core.jpg" alt="Open Core"></p>

<h2 id="mapbox-was-never-open-core">Mapbox was never Open Core</h2>

<p>From the very start (well, at least from the early middle), Mapbox was built to be a location-based services business. It was to be the Google Maps for people who were unwilling to accept the downsides of Google Maps.</p>

<p>Google Maps will track you. They will take your data exhaust and ruthlessly monetize it. They will take your data and use it to build a better Google Maps that they will then re-sell to others.</p>

<p>If you value your data at all (if you are, say, a major auto maker), you probably don‚Äôt want to use Google Maps, because they are going to steal your data while providing you services. Also, Google Maps is increasingly the ‚Äúonly game in town‚Äù for location based services, and it seems reasonable to expect price increases (<a href="https://housesigma.com/blog-en/2018/06/07/google-map-price-hike/">it has already happened once</a>).</p>

<p><img src="http://blog.cleverelephant.ca/images//2020/google-location-history.png" alt="Google is Tracking You"></p>

<p>Nobody can compete with Google Maps, can they? Why yes, they can! Mapbox fuses the collaborative goodness of the <a href="https://openstreemap.org/">OpenStreetMap</a> community with clever software that enables the kinds of services that Google sells 
(<a href="https://docs.mapbox.com/api/maps/#raster-tiles">map tiles</a>, 
<a href="https://docs.mapbox.com/#search">geocoding</a>, 
<a href="https://docs.mapbox.com/#navigation">routing</a>, 
<a href="https://docs.mapbox.com/help/troubleshooting/access-elevation-data/">elevation services</a>), and a bunch of services Google doesn‚Äôt sell (like <a href="https://www.mapbox.com/mapbox-studio/">custom map authoring</a>) or won‚Äôt sell (like <a href="https://www.mapbox.com/vision/">automotive vision</a>).</p>

<p>But like Google, the value proposition Mapbox sells isn‚Äôt in the software, so much as the data and the platform underneath. Mapbox has built a unique, scalable platform for handling the huge problem of turning raw OSM data into usable services, and raw location streams into usable services. They sell access to that platform.</p>

<p>Mapbox has never been a software company, they‚Äôve always been a data and services company.</p>

<p>The last company I worked for, <a href="https://carto.com/">CARTO</a>, had a similar model, only moreso. All the parts of their value proposition (PostgreSQL, PostGIS, the CARTO UI, the tile server, the upload, everything) are <a href="https://github.com/cartodb">open source</a>. But they want you to pay them when you load your data into their service and use their software there. How can that be? Well, do you want to assemble all those open source parts into a working system and keep it running? Of course not. You just want to publish a map, or run an analysis, or add a spatial analysis to an existing system. So you pay them money.</p>

<p>Is Mapbox an ‚Äúopen core‚Äù company? No, is there a ‚ÄúMapbox Community Edition‚Äù everyone can have, but an ‚ÄúEnterprise Edition‚Äù that is only available under a proprietary license? No. Does Mapbox even sell <strong>any software at all</strong>? No. (Yes, some.) They (mostly) sell services.</p>

<p>So what‚Äôs with the re-licensing? I‚Äôll come back to that, but first‚Ä¶</p>

<h2 id="open-core-is-a-shitty-model">Open Core is a Shitty Model</h2>

<p>Actually, no, it seems to be a passable <strong>monetization</strong> model, for some businesses. It‚Äôs a shitty open source model though.</p>

<ul>
  <li>MongoDB has an open source core, and sells a bunch of proprietary enterprise add-ons. They‚Äôve grown very fast and might even reach sufficient velocity to escape their huge VC valuation (or they may yet be sucked into the singularity).</li>
  <li>Cloudera before them reached huge valuations selling proprietary add-ons around the open Hadoop ecosystem.</li>
  <li>MySQL flirted with an open core model for many years, but mostly stuck to spreading FUD about the GPL in order to get customers to pay them for proprietary licenses.</li>
</ul>

<p>Easily the strangest part of the MySQL model was trash-talking the very open source license <strong>they chose</strong> to place their open source software under.</p>

<p>All those companies have been quite succesful along the axes of ‚Äúgetting users‚Äù and ‚Äúmaking money‚Äù. Let me tell you why open core is nonetheless a shitty model:</p>

<ul>
  <li>Tell me about the MongoDB developer community. Where do they work? Oh right, Mongo.</li>
  <li>Tell me about the Cloudary developer community? Where do they work?</li>
  <li>Tell me about the MySQL developer community? Where to they work? Oh right, <strong>Oracle</strong>. (There‚Äôs a whole other blog post to be written about why sole corporate control of open source projects is a <strong>bad idea</strong>.)</li>
</ul>

<p>A good open source model is one that promotes heterogeneity of contributors, a sharing of control, and a rising of all boats when the software succeeds. Open core is all about centralizing gain and control to the sponsoring organization.</p>

<p>This is going to sound precious, but the leaders of open core companies don‚Äôt ‚Äúcare‚Äù about the ethos of open source. The CEOs of open core companies view open source (correctly, from their point of view) as a ‚Äúsales channel‚Äù. It‚Äôs a way for customers to discover their paid offerings, it‚Äôs not an end in itself.</p>

<p><img src="http://blog.cleverelephant.ca/images//2020/funnel.png" width="75%" alt="Sales Funnel"></p>

<blockquote>
  <p>We didn‚Äôt open source it to get help from the community, to make the product better. We open sourced as a freemium strategy; to drive adoption. 
<br>‚Äì Dev Ittycheria, CEO, MongoDB</p>
</blockquote>

<p>So, yeah, open core is a way to make money but it doesn‚Äôt ‚Äúdo‚Äù anything for open source as a shared proposition for building useful tools anyone can use, for anything they find useful, anytime and anywhere they like.</p>

<p>Check out <a href="https://www.youtube.com/watch?v=8q5o-4pnxDQ">Adam Jacob‚Äôs take</a> on the current contradictions in the world of open source ethics; there are no hard and fast answers.</p>

<h2 id="mapbox-shook-me-too">Mapbox Shook Me Too</h2>

<p>I too was a little shook to learn of the <a href="https://news.ycombinator.com/item?id=25347310">Mapbox GL JS relicensing</a>, but perhaps not ‚Äúsurprised‚Äù. This had happened before, with <a href="https://news.ycombinator.com/item?id=14734589">Tilemill</a> (open) morphing into <a href="https://www.mapbox.com/mapbox-studio/">Mapbox Studio</a> (closed).</p>

<p>The change says nothing about ‚Äúopen source‚Äù in the large as a model, and everything about ‚Äúsingle vendor projects‚Äù and whether you should, strategically, believe their licensing.</p>

<p><img src="http://blog.cleverelephant.ca/images//2020/empty-promise.jpg" alt="Empty Promises"></p>

<p>I (and others) took the licensing (incorrectly) of Mapbox GL JS to be a promise, not only for now but the future, and made decisions based on that (incorrect) interpretation. I integrated GL JS into <a href="https://github.com/CrunchyData/pg_tileserv/blob/master/assets/preview-table.html">an open source project</a> and now I have to revisit that decision.</p>

<p>The license change also says something about the business realities Mapbox is facing going forward. The business of selling location based services is a competitive one, and one that is perhaps not panning out as well as their venture capital valuation (<a href="https://blog.mapbox.com/softbank-mapbox-series-c-be207b866b27">billions?</a>) would promise.</p>

<p>No doubt the board meetings are fraught. Managers are casting about for future sources of revenue, for places where more potential customers can be <strong>squeeeeezed</strong> into the sales funnel.</p>

<p>I had high hopes for Mapbox as a counterweight to Google Maps, a behemoth that seems <a href="https://www.justinobeirne.com/google-maps-moat">likely to consume us all</a>. The signs that the financial vice is beginning to close on it, that the promise might not be fulfilled, they shake me.</p>

<p>So, yeah, Joe, this is big news. Shaking news. But it has nothing to do with ‚Äúopen source as a business model‚Äù.</p>


</div></div>]]>
            </description>
            <link>http://blog.cleverelephant.ca/2020/12/mapbox-morrison.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371037</guid>
            <pubDate>Thu, 10 Dec 2020 07:54:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Restore pictures for free with deep learning tool]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25370708">thread link</a>) | @panabee
<br/>
December 9, 2020 | https://hotpot.ai/restore-picture | <a href="https://web.archive.org/web/*/https://hotpot.ai/restore-picture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="rootBody">

		


		<div id="rootYield">
			




<div id="pageBox">

	


	<div id="mainBox">

		<div id="controlBoxWrapper">
			<div id="controlBox">

				<div>
					<p><img src="https://hotpot.ai/images/site/transparent.gif">
					</p>
				</div>

				<p>Upload</p>

				

				<p><span>Restore</span>
				</p>

			</div>
		</div>

		

	</div>


	<article id="apiAccess">
		<h2>API Access</h2>

		<p>
			Add this service to your app, website, or company workflow with the <a href="https://hotpot.ai/docs/api">Hotpot API</a>.
		</p>
	</article>

	


	<article>
		<h2>Directions</h2>

		<p>
			Upload an image.
		</p>

		<p>
			If the image has scratches, enabling the "Has Scratches" option instructs our AI to remove scratches.
		</p>

		<p>
			To turn black &amp; white pictures to color, try our AI <a href="https://hotpot.ai/colorize-picture?s=restorer">Picture Colorizer</a> service.
		</p>
	</article>


	<article>
		<h2>Overview</h2>

		<p>
			This Hotpot AI service restores pictures by automatically performing scratch removal, face enhancement, and color sharpening. What used to require trained professionals hours can now be accomplished in seconds.
		</p>

		<p>
			The service can repair and restore both color and black &amp; white photographs.
		</p>

		<p>
			While this service automates photo restoration, it cannot replace experts for demanding restoration jobs. It is designed to help consumers with lightweight requirements while helping professionals save time on difficult restoration requests.
		</p>

		<p>
			For this service, pictures are not saved without user permission. For storage costs and user privacy, we only retain images for as long as necessary to run our machine learning models, and do not store photos beyond this.
		</p>

		<p>
			Note: the maximum image resolution we support is 1280x1280, but our new model supports larger images and is launching soon. Please contact us to try this newer model.
		</p>
	</article>


	<article>
	<h2>AI Tools</h2>

	<p>
		Explore other Hotpot <a href="https://hotpot.ai/tools">AI tools</a>, including ones for <a href="https://hotpot.ai/remove-background">background removal</a>, <a href="https://hotpot.ai/personalize-art">art personalization</a>, <a href="https://hotpot.ai/enlarge-picture">image upscaler</a> for photo prints, <a href="https://hotpot.ai/restore-picture">picture restoration</a>, <a href="https://hotpot.ai/colorize-picture">picture colorization</a>, and more.
	</p>
</article>


	<article>
		<h2>Research Credit</h2>

		<p>
			Our technology applies proprietary enhancements to the amazing Microsoft research project, <a href="https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life" target="_blank">Bringing Old Photos Back to Life</a>.
		</p>
	</article>


	<article>
		<h2>Contribute</h2>

		<p>
			Help improve our AI by <a href="https://hotpot.ai/contact">sharing images</a> that convert poorly.
		</p>
	</article>


</div>








<!---------------------------- Hotjar BEGIN ---------------------------->



<!---------------------------- Hotjar END ----------------------------->
		</div>

	</div></div>]]>
            </description>
            <link>https://hotpot.ai/restore-picture</link>
            <guid isPermaLink="false">hacker-news-small-sites-25370708</guid>
            <pubDate>Thu, 10 Dec 2020 07:02:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Measuring page performance ‚Äì Learn Puppeteer and Playwright]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25370533">thread link</a>) | @kiyanwang
<br/>
December 9, 2020 | https://theheadless.dev/posts/basics-performance/ | <a href="https://web.archive.org/web/*/https://theheadless.dev/posts/basics-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>The need for fast and responsive applications has never been greater because of the move from <a href="https://gs.statcounter.com/platform-market-share/desktop-mobile-tablet/worldwide/2019" target="_blank" rel="noopener noreferrer">desktop to mobile</a>. Still, web applications have been increasing in <a href="https://httparchive.org/reports/page-weight" target="_blank" rel="noopener noreferrer">complexity and size</a>, with rising load times. It is therefore clear why the topic of webpage performance is more popular today than it likely ever was.</p> <p>This article aims at giving a practical introduction to the whys and hows of web performance, without getting lost in the depth or breadth of this massive topic.</p> <h2 id="why-performance-matters"><a href="#why-performance-matters">#</a> Why performance matters</h2> <p>The time it takes for a service to become usable, as well as its general responsiveness, bear a lot of weight on the user's perception of that service. Helpful features, great design and other prominent characteristics all become irrelevant when an online service is so slow that users navigate away.</p> <p>You can build the best web application in the world, but be mindful that each user will have a specific amount of time they are willing to invest in your service to solve their problems. Exceed that amount, and you risk losing them to a different, more performant solution. This is even truer for new users, who haven't yet been given proof of the quality of your service, and are essentially investing their time up-front, hoping for a return.</p> <h3 id="a-competitive-differentiator"><a href="#a-competitive-differentiator">#</a> A competitive differentiator</h3> <p>There is a brighter side to the topic: if low performance can sink an online platform, high performance can very well help it rise to the top. Speed and responsiveness can be a differentiating characteristic for a service, prompting users to choose it over the competition. Therefore an investment in this area will almost always pay off. Some notorious real-world examples from known businesses include:</p> <ol><li>Pinterest decreasing wait time for their users, <a href="https://medium.com/@Pinterest_Engineering/driving-user-growth-with-performance-improvements-cfc50dafadd7" target="_blank" rel="noopener noreferrer">increasing both traffic and conversions</a>.</li> <li>Zalando applying small improvements in load time and finding a direct correlation with <a href="https://engineering.zalando.com/posts/2018/06/loading-time-matters.html" target="_blank" rel="noopener noreferrer">increased revenue per session</a>.</li> <li>The BBC discovering that every extra second that a page took to load led to 10% of <a href="https://www.creativebloq.com/features/how-the-bbc-builds-websites-that-scale" target="_blank" rel="noopener noreferrer">users leaving the page</a>.</li></ol> <h2 id="measuring-performance"><a href="#measuring-performance">#</a> Measuring performance</h2> <p>Given the importance of page performance, it is no coincidence that browsers expose a ton of insights into <a href="https://web.dev/metrics/" target="_blank" rel="noopener noreferrer">performance metrics</a>. Being aware of how your application scores against these <em>across time</em> will provide you the feedback you need to keep it performant for your users. There are several approaches that can be combined to achieve the best results:</p> <ol><li><em>Real user monitoring</em> to understand what performance actual end-users of your service are experiencing.</li> <li><em>Synthetic monitoring</em> to proactively gather intel on service performance, as well as to find issues before users stumble into them.</li> <li><em>Performance testing</em> to avoid releasing performance regression to production in the first place.</li> <li><em>Regular audits</em> to get an overview of your page's performance and suggestions on how to improve it, e.g. with tools such as <a href="https://developers.google.com/web/tools/lighthouse" target="_blank" rel="noopener noreferrer">Google Lighthouse</a>.</li></ol>  <p>As much as we should be striving to build performant applications, we should commit to monitoring and testing performance to enable continuous feedback and rapid intervention in case of degradation. Puppeteer and Playwright give us a great toolkit to power both synthetic monitoring and performance testing.</p> <ol><li>Access to the Web Performance APIs, especially <a href="https://developer.mozilla.org/en-US/docs/Web/API/PerformanceNavigationTiming" target="_blank" rel="noopener noreferrer">PerformanceNavigationTiming</a> and <a href="https://developer.mozilla.org/en-US/docs/Web/API/PerformanceResourceTiming" target="_blank" rel="noopener noreferrer">PerformanceResourceTiming</a>.</li> <li>Whenever testing against Chromium, access to the Chrome DevTools Protocol for traffic inspection, network emulation and more.</li> <li>Easy interoperability with performance libraries from the Node.js ecosystem.</li></ol> <h3 id="web-performance-apis"><a href="#web-performance-apis">#</a> Web Performance APIs</h3> <p>The <a href="https://www.w3.org/TR/navigation-timing/" target="_blank" rel="noopener noreferrer">Navigation Timing</a> and the <a href="https://www.w3.org/TR/resource-timing-1/" target="_blank" rel="noopener noreferrer">Resource Timing</a> performance APIs are <a href="https://www.w3.org/" target="_blank" rel="noopener noreferrer">W3C</a> specifications. The <a href="https://developer.mozilla.org/en-US/docs/Web/Performance/Navigation_and_resource_timings" target="_blank" rel="noopener noreferrer">MDN docs</a> very clearly define the scope of both:</p> <blockquote><p>Navigation timings are metrics measuring a browser's document navigation events. Resource timings are detailed network timing measurements regarding the loading of an application's resources. Both provide the same read-only properties, but navigation timing measures the main document's timings whereas the resource timing provides the times for all the assets or resources called in by that main document and the resources' requested resources.</p></blockquote> <p>We can use the Navigation Timing API to retrieve timestamps of key events in the page load timeline.</p>  <p>The Resource Timing API allows us to zoom in to single resources and get accurate information about how quickly they are being loaded. For example, we could specifically look at our website's logo:</p>  <h3 id="chrome-devtools-for-performance"><a href="#chrome-devtools-for-performance">#</a> Chrome DevTools for performance</h3> <p>The Chrome DevTools Protocol offers many great performance tools for us to leverage together with Puppeteer and Playwright.</p> <p>One important example is network throttling, through which we can simulate the experience of users accessing our page with different network conditions.</p>  <p>The DevTools Protocol is quite extensive. We recommend exploring the <a href="https://chromedevtools.github.io/devtools-protocol/" target="_blank" rel="noopener noreferrer">documentation</a> and getting a comprehensive overview of its capabilities.</p> <h3 id="additional-performance-libraries"><a href="#additional-performance-libraries">#</a> Additional performance libraries</h3> <p>Lighthouse can easily be used programmatically with Playwright and Puppeteer to gather values and scores for different metrics, like <a href="https://web.dev/interactive/" target="_blank" rel="noopener noreferrer">Time To Interactive (TTI)</a>:</p>  <h2 id="further-reading"><a href="#further-reading">#</a> Further reading</h2> <ol><li>The comprehensive <a href="https://developer.mozilla.org/en-US/docs/Web/Performance" target="_blank" rel="noopener noreferrer">MDN Web Performance documentation</a></li> <li><a href="https://web.dev/learn/#performance" target="_blank" rel="noopener noreferrer">web.dev's performance section</a></li> <li><a href="https://addyosmani.com/blog/puppeteer-recipes/" target="_blank" rel="noopener noreferrer">Web Performance Recipes With Puppeteer</a> by Addy Osmani</li> <li><a href="https://github.com/aslushnikov/getting-started-with-cdp" target="_blank" rel="noopener noreferrer">Getting started with Chrome DevTools Protocol</a> by Andrey Lushnikov</li> <li><a href="https://developers.google.com/web/tools/lighthouse#get-started" target="_blank" rel="noopener noreferrer">Get Started with Google Lighthouse</a></li></ol></div></div>]]>
            </description>
            <link>https://theheadless.dev/posts/basics-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25370533</guid>
            <pubDate>Thu, 10 Dec 2020 06:35:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Set Up OBS Studio for Screen Recording ‚Äì Step-by-Step Procedure]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25369651">thread link</a>) | @ponderingfish
<br/>
December 9, 2020 | https://ottverse.com/setup-obs-studio-for-recording-screen-tutorial/ | <a href="https://web.archive.org/web/*/https://ottverse.com/setup-obs-studio-for-recording-screen-tutorial/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

		<div>

		

	<div id="primary">

		
					<main id="main">

				
					
					

<article id="post-2893" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

		
	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>So, you‚Äôve downloaded and installed <a href="https://obsproject.com/" target="_blank" rel="noopener">OBS Studio</a> on your computer and you want to start recording your screen, but you‚Äôre lost?</p>



<p>Well, simply <strong>follow this step-by-step tutorial and you will be ready to start recording high-quality videos of your screen in no time with OBS Studio</strong>. </p>



<p>Let‚Äôs get started.</p>



<hr>



<h2>A Brief Overview of OBS Studio</h2>



<p>Before we go further, let‚Äôs get an idea of the GUI layout of OBS Studio. To keep things simple, we will divide OBS Studio into 6 sections.</p>



<div><figure><img width="1024" height="550" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=300%2C161&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=768%2C412&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1536%2C825&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1200%2C644&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?w=1598&amp;ssl=1 1598w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20550'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=300%2C161&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=768%2C412&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1536%2C825&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1200%2C644&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?w=1598&amp;ssl=1 1598w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1"></figure></div>



<h3>1. Scenes</h3>



<p>If OBS is a canvas, <code>Scenes</code> would be a place that stores various pictures you can switch at any time. Each scene is used for different purposes. For example, a streamer would use different ones to signify when he is playing, waiting in a lobby, or taking a break.</p>



<h3>2. Sources</h3>



<p>You can think of <code>Sources</code> like a set of colors, you use to paint a scene. These are all of the elements shown on your screen during a recording. A good example of Sources are your logo, webcam, and chat window.</p>



<h3>3. Audio Mixer</h3>



<p>The mixer is where you will set up everything audio-related. More on that later.</p>



<h3>4. Scene Transitions</h3>



<p>Transitions provide you with animations you can play while switching up the scenes.</p>



<h3>5. Controls</h3>



<p>This houses the most important controls you will use to manipulate your recording.</p>



<h3>6. Preview Window</h3>



<p>Finally, there is a Preview Window. This shows exactly what you will see after you‚Äôve recorded your video.</p>



<p>And don‚Äôt forget that OBS Studio is really customizable. You can drag and drop all of these windows and re-organize them to create a unique layout that suits your workflow.</p>



<p>Great, now that you have an idea of what hte OBS Studio layout looks like, let‚Äôs get started with setting up OBS Studio for recording.</p>



<hr>



<h2>Setup OBS Studio for Recording Your Screen</h2>



<p>Now let‚Äôs follow this step-by-step procedure to setup OBS Studio and start recording! </p>



<h3>1. Add Audio Sources</h3>



<p>Let‚Äôs start by setting up the audio. First, go to the <code>Controls &gt; Settings &gt; Audio</code>. Set both <code>Desktop Audio</code> and <code>Mic Audio</code> to <code>default</code>. Everything else should be disabled.</p>



<div><figure><img width="1024" height="576" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20576'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1"></figure></div>



<p>Let‚Äôs quickly add some filters to make your voice sound more professional. Click on the gear icon next to <code>Mic/Aux</code> in <code>Audio Mixer</code>.</p>



<div><figure><img width="742" height="431" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=742%2C431&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?w=742&amp;ssl=1 742w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=300%2C174&amp;ssl=1 300w" sizes="(max-width: 742px) 100vw, 742px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20742%20431'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?w=742&amp;ssl=1 742w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=300%2C174&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=742%2C431&amp;ssl=1"></figure></div>



<p>Here we have 3 options: <code>Noise Suppression</code>, <code>Noise Gate</code>, and <code>Gain</code>.</p>



<div><figure><img width="598" height="257" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=598%2C257&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?w=598&amp;ssl=1 598w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=300%2C129&amp;ssl=1 300w" sizes="(max-width: 598px) 100vw, 598px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20598%20257'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?w=598&amp;ssl=1 598w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=300%2C129&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=598%2C257&amp;ssl=1"></figure></div>



<ul><li><strong>Noise Suppression</strong> will remove most of your background noise. Start from -10 dB and drop lower until you can‚Äôt hear the noise.</li><li><strong>Noise Gate</strong> will turn off your microphone when the volume drops below the Close Threshold. This way you won‚Äôt record your breathing. Settings will vary depending on your type of mic, so play with it until it feels natural.</li><li><strong>Gain</strong> is used for changing the volume of your mic.</li></ul>



<h3>2. Choose Recording Quality</h3>



<p>Go to the <code>Output</code> tab on the left and under <code>Recording</code> choose the path where OBS will save all your videos. By default, it‚Äôs set to <code>\Users\OBS\Videos</code>.</p>



<div><figure><img width="1024" height="576" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20576'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1"></figure></div>



<p>Next, click on <code>Recording Quality</code>.</p>



<div><figure><img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=874%2C675&amp;ssl=1" alt="Set up OBS Studio for Recording" width="874" height="675" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?w=985&amp;ssl=1 985w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=300%2C232&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=768%2C593&amp;ssl=1 768w" sizes="(max-width: 874px) 100vw, 874px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20874%20675'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?w=985&amp;ssl=1 985w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=300%2C232&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=768%2C593&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=874%2C675&amp;ssl=1"></figure></div>



<p>If you are just beginning to record your videos, we recommend that you choose <code>High Quality</code>. This will provide you with pretty good quality and reasonable file size.</p>



<p>Others should pick <code>Indistinguishable Quality</code>. This will give you a fully professional video that you can later edit in post-processing.</p>



<p>We can‚Äôt really recommend <code>Lossless</code> as it will eat up your storage without providing a perceptible difference.</p>



<p>Under <code>Recording Format</code> choose either <code>MKV</code> or <code>FLV</code> as they are very stable container formats. In case your PC or PBS crashes, you will likely be able to save your recording. </p>



<div><figure><img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=864%2C666&amp;ssl=1" alt="Set up OBS Studio for Recording" width="864" height="666" srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?w=979&amp;ssl=1 979w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=300%2C231&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=768%2C592&amp;ssl=1 768w" sizes="(max-width: 864px) 100vw, 864px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20864%20666'%3E%3C/svg%3E" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?w=979&amp;ssl=1 979w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=300%2C231&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=768%2C592&amp;ssl=1 768w" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=864%2C666&amp;ssl=1"></figure></div>



<p>You can easily convert your files later, by going to <code>File &gt; Remux Recording</code>.</p>



<div><figure><img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=942%2C530&amp;ssl=1" alt="Set up OBS Studio for Recording" width="942" height="530" srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1536%2C864&amp;ssl=1 1536w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1200%2C675&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 942px) 100vw, 942px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20942%20530'%3E%3C/svg%3E" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1536%2C864&amp;ssl=1 1536w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1200%2C675&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=942%2C530&amp;ssl=1"></figure></div>



<h3>3. Add Scenes</h3>



<p>Now, you will want to create a game scene by clicking on the plus sign in <code>Scenes</code>. A new window will pop up where you can name it.</p>



<div><figure><img width="1024" height="576" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20576'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1"></figure></div>



<h3>4. Capture Your Game</h3>



<p>After creating an in-game scene, keep it selected and click on the <code>+</code> sign in <code>Sources</code>, and select <code>Game Capture</code>. This will open up the properties and let you pick which game you want to record.</p>



<div><figure><img width="562" height="380" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=562%2C380&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?w=562&amp;ssl=1 562w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=300%2C203&amp;ssl=1 300w" sizes="(max-width: 562px) 100vw, 562px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20562%20380'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?w=562&amp;ssl=1 562w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=300%2C203&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=562%2C380&amp;ssl=1"></figure></div>



<p>For <code>Mode</code> make sure it‚Äôs set to <code>Capture</code> any fullscreen application. Once you start playing your game, OBS will automatically focus on it.</p>



<p>Nowadays, many games have an anti-cheat system that might affect OBS Studio. For this reason, you should select <code>Use anti-cheat compatibility hook</code>. Don‚Äôt worry, you won‚Äôt get banned for it.</p>



<p>If you enable 3rd party overlays like Discord or Steam, OBS will try and capture them as well. However, this does not always work, so make sure to check the preview window.</p>



<div><figure><img width="717" height="605" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=717%2C605&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?w=717&amp;ssl=1 717w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=300%2C253&amp;ssl=1 300w" sizes="(max-width: 717px) 100vw, 717px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20717%20605'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?w=717&amp;ssl=1 717w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=300%2C253&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=717%2C605&amp;ssl=1"></figure></div>



<p>Once you are done with the setup, click OK and exit. Your game should now be displayed in the OBS.</p>



<h3>5. Add your Webcam</h3>



<p>Go back to the <code>+</code> sign in <code>Sources</code> and select <code>Video Capture Device</code>.</p>



<div><figure><img width="500" height="393" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=500%2C393&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?w=500&amp;ssl=1 500w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=300%2C236&amp;ssl=1 300w" sizes="(max-width: 500px) 100vw, 500px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20500%20393'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?w=500&amp;ssl=1 500w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=300%2C236&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=500%2C393&amp;ssl=1"></figure></div>



<p>That will take you to the <code>Properties</code>. Make sure that you select the right webcam and OBS will set it up. By default, <code>Resolution Type</code> is set to custom. If you want to change it, we recommend choosing either <code>1080p</code> or <code>720p</code>. Hit <code>OK</code> and your webcam will appear under <code>Scenes</code>. Just drag it where you want and resize if needed.</p>



<p>And that‚Äôs it! You are now ready to start recording videos in OBS Studio.</p>



<p>Hope you were able to follow this guide and set up your computer to record using <a href="https://obsproject.com/" target="_blank" rel="noopener">OBS Studio</a>. Have fun recording your screen, or games! Let us know if you have any tips for setting up your OBS Studio installation and we‚Äôll publish it. Thanks! </p>



<hr>

<!-- MOLONGUI AUTHORSHIP PLUGIN 4.2.11 -->
<!-- https://www.molongui.com/authorship/ -->

<div id="mab-2214772468" data-plugin-release="4.2.11" data-plugin-version="free" data-box-layout="slim" data-box-position="below" data-multiauthor="false" data-author-type="user" itemscope="" itemtype="https://schema.org/Person">

	
    <!-- Author headline -->
    <p>
        <h3>
            <span>About The Author</span>
        </h3>
    </p>

    <div>

        <div data-profile-layout="layout-1" data-author-ref="user-194568617">
            
<!-- End of .m-a-box-content-top -->

<div>

    <!-- Author picture -->
    
	<p><a href="https://ottverse.com/author/vkr2020/">
                    <img alt="" src="https://secure.gravatar.com/avatar/1b73140b34f836d184d53fbb00f406dd?s=150&amp;d=mp&amp;r=g" srcset="https://secure.gravatar.com/avatar/1b73140b34f836d184d53fbb00f406dd?s=300&amp;d=mp&amp;r=g 2x" height="150" width="150" itemprop="image" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">                </a>
                	</p>

    <!-- Author social -->
    
    <!-- Author data -->
    <div>

        <!-- Author name -->
        

        <!-- Author metadata -->
        

        <!-- Author bio -->
        
<div itemprop="description">
	<p>I‚Äôm Dr. Krishna Rao Vijayanagar, and I am the Founder and Editor of OTTVerse.com. I've spent several years working hands-on with Video Codecs (AVC, HEVC, MultiView Plus Depth), ABR streaming, and Video Analytics (QoE, Content &amp; Audience, and Ad). I hope to use my experience and love for video streaming to bring you information and insights into the OTT universe. Please use the Contact Page to get in touch with me.</p>
</div>

        
            <!-- Author related posts -->
            <!-- End of .m-a-box-related -->

        
    </div><!-- End of .m-a-box-data -->

</div><!-- End of .m-a-box-content-middle -->

<!-- End of .m-a-box-content-bottom -->        </div><!-- End of .m-a-box-profile -->

        
    </div><!-- End of .m-a-box-container -->

	
</div><!-- End of .m-a-box -->

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article><!-- #post-## -->


<!-- #comments -->

					
					
				
			</main><!-- #main -->
			
		
	</div><!-- #primary -->


	<!-- #secondary -->


			
			</div> <!-- ast-container -->

		</div></div>]]>
            </description>
            <link>https://ottverse.com/setup-obs-studio-for-recording-screen-tutorial/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25369651</guid>
            <pubDate>Thu, 10 Dec 2020 04:19:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Google Firestore Locally]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25368698">thread link</a>) | @adrianancona
<br/>
December 9, 2020 | https://ncona.com/2020/12/running-google-firestore-locally/ | <a href="https://web.archive.org/web/*/https://ncona.com/2020/12/running-google-firestore-locally/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In a previous article, <a href="https://ncona.com/2020/12/introduction-to-google-firestore/">we started playing with Google Firestore</a>. In this article we are going to learn how we can test our applications without the need to talk to Google Cloud.</p>

<p>Note that the local version of Google Firestore is intended for testing only and shouldn‚Äôt be used for production systems. It doesn‚Äôt provide the reliability or scalability features that the real Firestore does.</p>

<h2 id="firebase-emulator-suite">Firebase emulator suite</h2>

<p>Google provides this suite to help developers test applications without having to use production data or incur cost. The suite doesn‚Äôt only emulate the database, but also cloud functions and real-time functionality, to name a couple. In this article we‚Äôre only going to focus on the Firestore database.</p>

<!--more-->

<h2 id="firebase-cli">Firebase CLI</h2>

<p>We start by installing the <a href="https://firebase.google.com/docs/cli">Firebase CLI</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>curl -sL https://firebase.tools | bash
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can then start an instance of Firestore:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>firebase emulators:start --only firestore
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As part of the output we will get something like this:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Emulator  ‚îÇ Host:Port      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Firestore ‚îÇ localhost:8080 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Port <code>8080</code> is the default for Firestore. When the emulator starts it will look for a file named <code>firebase.json</code> where we can override the port:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
</pre></td><td><pre><span>{</span><span>
  </span><span>"emulators"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"firestore"</span><span>:</span><span> </span><span>{</span><span>
      </span><span>"port"</span><span>:</span><span> </span><span>"9999"</span><span>
    </span><span>}</span><span>
  </span><span>}</span><span>
</span><span>}</span><span>
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>One important thing to keep in mind about the emulator is that the data will be lost every time the emulator is stoped.</p>

<h2 id="connecting-to-the-emulator">Connecting to the emulator</h2>

<p>In <a href="https://ncona.com/2020/12/introduction-to-google-firestore/">Introduction to Google Firestore</a> we learned how to create a firestore client:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td><pre><span>// Constants necessary to create the firestore client</span>
<span>const</span> <span>GcpCredentialsFile</span> <span>=</span> <span>"/tmp/my-key.json"</span>
<span>const</span> <span>ProjectId</span> <span>=</span> <span>"project-12345"</span>

<span>// When done with the client, close it using:</span>
<span>// defer client.Close()</span>
<span>func</span> <span>createClient</span><span>(</span><span>ctx</span> <span>context</span><span>.</span><span>Context</span><span>)</span> <span>*</span><span>firestore</span><span>.</span><span>Client</span> <span>{</span>
  <span>client</span><span>,</span> <span>err</span> <span>:=</span> <span>firestore</span><span>.</span><span>NewClient</span><span>(</span><span>ctx</span><span>,</span> <span>ProjectId</span><span>,</span> <span>option</span><span>.</span><span>WithCredentialsFile</span><span>(</span><span>GcpCredentialsFile</span><span>))</span>

  <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
    <span>log</span><span>.</span><span>Fatalf</span><span>(</span><span>"Failed to create client: %v"</span><span>,</span> <span>err</span><span>)</span>
  <span>}</span>

  <span>return</span> <span>client</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To tell our app that we want to use the emulator, we need to set an environment variable:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>export </span><span>FIRESTORE_EMULATOR_HOST</span><span>=</span>localhost:8080
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This will cause the credentials to be ignored, and the client will connect to the emulator instead.</p>

<h2 id="conclusion">Conclusion</h2>

<p>This was a quick article to show how we can easily start a local version of Google Firestore that can be used for testing. The emulator provides a lot of advanced features, but I haven‚Äôt had the need for them, so I haven‚Äôt dived into them.</p>

  </div></div>]]>
            </description>
            <link>https://ncona.com/2020/12/running-google-firestore-locally/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25368698</guid>
            <pubDate>Thu, 10 Dec 2020 02:07:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming the ATtiny10]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25368633">thread link</a>) | @taf2
<br/>
December 9, 2020 | http://www.technoblogy.com/show?1YQY | <a href="https://web.archive.org/web/*/http://www.technoblogy.com/show?1YQY">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<p>11th November 2017</p>
<p>This article describes how to program the ATtiny10, Microchip's diminuitive 6-pin processor, using the Arduino IDE. It's a great chip for building small gadgets and wearables, or designing interface logic for other projects, and it really lives up to its "tiny" name:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10.jpg" alt="ATtiny10.jpg" width="250" height="300"></p>
<p>The following sections explain how to program the ATtiny10 in C, and how to download programs using a low-cost ISP programmer. It also illustrates some simple applications with example programs.</p>
<p>For a couple of projects based on the ATtiny10 see&nbsp;<a href="http://www.technoblogy.com/show?201J">ATtiny10 POV Pendant</a>&nbsp;and&nbsp;<a href="http://www.technoblogy.com/show?2G8A">ATtiny10 Thermometer</a>.</p>
<h3><span>Introduction</span></h3>
<p>If, like me, you like using the simplest possible chip for each application, the ATtiny10 will appeal to you&nbsp;<sup id="cite_ref1"><a href="#cite_note1">[1]</a></sup>; it's a 6-pin processor, about the same size as an 0805 SMD resistor, and it costs about 35p/35¬¢. It packs in the following features:</p>
<ul>
<li>Internal 8MHz clock, by default prescaled to 1MHz.</li>
<li>Three I/O lines.</li>
<li>Two 16-bit PWM analogue outputs.</li>
<li>Three 8-bit analogue inputs.</li>
<li>An analogue comparator.</li>
<li>A 16-bit timer with input capture and an event counter.</li>
<li>A watchdog timer.</li>
<li>1024 bytes of program memory, 32 bytes of RAM, and no EEPROM.</li>
</ul>
<p>All of these features will be familiar to users of the larger AVR chips. Here's the pinout (using Spence Konde's design conventions):</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10pinout.gif" alt="ATtiny10Pinout.gif" width="701" height="159"></p>
<p>The internal oscillator is accurate to within 10%, but you can calibrate it in software to within 1%. You can configure RESET as a fourth I/O line, which prevents further programming, but I don't cover that in this article.</p>
<p>To work with the ATtiny10 on a breadboard you can mount it on a SOT23 breakout board, such as the one available from Sparkfun <sup id="cite_ref2"><a href="#cite_note2">[2]</a></sup>.</p>
<h3>Programming the ATtiny10</h3>
<p>Unlike the SPI protocol used to program the larger AVR chips, such as the ATmega328 in the Arduino Uno, the ATtiny10 uses a programming protocol called TPI (Tiny Programming Interface) which needs only five wires. Fortunately Thomas Fischl's excellent USBasp programmer supports this protocol&nbsp;<sup id="cite_ref3"><a href="#cite_note3">[3]</a></sup>; you can build your own, order one from his site, or they are widely available on eBay&nbsp;<sup id="cite_ref4"><a href="#cite_note4">[4]</a></sup>, Banggood&nbsp;<sup id="cite_ref5"><a href="#cite_note5">[5]</a></sup>, etc. I recommend getting one with a 10-pin to 6-pin adapter for ISP programming. The current versions of the Arduino IDE support the ATtiny10, so you can program it in C and upload programs as easily as with the other AVR chips. Since an Arduino core would use up almost half of the available program memory the best way to program it is to access the registers directly, and I give an overview of how to do this in the section&nbsp;<a href="#Alternatives">Alternatives to core functions</a>&nbsp;below.</p>
<p>Here are step-by-step instructions for programming the ATtiny10.</p>
<p>NOTE: There is a problem with compiling for the ATtiny10 with versions of the Arduino IDE 1.8.9 and higher. If necessary, run version 1.8.8 to do this, or for a workaround see the Disqus comments below.</p>
<ul>
<li>Download the <strong>ATtiny10Core</strong> hardware configuration from my repository on GitHub <a href="https://github.com/technoblogy/attiny10core" target="_blank">ATtiny10Core</a>.</li>
<li>Copy it to the&nbsp;<strong>hardware</strong>&nbsp;folder in your&nbsp;<strong>Arduino</strong>&nbsp;folder in your <strong>Documents</strong> folder. If there isn't already a <strong>hardware</strong> folder there, create one first.</li>
<li>Restart the Arduino IDE.</li>
</ul>
<p>This should add an&nbsp;<strong>ATtiny10Core</strong>&nbsp;heading to the <strong>Board</strong> menu.</p>
<ul>
<li>Enter your program into the Arduino IDE editor.</li>
</ul>
<p>For example, try the&nbsp;<strong>Blink</strong>&nbsp;example program given below.</p>
<ul>
<li>Connect the USBasp to the ATtiny10 as shown in the following diagram:</li>
</ul>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10usbasp.gif" alt="ATtiny10USBasp.gif" width="203" height="157"></p>
<p><em>Connecting the USBasp programmer to an ATtiny10.</em></p>
<ul>
<li>Choose&nbsp;<strong>Board</strong>&nbsp;from the&nbsp;<strong>Tools</strong>&nbsp;menu, and select the&nbsp;<strong>ATtiny10/9/5/4</strong>&nbsp;option under the <strong>ATtiny10Core</strong> heading; it's the only option.</li>
<li>Choose the chip you want from the <strong>Chip</strong> menu; for example&nbsp;<strong>ATtiny10</strong>.</li>
<li>Choose <strong>USBasp</strong> from the&nbsp;<strong>Programmer&nbsp;</strong>option on the&nbsp;<strong>Tools</strong>&nbsp;menu.</li>
<li>Choose&nbsp;<strong>Upload</strong>&nbsp;to upload the program.</li>
</ul>
<p>The LED should blink at 0.5Hz.</p>
<p>Here's my test setup on a mini breadboard:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/usbasp.jpg" alt="USBasp.jpg" width="680" height="324"></p>
<p><em>Testing the ATtiny10 Blink program on a mini breadboard, using the USBasp programmer.</em></p>
<h3>Examples</h3>
<p>Here are a couple of examples using the ATtiny10:</p>
<h4>Blink</h4>
<p>This is the ubiquitous Blink program:</p>
<pre>#include &lt;avr/io.h&gt;
#include &lt;stdint.h&gt;

int main (void) {
  DDRB = 1;                       // PB0 as an output
  TCCR0A = 1&lt;&lt;COM0A0 | 0&lt;&lt;WGM00;  // Toggle OC0A, CTC mode
  TCCR0B = 1&lt;&lt;WGM02 | 3&lt;&lt;CS00;    // CTC mode; use OCR0A; /64
  OCR0A = 15624;                  // 1 second; ie 0.5Hz
  while (1);
}</pre>
<p>To run it connect an LED to PB0 as follows:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10usbasp2.gif" alt="ATtiny10USBasp2.gif" width="157" height="128"></p>
<p><em>Circuit using an ATtiny10 to blink an LED.</em></p>
<p>It uses Timer/Counter0 to divide the 1MHz system clock by a prescaler value of 64, and then by 15625, toggling the output PB0 with a period of 1 second.</p>
<h4>Analogue frequency generator</h4>
<p>The following program reads the voltage from a potentiometer on analogue input ADC1 (PB1), and then uses this to set the compare match register OCR0A of Timer/Counter0, to generate a square wave on PB0 whose frequency you can control with the potentiometer:</p>
<pre>#include &lt;avr/io.h&gt;
#include &lt;stdint.h&gt;

int main (void) {
  DDRB = 1;                       // PB0 as an output
  // Set up ADC on PB2
  ADMUX = 1&lt;&lt;MUX0;                // ADC1 (PB1)
  ADCSRA = 1&lt;&lt;ADEN | 3&lt;&lt;ADPS0;    // Enable ADC, 125kHz clock
  // Set up waveform on PB0
  TCCR0A = 1&lt;&lt;COM0A0 | 3&lt;&lt;WGM00;  // Toggle OC0A, Fast PWM
  TCCR0B = 3&lt;&lt;WGM02 | 4&lt;&lt;CS00;    // Fast PWM with OCR0A as TOP; /256
  // Main loop
  for (;;) {
    ADCSRA = ADCSRA | 1&lt;&lt;ADSC;    // Start
    while (ADCSRA &amp; 1&lt;&lt;ADSC);     // Wait while conversion in progress
    OCR0A = ADCL;                 // Copy result to frequency output
  }
}</pre>
<p>Note that because we're changing the compare match value, we need to use Fast PWM mode in this application, because it double-buffers the compare match value. Here's the circuit:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10usbasp3.gif" alt="ATtiny10USBasp3.gif" width="247" height="132"></p>
<p><em>Circuit using a potentiometer to adjust the frequency of a square wave generated by an ATtiny10.</em></p>
<p>It generates a frequency between 1MHz/256/256, or about 15Hz, and 1MHz/256/1, or 3.9kHz.</p>
<h3 id="Alternatives">Alternatives to core functions</h3>
<p>The following sections give some tips on programming the ATtiny10 to achieve some of the things provided by the Arduino core functions.</p>
<h4>includes</h4>
<p>You need to add these includes at the start of your program to include the AVR register definitions and standard C++ routines:</p>
<pre>#include &lt;avr/io.h&gt;
#include &lt;stdint.h&gt;</pre>
<h4>setup and loop</h4>
<p>Arduino programs are normally written with the initialization in&nbsp;<strong>setup()</strong>&nbsp;and the main program in&nbsp;<strong>loop()</strong>, rather than the standard&nbsp;<strong>int&nbsp;main()</strong>&nbsp;function required by C. If you want to keep to this convention you'll need to add the following definition at the end of your program:</p>
<pre>int main() {
  setup();
  for(;;) loop();
}</pre>
<h4>pinMode</h4>
<p>To specify whether pins are inputs or outputs you set the corresponding bits in the <strong>DDRB</strong> register to 0 or 1 respectively. For example, to define pins 1 and 3 as outputs (and leave the other pins as inputs):</p>
<pre>DDRB = 0b0101; &nbsp; &nbsp;     // Equivalent to pinMode(1, OUTPUT); pinMode(3, OUTPUT);</pre>
<h4>Input pullups</h4>
<p>Unlike the older AVR chips, such as the ATmega328 and ATtiny85, the ATtiny10 enables pullup resistors using a separate pullup register, <strong>PUEB</strong>. To set pullups on input pins you set the corresponding bits in this&nbsp;register. For example, to set a pullup resistor on input pin 2:</p>
<pre>PUEB = 0b0010;         // Equivalent to pinMode(2, INPUT_PULLUP);</pre>
<p>Note that it doesn't make sense to set a pullup on an output.</p>
<h4>digitalWrite</h4>
<p>To set the state of an output you set the corresponding bits in the <strong>PORTB</strong> register. For example, to set bit 1 low and bit 3 high (assuming they have been defined as outputs):</p>
<pre>PORTB = 0b0100;        // Equivalent to&nbsp;digitalWrite(1, LOW);&nbsp;digitalWrite(3, HIGH);</pre>
<p>Changing the state of&nbsp;an input has no effect.</p>
<h4>digitalRead</h4>
<p>To read the state of the I/O pins you read the <strong>PINB</strong> register:</p>
<pre>int temp = PINB;</pre>
<h4>analogWrite</h4>
<p>You can use OC0A (PB0) and OC0B (PB1) for analogue output using PWM. You first need to configure the Timer/Counter into PWM mode for that pin; for example, using PB0:</p>
<pre>TCCR0A = 2&lt;&lt;COM0A0 | 3&lt;&lt;WGM00; // 10-bit PWM on OC0A (PB0), non-inverting mode
TCCR0B = 0&lt;&lt;WGM02 | 1&lt;&lt;CS00;   // Divide clock by 1
DDRB = 0b0001;                 // Make PB0 an output</pre>
<p>To write an analogue value we then need to write the value to the appropriate output compare register, OCR0A:</p>
<pre>OCR0A = 1000;                  // Equivalent to analogWrite(0, 1000)</pre>
<p>With a 5V supply this will set PB0 to 1000/1024 * 5V, or 4.88V.</p>
<h4>analogRead</h4>
<p>To use an I/O pin for analogue input you first need to configure the Analogue-to-Digital Converter. For example, to use ADC0:</p>
<pre>ADMUX = 0&lt;&lt;MUX0;               // ADC0 (PB0)
ADCSRA = 1&lt;&lt;ADEN | 3&lt;&lt;ADPS0;   // Enable ADC, 125kHz clock</pre>
<p>To read an analogue value from the pin we then need to start a conversion, and when the conversion is ready read the ADC register:</p>
<pre>ADCSRA = ADCSRA | 1&lt;&lt;ADSC;     // Start
while (ADCSRA &amp; 1&lt;&lt;ADSC);      // Wait while conversion in progress
int temp = ADCL;               // Copy result to temp
</pre>
<h4>delay</h4>
<p>For a simple substitute for&nbsp;<strong>delay()</strong>&nbsp;you can use a loop adjusted to give roughly the right timing:</p>
<pre>void delay (int millis) {
  for (volatile unsigned int i = 34*millis; i&gt;0; i--);
}</pre>
<p>This would provide an alternative way of writing the Blink program. Note that the counter variable&nbsp;<strong>i</strong>&nbsp;must be defined as&nbsp;<strong>volatile</strong>&nbsp;or the compiler will optimise it out of the loop, eliminating the delay.</p>
<p>For more accurate delays, and to implement timers like&nbsp;<strong>millis()</strong>, you could set up Timer/Counter0 as a timer, or use the Watchdog Timer.</p>
<h3>Update</h3>
<p>30th December 2019: Added a note about problems compiling for the ATtiny10 with versions of the Arduino IDE 1.8.9 or later. Use 1.8 to 1.8.8.</p><hr>
<ol>
<li id="cite_note1"><a href="#cite_ref1">^</a> <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/Atmel-8127-AVR-8-bit-Microcontroller-ATtiny4-ATtiny5-ATtiny9-ATtiny10_Datasheet.pdf">ATtiny10 Datasheet</a> on Microchip.</li>
<li id="cite_note2"><a href="#cite_ref2">^</a> <a href="https://www.sparkfun.com/products/717" target="_blank">Sparkfun SOT23 to DIP Adapter</a> on Sparkfun.</li>
<li id="cite_note3"><a href="#cite_ref3">^</a> <a href="http://www.fischl.de/usbasp/" target="_blank">USBasp - USP programmer for Atmel AVE controllers</a>&nbsp;on www.fischl.de.</li>
<li id="cite_note4"><a href="#cite_ref4">^</a> <a href="https://www.ebay.co.uk/itm/USBASP-USBISP-ISP-Programmer-Cable-Adapter-KK2-0-KK2-1-Atmel-AVR-ATMega-ARDUINO/131241223483" target="_blank">USBASP ISP Programmer Cable Adapter</a>&nbsp;from Boos Bits on eBay.</li>
<li id="cite_note5"><a href="#cite_ref5">^</a> <a href="https://www.banggood.com/USBASP-USBISP-3_3-5V-AVR-Downloader-Programmer-With-ATMEGA8-ATMEGA128-p-934425.html" target="_blank">USBASP 3.3 5V AVR Downloader Programmer</a>&nbsp;on Banggood.</li>
</ol>

<hr>


<p><a href="http://disqus.com/">blog comments powered by </a></p></div></div>]]>
            </description>
            <link>http://www.technoblogy.com/show?1YQY</link>
            <guid isPermaLink="false">hacker-news-small-sites-25368633</guid>
            <pubDate>Thu, 10 Dec 2020 02:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Behind the scenes photos of YC S20]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25368499">thread link</a>) | @cheeseblubber
<br/>
December 9, 2020 | https://papercups.io/blog/what-remote-demo-day-looked-like | <a href="https://web.archive.org/web/*/https://papercups.io/blog/what-remote-demo-day-looked-like">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://papercups.io/blog/what-remote-demo-day-looked-like</link>
            <guid isPermaLink="false">hacker-news-small-sites-25368499</guid>
            <pubDate>Thu, 10 Dec 2020 01:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How eBPF Works]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25367728">thread link</a>) | @gk1
<br/>
December 9, 2020 | https://goteleport.com/blog/what-is-ebpf/ | <a href="https://web.archive.org/web/*/https://goteleport.com/blog/what-is-ebpf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <a href="https://goteleport.com/blog/index.xml"><i></i></a>
      
      

        

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-header.png" width="100%" alt="what is ebpf"></p>

<p>About a year ago, a friend of mine decided to build an <a href="https://medium.com/mycrypto/the-ethereum-virtual-machine-how-does-it-work-9abac2b7c9e">EVM</a> (Ethereum Virtual Machine) assembler in Rust. After some prodding from him, I began to help by writing unit tests. At the time, I knew very little about operating systems and started to read about lexical and symbolical analyzers. I was quickly in way over my head. What I did retain, however, was a newfound appreciation for the OS as a whole. So, when he started raving about eBPF, I knew I was in for a treat.</p>

<p>The bar for understanding what eBPF is and what it can do is high. Finding a good foothold to start was difficult for me. On the spectrum of basic 500-word mini-blogs to <a href="https://cilium.io/">Cilium‚Äôs</a> overwhelming documentation, material certainly skews towards documentation. My goal here is to provide a thorough entrypoint into this nascent technology, preparing you for progressively technical deep dives, like <a href="https://lwn.net/Articles/740157/">Linux Weekly News</a>, <a href="http://www.brendangregg.com/index.html">Brendan Gregg‚Äôs</a> website, and Cilium‚Äôs <a href="https://docs.cilium.io/en/stable/bpf/">documentation</a>. Together, we will explore:</p>

<ul>
<li>What eBPF does</li>
<li>How eBPF works</li>
<li>An example of eBPF in use</li>
<li>How to start using eBPF</li>
</ul>

<h2 id="what-does-ebpf-do">What Does eBPF Do?</h2>

<p>eBPF lets programmers execute custom bytecode within the kernel <em>without</em> having to change the kernel or load kernel modules. Exciting? Maybe not yet. eBPF is closely intertwined with the Linux kernel. For context, let‚Äôs briefly review some fundamental concepts.</p>

<p>Linux divides its OS into two distinct areas: kernel space and user space. Kernel space is where the core of the operating system resides. It has full and unrestricted access to all hardware - memory, storage, CPU, etc. Due to the privileged nature of kernel access, the space is protected and allowed to run only the most trusted code. User space is where anything that is not a kernel process runs - I/O, file system manipulation, etc. These programs have limited access to hardware and must make syscalls through an API exposed by the kernel. In other words, user space programs must be filtered through the kernel space.</p>

<p>While the system call interface was sufficient in most cases, developers need more flexibility to add support for new hardware, filesystems, network protocols, or even custom system calls. There had to be a way for custom programs to access hardware directly, a way to extend the base kernel without adding directly to the kernel source code. <a href="https://tldp.org/LDP/lkmpg/2.6/html/lkmpg.html">Linux Kernel Modules</a> (LKMs) serve this function. Unlike system calls, whereby requests traverse from the user space to kernel space, LKMs are loaded directly into the kernel, making them a part of it. Perhaps the most valuable feature of LKMs is that it can be loaded at runtime, removing the need to recompile the entire kernel and reboot the machine.</p>

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-1.png" width="60%" alt="LKMs in kernel space"></p>

<p>Figure 1 - LKMs can be dynamically loaded and unloaded as part of kernel space (<a href="http://derekmolloy.ie/writing-a-linux-kernel-module-part-1-introduction/">Source</a>)</p>

<p>As helpful as LKMs are, they do introduce a lot of risk to the system. The division of kernel and user spaces added a number of security measures to the OS. The kernel space is meant to run only a privileged OS kernel. The layer between, connected by the system call interface, separated user space programs that could mess with finely tuned hardware. In other words, LKMs could certainly crash the kernel. Aside from the wide blast radius of security vulnerabilities, modules incur a large overhead maintenance cost in that kernel version upgrades could break the module.</p>

<h4 id="what-is-ebpf">What is eBPF</h4>

<p>eBPF programs are a more recent invention for accessing services and hardware from the Linux kernel space. Already these programs have been used for networking, debugging, tracing, firewalls, and more.</p>

<p>Born out of a need for better Linux tracing tools, eBPF drew inspiration from <code>dtrace</code>, a dynamic tracing tool available primarily for Solaris and BSD operating systems. Unlike <code>dtrace</code>, Linux could not get a global overview of running systems, it was limited to specific frameworks for system calls, library calls, and functions. Building on the Berkeley Packet Filter (BPF), a tool for writing packer-filtering code using an in-kernel VM, a small group of engineers began to extend the BPF backend to provide a similar set of features as <code>dtrace</code>. First released in limited capacity in 2014 with Linux 3.18, making full use of eBPF requires at least Linux 4.4 or above.</p>

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-2.png" width="100%" alt="simplified visualization of eBPF architecture"></p>

<p>Figure 2</p>

<p>In Figure 2, we see a simplified visualization of eBPF architecture. Before being loaded into the kernel, the eBPF program must pass a certain set of requirements. Verification involves executing the eBPF program within the virtual machine. Doing so allows the <a href="https://github.com/torvalds/linux/blob/master/kernel/bpf/verifier.c">verifier</a>, with 10,000+ lines of code, to perform a series of checks. The verifier will traverse the potential paths the eBPF program may take when executed in the kernel, making sure the program does indeed run to completion without any looping that would cause a kernel lockup. Other checks, from valid register state, program size, to out of bound jumps, must also be met. Almost immediately, eBPF sets itself apart from LKMs with important safety controls in place.</p>

<p>If all checks are passed, the eBPFprogram is loaded and compiled into the kernel at a point in a code path and listens for the right signal. That signal comes in the form of an event that passes where the program is loaded in the code path. Once triggered, the bytecode executes and collects information as per its instructions.</p>

<p>So what does eBPF do? It lets programmers safely execute custom bytecode within the Linux kernel without modifying or adding to kernel source code. While still a far cry from replacing LKMs as a whole, eBPF programs introduce custom code to interact with protected hardware resources with minimal threat to the kernel.</p>

<h2 id="how-ebpf-works">How eBPF Works</h2>

<p>So far, I‚Äôve reduced eBPF to its bare architecture. But, there are more components working together, each of which has layers of complexity of their own.</p>

<h3 id="anatomy-of-an-ebpf-program">Anatomy of an eBPF Program</h3>

<h4 id="events-and-hooking">Events and Hooking</h4>

<p>eBPF programs are triggered by events that pass a particular location in the kernel. These events are captured at hooks when a specific set of instructions are executed in a single run. When triggered, these hooks will execute an eBPF program, letting us capture or manipulate data. The diversity of hook locations is one of the many aspects that makes eBPF so useful. A quick sampling of these locations include:</p>

<ul>
<li>System Calls - Inserted when user space functions transfer execution to the kernel</li>
<li>Function Entry and Exit - Intercepts calls to pre-existing functions</li>
<li>Network Events - Executes when packets are received</li>
<li>Kprobes and uprobes - Attach to probes for kernel or user functions</li>
</ul>

<h4 id="helper-calls">Helper Calls</h4>

<p>When eBPF programs are triggered at their hook points, they make calls to helper functions. These special functions are what makes eBPF feature-rich in accessing memory. For example, helpers can perform a wide variety of tasks:</p>

<ul>
<li>Search, update, and delete key-value pairs in tables</li>
<li>Generate a pseudo-random number</li>
<li>Collect and flag tunnel metadata</li>
<li>Chain eBPF programs together, known as tail calls</li>
<li>Perform tasks with sockets, like binding, retrieve cookies, redirect packets, etc.</li>
</ul>

<p>These helper functions must be defined by the kernel, meaning there is a whitelist of calls eBPF programs can make. But the <a href="https://man7.org/linux/man-pages/man7/bpf-helpers.7.html">number</a> is large and continues to grow.</p>

<h4 id="maps">Maps</h4>

<p>To store and share data between the program and kernel or user spaces, eBPF makes use of maps. As implied by the name, maps are key-value pairs. Supporting a number of different data structures, like hash tables, arrays, and tries, programs are able to send and receive data in maps using helper functions.</p>

<h3 id="executing-an-ebpf-program">Executing an eBPF Program</h3>

<h4 id="loading-and-verifying">Loading and Verifying</h4>

<p>The kernel expects all eBPF programs to be loaded as bytecode, so unless bytecode is being written, we need a way to compile higher level languages. To build out this compiler, eBPF uses <a href="https://llvm.org/">LLVM</a> as its back-end infrastructure on which a front-end for any programming language can be built. Because eBPF programs are written in C, that language front end is <a href="https://clang.llvm.org/">Clang</a>. But before compiled bytecode can be hooked anywhere, it must pass a series of checks. By simulating the program in a VM-like construct, an <a href="https://elixir.bootlin.com/linux/latest/source/kernel/bpf/verifier.c">in-kernel verifier</a> can prevent programs that loop, do not have the right permissions, or crash the kernel. If the program passes all checks, program bytecode will be loaded onto the hook point using a <code>bpf()</code> system call</p>

<h4 id="just-in-time-jit-compiler">Just-In-Time (JIT) Compiler</h4>

<p>After verification, eBPF bytecode is JIT‚Äôd into native machine code. eBPF has a modern design, meaning it has been upgraded to be 64-bit encoded with 11 total registers. This closely maps eBPF to hardware for x86_64, ARM, and arm64 architecture, amongst others. Fast compilation at runtime makes it possible for eBPF to remain performant even as it must first pass through a VM.</p>

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-3.png" width="100%" alt="eBPF architecture"></p>

<p>eBPF Architecture (<a href="https://lucid.app/invitations/accept/0096e31e-14f9-47d4-a1a0-57e82b3bc6f5">Raw LucidChart</a>)</p>

<h3 id="summary">Summary</h3>

<p>Putting this conceptual jigsaw together, eBPF programs are inserted into a hook point after passing a number of safety checks. When they are triggered by an event, programs execute immediately, using a combination of helper functions and maps to manipulate and store data. We‚Äôll take a closer look at how these components work together in the next section</p>

<h2 id="example-ebpf-in-action">Example: eBPF in Action</h2>

<p>At Teleport, we‚Äôve used a few eBPF programs in one of our open source projects, Teleport, for tracing and networking. For some necessary context: <a href="https://goteleport.com/teleport">Teleport</a> gives developers secure server access via SSH. Because organizations want to know what happens during a session, Teleport records user actions. Yet there are ways to bypass session recording entirely by obfuscating behavior within encoded commands, commands run in shell scripts, or even terminal commands like disabling <code>echo</code>.</p>

<p>Earlier this year with our <a href="https://goteleport.com/blog/teleport-release-4-2">Teleport 4.2 release</a>, we introduced <em>enhanced</em> session recording, which uses three eBPF programs (for now!) to take unstructured SSH sessions and transform them into a stream of structured events.</p>

<p>Consider <code>echo Y3VybCBodHRwOi8vd3d3LmV4YW1wbGUuY29tCg== | base64 --decode | sh</code>. Though we can capture this command printed in the terminal, it means nothing to us as the ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://goteleport.com/blog/what-is-ebpf/">https://goteleport.com/blog/what-is-ebpf/</a></em></p>]]>
            </description>
            <link>https://goteleport.com/blog/what-is-ebpf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25367728</guid>
            <pubDate>Thu, 10 Dec 2020 00:27:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DOSBox-X 0.83.8 Released]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25367662">thread link</a>) | @fm77
<br/>
December 9, 2020 | https://dosbox-x.com/release-0.83.8.html | <a href="https://web.archive.org/web/*/https://dosbox-x.com/release-0.83.8.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="100%">
            <tbody><tr>
            <td></td>
            <td>
            <p>1. Notable New Features</p>
<ul>
<li><p>Scalable TrueType font (TTF) output for DOS applications</p>With the new TrueType font (TTF) output, you will get nice high resolution DOS screen rendered using a TrueType font (either the built-in one or a TTF font of your choice), and the window can be set to almost any usable number of lines and columns. This feature greatly improved DOSBox-X's support for DOS applications. Set "output=ttf" (or from the "Video" menu) to enable this output.</li>

<li><p>On-screen text styles for DOS applications</p>With the TrueType font output, DOSBox-X now supports on-screen text styles for DOS applications including WordPerfect, WordStar, and XyWrite. With this feature you will visually see fonts in bold for bold text, and fonts in italics for italicized text, and so on. Set a DOS word processor (WP/WS/XY) to enable this feature.</li>

<li><p>Support for Apple M1 Mac and macOS Big Sur</p>DOSBox-X now supports the new Apple ARM-based M1 MacBooks! The dynamic core now works on the new ARM-based macOS systems. The audio also works once again when compiled and run on macOS 11 Big Sur.</li>

<li><p>Pasting clipboard text in macOS SDL1 builds</p>Pasting text from the host system clipboard is now supported in the macOS SDL1 build, similar to the Linux SDL1 build. On all other platforms (Windows SDL1/SDL2, Linux SDL2, and macOS SDL2) both copying to and pasting from the clipboard are supported.</li>

<li><p>System menu in Windows SDL2 builds</p>The system menu that was available in Windows SDL1 builds is now also
available for Windows SDL2 builds, which includes a few common menu options such as the configuration tool and the mapper editor.</li>

<li><p>Select common host keys from the menu</p>You can now select a host key from the "Main" menu, which now includes common key combinations such as Ctrl+Alt, Ctrl+Shift, and Alt+Shift, or you may just use the mapper-defined host key (which default to F11 on Windows and F12
otherwise). The default shortcuts for a few items are changed to use the host key style.</li>

<li><p>Switch OpenGL (GLSL) shaders at run-time</p>With the OpenGL outputs (opengl/opengnb/openghq), you can now select and switch to a different GLSL shader at the run-time by selecting the menu item "Select OpenGL (GLSL) shader..." from the "Video" menu, similar to the function for Direct3D pixel shaders for the Direct3D output.</li>

<li><p>Display IDE disk or CD status</p>There is now a menu option under "DOS" menu which allows you to see the current assignments (disk or CD image) of the IDE controllers.</li>

<li><p>Support for mounting MAME CHD CD images</p>Mounting the MAME CHD images is now supported in DOSBox-X! You can mount CHD files as CD images with IMGMOUNT command, or from the "Drive" menu.</li>

<li><p>Support for saving your files for the save-state feature</p>There is a now a FLAGSAVE command which allows you to mark files to be saved and loaded by the save-state feature. Type "FLAGSAVE /?" at the DOSBox-X shell for more usage information.</li>

<li><p>Enhanced MODE command to change screen dimensions</p>You can now change the number of columns and lines on the screen with the
MODE command, similar to real DOS systems. Alternatively, this can be done from the "Video" menu (within "Text-mode" menu group).</li>

<li><p>Improved LOADFIX command to auto-allocate memory</p>The LOADFIX command now has an -a option which will automatically allocate enough memory to fill lowest 64KB memory instead of using exactly 64KB memory. This will let some memory-demanding DOS programs or games to run with this command.</li>

<li><p>Improved automatic fix for the "Packed file corrupt" error</p>The handler for the "Packed file corrupt" error has been greatly improved so that it will likely automatically handle the error more efficiently. There is now also an option to silence the messages during the automatic fix.</li>

</ul>

            <p>2. Notable Usability Improvements</p>
<ul>
<li><p>Improved mapper editor interface</p>The mapper editor interface has been enhanced! The texts for the shortcut functions are now longer and clearer, and there are now multiple pages in the mapper, navigable with the "Previous Page" and "Next Page" buttons.</li>

<li><p>Load DOSBox-X mapper files from menu</p>You can now select and load DOSBox-X mapper files at run-time from the "Main" menu. Previously it was possible to load a mapper file dynmically from the command line, but now you can do so from the menu too.</li>

<li><p>List network interfaces from menu</p>There is now a "List network interfaces" menu option under the "Help" menu that will list the current network interfaces for the NE2000 networking feature. Previously you can only see the network interface list from the log file.</li>

<li><p>Display DOS command help from menu</p>You can now find a "DOS commands" menu group under the "Help" menu, which allows you to select a DOS shell command (DIR, CD, etc) to see its help messages. Alternatively you can type "[COMMAND] /?" (e.g. "DIR /?") for help information for the command.</li>

<li><p>Searching for config file and mapper file in DOSBox-X executable path</p>DOSBox-X will now look for the config file (e.g.
dosbox-x.conf) and the mapper file in the directory containing the DOSBox-X executable too if they cannot be found in the DOSBox-X working directory. This makes DOSBox-X even more portable.</li>

<li><p>More saving options for the built-in configuration tool</p>The graphical configuration tool now provides the option to save
to the primary or user config files, not just the dosbox-x.conf file.</li>

<li><p>New config options for save state options</p>The config options "saveremark" and "forceloadstate" are added to [dosbox]
section which can be used to control the save state-related options from the config file. In the previous section these can only be done from the "Capture" menu.</li>

</ul>

            <p>3. Bugfixes and Other Improvements</p>
There are also many bugfixes and other improvements, such as fixing the CD audio issue with the game "The Secret of Monkey Island" when talking to the pirate in Scumm Bar. Please see the full changelogs below for more information.
<p>4. Full Changelog In This Version</p>
<ul>
<li>
Added support for scalable TrueType font (TTF)
output for text-mode programs. Set "output=ttf"
and optionally a monospaced TTF font (such as
consola) with config option "ttf.font" to use it.
Lines and columns can be specified with config
options "ttf.lins" and "ttf.cols", and the cursor
can be made blinking with the option "ttf.blinkc".
The config options "ttf.ptsize" and "ttf.winperc"
can be used to set the TTF font size and window
percentage respectively. If you specify a TTF font
size with "ttf.ptsize" then "ttf.winperc" will be
ignored. You can also specify a word processor
(WP=WordPerfect, WS=WordStar, XY=XyWrite) for the
on-screen text-style and 512-character font (WP)
features. When using the TTF output DOSBox-X will
temporarily switch to a different output when a
graphical mode is requested (or when trying to take
a screenshot); the TTF output will be auto-switched
back later), which can be customized via config
option "ttf.outputswitch" (which defaults to auto).
Menu items in the "Text-mode" menu group (under
"Video" menu) have been expanded to support TTF
options such as increasing/decreasing the TTF font
sizes and on-screen text style toggling (including
bold, italics, underline and strikeout). You can
also select a TTF font to use at run-time with the
"Select TrueType font (TTF)" menu option. (Wengier)
</li><li>
Added the "Load mapper file..." menu option (under
"Main") to select and load a DOSBox-X mapper file
at run-time. Be sure to select a SDL1 mapper file
for SDL1 builds, and similar for SDL2. (Wengier)
</li><li>
You can now select a host key from the menu (under
"Main") including Ctrl+Alt, Ctrl+Shift, Alt+Shift,
or use the mapper-defined host key as in previous
versions (which default to F11 on Windows and F12
otherwise). A config option "hostkey" is added so
that you can specify it from config file. (Wengier)
</li><li>
Pasting text from the clipboard on macOS SDL1 build
is now supported like Linux SDL1 build. (Wengier)
</li><li>
Added support for ARM-based Apple M1 MacBook. The
dynamic core now works on ARM-based macOS systems.
SDL1 builds updated to use newer audio APIs on the
macOS platform so that the audio works once again
when compiled and run on macOS 11 (Big Sur). Prior
to the change, ancient versions of the API dating
back to the mid 2000s were used which no longer
work on Big Sur.
</li><li>
DOSBox-X will now look for the config file (i.e.
dosbox-x.conf/dosbox.conf) and the mapper file in
the directory containing the DOSBox-X executable
too if the config or mapper file cannot be found
in the DOSBox-X working directory. (Wengier)
</li><li>
The system menu in Windows SDL1 builds is now also
available for Windows SDL2 builds, and menu items
"Reset font size", "Increase TTF font size" and
"Decrease TTF font size" are added. (Wengier)
</li><li>
Enhanced the mapper editor interface to allow more
keyboard shortcuts to be added, shown in multiple
pages in the mapper, navigable with the "Previous
Page" and "Next Page" buttons. The text in the
grids are now longer and clearer too. The default
shortcuts for a few items are changed to use the
Host key style (e.g. Host+S and Host+L for saving
and loading states respectively). (Wengier)
</li><li>
Added menu item "List network interfaces" under
"Help" menu to list network interfaces in the host
system for the NE2000 feature. (Wengier)
</li><li>
Added menu group "DOS commands" under "Help" menu
to display the help content for the selected DOS
shell command (DIR, CD, etc). (Wengier)
</li><li>
Configuration Tool now provides the option to save
to the primary or user config files. (Wengier)
</li><li>
Certain config options (e.g. doublescan) that were
marked as advanced options are now general config
options and will appear in dosbox-x.reference.conf
apart from dosbox-x.reference.full.conf. (Wengier)
</li><li>
Added config options "saveremark" (default: true)
and "forceloadstate" (default: false) in [dosbox]
section which can be used to control if DOSBox-X
should ask users to enter remarks when saving a
state or show warnings when loading a saved state
if there is a mismatch found. (Wengier)
</li><li>
The config option "pixelshader" is moved from the
section [gui] to [render] ‚Ä¶</li></ul></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dosbox-x.com/release-0.83.8.html">https://dosbox-x.com/release-0.83.8.html</a></em></p>]]>
            </description>
            <link>https://dosbox-x.com/release-0.83.8.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25367662</guid>
            <pubDate>Thu, 10 Dec 2020 00:22:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Filmbox ‚Äì Physically accurate motion picture film emulation]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 43 (<a href="https://news.ycombinator.com/item?id=25367371">thread link</a>) | @wilg
<br/>
December 9, 2020 | https://videovillage.co/filmbox/ | <a href="https://web.archive.org/web/*/https://videovillage.co/filmbox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://videovillage.co/images/filmbox/hero-ee5486c3.jpg" alt="Hero"></p><p><h2>A complete reproduction of photochemical motion picture imaging.</h2><h2>Driven by empirical data and tailored to specific digital sensors.</h2><h2>Built for high-end production. Right in DaVinci Resolve.</h2></p><div><div><p><h2>The look and feel of motion picture film defines a century of art.</h2><h2>As we move beyond the photochemical process, we need not leave behind its aesthetic quality.</h2></p><div><div><div><p><h2>Film negative has a unique response to light intensity and wavelength. Filmbox reproduces this behavior using rich empirical datasets to transform digital sensor values to exhibit the same non-linearities.</h2></p></div></div></div><div><div><div><p><h2>As light strikes color film negative, different wavelengths scatter to different degrees within the layers of emulsion and affect neighboring image regions. Filmbox convolves the digital image data to recreate the soft yet detailed quality of the negative.</h2></p></div></div></div><div><div><div><p><h2>The perceptual intensity of film grain varies with the density of the developed negative. Filmbox reproduces the quality and tonal distribution of grain as well as other subtle effects of the development process.</h2></p></div></div></div><div><div><div><p><h2>Film camera transport mechanisms are not perfectly stable, and labs are not perfectly clean. If desired, Filmbox can model the subtle instability of real 35mm and 16mm cameras, and procedurally place samples of real dust.</h2></p></div></div></div><div><div><div><p><h2>The look of projected film is the combination of the characteristics of the negative and the print.</h2><h2>Filmbox maps the emulated negative to the light output of the digital display using a characterization of the combined photometric response of an actual contact printed negative.</h2></p></div></div></div></div></div><div><div><video autoplay="" data-sources="W3sic3JjIjoiL2ltYWdlcy9maWxtYm94L3ZpZGVvL2NvbXBhcmlzb24vdmlk
ZW8ubXA0IiwidHlwZSI6InZpZGVvL21wNDsgY29kZWNzPVwiYXZjMVwiIn1d
" loop="" muted="" playsinline="" poster="https://videovillage.co/images/filmbox/video/comparison/poster-c124bf44.jpg"><img alt="Comparison of Filmbox and actual film" src="https://videovillage.co/images/filmbox/video/comparison/poster-c124bf44.jpg"></video></div></div><div><div><p><h2>Built for simplicity, no tweaking necessary.</h2><h2>Consistent, predictable, understandable by the whole creative team.</h2><h2>Plenty of knobs under the hood if you want to tinker.</h2></p><div><p><img src="https://videovillage.co/images/filmbox/features/default-17385d13.jpeg" alt="Default"></p></div></div></div><div><div><p><img src="https://videovillage.co/images/filmbox/workflow_fb-f68b50df.jpg" alt="Workflow fb"></p><p>Pro Workflows</p><div><p>Profiled for Alexa, Venice, RED, Varicam, Blackmagic URSA, C300II</p><p>Work in the camera's native space, Resolve Intermediate, or ACES</p><p>Set looks between the Negative and Print to simulate DI and printer lights</p><p>Output as negative, or as print to standard display spaces or ACES</p></div></div><div><p><img src="https://videovillage.co/images/scatter/gpu-52db23e1.jpg" alt="Gpu"></p><p>Fast</p><div><p>Built for DaVinci Resolve using GPU acceleration</p><p>Realtime performance at DCI 4K</p></div></div></div><section><div><p><img width="128" height="128" src="https://videovillage.co/images/filmbox-6cdfa86d.png" alt="Filmbox"></p><p>Filmbox</p><p>Really good film emulation</p></div><div><div><p>Filmbox is still in early access so we can make sure it works great.</p>

<p>Plugin for DaVinci Resolve. Requires macOS 10.15 or later and DaVinci Resolve 16 or later.</p>
</div></div></section><section id="footer"><p>¬© &amp; ‚Ñ¢ 2014-2020 Video Village, LLC</p><p>Made in California by <a href="http://gregcotten.com/">Greg Cotten</a> &amp; <a href="http://wilgieseler.com/">Wil Gieseler</a> &amp; <a href="http://afinch.com/">Andrew Finch</a>.</p></section></div></div>]]>
            </description>
            <link>https://videovillage.co/filmbox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25367371</guid>
            <pubDate>Wed, 09 Dec 2020 23:57:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Own Your Email]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25367035">thread link</a>) | @fabienpenso
<br/>
December 9, 2020 | https://pen.so/2020/12/10/own-your-email/ | <a href="https://web.archive.org/web/*/https://pen.so/2020/12/10/own-your-email/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
		<p>Using <em>@gmail.com</em> for your email address is like living at someone‚Äôs house
without rent and potentially being kicked out any day without warning. All your
belongings inside, without any access.</p>

<p>One of my first jobs around 1997 was being a sysadmin and managing email
servers, writing <code>sendmail.cf</code> configuration files without M4, and I should
have known better.</p>

<p>Someone who used Gmail for over 10 years <a href="https://www.businessinsider.fr/us/google-users-locked-out-after-years-2020-10">recently got locked
out</a>
without explanation. When all services you use, tools, and all your life are
connected to your <em>@gmail.com</em> address, you can imagine how much of a nightmare
scenario this is.</p>

<blockquote>
  <p>‚ÄúIt feels like getting baited by all the convenience that Google offers, only for Google to use your data as it pleases and possibly takes it all away with no prior notice.‚Äù</p>

  <p><cite>‚Äî <a href="https://www.businessinsider.fr/us/google-users-locked-out-after-years-2020-10">What it‚Äôs like to get locked out of Google indefinitely</a></cite></p>
</blockquote>

<p>Gmail has been here for so long it‚Äôs hard to imagine they can take it away from
you just as quickly. And good luck to get it back once that happens‚Ä¶ Therefore
I highly recommend using their <a href="https://takeout.google.com/">Takeout</a> feature
to back up all your data and move away from using their domain <em>@gmail.com</em> in
your email address.</p>

<p>The unit of Internet space ownership is the domain name, get yours now.</p>

<p>I also use my <em>@gmail.com</em> too much because it‚Äôs easy, and its spam filtering
is so good. But I‚Äôve reconsidered it, moved away, and use a non-public address
on my own domain when registering for new services. The following is a detail
of what I did and what I used to implement it.</p>

<h4 id="email-portability">Email portability</h4>

<p>Mobile phone numbers are so critical to everyday life that France has a law
allowing you to keep your phone number using a <a href="https://fr.wikipedia.org/wiki/Relev%C3%A9_d%27identit%C3%A9_op%C3%A9rateur">Relev√© d‚Äôidentit√©
op√©rateur</a>
(carrier identity number) when changing carrier. This service must be provided
free of charge.</p>

<p>Email addresses are essential, and portability is as key for them as for phone
numbers. But you can‚Äôt keep the same address when switching from one provider
to another. Once you start using <em>something@gmail.com</em>, it is painful to move
to a new one as you have to change it on every service you use, confirming each
one, one by one.</p>

<p><a href="https://twitter.com/dhh/status/1323582505065320448">@dhh says</a> <em>Hey!</em> will
forward your email for life once you paid for the first year. That should be
mandatory for all providers, so you don‚Äôt have this Gmail life single point of
failure. It‚Äôs best to own your own domain name, but this is a lesser evil than
most other email providers.</p>

<p>I believe email providers should be legally obliged to forward your email
address for life to a new email address. A routing system similar to
<a href="https://fr.wikipedia.org/wiki/Relev%C3%A9_d%27identit%C3%A9_op%C3%A9rateur">RIO</a>
preventing the old provider from having to forward them to the new one would be
best, but this is not technically possible with the SMTP Protocol.</p>

<p>Some people went as far as <a href="https://kevq.uk/de-googling-my-life-2-years-on/">De-Googling their
life</a> completely with success.</p>



<p>I created my <a href="https://www.hey.com/">hey</a> account for both making sure
fabienAThey.com would be mine if I ever wanted to use it, and for trying it
after viewing <a href="https://www.youtube.com/watch?v=UCeYTysLyGI&amp;t=175s">this video</a>
about the service. Some of the features really make sense, like editing email
subjects <em>after</em> you received them or grouping multiple threads, but I still
prefer classic email interfaces.</p>

<p>After looking at a few options, I opted for
<a href="https://www.fastmail.com/">Fastmail</a> for their pricing, security disclaimer,
and overall good reputation. I used <a href="https://kolabnow.com/">Kolab</a> for years
but decided to move away. I also quickly tried Zoho but had a bad experience
with their UI trying to set things up.</p>

<p>I also used FM import feature to get all my old emails from Kolab back to FM.</p>

<p>I enabled catch-all emails on FM, meaning any email to my domain is redirected
to me. Anywhere I register, I use a different email address based on the
service‚Äôs name (service@my_domain_com). I can easily set specific filters like
anything sent to service@mydomain goes to its folder and skip the inbox, or
find who resell my email.</p>

<p>It used to be a real pain to do that, but the password manager included in
Safari (or 1Password) now remembers which email you used to register to a
service. You don‚Äôt have to remember that yourself anymore.</p>

<p>I added a server filter. Anything matching /unsubscribe/ goes to a specific
/unsub/ folder and skip the inbox. All newsletters usually get caught in this.
I enabled server-side spam filtering on FM and installed
<a href="https://c-command.com/spamsieve/">Spamsieve</a> on my laptop for a local bayesian
filter, moving detected spam to a Junk folder.</p>

<p>I use <a href="https://freron.com/">Mailmate</a> to read emails, which is by far the best
email client I ever found on macOS (a long way from Linux and in order Elm,
Pine, Mutt, Gnus). I now remember why I started using Gmail‚Ä¶ Because I was
coming from those MUA!</p>

	</div></div>]]>
            </description>
            <link>https://pen.so/2020/12/10/own-your-email/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25367035</guid>
            <pubDate>Wed, 09 Dec 2020 23:30:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to think about clean power generation]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25367014">thread link</a>) | @nitiniyer
<br/>
December 9, 2020 | https://climaticthoughts.com/clean-power-generation | <a href="https://web.archive.org/web/*/https://climaticthoughts.com/clean-power-generation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://climaticthoughts.com/content/images/size/w300/2020/12/Screen-Shot-2020-12-06-at-12.21.11-AM-1.png 300w,
                                https://climaticthoughts.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-06-at-12.21.11-AM-1.png 600w,
                                https://climaticthoughts.com/content/images/size/w1200/2020/12/Screen-Shot-2020-12-06-at-12.21.11-AM-1.png 1000w,
                                https://climaticthoughts.com/content/images/size/w2000/2020/12/Screen-Shot-2020-12-06-at-12.21.11-AM-1.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://climaticthoughts.com/content/images/size/w2000/2020/12/Screen-Shot-2020-12-06-at-12.21.11-AM-1.png" alt="Clean power generation: A 24 x 365 endeavor">
            </figure>
            <section>
                <div>
                    <h3 id="every-hour-of-every-day-of-every-year">Every hour of every day of every year</h3><p>A framework I‚Äôve found helpful for understanding what it means to get to 100% carbon-free electricity generation is a 24 x 365 grid. Each of the 8,760 squares represents an hour of power generation in the year that needs to be emissions free. I first came across this diagram reading <a href="https://storage.googleapis.com/gweb-sustainability.appspot.com/pdf/24x7-carbon-free-energy-data-centers.pdf">Google‚Äôs 2019 discussion paper</a> on their corporate efforts to match 100% of their data center‚Äôs electricity demand with zero-carbon sources at every hour. In Google‚Äôs version of the diagram (shown below), green indicates a 100% clean energy match and grey means a 0% match. The gradation across each day and throughout the year reveals where there‚Äôs progress and where difficulties remain. More organizations in the private sector and in government should adopt this method of thinking about power generation for themselves or the region in which they are responsible. This framework makes the problem tractable and makes the end goal clear. Every hour of every day of every year must be 100% clean ‚Äî each square needs to be solid green.</p><figure><img src="https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-12.43.00-AM.png" alt="" srcset="https://www.climaticthoughts.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-05-at-12.43.00-AM.png 600w, https://www.climaticthoughts.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-05-at-12.43.00-AM.png 1000w, https://www.climaticthoughts.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-05-at-12.43.00-AM.png 1600w, https://www.climaticthoughts.com/content/images/size/w2400/2020/12/Screen-Shot-2020-12-05-at-12.43.00-AM.png 2400w" sizes="(min-width: 1200px) 1200px"><figcaption>Example of 24 x 365 grid from Google's 2019 discussion paper</figcaption></figure><p>A benefit of the 24 x 365 diagram is the breakdown along the axes of time of day and time of year. Both are critical because the pathway to 100% clean energy runs through massively increasing solar and wind energy generation which are highly time dependent. While this framework makes visualizing the utilization of those two technologies easier, it also puts emphasis on the most important objective: Achieving 0 emissions from power generation at all times. The goal isn't just deploying 500 more megawatts of solar or closing down a specific natural gas plant, it‚Äôs about bringing each hour to 100% clean energy generation. Tactics should stay tactics while strategy is created to bring portions of the day or year to 100% zero emissions through any number of methods.</p><p>While useful on its own, the 24 x 365 grid is even better when paired with the ability to zoom in and observe the quantity and mix of power generated each day. These types of charts are common today among grid operators. <a href="https://www.nyiso.com/real-time-dashboard">NY ISO</a> and <a href="https://www.caiso.com/TodaysOutlook/Pages/supply.html">CA ISO</a> both have real-time dashboards of energy mix on their respective websites.</p><p>With the 24 x 365 grid and the per day breakout in hand, we can reason about what improvements would happen if specific actions are taken. Consider the following two examples.</p><p><strong>Example 1: Adding more solar generation</strong></p><p>Building a new solar farm would immediately allow afternoon hours during the summer to achieve a higher level of carbon free generation. Using the two visuals we can quickly see where a solar farm would provide benefits during the year as well as a specific day.</p><figure><div><div><p><img src="https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-9.49.17-PM.png" width="2000" height="1097" alt="" srcset="https://www.climaticthoughts.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-05-at-9.49.17-PM.png 600w, https://www.climaticthoughts.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-05-at-9.49.17-PM.png 1000w, https://www.climaticthoughts.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-05-at-9.49.17-PM.png 1600w, https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-9.49.17-PM.png 2282w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-9.49.34-PM.png" width="1772" height="1268" alt="" srcset="https://www.climaticthoughts.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-05-at-9.49.34-PM.png 600w, https://www.climaticthoughts.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-05-at-9.49.34-PM.png 1000w, https://www.climaticthoughts.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-05-at-9.49.34-PM.png 1600w, https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-9.49.34-PM.png 1772w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Visualizations made using 2019 NY ISO data</figcaption></figure><p><strong>Example 2: Building a closed loop pumped hydro system</strong></p><p><a href="https://www.energy.gov/eere/water/pumped-storage-hydropower">Closed loop pumped hydro systems</a> can be thought of as very large water batteries. During the day water is pumped from a lower reservoir to a higher one using renewable or other energy sources. Then in the night water is piped down leveraging &nbsp;gravity to spin a turbine thereby generating power. This system enables providing non-intermittent power in the evenings across the year but especially in the winter months when shorter days make solar infeasible during the late afternoon and early evening.</p><figure><div><div><p><img src="https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-10.08.29-PM.png" width="2000" height="1092" alt="" srcset="https://www.climaticthoughts.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-05-at-10.08.29-PM.png 600w, https://www.climaticthoughts.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-05-at-10.08.29-PM.png 1000w, https://www.climaticthoughts.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-05-at-10.08.29-PM.png 1600w, https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-10.08.29-PM.png 2292w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-10.09.01-PM.png" width="1742" height="1262" alt="" srcset="https://www.climaticthoughts.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-05-at-10.09.01-PM.png 600w, https://www.climaticthoughts.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-05-at-10.09.01-PM.png 1000w, https://www.climaticthoughts.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-05-at-10.09.01-PM.png 1600w, https://www.climaticthoughts.com/content/images/2020/12/Screen-Shot-2020-12-05-at-10.09.01-PM.png 1742w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Visualizations made using 2019 NY ISO data</figcaption></figure><p>Even tactics such as <a href="https://www.energy.gov/eere/solar/articles/solar-plus-storage-101">short duration battery storage</a> and <a href="https://nest.com/energy-solutions/#rush-hour">demand response programs</a> can be visualized with this framework. Batteries can extend the window of operation for solar and wind by storing excess electricity production. A 4-hour capacity of battery storage can enable solar and wind to take on peak demand in the evening hours. Residential demand response programs, where customers are paid to use less energy during certain parts of the day, when mapped onto the 24 x 365 grid would also serve to make certain hours cleaner as fewer <a href="https://en.wikipedia.org/wiki/Peaking_power_plant#:~:text=Peaking%20power%20plants%2C%20also%20known,as%20peak%20demand%2C%20for%20electricity.">peaker plants</a> would be needed to meet consumer demand. The per day breakout would similarly show a lower total quantity demanded and a cleaner mix of energy generation. These two visuals provide an easy way to conceptualize the effects of many different solutions all while keeping focus on the singular goal, 0 emissions at every single moment.</p><p>We collectively need to solve for 8,760 hours each year. Making each individual hour 100% clean will take a combination of technologies. What this visual framework provides is a map to gauge how far we‚Äôve come and what remains. There‚Äôs a satisfaction that comes when checking off an item on a to-do list, we should consider this the same. 8,760 to-dos, some harder than others, but all equally necessary. I hope these visuals are used more broadly across the climate space both in the private and public sector.</p><p>Below I‚Äôve created an <a href="https://public.tableau.com/profile/nitin.iyer#!/vizhome/shared/48H8ZRNTC">interactive version of the 24 x 365 grid</a> and per day demand graphs using data from the NY ISO in 2019. Hover the cursor over the 24 x 365 grid to see the breakout for an individual day.</p><p>Carbon Free and Fossil Fuel generation in the data:</p><ul><li>Carbon Free consists of: Hydro, Nuclear, Wind, and Other Renewables</li><li>Fossil generation consists of: Dual Fuel, Natural Gas, and Other Fossil Fuels</li></ul><!--kg-card-begin: html-->                <!--kg-card-end: html--><h3 id="low-hanging-hours-first">Low hanging hours first</h3><p>For any organization to have the most impact, the next step after constructing a snapshot of their 24 x 365 grid is to identify the low-hanging hours currently available. Low hanging hours are those hours of the day or year which are the easiest and cheapest to convert from fossil energy to clean energy. Depending on the geographic area that could be afternoons in July when the sun is always out and PV panels are readily available, or evenings in October when the wind blows continuously and turbines are relatively the cheapest. Not all hours of the day will be as easy or cheap to convert but emissions averted at 9 AM are the same as emissions averted at 12 PM. And in mitigating climate change, reducing emissions is of utmost importance.</p><p>On that last point, the advantages of tackling the low-hanging hours first are two-fold. One is that tackling those hours first preserves more of the <a href="https://www.carbonbrief.org/analysis-how-much-carbon-budget-is-left-to-limit-global-warming-to-1-5c#:~:text=The%20models%2C%20labelled%20%E2%80%9CIPCC%20AR5,until%20the%20budget%20is%20exhausted.">‚Äúbudget‚Äù of allowable emissions</a> for the harder to clean hours of the day. The nature of climate mitigation is that emissions averted sooner are much more valuable than emissions averted later. A <a href="https://ourworldindata.org/grapher/co2-mitigation-2c">great illustration</a> of this concept comes from Robbie Andrew who shows how far emissions must fall in each subsequent year depending on when we hit peak emissions in order to stay under 2¬∞C of warming. Assuming priority can only be given to one initiative at a time, the low hanging hours are the place to begin. This isn‚Äôt exactly like a to-do list where the common advice is tackle the hardest task of your day first. In that sense it's the complete opposite, clean the easiest parts of the day first and leave the difficult parts of the day for later.</p><p>The second advantage builds off of the first. As the low-hanging hours run out, demand for fossil energy will only exist for those harder to convert hours of the day. As a result, costs for fossil generation will increase as the fixed costs of those plants become spread across reduced hours of operation. Higher costs for fossil generation will make more expensive clean generation technologies such as <a href="https://www.eia.gov/energyexplained/geothermal/geothermal-power-plants.php#:~:text=Geothermal%20power%20plants%20use%20hydrothermal,or%20from%20hot%20water%20wells.&amp;text=The%20hot%20water%20or%20steam%20powers%20a%20turbine%20that%20generates%20electricity.">geothermal</a> more competitive. Without this demand reduction based cost increase or a price on carbon, these farther out zero-carbon baseload technologies may take too long to become cost competitive. This advantage could be hobbled by factors such as contract terms, political lobbying, or subsidies to fossil power generators. All of which may limit how fast fossil generation costs go up. But at some point the market overrides all barriers. Cheap energy is cheap energy.</p><p>Armed with the 24 x 365 framework and a strategy of addressing low hanging hours first, any organization is properly equipped to start the daunting task of getting to 100% clean energy. With climate change every solution is needed, but at the same time we cannot forget the power of prioritization. Tackling low hanging hours first provides some sense of direction in a flood of possible actions.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://climaticthoughts.com/clean-power-generation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25367014</guid>
            <pubDate>Wed, 09 Dec 2020 23:30:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make Your Monolith Last]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25366680">thread link</a>) | @atomkirk
<br/>
December 9, 2020 | https://atomkirk.com/2020-12-09-make-monolith-last/ | <a href="https://web.archive.org/web/*/https://atomkirk.com/2020-12-09-make-monolith-last/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>December 09, 2020</p></header><section><p>In Martin Fowler‚Äôs essay ‚ÄúMicroservice Premium‚Äù he makes the argument that as
the complexity of a system increases, the productivity of a monolith architecture
starts out as very productive, but decreases in productivity faster than a service oriented
architecture (SOA), until a SOA is more productive than the monolith.</p>
<p>Here‚Äôs a chart he provides to illustrate:</p>
<p><span>
      <a href="https://atomkirk.com/static/32b0cc0112aebd409996222f4f95ed1a/98b29/productivity.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Productivity" title="Productivity" src="https://atomkirk.com/static/32b0cc0112aebd409996222f4f95ed1a/fcda8/productivity.png" srcset="https://atomkirk.com/static/32b0cc0112aebd409996222f4f95ed1a/12f09/productivity.png 148w,
https://atomkirk.com/static/32b0cc0112aebd409996222f4f95ed1a/e4a3f/productivity.png 295w,
https://atomkirk.com/static/32b0cc0112aebd409996222f4f95ed1a/fcda8/productivity.png 590w,
https://atomkirk.com/static/32b0cc0112aebd409996222f4f95ed1a/efc66/productivity.png 885w,
https://atomkirk.com/static/32b0cc0112aebd409996222f4f95ed1a/98b29/productivity.png 937w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>But, come on, when you add all the drawbacks of an SOA, the costs are enormous and they get worse.
Data syncing, backfilling, inconsistencies, progogation of bad data. Books upon books on how to
deal with the problems specific to using an SOA. It takes a truly terribly designed monolith
and a fantastically designed SOA for those lines to cross. The chart should really look like this:</p>
<p><span>
      <a href="https://atomkirk.com/static/e9a3f3607ccbbaa0587090fbcce4a32a/98b29/reality.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Reality" title="Reality" src="https://atomkirk.com/static/e9a3f3607ccbbaa0587090fbcce4a32a/fcda8/reality.png" srcset="https://atomkirk.com/static/e9a3f3607ccbbaa0587090fbcce4a32a/12f09/reality.png 148w,
https://atomkirk.com/static/e9a3f3607ccbbaa0587090fbcce4a32a/e4a3f/reality.png 295w,
https://atomkirk.com/static/e9a3f3607ccbbaa0587090fbcce4a32a/fcda8/reality.png 590w,
https://atomkirk.com/static/e9a3f3607ccbbaa0587090fbcce4a32a/efc66/reality.png 885w,
https://atomkirk.com/static/e9a3f3607ccbbaa0587090fbcce4a32a/98b29/reality.png 937w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>As a project grows, most languages (Java, C++, Elixir)<sup id="fnref-1"><a href="#fn-1">1</a></sup> take longer and longer to compile. Death
by a thousand slow-ish tests build up. CI pipelines take 20+ minutes. With 50 engineers trying
to get their code into master, it takes days to get merged. The vast majority of that
time spent waiting for CI (compiling, tests, linting). You have two options: make all of that
faster, or harken back to the good old days when your project was smaller by splitting it up.</p>
<p>The problem is, in the good old days, all your data was still in one database. That‚Äôs a terrible
idea in a SOA. Now you‚Äôre sacrificing all kinds of simplicity and safety to make your project
compile and test faster in smaller pieces. Invalid data being the root of all evil,
giving up foreign key constraints is selling your soul.</p>
<p>Or, you could make things faster:</p>
<p><span>
      <a href="https://atomkirk.com/static/461eeb0ba4608076c3cc42f1332ade3f/98b29/ideal.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Ideal" title="Ideal" src="https://atomkirk.com/static/461eeb0ba4608076c3cc42f1332ade3f/fcda8/ideal.png" srcset="https://atomkirk.com/static/461eeb0ba4608076c3cc42f1332ade3f/12f09/ideal.png 148w,
https://atomkirk.com/static/461eeb0ba4608076c3cc42f1332ade3f/e4a3f/ideal.png 295w,
https://atomkirk.com/static/461eeb0ba4608076c3cc42f1332ade3f/fcda8/ideal.png 590w,
https://atomkirk.com/static/461eeb0ba4608076c3cc42f1332ade3f/efc66/ideal.png 885w,
https://atomkirk.com/static/461eeb0ba4608076c3cc42f1332ade3f/98b29/ideal.png 937w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Seeing as making all of this fast once your project is already huge is very hard to do, I think
there are a few actionable points of advice I would like to leave with people starting new projects:</p>
<ul>
<li>Pick a language and ecosystem that prioritizes fast compiles and a fast feedback loop dev experience. i.e. Go.</li>
<li>Keep your tests fast from day one.</li>
<li>Do not preoptimize for microservices. Don‚Äôt over-engineer your code to work like an SOA. If you follow the first two points of advice, you may never have to go there at all. Boundaries are great, so theres a lot of gray area here, but I think its important to keep things <a href="https://atomkirk.com/2020-12-04-simple-as-possible-as-long-as-possible/">as simple as possible as long as possible</a>.</li>
</ul>
</section><hr></article></div>]]>
            </description>
            <link>https://atomkirk.com/2020-12-09-make-monolith-last/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25366680</guid>
            <pubDate>Wed, 09 Dec 2020 23:07:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sales tax creates more unnecessary pain than value added tax]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25366136">thread link</a>) | @dyno-might
<br/>
December 9, 2020 | https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            
            <p><strong>Dec 9, 2020</strong></p>
            
            <p>It turns out that sales tax has a huge, gigantic, terrible flaw: It punishes specialized businesses. A value added tax (VAT) has no such problems.</p>

<p>The US has sales tax. Most of the planet has VAT.</p>

<p><img src="https://dyno-might.github.io/img/vat/VAT_map_updated.png" alt="VAT map"></p>

<p>Maybe it‚Äôs not the most important issue in the world, but it‚Äôs just so <em>clear</em>. Sales tax is dumb and VAT is better.</p>



<p>Many people apparently believe that in the US today, sales tax is only paid by final consumers. <strong><a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">THIS IS FALSE</a></strong>. It varies hugely by state, but the current situation is a hybrid between a ‚Äúpure final retail consumer only‚Äù sales tax and what the toy model below describes. You can debate if it‚Äôs ‚Äúsales tax‚Äù or ‚Äúgross receipts tax‚Äù or whatever, but it‚Äôs a fact that <em>businesses pay tax on business inputs</em> all the time. You can find proof of this <a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">here</a> or <a href="https://www.ncsl.org/documents/standcomm/sccomfc/Business-Inputs-Study.pdf">here</a> or <a href="https://www.jstor.org/stable/41788786">here</a> or <a href="https://en.wikipedia.org/wiki/Gross_receipts_tax#United_States">here</a>.</p>

<p>I emphasize that the explanation below is a toy illustration. The US tax code isn‚Äôt <i>nearly</i> this bad. But the flaw described <i>does</i> exist. I beg you: <strong><a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">IF YOU THINK THE US DOESN‚ÄôT HAVE TAXES WITH THE FLAW DESCRIBED BELOW PLEASE READ THIS LINK. SO FAR I AM NOT AWARE OF ANYONE WHO HAS READ THIS YET CONTINUES TO BELIEVE THAT.</a></strong></p>

<p>OK, let‚Äôs continue.</p>



<p>Say you decide to get into the decorative <a href="https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/(https://dyno-might.github.io/2020/09/11/comparative-advantage-and-when-to-blow-up-your-island/)">coconut</a> manufacturing business.</p>

<p>You‚Äôre good at painting coconuts. You find a friend who is good at picking them, and another who‚Äôs good at making coconut paint. You find a third friend who‚Äôs a genius with applying finishing lacquer and a fourth who runs a store.</p>

<p>You buy coconuts and paint, apply the paint, then sell to the finisher. He applies lacquer and sells to a retailer.</p>

<p><img src="https://dyno-might.github.io/img/vat/supply_chain.png" alt="supply chain"></p>

<p>After negotiating prices, you settle on $1 for a raw coconut, $1 for a coconut‚Äôs worth of paint, $3 for a painted coconut, $4 for a finished coconut, and $5 retail. This works out to everyone making $1 of profit.</p>

<p><img src="https://dyno-might.github.io/img/vat/market.png" alt="market"></p>

<p>Here‚Äôs a table showing the accounts:</p>

<table>
  <thead>
    <tr>
      <th>Item</th>
      <th>Cost of inputs</th>
      <th>Profit</th>
      <th>Price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raw coconuts</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
    </tr>
    <tr>
      <td>Paint</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
    </tr>
    <tr>
      <td>Painted coconut</td>
      <td>$2 (raw coconut+paint)</td>
      <td>$1</td>
      <td>$3</td>
    </tr>
    <tr>
      <td>Finished coconut</td>
      <td>$3 (painted coconut)</td>
      <td>$1</td>
      <td>$4</td>
    </tr>
    <tr>
      <td>Retail coconut</td>
      <td>$4 (finished coconut)</td>
      <td>$1</td>
      <td>$5</td>
    </tr>
  </tbody>
</table>



<p>For a while, everything runs beautifully. Every day you wake eager to help capture more beauty in coconut form ‚Äî and then the government announces a 20% sales tax. Whenever you sell something, you need to pay 20% of the sale price to the government.</p>

<p>You talk it over. Everyone feels they still deserve to make the same $1 profit as before. Since you now pay $1.20 for a raw coconut and $1.20 for paint, you need to mark up to $3.40 before tax, and $4.08 after.</p>

<p>After everyone marks up their prices in this way, here are the results:</p>

<p><img src="https://dyno-might.github.io/img/vat/sales_tax.png" alt="sales tax"></p>

<table>
  <thead>
    <tr>
      <th>Item</th>
      <th>Cost of inputs</th>
      <th>Profit</th>
      <th>Price</th>
      <th>Price after tax</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raw coconut</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Paint</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Painted coconut</td>
      <td>$2.4</td>
      <td>$1</td>
      <td>$3.40</td>
      <td>$4.08</td>
    </tr>
    <tr>
      <td>Finished coconut</td>
      <td>$4.08</td>
      <td>$1</td>
      <td>$5.08</td>
      <td>$6.10</td>
    </tr>
    <tr>
      <td>Retail coconut</td>
      <td>$6.10</td>
      <td>$1</td>
      <td>$7.10</td>
      <td>$8.52</td>
    </tr>
  </tbody>
</table>

<p>Your customers aren‚Äôt thrilled about the increase in price, but what are they going to do ‚Äî live <em>without</em> painted coconuts? So they pay the higher price, the government gets its tax, and life continues.</p>



<p>A few months later, your unscrupulous  cousin hears about your business. He‚Äôs the jealous type and decides to try stealing your customers. He opens a store and finds four friends to help make coconuts. Unlike you, however, he hires everyone as <em>employees</em>. He sells the coconuts for $6 ($5 plus tax) and gives everyone $1 per coconut in wages.</p>

<p><img src="https://dyno-might.github.io/img/vat/integrated2.png" alt="integrated"></p>

<p>Your cousin and friends don‚Äôt appreciate the subtle art of coconut decoration. Everyone agrees yours are better but they start to complain: Why are you charging $8.52 when a slightly worse product is available for only $6? Slowly, your loyal customers drift away and you go out of business.</p>

<p>How could this happen? Your team was asking for the same profit while doing a better job! Yet everyone is left with your cousin‚Äôs knock-off coconuts.</p>



<p>Suppose the government had instead announced a 20% VAT. With a VAT, whenever you sell something, you only pay tax on the sale price <em>minus the price of the stuff you bought to make it</em>.</p>

<p>As before, you‚Äôll need to pay $1.20 for raw coconuts and $1.20 paint. You charge $3.40 for painted coconuts, now you‚Äôre only taxed on the profit of $3.40-$2.40=$1.00. The price with tax is now $3.60.</p>

<p>Here are the final prices as they go through through the system. Everyone is making a profit of $1, so everyone pays a tax of $0.20.</p>

<p><img src="https://dyno-might.github.io/img/vat/vat.png" alt="vat"></p>

<table>
  <thead>
    <tr>
      <th>Item</th>
      <th>Cost of inputs</th>
      <th>Profit</th>
      <th>Price</th>
      <th>Price after tax</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raw coconut</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Paint</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Painted coconut</td>
      <td>$2.4</td>
      <td>$1</td>
      <td>$3.40</td>
      <td>$3.60</td>
    </tr>
    <tr>
      <td>Finished coconut</td>
      <td>$3.60</td>
      <td>$1</td>
      <td>$4.60</td>
      <td>$4.80</td>
    </tr>
    <tr>
      <td>Retail coconut</td>
      <td>$4.80</td>
      <td>$1</td>
      <td>$5.80</td>
      <td>$6.00</td>
    </tr>
  </tbody>
</table>

<p>The final price is $6.00. Since your coconuts are better, your cousin won‚Äôt be able to drive you out of business with his low-grade stuff.</p>



<p>What happened? Your cousin created a <em>vertically integrated</em> business. A sales tax is collected every time someone buys something. If you just do it yourself, no tax is collected.</p>

<p>Are vertically integrated businesses bad? Not necessarily.</p>

<p>However, take your chain of independent independent artisans making and selling coconut products. Imagine someone invents a paint that customers prefer. You almost <em>have</em> to switch, or some other painter will drive you out of business. Contrast this with cousin‚Äôs integrated business making all coconuts. In theory, the inventor could convince your cousin to hire him or license the paint process. If he won‚Äôt be convinced, the only way for that paint to get to customers is if the inventor develops an entire independent coconut manufacturing chain. Vertical integration means there are price signals at fewer points during production, which tends to make it harder for innovations to thrive.</p>

<p>There are times where vertical integration is better. (If everyone is independent, a lot of time is spent on negotiations!) That‚Äôs perfectly fine. What we <em>don‚Äôt</em> want is to artificially encourage vertical integration even when it‚Äôs less efficient, which sales tax does.</p>



<p>Another advantage of the VAT is it tends to be easier to enforce. When I sell something, I need to provide certificates proving I paid VAT on my inputs. This gives everyone an incentive to ensure compliance in the previous layer of the chain. With a sales tax, the government needs to watch every single transaction.</p>

<p>Of course, people know sales tax is distortionary. Many exceptions exist to minimize the worst distortions. For example, a retailer usually won‚Äôt pay sales tax on a manufactured good they intend to a consumer in the same form. Without this exception, we‚Äôd probably have a crazy economy where manufacterers sell directly to consumers. The messy patchwork of exceptions reduces the problems with sales tax but doesn‚Äôt eliminate them.</p>

<p>I think there are two major reasons to oppose replacing sales tax with VAT. The first is a Leninist ‚Äúworse is better‚Äù attitude. If you think <em>all taxes are bad</em> then you‚Äôd want to keep them painful and visible so people will be maximally annoyed by them. The second is that VAT is complicated to administer, particularly when sales tax can be different in each local area. This might be true, but I find it a bit hard to believe. VAT is more self-enforcing and sales taxes are <em>already</em> a nightmare, particularly for anyone selling to different cities/states. If we‚Äôre keeping the sales tax to keep things simple, where‚Äôs the payoff?</p>

<p><img src="https://dyno-might.github.io/img/vat/lenin_text_small.png" alt="lenin"></p>

<h3 id="notes">Notes</h3>

<ul>
  <li>The initial map is based on Wikipedia, but found that many places (<a href="https://taxsummaries.pwc.com/thailand/corporate/other-taxes">Thailand</a>, <a href="https://home.kpmg/us/en/home/insights/2020/05/tnf-saudi-arabia-vat-rate-to-increase-to-15-percent-covid-19.html">Saudi Arabia</a>, <a href="https://en.wikipedia.org/wiki/Taxation_in_Iran#Value_added_tax_(VAT)">Iran</a>, <a href="https://www2.deloitte.com/om/en/pages/tax/articles/oman-to-implement-vat-from-2021.html">Oman</a>, <a href="https://u.ae/en/information-and-services/finance-and-investment/taxation/valueaddedtaxvat">UAE</a>, <a href="https://www.reuters.com/article/us-kuwait-economy-tax-idUSKCN1IG0OW">Kuwait</a>, <a href="https://news.bloombergtax.com/daily-tax-report-international/insight-early-days-for-angola-value-added-tax">Angola</a>, <a href="https://www.avalara.com/vatlive/en/vat-news/liberia-to-introduce-vat-2019.html">Liberia</a>) have recently implemented VAT. I checked that most of the others (<a href="https://taxsummaries.pwc.com/jordan/corporate/other-taxes">Jordan</a>, <a href="https://en.wikipedia.org/wiki/Taxation_in_Greenland">Greenland</a>, <a href="https://www.tradecommissioner.gc.ca/france/market-facts-faits-sur-le-marche/7685.aspx?lang=eng#valuetax">French Guinana</a>, <a href="https://www.nordeatrade.com/en/explore-new-market/cuba/taxes">Cuba</a>, <a href="https://taxsummaries.pwc.com/libya/individual/other-taxes">Libya</a>, Hong Hong) still do not have a VAT.</li>
  <li>To be sure, if you could implement a sales tax that only applied to final consumers, that would be economically equivalent to VAT. Is that how state taxes work in the US? It‚Äôs hard to make simple generalizations because (1) it‚Äôs sometimes hard to say what a ‚Äúfinal consumer‚Äù is (2) there are different laws in each state and (3) the relevant tax is sometimes called a ‚Äúgross receipts‚Äù tax. The important question is: <strong>Does the US have taxes on intermediate products</strong> that ‚Äúcascade‚Äù like described in the above model? The answer to that question is <a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">YES</a>.</li>
</ul>

        </div>

        

        
        
    </div>
</div></div>]]>
            </description>
            <link>https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25366136</guid>
            <pubDate>Wed, 09 Dec 2020 22:24:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is SRE (Site Reliability Engineering?)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25365965">thread link</a>) | @anishdhar
<br/>
December 9, 2020 | https://www.getcortexapp.com/post/what-is-sre-site-reliability-engineering | <a href="https://web.archive.org/web/*/https://www.getcortexapp.com/post/what-is-sre-site-reliability-engineering">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Historically, development teams and operations teams have been at odds.<br></p><p>Development teams wanted to add slick new features to products. Operations teams wanted to make sure these features didn‚Äôt cause dysfunction.<br></p><p>This began to change in 2003 when software engineer Benjamin Treynor invented site reliability engineering (SRE) while working at Google. He made his software engineering team responsible for some ops tasks, creating the concept of SRE and helping to resolve issues between development and operations.</p><h2>How does SRE work?</h2><p>SRE is performed by site reliability engineers, also known as service reliability engineers. These professionals are typically software developers who have gained some operations experience. They can also be IT professionals who have development skills.<br></p><p>SRE teams set service-level agreements (SLAs) for each service in a system. The SLAs define the system‚Äôs required reliability, helping teams figure out which features they can implement.&nbsp;<br></p><p>Within each SLA are service-level indicators (SLIs) and service-level objectives (SLOs).<br></p><p>SLIs are metrics that measure a specific aspect of a service level. Examples of SLIs you might want to monitor could be availability, error rate, or system throughput.<br></p><p>An SLO is simply the target you want to hit for an SLI. For example, you might shoot for a 99.9% availability over the course of a year.<br></p><p>The difference is the downtime level. The downtime level is known as the ‚Äúerror-budget,‚Äù which is the maximum amount of error allowed in the system.&nbsp;<br></p><p>By acknowledging the error is inevitable, you can then plan for the errors, making it easier for the development team to release new features. See, the development team can release whatever features they want‚Äîwhenever they want‚Äîas long as they stay within the error budget. As soon as they step outside of it, they must reign in errors before moving forward with new features.<br></p><p>A vital part of an SRE‚Äôs work is automation. SREs often have to automate away repetitive manual tasks, called ‚Äútoil,‚Äù so they can focus on long-term, value-adding work. <a href="https://www.getcortexapp.com/post/understanding-kubernetes">Kubernetes</a> can be helpful with this.</p><h2>DevOps vs. SRE</h2><p><a href="https://aws.amazon.com/devops/what-is-devops/">DevOps</a> is a philosophy and set of practices that combines software development and IT operations. It consists of <a href="https://www.overops.com/blog/devops-vs-sre-whats-the-difference-between-them-and-which-one-are-you/">five pillars</a>. Google defines these pillars as:<br></p><ul role="list"><li>Reducing organizational silos</li><li>Accepting failure as normal</li><li>Implementing gradual changes</li><li>Leveraging tooling and automation</li><li>Measuring everything<br></li></ul><p>If DevOps is the ‚Äúwhat,‚Äù SRE is the ‚Äúhow.‚Äù It‚Äôs simply an implementation of the DevOps philosophy. In fact, SRE meets all five pillars of DevOps:<br></p><ul role="list"><li><strong>Reducing organizational silos:</strong> SREs share ownership with the developers, and they use the same tools and techniques.</li><li><strong>Accepting failure as normal:</strong> SREs quantify failure using SLIs and SLOs. They assume that errors will happen, but set a maximum allowable amount to balance failure against new releases.</li><li><strong>Implementing gradual changes:</strong> SREs encourage smaller, more iterative deployments of new features in order to reduce the cost of failure.</li><li><strong>Leveraging tooling and automation:</strong> SREs automate away manual tasks, as mentioned above.</li><li><strong>Measuring everything:</strong> SREs use metrics (SLIs) to quantify service levels. Consequently, they can keep errors down.</li></ul><h2>Benefits of SRE</h2><p>Let‚Äôs take a look at a few of the ways SRE can offer some major advantages to your organization.&nbsp;</p><h3>Provides clear metrics</h3><p>Clear metrics allow SRE teams to highlight areas of improvement, such as reducing security vulnerabilities.<br></p><p>SRE teams can also use metrics to calculate impact in other areas, such as revenue. For example, they could look at how much revenue they lose per minute of downtime.</p><h3>Improves code</h3><p>The development and SRE teams share the same talent pool. If the development team writes poor code, more talent is allocated to the SREs to fix these issues‚Äîleaving fewer people available for the development team.<br></p><p>As a result, the development team is incentivized to write better code. When their code works well, they could gain more teammates, bringing them the resources they need to create better features.</p><h3>Frees up time and resources to add value</h3><p>Better code, fewer bugs, and more efficiency creates more time to add value to the product.&nbsp;<br></p><p>The developers can create better and more exciting features that are less likely to cause problems. On the other side, operations can spend more time testing and performing upkeep.<br></p><p>Put these together, and you have a better product for the customer.</p><h2>The bottom line</h2><p>SRE is quickly taking hold as an essential part of many organizations. It can help close the gap between operations and development. Consequently, you can deliver better applications faster‚Äîwithout sacrificing the reliability of those applications.&nbsp;</p><p><br>Cortex can help your SRE team track service quality better so they can find more areas where service can be improved.<a href="https://www.getcortexapp.com/"> Schedule your demo today</a> to learn more about what we can do.</p></div></div>]]>
            </description>
            <link>https://www.getcortexapp.com/post/what-is-sre-site-reliability-engineering</link>
            <guid isPermaLink="false">hacker-news-small-sites-25365965</guid>
            <pubDate>Wed, 09 Dec 2020 22:10:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to give feedback to a developer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25365651">thread link</a>) | @thellimist
<br/>
December 9, 2020 | https://www.usehaystack.io/blog/5-steps-for-giving-developer-feedback | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/blog/5-steps-for-giving-developer-feedback">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="0ea0c8ae-8333-a516-8908-f86a85ef9373"><p>Feedback can be so easy to get wrong...</p><p>It sounds like an easy part of the job but it can be a task filled with dread, anxiety, or worry. <strong>Engineering leaders tend to be overly sympathetic and cautious</strong> when it comes to giving feedback.</p><p>Of course, no body wants to hurt anyone's feelings or upset the team but leaving problems unaddressed can boil up to much larger issues.</p><p>Unfortunately, <strong>it's not uncommon in engineering for feedback to go undelivered</strong>, causing problems to fester and performance to degrade - leaving managers wishing they spoke up sooner.</p><p>In this article <strong>we'll be sharing</strong> <strong>ways you can deliver feedback to your team effectively without being overbearing</strong>, seeming like a micromanager, or taking feedback too far and de-motivating your team.</p><p>‚Äç</p><h2>How NOT to give feedback to engineers</h2><figure id="w-node-cef329f9e82f-35f34600"><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5fd12d7b5075de2a084ec607_poor-feedback-example.png" loading="lazy" alt=""></p></figure><p>Woof. Tough day at the office.</p><p>‚Äç</p><p>Let's break down <strong>what went wrong:</strong></p><ol role="list"><li>Bill <strong>didn't have time to prepare</strong> for receiving feedback</li><li>"Andre isn't going to be happy" <strong>sounds threatening</strong></li><li>The feedback is vague and <strong>doesn't include specific examples</strong></li></ol><p>‚Äç</p><p>Lastly, the last sentence <strong>doesn't leave room to discuss</strong> or problem solve - leaving Bill feeling pretty defensive.</p><p>‚Äç</p><p>He probably doesn't feel great after that interaction.</p><p>‚Äç</p><h2>How to give feedback to engineers</h2><p>Inspired by <a href="http://www.martykaplanphd.com/blog/preparing-for-giving-and-receiving-feedback-a-guide-to-doing-it?utm_swu=9766" target="_blank">this classic post</a>, we use this framework at Haystack:</p><h3><strong>1)&nbsp;Seek permission</strong></h3><div><p><strong>‚Äç</strong>Before giving feedback, make sure the person is ready to receive it. Most of the time, this won't be an issue. But if they are having a bad day, they can delay. This helps both of you: they can take the time to prepare, and you can give feedback when they will be the most receptive.</p><p><strong>"Hey Bill, is now a good time to share some feedback with you?"</strong><br>‚Äç</p></div><h3><strong>2)&nbsp;Describe observable behavior with data</strong></h3><div><p><strong>‚Äç</strong>While it's fine to identify observable behavior batters, make sure to give concrete examples. Telling someone they "often" or "always" do something is vague, sounds an accusation, and puts them on the defensive. If you give examples, it's easier to discuss solutions.</p><p><strong>"I've noticed that the shared component refactor may miss our original estimation - but during standups this week everything sounded on track."</strong><br>‚Äç</p></div><h3><strong>3)&nbsp;Describe the impact</strong></h3><div><p><strong>‚Äç</strong>Be very specific when you describe the impact. This is important. Did it affect anyone on the team? Did it cause a larger issue or sour a client relationship? If you predict issues down the line, then you can note that impact.</p><p><strong>"This didn't give Product much time to coordinate with marketing. I'm concerned that if this happens again, we could hold back company wide growth goals due to this miscommunication"</strong><br>‚Äç</p></div><h3><strong>4)&nbsp;Own your feelings </strong></h3><p><strong>‚Äç</strong>Share how this made you feel. This shows that you're invested too. Make sure to make this its own step so it doesn't get confused with the previous steps.</p><p><br><strong>"I felt frustrated because I couldn't understand why these changes came at the last minute. It made me wonder if my expectations weren't clear, or whether I had misunderstood our progress."</strong></p><p>‚Äç</p><h3><strong>5)&nbsp;Come with questions, not conclusions</strong></h3><p><strong>‚Äç</strong>Be careful not to make too many assumptions. Present questions and be genuinely curious about the situation. Often you may find yoursef as a contributing factor to the behavior. Ask questions and understand the root cause.</p><p>‚Äç</p><p><strong>"I'm curious: what do you think caused the last minute changes? I wonder if there's something that I'm doing which is contributing to this. How can we prevent this in the future?"</strong></p><p>‚Äç</p><p>At <a href="https://usehaystack.io/">Haystack</a> <strong>this framework helps us get better, faster</strong>. We're constantly looking for ways to improve. You shouldn't have to worry about giving or receiving feedback on your team. It should be a safe place to air issues, brainstorm solutions, and get everyone working better together.</p><p>‚Äç</p><p>Did we miss something? Email us at <a href="mailto:hello@usehaystack.io">hello@usehaystack.io</a>!</p><p>‚Äç</p></div><div data-w-id="edf9fcce-8bb0-5aee-9560-d439cd0fdf41"><div><div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb363122d5a8_newsletter-image-saasy-template.svg" alt=""></p><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/blog/5-steps-for-giving-developer-feedback</link>
            <guid isPermaLink="false">hacker-news-small-sites-25365651</guid>
            <pubDate>Wed, 09 Dec 2020 21:45:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't call it tech debt]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25365570">thread link</a>) | @acconrad
<br/>
December 9, 2020 | https://adamconrad.dev/blog/dont-call-it-tech-debt/ | <a href="https://web.archive.org/web/*/https://adamconrad.dev/blog/dont-call-it-tech-debt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

        <section>

            <p>I think we, as a profession, shot ourselves in the foot when we coined the term <em>tech debt</em>. This <a href="https://daverupert.com/2020/11/technical-debt-as-a-lack-of-understanding/">recent post</a> (though my browser‚Äôs search bar found no less than 3 recent articles I read on the subject in Hacker News) got me thinking that the term tech debt is an exercise in bad marketing.</p>

<p>Debt is evil. It‚Äôs the stuff that can <a href="https://money.com/student-loan-forgiveness-death-discharge/">live on</a> longer than you do. There‚Äôs never been an instance where calling something ‚Äúdebt‚Äù elicited a positive response. So why do we tell our Product Managers we have to <em>tackle</em> tech debt?</p>

<p>Is it to create urgency? I hope not. Everyone believes their priorities are the most important priorities. So an engineer‚Äôs tech debt will never seem more important than a PM‚Äôs product backlog.</p>

<p>Is it to create gravity around the seriousness of the work involved? Then why is it that PMs always bucket ‚Äú20% time‚Äù for making room for tech debt that is never fully paid off?</p>

<p>I loved this analogy I saw on Hacker News about this concept:</p>

<blockquote>
  <p>If you run a commercial kitchen and you only ever cook food, because selling cooked food is your business ‚Äì if you never clean the dishes, never scrape the grill, never organize the freezer ‚Äì the health inspector will shut your shit down pretty quickly.</p>

  <p>Software, on the other hand, doesn‚Äôt have health inspectors. It has kitchen staff who become more alarmed over time at the state of the kitchen they‚Äôre working in every day, and if nothing is done about it, there will come a point where the kitchen starts failing to produce edible meals.</p>

  <p>Generally, you can either convince decision makers that cleaning the kitchen is more profitable in the long run or you can dust off your resume and get out before it burns down.</p>
</blockquote>

<p>On the flip side, if you ever have the luxury of getting ahead of your technical debt then you can contribute things called <a href="https://www.stillbreathing.co.uk/2016/10/13/technical-credit">technical credits</a>. As you can imagine, technical credits are the opposite of tech debt: things that <em>pay dividends</em> to your code rather than incur a cost and drag it down. <a href="https://gomakethings.com/progressive-enhancement-graceful-degradation-and-asynchronously-loading-css/">Progressive enhancement</a> is touted as an example of technical credit.</p>

<p>Marrying these two concepts, I actually think a way around the horrible marketing of tech debt can be resolved with Agile terminology that is already familiar to our product-positive counterparts: <strong>engineering-driving work.</strong></p>

<h2 id="engineering-driven-work-over-tech-debt">Engineering-driven work over tech debt</h2>

<p>At the end of the day, whether they be debt or credit, the work engineers want to accomplish to make their code better is something personal to them and them alone. Similarly, your product team has their own vision of what your code can become for your customers. So if we segment on the <em>owner</em> instead of the <em>outcome</em> we remove the negative connotations of the work involved.</p>

<p>On my teams, we make this distinction painfully simple in Jira:</p>

<ol>
  <li><strong>Was the work engineering-driven?</strong> Create a task.</li>
  <li><strong>Was the work product-driven?</strong> Create a story; use sub-tasks to create the work the engineers will do to complete that story.</li>
</ol>

<p>Everything lives on the same playing field and is up for grabs to assign priority. So rather than bucket 20% time for debt, if all engineering-driven tasks (whether they be credits, debts, or something else) are the most important work to be done this week, they take up 100% of the sprint. Similarly, if product‚Äôs work is the most important, it can dominate or completely own a sprint.</p>

<p>The important thing is that <strong>the owner of the ticket sells why their work should be as important as it is</strong>. If you can‚Äôt sell why a critical security upgrade is vital to the health of your application then you need to learn how to sell and influence others. But then again, you might think that switching from Formik to React Hook Forms would be awesome but if it‚Äôs based on personal bias and no tangible value creation for developer productivity you‚Äôre dead on arrival.</p>

<p>So I encourage all of my engineers to read sales books. Learn how to sell and influence others. Convincing someone that what you want to do matters is a much better message than starting things off on the wrong foot by calling your work debt that needs to be repaid. Debt makes people wince. Creating value makes people smile. Paying down tech debt adds value so lead with that and focus on why your work is important instead of giving it the Scarlet Letter from the onset.</p>


            <hr>

            

            <!-- Begin Substack Signup Form -->
            <div id="mc_embed_signup">
                <h4>Get the FREE UI crash course</h4>
                <p>
                    Sign up for our newsletter and receive a free UI crash course to help you build beautiful applications without needing a design background. Just enter your email below and you'll get a download link instantly.
                </p>
                
            </div>
            <!--End Substack Signup Form-->

        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://adamconrad.dev/blog/dont-call-it-tech-debt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25365570</guid>
            <pubDate>Wed, 09 Dec 2020 21:41:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Course of Pure Mathematics (1921)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25365318">thread link</a>) | @dvfjsdhgfv
<br/>
December 9, 2020 | https://avidemia.com/pure-mathematics/ | <a href="https://web.archive.org/web/*/https://avidemia.com/pure-mathematics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrap">

			
			
<!-- #site-header -->


			
			<main id="main" role="main">

				

<!-- .page-header -->


	
	<div id="content-wrap">

		
		<div id="primary">

			
			<div id="content">

				
				
<article>

	
<div itemprop="text">
		<div class="page" title="Page 5">
<div>
<div>
<p><a href="https://avidemia.com/pure-mathematics/attachment/puremathematics-2/" rel="attachment wp-att-7057"><img loading="lazy" src="https://avidemia.com/wp-content/uploads/PureMathematics-1.png" alt="" width="1200" height="675" srcset="https://avidemia.com/wp-content/uploads/PureMathematics-1.png 1200w, https://avidemia.com/wp-content/uploads/PureMathematics-1-1024x576.png 1024w, https://avidemia.com/wp-content/uploads/PureMathematics-1-100x56.png 100w" sizes="(max-width: 1200px) 100vw, 1200px"></a></p>

<p>by</p>
<h2>G. H. Hardy, M.A., F.R.S.</h2>
<p>FELLOW OF NEW COLLEGE <br>
SAVILIAN PROFESSOR OF GEOMETRY IN THE UNIVERSITY OF OXFORD<br>
LATE FELLOW OF TRINITY COLLEGE, CAMBRIDGE</p>
</div>

<p>Third Edition</p>
</div>
</div>
<p><span>Cambridge at the University Press</span></p>
<p><span>1921</span></p>


<h3 id="id5fd418e2f23f6" tabindex="0" title="Read the preface ">Read the preface </h3><div id="target-id5fd418e2f23f6">
<p><span><strong>Preface to the third edition</strong></span></p>
<div class="page" title="Page 7">
<div>
<div>
<p>No extensive changes have been made in this edition. The most important are in ¬ß¬ß 80‚Äì82, which I have rewritten in accordance with suggestions made by Mr S. Pollard.</p>
<p>The earlier editions contained no satisfactory account of the genesis of the circular functions. I have made some attempt to meet this objection in ¬ß 158 and Appendix III. Appendix IV is also an addition.</p>
<p>It is curious to note how the character of the criticisms I have had to meet has changed. I was too meticulous and pedantic for my pupils of fifteen years ago: I am altogether too popular for the Trinity scholar of to-day. I need hardly say that I find such criticisms very gratifying, as the best evidence that the book has to some extent fulfilled the purpose with which it was written.</p>
<p>G. H. H.</p>
<p><em>August</em> 1921</p>
</div>
<div class="page" title="Page 7">
<div>
<div>
<p><span><strong>Extract from the preface to the second edition</strong></span></p>
<p>The principal changes made in this edition are as follows. I have inserted in Chapter I a sketch of Dedekind‚Äôs theory of real numbers, and a proof of Weierstrass‚Äôs theorem concerning points of condensation; in Chapter IV an account of ‚Äòlimits of indetermination‚Äô and the ‚Äògeneral principle of convergence‚Äô; in Chapter V a proof of the ‚ÄòHeine-Borel Theorem‚Äô, Heine‚Äôs theorem concerning uniform continuity, and the fundamental theorem concerning implicit functions; in Chapter VI some additional matter concerning the integration of algebraical functions; and in Chapter VII a section on differentials. I have also rewritten in a more general form the sections which deal with the definition of the definite integral. In order to find space for these insertions I have deleted a good deal of the analytical geometry and formal trigonometry contained in Chapters II and III of the first edition. These changes have naturally involved a large number of minor alterations.</p>
<div class="page" title="Page 8">
<div>
<div>
<p>G. H. H.</p>
<p><em>October</em> 1914</p>
<p><span><strong>Extract from the preface to the first edition</strong></span></p>
<p>This book has been designed primarily for the use of first year students at the Universities whose abilities reach or approach something like what is usually described as ‚Äòscholarship standard‚Äô. I hope that it may be useful to other classes of readers, but it is this class whose wants I have considered first. It is in any case a book for mathematicians: I have nowhere made any attempt to meet the needs of students of engineering or indeed any class of students whose interests are not primarily mathematical.</p>
<p>I regard the book as being really elementary. There are plenty of hard examples (mainly at the ends of the chapters): to these I have added, wherever space permitted, an outline of the solution. But I have done my best to avoid the inclusion of anything that involves really difficult ideas. For instance, I make no use of the `principle of convergence‚Äô: uniform convergence, double series, infinite products, are never alluded to: and I prove no general theorems whatever concerning the inversion of limit-operations‚ÄîI never even define $\dfrac{\partial^{2} f}{\partial x\, \partial y}$ and $\dfrac{\partial^{2} f}{\partial y\, \partial x}$. In the last two chapters I have occasion once or twice to integrate a power-series, but I have confined myself to the very simplest cases and given a special discussion in each instance. Anyone who has read this book will be in a position to read with profit Dr Bromwich‚Äôs <em>Infinite Series</em>, where a full and adequate discussion of all these<br>
points will be found.</p>
<p><em>September </em>1908</p>
</div>
</div>


</div>
</div>
</div>
</div>
</div>
</div>
</div>
<h2>CONTENTS</h2>
<p><strong id="ch1">CHAPTER I</strong></p>
<p><strong>REAL VARIABLES</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/rational-numbers/">1-2. Rational numbers</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/irrational-numbers/">3-7. Irrational numbers</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/real-numbers/"> 8. Real numbers</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/relations-of-magnitude-between-real-numbers/">9. Relations of magnitude between real numbers</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/algebraical-operations-with-real-numbers/">10-11. Algebraical operations with real numbers</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-number-sqrt2/">12. The number $\sqrt{2}$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/quadratic-surds/">13-14. Quadratic surds</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-continuum/">15. The continuum</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-continuous-real-variable/">16. The continuous real variable</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/sections-of-the-real-numbers/">17. Sections of the real numbers. Dedekind‚Äôs Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/points-of-accumulation/">18. Points of condensation</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/weierstrass-theorem/">19. Weierstrass‚Äôs Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-i/"><span>Miscellaneous Examples</span></a></span></p>
<p><strong id="ch2">CHAPTER II</strong></p>
<p><strong>FUNCTIONS OF REAL VARIABLES</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-idea-of-a-function/">20. The idea of a function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-graphical-representation-of-functions/">21. The graphical representation of functions. Coordinates</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/polar-coordinates/"> 22. Polar coordinates</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/polynomials/">23. Polynomials</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/rational-functions/">24-25. Rational functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/algebraical-functions/">26-27. Algebraical functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/transcendental-functions/">28-29. Transcendental functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/graphical-solution-of-equations/">30. Graphical solution of equations</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/functions-of-two-variables-and-their-graphical-representation/">31. Functions of two variables and their graphical representation</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/curves-in-a-plane/">32. Curves in a plane</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/loci-in-space/">33. Loci in space</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-ii/"><span>Miscellaneous Examples</span></a></span></p>
<p><strong id="ch3">Chapter III</strong></p>
<p><strong>FUNCTIONS OF REAL VARIABLES</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/displacements/">34-38. Displacements</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/complex-numbers/">39-42. Complex numbers</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-quadratic-equation-with-real-coefficients/">43. The quadratic equation with real coefficients</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/argands-diagram/">44. Argand‚Äôs diagram</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/de-moivres-theorem/">45. De Moivre‚Äôs Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/rational-functions-of-a-complex-variable/">46. Rational functions of a complex variable</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/roots-of-complex-numbers/">47-49. Roots of complex numbers</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-iii/"><span>Miscellaneous Examples</span></a></span></p>
<p><strong id="ch4">Chapter IV</strong></p>
<p><strong>LIMITS OF FUNCTIONS OF A POSITIVE INTEGRAL VARIABLE</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/functions-of-a-positive-integral-variable/">50. Functions of a positive integral variable</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/interpolation/">51. Interpolation</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/finite-and-infinite-classes/">52. Finite and infinite classes</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/properties-possessed-by-a-function-of-n-for-large-values-of-n/">53-57. Properties possessed by a function of n for large values of n</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/definition-of-a-limit-and-other-definitions/">58-61. Definition of a limit and other definitions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/oscillating-functions/">62. Oscillating functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/general-theorems-concerning-limits/">63-68. General theorems concerning limits</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/steadily-increasing-or-decreasing-functions/">69-70. Steadily increasing or decreasing functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/alternative-proof-of-weierstrasss-theorem/">71. Alternative proof of Weierstrass‚Äôs Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-limit-of-x-power-n/">72. The limit of $x^n$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-limit-of-1-plus-1-n-power-n/">73. The limit of $(1 + \frac{1}{n})^n$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/some-algebraical-lemmas/">74. Some algebraical lemmas</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-limit-of-n-sqrt-nx-1/">75. The limit of $(n(\sqrt[n]{x}-1)$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/infinite-series/">76-77. Infinite series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-infinite-geometrical-series/">78. The infinite geometrical series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-representation-of-functions-of-a-continuous-real-variable-by-means-of-limits/">79. The representation of functions of a continuous real variable by means of limits</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-bounds-of-a-bounded-aggregate/">80. The bounds of a bounded aggregate</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-bounds-of-a-bounded-function/">81. The bounds of a bounded function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-limits-of-indetermination-of-a-bounded-function/">82. The limits of indetermination of a bounded function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-general-principle-of-convergence/">83-84. The general principle of convergence</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/limits-of-complex-functions-and-series-of-complex-terms/">85-86. Limits of complex functions and series of complex terms</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/applications-to-z-power-n-and-the-geometrical-series/">87-88. Applications to $z^n$ and the geometrical series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-iv/"><span>Miscellaneous Examples</span></a></span></p>
<p><strong id="ch5">Chapter V</strong></p>
<p><strong>LIMITS OF FUNCTIONS OF A CONTINUOUS VARIABLE. CONTINUOUS AND DISCONTINUOUS FUNCTIONS</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/limits-as-x-to-inf-or-x-to-%e2%88%92inf/">89-92. Limits as $x \to \infty$ or $x \to ‚àí\infty$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/limits-as-x-to-a/">93-97. Limits as $x \to a$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/continuous-functions-of-a-real-variable/">98-99. Continuous functions of a real variable</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/properties-of-continuous-functions-bounded-functions-the-oscillation-of-a-function-in-an-interval/">100-104. Properties of continuous functions. Bounded functions. The oscillation of a function in an interval</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/sets-of-intervals-on-a-line-the-heine-borel-theorem/">105-106. Sets of intervals on a line. The Heine-Borel Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/continuous-functions-of-several-variables/">107. Continuous functions of several variables </a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/implicit-and-inverse-functions/">108-109. Implicit and inverse functions</a></span></p>
<p><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-v/"><span>Miscellaneous Examples</span></a></p>
<p><strong id="ch6">Chapter VI</strong></p>
<p><strong>DERIVATIVES AND INTEGRALS</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/derivatives/">110‚Äì112. Derivatives</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/general-rules-for-differentiation/">113. General rules for differentiation</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/derivatives-of-complex-functions/">114. Derivatives of complex functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-notation-of-the-differential-calculus/">115. The notation of the differential calculus</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/differentiation-of-polynomials/">116. Differentiation of polynomials</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/differentiation-of-rational-functions/">117. Differentiation of rational functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/differentiation-of-algebraical-functions/">118. Differentiation of algebraical functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/differentiation-of-transcendental-functions/">119. Differentiation of transcendental functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/repeated-differentiation/">120. Repeated differentiation</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/general-theorems-concerning-derivatives-rolles-theorem/">121. General theorems concerning derivatives. Rolle‚Äôs Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/maxima-and-minima/">122‚Äì124. Maxima and minima</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-mean-value-theorem/">125‚Äì126. The Mean Value Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/integration-the-logarithmic-function/">127‚Äì128. Integration. The logarithmic function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/integration-of-polynomials/">129. Integration of polynomials</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/integration-of-rational-functions/">130‚Äì131. Integration of rational functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/integration-of-algebraical-functions-integration-by-rationalisation-integration-by-parts/">132‚Äì139. Integration of algebraical functions. Integration by rationalisation. Integration by parts</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/integration-of-transcendental-functions/">140‚Äì144. Integration of transcendental functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/areas-of-plane-curves/">145. Areas of plane curves</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/lengths-of-plane-curves/">146. Lengths of plane curves</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-vi/">Miscellaneous Examples</a></span></p>
<p><strong id="ch7">Chapter VII</strong></p>
<p><strong>ADDITIONAL THEOREMS IN THE DIFFERENTIAL AND INTEGRAL </strong><strong>CALCULUS</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/taylors-theorem/">147. Taylor‚Äôs Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/taylors-series/">148. Taylor‚Äôs Series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/applications-of-taylors-theorem-to-maxima-and-minima/">149. Applications of Taylor‚Äôs Theorem to maxima and minima</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/applications-of-taylors-theorem-to-the-calculation-of-limits/">150. Applications of Taylor‚Äôs Theorem to the calculation of limits</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-contact-of-plane-curves/">151. The contact of plane curves</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/differentiation-of-functions-of-several-variables/">152‚Äì154. Differentiation of functions of several variables</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/differentials/">155. Differentials</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/definite-integrals-areas-of-curves/">156‚Äì161. Definite Integrals. Areas of curves</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/alternative-proof-of-taylors-theorem/">162. Alternative proof of Taylor‚Äôs Theorem</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/application-to-the-binomial-series/">163. Application to the binomial series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/integrals-of-complex-functions/">164. Integrals of complex functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-vii/">Miscellaneous Examples</a></span></p>
<p><strong>Chapter VIII</strong></p>
<p><strong>THE CONVERGENCE OF INFINITE SERIES AND INFINITE INTEGRALS</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/series-of-positive-terms-cauchys-and-dalemberts-tests-of-convergence/">165‚Äì168. Series of positive terms. Cauchy‚Äôs and d‚ÄôAlembert‚Äôs tests of convergence</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/dirichlets-theorem/">169. Dirichlet‚Äôs Theorem</a></span></p>
<p><span><a href="https://avidemia.com/multiplication-of-series-of-positive-terms/">170. Multiplication of series of positive terms</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/further-tests-of-convergence-abels-theorem-maclaurins-integral-test/">171‚Äì174. Further tests of convergence. Abel‚Äôs Theorem. Maclaurin‚Äôs integral test</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-series-sum-n-s/">175. The series $\sum n^{-s}$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/cauchys-condensation-test/">176. Cauchy‚Äôs condensation test</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/infinite-integrals/">177‚Äì182. Infinite integrals</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/series-of-positive-and-negative-terms/">183. Series of positive and negative terms</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/absolutely-convergent-series/">184‚Äì185. Absolutely convergent series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/conditionally-convergent-series/">186‚Äì187. Conditionally convergent series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/alternating-series/">188. Alternating series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/abels-and-dirichlets-tests-of-convergence/">189. Abel‚Äôs and Dirichlet‚Äôs tests of convergence</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/series-of-complex-terms/">190. Series of complex terms</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/power-series/">191‚Äì194. Power series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/multiplication-of-series/">195. Multiplication of series in general</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-viii/">Miscellaneous Examples</a></span></p>
<p><strong>Chapter IX</strong></p>
<p><strong>THE LOGARITHMIC AND EXPONENTIAL FUNCTIONS OF A REAL VARIABLE</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-logarithmic-function/">196‚Äì197. The logarithmic function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-functional-equation-satisfied-by-log-x/">198. The functional equation satisfied by $\log x$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-behaviour-of-log-x-as-x-tends-to-infinity-or-to-zero/">199‚Äì201. The behaviour of $\log x$ as $x$ tends to infinity or to zero</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/scales-of-infinity/">202. The logarithmic scale of infinity</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-number-e/">203. The number $e$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-exponential-function/">204‚Äì206. The exponential function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-general-power-ax/">207. The general power $a^x$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-representation-of-ex-as-a-limit/">208. The exponential limit</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-representation-of-log-x-as-a-limit/">209. The logarithmic limit</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/common-logarithms/">210. Common logarithms</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/logarithmic-tests-of-convergence/">211. Logarithmic tests of convergence</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-exponential-series/">212. The exponential series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-logarithmic-series/">213. The logarithmic series</a></span></p>
<p><span><a href="https://avidemia.com/the-series-for-the-inverse-tangent/">214. The series for $\arctan x$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-binomial-series/">215. The binomial series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/alternative-development-of-the-theory/">216. Alternative development of the theory</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-ix/">Miscellaneous Examples</a></span></p>
<p><strong>Chapter X</strong></p>
<p><strong>THE GENERAL THEORY OF THE LOGARITHMIC, EXPONENTIAL, AND CIRCULAR FUNCTIONS</strong></p>
<p><span><a href="https://avidemia.com/pure-mathematics/functions-of-a-complex-variable/">217‚Äì218. Functions of a complex variable</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/curvilinear-integrals/">219. Curvilinear integrals</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/definition-of-the-logarithmic-function/">220. Definition of the logarithmic function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-values-of-the-logarithmic-function/">221. The values of the logarithmic function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-exponential-function-ch-x/">222‚Äì224. The exponential function</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-general-power-az/">225‚Äì226. The general power $a^z$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-trigonometrical-and-hyperbolic-functions/">227‚Äì230. The trigonometrical and hyperbolic functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-connection-between-the-logarithmic-and-inverse-trigonometrical-functions/">231. The connection between the logarithmic and inverse trigonometrical functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-power-series-for-exp-z/">232. The exponential series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-series-for-cos-z-and-sin-z/">233. The series for $\cos z$ and $\sin z$</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-logarithmic-series-2/">234‚Äì235. The logarithmic series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-exponential-limit/">236. The exponential limit</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/the-binomial-series-ch-x/">237. The binomial series</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/miscellaneous-examples-on-chapter-x/">Miscellaneous Examples</a></span></p>

<p><span><a href="https://avidemia.com/pure-mathematics/appendix-i/"><strong>Appendix I.</strong> The proof that every equation has a root</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/appendix-ii/"><strong>Appendix II.</strong> A note on double limit problems</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/appendix-iii/"><strong>Appendix III.</strong> The circular functions</a></span></p>
<p><span><a href="https://avidemia.com/pure-mathematics/appendix-iv/"><strong>Appendix IV.</strong> The infinite in analysis and geometry</a></span></p>
	</div>
</article>
				
			</div><!-- #content -->

			
		</div><!-- #primary -->

		

<!-- #right-sidebar -->


	</div><!-- #content-wrap -->

	

    ‚Ä¶</main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://avidemia.com/pure-mathematics/">https://avidemia.com/pure-mathematics/</a></em></p>]]>
            </description>
            <link>https://avidemia.com/pure-mathematics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25365318</guid>
            <pubDate>Wed, 09 Dec 2020 21:26:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Tailwind UI and Next.js Together]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25364901">thread link</a>) | @hkhanna
<br/>
December 9, 2020 | https://www.khanna.law/blog/using-tailwind-ui-and-next-js-together | <a href="https://web.archive.org/web/*/https://www.khanna.law/blog/using-tailwind-ui-and-next-js-together">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><em>This process has gotten much easier with the <a href="https://blog.tailwindcss.com/tailwindcss-v2">release of TailwindCSS 2.0</a>. These instructions have been updated to reflect the installation process for TailwindCSS 2.0 and Next.js 10.</em></p>
<hr>
<p><a href="https://nextjs.org/">Next.js</a> is an incredible framework for building server-side React applications. <a href="https://tailwindcss.com/">Tailwind CSS</a> is a utility-first CSS framework that makes designing and building websites a breeze. And <a href="https://tailwindui.com/">Tailwind UI</a> is a commercial set of pre-baked components made in Tailwind CSS by two incredible designers, Adam Wathan and Steve Schoger. Using these tools together, I can develop whole web applications that look beautiful, from scratch, in record time.</p>
<p>To figure out the right way to set them up together, I pulled the relevant pieces of documentation from each of Next.js, Tailwind CSS and Tailwind UI and synthesized them into this guide. I reference and link to those parts of documentation where appropriate.</p>
<ol>
<li>Set up Next.js with Tailwind CSS in development</li>
<li>Add Tailwind UI</li>
<li>Optimize for production with PurgeCSS</li>
</ol>
<h2>1. Set Up Next.js and Tailwind CSS in Development</h2>
<p>The <a href="https://tailwindcss.com/docs/guides/nextjs">Next.js-specific TailwindCSS installation instructions</a> do an excellent job of getting you setup with both of these in a project. Complete the steps there and come back here when you're done.</p>
<p>Confirm it works by running <code>npm run dev</code> and navigating in your browser to <code>localhost:3000</code>, where you should see a page that looks something like this:</p>
<p><img src="https://www.khanna.law/assets/blog/using-tailwind-ui-and-next-js-together/next-js-screenshot.png" alt="Next.js Default Page"></p>
<p>Edit <code>pages/index.js</code> to use some Tailwind CSS classes to make sure its working:</p>
<pre><code>// pages/index.js
import Head from 'next/head'

export default function Home() {
  return (
    &lt;div&gt;
      &lt;Head&gt;
        &lt;title&gt;Next.js TailwindCSS&lt;/title&gt;
        &lt;link rel="icon" href="/favicon.ico"/&gt;
      &lt;/Head&gt;

      &lt;div className="container mx-auto"&gt;
        &lt;h1 className="text-lg text-center m-4"&gt;TailwindUI/Next.js&lt;/h1&gt;
        &lt;p className="bg-green-600"&gt;This is a test of the tailwind next integration.&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  )
}
</code></pre>
<p>If Next.js has put a <code>Home.module.css</code> file in the <code>styles/</code> directory, you should delete that since that file just has the styling for the Next.js example page and should not be used anymore.</p>
<p>If it doesn't look like it working, you may need to stop the Next.js dev server and restart it because it may not pick up the changes to the <code>postcss.config.js</code> file unless you do a manual restart.</p>
<p>If you're still stuck, Next.js publishes an <a href="https://github.com/vercel/next.js/tree/canary/examples/with-tailwindcss">example app with Tailwind CSS</a> so you can see how your matches up.</p>
<p>One thing that may have noticed that may throw you off is that since this process creates a <code>postcss.config.js</code> file, it <a href="https://nextjs.org/docs/advanced-features/customizing-postcss-config">completely overwrites the implicit defaults used by Next.js</a>. On first glance, the defaults have a lot of stuff in it like <code>postcss-flexbox-fixes</code> and <code>postcss-preset-env</code> along with some configuration that we seem to have ignored. This is intentional.</p>
<p>Since by and large you won't be using CSS directly but will be using Tailwind CSS utility classes, you don't need that stuff and can just use the minimal <code>postcss.config.js</code> config from above.</p>
<h2>2. Add Tailwind UI</h2>
<p>The newest version of TailwindCSS and TailwindUI doesn't specifically require you to install TailwindUI-specific packages until you encounter that requirement by a particular TailwindUI component. For example, if you encounter a component that requires the <code>@tailwindcss/forms</code> plugin, you'll need to install it in your project with a <code>npm install --save @tailwindcss/forms</code> before you can use it.</p>
<p>There are some general and React-specific tips and tricks in the <a href="https://tailwindui.com/documentation">TailwindUI documentation</a>.</p>
<p>If things don't seem to be working and you've installed a new package or updated your <code>tailwind.config.js</code> file, you may need to stop and restart the Next.js dev server for it to pick up the changes.</p>
<p>If you are going to use the recommended <code>Inter var</code> font <a href="https://tailwindui.com/documentation#optional-add-the-inter-font-family">recommended by the TailwindUI documentation</a>, you'll need to put the <code>&lt;link&gt;</code> tag that it suggests in the <code>index.js</code> file <code>&lt;Head&gt;</code> tag:</p>
<pre><code>...
&lt;Head&gt;
  &lt;title&gt;Next.js TailwindCSS&lt;/title&gt;
  &lt;link rel="icon" href="/favicon.ico" /&gt;
  &lt;link rel="stylesheet" href="https://rsms.me/inter/inter.css" /&gt;
&lt;/Head&gt;
...
</code></pre>
<p>To test that Tailwind UI is working properly, in <code>pages/index.js</code>, copy and paste in an element that does not have any Javascript (e.g., the Marketing Blog Section component).</p>
<p>You may need find-and-replace the <code>class</code> attribute to <code>className</code> if your IDE doesn't do this for your automatically.</p>
<p>That's it! Integrating TailwindUI with Next.js has gotten much simpler since TailwindCSS 2.0 arrived on the scene.</p></div></div></div>]]>
            </description>
            <link>https://www.khanna.law/blog/using-tailwind-ui-and-next-js-together</link>
            <guid isPermaLink="false">hacker-news-small-sites-25364901</guid>
            <pubDate>Wed, 09 Dec 2020 21:01:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating realtime weather-data in Python]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25364877">thread link</a>) | @nanayaw1221
<br/>
December 9, 2020 | https://www.pythonstacks.com/blog/generating-realtime-weather-data-python/ | <a href="https://web.archive.org/web/*/https://www.pythonstacks.com/blog/generating-realtime-weather-data-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>In this short tutorial, you will learn to obtain the realtime/current weather conditions of any city in python. We are going to make use of the weather API from <a href="https://www.weatherapi.com/" target="_blank"><span>www.weatherapi.com</span></a>.</p>

<p>WeatherAPI is a service that provides weather data, including realtime weather data, forecasts, and historical data to developers for use in applications and other services.</p>

<p>Before using their API, you have to signup for a free account and generate an API key. You will need the API key for accessing their service.</p>

<p>We will use the Python Requests module for accessing the API. If you are not familiar with Requests, checkout Introduction to <a href="https://www.pythonstacks.com/blog/making-requests-python-requests-library/">Python's Requests library</a>.</p>

<p>Install the requests module by running:</p>

<pre><code>pip install requests</code></pre>



<h2>Retrieving the Current weather data</h2>

<p>Before we make the request, first we will create these variables:</p>

<ol>
	<li>
	<p><code>base_url </code>, which stores the API's URL which is <span>http://api.weatherapi.com/v1.</span></p>
	</li>
	<li>
	<p><code>api_key</code>, stores your API key</p>
	</li>
	<li>
	<p><code>city</code>, the city whose weather data is needed.</p>
	</li>
</ol>



<pre><code>import requests

api_key = "your_API_key"
base_url = "http://api.weatherapi.com/v1"
city = "london"

parameters = {"key":api_key, "q":city}         # URL parameters
r = requests.get(f"{base_url}/current.json", params=parameters)

data = r.json()         # retrieve the json data

print(data)</code></pre>

<p><strong>output:</strong></p>

<pre><code>{'location': {'name': 'London', 'region': 'City of London, Greater London', 'country': 'United
Kingdom', 'lat': 51.52, 'lon': -0.11, 'tz_id': 'Europe/London', 'localtime_epoch': 1606304125,
'localtime': '2020-11-25 11:35'}, 'current': {'last_updated_epoch': 1606302905, 'last_updated': 
2020-11-25 11:15', 'temp_c': 13.0, 'temp_f': 55.4, 'is_day': 1, 'condition': {'text': 'Partly
cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 8.1,
'wind_kph': 13.0, 'wind_degree': 200, 'wind_dir': 'SSW', 'pressure_mb': 1011.0, 'pressure_in': 30.3,
'precip_mm': 0.1, 'precip_in': 0.0, 'humidity': 82, 'cloud': 75, 'feelslike_c': 11.9, 'feelslike_f':
53.5, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 3.0, 'gust_mph': 11.9, 'gust_kph': 19.1}}</code></pre>

<p>The output is a python dictionary therefore, we can easily get the data we want from it by indexing.</p>

<p>Now let's parse this data into a nice piece of information</p>

<pre><code>import requests

api_key = "your_API_key"
base_url = "http://api.weatherapi.com/v1"
city = "london"

parameters = {"key":api_key, "q":city}         # URL parameters
r = requests.get(f"{base_url}/current.json", params=parameters)

data = r.json()         # retrieve json


# retriving Data

location = data['location']['name']
time = data['location']['localtime']

condition = data['current']['condition']['text']     
temperature_celcius = data['current']['temp_c']
temperature_farenheit = data['current']['temp_f']
feelslike_celcius = data['current']['feelslike_c']
wind_direction = data['current']['wind_dir']


# printing data
print(f"Location: {location}")
print(f"Current Time: {time}")
print()
print(f"Weather Condition: {condition}")
print(f"Temperature in Celcius: {temperature_celcius}")
print(f"Temperature in farenheit: {temperature_farenheit}")
print()
print(f"Temperature feels like: {feelslike_celcius} Celcius")
print(f"Wind Direction: {wind_direction}")</code></pre>

<p><strong>Output:</strong></p>

<pre><code>Location: London
Current Time: 2020-11-25 11:53

Weather Condition: Light rain
Temperature in Celcius: 14.0
Temperature in farenheit: 57.2

Temperature feels like: 13.1 Celcius
Wind Direction: SSW
</code></pre>


        </div></div>]]>
            </description>
            <link>https://www.pythonstacks.com/blog/generating-realtime-weather-data-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25364877</guid>
            <pubDate>Wed, 09 Dec 2020 21:00:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Statement Regarding Cyber Attack on European Medicines Agency]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25364862">thread link</a>) | @mudil
<br/>
December 9, 2020 | https://investors.biontech.de/news-releases/news-release-details/statement-regarding-cyber-attack-european-medicines-agency | <a href="https://web.archive.org/web/*/https://investors.biontech.de/news-releases/news-release-details/statement-regarding-cyber-attack-european-medicines-agency">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="block-nir-pid3469-content">
  
    
      <h2>

</h2>





<article role="article">

  <div>
                <p>Today, we were informed by the European Medicines Agency (EMA) that the agency has been subject to a cyber attack and that some documents relating to the regulatory submission for Pfizer and BioNTech‚Äôs COVID-19 vaccine candidate, BNT162b2, which has been stored on an EMA server, had been unlawfully accessed. It is important to note that no BioNTech or Pfizer systems have been breached in connection with this incident and we are unaware that any study participants have been identified through the data being accessed. At this time, we await further information about EMA‚Äôs investigation and will respond appropriately and in accordance with EU law. EMA has assured us that the cyber attack will have no impact on the timeline for its review.</p>

<p>Given the critical public health considerations and the importance of transparency, we continue to provide clarity around all aspects of the vaccine development and regulatory processes. Our focus remains steadfast on working in close partnership with governments and regulators to bring our COVID-19 vaccine to people around the globe as safely and as efficiently as possible to help bring an end to this devastating pandemic.</p>
  
      </div>
</article>
  </div></div>]]>
            </description>
            <link>https://investors.biontech.de/news-releases/news-release-details/statement-regarding-cyber-attack-european-medicines-agency</link>
            <guid isPermaLink="false">hacker-news-small-sites-25364862</guid>
            <pubDate>Wed, 09 Dec 2020 20:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Upcoming ARM Chip That's Faster Than Apple Silicon M1]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25364112">thread link</a>) | @singhkays
<br/>
December 9, 2020 | https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/ | <a href="https://web.archive.org/web/*/https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The release of Apple M1 Silicon has laid to rest many questions about whether ARM CPUs can go toe-to-toe with the best of the bunch from Intel and AMD. The question now is not whether ARM chips can perform better than Intel/AMD but whether others can build similarly powerful ARM CPUs. Today, companies like Marvell, Ampere and AWS are shipping ARM CPUs that keep getting better with each generation and close to the level of performance of top-end X86 CPUs. It only feels like a matter of time before ARM CPUs will provide tough competition to the X86 CPUs from Intel and AMD. This feels a bit like standing on the Florida coast and watching the first bands of a hurricane arrive. This reminds me of the iconic scene in the movie ‚ÄúThe Dark Knight Rises‚Äù when Selina Kyle (<em>Catwoman</em>) tells Bruce Wayne (<em>Batman</em>) that there‚Äôs a storm (<em>Bane</em>) coming. The full dialogue goes something like:</p>
<blockquote>
<p>Selina Kyle (Catwoman): There‚Äôs a storm coming, Mr. Wayne. You and your friends better batten down the hatches, because when it hits, you‚Äôre all gonna wonder how you ever thought you could live so large and leave so little for the rest of us.</p>
<p><em>‚ÄîThe Dark Knight Rises (2012)</em></p>
</blockquote>
<p>If you read between the lines, there are many parallels that you can draw from the characterization in the movie to real life.</p>
<ol>
<li>
<p>Batman and Catwoman are frenemies, which is not much different from Intel and AMD‚Äôs relationship. They are often competitors, just like Batman &amp; Catwoman. Still, they managed to work together once and ship this baby - <a href="https://ark.intel.com/content/www/us/en/ark/products/130409/intel-core-i7-8809g-processor-with-radeon-rx-vega-m-gh-graphics-8m-cache-up-to-4-20-ghz.html">Intel¬Æ Core i7-8809G</a> - a rare Intel CPU with AMD integrated graphics.</p>
</li>
<li>
<p>Intel has dominated a large part of the CPU market‚Äôs profits for a very long time. In contrast, everyone else has had to contend with using lower cost as a vector to compete against Intel‚Äôs hegemony. For e.g. <a href="https://venturebeat.com/2020/02/05/amd-gained-share-against-intel-in-x86-processor-market-in-q4/">Intel dominates about 95.5% of the server chip market</a>.</p>
</li>
<li>
<p><strong>(<em>SPOILER ALERT</em>)</strong> Selina ends up joining up with Bane by giving up Batman. This might be very similar to the rumors that AMD is planning its own ARM CPUs in real life.</p>
<blockquote><p lang="en" dir="ltr">AMD has an M1 competitor in prototype stages, one version with integrated RAM, and one without it<br>he said "almost ready"<br>but -imo- idk<br>leak is only a few days old, the chip idk</p>‚Äî Mauri QHD (@MauriQHD) <a href="https://twitter.com/MauriQHD/status/1332601734565416962?ref_src=twsrc%5Etfw">November 28, 2020</a></blockquote>

</li>
</ol>

<p>Apple Silicon M1 has taken the CPU market by storm and, in doing so, answered every doubt whether it can compete with the best of the best. The M1 is currently sitting at the top of Geekbench‚Äôs <a href="https://browser.geekbench.com/mac-benchmarks">single-core throne</a>, all while using less power than competing CPUs. The M1 has completely reset the Performance per Watt expectations. It‚Äôs even more astonishing to think that as Apple has introduced the M1 for only the lowest-end Macs, this is the slowest SoC that Apple will ever make (<em>for Macs</em>). Based on Apple‚Äôs history of consistently delivering year-over-year performance improvements, the follow-ups to the M1 will likely improve upon the current single-core performance very rapidly. It is not clear whether Intel and AMD have something in the pipeline that could shift the balance back in X86‚Äôs favor.</p>
<p><img src="https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/mac-mini-geekbench-anandtech.png" alt="Apple M1 Geekbench Benchmark"></p>
<p><em>From: <a href="https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested/2">https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested/2</a></em></p>
<p>However, this could change soon.</p>


<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-logo_hu7acda768cb08e21c8112331e97f9c4f0_28389_480x0_resize_box_2.png 480w,
            
                   https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-logo_hu7acda768cb08e21c8112331e97f9c4f0_28389_800x0_resize_box_2.png 800w,
            
                   
            
                   
            " src="https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-logo_hu7acda768cb08e21c8112331e97f9c4f0_28389_800x0_resize_box_2.png" alt="Nuvia Logo">
</figure>
<p><strong>Nuvia</strong> is a startup founded in early 2019 that is building an ARM CPU for the server market. The company was founded by John Bruno, Manu Gulati, and Gerard Williams III. They bring a breadth of experience in system engineering and silicon design for more than 20 chips and more than 100 patents. Nuvia‚Äôs leadership team holds an impressive resume with various architect and leadership roles at Google, Apple, ARM, Broadcom, and AMD (<a href="https://nuviainc.com/leadership"><em>See here for the leadership team‚Äôs full details</em></a>). It is quite possible that Nuvia‚Äôs leadership was involved with the previous Apple Silicon designs and bring with them the ideas and strategies that have made Apple‚Äôs chips a market-leader.</p>
<p>Here is <a href="https://medium.com/silicon-reimagined/performance-delivered-a-new-way-8f0f5ed283d5">more on Nuvia‚Äôs design goals and philosophy</a> (<em><strong>emphasis</strong> on key talking points mine</em>):</p>
<blockquote>
<p>Our focus at NUVIA is to develop an SoC that will deliver industry-leading performance with the highest levels of efficiency, at the same time. To do this, <strong>we are creating a server CPU that is built in a new way, with a complete overhaul of the CPU pipeline</strong>. Our first-generation CPU, code-named ‚Äú<strong>Phoenix</strong>‚Äù will be a custom core based on the ARM architecture and central to our ‚Äú<strong>Orion</strong>‚Äù SoC.</p>
</blockquote>
<blockquote>
<p>With X86 solutions claiming most of the market, only a small percentage of niche customers are willing to accept a lower per-core performance, high core count product. Arguably the most successful ARM-based design today is Amazon‚Äôs Graviton. Graviton is a captive design, aimed solely for a limited portion of AWS that values cost over performance. While there will likely be additional growth in this area, <strong>the heart of the market clearly demands the highest single-thread performance at TDP and the highest all-core performance at TDP</strong>. This is the fastest way to improve Performance/TCO for the most demanding hyperscale customers.</p>
</blockquote>
<blockquote>
<p>While these new entrant‚Äôs products show improvements, they still fall short of disrupting their X86 incumbents. At NUVIA, we are taking a different approach, with a clean-sheet CPU design that will deliver an elegant balance of performance leadership and power efficiency that maximizes memory bandwidth and core utilization. <strong>Our solution does not need to add extraneous cores to try and make up for a single-threaded performance deficit</strong>. Also, there would be <strong>no need to employ marketing-inflated boost clocks</strong> that are not achievable in any real-world applications of server SoCs, due to running into TDP constraints. In real-world scenarios, server SoCs are designed to be heavily loaded to make the best use of the capitalized hardware and allocated power and cooling budgets. The optimal solution is one where a workload finishes in the shortest time possible while consuming the least possible power.</p>
</blockquote>
<p>I‚Äôve highlighted the key design goals, but the gist of it is that:</p>
<ol>
<li>Nuvia is likely working on a custom ARM design like Apple rather than reusing ARM‚Äôs reference architecture like some other ARM licensees.</li>
<li>The goal is the highest single-thread performance possible without the use of boost or turbo clocks.</li>
</ol>

<p>Nuvia recently <a href="https://medium.com/silicon-reimagined/performance-delivered-a-new-way-8f0f5ed283d5">published their findings</a> on how their Phoenix CPU fares against the latest X86 and ARM CPUs. Here are the systems that were tested:</p>
<table>
<thead>
<tr>
<th>Device</th>
<th>SoC</th>
<th>Process Technology</th>
<th>CPU Microarchitecture</th>
<th>Frequency</th>
</tr>
</thead>
<tbody>
<tr>
<td>2020 Apple 13" MacBook Pro</td>
<td>Intel Core i7 -1068NG7</td>
<td>Intel 10nm</td>
<td>Sunny Cove</td>
<td>2.3GHz Base <br>4.1GHz Boost</td>
</tr>
<tr>
<td>2018 Apple 15" MacBook Pro</td>
<td>Intel Core i7 - 8750H</td>
<td>Intel 14nm</td>
<td>Skylake</td>
<td>2.2GHz Base <br>4.1GHz Boost</td>
</tr>
<tr>
<td>2020 Lenovo 14" Flex 5</td>
<td>AMD Ryzen 7 - 4700U</td>
<td>TSMC 7nm</td>
<td>Zen 2</td>
<td>2.OGHz Base <br>4.1GHz Boost</td>
</tr>
<tr>
<td>Samsung Galaxy S20</td>
<td>Qualcomm Snapdragon 865</td>
<td>TSMC 7nm</td>
<td>ARM A77, ARM A55</td>
<td>2.84GHz (xl-A77) <br>2.42GHz (x3-A77) <br>1.8GHz (x4-A55)</td>
</tr>
<tr>
<td>2020 Apple iPad Pro</td>
<td>Apple A12Z Bionic</td>
<td>TSMC 7nm</td>
<td>Vortex, Tempest</td>
<td>2.5GHz (x4-Vortex) <br>1.59GHz (x4-Tempest)</td>
</tr>
<tr>
<td>Apple iPhone 11</td>
<td>Apple A13 Bionic</td>
<td>TSMC 7nm</td>
<td>Lightning, Thunder</td>
<td>2.66 GHz (x2- Lightning) <br>1.73 GHz (x4-Thunder)</td>
</tr>
</tbody>
</table>
<p>The reasons for choosing these CPUs were as follows:</p>
<blockquote>
<p>The devices tested demonstrate the current state of the art from the majority of the major players, both ARM and X86 based platforms. Intel‚Äôs Core i7‚Äì1068NG7 Ice Lake based SoC is the highest performance variant currently available utilizing the new Sunny Cove CPU microarchitecture, based on Intel‚Äôs 10nm process node. We are also assuming that Intel‚Äôs next-generation Ice Lake Server will utilize a CPU core built upon a similar base architecture as Sunny Cove. The Intel Core i7‚Äì8750H is the last generation of the Skylake microarchitecture and is more closely related to the CPU core shipping in today‚Äôs latest Xeon processors. AMD‚Äôs Ryzen 4700U utilizes the latest Zen 2 CPU core on TSMC‚Äôs 7nm process node. AMD uses the same Zen 2 CPU core within the CCX chiplet in the Rome EPYC family of processors. Qualcomm‚Äôs Snapdragon 865 utilizes ARM‚Äôs latest A77 as its performance core and is implemented on TSMC‚Äôs 7nm process node. The latest announced Ampere Altra and Amazon Graviton 2 both use an ARM N1 CPU core that is more closely related to the older A76, and both are built upon TSMC‚Äôs 7nm process node. Lastly, the Apple A13 and A12Z demonstrate the current fastest ARM-based processors, also both built upon TSMC‚Äôs 7nm process node.</p>
</blockquote>

<p>Nuvia released the expected single-core Performance-Per-Watt curve of their upcoming CPU. To get an idea of how this ranks against the M1, I‚Äôve added the <a href="https://browser.geekbench.com/v5/cpu/5197838">single-core Geekbench score for M1 based Mac Mini</a> to Nuvia‚Äôs graph. Nuvia is not disclosing the actual score, just giving estimates for now. The actual scores will be released at a later date. My best estimate based on their current projections is that these are higher than Apple M1‚Äôs single-core score. Based on the posted graph, I would put the single-core score between <strong>1900</strong> to <strong>2250</strong> range which is about a <strong>10-30%</strong> improvement on single-core performance.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-phoenix-vs-apple-silicon-m1-small_hu89969aa063c3f421f6091600946740a1_258106_480x0_resize_box_2.png 480w,
            
                   https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-phoenix-vs-apple-silicon-m1-small_hu89969aa063c3f421f6091600946740a1_258106_800x0_resize_box_2.png 800w,
            
                   https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-phoenix-vs-apple-silicon-m1-small_hu89969aa063c3f421f6091600946740a1_258106_1200x0_resize_box_2.png 1200w,
            
                   https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-phoenix-vs-apple-silicon-m1-small_hu89969aa063c3f421f6091600946740a1_258106_1500x0_resize_box_2.png 1500w,
            " src="https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/media/nuvia-phoenix-vs-apple-silicon-m1-small_hu89969aa063c3f421f6091600946740a1_258106_800x0_resize_box_2.png" alt="Nuvia Phoenix CPU performance against Apple Silicon M1, A13 Bionic, Intel Sunny Cove, Snapdragon 865"> <figcaption>
<p>Nuvia Phoenix CPU performance compared to X86 and ARM CPUs</p>
</figcaption>
</figure>

<h3 id="how-to-read-these-results">How to read these results?</h3>
<p>From Nuvia:</p>
<blockquote>
<p>When measured against current products available in-market in the 1W-4.5W power envelope (<em>per core</em>), the Phoenix CPU core performs up to 2X faster than the competition.</p>
</blockquote>
<p>The 2X claim should now change since the results were published in August before the Apple M1 and the Zen 3 launch. These products now have higher single-core performance than the products Nuvia tested.</p>
<p>Nuvia did, however, expect such a scenario:</p>
<blockquote>
<p>We realize the companies we have measured against in these tests are not standing still and will have new products in the market over the next 18 months. That said, we believe that even with significant performance gains (20%+) with new CPU architectures, we will continue to hold a clear position of leadership in performance-per-watt.</p>
</blockquote>
<h3 id="why-is-nuvia-focusing-on-this-1w-45w-per-core-power-envelope">Why is Nuvia focusing on this 1W-4.5W per core power envelope?</h3>
<p>I‚Äôll let Nuvia answer this:</p>
<blockquote>
<p>All current and future flagship server SoCs are power constrained, very much like mobile SoCs. As core count increases, what is not increasing is the TDP. TDPs are likely going to remain in the 250W ‚Äî 300W ‚Ä¶</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/">https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/</a></em></p>]]>
            </description>
            <link>https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25364112</guid>
            <pubDate>Wed, 09 Dec 2020 20:15:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Problems in Financial Services Reconciliation]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25363650">thread link</a>) | @kunle
<br/>
December 9, 2020 | https://kunle.app/dec-2020-financial-reconciliation.html | <a href="https://web.archive.org/web/*/https://kunle.app/dec-2020-financial-reconciliation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  				
  				 <p>December 2020</p>

<p>If your product moves money on behalf of customers, and you manage the ledger, you need reconciliation. You can think of recon as the process of making sure every transaction in your system matches one in the external world. For every dollar you‚Äôve moved, an external entity agrees with the amount and direction, and has provided ‚Äúdocumentation‚Äù to that effect.</p>
<p>I‚Äôve seen a few performant recon systems that came under stress as they scaled, and I‚Äôve worked with startups at early enough stages that getting recon right was not existential. I‚Äôve also never built a recon system from scratch. Everything I'll say here is from the perspective of a user of recon systems rather than a maker of them. I‚Äôve been a customer of a couple, and their performance impacted my output so I have strong opinions about what I wish would exist. Since I'm not sure what a perfect recon system would look like, I'm writing this to flesh out the thought, and to smoke out anyone who already knows.</p>
<p>I‚Äôve interacted with reconciliation systems aimed at two types of problems:</p>
<h2>Reconciliation of transactions</h2>
<p>Transaction oriented recon makes sure that some external party agrees with every money movement in your ledger. I saw this philosophy in the recon systems I interacted with at Cash App &amp; Square in general. In this model, the objective is to make sure that every money movement action matches your intention. This means the state of the transaction, the direction, and the amount are what you expect. A secondary objective is ensuring the timing matches your intention. This is secondary because in a lot of cases, the actual precise timing doesn't matter as long as it happens&nbsp; "soon", and as long as the underlying accounts aren‚Äôt run at a $0 balance. In this case reconciliation solves an accounting problem, ensuring money movements are correct. It also helps ensure that the company's receivables and payables are complete, is useful for regulatory &amp; financial audits, and empowers your treasury team to make good cash management decisions. I suspect most acquirers (Stripe, Square, Adyen, etc.) at least start by pursuing transaction oriented recon.</p>
<p>Typically in an acquiring world, you construct the ‚Äúinternal‚Äù ledger from the settlement/capture messages generated by the card networks. This is what product teams look at to inform customer facing features. You construct the ‚Äúexternal‚Äù ledger from settlement files generated by the acquiring bank. Accounting teams look at the external ledger (technically accounting teams look at both ledgers, but product teams rarely look at the external ledger on an ongoing basis).</p>
<p>A recon system often includes an engineering team paired with an operations team, working together. In cases where the internal and external ledgers disagree, a human (on the ops team) reviews the data. They determine what‚Äôs causing the exception, whether it's systematic, how frequently it occurs, and what to do to fix it. The eng team continually optimizes the process to reduce the exception rate over time. Transaction oriented recon primarily solves accounting problems. You‚Äôre typically working towards SLAs designed for monthly/quarterly earnings close, and your outputs feed into income/cash flow statements.</p>
<h2>Reconciliation of balances</h2>
<p>Balance oriented recon ensures precise amounts in bank or customer accounts on a periodic basis. You use the same internal and external ledgers as in transaction oriented recon. However, you're comparing not only the amounts, state and direction of a transaction, but also its timing. This type of recon system can be useful for accounting, but is ideal for building systems that report a balance at a point in time. One example is a banking system of record. In the case of a system of record, a balance oriented recon system informs customer-facing balances and FDIC insurance.</p>
<p>Balance oriented recon systems are required for organizations that issue instruments and are the final source of truth for their own ledger. Most financial technology companies today rely on the ledgers managed by their infrastructure providers. For instance, if you issue cards, the banking as a service platform typically connects to the bank‚Äôs core, and most traditional bank cores have a balance oriented recon framework built in.</p>
<p>For context - in order to provide FDIC insurance to customers, banks are required to provide an auditable record of customer balances at any point in time. This is usually solved by being able to provide a daily snapshot of customer balances. This function is one of several provided by core processors, and as a result most core processors have a balance oriented recon process built in by default.</p>
<p>However if you‚Äôre the rare card issuer managing your own ledger (or really building any kind of financial product where you‚Äôre responsible for your own ledger, such as a digital wallet where you own the money transmission licenses), you‚Äôll need to build a balance oriented recon system eventually. It's the way you‚Äôll be sure you have the money that you‚Äôre telling customers you have.</p>
<h2>Common Problems in Recon</h2>
<h3>Adding a new money movement type to a single balance</h3>
<p>One overarching problem that affects all recon systems is what happens when new types of money movement impact a balance. For instance, imagine you run a digital wallet where your primary funding and cash-out transaction types are ACH debits and credits. Also, imagine you‚Äôve built a perfect reconciliation system, with the combination of technology and human process that allows you to tie out balances and payments with zero failures (this is super unlikely). The moment you add payment cards as funding/cash out instruments, you now have a different external ledger to integrate with. It will have different edges than you're used to. You'll deal with potentially different organizations, who have different processes for resolving exceptions. No matter what you do, this will take time to get right, and long after your new feature is launched, you‚Äôll probably discover new, undocumented quirks. Some of these quirks will only be clear when you‚Äôre processing money movements at scale. I‚Äôve seen cases where the incorrect MID set with a card network resulted in hundreds of millions of dollars routed to the wrong (internal) account. Survivable error as the transactions were reconciled in aggregate, but bad for accounting and distraction caused to cross functional team members pulled in to swarm the problem.</p>
<h3>Timing differences between authorization and settlement</h3>
<p>For balance oriented reconciliation systems in particular, solving timing problems is critical. Timing problems typically occur when a) the payment authorization time and the settlement time are different, and your system‚Äôs not necessarily aware, b) you‚Äôre dealing with payment types where the settlement amount can be adjusted multiple times c) your ledger updates customers balances when a new payment authorization comes in, rather than a settlement message. In all these cases you‚Äôre grappling with a few questions (I don‚Äôt actually know the right answers to these):</p>
<ul>
<li>When should you update a customer‚Äôs balance? When you know there is a transaction (when the auth comes in) or when amount is finalized (when the settlement comes in)</li>
<li>When the authorization and settlement amounts are different, do you retroactively adjust the balance for the day the authorization came in? Or do you fix that in place and only adjust the balance with the delta on the day the settlement arrives?</li>
<li>Is your snapshot on a particular day immutable (i.e. it can never be adjusted) and if so, how do you handle changes in amounts between the authorization and the settlement?</li>
<li>Traditional core systems will have an available balance (which is how much you can access, with pending transaction amounts removed), and an account balance (which includes pending transactions, and is typically higher than the available balance).</li>
</ul>
<h3>Relying on aged systems for exception handling</h3>
<p>Very often you work with a wholesale bank whose systems are seasoned and handle the majority of exceptions using manual workflows. This can be frustrating; you‚Äôre faced with either adopting their manual processes, which bind your cost structure to theirs, or accepting a higher exception rate temporarily while you build technical systems around their process. There‚Äôs no easy trade-off here.</p>
<h3>Early prototyping and float problems</h3>
<p>In the course of product development you‚Äôll often prototype by adding new money movement types to your ledger. A lot of these prototypes (as should happen) will be discarded. Despite this, they will have moved real money and affected your real ledger, and (at least for your accounting team's sanity) you‚Äôll need a stateful way to reconcile the money that moved to your ledger. While at Cash I once spent a year integrating into 6 card issuer processor systems while prototyping the Cash Card. With each integration we needed a float (depositing funds with the card issuer so we could test transactions in the real world) which meant our accounting team now had 6 new banking relationships to monitor, 4 of which lasted less than 6 months, but all of which required material floats amounts. In a few cases, the issuer processor didn‚Äôt actually enable us to manage our own ledger, so we‚Äôd have a parallel ledger (one on our databases and a mirror on theirs) that we‚Äôd have to keep in sync. There was at least one integration that we ultimately discarded, which took us several months to reconcile, long after we‚Äôd walked away from the partnership. How you handle these cases will depend on what‚Äôs financially ‚Äúmaterial‚Äù for your organization. In our cases, prototype floats were all sub $100k, so survivable at our scale. But tracking these down repeatedly was an insane level of tedium.</p>
<h3>Managing ledgers across many internal bank accounts</h3>
<p>Sometimes you‚Äôll contract with multiple banks for different financial services. For instance one bank for merchant acquiring and another for ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kunle.app/dec-2020-financial-reconciliation.html">https://kunle.app/dec-2020-financial-reconciliation.html</a></em></p>]]>
            </description>
            <link>https://kunle.app/dec-2020-financial-reconciliation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25363650</guid>
            <pubDate>Wed, 09 Dec 2020 19:50:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open source Internet-less IRC using LoRa, for disaster resilience]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25363427">thread link</a>) | @spiritplumber
<br/>
December 9, 2020 | http://f3.to/cellsol/ | <a href="https://web.archive.org/web/*/http://f3.to/cellsol/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
    


    








    <article>
        
        



    



<p>Welcome to CellSol!</p>
<p>This website and its associated project are now in beta! Come take a look at our <a href="https://github.com/RbtsEvrwhr-Riley/CellSol/">GitHub</a></p>
<p><img src="http://f3.to/cellsol/media/cellsol_large_236.png" alt="CellSol Logo - Large"></p>

<div><hr>
<h2 id="lastmod-2020-11-24">publishdate: 2019-11-17
lastmod: 2020-11-24</h2>

<p>What if the internet and cell phone towers went down for more than a few hours - or during an emergency situation? No communication could lead to lost lives.</p>

<p>The end goal of the project is to have a widespread network able to handle low-bandwidth traffic (text, compressed images) for a large number of users, to fill gaps when the larger Internet is unavailable.</p>
<p>In the event of an emergency, the CellSol network, much like the Internet, can be used as a knowledge base, as well as a rally point, giving people a tool to use to coordinate and organize even if 
other communication systems go down. We intend to scale the design, with long-haul routing capabilities, so that regional networks can intercommunicate and interoperate, allowing for a wider breadth of use cases.</p>

<p>The overall design is a <a href="https://en.wikipedia.org/wiki/Mesh_networking">mesh network</a> of <a href="https://www.semtech.com/lora/what-is-lora">LoRa</a> devices, called ‚ÄúPylons‚Äù
that act as repeaters (extending the range of the network). Terminals (devices that users access the network with) also repeat packets, so that a network
made up entirely of end users is possible.</p>
<p>The two basic types of pylons are the ESP32 WiFi Pylon (a terminal device) and the Ardunio Repeater Pylon (a pure repeater, but can have bluetooth to use as a terminal).</p>
<p>Pylons with more specialized uses, such as data repositories for local emergency resources (phone numbers, shelter locations, etc.) and knowledge bases (such as a Wikipedia mirror) are also intended to be
developed in the future, to add to the overall usefulness of the network.</p>
</div>



    </article>

                








    
    

    







            </div></div>]]>
            </description>
            <link>http://f3.to/cellsol/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25363427</guid>
            <pubDate>Wed, 09 Dec 2020 19:39:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Native JavaScript Document API for Cassandra]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25362944">thread link</a>) | @Gulthor
<br/>
December 9, 2020 | https://stargate.io/2020/12/09/announcing-stargate-10-ga-rest-graphql-schemaless-json-for-your-cassandra-development.html | <a href="https://web.archive.org/web/*/https://stargate.io/2020/12/09/announcing-stargate-10-ga-rest-graphql-schemaless-json-for-your-cassandra-development.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
        
        <h4>Level-up your app dev with fast and easy data APIs for the world‚Äôs most battle tested database.</h4>
      </p>
    </div><div>
      <div>
        <p><img data-src="/assets/images/stargate-profile.png" alt="Denise Gosnell" width="32" height="32" src="https://stargate.io/assets/images/stargate-profile.png">
          <span>By <span>Denise Gosnell</span></span>
          ‚Ä¢
          <span>Dec 9, 2020</span>
        </p>
      </div>
    </div><div>
      <div>
        <div>
          <p>It is a really great time to be a developer.</p>

<p>We have tons of APIs integrated within great tools for building dynamic, full stack apps. If you are a developer, you probably are using technologies like schemaless data stores, serverless architectures, JSON APIs, and/or the GraphQL language.</p>

<p>Further, there are a bunch of cool frameworks like the <strong>Jam</strong>stack (<strong>J</strong>avaScript, <strong>A</strong>PIs, and <strong>M</strong>arkup) and services like Netlify to make it fast to deploy a serverless app.</p>

<p>And now, for the first time ever, Apache Cassandra is a part of this stack because <a href="https://astra.datastax.com/">Stargate is now live on Astra</a> as the official data API.</p>

<p>The modern apps we build need data APIs which integrate into our toolset and work with native data shapes (JSON, REST, GraphQL, etc). These data APIs need to support schemaless JSON, while simultaneously providing speed and scalability.</p>

<p>Most importantly, it better only take a few minutes for us to use them within our project.</p>

<p>DataStax built <a href="https://stargate.io/">Stargate</a> into Astra to give us, app developers, a natural data API stack which meshes with the Jamstack (or serverless stack of your choice). Stargate in Astra is built on the rock solid NoSQL data engine (Apache Cassandra) which powers Netflix, Instagram, Yelp, iCloud and other apps we all use everyday.</p>

<h2 id="what-exactly-is-stargate">What exactly is Stargate?</h2>
<p>Stargate is an <a href="https://stargate.io/2020/09/14/init-stargate.html">open source data gateway</a> that sits between your app server and your databases. Stargate brings together an API platform and data request coordination code into one OSS project.</p>

<p>Multiple successful app companies - like Netflix and Yelp - built their own data gateways to help internal app developers create features using simple APIs, without needing to learn the underlying database or mess with schema.</p>

<p>DataStax integrated Stargate into Astra to give you the same power and ease of access to your data.</p>

<p>What does this mean for you?</p>

<ul>
  <li>No upfront data modelling needed for Documents.</li>
  <li>Less custom code to maintain.</li>
  <li>More time to build what you care about.</li>
</ul>

<p><img alt="" data-src="/assets/images/stargate-astra/stargate-astra.png" src="https://stargate.io/assets/images/stargate-astra/stargate-astra.png"></p>

<p>You can work with your data the way you want ‚Äì JSON via schemaless document APIs or database schema aware GraphQL and RESTful APIs ‚Äì while Stargate serves as the proxy that coordinates these requests to different flavors of Cassandra.</p>

<p>To see it in action, let‚Äôs see how this works by using JSON with Stargate‚Äôs schemaless Document API in a TikTok clone. Because, if Instagram and Snapchat have a TikTok clone, we should have one, too. Right?</p>

<h2 id="real-quick-note-first">Real Quick Note First</h2>

<p>Slinging JSON to and from Apache Cassandra without data modeling is just too much fun. You gotta <a href="http://astra.datastax.com/">try this out in Astra for yourself</a>. You can get <a href="https://www.datastax.com/dev/documents-api">hands on with it right away</a> or check out our <a href="https://astra.datastax.com/sample-app-gallery">sample app gallery</a> to see schemaless Cassandra in action.</p>

<p>We are stoked to have engineers from Netflix, Burberry, Macquarie Bank, USAA, and Yelp creating Stargate with us. They are already hard at work battletesting the APIs and collaborating on new features.</p>

<p>Ok, onto the code!</p>

<h2 id="posts-in-tiktok">Posts in TikTok</h2>

<p>We are going to walk through using Stargate‚Äôs APIs in Astra for creating and updating posts within a TikTok clone. We‚Äôre walking through examples that are ready to be pasted into your latest Jamstack app.</p>

<p>To use Stargate in Astra in your app, first install and set up our <a href="https://www.npmjs.com/package/@astrajs/collections">JavaScript SDK</a>. You can learn about storing environment <a href="https://www.youtube.com/watch?v=vSmzEGZQI5A">variables in your .env file here</a>.</p>

<p>Let‚Äôs start with a basic TikTok post: a video with a caption, like:</p>

<figure><pre><code data-lang="javascript"><span>const</span> <span>postData</span> <span>=</span> <span>{</span>
  <span>"</span><span>postId</span><span>"</span><span>:</span> <span>0</span><span>,</span>
  <span>"</span><span>video</span><span>"</span><span>:</span> <span>"</span><span>https://i.imgur.com/FTBP02Y.mp4</span><span>"</span><span>,</span>
  <span>"</span><span>caption</span><span>"</span><span>:</span> <span>"</span><span>These ducks are cute</span><span>"</span><span>,</span>
  <span>"</span><span>timestamp</span><span>"</span><span>:</span> <span>"</span><span>2020-12-09T09:08:31.020Z</span><span>"</span><span>,</span>
  <span>"</span><span>likes</span><span>"</span><span>:</span> <span>0</span><span>,</span>
<span>}</span></code></pre></figure>

<p>After connecting to Stargate in Astra with a nodejs client, let‚Äôs create a new collection in our app and add the post with:</p>

<figure><pre><code data-lang="javascript"><span>const</span> <span>postsCollection</span> <span>=</span> <span>astraClient</span><span>.</span><span>namespace</span><span>(</span><span>"</span><span>tikTokClone</span><span>"</span><span>).</span>
  <span>collection</span><span>(</span><span>"</span><span>posts</span><span>"</span><span>);</span>

<span>const</span> <span>post</span> <span>=</span> <span>await</span> <span>postsCollection</span><span>.</span><span>create</span><span>(</span><span>postData</span><span>);</span></code></pre></figure>

<p>If you‚Äôve ever used Cassandra before, you know this is amazing. Look at what we didn‚Äôt do: no data modeling, no table creation, no configuration code, no partition keys, no clustering columns. I think you get my drift.</p>

<p>Stargate in Astra allows you to add data to Apache Cassandra in one line of code.</p>

<p>This level of ease of use hasn‚Äôt previously been possible with Cassandra. Insert JSON and move on.</p>

<p>Next up, let‚Äôs say you want to find all posts about ducks. You can do that via:</p>

<figure><pre><code data-lang="javascript"><span>// find all posts about ducks</span>
<span>const</span> <span>posts</span> <span>=</span> <span>await</span> <span>postsCollection</span><span>.</span><span>find</span><span>({</span> <span>caption</span><span>:</span> 
  <span>{</span> <span>$in</span><span>:</span>  <span>[</span><span>"</span><span>ducks</span><span>"</span><span>]</span> <span>}</span> <span>});</span></code></pre></figure>

<p>And boom. Now you have your ducks channel all set up for your users. Because who doesn‚Äôt want a stream fully dedicated to ducks?</p>

<p>Now, your app isn‚Äôt going to <a href="https://www.newsweek.com/twitter-fleets-reactions-memes-edit-button-1548037">be like Twitter</a>. We can edit stuff here. Let‚Äôs show how to edit your post‚Äôs caption. Stories tho? That‚Äôs on you</p>

<figure><pre><code data-lang="javascript"><span>// update the post‚Äôs caption</span>
<span>const</span> <span>post</span> <span>=</span> <span>await</span> <span>postsCollection</span><span>.</span><span>update</span><span>(</span><span>post</span><span>.</span><span>documentId</span><span>,</span> <span>{</span>
  <span>caption</span><span>:</span> <span>"</span><span>These ducks are MEGA cute</span><span>"</span><span>,</span>
<span>});</span></code></pre></figure>

<p>The above was just a quick tour on how to do a few data API calls for a basic TikTok clone. Want to see the full thing? Check out <a href="https://www.youtube.com/watch?v=IATOicvih5A">Ania Kubow</a>‚Äôs tutorial to see how to wire this up into a full React app with Netlify.</p>

<h2 id="whats-next">What‚Äôs next?</h2>

<p>For more examples, we have hands-on tutorials for using <a href="https://www.datastax.com/dev/rest">Stargate‚Äôs REST</a>, <a href="https://www.datastax.com/dev/documents-api">Document</a> and <a href="https://www.datastax.com/dev/graphql">GraphQL APIs</a>. Check ‚Äòem out and let us know what you think.</p>

<p>Have an app idea or want to join the fun? <a href="https://discord.gg/2Xt8QNyFZA">You can join the Stargate community, too</a>.</p>

<p>We would love to see how you customize your TikTok clone to show off more ways to feature data in your app. Or, you can create your own non-TikTok example. We would love to showcase your example in our <a href="https://astra.datastax.com/sample-app-gallery">sample app gallery</a>, so tell us about it in <a href="https://discord.gg/33mKDHHFUE">our contribute channel</a>.</p>

<h2 id="so-you-are-down-here-looking-for-a-few-more-details">So, you are down here looking for a few more details</h2>
<p>If you came down here, maybe you are looking for a few more lines of code.</p>

<p>No problem.</p>

<p>Let‚Äôs show how to set up the node JS client and a few more data API calls. For starters, let‚Äôs take a look at how to set up your client to connect to Stargate in Astra.</p>

<figure><pre><code data-lang="javascript"><span>// npm install @astrajs/collections</span>
<span>const</span> <span>{</span> <span>createClient</span> <span>}</span> <span>=</span> <span>require</span><span>(</span><span>"</span><span>@astrajs/collections</span><span>"</span><span>);</span>

<span>// create an Astra client</span>
<span>const</span> <span>astraClient</span> <span>=</span> <span>await</span> <span>createClient</span><span>(</span>
<span>{</span>   <span>astraDatabaseId</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>ASTRA_DB_ID</span><span>,</span>
    <span>astraDatabaseRegion</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>ASTRA_DB_REGION</span><span>,</span>
    <span>username</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>ASTRA_DB_USERNAME</span><span>,</span>
    <span>password</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>ASTRA_DB_PASSWORD</span><span>,</span>
<span>});</span></code></pre></figure>

<p>Easy enough.</p>

<p>Then, let‚Äôs create a users collection in our database to store documents about our TikTok users:</p>

<figure><pre><code data-lang="javascript"><span>// create the users collection in the app</span>
<span>const</span> <span>usersCollection</span> <span>=</span> <span>astraClient</span><span>.</span><span>namespace</span><span>(</span><span>"</span><span>tikTokClone</span><span>"</span><span>).</span><span>collection</span><span>(</span><span>"</span><span>users</span><span>"</span><span>);</span></code></pre></figure>

<p>A TikTok user in our app will have the basics: a unique id, a name, username, etc.</p>

<figure><pre><code data-lang="javascript"><span>const</span> <span>userData</span> <span>=</span> <span>{</span>
  <span>"</span><span>id_3</span><span>"</span><span>:</span> <span>"</span><span>0</span><span>"</span><span>,</span>
  <span>"</span><span>name</span><span>"</span><span>:</span> <span>"</span><span>Mo Farooq</span><span>"</span><span>,</span>
  <span>"</span><span>username</span><span>"</span><span>:</span> <span>"</span><span>mofarooq32</span><span>"</span><span>,</span>
  <span>"</span><span>avatar</span><span>"</span><span>:</span> <span>"</span><span>https://i.imgur.com/9KYq7VG.png</span><span>"</span>
<span>};</span></code></pre></figure>

<p>So, let‚Äôs add our user into our collection:</p>

<figure><pre><code data-lang="javascript"><span>// create a new user</span>
<span>const</span> <span>user</span> <span>=</span> <span>await</span> <span>usersCollection</span><span>.</span><span>create</span><span>(</span><span>userData</span><span>);</span></code></pre></figure>

<p>You can check to make sure your user was stored in the database by reading the user back by any of their properties, like their username.</p>

<figure><pre><code data-lang="javascript"><span>// find our user by username</span>
<span>const</span> <span>users</span> <span>=</span> <span>await</span> <span>usersCollection</span><span>.</span><span>find</span><span>({</span> <span>username</span><span>:</span> <span>{</span> <span>$eq</span><span>:</span> 
  <span>"</span><span>mofarooq32</span><span>"</span> <span>}</span> <span>});</span></code></pre></figure>

<p>Or, you can lookup a user by their <strong>documentId</strong>:</p>

<figure><pre><code data-lang="javascript"><span>// get the user by document id</span>
<span>const</span> <span>user</span> <span>=</span> <span>await</span> <span>usersCollection</span><span>.</span><span>get</span><span>(</span><span>user</span><span>.</span><span>documentId</span><span>);</span></code></pre></figure>

<p>And, lastly, if you need to delete that user:</p>

<figure><pre><code data-lang="javascript"><span>// delete the post</span>
<span>const</span> <span>user</span> <span>=</span> <span>await</span> <span>usersCollection</span><span>.</span><span>delete</span><span>(</span><span>user</span><span>.</span><span>documentId</span><span>);</span></code></pre></figure>

<p>Want to see the full code? Check out <a href="https://github.com/kubowania/stargate-tik-tok">Ania Kubow‚Äôs app</a> to get all the goodness and start customizing it on your own. Let me know when you have stories up and I can subscribe to your ducks channel.</p>

<p>Thank you for following along all the way down here.</p>

<p>Happy building!</p>


        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://stargate.io/2020/12/09/announcing-stargate-10-ga-rest-graphql-schemaless-json-for-your-cassandra-development.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25362944</guid>
            <pubDate>Wed, 09 Dec 2020 19:11:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using targeted microbubbles to administer toxic cancer drugs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25362909">thread link</a>) | @finphil
<br/>
December 9, 2020 | https://nuadox.com/post/637052199365754880/microbubbles-to-administer-cancer-drugs | <a href="https://web.archive.org/web/*/https://nuadox.com/post/637052199365754880/microbubbles-to-administer-cancer-drugs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="637052199365754880">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/637052199365754880/microbubbles-to-administer-cancer-drugs"><h2>Using targeted microbubbles to administer toxic cancer drugs</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1427"><img src="https://64.media.tumblr.com/e8e08c021c8929b23df911cfdcb4ea05/8fb509913ffeb1da-07/s1280x1920/45b467280c3b670994284ac789da1d0b15cb14be.png" alt="image" data-orig-width="1920" data-orig-height="1427" width="1280" height="951"></figure><p><b>- <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.leeds.ac.uk%2F&amp;t=NjUxZmFiYjJlMDZmMjI5ODg3MDM3MjE0YzgzZGExNTZlN2MyNDcyOCxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607735529">By University of Leeds</a> -</b></p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.leeds.ac.uk%2F&amp;t=NjUxZmFiYjJlMDZmMjI5ODg3MDM3MjE0YzgzZGExNTZlN2MyNDcyOCxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607735529">University of Leeds</a>&nbsp;(UK) research has shown how microbubbles carrying powerful cancer drugs can be guided to the site of a tumour using antibodies.</p><p>Microbubbles are small manufactured spheres half the size of a red blood cell - and scientists believe they can be used to transport drugs to highly specific locations within the body. &nbsp;</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.thno.org%2Fv10p10973.htm&amp;t=MGJmMDRiZTAxMDNhY2UzMjg1MGQ3NjkwZjM3ZThjMThiNTdhZDFhNCxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607735529" title="The findings">The findings</a> are published in the journal <i><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.thno.org%2Fv10p10973.htm&amp;t=MGJmMDRiZTAxMDNhY2UzMjg1MGQ3NjkwZjM3ZThjMThiNTdhZDFhNCxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607735529">Theranostics</a></i>. </p><p>The lead authors, Drs Nicola Ingram and Laura McVeigh from the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedicinehealth.leeds.ac.uk%2Fmedicine&amp;t=YWZkNGU4MDg3NTc4Y2EwNWE3MGVmMjUwNTQwM2ZiYzc4ZGJiZDc4OCxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607735529" title="School of Medicine">School of Medicine</a>, describe how they targeted microbubbles through the use of a ‚Äònavigational aid‚Äô - antibodies attracted to the growth hormone found in high levels in the blood vessels supplying a tumour. </p><p>The antibodies were attached to the microbubbles. As a result of being attracted to the growth hormone, the microbubbles became concentrated at the site of the tumour. A pulse from an ultrasound device was used to burst open the microbubbles, and that released the anti-cancer agent. </p><p>The study was conducted on animals, which were used as a model to try and develop this technique for use in humans.</p><p>Dr Ingram said being able to deliver anticancer drugs in a very targeted fashion would be a major advance in cancer therapy. &nbsp;</p><p>She added: ‚ÄúOne of the big problems with cancer drugs is that they are highly toxic to the rest of the body too. Microbubble technology could allow us to use these very powerful drugs with precision and that reduces the risk of the drug damaging healthy cells nearby. </p><p>‚ÄúIt is about finely focused drug delivery.‚Äù </p><p>The study also revealed that by attaching the drug directly to the microbubbles allowed it to circulate in the body for longer, increasing delivery into the tumour - in effect making the drug more potent. &nbsp; </p><p>As a result, the scientists were able to slow cancer growth with a much smaller drug dose. &nbsp;</p><p>Professor Stephen Evans, head of the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmnp.leeds.ac.uk%2F&amp;t=ODZhOTk4OTRlM2VlYjZmOTk3MGJkYzg2Y2IxN2Y5MGExZjIzMjUwNyxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607735529" title="Molecular and Nanoscale Physics Group">Molecular and Nanoscale Physics Group</a> at Leeds and one of the paper‚Äôs authors, said: ‚ÄúThe results of this study are exciting because we not only show the very precise and targeted way microbubbles can be guided to cancer sites but that the efficacy of drug delivery is substantially improved, opening the way to use highly toxic drugs to fight cancer, without the harmful side effects. </p><p>‚ÄúPut simply: you get more bang for your buck.‚Äù </p><p>Watch the video where <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmicrobubbles.leeds.ac.uk%2Fabout%2F&amp;t=N2IzMGM1OTIxNzhkMTRlNTM4M2FmYTgzMDgyYmJmYTA2NTk0OWY3ZSxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607735529">Professor Evans describes the potential benefit of microbubble technology</a>. </p><p>The next stage of the research is to look at using microbubbles to develop targeted, triggered, delivery systems in patients for the diagnosis and treatment of advanced <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.cancerresearchuk.org%2Fabout-cancer%2Fbowel-cancer&amp;t=MTM2Y2FkMDNmODA4Nzk1MzdlOTc2YTA1ZWY2OTA1MGUxYjZiZmQ0MixiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607735529" title="colorectal cancer explainer">colorectal cancer</a>, the third most common cancer in the UK. &nbsp;</p><p>Co-author Professor Peter Simpson, Chief Scientific Officer at <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmd.catapult.org.uk%2F&amp;t=ZGU1MjI5OGQyMjg5MzBhNDgzZTYwZTE3Zjg5OGI2YTQwZWRhNTM0OSxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607735529" title="Medicines Discovery Catapult">Medicines Discovery Catapult</a> said: ‚ÄúComplex medicines have the potential to be the third wave of medicines, addressing patients‚Äô problems which conventionally administered small molecules and monoclonal antibodies cannot. &nbsp;</p><p>‚ÄúThis project is a very encouraging example of exploring how using an advanced drug delivery technology could improve biodistribution, targeting and efficacy of a potentially toxic therapeutic.‚Äù </p><p>This study involved a research team from the universities of Leeds, Bradford, Manchester, and the Medicines Discovery Catapult in Cheshire. The study and a follow-on study were funded by the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fepsrc.ukri.org%2F&amp;t=MzliMmQxYzljNjkxOTI3Nzg4ZWE3Y2M3OTE1OTk1NGE4MmUxOWFhYSxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607735529" title="Engineering and Physical Sciences Research Council">Engineering and Physical Sciences Research Council</a>. In addition, several PhD students are also developing microbubbles for treatment of other diseases and have been funded by University of Leeds alumni.</p><p>‚Äì</p><p><b>Source: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.leeds.ac.uk%2Fnews%2Farticle%2F4735%2Fusing_targeted_microbubbles_to_administer_toxic_cancer_drugs&amp;t=NGJkYWE0NDY2YjIzMzA1YmI3NDU5YjgzZTJkMGQ1MDc4MTc2NGE2YixiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607735529">University of Leeds</a></b></p><p><b>Full study:</b>&nbsp;‚ÄúUltrasound-triggered therapeutic microbubbles enhance the efficacy of cytotoxic drugs by increasing circulation and tumor drug accumulation and limiting bioavailability and toxicity in normal tissues‚Äù,&nbsp;<i>Theranostics</i>.</p><p>doi:<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.thno.org%2Fv10p10973.htm&amp;t=MGJmMDRiZTAxMDNhY2UzMjg1MGQ3NjkwZjM3ZThjMThiNTdhZDFhNCxiR25wbVd1cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F637052199365754880%2Fmicrobubbles-to-administer-cancer-drugs&amp;m=0&amp;ts=1607735529">10.7150/thno.49670</a></p><h2><b>Read Also</b></h2><p>A number of non-oncology drugs could potentially kill cancer cells</p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/cancer">cancer</a>
                                    
                                        <a href="https://nuadox.com/tagged/oncology">oncology</a>
                                    
                                        <a href="https://nuadox.com/tagged/medicine">medicine</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                        <a href="https://nuadox.com/tagged/pharma">pharma</a>
                                    
                                        <a href="https://nuadox.com/tagged/pharmaceuticals">pharmaceuticals</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/637052199365754880/microbubbles-to-administer-cancer-drugs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25362909</guid>
            <pubDate>Wed, 09 Dec 2020 19:09:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code Review Best Practices ‚Äì Lessons from the Trenches]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25362375">thread link</a>) | @eric_cartman
<br/>
December 9, 2020 | https://blogboard.io/blog/code-review-best-practices | <a href="https://web.archive.org/web/*/https://blogboard.io/blog/code-review-best-practices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1516259762381-22954d7d3ad2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDd8fGNvZGV8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 300w,
                            https://images.unsplash.com/photo-1516259762381-22954d7d3ad2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDd8fGNvZGV8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 600w,
                            https://images.unsplash.com/photo-1516259762381-22954d7d3ad2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDd8fGNvZGV8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 1000w,
                            https://images.unsplash.com/photo-1516259762381-22954d7d3ad2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDd8fGNvZGV8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1516259762381-22954d7d3ad2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDd8fGNvZGV8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Code Review Best Practices - Lessons from the Trenches">
            </figure>

            <section>
                <div>
                    <p>There's a ton of resources scattered around the web dealing with code review fundamentals, best practices, tools, etc. In this article we'll summarize the lessons from a dozen of official company engineering blogs. You can find links to the original articles in <a href="http://localhost:8080/blog/code-reviews"></a><a href="https://blogboard.io/search?searchQuery=code%20review">this blogboard search</a>.</p><h2 id="what-s-in-this-article">What's in this article?</h2><p>We'll cover several topics:</p><ol><li>Why do code reviews?<br>Besides the obvious, quality assurance, there are other benefits to code reviews</li><li>Code reviews as quality assurance<br>We'll cover the general recommendations on what to look for in a code review, why having a review checklist is beneficial, and you'll get a fairly long checklist that you can use as a base for your own list</li><li>Code reviews as a team improvement tool<br>If you've done more than a few code reviews, you know they're useful for more than just preventing bugs. We'll summarize common views on how reviews are beneficial as a learning and team bonding tool</li><li>Preparing a pull request for review<br>Lessons for pull request authors. There are rules of thumb consistently pointed out that help to prepare a PR for a smooth review</li><li>Reviewing code - Be human!<br>Lessons for reviewers on how wording and tone of your comments can make a huge difference in effectiveness of the whole review effort.</li></ol><p>The topics are covered fairly independently, so if you're curious about a particular topic feel free to skip ahead.</p><h2 id="why-do-code-reviews">Why do code reviews?</h2><p>It should be obvious that the primary purpose of code review is to assess quality of the changes being introduced. I mean, the dictionary definition of <em>review </em>says precisely that</p><blockquote><strong>review</strong> <em>(noun) - </em>a formal assessment of something with the intention of instituting change if necessary.</blockquote><p>Of course, code being code, there's a lot of things that can be checked and tested automatically, so there's nuance to what actually needs to be checked in an actual code review. We cover that in the next section.</p><p>On the other hand, code review is a form of communication between the <em><strong>author</strong> </em>of the change (these days usually <em>a pull request</em>) and one or several <em><strong>reviewers</strong>. </em>So it has side effects that go beyond preventing bugs from slipping in or keeping the codebase consistent in terms of style and architecture. </p><p>When done well, code reviews help accelerate learning across the team, create psychological safety for all team members, help establish and communicate best practices, teach proper communication and improve team dynamics. When done poorly, they can help deteriorate all of the above.</p><h2 id="code-reviews-as-quality-assurance">Code reviews as quality assurance </h2><p>There are a bunch of ways in which code reviews help maintain the quality bar for the codebase and the product. In the end it comes down to catching mistakes at the level which can hardly be automatically tested, such as architectural inconsistencies. Also, the code for automated tests should be reviewed, so there's a meta level at which reviews help with QA. </p><p>In <a href="https://engineering.gusto.com/high-leverage-code-reviews/">Giving High Leverage Code Reviews</a>, Casey Rollins advocates for having a checklist with all the usual things that need attention. </p><blockquote>When I‚Äôm reviewing a pull request, I often do multiple ‚Äúpasses‚Äù where I focus on one attribute at a time. I start at the beginning and review the pull request with a single attribute in mind before moving on to the next. When I‚Äôve worked through the checklist, I submit the review.<p>This checklist moves from general to specific checks because it‚Äôs important to focus on the high-level attributes first. It doesn‚Äôt make sense to offer a variable name suggestion if you‚Äôre also suggesting that an entire class or function be refactored.</p></blockquote><p>You can have your own checklist or make it a shared list for the team or a project. There's a ton of material written on the usefulness of checklists. In <em><a href="https://en.wikipedia.org/wiki/Getting_Things_Done">Getting Things Done</a>, </em>David Allen puts forward a simple idea -<em> </em>our minds are great at processing information, but terrible at storing and recalling it. That's why checklists are a great way of externally storing and breaking down a planned or repetitive task.</p><p>Compiled from several articles (<a href="https://medium.com/paypal-engineering/effective-code-reviews-53d62a203b2f">1</a>, <a href="https://engineering.gusto.com/high-leverage-code-reviews/">2</a>, <a href="https://medium.com/palantir/code-review-best-practices-19e02780015f">3</a>) here's a high-level list of things to be concerned about when reviewing a code change:</p><ul><li>Story alignment - does the change meet the requirements of the task at all; ie. does the code implement any and all of the specified functionalities?</li><li>Consistency across the codebase</li><li>Architectural considerations - how does the new piece of code fit the existing architecture. Can the new feature architecture be improved, is it too generic or not extensible enough?</li><li>Simplicity/over-engineering</li><li>Performance concerns - are there specific cases (eg. peak load times) when the code will break? Do the queries pull more data than necessary? Could new queries benefit from adding new indexes to the database?</li><li>Accidental errors such as typos or errors in math formulas - these can be either obvious or really tricky to notice, especially with math heavy code</li><li>Compliance with laws and regulations - depending on the business this might be the most important thing</li><li>Security concerns - are there any exploitable pieces of code being introduced? Are any secrets being shared or stored unsafely?</li><li>Readability and style - a seemingly perfect piece of code might not be immediately understandable and readable to a different pair of eyes. Is it possible to understand the changes without the author explaining them?</li><li>Best practices - programming languages usually have their best practices - are they met in the pull request? Also, with time any project, team and company will evolve their own set of best practices - code reviews are a way to enforce and spread knowledge about them</li><li>Localization - are all language dependent resources localized properly?</li><li>Dependencies - are there external libraries or APIs being introduced? Are there other simpler/faster/better ways to do this with different dependencies or without any?</li><li>Interactions and side effects - how does the new piece of code interact with the rest of the codebase; does the new function implementation break any existing functionality; are all relevant unit tests updated/added</li><li>Logging - it's practically impossible to debug server code properly without good logging. Is everything logged/traced correctly</li><li>Error handling - how are the errors handled on the backend; how are they communicated to the user; are fallbacks activated where possible?</li><li>Testability/Test coverage - is the new piece of code covered with automated tests? Have all the suspicious test cases been checked either automatically or manually? Is the code written in a way that's suitable for unit testing?</li><li>External documentation - in case it's necessary is the external documentation updated to reflect the change?</li></ul><p>It's a pretty long list. In addition to it, a recurring piece of advice is not to use code reviews in place of static code analysis tools. If your review is mostly about code formatting, variable naming and alphabetical ordering, it might be a good time to include an automated code analysis tool into your development workflow.</p><p>In <em><a href="https://medium.com/paypal-engineering/effective-code-reviews-53d62a203b2f">Effective Code Reviews: Bettering Products, Teams, and Engineers</a> </em>from PayPal engineering<em>, </em>Gabriel McAdams points out several important benefits of code reviews related to team dynamics:</p><ul><li>Team cohesion - by making everyone's code subject to peer review, code review process promotes <em>individual accountability, healthy conflict</em> and the idea that everyone's<em> working together</em> to make the product better. As said in <a href="https://medium.com/palantir/code-review-best-practices-19e02780015f">Code Review Best Practices</a>: <em>Code reviews are classless: being the most senior person on the team does not imply that your code does not need review.</em><br>In summary, McAdams puts it nicely: <em>Trust + healthy conflict + individual accountability + working together to better the team = team cohesion.</em></li><li>Free career improvement training - simply by virtue of reviewing other people's code you become more skilled at reading and understanding new code. I've heard it said that one of the foremost traits of great engineers is the ability to dive into and dissect a completely unfamiliar piece of code. Over time you learn how to spot common practices, little tricks, pieces of syntactic sugar, architectural abstractions and how to appreciate different mental models used to solve the same problem.</li></ul><p>In <a href="https://medium.com/palantir/code-review-best-practices-19e02780015f">Code Review Best Practices</a> from the Palantir Blog, Robert Fink lists several ways in which knowledge sharing and social side-effects happen via code reviews:</p><ul><li>Authors are motivated by the peer review process to do all the necessary pre-checks, tighten the loose ends and generally tidy up the code before sending to review</li><li>A code review explicitly communicates changes made to product functionality to team members</li><li>The author maybe used a technique, abstraction or an algorithm that reviewers are unfamiliar with. The opposite can also be the case - reviewers might be aware of a more appropriate way to solve a given problem</li><li>Positive communication strengthens social bonds within the team (might especially be true for remote teams)</li></ul><h2 id="preparing-a-pull-request-for-review-help-the-reviewer">Preparing a pull request for review - help the reviewer</h2><p>Code reviews should be seen as a team effort. Once you view them that way it becomes clear that both sides - the author and the reviewers - have their distinct sets of responsibilities.</p><p>In <a href="https://medium.engineering/the-code-review-mindset-3280a4af0a89">this short post</a> on Medium Engineering blog, Xiao Ma describes how a different perspective changes the way code reviews are done, how feedback is taken and how people on each side benefit by adopting a <em>positive mindset</em> about code reviews.</p><p>When we talk about the responsibilities of the pull request author, there are several key things recurring in all code review guides.</p><ol><li><strong>Make pull requests as atomic as possible</strong><br><a href="https://shopify.engineering/great-code-reviews">At Shopify</a> they advise to keep <em>your pull requests small </em>- it helps the reviewer dive into it and finish it as an atomic piece of work in their workday. In practice this can mean keeping your pull requests limited to <em>a single concern. </em>A single concern here means a single bug fix, a feature, an API change etc. Don't mix refactoring that doesn't alter behavior with bug fixes or new features. This is ‚Ä¶</li></ol></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blogboard.io/blog/code-review-best-practices">https://blogboard.io/blog/code-review-best-practices</a></em></p>]]>
            </description>
            <link>https://blogboard.io/blog/code-review-best-practices</link>
            <guid isPermaLink="false">hacker-news-small-sites-25362375</guid>
            <pubDate>Wed, 09 Dec 2020 18:45:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Marketing Tips for People with No Friends]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25362292">thread link</a>) | @kjcharles
<br/>
December 9, 2020 | http://keenen.xyz/marketing-for-people-with-no-friends/ | <a href="https://web.archive.org/web/*/http://keenen.xyz/marketing-for-people-with-no-friends/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>When you're just getting started building your own projects marketing seems like a daunting task, especially if your background is in development. You spend some time learning what you can about marketing but a lot of advice relies on utilising your "network".</p><p>That assumes you have a network.</p><p>If you're like me and few of your friends are interested in the products you build, that advice is completely useless.</p><p>Next, they'll suggest you reach out to your wider network and get their support in sharing your project. You'll read articles on "how I got 1000 signups for my product in two weeks" that fail to mention their 5000 followers on Twitter.</p><p>What I've learnt is that you have to look past these tips and focus on scalable and automated methods of growth when you're friendless. Is it harder? Definitely. Does it take a lot longer? 100%. Will you look on enviously as others with networks instantly launch to thousands of signups and acclaim? Absolutely.</p><p>But there is a bright side. Scalable methods are sustainable. They have long-term value while a large network can provide a false indicator of success. If your product is solving a real problem you'll get more rewards from focusing on sustainable methods of growth early on.</p><p>For every new project, I focus on creating small but steady streams of traffic and optimising how I capture that traffic for long-term growth.</p><h3 id="1-seo">1. SEO</h3><p>The first step is setting up your product pages or landing page perfectly for SEO. This means meta tags, titles with keywords, sub-pages that target niche keywords, and so on. You can find specific tips on this everywhere and if you're building a directory site <a href="http://keenen.xyz/seo-tips-for-online-directories/">these tips</a> might be even more helpful.</p><h3 id="2-submit-to-aggregators">2. Submit to Aggregators </h3><p>Next, you want to submit your project to aggregation sites to drive some traffic to your page. Product Hunt, Reddit, Hacker News, etc are all great for this. Submit to as many as you can and let the traffic flow in. Chances are without a network your project won't be number one on any of these sites but you're likely to get a decent bit of traffic and some initial users. Check out this <a href="https://github.com/mmccaff/PlacesToPostYourStartup">comprehensive list here</a>.</p><p>It's also a great way for getting backlinks that will compound the effect of the initial SEO work you did. I try to submit to as many startup directories and Product Hunt clones as I find and hope they use dofollow links. If you get a backlink great. If they don't but you get some traffic that's fine too. If you get nothing ü§∑‚Äç‚ôÄÔ∏è, it was free anyway (you definitely shouldn't pay to be listed on the majority of those sites, it's not worth it).</p><h3 id="3-email-signups">3. Email signups</h3><p>Whatever you're doing you should be collecting emails in some form. You want to be able to communicate with users of your product even if you don't require signup to use it. Create an account on Mailchimp or some other email service provider, embed a signup form on your page, and you're sure to get some signups.</p><p>As traffic trickles in from aggregators and SEO you'll begin to capture some emails. Once you do have a handful of signups you can start sharing regular updates with them. Chances are some of them will be drawn back to your product with each issue you send.</p><h3 id="4-reuse-content">4. Reuse Content</h3><p>If your product generates content you should find some way to share it on social media. Preferably in an automated way. Add relevant hashtags to each post and they can drive another bit of traffic to your product. With InboxReads I share every new submission to its' Twitter &amp; Facebook accounts and that results in a steady stream of traffic.</p><p>Emails you send can also be reused for future traffic. When picking an email service provider I would find one that creates indexable blog posts from each email you send. This means each issue becomes a piece of content that links back to your main product.</p><h3 id="5-optimize-repeat">5. Optimize &amp; Repeat</h3><p>Chances are you won't get everything right the first time. You might have misconfigured some meta tags or your social media work is just not getting any attention. It's important to be constantly analysing your results and testing new ideas to improve these steps. As you better understand your audience you'll be able to finetune this process to capture even more traffic.</p><p>These steps aren't likely to make you instantly rich or famous. You shouldn't expect a profile in TechCrunch or an influx of new followers. But they can give you a small but reliable and organic stream of traffic that lets you determine your product's viability. If it is viable then you would have invested time into sustainable and scalable marketing methods from the beginning. </p><p>And maybe you'll make some friends along the way.</p>
                </div>
            </section></div>]]>
            </description>
            <link>http://keenen.xyz/marketing-for-people-with-no-friends/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25362292</guid>
            <pubDate>Wed, 09 Dec 2020 18:41:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New York Times Best Seller Business Book]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25361439">thread link</a>) | @dubeyaayush07
<br/>
December 9, 2020 | https://dubeyaayush07.github.io/deliberate-mistakes/new-york-times-best-seller-business-book/ | <a href="https://web.archive.org/web/*/https://dubeyaayush07.github.io/deliberate-mistakes/new-york-times-best-seller-business-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p>December 08, 2020</p></header><section itemprop="articleBody"><h3>Oversimplified, Overgeneralized Rules to Make <del>Me</del> You Rich</h3>
<ul>
<li>It is good to be a contrarian but do you know what is even better? To be a contrarian contrarian and since according to an unrelated mathematical rule inverse of an inverse is equal to the same thing you should do what everyone is doing, that is buying my book.</li>
<li>Steve Jobs, Elon musk.</li>
<li><strong>PASSION</strong>, Do what you want, Quit your Job.</li>
<li>Case studies of why I am right based on misinterpretations of what really happened.</li>
<li>Correlation == Causation.</li>
<li>Cliched  general advice: Exercise, Brush Your teeth before bed, work hard to succeed, clean your room, etc.</li>
<li>Filler                 </li>
<li>Confirmation Bias, Anecdotal evidence.</li>
<li>Graphs, Plots(Who needs axes and scales), Math is on my side.</li>
<li>Random Philosophy detour which has nothing to do with my thesis</li>
<li>Arguments that look logical on paper but are just superficial overgeneralizations  targeted towards inexperienced individuals.</li>
<li>My life and how I applied these principles to get rich. People disagreed with me. I succeeded and now I am rich.</li>
</ul>
<hr>
<p>I wrote this post as a result of my frustration with popular business books and with non-fiction books in general. I am not saying every book is like this, some books are insightful and bring new ideas and perspectives to the table. But I have noticed that some authors have an idea and without fleshing it out and properly researching it they decide to write a book about it. Throw in cognitive dissonance, confirmation bias and an incompetent publishers and you have got yourself a popular non-fiction book. There is no peer review and if you sensationalize things you can earn a lot of money. </p>
<p>You cannot even trust books by experts in the field. I bought into the hype of the book Why We Sleep  by Matthew Walker the author seemed legit and well respected within his field. He even appeared on the Joe Rogan Experience. After reading the book I  began espousing the benefits of 8 hour sleep until I read <a href="https://guzey.com/books/why-we-sleep/">this</a> wonderful article by Alexey Guzey. So who should you trust? Should you stop reading non-fiction altogether? I suggest doing the opposite, read as much as you can and be wary of any broad sweeping statements. Even though some books might get something wrong, the good ideas are still valuable. And as with business you can only get better at it (i.e. filtering signal) by exposing yourself to more of it.</p></section><hr></article></div>]]>
            </description>
            <link>https://dubeyaayush07.github.io/deliberate-mistakes/new-york-times-best-seller-business-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25361439</guid>
            <pubDate>Wed, 09 Dec 2020 17:57:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Health Canada approves Pfizer Covid-19 vaccine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25361431">thread link</a>) | @vhodges
<br/>
December 9, 2020 | https://www.cbc.ca/news/politics/vaccine-rollout-plan-phac-1.5833912 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/vaccine-rollout-plan-phac-1.5833912">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The federal government has given the green light to the Pfizer-BioNTech's COVID-19 vaccine, a key step toward launching the largest inoculation campaign in Canada's history.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5826792.1607723934!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/health-coronavirus-britain-vaccine.JPG"></p></div><figcaption>A person in Mainz, Germany gets a dose of the Pfizer/BioNTech vaccine as part of the product's clinical trial.<!-- --> <!-- -->(Reuters)</figcaption></figure><p><span><p>The federal government has given the green light to the Pfizer-BioNTech's COVID-19 vaccine, a key step toward launching the largest inoculation campaign in Canada's history.</p>  <p>Health Canada&nbsp;announced the approval Wednesday after scientists finished a two-month review of the company's clinical trial data.</p>  <p>"The data provided supports favourably the efficacy of Pfizer-BioNTech COVID-19 vaccine as well as its safety," the department said in its report authorizing&nbsp;use of the vaccine&nbsp;in Canada for people over the age of 16.</p>  <p>"The efficacy of the vaccine was established to be approximately 95 per cent. The vaccine was well tolerated by participants and has no important safety concerns. The benefit-to-risk assessment for Pfizer-BioNTech COVID-19 vaccine is considered favourable."</p>  <p>Canada is just the third country in the world to authorize the vaccine, after the United Kingdom and Bahrain. The U.S. Food and Drug Administration will hear tomorrow from an advisory panel on whether the vaccine is safe for use in the United States and&nbsp;authorization&nbsp;is&nbsp;expected in "a matter of days," U.S. Health Secretary Alex Azar said Wednesday.</p>  <p>Dr. Howard Njoo, Canada's deputy chief public health officer, said&nbsp;249,000 doses of the two-dose Pfizer vaccine will be on hand by year's end ‚Äî shots primarily earmarked&nbsp;for long-term care home residents and the staff working there.</p>  <p>Maj.-Gen. Dany Fortin, the military commander leading vaccination logistics at the national operations centre,&nbsp;said 30,000 doses out of the&nbsp;initial run&nbsp;will be shipped from a Pfizer plant in Belgium on Friday.</p>  <p>"We expect&nbsp;vaccines to arrive as early as Monday," Fortin&nbsp;said, adding it's "totally possible" some&nbsp;Canadians could get their&nbsp;shots&nbsp;by mid-week.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5834779.1607545281!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/covid-cda-vaccine-20201209.jpg 300w,https://i.cbc.ca/1.5834779.1607545281!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/covid-cda-vaccine-20201209.jpg 460w,https://i.cbc.ca/1.5834779.1607545281!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/covid-cda-vaccine-20201209.jpg 620w,https://i.cbc.ca/1.5834779.1607545281!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/covid-cda-vaccine-20201209.jpg 780w,https://i.cbc.ca/1.5834779.1607545281!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/covid-cda-vaccine-20201209.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5834779.1607545281!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/covid-cda-vaccine-20201209.jpg"></p></div><figcaption>Maj.-Gen. Dany Fortin, left, said some Pfizer COVID-19 vaccine doses could arrive as early as Monday.<!-- --> <!-- -->(Adrian Wyld/Canadian Press)</figcaption></figure></span></p>  <p>Njoo said as many as six million doses will arrive&nbsp;in the first three months of 2021. Assuming other&nbsp;promising vaccine candidates from companies like Moderna and AstraZeneca secure regulatory approvals, millions more shots will come online in the months to follow, he said.</p>  <p>The Public Health Agency of Canada (PHAC) said today the country will begin immunizing non-priority populations ‚Äî people other than the elderly, health care workers and some adults in Indigenous communities ‚Äî&nbsp;in April 2021. The vaccination campaign is expected to end next December.</p>  <p>"At last, we have a reason to feel optimistic and excited about returning to the lives we led pre-COVID," Njoo said. "Things are happening quickly."</p>  <p>Speaking in question period today, Prime Minister Justin Trudeau called the Pfizer-BioNTech approval a "big deal" because it signals that the end of this destructive pandemic is in sight.</p>  <p>"It's a good news day for Canadians but we are not through this yet. We have a tough winter to go through," Trudeau said, urging Canadians to respect public health measures&nbsp;even as shots start to arrive.</p>  <h2>Long-term care homes to be among first to get vaccine</h2>  <p>The Pfizer trial had&nbsp;more than 43,000 participants ‚Äî one of the largest such trials ever conducted ‚Äî and regulators found that the vaccine's efficacy was consistent across age, gender, race and ethnicity demographics.</p>  <p>The vaccine is&nbsp;based on&nbsp;groundbreaking&nbsp;messenger RNA technology, or mRNA, which essentially directs cells in the body to make proteins to prevent or fight disease.</p>  <p>The shot was found to be 94.7 per cent effective among clinical&nbsp;trial subjects who were over the age of 65 and who had no prior COVID-19 infection ‚Äî a significant finding, given most&nbsp;novel coronavirus-related deaths in Canada have been reported among the elderly.</p>    <p>While the&nbsp;Pfizer vaccine has been given the necessary approvals, regulators conceded that the clinical&nbsp;trial data could not establish&nbsp;the long-term efficacy of the vaccine.</p>  <p>It is not yet known how long the vaccine-induced immunity will last but Health Canada said it will implement a robust "risk management plan"&nbsp;to monitor immunity and gather data on when it begins to wane. The regulator will also track any&nbsp;"adverse events" that follow immunization.</p>  <p>Cole Pinnow, the president of Pfizer Canada, said Health Canada's approval means the country can start to return to a sense of "normalcy," with&nbsp;millions of Canadians&nbsp;set to be vaccinated over the coming months.</p>  <p>"This is historic. We couldn't be more proud that Pfizer and BioNTech were able to bring to Canada the first COVID-19 vaccine. We think this represents a monumental change in the way that we are fighting the pandemic, and hopefully represents the first big step towards normalcy," Pinnow said in an interview with CBC Radio's&nbsp;<em>The Current</em>.</p>  <p>With recent polls showing that a sizeable number of Canadians will refuse a vaccine altogether, or will wait some time before lining up for a shot, Pinnow said he wants Canadians to be assured the product is safe.</p>  <p>"I would reassure Canadians that the scientific rigour and regulatory oversight that went into this product is as robust, if not more robust, than any other vaccine that's been brought to market," he said.</p>  <p><em><strong>WATCH: Pfizer addresses vaccine concerns:</strong></em></p>  <p><span><span><div><div title="Dr. Sharma calls the approval of the Pfizer vaccine a 'critical milestone' in the fight against COVID-19." role="button" tabindex="0"><div><div aria-labelledby="1829647939789-metadata-" title="Dr. Sharma calls the approval of the Pfizer vaccine a 'critical milestone' in the fight against COVID-19."><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/1017/255/ftr_SHARMA_approval_frame_3575_corrected.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Health Canada chief medical adviser Dr. Supriya Sharma briefed reporters on the vaccine's approval during a briefing on Wednesday.<!-- --> <!-- -->2:19</span></span></span></p>  <p>Dr. Supriya Sharma, the chief medical adviser at Health Canada, also sought to reassure Canadians that her department conducted a "rigorous" review of all the product's&nbsp;clinical trial and technical information.</p>  <p>She said&nbsp;scientists&nbsp;found "strong evidence"&nbsp;that the vaccine's potential benefits far outweigh any risks.</p>  <p>"Canadians can have confidence ... the vaccine was authorized only after a thorough assessment of the evidence demonstrated it had met Health Canada's strict standards for efficacy, safety and quality," she said.</p>  <p>"It's an exceptional day for Canada. In a year when we haven't had a lot of good news, this is a bit of good news and we should acknowledge that."</p>  <p><em><strong>WATCH: Health Canada calls Pfizer approval a 'critical milestone' in fight against COVID-19:</strong></em></p>  <p><span><span><div><div title="Pfizer Canada addresses concerns over Bell's palsy in U.S. vaccine trials" role="button" tabindex="0"><div><div aria-labelledby="1829670467550-metadata-" title="Pfizer Canada addresses concerns over Bell's palsy in U.S. vaccine trials"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/14/750/CP2459909.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Pfizer Canada president Cole Pinnow said the four occurrences of facial paralysis among close to 22,000 subjects in U.S. clinical trials who received the Pfizer-BioNTech COVID-19 vaccine represented a frequency not above what is expected in the general population.<!-- --> <!-- -->0:18</span></span></span></p>  <p>British regulators warned Wednesday that people who have a history of serious allergic reactions shouldn't receive the new Pfizer vaccine as they investigate two adverse reactions that occurred on the&nbsp;first day of the country's mass vaccination program.</p>  <p>Asked about those warnings, Sharma said Canada is in&nbsp;constant communication with British authorities.</p>  <p>"We are always on the lookout for more serious adverse events," she said. "It is still a vaccine and there are potential risks even if they are rare. That's why it's important that we still continue to monitor it.</p>  <p>"Because these vaccines will be used in otherwise healthy people ... our tolerance for safety issues is very, very low."</p>  <p><em><strong>WATCH: Health Canada discusses allergic reactions to the Pfizer vaccine:</strong></em></p>  <p><span><span><div><div title="Dr. Sharma discusses allergic reactions to Pfizer's&nbsp;vaccine and how it was approved" role="button" tabindex="0"><div><div aria-labelledby="1829669443969-metadata-" title="Dr. Sharma discusses allergic reactions to Pfizer's&nbsp;vaccine and how it was approved"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/13/775/ftr_SHARMA_how_it_was_approved_frame_1960_corrected.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Health Canada chief medical adviser Dr. Supriya Sharma briefed reporters on the vaccine's approval during a briefing on Wednesday.<!-- --> <!-- -->2:38</span></span></span></p>  <p>Sharma said Health Canada is recommending individuals with allergies to any of the vaccine's components avoid the shot.</p>  <p>Sharma noted that there were few serious medical incidents&nbsp;reported among the 43,000 clinical trial participants. The most common side effects were soreness at the site of injection, joint pain and fatigue, she said.</p>  <h2>Inoculation to take months</h2>  <p>Canada is expected to take delivery of vaccines produced in Puurs, a small town in the north of Belgium&nbsp;that will be churning out hundreds of millions of doses of the co-developed Pfizer-BioNTech&nbsp;vaccine for the European Union, Canada, Japan and the United Kingdom over the next 12 months.</p>  <p>Maj.-Gen.&nbsp;Fortin&nbsp;has been leading a series of dry-runs with the provinces and territories to ensure they are prepared to distribute the extremely heat-sensitive Pfizer shot, which must be stored at temperatures between ‚Äì80 C and ‚Äì60 C.</p>  <p>Because the Pfizer product is so temperature-sensitive, Pfizer is shipping it directly from its plants to 14 points of use throughout Canada to limit movement and keep the vaccine stable.</p>  <p><strong><em>WATCH | Canada approves 1st COVID-19 vaccine for Pfizer-BioNTech:</em></strong></p>  <p><span><span><div><div title="Canada approves 1st COVID-19 vaccine from Pfizer-BioNTech" role="button" tabindex="0"><div><div aria-labelledby="1829907523663-metadata-" title="Canada approves 1st COVID-19 vaccine from Pfizer-BioNTech"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/240/827/covid-pfizer-approved-cochrane-091220.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Health Canada has approved the first COVID-19 vaccine for Canadians. Priority populations could start getting the Pfizer-BioNTech vaccine as early as next week, with rollout for the general population slated tentatively for the spring.<!-- --> <!-- -->2:35</span></span></span></p>  <p>Those sites&nbsp;have the necessary cold storage in place and are ready for the "imminent arrival" of the shots, Fortin said.&nbsp;</p>  <p>"We're undertaking a mobilization effort of massive proportions.&nbsp;Never in modern memory have we seen such an unprecedented level of collaboration and cooperation," he said. "It&nbsp;really makes me proud to be a Canadian and proud to serve."</p>  <p>The vaccines will be distributed to jurisdictions on a per-capita basis, meaning each province&nbsp;will receive&nbsp;vaccine doses&nbsp;in numbers&nbsp;proportionate&nbsp;to its share of the population.&nbsp;The vaccine will not be sent&nbsp;to&nbsp;the territories for the time being&nbsp;as they now lack&nbsp;the capacity to safely store the Pfizer product.</p>  <p>While the exact location of each of the 14 distribution centres has not yet been disclosed, some provinces, including Newfoundland &amp; Labrador, have said the Pfizer vaccine will be stored at major hospitals in urban areas.</p>  <p>The national advisory committee on immunization (NACI) said last week the limited&nbsp;initial&nbsp;quantity of doses should be reserved for people who are most at risk of contracting ‚Ä¶</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cbc.ca/news/politics/vaccine-rollout-plan-phac-1.5833912">https://www.cbc.ca/news/politics/vaccine-rollout-plan-phac-1.5833912</a></em></p>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/vaccine-rollout-plan-phac-1.5833912</link>
            <guid isPermaLink="false">hacker-news-small-sites-25361431</guid>
            <pubDate>Wed, 09 Dec 2020 17:56:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualising Co-Occurring Pok√©mon Types with Chord Diagrams]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25361381">thread link</a>) | @DataCrayon
<br/>
December 9, 2020 | https://datacrayon.com/posts/statistics/data-is-beautiful/co-occurring-pokemon-types/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/statistics/data-is-beautiful/co-occurring-pokemon-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
            <div>
                <div>
                <div>
                    <h2>Data is Beautiful</h2>
                    <p>
                    A practical book on data visualisation that shows you how to
                    create static and interactive visualisations that are engaging and
                    beautiful.
                    </p>
                    <p><a href="https://datacrayon.com/shop/product/data-is-beautiful/">Get the book</a>
                </p></div>
                <p><img src="https://datacrayon.com/images/datacrayon/shop/covertop_dib.jpg">
</p>
                </div>
            </div>
            </div>
        </div><div itemprop="articleBody text">
    <!--% if post.meta('has_toc'):-->
    

        

        
            

            
<div id="support-this-work-top">
                                <p>Made with Chord Pro</p>
                                <p>
                        You can create beautiful interactive visualisations like this one with <a href="https://datacrayon.com/shop/product/chord-pro/">Chord Pro</a>. Learn how to make beautiful visualisations with the book, <a href="https://datacrayon.com/shop/product/data-is-beautiful/">Data is Beautiful</a>.</p>
                            </div>

            

    


                    <div id="support-this-work-bottom">
                                    <p>Made with Chord Pro</p>
                                    <p>
        You can create beautiful interactive visualisations like this one with <a href="https://datacrayon.com/shop/product/chord-pro/">Chord Pro</a>. Learn how to make beautiful visualisations with the book, <a href="https://datacrayon.com/shop/product/data-is-beautiful/">Data is Beautiful</a>.
        </p>
                                </div>
                            </div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/statistics/data-is-beautiful/co-occurring-pokemon-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25361381</guid>
            <pubDate>Wed, 09 Dec 2020 17:52:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Install and Compress Videos Using Handbrake ‚Äì A Step-by-Step Guide]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25361189">thread link</a>) | @ponderingfish
<br/>
December 9, 2020 | https://ottverse.com/install-and-compress-videos-using-handbrake/ | <a href="https://web.archive.org/web/*/https://ottverse.com/install-and-compress-videos-using-handbrake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

		<div>

		

	<div id="primary">

		
					<main id="main">

				
					
					

<article id="post-3018" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

		
	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>Handbrake is an open-source video transcoder that‚Äôs widely regarded as the best tool for video conversion. It‚Äôs effortless to use, multi-platform, and it covers a vast range of presets and devices as well. This means you will find it easier than ever to compress videos quickly without having to spend money on a conversion or transcoding tool. Instead, you can compress video using Handbrake very quickly, and the results will be great.</p>



<h2>Download and Install Handbrake on Windows</h2>



<p>The application is available free of charge at <a href="https://handbrake.fr/" target="_blank" rel="noopener">https://handbrake.fr/</a>, all you have to do is to visit the site and then select the platform you need the app for. They have multiple versions, including Mac, Windows, or Linux. In addition, you can access nightly builds and a command-line version too. </p>



<div><figure><img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=876%2C362&amp;ssl=1" alt="install handbrake on windows" width="876" height="362" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=1024%2C423&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=1200%2C496&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?w=1340&amp;ssl=1 1340w" sizes="(max-width: 876px) 100vw, 876px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20876%20362'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=1024%2C423&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=1200%2C496&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?w=1340&amp;ssl=1 1340w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-4.png?resize=876%2C362&amp;ssl=1"></figure></div>







<p>Begin the installation procedure by opening the <code>exe</code> file from the Download location. You should see a screen as follows ‚Äì </p>



<div><figure><img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-6.png?resize=494%2C406&amp;ssl=1" alt="install handbrake on windows" width="494" height="406" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-6.png?w=581&amp;ssl=1 581w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-6.png?resize=300%2C246&amp;ssl=1 300w" sizes="(max-width: 494px) 100vw, 494px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20494%20406'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-6.png?w=581&amp;ssl=1 581w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-6.png?resize=300%2C246&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-6.png?resize=494%2C406&amp;ssl=1"></figure></div>



<p>Agree to the License Terms and Conditions and hit ‚ÄúNext‚Äù.</p>



<div><figure><img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-8.png?resize=490%2C402&amp;ssl=1" alt="install handbrake on windows" width="490" height="402" srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-8.png?w=581&amp;ssl=1 581w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-8.png?resize=300%2C246&amp;ssl=1 300w" sizes="(max-width: 490px) 100vw, 490px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20490%20402'%3E%3C/svg%3E" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-8.png?w=581&amp;ssl=1 581w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-8.png?resize=300%2C246&amp;ssl=1 300w" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-8.png?resize=490%2C402&amp;ssl=1"></figure></div>







<p>Choose an installation location and hit ‚ÄúNext‚Äù. </p>



<div><figure><img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-9.png?resize=489%2C402&amp;ssl=1" alt="install handbrake on windows" width="489" height="402" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-9.png?w=581&amp;ssl=1 581w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-9.png?resize=300%2C246&amp;ssl=1 300w" sizes="(max-width: 489px) 100vw, 489px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20489%20402'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-9.png?w=581&amp;ssl=1 581w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-9.png?resize=300%2C246&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-9.png?resize=489%2C402&amp;ssl=1"></figure></div>



<p> And, that‚Äôs it. Handbrake should be installed on your Windows computer. </p>



<div><figure><img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-12.png?resize=498%2C408&amp;ssl=1" alt="install handbrake on windows" width="498" height="408" srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-12.png?w=581&amp;ssl=1 581w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-12.png?resize=300%2C246&amp;ssl=1 300w" sizes="(max-width: 498px) 100vw, 498px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20498%20408'%3E%3C/svg%3E" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-12.png?w=581&amp;ssl=1 581w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-12.png?resize=300%2C246&amp;ssl=1 300w" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/image-12.png?resize=498%2C408&amp;ssl=1"></figure></div>











<h2>Select the source file and open it</h2>



<p>Once you finish installing the app, open it.</p>



<p>Go to the left side of the app, choose the Source Selection and then flick File. Then you can choose the file you want to compress and click Open. Once the file is loaded, you can choose where to save it simply by clicking Browse. Make sure that you create a name for the video so you can identify it with ease. Add whatever name you are comfortable with, and then press Save.</p>



<div><figure><img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=843%2C539&amp;ssl=1" alt="compress video using handbrake" width="843" height="539" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=1024%2C656&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=300%2C192&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=768%2C492&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=1200%2C768&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?w=1257&amp;ssl=1 1257w" sizes="(max-width: 843px) 100vw, 843px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20843%20539'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=1024%2C656&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=300%2C192&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=768%2C492&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=1200%2C768&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?w=1257&amp;ssl=1 1257w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-13.png?resize=843%2C539&amp;ssl=1"></figure></div>



<h2>Picking the container type and video codec</h2>



<p>Right under the output settings, you can select the container. Ideally, you want to go with the <code>MP4</code> container format, unless you have any specific containers in mind. Under that you have the Video tab, here you want to select the H.264 codec.</p>



<div><figure><img width="1024" height="656" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=1024%2C656&amp;ssl=1" alt="compress video using handbrake" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=1024%2C656&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=300%2C192&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=768%2C492&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=1200%2C768&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?w=1257&amp;ssl=1 1257w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20656'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=1024%2C656&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=300%2C192&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=768%2C492&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=1200%2C768&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?w=1257&amp;ssl=1 1257w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-14.png?resize=1024%2C656&amp;ssl=1"></figure></div>



<p>Here you can also select the desired framerate and quality types. The app has options for different video qualities, such as web, HD, and so on. Or you can go with an average bitrate instead of a certain quality. The framerate can be <code>30</code> FPS or more. It all depends on the initial framerate of your video. Most of the time, settling for <code>30</code> FPS will do just fine.</p>



<h2>Selecting a preset</h2>



<p>One of the main benefits of Handbrake is that it has a vast range of presets. You can browse the list of presets on the right side of the user interface. </p>



<div><figure><img width="1024" height="656" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=1024%2C656&amp;ssl=1" alt="compress video using handbrake" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=1024%2C656&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=300%2C192&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=768%2C492&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?w=1032&amp;ssl=1 1032w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20656'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=1024%2C656&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=300%2C192&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=768%2C492&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?w=1032&amp;ssl=1 1032w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-16.png?resize=1024%2C656&amp;ssl=1"></figure></div>



<p>Normally you can go for <code>Fast 1080p 30</code>, as this is of great quality. But you can easily experiment with a variety of presets and see how the results turn out in the end. The average bitrate for a video should be anywhere from <code>5000</code> to <code>10000</code> kbps. Normally the higher the bitrate is, the better the video quality, but this will take a longer time to process and upload.</p>



<h2>Modifying the resolution and picture options</h2>



<p>In the Dimensions panel, you can see the source resolution and you can keep that or choose whatever resolution you find ok. Here you can also change the Anamorphic mode to None. Ideally, you want to have the modulus option to <code>16</code>. A good rule of thumb is to maintain the aspect ratio, you can do that simply by ticking the option with the same name right near the picture size.</p>



<div><figure><img width="1024" height="656" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=1024%2C656&amp;ssl=1" alt="compress video using handbrake" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=1024%2C656&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=300%2C192&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=768%2C492&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=1200%2C768&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?w=1257&amp;ssl=1 1257w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20656'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=1024%2C656&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=300%2C192&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=768%2C492&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=1200%2C768&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?w=1257&amp;ssl=1 1257w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/image-18.png?resize=1024%2C656&amp;ssl=1"></figure></div>



<h2>Modifying audio information</h2>



<p>Go to the Audio tab, here you can modify the sample rate and other options the way you want. A lot of people use <code>48</code> or <code>64</code> kbps as the ideal sample rate, and the mixdown is Stereo. You can also change the audio codec, not to mention you can modify the bitrate. You may want to stick with a <code>320</code> bitrate, as it delivers the best quality.</p>



<div><figure><img width="1024" height="656" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=1024%2C656&amp;ssl=1" alt="compress video using handbrake" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=1024%2C656&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=300%2C192&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=768%2C492&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=1200%2C768&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?w=1257&amp;ssl=1 1257w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20656'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=1024%2C656&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=300%2C192&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=768%2C492&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=1200%2C768&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?w=1257&amp;ssl=1 1257w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/image-20.png?resize=1024%2C656&amp;ssl=1"></figure></div>



<h2>Start the encoding process</h2>



<p>Once you fully customized everything, you want to press the Start Encode button. Then you can leave or do something else, as Handbrake will work on the video compression. </p>



<p>You will receive a notification when everything is fully completed.</p>



<h2>Conclusion</h2>



<p>Compressing any video using Handbrake helps a lot, and this free tool does bring in front incredible results. It does take a bit to get used to the interface, but with a little experimentation, you will have no problems. We recommend you to give Handbrake a try today, and you will be incredibly impressed with its ease of use and incredible compression quality!</p>

<!-- MOLONGUI AUTHORSHIP PLUGIN 4.2.11 -->
<!-- https://www.molongui.com/authorship/ -->

<div id="mab-2795617984" data-plugin-release="4.2.11" data-plugin-version="free" data-box-layout="slim" data-box-position="below" data-multiauthor="false" data-author-type="user" itemscope="" itemtype="https://schema.org/Person">

	
    <!-- Author headline -->
    <p>
        <h3>
            <span>About The Author</span>
        </h3>
    </p>

    <div>

        <div data-profile-layout="layout-1" data-author-ref="user-194568617">
            
<!-- End of .m-a-box-content-top -->

<div>

    <!-- Author picture -->
    
	<p><a href="https://ottverse.com/author/vkr2020/">
                    <img alt="" src="https://secure.gravatar.com/avatar/1b73140b34f836d184d53fbb00f406dd?s=150&amp;d=mp&amp;r=g" srcset="https://secure.gravatar.com/avatar/1b73140b34f836d184d53fbb00f406dd?s=300&amp;d=mp&amp;r=g 2x" height="150" width="150" itemprop="image" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">                </a>
                	</p>

    <!-- Author social -->
    
    <!-- Author data -->
    <div>

        <!-- Author name -->
        

        <!-- Author metadata -->
        

        <!-- Author bio -->
        
<div itemprop="description">
	<p>I‚Äôm Dr. Krishna Rao Vijayanagar, and I am the Founder and Editor of OTTVerse.com. I've spent several years working hands-on with Video Codecs (AVC, HEVC, MultiView Plus Depth), ABR streaming, and Video Analytics (QoE, Content &amp; Audience, and Ad). I hope to use my experience and love for video streaming to bring you information and insights into the OTT universe. Please use the Contact Page to get in touch with me.</p>
</div>

        
            <!-- Author related posts -->
            <!-- End of .m-a-box-related -->

        
    </div><!-- End of .m-a-box-data -->

</div><!-- End of .m-a-box-content-middle -->

<!-- End of .m-a-box-content-bottom -->        </div><!-- End of .m-a-box-profile -->

        
    </div><!-- End of .m-a-box-container -->

	
</div><!-- End of .m-a-box -->

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article><!-- #post-## -->


<!-- #comments -->

					
					
				
			</main><!-- #main -->
			
		
	</div><!-- #primary -->


	<!-- #secondary -->


			
			</div> <!-- ast-container -->

		</div></div>]]>
            </description>
            <link>https://ottverse.com/install-and-compress-videos-using-handbrake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25361189</guid>
            <pubDate>Wed, 09 Dec 2020 17:36:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A bookmark manager that uses GitHub Gist as data back end]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25361175">thread link</a>) | @clebert
<br/>
December 9, 2020 | https://bookmark.wtf/9803bde974539a8992c0515b28db439b | <a href="https://web.archive.org/web/*/https://bookmark.wtf/9803bde974539a8992c0515b28db439b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bookmark.wtf/9803bde974539a8992c0515b28db439b</link>
            <guid isPermaLink="false">hacker-news-small-sites-25361175</guid>
            <pubDate>Wed, 09 Dec 2020 17:35:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BashML: Why Spark when you can bash?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25360983">thread link</a>) | @aleclm
<br/>
December 9, 2020 | https://rev.ng/blog/bashml/post.html | <a href="https://web.archive.org/web/*/https://rev.ng/blog/bashml/post.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

<p>In one of our many research projects here at rev.ng, we are dealing with <strong>Big Data</strong> (is a 1..10 TB compressed database dump big? Well, probably not, but it is for us).
Our first approach was to extract the data and store it in an SQL database, then run a bunch of queries and finally export the processed tables for other purposes.
See the problem there? We used to use the database just like a, err... data processing tool?
Unfortunately this wasn't working very well: we were having all kinds of performance bottlenecks since we were doing bulk inserts and bulk selects.</p>
<p>We then thought of using <a href="https://spark.apache.org/"><strong>Spark</strong></a> or some other fancy stuff like that in order to stream process everything and just use text files.
But, you know, we are a binary analysis company so most of the people here don't like garbage collectors (except me, the author of this blogpost, who like them very much).
Anyway, we went from using MySQL to MongoDB+MySQL to MongoDB+PostgreSQL to, you guessed it, text <strong>files + good ol' Bash</strong>.</p>
<p>In this article I will persuade you, CEO at a brand-new Spark'ing startup that, sometimes, <strong>Bash'ing is all you need</strong>.</p>
<p><img src="https://rev.ng/blog/bashml/edited.svg"></p>
<p><strong>Note:</strong> If you haven't checked out our Big Match post, <a href="https://rev.ng/blog/big-match/post.html">go read it</a>.</p>

          
          
            <h2>An example dataset</h2>
<p>For this tutorial we will be using a simplified version of our internal <strong>Big Match</strong> dataset of github repositories. It consists of a set of txt files and each of them contains a newline-separated list of sha256 hashes of strings found in a repo.</p>
<p>So for example, in file <code>torvalds,linux.hashes.txt</code> we have all the hashes of all the strings found in the linux kernel. They are also sorted for ease of use. It's clear that we use commas in place of <code>'/'</code> as a separator between username and repo name.
So, in this case, <code>torvalds,linux.hashes.txt</code> refers to the GitHub repo <code>torvalds/linux</code>.</p>
<p>Let's take a quick look at one of our files:</p>
<div><pre><span></span>head -n <span>5</span> ./dataset/torvalds,linux.hashes.txt
</pre></div>
<div><pre><span></span>0000130323884123bd36b3460e2311191fb0663dc7765e2781b62e1bb4fb1694
000020f8aa6016e534263f726778ea7ed6f8bdc6eaad4db703200b37ae6cf00b
000050a6f4869b1ccb3dc2f76f857561d3bae7c1d01e7153c1a6ef543abbd3ff
000052d246cfb78ed0a80bd74071664dc6cb76e3b5586dfed18d8613251fdeba
00006711c3893c6716caeb147e8894ed5bd9a02d1b8743ac5b207ffcf4508494
</pre></div>
<div><pre><span></span>wc -l ./dataset/torvalds,linux.hashes.txt
</pre></div>
<div><pre><span></span>540297 ./dataset/torvalds,linux.hashes.txt
</pre></div>
<p>But before delving into the fun part, let's fix locale issues between tools. Trust me, you do want to do this, otherwise you will get all sorts of error when piping together different commands (e.g.: <code>sort</code> and <code>join</code> don't like each other very much).</p>

<h2>Building blocks</h2>
<p>Bash tools have all kinds of different options and there seem to be little to no consistency between them. We all know that: I know it, you know it, everybody knows it.
So before starting we are going to create some <strong>helper functions</strong> for the most useful bashML operations out there.</p>
<p>We will start with a <a href="https://hackage.haskell.org/package/base-4.14.0.0/docs/Prelude.html#v:fst">haskell-inspired</a> helper, <code>fst</code>:</p>
<div><pre><span></span><span># a b =&gt; a</span>
fst<span>()</span> <span>{</span>
    cut -d <span>' '</span> -f <span>1</span> <span>"</span><span>$@</span><span>"</span>
<span>}</span>
</pre></div>
<p>It's pretty simple: it takes the first column of a given file. By using <code>$@</code>, we can either give it a file argument or use it without arguments (think pipes) and it will <strong>Just Work‚Ñ¢</strong>:</p>
<div><pre><span></span><span>echo</span> -e <span>'ciao mondo\nhello world'</span> <span>|</span> fst
</pre></div>

<div><pre><span></span>fst &lt;<span>(</span><span>echo</span> -e <span>'ciao mondo\nhello world'</span><span>)</span>
</pre></div>

<p>If you are wondering what bash does on <code>&lt;(...)</code>, look no further:</p>


<p>Long story short, bash replaces the argument with a file descriptor that's connected to the output of the command inside <code>&lt;(...)</code>.
In fact, you can also <code>cat</code> it:</p>


<p>With that out of the way, let's create some additional helpers:</p>
<div><pre><span></span><span># Like `fst`, but returns the second column:</span>
<span># a b =&gt; b</span>
snd<span>()</span> <span>{</span>
    cut -d <span>' '</span> -f <span>2</span> <span>"</span><span>$@</span><span>"</span>
<span>}</span>

<span># Same as `snd`, but can handle multi-character separators:</span>
<span># a     b =&gt; b</span>
snd_awk<span>()</span> <span>{</span>
    awk <span>'{ print $2 }'</span> <span>"</span><span>$@</span><span>"</span>
<span>}</span>

<span># Turn whitespaces into newlines:</span>
<span># a b</span>
<span># c</span>
<span># =&gt;</span>
<span># a</span>
<span># b</span>
<span># c</span>
flat<span>()</span> <span>{</span>
    tr <span>' '</span> <span>'\n'</span> <span>"</span><span>$@</span><span>"</span>
<span>}</span>

<span># Similar to python `enumerate()`:</span>
<span># a</span>
<span># b</span>
<span># =&gt;</span>
<span># 0 a</span>
<span># 1 b</span>
enumerate<span>()</span> <span>{</span>
    nl -v0 -w1 -s<span>' '</span> <span>"</span><span>$@</span><span>"</span>
<span>}</span>

<span># Swap the first two columns in a file (and ignore the other columns):</span>
<span># a b =&gt; b a</span>
swap<span>()</span> <span>{</span>
    awk <span>'{ print $2 " " $1 }'</span>
<span>}</span>
</pre></div>
<p>For the few of you unfamiliar with <code>tr</code>, it's a little nice utility that can <em>translate</em> single characters (aka, map one character to another) or delete a character from a stream.</p>
<p>Another nice utility is <code>nl</code>, which counts the number of lines in a file.
Don't worry too much about the options: they are just there to output the format we want.</p>
<h2>Example pipelines</h2>
<p>It's now time to test our crazy bash skills to actually do something useful.</p>
<h3>Repository similarity</h3>
<p>Let's say we want to query our repos to <strong>find Linux forks</strong> just using common strings.
We can use a scoring formula called <a href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard index</a> (also called Jaccard similarity):</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi mathvariant="normal">‚à£</mi><mi>A</mi><mo>‚à©</mo><mi>B</mi><mi mathvariant="normal">‚à£</mi></mrow><mrow><mi mathvariant="normal">‚à£</mi><mi>A</mi><mo>‚à™</mo><mi>B</mi><mi mathvariant="normal">‚à£</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">‚à£</mi><mi>A</mi><mo>‚à©</mo><mi>B</mi><mi mathvariant="normal">‚à£</mi></mrow><mrow><mi mathvariant="normal">‚à£</mi><mi>A</mi><mi mathvariant="normal">‚à£</mi><mo>+</mo><mi mathvariant="normal">‚à£</mi><mi>B</mi><mi mathvariant="normal">‚à£</mi><mo>‚àí</mo><mi mathvariant="normal">‚à£</mi><mi>A</mi><mo>‚à©</mo><mi>B</mi><mi mathvariant="normal">‚à£</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">
J(A,B) = \frac{|A \cap B|}{|A \cup B|} = \frac{|A \cap B|}{|A| + |B| - |A \cap B|}
</annotation></semantics></math></span></span></span></p>
<p>So, if <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span></span> are our repositories, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">J(A, B)</annotation></semantics></math></span></span> is a measure of how many strings they share, divided by the total number of their strings.
How can you do this in bash?
Using <code>comm</code> and some basic <code>awk</code>.</p>
<p>If you are unfamiliar with <code>comm</code>, it's a simple command that is able to compare sorted files line by line.
If you run it without any specific option it will output 3 columns formatted like this:</p>
<div><pre><span></span>&lt;lines unique to file 1&gt; &lt;lines unique to file 2&gt; &lt;common lines&gt;
</pre></div>
<p>Remember to <strong>sort its input files</strong> otherwise <code>comm</code> will complain!</p>
<p>Anyway, if you run it with <code>--total</code>, it will also write a final line with the total count of lines for each column:</p>
<div><pre><span></span>mkdir -p ./tmp/

<span># a.txt</span>
cat &gt; ./tmp/a.txt <span>&lt;&lt;EOF</span>
<span>a</span>
<span>b</span>
<span>c</span>
<span>EOF</span>

<span># b.txt</span>
cat &gt; ./tmp/b.txt <span>&lt;&lt;EOF</span>
<span>c</span>
<span>d</span>
<span>e</span>
<span>EOF</span>

<span># Compare the lines in a.txt and b.txt (they are already sorted!)</span>
comm --total --check-order ./tmp/a.txt ./tmp/b.txt
</pre></div>

<p>See that last line?
It's the count we were talking about.
We can throw away everything <strong>except that last line</strong>, do some simple math in <code>awk</code>, and get the Jaccard index of the input files:</p>
<div><pre><span></span>jaccard<span>()</span> <span>{</span>
    <span># We don't need to sort because our input files are already sorted</span>
    comm --total --check-order <span>"</span><span>$@</span><span>"</span> <span>|</span> tail -n <span>1</span> <span>|</span> awk <span>'{ print ($3 / ($3 + $2 + $1)) }'</span>
<span>}</span>
jaccard ./tmp/a.txt ./tmp/b.txt
</pre></div>

<p>Same thing, but with a different file:</p>
<div><pre><span></span><span># c.txt</span>
cat &gt; ./tmp/c.txt <span>&lt;&lt;EOF</span>
<span>b</span>
<span>c</span>
<span>d</span>
<span>EOF</span>

jaccard ./tmp/a.txt ./tmp/c.txt
</pre></div>

<p>In this examples, the first two files have only one line in common out of 5 unique strings, so <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>5</mn></mfrac><mo>=</mo><mn>0.2</mn></mrow><annotation encoding="application/x-tex">J(A, B) = \frac{1}{5} = 0.2</annotation></semantics></math></span></span>.
In the second example, they share 2 lines out of 4 unique strings, so <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>2</mn><mn>4</mn></mfrac><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">J(A, B) = \frac{2}{4} = 0.5</annotation></semantics></math></span></span>.</p>
<p>Yes, this is what data scientists get paid to do by the way.</p>
<p>Now let's say we want to find the Jaccard similarity between Linux and the biggest repos in our dataset.
We need to start by getting the list of such big files:</p>
<div><pre><span></span><span># Get list of (size, filename)</span>
biggest_files<span>()</span> <span>{</span>
    find ./dataset/ -name <span>"*.hashes.txt"</span> -print0 <span>\</span>
    <span>|</span> xargs -0 du -a <span>\</span>
    <span>|</span> sort -t <span>' '</span> -nr <span>\</span>
    <span>|</span> head -n <span>"</span><span>$@</span><span>"</span>
<span>}</span>

<span>echo</span> <span>'== Biggest files =='</span>
biggest_files <span>5</span>
<span>echo</span> <span>'...'</span>
</pre></div>
<div><pre><span></span>== Biggest files ==
103288  ./dataset/mirror,dd-wrt.hashes.txt
66824   ./dataset/kishikawakatsumi,Mozc-for-iOS.hashes.txt
57564   ./dataset/mirek190,x86-android-5.0.hashes.txt
51008   ./dataset/CyberGrandChallenge,samples.hashes.txt
47068   ./dataset/AndreyPopovNew,asuswrt-merlin-rt-n.hashes.txt
...
</pre></div>
<p>We now want to use the same <code>jaccard()</code> function we defined above <strong>but</strong> we want to run it faster by exploiting <strong>parallel processing</strong>.
We can do that with GNU <code>parallel</code>.</p>
<p>GNU <code>parallel</code> has a metric ton of options.
Yes, that is 1000-kilograms-many options.
Unless you voted for Brexit or play football with your hands: in that case it's ~2205 pounds.
Since we are Europeans and are not here to start a debate about our (superior) measurement system, we will just use 2 options and ignore the others:</p>
<div><pre><span></span>cat ./tmp/a.txt <span>|</span> parallel -j<span>$(</span>nproc<span>)</span> -k -- <span>echo</span> <span>{}</span>
</pre></div>

<p>What's happening here? Quite a bit actually: <code>parallel</code> just ran <code>echo {}</code> 3 times, every time substituting <code>{}</code> with a line from the input.
Remember: the calls to <code>echo</code> happen <strong>in parallel</strong> using multiple processes!</p>
<p>GNU <code>parallel</code> allows you to use <code>{}</code> multiple times if you want:</p>
<div><pre><span></span>cat ./tmp/a.txt <span>|</span> parallel -j<span>$(</span>nproc<span>)</span> -k -- <span>echo</span> <span>{}</span> <span>{}</span> <span>{}</span>
</pre></div>

<p>The options we give to <code>parallel</code> are very important: <code>-j$(nproc)</code> is for using as many processes as the processing units on the system (returned by the command <code>nproc</code>), while <code>-k</code> tells <code>parallel</code> to <strong>honor the input order</strong> when printing the output (so we don't get, e.g., <code>c c c</code> then <code>b b b</code> then <code>a a a</code>).</p>
<p>We can now use our previous <code>jaccard</code> function inside <code>parallel</code> to get the <strong>similarity between Linux and the other repos</strong>.
However, we also want a nice output so we throw in a call to <code>printf</code>.
The command gets a little messy due to string formatting, but just focus on the <code>jaccard</code> part:</p>
<div><pre><span></span>similarity<span>()</span> <span>{</span>
    <span># Export the `jaccard` function so that it's available to `parallel`</span>
    <span>export</span> -f jaccard

    <span>echo</span> -e <span>'\n== Similarity to torvalds/linux =='</span>

    <span># Find most linux-like repos</span>
    biggest_files <span>30</span> <span>\</span>
        <span>|</span> snd_awk <span>\</span>
        <span>|</span> parallel -j<span>$(</span>nproc<span>)</span> -k -- <span>printf</span> <span>\'</span>%0.5f %s<span>\\</span>n<span>\'</span> <span>'$(jaccard ./dataset/torvalds,linux.hashes.txt {})'</span> <span>'{}'</span>
<span>}</span>
similarity
</pre></div>
<div><pre><span></span>== Similarity to torvalds/linux ==
0.27157 ./dataset/mirror,dd-wrt.hashes.txt
0.00068 ./dataset/kishikawakatsumi,Mozc-for-iOS.hashes.txt
0.22947 ./dataset/mirek190,x86-android-5.0.hashes.txt
0.00447 ./dataset/CyberGrandChallenge,samples.hashes.txt
0.16675 ./dataset/AndreyPopovNew,asuswrt-merlin-rt-n.hashes.txt
0.21503 ./dataset/ChrisP-Android,BananaPi-Android-4.2.2-Liab.hashes.txt
0.01760 ./dataset/scs,uclinux.hashes.txt
0.22131 ./dataset/xdtianyu,android_04.01.01_msm7627a.hashes.txt
0.03125 ./dataset/IIJ-NetBSD,netbsd-src.hashes.txt
0.17406 ./dataset/Mazout360,asuswrt-maz.hashes.txt
0.14198 ./dataset/labx-technologies-llc,mb-linux-labx.hashes.txt
0.03072 ./dataset/freebsd,freebsd.hashes.txt
0.03224 ./dataset/opnsense,src.hashes.txt
0.02743 ./dataset/Stichting-MINIX-Research-Foundation,netbsd.hashes.txt
0.25569 ./dataset/andy-padavan,rt-n56u.hashes.txt
0.25605 ./dataset/moonman,rt-n56u.hashes.txt
0.03061 ./dataset/CTSRD-CHERI,cheribsd.hashes.txt
0.64101 ./dataset/sonyxperiadev,kernel.hashes.txt
0.39307 ./dataset/beastix,beastix.hashes.txt
0.99817 ./dataset/srikard,linux.hashes.txt
0.99851 ./dataset/RobertCNelson,linux-stable-rcn-ee.hashes.txt
0.99705 ./dataset/lzto,linux.hashes.txt
0.99705 ‚Ä¶</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rev.ng/blog/bashml/post.html">https://rev.ng/blog/bashml/post.html</a></em></p>]]>
            </description>
            <link>https://rev.ng/blog/bashml/post.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360983</guid>
            <pubDate>Wed, 09 Dec 2020 17:20:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracking Hacker News sentiment towards Big Tech companies]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25360761">thread link</a>) | @greatwave1
<br/>
December 9, 2020 | https://www.quiverquant.com/sources/hackernews | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/sources/hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><a href="https://www.quiverquant.com/">
						<img src="https://www.quiverquant.com/static/img/logo.png" alt="">
					</a></p><p>Quiver scrapes alternative stock data from across the internet and aggregates it in a free, easy-to-use web dashboard.</p>
					<div>
						<p><span>Copyright ¬© 2020 Quiver Quantitative, Inc. All rights reserved.</span></p><ul>
							<li><a href="https://www.quiverquant.com/privacypolicy">Privacy Policy</a></li>
							<li><a href="https://www.quiverquant.com/termsofservice">Terms of Service</a></li>
						</ul>
					</div>
				</div></div>]]>
            </description>
            <link>https://www.quiverquant.com/sources/hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360761</guid>
            <pubDate>Wed, 09 Dec 2020 17:01:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A modest proposal to save the world]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25360668">thread link</a>) | @donohoe
<br/>
December 9, 2020 | https://restofworld.org/2020/saving-the-world-through-tequiology/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/saving-the-world-through-tequiology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>I</span>t is a myth of the West‚Äôs choosing: perpetual economic growth, advancing through a digestive system of sorts, one that uses technology as one of its core components. In its churn,<strong> </strong>ecosystems became goods; people, mere consumers. The myth turned the world into a place increasingly inhospitable to human life.</p>



<p>I write these words from the periphery of the metropolises that command this global digestive system ‚Äî an enclave that resists the myth‚Äôs logic. In these parts, resistance begins with a name. Here, Latin America is neither Latin nor America; it is Abya Yala, a term the Guna people of Panama use to describe the Western Hemisphere‚Äôs largest landmass as it existed before<strong> </strong>1492. This is a territory that comprises an array of Indigenous nations, Afro-descendant communities, and societies created by political projects of miscegenation. As a whole, the history of this diverse group of peoples is inextricable from the ravages of colonialism. Yet that history has also been defined by those peoples‚Äô ingenious use of new technologies ‚Äî not as consumable goods, but as means of resisting colonial imposition in the midst of an unprecedented climate crisis.</p>



<p><a href="https://www.cepal.org/en/publications/40840-science-technology-and-innovation-digital-economy-state-art-latin-america-and">To metropolitan eyes,</a> Latin America, with its minimal patent production and negligible investment in science and technology, lags behind. The Silicon Valleys springing up in different parts of the world ‚Äî more an ideological concept than a geographic location ‚Äî have long dismissed the region as a passive receptor for technology. But Abya Yala challenges that narrative. Here on the periphery, technology, when repurposed for resistance, can bolster the autonomy of peoples and communities.<strong> </strong>In Abya Yala, digital technologies have created virtual spaces to be shared ‚Äî woven webs of sustainable<strong> </strong>collaboration among the continent‚Äôs subaltern voices.</p>



<p>This form of collaborative effort has ancient roots. To many peoples in Mexico, it is known as <em>tequio</em> (from the N√°huatl <em>tequitl</em>) or, farther south, as <em>faena</em>, <em>kol</em>, or <em>minga</em>. Through tequio, schools have been built, potable-water systems have been installed, and art has been made. Tequio has also become a strategy for meeting everyday needs. Just as the modern-day technology of free, open-source code has enabled collective progress in the digital sphere, the communal labor of tequio raises the possibility of resistance in Abya Yala ‚Äî and survival of the world at large.</p>



<p>But as is true in every struggle against power, hegemonic narratives ‚Äî those dominant myths that determine how we see the world<strong> </strong>‚Äî must first be confronted in order to avoid what Nigerian writer Chimamanda Ngozi Adichie has called ‚Äú<a href="https://www.youtube.com/watch?v=D9Ihs241zeg&amp;ab_channel=TED">the danger of a single story</a>,‚Äù the all-encompassing Western mythology flooding our distant territories.&nbsp;</p>



<p>Since 2008, the Wayuu Film and Video Showcase, for instance, has given voice to the Wayuu, an indigenous people living in what<strong> </strong>is now<strong> </strong>Venezuela and Colombia. Similarly, the <a href="http://www.videonasaldeias.org.br/2009/">V√≠deo Nas Aldeias</a> streaming platform, created by Vincent Carelli and the Nambiquara, has enabled Indigenous peoples in Brazil to learn to make films and tell their stories in their own narrative formats. The purpose of these initiatives, according to Wayuu director and film curator David Hern√°ndez Palmar, is to ‚Äúclose the digital gap that exists between these peoples and technology.‚Äù But ‚Äúclosing the gap‚Äù doesn‚Äôt only mean bringing film to the Wayuu: It also means building a bridge to the West to foster intercultural exchange.</p>



<p>Abya Yala, by repurposing imported technologies, is far ahead of the West in understanding how digital technology can burst out from the realm of the intangible into the ‚Äúreal world.‚Äù The West has recently witnessed how ‚Äúfake news‚Äù and online interference in political disputes can spill over into its streets and ballot boxes. But Abya Yala has spent decades waging its struggles in digital spaces, particularly in defense of its native languages:<strong> </strong>Within the next hundred years, experts estimate that up to 80% of the world‚Äôs approximately 7,000 languages will have disappeared. Meanwhile, digital knowledge is accessible through just a few Portuguese-, <a href="https://restofworld.org/2020/saving-the-world-through-tequiology/">English</a>-, and <a href="https://restofworld.org/2020/tecnologia-tequio-cambio-climatico/">Spanish</a>-language<strong> </strong>gateways, inaccessible to non-hegemonic language communities in the periphery. But groups like<strong> </strong><a href="https://rising.globalvoices.org/lenguas/"><em>Activismo Digital de Lenguas Ind√≠genas</em></a><em> </em>are filling the void. This continent-wide digital indigenous-language movement has forged a network of activists from all over Abya Yala, including Wikipedians, app developers, and programmers, among others. Collectives like the one created in the <a href="https://rising.globalvoices.org/lenguas/2020/02/16/mozilla-en-triqui/">Triqui region of southern Mexico</a> have worked together to ensure that they have access to browsers in their own language. In this way,<strong> </strong>we see<strong> </strong>digitally underrepresented peoples appropriating technology<strong> </strong>as a tool of linguistic resistance<strong>.</strong>&nbsp;</p>



<p>Abya Yala‚Äôs technological struggle<strong> </strong>also<strong> </strong>extends to the vindication of material sovereignty. In Mexico, <a href="https://www.redesac.org.mx/telefoniacomunitaria">Community Cellular Technology</a>, through which cell phone systems are locally owned, administered, and operated, has been built against a backdrop that has started to crumble: As proprietors of their own cell company, these communities defy the slogan of the conglomerate that controls 70% of the country‚Äôs mobile communication services: ‚ÄúAll of Mexico is Telcel territory.‚Äù The response from these communities is No: Not all of Mexico is the territory of Carlos Slim, one of the wealthiest men in the world. They strive for technological sovereignty.</p>



<p>Technology has also tapped into ancient collective philosophies to resist the metropole. Rodrigo P√©rez Ram√≠rez, better known in Mexico as Zapoteco 3.0, is part of the <a href="https://mozillanativo.org/involucrate">Mozilla Nativo</a> movement, which seeks to empower indigenous peoples online. He told me that he had found in open-source software a natural ally to his local Zapotec-language activism. There is a serendipitous affinity between the logic of collective effort and free cooperation that defines open-source software like Linux and the philosophy of many indigenous communities who built structures to survive the harshness of colonial rule. Both rely on<strong> </strong>mutual support and small-scale, community-level labor linked into a circuit of larger tasks.<strong> </strong>Such tequio is an essential ‚Äúsocial technology‚Äù common<strong> </strong>across Abya Yala. It has been<strong> </strong>for a long time, including back when indigenous peoples, organized into small communities, created networks to resist paying taxes or to plan rebellions against the Iberian crowns.&nbsp;</p>



<p>However, this form of scalable Abya Yalan tequio could be a crucial asset to the entire world in the years ahead. When technologies are deployed in forms<strong> </strong>that resemble<strong> </strong>tequio,<strong> </strong>rather than in pursuit of insatiable competitive growth, we may indeed get a true solution to the dire climate emergency we are facing. Even so-called green capitalism has raised hopes that some technological invention will solve our ecological emergency. But we in Abya Yala can see how even some forms of renewable energy wind up as just another pollutant. Here, we have seen<strong> </strong>rare earths violently <a href="https://restofworld.org/2020/niobium-the-mighty-element-youve-never-heard-of/">extracted from our territories</a> in order to create ‚Äúgreen technologies,‚Äù which are then installed on ‚Äúempty land‚Äù by dispossessing our communities.<strong> </strong>This phenomenon was explored at the Wayuu Film and Video Showcase in a documentary called ‚ÄúTatuushi‚Äù<em> </em>(My Grandfather). Through traditional Wayuu singing, it tells the story of a grandfather who travels to the city in search of food. On his return, he finds that coal companies have devastated his land and destroyed his home. Faced with dispossession, the grandfather responds with a traditional prayer.</p>



<p>An alternative, offered by Abya Yala, lies in separating economic development and the development of new technologies from consumerism. This would place technological creation and ingenuity once again at the service of the common good, not of the market. Technology as tequio; technological creation and innovation as a common good. A kind of open-source software we can all participate in, just as we have participated in the construction of our lives as the colonized peoples of this continent, resisting genocide and extinction.&nbsp;In the face of our current global climate emergency, we need to foster forms of technological development that emphasize living with dignity, not infinite economic growth as an end in itself. We must focus on technologies based on collaborative labor more than on competition. As peoples of Abya Yala, we‚Äôre experienced in this strategy, which I call <em>tequiology</em>. If the world were to listen to the people of Abya Yala and adopt this new tequiological vision, we could perhaps escape the digestive system that so threatens our world‚Äôs climate and endangers human life.</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/saving-the-world-through-tequiology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360668</guid>
            <pubDate>Wed, 09 Dec 2020 16:53:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Automatic Customer Data Cleaning API]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25360553">thread link</a>) | @asharma327
<br/>
December 9, 2020 | https://www.cleanspreadsheets.com/api-docs | <a href="https://web.archive.org/web/*/https://www.cleanspreadsheets.com/api-docs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.cleanspreadsheets.com/api-docs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360553</guid>
            <pubDate>Wed, 09 Dec 2020 16:44:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Tyler Slide Rule]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25360450">thread link</a>) | @AlphaGeekZulu
<br/>
December 9, 2020 | https://osgalleries.org/collectors/davis/info_and_image.cgi?string1=weemsandplath&string2=2910 | <a href="https://web.archive.org/web/*/https://osgalleries.org/collectors/davis/info_and_image.cgi?string1=weemsandplath&string2=2910">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"> 


<p>
<span color="#000000"><img src="https://osgalleries.org/collectors/davis/oslogo.jpg" name="graphics1" width="150" height="63"></span></p>


<p>
<span color="#333399"><span face="Arial"><span size="6"><b>Archive
</b></span></span></span><span color="#333399"><span face="Arial"><span size="4"><b>of</b></span></span></span><span color="#333399"><span face="Arial"><span size="6"><b>
Collections </b></span></span></span>
</p>

<center>
<span>Details and Image</span>
</center>
    <center><table>
	<tbody><tr>
	<th>Type</th><th>Model No.</th><th>Maker</th><th>Country</th><th>Construction<br>Material</th><th>Date</th><th>Scale Length</th><th>Area of Use</th>
	</tr><tr>
			<td>Disk / Plate</td><td><center>Tyler Slide Rule</center></td><td>Weems and Plath</td><td>U.S.A.</td><td><center>Plastic</center></td><td>est. 1955</td><td>21.5 cm x 21.5 cm</td><td>General Purpose</td>
			</tr></tbody></table></center><br><b>Notes: </b>"1) Unusual slide rule designed by John Tyler 2) Interesting design using non-linear curved scales to determine answers 3) Reference Rodger Shepherd's Article ""Log Spiral"" Devices, JOS Vol 9, no. 1 4) Has a spiral C scale and A, T, T2, S, S2, LN scales"<center><b>Image 1</b></center><p><img src="https://osgalleries.org/collectors/davis/weemsandplath/images/2910a.jpg"></p><center><b>Image 2</b></center><p><img src="https://osgalleries.org/collectors/davis/weemsandplath/images/2910b.jpg"></p></div>]]>
            </description>
            <link>https://osgalleries.org/collectors/davis/info_and_image.cgi?string1=weemsandplath&amp;string2=2910</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360450</guid>
            <pubDate>Wed, 09 Dec 2020 16:36:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Old Are These Keys?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25360323">thread link</a>) | @breck
<br/>
December 9, 2020 | https://breckyunits.com/how-old-are-these-keys.html | <a href="https://web.archive.org/web/*/https://breckyunits.com/how-old-are-these-keys.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><a href="https://breckyunits.com/files/keyboard/"><img src="https://breckyunits.com/files/keyboard/screenshot.png"></a></p>

<p>One of the questions I often come back to is this: how much of our collective wealth is inherited by our generations versus created by our generations?</p>

<p>I realized that the keys on the keyboard in front of me might make a good dataset to attack that problem. So I built a small little <a href="https://breckyunits.com/files/keyboard/">experiment to explore the history of the keys on my keyboard</a>.</p>

<h2 id="the-five-waves-of-symbols">The Five Waves of Symbols</h2>

<p>Painting with broad strokes, there were approximately five big waves of inventions that have left their mark on the keyboard. The first wave was the invention of the phonetic alphabet letters. The second wave was the Hindu-Arabic Numerals. The third wave was the mathematical punctuation of the Enlightenment period. The fourth wave was the invention of the typewriter. And the fifth and most recent wave was the invention of the personal computer.</p>

<p>I haven‚Äôt made any traditional charts yet with this dataset, but you can roughly make out these waves in the interactive visualization by moving the slider around.</p>

<h2 id="concentric-circles">Concentric Circles</h2>

<p>An interesting pattern that I never saw before is how the five waves above are roughly arranged in circles. The oldest symbols (letters) are close to the center, followed by the Hindu-Arabic Numbers, surrounded by the punctuation of the Englightenment, surrounded by the keys of the keyboard, surrounded by the recent additions in the P.C. era. Again, painting with broad strokes, but I found that to be an interesting pattern.</p>

<h2 id="standing-on-the-shoulders-of-giants">Standing on the Shoulders of Giants</h2>

<p>All of these waves happened invented before my generation. Almost all of them before any generation alive today. The keyboard dataset provides strong evidence that most of our collective wealth is inherited.</p>

<h2 id="build-notes">Build Notes</h2>

<p>I got this idea last week and couldn‚Äôt get it out of my head. Yesterday I took a quick crack at it. I didn‚Äôt have much time to spare, just enough to explore the big ideas. I started by typing all the characters on my keyboard into a Tree Notation document. Then I dug up some years for a handful of the symbols. Then I found the great Apple CSS keyboard. I stitched together the two and it seemed to be at least mildly interesting so I opted to continue. I then flushed out most of the dataset. Finally I played around with a number of visualization effects. At first I thought heatmaps would work well, and tried a few variations on that, but wasn‚Äôt happy with anything. I posted my work-in-progress to a few friends last night and called it a day. Today I switched to the ‚Äúdisappearing keys‚Äù visualization. That definitely felt like a better approach than the heatmap. I made the thing as fun as I could given time constraints and then shipped.</p>

<p>Published 2/25/2020</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://breckyunits.com/how-old-are-these-keys.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360323</guid>
            <pubDate>Wed, 09 Dec 2020 16:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to model your data in a visual tool]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25360319">thread link</a>) | @vivek9209
<br/>
December 9, 2020 | https://terminusdb.com/blog/2020/11/19/model-builder-and-data-modeling/ | <a href="https://web.archive.org/web/*/https://terminusdb.com/blog/2020/11/19/model-builder-and-data-modeling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div id="markdown" itemprop="articleBody">
          <p>In this post, I will guide you through the steps needed to design your database schema using TerminusDB 4.0 Console and its model builder.</p>

<p>Having your data in the right format makes it easier to analyze the data properly but you can model your data in more than one way. This is a reality for all the databases, so how to make the right decision?</p>

<p>The model builder is a tool that lets you visualize and edit your database schema. It is very useful for designing and understanding complex data models.
I‚Äôll show you how you can start from a simple model and build out something more complex in no time.</p>

<p>if you have never used TerminusDB before, this article includes everything you need to get started with TerminusDB. <a href="https://terminusdb.com/blog/2020/09/01/my-first-terminusdb-3-0-graph-bike-share-data/">My First TerminusDB Graph Visualisation ‚Äî Bike Share Data</a>.</p>

<hr>

<h3 id="the-dataset">The Dataset</h3>

<p>In our examples we use the collection of data about the bike journeys between stations in Washington D.C., USA.</p>

<p>We have used this data in other blogs, where with woql.js, a javascript layer that help you to compose <a href="https://terminusdb.com/docs/reference/server/woql/"><strong>WOQL query</strong> (Web Object Query Language)</a>, we have created our database scheme.</p>

<p><img src="https://terminusdb.com/blog/assets/images/bike_table.png" alt="data about the bike journeys between stations in Washington D.C"></p>

<p>The CSV data used this tutorial is available at <a href="https://terminusdb.com/t/data/bike_tutorial.csv">https://terminusdb.com/t/data/bike_tutorial.csv</a></p>

<hr>

<h3 id="how-do-i-model-my-schema-using-the-model-builder">How do I model my schema using the model builder?</h3>

<p>I assume you already have TerminusDB and Console running in your system 
and you have created a db named <strong>myBikes</strong>.</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-02.png" alt="Go to model builder"></p>

<p>Form the <strong>myBikes</strong> main page.</p>

<ol>
  <li>Select the menu <strong>Schema-&gt;Schema Builder</strong> to arrive at the model builder interface.</li>
  <li>In the whiteboard select the node <strong>myBikes Schema</strong>, the list of all available node types will show up.</li>
</ol>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-03.png" alt="See the whiteboard"></p>

<p>Let‚Äôs see the different nodes in detail.</p>

<p><strong>Object</strong> contains a piece of the graph and can be accessed by a unique url.
An Object can have multiple properties and can be contained inside other objects.</p>

<p><strong>Document</strong> is a special type of Object. Documents are always top-level objects, never embedded inside other objects, using the Link Property you can link documents to each other.</p>

<p><strong>Enum</strong> or Enumerated is a special data type that enables a property to be a set of predefined constants. The property must be equal to one of the values that have been predefined for it. To use this set of values you‚Äôll need to create an Enum Property and link it to an Emun Element.</p>

<p>Let‚Äôs use these elements in practice.</p>

<hr>

<h3 id="add-nodes">Add Nodes</h3>

<p>For storing our data we have to create 3 different Documents  <strong>Bicycle</strong>, <strong>Station</strong> and <strong>Journey</strong></p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-04.png" alt="Node List"></p>

<p>Follow the steps and start to build your schema graph.</p>

<ol>
  <li>Select the <strong>myBikes Schema</strong> node in the whiteboard and click the + icon</li>
  <li>Select <strong>Add Document</strong> from the menu. A new node will be added under the node <strong>Documents</strong></li>
  <li>We start to add <strong>Bicycle</strong> Document. Fill the form in the right sidebar with the data from the image above. (Unique Id:Bicycle..)</li>
  <li>Follow the same steps above for adding the other Documents <strong>Station</strong> and <strong>Journey</strong></li>
  <li>Click on the <strong>Save</strong> icon button in the tools bar to save your work.</li>
</ol>

<p><strong>At this point our documents are completely unrelated.</strong></p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-05.png" alt="Documents"></p>

<hr>

<h3 id="add-properties">Add Properties</h3>

<p>To descrive your Documents and to link them with each other, we need to add properties to our documents.
We have various different type of properties identified by datatypes</p>

<p>DataProperty : String/Numeric/Geo/Temporal Property refers to the format of data storage</p>

<p>ObjectProperty : Enum/Link Property refers to a relationship between elements</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-06.png" alt="Property list"></p>

<p>Let‚Äôs add the property <strong>start_station</strong>.</p>

<ol>
  <li>Select the node <strong>Journey</strong> in the whiteboard, in the right panel click on the <strong>Properties</strong></li>
  <li>In the properties panel, click <strong>Add Property</strong> in the pop up menu you can see the list of the available property types.</li>
  <li>Select <strong>Property Link</strong> after the form shows up, fill the fields with the value reported in the table above (Unique ID/Label/Description).</li>
  <li>Click on the <strong>Link to Type</strong> menu and Select <strong>Bike Station</strong> 
  <em>Links to Type is a list with all the node that you can linked</em></li>
  <li>Follow the step 1 to 4 for adding the others properties <strong>end_station</strong>, <strong>journey_bicycle</strong></li>
</ol>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-07.png" alt="Property start_station"></p>

<ol>
  <li>Click on the <strong>Save</strong> icon button in the tools bar to save your work.</li>
  <li>Select <strong>Relationships</strong> in the right panel top bar to see the links.</li>
</ol>

<p><strong>We have created our relationship beetween Documents.</strong></p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-08.png" alt="Property start_station"></p>

<hr>

<h3 id="schema-evolution-and-compatibility">Schema Evolution and Compatibility</h3>

<p>An important aspect of data management is schema evolution. 
My initial schema is defined, but my application now need to change it, what can I do?</p>

<p>Let‚Äôs see.</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-09.png" alt="Property start_station"></p>

<p>Now we need to model the Document <strong>Station</strong> as Object, so we have to delete the Document <strong>Station</strong> and create a new node type.</p>

<p>The database doesn‚Äôt allow you to delete a node if it is related with another node.
More precisely the node can not have children and it can not be the range of a Link Property/Enum 
Property.
This constraint is used to prevent actions that would destroy the integrity of the data model.</p>

<hr>

<h3 id="delete-a-node">Delete a Node</h3>

<p>Here the step for doing this.
First we have to remove all the relationship related to our node.</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-10.png" alt="Property start_station"></p>

<ol>
  <li>Select the Document <strong>Journey</strong> node in the whiteboard, in the right panel Select <strong>Properties</strong>. the list of the properties will show up.</li>
  <li>Select <strong>End Station</strong> Property and delete it using the red delete icon.</li>
  <li>Follow the above steps for deleting <strong>Start Station</strong> Property too.</li>
  <li>All the <strong>Station</strong> node constraints have been removed</li>
  <li>Select the <strong>Station</strong> node in the whiteboard, in the right panel, Click the delete red icon.</li>
</ol>

<p>Deleting a node is easy at this stage because we don‚Äôt have any data in the database.</p>

<hr>

<h3 id="add-an-object-type">Add an Object Type</h3>

<p>Now we add the <strong>Station</strong> node as Object Type.</p>

<ol>
  <li>Select the <strong>Schema myBikes</strong>, click on the + icon, from the menu Select <strong>Add Object</strong> a new node will be add in the whiteboard.</li>
  <li>As we did before we have to add the Unique ID/Station and the Label/Description Bike Station in the fields in the right panel.</li>
  <li>Select the Node <strong>Journey</strong> and add the Link Property <strong>Start Station</strong> <strong>End Station</strong> again (Follow the add property steps above).</li>
</ol>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-11.png" alt="Property start_station"></p>

<hr>

<h3 id="difference-between-object-and-document-types">Difference between Object and Document Types</h3>

<p>The difference in Linking a Property to a Document than a Object is in how this data will be represented and managed in document form.</p>

<p>Here is an example with bike data</p>

<p>If <strong>Station</strong> is a Document Type you have to create a <strong>Station</strong> Document <br>
and link the id of the Document <strong>Station</strong> with the <strong>Journey</strong> Document</p>

<p>This means that if you remove one <strong>Journey</strong> Document 
it removes the link but not the data in the related <strong>Station</strong> document.</p>

<p>If, on the other hand, the <strong>Station</strong> is an Object Type, its data will be embedded in the <strong>Journey</strong> Document 
So if you remove one Journey Document entry it will be remove the related <strong>Station</strong>
Object.</p>

<hr>

<h3 id="add-an-enum-node">Add an Enum Node</h3>

<p>We continue our Schema evolution by adding the <strong>Type Bike</strong> enum node</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-12.png" alt="Property start_station"></p>

<ol>
  <li>Select the <strong>Schema myBikes</strong>, Select the + icon, from the menu Select <strong>Add Enum</strong></li>
  <li>The Enum node will be added in the whiteboard</li>
  <li>Fill the fields in the right panel (Unique Id:Bike_Type..)</li>
  <li>Select values, Fill the fields and click the button <strong>Add a value</strong> for adding the list of possible values</li>
</ol>

<hr>

<h3 id="link-the-enum-node-with-the-enum-property">Link the Enum Node with the Enum Property</h3>

<p>We are going to create our Enum property for the <strong>Bicycle</strong> Documents</p>

<ol>
  <li>Select the <strong>Bicycle</strong> node</li>
  <li>In the right panel, Select the <strong>Properties</strong> tab</li>
  <li>Select the <strong>Add Property</strong> menu and Click <strong>Enum Property</strong></li>
  <li>Fill the Property fields in the Property panel (Unique ID:bicycle_type ‚Ä¶.)</li>
  <li>From the <strong>Enum Type</strong> menu Select <strong>Bike Type</strong></li>
</ol>

<p>We said that the property <strong>Bicycle Type</strong> in <strong>Bicycle</strong> Document is a string with a value chosen from a list of permitted values.</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-13.png" alt="Property start_station"></p>

<hr>

<h3 id="add-children">Add Children</h3>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-14.png" alt="Property start_station"></p>

<p>We are going to add other elements to create a more complex hierarchy</p>

<p>At this point in our project we need to add information about the bike user, we suppose we can have 2 types of user that rent the bike, a registered user and a guest user.</p>

<p>First we create an abstract Document <strong>User</strong> for grouping the different type of user.</p>

<p>An Abstract Document is a completely ‚Äúabstract class‚Äù that is used to group related properties.</p>

<p>Abstract Documents cannot be used to create Data directly, you cannot add data in a <strong>User</strong>
Document. An abstract Document can have children, all the children will inherit all the parent‚Äôs properties and if the children are not abstract, you can insert data as children.</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-15.png" alt="Property start_station"></p>

<p>Let‚Äôs see all the steps for creating an abstract document and its children.</p>

<ol>
  <li>Select the <strong>Document</strong> node in the whiteboard, Select the + icon and from the menu that show up, Choose <strong>Add Document</strong>.</li>
  <li>A new node Document will be added.</li>
  <li>In the right panel fill the fields for the new Document (Unique ID:User, Label:Bike User‚Ä¶.)</li>
  <li>Check the <strong>Abstract</strong> checkbox.</li>
  <li>Select the tab <strong>Properties</strong>, from the menu <strong>Add Property</strong> Choose <strong>String Property</strong></li>
  <li>The String Property Panel will show up, fill the fields (Unique ID: email, Label:Email)
<img src="https://terminusdb.com/blog/assets/images/schema_builder-16.png" alt="Property start_station"></li>
  <li>Choose <strong>Email</strong> from the <strong>String Type</strong> menu.</li>
  <li>In the <strong>Cardinality Min</strong> field add 1 (this means that if you add an User Document, the email property must have a value in it).</li>
</ol>

<p><em>we added the Abstract <strong>User</strong> Document with its properties, now let‚Äôs add the children.</em></p>

<ol>
  <li>Select the node <strong>Bike User</strong> in the whiteboard, Click on the + icon, from the menu Select <strong>Add Child</strong></li>
  <li>A new Node will be added, in the right panel fill all the fields (Unique Id:Guest ‚Ä¶.)</li>
  <li>Follow the above steps for add the <strong>Member</strong> Document too</li>
</ol>

<p>We can decide to not add new properties in the Guest document so the guest user will be identified by the email, but for the <strong>Member</strong> Document we need to add at least the String property Password.</p>

<p>We have to create a Link Property <strong>Bicycle User</strong> in the <strong>Bike Journey</strong> Document for link the <strong>User</strong> Document with the <strong>Bike Journey</strong> Document.</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-17.png" alt="Property start_station"></p>

<hr>

<h3 id="add-a-parent">Add a Parent</h3>

<p>At this point of our project we want to reorganize our nodes.</p>

<p>We have to create an element that can be <strong>a Parent</strong> for an Object node and a Document node. 
Objects can only be children of Object types, Documents can be children of Object Types and Document Types, so we have to create a <strong>New Object Node</strong></p>

<p>We can call this node <strong>Entity</strong>. The <strong>Entity</strong> node is abstract and has a Geo Property  <strong>Position</strong></p>

<p>I am sure you already know all the steps for doing this üòä.</p>

<p><img src="https://terminusdb.com/blog/assets/images/schema_builder-18.png" alt="Add Parent"></p>

<p>Let‚Äôs group <strong>Bike Station</strong> and <strong>Bicycle</strong> under this new node.</p>

<ol>
  <li>Select the node <strong>Bicycle</strong> in the whiteboard, in the right panel Select <strong>Relationships</strong></li>
  <li>Under <strong>Add/Remove Parents</strong> panel from the menu ‚Ä¶</li></ol></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://terminusdb.com/blog/2020/11/19/model-builder-and-data-modeling/">https://terminusdb.com/blog/2020/11/19/model-builder-and-data-modeling/</a></em></p>]]>
            </description>
            <link>https://terminusdb.com/blog/2020/11/19/model-builder-and-data-modeling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360319</guid>
            <pubDate>Wed, 09 Dec 2020 16:27:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Online News Isn't Sustainable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25360153">thread link</a>) | @jaredwiener
<br/>
December 9, 2020 | https://blog.nillium.com/news-was-never-meant-for-social-platforms/ | <a href="https://web.archive.org/web/*/https://blog.nillium.com/news-was-never-meant-for-social-platforms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1460794418188-1bb7dba2720d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDMzfHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 300w,
                            https://images.unsplash.com/photo-1460794418188-1bb7dba2720d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDMzfHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 600w,
                            https://images.unsplash.com/photo-1460794418188-1bb7dba2720d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDMzfHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 1000w,
                            https://images.unsplash.com/photo-1460794418188-1bb7dba2720d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDMzfHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1460794418188-1bb7dba2720d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDMzfHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="News was never meant for social platforms">
            </figure>

            <section>
                <div>
                    <p>Yesterday, my cofounder wrote a <a href="https://blog.nillium.com/its-time-to-remove-news-from-facebook-and-google/">controversial post on this blog</a>, presenting a case for news publishers to limit -- or remove -- their reporting from Facebook and Google. &nbsp;The responses were immediate and plentiful, but fascinatingly different depending on the audience.</p><p>On Hacker News, a tech- and startup-focused forum, the link rose to the top of the list before being ‚Äúflagged‚Äù and removed from the front page. &nbsp;The<a href="https://news.ycombinator.com/item?id=25249414"> comments there</a> took a more pragmatic, technical approach to the problem, from ‚Äú<a href="https://news.ycombinator.com/item?id=25249553">The technical capability already exists in the form of robots.txt and the referer header,</a>‚Äù to constant reminders that news organizations <em>need</em> this traffic.</p><p>On the <a href="https://www.reddit.com/r/Journalism/comments/k3kmg9/its_time_to_remove_news_from_facebook_and_google/">r/journalism subreddit</a>, we were hit from the other side. &nbsp;Why not just ‚Äú<a href="https://www.reddit.com/r/Journalism/comments/k3kmg9/its_time_to_remove_news_from_facebook_and_google/ge3zqq2/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">nationalize the press so we can quit with the hand-wringing</a>?‚Äù suggested one commenter, while another lamented that ‚Äú<a href="https://www.reddit.com/r/Journalism/comments/k3kmg9/its_time_to_remove_news_from_facebook_and_google/ge51kko/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">this idea disenfranchises young journalists who don‚Äôt have any name credibility and recognition and need an established platforms [sic] gravitas to help establish them</a>.‚Äù</p><p>If ever there was a good illustration of the disconnect we face in trying to make journalism sustainable again, this is it. &nbsp;The tech side that constantly proclaims ‚Äúinformation wants to be free,‚Äù and sees pay-for-journalism as a solved problem through Substack, and the jaded newsroom audience who sees another tech platform trying to come in and get them financially hooked.</p><p>The problem, of course, is that it is not a problem equally felt across these camps. &nbsp;The Hacker News crowd is absolutely correct when they say that news organizations need the traffic coming from social media and aggregators -- they do! -- but that is a sign of addiction, not a healthy ecosystem. &nbsp;And the journalist demographic has every reason to assume the worst, because they have been hurt before.</p><p>The economics of this are simple. &nbsp;</p><p>A few decades ago, people subscribed to newspapers, written on paper, that were delivered every morning. &nbsp;The subscription fee never fully covered the cost of running a newspaper; ads appeared between articles, and that subscription base guaranteed an audience for the sponsors. &nbsp;These publications naively started putting their articles online for free -- if advertising could buoy their business up until this point, why would the web be any different? &nbsp;As the ad market matured, CPMs increased, and slowly, internet advertising started to represent real money.</p><p>But then things went viral. &nbsp;Lots of things. &nbsp;People started sharing news articles they read (or <a href="https://www.washingtonpost.com/news/the-intersect/wp/2016/06/16/six-in-10-of-you-will-share-this-link-without-reading-it-according-to-a-new-and-depressing-study/%20Show%20less">didn‚Äôt read</a>) on social media. &nbsp;Tech companies tweaked their sorting algorithms to get content to eyeballs -- and did so incredibly successfully. But, this created our first problem.</p><h3 id="problem-1-hard-news-doesn-t-trend">Problem 1: Hard news doesn't trend</h3><p>Admittedly, this is only a problem depending on what side of the fence you sit.</p><p>If your goal -- like that of any number of tech companies -- is to get content in front of your users that they will engage with -- then this has been an unmitigated success. &nbsp;However, if you are reporting out a story for a specific audience, not being able to reach them is problematic. &nbsp;</p><p>At this point, the tech side may wonder why if your articles are so great, the audience isn‚Äôt seeking it out. &nbsp;The answer, I suspect, is that the audience does not know it is there.</p><p>Virtually any digital editor will tell you that most traffic bypasses the homepage. &nbsp;Users rarely think &nbsp;‚ÄúI wonder what is happening today?‚Äù and seek out the news site; rather, they are told what is happening by the sorting algorithms and walk away feeling like they are updated. &nbsp;That works to a degree, except that hard news -- especially local news -- does not trend.</p><p>No one shares the summary of last night‚Äôs city council meeting. &nbsp;Even the most damning investigative report will only get so far if it is focused on a small area; users outside the area just won‚Äôt amplify it.</p><h3 id="problem-2-fake-news">Problem 2: Fake News</h3><p>What <em>does</em> trend? &nbsp;The outrageous, crazy things that you want to share with the world. &nbsp;Of course, that‚Äôs not to say all viral headlines are fake, but at this point it seems pretty well accepted that many are.</p><p>Because anyone can write and post anything, these wholly fabricated, or hyper-partisan stories are usually placed in the same regard as those that are rigorously reported and fact-checked. They are then forced to compete against each other for attention.</p><p>Worse yet, these posts can be so malignant that it impugns the reputation of ‚Äúthe media‚Äù -- because now you cannot believe what you read.<br></p><h3 id="problem-3-clickbait">Problem 3: Clickbait</h3><p>How do you compete then? &nbsp;By stooping lower. &nbsp;It means publishers resort to writing clickbait headlines to grab a second or two of user attention, and then covering the article page in more clickbait links to keep them there. &nbsp;</p><p>It can even creep into the editorial decisions: Knowing what people are searching for or clicking on can shape what reporters are assigned. <br></p><h3 id="problem-4-all-the-ads">Problem 4: All the ads</h3><p>Why do drivers in your area need to know about that new law? &nbsp;What celebrity finally ‚Äúbroke [their] silence?‚Äù &nbsp;I <em>know</em> I won‚Äôt believe what happens next. &nbsp;</p><p>These ads are annoying. These ads are detrimental to the user experience that any publication wants. &nbsp;But these ads are needed -- they are a symptom of the addiction. &nbsp;When the flow of users becomes constricted, these organizations have no other choice but to exploit their traffic for as much as it is worth; it‚Äôs survival.</p><p>Those ads in between articles in the print newspaper? &nbsp;They still exist, but they are now sold by Facebook, Twitter, and Google. &nbsp;Money is still being made off of the reader, it just is not going to the people doing the reporting. &nbsp;And partnerships between newsrooms and tech giants are generally for big, national outlets, leaving the local newsroom to suffer.</p><h3 id="problem-5-brain-drain">Problem 5: Brain drain</h3><p>As awful as this all is for the casual news consumer, it is worse for the people working on it all day everyday. &nbsp;No one wants assignment-by-SEO. No one wants the ads all over the place. And most of all, no one wants the layoffs. &nbsp;So those that can are fleeing to Substack, or creating their own publications.</p><p>That is great for them, and I wish them all the best. &nbsp;But as that Reddit commenter pointed out, that only works for reporters who have made a name for themselves. &nbsp;It is much more common to follow someone because you like their ideas than someone who you think reports out a story well. &nbsp;</p><p>What about all of those wide eyed, young, idealistic reporters <em>looking </em>to make a name for themselves? &nbsp;What about all of the important stories <em>they</em> are covering? &nbsp;Will now fewer people go to the legacy publications once the big names jump ship?<br></p><h3 id="what-we-re-doing">What we're doing</h3><p>This is why Xana wrote what she did, and made the case firms should pay up. &nbsp;First, it got your attention enough to rise above the noise (a requirement, as discussed above). And it also presented this point: The traffic coming from big tech, while needed for local news‚Äô survival, is also killing it. The answer cannot be found in robots.txt -- it comes from rethinking the model of how we find our users, and how we interact with them.</p><p>Forth is our answer. &nbsp; </p><p>We want to take what is appealing about discovering news on social, and replicate it, but with reporters we know and trust. &nbsp;We want to help them build personal brands because we know younger generations tend to trust real people over companies or institutions (think: influencers). &nbsp;We want to rev-share, not because we think it is a selling point, but to align our incentives with those of the newsrooms; we both succeed together.</p><p>We will be launching soon in markets where we feel we have enough reporters to make using our app worthwhile. &nbsp;If you are a reporter or represent a newsroom, we would love to hear from you at <a href="mailto:hello@nillium.com">hello@nillium.com</a>. &nbsp;If you want to read what our partners are writing, please sign up for the <a href="https://www.forthapp.com/list.html">waiting list</a> -- we will let you know as soon as we are live in your area.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.nillium.com/news-was-never-meant-for-social-platforms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25360153</guid>
            <pubDate>Wed, 09 Dec 2020 16:13:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief Goodbye to CentOS]]>
            </title>
            <description>
<![CDATA[
Score 176 | Comments 151 (<a href="https://news.ycombinator.com/item?id=25359951">thread link</a>) | @notadeveloper
<br/>
December 9, 2020 | https://www.clementchiew.me/blog/blog-013 | <a href="https://web.archive.org/web/*/https://www.clementchiew.me/blog/blog-013">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<hr>
<header>
		
</header>

<p>The traditional CentOS Linux distribution as we know it is dead. Here is another drop in the ocean of opinion pieces that follow the news of its death. After cooling down from the initial rush of blood to my head, here is my take on this event.</p>

<h2>Why Did This Probably Happen</h2>
<p>With the advent of DevOps and SRE, businesses and startups are moving away from the old-school concept of traditional server clusters to running their applications on disposable containers. The trend is clear and true. Developers are increasingly less reliant on a tried-and-true Linux distribution that lasts for a decade. With containers, developers can develop, test, deploy, and rollback with blazing fast velocity.

</p><h2>How It Will Affect All of Us</h2>
<p>Without a doubt one of the most popular Linux distributions to ever exist, CentOS was prevalent among all kinds of computing systems ranging from simple database servers to billion-dollar computer clusters. There are countless organizations have made the business decision to keep using the traditional model, or organizations that do not require microservices at all. With CentOS drawn from below their feet, a lot of organizations will be forced to migrate to another option, or fork out a pretty penny for RHEL. Besides, on-prem deployment of any container orchestration tool still requires a stable Linux distribution.</p>

<p>The second ripple effect it will have is towards the skilled professionals who have spend decades on CentOS. Not every company is willing to pay up for RHEL or risk using CentOS Stream. For those who migrate to Debian or OpenSUSE, they will have to retrain and adapt with different tools.</p>

<h2>Questioning IBM/Red Hat Decisions</h2>
<p>The most obvious of them all was, was it necessary for CentOS to die? With CentOS Stream to track ahead of RHEL, it is still possible for CentOS to remain functional and serve its purpose. This is clearly a business decision to increase profits. It used to be that developers wanted to write for RHEL but did not want pay for it; CentOS filled that need. What also happened was that some companies decided that they wanted the free experience all the way. Red Hat now provides free use of the Red Hat Universal Base Image for developers. With this, companies no longer have an excuse.</p>

<p>Secondly, why the PR disaster? In hindsight, there is no way to deliver this news gently to the public. However, I felt that Red Hat gave the bird to the open source community, especially those who contributed to CentOS, by pulling the plug on Centos 8 towards the end of 2021. There wasn't even a courtesy to end it later then CentOS 7's EOL date, June 30th 2024. A raw-dogged "Pay up, now" to everyone. </p>

<p>Last of all, what is the next move from Red Hat/IBM? With CentOS gone, there is a huge vacuum for another to take its place. RHEL sources are still available and can still be repackaged. While Red Hat currently has massive influence over Linux in general, is this a arrogant statement proclaiming "Hey, you can't live without me"? Another ominuous take with conspiratorial undertones would be that Red Hat plans to eventually scrap the FOSS model, but I would have to wear my tin hat for this one.

</p><h2>So, What Happens Now?</h2>
<p>Almost immediately after the release, all the attention is now directed to towards filling the space that CentOS will leave behind. Undoubtedly, Ubuntu and SUSE would try to assert their presence with their open source alternatives. Debian, the largest behemoth of them all, hopefully will receive funding and participation like never before. A silver lining of this event would perhaps be the buzzing excitement of what will be and can be. It is time to be excited about Linux again. I, for one, have to begin migrating my CentOS containers and virtual machines to Debian.</p>

<p>CentOS's founder, Gregory Kurtzer, is working with the community to establish Rocky Linux. Join them at https://webchat.freenode.net/#rockylinux .</p>
<hr>
<blockquote>
I doubt that the imagination can be suppressed. If you truly eradicated it in a child, he would grow up to be an eggplant.
<br>
- Ursula K. Le Guin
</blockquote>
</div>]]>
            </description>
            <link>https://www.clementchiew.me/blog/blog-013</link>
            <guid isPermaLink="false">hacker-news-small-sites-25359951</guid>
            <pubDate>Wed, 09 Dec 2020 15:58:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elm, Meet Streamlit]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25359906">thread link</a>) | @kantuni
<br/>
December 9, 2020 | https://blog.streamlit.io/elm-meet-streamlit/ | <a href="https://web.archive.org/web/*/https://blog.streamlit.io/elm-meet-streamlit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.streamlit.io/content/images/size/w300/2020/12/Version3-1.gif 300w,
                            https://blog.streamlit.io/content/images/size/w600/2020/12/Version3-1.gif 600w,
                            https://blog.streamlit.io/content/images/size/w1000/2020/12/Version3-1.gif 1000w,
                            https://blog.streamlit.io/content/images/size/w2000/2020/12/Version3-1.gif 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.streamlit.io/content/images/size/w2000/2020/12/Version3-1.gif" alt="Elm, meet Streamlit">
            </figure>

            <section>
                <div>
                    <p>Let me start this article by saying - I love Elm!</p><p>I enjoy learning new programming languages, and Elm has been my favorite language for almost 2 years now. I like everything about it - compiler error messages, type system soundness, <a href="https://guide.elm-lang.org/architecture/" rel="noopener noreferrer">The Elm Architecture</a>, pure functions, immutability, performance, etc. Around the time I discovered Elm, I got a job at <a href="https://www.streamlit.io/" rel="noopener noreferrer">Streamlit</a>, and I immediately saw the potential for how Elm and Streamlit could work together to supercharge apps. With the release of the Streamlit components architecture earlier this year, this was finally possible, and I'm excited to show you how! To get a taste, check out this awesome Elm <a href="https://terezka.github.io/line-charts/" rel="noopener noreferrer">line charts</a> library embedded into a Python <a href="https://share.streamlit.io/kantuni/streamlit-elm-chart/app.py" rel="noopener noreferrer">data app</a>.</p><p>Before we start, if you're new to Streamlit and would like to learn more about it - check out these two articles "<a href="https://towardsdatascience.com/coding-ml-tools-like-you-code-ml-models-ddba3357eace?sk=f7774c54571148b33cde3ba6c6310086">Intro to Streamlit</a>" and "<a href="https://blog.streamlit.io/introducing-streamlit-components/">Intro to Streamlit components</a>".</p><h2 id="ready-player-one">Ready Player One</h2><p>Here's the "<a href="https://guide.elm-lang.org/">Hello World</a>" of Elm examples:</p><pre><code>
import Browser
import Html exposing (Html, button, div, text)
import Html.Events exposing (onClick)

main =
  Browser.sandbox { init = 0, update = update, view = view }

type Msg = Increment | Decrement

update msg model =
  case msg of
    Increment -&gt;
      model + 1

    Decrement -&gt;
      model - 1

view model =
  div []
    [ button [ onClick Decrement ] [ text "-" ]
    , div [] [ text (String.fromInt model) ]
    , button [ onClick Increment ] [ text "+" ]
    ]

</code></pre><p>It is a simple counter app that demonstrates the simplicity, robustness, and beauty of The Elm Architecture. </p><p>We're going to build a Streamlit app that will use the above example as a Streamlit component. Streamlit components let you expand the functionality provided in the base Streamlit package. You can use Streamlit components to share any web-based UI, widget, or data visualization code with the broader Python data science community.</p><p>Creating a Streamlit component takes - literally - 2 lines of Python.</p><pre><code>
import streamlit as st
import streamlit.components.v1 as components

counter_component = components.declare_component(
    "counter",
    url="http://localhost:3000/",
)

count = counter_component(key="count", default=0)
st.markdown(f"The value of the counter is **{count}**.")

</code></pre><ul><li>We declare a new component by passing the name and the location of the component front-end files (or the URL of your development server).</li><li>We provide the default value for the counter.</li><li>We make sure that the component does not re-render unnecessarily by providing the <code>key</code>.</li></ul><h2 id="brave-new-world">Brave New World</h2><p>To establish a two-way connection between our app and the component, we are going to add <a href="https://guide.elm-lang.org/interop/ports.html" rel="noopener noreferrer">ports</a> to our Elm app.</p><p>To send a message from Elm to Streamlit, let's define a port that receives a number and produces a command.</p><pre><code>
port fromElm : Int -&gt; Cmd msg

</code></pre><p>We will need to send the new value back to Streamlit on <code>Increment</code> and <code>Decrement</code> events. So let's modify our update function to reflect that.</p><pre><code>
Increment -&gt;
    ( { model | count = model.count + 1 }
    , fromElm (model.count + 1)
    )

Decrement -&gt;
    ( { model | count = model.count - 1 }
    , fromElm (model.count - 1)
    )

</code></pre><!--kg-card-begin: markdown--><h2 id="thereandbackagain">There and Back Again</h2>
<!--kg-card-end: markdown--><p>To send a message from Streamlit to Elm, let's define a port that receives a number and produces a subscription.</p><pre><code>
port fromJS : (Int -&gt; msg) -&gt; Sub msg

</code></pre><p>Firstly, we will define a new message type.</p><pre><code>
type Msg
    = Default Int
    | Increment
    | Decrement

</code></pre><p>Secondly, we will add a handler for that message type to update.</p><pre><code>
Default value -&gt;
    ( { model | count = value }
    , Cmd.none
    )

</code></pre><p>And finally, we will subscribe to the messages on that port.</p><pre><code>
subscriptions : Model -&gt; Sub Msg
subscriptions _ =
    fromJS Default

</code></pre><p>When a message from JavaScript is sent to that port, the <code>Default</code> event will get a number and set the counter value to that number.</p><p>And that's <a href="https://share.streamlit.io/kantuni/streamlit-elm-counter/app.py">it</a>!</p><figure><img src="https://blog.streamlit.io/content/images/2020/12/Screen-Recording-2020-12-08-at-03.30.25-PM.gif" alt=""></figure><!--kg-card-begin: markdown--><h2 id="foundation">Foundation</h2>
<!--kg-card-end: markdown--><p>I hope this tutorial will help you build dazzling components in Elm. I believe there are a lot of incredible Elm packages that would boost the look and feel of Python data apps. To give you an idea, <a href="https://package.elm-lang.org/packages/gampleman/elm-visualization/latest/">elm-visualization</a> would make a fantastic Streamlit Component - and there are many, many more. I'm excited to see more people discover the awesomeness of Elm, and I look forward to seeing what you create!</p><p>P.S. <a href="https://share.streamlit.io/kantuni/streamlit-elm-chart/app.py">Both</a> <a href="https://share.streamlit.io/kantuni/streamlit-elm-counter/app.py">apps</a> are available on GitHub and have been deployed using <a href="https://www.streamlit.io/sharing-sign-up">Streamlit sharing</a>.</p>
                </div>
            </section>

            <div>

                <section>

                    <ul>
                        <li>


                            <a href="https://blog.streamlit.io/author/kantuni/">
                                <img src="https://blog.streamlit.io/content/images/size/w100/2020/12/kantuni.jpg" alt="Henrikh Kantuni">
                            </a>

                        </li>
                    </ul>

                    <section>
                        
                        <p><time datetime="2020-12-08">8 Dec 2020</time>
                            <span><span>‚Ä¢</span> 3 min read</span>
                        </p>
                    </section>

                </section>
            </div>



            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.streamlit.io/elm-meet-streamlit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25359906</guid>
            <pubDate>Wed, 09 Dec 2020 15:55:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DAML: A Haskell-Based Language for Blockchain]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25359249">thread link</a>) | @NaeosPsy
<br/>
December 9, 2020 | https://serokell.io/blog/daml-interview | <a href="https://web.archive.org/web/*/https://serokell.io/blog/daml-interview">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Digital Asset is a fintech company that helps companies design and run the next generation of business applications. One of their products is <a href="https://daml.com/">DAML</a>, a functional smart contract language.</p><p>While we have already covered Digital Asset in our <a href="https://serokell.io/blog/functional-programming-in-fintech">functional programming in fintech overview</a>, I recently got a chance to talk with Anthony Lusardi, a developer advocate at DAML, and delve deeper into the product. In the interview, we talk about DAML, the benefits and downsides of functional programming languages, and their practical experience while building DAML.</p><p><strong>Hi! Could you shortly explain what DAML is?</strong></p><p>Sure! DAML is an open-source smart contract language with roots firmly planted in Haskell. It‚Äôs designed so multiple parties/business entities can perform workflows with high assurances and consistency between parties. So you have this transactional language that is atomic with every update, high level, portable across data persistence backends, and with strongly enforced permissions over who can update data when.</p><p>In more practical terms, imagine you‚Äôre managing an operationally complex workflow where multiple different stakeholders (ie. parties) need to see and interact with different parts of the workflow, definitely should not see other parts, and have a complex tree of dependencies. Today implementing such a thing is truly hard to manage with complex access control schemes implemented at a level outside of your program, and substantial difficulties maintaining data privacy. DAML treats these concerns as first-class elements of every class (what DAML calls templates) and thus makes it much easier to implement and manage these types of workflows.</p><p><strong>Why should customers choose DAML over building their project on Ethereum, Tezos, or other public blockchains?</strong></p><p>This really boils down to their needs. If you‚Äôre building something that truly needs permissionless, censorship-resistant, and entirely public transactions, then a public blockchain might be a good fit despite what would be substantial tradeoffs for most real-world applications in terms of low data storage, poor privacy, and high cost. DAML, on the other hand, won‚Äôt give you a permissionless architecture but will allow you to have high data storage, strong privacy, and significantly lower costs.</p><p>In practice, very few use cases actually need the properties of a permissionless public blockchain. The one that comes to mind for me where a public blockchain is a better fit would be Bitcoin for permissionless value storage/transfer.</p><p>While I think there are some interesting projects on Ethereum, I‚Äôm not personally convinced most use cases need Ethereum‚Äôs architecture as, with a few exceptions, most have components that in practice are replaceable and centrally administered by their development team. In such cases, these teams are trading off ease of operation for decentralized architectures and really getting neither. That is, of course, open for extensive theoretical debate that is well beyond the scope of this interview :)</p><p><strong>What‚Äôs the main thing that separates DAML from other enterprise blockchain platforms like Corda and Hyperledger Fabric?</strong></p><p>DAML applications can be written once and deployed on any supported platform without changing a single line of code. In this way, your code written in DAML is decoupled from the underlying backend allowing for much greater architectural flexibility.</p><p>In fact, DAML actually runs on these platforms (and many others) with a runtime that runs alongside them and uses them for data persistence and consensus. It‚Äôll even run on PostgreSQL. It‚Äôs truly platform-agnostic.</p><p><strong>What‚Äôs the benefit of basing DAML on functional programming languages like Haskell and Scala?</strong></p><p>Simple. Functional programmers are the best programmers.</p><p>More seriously, though, the language is based on Haskell but has conventions and differences that make it uniquely its own language. The general benefits are a high degree of composability, as anyone who writes in functional languages knows, when your types match your functions and components can easily work together and extend each other. Functional languages are also beneficial for the more distributed applications that DAML is designed for because they reduce bugs and allow for better ensuring that operations will or won‚Äôt complete; both of which are big concerns whenever you‚Äôre writing a distributed application.</p><p><strong>Are there any features of the language that really help smart contract language development?</strong></p><p>Most definitely. DAML has two features that really help. The first is that all data concerns are laid out in templates and strongly typed. In a lot of ways, these templates are much like classes in imperative languages <strong><em>but</em></strong> they will always do what you expect them to.</p><p>The other feature (and this is really smart-contract specific) is that DAML treats permissions as first-class citizens, so we have observers, signatories, and choices which you can consider respectively akin to UNIX‚Äôs <code>rwx </code>permissions. Every template specifies ahead of time who has the authority to read, write, and execute functions on a given instance of that template (what we call a contract in DAML).</p><p><strong>Have you seen any non-technical benefits? ( e.g. is it easier to hire good developers, etc.)</strong></p><p>Reductions in codebase size and operational complexity are definitely benefits. It‚Äôs really designed from the ground up to allow developers to focus solely on business logic without having to worry about the backend. These factors, in turn, make DAML applications cheaper to maintain and easier to extend. Basically, all the benefits functional programmers have been touting for a long time.</p><p>One other great benefit is readability. While it takes a programmer to write DAML, many non-programmers can comprehend much of a DAML contract with just a little bit of familiarization. This really comes as a direct consequence of how explicit DAML is about data concerns and permissions. You can check out an example of this readability at <a href="https://beer.woah.xyz/">https://beer.woah.xyz</a>.</p><p><strong>What about downsides? Are there any downsides to choosing a programming language for your project that is not that popular?</strong></p><p>There certainly are, but if you‚Äôre reading this blog post, then you probably already use non-mainstream programming languages that are still wonderful and let you get your work done in effective ways that mainstream languages don‚Äôt support. Innovation happens at the edges so I think DAML‚Äôs benefits in the smart contract space and its enthusiastic and supportive engineers on our forum more than outweigh the tradeoffs.</p><p>Really the biggest concern people have is essentially ‚Äúif I choose to invest time in learning this language, will it still be there next year?‚Äù and for that, the answer is yes. DAML is an open-source language maintained by Digital Asset, which is a company of 140+ people currently and growing. DAML will be here for years to come.</p><p><strong>Do you feel happy about your choice to create an FP language for your project?</strong></p><p>I don‚Äôt think you could build a non-functional language that accomplished what DAML does. It‚Äôs really a prerequisite for the rest of the stack. So in that sense, yes, and also the decision was made well before I joined Digital Asset.</p><p><strong>If you had to give one tip to customers looking to come into the blockchain/DLT space, what would it be?</strong></p><p>If the app needs you to first buy a token to use it, then run away.</p><hr><p>I would like to thank Anthony for the interview and wish DAML the best of luck in conquering the private blockchain market!</p><p>If you wish to get more details on DAML, go straight to their <a href="https://daml.com/">homepage</a>. You can also follow DAML on <a href="https://twitter.com/damldriven">Twitter</a> for updates and cool blog articles.</p><p>For more interviews with interesting projects in the functional programming space, be sure to check out the <a href="https://serokell.io/blog/interviews">interview</a> section of our blog.</p></div></div>]]>
            </description>
            <link>https://serokell.io/blog/daml-interview</link>
            <guid isPermaLink="false">hacker-news-small-sites-25359249</guid>
            <pubDate>Wed, 09 Dec 2020 15:10:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Social media was tool to subvert the powerful. When did it become the other way?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25359045">thread link</a>) | @CapitalistCartr
<br/>
December 9, 2020 | https://restofworld.org/2020/when-humor-becomes-horror/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/when-humor-becomes-horror/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>F</span>eel-good moments are difficult to come by on Twitter in Pakistan. In between the political infighting and trolls, though, there was a brief moment where the ugliness the platform often brings out in people gave way to the app‚Äôs potential for humanity.&nbsp;</p>



<p>In October, a Karachi school teacher, Aimun Faisal, tweeted questions from her students about space and space travel. ‚ÄúDo you get scared that your space shuttle might get lost?‚Äù one 10-year-old asked. Ms. Faisal tagged NASA and other space agencies in the post, encouraging readers to retweet it and bring it to their attention. <a href="https://gulfnews.com/world/asia/pakistan/nasa-astronauts-scientists-answer-pakistani-fourth-graders-science-questions-on-twitter-1.1602755591289">It worked</a>.</p>



<p>A Canadian astronaut who has flown in a space shuttle twice replied that he wasn‚Äôt scared because Earth was nearby, and he could use the stars to find his way. ‚ÄúI felt especially comforted when I flew over home,‚Äù <a href="https://twitter.com/Cmdr_Hadfield/status/1316390465277767682?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1316390465277767682%7Ctwgr%5E%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fgulfnews.com%2Fworld%2Fasia%2Fpakistan%2Fnasa-astronauts-scientists-answer-pakistani-fourth-graders-science-questions-on-twitter-1.1602755591289">he tweeted</a>. ‚ÄúHere‚Äôs a photo I took of Karachi ‚Äî can you find your school?‚Äù</p>



<p>It‚Äôs the kind of interaction that leads one to believe that perhaps all you need in life is a Twitter account and a heart that still beats. The media ate it up too: Ms. Faisal and her tweet were in all the major newspapers and even on TV. We were gushy over Ms. Faisal; we wished there were more teachers like her.&nbsp;</p>



<p>Just a few weeks later, people were suggesting that Ms. Faisal should go jump into a river or move to another country.&nbsp;</p>



<p>It all turned after ‚Äî what else? ‚Äî a series of tweets.&nbsp;</p>



<p>One evening this past September, a woman set out in her car on a motorway outside Lahore, her two children in tow. Motorways in Pakistan are safer than most roads there; they have their own police, who have a reputation, unlike other police units, for being well-dressed and resistant to corruption.&nbsp;</p>



<p>That evening, the woman‚Äôs car ran out of fuel. She locked her car doors and made some phone calls, but the rescue service didn‚Äôt answer, and she couldn‚Äôt get through to her family. By now, it was past midnight. She made more calls and waited for a friend to come pick her up. While she waited, two men emerged from the darkness, broke her car window, and when she fought back, took her children into some nearby bushes. She scrambled to save them, and while she fought, she was gang-raped.&nbsp;</p>



<p>In the pre‚Äìsocial media age, if a rape story ever got more than a couple of column inches on the inside pages of a newspaper, the victim not only had asked for it but, by reporting it and making it public, was asking for something more.&nbsp;</p>



<p>In an interview with the <em>Washington Post</em>, Pakistan‚Äôs former president and army chief Pervez Musharraf (now absconded from the country) once said <a href="https://www.washingtonpost.com/archive/politics/2005/09/19/musharraf-denies-rape-comments/5f2e0d4c-5ff2-4273-81e5-878cd59a1744/">Pakistani women get themselves raped so they can get a Canadian visa</a>. He probably thought he was being funny or insightful. When his office denied his having said it, the <em>Post</em> made the audio public. You can hear one of his aides laughing in the background.&nbsp;</p>



<p>Attitudes toward rape haven‚Äôt changed much since the Musharraf days, but there was something about the awfulness of a woman trapped with her children on a motorway at night that struck a chord with the Pakistani public. As the news rippled through Twitter, #LahoreMotorwayIncident became a trending hashtag. The details of the crime were so grotesque that, for a few days, it <a href="https://www.bbc.com/news/world-asia-54186609">seemed the nation actually believed that rape was a crime</a> and that the woman hadn‚Äôt asked for it.&nbsp;</p>



<p>Pakistan‚Äôs traditional and social media go into this kind of outrage cycle when children get raped, or get raped and then killed, which happens more often than one can stomach. There was genuine fury across the country when a 7-year-old girl was raped, strangled, and left in a rubbish heap two years ago. <a href="https://www.dawn.com/news/1439587">Her name was Zainab</a>. On Twitter and Facebook, users argued over whether her rapist and killer should be hanged in public, quartered, doused in acid, or just locked up for life.</p>



<p>After the motorway incident, the usual bloodlust was on display. There were calls for public hangings and for chopping up the culprits. Prime Minister Imran Khan even appeared on a TV interview saying <a href="https://www.cnn.com/2020/09/16/asia/imran-khan-chemical-castration-rapists-intl/index.html">he has been contemplating chemical castration as a punishment for such crimes</a>.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-1228489392-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-1228489392-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-1228489392-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1228489392-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1228489392-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1228489392-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1228489392-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="People protesting in Karachi after the gang rape of a woman on a motorway near Lahore.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Rizwan Tabassum/AFP via Getty Images</span>
			</figcaption>
		</figure>


<p>And while the Lahore rapists were still on the loose, the newly appointed Lahore police chief appeared on one of the nightly news shows during the wall-to-wall media coverage. In effect, he said he was surprised that a mother of two had decided to take the motorway when another road would have sufficed for her journey. And if she had to take the motorway, he went on to ask, couldn‚Äôt she at least have checked her gas tank?&nbsp;</p>



<p>Ms. Faisal, the teacher we had fawned over just weeks prior for her tweets about space travel, was outraged. On Twitter, she was one of many to demand the police chief‚Äôs resignation, tweeting in disgust at the craven responses to the news she and others were seeing, rhetorical questions as to why the woman had failed to prevent her own assault.&nbsp;</p>



<p>In return, our beloved Ms. Faisal was met with a flood of insults; trolls suggested she leave Pakistan if she had a problem with it. Being stuck on the motorway without gas became an internet meme that small-time politicians and social media trolls lobbed at one another. Somewhere along the way, ‚ÄúWhy didn‚Äôt she check her petrol tank before leaving her home?‚Äù replaced the original question: ‚ÄúWhat kind of beasts would rape a woman in front of her children?‚Äù&nbsp;</p>



<p>How did this horror morph into a meme? Does every one of us carry inside us a bit of General Musharraf, smirking while his aides giggle?&nbsp;</p>



<p>Long before we had social media, Pakistan swam through its sea of miseries on the backs of jokes. The mausoleum of Pakistan‚Äôs longest-serving dictator, General Zia‚Äôul Haq, is jokingly referred to as Jaws Square. Guess why? Because, after ruling over us for 11 years, he died in a plane crash, and only his teeth survived.&nbsp;</p>



<p>Jokes back then went viral before we ever began to call them ‚Äúviral.‚Äù You would hear one about the dictator in Urdu in Karachi one day, and the next day in Peshawar, someone would tell you it in Pashto. Jokes eased us out of our terror.&nbsp;</p>



<p>But now the jokes themselves have become the terror. You can make a joke about a dead dictator, or Osama bin Laden becoming fish food, but how do you laugh at a joke about a woman raped in front of her children on the side of the motorway in the dead of night? Jokes were meant to subvert the powerful, not kick the poor to the ground.&nbsp;</p>



<p>For a brief moment, social media in Pakistan made it easy to laugh at despots and oppressors. They answered with troll farms, indoctrinating the youth to be subservient to power. Even in the midst of incidents so nauseating that they capture the attention of our fractured social media, the horrors of which seem undeniable, the trolls find ways to mock and belittle.&nbsp;</p>



<p>In November, another shocking piece of news roiled Pakistan‚Äôs social media: A 4-year-old rape survivor told her gut-wrenching story in a video that went viral. It was so harrowing, I couldn‚Äôt bring myself to watch it, even for reporting purposes. In another video, also shared widely online, the doctor who treated her after the assault broke down crying.&nbsp;</p>



<p>On Twitter, it‚Äôs easy to find redemption in the narrative too. In the middle of the outrage cycle, social media made a hero of the policeman <a href="https://www.gulftoday.ae/news/2020/11/14/pakistani-policeman-uses-own-daughter-as-bait-to-nab-rapists">who had found the girl‚Äôs rapist by enlisting his own daughter to lure him</a>. The rapist was killed in a police encounter.&nbsp;</p>



<p>The policeman and his underage daughter were forced to take this extreme step because there were no women officers in his district. The prime minister called to congratulate the man, and his daughter was awarded a million rupees as a prize along with a guaranteed college scholarship.&nbsp;</p>



<p>Ms. Faisal, who by now has endured a litany of abuses online, questioned the collective satisfaction on social media. As proud as we are of the police officer, she tweeted, the story said more about the country‚Äôs broken system than it did about heroism. ‚ÄúNo police officer should be forced to risk his family to perform his duty,‚Äù<a href="https://twitter.com/bluemagicboxes/status/1327209635594588165"> she wrote</a>.</p>



<p>‚ÄúTum kabhi khush na hona,‚Äù someone tweeted back. ‚ÄúYou‚Äôll never be happy.‚Äù</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/when-humor-becomes-horror/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25359045</guid>
            <pubDate>Wed, 09 Dec 2020 14:53:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YouTube to remove content that alleges widespread election fraud]]>
            </title>
            <description>
<![CDATA[
Score 972 | Comments 2562 (<a href="https://news.ycombinator.com/item?id=25359003">thread link</a>) | @1cvmask
<br/>
December 9, 2020 | https://blog.youtube/news-and-events/supporting-the-2020-us-election | <a href="https://web.archive.org/web/*/https://blog.youtube/news-and-events/supporting-the-2020-us-election">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div tabindex="-1">
            
  <article>
    
    


<div>

<section>
    
    <div>
      
      
      <p>
        <article>
          Updates to our work supporting the integrity of the 2020 U.S. election.
        </article>
      </p>
    </div>
  </section>
</div>


    
      
        



<section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><p>Over the past weeks and months, we‚Äôve seen people coming to YouTube to learn more about where and how to vote or learning more about a candidate or an issue. We‚Äôve seen news organizations grow their audience. And we‚Äôve seen people turn to YouTube for the latest election results or simply to follow an historic event with the highest voting turnout in over a century in the U.S.&nbsp;&nbsp;</p><p>Our main goal going into the election season was to make sure we‚Äôre connecting people with authoritative information, while also limiting the reach of misinformation and removing harmful content. The work here is ongoing and we wanted to provide an update.&nbsp;&nbsp;</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><h2>Removing content that violates our policies</h2><p>Our <a href="https://www.youtube.com/howyoutubeworks/policies/community-guidelines/">Community Guidelines</a> prohibit spam, scams, or other manipulated media, coordinated influence operations, and any content that seeks to incite violence. Since September, we've terminated over 8000 channels and thousands of harmful and misleading elections-related videos for violating our existing policies. Over 77% of those removed videos were taken down before they had 100 views.&nbsp;</p><p>We also work to make sure that the line between what is removed and what is allowed is drawn in the right place. Our policies prohibit misleading viewers about where and how to vote. We also disallow content alleging widespread fraud or errors changed the outcome of a historical U.S. Presidential election. However in some cases, that has meant allowing controversial views on the outcome or process of counting votes of a current election as election officials have worked to finalize counts.&nbsp;</p><p>Yesterday was the safe harbor deadline for the U.S. Presidential election and enough states have certified their election results to determine a President-elect. Given that, we will start removing any piece of content uploaded today (or anytime after) that misleads people by alleging that widespread fraud or errors changed the outcome of the 2020 U.S. Presidential election, in line with our approach towards historical U.S. Presidential elections. For example, we will remove videos claiming that a Presidential candidate won the election due to widespread software glitches or counting errors. We will begin enforcing this policy today, and will ramp up in the weeks to come. As always, news coverage and commentary on these issues can remain on our site if there‚Äôs sufficient <a href="https://blog.youtube/inside-youtube/look-how-we-treat-educational-documentary-scientific-and-artistic-content-youtube/">education, documentary, scientific or artistic</a> context.</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/MostViewed-Elections-Blog_Lists_AddedBorder.png" alt="most viewed u.s. election-related content">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><h2>Connecting people to authoritative information</h2><p>While only a small portion of watch time is election-related content, YouTube continues to be an important source of election news. On average 88% of the videos in top 10 search results related to elections came from authoritative news sources (amongst the rest are things like newsy late-night shows, creator videos and commentary). And the most viewed channels and videos are from news channels like NBC and CBS.</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Election_Results_Blog_437_x_879_1.gif" alt="election results gif">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><p>We also showed information panels linking both to Google‚Äôs election results feature, which sources election results from The Associated Press, and to the Cybersecurity &amp; Infrastructure Security Agency‚Äôs (CISA) ‚ÄúRumor Control‚Äù page for debunking election integrity misinformation, alongside these and over 200,000 other election-related videos. Collectively, these information panels have been shown over 4.5 billion times. Starting today, we will update this information panel, linking to the ‚Äú2020 Electoral College Results‚Äù page from the Office of the Federal Register, noting that as of December 8, states have certified Presidential election results, with Joe Biden as the President-elect. It will also continue to include a link to CISA, explaining that states certify results after ensuring ballots are properly counted and correcting irregularities and errors.</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Fact_Check_Dominion_voting__Michigan_recount.png" alt="fact check">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><p>Additionally, since Election Day, relevant <a href="https://blog.youtube/news-and-events/expanding-fact-checks-on-youtube-to-united-states">fact check information panels</a>, from third party fact checkers, were triggered over 200,000 times above relevant election-related search results, including for voter fraud narratives such as ‚ÄúDominion voting machines‚Äù and ‚ÄúMichigan recount.‚Äù</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Recommended-Elections-Blog_Lists_AddedBorder.png" alt="most recommended u.s. election-related content">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><p>Now let‚Äôs look at recommendations, one of the main ways our viewers find content. Limiting the reach of borderline content and prominently surfacing authoritative information are important ways we protect people from problematic content that doesn‚Äôt violate our Community Guidelines. Over 70% of recommendations on election-related topics came from authoritative news sources and the top recommended videos and channels for election-related content were primarily authoritative news. In fact, the top 10 authoritative news channels were recommended over 14X more than the top 10 non-authoritative channels on election-related content.&nbsp;</p><p>Despite these encouraging results, we recognize there's always more to do. For example, while problematic misinformation represents a fraction of 1% of what's watched on YouTube in the U.S., we know we can bring that number down even more. And some videos, while not recommended prominently on YouTube, continue to get high views, sometimes coming from other sites. We're continuing to consider this and other new challenges as we make ongoing improvements.&nbsp;</p><p>We understand the need for intense scrutiny on our elections-related work. Our teams work hard to ensure we are striking a balance between allowing for a broad range of political speech and making sure our platform isn't abused to incite real-world harm or broadly spread harmful misinformation. We welcome ongoing debate and discussion and will keep engaging with experts, researchers and organizations to ensure that our policies and products are meeting that goal. And as always, we'll apply learnings from this election to our ongoing efforts to protect the integrity of elections around the world.<br></p></div>
      </div>
      
    </div>
  </div>
</section>

      
    

    


<section>
  <article>
    
  </article>
</section>


    
    
  


  </article>


        </div></div>]]>
            </description>
            <link>https://blog.youtube/news-and-events/supporting-the-2020-us-election</link>
            <guid isPermaLink="false">hacker-news-small-sites-25359003</guid>
            <pubDate>Wed, 09 Dec 2020 14:50:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steps to Designing Better Data Structures]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25358738">thread link</a>) | @todsacerdoti
<br/>
December 9, 2020 | https://mochromatic.com/3-steps-to-designing-better-data-structures-in-elixir/ | <a href="https://web.archive.org/web/*/https://mochromatic.com/3-steps-to-designing-better-data-structures-in-elixir/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
            <!--kg-card-begin: html--><p><span><small>Photo by <a href="https://unsplash.com/@alexas_fotos?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Alexas_Fotos</a> on <a href="https://unsplash.com/t/nature?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></small></span></p><!--kg-card-end: html--><p>As developers, one of the most valuable things we can do before we get to the keyboard and start coding, is to figure out what types of data structures our functions and modules will operate on. Why? As you will see below, when we use the right data structures it becomes much easier to write functions that operate on them, which in turn leads to fun and profit!</p><p>The goal of this article is to show you an example of how to approach coming up with good data structures. We'll do this by comparing three different data structures for a <a href="https://en.wikipedia.org/wiki/Tic-tac-toe">Tic Tac Toe</a> board.</p><p>Here's a sneak peek at them. Which one would you bet your lunch money on?</p><figure><img src="https://monicao.s3.amazonaws.com/blog/2020-11-25/tic_tac_toe_boards_elixir.png" alt="boards"></figure><h2 id="a-quick-real-world-example">A quick real-world example</h2><p>But first, let me describe a problem I ran into in the past. I was building an Elixir/Phoenix application that served as a backend to a React client. One of the API endpoints was designed to serve up a large chunk of the current user's state, because &nbsp; &nbsp;we wanted the React application to be very fast after the initial page load. The initial JSON payload looked something like this:</p><pre><code>{
  "user": {
    "id": 1,
    "full_name": "Bob Dobolina",
    "email": "bob@dobo.inc",
    "projects": [
      {
        "id": 1,
        "name": "Project 1",
        "proofs": [
          {
            "id": 1, 
            "title": "A design proof",
            "comments": [...]
          }
        ]
      }
    ]
  }
}
</code></pre><p>On the user's dashboard we show a list of projects, and that's fairly easy to do with this structure. Where things get hairy, is when we render the page that displays a proof along with the comments for that proof. With this deeply nested data structure it would have been a real pain for the React client to traverse the tree and pull the data for a specific proof. The solution was to flatten this data structure and make look-up by id easier. The data structure had to make sense for the main operation we were performing on it, which was data lookup by id.</p><h2 id="the-three-steps">The three steps</h2><p>The examples below are in Elixir, but the general approach applies to any programming language. Here is the general approach:</p><ol><li>Make a list of the operations you will need to perform on the data structure</li><li>Brainstorm some data structures</li><li>Evaluate each data structure by going over the operations you need to perform on them</li></ol><p>At this stage you want to get a sense of whether or not the code will be easy to write and the performance is OK in terms of CPU and memory usage.</p><p>If you are thinking: "I work on web applications for businesses. What could I possibly learn from a Tic Tac Toe game?", I ask for your patience. The takeaways from this article are very relevant to the algorithmic problems we have to solve in our day-to-day work.</p><h2 id="what-are-the-operations-that-will-be-performed-on-the-board">What are the operations that will be performed on the board?</h2><p>First, let's put together a list of the operations that we will perform on the data structure, because without knowing this, we cannot evaluate if the data structures we're coming up with are any good. There are many ways we could represent a 3x3 board, but which one is a good fit for a Tic Tac Toe board? Well, what are some things we need to do with a Tic Tac Toe board?</p><ul><li>Read and write the value at a given coordinate</li><li>Display the board as a 3 x 3 grid in the terminal</li><li>Check the 8 different positions that indicate a win</li><li>Know if the board is full, so we can see if the game is over</li></ul><h2 id="brainstorm-data-structures-and-evaluate-them">Brainstorm data structures and evaluate them</h2><p>For the rest of the article we will be starting off with this board:</p><pre><code>X _ _
_ O _
_ X _
</code></pre><p>Let's try out some data structures and evaluate the pros and cons.</p><h3 id="first-attempt-nested-tuples-of-rows-and-columns">First attempt: Nested tuples of rows and columns</h3><p>Intuitively, when you think of a 3x3 grid you might think of a matrix or two-dimensional array. One way to implement that in Elixir is by using nested <a href="https://hexdocs.pm/elixir/Tuple.html#content">Tuples</a>.</p><p>Side note: Why not use nested Lists here? For functional data structures, it's recommended to use tuples in situations where the position of a value means something. In this case, the position of the outer tuples represents rows, and the inner tuples represent columns.</p><pre><code>{
  {"X", nil, nil},
  {nil, "O", nil},
  {nil, "X", nil}
}
</code></pre><p>Seems like a good start.</p><p>Let's look at our list of operations and get a sense of how easy it will be to write these as functions.</p><p><strong>Reading and writing the value at a given coordinate.</strong></p><p>It's the second player's turn and they want to write an O in the top corner of the board at row 1, col 3.</p><p>To do this we might write a function like <code>write(board, row: 1, col: 3, move: "O")</code>.</p><p>How would you implement this function?</p><p>Since data structures in Elixir are immutable, it means we have to re-create the tuple for row 1 and re-create the board tuple to return an updated board. This is not hard to do, but it's clunky and the code is not very readable.</p><p>We don't have to write out the function to know that this would be unwieldy to implement.</p><p><strong>Displaying the board as a 3x3 grid</strong></p><p>This seems like it will be pretty straightforward if we flatten the nested tuples into a list and iterate over each element.</p><p><strong>Checking the 8 different positions that indicate a win</strong></p><p>Thanks to Elixir's pattern matching, checking if a board has a winning line is fairly easy to read and implement. For example, if you wanted to check if the middle row has a winning line you could write.</p><pre><code>def find_winner(
  {
    {_, _, _},
    {a, b, c},
    {_, _, _},
  }
) when a == b and b == c and !is_nil?(a), do: a</code></pre><p><strong>Knowing if the board is full</strong></p><p>To check if the board is full we can count up all the free tiles, which are represented as <code>nil</code>:</p><pre><code>def board_full?(board)
  num_free_tiles = board
    |&gt; Tuple.to_list
    |&gt; Enum.reduce(0, fn(row, free_spots) -&gt;
      free_in_row = row |&gt; Tuple.to_list |&gt; Enum.count(&amp;is_nil/1)
      free_in_row + free_spots
    end)
  num_free_tiles == 0
end</code></pre><p>Maybe there's a better implementation here, but so far, the code above is not looking very easy to read and maintain.</p><p>Overall, one of the weaknesses of this data structure seems to be that it is nested and accessing a value requires reading two tuples. Also tuples are not that easy to iterate over as we have to convert them to lists, if we want to use those juicy <code>Enum</code> functions.</p><h3 id="second-attempt-map-with-coordinates-as-keys">Second attempt: Map with coordinates as keys</h3><p>In the tuple data structure our biggest issue seemed to be making it easy to access values at a given row and column. Let's try making that easier by creating a <a href="https://hexdocs.pm/elixir/Map.html#content">Map</a> where the keys are the <code>{row, col}</code> coordinate.</p><pre><code>{
  {1, 1} =&gt; "X",
  {1, 2} =&gt; nil,
  {1, 3} =&gt; nil,
  {2, 1} =&gt; nil,
  {2, 2} =&gt; "O",
  {2, 3} =&gt; nil,
  {3, 1} =&gt; nil,
  {3, 2} =&gt; "X",
  {3, 3} =&gt; nil
}
</code></pre><p><strong>Reading and writing to a position</strong></p><p>This becomes easier with this data structure.</p><p>For reading the item at row 1, column 1 we can simply do a lookup by key:</p><pre><code>%{{1, 1} =&gt; val} = board
</code></pre><p>To update the value at row 1, column 3 we can use <code>Map.put</code>:</p><pre><code>Map.put(board, {1, 3}, "O")
</code></pre><p><strong>Checking the 8 different positions to win</strong></p><p>We can apply the same strategy for reading a single value to reading a group of values. For example, here's what it would look like if we used pattern matching to check if the first row had equal values.</p><pre><code>@doc ~S"""
  Takes in a board and returns either "X" or "O" if there is a winner or nil.
  
  Example
  
  iex&gt; TicTacToe.find_winner(
      {
        {1, 1} =&gt; "X", {1, 2} =&gt; "O", {1, 3} =&gt; nil,
        {2, 1} =&gt; nil, {2, 2} =&gt; "X", {2, 3} =&gt; nil,
        {3, 1} =&gt; nil, {3, 2} =&gt; "O", {3, 3} =&gt; "X"
      }
    )
  "X"

"""
# checks if the first row has the same tile 
def find_winner(%{{1, 1} =&gt; a, {1, 2} =&gt; b, {1, 3} =&gt; c})
  when a == b and b == c and !is_nil(a), do: a # check first row
def find_winner(%{{1, 1} =&gt; a, {2, 2} =&gt; b, {3, 3} =&gt; c})
  when a == b and b == c and !is_nil(a), do: a # check \ diagonal
def find_winner(%{{1, 3} =&gt; a, {2, 2} =&gt; b, {3, 1} =&gt; c})
  when a == b and b == c and !is_nil(a), do: a # check / diagonal
# ... and so on for the remaining 5 cases
def find_winner(_board), do: nil
</code></pre><p>This is easy enough to implement, but the code itself is not all that easy to read, in my opinion. From reading the first clause, it's not that easy to see that it deals with checking if the first row has the same tiles. It's always a bit of &nbsp;a code smell to me when I have to add a comment to explain what a line does. Also, the board itself is not very readable in the doctest, not to mention that when you <code>IO.inspect</code> it in IEx it will be even less readable, because each key will be printed on a new line.</p><p><strong>Displaying the board as a 3x3 grid</strong></p><p>Maps in Elixir are not ordered, <a href="https://stackoverflow.com/questions/40392012/is-ordering-of-keys-and-values-preserved-in-elixir-when-you-operate-on-a-map">even though it seems like they are because IEx displays them in order</a>. This means we can't just iterate over the keys and print out the values.</p><p>To display the board we can use a nested loop of row and column ids and look up the values that way.</p><p>This is not ideal. Let's see if we can come up with something better.</p><h4 id="third-attempt-list-of-positions">Third attempt: List of positions</h4><p>Instead of thinking of the board in terms of rows and columns, what if we think of the board with positions from 0 to 8?</p><pre><code>0 1 2
3 4 5
6 7 8
</code></pre><p>In Elixir, we could use a <a href="https://hexdocs.pm/elixir/List.html#content">List</a> to represent this.</p><pre><code>[
  "X", nil, nil,
  nil, "O", nil,
  nil, "X", nil
]
</code></pre><p>This feels like a better fit than the other two! Are your intuition butterflies fluttering yet? Let's double check this intuition by reviewing the operations.</p><p><strong>Reading and writing to a position</strong></p><p>Instead of saying <em>"Player 1 marked X at row 1 column 3"</em>, we would think of it as <em>"Player 2 marked O at position 2"</em>, which is as simple as <code>List.update_at(board, 2, "X")</code>.</p><p>To check if position 2 has already been taken, it's as easy as <code>Enum.at(board, 2)</code>, which is an O(n) operation, but we don't need to worry about the time complexity for this problem at all, because we are dealing with such a small data set.</p><p><strong>Checking the 8 different positions to win</strong></p><p>Just as with the nested tuple example, checking if there is a winning line on the board we can use pattern matching. Let's say you wanted to check if the second row has all the same numbers:</p><pre><code>[
  _, _, _,
  a, b, c,
  _, _, _
] = board
</code></pre><p>How about a diagonal?</p><pre><code>[
  a, _, _,
  _, b, _,
  _, _, c
] = board
</code></pre><p><strong>Knowing if the board is full &amp; Displaying ‚Ä¶</strong></p></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mochromatic.com/3-steps-to-designing-better-data-structures-in-elixir/">https://mochromatic.com/3-steps-to-designing-better-data-structures-in-elixir/</a></em></p>]]>
            </description>
            <link>https://mochromatic.com/3-steps-to-designing-better-data-structures-in-elixir/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358738</guid>
            <pubDate>Wed, 09 Dec 2020 14:24:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How redundant is your dataset?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25358726">thread link</a>) | @isusmelj
<br/>
December 9, 2020 | https://lightly.ai/post/how-redundant-is-your-dataset | <a href="https://web.archive.org/web/*/https://lightly.ai/post/how-redundant-is-your-dataset">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>‚Äç<em>Lots of interesting Deep learning applications rely on the use of complex architectures fueled by large datasets. With the growing storage capacities and ease of data collection [1], it is very easy to build a large dataset. However, when doing so, one ends up with lots of redundancies within the dataset. Many of these redundancies are systematically introduced by the data collection process: consecutive frames extracted from a video, very similar images collected from the web.</em></p><p>‚Äç</p><p><em>In this blog post, we present the results of a benchmark study showing the benefits of filtering redundant data.</em></p><p>‚Äç</p><p>Redundancies can take multiple forms, the simplest one is having exact image duplicates. Another form is near-duplicates, i.e images shifted with few pixels across some direction or images having slight light changes. These redundancies not only lead to biased results of the model‚Äôs performance, be it accuracy or mean average precision mAP score, but also lead to high annotation costs. In addition, redundancies have also been observed in very known academic datasets: CIFAR-10, CIFAR-100, and ImageNet [2,3].</p><p><em>This benchmark study investigates the effect of redundancies in the image-based datasets collected by AI Retailer Systems (AIRS), an innovative start-up developing a checkout-free solution for retailers, which concentrates to answer ‚Äúwho picks up what?‚Äù. In this study, we consider an object detection task. An intelligent vision system recognizes products on a shelf or on a customer‚Äôs hand. This study was done as part of my role as a machine learning engineer at Lightly, a tech-based start-up that provides a solution to improve the Machine Learning workflow by finding and removing redundancies in unlabeled data.</em></p><p>This blog post will be structured as follow, we start by describing the dataset, we list the methods used in this study. We present the results obtained and finally, we discuss the importance of filtering redundant data.</p><p>‚Äç</p><h3>AI Retailer System dataset</h3><figure id="w-node-fb91938a7325-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc116f1e87ac1_1*d-3gi2AuKFbrOm7UnfCIQg.gif"></p><figcaption>Short video sample extracted from AIRS video.</figcaption></figure><p>‚Äç</p><p>The dataset used consists of images extracted from short videos capturing a customer grabbing different products. There are two different cameras recording videos of the shelf, each camera has a different angle of view. There are 12 different kinds of products -12 classes.</p><p>The dataset has been manually annotated using the open-source annotation tool Vatic, we measured the annotation rate: number of frames per time unit. In our case this was 2.3 ¬± 0.8 frames per minute, given that there are 51 objects on average in each image, this is equivalent to 0.51 seconds for each bounding box.</p><figure id="w-node-16a5839147a8-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc10ddee87ac3_1*Yzs8PZV1FB_MJ5b38ngf-A.png"></p><figcaption>Sample image from Camera 1 with annotations: the box color does not represent the article class.</figcaption></figure><p>‚Äç</p><figure id="w-node-ff8edff111f8-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc1e0c0e87ac4_1*_dvPbzOu1xxvWH3otGcalA.png"></p><figcaption>Sample image from Camera 2 with annotations: the box color does not represent the article class.</figcaption></figure><p>‚Äç</p><p>The annotated dataset has 7909 images. The training dataset has 2899 images, 80% of these images are from camera 2 and 20% from camera 1. For the test dataset, it has 5010 images and all of them from camera 1.</p><figure id="w-node-da318627f465-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc1f6afe87ad4_1*bI7L8tkO5M0ohX70o-MqYg.png"></p><figcaption>Visualization of the train-test setting for AIRS dataset.</figcaption></figure><p>‚Äç</p><p>This specific design of the train and test datasets was motivated by the following points: First, we build an imbalanced dataset with a high fraction of images coming from one camera. Second, we make the object detection task hard for the model. With this train-test setting, we can calculate the fraction of images from Camera 1 in the filtered data. Therefore, we can see if there is any re-balancing that is introduced by the different filtering methods used.</p><p>Next, we present the methods used in this case study.</p><p>‚Äç</p><h3>Active learning and Sampling methods</h3><p>To probe the effects of filtering the dataset, we borrowed ideas from the field of <strong>Active learning</strong>.</p><figure id="w-node-04f7b8ea6774-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc1a186e87ae5_1*OQsiXePTV5fesdkxPB-sIw.png"></p><figcaption>Active learning loop used in this case study.</figcaption></figure><p>‚Äç</p><p>Active learning aims at finding a subset of the training data achieving the highest possible performance. In this study, we used the pool-based active learning loop that works as follows: Start with a small fraction of the training dataset called the labeled pool. Train a model on this labeled pool. Then, use the model along with a filtering method to select new data points that should be labeled. Add the newly selected samples to the labeled pool and finally train the model from scratch on the updated labeled pool. After each cycle, we report the model‚Äôs performance on the test dataset for each filtering method used. In our case, we used 5% of the training data as the initial labeled pool, we trained the model for 50 epochs, and we added 20% of the training data in each active learning loop.</p><p>The object detection model used in this benchmark study is YOLO V3 (You Only Look Once) [4]. We used the implementation provided by the Ultralytics Github repository. The code was slightly modified in order to introduce the active learning loop.</p><p>As for the filtering methods, we used four different filtering methods provided by Lightly:</p><ul role="list"><li>‚Äú<strong>RSS</strong>‚Äù: Refers to random sub-sampling which will be used as a baseline.</li><li>‚Äú<strong>WTL_unc</strong>‚Äù: This method refers to Lightly uncertainty based sub-sampling, it selects difficult images that the model is highly uncertain about. The uncertainty is assessed using the model‚Äôs predictions.</li><li>‚Äú<strong>WTL_CS</strong>‚Äù: This method uses image representations to select images that are both diverse and difficult. It combines uncertainty-based sub-sampling with diversity selection. The image representations are obtained using state-of-the-art self-supervised learning methods using the PIP package Boris-ml. The advantage of self-supervised learning methods is that they don‚Äôt require annotations to generate image representations.</li><li>‚Äú<strong>WTL_pt</strong>‚Äù: Relies on pre-trained models to learn image representations, the filtering is performed by removing the most similar images. Similarity in this case is given by the L2 distance between image representations.</li></ul><p>Both methods ‚Äú<strong>WTL_unc</strong>‚Äù and ‚Äú<strong>WTL_CS</strong>‚Äù use active learning since they use the deep learning model to decide which data points to filter. Whereas the ‚Äú<strong>WTL_pt</strong>‚Äù method does require neither labels nor a deep learning model to filter the dataset. For curious readers, this article presents a comprehensive overview of different sampling strategies used in active learning.</p><p>‚Äç</p><h3>Benchmark study results</h3><p>We present the results of these experiments below.</p><figure id="w-node-08c3a0c158ed-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc18dece87ae7_1*e7rBEziO4Nc3Ci_SqTlAjQ.png"></p><figcaption>Averaged mAP score for different fractions of the training dataset using 4 seeds.</figcaption></figure><p>‚Äç</p><p>We see that the mAP score is low at small fractions of the training dataset. We observe that mAP score saturates when using only 25% of the training data and reaches a value of 0.8. Above the saturation point, the mAP score increases very slowly until it reaches its highest value of 0.84. The saturation at low fractions of the training dataset indicates that there are lots of redundancies in the dataset.</p><p>We notice that for small fractions, i.e 5%, the ‚Äú<strong>WTL_CS</strong>‚Äù filtering method is significantly better than the random baseline. As for high fractions, i.e 85%, the ‚ÄúWTL_pt‚Äù is able to <strong>achieve the same performance achieved when using the full training dataset</strong>. The ‚Äú<strong>WTL_unc</strong>‚Äù method is on par or worse with the random sub-sampling method ‚Äú<strong>RSS</strong>‚Äù.</p><p>Given that the saturation is reached within a small fraction of the training dataset, we perform a ‚ÄúZoom-in‚Äù experiment where we evaluate the model‚Äôs performance using fractions of the training dataset between 5% and 25%. In this experiment, we drop the ‚Äú<strong>WTL_unc</strong>‚Äù for its poor performance.</p><figure id="w-node-21c991b3b9ce-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc1bf0be87ae9_1*7MHwyOMtGEauLxja2J9LjA.png"></p><figcaption>Zoom-in experiment: Averaged mAP score for different fractions of the training dataset using 4 seeds.</figcaption></figure><p>‚Äç</p><p>We see in the results above that the sampled subsets using ‚Äú<strong>WTL_CS</strong>‚Äù and ‚Äú<strong>WTL_pt</strong>‚Äù methods consistently outperform random sub-sampling. In addition, using only 20% of the training dataset, the ‚Äú<strong>WTL_CS</strong>‚Äù sampling method is able to achieve a mAP score of 0.80. <strong>We achieve 90% of the highest mAP score using only 20% of the training dataset</strong>.</p><p>‚Äç</p><h3>Why ‚ÄúWTL_CS‚Äù and ‚ÄúWTL_pt‚Äù perform better than random sub-sampling ‚ÄúRSS‚Äù</h3><p>To answer this question, we make a simple comparison between the images selected with the ‚Äú<strong>RSS</strong>‚Äù method with the images selected with ‚Äú<strong>WTL_CS</strong>‚Äù and ‚Äú<strong>WTL_pt</strong>‚Äù. For this purpose, we compute the fraction of images from camera 1 in the selected samples for different fractions of the training dataset and for different filtering methods. This comparison is done in both the normal and the zoom-in experiments. Note that in the training dataset, the original fraction of images from Camera 1 is around 20%.</p><p>‚Äç</p><figure id="w-node-75ccc62a0fd7-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc1ea99e87aeb_1*lQiGxxeXL_KGcJHNKR1FSQ.png"></p><figcaption>The fraction of Camera 1 images in the sampled images as a function of fraction of the training dataset.</figcaption></figure><figure id="w-node-d81505eb589c-e7e87989"><p><img alt="Image for post" src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/5f7ac1d59a6fc1624be87aea_1*6qU_7ccA6-ic0C4ZgQWuNg.png"></p><figcaption>Zoom-in experiment: Fraction of Camera 1 images in the sampled images as a function of the fraction of the training dataset.</figcaption></figure><p>‚Äç</p><p>We see that the sampling methods ‚Äú<strong>WTL_CS</strong>‚Äù and ‚Äú<strong>WTL_p</strong>t‚Äù select more samples from Camera 1 and therefore, they re-balance the sub-sampled training dataset. This explains the gain in performance obtained using different samplings other than random sub-sampling. Since both ‚Äú<strong>WTL_CS</strong>‚Äù and ‚Äú<strong>WTL_p</strong>t‚Äù methods select non-redundant data, they choose more images from camera 1, and therefore the sub-sampled dataset is more diverse.</p><p>‚Äç</p><h3>Summary and outlook</h3><p>In this case study, we have seen the importance of filtering the redundancies within a dataset. We have found the following results:</p><ul role="list"><li>The AIRS dataset contains lots of redundant images.</li><li>Achievement of the highest mAP score using only 85% of the training dataset.</li><li>Achievement of 90% of the highest mAP using only 20% of the training dataset.</li><li>Filtering re-balanced the AIRS dataset.</li></ul><p>This benchmark study showed the importance of filtering redundant data. With Lightly filtering methods, it was possible to achieve <strong>annotation costs reductions between 15% and 80%</strong>. We found lots of redundancies in the AIRS dataset even though it was collected in a controlled environment: There is at least one customer in each video and the customer grabbed different products. We expect the redundancies to be more pronounced in a general uncontrolled case where different customers grab products at a supermarket.</p><p>Anas, Machine Learning Engineer,<br>lightly.ai</p><p>‚Äç</p><p>‚Äç</p><p>[‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lightly.ai/post/how-redundant-is-your-dataset">https://lightly.ai/post/how-redundant-is-your-dataset</a></em></p>]]>
            </description>
            <link>https://lightly.ai/post/how-redundant-is-your-dataset</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358726</guid>
            <pubDate>Wed, 09 Dec 2020 14:23:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Ruby 3 Three Times Faster?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25358524">thread link</a>) | @todsacerdoti
<br/>
December 9, 2020 | https://codefol.io/posts/is-ruby-3-actually-three-times-faster/ | <a href="https://web.archive.org/web/*/https://codefol.io/posts/is-ruby-3-actually-three-times-faster/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <!-- .post-header -->
            <div>
                  
<figure>
    <p><img src="https://codefol.io/img/RadioRepair_aside_216_162.png" alt="A chalk figure kneeling to repair (possibly) a radio." width="216" height="162" title="We're Still Mid-Upgrade">
    </p>

      <figcaption>
        We're Still Mid-Upgrade
        
        
      </figcaption>
</figure>

                <p>Ruby 3x3 announced that Ruby 3.0 would be three times as fast as Ruby 2.0. It was an audacious goal, especially for <a href="https://en.wikipedia.org/wiki/Ruby_(programming_language)">a language released in 1995</a>.</p>

<p>Ruby 3 is due to be released in less than a month. They‚Äôre hard at work on some of the features, but non-JIT performance is pretty close to release speed. If they pull another 5%-10% speed increase at the last minute (which <a href="https://bugs.ruby-lang.org/issues/14104">happened for Ruby 2.5</a>!) it‚Äôll be surprising. The current performance is basically the ‚Äúreal‚Äù Ruby 3 performance.</p>

<p>So‚Ä¶ Did it happen? Is Ruby 3 really three times the speed?</p>

<p>The answer is a little complicated, but overall it‚Äôs ‚Äúyes.‚Äù</p>

<p>Now: let‚Äôs hit the <strong><em>real</em></strong> answer and the details. That‚Äôs the fun part.</p>

<h2>Who‚Äôs This Guy?</h2>

<p>Why listen to me? Well, I wrote <a href="https://github.com/noahgibbs/rails_ruby_bench">one of the two official Ruby 3 benchmarks</a>. I <a href="https://engineering.appfolio.com/appfolio-engineering/2016/6/3/ruby-fellow-hired">worked for AppFolio on Ruby 3</a> for about three years. I keep track of this stuff pretty closely. But mostly I‚Äôll be linking to other posts I wrote for <a href="https://engineering.appfolio.com/">AppFolio</a> and on <a href="https://fastruby.io/blog">FastRuby</a> and maybe elsewhere. They all have open source code. Feel free to check me!</p>

<h2>What‚Äôs Performance, Exactly?</h2>

<p>A language doesn‚Äôt have one speed. When somebody says ‚Äúlanguage X is 2.5 times as fast as language Y,‚Äù that‚Äôs always an approximation. All languages run ‚Äúsleep‚Äù at exactly the same speed, and two of them may use the exact same regexp library. But maybe variable assignment is way faster in one language than another, while the second language is better at optimising away stack variables.</p>

<p>In other words, performance is a million little things that are faster‚Ä¶ or they‚Äôre slower or they‚Äôre the same. We take an average and hand-wave. That‚Äôs okay. It‚Äôs how humans deal with complicated things.</p>

<p>Benchmarks are all lies because of this. <a href="https://engineering.appfolio.com/appfolio-engineering/2019/1/7/microbenchmarks-vs-macrobenchmarks-ie-whats-a-microbenchmark">Little operations make for dramatic benchmarks, and big operations make (if you‚Äôre lucky) representative ‚Äúworkload benchmarks.‚Äù</a> We can‚Äôt make a benchmark <strong><em>not</em></strong> lie. We can only pick our favourite lie.</p>

<h2>What‚Äôs Our Favourite Lie?</h2>

<p>Here are two favourite lies, embodied by my benchmark (Rails Ruby Bench) and <a href="https://twitter.com/mametter">Mame-san‚Äôs</a> benchmark, <a href="https://github.com/mame/optcarrot">OptCarrot</a>.</p>

<p>One favourite lie is this: Ruby performance means Rails performance. How is Ruby 3‚Äôs Rails performance?</p>

<p>It turns out it <a href="https://www.fastruby.io/blog/rails/performance/ruby/hows-the-performance-of-ruby-3.0.0-preview1.html">hasn‚Äôt changed significantly</a> <a href="https://engineering.appfolio.com/appfolio-engineering/2019/12/27/ruby-270s-rails-ruby-bench-speed-is-unchanged-from-260">since Ruby 2.6</a>. It also turns out <a href="https://engineering.appfolio.com/appfolio-engineering/2019/3/7/ruby-speed-roundup-20-through-26">it <strong><em>got far better</em></strong> from Ruby 2.0 to 2.6</a>.</p>

<p>We don‚Äôt know the exact final performance of Ruby 3.0. Watch for a benchmark from me in January! But it‚Äôs going to look a lot like Ruby 2.6 and Ruby 2.7.</p>

<p>And that means a large Rails app‚Äôs performance has increased by over 70% since Ruby 2.0.</p>

<p>Let‚Äôs be clear: <strong><em>that‚Äôs a lot</em></strong>.</p>

<p>That‚Äôs total end-to-end performance to handle HTTP requests in parallel. It uses the same exact Ruby code with the same exact SQL queries, attached to Redis and Postgres and real service with a <a href="https://github.com/discourse/discourse">real big open-source Rails app</a> that people actually use.</p>

<p>In other words, <strong><em>the Ruby part of that performance has increased by a lot more than 70%</em></strong>, because everything that isn‚Äôt Ruby is the exact same in my tests.</p>

<p>A lot of a Rails app isn‚Äôt Ruby time. It‚Äôs waiting for the database. It‚Äôs waiting for the disk. The web server is serving static files. A Rails app does a lot of non-Ruby stuff, and it should.</p>

<p>A Rails app wasn‚Äôt going to triple in speed. It‚Äôs doing too much non-Ruby stuff. Realistically, the Ruby part hasn‚Äôt tripled in speed. I don‚Äôt have exact numbers, but it would be fair to estimate around 2.5x. It would be very hard to get an accurate only-the-Ruby-parts number, for all kinds of good reasons.</p>

<p>Still, 2.5x is very, very good. Ruby 3.0 will have a big jump in Rails performance, but most people are already using it.</p>

<p>Ractors (a new Ruby 3 concurrency primitive) will also pave the way for later speedups if Rails takes advantage of them. Like threads, it‚Äôll take time and changes to the framework. And right now, <a href="https://www.fastruby.io/blog/ruby/performance/how-fast-are-ractors.html">Ractors‚Äô performance is underwhelming</a>. But they‚Äôre also a not-yet-released new feature, so there‚Äôs a lot of room to improve.</p>

<h2>Our Other Favourite Lie</h2>

<p>Other than Rails performance, what matters?</p>

<p>One other answer is ‚Äústraight-line CPU performance on a CPU-intensive benchmark.‚Äù And for that we‚Äôll turn to OptCarrot, an <a href="https://engineering.appfolio.com/appfolio-engineering/2017/9/22/optcarrot-an-excellent-cpu-benchmark-for-ruby-3x3">excellent Ruby 3 benchmark</a>. It runs a headless Nintendo (NES) emulator as fast as it can, which is a fun way to measure.</p>

<p>Rails didn‚Äôt benefit from <a href="https://engineering.appfolio.com/appfolio-engineering/2019/7/18/jit-and-rubys-mjit">Ruby‚Äôs new-ish opt-in JIT system</a>. MJIT is <a href="https://engineering.appfolio.com/appfolio-engineering/2019/7/19/how-mjit-generates-c-from-ruby-a-deep-dive">a complicated beast</a> with interesting trade-offs. If you turn it on then Rails Ruby Bench gets slower, not faster.</p>

<p>But OptCarrot is exactly what MJIT was designed for and it does really well with it.</p>

<p><a href="https://speakerdeck.com/k0kubun/ruby-3-dot-0-jit-on-rails?slide=9">Ruby 3.0 recently hit 3x Ruby 2.0‚Äôs performance with JIT</a>. We‚Äôre there. Assuming they can keep performance that good for the actual release, Ruby 3.0 manages 3x the frames that Ruby 2.0 did.</p>

<p>The answer, then, is a straightforward ‚Äúyes.‚Äù</p>

<p>Note that JIT does <strong><em>not</em></strong> ‚Äúmake Ruby three times faster.‚Äù It‚Äôs that Ruby 3.0, which is already a lot faster than Ruby 2.0, is three times as fast <strong><em>as Ruby 2.0</em></strong> with JIT turned on. It‚Äôs fast without JIT, but not a full three times the speed of Ruby 2.0.</p>

<p>Make sense?</p>

<h2>What‚Äôs the Score, Then?</h2>

<p>It‚Äôs been nearly eight years since Ruby 2.0. There have been a lot of performance changes. The generational garbage collection in Ruby 2.4 is <strong><em>hugely</em></strong> faster than the much simpler 2.0 GC. <a href="https://github.com/Shopify/bootsnap">BootSnap</a> has made bootup in Rails far faster. If you remember back to Ruby 1.8.7 in 2008, Ruby has more-than-doubled in speed to Ruby 2.0, and then tripled again for Ruby 3.0. The OptCarrot results are more like 10x from Ruby 1.8.7 to Ruby 3. A 10x speedup in 10 years? Not bad for a language that just turned 25.</p>

<p>It‚Äôs been a long trip. And that‚Äôs without going into the other two parts of Ruby 3 ‚Äî concurrency and type safety, both of which are separate major efforts.</p>

<p>Is Ruby 3 really three times the speed of eight-years-ago Ruby? Day-to-day, yes, it absolutely is. The Rails speedup is more like double than triple in practice since a lot of Rails time isn‚Äôt Ruby. But double isn‚Äôt bad! And CPU-intensive code is now solidly three times the speed.</p>

<p>You can judge the concurrency and type-safety of Ruby 3 for yourself. But <em>I‚Äôm going to call the performance goal a solid success</em>.</p>

<p>Sure, we have to wait a month. Ruby 3 will actually be released on 25th December of 2020. But all the signs are good.</p>

<p>You can also play with <a href="https://www.ruby-lang.org/en/news/2020/09/25/ruby-3-0-0-preview1-released/">Ruby 3.0.0-preview1</a> right now, and I‚Äôm sure there will be at least one more before the final release.</p>

            </div>
            
        </article></div>]]>
            </description>
            <link>https://codefol.io/posts/is-ruby-3-actually-three-times-faster/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358524</guid>
            <pubDate>Wed, 09 Dec 2020 14:04:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NumPy ‚Äì Ndarray Object]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25358495">thread link</a>) | @Eyssant
<br/>
December 9, 2020 | https://www.alphacodingskills.com/numpy/numpy-ndarray.php | <a href="https://web.archive.org/web/*/https://www.alphacodingskills.com/numpy/numpy-ndarray.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  

<hr>

<hr>
<p>Ndarray is the n-dimensional array object defined in the numpy. It stores the collection of elements of the same type. Elements in the collection can be accessed using a zero-based index. Each element in an ndarray takes the same size in memory.</p>
<h2>Create a Numpy ndarray object</h2>
<p>A Numpy ndarray object can be created using <span>array()</span> function. A list, tuple or any array-like object can be passed into the array() function to convert it into an ndarray. The syntax for using the function is given below:</p>
<h3>Syntax</h3>
<div>
<pre>numpy.array(object, dtype=None, copy=True, order='K', subok=False, ndmin=0)
</pre>
</div>
<br><h3>Parameters</h3>
<table>
<tbody><tr><td><code>object</code></td>
<td><code>Required. </code>Specify the collection object to be converted into ndarray. It can be list, tuple, set, dictionary etc.</td></tr>    
<tr><td><code>dtype</code></td>
<td><code>Optional. </code>Specify the desired data type. It is used to change the data type of the array element.</td></tr>
<tr><td><code>copy</code></td>
<td><code>Optional. </code>Specify True to copy the object, False otherwise.</td></tr>
<tr><td><code>order</code></td>
<td><code>Optional. </code>Specify order. It can take four possible values.
<ul>
	<li>'C' - for C order (row major).</li>
	<li>'F' - for F order (column major).</li>
	<li>'A' - unchanged if copy=False. If copy=True, F and C order preserved.</li>
	<li>'K' - unchanged if copy=False. If copy=True, When the input is F and not C then F order otherwise C order.</li>
</ul>
</td></tr>
<tr><td><code>subok</code></td>
<td><code>Optional. </code>Specify True to make the returned array sub-classes pass through. By default, the returned array forced to be base class array.</td></tr>
<tr><td><code>ndmin</code></td>
<td><code>Optional. </code>Specify the minimum dimension of the array.</td></tr>
</tbody></table><br>

<h3>Example: Create 1-D Array</h3>
<p>In the below example, a list is used to create a 1-D numpy array.</p>

<div>
<pre>import numpy as np
MyList = [1, 2, 3, 4, 5]
npArray = np.array(MyList)
print(npArray)
</pre>
</div>
<p>The output of the above code will be:</p>

<br>

<h3>Example: Create 2-D Array</h3>
<p>In this example, a list of lists is used to create a 2-D numpy array. </p>
<div>
<pre>import numpy as np
MyList = [[1, 2, 3], [4, 5, 6]]
npArray = np.array(MyList)
print(npArray)
</pre>
</div>
<p>The output of the above code will be:</p>

<br>

<h3>Example: Create 2-D Array using ndmin parameter</h3>
<p>A n-dimensional array can be created using <span>ndmin</span> parameter of the array function. Like, in this example, it is used to create 2-D array. </p>
<div>
<pre>import numpy as np
MyList = [1, 2, 3, 4, 5]
npArray = np.array(MyList, ndmin=2)
print(npArray)
</pre>
</div>
<p>The output of the above code will be:</p>

<br>

<h3>Example: Create 1-D Array with dtype parameter</h3>
<p>The <span>dtype</span> argument is used to change the data type of elements of the ndarray object. </p>
<div>
<pre>import numpy as np
MyList = [1, 0, 0, 1, 0]
npArray = np.array(MyList, dtype=bool)
print(npArray)
</pre>
</div>
<p>The output of the above code will be:</p>
<div>	
<pre>[ True False False  True False]
</pre>
</div>


<hr>



<!-- 2nd column end -->
</div></div>]]>
            </description>
            <link>https://www.alphacodingskills.com/numpy/numpy-ndarray.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358495</guid>
            <pubDate>Wed, 09 Dec 2020 14:01:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring Business in the UK]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25358471">thread link</a>) | @logikblok
<br/>
December 9, 2020 | https://logikblok.github.io/sketches/ukbusiness/index.html | <a href="https://web.archive.org/web/*/https://logikblok.github.io/sketches/ukbusiness/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

  <!-- Primary Page Layout ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  
  <!-- Introduction ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  
  <!-- 1. What is a business in the UK? ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <div>
    <section>
      <a name="question1"></a>
      <h3>1. What does it mean to be a business in the UK?</h3>
      <blockquote>
        <p>
          <b>In summary:</b> A business is a legally recognised unit producing goods or services and usually paying taxes. They are categorised by a series of defined codes. Business statistics make use of a register, referenced as
          <em>enterprises</em> or they are <em>estimated</em>, this is because some are too small to be registered.
        </p>
      </blockquote>
      <p>Being a business first invovles a type of registration or formation. There are three common ways people go about doing this in the UK:</p>
      <ul>
        <li>Individuals can do business by registering as a <em>sole trader</em>.</li>
        <li>Individuals or groups can incorporate a <em>company</em>.</li>
        <li>Groups can come together and register as a <em>partnership</em>.</li>
      </ul>
      <p>There are lots more business structures available. People choose a structure that works best how they plan to operate, how many people are responsible and other considerations.</p>
      <p>Due to the variety of ways a business can operate and the need for alignment to the same concepts, the core sets of UK statistics make use of two elements the Inter-Departmental Business Register (<a href="https://www.ons.gov.uk/aboutus/whatwedo/paidservices/interdepartmentalbusinessregisteridbr">IDBR</a>) and the Business
              Population Estimates <a href="https://www.gov.uk/government/statistics/business-population-estimates-2019">(BPE)</a> to <em>analyse</em> businesses as a whole.</p>
      <p>When using data that uses the IDBR in particular and refering to a single business in the UK, we are actually
        refering to an <em>enterprise unit</em>.</p>
      <blockquote cite="https://www.ons.gov.uk/businessindustryandtrade/business/activitysizeandlocation/bulletins/ukbusinessactivitysizeandlocation/2019">
        <p>
          The term ‚Äúbusiness‚Äù is used to represent an enterprise. An enterprise can be defined as the smallest combination of legal units (generally based on VAT and/or PAYE records) that is an organisational unit producing goods or services, which
          benefits from a certain degree of autonomy in decision-making, especially for the allocation of its current resources. <a href="https://www.ons.gov.uk/businessindustryandtrade/business/activitysizeandlocation/bulletins/ukbusinessactivitysizeandlocation/2019">via ONS</a>
        </p>
      </blockquote>
      <p>However businesses can be so small that the register may not include them, which is where we can make use of the <a href="https://www.gov.uk/government/statistics/business-population-estimates-2019">Business
          Population Estimates</a> (BPE):</p>
      <blockquote cite="https://www.gov.uk/government/statistics/business-population-estimates-2019">
        <p>[As] there is no single database in the UK which contains details of every active
          business. The [BPE] takes data on businesses on the IDBR, and then <em>estimates the number of additional very small businesses
            unregistered for VAT or PAYE</em> <a href="https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/836574/METHODOLOGY___QUALITY_NOTE_BPE.pdf">via BEIS</a></p>
      </blockquote>
      <p>So we can use <em>both</em> these data sets to get a general picture of what's happening in the UK. For more on the differences <a href="https://www.gov.uk/government/statistics/guide-to-business-statistics">this guide</a> offers a good overview. More detail on the data used is available <a href="https://logikblok.github.io/sketches/ukbusiness/data.html#IDBRandBPE">here</a>.</p>
      <p>Next, we also need to consider Standard Industrial Classifications or (<a href="https://www.ons.gov.uk/methodology/classificationsandstandards/ukstandardindustrialclassificationofeconomicactivities/uksic2007">SIC codes</a>). Just like
        the variety of structures there are a large number of things a business can do to meet the needs of it's customers. So to capture what businesses typically do, SIC codes are used to classify economic activites.</p>
      <blockquote cite="https://www.ons.gov.uk/methodology/classificationsandstandards/ukstandardindustrialclassificationofeconomicactivities/uksic2007">
        <p>A Standard Industrial Classification (SIC) was first introduced into the UK in 1948 for use in classifying business establishments and other statistical units by the type of economic activity in which they are engaged.<a href="https://www.ons.gov.uk/methodology/classificationsandstandards/ukstandardindustrialclassificationofeconomicactivities/uksic2007">via ONS</a></p>
      </blockquote>
      <p>Let's explore some of these now. Press the button below to see an example SIC code and it's description.</p>
      
      <code>
        <p id="sicCode">1110,Growing of cereals (except rice), leguminous crops and oil seeds</p>
      </code>
      
      <p>As you can see the codes have a number and a description. The number code can be used to identify the activities of a business into an area and the descriptions can provide further context.</p>
      <p>These activities are organised into <em>classes or subclasses</em>, <em>groups</em>, <em>divisions</em>, <em>sections</em> and <em>broad industry groups (BIG)</em>. The chart below provides an outline of the breakdown with the number of each
        categorisation level and an example
        using <em>25.91 Manufacture of steel drums and similar containers</em>.</p>
      
      
      <p>Complex businesses can apply multiple SICs to themselves. For example, a software firm might list themselves engaging in design, software
        development, professional services and more. Here's another example using a popular UK super market store:</p>
      <blockquote cite="https://beta.companieshouse.gov.uk/company/00519500">
        <p> <em>TESCO STORES LIMITED Company number 00519500</em></p>
        <p>
          Nature of business (SIC):
        </p><ul> 47110 - Retail sale in non-specialised stores with food, beverages or tobacco predominating </ul>
        <ul>47290 - Other retail sale of food in specialised stores</ul>
        <ul>47710 - Retail sale of clothing in specialised stores</ul>
        <ul>47750 - Retail sale of cosmetic and toilet articles in specialised stores</ul>
        <a href="https://beta.companieshouse.gov.uk/company/00519500">via Companies House</a>
        
      </blockquote>
      <p>For the majority of our purposes, we'll mainly be looking at things at the <em>Broad Industry group</em> level which is the highest categorisation available.</p>
      <p>The chart below shows all the Broad Industry Groups (BIG) and their breakdown composition below them. Most BIGs have one <em>section</em> and a number of <em>divisions</em> below them. As you can see Production is the most complex, with two
        layers structured below it.</p>
      
      <p>This higlights an overall indication of how the UK business landscape is structured, at least statistically speaking.
        The SIC hierarchy can be explored <a href="https://onsdigital.github.io/dp-classification-tools/standard-industrial-classification/ONS_SIC_hierarchy_view.html">further here</a>.</p>
    </section>
  </div>
  <!-- 2. How many businesses are there? ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <div>
    <section>
      <a name="question2"></a>
      <h3>2. How many businesses are there?</h3>
      <blockquote>
        <p>
          <b>In summary:</b> As of 2019 over 5.8 million business are estimated to be present in the UK.
        </p>
      </blockquote>
      <p>The estimation is called out specifically because there are are a vast number of businesses too small to be registered using the IDBR, more detail on the data differences is available <a href="https://logikblok.github.io/sketches/ukbusiness/data.html#IDBRandBPE">here</a></p>
      <p>The chart below shows the difference between the data sets of registered enterprises versus the estimated numbers by industry groups. </p>
      
      <p>The differences above are expected as each data set serves different purposes. However overall both correlate to show similar patterns that the UK has prominent numbers of businesses in industries related to construction and proffesional services.</p>
      
      <p>The chart above shows the total estimated number of businesses highlighting the growth of the UK business population across a six year range.</p>
    </section>
  </div>
  <!-- 3. Where are they in the UK? ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <div>
    <section>
      <a name="question3"></a>
      <h3>3. Where are businesses located in the UK?</h3>
      <blockquote>
        <p>
          <b>In summary:</b> There is a concentration of businesses towards the south of the UK. The highest number in London with the lowest in Northern Ireland.
        </p>
      </blockquote>
      <p>As a quick reminder the The United Kingdom of Great Britain and Northern Ireland (UK) is shaped liked the below. The UK consists of four countries: England, Scotland, Wales and Northern Ireland.</p>
      <p>England is split into smaller 9 regions whilst Scotland, Wales and Northern Ireland are treated as individual regions, bringing up the total number of regions to be <em>12</em>.</p>
      
      <p>The chart below shows the number of businesses by region. It highlights the  higher number of businesses towards the south of the UK with London first, followed by the South East and the East of England.</p>
      
      <p>The chart below shows a time series of the numbers of businesses by their region. Click on any of legend items to hide them on the chart.</p>
      
      <p>It shows how consistently those regions maintain the highest number of businesses in the UK.</p>
    </section>
  </div>
  <!-- 4. What are the most popular business activites? ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <div>
    <section>
      <a name="question4"></a>
      <h3>4. What are the most popular business activities?</h3>
      <blockquote>
        <p>
          <b>In summary:</b> The UK's highest buisness activities are typically those related to construction or proffesional activites. In order at the SIC Division level they are:
          </p><li>43 Specialised construction activities</li>
          <li>41 Construction of buildings</li>
          <li>85 Education</li>
          <li>47 Retail trade, except of motor vehicles and motorcycles</li>
          <li>81 Services to buildings and landscape activities</li>
        
      </blockquote>
      <p>The chart below tries to show the regional differences in the concentraion of <em>enterprises</em>. It's using 2019 ONS data on activity and size.
</p>
      
      <p>Couple of interesting points above:
        </p><ul>
          <li>Construction and professional services are fairly consistently spread across the UK.</li>
          <li>Notice the more common aspects for Northern Ireland and Scotland in Agriculture &amp; Fishing.</li>
          <li>Education and Arts concentraion in London.</li>
        </ul>
        
      <p>The chart below shows a treemap of the number of estimated businesses by their broad industry group and their SIC industry division, allowing us to see a little more detail into the most popular business activites.</p>
      

    </section>
  </div>
  <!-- 5. Who invests in these businesses? ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <div>
    <section>
      <a name="question5"></a>
      <h3>5. Who is investing into the UK?</h3>
      <blockquote>
        <p>
          <b>In summary:</b>  Historically the largest amount of investment into the UK has come from Europe followed by the Americas, however in recent years the overall net flow of investment has decreased from Europe with the Americas taking the lead.
        </p>
      </blockquote>
      <p>Businesses can take on debt or investment or alternative financial approaches to meet their needs. Here we're looking at Foreign Direct Investment (FDI) as a whole.</p>
      <p>The chart below shows the net flow of FDI by continent. These are net values showing investments minus disinvestments. It shows a shift from Europe to the Americas between 2016-2018.</p>
      
      <p>Considering overall positions, which we mean to be the value of a stock of investment held at a point in time, the UK continues to see an increase overall. The chart below shows the <em>World Total</em> of International investment positions
        in the UK by industrial activity.</p>
      <p>Click on any of the items in the legend to hide them from view.</p>
      <p>Financial services continues to be the highest, food and drink along with mining activites have seen the largest changes in international investment positions.</p>
      
    </section>
  </div>
  <!-- 6. UK businesses internationally? ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <div>
    <section>
      <a name="question6"></a>
      <h3>6. How are UK business trading internationally?</h3>
      <blockquote>
        <p>
          <b>In summary:</b> An estimated total of 2,424,700 enterprises carried out exporting or importing activity, with a slightly larger number importing. For most it's either exporting or importing rather than doing both activities.
        </p>
        <p>The largest number of enterprises trading internationally was ‚Ä¶</p></blockquote></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://logikblok.github.io/sketches/ukbusiness/index.html">https://logikblok.github.io/sketches/ukbusiness/index.html</a></em></p>]]>
            </description>
            <link>https://logikblok.github.io/sketches/ukbusiness/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358471</guid>
            <pubDate>Wed, 09 Dec 2020 13:58:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Question That Got Google‚Äôs Timnit Gebru Fired: Can an AI Model Be Too Big?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25358384">thread link</a>) | @nibbleshift
<br/>
December 9, 2020 | https://thedebrief.org/the-question-that-got-googles-timnit-gebru-fired-can-an-ai-model-be-too-big/ | <a href="https://web.archive.org/web/*/https://thedebrief.org/the-question-that-got-googles-timnit-gebru-fired-can-an-ai-model-be-too-big/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p><a href="https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/">Last week, news broke that Google fired the co-lead of its ethical AI team, Dr. Timnit Gebru</a>. Since then, the artificial intelligence community has been taking stock of a host of issues. Chief among them is the intersection of corporate power and research institutions: can a company effectively question its own products? Under the surface of this firing are long-standing and intensifying questions about the ethical implications of artificial intelligence that have yet to fully translate to the wider public.</p>
<p>Dr. Gebru‚Äôs departure was precipitated by a paper she co-authored with four other Google employees. The draft paper, titled ‚ÄúOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big?‚Äù examines the potential multifaceted hazards of a new class of large machine learning models that are widely used by Google and other large technology companies.</p>
<figure id="attachment_1633" aria-describedby="caption-attachment-1633"><img src="https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-1024x599.jpeg" alt="Timnit Gebru" width="1024" height="599" srcset="https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-1024x599.jpeg 1024w,https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-300x176.jpeg 300w,https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-768x449.jpeg 768w,https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-770x451.jpeg 770w,https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-1400x819.jpeg 1400w,https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021.jpeg 1504w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-1024x599.jpeg 1024w, https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-300x176.jpeg 300w, https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-768x449.jpeg 768w, https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-770x451.jpeg 770w, https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-1400x819.jpeg 1400w, https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021.jpeg 1504w" data-src="https://thedebrief.org/wp-content/uploads/2020/12/Timnit-Gebru-Google-Culture-2021-1024x599.jpeg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-1633">Dr. Timnit Gebru. Image: Last Futurist</figcaption></figure>
<p><a href="https://twitter.com/JeffDean/status/1334953632719011840">Jeff Dean, head of Google AI, stated that the paper was submitted for review with little notice and that it ‚Äúdidn‚Äôt meet our bar for publication.‚Äù</a> Further, Dean claimed that the paper had overlooked scholarship that mitigated the concerns detailed by Dr. Gebru and her co-authors. The conflict eventually led Dr. Gebru to request a set of specific conditions in order to continue her employment at Google. Dean ultimately declined and interpreted her message as an immediate resignation. Gebru has since explained that she was effectively terminated before she had an opportunity to negotiate the timing of her exit.</p>
<p>The news of her departure has sparked an intense reaction in the tech community.<a href="https://googlewalkout.medium.com/standing-with-dr-timnit-gebru-isupporttimnit-believeblackwomen-6dadc300d382"> As of the time of writing, nearly 2,000 Google employees and 3,000 others have signed a letter of protest to Dr. Gebru‚Äôs firing</a>. The letter accuses Google of retaliatory practices and of censoring a line of research that is critical of some of its core products.</p>
<p>Since her firing, Dr. Gebru and her colleagues‚Äô paper has leaked online. Unlike recent years, where we have seen public fretting <a href="https://www.oreilly.com/radar/maximizing-paper-clips/">from figures like Elon Musk</a> that<a href="https://www.economist.com/special-report/2016/06/23/frankensteins-paperclips"> rogue AI would somehow turn the world into paper clips,</a> the paper by Gebru et al. is grounded in present-tense issues. Throughout, I will occasionally refer to Dr. Gebru in the singular for the sake of simplicity; please keep in mind that she had several co-authors on this paper. Their identities are being protected as current employees of Google.</p>
<p>The paper centers around problems that are inherent in a quickly evolving class of artificial intelligence techniques that attempt to model human language. In simplified terms, these models are designed to do one of two tasks: they either predict what comes next after a string of text, or they predict what should go in the middle of a sentence. While this may sound less than exciting, it is massively important‚Äîit is a core part of the technology that powers machine translation, automated speech recognition, and virtually anything else to do with language. Imagine something like a sophisticated statistical ‚ÄúMad Lib‚Äù solver and you‚Äôre on the right path.</p>
<p>In recent years, these technologies have grown vastly more powerful due to a confluence of factors that constitute a familiar story: ever-larger datasets help to train bigger and more complex models enabled by radical improvements in computer infrastructure.</p>
<p>At present, the largest of these models is OpenAI‚Äôs GPT-3. The model uses some 175 billion parameters, and each must be tuned or ‚Äútrained‚Äù on example data via an iterative process. In the case of GPT-3, that data is 570 gigabytes of text data drawn from a variety of sources from the Internet. The previous largest model, Microsoft‚Äôs T-NLG announced in February of this year, used less than 10% of the parameters and 30% of the training data. In short, this is a very quickly moving space.</p>
<p>Dr. Gebru and her colleagues ask a straightforward but provocative question: How big is too big? To understand that, we have to look closely at what it means to train a machine learning model.</p>
<p>Machine learning researchers and computer scientists tend to divide calculation of costs between ‚Äútraining‚Äù time and ‚Äúinference‚Äù time. Training refers to the process of ‚Äúteaching‚Äù the model on the basis of large datasets. That process is typically iterative; it takes many cycles of repetition to develop a robust model. Researchers must also be careful that the training data is diverse enough that models don‚Äôt ‚Äúovertrain‚Äù and become fixated on idiosyncratic patterns.</p>
<p>For example, imagine you have a set of ‚Äúnoisy‚Äù points like the black dots below:</p>
<p><img src="https://thedebrief.org/wp-content/uploads/2020/12/Overfitted_Data.png" alt="" width="377" height="256" srcset="https://thedebrief.org/wp-content/uploads/2020/12/Overfitted_Data.png 377w,https://thedebrief.org/wp-content/uploads/2020/12/Overfitted_Data-300x204.png 300w" sizes="(max-width: 377px) 100vw, 377px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/12/Overfitted_Data.png 377w, https://thedebrief.org/wp-content/uploads/2020/12/Overfitted_Data-300x204.png 300w" data-src="https://thedebrief.org/wp-content/uploads/2020/12/Overfitted_Data.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Your goal is to come up with a function that will predict a new set of points in the future from the same underlying process ‚Äî recognizing that this particular collection of black dots has some measurement error and uncertainty in it.</p>
<p>The two lines show two possible solutions. The first is a very simple line. While it doesn‚Äôt perfectly ‚Äúfit‚Äù the dots, it captures the basic trend. The second is the blue line, which perfectly fits each and every dot, and relies on a more complicated function. If you measure the accuracy of these two models on just this data, the blue line is better. In fact, it is technically perfect.</p>
<p>But is it? You can imagine that over time, with new datasets that won‚Äôt have the dots in exactly the same place, the simple line will actually be more accurate. The simple line is less complex, but actually captures the data better by not being overly influenced by just one example.</p>
<p>Finding the right balance in model complexity is difficult work. Too simple, and the model can‚Äôt capture important nuances‚Äîtoo complex and it becomes fragile, or at worst a mere portrait of the training data. The goal, as in so many things, is to find the sweet spot in the middle: a tool that is general enough to handle the messiness of the real world without sacrificing too much in terms of accuracy.</p>
<p>Finding that sweet spot often requires vast computational resources, particularly in the modern context. This is partly due to the inherent need for repetition in ‚Äúteaching‚Äù the model, and also the need to ensure that the model doesn‚Äôt become too dependent on one narrow slice of training data.</p>
<p>In comparison to training, ‚Äúinference‚Äù ‚Äî that is, actually using the model to make a prediction ‚Äî is much cheaper. The expensive part is finding the right values for all those parameters discussed above. Once you have them, making predictions with the model is relatively easy.</p>
<p>If you squint, a rough analogy can be made to raising children. The cost of raising an infant to school age is profound in comparison to babysitting a kid for a day. The hard part is teaching an infant all the basics of human life: not to touch the stove and stick fingers in the electrical sockets. Once the child, or the model, has reached maturity, it ‚Äúoperates‚Äù relatively cheaply in comparison to the cost of its upbringing.</p>
<p>This brings us back to Dr. Gebru‚Äôs work. One of her arguments is that ‚Äúraising‚Äù AI is expensive in terms of raw energy. She cites the work of<a href="https://arxiv.org/abs/1906.02243"> Dr. Emma Strubell and others</a>, who<a href="https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/"> demonstrated that training big models can emit as much carbon as five cars</a> do over their full lifetime of use. That fantastically powerful computer infrastructure comes at a cost.</p>
<p><img src="https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1024x1024.jpg" alt="Google fired Timnit Gebru" width="1024" height="1024" srcset="https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1024x1024.jpg 1024w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-300x300.jpg 300w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-150x150.jpg 150w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-768x768.jpg 768w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1536x1536.jpg 1536w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-70x70.jpg 70w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-120x120.jpg 120w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-240x240.jpg 240w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-360x360.jpg 360w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-540x540.jpg 540w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-720x720.jpg 720w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-770x770.jpg 770w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1400x1401.jpg 1400w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-125x125.jpg 125w,https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1024x1024.jpg 1024w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-300x300.jpg 300w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-150x150.jpg 150w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-768x768.jpg 768w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1536x1536.jpg 1536w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-70x70.jpg 70w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-120x120.jpg 120w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-240x240.jpg 240w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-360x360.jpg 360w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-540x540.jpg 540w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-720x720.jpg 720w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-770x770.jpg 770w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1400x1401.jpg 1400w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-125x125.jpg 125w, https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash.jpg 1920w" data-src="https://thedebrief.org/wp-content/uploads/2020/12/ian-battaglia-9drS5E_Rguc-unsplash-1024x1024.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Google and others contend that innovation has helped to offset these costs and prevent them from becoming another worrying source of carbon pollution. However, Dr. Gebru rightly points out that the wider enterprise of cloud computing is not necessarily carbon neutral, whatever Google‚Äôs particular commitments may be.</p>
<p>She further argues that the benefits and costs of these models are lopsided. Is it fair to ask residents of the Maldives, expected to be underwater before the end of the century, to foot the environmental bill for marginally improved language models ‚Äî particularly when those language models don‚Äôt include Dhivehi? In short, the people most exposed to the risks of climate change are some of the least positioned to benefit from technologies like Google Home or Amazon‚Äôs Alexa.</p>
<p>Put more pointedly: What good is a Siri that doesn‚Äôt understand your language when the water is rising?</p>
<p>Should we hasten the flood so that gadgets become slightly less stupid? How about when such machines do other more important work,<a href="https://thedebrief.org/deepminds-ai-makes-history-by-solving-protein-folding-problem/"> like predicting the structure of medically relevant proteins</a>? To be sure, these are not easy questions ‚Äî but they are important ones, and ones that should be widely assessed.</p>
<p>Next among Dr. Gebru‚Äôs concerns is ‚Äúunfathomable‚Äù training data. Those 570 gigabytes of Internet data referenced above largely come from sources that represent a very narrow slice of society. In the analogy above between training a model and raising a child, imagine a child raised largely by Reddit or Twitter, with occasional babysitting from Wikipedia. Are you confident that a well-rounded, tolerant person would result? Would you take that teenager to an important company dinner, trusting that they wouldn‚Äôt say anything offensive or laughably wrong?</p>
<p>The deeper problem Dr. Gebru raises is that the training datasets themselves are too large to effectively audit or even fully understand as a researcher. How can we assess the ethics of something so vast we can‚Äôt effectively explore it? The risk, Gebru‚Äôs team and others argue, is that by averaging together such sources, models will come to ‚Äúencode hegemonic worldviews.‚Äù</p>
<p>The risk only becomes more pronounced as the models become increasingly convincing. Advances in language models have enabled automated text that seems coherent across sentences and even paragraphs.</p>
<p>Take this example of GPT-3 answering questions about the Russian private military company, the Wagner Group:</p>
<p><img src="https://thedebrief.org/wp-content/uploads/2020/12/wagner_group_ai.png" alt="AI GPT3" width="633" height="598" srcset="https://thedebrief.org/wp-content/uploads/2020/12/wagner_group_ai.png 633w,https://thedebrief.org/wp-content/uploads/2020/12/wagner_group_ai-300x283.png 300w" sizes="(max-width: 633px) 100vw, 633px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/12/wagner_group_ai.png 633w, https://thedebrief.org/wp-content/uploads/2020/12/wagner_group_ai-300x283.png 300w" data-src="https://thedebrief.org/wp-content/uploads/2020/12/wagner_group_ai.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><div><div id="block-wrap-87014" data-id="87014"><div><div><div>		<article>
					<p><a href="https://thedebrief.org/pope-francis-calls-for-prayers-as-ai-research-progresses/">
				<img width="120" height="80" src="https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis.jpg" alt="Pope Francis" srcset="https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis.jpg 1500w,https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis-300x200.jpg 300w,https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis-1024x683.jpg 1024w,https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis-768x512.jpg 768w" sizes="(max-width: 120px) 100vw, 120px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis.jpg 1500w, https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis-300x200.jpg 300w, https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis-1024x683.jpg 1024w, https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis-768x512.jpg 768w" data-src="https://thedebrief.org/wp-content/uploads/2020/11/Pope-Francis.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">			</a>
		</p>
					
		</article>
		</div></div></div></div></div>
<p>The model does an admirable job of answering basic questions. The responses feel logically and intentionally composed.</p>
<p>The example comes from a paper earlier this year by two researchers from the Middlebury Institute of International Studies. They ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thedebrief.org/the-question-that-got-googles-timnit-gebru-fired-can-an-ai-model-be-too-big/">https://thedebrief.org/the-question-that-got-googles-timnit-gebru-fired-can-an-ai-model-be-too-big/</a></em></p>]]>
            </description>
            <link>https://thedebrief.org/the-question-that-got-googles-timnit-gebru-fired-can-an-ai-model-be-too-big/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358384</guid>
            <pubDate>Wed, 09 Dec 2020 13:50:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Everything Up? Monitoring 29,302 Points In-the-Loop in the FlightAware Stack]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25358284">thread link</a>) | @jsulak
<br/>
December 9, 2020 | https://flightaware.engineering/is-everything-up-monitoring-29-302-points-in-the-loop-in-the-flightaware-production-stack/ | <a href="https://web.archive.org/web/*/https://flightaware.engineering/is-everything-up-monitoring-29-302-points-in-the-loop-in-the-flightaware-production-stack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p><em>Take lessons from high stakes monitoring in the physical world (electrical grids, nuclear power plants, oil rigs, data centers) and apply them to a pure software stack.</em></p><p><em>Karl Lehenbauer is FlightAware</em>‚Äô<em>s Chief Technology Officer. </em></p><p>Little is worse for someone committed to providing reliable service than to have your customer call you to tell you your service isn‚Äôt working. It‚Äôs a double whammy. You‚Äôre broken and you don‚Äôt know you‚Äôre broken. You hate that. So do we. Worse, we have service level agreements with many of our customers‚Äî if a service isn‚Äôt working for long enough, we have to start dishing out refunds.</p><p>But far more important than that, if we‚Äôre down our customers don‚Äôt know where their airplanes are. This can be a regulatory violation. It can also mean that the line service technicians aren‚Äôt available to meet the plane (if you travel much at all you‚Äôve heard the pilot come on the PA and announce, ‚ÄúWell folks, we‚Äôve arrived but the ground crew isn‚Äôt here to help get us into the gate‚Äù). Then you sit on the plane in the alleyway until the wing walkers, jetway driver, baggage handlers, etc., show up to guide the plane in.</p><p>But more than that, we provide Global Aviation Distress and Signaling System (GADSS) <a href="https://globalbeacon.aero/">surveillance</a> to lots of airlines as mandated by the International Civil Aviation Organization. They might literally not know that one of their airplanes is in distress or has some kind of incident or even has crashed if our stuff isn‚Äôt working properly. People‚Äôs lives are on the line.</p><p>Let‚Äôs go back in time a bit.</p><h2 id="monitoring-the-real-world">Monitoring the Real World</h2><p><br>I got my start in control systems, first at a power company, monitoring and controlling electrical power generation, transmission and distribution. Later, I went to work at a vendor of those systems, followed by a stint at GE Aircraft Instruments working on turbine engine monitoring.</p><p>By the early 1990s I was leading the engineering team for a very early Internet Service Provider.</p><p>One day, our air conditioning failed. The computer room overheated, we lost some disk drives, and I resolved that we should be alerted if it ever started happening again.</p><p>This was before you could read the air inlet temperature off of your high-end router or from your fancy air conditioner or from one of the inexpensive SNMP-enabled temperature monitoring solutions of today.</p><p>So we came up with a clever solution. We‚Äôd use an old school thermostat, wire the transmit pin of a computer‚Äôs serial port through the thermostat‚Äôs mercury switch to the port‚Äôs receive pin, and we‚Äôd send a character through the serial port every few seconds. If the computer room went above a threshold temperature, the blob of mercury would complete the circuit and we‚Äôd start reading the characters back from the serial port. Then our little program would recognize this and start sending messages to peoples‚Äô pagers using a modem.</p><figure><img src="https://flightaware.engineering/content/images/2020/12/Image-1-.png" alt="" srcset="https://flightaware.engineering/content/images/size/w600/2020/12/Image-1-.png 600w, https://flightaware.engineering/content/images/size/w1000/2020/12/Image-1-.png 1000w, https://flightaware.engineering/content/images/size/w1600/2020/12/Image-1-.png 1600w, https://flightaware.engineering/content/images/2020/12/Image-1-.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>Fine.</p><p>Lo and behold, one day we partially lost cooling in the data center, only we didn‚Äôt get any callouts. An investigation revealed that one of the wires had gotten janked, and though the blob of mercury made contact, no characters were received by the monitoring program.</p><p>Meditating on this led to a critical insight. <em>We had it backwards! </em>Rather than completing the circuit when there was a problem, we needed instead to make the circuit normally closed and open it when there was a problem. Instead of wiring into the air conditioning contacts of the thermostat we would wire into the heating ones. We would receive the characters we were sending as long as everything was OK. If the temperature rose past a threshold, the blob of mercury would pull away from the contacts, breaking the circuit, so whenever our program <strong>stopped</strong> seeing the characters, the alarm would be raised.</p><p>By flipping it like this, if one of the wires got inadvertently pulled or whatever, we‚Äôd immediately get the alarm.</p><p>In other words, <strong>the lack of a signal telling you everything is OK means something is wrong.</strong></p><h2 id="on-the-trail-of-monitoring-your-applications">On the Trail of Monitoring Your Applications</h2><p>Now, consider we have a service and we want to make sure it‚Äôs working. Can I ping the machine or machines? Great. The machine is up. Or is it? Ping is pretty basic in the network stack; ping packets are typically responded to directly from the kernel. We‚Äôve seen machines that are pretty crashed and won‚Äôt run programs that will still ping.</p><p>OK, so we‚Äôll ping the machine, but we‚Äôll have some kind of agent program that runs on the machines that we‚Äôll talk to over the network. If we can talk to the agent, then we know a little more that the machine is working. But does the machine have enough storage? Does it have enough memory? OK, we‚Äôll make our agent check and alert us if the machine is low on storage or memory, if the swap utilization is abnormally high, etc.</p><p>But is the program running? Sure, no problem. We‚Äôll add some code to our agent to read the process table and see if the program shows up there. If it doesn‚Äôt, we‚Äôll alarm.</p><p>But is the program getting work done? The process might exist, but it might not be doing anything. Well we could read the program‚Äôs CPU time repeatedly and see if it‚Äôs accumulating time.</p><p>But does that mean it‚Äôs working? No, it doesn‚Äôt. Maybe it‚Äôs lost its database connection. Maybe it‚Äôs accumulating CPU time but because it wasn‚Äôt written defensively enough, it‚Äôs trying to do database updates and failing and logging errors but not reconnecting to the database.</p><p>Maybe it‚Äôs got a good connection to the database server but it‚Äôs not receiving any messages.</p><p>You can keep increasing the sophistication of your agent. You can keep adding new checks as you discover (usually the hard way) new failure modes you missed, but with this approach you‚Äôre vulnerable to any new or unanticipated breakdowns. You might never be completely sure work is getting done.</p><h3 id="in-the-loop-monitoring">In-the-Loop Monitoring</h3><p>I assert that you can‚Äôt know your program is doing the work it‚Äôs supposed to be doing unless it‚Äôs telling you that it is. Call this ‚Äúin-the-loop‚Äù monitoring. If a program is expected to repeatedly receive input messages and update a table in a database, then every time it has done this it should send a message to monitoring software reporting that it has successfully done it.</p><p>It should only send the success message to the monitoring program upon completion of the work. So once an input message has been received, successfully processed, and the database updated, a separate message is sent to the monitoring software saying it has succeeded. If no input message is received or the database update fails, the message should not be sent to the monitoring software.</p><p>To reiterate, you make a call from inside the program to send a message to your monitoring software every time the program succeeds in doing a parcel of work.</p><p>Meanwhile, if a certain amount of time passes without the monitoring program receiving a ‚Äúwork completed‚Äù message, it raises an alarm that something is wrong.</p><p>The beautiful thing here is that the monitoring program doesn‚Äôt have to know why it didn‚Äôt receive a message. We don‚Äôt have to try to check for every possible reason. All we have to do is recognize that we stopped being told it was OK. The machine may have crashed, the router may have failed, the program may have lost its receive socket or its database connection. The program feeding data to our program may have stopped sending, the ethernet cable may have gotten pulled, a circuit breaker may have tripped, the program may have divided by zero or gotten a memory protection violation, there could have been an earthquake, a flood‚Ä¶ locusts! We don‚Äôt have to check for all those things. All we have to do is recognize that the program stopped telling us it was OK.</p><h3 id="watchdog-timers">Watchdog Timers</h3><p>What I‚Äôm describing is a variation of a <a href="https://en.wikipedia.org/wiki/Watchdog_timer">watchdog timer</a>, technology common in real-time systems, space probes, satellites, etc., where software on a computer periodically resets a hardware timer. The hardware timer counts down, but every time the reset signal is received the counter is reset. If for any reason the software stops resetting the hardware timer, the counter eventually reaches zero and triggers a reboot or some other corrective action. Our variation is much more granular and is software-based, but the principle is the same.</p><h2 id="on-the-trail-of-watchdog-resets-in-the-modern-production-software-stack">On the Trail of Watchdog Resets in the Modern Production Software Stack</h2><p>Now, if your program is processing 40,000 messages a second, it needn‚Äôt send 40,000 messages a second to your monitoring system saying it‚Äôs completed work. So the watchdog reset subroutine can have a threshold and only send a completion message once a second or whatever, regardless of how many messages it processed. Fine.</p><p>Also, the watchdog reset subroutine must never break the program! So if it can‚Äôt reach the monitoring server, the program should keep going regardless. The program shouldn‚Äôt freeze if the monitoring software stops responding. For this reason our in-the-loop code has been kept very simple, and uses UDP datagrams to send watchdog resets to the monitoring software. It also makes sure that even if there is an error returned, which can happen even with UDP if the sender and recipient are on the same LAN, that it doesn‚Äôt stop or break the program.The watchdog reset message should identify the program, the machine (typically), and perhaps the activity within the program that has succeeded. Examples include the receipt of a message from the FAA, from Aireon‚Äôs Space-Based ADS-B network, from our provider of airline schedules, from each of our multiplexing agents that aggregate data from our tens of thousands of ADS-B ground stations, or from <a href="https://flightaware.com/about/datasources/">HyperFeed</a>¬Æ, our suite of programs that process all the input data to produce our coherent feed of what is happening with all the aircraft that are in the air or moving on the ground in the world.</p><figure><img src="https://flightaware.engineering/content/images/2020/12/Image-2-4.png" alt="" srcset="https://flightaware.engineering/content/images/size/w600/2020/12/Image-2-4.png 600w, https://flightaware.engineering/content/images/size/w1000/2020/12/Image-2-4.png 1000w, https://flightaware.engineering/content/images/2020/12/Image-2-4.png 1330w" sizes="(min-width: 720px) 720px"><figcaption>Watchdog reset call in Python ‚Äì If one of our 12M+ users hasn‚Äôt logged into the website in the last 15 minutes, something‚Äôs wrong.</figcaption></figure><p>Creation of watchdog entries in the monitoring software should be zero config. That is to say on the first receipt by the ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://flightaware.engineering/is-everything-up-monitoring-29-302-points-in-the-loop-in-the-flightaware-production-stack/">https://flightaware.engineering/is-everything-up-monitoring-29-302-points-in-the-loop-in-the-flightaware-production-stack/</a></em></p>]]>
            </description>
            <link>https://flightaware.engineering/is-everything-up-monitoring-29-302-points-in-the-loop-in-the-flightaware-production-stack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358284</guid>
            <pubDate>Wed, 09 Dec 2020 13:38:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Ethereum Keys Are the Core of Space Accounts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25358155">thread link</a>) | @itsnicoggi
<br/>
December 9, 2020 | https://blog.space.storage/posts/why-ethereum-keys-are-the-core-of-space-accounts | <a href="https://web.archive.org/web/*/https://blog.space.storage/posts/why-ethereum-keys-are-the-core-of-space-accounts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://fleek-team-bucket.storage.fleek.co/thumbnails-blog/Space%20Ethereum.jpg" alt="Ethereum keys in Space Storage"></p>
<p>In our last piece, we talked about the <a href="https://blog.space.storage/posts/the-dweb-protocols-behind-space" target="_blank" rel="nofollow noopener noreferrer">Dweb protocols </a>behind the building of Space, and how each of them allows us to take our platform further away from Web 2.0 and into Web 3.0.</p>
<p>One of those protocols is Ethereum, which we think of as the centerpiece of our user‚Äôs accounts. We want to tie each user to an ETH key/address, whether they sign up using email and social accounts (via Torus); or by linking their own ETH wallet (via MetaMask or Wallet Connect).</p>
<p>Why? There are many reasons behind this choice. The first and most immediate one is that we think Ethereum keys are the future of authentication. The second one is a long term one. When we think about the future of Space and the Dweb, we see Ethereum as the main connection point for a wide array of tools and use cases that benefit from pairing with a user-owned platform.</p>
<p>Let‚Äôs go over a couple reasons and what they mean for us‚Ä¶</p>
<h2 id="exploring-the-future-of-authentication"><a href="#exploring-the-future-of-authentication" aria-label="exploring the future of authentication permalink"></a>Exploring the Future of Authentication</h2>
<p><img src="https://fleek-team-bucket.storage.fleek.co/Blog%20Inline/Enter%20Password.gif" alt="Authentication"></p>
<p>At Space, we‚Äôve discussed several times about what the future of authentication looks like. Whether you sign up using email, social media, or an ETH wallet, we all agree with one thing: public/private key pairs proved to be a solid alternative to passwords, and an overall better authentication model.</p>
<p>So far, key pairs have addressed key issues in the authentication process, and many core negative aspects of the Web 2.0 auth paradigm.</p>
<p>We can see this from the get go if we compare both models. With passwords, authentication is handled from the platform‚Äôs end, with the user having to expose their main credentials every time to the platform, who also keeps these credentials on their end.</p>
<p>Key pairs, on the other hand, allow for blind verification of a user‚Äôs identity, since they don‚Äôt need to expose their private key but sign proof that the platform can verify by just knowing the user‚Äôs public key.</p>
<p>This means there‚Äôs a lot less instances the user has to worry about when it comes to their credential‚Äôs security.</p>
<p>However, we do also understand that key pairs fundamentally change the user‚Äôs experience entirely. Generating, saving, and safekeeping keys is not the standard experience everyone, and making a hard switch would mean exposing users to a new model that has its own security needs, and ways of handling/storing/backuping than passwords.</p>
<p>Convenience is a known security killer, and we don‚Äôt want users to make sacrifices either in their safety, or their experience.</p>
<p><img src="https://fleek-team-bucket.storage.fleek.co/Blog%20Inline/Change.gif" alt="Experience changes"></p>
<p>That‚Äôs why we‚Äôre focusing on finding a place in-between for users to leverage the best aspects of key-pair based authentication, and still maintain a seamless and known login experience. We want to provide a wide selection to cover the spectrum, for both those who simply want to use their email as a login, for example, and those who want to handle their ETH keys with a crypto wallet.</p>
<p>Torus helps us achieve that for the first group, by abstracting key management and letting us provide users with a known sign in experience in the front (using Twitter, or Email magic links, etc.), while abstracting and securely retrieving the users Ethereum private key in the background, via a distributed, non-custodial, sharded key network (the Torus network) that a user can authenticate to with any of their usual, and quick login options.</p>
<p>That way, we can provide a flexible flow for each user without having to grandfather the platform to an authentication model that we think is not the future, and we can build the platform from the ground up so that every user can transition to key-pair auth more easily.</p>
<h2 id="rethinking-account-ownership"><a href="#rethinking-account-ownership" aria-label="rethinking account ownership permalink"></a>Rethinking Account Ownership</h2>
<p><img src="https://fleek-team-bucket.storage.fleek.co/Blog%20Inline/Account%20Ownership.jpg" alt="user-owned accounts"></p>
<p>There‚Äôs another reason, other than security, behind our choice to work with Ethereum key pairs.</p>
<p>Today, accounts in services are usually centralized, and tied in exclusivity/ownership to the platform itself, and not to the user. That‚Äôs why in Web2 we have an endless stream of different accounts for each service, all bound to the platform‚Äôs existence.</p>
<p>We see Ethereum keys as the opportunity to switch accounts from entity/platform controlled to completely user owned and controlled. Where instead of a platform authorizing you to use their platform internally, you -as your own entity- would authorize different platforms to access your own personal account and permission each platform to access just the specific data it needs in order for you to use the service.</p>
<p>In the storage world itself this has a special connotation, because today not only is your account tied to a specific storage platform, but your storage/files/data are as well.</p>
<p>As we move forward towards distributing storage (on IPFS, Textile, Filecoin, etc), we want to give users the chance to truly own their account and storage, and be able to choose how they want to access it, and where.</p>
<p>We view files stored in Space as platform and interface agnostic, and in that vision, Ethereum keys play a part in building user-owned accounts that are not siloed or specific to the Space interface itself, but rather existing on an open global data network (or the user‚Äôs hands) for the user to own.</p>
<p>It‚Äôs an ever evolving and improving concept, but we are looking to break the traditional way of handling storage, where companies own the data/accounts, and move towards a place where platforms just become interfaces for a user to surface, manage, and interact with their files/data that live on this open global file/data layer (powered by IPFS and Textile).</p>
<h2 id="opening-up-to-ethereum-use-cases"><a href="#opening-up-to-ethereum-use-cases" aria-label="opening up to ethereum use cases permalink"></a>Opening up to Ethereum Use Cases</h2>
<p><img src="https://fleek-team-bucket.storage.fleek.co/Blog%20Inline/Ethereum%20Keys.jpg" alt="ethereum use cases"></p>
<p>The final and longer term reason for using Ethereum keys in our architecture, is to serve as a seamless bridge between Ethereum based use cases, and their potential data/file storage, hosting and access needs.</p>
<p>Ethereum is a melting pot of decentralized use cases and possibilities that benefit a lot from integrating with each other.</p>
<p>From tokens, DAOs, NFTs, to the wonderful array of Dapps that are growing each day, it‚Äôs simply natural to think that any of these could benefit from being able to interact directly with distributed and user-owned (or ETH wallet or contract owned) files/data.</p>
<p>For us, Ethereum is the base layer that everything will be controlled from in the future (using ETH wallets or contracts), and so having an ETH key/wallet associated with each user allows us to explore combining and integrating different ETH use cases (tokens, DAO‚Äôs, NFT‚Äôs, etc.) into Space without having to rebuild the wheel and isolate our platform from an already thriving decentralized environment.</p>
<p>For example, by enabling ETH and ERC20 payments, in the future that could evolve into users being able to seamlessly create paywalls or different access token based mechanisms in front of files or content stored in Space.</p>
<p>Or by taking the ‚Äúuser-owned‚Äù nature of NFTs to a new level, and allowing users to store/serve the image/file related to their NFT (which lives on IPFS) in the same account as the token itself (which lives on Ethereum) - rather than just relying on NFT platforms to keep the NFT image/file pinned and existing on IPFS forever.</p>
<p>There‚Äôs definitely a lot of exciting opportunities for Space to grow, and for the developer community to build on Space and take some of these ideas to the next level (using the SpaceSDK for web or mobile apps or Space Daemon for desktop apps).</p>
<p>Storage is the cornerstone, and from there, there‚Äôs a lot of Space to explore! üöÄüöÄ</p>
<ul>
<li>Sign up for <a href="https://space.storage/" target="_blank" rel="nofollow noopener noreferrer">Space Beta</a></li>
<li>Follow us on <a href="https://twitter.com/spacestorage" target="_blank" rel="nofollow noopener noreferrer">Twitter</a></li>
<li>Reach out at <a href="https://blog.space.storage/cdn-cgi/l/email-protection" data-cfemail="dcb4b59cafacbdbfb9f2afa8b3aebdbbb9">[email&nbsp;protected]</a></li>
<li>Check out our <a href="https://docs.fleek.co/space-daemon/overview/" target="_blank" rel="nofollow noopener noreferrer">Tech Docs</a></li>
<li>Spread the word</li>
</ul></div></div>]]>
            </description>
            <link>https://blog.space.storage/posts/why-ethereum-keys-are-the-core-of-space-accounts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358155</guid>
            <pubDate>Wed, 09 Dec 2020 13:20:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unit-testing a console app]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25358087">thread link</a>) | @jmmv
<br/>
December 9, 2020 | https://jmmv.dev/2020/12/unit-testing-a-console-app.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/12/unit-testing-a-console-app.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article><p>The most notable feature in <a href="https://jmmv.dev/2020/11/endbasic-0.3.html">EndBASIC 0.3</a> is its new full-screen console-based text editor. It took longer than I wanted to start developing this, in part because I was busy moving, and in part because I <em>dreaded the thought of having to unit test the text editor</em>. (Yes, EndBASIC is a personal project and I develop it in my free time, but that doesn‚Äôt mean I don‚Äôt want it to be properly engineered!)</p>
<figure>
  <img src="https://jmmv.dev/images/2020-12-08-endbasic-welcome.gif">
  <figcaption>The text editor we will be unit-testing, in action.</figcaption>
</figure>
<p>In the end, I rolled up my sleeves, got to work, and achieved reasonable test coverage. In fact, the tests have already paid off by uncovering various bugs and inefficiencies, so the effort was well-spent. Developing these tests was non-trivial, though, so here is an overview on <em>why</em> it is worthwhile to unit-test a full-screen console app and <em>how</em> to go about it.</p>
<blockquote>
<p>The key insight, unsurprisingly, is to <strong>design for testability</strong>. I knew I wanted to unit-test the text editor from the beginning, so I had to come up with a design that allowed for this. Retrofitting tests into code that never considered testing is very difficult.</p>
</blockquote>
<p>As usual, while the specific code I‚Äôm going to show you is in Rust, you can easily apply these ideas to your favorite language. All you need is a mechanism to express an abstraction layer between your app and the console manipulation code‚Äîand you could do that even in the shell.</p>

<p>Command-line applications typically interact with the console by reading from their standard input (stdin) and writing to their standard output (stdout). Both stdin and stdout are ‚Äústreams‚Äù: you can read from and write to them, but these I/O operations are sequential. The streams do not know anything about where the cursor is or how to change colors or anything like that. And this makes sense because if stdin and stdout are connected to files, what does it mean to ‚Äúclear the screen‚Äù?</p>
<p>If that‚Äôs the case, though, how does a console program manipulate the screen to, for example, clear it and position the cursor at an arbitrary location? Well, the answer is that‚Ä¶ it depends.</p>
<p>On Unix-like systems, the application writes special collections of bytes, known as <strong>escape sequences</strong>, to stdout. How the escape sequences look like and what they mean depends completely on what stdout is attached to. Again, if stdout is attached to a file, these sequences mean nothing more than a sequence of bytes. Contrariwise, if stdout is attached to a terminal, then the terminal interprets them and performs certain actions.</p>
<p>The most obvious escape sequence you can think of is the line terminator, or <code>\n</code>. On its own, <code>\n</code> is nothing more than ASCII byte 10. But when the terminal sees this byte, the terminal knows that it has to advance the cursor to the next line <em>and</em> move it to the first column. But the semantics of what <code>\n</code> does vary across systems: Windows interprets <code>\n</code> as <em>just</em> moving the cursor one line down, not rolling it back go the first column.</p>
<p>There are more complex escape sequences, of course. This is why you can trivially (assuming you know what terminal type you are talking to) embed escape sequences in <code>printf</code> or <code>echo -e</code> invocations to control how things look like. You essentially use escape sequences as a way to mark up the text:</p>
<figure>
  <img src="https://jmmv.dev/images/2020-12-08-escape-sequences.png">
  <figcaption>Two `printf(1)` command invocations showing how escape sequences change the color of the printed text.</figcaption>
</figure>
<p>For completeness, I‚Äôll also mention that the terminal emulator is usually in the kernel, which is what allows you to have full-screen text apps in the text mode console, but it can also be implemented in <em>hardware</em> (where the concept originated), and thus also in user space, which is what graphical programs like <code>xterm</code> used to do before PTYs (and is why they are called terminal <em>emulators</em>).</p>
<p>If you haven‚Äôt connected the dots yet, this is precisely what the ancient <code>TERM</code> environment variable is about: it tells the console applications what specific terminal it is talking to so that the application itself can generate the correct escape sequences to control it. Nowadays, the <a href="https://en.wikipedia.org/wiki/ANSI_escape_code">ANSI escape sequences</a> are almost universal, but they weren‚Äôt always. <code>terminfo</code>/<code>termcap</code> and <code>(n)curses</code> are libraries to abstract all these details away and offer the programmer a generic console-manipulation interface that works across <code>TERM</code> variants.</p>
<p>This is all about Unix though. On Windows, things are different (and my knowledge is very limited). Command-line applications communicate with the Console Window Host (<code>conhost.exe</code>) by means of <code>ioctl</code>-like calls. In other words: console manipulation happens out of band and isn‚Äôt part of what goes into stdout. Or at least that‚Äôs the only way it used to be: the new console host supports ANSI escape sequences too, presumably to facilitate interop with WSL.</p>
<p>Anyhow. We don‚Äôt care about how the console is updated from a testing perspective: we want to know how the console changes, but not exactly how that‚Äôs done by the OS. Therefore, I‚Äôm going to refer to the escape sequences and/or the <code>ioctl</code>s sent to the console as <strong>console manipulation commands</strong> or <strong>console commands</strong> in the text below.</p>

<p>Testing a full-screen console app‚Äîwhich some people refer to as a <strong>Text User Interface</strong> or <strong>TUI</strong> for short‚Äîexposes essentially the same difficulties as testing a GUI:</p>
<blockquote>
<p>We are trying to write tests for something that <strong>responds to user input</strong>, and every user interaction causes <strong>changes that are inherently visual</strong> and require the human eye for interpretation.</p>
</blockquote>
<p>Let‚Äôs break these problems down into pieces and see how we can approach them.</p>
<p>First and foremost: we have to ensure that the <em>outcome</em> of our input (key presses) has the right effect on the program <em>state</em>. Given that we are testing a text editor, this is easy: we can populate the editor‚Äôs buffer with some text, let the editor process a set of key presses, and then verify that the contents of the editor‚Äôs buffer match a golden text. Not very different from other, more traditional tests.</p>
<p>Second, we need to worry about user input. After all, the TUI is interactive and reacts to user key presses, so our tests will have to drive the TUI. This is easier than dealing with the visual console updates, as all we have to do is represent the sequence of key presses to send to the app and then feed those to it in some way. Again, this is not very different from other tests: we have an algorithm and we inject some input.</p>
<p>And third, we have to worry about how things look like, which is the most interesting part of this problem. Because, after all‚Ä¶ we can write a test to verify that a piece of code selects the blue color and then clears the screen, but unless we <em>see</em> the result, we don‚Äôt know if the screen was all emptied with a blue background or not.</p>
<p>Well, we <em>could</em>. Presumably, we could capture the raw screen contents (or poke at them if we were in the DOS era; <code>0xB8000</code> anyone?) and compare those against golden ‚Äúscreenshots‚Äù after every key press. This would do the trick and would result in tests that are completely decoupled form the way the screen is updated‚Ä¶ which actually sounds like a good idea. The problem with this approach of comparing screen contents is that we would need a terminal emulator to ‚Äúrender‚Äù the console from the console commands that the application emits, and a terminal emulator isn‚Äôt a trivial piece of software.</p>
<p>The alternative to this idea of comparing screen <em>contents</em> is to capture the console commands that the app emits and compare those to expectations. This is easier to implement but has different fidelity tradeoffs as we shall see below.</p>

<p>If we follow the ideas presented above, we will end up with a bunch of tests that inject key presses into the TUI and, for each of them, we will capture which console manipulation commands were emitted and we will compare them against expectations.</p>
<p>Which‚Ä¶ sounds fragile and not particularly useful, doesn‚Äôt it? As mentioned earlier, a sequence of commands is meaningless <em>unless we humans see the visual results</em> once a terminal emulator has processed the commands. You could then say that these tests are pointless. But these tests provide three separate benefits:</p>
<ol>
<li>
<p><strong>Corner-case and regression validation.</strong> In the scenario we are looking at, a lot of the editor behavior is obvious: if we press the right arrow key, we know that the cursor has to move one position to the right if the line of text permits. If we break the way this works, the breakage will be extremely visible once we do any kind of manual test.</p>
<p>But‚Ä¶ what happens if the cursor is located in the middle of the last visible line of text, with the viewport scrolled to the right because the line was extremely long, and we press enter to split it? That‚Äôs not something you usually do, so what‚Äôs the expected behavior there? We need to make sure that, once this works as we intend, it doesn‚Äôt unexpectedly break, and we don‚Äôt want to have to manually verify this every time we change the editor logic.</p>
</li>
<li>
<p><strong>Behavior documentation.</strong> The collection of test cases for the TUI will serve us as the documentation of all cases we must care about in the code if we are doing any kind of refactoring, for example. As illustrated above, there are a lot of corner cases to deal with, and unless they are tracked somewhere, it‚Äôs too easy to forget about them.</p>
</li>
<li>
<p><strong>Efficiency measures.</strong> The last benefit these tests give us is a way to measure efficiency. By capturing the sequence of commands emitted by the TUI logic, we can see if those commands are <em>minimal</em>. Because if they are not, the TUI will flicker.</p>
<p>For example: an easy way to implement the TUI is to refresh the whole screen after every key press‚Äîand while that will yield updates that <em>look</em> correct (and that would pass a testing model where we verify screen contents), the app will be doing too much work to update the screen. We need to worry about only doing partial screen updates (clearing a single line, using terminal scrolling features, etc.), and to that end, capturing the sequence of commands lets us do that.</p>
</li>
</ol>
<p>The downside of this testing approach is that, again, we ‚Ä¶</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jmmv.dev/2020/12/unit-testing-a-console-app.html">https://jmmv.dev/2020/12/unit-testing-a-console-app.html</a></em></p>]]>
            </description>
            <link>https://jmmv.dev/2020/12/unit-testing-a-console-app.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25358087</guid>
            <pubDate>Wed, 09 Dec 2020 13:09:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prisma Migrate is now ready]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25357937">thread link</a>) | @sorenbs
<br/>
December 9, 2020 | https://www.prisma.io/blog/prisma-migrate-preview-b5eno5g08d0b?a | <a href="https://web.archive.org/web/*/https://www.prisma.io/blog/prisma-migrate-preview-b5eno5g08d0b?a">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><h2 id="contents"><a href="#contents" aria-label="contents permalink"></a>Contents</h2><ul><li><a href="#schema-migrations-with-prisma-migrate">Schema migrations with Prisma Migrate</a></li><li><a href="#how-does-prisma-migrate-work">How does Prisma Migrate work?</a></li><li><a href="#what-has-changed-since-the-experimental-version">What has changed since the Experimental version?</a></li><li><a href="#whats-next">What's next</a></li><li><a href="#try-prisma-migrate-and-share-your-feedback">Try Prisma Migrate and share your feedback</a></li></ul><h2 id="schema-migrations-with-prisma-migrate"><a href="#schema-migrations-with-prisma-migrate" aria-label="schema migrations with prisma migrate permalink"></a>Schema migrations with Prisma Migrate</h2><p>Today we're excited to share the new version of Prisma Migrate! üéä</p><p>Prisma Migrate is a data modeling and migrations tool that simplifies evolving the database schema with the application in-tandem. Migrate is based on the <a href="https://www.prisma.io/docs/concepts/components/prisma-schema#example">Prisma schema</a> ‚Äì a declarative data model definition that codifies your database schema.</p><p>This Preview release is the evolution of the Experimental version of Migrate that we released last year. Since then, we've been gathering feedback from the community and incorporating it into Prisma Migrate.</p><h3 id="making-schema-migrations-predictable"><a href="#making-schema-migrations-predictable" aria-label="making schema migrations predictable permalink"></a>Making schema migrations predictable</h3><p>Database schema migrations play a crucial role in software development workflows and affect the most critical component in your application ‚Äì the database. We've built Migrate to be predictable while allowing you to control how database schema changes are carried out.</p><p>Prisma Migrate generates migrations as plain SQL files based on changes in your Prisma schema. These SQL files are fully customizable and allow you to use any feature of the underlying database, such as manipulating data supporting a migration, setting up triggers, stored procedures, and views.</p><p>Prisma Migrate treads the balance between productivity and control by automating the repetitive and error-prone aspects of writing database migrations while giving you the final say over how they are executed.</p><h3 id="integration-with-prisma-client"><a href="#integration-with-prisma-client" aria-label="integration with prisma client permalink"></a>Integration with Prisma Client</h3><p>Prisma Migrate integrates with Prisma Client using the Prisma schema as their shared source of truth. In other words, both Prisma Client and migrations are generated based on the Prisma schema. This makes synchronizing and verifying database schema changes in your application code easier by leveraging Prisma Client's type safety.</p><h3 id="prisma-migrate-is-ready-for-broader-testing"><a href="#prisma-migrate-is-ready-for-broader-testing" aria-label="prisma migrate is ready for broader testing permalink"></a>Prisma Migrate is ready for broader testing</h3><p>Prisma Migrate has passed rigorous testing internally and is now ready for broader testing by the community. You can use it with PostgreSQL, MySQL, SQLite, and SQL Server. <strong>However, as a Preview feature, it is not fully production-ready yet.</strong> To read more about what Preview means, check out the <a href="https://www.prisma.io/docs/more/releases#preview">maturity levels</a> in the Prisma docs.</p><p>Thus, we're inviting you to try it out and <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/4531">give us feedback</a> so we can bring Prisma Migrate to General Availability. üö¢</p><p>Your feedback and suggestions will help us shape the future of Prisma Migrate. üôå</p><hr><h2 id="how-does-prisma-migrate-work"><a href="#how-does-prisma-migrate-work" aria-label="how does prisma migrate work permalink"></a>How does Prisma Migrate work?</h2><p>Prisma Migrate is based on the <a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-schema">Prisma schema</a> and works by generating <code>.sql</code> migration files that are executed against your database.</p><p>The Prisma schema is the starting point for schema migrations and provides an overview of your desired end-state of the database. Prisma Migrate inspects changes in the Prisma schema and generates the necessary <code>.sql</code> migration files to apply.</p><p>Applying migrations looks very different depending on the stage of development. For example, during development, there are scenarios where resetting the database can be tolerated for quicker prototyping, while in production, great care must be taken to avoid data loss and breaking changes.</p><p>Prisma Migrate accommodates for this with workflows for local development and applying migrations in production.</p><h3 id="evolving-the-schema-in-development"><a href="#evolving-the-schema-in-development" aria-label="evolving the schema in development permalink"></a>Evolving the schema in development</h3><p>To use the new version of Prisma Migrate, you should have at least version <code>2.13.0</code> of the <a href="https://www.prisma.io/docs/concepts/components/prisma-cli/installation"><code>@prisma/cli</code></a> package installed.</p><p>During development, you first define the Prisma schema and then run the <code>prisma migrate dev --preview-feature</code> command, which generates the migration, applies it, and generates Prisma Client:</p><p><span><img src="https://d33wubrfki0l68.cloudfront.net/9dee8cc50b930a017447904d95e15e0e82f9a3bf/426d4/blog/posts/2020-12-migrate-development-workflow.png" alt="Development workflow"><span>Development workflow</span></span></p><p>Here is an example showing it in action:</p><p><strong>1. Define your desired database schema using the Prisma schema:</strong></p><pre><code><span>datasource</span> <span>db</span> <span>{</span>
  provider <span>=</span> <span>"postgresql"</span>
  url      <span>=</span> <span>env</span><span>(</span><span>"DATABASE_URL"</span><span>)</span>
<span>}</span>

<span>model</span> <span>User</span> <span>{</span>
  id    <span>Int</span>      <span>@id</span> <span>@default</span><span>(</span><span>autoincrement</span><span>(</span><span>)</span><span>)</span>
  name  <span>String</span>
  posts <span>Post</span><span>[</span><span>]</span>
<span>}</span>

<span>model</span> <span>Post</span> <span>{</span>
  id        <span>Int</span>     <span>@id</span> <span>@default</span><span>(</span><span>autoincrement</span><span>(</span><span>)</span><span>)</span>
  title     <span>String</span>
  published <span>Boolean</span> <span>@default</span><span>(</span><span>true</span><span>)</span>
  authorId  <span>Int</span>
  author    <span>User</span>    <span>@relation</span><span>(</span><span>fields:</span> <span>[</span>authorId<span>]</span><span>,</span> <span>references:</span> <span>[</span>id<span>]</span><span>)</span>
<span>}</span>
</code></pre><p><strong>2. Run <code>prisma migrate dev --preview-feature</code> to create and execute the migration.</strong></p><div><div><svg width="6" height="9" viewBox="0 0 6 9" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M7.3273 0C7.88605 0 8.20036 0.653318 7.85732 1.1017L4.53001 5.45076C4.26119 5.80213 3.73881 5.80213 3.46999 5.45076L0.142684 1.1017C-0.200356 0.653318 0.113948 0 0.672698 0H7.3273Z" transform="rotate(-90 4.5 4.357)" fill="#8FA6B2"></path></svg><p><label for="tab-1">Expand to view the SQL contents of the generated migration</label></p><div><pre><code>
<span>CREATE</span> <span>TABLE</span> <span>"User"</span> <span>(</span>
  <span>"id"</span> <span>SERIAL</span><span>,</span>
  <span>"name"</span> <span>TEXT</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>PRIMARY</span> <span>KEY</span> <span>(</span><span>"id"</span><span>)</span>
<span>)</span><span>;</span>

<span>CREATE</span> <span>TABLE</span> <span>"Post"</span> <span>(</span>
  <span>"id"</span> <span>SERIAL</span><span>,</span>
  <span>"title"</span> <span>TEXT</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>"published"</span> <span>BOOLEAN</span> <span>NOT</span> <span>NULL</span> <span>DEFAULT</span> <span>true</span><span>,</span>
  <span>"authorId"</span> <span>INTEGER</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>PRIMARY</span> <span>KEY</span> <span>(</span><span>"id"</span><span>)</span>
<span>)</span><span>;</span>

<span>ALTER</span> <span>TABLE</span> <span>"Post"</span> <span>ADD</span> <span>FOREIGN</span> <span>KEY</span><span>(</span><span>"authorId"</span><span>)</span><span>REFERENCES</span> <span>"User"</span><span>(</span><span>"id"</span><span>)</span> <span>ON</span> <span>DELETE</span> <span>CASCADE</span> <span>ON</span> <span>UPDATE</span> <span>CASCADE</span><span>;</span>
</code></pre></div></div></div><p>After the migration has been executed, the migration files are typically committed to the repository so that the migration can be applied in other environments.</p><p>Further changes to the database schema follow the same workflow and begin with updating the Prisma schema.</p><h3 id="customizing-sql-migrations"><a href="#customizing-sql-migrations" aria-label="customizing sql migrations permalink"></a>Customizing SQL migrations</h3><p>You can customize the migration SQL with the following workflow:</p><ol><li>Run <strong><code>prisma migrate dev --create-only --preview-feature</code></strong> to create the SQL migration without applying it.</li><li>Edit the migration SQL.</li><li>Run <strong><code>prisma migrate dev --preview-feature</code></strong> to apply it.</li></ol><h3 id="applying-migrations-in-production-and-other-environments"><a href="#applying-migrations-in-production-and-other-environments" aria-label="applying migrations in production and other environments permalink"></a>Applying migrations in production and other environments</h3><p>To apply migrations to other environments such as production, you pull changes to the repository containing the migrations and run the <code>prisma migrate deploy</code> command:</p><p><span><img src="https://d33wubrfki0l68.cloudfront.net/5d9831941c87b7e24646bca3d96f91d4b799af6a/b7004/blog/posts/2020-12-migrate-production-workflow.png" alt="Production workflow"><span>Production workflow</span></span></p><hr><h2 id="what-has-changed-since-the-experimental-version"><a href="#what-has-changed-since-the-experimental-version" aria-label="what has changed since the experimental version permalink"></a>What has changed since the Experimental version?</h2><p>The most significant change since the Experimental version is the use of SQL as the format for migrations, making migrations <strong>deterministic</strong>. In other words, the exact steps of the migration are determined when the migration is created, allowing you to inspect the SQL (and make changes if necessary) before running.</p><p>This approach has the following benefits:</p><ul><li>The generated SQL is editable, thereby allowing you to control the exact schema changes.</li><li>The migration is predictable with the exact SQL that will be applied.</li><li>You don't need to write SQL unless you want to change a migration.</li><li>You can perform data migrations using SQL as part of a migration.</li></ul><p>Editable SQL for migrations is useful in scenarios where there are multiple ways to map changes in the Prisma schema to the database, and the desired path cannot be automatically determined.</p><p>For example, when you rename a field in the Prisma schema, that can be interpreted as either deleting the column and adding an unrelated new one or as you renaming the column. By allowing you to inspect and edit the migration SQL, you can decide whether to rename the column (and retain the data in the column) or drop it and add a new one.</p><p>If you're upgrading Prisma Migrate from the Experimental version, check out the <a href="https://www.prisma.io/docs/guides/prisma-guides/prisma-migrate-guides/add-prisma-migrate-to-a-project">upgrade guide</a>.</p><hr><h2 id="whats-next"><a href="#whats-next" aria-label="whats next permalink"></a>What's next</h2><p>This Preview version of Prisma Migrate lays the foundations for the upcoming General Availability release. Some of the improvements we are considering are improved support for native database types, seeding functionality, and finding a way to make database resets in development less disruptive.</p><h3 id="native-database-types"><a href="#native-database-types" aria-label="native database types permalink"></a>Native database types</h3><p>One of the most requested features in Prisma is support for the database's native types. This release is a step closer to that ‚Äì however, there's still more work to be done for native types to be fully supported.</p><p>Currently, the Prisma schema can only represent a limited set of types: <code>String</code>, <code>Int</code>, <code>Float</code>, <code>Boolean</code>, <code>DateTime</code>, and <code>Json</code>. Each of these types has a default mapping to an underlying database type that's specified for each database connector (see the mappings for <a href="https://www.prisma.io/docs/concepts/database-connectors/postgresql#prisma-migrate">PostgreSQL</a> and <a href="https://www.prisma.io/docs/concepts/database-connectors/mysql#prisma-migrate">MySQL</a>).</p><p>In version <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/releases/tag/2.11.0">2.11.0</a>, we released the <code>nativeTypes</code> Preview feature ‚Äì the ability to annotate fields in the Prisma schema with the specific native database type that it should be mapped to. <strong>However, the native types preview feature doesn't work with Prisma Migrate yet</strong>.</p><p>Even so, you can still change the types of columns in the generated SQL as long as they are supported, as documented in the <a href="https://www.prisma.io/docs/concepts/database-connectors/postgresql#prisma-migrate">PostgreSQL</a> and <a href="https://www.prisma.io/docs/concepts/database-connectors/mysql#prisma-migrate">MySQL</a> connector docs.</p><hr><p>We built Prisma Migrate for you and are keen to hear your feedback.</p><p>We want to understand how Prisma Migrate fits into your development workflow and how we can help you stay productive and confident while building and evolving data-centric applications.</p><p>üêõ Tried it out and found that it's missing something or stumbled upon a bug? Please <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/new/choose">file an issue</a> so we can look into it.</p><p>üèó Share your feedback about how the new Prisma Migrate is working out for you on <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/4531">GitHub</a>.</p><p>üåç Join us on our <a target="_blank" rel="noopener noreferrer" href="https://slack.prisma.io/">Slack</a> in the <a target="_blank" rel="noopener noreferrer" href="https://app.slack.com/client/T0MQBS8JG/C01ACF1DJ1M"><code>#prisma-migrate</code></a> channel for help.</p><p>üë∑‚Äç‚ôÄÔ∏è We are thrilled to finally share the Preview version of Prisma Migrate and can't wait to see what you all build with it.</p></div></div></article></div>]]>
            </description>
            <link>https://www.prisma.io/blog/prisma-migrate-preview-b5eno5g08d0b?a</link>
            <guid isPermaLink="false">hacker-news-small-sites-25357937</guid>
            <pubDate>Wed, 09 Dec 2020 12:47:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Games people play with cash flow]]>
            </title>
            <description>
<![CDATA[
Score 329 | Comments 126 (<a href="https://news.ycombinator.com/item?id=25357669">thread link</a>) | @kalonis
<br/>
December 9, 2020 | https://commoncog.com/blog/cash-flow-games/ | <a href="https://web.archive.org/web/*/https://commoncog.com/blog/cash-flow-games/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <section>
        <p>In my <a href="https://commoncog.com/blog/how-first-principles-thinking-fails/">last post</a> I examined how first principles thinking fails. This post is going to be about a single, concrete example ‚Äî about an argument that started me down this path in the first place.</p><p>A couple of months ago, a friend sent me a blog post titled <em><a href="https://ensorial.com/2020/dont-raise-money/">Startups Shouldn‚Äôt Raise Money</a></em>, over at a website called ensorial.com. I thought that the post was tightly argued and reasonably put together, with each proposition leading logically and coherently to the next. I also noticed that the author had taken the time to construct their argument from first principles ‚Ä¶ which meant it was difficult to refute any individual clause in their chain of reasoning.</p><p>But I also thought it was wrong. I told my friend as much.</p><p>‚ÄúHow is it wrong?‚Äù he immediately challenged.</p><p>‚ÄúWell ‚Ä¶‚Äù I began. And then I stopped. I realised I didn‚Äôt have a good argument for <em>why</em> it was wrong. Every axiom and intermediate proposition were ideas that I agreed with. And it wasn‚Äôt so simple as the conclusion being flat out mistaken ‚Äî you <em>could</em> probably run a small, successful internet business using the ideas laid out in the posts‚Äôs argument (internet-based businesses tend to be simpler to manage, and there are many niches you can occupy).</p><p>But I felt uneasy because I thought the framing wasn‚Äôt as <em>useful</em>. This was a more complex thing to debunk.</p><h2 id="the-setup">The Setup</h2><p>It‚Äôs easy to think that arguments have just three terminal truth values: right, maybe, and wrong. In practice, arguments (and in particular, the sort of argument that we use to justify actions) have many possible truth values. These include things like ‚Äògot the details wrong, but is by-and-large correct‚Äô, or ‚Äòis correct but for a <a href="https://commoncog.com/blog/the-right-level-of-abstraction/">different level of abstraction</a>; doesn‚Äôt apply here‚Äô, or ‚Äòis partially correct, but isn‚Äôt as useful compared to a different framing of things.‚Äô The ensorial.com piece is interesting because I think it is an instance of that last one. It was what pushed me to start thinking about all the various ways first principles thinking could go wrong.</p><p>The author‚Äôs argument unfolds as follows:</p><ol><li>Startups are risky.</li><li>Raising capital to do a startup reduces skin in the game (you‚Äôre spending other people‚Äôs money, after all).</li><li>Once you have less skin in the game, it is easier to make bad decisions. The author argues this is due to a) having a capital buffer to cushion you, and b) having more time to waste.</li><li>The alternative is to forego raising venture capital and to create a sustainable business from the beginning, ‚Äògrowing linearly with the number of people that give you money for your product.‚Äô</li><li>This aligns incentives: you grow only by solving customer problems that they would pay you for. And you‚Äôll pick the shortest path, because you don‚Äôt have the luxury of time given to you by an infusion of other people‚Äôs money.</li><li>Therefore: startups shouldn‚Äôt raise money.</li></ol><p>At first glance, there doesn‚Äôt seem to be anything that‚Äôs explicitly <em>wrong</em> with this argument. I agree with all the base ideas, and I found myself nodding to the intermediate propositions. The logical correctness of the argument wasn‚Äôt a problem. No, my unease stemmed from experience: I <em>knew</em> this wasn‚Äôt the right way to think about raising capital. But I couldn‚Äôt begin to construct an argument that went against it.</p><figure><img src="https://commoncog.com/blog/content/images/2020/12/argument_chain.f369ba07141442ea959636c21f56e207.png" alt=""></figure><p>My friend and I spent no more than 10 minutes discussing this piece. But in the months after our conversation, I continued to return to the author‚Äôs argument. I thought it was interesting because it represented a type of thinking error that you and I are likely to encounter in our lives. The form of the error is subtle, and therefore more difficult to detect; the best description I have for it is: ‚Äòperfectly rational, logically constructed, and not really <em>wrong</em> ‚Äî but not as useful or as powerful as some other framing.‚Äô</p><p>Of course, my obsession was for instrumental reasons: how might you recognise a better framing when you found one? I‚Äôll admit that I was a little naive here: I thought that if I could generalise the structure of this argument, I would be better able to recognise similar errors in the future. Alas, I have not been able to do this to my satisfaction.</p><p>(In practice, most of the older entrepreneurs I know seem to understand the problems with such sensemaking. Plausible arguments are dealt with in a simple manner: you try the recommendations that unfold from the analysis, but you remain alert to see if they give you exactly the results you want. If they don‚Äôt, you keep the frame for the time being, but you continue to look out for a better explanation. And how would you know if you have found a better way of thinking about your situation? Simple: you listen carefully. In the words of Malaysian magnate Robert Kuok, ‚Äúyou learn to distill wisdom from the air.‚Äù)</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>The most I‚Äôve been able to do is to articulate <em>how</em> the author messed up ‚Äî and therefore how first principles thinking may fail ‚Äî something that I <a href="https://commoncog.com/blog/how-first-principles-thinking-fails/">explored in my previous post</a>. The core idea is simple: I believe the author started from a limited set of axioms. If you start from a wrong set of axioms, you would eventually end up with a flawed conclusion. In this case, I think the ensorial.com author started from a deficient understanding of business.</p><p>To generalise a little, people with limited understanding of business think that business is all about making profits. But those who actually run businesses know that running a business is all about managing cash flows.</p><p>And the ensorial.com author‚Äôs argument fails because he doesn‚Äôt appear to understand this.</p><h2 id="john-malone-and-the-invention-of-ebitda">John Malone and the Invention of EBITDA</h2><p>In 1972, a 32 year old man named John Malone was offered the top job at Tele-Communications Inc (TCI), a cable company. He took charge on April Fool‚Äôs Day, 1973.</p><p>At the time of his hiring, Malone was president of Jerrold Electronics, a division of General Instrument that supplied cable boxes and credit to the cable systems companies. He had been offered the Jerrold Electronics job when he was 29 years old, just two years earlier. Before JE, he was at McKinsey Consulting. And before McKinsey, he had a job at AT&amp;T‚Äôs famed Bell Labs, where he applied operations research to find optimal company strategies in monopoly markets. Malone concluded that AT&amp;T should increase its debt load and aggressively reduce its equity base through share repurchases ‚Äî a highly unorthodox recommendation at the time. His advice was delivered to AT&amp;T‚Äôs board and then promptly ignored.</p><p>Malone had been thinking about the interplay between debt, profit, cash flow, and corporate taxes for some time. In 1972, when he was first offered the TCI job, he had already noticed a number of structural properties in the cable industry that piqued his interest:</p><ol><li>The cable industry had highly predictable subscription revenues. Cable television customers in the 60s ‚Äî especially those in rural communities ‚Äî were eager to upgrade to cable for better TV reception. These subscribers paid monthly fees and rarely cancelled.</li><li>Cable franchises were essentially a legal right to a local monopoly, which meant that cable system operators had limited competition once it established itself in a given locale.</li><li>The industry itself had very favourable tax characteristics ‚Äî smart cable operators could shelter their cash flow from taxes by using debt to build new systems, and by aggressively depreciating the costs of construction. Once the depreciation ran out on particular systems, they could then sell them to another operator, where the depreciation clock would start anew.</li><li>Most importantly, the entire market was growing like a weed: over the course of the 60s and into the start of the 70s, subscriber counts had grown over twentyfold.</li></ol><p>Of course, Malone didn‚Äôt have much time to reflect on these observations. He landed at TCI and found the company at the brink of bankruptcy.</p><p>Bob Magness, the founder of TCI, had grown the company over the course of two decades using a ridiculous pile of debt ‚Äî about 17 times revenues, at the time of Malone‚Äôs hiring. Malone spent his first couple of years at TCI fighting to keep the company alive. He flew into New York every couple of weeks, hat in hand, renegotiating <a href="https://www.investopedia.com/terms/c/covenant.asp">covenants</a> and asking for extensions on debt repayments. At one point during a meeting with TCI‚Äôs bankers, Malone threw his keys on the table and threatened to walk, leaving the company to the banks. The bankers capitulated, granting TCI a much needed extension.</p><p>Malone and Magness also had to worry about hostile takeovers, given TCI‚Äôs low stock price in the early 70s. They executed a series of complicated financial manoeuvres a year or so after Malone took over, placing a large chunk of stock in a holding company to grant them majority control. Later, they created a separate class of voting stock. These moves gave them hard control of the company, allowing Malone the freedom to focus on righting its finances.</p><p>After three years of hell, TCI was finally pulled back from the brink of financial disaster. And then Malone got to work.</p><p>Malone understood a few things about the cable industry that many outsiders didn‚Äôt. First, he understood that cable was like real estate: incredibly high fixed costs up front as you built or bought the systems, and then highly predictable, monopoly cash flows for a long time afterwards. He understood that if he used debt to finance acquisitions, he could keep growing the company, and use the depreciation on acquired systems (plus the write-offs from the loans itself) to delay paying taxes on that cash flow. Third, Malone understood that untaxed cash flows from all of those cable subscribers could be used to a) service the debt, b) pay down some of those loans ‚Äî only when necessary; Malone wanted to keep the debt-to-earnings ratio at a five-to-one level ‚Äî but more importantly c) demonstrate to creditors that TCI was a worthy debtor. And finally, Malone understood the benefits of size: the larger TCI got, the lower the cost of acquiring programming (i.e. shows and programs), because it could amortise those costs across its entire subscriber ‚Ä¶</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://commoncog.com/blog/cash-flow-games/">https://commoncog.com/blog/cash-flow-games/</a></em></p>]]>
            </description>
            <link>https://commoncog.com/blog/cash-flow-games/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25357669</guid>
            <pubDate>Wed, 09 Dec 2020 11:53:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is the Google Cloud UI so slow?]]>
            </title>
            <description>
<![CDATA[
Score 468 | Comments 370 (<a href="https://news.ycombinator.com/item?id=25357409">thread link</a>) | @mostlystatic
<br/>
December 9, 2020 | https://www.debugbear.com/blog/slow-google-cloud-ui | <a href="https://web.archive.org/web/*/https://www.debugbear.com/blog/slow-google-cloud-ui">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>
    <div>
    
      
      

      

      <div>
        
        

        <p>Opening a page in the Google Cloud Console always takes a long time.</p>
<p>Here are some metrics I collected on a high-end 2018 MacBook Pro on a UK-based Gigabit internet connection.</p>

<div id="slow-gcp-table">
<table>
<thead>
<tr>
<th>Page</th>
<th>Download</th>
<th>JavaScript</th>
<th>CPU Time</th>
<th>Main Content</th>
<th>Fully Loaded</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cloud Functions</td>
<td>4.2 MB</td>
<td>15.7 MB</td>
<td>5.3s</td>
<td>6.7s</td>
<td>8.1s</td>
</tr>
<tr>
<td>Compute Engine</td>
<td>4.5 MB</td>
<td>15.1 MB</td>
<td>6.5s</td>
<td>6.7s</td>
<td>8.1s</td>
</tr>
<tr>
<td>Cloud Storage</td>
<td>4.3 MB</td>
<td>16.2 MB</td>
<td>6.2s</td>
<td>6.5s</td>
<td>8.2s</td>
</tr>
</tbody>
</table>
</div>
<p>Download size is the compressed size, JavaScript size is uncompressed. Main Content is the time when e.g. the Cloud Functions become visible, Fully Loaded is when no more changes are made to the UI.</p>

<p>We can see that each page loads over 15 MB of JavaScript code. A look at the performance timeline in Chrome DevTools confirms that running this code is the primary cause of the poor page performance.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/timeline.png" alt="DevTools CPU timeline showing a large amount of JavaScript work"></p>
<p>This article will take a closer look at the page load process of the Google Cloud Functions page, and examine how it could be sped up.</p>
<p>You can use these strategies to investigate and improve the performance of the apps you're working on.</p>
<h2 id="loading-the-html-document">Loading the HTML document</h2>
<p>The initial HTML request is very fast and only takes about 150ms. It contains an embedded SVG spinner that shows while the first chunk of JavaScript code is loading.</p>
<video autoplay="" muted="" loop="" playsinline="">
    <source src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/gcp-spinner.mp4" type="video/mp4">
</video>
<h2 id="loading-the-initial-java-script-bundles">Loading the initial JavaScript bundles</h2>
<p>These are the first two JavaScript bundles the page starts loading.</p>
<ul>
<li><strong>routemap</strong> 21 KB (103 KB uncompressed)</li>
<li><strong>core,pm_ng1_bootstrap</strong> 1.3 MB (4.8 MB uncompressed)</li>
</ul>
<p>These files don't take too long to download, but running the code freezes the UI for a while. The spinner SVG becomes stuck at this point, until it's replaced by a skeleton UI for Google Cloud Console page.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/gcp-initial-load.png" alt="Filmstrip showing initial rendering of the GCP page"></p>
<p>Here's what happens when the browser wants to run some JavaScript code.</p>
<ol>
<li><strong>Parsing</strong> (done lazily at first, and then as needed later on)</li>
<li><strong>Compilation</strong> (also happens lazily)</li>
<li><strong>Initialization</strong> ‚Äì&nbsp;the browser runs module initialization code, i.e. code that runs when loading a module rather than when calling one of its functions</li>
<li><strong>Running core app code</strong> ‚Äì renders the application using the initialized modules</li>
</ol>
<p>For the whole Google Cloud page, just parsing the source code takes 250ms, and compilation takes another 750ms (not including the 113 ms spent on "Compile Script").</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/devtools-profile.png" alt="DevTools profile showing a breakdown of CPU activity"></p>
<p>The initial render of the Angular app takes about 1s.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/initial-bundle.png" alt="JavaScript execution flamechart"></p>
<p>Eventually we start to see a new spinner.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/second-spinner.png" alt="Page frame and new spinner"></p>
<h2 id="loading-page-bundles">Loading page bundles</h2>
<p>Once the generic Google Cloud UI is rendered the page starts loading 18 additional JavaScript files with an overall size of 1.5 MB.</p>
<p>Making a lot of separate requests isn't actually a problem though ‚Äì it can improve performance by increasing the likelinhood of cache hits, and splitting up bundles makes it easy to load only necessary code.</p>
<p>After loading the first set up bundles the app starts making fetch requests and loads 3 more bundles at a total size of 6 MB.</p>
<p>When loading the page on my normal network the requests all kind of blurred together and it was hard to see which requests were sequential. So this screenshot shows the request chart on a throttled connection.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/more-page-bundles.png" alt="Request waterfall showing three sets of JavaScript being loaded sequentially"></p>
<h2 id="loading-the-list-of-cloud-functions">Loading the list of Cloud Functions</h2>
<p>The request loading the list of Cloud Functions takes about 700ms. But it doesn't start as soon as the bundles are loaded, in part because there's a <code>testIamPermissions</code> request that needs to finish first.</p>
<p>As a result the CPU ends up being idle for half a second ‚Äì&nbsp;this time could be used better if the request started sooner.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/loading-functions.png" alt="Waterfall showing requests made to load the list of cloud functions"></p>
<p>Finally the app re-renders and we get the list of Cloud Functions we wanted to see.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/cloud-functions.png" alt="Page showing GCP Cloud Functions"></p>

<p>Chrome DevTools has a code coverage tool tracks which parts of the code actually run on the current page. This can help identify code that doesn't have to be loaded.</p>
<p>The Cloud Functions page runs 53% of the JavaScript code it downloads. This is actually a bit disappointing, as it means that even if only necessary code is loaded it would still only cut the total JavaScript size of the page in half.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/code-coverage.png" alt="Chrome DevTools Code Coverage tool"></p>
<h2 id="moving-configuration-into-json">Moving configuration into JSON</h2>
<p>A good amount of the code actually consists of configuration objects. For example, this 200 KB object with 4997 keys.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/configuration.png" alt="Configuration object in a JavaScript bundle"></p>
<p>Loading this as a JSON string with <code>JSON.parse</code> could be faster, as JSON is simpler to parse than a JavaScript object. This would be easy to do, but might not result in a huge performance improvement.</p>
<p>Ideally the app wouldn't need to load the full list on the client, but this would be harder to implement.</p>
<h2 id="reduce-code-duplication">Reduce code duplication</h2>
<p>The 200KB JSON object above is actually included in two of the JavaScript bundles. Breaking it out and reusing it would save download and processing time.</p>
<p>The same seems to apply to a bunch of UI components, like this one.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/code-duplication.png" alt="Duplicate code in DevTools code search"></p>
<h2 id="prioritize-primary-content">Prioritize primary content</h2>
<p>The Google Cloud page loads a large initial JavaScript bundle. The longer it takes to load and initialize this code, the longer it takes to load page-specific code and to render the list of Cloud Functions the user wants to see.</p>
<p>But the initial bundle also contains secondary content, like the complex navigation sidebar. This menu becomes functional before the main page content is loaded, but it should only be loaded after the primary content.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/prioritize-primary-content.png" alt="Sidebar menu is open while main content is still loading"></p>
<p>Google Cloud already does this in some cases. For example, the page initially renders a simpler version of the header and then loads more complex features later on.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/header.png" alt="Header doesn't show project dropdown at first and then shows it later"></p>
<h2 id="conclusion">Conclusion</h2>
<p>While the performance of static pages tends to be dominated by render-blocking network requests, single-page apps are often blocked by JavaScript execution or loading account data.</p>
<p>Downloading large amounts of code can hurt performance on slow connections, but due to compression and caching CPU processing often has a greater impact.</p>
<p>If you want to track the performance of your website, including logged-in pages, <a href="https://www.debugbear.com/">give DebugBear a try</a>.</p>
<blockquote><p lang="en" dir="ltr">Why is the Google Cloud UI so slow? This article looks at the performance of a large JavaScript application and explores how it could be made faster.<a href="https://t.co/HSHhCXYQCi">https://t.co/HSHhCXYQCi</a></p>‚Äî DebugBear (@DebugBear) <a href="https://twitter.com/DebugBear/status/1336621651669213186?ref_src=twsrc%5Etfw">December 9, 2020</a></blockquote> 

        

        
        <div>
            <div>
                <p>
                    DebugBear is a website monitoring tool built for front-end teams.
                    Track performance metrics and Lighthouse scores in CI and production.
                    <a href="https://www.debugbear.com/?noredirect&amp;from_blog">Learn more</a>.
                </p>
                
            </div>
        </div>
        <div>
        
                    <!-- Begin Mailchimp Signup Form -->
            
            
            <div>
                <div>
                    
                    <div>
                        
                        <h2>Get new articles on web performance <!-- and debugging --> by email.</h2>
                    </div>
                </div>
                
            </div>
        
            
        
        </div>      </div>
    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://www.debugbear.com/blog/slow-google-cloud-ui</link>
            <guid isPermaLink="false">hacker-news-small-sites-25357409</guid>
            <pubDate>Wed, 09 Dec 2020 11:08:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Python object system works]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25357032">thread link</a>) | @r4victor
<br/>
December 9, 2020 | https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/ | <a href="https://web.archive.org/web/*/https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <p>As we know from the previous parts of this series, the execution of a Python program consists of two major steps:</p>
<ol>
<li><a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/">The CPython compiler</a> translates Python code to bytecode.</li>
<li><a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-1-how-the-cpython-vm-works/">The CPython VM</a> executes the bytecode.</li>
</ol>
<p>We've been focusing on the second step for quite a while. In <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/">part 4</a> we've looked at the evaluation loop, a place where Python bytecode gets executed. And in <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-5-how-variables-are-implemented-in-cpython/">part 5</a> we've studied how the VM executes the instructions that are used to implement variables. What we haven't covered yet is how the VM actually computes something. We postponed this question because to answer it, we first need to understand how the most fundamental part of the language works. Today, we'll study the Python object system.</p>
<p><strong>Note</strong>: In this post I'm referring to CPython 3.9. Some implementation details will certainly change as CPython evolves. I'll try to keep track of important changes and add update notes.</p>
<h2>Motivation</h2>
<p>Consider an extremely simple piece of Python code:</p>



<p>To compute the function <code>f</code>, CPython must evaluate the expression <code>x + 7</code>. The question I'd like to ask is: How does CPython do that? Special methods such as <code>__add__()</code> and <code>__radd__()</code> probably come to your mind. When we define these methods on a class, the instances of that class can be added using the <code>+</code> operator. So, you might think that CPython does something like this:</p>
<ol>
<li>It calls <code>x.__add__(7)</code> or <code>type(x).__add__(x, 7)</code>.</li>
<li>If <code>x</code> doesn't have <code>__add__()</code>, or if this method fails, it calls <code>(7).__radd__(x)</code> or <code>int.__radd__(7, x)</code>.</li>
</ol>
<p>The reality, tough, is a bit more complicated. What really happens depends on what <code>x</code> is. For example, if <code>x</code> is an instance of a user-defined class, the algorithm described above resembles the truth. If, however, <code>x</code> is an instance of a built-in type, like <code>int</code> or <code>float</code>, CPython doesn't call any special methods at all.</p>
<p>To learn how some Python code is executed, we can do the following:</p>
<ol>
<li>Disassemble the code into bytecode.</li>
<li>Study how the VM executes the disassembled bytecode instructions.</li>
</ol>
<p>Let's apply this algorithm to the function <code>f</code>. The compiler translates the body of this function to the following bytecode:</p>
<div><pre><span></span>$ python -m dis f.py
...
  2           0 LOAD_FAST                0 (x)
              2 LOAD_CONST               1 (7)
              4 BINARY_ADD
              6 RETURN_VALUE
</pre></div>


<p>And here's what these bytecode instructions do:</p>
<ol>
<li><code>LOAD_FAST</code> loads the value of the parameter <code>x</code> onto the stack.</li>
<li><code>LOAD_CONST</code> loads the constant <code>7</code> onto the stack.</li>
<li><code>BINARY_ADD</code> pops two values from the stack, adds them and pushes the result back onto the stack.</li>
<li><code>RETURN_VALUE</code> pops the value from the stack and returns it.</li>
</ol>
<p>How does the VM add two values? To answer this question, we need to understand what these values are. For us, <code>7</code> is an instance of <code>int</code> and <code>x</code> is, well, anything. For the VM, though, everything is a Python object. All values the VM pushes onto the stack and pops from the stack are pointers to <code>PyObject</code> structs (hence the phrase "Everything in Python is an object").</p>
<p>The VM doesn't need to know how to add integers or strings, that is, how to do the arithmetic or concatenate sequences. All it needs to know is that every Python object has a type. A type, in turn, knows everything about its objects. For example, the <code>int</code> type knows how to add integers, and the <code>float</code> type knows how to add floats. So, the VM asks the type to perform the operation.</p>
<p>This simplified explanation captures the essence of the solution, but it also omits a lot of important details. To get a more realistic picture, we need to understand what Python objects and types really are and how they work.</p>
<h2>Python objects and types</h2>
<p>We've discussed Python objects a little in <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-3-stepping-through-the-cpython-source-code/">part 3</a>. This discussion is worth repeating here.</p>
<p>We begin with the definition of the <code>PyObject</code> struct:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>_object</span> <span>{</span>
    <span>_PyObject_HEAD_EXTRA</span> <span>// macro, for debugging purposes only</span>
    <span>Py_ssize_t</span> <span>ob_refcnt</span><span>;</span>
    <span>PyTypeObject</span> <span>*</span><span>ob_type</span><span>;</span>
<span>}</span> <span>PyObject</span><span>;</span>
</pre></div>


<p>It has two members:</p>
<ul>
<li>a reference count <code>ob_refcnt</code> that CPython uses for garbage collection; and</li>
<li>a pointer to the object's type <code>ob_type</code>.</li>
</ul>
<p>We said that the VM treats any Python object as <code>PyObject</code>. How is that possible? The C programming language has no notion of classes and inheritance. Nevertheless, it's possible to implement in C something that can be called a single inheritance. The C standard states that a pointer to any struct can be converted to a pointer to its first member and vice versa. So, we can "extend" <code>PyObject</code> by defining a new struct whose first member is <code>PyObject</code>.</p>
<p>Here's, for example, how the <code>float</code> object is defined:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>PyObject</span> <span>ob_base</span><span>;</span> <span>// expansion of PyObject_HEAD macro</span>
    <span>double</span> <span>ob_fval</span><span>;</span>
<span>}</span> <span>PyFloatObject</span><span>;</span>
</pre></div>


<p>A <code>float</code> object stores everything <code>PyObject</code> stores plus a floating-point value <code>ob_fval</code>. The C standard simply states that we can convert a pointer to <code>PyFloatObject</code> to a pointer to <code>PyObject</code> and vice versa:</p>
<div><pre><span></span><span>PyFloatObject</span> <span>float_object</span><span>;</span>
<span>// ...</span>
<span>PyObject</span> <span>*</span><span>obj_ptr</span> <span>=</span> <span>(</span><span>PyObject</span> <span>*</span><span>)</span><span>&amp;</span><span>float_object</span><span>;</span>
<span>PyFloatObject</span> <span>*</span><span>float_obj_ptr</span> <span>=</span> <span>(</span><span>PyFloatObject</span> <span>*</span><span>)</span><span>obj_ptr</span><span>;</span>
</pre></div>


<p>The reason why the VM treats every Python object as <code>PyObject</code> is because all it needs to access is the object's type. A type is also a Python object, an instance of the <code>PyTypeObject</code> struct:</p>
<div><pre><span></span><span>// PyTypeObject is a typedef for "struct _typeobject"</span>

<span>struct</span> <span>_typeobject</span> <span>{</span>
    <span>PyVarObject</span> <span>ob_base</span><span>;</span> <span>// expansion of PyObject_VAR_HEAD macro</span>
    <span>const</span> <span>char</span> <span>*</span><span>tp_name</span><span>;</span> <span>/* For printing, in format "&lt;module&gt;.&lt;name&gt;" */</span>
    <span>Py_ssize_t</span> <span>tp_basicsize</span><span>,</span> <span>tp_itemsize</span><span>;</span> <span>/* For allocation */</span>

    <span>/* Methods to implement standard operations */</span>

    <span>destructor</span> <span>tp_dealloc</span><span>;</span>
    <span>Py_ssize_t</span> <span>tp_vectorcall_offset</span><span>;</span>
    <span>getattrfunc</span> <span>tp_getattr</span><span>;</span>
    <span>setattrfunc</span> <span>tp_setattr</span><span>;</span>
    <span>PyAsyncMethods</span> <span>*</span><span>tp_as_async</span><span>;</span> <span>/* formerly known as tp_compare (Python 2)</span>
<span>                                    or tp_reserved (Python 3) */</span>
    <span>reprfunc</span> <span>tp_repr</span><span>;</span>

    <span>/* Method suites for standard classes */</span>

    <span>PyNumberMethods</span> <span>*</span><span>tp_as_number</span><span>;</span>
    <span>PySequenceMethods</span> <span>*</span><span>tp_as_sequence</span><span>;</span>
    <span>PyMappingMethods</span> <span>*</span><span>tp_as_mapping</span><span>;</span>

    <span>/* More standard operations (here for binary compatibility) */</span>

    <span>hashfunc</span> <span>tp_hash</span><span>;</span>
    <span>ternaryfunc</span> <span>tp_call</span><span>;</span>
    <span>reprfunc</span> <span>tp_str</span><span>;</span>
    <span>getattrofunc</span> <span>tp_getattro</span><span>;</span>
    <span>setattrofunc</span> <span>tp_setattro</span><span>;</span>

    <span>/* Functions to access object as input/output buffer */</span>
    <span>PyBufferProcs</span> <span>*</span><span>tp_as_buffer</span><span>;</span>

    <span>/* Flags to define presence of optional/expanded features */</span>
    <span>unsigned</span> <span>long</span> <span>tp_flags</span><span>;</span>

    <span>const</span> <span>char</span> <span>*</span><span>tp_doc</span><span>;</span> <span>/* Documentation string */</span>

    <span>/* Assigned meaning in release 2.0 */</span>
    <span>/* call function for all accessible objects */</span>
    <span>traverseproc</span> <span>tp_traverse</span><span>;</span>

    <span>/* delete references to contained objects */</span>
    <span>inquiry</span> <span>tp_clear</span><span>;</span>

    <span>/* Assigned meaning in release 2.1 */</span>
    <span>/* rich comparisons */</span>
    <span>richcmpfunc</span> <span>tp_richcompare</span><span>;</span>

    <span>/* weak reference enabler */</span>
    <span>Py_ssize_t</span> <span>tp_weaklistoffset</span><span>;</span>

    <span>/* Iterators */</span>
    <span>getiterfunc</span> <span>tp_iter</span><span>;</span>
    <span>iternextfunc</span> <span>tp_iternext</span><span>;</span>

    <span>/* Attribute descriptor and subclassing stuff */</span>
    <span>struct</span> <span>PyMethodDef</span> <span>*</span><span>tp_methods</span><span>;</span>
    <span>struct</span> <span>PyMemberDef</span> <span>*</span><span>tp_members</span><span>;</span>
    <span>struct</span> <span>PyGetSetDef</span> <span>*</span><span>tp_getset</span><span>;</span>
    <span>struct</span> <span>_typeobject</span> <span>*</span><span>tp_base</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_dict</span><span>;</span>
    <span>descrgetfunc</span> <span>tp_descr_get</span><span>;</span>
    <span>descrsetfunc</span> <span>tp_descr_set</span><span>;</span>
    <span>Py_ssize_t</span> <span>tp_dictoffset</span><span>;</span>
    <span>initproc</span> <span>tp_init</span><span>;</span>
    <span>allocfunc</span> <span>tp_alloc</span><span>;</span>
    <span>newfunc</span> <span>tp_new</span><span>;</span>
    <span>freefunc</span> <span>tp_free</span><span>;</span> <span>/* Low-level free-memory routine */</span>
    <span>inquiry</span> <span>tp_is_gc</span><span>;</span> <span>/* For PyObject_IS_GC */</span>
    <span>PyObject</span> <span>*</span><span>tp_bases</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_mro</span><span>;</span> <span>/* method resolution order */</span>
    <span>PyObject</span> <span>*</span><span>tp_cache</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_subclasses</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_weaklist</span><span>;</span>
    <span>destructor</span> <span>tp_del</span><span>;</span>

    <span>/* Type attribute cache version tag. Added in version 2.6 */</span>
    <span>unsigned</span> <span>int</span> <span>tp_version_tag</span><span>;</span>

    <span>destructor</span> <span>tp_finalize</span><span>;</span>
    <span>vectorcallfunc</span> <span>tp_vectorcall</span><span>;</span>
<span>};</span>
</pre></div>


<p>By the way, note that the first member of a type is not <code>PyObject</code> but <code>PyVarObject</code>, which is defined as follows:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>PyObject</span> <span>ob_base</span><span>;</span>
    <span>Py_ssize_t</span> <span>ob_size</span><span>;</span> <span>/* Number of items in variable part */</span>
<span>}</span> <span>PyVarObject</span><span>;</span>
</pre></div>


<p>Nevertheless, since the first member of <code>PyVarObject</code> is <code>PyObject</code>, a pointer to a type can still be converted to a pointer to <code>PyObject</code>.</p>
<p>So, what is a type and why does it have so many members? A type determines how the objects of that type behave. Each member of a type, called slot, is responsible for a particular aspect of the object's behavior. For example:</p>
<ul>
<li><code>tp_new</code> is a pointer to a function that creates new objects of the type.</li>
<li><code>tp_str</code> is a pointer to a function that implements  <code>str()</code> for objects of the type.</li>
<li><code>tp_hash</code> is a pointer to a function that implements  <code>hash()</code> for objects of the type.</li>
</ul>
<p>Some slots, called sub-slots, are grouped together in suites. A suite is just a struct that contains related slots. For example, the <code>PySequenceMethods</code> struct is a suite of sub-slots that implement the sequence protocol:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>lenfunc</span> <span>sq_length</span><span>;</span>
    <span>binaryfunc</span> <span>sq_concat</span><span>;</span>
    <span>ssizeargfunc</span> <span>sq_repeat</span><span>;</span>
    <span>ssizeargfunc</span> <span>sq_item</span><span>;</span>
    <span>void</span> <span>*</span><span>was_sq_slice</span><span>;</span>
    <span>ssizeobjargproc</span> <span>sq_ass_item</span><span>;</span>
    <span>void</span> <span>*</span><span>was_sq_ass_slice</span><span>;</span>
    <span>objobjproc</span> <span>sq_contains</span><span>;</span>

    <span>binaryfunc</span> <span>sq_inplace_concat</span><span>;</span>
    <span>ssizeargfunc</span> <span>sq_inplace_repeat</span><span>;</span>
<span>}</span> <span>PySequenceMethods</span><span>;</span>
</pre></div>


<p>If you count all the slots and sub-slots, you'll get a scary number. Fortunately, each slot is very well <a href="https://docs.python.org/3/c-api/typeobj.html">documented</a> in the Python/C API Reference Manual (I strongly recommend you to bookmark this link). Today we'll cover only a few slots. Nevertheless, it shall give us a general idea of how slots are used.</p>
<p>Since we're interested in how CPython adds objects, let's find the slots responsible for addition. There must be at least one such slot. After careful inspection of the <code>PyTypeObject</code> struct, we find that it has the "number" suite <code>PyNumberMethods</code>, and the first slot of this suite is a binary function called <code>nd_add</code>:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>binaryfunc</span> <span>nb_add</span><span>;</span> <span>// typedef PyObject * (*binaryfunc)(PyObject *, PyObject *)</span>
    <span>binaryfunc</span> <span>nb_subtract</span><span>;</span>
    <span>binaryfunc</span> <span>nb_multiply</span><span>;</span>
    <span>binaryfunc</span> <span>nb_remainder</span><span>;</span>
    <span>binaryfunc</span> <span>nb_divmod</span><span>;</span>
    <span>// ... more sub-slots</span>
<span>}</span> <span>PyNumberMethods</span><span>;</span>
</pre></div>


<p>It seems that the <code>nb_add</code> slot is what we're looking for. Two questions naturally arise regarding this ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/</a></em></p>]]>
            </description>
            <link>https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25357032</guid>
            <pubDate>Wed, 09 Dec 2020 10:04:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Highly Effective Techniques to Study More Effectively in 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25356878">thread link</a>) | @rossnoel
<br/>
December 9, 2020 | https://productive.fish/blog/how-to-study-effectively/ | <a href="https://web.archive.org/web/*/https://productive.fish/blog/how-to-study-effectively/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>16 Aug 2020 ‚Ä¢ 5 min read</p><p>Have you been struggling to study effectively? Sometimes it seems as if we have more pages to read than time on the clock. However, if you decide to study smart instead of studying hard, you are more likely to get the outcome that you desire. In this article, you will be given strategies on how to study effectively.</p><picture><source media="(min-width: 1100px)" srcset="https://productive.fish/blog/how-to-study-effectively/studying-920.jpg, https://productive.fish/blog/how-to-study-effectively/studying.jpg 2x"><source media="(max-width: 1099px) and (min-width: 421px)" srcset="https://productive.fish/blog/how-to-study-effectively/studying-640.jpg, https://productive.fish/blog/how-to-study-effectively/studying-1280.jpg 2x"><source media="(max-width: 420px)" srcset="https://productive.fish/blog/how-to-study-effectively/studying-420.jpg, https://productive.fish/blog/how-to-study-effectively/studying-840.jpg 2x"><img src="https://productive.fish/blog/how-to-study-effectively/studying.jpg" alt="Illustration of studying person"></picture><h2 id="organize-your-learning-process">Organize your learning process</h2><p>Organizing your entire learning process is the very first step that you need to take in studying more effectively. You will need to assign a particular place in your home where you get your studying done, determine a schedule that guides your study time, and you will need to decide whether or not you will be studying in a group or by yourself. You will also need to determine what study style is best for you. Having this in place helps you to approach your studying in a more systematic and efficient manner.</p><p>Let‚Äôs take a look at approaches that can help you to better understand how to learn effectively.</p><h3 id="spaced-repetition">Spaced Repetition</h3><p><a href="https://productive.fish/blog/spaced-repetition">Spaced repetition</a> refers to the practice of allowing space between each study session. By integrating time intervals in your study schedule, you will be able to retain more even if you spend less time studying.</p><p>This works by tapping into the potential of what is called the spacing effect. This speaks to the fact that our brain is better able to learn new concepts by using intervals between exposure to the information.</p><p>How to study more effectively with this method? Let‚Äôs say you have an exam scheduled for next week. You should have a study session today. Your next study session would be two days from today. You should then have a final study session the day before the test.</p><h3 id="active-recall">Active recall</h3><p>Another way to learn effectively is to employ the principles of active recall. This approach has been found to be the most effective, efficient, and quickest way to study materials. This approach holds that in order to get the best out of studying, you need to actively stimulate your memory. This moves students from a passive approach to studying such as simply reading silently to an approach where the student interacts with the material.</p><p>This includes asking and answering questions about the material read and many other tactics. You will find that there are a number of different ways to implement active recall. Two popular methods of active learning are the Read-Recite-Review (3R) method and the Feynman Technique.</p><h3 id="pomodoro-technique-and-the-importance-of-study-breaks">Pomodoro Technique and the Importance of Study Breaks</h3><p>The struggle we all have with procrastination is real and should not be overlooked. One of the best strategies for minimizing distractions is the <a href="https://productive.fish/blog/pomodoro-technique">Pomodoro technique</a>. This approach helps to keep you from becoming overwhelmed by studying and from burnouts. It includes stipulated work intervals and breaks.</p><p>An example of studying effectively with the Pomodoro technique is as follows:</p><ul><li>Study for 25 minutes</li><li>Distractions will come. When they do, write them down on a piece of paper.</li><li>At the end of the 25-minute period, place a check mark on your paper.</li><li>Break from studying for 5 minutes.</li><li>After doing this 4 times, take a 30-minute break.</li><li>Repeat the entire process.</li></ul><p>This method was developed by Francesco Cirillo. This time management technique was inspired by the popular tomato-shaped kitchen timer.</p><p>Breaks are critical to learning effectively. These breaks help to maintain performance while studying, reduce the stress associated with studying, increase focus, and help with memory retention.</p><h3 id="bite-sized-learning">Bite-sized learning</h3><p>Another method to consider when trying to uncover how to study better is bite-sized learning. This method means just what the name suggests ‚Äì studying information in small bits or spending very short periods studying at a time.</p><p>With the constant reduction of attention span among humans in the 21st century, it is becoming more and more important that you spend 1-15 minutes at a time on any given learning objective. The focus that you will have in this short period of time makes learning more effective.</p><h2 id="take-notes-the-right-way">Take notes the right way</h2><p>There are many powerful reasons that all students should actively take notes in class and while studying. These reasons include:</p><p>Taking notes is helpful in keeping your mind alert. By actively writing notes, you are interacting with the information. This helps to reduce drowsiness and prevents distractions. The act of deciphering what information to jot down helps to keep your mind engaged in what you are reading or listening to. Taking notes gives you an opportunity to highlight or emphasize certain bits of information. It also helps with the organization of said information. The highlighted and organized information that you take during class or in a study session helps to make your future study sessions or review of class information much more effective. Taking good notes in class or during a study session provides you with an abbreviated yet potent set of information for effective studying. When it becomes necessary to study for an exam or a test, you can easily draw on your notes and spend less time reinforcing the most important points.</p><p>Let‚Äôs look at some note-taking techniques to help you effectively study.</p><h3 id="the-cornell-note-taking-system">The Cornell Note Taking System</h3><p>This system of note-taking was developed by Walter Pauk in the 1940s. This approach to notetaking is systematic and more condensed. It can be used by high school students or students at the college level.</p><p>This method entails a student dividing a page into three sections. A keyword section, the notes section, and a section for a summary of the lesson. In this method, long sentences are avoided while taking notes to reduce the bulk. The keyword section only features words or questions that are most important , which students can easily reflect on when reviewing their notes.</p><h3 id="the-outlining-method">The Outlining Method</h3><p>This method is ideal for you when your are trying to discover how to study more effectively. It includes creating an outline of the course, article or a book. In this method, information is summarized in brief bullet points. The major points are at farthest to the left while minor points are indented.</p><h3 id="the-mapping-method">The Mapping Method</h3><p>The mapping method involves the use of a graphic representation of that which is being studied. It shows how the various pieces of information to be absorbed relates to each other. The <a href="https://productive.fish/blog/mind-mapping-software">mind mapping method</a> can be coupled with the outline method or the Cornell note-taking system quite effectively.</p><h2 id="teach-someone-else">Teach someone else</h2><p>It is always said that the best way to better learn a subject is to teach it to someone else. One of the most effective ways to retain information is to share it with others. You could develop a habit of mentoring students in your class who are having a hard time grasping the concepts being taught.</p><p>Another creative way to deepen your understanding of a subject by teaching others is by starting a blog series on the topic that you are studying. You will be able to edify others while being better prepared to succeed in your next exam.</p><h2 id="conclusion">Conclusion</h2><p>Learning to study more effectively is a critical part of student success. While all of these methods have been proven to be effective, everybody learns differently; therefore, it is best for you to try each of these methods to see which is most effective for you. Fight the temptation to be lazy in this process. By finding the approach that is best for you, your entire academic life can become much smoother.</p></article></div>]]>
            </description>
            <link>https://productive.fish/blog/how-to-study-effectively/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25356878</guid>
            <pubDate>Wed, 09 Dec 2020 09:40:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Graphcore Sets New AI Performance Standards with Mk2 IPU Systems]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25356767">thread link</a>) | @ingve
<br/>
December 9, 2020 | https://www.graphcore.ai/posts/graphcore-sets-new-ai-performance-standards-with-mk2-ipu-systems | <a href="https://web.archive.org/web/*/https://www.graphcore.ai/posts/graphcore-sets-new-ai-performance-standards-with-mk2-ipu-systems">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				
				
				

				<div>
					
					<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>We‚Äôre sharing a raft of new performance results for our MK2 IPU-based machine intelligence systems today. You‚Äôll see our IPU-M2000 system significantly outperforms the Nvidia A100 DGX across the board, with orders of magnitude performance improvements for some models.</p>
<!--more-->
<p>Graphcore customers are already making big leaps forward with our second generation IPU systems ‚Äì whether they prioritise faster time to result, model accuracy, better efficiency, lower TCO (Total Cost of Ownership) or the chance to make new breakthroughs in AI with the IPU.</p>
<p>We‚Äôve chosen a range of the most popular models our customers frequently turn to as proxies for their proprietary production AI workloads in natural language processing, computer vision and more, both in training and inference.</p>
<p>We are also delighted to share results in this blog using our new PyTorch framework support. We are continuing to develop and expand this capability ‚Äì you can find out more in our blog <a href="https://www.graphcore.ai/posts/introducing-pytorch-for-the-ipu"><span>here</span></a>. <span>&nbsp;</span></p>
<p>The results are measured on IPU-M2000 &amp; IPU-POD<sub>64</sub> platforms. Wherever possible, we compare IPU performance against performance numbers published by NVIDIA for the A100 GPU as part of the DGX A100 platform. It‚Äôs notoriously hard to find an exact apples-to-apples comparison for very different products and chip architectures, so we compare against the closest platform in terms of price and power. Where NVIDIA has not published results for a particular model, measured results are used.<span>&nbsp;</span></p>
<p>Code for all of our benchmarks is available from the examples repo on the <a href="https://github.com/graphcore"><span>Graphcore GitHub</span></a> site where you can also find code for many other model types and application examples.<span>&nbsp;</span></p>
<p>We‚Äôve included notes for each chart to explain our methodology and to provide additional information about batch sizes, data sets, floating point arithmetic, frameworks etc. In addition to publishing our benchmarking charts in this blog and on our <a href="https://www.graphcore.ai/benchmarks" rel="noopener" target="_blank">website</a>, we are also publishing performance data in <a href="https://www.graphcore.ai/performance-results" rel="noopener" target="_blank">tabular format </a>for IPU-M2000 and IPU-POD systems on our website. We‚Äôll add more and update the results regularly.</p>
<p>Finally, we‚Äôve also joined <a href="https://mlcommons.org/en/" rel="noopener" target="_blank">MLCommons</a>, the governing body for the independent benchmarking organisation, MLPerf. We will be participating in MLPerf in 2021 ‚Äì starting with the first training submission in the Spring ‚Äì as well as continuing to build out our own performance results.</p>
<p><strong><span>Natural Language Processing (NLP)</span>&nbsp;</strong></p>
<p><strong>BERT-Large Training</strong></p>
<p>BERT-Large <span>(Bidirectional Encoder Representations from Transformers)</span> is established as one of the most widely used models for NLP.</p>
<p>The IPU-POD<sub>64 </sub>is over 5x faster than a DGX A100 system for end-to-end BERT-Large Training to convergence to reference accuracies. To provide consistency in the comparisons used in our other charts, we also show time-to-train for a 2x DGX A100 system.<span>&nbsp;</span></p>
<p><span><img src="https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Training_December%202020.jpg?width=2000&amp;name=BERT%20Large%20Training_December%202020.jpg" alt="BERT Large Training_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Training_December%202020.jpg?width=1000&amp;name=BERT%20Large%20Training_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Training_December%202020.jpg?width=2000&amp;name=BERT%20Large%20Training_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Training_December%202020.jpg?width=3000&amp;name=BERT%20Large%20Training_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Training_December%202020.jpg?width=4000&amp;name=BERT%20Large%20Training_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Training_December%202020.jpg?width=5000&amp;name=BERT%20Large%20Training_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Training_December%202020.jpg?width=6000&amp;name=BERT%20Large%20Training_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></span></p>
<p><strong>BERT-Large Inference</strong></p>
<p>The goal in inference production systems is typically to achieve the highest possible throughput at the lowest possible latency. For example, search engine companies and many automated services using inference need to respond in near real time.</p>
<p>For BERT-Large Inference, the IPU-M2000 delivers 3.4x higher throughput at the lowest latency compared to the A100.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Inference_December%202020.jpg?width=2000&amp;name=BERT%20Large%20Inference_December%202020.jpg" alt="BERT Large Inference_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Inference_December%202020.jpg?width=1000&amp;name=BERT%20Large%20Inference_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Inference_December%202020.jpg?width=2000&amp;name=BERT%20Large%20Inference_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Inference_December%202020.jpg?width=3000&amp;name=BERT%20Large%20Inference_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Inference_December%202020.jpg?width=4000&amp;name=BERT%20Large%20Inference_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Inference_December%202020.jpg?width=5000&amp;name=BERT%20Large%20Inference_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/BERT%20Large%20Inference_December%202020.jpg?width=6000&amp;name=BERT%20Large%20Inference_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><strong>Computer Vision&nbsp;</strong></p>
<p><strong>ResNet-50 Training</strong></p>
<p>The IPU-M2000 processes 2.6x more images per second vs the A100 for <a href="https://arxiv.org/abs/1512.03385"><span>ResNet-50</span></a>, a common model for image classification used as a baseline performance metric across the industry, which has been highly optimised on GPU architectures. Here we show results for IPU with both TensorFlow and PyTorch.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Training_December%202020.jpg?width=2000&amp;name=ResNet%2050%20Training_December%202020.jpg" alt="ResNet 50 Training_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Training_December%202020.jpg?width=1000&amp;name=ResNet%2050%20Training_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Training_December%202020.jpg?width=2000&amp;name=ResNet%2050%20Training_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Training_December%202020.jpg?width=3000&amp;name=ResNet%2050%20Training_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Training_December%202020.jpg?width=4000&amp;name=ResNet%2050%20Training_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Training_December%202020.jpg?width=5000&amp;name=ResNet%2050%20Training_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Training_December%202020.jpg?width=6000&amp;name=ResNet%2050%20Training_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><strong>ResNet-50 Inference</strong></p>
<p>The IPU-M2000 delivers 4.6x higher throughput at lowest latency comparing with published results for the A100 80GB GPU, for both PyTorch and TensorFlow, achieving much higher absolute throughput of 58,112 images per second.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Inference_December%202020.jpg?width=2000&amp;name=ResNet%2050%20Inference_December%202020.jpg" alt="ResNet 50 Inference_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Inference_December%202020.jpg?width=1000&amp;name=ResNet%2050%20Inference_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Inference_December%202020.jpg?width=2000&amp;name=ResNet%2050%20Inference_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Inference_December%202020.jpg?width=3000&amp;name=ResNet%2050%20Inference_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Inference_December%202020.jpg?width=4000&amp;name=ResNet%2050%20Inference_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Inference_December%202020.jpg?width=5000&amp;name=ResNet%2050%20Inference_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/ResNet%2050%20Inference_December%202020.jpg?width=6000&amp;name=ResNet%2050%20Inference_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><strong>EfficientNet Training</strong></p>
<p><span><a href="https://arxiv.org/abs/1905.11946">EfficientNet</a></span> uses innovative techniques like group separable and depth-wise convolutions to deliver far higher accuracy per parameter than legacy image classification models like ResNet-50.<span>&nbsp;</span></p>
<p>Group and depth-wise convolutions use smaller kernels which are not well suited to GPUs and this has limited their adoption to date.<span>&nbsp;</span></p>
<p>By contrast, a fine-grained processor like the IPU, with its unique MIMD architecture, is much better suited to group convolution, depth-wise convolution and more generally sparse models which inherently do not use dense, contiguous data structures.<span>&nbsp;</span></p>
<p><span>For standard EfficientNet-B4 Training for both PyTorch and TensorFlow, the IPU-M2000 achieves 10x throughput advantage versus the latest GPU.</span></p>
<p><span><img src="https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg?width=2000&amp;name=EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg" alt="EfficientNet Training PyTorch and TensorFlow_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg?width=1000&amp;name=EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg?width=2000&amp;name=EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg?width=3000&amp;name=EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg?width=4000&amp;name=EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg?width=5000&amp;name=EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg?width=6000&amp;name=EfficientNet%20Training%20PyTorch%20and%20TensorFlow_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></span></p>
<p>With optimised EfficientNet-B4 Training, the IPU-M2000 achieves 18x throughput advantage versus the latest GPU.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20IPU%20optimised_December%202020.jpg?width=2000&amp;name=EfficientNet%20Training%20IPU%20optimised_December%202020.jpg" alt="EfficientNet Training IPU optimised_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20IPU%20optimised_December%202020.jpg?width=1000&amp;name=EfficientNet%20Training%20IPU%20optimised_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20IPU%20optimised_December%202020.jpg?width=2000&amp;name=EfficientNet%20Training%20IPU%20optimised_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20IPU%20optimised_December%202020.jpg?width=3000&amp;name=EfficientNet%20Training%20IPU%20optimised_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20IPU%20optimised_December%202020.jpg?width=4000&amp;name=EfficientNet%20Training%20IPU%20optimised_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20IPU%20optimised_December%202020.jpg?width=5000&amp;name=EfficientNet%20Training%20IPU%20optimised_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Training%20IPU%20optimised_December%202020.jpg?width=6000&amp;name=EfficientNet%20Training%20IPU%20optimised_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><strong>EfficientNet-B0 Inference</strong></p>
<p>We see an even greater advantage with inference. The IPU-M2000 achieves more than 60x higher throughput and 16x lower latency than the latest GPU in a lowest latency comparison for both TensorFlow and PyTorch. In fact, the IPU-M2000 delivers higher throughput at its lowest latency than is achievable by the latest GPU at any batch size.<span>&nbsp;</span></p>
<p><span><img src="https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Inference_December%202020.jpg?width=2000&amp;name=EfficientNet%20Inference_December%202020.jpg" alt="EfficientNet Inference_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Inference_December%202020.jpg?width=1000&amp;name=EfficientNet%20Inference_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Inference_December%202020.jpg?width=2000&amp;name=EfficientNet%20Inference_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Inference_December%202020.jpg?width=3000&amp;name=EfficientNet%20Inference_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Inference_December%202020.jpg?width=4000&amp;name=EfficientNet%20Inference_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Inference_December%202020.jpg?width=5000&amp;name=EfficientNet%20Inference_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/EfficientNet%20Inference_December%202020.jpg?width=6000&amp;name=EfficientNet%20Inference_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></span></p>
<p><strong>ResNeXt-101 Training</strong></p>
<p>ResNeXt-101 is an innovative model that delivers higher accuracy for image classification. <a href="https://arxiv.org/abs/1611.05431"><span>ResNeXt</span></a> uses depth-wise separable convolutions which perform far better on the IPU architecture than on the GPU resulting in 3.7x higher throughput on the IPU-M2000 with TensorFlow vs A100 GPU.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Training_December%202020.jpg?width=2000&amp;name=ResNeXt%20Training_December%202020.jpg" alt="ResNeXt Training_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Training_December%202020.jpg?width=1000&amp;name=ResNeXt%20Training_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Training_December%202020.jpg?width=2000&amp;name=ResNeXt%20Training_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Training_December%202020.jpg?width=3000&amp;name=ResNeXt%20Training_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Training_December%202020.jpg?width=4000&amp;name=ResNeXt%20Training_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Training_December%202020.jpg?width=5000&amp;name=ResNeXt%20Training_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Training_December%202020.jpg?width=6000&amp;name=ResNeXt%20Training_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><strong>ResNeXt-101 Inference</strong></p>
<p>The IPU-M2000 achieves 40x higher throughput and 10x lower latency for ResNeXt-101 inference using TensorFlow.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Inference_December%202020.jpg?width=2000&amp;name=ResNeXt%20Inference_December%202020.jpg" alt="ResNeXt Inference_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Inference_December%202020.jpg?width=1000&amp;name=ResNeXt%20Inference_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Inference_December%202020.jpg?width=2000&amp;name=ResNeXt%20Inference_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Inference_December%202020.jpg?width=3000&amp;name=ResNeXt%20Inference_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Inference_December%202020.jpg?width=4000&amp;name=ResNeXt%20Inference_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Inference_December%202020.jpg?width=5000&amp;name=ResNeXt%20Inference_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/ResNeXt%20Inference_December%202020.jpg?width=6000&amp;name=ResNeXt%20Inference_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><span><strong>Probabilistic Learning</strong></span><span>&nbsp;</span></p>
<p>Probabilistic models are used in applications where the underlying system is inherently stochastic. They are widely used in the financial sector and as well as in scientific research. However, many varieties of probabilistic models do not fit well with the SIMD/SIMT architecture of GPUs and run far too slowly to be of use. <span>&nbsp;</span></p>
<p><strong>Markov Chain Monte Carlo (MCMC) Training</strong></p>
<p>Using an off-the-shelf TensorFlow Probability (TFP) library to assess the performance of probabilistic models on IPU, we see that a financial MCMC workload trains in less than 3 hours on the IPU-M2000 platform, 17x faster than the 48 hours measured on the latest GPU.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/MCMC%20Training_December%202020.jpg?width=2000&amp;name=MCMC%20Training_December%202020.jpg" alt="MCMC Training_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/MCMC%20Training_December%202020.jpg?width=1000&amp;name=MCMC%20Training_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/MCMC%20Training_December%202020.jpg?width=2000&amp;name=MCMC%20Training_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/MCMC%20Training_December%202020.jpg?width=3000&amp;name=MCMC%20Training_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/MCMC%20Training_December%202020.jpg?width=4000&amp;name=MCMC%20Training_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/MCMC%20Training_December%202020.jpg?width=5000&amp;name=MCMC%20Training_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/MCMC%20Training_December%202020.jpg?width=6000&amp;name=MCMC%20Training_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><strong>Speech Processing</strong><span>&nbsp;</span></p>
<p>Converting written text into speech is a challenging but highly valuable area of speech technology research, with a wide variety of use-cases across most industry verticals.<span>&nbsp;</span></p>
<p>A number of text-to-speech models have risen to prominence, including Tacotron from Google, Deep Voice from Baidu and FastSpeech from Microsoft, enabling high-quality, end-to-end speech synthesis.</p>
<p><strong>Deep Voice 3 Training</strong></p>
<p>Here we focus on the third Deep Voice iteration. The <a href="https://arxiv.org/abs/1710.07654"><span>Deep Voice 3</span></a> model is fully convolutional and uses attention blocks to decode the input text sequence to the output audio sequence representation. More details about our Deep Voice 3 implementation are provided in the <a href="https://www.graphcore.ai/posts/accelerating-text-to-speech-models-with-the-ipu"><span>Accelerating Text-To-Speech models with the IPU</span></a> blog.</p>
<p>The chart below highlights the performance advantage of the IPU-M2000 on the Deep Voice 3 model, with over 13x higher throughput versus the latest GPU.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/Deep%20Voice%203_December%202020.jpg?width=2000&amp;name=Deep%20Voice%203_December%202020.jpg" alt="Deep Voice 3_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/Deep%20Voice%203_December%202020.jpg?width=1000&amp;name=Deep%20Voice%203_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/Deep%20Voice%203_December%202020.jpg?width=2000&amp;name=Deep%20Voice%203_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/Deep%20Voice%203_December%202020.jpg?width=3000&amp;name=Deep%20Voice%203_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/Deep%20Voice%203_December%202020.jpg?width=4000&amp;name=Deep%20Voice%203_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/Deep%20Voice%203_December%202020.jpg?width=5000&amp;name=Deep%20Voice%203_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/Deep%20Voice%203_December%202020.jpg?width=6000&amp;name=Deep%20Voice%203_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><span><strong>Time Series Analysis</strong></span><span>&nbsp;</span></p>
<p>Time series forecasting models can predict future values based on previous, sequential data. LSTM is one of the most widely used time series analysis models. Financial companies in particular rely on LSTMs for modelling and predicting financial data such as stock prices. The use of LSTM-based methods in the finance industry is highlighted in this <a href="https://arxiv.org/pdf/2007.06848.pdf"><span>arxiv paper</span></a>.</p>
<p><strong>LSTM Inference</strong></p>
<p>The chart below compares throughput vs latency across a range of batch sizes for the IPU-M2000 vs the latest GPU for an LSTM 2-Layer Inference model. Across a range of batch sizes the performance advantage is apparent. At the lowest latency achievable by the GPU, the IPU-M2000 is capable of achieving 600x higher throughput at a lower latency.</p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/LSTM%20Inference_December%202020.jpg?width=2000&amp;name=LSTM%20Inference_December%202020.jpg" alt="LSTM Inference_December 2020" width="2000" srcset="https://www.graphcore.ai/hs-fs/hubfs/LSTM%20Inference_December%202020.jpg?width=1000&amp;name=LSTM%20Inference_December%202020.jpg 1000w, https://www.graphcore.ai/hs-fs/hubfs/LSTM%20Inference_December%202020.jpg?width=2000&amp;name=LSTM%20Inference_December%202020.jpg 2000w, https://www.graphcore.ai/hs-fs/hubfs/LSTM%20Inference_December%202020.jpg?width=3000&amp;name=LSTM%20Inference_December%202020.jpg 3000w, https://www.graphcore.ai/hs-fs/hubfs/LSTM%20Inference_December%202020.jpg?width=4000&amp;name=LSTM%20Inference_December%202020.jpg 4000w, https://www.graphcore.ai/hs-fs/hubfs/LSTM%20Inference_December%202020.jpg?width=5000&amp;name=LSTM%20Inference_December%202020.jpg 5000w, https://www.graphcore.ai/hs-fs/hubfs/LSTM%20Inference_December%202020.jpg?width=6000&amp;name=LSTM%20Inference_December%202020.jpg 6000w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p><strong>Future Breakthroughs with the IPU</strong></p>
<p>As we have seen, the IPU delivers state of the art performance on established image processing and language models such as ResNet and BERT.<span>&nbsp;</span></p>
<p>It is also clear that the IPU can deliver huge performance gains in several new or currently under-utilised model types which are indicative of the future trend in machine intelligence, like EfficientNet, ResNeXt and MCMC (Markov Chain Monte Carlo) probability-based methods.</p>
<p>We are also working on some exciting developments with sparse models, and are introducing a preview version of our generalized sparse library support in <a href="https://www.graphcore.ai/posts/introducing-pytorch-for-the-ipu" rel="noopener" target="_blank">Poplar SDK 1.4</a>, which was released today.&nbsp;</p>
<p>Machine intelligence innovation is still in the early stages and we expect to see many new innovations developed over the next few years. The IPU has been designed to help innovators create these new breakthroughs.</p>
<p>Graphcore<a href="https://www.graphcore.ai/products/mk2/ipu-machine-ipu-pod" rel="noopener" target="_blank"> IPU-M2000 and IPU-POD</a> systems are shipping and available to order today through our <a href="https://www.graphcore.ai/partners" rel="noopener" target="_blank">partner network</a>. For more information or to be contacted by one of our AI experts, please register your interest <a href="https://www.graphcore.ai/product_info"><span>here</span></a>.</p>
<p>The products, systems, software, and results are based on configurations existing at the time of the measurements, and as such are subject to change at any time, without notice. For more information regarding methodology or results, please contact us.</p>
</span></p>
				</div>
			</div><div>
    
      
      <div>
        <p><small>¬© Copyright 2020 Graphcore</small>
        </p>
      </div>
</div></div>]]>
            </description>
            <link>https://www.graphcore.ai/posts/graphcore-sets-new-ai-performance-standards-with-mk2-ipu-systems</link>
            <guid isPermaLink="false">hacker-news-small-sites-25356767</guid>
            <pubDate>Wed, 09 Dec 2020 09:17:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AsyncAPI partners with Postman to boost development of Asynchronous APIs]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25356677">thread link</a>) | @derberg
<br/>
December 9, 2020 | https://www.asyncapi.com/blog/asyncapi-partners-with-postman | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/asyncapi-partners-with-postman">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><img src="https://www.asyncapi.com/img/posts/asyncapi-partners-with-postman.png" alt="Post cover image"><p>I'm proud and honored to let you know that we're partnering with <a href="https://www.postman.com/">Postman</a><undefined> to boost the development of Asynchronous APIs to a new level <span role="img" aria-label="rocket">üöÄ</span></undefined></p><p>Since the very beginning, I knew the duty we had at hand was challenging. And still is! The specification was just the trigger of a snowball effect. What's the spec for if you can't do anything with it? Tooling is as important as the specification. However, tooling is a number of times more complex than the specification. We engineers don't want to abandon our favorite programming language and framework, therefore, it's AsyncAPI's responsibility to integrate with the existing tools in the market. <strong>The specification (and tools) should work for the user, not the other way around.</strong> Partnering with Postman allows us to boost the development of more and better tools to help engineers create and maintain Asynchronous APIs while using their favorite programming languages and frameworks.</p><p><strong>Our goal is to make Asynchronous APIs as successful and mature as REST APIs.</strong> We are aware this is a long journey but, with Postman's help, we'll be able to grow the team and continue working on the AsyncAPI specification and all the necessary tools to create a delightful developer experience. The AsyncAPI Initiative team is fully committed to open source software (OSS), and the partnership with Postman will help us keep doing our job with freedom and independence.</p><h2 id="next-steps">Next steps</h2><p>We want to make the AsyncAPI Initiative a neutral and independent place for collaborating on defining the future of Asynchronous APIs. Next step for us is to host the project in a neutral foundation to guarantee the long-term success of the initiative. We're currently in conversations with different actors of the OSS world to make sure the initiative remains independent.</p><p>Also, we want you to work with us. <a href="https://www.asyncapi.com/jobs">We are hiring</a> at Postman to work full-time on AsyncAPI. In the first half of 2021, we'll open a bunch of positions, including Software Engineers, Graphic Designers, Technical Writers, and more. Make sure you don't miss them!</p><div><h3>Receive an email when we publish a new job offer:</h3><p>We respect your inbox. No spam, promise ‚úåÔ∏è</p></div><p>Before I finish, I would love to thank <a href="https://twitter.com/kinlane/">Kin Lane</a> and <a href="https://twitter.com/a85">Abhinav Asthana</a> for being so supportive. And of course, a huge shout out to <a href="https://twitter.com/derberq">≈Åukasz Gornicki</a> and <a href="https://twitter.com/e_morcillo">Eva Morcillo</a> for their tireless support. None of these would be possible without their help.</p><p>There's a bright future ahead for Asynchronous APIs. 2021 will be the year of AsyncAPI, the year of you, our beloved open-source community.</p><p><undefined>Cheers! <span role="img" aria-label="clinking beer mugs">üçª</span></undefined></p></article></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/asyncapi-partners-with-postman</link>
            <guid isPermaLink="false">hacker-news-small-sites-25356677</guid>
            <pubDate>Wed, 09 Dec 2020 08:57:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Validate your parking ‚Äì an introduction to React Hook Form]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25356618">thread link</a>) | @selbekk
<br/>
December 9, 2020 | https://react.christmas/2020/9 | <a href="https://web.archive.org/web/*/https://react.christmas/2020/9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>He couldn't believe it. This certainly couldn't be true. Someone else must have made a mistake here. He read the email a second time. Maybe he missed something and the whole thing was just a big misunderstanding? But he didn't, of course. He is the kind of person who always pays attention to typos, therefore reading it again was quite pointless. Anger started spreading through him. How dare they? It felt so incredibly stupid and unfair. Especially considering he was such a law-abiding citizen. He despised those who didn't follow rules. They couldn't possibly mean that he was one of them? Yet this is exactly what the email was saying: "We can inform you that you unfortunately have used the wrong licence plate in the app, which is why you have been given a fine. In this case the fine is issued on <strong>AB12345</strong>, while parking was activated for <strong>AB1234</strong> in the app.". Filled with rage, he locked his phone and shoved it back into his pocket. He missed one bloody number!</p>
</section><article><section><h2>Validation to the Rescue</h2>
<p>In Norway, license plates for cars follow a certain pattern: they consist of two letters and five digits (there are some exceptions, such as personal license plates). Considering this, we realize that the above scenario could have been avoided merely by adding some form validation! For this, we will utilize <a href="https://react-hook-form.com/">React Hook Form</a>, which has become quite popular over the last year. React Hook Form is easy to use, quite lightweight and very performant. It has built-in validation, but also supports schema-based form validation with other tools such as <a href="https://github.com/jquense/yup">Yup</a>, <a href="https://github.com/ianstormtaylor/superstruct">Superstruct</a> and <a href="https://github.com/sideway/joi">Joi</a>.</p>
<p>Let's assume we have this very basic skeleton for a parking app:</p>
<div data-language="javascript"><pre><code><span>export</span> <span>default</span> <span>function</span> <span>App</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>onFormSubmit</span> <span>=</span> <span>(</span><span>e</span><span>)</span> <span>=&gt;</span> e<span>.</span><span>preventDefault</span><span>(</span><span>)</span><span>;</span>

  <span>return</span> <span>(</span>
    <span>&lt;</span><span>&gt;</span>
      <span>&lt;</span>h1<span>&gt;</span>Parking App<span>&lt;</span><span>/</span>h1<span>&gt;</span>
      <span>&lt;</span>form onSubmit<span>=</span><span>{</span>onFormSubmit<span>}</span><span>&gt;</span>
        <span>&lt;</span>label<span>&gt;</span>License number<span>&lt;</span><span>/</span>label<span>&gt;</span>
        <span>&lt;</span>input name<span>=</span><span>"licenseNo"</span> placeholder<span>=</span><span>"AA11111"</span> <span>/</span><span>&gt;</span>
        <span>&lt;</span>button<span>&gt;</span>Start parking<span>&lt;</span><span>/</span>button<span>&gt;</span>
      <span>&lt;</span><span>/</span>form<span>&gt;</span>
    <span>&lt;</span><span>/</span><span>&gt;</span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>The app contains a form with a text input and a button. We also added an <code>onSubmit</code> method that prevents the form from being submitted and the page from being refreshed. Apart from that, the app doesn't really do anything meaningful. Let's add some validation:</p>
<div data-language="javascript"><pre><code><span>export</span> <span>default</span> <span>function</span> <span>App</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>{</span> handleSubmit<span>,</span> register <span>}</span> <span>=</span> <span>useForm</span><span>(</span><span>)</span><span>;</span>

  <span>const</span> <span>onFormSubmit</span> <span>=</span> <span>(</span><span>data</span><span>)</span> <span>=&gt;</span> console<span>.</span><span>log</span><span>(</span>data<span>)</span><span>;</span>

  <span>return</span> <span>(</span>
    <span>&lt;</span><span>&gt;</span>
      <span>&lt;</span>h1<span>&gt;</span>Parking App<span>&lt;</span><span>/</span>h1<span>&gt;</span>
      <span>&lt;</span>form onSubmit<span>=</span><span>{</span><span>handleSubmit</span><span>(</span>onFormSubmit<span>)</span><span>}</span><span>&gt;</span>
        <span>&lt;</span>label<span>&gt;</span>License number<span>&lt;</span><span>/</span>label<span>&gt;</span>
        <span>&lt;</span>input name<span>=</span><span>"licenseNo"</span> placeholder<span>=</span><span>"AA11111"</span> ref<span>=</span><span>{</span>register<span>}</span> <span>/</span><span>&gt;</span>
        <span>&lt;</span>button<span>&gt;</span>Start parking<span>&lt;</span><span>/</span>button<span>&gt;</span>
      <span>&lt;</span><span>/</span>form<span>&gt;</span>
    <span>&lt;</span><span>/</span><span>&gt;</span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>As you can see, we don't need to add much code to set up React Hook Form. We have to call the <code>useForm</code> hook which returns a bunch of methods. For the time being, we simply use <code>handleSubmit</code> and <code>register</code>. We then wrap the <code>onFormSubmit</code> method into the <code>handleSubmit</code> method. This will take care of only invoking <code>onFormSubmit</code> and pass the form data when all fields are valid (it also prevents the form from submitting, so we don't need to explicitly call the <code>preventDefault</code> method). Finally, we need to set the <code>register</code> method as the input field's ref attribute. But this is not the end of the story! The form allows any input, even if it is left empty. This is why we have to specify some validation rules:</p>
<div data-language="javascript"><pre><code><span>&lt;</span>input 
  name<span>=</span><span>"licenseNo"</span> 
  placeholder<span>=</span><span>"AA11111"</span> 
  ref<span>=</span><span>{</span><span>register</span><span>(</span><span>{</span>
    required<span>:</span> <span>"You must enter a license number."</span><span>,</span>
    pattern<span>:</span> <span>{</span>
      value<span>:</span> <span>/^[a-z]{2}\d{5}$/i</span><span>,</span>
      message<span>:</span> <span>"The license number must be a combination of two letters and five digits."</span>
    <span>}</span>
  <span>}</span><span>)</span><span>}</span>
<span>/</span><span>&gt;</span></code></pre></div>
<p>When registering the input field, we can add several options to adjust how the field should be validated. In the above example, we tell our form that the field is required and that the value must match a specific regex pattern. We also define some error messages. If we try to submit the form, but validation fails, the error message is returned by <code>useForm</code> as an object called <code>errors</code>. Every form field gets its own error message corresponding to the field's <code>name</code> attribute:</p>
<div data-language="javascript"><pre><code><span>{</span>errors<span>.</span>licenseNo <span>&amp;&amp;</span> errors<span>.</span>licenseNo<span>.</span>message<span>}</span></code></pre></div>
<p>Alternatively, we can use a simple component, <code>ErrorMessage</code> (we must first install a separate NPM package):</p>
<div data-language="javascript"><pre><code><span>&lt;</span>ErrorMessage
  errors<span>=</span><span>{</span>errors<span>}</span>
  name<span>=</span><span>"licenseNo"</span>
<span>/</span><span>&gt;</span></code></pre></div>
<p>This is all we need to avoid registering an invalid license number! However, there are some more concepts we should have a look at.</p>
<h2>Controlled vs. Uncontrolled</h2>
<p>React Hook Form is designed to work best with <em>uncontrolled components</em>. This means that form data is handled by the DOM itself and can be accessed directly using refs (which is why we put the <code>register</code> method there). <em>Controlled components</em> on the other hand, use event handlers such as <code>onChange</code> to update values at state change. Many third-party libraries use controlled components, and luckily there is a way we can use those together with React Hook Form:</p>
<div data-language="javascript"><pre><code><span>&lt;</span>Controller
  <span>as</span><span>=</span><span>{</span>ReactSelect<span>}</span>
  name<span>=</span><span>"fuelType"</span>
  rules<span>=</span><span>{</span><span>{</span> required<span>:</span> <span>"You must select a fuel type."</span> <span>}</span><span>}</span>
  options<span>=</span><span>{</span><span>[</span>
    <span>{</span> value<span>:</span> <span>"electric"</span><span>,</span> label<span>:</span> <span>"Electric"</span> <span>}</span><span>,</span>
    <span>{</span> value<span>:</span> <span>"petrol"</span><span>,</span> label<span>:</span> <span>"Petrol"</span> <span>}</span><span>,</span>
    <span>{</span> value<span>:</span> <span>"diesel"</span><span>,</span> label<span>:</span> <span>"Diesel"</span> <span>}</span>
  <span>]</span><span>}</span>
  isClearable
<span>/</span><span>&gt;</span></code></pre></div>
<p>We add a <a href="https://github.com/JedWatson/react-select">React Select</a> for choosing the cars fuel type by wrapping it inside a <code>Controller</code> component using the <code>as</code> prop. The Controller automatically injects the <code>onChange</code>, <code>onBlur</code> and <code>value</code> props into the wrapped component. The same applies to other props that may be required by the underlying component (in this case the props <code>options</code> and <code>isClearable</code>). Validation rules are applied by setting the <code>rules</code> prop. Although this is the preferred syntax, you sometimes need to use the <code>render</code> prop instead of the <code>as</code> prop, which lets you customize events, value and ref:</p>
<div data-language="javascript"><pre><code><span>&lt;</span>Controller
  name<span>=</span><span>"fuelType"</span>
  rules<span>=</span><span>{</span><span>{</span> required<span>:</span> <span>"You must select a fuel type."</span> <span>}</span><span>}</span>
  render<span>=</span><span>{</span><span>(</span><span><span>{</span> onChange<span>,</span> onBlur<span>,</span> value<span>,</span> ref <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span>
    <span>&lt;</span>ReactSelect
      options<span>=</span><span>{</span><span>[</span>
        <span>{</span> value<span>:</span> <span>"electric"</span><span>,</span> label<span>:</span> <span>"Electric"</span> <span>}</span><span>,</span>
        <span>{</span> value<span>:</span> <span>"petrol"</span><span>,</span> label<span>:</span> <span>"Petrol"</span> <span>}</span><span>,</span>
        <span>{</span> value<span>:</span> <span>"diesel"</span><span>,</span> label<span>:</span> <span>"Diesel"</span> <span>}</span>
      <span>]</span><span>}</span>
      onChange<span>=</span><span>{</span>onChange<span>}</span>
      onBlur<span>=</span><span>{</span>onBlur<span>}</span>
      inputValue<span>=</span><span>{</span>value<span>?.</span>key<span>}</span>
      inputRef<span>=</span><span>{</span>ref<span>}</span>
    <span>/</span><span>&gt;</span>
  <span>)</span><span>}</span>
<span>/</span><span>&gt;</span></code></pre></div>
<h2>Form Context</h2>
<p>When moving input fields to shared components in order to make them reusable, you can of course pass all neccessary methods from <code>useForm</code> as props. In many cases, it would be a more elegant solution to put the whole form into a <code>FormProvider</code> and access the context of the form with <code>useformContext</code>:</p>
<div data-language="javascript"><pre><code><span>const</span> methods <span>=</span> <span>useForm</span><span>(</span><span>)</span><span>;</span>

<span>return</span> <span>(</span>
    <span>&lt;</span>FormProvider <span>{</span><span>...</span>methods<span>}</span><span>&gt;</span>
      <span>&lt;</span>form onSubmit<span>=</span><span>{</span>methods<span>.</span><span>handleSubmit</span><span>(</span>onSubmit<span>)</span><span>}</span><span>&gt;</span>
        <span>&lt;</span>LicenseNoInput <span>/</span><span>&gt;</span>
        <span>&lt;</span>button<span>&gt;</span>Start parking<span>&lt;</span><span>/</span>button<span>&gt;</span>
      <span>&lt;</span><span>/</span>form<span>&gt;</span>
    <span>&lt;</span><span>/</span>FormProvider<span>&gt;</span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>The <code>LicenseNoInput</code> component can then access the form methods as simple as this:</p>
<div data-language="javascript"><pre><code><span>const</span> <span>{</span> errors<span>,</span> register <span>}</span> <span>=</span> <span>useFormContext</span><span>(</span><span>)</span><span>;</span></code></pre></div>
<p>Let's pack it all up, add a little more logic and styling and voil√† ‚Äì we have a parking app with form validation that actually works!</p>

<h2>Like a Swiss Army Knife</h2>
<p>There is so much more you can do with React Hook Form! It's too bad I can't cover it all in a single article. I can recommend a look at the <a href="https://react-hook-form.com/api/">official documentation</a>, which also provides many useful examples. Personally, I have been using this tool for about a year now and have never been in a situation where it couldn't solve a problem. If you are still not convinced, the fact that TypeScript is fully supported will hopefully change your mind.</p></section></article></div>]]>
            </description>
            <link>https://react.christmas/2020/9</link>
            <guid isPermaLink="false">hacker-news-small-sites-25356618</guid>
            <pubDate>Wed, 09 Dec 2020 08:44:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Progress Over Perfection]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25356266">thread link</a>) | @phughes1980
<br/>
December 8, 2020 | https://www.thedailymba.com/2020/12/08/my-new-side-hustle-mantra-progress-over-perfection/ | <a href="https://web.archive.org/web/*/https://www.thedailymba.com/2020/12/08/my-new-side-hustle-mantra-progress-over-perfection/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main><article aria-label="My New Side Hustle Mantra: Progress Over Perfection"><div><figure><img loading="lazy" width="1880" height="1249" src="https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?resize=1880%2C1249&amp;ssl=1" alt="traffic red blue sign" srcset="https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?w=1880&amp;ssl=1 1880w, https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?resize=300%2C199&amp;ssl=1 300w, https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?resize=1024%2C680&amp;ssl=1 1024w, https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?resize=768%2C510&amp;ssl=1 768w, https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?resize=1536%2C1020&amp;ssl=1 1536w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"><figcaption>Photo by Mabel Amber on <a href="https://www.pexels.com/photo/traffic-red-blue-sign-117602/" rel="nofollow">Pexels.com</a></figcaption></figure><p>A Guest Post by Phil Hughes</p><p>‚ÄúProgress over perfection‚Äù. I‚Äôve written this on the whiteboard next to my standing desk in the home office/guitar studio/mancave/junk room.&nbsp;</p><p>I heard this statement earlier on in the year. Must have been around May or June, it instantly struck a chord with me.</p><p>Working full time and trying to get no less than 3 side hustles and a podcast off the ground is a big ask.&nbsp;</p><p>I have used the progress over perfection mantra before. It was worded slightly differently; I can‚Äôt remember the exact statement.</p><p>However, I hadn‚Äôt fully embraced the concept.&nbsp;</p><p>When it came to my core skill of software development, I could easily apply this principle.&nbsp;</p><p>Every other part of the side hustle lifestyle was still ‚ÄúI got to make sure this is the best it can be‚Äù.</p><h2 id="h-already-integrated-into-my-9-5"><span id="Already_Integrated_into_My_95"></span>Already Integrated into My 9-5<span></span></h2><p>Like I‚Äôve just touched on. I‚Äôve used progress over perfection, day to day with my software development ‚Äòhat‚Äô on.</p><p>I‚Äôm going to sound arrogant now. Having spent 14+ years developing software, I‚Äôm confident in my skills and the fact I can get stuff done and out the door, quicker than a lot of my ‚Äúdevelopment‚Äù peers.</p><p>By using this principle, I can get the feature ‚ÄòX‚Äô out to the world. Start feature ‚ÄòY‚Äô and deliver that in rapid time. Same too with Feature ‚ÄòZ‚Äô</p><p>Then go back to feature ‚ÄòX‚Äô and make it better. Progress over perfection in action.</p><h3 id="h-progress-over-perfection-a-real-world-app-example"><span id="Progress_Over_Perfection_%E2%80%93_A_Real_World_App_Example"></span>Progress Over Perfection ‚Äì A Real World App Example<span></span></h3><p>I‚Äôm writing this post towards the end of 2020, having gone through the Coronavirus pandemic.</p><p>At the start of lockdown, I had more spare time and I came up with a <a href="https://baitcamp.net/">mobile app idea for a hobby of mine, fishing</a>.&nbsp;</p><p>After doing a bit of product validation and finding out what other fishermen would like to see in the app. I sketched out the features I was going to include in version 1 of the app.</p><p>One of the features was to allow the user to upload photos to the app, linking them to a fishing trip.</p><p>Having never done anything like this before, it was a learning curve, to say the least. I decided to use the ‚Äúprogress over perfection‚Äù mantra by making sure the uploading, editing, removing, and retrieving of the photos, from a functionality point of view, was ‚Äúperfect‚Äù</p><p>However, the way the user uploaded the photos and then viewing them was shocking, ‚Äúperfect‚Äù was just a dot on the horizon.&nbsp;</p><p>That said, I went with it as I wanted to get the app published on both the <a href="https://apps.apple.com/us/app/id1519992229">Apple App Store</a> and <a href="https://play.google.com/store/apps/details?id=uk.co.phhdigital.baitcamp">Google Play</a> as quickly as possible.&nbsp;</p><p>5 months after the initial idea came to me, I had published the app on both platforms. WAHOO!</p><p>After feedback from people testing version 1. And the fact I wasn‚Äôt happy with the photo upload/viewing features. I have been able to start work on version 1.1 to sort this problem out.</p><p>Another day or two and I will have a slick way of managing the photos. Be able to release an update very quickly. As well as ironing out a few bugs that have come to light.</p><p>I genuinely believe if I had kept on working on the app until I was entirely happy with the photo functionality, I wouldn‚Äôt have it published or have people downloading the app and using it.</p><p>The key here was ‚Äúprogress over perfection‚Äù to get something live that was usable, then go from there.</p><h2 id="h-side-hustling-and-what-you-need-to-learn"><span id="Side_Hustling_and_What_You_Need_To_Learn"></span>Side Hustling and What You Need To Learn<span></span></h2><p>When it comes to other aspects of side hustling, I‚Äôm still ‚Äúnewborn‚Äù in a lot of the skills you need.&nbsp;</p><p>Writing blog posts, writing social media posts, copywriting, creating nice-looking webpages, building sales funnels, creating ads, shooting walkthroughs for YouTube, recording video sales letters, editing videos, coming up with offers, researching, scheming and plotting, creating eBooks, creating eBook covers, creating eBook mock-ups, recording podcasts, editing podcasts.</p><p>How did I come up with that list of things to do? I looked at my planner at what tasks I wanted to achieve over the last 2 weeks.&nbsp;</p><p>That‚Äôs on top of coding 3 software products by myself. Working 8-4 Monday through Thursday. And, having a life, like spending time with my wife, playing guitar, and going fishing.</p><p>It can be very overwhelming.&nbsp;</p><p>You see how great other people are at all these other things and want your stuff to be as ‚Äúperfect‚Äù as theirs</p><p>That‚Äôs why this new mantra has been a bit of a breakthrough for me.</p><h2 id="h-progress-over-perfection-and-switching-your-mindset"><span id="Progress_Over_Perfection_and_Switching_Your_Mindset"></span>Progress Over Perfection and Switching Your Mindset<span></span></h2><p>As I‚Äôve touched upon. For certain aspects of my day to day I would apply ‚Äúprogress over perfection‚Äù. Not all aspects though.</p><p>Hearing this really got me thinking about what I wanted to achieve.&nbsp;</p><p>One thing it also did was remove some fear I had around things.&nbsp;</p><p>For example, I had started digging deep into the concept of creating online sales funnels to promote my products and reach my ‚Äúgolden goose‚Äù of 350 paying customers.</p><p>My dream is to work for myself running a software product. After a bit of number crunching, I worked out I would need 350 monthly subscribers for me to realize my dream.&nbsp;</p><p>Sales funnels could help me achieve this.</p><h3 id="h-sales-funnel-progress-over-perfection"><span id="Sales_Funnel_Progress_Over_Perfection"></span>Sales Funnel Progress Over Perfection<span></span></h3><p>This is where the fear kicked in. I was worried that I would create a sales funnel, it would completely bomb, and I would feel like a failure.&nbsp;</p><p>I wanted my sales funnels to be successful as soon as I start driving traffic to it. If this were a software product, I wouldn‚Äôt think like that. I know they will be some bugs and users would probably want something different than what I had built.</p><p>After consuming a lot of content around the sales funnel process and how even the most experienced ‚Äúfunnel hackers‚Äù can‚Äôt get their funnel to work out of the gate.&nbsp;</p><p>I decided that I just need to get it out there and see what ‚Äúfeedback‚Äù I get.</p><p>So, I continued to put it together as best I could, giving myself a time constraint that it must be done by the end of that week. Then the week after I could drive some paid traffic to it.</p><p>I got the opt-in page up and running, where someone could submit their details and in return get a free eBook user guide.</p><p>Next, I spent most of my time working on the sales page and putting together an offer and pricing.&nbsp;</p><p>Thirdly, I added a ‚ÄúOne Time Offer‚Äù that the person would be shown if they subscribed to the product I was promoting on the sales page.</p><p>Finally, I put together an email sequence that would be sent to anyone who opted in for the free eBook, as a follow up to get them to revisit my funnel.</p><p>The next week I created a Facebook ad campaign and got loads of people into the funnel. Guess how many sales I made?</p><p>ZERO.</p><h3 id="h-analyzing-the-results"><span id="Analyzing_the_Results"></span>Analyzing the Results<span></span></h3><p>Sounds terrible right? It was, but I wasn‚Äôt downhearted.&nbsp;</p><p>Looking into the stats, the opt-in page was working. I was getting almost 45% of the visitors to put in their email address and request a copy of the eBook.</p><p>Yes, no one bought from me. I knew that part of my sales funnel did work. However, I was building an email list of people that I could keep in contact with, which I hadn‚Äôt be able to do before.</p><p>‚ÄúProgress over perfection‚Äù.</p><p>I ended up scrapping this funnel as I still didn‚Äôt ‚Äòconvert‚Äô after a few attempts at rewriting parts of the sales page.</p><p>Taking the learnings from the opt-in success, I created a brand-new funnel. This targeted a different group of people. Again, this funnel wasn‚Äôt the success I wanted. My opt-in rate was still high, 35% and I got my first ever paying customer.</p><p>Someone signed up and subscribed to <a href="https://outflash.xyz/">my software product called Outflash</a>. They even took my up one-time offer.</p><p>I was blown away. Yes, it wasn‚Äôt the riches you pray for, but I had made progress on this skill.</p><p>Progress! Progress towards what I deem successful.</p><h2 id="h-podcasting-and-getting-yourself-out-there"><span id="Podcasting_and_Getting_Yourself_Out_There"></span>Podcasting and Getting Yourself Out There<span></span></h2><p>A problem with being a developer, is you think it will be like the movie Field of Dreams. ‚ÄúBuild it and they will come‚Äù. With a software product, this NEVER happens.</p><p>Someone said if you want to get yourself out there to promote your products and services. Use a platform or media that you enjoy yourself. For me this was podcasting.</p><p>I‚Äôm an avid podcast listener. Whether it be working out, going for a run, listening while coding. I even put a podcast on while cooking a Sunday Dinner.</p><p>Starting a podcast can be scary though. What do I talk about? Do I have enough content to get past the first 10 episodes? How do I even publish a podcast? Which platforms do I publish to?</p><h3 id="h-excuses-excuses-just-do-it"><span id="Excuses,_Excuses,_Just_Do_It"></span>Excuses, Excuses, Just Do It<span></span></h3><p>Having mild success with the sales funnels gave me a lot of belief in the saying ‚ÄúJust Do It‚Äù.</p><p>One of the podcasts I listen to is by two guys that have launched their own podcasting hosting and publishing platform. I know, a bit Inception right!</p><p>So, I decided to use their platform to publish and host <a href="https://www.philliphughes.co.uk/podcast/">my podcast</a>. Which platforms to publish to? Their service had guides on how to publish to <a href="https://podcasts.apple.com/gb/podcast/find-your-side-hustle/id1523991465">Apple</a> and <a href="https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy50cmFuc2lzdG9yLmZtL2ZpbmQteW91ci1zaWRlLWh1c3RsZQ?sa=X&amp;ved=0CBUQ27cFahcKEwiIrMe2-eLqAhUAAAAAHQAAAAAQAQ">Google podcasts</a>, <a href="https://open.spotify.com/show/19pwsqTl75RSGrhhrsFIWW">Spotify</a>, and <a href="https://www.stitcher.com/podcast/find-your-side-hustle">Stitcher</a>. I didn‚Äôt overthink it, I registered with those 4 providers first and thought, ‚Äúprogress over perfection‚Äù, I can publish to more platforms later.</p><p>People also think they need a mass of equipment to record and edit a podcast. I was on a roll; nothing was stopping me from getting my first episode out to the world.&nbsp;</p><p>Quickly opening Amazon and searching for ‚Äúcheap podcast mic‚Äù. I bought the 3<sup>rd</sup> one I saw for ¬£20, with Amazon Prime it was delivered the next day.</p><p>In another quick search for ‚Äúfree podcast editing software,‚Äù I found a piece of software that I could do basic audio editing with, like snipping or increasing the volume.&nbsp;</p><h3 id="h-other-people-skills-to-progress-over-perfection"><span id="Other_People_Skills_To_Progress_Over_Perfection"></span>Other People Skills To Progress Over Perfection<span></span></h3><p>The last two pieces of the podcasting puzzle were that I needed a logo/header for the podcast that will be unique to me and my chosen topic.</p><p>I have used Fiverr in the past and thought it would be a good place to find someone to do it for me, quickly.&nbsp;</p><p>If I didn‚Äôt like it, I could always change it a few months down the line. I found someone who had a decent portfolio of similar work, that wasn‚Äôt too pricy. I put the order in, with a description of what I was looking for, and forgot about it for the rest of the evening.</p><p>While the logo was being designed, I needed to get together a list of episode ideas so I could record a least a handful to get me started.</p><p>This time I turned to Evernote, created ‚Ä¶</p></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thedailymba.com/2020/12/08/my-new-side-hustle-mantra-progress-over-perfection/">https://www.thedailymba.com/2020/12/08/my-new-side-hustle-mantra-progress-over-perfection/</a></em></p>]]>
            </description>
            <link>https://www.thedailymba.com/2020/12/08/my-new-side-hustle-mantra-progress-over-perfection/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25356266</guid>
            <pubDate>Wed, 09 Dec 2020 07:38:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Useful Notifications in iTerm2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25355688">thread link</a>) | @CGamesPlay
<br/>
December 8, 2020 | https://cgamesplay.com/post/2020/12/09/iterm-notifications/ | <a href="https://web.archive.org/web/*/https://cgamesplay.com/post/2020/12/09/iterm-notifications/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>For some reason, I've found that in my career a lot of the work I do ends up involving slow REPL loops: I make a change, run a command, wait for it to finish, and repeat. While I'm sitting there waiting, it's easy to be distracted by things, and I want my task to bring itself back to my attention when it's ready. This desire has led me on a multi-year quest to tailor my notifications perfectly, and in this post I'm going to share what I've come up with.</p>
<p>Here are the features I want my notifications to have:</p>
<ul>
<li>I should be able to activate them from anywhere in the terminal: in bash, from the ruby console, over SSH, or anywhere else I find myself (in the terminal).</li>
<li>They should be subtle so they don't get too annoying, but noticeable enough that I don't miss them.</li>
<li>The should only fire when I want them: too many notifications will cause me to ignore all of them.</li>
</ul>
<h2>The early days</h2>
<p>Back in 2015 or so, my company was writing scrapers to extract detailed, structured information from hundreds of websites. Each website was different and since we needed the information to be structured, we had to write a different scraper for each one. A single site could be scraped in about 5 minutes, and the data only changed a few times each year. Still, the sites would change often enough that I frequently found myself sitting in the office until late at night, mostly waiting for these scrapers to break so I could make one small fix, and repeat. Five minutes for each change really adds up when you have to repeat the entire scraper to test a single-line change.</p>
<p>Fortunately, writing scrapers is pretty easy technically, so I didn't need to be 100% focused as I was working on them. That meant that while I was waiting on the latest change I'd made to a scraper, I was able to focus on other high-value activities like shooting for a high score in Peggle Nights.</p>
<p><img src="https://cgamesplay.com/media/20201201-1309-peggle-small.jpg" alt="Screenshot of Peggle Nights"></p>
<p>But sometimes, when I was planning a tough shot on a high-scoring round, I could forget that I was still at the office waiting for my scraper to crash so I could fix it. That's why I wanted a simple way to get notified when it was waiting for me. My first-ever attempt at building a notifications system used a feature built-in to Mac OS: the <code>say</code> command.</p>
<pre><code>long_running_command<span>;</span> say <span>"done"</span>
</code></pre>
<p>This command uses the system's text-to-speech to play through your computer speakers. The scrapers I was writing were mostly in Ruby, so if I were in IRB I could still get the notification:</p>
<pre><code>my_scraper<span>.</span>run_main <span>rescue</span> ex <span>=</span> $<span>!</span><span>;</span> `say done`
</code></pre>
<p>This will play the notification even if the scraper fails, and preserve the raised exception in the <code>ex</code> variable. Neat!</p>
<p>I used this solution for a few months, but I always felt that the text-to-speech was a little unpleasant. I decided to switch out the <code>say</code> command for the built-in audio file player, <code>afplay</code>, and I used one of the default sounds that comes with Mac OS.</p>
<pre><code><span>function</span> <span>ding</span> <span>{</span>
  afplay /System/Library/Sounds/Glass.aiff
<span>}</span>
long_running_command<span>;</span> ding
</code></pre>
<p>That makes this sound, which is a little more subtle than a robotic voice shouting at me.</p>
<p><audio controls="" src="https://cgamesplay.com/media/20201125-1600-iterm-sounds-glass.aiff"><a href="https://cgamesplay.com/media/20201125-1600-iterm-sounds-glass.aiff">Click to download</a></audio></p>
<p>These two tricks got me along just fine for years. I felt like I had solved the problem and didn't need to think about it any more. Well, except when I started a command that I thought would be fast but it instead took an hour to run. But I developed a trick for that: if you press <code>^Z</code> (Ctrl-Z) to pause the job, then you can use <code>fg; ding</code> to resume it  and ding when it finishes. There. Now it's perfect.</p>
<h2>Improving on perfection</h2>
<p>One day I learned about <a href="https://iterm2.com/documentation-shell-integration.html" target="_blank" rel="noopener">iTerm2 shell integration</a>. This provides a bunch of neat features, and one of them is about notifications! It's not very well documented, but if you use Edit ‚ñ∫ Marks and Annotations ‚ñ∫ Alerts ‚ñ∫ Alert on Next Mark, or the much-easier-to-remember Option-Command-A, you'll get a native notification when the currently running command finishes. I installed the shell integration and to this day I use this feature more than anything else that it provides.</p>
<p>Fast forward to 2020 and I've changed roles again. This time, I find myself automating cloud server provisioners, and waiting for the machines to come up isn't fast. Sadly, the iTerm shell integration has to be installed on each server, and my perfect notification scripts don't work over SSH. Realizing that perfection is a journey and not a destination, I set out to improve my notifications once again. Except this time, I was going to go industrial-strength.</p>
<p>When I was learning about the iTerm2 shell integration, I also found out about <a href="https://cgamesplay.com/post/2020/11/25/iterm-plugins/">a bunch of other features that iTerm2 supports</a>. If you want to follow along with me, read over that post and install <code>PlaySound.py</code>, <code>iterm_notify</code>, <code>iterm_badge</code>, and <code>iterm_bounce</code> on your computer. These new features had already made my notifications more powerful and SSH-compatible, but I had set my sights beyond a simple "ding!" sound. I wanted a smart notification system that would "ding" when the command completed, but "bonk" when it failed. But first I needed to find the right sounds to use.</p>
<p><img src="https://cgamesplay.com/media/20201201-1344-oot-navi.jpg" alt="The Legend of Zelda: Ocarina of Time"></p>
<p>The first sound that came to mind was the iconic "Hey! Listen!" from Ocarina of Time. If you played this game, then you probably know exactly how that sounds. I found a gallery of <a href="http://noproblo.dayjo.org/ZeldaSounds/" target="_blank" rel="noopener">sounds from the Zelda games</a> and searched for some appropriate ones. Eventually I settled on these two, for my "good" and "bad" sounds:</p>
<p><audio controls="" src="https://cgamesplay.com/media/20201201-1347-ootpressstart.wav"><a href="https://cgamesplay.com/media/20201201-1347-ootpressstart.wav">Click to download</a></audio></p>
<p><audio controls="" src="https://cgamesplay.com/media/20201201-1349-mmtatlalarm.wav"><a href="https://cgamesplay.com/media/20201201-1349-mmtatlalarm.wav">Click to download</a></audio></p>
<p>The first thing to do is wrap them up in scripts to make them easy to use. I put them in my sound library (which is listing in <a href="https://github.com/CGamesPlay/dotfiles/blob/bee7d071a7b85f7becc696edc0b328677eb16c40/macos/Library/Application%20Support/iTerm2/Scripts/AutoLaunch/PlaySound.py" target="_blank" rel="noopener">PlaySound.py</a>) and wrote these:</p>
<pre><code><span>function</span> <span>ding</span> <span>{</span>
    iterm_sound OOT_PressStart
<span>}</span>

<span>function</span> <span>bonk</span> <span>{</span>
    iterm_sound MM_Tatl_Alarm.wav
<span>}</span>
</code></pre>
<p>Now I can run my provisioning script like this:</p>
<pre><code>./provision.sh <span>&amp;&amp;</span> ding <span>||</span> bonk
</code></pre>
<p>If the script succeeds, the <code>&amp;&amp; ding</code> will run, resulting in a pleasant chime. Otherwise the <code>|| bonk</code> sound will run and I'll hear a nervous fairy. But I can do better! This is too much to type, and I want to leverage all of my notification channels, not just sound. So I wrote this function:</p>
<pre><code><span>function</span> <span>sound_status</span> <span>{</span>
    <span>local</span> <span>last_status</span><span>=</span><span>$?</span>
    <span>test</span> <span>$last_status</span> -eq <span>0</span> <span>&amp;&amp;</span> ding <span>||</span> bonk
    iterm_bounce
    <span>if</span> <span>test</span> -z <span>"<span>$@</span>"</span><span>;</span> <span>then</span>
        iterm_notify <span>"Command finished with status <span>$last_status</span>"</span>
    <span>else</span>
        iterm_notify <span>"<span>$@</span> finished with status <span>$last_status</span>"</span>
    <span>fi</span>
    <span>return</span> <span>$last_status</span>
<span>}</span>
</code></pre>
<p>This function has 3 important qualities:</p>
<ol>
<li>It automatically chooses the sound to play.</li>
<li>It also shows a system notification, with an optional custom message.</li>
<li>It passes on the exit code, so you can run it in a pipeline.</li>
</ol>
<p>For example, I can use it like this:</p>
<pre><code>./provision.sh<span>;</span> sound_status <span>"provision.sh"</span> <span>&amp;&amp;</span> <span>ssh</span> myhost
</code></pre>
<p>Because it passes on the exit status, the <code>&amp;&amp; ssh</code> will only happen when the command succeeds, just like if the <code>; sound_status</code> hadn't been there at all.</p>
<h2>The little things in life</h2>
<p>This notification script feels great: simple, only when requested, and with just a bit of "fun" flavor. But there is another area where I think that a subtle audio cue would help streamline my workflow. Sometimes I need to type 3 or 4 quick commands back-to-back. Has this ever happened to you?</p>
<pre><code>$ <span>git</span> commit -m <span>"respond to feedback"</span>
no changes added to commit <span>(</span>use <span>"git add"</span> and/or <span>"git commit -a"</span><span>)</span>
$ <span>git</span> push
Everything up-to-date
</code></pre>
<p>I run these commands, see that it succeeded, shut my laptop, and head out to lunch. Later that day I wonder why nobody has reviewed my code, only to find that the second command had failed because I never staged those files, so I never pushed any changes at all. If I had been more careful, this wouldn't have happened. As a substitute for being more careful, I can have the computer tell me when my commands fail!</p>
<p>When I want is a subtle ping to tell me that something bad happened, every time a command fails. A lot of times this notification will be unnecessary. For example, if  <code>make</code> fails with a compile error, I don't really need a sound to tell me about that. So I wanted a "negative" sound that wasn't too distracting. I eventually settled on this one.</p>
<p><audio controls="" src="https://cgamesplay.com/media/20201201-1409-alert-destroyed.wav"><a href="https://cgamesplay.com/media/20201201-1409-alert-destroyed.wav">Click to download</a></audio></p>
<p>Can you recognize it? It's a sound you'll have heard pretty often if you've ever played Factorio: the notification that a building you own has been destroyed. In the game, you'll often hear this sound altering you of an attack while you're working on some other task. Generally, it indicates a problem, but not necessarily an urgent one. I thought it would be perfect. Since I'm a user of <a href="https://fishshell.com/" target="_blank" rel="noopener">Fish shell</a>, I rigged up the notification like this:</p>
<pre><code>
<span>if</span> <span>test</span> -z <span>$beep_command</span>
  <span>set</span> beep_command <span>"printf <span title="\a">\a</span>"</span>
end
<span>set</span> beep_primed <span>""</span>
<span>function</span> beep_preexec --on-event fish_preexec
  <span>set</span> -g beep_primed <span>1</span>
end
<span>function</span> beep_postexec --on-event fish_postexec
  <span>set</span> -l last_status <span>$status</span>
  <span>if</span> <span>test</span> <span>!</span> -z <span>$beep_primed</span> -a <span>!</span> -z <span>$argv</span><span>[</span><span>1</span><span>]</span> -a <span>$last_status</span> -ne <span>0</span>
    <span>eval</span> <span>$beep_command</span>
  end
  <span>set</span> -g beep_primed <span>""</span>
end
</code></pre>
<p>There's a few things worth mentioning here:</p>
<ul>
<li>To set the beep command, I used <code>set -U beep_command "iterm_sound Factorio/alert-destroyed.wav"</code>. This sets a "<a href="https://fishshell.com/docs/current/#variable-scope" target="_blank" rel="noopener">universal variable</a>" in fish, so it's permanent and system-wide. This lets me change the sound easily whenever I want.</li>
<li>The <code>fish_postexec</code> command runs even if you didn't run a command (pressed enter at an empty prompt), so we use the <code>-z $argv[1]</code> to filter that out.</li>
<li>The <code>beep_primed</code> variable is needed to ensure that the sound only happens once when the command fails. This is necessary to avoid some awkward situations that come up when you press Ctrl-C to cancel a command.</li>
</ul>
<p>So that's where I am today. I am very happy with how my notifications work and I'm glad I was able to add a unique bit of flavor to them by sampling from some nostalgic video games. Thanks for reading! If you want to set up something like this and are having problems, feel free to <a href="https://cgamesplay.com/contact">reach out to me</a>.</p></div></div>]]>
            </description>
            <link>https://cgamesplay.com/post/2020/12/09/iterm-notifications/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25355688</guid>
            <pubDate>Wed, 09 Dec 2020 05:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transcending the Visual Appearance of a Paper]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25355291">thread link</a>) | @harporoeder
<br/>
December 8, 2020 | https://cr.yp.to/writing/visual.html | <a href="https://web.archive.org/web/*/https://cr.yp.to/writing/visual.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<a href="https://cr.yp.to/djb.html">D. J. Bernstein</a>
<br><a href="https://cr.yp.to/writing.html">Notes on writing papers</a>

Here's a quote from the paper "Document Production: Visual or Logical?"
in Notices of the American Mathematical Society (June 1987), pages 621-624,
by LaTeX author Leslie Lamport:
<blockquote>
The purpose of writing is to convey ideas to the reader.
The worst aspect of visual systems
is that they subvert the process of communicating ideas
by encouraging the writer to concentrate on form rather than content.
Ideas are conveyed by the logical structure of the text;
the function of the visual format is to display this structure.
The author should be concerned with the structure,
not any particular visual representation.
</blockquote>
Here's another quote:
<blockquote>
Document design is a skill acquired through training and experience.
A logical system can apply the skill of a trained designer
to the formatting of a document.
</blockquote>
<p>
Let's see how well this worked for one of my papers,
a paper that was forced to switch visual formats.
</p><p>
Originally I had used the American Mathematical Society's "amsart" format:
<table>
<tbody><tr>
<td><a href="https://cr.yp.to/writing/visual/ams-000001.png"><img src="https://cr.yp.to/writing/visual/ams-000001-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000002.png"><img src="https://cr.yp.to/writing/visual/ams-000002-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000003.png"><img src="https://cr.yp.to/writing/visual/ams-000003-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000004.png"><img src="https://cr.yp.to/writing/visual/ams-000004-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000005.png"><img src="https://cr.yp.to/writing/visual/ams-000005-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000006.png"><img src="https://cr.yp.to/writing/visual/ams-000006-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000007.png"><img src="https://cr.yp.to/writing/visual/ams-000007-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000008.png"><img src="https://cr.yp.to/writing/visual/ams-000008-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000009.png"><img src="https://cr.yp.to/writing/visual/ams-000009-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000010.png"><img src="https://cr.yp.to/writing/visual/ams-000010-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000011.png"><img src="https://cr.yp.to/writing/visual/ams-000011-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000012.png"><img src="https://cr.yp.to/writing/visual/ams-000012-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000013.png"><img src="https://cr.yp.to/writing/visual/ams-000013-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000014.png"><img src="https://cr.yp.to/writing/visual/ams-000014-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000015.png"><img src="https://cr.yp.to/writing/visual/ams-000015-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000016.png"><img src="https://cr.yp.to/writing/visual/ams-000016-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000017.png"><img src="https://cr.yp.to/writing/visual/ams-000017-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000018.png"><img src="https://cr.yp.to/writing/visual/ams-000018-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000019.png"><img src="https://cr.yp.to/writing/visual/ams-000019-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/ams-000020.png"><img src="https://cr.yp.to/writing/visual/ams-000020-4.png" height="439" width="310"></a>
</td></tr>
</tbody></table>
</p><p>
But then I found out that the book containing my paper
would use the "msripub" format
designed by MSRI book editor Silvio Levy.
Here's what happens when the same document is formatted
with "msripub" rather than "amsart":
<table>
<tbody><tr>
<td><a href="https://cr.yp.to/writing/visual/msripub-000001.png"><img src="https://cr.yp.to/writing/visual/msripub-000001-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000002.png"><img src="https://cr.yp.to/writing/visual/msripub-000002-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000003.png"><img src="https://cr.yp.to/writing/visual/msripub-000003-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000004.png"><img src="https://cr.yp.to/writing/visual/msripub-000004-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000005.png"><img src="https://cr.yp.to/writing/visual/msripub-000005-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000006.png"><img src="https://cr.yp.to/writing/visual/msripub-000006-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000007.png"><img src="https://cr.yp.to/writing/visual/msripub-000007-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000008.png"><img src="https://cr.yp.to/writing/visual/msripub-000008-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000009.png"><img src="https://cr.yp.to/writing/visual/msripub-000009-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000010.png"><img src="https://cr.yp.to/writing/visual/msripub-000010-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000011.png"><img src="https://cr.yp.to/writing/visual/msripub-000011-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000012.png"><img src="https://cr.yp.to/writing/visual/msripub-000012-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000013.png"><img src="https://cr.yp.to/writing/visual/msripub-000013-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000014.png"><img src="https://cr.yp.to/writing/visual/msripub-000014-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000015.png"><img src="https://cr.yp.to/writing/visual/msripub-000015-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000016.png"><img src="https://cr.yp.to/writing/visual/msripub-000016-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000017.png"><img src="https://cr.yp.to/writing/visual/msripub-000017-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000018.png"><img src="https://cr.yp.to/writing/visual/msripub-000018-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000019.png"><img src="https://cr.yp.to/writing/visual/msripub-000019-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000020.png"><img src="https://cr.yp.to/writing/visual/msripub-000020-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000021.png"><img src="https://cr.yp.to/writing/visual/msripub-000021-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000022.png"><img src="https://cr.yp.to/writing/visual/msripub-000022-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000023.png"><img src="https://cr.yp.to/writing/visual/msripub-000023-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000024.png"><img src="https://cr.yp.to/writing/visual/msripub-000024-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000025.png"><img src="https://cr.yp.to/writing/visual/msripub-000025-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000026.png"><img src="https://cr.yp.to/writing/visual/msripub-000026-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000027.png"><img src="https://cr.yp.to/writing/visual/msripub-000027-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/msripub-000028.png"><img src="https://cr.yp.to/writing/visual/msripub-000028-4.png" height="439" width="310"></a>
</td></tr>
</tbody></table>
</p><p>
Wow, that's a really pleasant document to read!
I love the huge chunks of white space,
the visually stunning bibliography,
the completely non-functional citations to that bibliography,
the entertaining little black boxes everywhere,
and the line on page 24 sticking not merely into the margin but beyond the printed area of the page.
I'm glad that I concerned myself solely with the structure of my document,
and not with any particular visual representation.
</p><p>
This document must have been first seen by Levy,
who was not merely the skilled "msripub" designer
but also the editor of this particular book.
Surely he was inspired by the document's near-perfect beauty
and thought that a few additional tweaks
would produce a truly stunning work of art.
The scientific editors of the book waited for Levy to act.
But Levy did nothing.
Perhaps the explanation lies in Lamport's wise words:
</p><blockquote>
A logical system forces the writer
to think in terms of the document's logical structure;
it doesn't give him the illusion
that he is accomplishing anything with cosmetic formatting changes.
</blockquote>
<p>
In any event,
I wasn't able to see the "msripub" version of the document until April 2007.
Levy never sent me a copy.
You might think that I could simply change "amsart" to "msripub"
in my own copy of the document,
but "msripub" is a proprietary format:
Levy keeps it to himself.
Eventually the scientific editors convinced Levy to send "msripub" to me.
I fed my document through "msripub" and admired the output.
</p><p>
Beautiful!
</p><p>
I returned to Lamport's article
and discovered that he allowed certain minor exceptions to his "illusion":
</p><blockquote>
Achieving the highest possible quality
requires the ability to make changes to the system's output.
This will be a matter of fine tuning,
changing such things as page breaks and figure placement. ...
[However:]
The changes will generally be of such a minor nature
that they are not worth bothering with
in a preliminary version intended for a small audience,
nor for any document that is not widely distributed.
...
I usually spend less than two minutes per page
doing the final formatting to produce camera-ready output.
This is insignificant compared with the two to eight hours per page I spend writing.
</blockquote>
"Highest possible quality" sounds desirable,
and "two minutes" sounds tolerably small,
so I decided to edit the "msripub" version of my document.
<p>
You might like to pause at this point to contemplate the goals of scientific publication.
Isn't it wonderful to see science propelled forward
by something as small and simple as the switch from "amsart" to "msripub"?
</p><p>
Back to the story.
After many, many, many hours of work I had a new version of the document:
<table>
<tbody><tr>
<td><a href="https://cr.yp.to/writing/visual/34-000001.png"><img src="https://cr.yp.to/writing/visual/34-000001-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000002.png"><img src="https://cr.yp.to/writing/visual/34-000002-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000003.png"><img src="https://cr.yp.to/writing/visual/34-000003-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000004.png"><img src="https://cr.yp.to/writing/visual/34-000004-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000005.png"><img src="https://cr.yp.to/writing/visual/34-000005-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000006.png"><img src="https://cr.yp.to/writing/visual/34-000006-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000007.png"><img src="https://cr.yp.to/writing/visual/34-000007-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000008.png"><img src="https://cr.yp.to/writing/visual/34-000008-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000009.png"><img src="https://cr.yp.to/writing/visual/34-000009-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000010.png"><img src="https://cr.yp.to/writing/visual/34-000010-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000011.png"><img src="https://cr.yp.to/writing/visual/34-000011-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000012.png"><img src="https://cr.yp.to/writing/visual/34-000012-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000013.png"><img src="https://cr.yp.to/writing/visual/34-000013-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000014.png"><img src="https://cr.yp.to/writing/visual/34-000014-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000015.png"><img src="https://cr.yp.to/writing/visual/34-000015-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000016.png"><img src="https://cr.yp.to/writing/visual/34-000016-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000017.png"><img src="https://cr.yp.to/writing/visual/34-000017-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000018.png"><img src="https://cr.yp.to/writing/visual/34-000018-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000019.png"><img src="https://cr.yp.to/writing/visual/34-000019-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000020.png"><img src="https://cr.yp.to/writing/visual/34-000020-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000021.png"><img src="https://cr.yp.to/writing/visual/34-000021-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000022.png"><img src="https://cr.yp.to/writing/visual/34-000022-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000023.png"><img src="https://cr.yp.to/writing/visual/34-000023-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000024.png"><img src="https://cr.yp.to/writing/visual/34-000024-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000025.png"><img src="https://cr.yp.to/writing/visual/34-000025-4.png" height="439" width="310"></a>
</td><td><a href="https://cr.yp.to/writing/visual/34-000026.png"><img src="https://cr.yp.to/writing/visual/34-000026-4.png" height="439" width="310"></a>
</td></tr>
</tbody></table>
I had changed more than 100 separate lines of the main text,
not to mention the introductory figures, the bibliography, etc.
Many of those lines were quite difficult to adjust:
eliminating one bad line break
often meant experimenting with several different wordings and inspecting the output of each.
"Two minutes" is, I regret to report, a rather severe underestimate.
Could it be that Levy had a different reason for doing nothing at all with this paper?
</p><p>
I spent a few more hours carefully checking the paper
against the old "amsart" version
to see whether any bugs had been introduced by this flood of changes.
I ended up fixing two obsolete cross-references and two typos.
And so, finally, the conversion from "amsart" to "msripub" came to an end.


</p></div>]]>
            </description>
            <link>https://cr.yp.to/writing/visual.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25355291</guid>
            <pubDate>Wed, 09 Dec 2020 04:16:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Energy-Based Perspective on Attention Mechanisms in Transformers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25355096">thread link</a>) | @wavelander
<br/>
December 8, 2020 | https://mcbal.github.io/post/an-energy-based-perspective-on-attention-mechanisms-in-transformers/?ref=mlnews | <a href="https://web.archive.org/web/*/https://mcbal.github.io/post/an-energy-based-perspective-on-attention-mechanisms-in-transformers/?ref=mlnews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
  <a href="https://xkcd.com/793/">XKCD 793: A physicist encountering machine learning for the first time</a>
</p>
<hr>
<ol>
<li><a href="#1-introduction">Introduction</a></li>
<li><a href="#2-a-growing-zoo-of-transformers">A growing zoo of Transformers</a>
<ol>
<li><a href="#vanilla-transformers">Vanilla Transformers</a></li>
<li><a href="#beyond-vanilla-confronting-quadratic-scaling">Beyond vanilla: confronting quadratic scaling</a></li>
</ol>
</li>
<li><a href="#3-from-hopfield-networks-to-transformers">From Hopfield networks to Transformers</a>
<ol>
<li><a href="#classical-discrete-hopfield-networks">Classical discrete Hopfield networks</a></li>
<li><a href="#modern-discrete-hopfield-networks">Modern discrete Hopfield networks</a></li>
<li><a href="#modern-continuous-hopfield-networks">Modern continuous Hopfield networks</a></li>
<li><a href="#modern-continuous-hopfield-networks-as-energy-based-models">Modern continuous Hopfield networks as energy-based models</a>
<ol>
<li><a href="#energy-based-models-a-gentle-introduction">Energy-based models: a gentle introduction</a></li>
<li><a href="#exactly-optimizing-modern-continuous-hopfield-networks">Exactly optimizing modern continuous Hopfield networks</a></li>
</ol>
</li>
<li><a href="#transformers-store-and-retrieve-context-dependent-patterns">Transformers store and retrieve context-dependent patterns</a></li>
<li><a href="#where-are-patterns-stored-in-a-transformer">Where are patterns stored in a Transformer?</a></li>
</ol>
</li>
<li><a href="#4-training-transformers">Training Transformers</a>
<ol>
<li><a href="#pretraining-loss-functions">Pretraining loss functions</a></li>
<li><a href="#stepping-through-the-transformer-implicit-energy-minimization">Stepping through the Transformer: implicit energy minimization</a></li>
<li><a href="#meta-learning-and-few-shot-inference">Meta-learning and few-shot inference</a></li>
</ol>
</li>
<li><a href="#5-beyond-dot-product-attention">Beyond dot-product attention</a>
<ol>
<li><a href="#attention-dynamics-embracing-collective-phenomena">Attention dynamics: embracing collective phenomena</a></li>
<li><a href="#why-very-long-sequences-should-not-be-needed">Why very long sequences should not be needed</a></li>
</ol>
</li>
<li><a href="#6-conclusion">Conclusion</a></li>
<li><a href="#references--footnotes">References &amp; footnotes</a></li>
</ol>
<hr>

<p>In 2017, <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need</a> <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> demonstrated state-of-the-art performance in neural machine translation by stacking only (self-)attention layers. Compared to recurrent neural networks, Transformer models exhibit efficient parallel processing of tokens, leading to better modeling of long-range correlations and, most importantly, <a href="https://arxiv.org/abs/2001.08361" target="_blank" rel="noopener">favorable scaling in terms of data and compute</a>. Since then, Transformers seem to have taken over natural language processing. Widespread adoption of attention-based architectures seems likely given recent work like <a href="https://arxiv.org/abs/2010.11929" target="_blank" rel="noopener">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a> and the flurry of developments addressing the architecture‚Äôs quadratic scaling bottlenecks.</p>
<p>Recently, the papers <a href="https://arxiv.org/abs/2008.02217" target="_blank" rel="noopener">Hopfield Networks is All You Need</a> <sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> <sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> <sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> and <a href="https://arxiv.org/abs/2008.06996" target="_blank" rel="noopener">Large Associative Memory Problem in Neurobiology and Machine Learning</a> <sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> provided complementary post-facto explanations of some of the success of Transformers from the perspective of energy-based models. In this post, I provide a biased overview of (self-)attention in Transformers and summarize its connections to modern Hopfield networks. Along the way, I look for intuition from physics and indulge in hand-wavy arguments on how an energy-based perspective can shed light on training and improving Transformer models.</p>

<p>Let‚Äôs start off with an overview of the components in a vanilla Transformer model. Since our focus is on (self-)attention, I am going to assume some prior knowledge<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup> and skip comprehensive architecture descriptions and experimental results. In <a href="#3-from-hopfield-networks-to-transformers">Section 3</a>, we will start from scratch and use Hopfield networks to build back up to the attention module described below.</p>
<h2 id="vanilla-transformers">Vanilla Transformers</h2>
<p>The proto-Transformer was introduced in an encoder-decoder context for machine translation in <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need</a>. The original motivation seems to have been mostly driven by engineering efforts to model long-range correlations in sequence data and the recent successes of attention mechanisms stacked on top of recurrent neural networks. The main contribution and selling point of the paper was making an attention-only approach to sequence modeling work.</p>
<p><img src="https://mcbal.github.io/post/an-energy-based-perspective-on-attention-mechanisms-in-transformers/vanilla_transformer.png" alt="alt text" title="Vanilla Transformers encoder-decoder architecture"></p>
<p>Let‚Äôs focus on the encoder on the left and ignore the decoder on the right. Transformer models accept (batches of) sets of vectors, which covers most inputs people care about in machine learning. Text can be modelled as a sequence of embedded tokens. Images can be viewed as a snaky sequence of embedded pixels or embedded patches of pixels. Since sets have no notion of ordering, learned or fixed positional information needs to be explicitly added to the input vectors.</p>
<p>The main module in the Transformer encoder block is the multi-head <em>self-attention</em>, which is based on a (scaled) dot-product attention mechanism acting on a set of $d$-dimensional vectors:</p>
<p>\begin{equation}
\mathrm{Attention}\left( \mathbf{Q}, \mathbf{K}, \mathbf{V} \right) = \mathrm{softmax} \left( \frac{\mathbf{Q} \mathbf{K}^T}{\sqrt{d}} \right) \mathbf{V}
\label{eq:vanilla-attention}
\end{equation}</p>
<p>Here, queries $\mathbf{Q}$, keys $\mathbf{K}$, and values $\mathbf{V}$ are matrices obtained from acting with different linear transformations ‚Äî parametrized respectively by weights $\mathbf{W}_{\mathbf{Q}}$, $\mathbf{W}_{\mathbf{K}}$, and $\mathbf{W}_{\mathbf{V}}$ ‚Äî on the same set of $d$-dimensional inputs. <em>Cross-attention</em> takes the inputs for its queries from a different source than for its keys and values, as can be glimpsed from the decoder part of the architecture on the right.</p>
<p>For every input query, the updated output query of \eqref{eq:vanilla-attention} is a linear combination of values weighted by an attention matrix quantifying the overlap of the input query with the keys corresponding to these values. Since all objects are vectors and the attention mechanism is just a dot product between vectors, we can think of the attention module as matching query vectors to their ‚Äúclosest‚Äù key vectors in latent space and summing up contributions from value vectors, weighted by the ‚Äúcloseness‚Äù of their keys to the queries.</p>
<p>The remaining components of the Transformer encoder block are needed to make the module work properly in practice:</p>
<ul>
<li>The <em>multi-headedness</em> of the attention module refers to chunking up the dimension of the vector space and having multiple attention operations running in parallel in the same module, yet with each acting on a lower-dimensional segment of the full space. This is a trick to (1) get around the fact that every input vector only couples to one query at a time to calculate its attention coefficient, and (2) provide multiple starting points in the subspaces for the queries, which might help to avoid bad local minima in parameter space during optimization.</li>
<li>A positional feed-forward network, made up of two linear layers with a non-linearity in between, is inserted at the end of the module. Folklore wisdom tells us that the feed-forward layer needs to blow up the dimension of the latent space by a factor of four for it to be able to ‚Äúdisentangle‚Äù the represention. More likely though, it‚Äôs a way to increase model capacity and warp latent spaces since the attention modules on their own are pretty much linear apart from the $\mathrm{softmax}$-operator used to obtain the normalized attention coefficients.</li>
<li>Residual connections are added to control the flow of gradients.</li>
<li>Layer normalisation is used to control learning dynamics and keep vector norms from exploding.</li>
</ul>
<h2 id="beyond-vanilla-confronting-quadratic-scaling">Beyond vanilla: confronting quadratic scaling</h2>
<p>Most architectural variations of the vanilla Transformer are targeted at the attention module, which scales poorly with respect to the input sequence length $N$. Since the overlap of all queries with all keys is required, calculating a dense attention matrix scales like $\mathcal{O}(N^2)$ in time and space. Limits on the context window of the attention mechanism during training prevent the model from learning how to deal with long sequences and long-range correlations. The majority of post-vanilla Transformer species can be classified into one of the following buckets<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup>:</p>
<ul>
<li>Low-rank approximations: truncate the matrix product $\mathbf{Q} \mathbf{K}^T$ since it‚Äôs likely not full rank for structured data</li>
<li>Sparsification: reduce the attention calculation from all query-key pairs to a subset because not all of them feel the need to talk to each other</li>
<li>Recurrence: keep track of a (compressed) history of context</li>
<li>Kernels: approximate the attention operation with kernel methods</li>
</ul>
<p>For the remainder of our discussion, we will focus on vanilla Transformers. One of the goals of this blog post is to explore how a different perspective on the <em>function</em> of attention-based algorithms might lead to qualitatively different improvements beyond what is possible by relying on scaling and reducing computational complexity alone.</p>

<p>In this section, we provide a short history of Hopfield networks and gradually build up intuition until we can recognize the Transformer self-attention mechanism for what it really is. We refer to the <a href="https://ml-jku.github.io/hopfield-layers/" target="_blank" rel="noopener">blog post</a> accompanying <a href="https://arxiv.org/abs/2008.02217" target="_blank" rel="noopener">Hopfield Networks is All You Need</a> for more details and insightful visualizations of pattern storage and retrieval.</p>
<h2 id="classical-discrete-hopfield-networks">Classical discrete Hopfield networks</h2>
<p>A <a href="https://en.wikipedia.org/wiki/Hopfield_network" target="_blank" rel="noopener">Hopfield network</a> is a simple model for associative memory popularized by John Hopfield in his 1982 paper <a href="https://www.pnas.org/content/pnas/79/8/2554.full.pdf" target="_blank" rel="noopener">Neural Networks and Physical Systems with Emergent Collective Computational Abilities</a><sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>. The task of an associative memory is to store and retrieve patterns, preferably in a way that allows one to recover stored patterns quickly with a low error rate.</p>
<p>The basic idea of the Hopfield network ‚Äî and other energy-based models like <a href="https://en.wikipedia.org/wiki/Boltzmann_machine" target="_blank" rel="noopener">Boltzmann machines</a> ‚Äî is to construct an <em>energy function</em> which defines an <em>energy landscape</em> containing basins of attraction around patterns we want to store. Starting at any pattern, we want to have an update rule pointing towards the closest stored pattern, guided by a scalar ‚Äúcloseness‚Äù score provided by the energy function.</p>
<p><a href="https://en.wikipedia.org/wiki/Hopfield_network" target="_blank" rel="noopener"><img src="https://mcbal.github.io/post/an-energy-based-perspective-on-attention-mechanisms-in-transformers/energy_landscape.png" alt="alt text" title="Toy energy landscape of a Hopfield Network"></a></p>
<p>Let‚Äôs make this a bit more formal but not too formal. Consider trying to store a set of $N$ binary patterns $\{\boldsymbol{x}_{i}\}_{i=1}^{N}$ where each pattern $\boldsymbol{x}_{i}$ is a $d$-dimensional vector whose entries are either $-1$ or $1$. For example, in the case of storing black-and-white images, every image would correspond to a string of pixel values, a binary pattern $\boldsymbol{x}_{i}$.</p>
<p>For any query $\boldsymbol{\xi} \in \mathbb{R}^{d}$, or <em>state pattern</em>, we want to find a way to retrieve the closest <em>stored pattern</em>. In his paper, Hopfield considered the energy function</p>
<p>\begin{equation}
E = - \frac{1}{2} \boldsymbol{\xi}^{T} \boldsymbol{W} \boldsymbol{\xi} + \boldsymbol{\xi}^{T} \boldsymbol{b} = - \frac{1}{2} \sum_{i=1}^{d} \sum_{j=1}^{d} w_{ij} \xi_{i} \xi_{j} + \sum_{i=1}^{d} b_{i} \xi_{i} ,
\label{eq:ising}
\end{equation}</p>
<p>where $\boldsymbol{b} \in \mathbb{R}^{d}$ denotes a bias vector and the weights $\boldsymbol{W} \in \mathbb{R}^{d \times d}$ are set to the sum of the outer products of the patterns we want to store</p>
<p>\begin{equation}
\boldsymbol{W} = \sum_{i=1}^{N} \boldsymbol{x}_{i} \otimes ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mcbal.github.io/post/an-energy-based-perspective-on-attention-mechanisms-in-transformers/?ref=mlnews">https://mcbal.github.io/post/an-energy-based-perspective-on-attention-mechanisms-in-transformers/?ref=mlnews</a></em></p>]]>
            </description>
            <link>https://mcbal.github.io/post/an-energy-based-perspective-on-attention-mechanisms-in-transformers/?ref=mlnews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25355096</guid>
            <pubDate>Wed, 09 Dec 2020 03:48:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I'm Skeptical of ‚ÄúExperts‚Äù]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25354995">thread link</a>) | @karlhughes
<br/>
December 8, 2020 | https://www.karllhughes.com/posts/experts | <a href="https://web.archive.org/web/*/https://www.karllhughes.com/posts/experts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article>
<div>
<p><img src="https://i.imgur.com/Hx2paJy.jpg" alt="The Danger in Listening to Experts">
</p> 

<p>
2020, Oct 27&nbsp;&nbsp;&nbsp;‚Äî&nbsp;
11 minute read
</p>
<section id="mc_embed_signup">

</section>
<blockquote>
<p>‚ÄúMost of all, there is this truth: No matter how great your teachers may be, and no matter how esteemed your academy‚Äôs reputation, eventually you will have to do the work by yourself. Eventually, the teachers won‚Äôt be there anymore. The walls of the school will fall away, and you‚Äôll be on your own.‚Äù - <a href="https://amzn.to/2TtGVsm">Elizabeth Gilbert, Big Magic</a></p>
</blockquote>
<p>I am very intentional about cultivating peers and mentors who I trust. When I <a href="https://www.karllhughes.com/posts/cto-writer">left my job to start a business</a> earlier this year, one of the first things I did was create a list of informal advisors - mostly experienced entrepreneurs who I could count on for candid feedback.</p>
<p>Still, when I meet with one of my mentors to ask them a specific question, I start the conversation with a warning:</p>
<p>‚ÄúI have a question, but just so you know, you‚Äôre not the only person I‚Äôm asking. If I don‚Äôt take your advice, I don‚Äôt want you to take it personally, okay?‚Äù</p>
<p>Every one of them appreciates this caveat because <strong>giving advice is really hard.</strong> In fact, I am starting to realize that you should be wary of people who are too quick to offer it.</p>
<p>The further I go in my career, the more skeptical I am of ‚Äúexperts.‚Äù While people with experience may generally make better decisions, I don‚Äôt know if their advice transfers the way they think it does.</p>
<p>Now, I realize the irony in offering advice to ignore advice, but my goal is to make you reconsider all advice - including the advice I give.</p>
<p>Above all, I hope this makes you think before you blindly follow others.</p>
<h2 id="1-experts-overgeneralize-their-experience">1. Experts Overgeneralize Their Experience</h2>
<p>Many legitimately successful people got lucky once.</p>
<p>You see this a lot in Silicon Valley-style businesses where a single expert or lucky investment might lead to generational wealth. These successful and wealthy people feel that they‚Äôve discovered the ‚Äúsecret‚Äù to building a business based on a single runaway success.</p>
<p>This bias is called <a href="http://iameduard.com/overgeneralization/">overgeneralization</a>, and both advice givers and receivers fall into it.</p>
<p>For example, if you‚Äôve read <a href="https://amzn.to/3oy8DSY">Walter Isaacson‚Äôs biography</a>, you know that Steve Jobs was a ruthless boss and obsessive about details. Jobs was amazingly successful as an entrepreneur and executive; therefore, you should be ruthless and obsessive if you want to be a successful entrepreneur and executive.</p>
<p>The logical fallacy here is obvious - we can point to dozens of counterpoints - but it illustrates the danger in overgeneralizing an expert‚Äôs advice or behavior.</p>
<p>Part of the reason we fall prey to experts who overgeneralize their experience is that as humans, <a href="https://manuel.friger.io/blog/advice">we really like stories</a>:</p>
<blockquote>
<p>‚ÄúWe love anecdotes so much because it‚Äôs often much easier for people to believe someone‚Äôs testimony as opposed to <strong>understanding complex data and variation across a continuum</strong>. Anecdotes exempt us from having to prove our point: it‚Äôs happened once; that‚Äôs solid proof as far as I‚Äôm concerned.‚Äù - <a href="https://manuel.friger.io/blog/advice">Manuel Frigerio</a></p>
</blockquote>
<p>Manuel cites Jeanne Calment, who lived to 116 years old and smoked every day of her adult life. Jeanne Calment is one data point. <strong>What worked for one person one time many years ago will not work for everyone for all time.</strong></p>
<p><img src="https://paper-attachments.dropbox.com/s_11C9E1C44BCB40F0FE12CD8C443C12B2DA5D48417F2028A6D847E5BE71580EB1_1603765436506_ovg.jpg" alt=""></p>
<p>Additionally, many experts <a href="https://twitter.com/KarlLHughes/status/1284104244891721730">rewrite their stories in their minds</a>.</p>
<p>Take Brian Williams, once an upstanding NBC news anchor and respected journalist. He told a complete fabrication of his experience in Iraq multiple times, including in an especially vivid recounting at a hockey game:</p>
<blockquote>
<p>‚ÄúThe story actually started with a terrible moment a dozen years back during the invasion of Iraq when the helicopter we were traveling in was forced down after being hit by an RPG.‚Äù - <a href="https://www.vox.com/2015/2/5/7987439/brian-williams-iraq-apology-helicopter">Brian Williams</a></p>
</blockquote>
<p>I don‚Äôt know if Williams knew he was lying or not, but if you want to believe his apology, he mistakenly inserted himself into a true story that he had seen:</p>
<blockquote>
<p>‚ÄúI think the constant viewing of the video showing us inspecting the impact area ‚Äî and the fog of memory over 12 years ‚Äî made me conflate the two.‚Äù - Brian Williams (later apologizing)</p>
</blockquote>
<p>Whatever the details of Williams‚Äô story, it‚Äôs easy to imagine that most professionals with 10+ years of experience will misremember or rewrite parts of their own experience when asked. This problem gets compounded when beginners ask for advice from experts because they can‚Äôt discern the misremembering from the truth.</p>
<p>Beginners don‚Äôt have enough experience to call bullsh** on experts.</p>
<h2 id="2-inherent-survivorship-bias">2. Inherent Survivorship Bias</h2>
<blockquote>
<p>‚Äú<strong>The Misconception:</strong> You should focus on the successful if you wish to become successful.</p>
<p><strong>The Truth:</strong> When failure becomes invisible, the difference between failure and success may also become invisible.‚Äù - <a href="https://youarenotsosmart.com/2013/05/23/survivorship-bias/">David McRaney</a></p>
</blockquote>
<p><strong>Survivors become experts</strong>, regardless of their skills, knowledge, or the repeatability of their experience.</p>
<p>Survivorship bias is one of the most dangerous ones in finance, and it‚Äôs one of the easiest traps to fall into when you look for advice. By taking only the positive cases (i.e.: people who succeeded in your field), you are unable to tell which factors were vital to their success and which factors were unrelated to it.</p>
<p>You hear the same thing from people who claim, ‚Äúthey sure don‚Äôt make ‚Äòem like they used to.‚Äù</p>
<blockquote>
<p>‚ÄúA commonly held opinion in many populations is that machinery, equipment, and goods manufactured in previous generations often is better built and lasts longer‚Ä¶because of the selective pressures of time and use, it is inevitable that only those items that were built to last will have survived into the present day.</p>
<p>Therefore, most of the old machinery still seen functioning well in the present day must necessarily have been built to a standard of quality necessary to survive. All of the machinery, equipment, and goods that have failed over the intervening years are no longer visible to the general population as they have been junked, scrapped, recycled, or otherwise disposed of.‚Äù - <a href="https://en.wikipedia.org/wiki/Survivorship_bias">Wikipedia, Survivorship Bias</a></p>
</blockquote>
<p><img src="https://paper-attachments.dropbox.com/s_11C9E1C44BCB40F0FE12CD8C443C12B2DA5D48417F2028A6D847E5BE71580EB1_1603765755896_survivor.jpg" alt=""></p>
<p>When survivors give advice, they conflate correlation and causation. Was the fact that <a href="https://tim.blog/about/">Tim Ferriss</a> executed his book launch a certain way the reason it succeeded? Or was the fact that Tim Ferriss had a massive audience of followers before his latest book launch the real reason?</p>
<p>We can‚Äôt know <a href="https://pjrvs.com/survivorship">because Tim Ferriss is a survivor</a>. He is one of the few authors who has ‚Äúmade it‚Äù to the level he has. By virtue of surviving this far, we have to take all of his marketing advice with a grain of salt.</p>
<p>The danger of survivorship bias is that it‚Äôs tough to combat. People <a href="https://www.inc.com/jeff-haden/want-to-really-help-others-talk-about-your-failures-not-successes.html">don‚Äôt like to talk about their failures</a>, and failures are subject to the same overgeneralization biases that successes are. In other words, <strong>even if someone tells you why they think they failed, they‚Äôre probably wrong.</strong></p>
<h2 id="3-the-expert-beginner-experience-gulf">3. The Expert-Beginner Experience Gulf</h2>
<p>Knowledge isn‚Äôt discrete - it‚Äôs a continuum.</p>
<p>Experts tend to forget that they have a considerable base of knowledge that beginners lack. This experience gap means that realizations the expert recently had will be useless (or even harmful) to beginners who lack the same foundational understanding.</p>
<p>For example, a friend of mine recently graduated from a coding bootcamp and asked me what podcasts I listen to.</p>
<p>I thought about it for a while. Are the software architecture and management podcasts I listen to going to help this guy? There weren‚Äôt many programming podcasts around when I learned to code, so I can‚Äôt tell him which ones helped me when I was just starting out. Should I selfishly send him the podcast that recently invited me on as a guest?</p>
<p>I struggle with advising new programmers because the gulf between my current level of experience and theirs is too broad. I don‚Äôt remember what I didn‚Äôt know when I was just starting out; plus, the world has changed. The books I read back then are hopelessly out of date, and the books I read now are hopelessly indecipherable to most new programmers.</p>
<p>This chart illustrates the problem. When you‚Äôre just starting to learn about a topic, you start in the bottom-left, and over time you move to the top right:</p>
<p><img src="https://i.imgur.com/zxD9C4I.png" alt="Knowledge contimuum"></p>
<p>Beginners need to grasp relationships and patterns, while experts are interested in uncovering principles. The advice experts give often comes from their higher-level understanding.</p>
<p>What‚Äôs more insidious about the expert-beginner gulf is that people‚Äôs brains actually <a href="https://www.wired.com/2009/03/financebrain/"><em>shut down</em> when given advice from an expert</a>:</p>
<blockquote>
<p>‚ÄúWhen thinking for themselves, students showed activity in their anterior cingulate cortex and dorsolateral prefrontal cortex ‚Äî brain regions associated with making decisions and calculating probabilities. When given advice from Noussair, activity in those regions flat lined. - <a href="https://www.wired.com/2009/03/financebrain/">Brandon Keim, Wired</a></p>
</blockquote>
<p>Even if the advice makes sense given the expert‚Äôs current level of understanding, the beginner may not grasp the underlying patterns required to make good use of the advice.</p>
<p>For example, we typically tell new drivers to stop at red lights. This is good generalized advice, but a beginner may not realize that there exceptions to this rule. What if the light is flashing red? What if it‚Äôs red, but no traffic is coming, and you want to turn right? What if you have a medical emergency?</p>
<p>Experienced drivers can make judgment calls based on advice and experience, but beginners cannot. They haven‚Äôt developed the filters to process and individualize advice.</p>
<h2 id="4-they-might-be-charlatans">4. They Might Be Charlatans</h2>
<p>It‚Äôs hard to believe I‚Äôve gotten this far without mentioning experts who are blatantly slanting their advice towards profit, but I‚Äôll get to it now.</p>
<p>First, what is a <em>charlatan?</em></p>
<blockquote>
<p>‚ÄúA person who pretends or claims to have more knowledge or skill than he or she possesses; quack.‚Äù - <a href="https://www.dictionary.com/browse/charlatan">Dictionary.com</a></p>
</blockquote>
<p>Right now, most online courses are sold by charlatans. I‚Äôm not saying you can‚Äôt learn anything from them, but most people selling them don‚Äôt have much more knowledge than you do; they just offer their advice more confidently.</p>
<blockquote>
<p>‚ÄúWe now live in a time where information is becoming less and less commoditized and learning is becoming freer by passing days. So, it‚Äôs surprising that institutes and ‚Äúexperts‚Äù still exist and charge big money for courses.‚Äù - <a href="https://thatnameasif.medium.com/digital-marketing-courses-scam-be96464c12e2">Asif Ali</a></p>
</blockquote>
<p>Ironically, most charlatans don‚Äôt even know ‚Ä¶</p></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.karllhughes.com/posts/experts">https://www.karllhughes.com/posts/experts</a></em></p>]]>
            </description>
            <link>https://www.karllhughes.com/posts/experts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25354995</guid>
            <pubDate>Wed, 09 Dec 2020 03:28:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Webless Initiative]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25354786">thread link</a>) | @userbinator
<br/>
December 8, 2020 | http://repo.hu/projects/webless/ | <a href="https://web.archive.org/web/*/http://repo.hu/projects/webless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><a href="http://repo.hu/projects/webless/index.html#webless">The Webless Initiative</a> |
Rules: <a href="http://repo.hu/projects/webless/rules-friends.html">Friends</a> /
<a href="http://repo.hu/projects/webless/rules-validated.html">Validated</a> |
<a href="http://repo.hu/projects/webless/index.html#mailinglist">Mailing List</a> |
<a href="http://repo.hu/projects/webless/faq.html">FAQ</a> |
<a href="http://repo.hu/projects/webless/index.html#contact">Contact</a> |
<a href="http://repo.hu/projects/webless/friends.html">The Friends of Webless</a>
<hr>



<p>See the <a href="http://repo.hu/projects/webless/antiweb.html">Anti-web Manifesto</a>

</p><p><b>The Webless Initiative</b> is a campaign to make the modern Web a more
livable place. We aim to accomplish this by:
</p><ul>
	<li>Discouraging useless "style" or "interactive" features
	</li><li>Encouraging fast, portable, readable pages, with simpler HTML
</li></ul>
<p>This should:
</p><ul>
	<li>Make web browsers potentially a lot smaller, faster and comfortable<br>
	(realistically, make it possible to use existing small web browsers)
	</li><li>Drastically lessen the necessary bandwidth, making more room for real content
</li></ul>
<p>We plan to provide a set of rules and recommendations for anyone who wishes
to make their web page conformant. There will be an automatic validator for this
ruleset.
</p><p>We plan to create and maintain <b>two lists of websites</b>, with an appropriate
label or banner site owners can publish to indicate their membership:
</p><ul>
<li><b><a href="http://repo.hu/projects/webless/friends.html">Friends of Webless</a></b>
<p>
Simply by expressing their wish, anyone can be part of this list. The only
condition is that their site is <b>comfortably usable with a small web browser</b>.
</p><p>This might be manually checked, and Webless might refuse to keep the site listed,
if we perceive that it does not meet <a href="http://repo.hu/projects/webless/rules-friends.html">this rule</a>.

</p></li><li><b>Validated Webless</b>
<p>
Membership on this list is per request. The site will be checked
(and may be periodically rechecked) against the <a href="http://repo.hu/projects/webless/rules-validated.html">Webless Rules.</a>
Only sites passing these tests will be listed.
</p></li></ul>
<p>
We ask that listed (friends and validated) sites place a link on this page.
This is not mandatory; and the link might serve as a disclaimer for when
visitors are asking why your page is lacking all the modern whizbang.

</p><h2><a name="mailinglist">Contact</a></h2>

<p>For the moment, if you want to see your site on either the Friends or the
Validated list, please send me a mail (see address below).

</p><h2><a name="extern">Recommended Reading</a></h2>

<ul>
<li><a href="http://www.anybrowser.org/campaign/">Viewable with Any Browser</a>
</li><li><a href="http://www.websiteoptimization.com/speed/tweak/average-web-page/">Average Web Page Size Triples Since 2003</a>
</li><li><a href="http://www.flownet.com/ron/css-rant.html">Why CSS should not be used for layout</a>
</li></ul>

<h2><a name="contact">Contact</a></h2>

<p>You can reach us on IRC: server <code>repo.hu</code>, channel <code>#dev</code>.
</p><p>Via e-mail: <code>webless (at) igor2.repo.hu</code>
</p></div>]]>
            </description>
            <link>http://repo.hu/projects/webless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25354786</guid>
            <pubDate>Wed, 09 Dec 2020 02:55:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs Survey 2020 Results]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25354551">thread link</a>) | @pama
<br/>
December 8, 2020 | https://emacssurvey.org/2020/ | <a href="https://web.archive.org/web/*/https://emacssurvey.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2>Questions</h2>
      <p>For reference, this was <a href="https://emacssurvey.org/2020/emacs-user-survey-2020.org">the survey questions</a> in org-mode format.</p>
      <h2>Data</h2>
      <ul>
        <li>
          <a href="https://emacssurvey.org/2020/Emacs-User-Survey-2020-raw.csv">Raw data</a>
          <ul>
            <li>the reconciled data from both webform and email submissions</li>
            <li>absolutely no change made aside from a few instances where PII and email addresses were redacted</li>
          </ul>
        </li>
        <li>
          <a href="https://emacssurvey.org/2020/Emacs-User-Survey-2020-clean.csv">Cleaned up data</a><br>
          It might get updated in the future, but right now it was derived from the raw data in a best-effort attempt:
          <ul>
            <li>removed negative years in "For how many years have you been using Emacs?"</li>
            <li>unified responses for "How did you hear about this survey?" as Hacker News, Emacs China and Emacs News weren't part of the options</li>
            <li>unified responses for "Which theme do you use?", especially around spelling</li>
            <li>general cleanup and unified of responses which only differed by punctuation and casing</li>
          </ul>
        </li>
      </ul>
      <h2>Statistics about the survey</h2>
      
      <h2>Analysis</h2>
      <p>There is a lot of data to look at in many different ways. For now, I performed a simple question-by-question analysis using a <a href="https://github.com/abrochard/emacs-survey/blob/main/2020/Emacs%20User%20Survey%202020.ipynb">Jupyter Notebook</a>.</p>
      <p>Also, since free text was available for most questions, it can be hard to categorize some of the results. For multiple choice questions, I did a best effort attempt to bundle responses with low cardinality into an "other" section, which can get quite big in some cases! I also did not attempt to graph anything for pure free text questions. I encourage anyone who is curious to inspect the full responses, either in the notebook or looking at the data directly. The omitted free text questions are:
        </p><ul>
          <li>If you use org-mode, for what purpose?</li>
          <li>Do you use a language server with lsp-mode or eglot? With what languages?</li>
          <li>Do you use an Emacs debugger interface? What do you use? (Gdb, dap-mode etc)</li>
          <li>What are some of the Emacs improvements you are the most interested in?</li>
          <li>What do you think are Emacs' greatest strengths?</li>
          <li>Can you recall any difficulties you faced initially learning Emacs?</li>
          <li>What is the one thing you would like Emacs to do differently?</li>
          <li>If there is another survey in 2021, would you be opposed to it containing optional &amp; general demographics questions?</li>
          <li>Do you have a preferred platform for filling out the survey in the future?</li>
          <li>Do you have general feedback about the survey process?</li>
        </ul>
      

      <p>Also if you have some cool analysis and want to share it, please <a href="mailto:contact@emacssurvey.org">let us know</a> and we can link to you.</p>
      <p><img src="https://emacssurvey.org/2020/how-would-you-characterize-your-use-of-emacs.png">
      <img src="https://emacssurvey.org/2020/what-do-you-use-emacs-for.png">
      <img src="https://emacssurvey.org/2020/for-how-many-years-have-you-been-using-emacs.png">
      <img src="https://emacssurvey.org/2020/which-version-of-emacs-do-you-primarily-use.png">
      <img src="https://emacssurvey.org/2020/which-os-do-you-primarily-use-emacs-on.png">
      <img src="https://emacssurvey.org/2020/how-do-you-run-emacs.png">
      <img src="https://emacssurvey.org/2020/how-do-you-use-emacs.png">
      <img src="https://emacssurvey.org/2020/if-you-use-emacs-gui-do-you-disable-any-of-the-graphical-elements.png">
      <img src="https://emacssurvey.org/2020/is-your-configuration-based-on-any-starter-kit.png">
      <img src="https://emacssurvey.org/2020/what-keybindings-do-you-use-now.png">
      <img src="https://emacssurvey.org/2020/when-you-started-using-emacs-what-keybindings-did-you-use-then.png">
      <img src="https://emacssurvey.org/2020/prior-to-using-emacs-what-was-your-primary-editor.png">
      <img src="https://emacssurvey.org/2020/describe-your-org-mode-usage.png"></p><!-- <p>If you use org-mode, for what purpose?</p> -->
      <p><img src="https://emacssurvey.org/2020/which-completionselection-framework-do-you-use.png">
      <img src="https://emacssurvey.org/2020/how-do-you-manage-third-party-elisp.png">
      <img src="https://emacssurvey.org/2020/how-do-you-get-emacs-packagesif-applicable.png">
      <img src="https://emacssurvey.org/2020/can-you-list-some-of-your-favorite-packages.png">
      <img src="https://emacssurvey.org/2020/which-theme-do-you-use.png">
      <img src="https://emacssurvey.org/2020/what-package-do-you-use-for-error-checking.png">
      <img src="https://emacssurvey.org/2020/do-you-use-tramp.png">
      <img src="https://emacssurvey.org/2020/do-you-use-magit.png">
      <img src="https://emacssurvey.org/2020/what-package-do-you-use-for-project-management.png">
      <img src="https://emacssurvey.org/2020/do-you-use-a-shellterminal-emulator-in-emacs.png">
      <img src="https://emacssurvey.org/2020/do-you-use-an-email-client-in-emacs.png">
      <img src="https://emacssurvey.org/2020/what-is-your-elisp-proficiency.png">
      <img src="https://emacssurvey.org/2020/if-you-use-emacs-for-programming-which-languages-do-you-program-in.png"></p><!-- <p>Do you use a language server with lsp-mode or eglot? With what languages?</p>
           <p>Do you use an Emacs debugger interface? What do you use? (Gdb, dap-mode etc)</p> -->
      <p><img src="https://emacssurvey.org/2020/have-you-ever-contributed-to-gnu-emacs-coreelpa.png">
      <img src="https://emacssurvey.org/2020/have-you-ever-contributed-to-melpa-package.png">
      <img src="https://emacssurvey.org/2020/have-you-ever-contributed-financially-to-emacs-development-either-via-fsf-or-directly.png">
      <img src="https://emacssurvey.org/2020/what-emacs-community-forums-have-you-visited-in-the-past-year.png"></p><!-- <p>What are some of the Emacs improvements you are the most interested in?</p>
           <p>What do you think are Emacs' greatest strengths?</p>
           <p>Can you recall any difficulties you faced initially learning Emacs?</p>
           <p>What is the one thing you would like Emacs to do differently?</p> -->
      <p><img src="https://emacssurvey.org/2020/how-did-you-hear-about-this-survey.png"></p><!-- <p>If there is another survey in 2021, would you be opposed to it containing optional & general demographics questions?</p>
           <p>Do you have a preferred platform for filling out the survey in the future?</p>
           <p>Do you have general feedback about the survey process?</p> -->
    </div></div>]]>
            </description>
            <link>https://emacssurvey.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25354551</guid>
            <pubDate>Wed, 09 Dec 2020 02:17:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Starlink offers fast internet connections to rural Canadians. But it's not cheap]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25354122">thread link</a>) | @rhschan
<br/>
December 8, 2020 | https://www.cbc.ca/news/technology/starlink-internet-beta-testing-in-canada-1.5831765 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/technology/starlink-internet-beta-testing-in-canada-1.5831765">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The new high-speed internet service from Elon Musk's SpaceX firm recently approved by the CRTC does have drawbacks, including its price tag and the potential impact its satellites will have on stargazing. But it's offering hope to users in rural areas who've long struggled to get high-speed connections.</p><div><p><span><span><div><div title="SpaceX satellite internet Starlink being tested in remote areas of Canada" role="button" tabindex="0"><div><div aria-labelledby="1827994179791-metadata-" title="SpaceX satellite internet Starlink being tested in remote areas of Canada"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/464/103/STARLINK-INTERNET-DAIGLE-041220.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Elon Musk's new satellite internet service is being tested by some Canadians in rural and remote parts of the country. It's supposed to give them a good quality, high-speed internet connection, but it's not cheap and some say the low-orbit Starlink satellites are ruining their view of the night sky.<!-- --> <!-- -->2:06</span></span></span></p><p><span><p>When Vernon Kejick got a first taste of Starlink satellite internet on the Pikangikum First Nation, his initial review was succinct.</p>  <p>"All I can say is it's a lot faster than what I had before," he said. Kejick's response highlights a long-running disparity that may finally have met a resolution.</p>  <p>Starlink, the new high-speed internet service provided by Elon Musk's U.S.-based SpaceX firm, and recently <a href="https://www.cbc.ca/news/canada/new-brunswick/elon-musk-tesla-starlink-low-earth-orbit-high-speed-rural-internet-rockets-satellite-1.5768338"><u>approved</u></a> by the CRTC, does have drawbacks. It's expensive. And stargazers fear it will ruin the night sky.</p>  <p>But for users in rural and remote areas who've long struggled to obtain internet access on equal footing with Canadians in urban areas, Starlink is offering hope. The service was recently made available to select users for "beta testing," with the promise of wider availability in 2021.&nbsp;</p>  <p>In Pikangikum, a fly-in community of 2,800 residents in northwest Ontario, Kejick said he'd become accustomed to download speeds of only 2 megabits per second ‚Äî&nbsp;a fraction of the 50 megabits per the second the federal government considers a standard minimum for broadband.</p>    <p>At work, Kejick couldn't open large email attachments. He described the service as "deplorable."</p>  <p>At the end of November, Pikangikum became the first Indigenous community to get connected to Starlink, with 60 dishes reserved for homes and businesses in the community in the initial phase of installation, and potentially another 40 by the end of December.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5831800.1607376960!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/tesla-musk-germany.JPG 300w,https://i.cbc.ca/1.5831800.1607376960!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/tesla-musk-germany.JPG 460w,https://i.cbc.ca/1.5831800.1607376960!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/tesla-musk-germany.JPG 620w,https://i.cbc.ca/1.5831800.1607376960!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/tesla-musk-germany.JPG 780w,https://i.cbc.ca/1.5831800.1607376960!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/tesla-musk-germany.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5831800.1607376960!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/tesla-musk-germany.JPG"></p></div><figcaption>Elon Musk's SpaceX firm has promised Starlink internet will provide 'near global coverage of the populated world' in 2021.<!-- --> <!-- -->(Hannibal Hanschke/Pool via REUTERS)</figcaption></figure></span></p>  <p>Now, Kejick said his devices have been reaching 144 megabits per second. Not only can he quickly download attachments, Kejick said his wife has finally been able to chat with relatives in the Philippines over FaceTime.&nbsp;</p>  <p>"It's as if you're sitting in the same room," he said.</p>  <p>In Pikangikum, however, Starlink could offer more fundamental changes. Kejick, a victim services advocate with the Ontario Ministry of the Attorney General, said he hopes victims of crime will&nbsp;now be able to testify virtually, lessening the burden on them.</p>  <p>Members of the remote Ojibwe community hope the faster internet will remove barriers to access virtual healthcare services and education, too.</p>    <p>"It's doing everything that people are asking it to do," said David Brown, CEO of FSET Information Technology in Kenora, Ont. His firm had been working with Pikangikum for several years to try to improve their connectivity.&nbsp;</p>  <p>When he heard about Starlink, Brown jokingly promised his staff he would directly contact SpaceX's Musk ‚Äî&nbsp;who recently surpassed Microsoft founder Bill Gates as one of the world's richest people, second only to Amazon CEO Jeff Bezos.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5768390.1603139721!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/spacex-starlink.jpg 300w,https://i.cbc.ca/1.5768390.1603139721!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/spacex-starlink.jpg 460w,https://i.cbc.ca/1.5768390.1603139721!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/spacex-starlink.jpg 620w,https://i.cbc.ca/1.5768390.1603139721!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/spacex-starlink.jpg 780w,https://i.cbc.ca/1.5768390.1603139721!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/spacex-starlink.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5768390.1603139721!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/spacex-starlink.jpg"></p></div><figcaption>A SpaceX craft launches a cluster of 60 Starlink satellites. The company was founded by Tesla carmaker Elon Musk. More than 800 Starlink satellites are in low Earth orbit. <!-- --> <!-- -->(SpaceX, Twitter)</figcaption></figure></span></p>  <p>Brown didn't reach Musk, but he did secure dozens of dishes for Pikangikum. FSET recently helped install the first batch. And the result, Brown said, was better than he expected.</p>  <p>Starlink is "a wonderful thing," he said. "It's going to change the world for people."</p>  <h2>Rural, remote areas lack broadband</h2>  <p>Across Canada, only 40.8 per cent of rural communities have access to adequate broadband, according to federal <a href="https://crtc.gc.ca/eng/internet/internet.htm"><u>data</u></a>.</p>  <p>Greg Rekounas, a database administrator who has long worked from home, said he contacted various service providers and could never find suitable broadband for his house on New Brunswick's Kingston Peninsula, near Saint John.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5818012.1606424644!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/greg-rekounas.jpg 300w,https://i.cbc.ca/1.5818012.1606424644!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/greg-rekounas.jpg 460w,https://i.cbc.ca/1.5818012.1606424644!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/greg-rekounas.jpg 620w,https://i.cbc.ca/1.5818012.1606424644!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/greg-rekounas.jpg 780w,https://i.cbc.ca/1.5818012.1606424644!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/greg-rekounas.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5818012.1606424644!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/greg-rekounas.jpg"></p></div><figcaption>Greg Rekounas tests download and upload speeds via his newly installed link to Starlink low earth orbit satellites. <!-- --> <!-- -->(Greg Rekounas, submitted)</figcaption></figure></span></p>  <p>The quality of his home connection suffered under the strain of increased streaming and surfing during the pandemic. So when he heard about Starlink, he signed up in November to become one of the company's Canadian beta testers. Rekounas received an email saying he'd been selected, and received the installation kit within days.</p>  <p>"I've been waiting for something like this for a long time," he said. There have been some hiccups with certain streaming apps, but Rekounas said "in general, it's been fantastic."</p>  <p>SpaceX said&nbsp;there are bound to be interruptions while its service is in beta testing, which it describes as "Better Than Nothing Beta."</p>  <p>Not everyone who registers to become a tester is selected to take part. SpaceX did not respond to emailed questions about the number of Canadians testing its service, or when exactly the firm expects to make Starlink available to the general public.</p>  <p>The cost alone is bound to turn off some consumers. Delores Waye of Taymouth, N.B., north of Fredericton, recently received an invitation from Starlink after her son had made the request. She was interested in signing up, until Waye saw the price at the bottom of the email.</p>  <p><em><strong>WATCH |&nbsp;Starlink satellites spotted over New Brunswick:</strong></em></p>  <p><span><span><div><div title="Starlink satellites spotted over New Brunswick" role="button" tabindex="0"><div><div aria-labelledby="1828820035953-metadata-" title="Starlink satellites spotted over New Brunswick"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/227/715/1-STARLINK-OVER-FREDERICTON.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Michael Stemm captured low orbit SpaceX Starlink satellites over Fredericton on the evening of June 4, 2020.<!-- --> <!-- -->0:51</span></span></span></p>  <p>Buying the dish and other gear needed for the Starlink service costs $649, plus tax. Rekounas said he paid $820 in total. Users are expected to install the kit themselves. Then, it's $129 per month for the service.</p>  <p>"I was floored," Waye&nbsp;said. "When you're doing beta testing, you would expect the company to at least provide you with the equipment. It just seems crazy."</p>  <h2>Trouble above</h2>  <p>There's also another kind of cost to consider: the lasting impact of thousands of low Earth orbit satellites sent into the sky. Starlink satellites orbit the Earth at an altitude of 550 kilometres. That's thousands of kilometres lower than conventional satellites ‚Äî reducing&nbsp;the distance the signal must travel.&nbsp;</p>  <p>SpaceX has been launching up to 60 satellites at a time, with hundreds already in orbit. The firm <a href="https://www.forbes.com/sites/johnkoetsier/2020/01/09/elon-musks-42000-starlink-satellites-could-just-save-the-world/?sh=1cd601f94c2c"><u>reportedly</u></a> plans to launch as many as 42,000 in total.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5831815.1607377738!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/spacex-launch.jpg 300w,https://i.cbc.ca/1.5831815.1607377738!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/spacex-launch.jpg 460w,https://i.cbc.ca/1.5831815.1607377738!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/spacex-launch.jpg 620w,https://i.cbc.ca/1.5831815.1607377738!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/spacex-launch.jpg 780w,https://i.cbc.ca/1.5831815.1607377738!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/spacex-launch.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5831815.1607377738!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/spacex-launch.jpg"></p></div><figcaption>The SpaceX Falcon 9 rocket carrying Starlink satellites launched Oct. 6, from the Kennedy Space Center in Florida. <!-- --> <!-- -->(Tim Shortt/Florida Today via AP)</figcaption></figure></span></p>  <p>Stargazers such as University of Regina astronomy professor Samantha Lawler <a href="https://theconversation.com/spacexs-starlink-satellites-are-about-to-ruin-stargazing-for-everyone-149516"><u>anticipate</u></a> a visible impact. "It's going to dramatically change the way the night sky looks for everyone in the world," she said in an interview.</p>  <p>Canadians have already been reporting sightings of the bright Starlink satellites at night, in a distinct train-like formation.&nbsp;</p>  <p>Earlier this year, SpaceX <a href="https://www.spacex.com/updates/starlink-update-04-28-2020/"><u>committed</u></a> to making changes so their satellites wouldn't be so visible. The company pledged to add a visor to each satellite as a way to prevent the sun's reflection.</p>  <p><em><strong>LISTEN&nbsp;|&nbsp;Why the race to deliver better internet service has many astronomers concerned:</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="Astronomers are worried about plans for thousands of new satellites"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/926/743/Generic_CBC_Radio_One_640.jpg" alt=""></p><p><span>Columnists from CBC Radio</span><span>3:55</span><span>Astronomers are worried about plans for thousands of new satellites</span></p></div></div></div><span>The space just beyond our planet is quickly becoming more crowded thanks to Elon Musk and his Starlink satellite project. CBC's Blair Sanderson explores why the race to deliver better internet service has many astronomers concerned.<!-- --> <!-- -->3:55</span></span></span></p>  <p>Amazon is planning its own low Earth orbit satellite constellation, too. And Canadian firm Telesat signed an agreement with the federal government to provide high-speed internet with a new low orbit fleet of its own.&nbsp;</p>  <p>Lawler said the satellites will be brightest in places such as Regina, Saskatoon, Calgary and Vancouver. "We're at pretty much the worst latitude for it," she warned.</p>  <p>"For a couple of hours after sunset and a couple of hours before sunrise‚Ä¶ you will see more satellites in the sky than stars."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5570100.1589484071!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/elon-musk.jpg 300w,https://i.cbc.ca/1.5570100.1589484071!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/elon-musk.jpg 460w,https://i.cbc.ca/1.5570100.1589484071!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/elon-musk.jpg 620w,https://i.cbc.ca/1.5570100.1589484071!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/elon-musk.jpg 780w,https://i.cbc.ca/1.5570100.1589484071!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/elon-musk.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5570100.1589484071!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/elon-musk.jpg"></p></div><figcaption>Musk has become one of the richest people on Earth.<!-- --> <!-- -->(Frederic J. Brown/AFP via Getty Images)</figcaption></figure></span></p>  <p>Ottawa recently <a href="https://www.cbc.ca/news/politics/broadband-internet-1.5794901"><u>announced</u></a> plans to ensure 98 per cent of Canadians are connected to high-speed internet by 2026. The announcement included $150 million in funding for quick-turnaround projects to connect more households by next fall.</p>  <p>A government spokesperson&nbsp;told CBC News that Starlink projects aren't excluded from the plans&nbsp;and Canadians may apply for <a href="https://www.ic.gc.ca/eic/site/139.nsf/eng/h_00012.html"><u>funding</u></a> if certain criteria are met.</p>  <p>Rekounas in New Brunswick said he's heard from about five other local&nbsp;residents who received a link to take part in the beta testing. He expects many more will follow once the service is more widely available.</p>  <p>"Everybody's very excited," he said. "It's a game changer."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/technology/starlink-internet-beta-testing-in-canada-1.5831765</link>
            <guid isPermaLink="false">hacker-news-small-sites-25354122</guid>
            <pubDate>Wed, 09 Dec 2020 01:19:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Process a Moat in SaaS?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25353607">thread link</a>) | @Peteris
<br/>
December 8, 2020 | https://www.peteriserins.com/is-process-a-moat-in-saas/ | <a href="https://web.archive.org/web/*/https://www.peteriserins.com/is-process-a-moat-in-saas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
            <p>In <a href="https://www.saastr.com/whats-your-moat/">What's Your Moat</a>, Jason Lemkin lists several moats (sources of defensibility) that apply to SaaS businesses. I categorised them based on the <a href="https://www.amazon.com/7-Powers-Foundations-Business-Strategy-ebook/dp/B01MRLFFQ7">7 Powers</a> framework by Hamilton Helmer and found two powers missing (Cornered Resource and Process Power).</p><p>While Cornered Resources (such as a strong early team) are commonly considered doctrine rather than a moat, the omission of process power was more interesting.</p><h3 id="what-is-process-power">What is Process Power?</h3><p>Helmer describes companies with Process Power as follows:</p><blockquote>Benefit. A company with Process Power is able to improve product attributes and/or lower costs as a result of process improvements embedded within the organization. For example, Toyota has maintained the quality increases and cost reductions of the TPS over a span of decades; these assets do not disappear as new workers are brought in and older workers retire.<p>Barrier. The Barrier in Process Power is hysteresis: these process advances are difficult to replicate, and can only be achieved over a long time period of sustained evolutionary advance.</p></blockquote><p>He admits that process power is rare and difficult to achieve. But is it too rare to apply to SaaS companies?</p><p>On one hand, the path to growing a SaaS business is <a href="https://stripe.com/gb/atlas/guides/business-of-saas">well benchmarked</a> and there are processes describing anything from finding leads to deploying reliable infrastructure.</p><p>But there are companies that get very different results.</p><h3 id="the-process-outliers">The process outliers</h3><p><a href="https://ahrefs.com/">Ahrefs</a> is a popular SEO tool with a fifth of the engineering resources of their biggest competitor Moz. They <a href="https://ahrefs.com/blog/keywords-explorer-3-0/">claim to achieve this by using an OCaml based stack</a> also favoured by Wall Street traders <a href="https://www.janestreet.com/">Jane Street</a>.</p><p><a href="https://www.tinycapital.com/">Tiny</a> is a start-up conglomerate that uses several ideas like simple positioning and No Code to quickly spin up new businesses in record speed. They also run one of the leading design and development studios <a href="https://www.metalab.com/">Metalab</a>, and one of the earliest No Code agencies <a href="https://www.8020.inc/">8020</a>, ensuring excellence in both areas.</p><p>Does this mean that every SaaS company should use OCaml and Webflow or is there a way to create process advantages organically?</p><p>In an industry that speeds things up traditionally with investment, we have ignored frameworks that build process advantages in a capital-agnostic way.</p><h3 id="improving-process">Improving process</h3><p>I'll offer three examples.</p><p>The first is the Theory of Constraints, a framework introduced in <a href="https://www.amazon.co.uk/Goal-Process-Ongoing-Improvement/dp/0566086654">The Goal</a>. The Theory of Constraints predicts that every company is usually constrained by one bottleneck at a time, called a ‚Äúconstraint‚Äù and releasing that constraint is the key for increasing output.</p><p>Another theory, promoted by Douglas Engelbart is the <a href="https://www.dougengelbart.org/content/view/192/165/">ABCs of Organizational Improvement</a>. Engelbart argues that we should manage not only core activities (also known as ‚ÄúA activities‚Äù or ‚ÄúBusiness as usual‚Äù) but have explicit roadmaps for both B activities (‚Äúimproving how we do A‚Äù) and C activities (‚Äúimproving how we improve‚Äù). By focusing on process improvement explicitly, we can create compounding leverage for core activities.</p><p>A more modern example of continuous process improvement is described in the <a href="https://medium.com/quantumblack/the-protocol-series-how-formula-1-pitstop-teams-inspired-the-codification-of-our-ways-of-working-7b59b40a8fa1">Protocol Series</a> by QuantumBlack.</p><p>To summarise, having a great process is not the same as having great execution and we should not neglect that, even in SaaS.</p><hr><p><strong>P.S.</strong> Here is the categorization of the SaaS moats I went with. The high-level categories are from 7 Powers, the bullets are from Lemkin.</p><p>Counter-positioning</p><ul><li>‚ÄúNo Contract at all‚Äù easy on-boarding</li></ul><p>Network effects</p><ul><li>Data</li><li>Structured Data</li><li>Partners + Ecosystem</li><li>Agencies and Implementation Partners</li></ul><p>Switching costs</p><ul><li>Integrations</li><li>‚ÄúMost Enterprise‚Äù Vendor</li><li>Long Term Contracts</li></ul><p>Economies of scale</p><ul><li>Using massive amounts of capital to play in every segment</li></ul><p>Brand</p><ul><li>Brand</li></ul><p>Cornered resource</p><ul><li>???</li></ul><p>Process power</p><ul><li>???</li></ul>
    </div>
        
</article>                    
                </main>
</div>
        </div></div>]]>
            </description>
            <link>https://www.peteriserins.com/is-process-a-moat-in-saas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25353607</guid>
            <pubDate>Wed, 09 Dec 2020 00:22:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kite Power for Mauritius]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25353559">thread link</a>) | @usrusr
<br/>
December 8, 2020 | https://skysails-power.com/index.html?artikel=Kite-Power-For-Mauritius | <a href="https://web.archive.org/web/*/https://skysails-power.com/index.html?artikel=Kite-Power-For-Mauritius">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://skysails-power.com/index.html?artikel=Kite-Power-For-Mauritius</link>
            <guid isPermaLink="false">hacker-news-small-sites-25353559</guid>
            <pubDate>Wed, 09 Dec 2020 00:16:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Better Monolith (With WebAssembly)]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25353335">thread link</a>) | @cohix
<br/>
December 8, 2020 | https://blog.suborbital.dev/building-a-better-monolith | <a href="https://web.archive.org/web/*/https://blog.suborbital.dev/building-a-better-monolith">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><h2 id="the-monolith-gets-a-bad-rap">The monolith gets a bad rap</h2>
<p>When you hear that a company runs a monolith, you may think they're old-fashioned and they must have trouble scaling it, right? I'm here to tell you that <a target="_blank" href="https://m.signalvnoise.com/the-majestic-monolith/">some people</a> (myself included) think monoliths are awesome for a whole lot of teams. That said, technology has advanced, and I truly think it's time to revisit the monolith with a new approach.</p>
<p>If you're new to back-end development, a monolith is a server-side system that runs as one.... thing. It's a single program that starts up, serves some network requests, and then terminates. Alternatives to 'the monolith' include service-oriented architectures (SOA), microservices, serverless functions, and probably a few that I haven't heard of. Each of these approaches has their time and place, and I salute anyone who has made an educated decision to build a system with these patterns. I'm of the opinion that a large number of web applications and services would be well served by a monolith.... but with some upgrades.</p>
<h2 id="you-need-some-services-to-lighten-the-load">You need some services to lighten the load</h2>
<p>The reasoning behind the alternative design patterns is very sound. By distributing the work among many different ‚Äúthings‚Äù, you make the system as a whole able to handle more. It is well known that by doing so, you introduce more complexity, which requires more effort, and therefore often more people-power and more money. The one possible exception I can see is serverless functions, which do indeed simplify many things, but whose downsides comes in the form of more difficult testing, vendor dependence, or the need for non-commodity tooling. When done right, the extra effort can lead to a very capable system whose benefits are truly remarkable. The classic example is Netflix, and they‚Äôve done very well for themselves.</p>
<h2 id="finding-a-middle-ground">Finding a middle ground</h2>
<p>If monoliths are hard to scale and microservices are too complex, then how do you design a system that can scale with your traffic and your development team without becoming a pain to operate, maintain and expand its functionality? Over the past few years, it has become clear that a middle-ground is needed. I don‚Äôt expect this solution to work for everyone, but most products aren‚Äôt serving the kind of traffic that <strong>really</strong> makes the microservice effort worth it.</p>
<h2 id="enter-the-sufa-design-pattern">Enter the SUFA design pattern</h2>
<p>Before getting into the core of what SUFA is, I want to mention that this is not an entirely new way of thinking. Things like the actor pattern, the <a target="_blank" href="https://inconshreveable.com/10-07-2015/the-neomonolith/">Neomonolith</a>, and others have stipulated some similar ideas over the years, and SUFA is just one way of combining several concepts into one straightforward design pattern. So, what is it?</p>
<p><strong>Simple, Unified, Function-based Applications.</strong></p>
<p>Let‚Äôs break that down:</p>
<h3 id="simple">Simple</h3>
<p>A system designed with SUFA can be run in the simplest of deployment scenarios. Auto-scaling groups have existed for a long time, and they‚Äôre made even easier by container orchestration systems. A SUFA system can be run on one ASG, or can be expanded with a service mesh to allow for capability groups (which we‚Äôll talk about in a future post).</p>
<h3 id="unified">Unified</h3>
<p>Rather than multiple services who each exist as something to be deployed, SUFA systems exist as one single deployable. This can be a Docker image, an AMI, or some other artifact, but there is only one <strong>thing</strong> that needs to be built. It should be built by CI/CD on a continuous or tagged release cadence, and it should be made available in an artifact registry such as a Docker registry or S3 bucket. </p>
<h3 id="function-based">Function-based</h3>
<p>A standard monolith probably includes a handler layer which is responsible for taking API requests and making calls to a business logic or data storage layer to handle those requests. SUFA systems instead handle requests by chaining together a series of functions, each completely independent and unaware of one another. Functions should expect a particular input, perform some operations, and produce an output to be passed into functions further down the chain. Functions should be easily testable and reusable across different scenarios (such as for different API requests). SUFA systems should also be designed to consume and produce event-based traffic as a primary method of communication.</p>
<h3 id="applications">Applications</h3>
<p>Well this seems like it should be straightforward, but in SUFA design, ‚ÄúApplication‚Äù has a very particular meaning. A SUFA system should serve one single application, meaning that it should encompass all of the capabilities needed for a fully formed product. This can be up for some interpretation (such as whether a company should have one SUFA for their whole business, even if they have distinct product areas), but the point is to avoid having multiple ‚Äúthings‚Äù serving one application. If functionality needs to be shared across multiple applications, the functions comprising the SUFA system should be easily reusable and composed for other purposes. </p>
<p>You'll notice that this is all very technology-agnostic and vendor-agnostic. SUFA is meant to span across languages, cloud vendors, and deployment environments. SUFA is a way of designing your server-side system such that it is testable, scalable, and secure. You'll notice I haven't touched on scalability yet, so let's discuss that</p>
<h2 id="sufa-at-scale">SUFA at scale</h2>
<p>The critical factor that allows a SUFA system to scale is that it is composed of independent functions. SUFA systems should rely on an underlying framework to orchestrate the execution of these functions such that it can scale effectively. By using a function runner or job scheduler to run the required functions, a SUFA framework abstracts away <em>how</em> the functions are executed, and the programmer writing the code only needs to indicate which functions to run, and in what order.</p>
<p>Additional scalability is provided by <strong>capability groups</strong> and <strong>meshing</strong>, which I plan on writing follow-up posts for, as they deserve to be explored at length.</p>
<h2 id="suborbital-atmo">Suborbital Atmo</h2>
<p>The SUFA pattern was designed in concert with <a target="_blank" href="https://github.com/suborbital/atmo">Atmo</a>, which is an all-in-one framework upon which SUFA systems can be built. Atmo uses a file known as a 'Directive' to describe all aspects of your application, including how to chain functions to handle requests. You can write your functions using several languages to be run atop Atmo, as it is built to use WebAssembly modules as the unit of compute. Atmo will automatically scale out to handle your application load, and includes all sorts of tooling and built-in best practices to ensure you're getting the best performance and security without needing to write a single line of boilerplate ever again.</p>
<p>The awesome capabilities of WebAssembly and the design thinking behind SUFA are being harnessed by the open source <a target="_blank" href="https://suborbital.dev/">Suborbital Development Platform</a> to introduce a new way to build your web applications. I've been working for over a year to realize this goal, and I'm extremely happy with the results thus far. Riding the wave of new technologies and practices such as JAMStack and edge computing means that we have a opportunity to bring the best of the old and the new to the next generation of software makers to do incredible things. I hope you'll come and join me!</p>
<p>Please reach out on Twitter (<a target="_blank" href="https://twitter.com/cohix">@cohix</a> or <a target="_blank" href="https://twitter.com/suborbitaldev">@SuborbitalDev</a> if you'd like to talk about SUFA design or the Suborbital project!</p>
</div></div>]]>
            </description>
            <link>https://blog.suborbital.dev/building-a-better-monolith</link>
            <guid isPermaLink="false">hacker-news-small-sites-25353335</guid>
            <pubDate>Tue, 08 Dec 2020 23:52:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Watermark Video Utility ‚Äì upload a video and add your logo]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25353156">thread link</a>) | @200_OK
<br/>
December 8, 2020 | https://shotstack.io/demo/watermarker/ | <a href="https://web.archive.org/web/*/https://shotstack.io/demo/watermarker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <h3>About the video watermark demo</h3>
                <p>
                    This demo application shows how you can build an interface to apply a watermark to a video using the
                    <a href="https://shotstack.io/">Shotstack</a> cloud video editing API. The form prepares the video, 
                    watermark and watermark settings and posts the required parameters to the Shotstack API which takes
                    care of rendering the video.
                </p>
                <p>
                    This demo is provided as 
                    <a href="https://github.com/shotstack/watermark-demo" target="_blank">open source</a> code so you 
                    can use it as is, adapt it to your own needs or use it as the basis to build a fully automated 
                    video watermark application that can apply a watermark to 1000's of videos as part of an automated
                    workflow. Our <a href="https://shotstack.io/learn/add-watermarks-to-your-videos-using-code/">How to watermark video tutorial</a>
                    also provides more information.
                </p>
            </div>
        </div></div>]]>
            </description>
            <link>https://shotstack.io/demo/watermarker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25353156</guid>
            <pubDate>Tue, 08 Dec 2020 23:39:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a scalable e-commerce data model]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25353148">thread link</a>) | @robric
<br/>
December 8, 2020 | https://resources.fabric.inc/blog/ecommerce-data-model | <a href="https://web.archive.org/web/*/https://resources.fabric.inc/blog/ecommerce-data-model">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div data-widget-type="cell" data-x="0" data-w="12">

<div>
<div>
<div data-widget-type="custom_widget" data-x="0" data-w="12">
<div id="hs_cos_wrapper_module_151388194052436" data-hs-cos-general-type="widget" data-hs-cos-type="module">
    
<div>
<div>
<div>

 
<div>
<p><img width="100" height="100" alt="James Hickey" src="https://resources.fabric.inc/hs-fs/hubfs/james-hickey.jpeg?width=100&amp;height=100&amp;name=james-hickey.jpeg" srcset="https://resources.fabric.inc/hs-fs/hubfs/james-hickey.jpeg?width=50&amp;height=50&amp;name=james-hickey.jpeg 50w, https://resources.fabric.inc/hs-fs/hubfs/james-hickey.jpeg?width=100&amp;height=100&amp;name=james-hickey.jpeg 100w, https://resources.fabric.inc/hs-fs/hubfs/james-hickey.jpeg?width=150&amp;height=150&amp;name=james-hickey.jpeg 150w, https://resources.fabric.inc/hs-fs/hubfs/james-hickey.jpeg?width=200&amp;height=200&amp;name=james-hickey.jpeg 200w, https://resources.fabric.inc/hs-fs/hubfs/james-hickey.jpeg?width=250&amp;height=250&amp;name=james-hickey.jpeg 250w, https://resources.fabric.inc/hs-fs/hubfs/james-hickey.jpeg?width=300&amp;height=300&amp;name=james-hickey.jpeg 300w" sizes="(max-width: 100px) 100vw, 100px"> 
</p>
<div>
<p id="hubspot-author_data" data-hubspot-form-id="author_data" data-hubspot-name="Blog Author">
James Hickey
</p>
<p> December 08</p><p> &nbsp; ‚Ä¢ &nbsp;</p>
<p>
7 minute read
</p>
</div>
</div>
</div>
<p><img src="https://resources.fabric.inc/hubfs/ecommerce-data-model.png" alt="ecommerce data model">
</p>
<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>If selling products online is a core part of your business, then you need to build an e-commerce data model that‚Äôs scalable, flexible, and fast. Most off-the-shelf providers like Shopify and BigCommerce are built for small stores selling a few million dollars in orders per month, so many e-commerce retailers working at scale start to investigate creating a bespoke solution.</p>
<!--more-->
<p>This article will look at what it takes to start building this infrastructure on your own. What are some of the areas to consider? What might the data model look like? How much work is involved?</p>
<p>Along the way, we‚Äôll explore an alternative: API-based commerce platforms that manage data for you across product catalogs, pricing, and orders‚Äîwithout locking you into a monolith, and without requiring you to replatform.</p>
<p><em><strong>Note:</strong> A full summary diagram of the e-commerce data model is at the end of the article.</em></p>

<h2 id="who-are-your-customers-">Who Are Your Customers?</h2>
<p>First, you need to consider <em>who</em> will be purchasing items from your e-commerce application. How might you model customer information in a database as a result? You‚Äôll probably want to have basic information like your customer's name, email address, etc. Do you want your customers to be able to create a profile in your system? Or just fill out a form each time they want to purchase something?</p>
<p>Just starting out, a basic model might look like this:</p>
<p><img src="https://resources.fabric.inc/hs-fs/hubfs/Basic%20e-commerce%20customer%20data%20model.png?width=308&amp;name=Basic%20e-commerce%20customer%20data%20model.png" alt="Basic e-commerce customer data model" width="308" srcset="https://resources.fabric.inc/hs-fs/hubfs/Basic%20e-commerce%20customer%20data%20model.png?width=154&amp;name=Basic%20e-commerce%20customer%20data%20model.png 154w, https://resources.fabric.inc/hs-fs/hubfs/Basic%20e-commerce%20customer%20data%20model.png?width=308&amp;name=Basic%20e-commerce%20customer%20data%20model.png 308w, https://resources.fabric.inc/hs-fs/hubfs/Basic%20e-commerce%20customer%20data%20model.png?width=462&amp;name=Basic%20e-commerce%20customer%20data%20model.png 462w, https://resources.fabric.inc/hs-fs/hubfs/Basic%20e-commerce%20customer%20data%20model.png?width=616&amp;name=Basic%20e-commerce%20customer%20data%20model.png 616w, https://resources.fabric.inc/hs-fs/hubfs/Basic%20e-commerce%20customer%20data%20model.png?width=770&amp;name=Basic%20e-commerce%20customer%20data%20model.png 770w, https://resources.fabric.inc/hs-fs/hubfs/Basic%20e-commerce%20customer%20data%20model.png?width=924&amp;name=Basic%20e-commerce%20customer%20data%20model.png 924w" sizes="(max-width: 308px) 100vw, 308px"></p>
<p>If you want your customers to have a persistent profile, then you need to build some way for them to log in to your application. Moving forward with more real-world requirements, you might also want to keep track of their login attempt history and password history.</p>
<p><img src="https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20customer%20data%20model.png?width=891&amp;name=More%20complex%20e-commerce%20customer%20data%20model.png" alt="More complex e-commerce customer data model" width="891" srcset="https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20customer%20data%20model.png?width=446&amp;name=More%20complex%20e-commerce%20customer%20data%20model.png 446w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20customer%20data%20model.png?width=891&amp;name=More%20complex%20e-commerce%20customer%20data%20model.png 891w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20customer%20data%20model.png?width=1337&amp;name=More%20complex%20e-commerce%20customer%20data%20model.png 1337w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20customer%20data%20model.png?width=1782&amp;name=More%20complex%20e-commerce%20customer%20data%20model.png 1782w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20customer%20data%20model.png?width=2228&amp;name=More%20complex%20e-commerce%20customer%20data%20model.png 2228w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20customer%20data%20model.png?width=2673&amp;name=More%20complex%20e-commerce%20customer%20data%20model.png 2673w" sizes="(max-width: 891px) 100vw, 891px"></p>
<p>You might also want to consider whether your customers are part of a large organization; and, if so, how would they like to handle password resets? Do they need single sign-on or OAuth support?</p>
<h4 id="deep-dive-addresses">Deep Dive: Addresses</h4>
<p>Did you notice there‚Äôs no address tied to a customer in any of the data models shown so far? It might be your first inclination to include a customer‚Äôs address as part of those models. However, most customers will have multiple addresses and multiple <em>kinds</em> of addresses, like billing and shipping. B2B retailers might also have to consider multiple delivery locations based on the number of warehouses and offices they support.</p>
<p>What happens if the billing and shipping address are different? Well, you‚Äôll need to do more than just add extra columns to the <code>Customer</code> table! It‚Äôs not that simple.</p>
<p>So how <em>does</em> storing a billing address affect the scalability of your application?</p>
<p>If you were to split the payment and shipping areas into separate (micro)services each having their own database, then putting billing and payment addresses into the <code>Customer</code> area would lead to having ‚Äúchatty‚Äù services. This is a <a href="https://docs.aws.amazon.com/whitepapers/latest/microservices-on-aws/chattiness.html" rel="noopener" target="_blank">well-known <em>design smell</em> when building microservices</a>.</p>
<p>To avoid this issue, you‚Äôre better off putting the addresses within the appropriate area/service that requires them, but with that, your data model becomes more complex.</p>
<p>One way to avoid much of this complexity is to consider an <a href="https://resources.fabric.inc/glossary/oms-software" rel="noopener">order management system (OMS)</a> by an API-first software provider. With this software, you can integrate the OMS into your data model without spending months of engineering time.</p>

<h2 id="how-do-you-organize-products-and-catalog-">How Do You Organize Products And Catalog?</h2>
<p>The first thing you see when you enter a store (either in-person or digitally) are products ready for you to purchase, and usually displayed with some thought for how you might be likely to shop.</p>
<p>For an e-commerce web application, you will probably want to highlight things like:</p>
<ul>
<li>Best selling products</li>
<li>Trending products</li>
<li>New products</li>
<li>The ability to browse products by search criteria</li>
</ul>
<p>Providing customers with that information means you first need to keep track of a lot of data about your products: their prices, historical purchase data, and so on.</p>
<p>Let‚Äôs see what a ‚Äúfirst shot‚Äù at creating a data model for a product catalog might look like:</p>
<p><img src="https://resources.fabric.inc/hs-fs/hubfs/Simple%20e-commerce%20product%20data%20model.png?width=562&amp;name=Simple%20e-commerce%20product%20data%20model.png" alt="Simple e-commerce product data model" width="562" srcset="https://resources.fabric.inc/hs-fs/hubfs/Simple%20e-commerce%20product%20data%20model.png?width=281&amp;name=Simple%20e-commerce%20product%20data%20model.png 281w, https://resources.fabric.inc/hs-fs/hubfs/Simple%20e-commerce%20product%20data%20model.png?width=562&amp;name=Simple%20e-commerce%20product%20data%20model.png 562w, https://resources.fabric.inc/hs-fs/hubfs/Simple%20e-commerce%20product%20data%20model.png?width=843&amp;name=Simple%20e-commerce%20product%20data%20model.png 843w, https://resources.fabric.inc/hs-fs/hubfs/Simple%20e-commerce%20product%20data%20model.png?width=1124&amp;name=Simple%20e-commerce%20product%20data%20model.png 1124w, https://resources.fabric.inc/hs-fs/hubfs/Simple%20e-commerce%20product%20data%20model.png?width=1405&amp;name=Simple%20e-commerce%20product%20data%20model.png 1405w, https://resources.fabric.inc/hs-fs/hubfs/Simple%20e-commerce%20product%20data%20model.png?width=1686&amp;name=Simple%20e-commerce%20product%20data%20model.png 1686w" sizes="(max-width: 562px) 100vw, 562px"></p>
<p>Here‚Äôs a <code>Product</code> table with some basic information, like a product‚Äôs name, SKU, and price. The product is also linked to another table representing various categories that product is associated with. You might also strategically add indexes and full-text search to the <code>Product</code> table to enable site visitors to efficiently search for various products.</p>
<p>This is a decent first attempt. However, to get an even more realistic and useful e-commerce product catalog, you‚Äôll need to support more requirements such as:</p>
<ul>
<li>Tracking pricing history so site administrators can analyze trends in product pricing</li>
<li>Supporting related products to display on a product‚Äôs page</li>
<li>Incorporating product vendors so customers can view all products sold by an individual vendor/company</li>
</ul>
<p>To address those extra requirements, you might end up with the following data model:</p>
<p><img src="https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20product%20data%20model.png?width=816&amp;name=More%20complex%20e-commerce%20product%20data%20model.png" alt="More complex e-commerce product data model" width="816" srcset="https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20product%20data%20model.png?width=408&amp;name=More%20complex%20e-commerce%20product%20data%20model.png 408w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20product%20data%20model.png?width=816&amp;name=More%20complex%20e-commerce%20product%20data%20model.png 816w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20product%20data%20model.png?width=1224&amp;name=More%20complex%20e-commerce%20product%20data%20model.png 1224w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20product%20data%20model.png?width=1632&amp;name=More%20complex%20e-commerce%20product%20data%20model.png 1632w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20product%20data%20model.png?width=2040&amp;name=More%20complex%20e-commerce%20product%20data%20model.png 2040w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20product%20data%20model.png?width=2448&amp;name=More%20complex%20e-commerce%20product%20data%20model.png 2448w" sizes="(max-width: 816px) 100vw, 816px"></p>
<p>This model still isn‚Äôt perfect as it embeds your prices into the product itself, but at least it lets you maintain a previous pricing history.</p>
<p>Another option is to integrate your e-commerce store with a <a href="https://resources.fabric.inc/glossary/promotions-engine" rel="noopener">pricing and promotions engine</a> from an API-first software provider that handles pricing for you. This will let you roll out different prices to different users based on their intent, location, cart, or order history.</p>
<h4 id="deep-dive-pricing">Deep Dive: Pricing</h4>
<p>While the more complex product data model still has a product‚Äôs price in the same table, this may not be the best thing to do in a real large-scale application.</p>
<p>Consider that your organization has various departments, such as inventory/warehousing, sales, marketing, customer support, etc. You might have dedicated systems that allow merchandisers to change the price of an item since they are the experts in determining how much a product should sell for. Similar to the considerations with a customer‚Äôs billing and shipping addresses, this would lead to cross-boundary/service communication if we left the price in the core <code>Product</code> table.</p>
<p>Therefore, you might want to store product prices under the data stores that the sales department owns. But don‚Äôt forget, there are many different kinds of ‚Äúprices‚Äù that haven‚Äôt been taken into consideration yet, including:</p>
<ul>
<li>Price (cost) when purchasing stock from vendors</li>
<li>Customer sale price</li>
<li>Discounted sale prices</li>
<li>Manufacturer‚Äôs suggested retail price</li>
</ul>
<p>Handling all these in context of your organizational structure would require even more exploration and complexity in your data model. While your engineering team could likely accomplish this task, it‚Äôs going to take time. Using ready-made solutions can shave weeks or months off your e-commerce data modeling timeline.</p>

<h2 id="how-do-you-streamline-orders-">How Do You Streamline Orders?</h2>
<p>Now that you have customers in your database and products available to purchase, you‚Äôll need to think about how to design the order-taking process and data model.</p>
<p>The process of placing an order might look something like this:</p>
<ol>
<li>A customer places products into their cart while browsing.</li>
<li>The customer decides they want to purchase the products that are in their cart.</li>
<li>They proceed to purchase the order.</li>
<li>The customer gets an emailed receipt or confirmation number.</li>
</ol>
<p>However, it‚Äôs rarely so simple. Placing orders can be deceptively tricky as there are many moving parts:</p>
<ul>
<li>Products</li>
<li>An active cart</li>
<li>Cart converted into an order</li>
<li>A finalized order with confirmation</li>
</ul>
<p>If you were to look at a simple data model for an order placement, it might look something like this:</p>
<p><img src="https://resources.fabric.inc/hs-fs/hubfs/Orders%20data%20model.png?width=837&amp;name=Orders%20data%20model.png" alt="Orders data model" width="837" srcset="https://resources.fabric.inc/hs-fs/hubfs/Orders%20data%20model.png?width=419&amp;name=Orders%20data%20model.png 419w, https://resources.fabric.inc/hs-fs/hubfs/Orders%20data%20model.png?width=837&amp;name=Orders%20data%20model.png 837w, https://resources.fabric.inc/hs-fs/hubfs/Orders%20data%20model.png?width=1256&amp;name=Orders%20data%20model.png 1256w, https://resources.fabric.inc/hs-fs/hubfs/Orders%20data%20model.png?width=1674&amp;name=Orders%20data%20model.png 1674w, https://resources.fabric.inc/hs-fs/hubfs/Orders%20data%20model.png?width=2093&amp;name=Orders%20data%20model.png 2093w, https://resources.fabric.inc/hs-fs/hubfs/Orders%20data%20model.png?width=2511&amp;name=Orders%20data%20model.png 2511w" sizes="(max-width: 837px) 100vw, 837px"></p>
<p>Notice that each row in the <code>ShoppingCartItem</code> table contains the ‚Äúcaptured‚Äù price of the product. When the customer puts an item into their shopping cart should the price at that moment be ‚Äúlocked-in‚Äù? If so, for how long?</p>
<p><em><span>Note:</span> How the price functions is a business requirement that would need to be discussed with your product owners, and so on, as mentioned in the "Deep Dive: Pricing" section earlier.</em></p>
<p>The same question applies to an unpaid order. If a customer has ordered a discounted item, should they be able to keep the promise of that discounted price forever until they pay? Or does it expire?</p>
<p>Other questions to consider for an orders data model might include:</p>
<ul>
<li>Are you tracking analytics on orders?</li>
<li>What happens if a customer returns a defective item?</li>
<li>Should you handle shipping within the same data model or have a dedicated shipping context/schema?</li>
</ul>
<p>With some of these concerns in mind, you might end up with a data model that looks more like this:</p>
<p><img src="https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20orders%20data%20model.png?width=1112&amp;name=More%20complex%20orders%20data%20model.png" alt="More complex orders data model" width="1112" srcset="https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20orders%20data%20model.png?width=556&amp;name=More%20complex%20orders%20data%20model.png 556w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20orders%20data%20model.png?width=1112&amp;name=More%20complex%20orders%20data%20model.png 1112w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20orders%20data%20model.png?width=1668&amp;name=More%20complex%20orders%20data%20model.png 1668w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20orders%20data%20model.png?width=2224&amp;name=More%20complex%20orders%20data%20model.png 2224w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20orders%20data%20model.png?width=2780&amp;name=More%20complex%20orders%20data%20model.png 2780w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20orders%20data%20model.png?width=3336&amp;name=More%20complex%20orders%20data%20model.png 3336w" sizes="(max-width: 1112px) 100vw, 1112px"></p>
<p>Some things to take note of in this more complex orders model:</p>
<ul>
<li><code>ShoppingCartItem</code> now supports an expiration date for a locked-in price.</li>
<li><code>ShoppingCartHistory</code> tracks when items are added, removed, etc.</li>
<li>An order item may be returned (this still does not handle cases where 1 out of X items of the same product are returned).</li>
<li>An order may have multiple shipments (eg, how Amazon will sometimes split an order up into multiple packages/shipments).</li>
</ul>
<p>This article also hasn‚Äôt even touched the surface of using alternative data storage methods like JSON documents or event sourcing!</p>

<h2 id="conclusion">Conclusion</h2>
<p>To help you see how all the pieces fit together, here are all the diagrams shown together. I‚Äôve removed a number of links/lines to the <code>Customer</code> table to increase readability:</p>
<p><img src="https://resources.fabric.inc/hs-fs/hubfs/Summary%20e-commerce%20data%20model.png?width=1396&amp;name=Summary%20e-commerce%20data%20model.png" alt="Summary e-commerce data model" width="1396" srcset="https://resources.fabric.inc/hs-fs/hubfs/Summary%20e-commerce%20data%20model.png?width=698&amp;name=Summary%20e-commerce%20data%20model.png 698w, https://resources.fabric.inc/hs-fs/hubfs/Summary%20e-commerce%20data%20model.png?width=1396&amp;name=Summary%20e-commerce%20data%20model.png 1396w, https://resources.fabric.inc/hs-fs/hubfs/Summary%20e-commerce%20data%20model.png?width=2094&amp;name=Summary%20e-commerce%20data%20model.png 2094w, https://resources.fabric.inc/hs-fs/hubfs/Summary%20e-commerce%20data%20model.png?width=2792&amp;name=Summary%20e-commerce%20data%20model.png 2792w, https://resources.fabric.inc/hs-fs/hubfs/Summary%20e-commerce%20data%20model.png?width=3490&amp;name=Summary%20e-commerce%20data%20model.png 3490w, https://resources.fabric.inc/hs-fs/hubfs/Summary%20e-commerce%20data%20model.png?width=4188&amp;name=Summary%20e-commerce%20data%20model.png 4188w" sizes="(max-width: 1396px) 100vw, 1396px"></p>
<p>As I mentioned above, this article still doesn‚Äôt even cover many of the basics like payment processing and invoicing. Beyond the features covered here, you might eventually require more advanced features like:</p>
<ul>
<li>Coupon codes</li>
<li>Taxes</li>
<li>Third-party integrations with OAuth providers, other retailers, or partners</li>
<li>Shipment tracking notifications</li>
</ul>
<p>Building a data model for an e-commerce application, as you can see, is not so simple. What looks up front to be a straightforward set of database tables is not so simple once you dig into real-world requirements.</p>
<h4 id="there-s-another-way">There‚Äôs Another Way</h4>
<p>What if you could have more of these abilities out-of-the-box?</p>
<p><a href="https://fabric.inc/solutions">Fabric</a> is an all-in-one commerce platform that helps you do everything this article talked about, like manage customers, orders, and shipments. Most importantly, it is a microservices-based and API-first platform. This means you can choose the services you need and integrate them ‚Ä¶</p></span></p></div></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://resources.fabric.inc/blog/ecommerce-data-model">https://resources.fabric.inc/blog/ecommerce-data-model</a></em></p>]]>
            </description>
            <link>https://resources.fabric.inc/blog/ecommerce-data-model</link>
            <guid isPermaLink="false">hacker-news-small-sites-25353148</guid>
            <pubDate>Tue, 08 Dec 2020 23:38:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What remote YC demo day looked like]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25353088">thread link</a>) | @cheeseblubber
<br/>
December 8, 2020 | https://papercups.io/blog/what-remote-demo-day-looked-like | <a href="https://web.archive.org/web/*/https://papercups.io/blog/what-remote-demo-day-looked-like">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://papercups.io/blog/what-remote-demo-day-looked-like</link>
            <guid isPermaLink="false">hacker-news-small-sites-25353088</guid>
            <pubDate>Tue, 08 Dec 2020 23:33:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Developer? Do Code Reviews]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25352728">thread link</a>) | @_elergy_
<br/>
December 8, 2020 | https://evgenii.info/new-developer-do-code-reviews/ | <a href="https://web.archive.org/web/*/https://evgenii.info/new-developer-do-code-reviews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://evgenii.info/content/images/size/w300/2020/12/code-review-beginner.jpg 300w,
                            https://evgenii.info/content/images/size/w600/2020/12/code-review-beginner.jpg 600w,
                            https://evgenii.info/content/images/size/w1000/2020/12/code-review-beginner.jpg 1000w,
                            https://evgenii.info/content/images/size/w2000/2020/12/code-review-beginner.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://evgenii.info/content/images/size/w2000/2020/12/code-review-beginner.jpg" alt="New to the Project? Do Code Reviews!">
            </figure>

            <section>
                <div>
                    <p>I put it straight ‚Äì you do not need to have any prior knowledge about the codebase to start doing code reviews.</p><p>This article is going to be about why all new developers should review code, and how to get the most out of it. If you do not need any convincing or guidance, you may rather watch <a href="https://www.instagram.com/p/BwAa3I-hjkI/"><u>how I win a fight with my cat</u></a>.</p><blockquote>"New developers" in this context are not only people who have just started a career but also experienced developers working with the unfamiliar codebase.</blockquote><h2 id="benefits-of-doing-code-reviews">Benefits of doing code reviews</h2><p>First of all, it is going to speed up your onboarding. Right now, your learning is limited by the number of tasks you are directly involved in ‚Äî you learn from your own successes and mistakes.</p><p>Reviewing other solutions is a quick way to get around this limit. You can get to know various parts of code without touching them personally and see what works and what does not for different types of problems.</p><p>On the other hand, your feedback will be beneficial to the team because you have a crucial trait that no one else has ‚Äî fresh eyes with no prior context. <br>As writers cannot edit their own texts, programmers rarely can judge their code. We know too much about why it is written this way, and the more people share the same understanding, the harder it is to have an unbiased opinion. While you have limited knowledge, you are the only person who can give a fresh view and challenge what others take for granted.</p><h2 id="how-to-approach-code-reviews">How to approach code reviews</h2><h3 id="1-do-not-be-afraid">1. Do not be afraid</h3><p>All teams I worked with had a high demand for code reviews, which is quite common in the industry. Therefore, do not be afraid of starting ‚Äî nobody will mind having one more pair of eyes available.</p><p>It is quite common to fear not catching a bug or merging code that would need some improvements. A workaround is simple ‚Äî do not approve a pull request if you are not sure. Leave your comments, ask questions, and ping somebody else for a final verdict.</p><h3 id="2-understand-the-problem">2. Understand the problem</h3><p>Before looking closely at the code, familiarize yourself with the problem:</p><ul><li>What is the definition of done? </li><li>Is it complete? </li><li>Would you add anything else? </li><li>How would you test it?</li></ul><p>Think about all possible use-cases the author may need to implement. Then, either remember them or write them down ‚Äî this is going to be handy soon.</p><h3 id="3-draft-your-own-solution">3. Draft your own solution</h3><p>Remember, we are not reading code yet :-)</p><p>To get the most from this learning opportunity, think about how you would approach this task:</p><ul><li>How to structure data?</li><li>Where to put logic?</li><li>Is there anything in the codebase you should reuse? If unknown, how would you search for it?</li><li>Who is more knowledgeable in this area to advise you if you were the one picking this task?</li></ul><p>Once again, write it down or keep in your memory ‚Äî up to you.</p><h3 id="4-prove-that-the-problem-is-solved-fully">4. Prove that the problem is solved fully</h3><p>Now it is the time to start looking at implementation but only at a high-level. Focus on <em>what</em> rather than <em>how</em>.</p><p>Sometimes, clear and correct code does a wrong job:</p><ul><li>An author may misread or misinterpret requirements</li><li>They may implement some parts and forget the others</li></ul><p>Look at the list of possible use-cases you prepared earlier:</p><ul><li>Are all of them handled? <br>If not, ask whether they need to be ‚Äî it is safe to assume that you are the one who misunderstood the problem.</li><li>Are there any cases you did not consider? <br>If the author implemented something you did not even think about, it is excellent ‚Äî you already learned something new!</li></ul><h3 id="5-compare-your-solution-with-the-pull-request-">5. Compare your solution with the pull request.</h3><p>Now you know how you would approach this problem, but how did the author solve it?</p><p>Find differences between both approaches and try to understand the pros and cons of each. The best way to do it is to ask questions:</p><ul><li>Why was it preferred to put X and Y to the same database table, rather than keeping them separately?</li><li>Why was the primary logic put to module A, while module B has similar pieces that might be collocated?</li></ul><p>This way is how you learn the most ‚Äî not by reading the code and checking it for correctness, but by exercising your skills and validating proposed solutions.</p><h3 id="6-ask-questions-about-code-">6. Ask questions about code.</h3><p>When you get the answers to all high-level questions, it is time to zoom in and look deeply at code:</p><ul><li>Is it easy to understand or something needs further clarification? <br>Questions from new developers often mean that the code is not as self-explanatory as it could be. The author may consider adding comments or restructuring obscure fragments.</li><li>Are there ways to improve the code? <br>Even though you're new to the project, you can read and write code, right? Leave a suggestion when you see a room for improvement ‚Äî after all, it can only help.</li></ul><p>People frequently ask where is that line between giving useful comments and nitpicking. Is it appropriate to ask to rename a variable or to chase a negligible performance improvement?</p><p>As for me, everything is alright as soon as you communicate what is essential and what is not. I always prefix minor comments with the words 'minor' or 'nit', so the author knows which are ok to ignore.</p><h3 id="come-back-later">Come back later</h3><p>If the pull request was not immediately merged ‚Äî make sure you check it for new comments later.</p><p>Someone may reject it despite your approval; someone may add fruitful comments ‚Äî this is just another piece of context that is never superfluous.</p><hr><p>As always, you can <a href="https://evgenii.info/new-developer-do-code-reviews#subscribe"><u>subscribe to Resilient Systems</u></a> and receive new articles by email if you haven't done it yet. <br>You also can <a href="https://twitter.com/_elergy_"><u>find me on Twitter</u></a> or somewhere else ‚Äì I am always happy to chat :-) </p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Resilient Systems</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://evgenii.info/new-developer-do-code-reviews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25352728</guid>
            <pubDate>Tue, 08 Dec 2020 23:00:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Working with Unikernel Volumes in Nanos]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25352718">thread link</a>) | @eyberg
<br/>
December 8, 2020 | https://nanovms.com/dev/tutorials/working-with-unikernel-volumes-in-nanos | <a href="https://web.archive.org/web/*/https://nanovms.com/dev/tutorials/working-with-unikernel-volumes-in-nanos">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    <p>Today's article is about working with external volumes for your
unikernel instance. Many applications won't use this feature but there
are also situations where this makes sense.</p>

<p>The most obvious time when you would want to attach a volume to your
unikernel instance is when you are working with a database. Your
database image probably doesn't change that much but many databases can
grow very large and it makes no sense to keep the same data volume in
your base image.</p>

<p>The second use-case is when you have a base image, say a webserver,
and you want to package additional files or configuation as a build
step. For instance some companies will rotate certificates every few
hours in the day to protect access to various services and this rotation
is usually done out-of-band of deploys. Now unikernel deploys for small
webservers are typically fairly fast but the ability to put your
configuration on a separate partition and re-mount the volume on the fly
every few hours is definitely enticing.</p>

<p>Ok, let's start with the code. For this example we have a simple
little go webserver that implements a root filesystem filewalker. We've
declared that there is a separate partition called 'mnt' in the code but
it is non-existent right now.</p>

<pre><code>import (
  "fmt"
  "io/ioutil"
  "net/http"
  "os"
  "path/filepath"
)

func printDir() {
  err := filepath.Walk("/",
    func(path string, info os.FileInfo, err error) error {
      if err != nil {
        return err
      }
      fmt.Println(path, info.Size())
      return nil
    })
  if err != nil {
    fmt.Println(err)
  }
}

func main() {
  printDir()

  b, err := ioutil.ReadFile("/mnt/bob.txt")
  if err != nil {
    fmt.Println(err)
  }

  fmt.Println(string(b))

  http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
    printDir()

    b, err := ioutil.ReadFile("/mnt/bob.txt")
    if err != nil {
      fmt.Println(err)
    }

    fmt.Println(string(b))
    fmt.Fprintf(w, "Welcome to my website!")
  })

  fs := http.FileServer(http.Dir("static/"))
  http.Handle("/static/", http.StripPrefix("/static/", fs))

  go func() {
    err = http.ListenAndServe(":80", nil)
    if err != nil {
      fmt.Println(err)
    }
  }()

  http.ListenAndServe(":8080", nil)
}
</code></pre><p>

If you run it locally you should see something like this:
</p><pre><code>‚ûú  g2 ops run -p 8080 g2
booting /Users/eyberg/.ops/images/g2.img ...
assigned: 10.0.2.15
/ 0
/dev 0
/dev/null 0
/dev/urandom 0
/etc 0
/etc/passwd 33
/etc/resolv.conf 18
/etc/ssl 0
/etc/ssl/certs 0
/etc/ssl/certs/ca-certificates.crt 207436
/g2 7533614
/lib 0
/lib/x86_64-linux-gnu 0
/lib/x86_64-linux-gnu/libnss_dns.so.2 26936
/proc 0
/proc/self 0
/proc/self/exe 0
/proc/self/maps 0
/proc/sys 0
/proc/sys/kernel 0
/proc/sys/kernel/hostname 7
/sys 0
/sys/devices 0
/sys/devices/system 0
/sys/devices/system/cpu 0
/sys/devices/system/cpu/cpu0 0
/sys/devices/system/cpu/online 0
open /mnt/bob.txt: no such file or directory
</code></pre>

<h3>Creating a Volume</h3>

<p>Let's create a simple volume with one file in it - bob.txt.</p>

<pre><code>mkdir mnt
echo "Hi - I'm a text file" &gt; mnt/bob.txt
‚ûú  g2 ops volume create mnt -d mnt
2020/12/08 11:12:35 volume: mnt created with UUID 04c56e4a-5b8b-512c-eaa3-b82b4cd46d9e and label mnt
</code></pre><p>

You'll see that we can now see it in our local volume store:

</p><pre><code>‚ûú  g2 ops volume list
+--------------------------------------+------+--------+-----------+-------------------------------------------------------------------------+---------+----------+
|                 UUID                 | NAME | STATUS | SIZE (GB) | LOCATION                                 | CREATED | ATTACHED |
+--------------------------------------+------+--------+-----------+-------------------------------------------------------------------------+---------+----------+
| 04c56e4a-5b8b-512c-eaa3-b82b4cd46d9e | mnt  |        | 1.6 MB    | /Users/eyberg/.ops/volumes/mnt:04c56e4a-5b8b-512c-eaa3-b82b4cd46d9e.raw |         |          |
+--------------------------------------+------+--------+-----------+-------------------------------------------------------------------------+---------+----------+
</code></pre>

<h3>Attaching a Volume</h3>

<p>You can attach a volume to an instance that is expecting one. So that
means when we create the image we'll want to pass any mount points with
the volume label and mount path - this is loosely similar to how
something in /etc/fstab would work. Ran locally you can test with 'ops
run' but you can pass the same '--mounts' flag when issuing 'ops image
create' for images ran on Google or AWS. Let's try it out locally:
</p>

<pre><code>‚ûú  g2 ops run -p 8080 g2 --mounts mnt:/mnt
booting /Users/eyberg/.ops/images/g2.img ...
assigned: 10.0.2.15
/ 0
/dev 0
/dev/null 0
/dev/urandom 0
/etc 0
/etc/passwd 33
/etc/resolv.conf 18
/etc/ssl 0
/etc/ssl/certs 0
/etc/ssl/certs/ca-certificates.crt 207436
/g2 7533614
/lib 0
/lib/x86_64-linux-gnu 0
/lib/x86_64-linux-gnu/libnss_dns.so.2 26936
/mnt 0
/mnt/bob.txt 21
/proc 0
/proc/self 0
/proc/self/exe 0
/proc/self/maps 0
/proc/sys 0
/proc/sys/kernel 0
/proc/sys/kernel/hostname 7
/sys 0
/sys/devices 0
/sys/devices/system 0
/sys/devices/system/cpu 0
/sys/devices/system/cpu/cpu0 0
/sys/devices/system/cpu/online 0
Hi - I'm a text file
</code></pre>

<p>Cool! It works! Now let's edit the file.</p>

<pre><code>echo "New text has come to light." &gt; mnt/bob.txt
‚ûú  g2 ops volume create mnt2 -d mnt
2020/12/08 11:19:41 volume: mnt2 created with UUID f82da0e3-3980-ddd8-5720-e1b320e21371 and label mnt2
</code></pre>

<p>Keep in mind we are creating a *new* volume with new contents and then re-attaching the volume to the instance.</p>

<pre><code>‚ûú  g2 ops run -p 8080 g2 --mounts mnt2:/mnt
booting /Users/eyberg/.ops/images/g2.img ...
assigned: 10.0.2.15
/ 0
/dev 0
/dev/null 0
/dev/urandom 0
/etc 0
/etc/passwd 33
/etc/resolv.conf 18
/etc/ssl 0
/etc/ssl/certs 0
/etc/ssl/certs/ca-certificates.crt 207436
/g2 7533614
/lib 0
/lib/x86_64-linux-gnu 0
/lib/x86_64-linux-gnu/libnss_dns.so.2 26936
/mnt 0
/mnt/bob.txt 28
/proc 0
/proc/self 0
/proc/self/exe 0
/proc/self/maps 0
/proc/sys 0
/proc/sys/kernel 0
/proc/sys/kernel/hostname 7
/sys 0
/sys/devices 0
/sys/devices/system 0
/sys/devices/system/cpu 0
/sys/devices/system/cpu/cpu0 0
/sys/devices/system/cpu/online 0
New text has come to light.
</code></pre>

<p>If you are attaching the volume to an instance on Google or AWS you'd
use the attach command:</p>

<pre><code>ops volume attach g2 mnt mnt2 -t gcp -c config.json</code></pre>

<p>Similarly, you can detach as well:</p>

<pre><code>ops volume detach g2 mnt -t gcp -c config.json</code></pre>

<p>What's really great about unikernel volumes when working on AWS or
Google is that this is all managed for you by the cloud provider of choice. There is no duplicate storage layer
you have to manage like you do in container land. Now you know the basics of mounting external volumes into your unikernel images.</p>
                    </div></div>]]>
            </description>
            <link>https://nanovms.com/dev/tutorials/working-with-unikernel-volumes-in-nanos</link>
            <guid isPermaLink="false">hacker-news-small-sites-25352718</guid>
            <pubDate>Tue, 08 Dec 2020 22:59:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating a Blog in Org-Mode in 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25352702">thread link</a>) | @slondr
<br/>
December 8, 2020 | https://blog.ericlondr.es/creating-a-blorg-in-2020.html | <a href="https://web.archive.org/web/*/https://blog.ericlondr.es/creating-a-blorg-in-2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<header>

<p>Published: <span><span> Tuesday, December 8, 2020 </span></span></p>
</header><p>
I just finished<sup><a id="fnr.1" href="#fn.1">1</a></sup> building a new blog <a href="https://orgmode.org/">org-mode</a>. You're now looking at that blog (I should think). <a href="https://rakhim.org/honestly-undefined/19/">As is customary</a> for any new blog designed in a relatively obscure way, I shall attempt to justify my technical choices and also assemble a rough guide for you to build your own "blorg."
</p>
<div id="outline-container-org614ecaa">
<h2 id="org614ecaa">What Doesn't Work</h2>
<div id="text-org614ecaa">
<p>
This is the fourth or fifth blog I've constructed in the last few years. I used <a href="https://jekyllrb.com/">Jekyll</a> for quite some time, before moving to <a href="https://metalsmith.io/">Metalsmith</a> + <a href="https://pugjs.org/api/getting-started.html">Pug</a>, then <a href="https://www.netlifycms.org/">Netlify</a> + <a href="https://www.gatsbyjs.com/">GatsbyJS</a>, then finally <a href="https://ghost.org/">Ghost</a> hosted on a Google VPS before deciding to build my current system. I reached a point where I actually began to version my personal website, adhered to semver, and tagged releases on GitLab. I will try to explain, briefly, why each of these setups was either insufficient for my (relatively meager) needs, or just rubbed me the wrong way.
</p>
<dl>
<dt>Jekyll</dt><dd>In my opinion, Jekyll deserves its popularity. Few static site generators manage to have as low a barrier to entry as Jekyll has while avoiding cruft and slowness. However, this is also Jekyll's main flaw ‚Äî there is very little you can <i>do</i> with Jekyll beyond write posts in Markdown, attach templates to them, and publish them as HTML. If all you plan on doing with your website is authoring simple posts and publishing them, and you want to do this efficiently, Jekyll is probably right for you. If you, like me, are never satisfied unless you can push the software you use to near-ludicrous limits, Jekyll is something you will outgrow very quickly. It is very difficult to use source formats other than Markdown with Jekyll ‚Äî there are org-mode packages which claim to work, but, in my experience, they do not.</dd>
<dt>Metalsmith</dt><dd><p>
My search for extensibility led me to Metalsmith, which uses a rather complex mix of GNU makefiles and JSON for configuration and compilation. Metalsmith, if you are unfamiliar, provides a "black box" which you can connect arbitrary sources and destinations to. You can tell it that you'll hand it content in Markdown, HTML, Pug, and org-mode syntax, and that you want that content converted to HTML, and it will <i>just work</i> provided you have a proper plugin.
</p>
<p>
The main problem I had with Metalsmith is that it is extremely slow. My GitLab CI deployments would oftentimes take upwards of ten minutes to complete, which, as someone who likes to stare at deploy logs as they get produced, was annoying. Also, I made the error to begin by writing content in Pug, which is not a very good template engine and has poor support in editors. By the time I had a technical stack I was comfortable with, I had installed so many plugins that Metalsmith was struggling to cope. Eventually I decided that is was more worth my time to dump Metalsmith entirely and rewrite my content in something more focused.
</p></dd>
<dt>Netlify CMS</dt><dd>Admittedly I did not spend much time here ‚Äî I was unable to get GitLab's default Gatsby setup to work with Netlify, even though they both advertise built-in support for each other. This may have been my fault, but I did spend some 20 or so hours fiddling with settings and configuration files to get it to work, to no avail.</dd>
<dt>Ghost</dt><dd><p>
Ghost is good software. It is the only WordPress competitor I have discovered which I would recommend to people with a straight face. I am actually currently building a large website for a client in Ghost, based partly on my experiences using it for my personal blog. It isn't as featured as WordPress, but it is <i>much</i> faster, more modern, and provides more out-of-the-box compared to WordPress's "There's a plugin for that" culture.<sup><a id="fnr.2" href="#fn.2">2</a></sup>
</p>
<p>
After a year of using Ghost, my GCP free trial expired and Google shut down my VPS. While I could have reinstalled Ghost onto a new system, I decided that it was time I returned to static hosting ‚Äî I missed org-mode too much!
</p></dd>
</dl>
</div>
</div>
<div id="outline-container-org28431ba">
<h2 id="org28431ba">The Road to Org</h2>
<div id="text-org28431ba">
<p>
Org-mode, and Emacs in general, have absorbed aspects of my life in a roughly linear trajectory since I first discovered Emacs in 2012. I have an <a href="https://www.orgroam.com/">org-roam</a> database full of thousands of lines of my academic notes, notes on literature, journal entries, contacts, etc. Org's literate programming features simply have no peer right now. When I try to use any other markdown format, I'm uncomfortable at how barebones they all are. Painless export to HTML, LaTeX, presentations, etc. (even simultaneously), backporting of some of LaTeX's more seamless syntactical features to other export modes, the footnote syntax, table manipulation; all of these things I hate to live without and am increasingly finding myself unwilling to. So I decided I would use org-mode for my blog. But this means not using the watered-down org-mode "renderers" that exist on GitLab, GitHub, etc. ‚Äî all of which are missing critical features, sometimes basic ones such as boldface. I need Emacs to do the heavy lifting.
</p>
<p>
I tried <a href="https://ox-hugo.scripter.co/">ox-hugo</a> but its setup was tedious to the point of absurdity. I started writing a generator to export org-mode files to <a href="https://www.getzola.org/">Zola</a>'s syntax, but this turned out to be equally too much work and not enough benefit. Without basing any generator on org-mode's extant output formats, some of org's strengths (such as execute-on-export for literate programming) vanish. Ox-hugo gets around this by exporting to markdown rather than building a novel Hugo front-end, but in my opinion this is not the right attitude to take towards building an Emacs-based blog. Org-mode already has an HTML exporter, why go through a less-featured middle-man?
</p>
<p>
That's how I arrived at <a href="https://orgmode.org/manual/Publishing.html">org-publish</a>, which is [1] built-in to org-mode, [2] supports all features and even allows for some custom configuration, and [3] is <i>extremely</i> simple.
</p>
</div>
</div>
<div id="outline-container-org082d001">
<h2 id="org082d001">Publishing from Org</h2>
<div id="text-org082d001">
<p>
To use org-publish, you simply assign a directory of "source" posts, a directory to export those posts to, and any settings you would like applied during translation. These settings are defined just like any other emacs settings, using Emacs Lisp in your configuration directory or a custom file. The tight integration with regular Emacs configuration means you have free reign to set up the system however you want ‚Äî for example, I wrote a function which loads a deploy script (also written in Emacs Lisp) before calling org-publish. That script acts as a sort of makefile: calling <code>sassc</code> to compile my <a href="https://sass-lang.com/">Sass</a> files into CSS files and placing them in the proper directory, running <code>surge</code> with the proper settings to deploy the static files, etc. Org-publish includes a feature to generate a "sitemap" out of the box, which I use as my blorg's landing page.
</p>
<p>
Once that is set up, simply calling my function from anywhere in Emacs will publish (export), build (compile), and deploy my blog. No more waiting around for GitLab's CI to spin up; no more 100-commit days where syntax errors in obscure configuration formats brought down the runner, no more refreshing my home page every few seconds while guessing if Cloudflare is just taking awhile or if the deployment really broke (again). And Google won't shut off my server again.
</p>
<p>
For convenience, I'll include some snippets of the configuration I wrote here. However, I intended this setup to be deeply integrated with the rest of my Emacs workflow ‚Äî I define blog posts with an org-capture, which I have bound to <code>C-c n c p</code>; a lot of my HTML configuration is defined globally rather than just for blog posts; etc. My entire Emacs configuration is hosted on GitLab<sup><a id="fnr.3" href="#fn.3">3</a></sup> and is publicly licensed, so you can take a peak at the monsters I've assembled if you'd like. For example, you can find the org-capture template <a href="https://gitlab.com/slondr/emacs-config/-/blob/master/org-templates/post.orgcaptmpl">here</a> and my general org configuration (including all of my configuration for org-publish) <a href="https://gitlab.com/slondr/emacs-config/-/blob/master/lib/org.el">here</a>; note the hard-coded fully-qualified filenames.<sup><a id="fnr.4" href="#fn.4">4</a></sup> Change that if you intend to remix what I've written.
</p>
<p>
My deploy script is in the root directory of the blog, and contains only two lines:
</p>
<div>
<pre><span>(</span>shell-command <span>"sassc -a src/sass/index.sass css/index.css"</span><span>)</span>ÓÄÄÓÄÅÓÄÅ
<span>(</span>shell-command <span>"surge public blog.ericlondr.es"</span><span>)</span>
</pre>
</div>
<p>
Again, note the use of fully-qualified absolute filenames. The key function in my global Emacs configuration is this:
</p>
<div>
<pre><span>(</span><span>require</span> '<span>ox-publish</span><span>)</span>ÓÄÄÓÄÅÓÄÅ
<span>(</span><span>defun</span> <span>blog-deploy</span> <span>()</span>ÓÄÄÓÄÅÓÄÅ
  <span>(</span><span>interactive</span><span>)</span>ÓÄÄÓÄÅÓÄÅ
  <span>(</span><span>let</span> <span>(</span><span>(</span>wd default-directory<span>)</span><span>)</span>ÓÄÄÓÄÅÓÄÅ
    <span>(</span>org-publish-all<span>)</span>ÓÄÄÓÄÅÓÄÅ
    <span>(</span>cd <span>"~/org/blog/"</span><span>)</span>ÓÄÄÓÄÅÓÄÅ
    <span>(</span>load-file <span>"deploy.el"</span><span>)</span>ÓÄÄÓÄÅÓÄÅ
    <span>(</span>cd wd<span>)</span><span>)</span><span>)</span>
</pre>
</div>
<p>
<code>blog-deploy</code> publishes the blog and then runs the deploy script, returning Emacs's session to the proper working directory afterwards.
</p>
<p>
Take note that there is nothing special about the deploy script. It doesn't <i>need</i> to be Emacs Lisp, I just decided I liked it like that. You could write a makefile, or use some other scripting languages such as bash or Python or even Rust, or include the deployment commands in the <code>blog-deploy</code> function (once the directory is set). That's one of the beauties of this setup ‚Äî the ecosystem is completely divorced from the static file generation, so any additional configuration or compilation steps you want to do you can just script yourself.
</p>
<p>
The capture template I use for starting off new posts is this:
</p>
<div>
<pre><span>#+title:</span> <span>%^</span><span>{</span><span>Name</span><span>}</span>
<span>#+date:</span> <span>%t</span>
<span>#+subtitle: Published: </span><span>{</span><span>{</span><span>{</span><span>date</span><span>}</span><span>}</span><span>}</span>
<span>#+setupfile: /home/eric/org/blog/org-template/style.org</span>

%?
</pre>
</div>
<p>
When you run org-capture and call this template, it will ask you first for the slug (filename), and then for the title ("Name"). The date will be automatically inserted. To render the dates as I have, eg in this post, customize <code>org-time-stamp-custom-formats</code> and then run <code>C-c C-x C-t</code> in the new buffer. The setupfile listed here will be included verbatim when org-publish converts the file to HTML. My setup file is very basic, but it would be difficult to accomplish this using other features:
</p>

<p>
This loads my site CSS and preferred webfont in each HTML page. It's infeasible to include this in the capture template, because the capture template will not apply to the sitemap (index.html).
</p>
<p>
That's pretty much it. Beyond some specific customizations of HTML flavor and export options, that's more or less all you need to get a robust yet simple blog built in Emacs. I tried to ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ericlondr.es/creating-a-blorg-in-2020.html">https://blog.ericlondr.es/creating-a-blorg-in-2020.html</a></em></p>]]>
            </description>
            <link>https://blog.ericlondr.es/creating-a-blorg-in-2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25352702</guid>
            <pubDate>Tue, 08 Dec 2020 22:58:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CASP14: What Google DeepMind‚Äôs AlphaFold 2 achieved and what it means]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25352334">thread link</a>) | @ninjani23
<br/>
December 8, 2020 | https://www.blopig.com/blog/2020/12/casp14-what-google-deepminds-alphafold-2-really-achieved-and-what-it-means-for-protein-folding-biology-and-bioinformatics/ | <a href="https://web.archive.org/web/*/https://www.blopig.com/blog/2020/12/casp14-what-google-deepminds-alphafold-2-really-achieved-and-what-it-means-for-protein-folding-biology-and-bioinformatics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><em>Disclaimer: this post is an opinion piece based on the experience and opinions derived from attending the CASP14 conference as a doctoral student researching protein modelling. When provided, quotes have been extracted from my notes of the event, and while I hope to have captured them as accurately as possible, I cannot guarantee that they are a word-by-word facsimile of what the individuals said. Neither the Oxford Protein Informatics Group nor I accept any responsibility for the content of this post.</em></p>



<p>You might have heard it from the <a href="https://www.nature.com/articles/d41586-020-03348-4">scientific</a> or <a href="https://www.nytimes.com/2020/11/30/technology/deepmind-ai-protein-folding.html">regular press</a>, perhaps even from <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">DeepMind‚Äôs own blog</a>. Google ‚Äòs AlphaFold 2 indisputably won the <a href="https://predictioncenter.org/casp14/index.cgi">14<sup>th</sup> Critical Assessment of Structural Prediction</a> competition, a biannual blind test where computational biologists try to predict the structure of several proteins whose structure has been determined experimentally ‚Äî yet not publicly released. Their results are so incredibly accurate that many have hailed this code as the solution to the long-standing protein structure prediction problem.</p>



<p>Protein structure is at the core of biochemistry, and has profound implications for medicine and technology. Establishing the structure of a protein is a bottleneck in <a href="https://en.wikipedia.org/wiki/Drug_design#Structure-based">structure-based drug discovery</a>, and accurate structure prediction is expected to improve the productivity of pharmaceutical research pipelines (although it is only one factor, and we will need to get other things right before truly revolutionary changes happen ‚Äî check Derek Lowe‚Äôs posts <a href="https://blogs.sciencemag.org/pipeline/archives/2019/09/25/whats-crucial-and-what-isnt">here</a> and <a href="https://blogs.sciencemag.org/pipeline/archives/2020/12/01/the-big-problems">here</a>). Structural information of proteins is also essential in biology, where it helps to elucidate function ‚Äî many key papers in biochemistry derive insight from experimental advances in structure determination. </p>



<p>Given the importance of the problem, and the wide network of resources that have slowly been advancing for decades, I think nobody was expecting that a solution would be presented too quickly. I myself decided to focus my PhD research in the field of structure prediction, thinking like many others that several years of work across many research lines would be necessary before we could achieve something close to a solution. I may now need to change topics.</p>



<p>How much of the press release is true, what has actually happened, and how significant is it? There has been endless discussion about this topic in multiple forums. Frankly, I haven‚Äôt been able to think about anything else for the past 72 hours. In an attempt to clear my own thoughts, I have decided to write this blog post detailing everything I have learned since my scientific world was turned upside down around 3 pm GMT on Monday. I hope this is useful for my fellow protein bioinformaticians who could not attend CASP14, but also to anyone who wants to hear a little bit more about this topic.</p>



<p>Please bear in mind that my report of the CASP14 assessment and conference will necessarily be interspersed with conjecture. The details of how <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">AlphaFold 2</a> works are still unknown, and we may not have full access to them until their paper is peer-reviewed (which may take more than a year, based on their CASP13 paper). The magnitude of the breakthrough is undeniable ‚Äî but we need more details to gauge its potential impact.</p>



<p>This is going to be a long post. Don‚Äôt say I didn‚Äôt warn you.</p>



<h2>How good is AlphaFold 2, exactly?</h2>



<p>Astoundingly so.</p>



<p>Let me tell you the story as it happened last Monday. A handful of hours before the start of the CASP14 meeting ‚Äî around noon GMT ‚Äî the organisers released the results of the assignment. Almost immediately, comments started to circulate around Twitter. This is the image everyone was sharing:</p>



<div><figure><a href="https://predictioncenter.org/casp14/zscores_final.cgi"><img loading="lazy" src="https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-2.png?resize=625%2C256&amp;ssl=1" alt="" width="625" height="256" srcset="https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-2.png?resize=1024%2C420&amp;ssl=1 1024w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-2.png?resize=300%2C123&amp;ssl=1 300w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-2.png?resize=768%2C315&amp;ssl=1 768w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-2.png?resize=624%2C256&amp;ssl=1 624w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-2.png?w=1206&amp;ssl=1 1206w" sizes="(max-width: 625px) 100vw, 625px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-2.png?resize=1024%2C420&amp;ssl=1 1024w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-2.png?resize=300%2C123&amp;ssl=1 300w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-2.png?resize=768%2C315&amp;ssl=1 768w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-2.png?resize=624%2C256&amp;ssl=1 624w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-2.png?w=1206&amp;ssl=1 1206w" data-lazy-src="https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-2.png?resize=625%2C256&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Ranking of participants in CASP14, as per the sum of the Z-scores of their predictions (provided that these are greater than zero). One group, 427, named AlphaFold 2, shows an incredible improvement with respect to the second best group, 473 (BAKER). This figure was obtained from the official CASP14 webpage on Tuesday 1st December, 2020.</figcaption></figure></div>



<p>This bar plot describes the sum of <a href="https://en.wikipedia.org/wiki/Standard_score">Z-scores</a> representing the predictions from the different groups. Remember that the Z-score is just the difference of a sample‚Äôs value with respect to the population mean, divided by the standard deviation; a high value represents a large deviation from the mean, and is commonly used as a outlier detection procedure. In other words, the groups that are markedly better than the average will have larger Z-scores. In this graph we see that one group performs a lot better than the rest: Group 427, whose average Z-score was around 2.5 when considering all targets, and rose to 3.8 in the hardest ones. If this was an intelligence test, AlphaFold 2 would score an <a href="https://en.wikipedia.org/wiki/Intelligence_quotient">intelligence quotient</a> (IQ) above 160.</p>



<p>If the relative comparison is astounding, the actual performance is just as impressive. I am going to consider a typical metric in structural biology, the <a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation_of_atomic_positions">root-mean-square deviation (RMSD) of atomic positions</a>. If you are not much of a protein folder, these numbers may not say much to you. Don‚Äôt worry ‚Äî in next section I will show a few graphical examples. Just keep in mind that (1) a lower RMSD represents a better predicted structure, and that (2) most experimental structures have a resolution around 2.5 √Ö (<strong>updated 8th Dec:</strong> although, as many have pointed out in Twitter, this is an apples to oranges comparison). Taking this into consideration, about a third (36%) of Group 427‚Äôs submitted targets were predicted with a root-mean-square deviation (RMSD) under 2 √Ö, and 86% were under 5 √Ö, with a total mean of 3.8 √Ö.</p>



<div><figure><a href="https://predictioncenter.org/download_area/CASP14/"><img loading="lazy" src="https://i2.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/rmsd.png?resize=437%2C328&amp;ssl=1" alt="" width="437" height="328" srcset="https://i2.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/rmsd.png?w=640&amp;ssl=1 640w, https://i2.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/rmsd.png?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/rmsd.png?resize=624%2C468&amp;ssl=1 624w" sizes="(max-width: 437px) 100vw, 437px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/rmsd.png?w=640&amp;ssl=1 640w, https://i2.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/rmsd.png?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/rmsd.png?resize=624%2C468&amp;ssl=1 624w" data-lazy-src="https://i2.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/rmsd.png?resize=437%2C328&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Distribution of RMSDs for the highest-ranked models submitted by AlphaFold 2. Data obtained from the CASP14 website on Tuesday 1st December, 2020.</figcaption></figure></div>



<p>We were still digesting this information when the conference started and, oh boy, did we suffer the first half an hour. Claims that this year‚Äôs competition was ‚Äúa little unusual‚Äù were followed by suggestions that one particular group had produced impressive results. Finally, John Moult, who has chaired every CASP since 1994, masterfully delivered a nail-biting exposition of the history of the competition, slowly feeding us information until he finally showed the graph we were all expecting. Here it is:</p>



<div><figure><img loading="lazy" width="625" height="435" src="https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/MicrosoftTeams-image-1.png?resize=625%2C435&amp;ssl=1" alt="" srcset="https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/MicrosoftTeams-image-1.png?resize=1024%2C712&amp;ssl=1 1024w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/MicrosoftTeams-image-1.png?resize=300%2C209&amp;ssl=1 300w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/MicrosoftTeams-image-1.png?resize=768%2C534&amp;ssl=1 768w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/MicrosoftTeams-image-1.png?resize=624%2C434&amp;ssl=1 624w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/MicrosoftTeams-image-1.png?w=1143&amp;ssl=1 1143w" sizes="(max-width: 625px) 100vw, 625px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/MicrosoftTeams-image-1.png?resize=1024%2C712&amp;ssl=1 1024w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/MicrosoftTeams-image-1.png?resize=300%2C209&amp;ssl=1 300w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/MicrosoftTeams-image-1.png?resize=768%2C534&amp;ssl=1 768w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/MicrosoftTeams-image-1.png?resize=624%2C434&amp;ssl=1 624w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/MicrosoftTeams-image-1.png?w=1143&amp;ssl=1 1143w" data-lazy-src="https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/MicrosoftTeams-image-1.png?resize=625%2C435&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Combined results of all the CASP competitions. The dark orange line (CASP14_serv) corresponds to the predictions made by fully automated servers, the olive green line (CASP14_w/o427) includes all predictions assisted by humans except for the highest performing group; and the black line (CASP14) represents the predictions by the best performing team: Group 427, or AlphaFold 2. This plot uses the GDT_TS score, where 100 represents perfect results and 0 is a meaningless prediction.</figcaption></figure></div>



<p>As a rule of thumb, a GDT_TS around 60% represents a ‚Äúcorrect fold‚Äù, meaning that we have an idea of how the protein folds globally; and over 80% we start seeing side chains that closely resemble the model. As you can see, AlphaFold 2 achieves this objective for all but a small percentage of the tasks.</p>



<p>And then, after three decades of competitions, the assessors declared that AlphaFold 2 had succeeded in solving a challenge open for 50 years: to develop a method that can accurately, generally and competitively predict a protein structure from its sequence (or, well, a multiple sequence alignment, as we will see later). There are caveats and edge cases, as in any application ‚Äî but the magnitude of the breakthrough, as well as its potential impact, are undeniable.</p>



<p>The story does not end there. The models produced by AlphaFold 2 were so good that in some cases defied the results of the experiment. I will provide two brief examples, based on examples mentioned in the conference. The first example comes from the group of <a href="http://www.chem.umd.edu/faculty-staff-directory/facultydirectory/osnat-herzberg">Osnat Herzberg</a>, who were studying a phage tail protein. After appreciating the excellent agreement of DeepMind‚Äôs model with their structure, they noticed that they had a different assignment for a cis-proline. Upon reviewing the analysis, they realised they had made a mistake in the interpretation and corrected it.</p>



<p>The second comes from the group of <a href="https://www.chemie.uni-hamburg.de/en/institute/bc/arbeitsgruppen/tidow/personen/tidow-henning.html">Henning Tidow</a>, who was studying an integral membrane protein, the reductase FoxB (apparently related to iron uptake in Gram-negative bacteria). Prof. Tidow‚Äôs group worked on this model for about two years, trying different methodologies to solve the crystal structure, including <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5947774/">experimental phasing</a> methods. When they were given the models from DeepMind‚Äôs prediction, they managed to solve the problem by <a href="https://en.wikipedia.org/wiki/Molecular_replacement#:~:text=Molecular%20replacement%20(or%20MR)%20is,the%20diffraction%20data%20is%20derived.">molecular replacement</a> in a matter of hours.</p>



<p>There is one last point to clear. Some people have wondered if Google‚Äôs incredible success is not perhaps related to an easier set of target proteins this year. This is, <em>per se</em>, a difficult claim to sustain (after all, wouldn‚Äôt other groups with much more experience have also benefited from this?), but to disprove this point the assessors have concluded that the targets for CASP14 were the most difficult to date, based on the similarity of existing protein structures to the targets:</p>



<div><figure><img loading="lazy" src="https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-3.png?resize=577%2C510&amp;ssl=1" alt="" width="577" height="510" srcset="https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-3.png?w=577&amp;ssl=1 577w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-3.png?resize=300%2C265&amp;ssl=1 300w" sizes="(max-width: 577px) 100vw, 577px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-3.png?w=577&amp;ssl=1 577w, https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-3.png?resize=300%2C265&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/www.blopig.com/blog/wp-content/uploads/2020/12/image-3.png?resize=577%2C510&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Comparison of the targets of the last four CASPs in terms of the coverage and sequence identity of the available templates. On both counts, CASP14 includes the most difficult free-modelling (FM) targets yet provided. TBM stands for Template Based Models.</figcaption></figure></div>



<p>There are still many interesting points of discussion. Many will argue that the set of targets studied at CASP14 is not representative of <em>all</em> interesting structural prediction problems ‚Äî and they will be right. And, yes, certainly there are some problems where AlphaFold 2 hasn‚Äôt performed that well. I will give you my thoughts on some of the caveats later, when we near the end of this blog post. But, for now, let‚Äôs be clear on something: AlphaFold 2 is a tool that can solve the protein structure prediction <em>for a very significant number of targets</em>.</p>



<h2>How does this compare to other methods?</h2>



<p>I might have convinced you that AlphaFold 2 is a massive breakthrough. Now it is time ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.blopig.com/blog/2020/12/casp14-what-google-deepminds-alphafold-2-really-achieved-and-what-it-means-for-protein-folding-biology-and-bioinformatics/">https://www.blopig.com/blog/2020/12/casp14-what-google-deepminds-alphafold-2-really-achieved-and-what-it-means-for-protein-folding-biology-and-bioinformatics/</a></em></p>]]>
            </description>
            <link>https://www.blopig.com/blog/2020/12/casp14-what-google-deepminds-alphafold-2-really-achieved-and-what-it-means-for-protein-folding-biology-and-bioinformatics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25352334</guid>
            <pubDate>Tue, 08 Dec 2020 22:29:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Starship Test Flight ‚Äì ‚Äúnow targetting ~4:30PM CST‚Äù ‚Äì 3 minutes from now]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25352296">thread link</a>) | @tpmx
<br/>
December 8, 2020 | https://multistream.co/p/QK5Dixfxj25/SN8_Hop?whoop=1 | <a href="https://web.archive.org/web/*/https://multistream.co/p/QK5Dixfxj25/SN8_Hop?whoop=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://multistream.co/p/QK5Dixfxj25/SN8_Hop?whoop=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25352296</guid>
            <pubDate>Tue, 08 Dec 2020 22:26:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The key to happiness is to stop getting upset all the time]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25351689">thread link</a>) | @mcrittenden
<br/>
December 8, 2020 | https://critter.blog/2020/12/08/the-key-to-happiness-is-to-stop-getting-upset-all-the-dang-time/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/12/08/the-key-to-happiness-is-to-stop-getting-upset-all-the-dang-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-4012">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>I spent a few years working on a project for a big soccer league. One guy on the team had spent some time back in the day writing embedded software for medical equipment. He came from a world where a bug could mean someone dies. </p>



<p>Whenever something broke on the league‚Äôs website, say the stats were wrong or live scores weren‚Äôt updating, <a href="https://critter.blog/2020/12/02/we-become-what-we-are-told-we-are/">everyone lost their crap</a> except for that guy. ‚ÄúIt‚Äôs just soccer,‚Äù he said as he fixed everything. ‚Äú<a href="https://critter.blog/2020/11/04/what-we-have-left/">Nobody‚Äôs going to die</a>.‚Äù</p>



<p>He taught me that sometimes we all need to care just a <em>little bit </em>less.</p>



<p><a href="https://twitter.com/m_ashcroft/status/1264499790865408000">A Twitter thread</a> reminded me of that guy recently. The thread talks about the difference between being ‚Äúserious‚Äù and ‚Äúsincere‚Äù in life. </p>



<p>Ever played a game against someone who forgot it was a game? My grandmother is like that with the card game Bridge. Bridge is not entertainment for her. It‚Äôs about pride and victory. She‚Äôs ‚Äúserious‚Äù about Bridge.</p>



<p>Nobody likes playing a game against someone like that. It <a href="https://critter.blog/2020/10/28/the-all-powerful-bad-apple/">takes the fun out of it</a> for everyone.</p>



<p>If she were able to keep the passion and the dedication but still have fun with it, then she‚Äôd be ‚Äúsincere‚Äù about Bridge. Sincere people still care just as much as serious people, but <a href="https://critter.blog/2020/11/17/stop-trying-to-be-impressive-start-trying-to-be-warm/">in a different way</a>. Sincere people remember that it‚Äôs a game and don‚Äôt get all in a tizzy when things don‚Äôt go their way. Sincere people know that ‚Äúit‚Äôs just soccer.‚Äù</p>



<p>I heard a description of <a href="https://www.iheart.com/podcast/105-stuff-you-should-know-26940277/episode/what-exactly-is-stoicism-29467386/">Stoicism on a podcast</a> a few months back. They talked about how life always tries to get your goose, and Stoicism is the art of ‚Äúpreventing your goose from becoming gotten‚Äù. That‚Äôs sincerity.</p>



<p>Can we stop being so ‚Äúserious‚Äù about the game that is life and start being ‚Äúsincere‚Äù about it? Can we keep the passion, hard work, and growth but swap the upset-edness for silliness and joy? </p>



<p>After all, it‚Äôs just soccer.</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/12/08/the-key-to-happiness-is-to-stop-getting-upset-all-the-dang-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25351689</guid>
            <pubDate>Tue, 08 Dec 2020 21:35:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Developers guide for building a dWebsite in Ethereum testnet]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25351601">thread link</a>) | @_mdt_
<br/>
December 8, 2020 | http://blog.almonit.eth.link/2020-12-07/testnet_ENS_instruction_Almonit_extention.html | <a href="https://web.archive.org/web/*/http://blog.almonit.eth.link/2020-12-07/testnet_ENS_instruction_Almonit_extention.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  <p><span>Written by</span>
    
        Almonit
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2020-12-07 00:00:33 +0100">December 07, 2020</time>
    
  </p>

  
  

  <p>This is developers guide for building dWebsites in testnet. It follows an example of making a dWebsite, <code>tutorial.eth</code> in Rinkeby testnet.</p>

<p>The guide is comprehensive, trying to fill in all aspects of making a testnet dWebsites. We divided it into many subsections, so you can easily read only the topics relevant to you.</p>

<p><em>Note</em>: testnet dWebsites are not safe! They may be deleted, modified, or removed. When you buy a testnet name there is no guarantee this name will be there the following day. Testnet dWebsites are meant for developers to test their products before putting it on the ‚Äúreal‚Äù Ethereum.</p>

<h2 id="prerequisites-almonit-browser-extension">Prerequisites: Almonit Browser Extension</h2>
<p>You will need the latest version Almonit Browser Extension to complete this guide. It includes testnet dWesbites support.</p>

<p>Install it either versions for <a href="https://addons.mozilla.org/en-US/firefox/addon/almonit/">Firefox</a> or for <a href="https://chrome.google.com/webstore/detail/almonit/adobfkcnfkodjfobnndpfipdanhdcafm">Chromium-based browsers</a>, like Chrome, Brave, Opera etc.</p>

<h2 id="choosing-an-ethereum-testnet">Choosing an Ethereum testnet</h2>
<p>Currently, our browser extension supports ENS in two Ethereum testnets, Ropsten, and Rinkeby. What‚Äôs the difference between them?</p>

<p>Ropsten is an unsecured proof-of-work (PoW) blockchain. Since Ropsten is PoW, just like Ethereum‚Äôs mainnet,  Ropsten simulates the bests how dApps behave in Ethereum. However, Ropsten is relatively slow (block time 30 seconds, compared to 15 seconds of Rinkey), exposed to spamming attack (where someone spams the blockchains with many transactions, making it impossible for anyone else to you), while not being eco-friendly.</p>

<p>Rinkeby is a proof-of-authority (PoA) blockchain, meaning it‚Äôs being operated by a small known group of trusted entities.  PoA blockchains are both very eco-friendly and immune to spamming attacks. However, they simulate Ethereum less accurately, and to get tokens for them you need to use social media (brrrr).</p>

<p>You can <a href="https://ethereum.stackexchange.com/questions/27048/comparison-of-the-different-testnets">find here</a> excellent detailed analysis of the differences between all the testnets.</p>

<p>ENS is also deployed on Goerli testnet. However, Goerli is not supported by the current version of Almonit browser extension so we don‚Äôt dwell on it here.</p>

<h2 id="how-to-get-testnet-tokens">How to get testnet tokens?</h2>
<p>First, switch your wallet to testnet. In Metamask, for example, it‚Äôs done a select box in the wallet popup.</p>

<p><img src="http://blog.almonit.eth.link/resources/images/Almonit-extension-testnet-developers-guide/metamask_testnet.jpg"></p>

<p>We recommend creating a new account only for testnet. Don‚Äôt use the same accounts for mainnet and testnet activities, as it‚Äôs an invitation for crucial accidents.</p>

<p>Getting testnet tokens depends on which testnet you use.</p>

<ol>
  <li>
    <p><strong>Ropsten</strong>. Super easy! Go to a <a href="https://faucet.ropsten.be/">Ropsten faucet</a>, enter your Ropsten wallet address, and click ‚ÄòSend me test Ether‚Äô. That‚Äôs all!</p>
  </li>
  <li>
    <p><strong>Rinkeby</strong>. We use a <a href="https://faucet.rinkeby.io/">Rinkey faucet</a>. The process has <em>two</em> steps, meant to protect Rinkeby from spamming attacks.</p>

    <p>Step 1: Make a Twitter or Facebook post with your account address.</p>

    <p><img src="http://blog.almonit.eth.link/resources/images/Almonit-extension-testnet-developers-guide/Rinkeby_twitter_request.jpg"></p>

    <p>Step 2: Paste the URL of your post into the faucet.</p>

    <p><img src="http://blog.almonit.eth.link/resources/images/Almonit-extension-testnet-developers-guide/Rinkeby_faucet.jpg"></p>
  </li>
</ol>

<h2 id="buy-ens-name-in-testnet">Buy ENS name in testnet</h2>
<p>Once you have testnet tokens, you can buy an ENS testnet name! We demonstrate the process on Rinkeby testnet, though it‚Äôs identical for all of them.</p>

<ol>
  <li>
    <p>Switch your wallet to the testnet you‚Äôre buying a name in (see the previous section for how it‚Äôs done in Metamask).</p>
  </li>
  <li>
    <p>Go to the <a href="https://app.ens.domains/">ENS app</a>. Verify, at the upper left corner of the app, that it works in the correct testnet.</p>
  </li>
  <li>
    <p>Enter the name you want to buy and press search. You can choose between a <code>.eth</code>  or  a<code>.test</code>. The difference is in the purchase process. A <code>.eth</code> name imitates the purchase process of mainnet ENS names, and hence is a bit slow. a <code>.test</code> name is much faster to buy.</p>

    <p><strong>Note</strong>: at the time of writing this post <code>.test</code> names don‚Äôt work in testnet. However, we leave it here for the instructions to be valid once ENS fix this.</p>
  </li>
  <li>
    <p>Press <code>Register</code>, and follow the instructions till you obtain the name.</p>
  </li>
</ol>

<p>Congratulations! You just bought an ENS name in testnet!</p>

<h2 id="create-your-first-testenet-dwebsite">Create your first testenet dWebsite</h2>
<ol>
  <li>In ENS App, go to the manage screen of the name you bought in the previous step.</li>
  <li>Press ‚Äòadd/edit record‚Äô</li>
  <li>Insert an IPFS CID of a dWebsite in the content field. For example, this CID would give you a cool ‚ÄòALmonit Tutorial‚Äô dWebsite: <code>ipfs://QmTXWx6pLwYoX3HUGxyM7qCR3qF9MdtRMcC3fx8qnnUHU2</code></li>
  <li>Press ‚ÄòConfirm‚Äô and confirm the transaction in your wallet.</li>
</ol>

<h2 id="browse-to-your-dwebsite">Browse to your dWebsite</h2>
<p>First, enable testnet support in Almonit Browser extension using those steps.</p>

<ol>
  <li>
    <p>In the Almonit popup in yoru browser, press the settings button: <img src="http://blog.almonit.eth.link/resources/images/Almonit-extension-testnet-developers-guide/settings.jpg"></p>
  </li>
  <li>
    <p>In the general tab, enable the checkbox of ‚ÄòEnable ENS testnet Dwebsites‚Äô, and select the testnet you want to use.</p>
  </li>
</ol>

<p>Now you can surf to your website!</p>

<p>You <em>can‚Äôt</em> simply enter the name of your testnet dWebsite, because <code>.test</code> and <code>.eth</code> are already reserved for real DNS and real ENS websites.</p>

<p>Instead, you need to replace <code>.test</code> in your name with <code>.teth</code>, and <code>.eth</code> with <code>.testeth</code>.</p>

<p>So, if we made a testnet dWebsite tutorial.test, you‚Äôll have to type <code>http://tutorial.teth</code> in your address bar to access it. Or, if we made a test dWebsite tutorial.eth, you could access it by typing in the address bar <code>http://tutorial.testeth</code>.</p>

</div>



    </div></div>]]>
            </description>
            <link>http://blog.almonit.eth.link/2020-12-07/testnet_ENS_instruction_Almonit_extention.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25351601</guid>
            <pubDate>Tue, 08 Dec 2020 21:28:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dataform (YC W18) has been acquired by Google]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25351395">thread link</a>) | @knes
<br/>
December 8, 2020 | https://dataform.co/blog/dataform-is-joining-google-cloud?HN | <a href="https://web.archive.org/web/*/https://dataform.co/blog/dataform-is-joining-google-cloud?HN">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Today we're excited to announce that we've joined Google Cloud. Over the course of the past several months, our partnership with Google Cloud has deepened and we believe that our new combined efforts can make our customers and partners even more successful.</p><div><div><p>To our customers, users, supporters and contributors - today, we are extremely excited to share that Dataform is joining Google Cloud!</p>
<p>Before we jump into the story, let us quickly answer what we think will be the most important questions for existing and new users:</p>
<ul>
<li>Dataform Web will continue to be run and maintained by us, as part of Google Cloud.</li>
<li>Dataform Web will be free for all new users as of today, December 8th 2020.</li>
<li>Existing customers will be transitioned onto the free plan immediately.</li>
<li>Dataform Web will focus on support for BigQuery going forward.</li>
<li>We√¢‚Ç¨‚Ñ¢ll be working closely with the rest of the Google Cloud Data Analytics team over the next year to deliver our vision for Dataform within Google Cloud.</li>
</ul>
<p>Three years ago we started Dataform with a mission to <strong>empower analysts to manage the entire flow of data in the warehouse, using a single, unified workflow</strong>. Throughout our journey we√¢‚Ç¨‚Ñ¢ve been focused on giving data analysts and data engineers the tools they need to take raw, messy data, transform it, and put it into the hands of their organization. We√¢‚Ç¨‚Ñ¢ve only just scratched the surface of this problem and solving it will continue to be our core mission and focus going forward.</p>
<p>We√¢‚Ç¨‚Ñ¢ve followed Google√¢‚Ç¨‚Ñ¢s products and successes within analytics closely over the past few years, and always felt that they were a product leader when it came to cloud data warehousing, SQL, and now business intelligence; with products such as Looker that inspired us significantly in our own journey. After several conversations with the Google Cloud team it became clear that we are deeply aligned on the importance of serving analysts with the right tools and technology in order to fill what we all perceive as a missed opportunity in existing solutions.</p>
<p>At the same time, as a team of just 7, in a complex, competitive and rapidly changing market, we had more ideas than we had people or resources to accomplish. There has always been so much more we wanted to do each quarter than we could achieve. With the support of the BigQuery and Cloud Analytics teams and our combined thought leadership and efforts, we felt that together we could achieve something bigger than we could separately.</p>
<p>There will inevitably be some changes to the product and how we operate over the coming years, but one thing that will not change is our commitment to the principles that we feel have gotten us this far: working closely with our customers, making sure we continue to collect and act upon your feedback, and a laser focus on doing one thing and doing it well.</p>
<p>At Dataform we always felt we were delivering a unique and innovative product to our customers and the data community. With Google√¢‚Ç¨‚Ñ¢s support, we have even more confidence in our ability to build and deliver a product that can truly change the way that all companies, large and small, work with data. </p>
<p>In the coming months we√¢‚Ç¨‚Ñ¢ll be able to share more details of our product roadmap. In the meantime please reach out to us if you have any questions. Thank you again for joining us on this journey. We√¢‚Ç¨‚Ñ¢re uncomfortably excited about what we can accomplish together over the coming years!</p>
<p>Guillaume-Henri Huon &amp; Lewis Hemens, co-founders of Dataform</p></div></div></div>]]>
            </description>
            <link>https://dataform.co/blog/dataform-is-joining-google-cloud?HN</link>
            <guid isPermaLink="false">hacker-news-small-sites-25351395</guid>
            <pubDate>Tue, 08 Dec 2020 21:10:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Measuring "efficiency" in document prepration: Microsoft Word vs. LaTex]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 155 (<a href="https://news.ycombinator.com/item?id=25350851">thread link</a>) | @1vuio0pswjnm7
<br/>
December 8, 2020 | https://blog.cr.yp.to/20201206-msword.html | <a href="https://web.archive.org/web/*/https://blog.cr.yp.to/20201206-msword.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<hr>
<hr>

<p>
The boss needed item 3 inserted into a numbered list of hundreds of items.
The intern used a mouse to select the original 3 on the screen,
then typed 4,
then selected the original 4,
then typed 5,
then scrolled down,
then selected the original 5,
then typed 6,
and so on.
Another intern sat watching the screen to make sure there were no mistakes.
</p>
<p>
I happened to be in the room for other reasons.
I remember the horror of watching the beginning of this barbaric editing process.
Those poor interns!
</p>
<p>
When I enter a list of items into the computer,
what I'm typing doesn't look like
</p>
<pre>     1. ...
     2. ...
     3. ...
</pre>
<p>
but more like
</p>
<pre>     * ...
     * ...
     * ...
</pre>
<p>
Each asterisk is a special command to the computer,
telling the computer to automatically display the next number for the reader.
The reader eventually sees
</p>
<pre>     1. ...
     2. ...
     3. ...
</pre>
<p>
but that isn't what I typed.
This small difference produces a tremendous savings of time
whenever I insert an item, or delete an item, or move an item.
</p>
<p>
If I decide later
to skip the numbers
and use bullets instead,
I tell the computer
to introduce each list item with a bullet.
This is one command covering the whole list.
There's also a command that does the same thing
for the whole document.
There isn't separate work for each item.
It's no problem if a coauthor
later wants to change bullets back to numbers.
</p>
<p>
The interns, I suppose,
would be manually changing "1." and "2." and "3."
and so on to "‚Ä¢" and "‚Ä¢" and "‚Ä¢" and so on.
Or maybe they would be trying to figure out
how some search-and-replace feature could do the same thing;
let's hope the document doesn't have a sentence somewhere
that talks about something that happened in the year 2001.
Or maybe the interns would be quitting and finding a better job.
</p>
<p>
[Note added 2020.12.07:
I was expecting that many of my readers
would already be accustomed to relying on the computer
for automatic numbering.
I was surprised, however,
to see some comments along the lines of "Inconceivable!"
from readers unable to imagine
how the interns could have been in a different situation,
going through such a shockingly inefficient revision process.
Here's a hint:
Each item in the list looked like a flush-left paragraph,
like the paragraphs in this blog post,
adjacent to the left margin.
The text being selected by the mouse,
for example to change "3" to "4",
was to the right of the margin,
like the rest of the text in each item.]
</p>
<p>
<b>Abstraction as a time-saver for authors.</b>
This use of asterisks
is just one example of how I'm often typing something more abstract
than what's seen by the ultimate reader.
I don't type "Figure 12" or "see [41]", for example;
I type things like "Figure \ref{network-measurements}" and "see \cite{multiplication-survey}",
and I let the computer automatically convert
"\ref{network-measurements}" and "\cite{multiplication-survey}"
into numbers to display for the reader.
</p>
<p>
With one extra command,
covering the entire document,
I can tell the computer
to include section numbers
as part of all figure numbers in the document,
so that the figures are easier for the reader to find:
e.g., Figures 3.1 and 3.2 and 3.3 are in Section 3.
With another command,
again covering the entire document,
I can tell the computer
to cite all authors by name rather than by number.
</p>
<p>
As another example,
I was recently editing a mathematical paper,
and I decided that a particular concept
would be easier for the reader to remember
if I changed the notation that I was using for the concept.
The notation was all over the paper,
but this change took just a few seconds of editing.
I had given a name to the concept,
had told the computer <i>once</i> to display this name as a particular notation,
and had then typed this name throughout the paper,
so there was only one place where I had to change the notation.
</p>
<p>
Of course one can't,
and shouldn't try to,
prepare in advance for <i>every</i> possible change to a document.
But it's not hard to prepare for the most likely changes.
This small initial effort
saves a tremendous amount of time later.
When I say "small",
I'm including the effort to select a document-creation system
that's designed to
<a href="https://en.wikipedia.org/wiki/LaTeX">make this sort of thing easy</a>.
</p>
<p>
(As a side note,
programmers will recognize this strategy
as an example of the
<a href="https://en.wikipedia.org/wiki/Information%5Fhiding">information hiding</a>
strategy introduced by Parnas,
and will recognize that modern program-creation systems
are designed to make this easy.)
</p>
<p>
Microsoft Word isn't completely missing abstractions,
but these abstractions
are competing for user-interface resources
against features encouraging the user
to work at lower abstraction layers.
The extra effort to use the abstractions
ends up pushing users into doing something simpler,
something that just works now,
and paying heavily for this choice
later when the document is being revised.
</p>
<p>
Have I done a scientific study
<i>proving</i> that Microsoft Word
is less efficient than LaTeX?
No.
I'd love to see a careful study of this topic.
Short-term,
this would help guide new authors to make sensible choices.
Longer-term,
insights from this sort of study could be the basis for further improving
our document-creation systems.
I certainly don't think that the existing systems are perfect.
(<a href="https://cr.yp.to/writing/visual.html">Example.</a>)
</p>
<p>
Imagine, however, that a study looks only at
<i>the time for someone looking at a printout to create a document matching this printout</i>.
This would be blind to the time for subsequent edits.
This would be blind to the suffering of those interns.
This would incorrectly conclude that typing
"1. ... 2. ... 3. ..." and "see [41]"
is more efficient than typing
"* ... * ... * ..." and "see \cite{multiplication-survey}".
It <i>is</i> slightly more efficient in this limited metric,
but it is much less efficient in the metric that matters,
namely the total time spent by the user.
</p>
<p>
<b>An example of a "scientific" study.</b>
At this point you're probably thinking that
nobody could possibly miss such an obvious issue.
This brings me to the main topic of this blog post,
a 2014 peer-reviewed study
<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115069">"An Efficiency Comparison of Document Preparation Systems Used in Academic Research and Development"</a>
by two psychologists,
Knauff and Nejasmic ("KN").
</p>
<p>
Participants in the study were given a page of text
and were given a limited time to type the page into the computer.
There were three different types of text:
</p>
<ul>
<li>simple prose with a few footnotes;
</li>
<li>a page with a complicated table of data;
and
</li>
<li>a page with many mathematical formulas.
</li>
</ul>
<p>
Participants were scored
on the basis of how much text they typed and how accurately they typed it.
The time was so rushed that a significant fraction of participants
didn't finish typing the whole page,
even for the case of simple prose.
</p>
<p>
The study considered two document-creation systems:
LaTeX and Microsoft Word,
in each case with "all tools, editors, plug-ins, and add-ons"
that participants were "accustomed to using".
Of course different "add-ons" could have different efficiency,
and of course there are other document-creation systems,
but these are topics for another blog post.
</p>
<p>
The study produced many pages of results,
which I'll summarize by saying that
Word did slightly better on the prose
and much better on the table,
while LaTeX did better on the formulas.
The study authors made no effort to measure any subsequent document-editing step.
</p>
<p>
<b>Slithering from one metric to another.</b>
The fundamental mistake in the KN paper
is the change of cost metric.
</p>
<p>
The original question was how efficiently authors are creating documents:
in particular, how efficiently authors are creating academic research papers.
KN claimed in their title to be comparing "efficiency"
of "document preparation systems used in academic research".
But they then quietly changed this metric in three ways:
</p>
<ul>
<li>
They considered only the efficiency of an initial fragment of the document-creation process,
ignoring the time spent revising documents.
They provided no reason to believe that the efficiency of this fragment
was well correlated with what they had previously claimed to be measuring.
Nothing in their paper acknowledges
the most obvious reason for a negative correlation,
namely that slightly more work at the outset
makes revisions much easier later.
In my experience,
document-creation systems vary in how well they support this work.
</li>
<li>
KN didn't even measure the time taken for this initial fragment of the process.
Instead they imposed a rushed time limit,
and measured how incomplete and inaccurate the resulting document was.
Again they provided no reason to believe that what they measured
was well correlated with what they had previously claimed to be measuring.
Perhaps they were assuming that more mistakes will take more time to fix,
but my experience is that some types of mistakes are much easier to fix than others,
and that document-creation systems vary in the types of mistakes they encourage.
</li>
<li>
KN didn't even measure creating a <i>new</i> document,
which is what academics are actually spending their time doing.
People who were writing papers in the age of typewriters
will remember writing and editing papers <i>by hand</i>
before tediously typing the final pages,
but that was because editing a typed page
ranged from annoying
(<a href="https://en.wikipedia.org/wiki/Correction%5Ffluid">white-out</a>,
or sometimes scissors and tape)
to super-annoying
(retyping the whole page).
Today the initial writing on paper is skipped,
and typing is interleaved in small chunks
with parts of the author's thought process,
making the typing process much less boring.
I'm continually re-reading
and thinking about what I just typed.
Is the error rate of the academic's modern typing process
well correlated with the error rate of the
archaic retyping process that KN measured?
Again KN provide no reason to believe this.
</li>
</ul>
<p>
Did KN use the honest title
"A comparison of the unreliability of
rushed retyping of a page
using document preparation systems
that are also used for academic research and development"?
No.
Would you expect a journal to accept a paper
with such a title?
</p>
<p>
Instead they used a title ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cr.yp.to/20201206-msword.html">https://blog.cr.yp.to/20201206-msword.html</a></em></p>]]>
            </description>
            <link>https://blog.cr.yp.to/20201206-msword.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25350851</guid>
            <pubDate>Tue, 08 Dec 2020 20:25:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meso-computing and meso-data: the forgotten middle]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25350717">thread link</a>) | @milliams
<br/>
December 8, 2020 | https://milliams.com/posts/2020/mesocomputing/ | <a href="https://web.archive.org/web/*/https://milliams.com/posts/2020/mesocomputing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I've been working as a <a href="https://www.software.ac.uk/blog/2016-08-17-not-so-brief-history-research-software-engineers-0">Research Software Engineer</a> (RSE) at universities in the UK for many years now, across a variety of fields of research (particle physics, synthetic biology, cardiology, etc.) as both a user of computing services and as a provider of them.
One thing that I've seen cropping up repeatedly is a tendency to want to chase the latest fad.
Now, in academia the latest fad is often up to ten years behind the state-of-the-art so, for example, it's only in the last few years that we've seen "deep learning" cropping up in every grant application.
One of the things I do in my job is try to <a href="https://milliams.com/courses">educate researchers</a> about these technologies so that they know what they're actually asking for and to ensure that if researchers are talking about doing "big data" since they have "megabytes of data" they won't be embarased by a grant reviewer who knows their stuff.</p>
<p>The push in this direction is completely understandable. The grant application business is extremely competitive and anything you can put in your proposal to catch the eye of a reviewer is going to count in your favour.</p>
<p>This is all particularly evident when talking about data.
Research money goes to the problems which are most worthy and there's an assumption that the harder the problem, the more worthy it is.
Furthermore, there's an assumption that the more data one has, the bigger and more difficult the research problem.
This naturally pulls together into an idea that if your problem is a "big data" problem then it's more likely to get funded.
You therefore see grant applications trying to convince reviewers that they're doing "big data" when really they're dealing with linear or spatial datasets of maybe only gigabytes to a terabyte.
That's certainly <em>a lot of</em> data but it often lacks the complexity that requires what one would really consider <em>big</em> data solutions.</p>
<p>Now, I'm not trying to downplay these areas of research.
Instead I'm trying to argue that the problems being solved here are just as worthy of investigation, even without couching it in terms of "big data".
<em>Most</em> research problems I see discussed at Universites are not big data and they are all interesting problems.
I think it would be healthy to reduce the allure of big data and let people know that it's ok to not fall into that category.
Part of the problem is that there's no good name for this scale of data problem: that which is a little too big to realistically do on a single laptop or desktop but well below the size or complexity to require a big data machine or a Hadoop cluster.</p>
<p>I've toyed with many names when trying to teach how to tackle problems of this size: <em>Large Data</em>, <em>Biggish Data</em>, <em>Medium Data</em>.
Until now, none have ever grabbed me so I've decided to coin a new term, <strong>meso-data</strong>.
<em>Meso</em> here means "middle" or "intermediate" cf. <a href="https://en.wikipedia.org/wiki/Mesopotamia#Etymology">Mesopotamia</a> ("between rivers").</p>
<div id="meso-computing">
<h2>Meso-computing</h2>
<p>Along with the problem in the data domain (mostly coming from buzzword-chasing), there's a similar issue in the computing-power domain.
Most research follows a common path of starting with a small investigation on a researcher's laptop until they have too many simulations to run or they are taking longer than the working day and so can't be finished in time.
At this point most research institutes will encourage the use of whatever central computing resources they have, usually a single large HPC cluster.</p>
<p>Research institutes such as Universities face a pressure of trying to justify their expenditure on computing resources by extolling all the big problems they're solving: how many nano-seconds of molecular dynamics they're pushing thorugh or how fine-grained the meteorological grid they can simulate.
This encourages the creation of systems which cater towards those few groups in the university who are able to make really good use of a supercomputer ‚Äî those who can run large multi-node MPI jobs with optimised code for the specific hardware and who have experts in their team who understand high-performance computing.</p>
<p>The problem with this is that it further increases the divide in power and complexity between running on one's laptop and using a central facility.
Similar to with meso-data, there's a large number of researchers ‚Äî I would argue <em>most</em> researchers ‚Äî whose needs sit right in the middle.
They're not doing <em>super</em>computing, they're doing <em>meso</em>-computing.</p>
<p>These researchers are best supported with small domain-specific batch clusters, with cloud computing (perhaps using <a href="https://cluster-in-the-cloud.readthedocs.io/">Cluster in the Cloud</a>), with software-as-a-service or with just some hands-on help from an RSE to get their code running more efficiently on their laptop.</p>
<p>Maybe Pandas is sufficient or perhaps they need to use Dask.
Maybe <a href="https://milliams.com/courses/parallel_python">a course</a> on <tt>concurrent.futures</tt> to magically make their code finish in a quarter of the time is the right solution.
Regardless, the solution is probably not to rewrite it in Fortran, using MPI to scale across 64 nodes or to rent a Hadoop cluster.</p>
</div>
<div id="the-middle">
<h2>The middle</h2>
<p>There will be those reading this who think I'm stating the obvious, who think "I've been working in this area for years, what's new?".
That's kind of the point, a lot of researchers sit here but the fact is that they are under-served.
Most aren't computer experts and will use whichever tools are available, advertised to them and are easy to use.
This inevitably means that they email to one another Excel spreadsheets with maybe some R or Python scripts with hard-coded paths.
These researchers are getting stuck as "<a href="https://daedtech.com/how-developers-stop-learning-rise-of-the-expert-beginner/">Expert Beginners</a>".
People who know their entry-level tools so well the short-term barrier to learning how to use them properly or using a better tool for the job is higher than seems worthwhile.</p>
<p>They want to scale their research but when they look around themselves to see what the University can provide, they're told about getting access to the supercomputer or how if they put their data into an Elasticsearch database things would be better.
That jump is far too big and we need to solve the social problem of allowing them to take only as many steps across the meso-data divide as they need to.
We need well-explained and easy-to-use tools at every stage of the scaling process, not just at the top end.</p>
<p>These terms, <em>meso-computing</em> and <em>meso-data</em>, are deliberately humble.
They are explicitly not about trying to be the biggest but rather about thoughtfully considering the problem at hand and choosing the right hammer.
Unlike with big data, people shouldn't have to ask the question "is this a meso-data problem" because if they're asking the question, the answer is "yes".
I want people to be comfortable saying in grant applications "since this is a meso-data challenge, we request funding for the skills and resources needed to tackle it" and ask for a full-time RSE without having to pretend that they're doing big data or need a dedicated supercomputer.
Labels are helpful and I think that these labels apply well to a good chunk of the research community.</p>
<p>Meso-data comes with its own set of tools and solutions which are partially distinct to big data's.
I haven't invented a whole new area of endeavour, many people have been working on solutions here for decades, but it's certainly not an area that attracts excitement or research money as it should.</p>
<p>These are still hard problems, and in my experience they are solving real-world challenges or furthering our understanding of the universe.
Meso-computing and meso-data projects still need expertise from RSEs or data scientists to make sure that the research is still reliable, reproducible, tested and understandable.</p>
</div>

  </div></div>]]>
            </description>
            <link>https://milliams.com/posts/2020/mesocomputing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25350717</guid>
            <pubDate>Tue, 08 Dec 2020 20:13:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Founders need to get radically better at sales]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25350472">thread link</a>) | @trensonmay
<br/>
December 8, 2020 | https://buzzchronicles.com/b/tech/745/ | <a href="https://web.archive.org/web/*/https://buzzchronicles.com/b/tech/745/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
          <div>

           <!-- <h3 class="rheading" style="margin-bottom: 25px;">Full Thread </h3>-->

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053056467702444032" target="_blank">
              
              </a><p>

            
            For technical founders it is irrationally, obscenely hard to reverse years of programming (ba dum bum) that sales is a value-destroying activity. Sales is CLEARLY a value-creating activity, contingent on you have a value-creating product.
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053056810356076544" target="_blank">
              
              </a><p>

            
            The world will not drop what they are doing to adopt your work. This is particularly true in B2B, where simply building a better mousetrap won't overcome the activation energy required to get people with additional non-mice problems to prioritize changing mousetraps today.
            

            

            </p></div>

            


            




            <div>
	      <a href="https://twitter.com/patio11/status/1053057216687685633" target="_blank">
              
              </a><p>

            
            This is very non-obvious for founders because founders are not often people who *want* to be sold to. We often come from a background where trying out tools is a bit of a fun hobby. We like looking at all the options, making charts, and ripping out partially complete tests.
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053057464927567873" target="_blank">
              
              </a><p>

            
            "This week I unsuccessfully trialed four software options for automating that thing that has been killing us. Our actual production process remains the same as last week. Don't worry; this was a great use of time." is not a thing you want to write in a progress report to manager.
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053057732473905152" target="_blank">
              
              </a><p>

            
            The process of sales pushes the burden for understanding the market and distilling it from the customer to the sales person. That is a very valuable thing; it is why almost all businesses buy almost all of their big-ticket purchases (including e.g. employees) from sales.
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053057944344883200" target="_blank">
              
              </a><p>

            
            (A candidate is absolutely doing a sales job when attempting to get hired by a company. This is one of the things that both sides of that market are frequently in denial about, but I digress.)
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053058257823031296" target="_blank">
              
              </a><p>

            
            Simply getting oneself to be comfortable with sales (or at least present as being comfortable for a phone call or two) unlocks a crazy amount of success for founders, because founders have a few advantages over every other sales rep.
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053058708459016193" target="_blank">
              
              </a><p>

            
            One is that they present as being almost irrationally obsessed with the market. Founders tend to live and breath the product for a few years, and it often shows, mostly in positive ways. </p><p>   Unlike most sales reps, founders can credibly promise tight feedback loops for product.
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053059070700150784" target="_blank">
              
              </a><p>

            
            Stealing a line from <a href="https://twitter.com/asmartbear" target="_blank">@asmartbear</a> which has paid for at least a year or two of my kids' education: </p><p>   "If you go with BigCo, you can call them at 3 AM. Someone will listen to you politely, explain they have no solution, and open a ticket. If you call at 3 PM, same answer."
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053059474037006336" target="_blank">
              
              </a><p>

            
            "You can't get a useless answer from me at 3 AM in the morning. But when I'm up, your business *really is* important to me. I am the engineering team. I will push fixes so fast you will be amazed. I *will* get this right because it *actually matters* to my business that I do."
            

            

            </p></div>

            



            



            <div>
	      <a href="https://twitter.com/patio11/status/1053059940036698112" target="_blank">
              
              </a><p>

            
            Founders have to sell. </p><p>   Many, many technical founders of my acquaintance want to offload this to someone ASAP. I've never seen this work: you need to have a deep understanding of your market and customers to arm that first non-founder salesperson. It is gained by doing.
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053060215304740864" target="_blank">
              
              </a><p>

            
            (And even if you don't do sales day-to-day anymore, you still have to sell candidates, investors, and partners on the desirability of using your company. Though most B2B SaaS CEOs that I know still very much have an account in their CRM and talk to "opportunities" frequently.)
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053060564706979840" target="_blank">
              
              </a><p>

            
            The transition from founder-driven sales to founder-assisted sales generally starts with hiring a "maverick" sort of salesperson; someone who is comfortable extracting what you know about the market, iterating rapidly on scripts, and doing "things that don't scale" to win.
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053060834581049344" target="_blank">
              
              </a><p>

            
            This may often be a necessary step, but it generally doesn't last for growing companies, partly because there is a crushing market undersupply of very effective mavericks. </p><p>   These folks are capable of writing their own ticket and then, by construction, getting folks to buy it.
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053061104639725568" target="_blank">
              
              </a><p>

            
            So eventually one tends to hire a VP of Sales who has done this before. They'll immediately start hiring reps under them, and start systematizing what you've learned about sales into scripts and playbooks.
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053061343773831168" target="_blank">
              
              </a><p>

            
            You'll see this maturity model start to creep into all parts of the funnel, too, which will probably actually be written down for the first time somewhere around this stage. </p><p>   Sophisticated, mature processes for marketing to pass leads over to sales for qualification.
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053061715879837699" target="_blank">
              
              </a><p>

            
            Sophisticated, maturing processes for sales to actually physically close deals. ("What, you mean we don't just edit a few things in Word and then ask them to print, sign, scan, and send back?") Defined, scheduled startup calls, onboarding, and handover to AMs / CS aftewards.
            

            

            </p></div>

            




            


            <div>
	      <a href="https://twitter.com/patio11/status/1053062556472864768" target="_blank">
              
              </a><p>

            
            (Sales, like many professions, benefits from specialization of labor. One that happens early is splitting the team into "account executives" (AEs) focused on getting new accounts and "account managers" (AMs), focused on keeping existing customers happy and expansion revenue.
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053062832965603328" target="_blank">
              
              </a><p>

            
            (Some companies even split their AM teams into dedicated subteams for doing true expansion, for cross-selling products, for winning renewals, and for the generic "I want the direct contact information for someone at your company because our business must be important enough" job)
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053063918598287360" target="_blank">
              
              </a><p>

            
            If you're at all interested in these topics, the people to read a heck out of are Steli and <a href="https://twitter.com/jasonlk" target="_blank">@jasonlk</a> (who writes <a href="https://t.co/7FpEMvXdLZ" rel="nofollow">https://t.co/7FpEMvXdLZ</a> ). </p><p>   Steli is so effective at sales he has closed deals he wasn't even a party to. My favorite anecdote about this:
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053064199780261888" target="_blank">
              
              </a><p>

            
            At a previous company I had invited myself out to lunch with a software CEO, with intent to get them to sign up, but was not really sure where we were at end of lunch. </p><p>   "Hey apropos of nothing: do you know Steli?" <br> "Oh yeah he's great." <br> "He is. Steli wouldn't let me leave lunch...
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053064425165320192" target="_blank">
              
              </a><p>

            
            ... until you explicitly tell me you're going to use our product." <br> "He wouldn't, would he." <br> "He wouldn't." <br> "OK then; we will." <br> "Great! Email me and we'll figure out logistics."
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053064717621575680" target="_blank">
              
              </a><p>

            
            That is called "asking for the sale" and, while that is a very unconventional way to ask for the sale, a *ridiculous* portion of all energy expended in the art of sales is to get conversations to the point where someone has to actually say yes or no.
            

            

            </p></div>

            





            <div>
	      <a href="https://twitter.com/patio11/status/1053065301045141505" target="_blank">
              
              </a><p>

            
            Relatedly: in the highly likely event that you get an answer which is not a yes or no, effective salespeople follow up until the sun goes nova waiting for either a yes or no.
            

            

            </p></div>

            
            
                        
          </div>
        </div></div>]]>
            </description>
            <link>https://buzzchronicles.com/b/tech/745/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25350472</guid>
            <pubDate>Tue, 08 Dec 2020 19:54:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Waiting for Postgis 3.1: Output functions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25350465">thread link</a>) | @clairegiordano
<br/>
December 8, 2020 | https://rmr.ninja/2020-12-06-waiting-for-postgis-3-1-output/ | <a href="https://web.archive.org/web/*/https://rmr.ninja/2020-12-06-waiting-for-postgis-3-1-output/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>To continue with the changes in <a href="http://postgis.net/2020/11/19/postgis-3.1.0alpha3/">PostGIS 3.1</a>, in this post I‚Äôll cover the performance improvements on many functions that output geometries either as binary or as text. I will talk about several changes which have in common that they kicked off by a single question: ‚ÄúNow what?‚Äù</p>

<p>After the release of 3.0 back in October 2019, I wasn‚Äôt working on anything directly related to PostGIS with the exception of using MVTs to make maps. Since I had recently improved vector tile functions and I was ok with their performance (<em>spoiler alert</em>: <a href="https://rmr.ninja/2020-11-19-waiting-for-postgis-3-1-mvt/">I ended up improving them again in 3.1</a>) I didn‚Äôt have any good ideas about what to work on next. But then two events happened around the same time: <a href="https://cppcon.org/">CppCon</a> released their 2019 talks on YouTube and a coworker mentioned moving large amounts of information between PostgreSQL and BigQuery, which was not only slow but also prone to add inaccuracies to the data.</p>

<p>It turned out that the only way there was to avoid BigQuery altering the geometries on input <a href="https://cloud.google.com/bigquery/docs/gis-data#loading_geojson_data">was to use the GeoJSON</a> format (<a href="https://postgis.net/docs/ST_AsGeoJSON.html">ST_AsGeoJSON</a>) which outputs a JSON with the geometry in its text form, and I had <a href="https://www.youtube.com/watch?v=4P_kbF0EbZM">just watched</a> Stephan T. Lavavej talk where he explained how they had improved the performance of the conversion from floating point numbers to string in Microsoft‚Äôs <a href="https://github.com/microsoft/STL">C++ Standard Library</a>. Those two things clicked in my head: If I could apply a similar approach inside PostGIS, we would print geometries 10x faster. Once I started exploring the code and deciding how to best approach the issue I also found several quick enhancements that could be both to text and binary output functions so the task grew but the spirit remained: Let‚Äôs make getting geometries out of PostGIS faster.</p>

<h2 id="floating-point-to-string">Floating point to string</h2>

<p>The foundation on which Microsoft‚Äôs &lt;charconv&gt; change rested was <strong>Ry≈´</strong>, an <a href="https://github.com/ulfjack/ryu">algorithm</a> developed by Ulf Adams that greatly improved the speed of float to string conversion, which is likely to be one of the most used functions in computer programs. Think about how many times we print numbers every day: anything from logs, reports, showing them on screen, ETLs‚Ä¶ Improving  a function like this means a direct reduction in the energy we use on our devices and data centers, which means that it literally avoids the emission of tons of CO2, which reduces the impact of mankind on climate, slightly tipping the scale on our favor in the fight to save the world from ourselves.</p>

<p>Most developers don‚Äôt need to know how to convert a floating point number to string since the standard libraries or the programming languages themselves give us that functionality, and in an ideal world the enhancements introduced by Ry≈´ would be automagically implemented everywhere solving all of our problems. Sadly for us the reality is different and the changes in the output (when compared with the traditional <code>printf</code> output) and the extremely long process to update core system libraries means that there is always more work to do. So although not every programmer has to care about this kind of stuff, some do. For example, Andrew Gierth (a.k.a. our beloved <a href="http://blog.rhodiumtoad.org.uk/">RhodiumToad</a> on IRC) brought Ry≈´‚Äôs improvements to PostgreSQL 12 and I set up to emulate him and do the same in PostGIS.</p>

<h3 id="first-implementation-a-hack">First implementation: A hack</h3>

<p>The first step in the process was to confirm the estimation of how impactful the change would be. I wasn‚Äôt looking for a perfect match, instead I just wanted to get something that was close enough to the existing coordinate output with a much better performance.</p>

<p>Since PostgreSQL 12 had introduced a similar change, I modified PostGIS‚Äô <a href="https://github.com/postgis/postgis/blob/d1a410ac26b96d325aebc5915fd5a591da5ba934/liblwgeom/lwprint.c#L455"><code>lwprint_double</code></a> to use those functions directly with an ugly hack that involved hardcoding compiler and linker flags relative to my local installation. This confirmed that I was in the correct path as I saw a <strong>3-4x</strong> improvement in performance in <code>ST_AsText</code>. From that moment, I knew that working on a clean integration was indeed worth it.</p>

<h3 id="second-implementation-ry≈´">Second implementation: Ry≈´</h3>

<p>With the proven thesis I moved on to integrate the library into PostGIS itself. In the proposed change (<a href="https://github.com/postgis/postgis/pull/523/">#523</a>) I used Ry≈´‚Äôs <code>d2fixed_buffered_n</code> and <code>d2exp_buffered_n</code> to print coordinates and it worked great: depending on the function (and what percentage of the CPU time was actually spent printing doubles) they became <strong>1.2x to 8x</strong> as fast as they were in 3.0. Nevertheless I did find several points of friction when trying to match the previous output:</p>

<ul>
  <li>
    <p>It printed as many decimal digits as required by the caller. This was in part because it was hard to know how many digits you needed to ensure the number you printed would be reimported as exactly the same binary number, and in many occasions it lead to having a lot of meaningless data: for example, <code>0.3</code> with precision <code>40</code> becomes <code>0.2999999999999999888977697537484345957637</code>.</p>
  </li>
  <li>
    <p>The previous implementation had some bugs with the precision parameter (which determines how many <strong>decimal</strong> digits are included) and sometimes returned less characters than requested. Those issues had to be addressed.</p>
  </li>
  <li>
    <p>I couldn‚Äôt simply replace the old call to <code>sprintf</code> with Ryu‚Äôs functions because 3.0 did extra operations like trimming trailing zeros. I initially added this truncation to our version of Ry≈´ but I wasn‚Äôt very happy with the change since I was adding characters to the buffer to remove them moments later.</p>
  </li>
  <li>
    <p>Ry≈´‚Äôs <code>d2fixed_buffered_n</code> doesn‚Äôt provide a way to limit the precision of the output. My initial implementation truncated the string result, which was slow and wrong as it didn‚Äôt do proper rounding.</p>
  </li>
</ul>

<p>With all this in mind I decided that I would rather break compatibility and change the coordinate output format to provide a faster and more human friendly alternative. Hopefully with less bugs.</p>

<h3 id="third-implementation-custom-ry≈´">Third implementation: Custom Ry≈´</h3>

<p>The final step, which will be part of PostGIS 3.1, was focused on getting a better coordinate output while keeping the performance improvements of the second iteration. After multiple tests and discussions, the final decision was to use the following rules:</p>

<ul>
  <li>
    <p>Use the <strong>shortest representation</strong>, which is enough to guarantee round-trip safety. <code>0.3</code> will always be represented as <code>0.3</code> for any precision greater than 0.</p>
  </li>
  <li>
    <p>Use scientific notation for absolute numbers smaller than <code>1e-8</code>. The previous behaviour was to output <code>0</code> for absolute values smaller than <code>1e-12</code>, which meant a precision loss around zero.</p>
  </li>
  <li>
    <p>Use scientific notation for absolute numbers greater than <code>1e+15</code>, which was the same behaviour as before.</p>
  </li>
  <li>
    <p>The precision parameter still limits only the number of decimal digits of the output but now it is applied with proper rounding to the shortest representation, that is it will only trim <strong>meaningful</strong> decimal digits. It will also be applied exactly in the same way to all text output functions.</p>
  </li>
  <li>
    <p>The precision parameter now also affects the scientific notation too, whereas before the precision for large numbers was fixed to between 5 and 8 digits.</p>
  </li>
  <li>
    <p>The default precision value remains unchanged: <code>9</code> for GeoJSON and <code>15</code> for everything else.</p>
  </li>
</ul>

<p>The <a href="https://github.com/postgis/postgis/pull/570">new code</a> is based on Ry≈´‚Äôs <code>d2s</code> and modified to handle the format defined above and has a faster and more consistent output than before. Let‚Äôs see an example of the same geometry at different precision levels:</p>

<h4 id="postgis-30">Postgis 3.0:</h4>

<div><div><pre><code><span>SELECT</span> <span>x</span><span>,</span> <span>ST_AsText</span><span>(</span><span>ST_MakePoint</span><span>(</span><span>0</span><span>.</span><span>3</span><span>,</span> <span>22</span><span>.</span><span>200000000000003</span><span>),</span> <span>x</span><span>)</span>
<span>FROM</span> <span>generate_series</span><span>(</span><span>1</span><span>,</span> <span>20</span><span>,</span> <span>2</span><span>)</span> <span>x</span><span>;</span>
 <span>x</span>  <span>|</span>                     <span>st_astext</span>                     
<span>----+---------------------------------------------------</span>
  <span>1</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>2</span><span>)</span>
  <span>3</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>2</span><span>)</span>
  <span>5</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>2</span><span>)</span>
  <span>7</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>2</span><span>)</span>
  <span>9</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>2</span><span>)</span>
 <span>11</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>2</span><span>)</span>
 <span>13</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>2</span><span>)</span>
 <span>15</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>2</span><span>)</span>
 <span>17</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>29999999999999999</span> <span>22</span><span>.</span><span>200000000000003</span><span>)</span>
 <span>19</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>2999999999999999889</span> <span>22</span><span>.</span><span>20000000000000284</span><span>)</span>
<span>(</span><span>10</span> <span>rows</span><span>)</span>
</code></pre></div></div>

<h4 id="postgis-31">Postgis 3.1:</h4>

<div><div><pre><code><span>SELECT</span> <span>x</span><span>,</span> <span>ST_AsText</span><span>(</span><span>ST_MakePoint</span><span>(</span><span>0</span><span>.</span><span>3</span><span>,</span> <span>22</span><span>.</span><span>200000000000003</span><span>),</span> <span>x</span><span>)</span>
<span>FROM</span> <span>generate_series</span><span>(</span><span>1</span><span>,</span> <span>20</span><span>,</span> <span>2</span><span>)</span> <span>x</span><span>;</span>
 <span>x</span>  <span>|</span>           <span>st_astext</span>           
<span>----+-------------------------------</span>
  <span>1</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>2</span><span>)</span>
  <span>3</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>2</span><span>)</span>
  <span>5</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>2</span><span>)</span>
  <span>7</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>2</span><span>)</span>
  <span>9</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>2</span><span>)</span>
 <span>11</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>2</span><span>)</span>
 <span>13</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>2</span><span>)</span>
 <span>15</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>200000000000003</span><span>)</span>
 <span>17</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>200000000000003</span><span>)</span>
 <span>19</span> <span>|</span> <span>POINT</span><span>(</span><span>0</span><span>.</span><span>3</span> <span>22</span><span>.</span><span>200000000000003</span><span>)</span>
<span>(</span><span>10</span> <span>rows</span><span>)</span>
</code></pre></div></div>

<p>We can see the two most noticeable changes here:</p>

<ul>
  <li>
    <p><code>0.29999999999999999</code> represents the same binary value as <code>0.3</code>, so in 3.1 we always prefer <code>0.3</code> as it‚Äôs sorter and still safe for a round trip.</p>
  </li>
  <li>
    <p>At precision 15, you already have enough digits to show <code>22.200000000000003</code> which, but due to a bug, wouldn‚Äôt show until precision 17 in 3.0. As it‚Äôs the case for <code>0.3</code>, that number already has as many digits as needed to uniquely identify a binary floating point number, so there is no need to add more digits in higher precision levels.</p>
  </li>
</ul>

<h2 id="other-changes">Other changes</h2>

<p>Once you speed up the slowest wheel in the process others raise in importance or even become the new bottleneck, so aside from introducing Ry≈´ and changing the coordinate output format I also applied several other performance improvements:</p>

<ul>
  <li>
    <p>In many output functions, both in text and binary output, we now generate the exact buffer that we are going to return to PostgreSQL instead of a temporary one that later needs to be copied to add a header (<a href="https://github.com/postgis/postgis/pull/541">#541</a>).</p>
  </li>
  <li>
    <p>We no longer use intermediate buffers when printing individual coordinates (<a href="https://github.com/postgis/postgis/pull/573">#573</a>) to avoid <code>memcpy</code> and <code>strlen</code> calls (<a href="https://github.com/postgis/postgis/pull/537">#537</a>, <a href="https://github.com/postgis/postgis/commit/87922037fd09b68ad2ada409f776e06590924256">r8792203</a>).</p>
  </li>
  <li>
    <p>In functions that need the SRS for the output (like ST_AsGML or optionally ST_AsGeoJSON) we cache it instead of generating it for each row (<a href="https://github.com/postgis/postgis/pull/557">#557</a>). We also avoid SQL inlines where the cache is destroyed after each row, which made it useless (<a href="https://github.com/postgis/postgis/pull/561">#561</a>). This also affects <a href="https://postgis.net/docs/ST_GeomFromGeoJSON.html">ST_GeomfromGeoJSON</a> and the the equivalent <code>'{}'::geometry</code>.</p>
  </li>
  <li>
    <p>I also adapted the cost of the SQL functions to help PostgreSQL planner make better decisions (<a href="https://github.com/postgis/postgis/pull/556">#556</a>).</p>
  </li>
</ul>

<h2 id="performance-comparison">Performance comparison</h2>

<p>For most of the benchmarks I‚Äôll use the <a href="https://open.canada.ca/data/en/dataset/a883eb14-0c0e-45c4-b8c4-b54c4a819edb">Boundaries of Canada Provinces</a> dataset, which contains only 13 multipolygons with an average of 260k points and over 2000 rings. It‚Äôs my favourite ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rmr.ninja/2020-12-06-waiting-for-postgis-3-1-output/">https://rmr.ninja/2020-12-06-waiting-for-postgis-3-1-output/</a></em></p>]]>
            </description>
            <link>https://rmr.ninja/2020-12-06-waiting-for-postgis-3-1-output/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25350465</guid>
            <pubDate>Tue, 08 Dec 2020 19:54:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The State of Ruby Static Typing at Shopify]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25350136">thread link</a>) | @theBashShell
<br/>
December 8, 2020 | https://shopify.engineering/the-state-of-ruby-static-typing-at-shopify | <a href="https://web.archive.org/web/*/https://shopify.engineering/the-state-of-ruby-static-typing-at-shopify">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>Shopify changes a lot. We merge around 400 commits to the main branch daily and deploy a new version of our core monolith 40 times a day. The Monolith is also big: 37,000 Ruby files, 622,000 methods, more than 2,000,000 calls. At this scale with a dynamic language, even with the most rigorous review process and over 150,000 automated tests, it‚Äôs a challenge to ensure everything works properly. Developers benefit from a short feedback loop to ensure the stability of our monolith for our merchants.</p>
<p>Since 2018, our Ruby Infrastructure team has looked at ways to make the development process safer, faster, and more enjoyable for Ruby developers. While Ruby is different from other languages and brings amazing features allowing Shopify to be what it is today, we felt there was a feature from other languages missing: static typing.</p>

<p>On&nbsp;November 25, 2020, Shipit!, our monthly event series, presented The State of Ruby Static Typing at Shopify. Alexandre Terrasa and I talked about the history of static typing at Shopify and our adoption of Sorbet.</p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/DA9gPuBkhFk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>We weren't able to answer all the questions during the event, so we've included answers to&nbsp;them&nbsp;below.</p>
<p><strong>What are some challenges with adopting Sorbet? What was some code you could not type?</strong></p>
<p>So far most of our problems are in modules that use ActiveSupport::Concern (many layers deep, even) and modules that assume they will be included in a certain kind of class, but have no way of making that explicit. For example, a module that assumes it will be included in an ActiveRecord model could be calling <code>before_save</code> to add a hook, but Sorbet would have no idea where <code>before_save</code> is defined. We are also looking to make those kinds of dependencies between modules and include sites explicit in Sorbet.</p>
<p>Inclusion requirements is also something we‚Äôre trying to fix right now, mostly for our helpers. The problem is explained in the description of this pull-request: <a href="https://github.com/sorbet/sorbet/pull/3409" target="_blank" title="Allow modules and classes to specify required ancestors #3409" rel="nofollow noopener noreferrer">https://github.com/sorbet/sorbet/pull/3409</a>.</p>
<p><strong>If a method has an array in argument, do you have to specify it is an array of what type? And if not, how do Sorbet makes the method you call on the array's element exists?</strong></p>
<p>It depends on the type of elements inside the array. For simple types like Integer or Foo, you can easily type it as <code>T::Array[Integer]</code> and Sorbet will be able to type check method calls. For more complex types like arrays containing hashes it depends, you may use <code>T::Array[T.untyped]</code> in which case Sorbet won‚Äôt be able to check the calls. Using <code>T.untyped</code> you can go as deep and precise you want it to be: <code>T::Array[T::Hash[String, T.untyped]]</code>, <code>T::Array[T::Hash[String, T::Array[T.untyped]]]</code>, <code>T::Array[T::Hash[String, T::Array[Integer]]]</code> and Sorbet will check the calls on what it knows about. Note that as your type becomes more and more complex, maybe you should start thinking about making a class about it so you can just use <code>T::Array[MyNewClass]</code>.</p>
<p><strong>How would you compare the benefits of Sorbet to Ruby relative to the benefits of Typescript to Javascript?</strong></p>
<p>There are similar benefits, but Ruby is a much more dynamic language than JavaScript and Sorbet is a much younger project than TypeScript. So the coverage of Ruby features and expressiveness of the type system of Sorbet lags behind the same benefits that TypeScript brings to JavaScript.On the other hand, Sorbet annotations are pure Ruby. That means you don‚Äôt have to learn a new language and you can keep using your existing editors and tooling to work with it. There is also no compilation of Ruby code with types to plain Ruby, like how you need to compile TypeScript to JavaScript. Finally, Sorbet also has a runtime type-checker and it can verify your types and alert you if they don‚Äôt check when your application is running, which is a great additional safety that TypeScript does not have.</p>
<p><strong>Could you quickly relate Sorbet with RBS and what is the future of sorbet after Ruby 3.0?</strong></p>
<p>Stripe gave an interesting answer to this question: <a href="https://sorbet.org/blog/2020/07/30/ruby-3-rbs-sorbet" target="_blank" rel="nofollow noopener noreferrer">https://sorbet.org/blog/2020/07/30/ruby-3-rbs-sorbet</a>. RBS is about the language to write the signatures, you still need a type checker to check those signatures against your code. We see Sorbet as one of the solution that can use those types, and currently it‚Äôs the fastest solution. One limitation of RBS is the lack of inline type annotations, for example there is no syntax to cast a variable to another type. So type checkers have to use additional syntax to make this possible. Even if Sorbet doesn‚Äôt support RBS at the moment, it might in the future. And in the case it never happens, remember that it‚Äôs easier to go from one type specification to another rather than an untyped codebase to a typed one. So all the efforts are not lost.</p>
<p><strong>Does Tapioca support Enums etc?</strong></p>
<p>Tapioca is able to generate RBI files for T::Enum definitions coming from gems. It can also generate method definitions for the ActiveRecord enums as DSL generators.</p>
<p><strong>In which scenarios would you NOT use Sorbet?</strong></p>
<p>I guess the one scenario where using Sorbet would be counterproductive is if there is no team buy-in for adopting Sorbet. If I were on such a team and I couldn‚Äôt convince the rest of the team of the utility of it, I would not push to use Sorbet.Other than that, I can only think of a code base that has a LOT of metaprogramming idioms to be a bad target for using Sorbet. You would still get some benefits from even running Sorbet at <code>typed: false</code> but it might not be worth the effort.</p>
<p><strong>What editors do you personally use? Any standardization across the organization?</strong></p>
<p>We have not standardized on a single editor across the company and we probably will not do so, since we believe in developers‚Äô freedom to use the tools that make them the most productive. However, we also cannot build tooling for all editors, either. So, most of our developer acceleration team builds tooling primarily for VSCode, today. Ufuk personally uses VSCode and Alex uses VIM.</p>
<p><strong>Is there a roadmap for RBI -&gt; RBS conversion for when Ruby 3.0 comes out?</strong></p>
<p>No official roadmap yet, we‚Äôre still experimenting with this on the side of our main project: 100% typed: true files in our monolith. We can already say that some features from RBS will not directly translate to RBI and vice versa. You can see a comparison of both specifications here: <a href="https://github.com/Shopify/rbs_parser#whats-supported" target="_blank" title="rbs_parser What's supported" rel="nofollow noopener noreferrer">https://github.com/Shopify/rbs_parser#whats-supported</a> (might not be completely up-to-date with the latest version of RBS).</p>
<p><strong>What are the major challenges you had or are having with Ruby GraphQL libraries?</strong></p>
<p>Our team tried to marry the GraphQL typing system and the Sorbet types using RBI generation but we got stuck in some very dynamic usages of GraphQL resolvers, so we paused that work for now. On the other hand, there are teams within Shopify who have been using Sorbet and GraphQL together by changing the way they write GraphQL endpoints. You can read more about the technical details of that from the blog post of one of the Shopify engineers that has worked on that: <a href="https://gmalette.dev/posts/graphql-and-sorbet-and-unit-tests/" target="_blank" title="GraphQL love Sorbet and Unit Tests" rel="nofollow noopener noreferrer">https://gmalette.dev/posts/graphql-and-sorbet-and-unit-tests/</a>.</p>
<p><strong>What would be the first step in getting started with typing in a Rails project? What are kind of files that should be checked in to a repo?</strong></p>
<p>The fastest way to start is to use the steps listed on the Sorbet site to start running with Sorbet. After doing that, you can take a look at using <code>sorbet-rails</code> to generate Rails RBI files for you, or you can look at <code>tapioca</code> to generate gem RBIs. Since you can go gradual it‚Äôs totally up to you.</p>
<p>Our advice would be to first target all files at <code>typed: false</code>. If you use tapioca, the price is really low and already brings a lot of benefit. Then try to move the files to <code>type: true</code> where it does not create new type errors (you can use <code>spoom</code> for that: <a href="https://github.com/Shopify/spoom#change-the-sigil-used-in-files" target="_blank" title="Change the sigil used in files - spoom" rel="nofollow noopener noreferrer">https://github.com/Shopify/spoom#change-the-sigil-used-in-files</a>).</p>
<p>When it comes to adding signatures, prefer the files that are the most reused or, if you track the errors from production, going first with the files that create the most errors might be a good choice. Files touched by many teams are also an interesting target as signatures make collaboration easier. Files with a lot of churn. Or files defining methods reused a lot across your codebase.</p>
<p>As for the files that you need to check-in to a repository, the best practice is to check-in all the files (mostly RBI files) generated by Sorbet and/or tapioca/sorbet-typed. Those files enable the code to be type checked, so should be available to all the developers that work on the code base.</p>

<ul>
<li><a href="https://shopify.engineering/static-typing-ruby" target="_blank" rel="nofollow noopener noreferrer">Static Typing for Ruby</a></li>
<li><a href="https://shopify.engineering/adopting-sorbet" target="_blank" rel="nofollow noopener noreferrer">Adopting Sorbet at Scale</a></li>
<li><a href="https://shopify.engineering/writing-better-type-safe-code-with-sorbet" target="_blank" title="Writing Better, Type-safe Code with Sorbet - Shopify Engineering" rel="nofollow noopener noreferrer">Writing Better, Type-safe Code with Sorbet</a></li>
<li><a href="https://shopify.engineering/shopify-monolith" target="_blank" title="Under Deconstruction: The State of Shopify‚Äôs Monolith" rel="nofollow noopener noreferrer">Under Deconstruction: The State of Shopify‚Äôs Monolith</a></li>
</ul>
<p><strong>Open Source</strong></p>
<ul>
<li>
<a href="https://github.com/Shopify/tapioca" target="_blank" title="Tapioca" rel="nofollow noopener noreferrer">Tapioca</a>&nbsp;&nbsp;</li>
<li><a href="https://github.com/Shopify/spoom" target="_blank" title="Spoom" rel="nofollow noopener noreferrer">Spoom</a></li>
<li>
<a href="https://github.com/Shopify/rubocop-sorbet" target="_blank" title="rubocop-sorbet" rel="nofollow noopener noreferrer">RuboCop Sorbet</a>&nbsp;</li>
</ul>
<hr>
<p>We're planning to DOUBLE our engineering team in 2021 by hiring 2,021 new technical roles (see what we did there?). Our platform handled record-breaking sales over BFCM and commerce isn't slowing down.&nbsp;<a href="https://www.shopify.com/careers/2021" target="_blank" title="We‚Äôre planning to double our engineering team in 2021 by hiring 2,021 new technical roles" rel="noopener noreferrer">Help us scale &amp; make commerce better for everyone</a>.</p>
</div></div>]]>
            </description>
            <link>https://shopify.engineering/the-state-of-ruby-static-typing-at-shopify</link>
            <guid isPermaLink="false">hacker-news-small-sites-25350136</guid>
            <pubDate>Tue, 08 Dec 2020 19:29:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Serverless Express project graduates from AWS to Vendia]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25349602">thread link</a>) | @timawagner
<br/>
December 8, 2020 | https://vendia.net/blog/serverless-express-finds-home-at-vendia | <a href="https://web.archive.org/web/*/https://vendia.net/blog/serverless-express-finds-home-at-vendia">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><span><blockquote><p><em>Tl;dr</em>: The <a href="https://github.com/vendia/serverless-express">aws-serverless-express</a> open source project has graduated from <a href="http://github.com/awslabs/">AWS Labs</a> and is now being actively supported and sponsored by Vendia!</p></blockquote><p><img width="400" src="https://user-images.githubusercontent.com/532272/101377847-35c7b700-3867-11eb-9198-4fcaa66ddfdd.jpg"></p><h2 id="about-serverless-express"><span data-href="#about-serverless-express">
      <svg>
        <use href="#link-out"></use>
      </svg>
    </span><a href="#about-serverless-express">About Serverless Express</a></h2><p>Back in 2016 I was General Manager of two up-and-coming AWS Services: <a href="https://aws.amazon.com/lambda/">AWS Lambda</a> and <a href="https://aws.amazon.com/api-gateway/">Amazon API Gateway</a>.</p><p>APIs were already well understood by our customer base, but selling Lambda was initially a little more difficult - not only was the idea of a fully managed, pay-by-the-call function hosting service a novelty among public cloud providers, it was also very different from existing developer practices. Case in point: <em>Express-based web services</em>.</p><p>Lambda launched with support for <a href="https://nodejs.org/en/">Node.js</a>, which helped a lot of customers start using it easily, given their existing familiarity with <a href="https://www.javascript.com/">JavaScript</a>. But for many customers, just having a familiar language wasn‚Äôt enough ‚Äî they were also looking for familiar frameworks, such as <a href="https://expressjs.com/">Express</a>, on which to build their Lambda-based web applications.</p><p>After hearing this feedback from many customers, we realized we needed to ‚Äúmeet customers where they were‚Äù by bringing Serverless solutions to existing frameworks‚Ä¶.and thus the <a href="https://github.com/vendia/serverless-express">Serverless Express GitHub project</a> was born!</p><p>Over the course of the last four years many developers have adopted Serverless solutions, including Serverless Express, to help accelerate development and gain Serverless benefits like lower operational overhead, automatic per-request scaling, built-in fault tolerance, and pay-per-call pricing. Today, the <a href="https://www.npmjs.com/package/aws-serverless-express">aws-serverless-express</a> NPM package gets over 1.3M downloads per month, and its GitHub repository has over 3.7K stars.</p><p>The original author of the Serverless Express project, <a href="https://twitter.com/AWSbrett">Brett Andrews</a>, joined <a href="http://vendia.net/">Vendia</a> recently, and we realized we can do even more in our mission to help customers share code and data effectively by giving back to the open source community by helping the Serverless Express project ‚Äúgraduate‚Äù from its initial location in AWS Labs to a permanent place in Vendia‚Äôs repository. As the original project sponsor, and with the guidance of the project‚Äôs original author, AWS trusted us to being thoughtful and proactive stewards of this project. We will continue meeting with AWS monthly to gather customer feedback, and be briefed on upcoming AWS Serverless releases so that we may be a launch partner and provide day 1 support in Serverless Express.</p><h2 id="migration-instructions"><span data-href="#migration-instructions">
      <svg>
        <use href="#link-out"></use>
      </svg>
    </span><a href="#migration-instructions">Migration Instructions</a></h2><p>If you‚Äôre an existing Serverless Express user, you don‚Äôt need to take any immediate action. For convenience we‚Äôve published <a href="https://www.npmjs.com/package/aws-serverless-express">aws-serverless-express v3.4.0</a> that takes a direct dependency on the new official package <a href="https://www.npmjs.com/package/@vendia/serverless-express">@vendia/serverless-express@^3.4.0</a>.</p><p>This means that by simply upgrading to <a href="mailto:aws-serverless-express@3.4.0">aws-serverless-express@3.4.0</a> you‚Äôll get all downstream patches and features without needing to update your code. Alternatively, you can run the following command  to take a direct dependency on the new official package</p><pre><code><span>npm</span> uninstall aws-serverless-express <span>&amp;&amp;</span> <span>npm</span> <span>install</span> @vendia/serverless-express
</code></pre><p>After updating the deps, update your code accordingly - e.g., change your imports.</p><pre><code><span>- require('aws-serverless-express')
</span><span>+ require('@vendia/serverless-express')
</span></code></pre><p>If you're new to Serverless Express and wondering how to get started, you can deploy a Serverless REST API to AWS in under 5 minutes by following the <a href="https://github.com/vendia/serverless-express/tree/master/examples/basic-starter">Serverless Express Basic Starter on GitHub</a>.</p><h2 id="whats-next"><span data-href="#whats-next">
      <svg>
        <use href="#link-out"></use>
      </svg>
    </span><a href="#whats-next">Whats Next</a></h2><p>In January 2021 we'll be releasing Serverless Express v4 that:</p><ol><li>Supports event sources other than API Gateway such as ALB, Lambda Edge, HTTP API, and makes it easy to provide your own custom event source mapping for other services that are integrated with Lambda</li><li>Has improved logging and debugging support</li><li>Is more extensible and simpler to use with an improved developer experience</li><li>Uses Promise resolution by default</li><li>Is upgraded to Node.js 10 (compatible with Node.js 12+)</li><li>Makes it easier to work with Custom Domain Names</li><li>Has improved documentation and examples</li><li>Supports Multiple header values</li></ol><p><em>What‚Äôs in it for Vendia?</em> First of all, Brett and I feel a strong connection to helping the Serverless community succeed. Technologies like Lambda, managed API and database services, and other Serverless offerings power Vendia‚Äôs implementations and help us deliver scalable, low-cost code and data sharing solutions for our customers. We also continue to believe strongly in the mission of Serverless Express: To give developers a simple, scalable platform that meets them where they are, and then helps them gain the best of what the cloud has to offer...without unnecessary retraining, rewriting, or porting exercises. We're also excited to find ways to bring Vendia Share - the next generation Serverless platform - and Serverless Express users closer together with easy ways to use both platforms in combination.</p><p>To all the existing (and future) Serverless Express users, we look forward to making your experience even better. To all the project contributors, we look forward to being great partners, building on your existing contributions and successes in this project. And to AWS, a huge ‚ÄúThank You‚Äù for believing in this idea back when it felt risky and uncertain,and for allowing it to leave the nest now that it‚Äôs grown. Stay tuned for more technical and project roadmap details coming soon...and <em>Go Serverless!</em></p><p>Tim Wagner, Vendia CEO (and former AWS Lambda General Manager) &amp;
Brett Andrews, Vendia Senior Developer (and former Amazon API Gateway Developer)</p></span></p></div></div></div></div>]]>
            </description>
            <link>https://vendia.net/blog/serverless-express-finds-home-at-vendia</link>
            <guid isPermaLink="false">hacker-news-small-sites-25349602</guid>
            <pubDate>Tue, 08 Dec 2020 18:43:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Graph Programming]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25349502">thread link</a>) | @puttycat
<br/>
December 8, 2020 | https://www.hyro.ai/post/graph-programming | <a href="https://web.archive.org/web/*/https://www.hyro.ai/post/graph-programming">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Composition is like taking two things and connecting them. Not one thing is on top of, embedded or superior to the other, they just feed into each other. Consequently the functions involved are oblivious to one another, which is great because you get to mix and match, test and debug them separately.</p><p>Most composition utils or libraries will generate a new function or object that represents the composition of its constituents, but it is no longer possible to refer to the constituents. You sort of get a new impenetrable box (nesting all over again).</p><p>In typical composition you can continue composing into or out of this box, as long as the composition is done on the sides, and not the individual constituents. However, if you have non-unary functions, you need to start using currying and things may get complicated.</p><p>As humans we don‚Äôt think or talk this way, we can refer to concepts arbitrarily and compose freely in a non-unary fashion.</p><p>This work presents the notion of graph programming, a way to program by building graphs of functions from connecting pairs of functions in a non-enclosing way, and aims to replace typical function composition.</p><h2>Prerequisites</h2><p>I will use python to illustrate my examples. I will also be using a functional programming style.</p><p>You should be familiar with <strong><em>compose_left</em></strong> , <strong><em>pipe </em></strong>and<strong><em> curry</em></strong> to follow along.</p><p>In case you are not, here are plausible implementations for the first two:</p><figure id="w-node-2597c9518367-ecc4c967"><p><img src="https://uploads-ssl.webflow.com/5e28111d4277514e827921e5/5fbce2dbb35bb5f2e8168c57_Screen%20Shot%202020-11-24%20at%2012.39.04.png" loading="lazy" alt=""></p></figure><p>As for <strong><em>curry</em></strong> since its implementation is a bit less trivial you can use this usage example to get an idea about what it does:</p><figure id="w-node-24bb02446013-ecc4c967"><p><img src="https://uploads-ssl.webflow.com/5e28111d4277514e827921e5/5fbce30681fb5263ead5a8be_Screen%20Shot%202020-11-24%20at%2012.39.55.png" loading="lazy" alt=""></p></figure><h2>Non linear programs</h2><p>Consider the following situation, where you have the following pipeline:</p><p><strong><em>foo = compose_left(x_1, x_2, ..., x_n)</em></strong></p><p><strong><em>foo</em></strong> is a composition of some functions. Great.</p><p>Now imagine the case where <strong><em>x_n</em></strong> gets two arguments, instead of just one. So we can no longer have this composition by itself, and we are required to use currying and an extra <strong><em>def</em></strong> like so:</p><figure id="w-node-ab79ecf119f3-ecc4c967"><p><img src="https://uploads-ssl.webflow.com/5e28111d4277514e827921e5/5fbce3c05e7511ace38ff0da_Screen%20Shot%202020-11-24%20at%2012.43.03.png" loading="lazy" alt=""></p></figure><p>Currying is great, because we don‚Äôt need to complicate <strong><em>x_n</em></strong> to express that it will get its two dependencies in two different places in the code. <strong><em>side_input</em></strong> will find its way into <strong><em>x_n</em></strong> as <strong><em>arg2</em></strong>.</p><p>Still there is some leakage here. We needlessly expose the rest of the composition code to <strong><em>side_input</em></strong>. This could become pretty messy if I have many dependencies, and I want to give them at different times.</p><p>Consider the case where <strong><em>x_n</em></strong> is a member of two independent pipelines, each giving it a different input.</p><p>We might try to program it like this (which obviously won‚Äôt work):</p><figure id="w-node-00fd916ff7c5-ecc4c967"><p><img src="https://uploads-ssl.webflow.com/5e28111d4277514e827921e5/5fbce407256a75d5466fce22_Screen%20Shot%202020-11-24%20at%2012.44.14.png" loading="lazy" alt=""></p></figure><p>Calling <strong><em>foo</em></strong> or <strong><em>bar</em></strong> would give us a familiar exception about <strong><em>baz</em></strong> expecting two arguments but got only one.</p><p>We can overcome this with some imperative style:</p><figure id="w-node-ea6e64bb6715-ecc4c967"><p><img src="https://uploads-ssl.webflow.com/5e28111d4277514e827921e5/5fbce43672e5af3fcca58c93_Screen%20Shot%202020-11-24%20at%2012.44.57.png" loading="lazy" alt=""></p></figure><p>And while this works for simple cases, it would not scale to the general case. If I had several functions connected at different stages, I would then have to give up the composition notation and end up in imperative style, or simply have a single large function where everything is exposed to everything.</p><p>‚Äç</p><figure><p><img src="https://uploads-ssl.webflow.com/5e28111d4277514e827921e5/5fbce45cef0f2f3695f27d2b_Graph_Programming_by_uri_1.png" loading="lazy" alt=""></p><figcaption><br></figcaption><figcaption>Complex dependency structure (<em>Image by author</em>)</figcaption></figure><p>‚Äç</p><p>Imagine having to write a single signature to support the above structure. It would have to be the union of <strong><em>d3</em></strong>, <strong><em>d1</em></strong>, <strong><em>p1</em></strong>, <strong><em>d2</em></strong>. The function body itself would expose the variables globally, and it would be pretty hard to understand the dependency structure.</p><p>As humans it‚Äôs pretty obvious how to express it. We just draw it. Let‚Äôs get back to the simple example above.</p><p>‚Äç</p><figure><p><img src="https://uploads-ssl.webflow.com/5e28111d4277514e827921e5/5fbce4cdb35bb578f7169176_Graph_Programming_by_uri_2.png" loading="lazy" alt=""></p><figcaption><br></figcaption><figcaption>No currying needed when you can draw (<em>Image by author</em>)</figcaption></figure><p>We can ‚Äúcode‚Äù it too, for example this is the code I used to generate the above image:</p><figure id="w-node-df6a04ac2ec9-ecc4c967"><p><img src="https://uploads-ssl.webflow.com/5e28111d4277514e827921e5/5fbce6299ba3354de8502d28_Screen%20Shot%202020-11-24%20at%2012.53.19.png" loading="lazy" alt=""></p></figure><p>So I should be able to do the same when programming.</p><h2>Prographers</h2><p>The word ‚Äúgraph‚Äù itself comes from drawing or painting, and this is really the right sense. We want to be able to draw programs, because our mental models of them are nonlinear structures*.</p><p>*The word programming itself comes from the earlier Greek word ‚Äúprographein‚Äù. We are all really just prographers.</p><p><a href="https://github.com/hyroai/computation-graph">https://github.com/hyroai/computation-graph</a> implements the first graph-programming framework, in python.</p><p>It allows taking pure functions written in plain python, and declare their dependencies explicitly, without them being aware of each other. That is similar to any function composition framework. What cg does beyond that is a few other tricks.</p><h2>Non linear composition</h2><p>The first trick is generalizing composition to non unary functions, and pipelines to directed acyclic graphs (DAGs). Dependencies are not only ‚Äúlines‚Äù, and so we should be able to, for example, connect two lines into a binary function. I only need to state the keyword I‚Äôm composing on to make this example complete.</p><p>An example:</p><figure id="w-node-cba60e3ef9ba-ecc4c967"><p><img src="https://uploads-ssl.webflow.com/5e28111d4277514e827921e5/5fbce64c09e861c77ba2247f_Screen%20Shot%202020-11-24%20at%2012.53.54.png" loading="lazy" alt=""></p></figure><p>Each composition is essentially a collection of edges, with some syntactic sugar that allows you to create substructures easily.</p><h2>Memory</h2><p>Pure functions and compositions are easy to work with. They are easy to test and reason about, and are not exposed to pesky state. But still reality needs programs with memory, or programs which are run a few times and retain some context so we needed to introduce state or memory into pure functions. The popular UI framework React has solved this problem using hooks (e.g. <strong><em>useState</em></strong>). We wanted to be more strict in the purity of the functions that we use, and not introduce any magic calls within the function. In other words we wanted the input to be fully described within the function‚Äôs parameter, and output to be fully defined as the function‚Äôs output.</p><p>We started by implementing a special kind of node, called a reducer. The reducer returns two elements, an output and its memory, and the computation graph framework would give the function its memory on the next ‚Äúturn‚Äù, in a special argument called <strong><em>state</em></strong> (similar to <strong><em>self</em></strong> in python).</p><p>We then realized that this pattern can be implemented in a much simpler way, without any special keyword arguments or constructs. We realized that memory is a dependency into the future. Future here means the next time you run the computation graph. And so we changed the implementation to have something we call ‚Äúfuture edges‚Äù. Future edges describe function composition in the axis of time. So a function can be composed (namely have an edge) onto itself or a some other functions (even functions it supposedly depends on!), without really creating loops. This is because the value needed for the current turn exists from the previous turn.</p><p>When we introduce this concept, we are no longer talking about DAGs, but general graphs, that may have ‚Äúcycles‚Äù (as long as the cycle has at least one future edge to break it).</p><p>Note that when we introduced memory the signature of the entire computation graph becomes two elements, where one is the output and the other is the state, and when we run it again, we make sure to give it the state from the previous turn. So when zooming out, the entire computation graph has the signature of a reducer function.</p><h2>Logging</h2><p>Logging is a classic problem in programming. We write some code to do something, then we want to watch it and log what it is doing. As an example consider the pipeline <strong><em>compose_left(x, y, z_1, ..., z_n)</em></strong>.</p><p>And say we would like to watch the output of <strong><em>y</em></strong>. So we might do something like this:</p><figure id="w-node-84a627a4fed9-ecc4c967"><p><img src="https://uploads-ssl.webflow.com/5e28111d4277514e827921e5/5fbcf05acfb43b949c54f9a5_Screen%20Shot%202020-11-24%20at%2013.36.46.png" loading="lazy" alt=""></p></figure><p>But alas, <strong><em>z_1</em></strong> expects to get the output of <strong><em>y</em></strong>. This means we would have to complicate <strong><em>z_i</em></strong> to handle a pair of elements. We would like to avoid it. With graph programming this is trivial to do. Simply connect <strong><em>y</em></strong> into two facets:</p><figure id="w-node-2ba6874af009-ecc4c967"><p><img src="https://uploads-ssl.webflow.com/5e28111d4277514e827921e5/5fbcf0969bd80df73e79cd5e_Screen%20Shot%202020-11-24%20at%2013.37.48.png" loading="lazy" alt=""></p></figure><h2>Async programming</h2><p>Async in python is really hard to get right. Synchronous functions cannot call async ones and so mixing the two is nontrivial to say the least. In addition you have to carefully select when to <strong><em>await</em></strong> in two consecutive lines, and when to use things like <strong><em>asyncio.gather</em></strong>. But this information, of what needs to happen first, is already in your program. For example, the following example is not efficient.</p><figure id="w-node-318eb353e456-ecc4c967"><p><img src="https://uploads-ssl.webflow.com/5e28111d4277514e827921e5/5fbcf0e14349776252f3a83e_Screen%20Shot%202020-11-24%20at%2013.38.59.png" loading="lazy" alt=""></p></figure><p>This is because we can <strong><em>await</em></strong> on <strong><em>x</em></strong> in parallel to <strong><em>y</em></strong>. But why should we notice it as humans, instead of having it be inferred?</p><p>If we draw it, it becomes obvious.</p><p>‚Äç</p><figure><p><img src="https://uploads-ssl.webflow.com/5e28111d4277514e827921e5/5fbcf14c09e7536fa676e295_Graph_Programming_by_uri_3.png" loading="lazy" alt=""></p><figcaption><br></figcaption><figcaption>(<em>Image by author</em>)</figcaption></figure><p>‚Äç</p><p>And so the computation graph library lets you mix async and synchronous functions, and even infers for you, using a topological sort, what can be run in parallel. This would be written as follows.</p><figure id="w-node-7bd05cbe3efa-ecc4c967"><p><img src="https://uploads-ssl.webflow.com/5e28111d4277514e827921e5/5fbcf190c24a43a2ec3705b7_Screen%20Shot%202020-11-24%20at%2013.41.55.png" loading="lazy" alt=""></p></figure><h2>Ambiguity</h2><p>Another cool feature is that you can actually compose more than one option onto a function, making the graph sort of like a nondeterministic model. This implies that the input can come from either edge. To make results predicable, these edges have priorities, so the computation graph will try the more prioritized edge first, and only if that computation path does not succeed (namely raises a specific exception), will the graph runner attempt a different path.</p><figure id="w-node-bfb6f5f3b95d-ecc4c967"><p><img src="https://uploads-ssl.webflow.com/5e28111d4277514e827921e5/5fbcf1e7cfb43b66c654fd60_Screen%20Shot%202020-11-24%20at%2013.43.21.png" loading="lazy" alt=""></p></figure><p>In the above code, <strong><em>g</em></strong> might get its input from <strong><em>f1</em></strong> or if that doesn‚Äôt work, from <strong><em>f2</em></strong>. Note we use the lower level API here, but this is very similar to <strong><em>compose_left</em></strong>.</p><h2>TODO: Loops</h2><p>The computation graph does not yet support loops. When it will, they would probably be implemented as a special edge as well. This is still in early planning, comments about this (or PRs) are welcome.</p><h2>Small note: Computation graphs and monads</h2><p>Some of the problems discussed above are traditionally solved by monads in functional programming languages. Because I am not experienced myself with working with monads, I choose to leave it for the reader to determine the relationship of graph programming and monads, and may revisit this section in the future.</p><p>Imperative programming is characterized by iterative nesting. A function has embedded calls to other ones. By embedded I mean that these calls are in the function body, and so there is a tight coupling between a function and its constituents. This has many shortcomings and is typically solved by function composition.</p></div></div>]]>
            </description>
            <link>https://www.hyro.ai/post/graph-programming</link>
            <guid isPermaLink="false">hacker-news-small-sites-25349502</guid>
            <pubDate>Tue, 08 Dec 2020 18:36:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notion API]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25349335">thread link</a>) | @theBashShell
<br/>
December 8, 2020 | https://www.notion.so/api-beta | <a href="https://web.archive.org/web/*/https://www.notion.so/api-beta">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/api-beta</link>
            <guid isPermaLink="false">hacker-news-small-sites-25349335</guid>
            <pubDate>Tue, 08 Dec 2020 18:24:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Feature flags and staging environments can be best friends]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25349269">thread link</a>) | @tommy_mcclung
<br/>
December 8, 2020 | https://releaseapp.io/blog/feature-flags-and-ephemeral-environments | <a href="https://web.archive.org/web/*/https://releaseapp.io/blog/feature-flags-and-ephemeral-environments">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><h2 id="feature-flags-and-ephemeral-environments">Feature Flags and Ephemeral Environments</h2><p>Feature Flags are a necessary and ubiquitous part of modern software development.  As your company and the complexity of your application grows it becomes imperative to be able to control what features are available to your internal development teams, stakeholders and customers.  In the long-ago, before-times, we would just have a variable that you would toggle between true and false to control behavior of your application.  However, as application development transitioned to the Web we needed the same kind of control, except that hard-coded feature flags just weren‚Äôt going to cut it. Enter Dynamic Feature Flags!</p><p>Dynamic feature flags were a big improvement over static feature flags, but also added complexity and presented challenges different from static feature flags.  Gone were hard-coded flags, but they were replaced with if statements and more importantly, retrieving the appropriate flags for your application.  Most people started by rolling their own, but as developing with feature flags gained popularity many different companies popped into existence looking to solve the problems of:</p><ul><li>One interface to manage your flags</li><li>Easy maintenance of your flags</li><li>Very fast and reliable retrieval of your flags</li><li>Splitting traffic to one feature or another </li></ul><p>While companies like LaunchDarkly, Optimizely, Rollout, Split.io and others made it fairly easy to create and manage these flags this doesn‚Äôt solve all of your issues.  Many software orgs, especially as they grow, need lots of environments for testing. This poses a challenge to your Feature Flag setup specifically if your environments are ephemeral.</p><p>Ephemeral environments are like any environment except they will be removed in a relatively short amount of time unlike your staging or production environments.  Good examples are:</p><ul><li>Feature branches</li><li>Sales Demos</li><li>Load Testing</li><li>Refactors</li></ul><p>These environments may not last a long time, but they are exceedingly important and can be just as complex as production.  While a sales demo environment may be able to function with seed data, a load testing environment will need production or production-like data and many replicas of each service to give a valid result.  These can be super complex to create and manage and their ephemeral nature can play havoc with your feature flag setup.</p><h2 id="feature-flag-environments-to-the-rescuesort-of">Feature Flag Environments to the Rescue‚Ä¶Sort of</h2><p>LaunchDarkly (and others) recognized this issue and created the concept of environments in their own applications.  You can read about their implementation here.  They have apis that allow you to create and manipulate these sets of feature flags on an environment by environment basis. This works great if you have a finite set of environments and the set of them doesn‚Äôt change often, but with ephemeral environments the ability to spin them up and down is a feature not a bug.</p><p>In order to simplify this issue most people create two kinds of environments in their favorite Feature Flag provider: one for development (or test) and one for production.  In larger organizations development teams may have a few, such as development, test, uat, staging, and production.  This works fine as long as you don‚Äôt want to add another one or you never take the plunge toward truly ephemeral application environments.  </p><p>Once you move to ephemeral environments most people take the shortcut of assigning every ephemeral environment to a single Feature Flag environment, which is simple enough, but creates a large problem with people stepping on each other‚Äôs toes.  </p><p>Imagine you have 10 environments all pointing to a single database with writes happening from all those environments: it‚Äôs the same issue here.  The great thing about feature flags is the ability to toggle them and see different behavior, but if every environment is pointing to the same one you now have another resource contention problem.  If you toggle Feature A ‚Äòon‚Äô what‚Äôs to stop your co-worker from toggling it ‚Äòoff‚Äô?  Any issues you have with permanent staging environments are magnified with ephemeral environments.</p><p>The best solution would be upon the creation of an ephemeral environment you would create an environment in LaunchDarkly based on something unique about your ephemeral environment and when it comes up, you would make sure it was using the unique SDK api for that particular Feature Flag Environment.  Let‚Äôs implement the workflow and see how that would work with Release!</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/6iJFF3Zu70PwOxkxXCKtp3/24f7412df0886df79f4ff1239d1eeffc/image9.png" alt="FF workflow"></p><h2 id="working-with-ephemeral-environments">Working with Ephemeral Environments</h2><p>In order to try this out with Release we need a repository with a Docker File that has implemented Feature Flags with LaunchDarkly.  I‚Äôm going to use <a href="https://github.com/elanderholm/rails_postgres_redis" target="_blank" rel="noreferrer">this</a> repository on Github and you can do the same by first forking the repository so you can use it to create an application with Release.</p><p>Once you have forked the repository you can navigate to <a href="https://releaseapp.io/" target="_blank" rel="noreferrer">releaseapp.io </a>and sign-in using github in order to follow along with this example.</p><p>The steps to get our ephemeral environments created in Release with support for environments in LaunchDarkly are:</p><ol><li>Create our application in Release</li><li>Create a job with Release to create the environment in LaunchDarkly</li><li>Add some environment variables so the application can contact LaunchDarkly and pull in the SDK Api key from our newly created LaunchDarkly Environment</li><li>Deploy our Ephemeral Environment</li></ol><blockquote><p>If you don‚Äôt have a launch darkly account, you can create one for free for 30 days to use for this example.  You will also need to create at least one feature flag.  If you already have a launch darkly account with a lot of feature flags you can just skip this step.</p></blockquote><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/4O6rr31peejXL43aLTPrAi/dc7022076bd7b28e2e189431a5262c7b/image3.png" alt="LaunchDarkly Test Flag"></p><h2 id="create-the-application-in-release">Create the Application In Release</h2><p>Once we are logged into Release we want to click <strong>Create New Application</strong> in the left-hand sidebar.  After doing that we will be presented with Create New Application Workflow.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/5LbYmJLNvAIZwuUqcjMtsv/5aeb59c6fef3b73532e04125a676dd0e/image12_png.png" alt="Create Application With Refresh Button"></p><p>First, we will click the ‚Äúrefresh‚Äù button to find our newly forked repository.  Then, we will select that repository and ‚ÄúDocker‚Äù for the ‚Äúapi‚Äù service.  Finally,  name your application.  Once you have finished click the purple ‚ÄúGenerate App Template‚Äù button.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/7HFUIDbur1n6r5aELXgb01/f8e12dfed6ca2cb6130fbdb68c98342a/image2.png" alt="Pick your Repository"></p><p>Lastly name your application and generate the template for your configuration.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/WKSmTIAeyTjNKCHLTVbEe/a17a56b380c61066b4fa89fc85690475/image4.png" alt="Name your Application"></p><h2 id="modify-the-application-template">Modify the Application Template</h2><p>Before we can deploy our environment(s) we need to make a modification to our application template and add a few environment variables.  We also need to create a job that will create our LaunchDarkly environment upon initial environment deployment.  Jobs in Release are described in detail <a href="https://docs.releaseapp.io/reference-guide/application-settings/application-template#jobs" target="_blank" rel="noreferrer">here</a>.  The TL;DR is that with a small amount of configuration you can run any arbitrary script or task in a container.  For example, these jobs are very useful for running migrations before a deployment of your backend service.  In this case we will run a rake task to set up our LaunchDarkly Environment.</p><div><pre><p><span>1</span><span>jobs:</span></p><p><span>2</span><span>- name: create-launch-darkly-env</span></p><p><span>3</span><span>  from_services: api</span></p><p><span>4</span><span>  args:</span></p><p><span>5</span><span>  - bundle</span></p><p><span>6</span><span>  - exec</span></p><p><span>7</span><span>  - rake</span></p><p><span>8</span><span>  - launch_darkly:create_environment</span></p></pre></div><blockquote><p>The above yaml represents a job in Release</p></blockquote><p>We will place the above lines right before the ‚Äúservices‚Äù stanza in our application template.</p><div><pre><p><span>1</span><span>memory:</span></p><p><span>2</span><span>   limits: 1Gi</span></p><p><span>3</span><span>   requests: 100Mi</span></p><p><span>4</span><span> replicas: 1</span></p><p><span>5</span><span>jobs:</span></p><p><span>6</span><span>  - name: create-launch-darkly-env</span></p><p><span>7</span><span>    from_services: api</span></p><p><span>8</span><span>    args:</span></p><p><span>9</span><span>    - bundle</span></p><p><span>10</span><span>    - exec</span></p><p><span>11</span><span>    - rake</span></p><p><span>12</span><span>    - launch_darkly:create_environment</span></p><p><span>13</span><span>services:</span></p><p><span>14</span><span>  - name: api</span></p><p><span>15</span><span>    image: erik-opsnuts-test-001/rails_postgres_redis/api</span></p><p><span>16</span><span>    has_repo: true</span></p><p><span>17</span><span>    static: false</span></p></pre></div><blockquote><p>Place the jobs snippet into the Application Template</p></blockquote><p>In order for Release to utilize this job as part of the workflow to deploy an environment we will need to add one line near the bottom of the file in the ‚Äòworkflows` section.  Under ‚Äòsetup‚Äô:‚Äôorder<!-- -->_<!-- -->from‚Äô we will add <strong>jobs.create-launch-darkly-env</strong>. Then, click ‚ÄúSave and Continue.‚Äù</p><div><pre><p><span>1</span><span>workflows:</span></p><p><span>2</span><span>- name: setup</span></p><p><span>3</span><span>  order_from:</span></p><p><span>4</span><span>  - jobs.create-launch-darkly-env</span></p><p><span>5</span><span>  - services.all</span></p><p><span>6</span><span>- name: patch</span></p><p><span>7</span><span>  order_from:</span></p><p><span>8</span><span>  - services.api</span></p><p><span>9</span><span>  - services.sidekiq</span></p><p><span>10</span><span>  - services.db</span></p><p><span>11</span><span>  - services.redis</span></p></pre></div><blockquote><p>Place jobs.create-launch-darkly-env before services.all under the workflows stanza</p></blockquote><p><strong>That‚Äôs all the configuration needed, now we just need to add two environment variables before we deploy!</strong></p><h2 id="adding-environment-variables">Adding Environment Variables</h2><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/2afDqMwgfbBgsxc5WHAlCL/f43f8e929dcd4e73d0efdb46cab6dc3b/image11.png" alt="Adding Env Variables"></p><p>Click ‚ÄòEDIT‚Äô for ‚ÄòDefault Environment Variables‚Äô to bring up the editor.  We will add two environment variables that contain information about LaunchDarkly.  They are:</p><p><strong>LAUNCH<!-- -->_<!-- -->DARKLY<!-- -->_<!-- -->API<!-- -->_<!-- -->KEY</strong>: Your LaunchDarkly Api Key which is found here.  If you don‚Äôt have an api token create the ‚Äú+ TOKEN‚Äù button to make one.  You will want to give it admin privileges.  If you can‚Äôt do that contact your administrator.  <em><strong>Once you create it, make sure you copy it and paste it somewhere you can retrieve it.</strong></em>  LaunchDarkly will obfuscate your token and if you don‚Äôt save it somewhere you will need to generate a new one.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/6jdsjV6ETNJUOnmCNWP9tZ/75653f2eeb2217930777e900b4ff6746/image7.png" alt="Create LD token"></p><p><strong>LAUNCH<!-- -->_<!-- -->DARKLY<!-- -->_<!-- -->PROJECT<!-- -->_<!-- -->NAME</strong>:  We will just use ‚Äòdefault‚Äô for this example, but if there is another project you would like to test with feel free.</p><div><pre><p><span>1</span><span>defaults:</span></p><p><span>2</span><span>- key: POSTGRES_USER</span></p><p><span>3</span><span>  value: postgres</span></p><p><span>4</span><span>- key: POSTGRES_PASSWORD</span></p><p><span>5</span><span>  value: postgres</span></p><p><span>6</span><span>- key: LAUNCH_DARKLY_PROJECT_NAME</span></p><p><span>7</span><span>  value: default</span></p><p><span>8</span><span>- key: LAUNCH_DARKLY_API_KEY</span></p><p><span>9</span><span>  value: your-api-key</span></p><p><span>10</span><span>  secret: true</span></p></pre></div><p>Click ‚ÄòSave‚Äô to save your environment variables as part of your application configuration.  Then, click ‚ÄòBuild and Deploy‚Äô. You will be redirected to the activity dashboard for that application and a Docker build was kicked off in the background. This will be followed by the deployment of the environment for your application.  You can view the build and the deployment under the ‚Äòbuilds‚Äô and ‚Äòdeploys‚Äô sections respectively.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/0RxHLU0FDRkPRdE8NRzDf/b086b5e3ff3fb0cec0b744ec4e43f8d9/image10.png" alt="left-hand-nav"></p><h2 id="your-environment">Your Environment</h2><p>This process of doing the docker build will take a few minutes the first time.  Once the build and deployment have finished you can find the url for your new environment by clicking ‚ÄòEnvironments‚Äô on the left and then by clicking into your new environment.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/3JfGh3cQnbXMea0fkcCZd1/061efc9db04bfcb0c34e66826a0b06cf/image6.png" alt="Enviro"></p><p>Once you click on the url for your newly created ephemeral environment another window in your browser will open to the example rails site with postgres and redis.  It should look something like this:</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/7uUfgJGrmodl3QwVsAI8wk/07de4d7da560256378414160f1cca5c3/image8.png" alt="test-a"></p><p>If you have a flag named ‚Äòtest-flag‚Äô in your launch darkly account you can go ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://releaseapp.io/blog/feature-flags-and-ephemeral-environments">https://releaseapp.io/blog/feature-flags-and-ephemeral-environments</a></em></p>]]>
            </description>
            <link>https://releaseapp.io/blog/feature-flags-and-ephemeral-environments</link>
            <guid isPermaLink="false">hacker-news-small-sites-25349269</guid>
            <pubDate>Tue, 08 Dec 2020 18:19:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Summary: The Bed of Procrustes by Nassim Taleb]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25348534">thread link</a>) | @yarapavan
<br/>
December 8, 2020 | https://blas.com/the-bed-of-procrustes/ | <a href="https://web.archive.org/web/*/https://blas.com/the-bed-of-procrustes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<!-- #masthead -->

	<div id="main">

	<div id="primary">
		<div id="content" role="main">

			
				
	<article id="post-5259">
				<!-- .entry-header -->

				<div>
			
<p>Summary</p>



<ol><li>Every aphorism here is about a Procrustean bed of sorts ‚Äì we humans, facing limited knowledge, and things we do not observe, the unseen and the unknown, resolve the tension by squeezing life and the world into crisp commoditized ideas, reductive categories, specific vocabularies, and prepackaged narratives, which, on the occasion, has explosive consequences. Further,w e seem unaware of this backward fitting, much like tailors who take great pride in delivering the perfectly fitting suit ‚Äì but do so by surgically altering the limbs of their customers. For instance, few realize that we are changing the brains of schoolchildren through medication in order to make them adjust to the curriculum, rather than the reverse. (My use of the metaphor of the Procrustes bed isn‚Äôt just about something in the wrong box; it‚Äôs mostly that inverse operation of changing the wrong variable, here the person rather than the bed. Note that every failure of what we call ‚Äúwisdom‚Äù (couple with technical proficiency) can be reduced to Procrustean bed situation.)</li></ol>



<p>Key Takeaways</p>



<ol><li>Bed of Procrustes ‚Äì fit person/model to the situation rather than the other way around.&nbsp;</li><li>Work destroys your soul by stealthily invading your brain during the hours not officially spent working; be selective about professions</li><li>Using, as an excuse, others‚Äô failure of common sense is in itself a failure of common sense</li><li>Life is about execution rather than purpose</li><li>The ultimate freedom lies in not having to explain why you did something</li><li>You exist if and only if you are free to do things without a visible objective, with no justification and, above all, outside the dictatorship of someone else‚Äôs narrative</li><li>The source of the tragic in history is in mistaking someone else‚Äôs unconditional for conditional ‚Äì and the reverse</li><li>What fools call ‚Äúwasting time is most often the best investment</li><li>You want to avoid being disliked without being envied or admired</li><li>The fastest way to become rich is to socialize with the poor; the fastest way to become poor is to socialize with the rich</li><li>You will be civilized on the day you can spend a long period doing nothing, learning nothing, and improving nothing, without feeling the slightest amount of guilt</li><li>There are 2 types of people: those who try to win and those who try to win arguments. They are never the same</li><li>Social networks present information about what people like; more informative if, instead, they described what they don‚Äôt like</li><li>My only measure of success is how much time you have to kill</li><li>Only in recent history has ‚Äúworking hard‚Äù signaled pride rather than shame for lack of talent, finesse, and, mostly, sprezzatura</li><li>Life is about early detection of the reversal point beyond which your own belongings (say, a house, country house, car, or business) start owning you</li><li>In any subject, if you don‚Äôt feel that you don‚Äôt know enough, you don‚Äôt know enough</li><li>Regular minds find similarities in stories (and situations); finer minds detect differences</li><li>The more complex the system, the weaker the notion of Universal</li><li>Just as dyed hair makes older men less attractive, it is what you do to hide your weaknesses that makes them repugnant</li><li>Robustness is progress without impatience</li><li>Failure-resistant is achievable; failure-free is not</li><li>For a free person, the optimal ‚Äì most opportunistic ‚Äì route between two points should never be the shortest one</li><li>Knowledge is subtractive, not additive ‚Äì what we subtract (reduction by what does not work, what <em>not</em> to do), not what we add (what to do). The best way to spot a charlatan: someone (like a consultant or stockbroker) who tells you what to do instead of what not to do)</li><li>They think that intelligence is about noticing things that are relevant (detecting patterns); in a complex world, intelligence consists in ignoring things that are irrelevant (avoiding false patterns).</li><li>They would take forecasting more seriously if it were pointed out to them that in Semitic languages the word for ‚Äúforecast‚Äù and ‚Äúprophecy‚Äù are the same</li><li>Economics is about making simple things more complicated, mathematics about making complicated things simpler</li><li>It is easier to macrobullshit than microbullshit</li><li>It is a sign of weakness to avoid showing signs of weakness</li><li>The only definition of an alpha male: if you try to be an alpha male, you will never be one</li><li>The weak shows his strength and hides his weaknesses; the magnificent exhibits his weaknesses like ornaments</li><li>Contra the prevailing belief, ‚Äúsuccess‚Äù isn‚Äôt being on top of a hierarchy, it is standing outside all hierarchies</li><li>It is very easy to be stoic, in failure</li><li>A verbal threat is the most authentic certificate of impotence&nbsp;</li><li>Wisdom that is hard to execute isn‚Äôt really wisdom</li><li>If something looks irrational ‚Äì and has been so for a long time ‚Äì odds are you have a wrong definition of rationality</li><li>Knowing stuff others don‚Äôt know is most effective when others don‚Äôt know you know stuff they don‚Äôt know</li><li>Humans need to complain just as they need to breathe. Never stop them; just manipulate them by controlling what they complain about and supply them with reasons to complain. They will complain but be thankful&nbsp;</li><li>Injuries done to us by others tend to be acute; the self-inflicted ones tend to be chronic</li><li>We often benefit from harm done to us by others, almost never from self-inflicted injuries&nbsp;</li><li>By setting oneself totally free of constraints, free of thoughts, free of this debilitating activity called work, free of efforts, elements hidden in the texture of reality start staring at you; then mysteries that you never thought existed emerge in front of your eyes.&nbsp;</li></ol>



<p>What I got out of it</p>



<ol><li>A lot of wisdom to meditate on and absorb ‚Äì best read a couple lines per day to let these ideas sink in.</li></ol>
					</div><!-- .entry-content -->
		
		<!-- .entry-meta -->
	</article><!-- #post -->

				<nav>
					<h3>Post navigation</h3>
					<span><a href="https://blas.com/october-2020/" rel="prev"><span>‚Üê</span> October 2020</a></span>
					<span><a href="https://blas.com/what-owen-didnt-know/" rel="next">What Owen Didn‚Äôt Know by Laurence Endersen <span>‚Üí</span></a></span>
				</nav><!-- .nav-single -->

				
<!-- #comments .comments-area -->

			
		</div><!-- #content -->
	</div><!-- #primary -->


			<!-- #secondary -->
		</div><!-- #main .wrapper -->
	<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://blas.com/the-bed-of-procrustes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25348534</guid>
            <pubDate>Tue, 08 Dec 2020 17:33:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linear ‚Äì Raises Series A, adds roadmaps, themes, workflows]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25348525">thread link</a>) | @tommoor
<br/>
December 8, 2020 | https://linear.app/release-2020-12 | <a href="https://web.archive.org/web/*/https://linear.app/release-2020-12">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="splash"><div><div><p><img src="https://linear.app/static/release/mask2.svg" width="158"></p></div><p><span><h4>Linear Release 2020.12</h4></span><span></span><span><p>In this release, we are taking our software development tool to the next level. Linear fits into your builder workflow even better with a product roadmap, customizable views, list controls, sorting options and an enhanced sub-issue editor.</p></span></p></div></div><p><span><div><div><div><div><div><h2>Tactile feel</h2><p>Update multiple issues quickly and confidently with smoother issue selection, contextual menus for mouse users and global undo.</p></div><video loop="" autoplay="" muted="" playsinline=""><source data-src="/static/release/tactile.mp4" type="video/mp4" src="https://linear.app/static/release/tactile.mp4"></video></div></div></div><div><div><div><div><h2>Roadmap: Codify the company direction</h2><div><p>Set milestones to tie projects to larger company goals and motivate your team. Clarify the company direction so that everyone knows why their work matters and how to prioritize it. View all company projects in one streamlined view and easily identify what needs your attention.</p></div></div><p><img src="https://linear.app/static/release/roadmap.png"></p></div></div></div><div><div><div><div><h3>Industry√¢‚Ç¨‚Ñ¢s best performance</h3><p>We shipped several performance improvements for speedier launch, list viewing and scrolling.</p></div><div><div><p>Open issue from list view</p></div><div><p>Add a label to 100 issues</p></div></div></div></div><div><div><div><h3>Streamlined views</h3><p>Show relevant information. Hide the rest. View options let you see the work how you want to.</p><p>Search faster with content search for lists and boards.</p></div><p><img src="https://linear.app/static/release/view-options.png"></p></div></div></div><div><div><div><div><h2>Views: Add faster workflows</h2><div><p>Create and save custom views that include exactly the issues you want to see. Focus better by filtering only relevant issues. Save time by creating views for common workflows. Manage work across teams easily with new all team and multi-team views. Share views with your team or workspace to make sure everyone√¢‚Ç¨‚Ñ¢s on the same page.</p></div></div><p><img src="https://linear.app/static/release/views.png"></p></div></div></div><div><div><div><div><h3>Smarter notifications</h3><p>Trigger notifications when it matters. We added more granular notification options for desktop, email and Slack.</p></div><p><img src="https://linear.app/static/release/notifications.png"></p></div></div><div><div><div><h3>React with custom emoji</h3><p>Make the workspace your own with custom emoji. Import from Slack or upload as you go.</p></div><p><img src="https://linear.app/static/release/partyparrot.gif"><img src="https://linear.app/static/release/chefkiss.png"><img src="https://linear.app/static/release/lacroix.png"></p></div></div></div><div><div><div><div><h3>Integrations support OAuth2</h3><p>Linear OAuth and GraphQL API bring more power to you and your favorite tools. Build extensions and add integrations securely.</p></div><p><img src="https://linear.app/static/release/oauth.png"></p></div></div><div><div><div><h3>Enhanced sub-issues</h3><p>We redesigned sub-issue creation and navigation for a faster, more complete experience. Add a description, labels and cycles directly from the issue editor.</p></div><p><img src="https://linear.app/static/release/sub-issues.png"></p></div></div></div><div><div><div><div><h2>A theme for every occasion</h2><p>Use one of our themes or create your own to match your other tools.</p></div></div></div></div><div><div><div><div><p><img src="https://linear.app/static/release/linear-method.jpg"></p></div></div></div><div><div><div><p><img src="https://linear.app/static/release/sequoia.jpg"></p></div><div><h3>Linear raises $13M Series A led by Sequoia Capital</h3><p>Linear is used and loved by thousands of organizations to help them deliver high quality software.</p><p><a href="https://medium.com/linear-app/linear-raises-13m-in-series-a-funding-from-sequoia-capital-daa0f0c43758">Read more on Medium √¢‚Ä†‚Äô</a></p></div></div></div></div><div><p color="#8A8F98">Linear keeps everyone aligned and working without friction. Engineers, designers, and peers all collaborating in one tool.</p><p><a kind="primary">Sign up √¢‚Ä†‚Äô</a></p><div><div><div><div><div color="#F7F8F8"><div><p>Before everything was scattered across GitHub, notes, reminders, Google Docs and just a bunch of different places.</p><p>We've centralized all of it in Linear and greatly benefited from all of the automations.</p></div></div></div></div><div><div><div color="#F7F8F8"><div><p>I think that one of the things that really high performing teams do is go from product feedback and into an execution. You err towards speed of execution because that√¢‚Ç¨‚Ñ¢s how you find product-market fit and that√¢‚Ç¨‚Ñ¢s ultimately what √¢‚Ç¨≈ìmake something people want√¢‚Ç¨ÔøΩ means.</p><p>Linear, in my opinion, is optimized for this and where it√¢‚Ç¨‚Ñ¢s best in class.</p></div></div><p><span color="labelMuted">Troy Goode, Co-founder &amp; CEO</span><img src="https://linear.app/static/release/logos/courier.svg"></p></div></div></div><div><div><div><p>Our product got better and our releases got shorter and we√¢‚Ç¨‚Ñ¢ve had fewer bugs because we now have every single detail written down in Linear.</p><p><span color="labelMuted">Michael Lukaszczyk, CEO &amp; Co-founder</span><img src="https://linear.app/static/release/logos/graphcms.svg"></p></div></div><div><div><p>When we're talking about something, whether it's over Zoom or in Slack, it doesn't become real until it goes into Linear. It's become the nucleus of our organization.</p><p><span color="labelMuted">Amanda Peyton, CEO &amp; Co-founder</span><img src="https://linear.app/static/release/logos/braid.png"></p></div></div></div><div><div><div><p>Using the tool creates a sense of momentum. It goes beyond just issue tracking.</p><p><span color="labelMuted">Kurt Ruppel, CTO &amp; Co-founder</span><img src="https://linear.app/static/release/logos/middesk.svg"></p></div></div><div><div><p>In a remote world communication tools are everything. You move as fast as your communication tools.</p><p><span color="labelMuted">Dani Grant, Co-founder</span><img src="https://linear.app/static/release/logos/jam.svg"></p></div></div></div></div></div></div></span></p></div></div>]]>
            </description>
            <link>https://linear.app/release-2020-12</link>
            <guid isPermaLink="false">hacker-news-small-sites-25348525</guid>
            <pubDate>Tue, 08 Dec 2020 17:32:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prisma Migrate ‚Äì Database Migrations Simplified]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25347519">thread link</a>) | @sologuardsman2
<br/>
December 8, 2020 | https://www.prisma.io/blog/prisma-migrate-preview-b5eno5g08d0b | <a href="https://web.archive.org/web/*/https://www.prisma.io/blog/prisma-migrate-preview-b5eno5g08d0b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><h2 id="contents"><a href="#contents" aria-label="contents permalink"></a>Contents</h2><ul><li><a href="#schema-migrations-with-prisma-migrate">Schema migrations with Prisma Migrate</a></li><li><a href="#how-does-prisma-migrate-work">How does Prisma Migrate work?</a></li><li><a href="#what-has-changed-since-the-experimental-version">What has changed since the Experimental version?</a></li><li><a href="#whats-next">What's next</a></li><li><a href="#try-prisma-migrate-and-share-your-feedback">Try Prisma Migrate and share your feedback</a></li></ul><h2 id="schema-migrations-with-prisma-migrate"><a href="#schema-migrations-with-prisma-migrate" aria-label="schema migrations with prisma migrate permalink"></a>Schema migrations with Prisma Migrate</h2><p>Today we're excited to share the new version of Prisma Migrate! üéä</p><p>Prisma Migrate is a data modeling and migrations tool that simplifies evolving the database schema with the application in-tandem. Migrate is based on the <a href="https://www.prisma.io/docs/concepts/components/prisma-schema#example">Prisma schema</a> ‚Äì a declarative data model definition that codifies your database schema.</p><p>This Preview release is the evolution of the Experimental version of Migrate that we released last year. Since then, we've been gathering feedback from the community and incorporating it into Prisma Migrate.</p><h3 id="making-schema-migrations-predictable"><a href="#making-schema-migrations-predictable" aria-label="making schema migrations predictable permalink"></a>Making schema migrations predictable</h3><p>Database schema migrations play a crucial role in software development workflows and affect the most critical component in your application ‚Äì the database. We've built Migrate to be predictable while allowing you to control how database schema changes are carried out.</p><p>Prisma Migrate generates migrations as plain SQL files based on changes in your Prisma schema. These SQL files are fully customizable and allow you to use any feature of the underlying database, such as manipulating data supporting a migration, setting up triggers, stored procedures, and views.</p><p>Prisma Migrate treads the balance between productivity and control by automating the repetitive and error-prone aspects of writing database migrations while giving you the final say over how they are executed.</p><h3 id="integration-with-prisma-client"><a href="#integration-with-prisma-client" aria-label="integration with prisma client permalink"></a>Integration with Prisma Client</h3><p>Prisma Migrate integrates with Prisma Client using the Prisma schema as their shared source of truth. In other words, both Prisma Client and migrations are generated based on the Prisma schema. This makes synchronizing and verifying database schema changes in your application code easier by leveraging Prisma Client's type safety.</p><h3 id="prisma-migrate-is-ready-for-broader-testing"><a href="#prisma-migrate-is-ready-for-broader-testing" aria-label="prisma migrate is ready for broader testing permalink"></a>Prisma Migrate is ready for broader testing</h3><p>Prisma Migrate has passed rigorous testing internally and is now ready for broader testing by the community. You can use it with PostgreSQL, MySQL, SQLite, and SQL Server. <strong>However, as a Preview feature, it is not fully production-ready yet.</strong> To read more about what Preview means, check out the <a href="https://www.prisma.io/docs/more/releases#preview">maturity levels</a> in the Prisma docs.</p><p>Thus, we're inviting you to try it out and <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/4531">give us feedback</a> so we can bring Prisma Migrate to General Availability. üö¢</p><p>Your feedback and suggestions will help us shape the future of Prisma Migrate. üôå</p><hr><h2 id="how-does-prisma-migrate-work"><a href="#how-does-prisma-migrate-work" aria-label="how does prisma migrate work permalink"></a>How does Prisma Migrate work?</h2><p>Prisma Migrate is based on the <a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-schema">Prisma schema</a> and works by generating <code>.sql</code> migration files that are executed against your database.</p><p>The Prisma schema is the starting point for schema migrations and provides an overview of your desired end-state of the database. Prisma Migrate inspects changes in the Prisma schema and generates the necessary <code>.sql</code> migration files to apply.</p><p>Applying migrations looks very different depending on the stage of development. For example, during development, there are scenarios where resetting the database can be tolerated for quicker prototyping, while in production, great care must be taken to avoid data loss and breaking changes.</p><p>Prisma Migrate accommodates for this with workflows for local development and applying migrations in production.</p><h3 id="evolving-the-schema-in-development"><a href="#evolving-the-schema-in-development" aria-label="evolving the schema in development permalink"></a>Evolving the schema in development</h3><p>To use the new version of Prisma Migrate, you should have at least version <code>2.13.0</code> of the <a href="https://www.prisma.io/docs/concepts/components/prisma-cli/installation"><code>@prisma/cli</code></a> package installed.</p><p>During development, you first define the Prisma schema and then run the <code>prisma migrate dev --preview-feature</code> command, which generates the migration, applies it, and generates Prisma Client:</p><p><span><img src="https://d33wubrfki0l68.cloudfront.net/9dee8cc50b930a017447904d95e15e0e82f9a3bf/426d4/blog/posts/2020-12-migrate-development-workflow.png" alt="Development workflow"><span>Development workflow</span></span></p><p>Here is an example showing it in action:</p><p><strong>1. Define your desired database schema using the Prisma schema:</strong></p><pre><code><span>datasource</span> <span>db</span> <span>{</span>
  provider <span>=</span> <span>"postgresql"</span>
  url      <span>=</span> <span>env</span><span>(</span><span>"DATABASE_URL"</span><span>)</span>
<span>}</span>

<span>model</span> <span>User</span> <span>{</span>
  id    <span>Int</span>      <span>@id</span> <span>@default</span><span>(</span><span>autoincrement</span><span>(</span><span>)</span><span>)</span>
  name  <span>String</span>
  posts <span>Post</span><span>[</span><span>]</span>
<span>}</span>

<span>model</span> <span>Post</span> <span>{</span>
  id        <span>Int</span>     <span>@id</span> <span>@default</span><span>(</span><span>autoincrement</span><span>(</span><span>)</span><span>)</span>
  title     <span>String</span>
  published <span>Boolean</span> <span>@default</span><span>(</span><span>true</span><span>)</span>
  authorId  <span>Int</span>
  author    <span>User</span>    <span>@relation</span><span>(</span><span>fields:</span> <span>[</span>authorId<span>]</span><span>,</span> <span>references:</span> <span>[</span>id<span>]</span><span>)</span>
<span>}</span>
</code></pre><p><strong>2. Run <code>prisma migrate dev --preview-feature</code> to create and execute the migration.</strong></p><div><div><svg width="6" height="9" viewBox="0 0 6 9" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M7.3273 0C7.88605 0 8.20036 0.653318 7.85732 1.1017L4.53001 5.45076C4.26119 5.80213 3.73881 5.80213 3.46999 5.45076L0.142684 1.1017C-0.200356 0.653318 0.113948 0 0.672698 0H7.3273Z" transform="rotate(-90 4.5 4.357)" fill="#8FA6B2"></path></svg><p><label for="tab-1">Expand to view the SQL contents of the generated migration</label></p><div><pre><code>
<span>CREATE</span> <span>TABLE</span> <span>"User"</span> <span>(</span>
  <span>"id"</span> <span>SERIAL</span><span>,</span>
  <span>"name"</span> <span>TEXT</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>PRIMARY</span> <span>KEY</span> <span>(</span><span>"id"</span><span>)</span>
<span>)</span><span>;</span>

<span>CREATE</span> <span>TABLE</span> <span>"Post"</span> <span>(</span>
  <span>"id"</span> <span>SERIAL</span><span>,</span>
  <span>"title"</span> <span>TEXT</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>"published"</span> <span>BOOLEAN</span> <span>NOT</span> <span>NULL</span> <span>DEFAULT</span> <span>true</span><span>,</span>
  <span>"authorId"</span> <span>INTEGER</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>PRIMARY</span> <span>KEY</span> <span>(</span><span>"id"</span><span>)</span>
<span>)</span><span>;</span>

<span>ALTER</span> <span>TABLE</span> <span>"Post"</span> <span>ADD</span> <span>FOREIGN</span> <span>KEY</span><span>(</span><span>"authorId"</span><span>)</span><span>REFERENCES</span> <span>"User"</span><span>(</span><span>"id"</span><span>)</span> <span>ON</span> <span>DELETE</span> <span>CASCADE</span> <span>ON</span> <span>UPDATE</span> <span>CASCADE</span><span>;</span>
</code></pre></div></div></div><p>After the migration has been executed, the migration files are typically committed to the repository so that the migration can be applied in other environments.</p><p>Further changes to the database schema follow the same workflow and begin with updating the Prisma schema.</p><h3 id="customizing-sql-migrations"><a href="#customizing-sql-migrations" aria-label="customizing sql migrations permalink"></a>Customizing SQL migrations</h3><p>You can customize the migration SQL with the following workflow:</p><ol><li>Run <strong><code>prisma migrate dev --create-only --preview-feature</code></strong> to create the SQL migration without applying it.</li><li>Edit the migration SQL.</li><li>Run <strong><code>prisma migrate dev --preview-feature</code></strong> to apply it.</li></ol><h3 id="applying-migrations-in-production-and-other-environments"><a href="#applying-migrations-in-production-and-other-environments" aria-label="applying migrations in production and other environments permalink"></a>Applying migrations in production and other environments</h3><p>To apply migrations to other environments such as production, you pull changes to the repository containing the migrations and run the <code>prisma migrate deploy</code> command:</p><p><span><img src="https://d33wubrfki0l68.cloudfront.net/5d9831941c87b7e24646bca3d96f91d4b799af6a/b7004/blog/posts/2020-12-migrate-production-workflow.png" alt="Production workflow"><span>Production workflow</span></span></p><hr><h2 id="what-has-changed-since-the-experimental-version"><a href="#what-has-changed-since-the-experimental-version" aria-label="what has changed since the experimental version permalink"></a>What has changed since the Experimental version?</h2><p>The most significant change since the Experimental version is the use of SQL as the format for migrations, making migrations <strong>deterministic</strong>. In other words, the exact steps of the migration are determined when the migration is created, allowing you to inspect the SQL (and make changes if necessary) before running.</p><p>This approach has the following benefits:</p><ul><li>The generated SQL is editable, thereby allowing you to control the exact schema changes.</li><li>The migration is predictable with the exact SQL that will be applied.</li><li>You don't need to write SQL unless you want to change a migration.</li><li>You can perform data migrations using SQL as part of a migration.</li></ul><p>Editable SQL for migrations is useful in scenarios where there are multiple ways to map changes in the Prisma schema to the database, and the desired path cannot be automatically determined.</p><p>For example, when you rename a field in the Prisma schema, that can be interpreted as either deleting the column and adding an unrelated new one or as you renaming the column. By allowing you to inspect and edit the migration SQL, you can decide whether to rename the column (and retain the data in the column) or drop it and add a new one.</p><p>If you're upgrading Prisma Migrate from the Experimental version, check out the <a href="https://www.prisma.io/docs/guides/prisma-guides/prisma-migrate-guides/add-prisma-migrate-to-a-project">upgrade guide</a>.</p><hr><h2 id="whats-next"><a href="#whats-next" aria-label="whats next permalink"></a>What's next</h2><p>This Preview version of Prisma Migrate lays the foundations for the upcoming General Availability release. Some of the improvements we are considering are improved support for native database types, seeding functionality, and finding a way to make database resets in development less disruptive.</p><h3 id="native-database-types"><a href="#native-database-types" aria-label="native database types permalink"></a>Native database types</h3><p>One of the most requested features in Prisma is support for the database's native types. This release is a step closer to that ‚Äì however, there's still more work to be done for native types to be fully supported.</p><p>Currently, the Prisma schema can only represent a limited set of types: <code>String</code>, <code>Int</code>, <code>Float</code>, <code>Boolean</code>, <code>DateTime</code>, and <code>Json</code>. Each of these types has a default mapping to an underlying database type that's specified for each database connector (see the mappings for <a href="https://www.prisma.io/docs/concepts/database-connectors/postgresql#prisma-migrate">PostgreSQL</a> and <a href="https://www.prisma.io/docs/concepts/database-connectors/mysql#prisma-migrate">MySQL</a>).</p><p>In version <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/releases/tag/2.11.0">2.11.0</a>, we released the <code>nativeTypes</code> Preview feature ‚Äì the ability to annotate fields in the Prisma schema with the specific native database type that it should be mapped to. <strong>However, the native types preview feature doesn't work with Prisma Migrate yet</strong>.</p><p>Even so, you can still change the types of columns in the generated SQL as long as they are supported, as documented in the <a href="https://www.prisma.io/docs/concepts/database-connectors/postgresql#prisma-migrate">PostgreSQL</a> and <a href="https://www.prisma.io/docs/concepts/database-connectors/mysql#prisma-migrate">MySQL</a> connector docs.</p><hr><p>We built Prisma Migrate for you and are keen to hear your feedback.</p><p>We want to understand how Prisma Migrate fits into your development workflow and how we can help you stay productive and confident while building and evolving data-centric applications.</p><p>üêõ Tried it out and found that it's missing something or stumbled upon a bug? Please <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/new/choose">file an issue</a> so we can look into it.</p><p>üèó Share your feedback about how the new Prisma Migrate is working out for you on <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/4531">GitHub</a>.</p><p>üåç Join us on our <a target="_blank" rel="noopener noreferrer" href="https://slack.prisma.io/">Slack</a> in the <a target="_blank" rel="noopener noreferrer" href="https://app.slack.com/client/T0MQBS8JG/C01ACF1DJ1M"><code>#prisma-migrate</code></a> channel for help.</p><p>üë∑‚Äç‚ôÄÔ∏è We are thrilled to finally share the Preview version of Prisma Migrate and can't wait to see what you all build with it.</p></div></div></article></div>]]>
            </description>
            <link>https://www.prisma.io/blog/prisma-migrate-preview-b5eno5g08d0b</link>
            <guid isPermaLink="false">hacker-news-small-sites-25347519</guid>
            <pubDate>Tue, 08 Dec 2020 16:34:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I accidentally built a Podcast API business]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25347050">thread link</a>) | @wenbin
<br/>
December 8, 2020 | https://lnns.co/3GBq7wJ2nNL | <a href="https://web.archive.org/web/*/https://lnns.co/3GBq7wJ2nNL">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><a href="https://www.listennotes.com/">Listen Notes</a> is a podcast search engine that allows people to search <a href="https://www.listennotes.com/podcast-stats/">nearly two million podcasts and more than 89&nbsp;million episodes</a>&nbsp;by people or topics. We also provide a<a href="https://www.listennotes.com/api/"> podcast API</a> for developers to use, which is called Listen API. It has become a core part of our business.</p>
<p>In this article, I‚Äôll share with you the journey of building this API business, the technology behind it, and hopefully&nbsp;you can&nbsp;learn one thing or two and build&nbsp;your own API business in the future.</p>
<p>Please note that I use ‚ÄúI‚Äù and ‚Äúwe‚Äù interchangeably in this article :)</p>

<h2><strong>An accidental API&nbsp;business</strong></h2>

<p>I left my previous failed startup in September 2017. After a few days of tinkering, I picked up one of my fledgling side projects to polish the UI a bit. That side project was<a href="https://www.listennotes.com/"> Listen Notes</a>, a podcast search engine website, which was just a single page React JS app running on three $10/month DigitalOcean droplets.</p>
<p>Little did I know a few years ago that my small, neglected side project would turn into a helpful business it has blossomed into.</p>

<p><img src="https://production.listennotes.com/web/image/37454d6afb7b458ca58ae4e5873ddbbd.png"></p>
<p><small>Listen Notes around September 2017</small></p>

<p>I continued to work on Listen Notes full-time and incorporated Listen Notes as a Delaware C-Corp in October 2017. One of my goals was to experience as many facets of business as possible, rather than just writing code behind the scenes.</p>
<p>My initial plan was as follows: (Don‚Äôt laugh at me!)</p>
<ul>
<li>Build a podcast search engine website and make some money from advertising, just like Google. Simple!</li>
<li>If this Listen Notes thing doesn‚Äôt work in two or three months, then I‚Äôll run out of cash, and I‚Äôll go into credit card debt to keep going for one more month or so. If it still doesn‚Äôt work, then I‚Äôll have to find a full-time job. Although Jeff Bezos‚Äô parents invested $300,000 in early Amazon and Mark Zuckerberg‚Äôs parents loaned $100,000 to early Facebook, not every family is able to casually toss six figures of cash at web projects.</li>
</ul>
<p>Then something happened.</p>
<p>On November 20, 2017, I got an email from the developer of a new podcast app, who asked if Listen Notes provided an API. He wanted to be able to search episodes in his app, but he didn‚Äôt want to build the entire backend. I asked a few questions (e.g., how would the endpoints look, what data fields did he need, how much was he willing to pay‚Ä¶). I got his answers. All were in an email thread within a couple days.</p>
<p>On November 30, 2017, I quickly implemented three endpoints (<em>GET /search, GET /podcasts/{id}, and GET /episodes/{id}</em>), which were basically three<a href="https://docs.djangoproject.com/en/3.1/topics/http/views/"> Django views</a>. I Googled ‚ÄúAPI gateway‚Äù or something like that and found a service called<a href="https://konghq.com/blog/mashape-has-a-new-homepage/"> Mashape</a>, which was an API marketplace that handled payment, user management, and API documentation. So I put my three endpoints on Mashape and created two plans there: FREE and PRO. I emailed the developer back to tell him the API was ready to use.</p>
<p>This is the email thread that prompted me to build Listen API:</p>
<p><img src="https://production.listennotes.com/web/image/125d913b8ad14bbd99fbc7c1cfe49e04.png"></p>

<p>Then nothing happened. The podcast app developer didn‚Äôt use our API and instead phased out their project.</p>
<p>Eventually, I moved on to primarily focus on the development of listennotes.com. The API was basically in self-driving mode on the open web. Anyone who happened to discover our API could sign up, without talking to any human beings.</p>
<p>On January 14, 2018, I got my first paying user. A few more paying users arrived that same year.</p>
<p>Here is the email notification I received for my first paying user:</p>
<p><img src="https://production.listennotes.com/web/image/1cf8ad68f0c345318c9c64b3f370764b.png"></p>

<p>Wait, what is RapidAPI? Well, Mashape was acquired by a startup named RapidAPI. They didn‚Äôt rebrand Mashape to RapidAPI completely until mid-2018. Startups typically don‚Äôt do things in a clean and methodical way, which is totally understandable.</p>
<p>Then something happened.</p>
<p>There was an outage on the RapidAPI end on November 29, 2018. This was the email I sent to people in RapidAPI when the outage happened.</p>

<p><img src="https://production.listennotes.com/web/image/4d1a713f41dd465b9e57fa4e34be4208.png"></p>

<p>RapidAPI had performed a big backend upgrade around that time. As an engineer, I totally understand that outages happen, especially when making huge changes in the backend. But I felt helpless because their customer support didn‚Äôt reply to my email. Phone call didn't work, as expected.</p>
<p>Usually their customer support was very responsive; perhaps it was the holiday season and people were on vacation. So I used hunter.io to find work emails of individual RapidAPI employees, the CEO, as well as the CTO. The issue was finally resolved, many hours later. In other words, our API was completely unusable during those down hours. I felt very sorry for our paying users.</p>
<p>Then around mid-February 2019, RapidAPI had billing problems and failed to pay us a few thousand bucks. Our paying users paid RapidAPI first. RapidAPI took a 20% cut. Then they paid the remaining 80% (minus PayPal fees) to us. After several back-and-forth emails and phone calls, we finally got our payment. It‚Äôs understandable. Again, startups make mistakes.</p>
<p>In late February 2019, I decided to build our own RapidAPI replacement, for a few reasons:</p>
<ul>
<li>Our API revenue became nontrivial. The 20% cut from RapidAPI was a bit too much for us.</li>
<li>We wanted API requests to hit our own servers directly, thus lowering latency for our users.</li>
<li>I didn‚Äôt want to feel helpless when RapidAPI had outages. Overall they did a good job running the service. But I wanted to control my own destiny.</li>
<li>I wanted to contact my API users directly. Using RapidAPI, API providers like me didn‚Äôt have access to our users‚Äô email addresses. It‚Äôs understandable. It‚Äôs like the ‚ÄúUber for X‚Äù companies that don‚Äôt want workers and customers to bypass them and strike deals under the table. Marketplaces don‚Äôt want users to skip the middleman‚Äôs commission fees.</li>
</ul>
<p>In addition, I vowed to do two things really well for our new API system:</p>
<ul>
<li>We must provide great customer service to our paying users.</li>
<li>We will give customers a very stable &amp; reliable backend service.</li>
</ul>
<p>After 30 days of hard work,<a href="https://www.listennotes.com/blog/listen-api-v2-simple-pricing-same-endpoints-39/"> we launched Listen API v2</a> on March 27, 2019. The legacy API hosted on RapidAPI became Listen API v1, a version we won‚Äôt add new features to but don‚Äôt want to shut down because some apps are still using it as of December 2020!</p>
<p>We continue to improve our new Listen API v2 by adding new endpoints, new data fields, improving operational efficiency, as well as spiffing up the user dashboard and our internal tools.</p>
<p>Things are picking up speed gradually. I‚Äôve been happy since then.</p>
<p>So, that‚Äôs the journey of Listen API so far.</p>
<p><em>Note: Although we decided to move on from RapidAPI, I still think it‚Äôs a great service. Startups all make mistakes in the early stage. They fix things and continue to improve their service, which is great! </em></p>

<h2><strong>The technology behind Listen&nbsp;API</strong></h2>

<p>Developers can use our API to search podcasts and fetch detailed podcast-episode metadata. To make this whole thing work, we need to make sure a few core components are in place.</p>
<p>The following graph summarizes those components and the technologies used:</p>

<p><img src="https://production.listennotes.com/academy/image/3c36ff70b8ab4d25aa85bfa567007087.png"></p>

<h3><strong>Datastore and search&nbsp;engine</strong></h3>

<p>This is a shared component with our website. Therefore, I didn‚Äôt need to change anything in the datastore and search engine when building our API infrastructure.</p>
<p>We use Postgres as our main data store (e.g., for podcast metadata, user accounts‚Ä¶), and Elasticsearch as the search engine.</p>
<p>I wrote an old blog post with<a href="https://www.listennotes.com/blog/the-boring-technology-behind-a-one-person-23/"> details of the entire tech stack</a>.</p>

<h3><strong>Internal tools and processes</strong></h3>

<p>If you‚Äôve worked in any web companies, you probably know what I‚Äôm referring to here.</p>
<p>It‚Äôs rare for an Internet business to be 100% automatic. A company always needs to build tons of internal tools and set up manual processes to keep the service functional. That‚Äôs why companies like<a href="https://www.bloomberg.com/news/articles/2020-10-20/retool-nears-1-billion-valuation-with-funding-from-sequoia"> Retool have such a high valuation</a> nowadays.&nbsp;</p>
<p>Companies are investing big money in internal tools that are invisible to end users:</p>

<p><img src="https://production.listennotes.com/web/image/e448df5503934491b251a2a85b815686.png"></p>
<p>Credits: <a href="https://retool.com/blog/state-of-internal-tools-2020/">Retool</a></p>

<p>To start our API business, we needed to build (at least) two types of internal tools:</p>
<ul>
<li><strong>For data operations</strong>: We needed the ability to keep the podcast metadata up-to-date, fix corrupted metadata, plus review and approve any changes made by users. Additionally, we required a framework that handled new, rare edge cases of corrupted podcast data along the way. To some degree, building a software product means handling tons of edge cases for a very long period of time (e.g., years), rather than launching new features every day.</li>
<li><strong>For user operations</strong>: We required the ability to suspend a bad user‚Äôs account, as well as immediately look up all information related to a specific user who contacted us for a specific issue. Plus, we had to be able to quickly evaluate if ‚Äúit‚Äôs our fault‚Äù (server-side errors) or ‚Äúit‚Äôs their fault‚Äù (client-side errors) when users complained.</li>
</ul>
<p>Internal tools are used by employees inside the company. Some of those tools are fully automated, such as cron jobs that perform scheduled tasks. But many tools should be used manually by human employees, e.g., when inputting a user‚Äôs ID number and clicking a button.</p>
<p>Most of our internal tools have ugly web UIs, with default<a href="https://getbootstrap.com/"> Bootstrap</a> styling :) The following screenshot displays a portion of our internal tool‚Äôs UI that allows us to suspend an API user‚Äôs account:</p>
<p><img src="https://production.listennotes.com/web/image/f5c69dcc39a041bdbb230bcc25b3a36c.png"></p>

<p>Fortunately, our API shares many internal tools with the website. So we didn‚Äôt need to build too many new things here.</p>

<h3><strong>The analytics and billing&nbsp;system</strong></h3>

<p>The pricing model of an API is typically usage-based. Check out some real world examples:</p>
<ul>
<li><a href="https://www.twilio.com/pricing" rel="nofollow noopener" target="_blank">https://www.twilio.com/pricing</a></li>
<li><a href="https://sendgrid.com/pricing/" rel="nofollow noopener" target="_blank">https://sendgrid.com/pricing/</a></li>
<li><a href="https://cloud.google.com/maps-platform/pricing/" rel="nofollow noopener" target="_blank">https://cloud.google.com/maps-platform/pricing/</a></li>
<li><a href="https://www.microsoft.com/en-us/bing/apis/pricing">https://www.microsoft.com/en-us/bing/apis/pricing</a></li>
</ul>
<p>It‚Äôs a must to track how many requests a user uses in real-time. We use Redis to keep track of such stats and periodically dump into Postgres for persistent storage.&nbsp;</p>
<p>What happens if our Redis has an outage? We might temporarily lose some tracking stats. In this case, we have an internal tool to sync stats from raw Nginx logs.</p>
<p>We have to change billing plans without affecting existing users. For example, if we raise prices, existing users should still enjoy the benefit of the old plans. If it‚Äôs not done right, it‚Äôs easy to have inconsistent states across the board, ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lnns.co/3GBq7wJ2nNL">https://lnns.co/3GBq7wJ2nNL</a></em></p>]]>
            </description>
            <link>https://lnns.co/3GBq7wJ2nNL</link>
            <guid isPermaLink="false">hacker-news-small-sites-25347050</guid>
            <pubDate>Tue, 08 Dec 2020 16:06:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Towards a Strong Mental Model of Docker]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25346980">thread link</a>) | @throughnothing
<br/>
December 8, 2020 | http://blog.andrewray.me/towards-a-strong-mental-model-of-docker/ | <a href="https://web.archive.org/web/*/http://blog.andrewray.me/towards-a-strong-mental-model-of-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <p><strong>TL;DR</strong> I'm a full stack engineer who works almost exclusively on Macs. I don't have a computer science degree nor do I have strong experience with Linux architecture. This post documents my journey of learning Docker.</p>



<p><strong>If you stick with this blog post, you'll have decent answers for the following questions.</strong> If you've already used Docker, these questions will strengthen your understanding.</p>

<ol>
<li>What is "Docker"?  </li>
<li>What is a "container"? Did Docker invent containers?  </li>
<li>What does it mean to "run a container"?  </li>
<li>Are containers stateful? What does container state even mean?  </li>
<li>Do containers run only one process? Or can they run multiple processes?  </li>
<li>What exactly is "Docker for Mac"? I thought Docker was cross platform?  </li>
<li>Does Docker work for Windows development?  </li>
<li>What are "docker-compose" and "BuildKit"? Why are there so many different applications?  </li>
<li>Most Docker images start with something like <code>FROM ubuntu</code>. Is my container running a full Ubuntu operating system? If not, why is it <em>from</em> Ubuntu? In fact, what does it even mean to "run an operating system?"</li>
</ol>

<p>The summarized answers for all of these questions are at the end of this post.</p>



<p>How might you <a href="https://blog.andrewray.me/reactjs-for-stupid-people/">explain React.js</a> to a newcomer? You <em>could</em> say:</p>

<blockquote>
  <p>React is a JavaScript library for building user interfaces</p>
</blockquote>

<p>I don't think this would help a newcomer form a mental model of React, as it's <strong>too high level</strong>. You could also say:</p>

<blockquote>
  <p>React is a declarative DSL that outputs a tree-like "virtual DOM," mutating the DOM (or another view target) with O(n) reconciliation performance, as a pure function of component state and props</p>
</blockquote>

<p>And I think, justifiably, the newcomer would slap you in the face, because you just told them to go to hell.</p>

<p>Something more approachable is:</p>

<blockquote>
  <p>React is mainly a Javascript library that takes in data, like a username, and spits out HTML based on that data. It gives you a performant way to update the view in real time based on changes to that data. React can do a lot more than this, but the most common use case is taking in data and spitting out HTML.</p>
</blockquote>

<p>Does this accurately describe all of React? No, and once someone dives in, they'll have to learn the intricacies of the API. But it's more <strong>approachable.</strong></p>

<p>I find the Docker documentation is written by, and targeted to, people who already have a deeper understanding of Linux fundamentals, virtualization, and kernels versus operating systems.</p>

<p>If someone tells you that Docker is "cgroups and namespaces" with no other information, it's technically accurate, but not approachable.</p>



<p>If you just want to build web servers, why care about Docker at all? Well, I've personally encountered many of the issues containers claim to solve:</p>

<ul>
<li>Requiring multiple versions of <strong>userland libraries</strong> (like Node, and also npm packages) in different repositories, causing conflicts for local development because they aren't isolated</li>
<li>Requiring <strong>multiple service or database versions</strong> causing conflict in local development (have you ever tried to run two versions of MySQL on a Mac using Homebrew?)</li>
<li>Running into <strong>dependency installation issues</strong> when checking out both old and new projects (Ruby / Rails are particularly bad at this, damn you <a href="https://stackoverflow.com/q/33996523/743464">Nokogiri</a>). Who hasn't run an old project only to learn everything is broken?</li>
<li>Needing to <strong>easily run multiple services</strong> for local development, some of which need multiple commands (such as both a server process and a static file builder process like Webpack)</li>
<li>Losing <strong>parity between environments</strong> due to version or process execution discrepancies, making it impossible to reproduce situations that cause some production bugs</li>
</ul>



<p>This post <strong>isn't</strong> a deep dive on Docker's API. We won't explain the syntax of <code>Dockerfile</code>s, <code>docker-compose.yml</code> files, nor the CLI. We also won't talk much about "orchestration," the verb used to describe running multiple containers and their dependencies and dealing with things like networking and automatically restarting containers.</p>



<h4 id="whatisdocker">What is Docker?</h4>

<p>Believe it or not, let's start with the Docker logo. It's great for our mental model!</p>

<p><img src="http://blog.andrewray.me/content/images/2020/05/Moby-logo.png" alt="The Docker Logo, which is a whale with a stack of shipping containers on its back"></p>

<p>We have a whale carrying some shipping containers. (His name is "Moby Dock," <strong>Moby</strong> for short). He's a whale because, a long time ago, he beat out other animals in <a href="https://99designs.com/logo-design/contests/create-cool-open-source-project-logo-219415/entries">a community logo design contest</a>.</p>

<p>In our mental model, the whale is Docker. <strong>Docker is a <em>platform</em>.</strong> It's not one thing, it's a collection of different technologies and standards that provide a platform to <strong>run containers!</strong> The whale is supporting, or "running" containers. We'll learn more about "containers" soon.</p>

<p><img src="http://blog.andrewray.me/content/images/2014/Oct/key.png#inline-block" alt="Key icon" title=""> <strong>Key concept:</strong> Docker is a platform, including online hosting, and a suite of local tools, like <code>docker-compose</code> and the Docker engine.</p>

<p>When learning Docker, you might wonder what the "right" or "Docker" way is. By viewing Docker as a platform, we realize there are multiple ways to do things. <strong>It's like Git:</strong> Git is a platform and suite of command line tools. In Git there are different ways to use the suite of tools. Some people use forks, some use feature branches, some use rebasing, some use merging. Docker provides you tools to build "images" and "run" "containers," with multiple ways to achieve the same thing.</p>

<p>"Docker" also means the <strong>company.</strong> I think this overloading makes learning Docker confusing. The Docker <em>platform</em> is <a href="https://github.com/docker">entirely open source</a>, so what does the company do? It makes money by <a href="https://hub.docker.com/pricing">charging for private hosting and management tools</a>, and offering <a href="https://hub.docker.com/pricing">enterprise services</a> for complex image/container management.</p>

<p>An aside: In 2019 Docker was <a href="https://techcrunch.com/2019/11/13/mirantis-acquires-docker-enterprise/">acquired</a> by a company named <a href="https://www.mirantis.com/software/mcp/">Mirantis</a> which makes money by supporting cloud application development around Kubernetes.</p>



<h4 id="whatisacontainerdiddockerinventcontainers">What is a "container"? Did Docker invent containers?</h4>

<p>Containers were the most difficult part of Docker for me to understand. I had some idea they were running a process in isolation, but I didn't really know what that meant. To answer this, let's make sure we understand the Docker platform by looking at a different question.</p>

<h4 id="whatexactlyisdockerformacithoughtdockerworkedonallplatforms">What exactly is "Docker for Mac?" I thought Docker worked on all platforms?</h4>

<p>I initially thought Docker was "cross platform." This is both true and a complete, filthy lie.</p>

<p>Take Docker for Mac out of the equation and pretend like you're developing directly on a Linux operating system, like Ubuntu. All operating systems have a "<a href="https://en.wikipedia.org/wiki/Kernel_(operating_system)"><strong>kernel</strong></a>", the core computer program of the operating system that controls everything and facilitates access to hardware.</p>

<p>The Linux kernel has features that allow you to run processes (computer programs) in "isolation":</p>

<ul>
<li>"<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/ch01">Control groups</a>", usually called "cgroups," let you run a Linux process with a specifically allocated set of resources, such as how much memory it has.</li>
<li>"<a href="https://en.wikipedia.org/wiki/Linux_namespaces">Namespaces</a>", which add additional isolation, like making your process look like it's the only one on the system.</li>
</ul>

<p><img src="http://blog.andrewray.me/content/images/2014/Oct/key.png#inline-block" alt="Key icon" title=""> <strong>Key concept:</strong>
Docker uses existing Linux features to run containers. These features <strong>only</strong> work on Linux. MacOS and Windows don't have cgroups nor namespaces.</p>

<p>So what is Docker for Mac, if these technologies only exist on Linux? Docker for Mac runs a full <strong>Linux "virtual machine."</strong> Virtual machines are a broader topic, but they contain full operating systems, including kernels, so we have access to these Linux features.</p>

<p>My mental image is the whale icon on my Mac's status bar holds a little Linux computer.</p>

<p>This also has the implication that the most common type of application developed with Docker is an application <em>for</em> Linux. For example, you <a href="https://serverfault.com/questions/607443/can-mac-os-x-be-run-inside-docker">can't run a Mac native application</a> like Photoshop in a Docker container. On Windows there's Docker container support for both Windows (.exe) applications as well as Linux applications, but they use different underlying technologies. And you can't run a Windows container on a Mac. See what I mean about Docker not really being "cross platform"?</p>

<p>On Mac and Windows, the Linux virtual machine is hidden from you as an implementation detail. You can typically SSH into computers and run commands on them. Docker for Mac <strong>doesn't let you directly SSH into this virtual machine.</strong> Instead, the Docker commands you run locally are what coordinate sending files and commands into this Linux virtual machine.</p>

<p>Finally, did Docker invent containers? No, containers are a <a href="https://en.wikipedia.org/wiki/List_of_Linux_containers">general concept</a>. <strong>Docker didn't invent containers.</strong> You can create and run containers <a href="https://jvns.ca/blog/2016/10/26/running-container-without-docker/">without Docker</a>. Cgroups and namespaces also aren't the only way to run processes in isolation, they're just the tools Docker uses.</p>

<h4 id="sodoesdockerworkonwindows">So does Docker work on Windows?</h4>

<p>The <a href="" windows="" container"="" https:="" www.youtube.com="" watch?v="8gG6_Xr68D8" are="" the"="">official Docker Enterprise video, at 0:45,</a> mentions "Windows containers." So you <em>can</em> use Docker on Windows?</p>

<p>It depends on what you mean by "use on Windows." If you're developing Linux applications, then <strong>Docker for Windows does the same thing as Docker for Mac,</strong> it runs a Linux virtual machine, and you communicate with that.</p>

<p>If however you want to develop an application that only runs on Windows, like a file ending in ".exe," you have to run your containers on a Windows host somehow. This is supported by Docker Enterprise, but much less common.</p>

<h4 id="whatdoesitmeantorunacontainer">What does it mean to "run a container"?</h4>

<p>"Container" is a noun. What we've talked about so far is the verb of "running" a container.</p>

<p><strong>Recap:</strong> When Docker runs your container, it starts your process (your computer program, developed for Linux architecture) wrapped in suite of Linux kernel tools to make it look like it's the only process on the system. Docker for Mac (and Windows) provide a Linux virtual machine so you can use these technologies. Running the container is basically the same as what you'd do on your host machine (like <code>npm start</code> or <code>rails s</code>), it's just in "isolation" inside the Linux VM.</p>

<p>Let's poke at containers a little more to strengthen our understanding.</p>

<h4 id="docontainershave_only_oneprocessorcantheyhavemultipleprocesses">Do containers have <em>only</em> one process? Or can they have multiple processes?</h4>

<p>Let's check! First let's install <code>htop</code>, the awesome process viewer on your Mac (not in a container): <code>brew install htop</code>.</p>

<p>Now run <code>htop</code> on your Mac. If you haven't used <code>htop</code>, don't worry too much about the interface, just note you see all sorts of processes running:</p>

<p><img src="http://blog.andrewray.me/content/images/2020/05/Screen-Shot-2020-05-07-at-8.42.50-PM.png" alt="A screenshot of htop running on Mac, showing multiple processes"></p>

<p>Press <code>ctrl-c</code> to exit <code>htop</code>. ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.andrewray.me/towards-a-strong-mental-model-of-docker/">http://blog.andrewray.me/towards-a-strong-mental-model-of-docker/</a></em></p>]]>
            </description>
            <link>http://blog.andrewray.me/towards-a-strong-mental-model-of-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25346980</guid>
            <pubDate>Tue, 08 Dec 2020 16:01:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Love GPLv3, but Are Switching License to Apache 2.0]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 243 (<a href="https://news.ycombinator.com/item?id=25346965">thread link</a>) | @vivek9209
<br/>
December 8, 2020 | https://terminusdb.com/blog/2020/12/08/we-love-gplv3-but-are-switching-license-to-apache-2-0-terminusdb/ | <a href="https://web.archive.org/web/*/https://terminusdb.com/blog/2020/12/08/we-love-gplv3-but-are-switching-license-to-apache-2-0-terminusdb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div id="markdown" itemprop="articleBody">
          <h2 id="changing-license-from-gplv3-to-apache-20-terminusdb">Changing License from GPLv3 to Apache 2.0: TerminusDB</h2>

<p>We have decided to re-license TerminusDB from GPLv3 to Apache 2.0. We want independent software developers (ISVs) to embed TerminusDB in their applications and those developers feel that Apache is a lower risk option. The substantive points of practical difference are far less important ‚Äì sufficient people believe it to be true and sufficient lawyers have advised teams to be wary of GPL.</p>

<p>In our experience, ISVs and devs in large companies/institutions size up their options at project conception and there remains a niggling doubt that ‚ÄòGPL might limit commercial prospects and cause me headaches‚Äô. The world has changed ‚Äì and code freedom is being overtaken by developer freedom.</p>

<p>Open-source software is everywhere. It‚Äôs eating the world. In the top 10 databases on <a href="https://db-engines.com/en/ranking">DB-Engines</a>, the remaining proprietary databases were released in 1980 (Oracle), 1983 (IBM Db2) and 1989 (Microsoft SQL Server). It is hard to imagine another non-OSS database ever entering the top 10.</p>

<p>We had hoped that our association with the principals of the free software movement would result in community adoption and contribution, but that hasn‚Äôt really been the case. We see limited community input that relates to our choice of GPL. That might not be too surprising as when you investigate which license to choose on Stackoverflow, you get popular but wrong-headed comments like:</p>

<p><code>the GNU/GPL bunch are generally extremists when you encounter them in the wild.</code></p>

<p><code>don‚Äôt use GPL if you want your project to be commercial</code></p>

<p>With the shift to Apache, TerminusDB is, in a sense, becoming more open source as we are removing restrictions on how you can use the software.</p>

<h3 id="debate">Debate</h3>

<p>The core TerminusDB team had a long debate about licenses before the release of 1.0 last year. The main topics of discussion were:</p>

<ol>
<li>The risks of a cloud provider forking the code then hosting the database</li>
<li>What open source means to TerminusDB as a group</li>
<li>What we, as a community of devs and users, are most comfortable with</li>
</ol>

<h4 id="1-the-big-bad-cloud-providers">1. The big bad cloud providers</h4>

<p>In the past there was an unwritten rule, that big platforms wouldn‚Äôt come along and fork open source code and deliver the same product as a service. Unfortunately, those days are gone. AWS in particular has actively sought to offer very similar services to open source products. This led to <a href="https://www.mongodb.com/licensing/server-side-public-license/faq">MongoDB</a>, <a href="https://www.cockroachlabs.com/blog/oss-relicensing-cockroachdb/">CockroachDB</a> and <a href="https://www.confluent.io/confluent-community-license-faq/">Confluent</a> (among others) changing their licences to variations of ‚Äòserver side‚Äô and moving away from the open-source tradition. They try to say ‚Äòwe are still open source, we are just forbidding a specific type of action‚Äô, but it can feel like window dressing for ‚Äòwe want to sweat our assets‚Äô.</p>

<p>Mongo, for example, is hardly suffering ‚Äì it‚Äôs valued at over $15 billion. With such vast resources, they should be (and are) able to compete in the provision of their own database. MongoDB‚Äôs technology is more than competitive with AWS‚Äô DocumentDB, and Mongo‚Äôs Atlas DBaaS - which runs on AWS infra - has been a huge success.</p>

<p>I‚Äôm sure our perspective will shift over time, but from where we‚Äôre standing, having a cloud provider launch a competing service would be a sign of enormous success. (And this is not to say that the cloud providers‚Äô parasitic approach to OSS projects is not a genuine problem, it simply acknowledges that you have to be a widely used OSS project before it *becomes* a problem).</p>

<h3 id="2-free-software">2. Free software</h3>

<p>We don‚Äôt think it should be our job to provide corporations with free labor.</p>

<p>We do think that the software community should be able to access and use TerminusDB.</p>

<p>In 1974 software became copyrightable in the USA. It subsequently became obvious that researchers were giving out software for free, but businesses were not giving back. GNU/GPL came along to provide a new framework for that interface ‚Äì the software would be free as in freedom (libre). Everybody would be free to modify and distribute, but proprietary additions would not be allowed.</p>

<p>The problem of businesses not giving back remains today.</p>

<p>GPL and copyleft provisions work well when they dominate open-source, but their waning popularity increases the ability for ISVs and corporates to go for more open licensing and for legal teams to write anti-GPL provisions into internal rules. Only significant developer push back can change that reality (and why push back when there are so many OSS options with permissive licenses).</p>

<p>Maybe if <a href="https://db-engines.com/en/system/MySQL">MySQL</a>, its offshoot <a href="https://db-engines.com/en/system/MariaDB">MariaDB</a>, and our graph brothers <a href="https://db-engines.com/en/system/Neo4j">Neo4j</a> weren‚Äôt the only GPL flag flyers in the top 20 databases, it might be easier to gain adoption with GPL; however, the other big OSS players: Postgres, Cassandra, Elastic &amp; Redis all go for less restrictive licenses.</p>

<p>The Affero GPL (AGPL) is treated as an even greater pariah than the GPLv3. The Google internal policy] bans all use of AGPL:</p>

<p><img src="https://terminusdb.com/blog/assets/uploads/agpl-at-google.jpg" alt=""></p>

<p><img src="https://terminusdb.com/blog/assets/uploads/agpl-at-google-2.jpg" alt=""></p>

<p>It reminds of <a href="https://news.ycombinator.com/item?id=13421608">this HN comment</a> on the <a href="http://www.defmacro.org/2017/01/18/why-rethinkdb-failed.html">excellent postmortem</a> of the demise of RethinkDB (recommended reading for all OSS folk):</p>

<p><img src="https://terminusdb.com/blog/assets/uploads/agpl-hn.jpg" alt=""></p>

<p>Our graph database brothers and sisters in <a href="https://neo4j.com/open-core-and-neo4j/">Neo4j moved</a> from the AGPL to ‚ÄòAGPL with a commons clause‚Äô to GPLv3 to making some of the code proprietary. Getting the right license for an OSS project that also allows for some commercialization is far from straightforward. (As Neo certainly know ‚Äì check out this <a href="https://public.igovsol.com/neo4j-court-records/graphfoundation/80-main.pdf">current court case about the formerly GPL enterprise code</a>).</p>

<p>It seems that <a href="https://github.com/graknlabs/grakn">Grakn</a> and <a href="https://github.com/fluree/db">Fluree</a> are seeing some success with the AGPL. We genuinely wish them well as we know it is a hard path to walk.</p>



<p>We did get some negative feedback about the GPL prior to launch. Some people working in corporates weren‚Äôt comfortable and thought that it would prevent them from using Terminus. Our response was ‚Äì <strong>we didn‚Äôt develop for them</strong>. And that remains the case; however, the GPL skeptical environment is pervasive. There is a person who tweets TerminusDB after every release asking when the Apache version will land ‚Äì I always ask him why he thinks he needs an Apache version and he doesn‚Äôt really know‚Ä¶ though he has a vague feeling that the application he builds on top will be less valuable.</p>

<p>We thought we would focus on the cloud offering ‚Äì <a href="https://terminusdb.com/hub/">TerminusHub</a>, which, as SaaS built on the database, has the benefit of being an in-house ‚Äòproduct‚Äô that doesn‚Äôt worry about the license of the underlying software. However, the community wants to build applications on the software and we want to offer an easy way to build a version control and collaboration layer into ISV applications. We think TerminusDB is the perfect infrastructure to build the next <a href="https://www.notion.so/">Notion</a> or <a href="https://roamresearch.com/">Roam Research</a>. We worry about the syncing, versioning and data collaboration ‚Äì you worry about your users.</p>

<h3 id="why-shift-licenses">Why shift Licenses</h3>

<p>We do not think that our job is to provide corporations with free labor.</p>

<p>We still believe that <a href="https://www.gnu.org/gnu/manifesto.en.html">‚Äúthe fundamental act of friendship among programmers is the sharing of programs.‚Äù</a></p>

<p>We would welcome a GPL fork of the TerminusDB code ‚Äì we are happy to work with any such project should it emerge.</p>

<p>But we wish to build a community first and foremost. In order to facilitate that community, we will be moving to Apache 2.0 immediately.</p>

<p>We are going to continue to focus on creating a great open-source database and allow everybody to use that software in their projects.</p>

        </div>

        



      </div>
    </div></div>]]>
            </description>
            <link>https://terminusdb.com/blog/2020/12/08/we-love-gplv3-but-are-switching-license-to-apache-2-0-terminusdb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25346965</guid>
            <pubDate>Tue, 08 Dec 2020 16:00:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Altered states can help us face death with serenity and levity]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25346860">thread link</a>) | @pseudolus
<br/>
December 8, 2020 | https://psyche.co/ideas/altered-states-can-help-us-face-death-with-serenity-and-levity | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/altered-states-can-help-us-face-death-with-serenity-and-levity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>One way or another</strong>, we will all approach the end of life, we are all terminal, and existential anxiety can be a burden long before this. Studies by terror management theory researchers have <a href="https://aeon.co/essays/how-to-apply-terror-management-theory-to-improve-human-lives" rel="noopener">found</a> that when death salience is aroused in people, they adapt their behaviour and increase their reliance on defence mechanisms such as denial. The cultural anthropologist Ernest Becker argued in <em>The Denial of Death</em> (1973) that human civilisation is ultimately a symbolic defence mechanism against the awareness of our finite existence. He suggested that √¢‚Ç¨Àúconsciousness of death is the primary repression, not sexuality√¢‚Ç¨‚Ñ¢ as Sigmund Freud had popularised. Unconscious denial of death can have a demoralising effect on an individual, potentially affecting loved ones and the community as a whole.</p>
<p>By not facing the issue of our mortality prior to our passing, we miss a unique opportunity, not only to reconcile with death and make peace with it, but also to gain a sense of levity and serenity that we can carry with us through our lives. But how can we overcome a fear of death that√¢‚Ç¨‚Ñ¢s so deeply rooted in our culture?</p>
<p>Research is starting to reveal that certain states of consciousness can have a powerful and positive effect on how we perceive our own mortality. There√¢‚Ç¨‚Ñ¢s a strong association between a decreased fear of death and undergoing a near-death experience (NDE), out-of-body experience (OBE), lucid dream and psychedelic experience.</p>
<p>During an NDE, people report several features such as a transcendence of time and space, a life review, feelings that the experience is ineffable and authentic, encounters with deceased loved ones, and deep feelings of love and peace. One of the core transformative features of the NDE is an out-of-body experience, which is also associated with psychedelic experiences but, unlike these other states, is something that can be induced through training and intent.</p>
<p>One doesn√¢‚Ç¨‚Ñ¢t even need to have these experiences personally to benefit from them. A number of NDE researchers have noted profound changes in their own outlook following encounters with people who have had an NDE. As noted by one leading researcher, simply hearing or reading about NDEs can have a profound impact, acting as a √¢‚Ç¨Àúbenign virus√¢‚Ç¨‚Ñ¢. Research has <a href="https://www.tandfonline.com/doi/abs/10.1080/19349637.2016.1206844" rel="nofollow noreferrer noopener">revealed</a> that this can yield significant changes in people√¢‚Ç¨‚Ñ¢s spirituality and appreciation for both life and death.</p>
<p>The psychiatrist Elaine Drysdale, who works with terminally ill cancer patients in Canada, has heard countless reports of NDEs, and assures patients and their relatives that the experience of death itself isn√¢‚Ç¨‚Ñ¢t as painful or frightening as it might appear. She now teaches medical students and palliative care staff about the benefits of near-death research, and argues that NDEs allow us to approach the unknown and death without framing things in a religious way √¢‚Ç¨‚Äú they√¢‚Ç¨‚Ñ¢re inclusive, personal and occur in cultures all over the world.</p>
<p>An out-of-body experience can act as a motivating catalyst to further understand yourself</p>
<p>An OBE is a transpersonal experience where you feel your √¢‚Ç¨Àúsense of self√¢‚Ç¨‚Ñ¢ shift beyond your physical body, encountering beings and places that feel real. Unlike NDEs, OBEs can be induced willingly. This experience can also occur spontaneously in healthy people while they√¢‚Ç¨‚Ñ¢re deeply relaxed, in hypnagogic states, on the cusp of sleep, and during meditation. Almost all OBEs have a positive impact, with experiencers commonly reporting a sense of serenity, mental clarity, awe and interconnectedness.</p>
<p>The experience can act as a motivating catalyst to further understand yourself, and is commonly associated with a reduced fear of death. As the American neuroscientist Sam Harris points out: √¢‚Ç¨Àúwhether or not a person√¢‚Ç¨‚Ñ¢s consciousness can actually be displaced is perhaps irrelevant; the point is it can <em>seem</em> to be.√¢‚Ç¨‚Ñ¢ Distortion of embodiment can be disorientating, but disorientating to <em>whom</em>, if we experience that we aren√¢‚Ç¨‚Ñ¢t solely the totality of our body? One core feature <a href="https://pdfs.semanticscholar.org/4338/745de83065ca3c853a4d1695d76c1f65374b.pdf" rel="nofollow noreferrer noopener">linking</a> these various experiences is the feeling of transcending one√¢‚Ç¨‚Ñ¢s primary identification with the physical body. The perspective-shifting power of this effect is supported by experiments <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0169343" rel="nofollow noreferrer noopener">showing</a> that even a simulated OBE induced by immersive virtual reality can lessen death anxiety.</p>
<p><strong>The experience of transcending</strong> the physical body is frequently tied to feelings of connecting to something larger than oneself. This is usually associated with the experience of awe, an emotional state commonly linked to NDEs, OBEs and psychedelic experiences. It√¢‚Ç¨‚Ñ¢s also experienced by astronauts when viewing the Earth from space, <a href="https://aeon.co/essays/psychedelics-can-have-the-same-overview-effect-as-a-space-journey" rel="noopener">referred</a> to as the √¢‚Ç¨Àúoverview effect√¢‚Ç¨‚Ñ¢. It conjures a cognitive shift of perceptual vastness, reframing one√¢‚Ç¨‚Ñ¢s reality and place within it. This draws parallels with OBEs and NDEs, which appear to evoke a kind of √¢‚Ç¨Àúouterview effect√¢‚Ç¨‚Ñ¢ when people glance back at their body and feel separate from it. This change of core identification from a limited body to a more expansive sense of self can radically curb existential anxiety.</p>
<p>These altered traits could be <a href="https://aeon.co/essays/religion-has-no-monopoly-on-transcendent-experience" rel="noopener">related</a> to ego-dissolution, which is another important experiential component of transcendent experiences. Such experiences are reliably catalysed by psychedelics and characterised by a loss of subjective self-identity; in essence, a simulated dying or death and rebirth experience. Following its dissolution, there√¢‚Ç¨‚Ñ¢s a blurring of the perceived boundaries between self and other. Deep feelings of unity, awe and interconnection can stem from this. This experience is strongly associated with the mystical-type experiences that psychedelics can elicit and appears to be an important part of how psychedelics can alleviate death anxiety. Psychedelic therapy might also invoke a sense of ritual √¢‚Ç¨‚Äú something that has largely been lost to Western culture, but is an important part of many Indigenous cultures, including those that employ psychedelic substances, such as psilocybin, shamanically.</p>
<p>√¢‚Ç¨ÀúIf it helps them to die peacefully with their friends and family at their side, I don√¢‚Ç¨‚Ñ¢t care if it√¢‚Ç¨‚Ñ¢s real or an illusion√¢‚Ç¨‚Ñ¢</p>
<p>The evidence of the efficacy for psilocybin in treating existential angst is arguably the strongest of any yet obtained in the field of psychedelic research, following clinical studies conducted by the <a href="https://pubmed.ncbi.nlm.nih.gov/20819978/" rel="nofollow noreferrer noopener">University of California, Los Angeles</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5367557/" rel="nofollow noreferrer noopener">Johns Hopkins University</a> in Baltimore and New York University (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5367551/" rel="nofollow noreferrer noopener">NYU</a>) exploring psilocybin as a treatment for existential anxiety in terminally ill cancer patients. Follow-up <a href="https://pubmed.ncbi.nlm.nih.gov/31916890/" rel="nofollow noreferrer noopener">research</a> by NYU found sustained reductions in death anxiety <span>4.5 years</span> after a single psilocybin session in the overwhelming majority of study participants. Psilocybin can also <a href="https://link.springer.com/article/10.1007%2Fs00213-011-2358-5" rel="nofollow noreferrer noopener">catalyse</a> feelings of death transcendence in those who aren√¢‚Ç¨‚Ñ¢t facing a terminal diagnosis. This is an unprecedented finding in the field of psychiatry.</p>
<p>In the words of Anthony <span>P Bossis,</span> a clinical assistant professor of psychiatry at the NYU School of Medicine and the former director of palliative care research for the NYU trial:</p>
<blockquote>While there have been advances in chemotherapies and pain management, there remains a paucity of therapies to address and relieve the emotional anguish experienced by the dying. The psychedelic therapy model represents a potential paradigm shift for the future of hospice and palliative care, providing a novel and effective therapy to relieve the emotional and spiritual distress so often experienced at the end of life. Not only can it offer emotional and spiritual healing for those facing their mortality, but it can also help their families who witness the relief of suffering in their loved one.</blockquote>
<p><strong>Another substance that reliably</strong> yields ego-dissolving transcendental experiences and might hold promise is ketamine. Numerous <a href="https://www.sciencedirect.com/science/article/abs/pii/S105381001830535X" rel="nofollow noreferrer noopener">studies</a> have found that the experiences it elicits are closest to the NDE, in phenomenological quality, of all substances examined. On the matter of authenticity of psychedelic insights, the veteran American psychedelic pharmacologist David Nichols had this to say: √¢‚Ç¨ÀúIf it gives them peace, if it helps them to die peacefully with their friends and family at their side, I don√¢‚Ç¨‚Ñ¢t care if it√¢‚Ç¨‚Ñ¢s real or an illusion.√¢‚Ç¨‚Ñ¢</p>
<p>The psychiatrist Stanislav Grof has likely supervised more psychedelic therapy sessions than anyone else alive. He treated terminally ill cancer patients with psychedelic therapy as part of his work with the Maryland Psychiatric Research Center. He observed patients describing these sessions as invaluable experiential training for dying, with some reporting NDEs as their disease progressed, which they described as yielding very similar states of consciousness. Grof commented that:</p>
<blockquote>√¢‚Ç¨Àúdying before dying√¢‚Ç¨‚Ñ¢ influences deeply the quality of life and the basic strategy of existence. It reduces irrational drives √¢‚Ç¨¬¶ and increases the ability to live in the present and to enjoy simple life activities. Another important consequence √¢‚Ç¨¬¶ is a radical opening to spirituality of a universal and non-denominational type.</blockquote>
<p>One thing reported in association with NDEs, OBEs, lucid dreams (dreams in which the dreamer is aware that they√¢‚Ç¨‚Ñ¢re dreaming) and psychedelics (such as <a href="https://link.springer.com/article/10.1007/s00213-019-05446-2" rel="nofollow noreferrer noopener">ayahuasca</a>) is encountering deceased loved ones. Whether or not one takes the view such experiences are illusionary or √¢‚Ç¨Àúreal√¢‚Ç¨‚Ñ¢ in some sense doesn√¢‚Ç¨‚Ñ¢t take away from the therapeutic power of these encounters. The Holocaust survivor, financier and philanthropist George Sarlo had a life-changing <a href="https://www.jweekly.com/2020/07/16/psychedelic-journeys-brought-peace-to-this-holocaust-survivor-now-hes-helping-others-on-their-own-journeys/" rel="nofollow noreferrer noopener">encounter</a> with ayahuasca in his 70s, during which he had a conversation with his dead father who told him why he hadn√¢‚Ç¨‚Ñ¢t said goodbye before he was deported to a Nazi labour camp. In turn, feelings of depression that Sarlo had harboured for much of his life evaporated. Others report the resolution of relationship conflicts, feelings of relief, and a sense of closure after encountering a deceased relative. However, these extraordinary experiences aren√¢‚Ç¨‚Ñ¢t new, as Tibetan Buddhists have been wilfully inducing both OBEs and lucid ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/altered-states-can-help-us-face-death-with-serenity-and-levity">https://psyche.co/ideas/altered-states-can-help-us-face-death-with-serenity-and-levity</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/altered-states-can-help-us-face-death-with-serenity-and-levity</link>
            <guid isPermaLink="false">hacker-news-small-sites-25346860</guid>
            <pubDate>Tue, 08 Dec 2020 15:53:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How did JavaScript‚Äôs console.log get its name?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25346856">thread link</a>) | @jshakes
<br/>
December 8, 2020 | https://jshakespeare.com/javascript-console-log-etymology/ | <a href="https://web.archive.org/web/*/https://jshakespeare.com/javascript-console-log-etymology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page"><div><main id="main"><article><div><p>If you‚Äôre a JavaScript developer you will be familiar with <code>console.log</code>, a function for printing a value to the console. <code>console.log</code> is often used for debugging, and if you‚Äôre a great JavaScript developer like me, you mostly use it to determine whether your code is working by printing things like <code>'asdasdsds'</code> or <code>'HELLO IS THIS RUNNING?!?!'</code>.</p><div><pre><code data-lang="javascript"><span>const</span> <span>msg</span> <span>=</span> <span>'JavaScript is fun'</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span> <span>msg</span> <span>)</span><span>;</span>
</code></pre></div><p>Even if you write <code>console.log</code> many times a day, you probably haven‚Äôt stopped to think about how the words ‚Äòconsole‚Äô and ‚Äòlog‚Äô ended up in a programming language. Isn‚Äôt ‚Äòconsole‚Äô something you do when someone is upset? Isn‚Äôt a ‚Äòlog‚Äô something you put on a fire?</p><p>Let‚Äôs take an etymological stroll through history and see what we can find. Our journey will take us from the early days of computing to medieval churches to the high seas, and we‚Äôll learn that the seemingly unrelated definitions of these words have more in common than you might think.</p><h2 id="console">Console</h2><p>This is a JavaScript debugging console. It displays messages that help a programmer understand what‚Äôs happening in the code that‚Äôs being executed.</p><figure><img src="https://jshakespeare.com/post_images/js-console.gif" alt="A screenshot of the JavaScript debugging console in Google Chrome showing various logged messages"><figcaption><p>The JavaScript console in Google Chrome‚Äôs developer tools. Messages from <code>console.log</code> (or in the case of the red and yellow messages, <code>console.error</code> and <code>console.warn</code>) appear here</p></figcaption></figure><p>The concept of a debugging console is not unique to JavaScript. It‚Äôs a basic software interface common to many programming languages and applications. It provides a way for a program to output low-level textual information and, optionally, receive inputs for controlling the program.</p><figure><img src="https://jshakespeare.com/post_images/osx-console.gif" alt="A screenshot of the OSX Console application"><figcaption><p>The OSX Console application</p></figcaption></figure><p>The definition of console as a software feature comes from the early days of computing, when a user interacted with a computer mainframe (which was often very large and possibly located in another room or building) via an array of controls set in a desk.</p><figure><img src="https://jshakespeare.com/post_images/ibm7090.jpg" alt="A man in a white shirt pressing a button on a 1960's IBM computer console"><figcaption><p>A meteorologist at the console of the IBM 7090 electronic computer in the Joint Numerical Weather Prediction Unit in 1965. Image credit: <a href="https://commons.wikimedia.org/wiki/File:IBM_7090_console_used_by_a_meteorologist,_1965.jpg">Wikimedia Commons</a></p></figcaption></figure><p>Early computer consoles were controlled by switches and buttons, while output was relayed to the operator via lights, dials, and paper printouts. Over time, consoles evolved to incorporate a command-line interface on a screen, with which the user would enter instructions using a keyboard.</p><p>We can find analogs of the computer console by looking to the world of music. Sound mixing consoles have existed in one form or another since the advent of electrical audio recording and broadcast almost a century ago.</p><p>But the use of the word console to describe a panel of electrical controls can be traced even further back, beyond the discovery of electricity itself, to the pipe organ.</p><figure><img src="https://jshakespeare.com/post_images/pipe-organ-ebrach-kirche.jpg" alt="Interior photograph of a church showing the pipe organ facade below a large stained glass window"><figcaption><p>The pipe organ facade in the former abbey church in Ebrach, Germany. Image credit: <a href="https://commons.wikimedia.org/wiki/File:Ebrach_Kirche_rose_window_Orgel_P4252411efs.jpg">Wikimedia Commons</a></p></figcaption></figure><p>The pipe organ is the largest musical instrument, and is played by an organist who sits at a complex array of controls called a console. Organ consoles consist of keyboards (typically three to five), pedals, and stops - binary valves used for controlling wind flow to the pipes.</p><figure><img src="https://jshakespeare.com/post_images/organ-console.jpg" alt="A pipe organ console with console brackets"><figcaption><p>Image credit: <a href="https://commons.wikimedia.org/wiki/File:Usnaconsole.jpg">Wikimedia Commons</a></p></figcaption></figure><p>Organ consoles give us another everyday term: the idiom ‚Äòpulling out all the stops‚Äô, meaning to apply maximum effort to a task. When every stop on the console is open an organ will produce sound using every available pipe, and therefore at maximum volume.</p><figure><img src="https://jshakespeare.com/post_images/cesar-franck.jpg" alt="Painting of composer and organist C√©sar Franck pulling out an organ stop"><figcaption><p>Composer C√©sar Franck pulling out a stop at the console of the organ at St. Clotilde Basilica, Paris, 1885. Image credit: <a href="https://commons.wikimedia.org/wiki/File:Cesar_Franck_At_Organ.jpg">Wikimedia Commons</a></p></figcaption></figure><p>But where did this type of console get its name? One clue lies in the fact that many organ consoles share a design feature with the console table. Modern console tables are typically four-legged, free-standing structures designed to abut a wall. But if we go back a few centuries, we find that console tables were more commonly wall-mounted with brackets beneath the table surface to bear the load.</p><figure><img src="https://jshakespeare.com/post_images/console-table.jpg" alt="Marble and gilt oak console table with decoratively carved supporting brackets"><figcaption><p>French Regency console table from the Metropolitan Museum of Art collection in New York. Image credit: <a href="https://commons.wikimedia.org/wiki/File:Console_table_MET_DP268329.jpg">Wikimedia Commons</a></p></figcaption></figure><p>These supporting brackets are where the console table, (and perhaps the organ console) gets its name. In architecture, a console refers to an ornamental bracket that supports a protruding structure, such as a ledge, cornice, or balcony.</p><figure><img src="https://jshakespeare.com/post_images/console-architecture.jpg" alt="A neoclassical stone console supporting a balcony"><figcaption><p>Neoclassical stone console supporting a balcony at the Maison m√©dicale de l'≈íuvre du calvaire in Brussels. Image credit: <a href="https://commons.wikimedia.org/wiki/File:Fa%C3%A7adebalconconsolechausseewavreneoclassique.jpg">Wikimedia Commons</a></p></figcaption></figure><p>At this point, our etymological path forks. An architectural console may get its name from the verb ‚Äòto console‚Äô: literally <em>con solaris</em> or ‚Äòwith soothing‚Äô; a relieving of pain or, perhaps, of weight. You could consider the job of a console to ‚Äòrelieve‚Äô the weight of the structure above it.</p><p>An alternative explanation takes us back to the church, where in medieval times choir stalls were decorated with carved male figures called <em>consolateurs</em> or ‚Äòconsolers‚Äô. This in itself may have been a pun on the fact that consolers were often carved into armrests, thus supporting the weight of a seated chorist‚Äôs arms.</p><figure><img src="https://jshakespeare.com/post_images/choir-stall.jpg" alt="Illustration of wooden choir stalls showing carved consoles in the arm rests"><figcaption><p>Illustration showing the carved wooden <em>consolateurs</em> in the armrests of the choir stalls at Andlau Abbey in Alsace, France. Image credit: <a href="https://commons.wikimedia.org/wiki/File:Stalles.eglise.Anellau.png">Wikimedia Commons</a></p></figcaption></figure><p>So, far from being coincidental homonyms, it turns out that the many definitions of ‚Äòconsole‚Äô share a common etymological root, even when it‚Äôs used as a verb. Does the same go for ‚Äòlog‚Äô?</p><h2 id="log">Log</h2><p>In computing, the term ‚Äòlog‚Äô derives from a ship‚Äôs log, which is short for ‚Äòlogbook‚Äô. A logbook is used for recording information about any event taking place aboard a vessel, from navigation to maintenance to changes in crew. While there are typically no restrictions about what can be recorded in a logbook, the name comes from a very specific use: recording the ship‚Äôs speed.</p><p>Long before the invention of modern instruments, such as GPS, recording speed was an essential part of navigating the seas. Sailors would measure their speed and record it in the logbook every half hour, and by knowing how fast they were going, combined with the direction in which they were traveling (measured using a compass), they could work out where they were on the map.</p><figure><img src="https://jshakespeare.com/post_images/ships-logbook.jpg" alt="Ships logbook showing handwritten entries"><figcaption><p>Logbook from the USS Savannah with entries from September 3-15, 1943. Image credit: <a href="https://commons.wikimedia.org/wiki/File:19430903-19430915_USS_Savannah_CL-42_Turret_Two_log_book_entries.jpg">Wikimedia Commons</a></p></figcaption></figure><p>The logbook got its name from the chip log, a device that sailors used to measure the ship‚Äôs speed. This consisted of a quarter-circle piece of wood (the ‚Äòchip‚Äô) with a rope tied to it, in which knots were tied at regular intervals.</p><figure><img src="https://jshakespeare.com/post_images/chip-log.jpg" alt="Chip log"><figcaption><p>19th century chip log. Image credit: <a href="https://en.wikipedia.org/wiki/File:Loch_%C3%A0_plateau.jpg">Wikimedia Commons</a></p></figcaption></figure><p>A sailor would throw the chip overboard and count how many knots spooled out while another sailor timed him using a sand timer. When the timer was up, the number of knots that had passed over the stern could be used to calculate the ship‚Äôs speed, which was then recorded in the logbook. This is where we get the term ‚Äòknot‚Äô as shorthand for 1 nautical mile per hour.</p><figure><img src="https://jshakespeare.com/post_images/chip-log-engraving.jpg" alt="An engraving of three mates measuring a ship‚Äôs speed using a chip log"></figure><p>Before the invention of the chip log, an even more rudimentary technique for gauging speed was the Dutchman‚Äôs log. One sailor would throw any floating object (probably an actual log) over the bow of the ship while another sailor on the stern timed how long it took for the object to pass him. With this measurement (and knowing the length of the ship), the sailors could make a rough estimate of how fast they were travelling.</p><p>The days of using a log to measure a ship‚Äôs speed lie centuries behind us, but ‚Äòlog‚Äô is a ubiquitous term in modern life thanks to its importance in computing (just think how many times you ‚Äòlog in‚Äô to various pieces of software every day). And it‚Äôs just one of many modern definitions whose origins lie in our civilization‚Äôs long maritime history. We don‚Äôt need to look far to find more: the word ‚Äòcyber‚Äô derives from the ancient Greek word <em>kubernƒìtƒìs</em>, meaning steersman or rudder, and the word ‚Äògadget‚Äô was a slang term used by sailors for any part of a ship that they couldn‚Äôt remember the correct name of.</p><p>So next time you write <code>console.log</code> in your editor, spare a thought for the computer pioneers, pipe organists, medieval carvers, and old-word mariners who played a small part in giving us the very modern definitions of these two words.</p><hr><p><em>If you enjoyed this, you may want to read <a href="https://jshakespeare.com/your-creations-will-not-outlast-you/">Your creations will not outlast you</a>.</em></p></div></article></main></div></div></div>]]>
            </description>
            <link>https://jshakespeare.com/javascript-console-log-etymology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25346856</guid>
            <pubDate>Tue, 08 Dec 2020 15:52:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kafka Is Not a Database]]>
            </title>
            <description>
<![CDATA[
Score 309 | Comments 161 (<a href="https://news.ycombinator.com/item?id=25346851">thread link</a>) | @andrioni
<br/>
December 8, 2020 | https://materialize.com/kafka-is-not-a-database/ | <a href="https://web.archive.org/web/*/https://materialize.com/kafka-is-not-a-database/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>This post is co-authored by George Fraser, the CEO of <a href="http://fivetran.com/">Fivetran</a>, and Arjun Narayan, the CEO of Materialize. This blog post is cross-posted <a href="https://fivetran.com/blog/kafka-is-not-a-database">on the Fivetran blog</a>.</em></p>
<p>It‚Äôs important to understand the uses and abuses of streaming infrastructure.</p>
<p>Apache Kafka is a message broker that has rapidly grown in popularity in the last few years. Message brokers have been around for a long time; they‚Äôre a type of datastore specialized for ‚Äúbuffering‚Äù messages between producer and consumer systems. Kafka has become popular because it‚Äôs open-source and capable of scaling to very large numbers of messages.</p>
<p>Message brokers are classically used to decouple producers and consumers of data. For example, at Fivetran, we use a message broker similar to Kafka to buffer customer-generated webhooks before loading them in batches into your data warehouse:</p>
<p><img src="https://materialize.com/wp-content/uploads/2020/12/kafka_overview.png" data-src="https://materialize.com/wp-content/uploads/2020/12/kafka_overview.png" alt="A Message Broker Used as a buffer before loading into a data warehouse" width="960" height="124" data-srcset="https://materialize.com/wp-content/uploads/2020/12/kafka_overview.png 960w, https://materialize.com/wp-content/uploads/2020/12/kafka_overview-300x39.png 300w, https://materialize.com/wp-content/uploads/2020/12/kafka_overview-768x99.png 768w" data-sizes="(max-width: 960px) 100vw, 960px" srcset="https://materialize.com/wp-content/uploads/2020/12/kafka_overview.png 960w, https://materialize.com/wp-content/uploads/2020/12/kafka_overview-300x39.png 300w, https://materialize.com/wp-content/uploads/2020/12/kafka_overview-768x99.png 768w"></p>
<p>In this scenario, the message broker is providing durable storage of events between when a customer sends them, and when Fivetran loads them into the data warehouse.</p>
<p>However, Kafka has occasionally been described as something much more than just a better message broker. Proponents of this viewpoint position Kafka as a fundamentally new way of managing data, where <a href="https://www.confluent.io/blog/okay-store-data-apache-kafka/" target="_blank" rel="noopener noreferrer">Kafka replaces the relational database as the definitive record of what has happened</a>. Instead of reading and writing a traditional database, you append events to Kafka, and read from downstream views that represent the present state. This architecture has been described as ‚Äú<a href="https://www.confluent.io/blog/turning-the-database-inside-out-with-apache-samza/" target="_blank" rel="noopener noreferrer">turning the database inside out</a>‚Äú.</p>
<p>In principle, it is possible to implement this architecture in a way that supports both reads and writes. However, during that process you will eventually confront every hard problem that database management systems have faced for decades. You will more or less have to write a full-fledged DBMS in your application code. And you will probably not do a great job, because databases take years to get right. You will have to deal with dirty reads, phantom reads, write skew, and all the other symptoms of a hastily implemented database.</p>

<p>The fundamental problem with using Kafka as your primary data store is it provides no isolation. Isolation means that, globally, all transactions (reads and writes) occur along some consistent history. Jepsen provides a <a href="https://jepsen.io/consistency">guide</a> of isolation levels (inhabiting an isolation level means that the system will never encounter certain anomalies).</p>
<p>Let‚Äôs consider a simple example of why isolation is important: suppose we‚Äôre running an online store. When a user checks out, we want to make sure all their items are actually in stock. The way to do this is to</p>
<ol>
<li>Check the inventory level for each item in the user‚Äôs cart.</li>
<li>If an item is no longer available, abort the checkout.</li>
<li>If all items are available, subtract them from the inventory and confirm the checkout.</li>
</ol>
<p>Suppose we are using Kafka to manage this process. Our architecture might look something like this:</p>
<p><img src="https://materialize.com/wp-content/uploads/2020/12/kafka_checkout.png" data-src="https://materialize.com/wp-content/uploads/2020/12/kafka_checkout.png" alt="A microservice workflow for processing checkouts" width="960" height="753" data-srcset="https://materialize.com/wp-content/uploads/2020/12/kafka_checkout.png 960w, https://materialize.com/wp-content/uploads/2020/12/kafka_checkout-300x235.png 300w, https://materialize.com/wp-content/uploads/2020/12/kafka_checkout-768x602.png 768w" data-sizes="(max-width: 960px) 100vw, 960px" srcset="https://materialize.com/wp-content/uploads/2020/12/kafka_checkout.png 960w, https://materialize.com/wp-content/uploads/2020/12/kafka_checkout-300x235.png 300w, https://materialize.com/wp-content/uploads/2020/12/kafka_checkout-768x602.png 768w"></p>
<p>The web server reads the inventory level from a view downstream from Kafka, but it can only commit the transaction <em>upstream</em> in the checkouts topic. The problem is one of <strong>concurrency control</strong>: if there are two users racing to buy the last item, <em>only one must succeed</em>. We need to read the inventory view and confirm the checkout at <em>a single point in time</em>. However, there is no way to do this in this architecture.</p>
<p>The problem we now have is called <a href="http://justinjaffray.com/what-does-write-skew-look-like/">write skew</a>. Our reads from the inventory view can be out of date by the time the checkout event is processed. If two users try to buy the same item at nearly the same time, they will both succeed, and we won‚Äôt have enough inventory for them both.</p>
<p>Event-sourced architectures like these suffer many such isolation anomalies, which constantly gaslight users with ‚Äútime travel‚Äù behavior that <a href="https://www.google.com/search?q=facebook+unread+notification+glitch">we‚Äôre all familiar with</a>. Even worse, research shows that anomaly-permitting architectures create outright security holes that allow hackers to steal data, as covered in <a href="https://www.cockroachlabs.com/blog/acid-rain/">this excellent blog post</a> on <a href="http://www.bailis.org/papers/acidrain-sigmod2017.pdf">this research paper.</a></p>

<p>These problems can be avoided if you use Kafka as a <em>complement</em> to a traditional database:</p>
<p><img src="https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow.png" data-src="https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow.png" alt="kafka used for Change Data Capture from an OLTP database" width="960" height="658" data-srcset="https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow.png 960w, https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow-300x206.png 300w, https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow-768x526.png 768w" data-sizes="(max-width: 960px) 100vw, 960px" srcset="https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow.png 960w, https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow-300x206.png 300w, https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow-768x526.png 768w"></p>
<p>OLTP databases perform a crucial task that message brokers are not well suited to provide: admission control of events. Rather than using a message broker as a receptacle for ‚Äúfire and forget‚Äù events, forcing your event schema into an ‚Äúintent pattern‚Äù, an OLTP database can <em>deny</em> events that conflict, ensuring that only a single consistent stream of events are ever emitted. OLTP databases are really good at this core <strong>concurrency control</strong> task ‚Äì scaling to many millions of transactions per second.</p>
<p>Using a database as the point-of-entry for writes, the best way to extract events from a database is via streaming <strong>change-data-capture</strong>. There are several great open CDC frameworks like <a href="http://debezium.io/">Debezium</a> and <a href="http://maxwells-daemon.io/">Maxwell</a>, as well as native CDC from <a href="https://www.cockroachlabs.com/docs/stable/change-data-capture.html">modern</a> <a href="https://docs.oracle.com/cd/B28359_01/server.111/b28313/cdc.htm">SQL</a> <a href="https://docs.yugabyte.com/latest/architecture/docdb-replication/change-data-capture/">databases</a>. Change-data-capture also sets up an elegant operational story. In recovery scenarios, everything can be purged downstream and rebuilt from the (very durable) OLTP database.</p>

<p>The database community has learned (and re-learned) several important lessons over decades. Each one of these lessons was obtained at the high prices of data corruption, data loss, and numerous user-facing anomalies. The last thing you want to do is to find yourself relearning these lessons because you <a href="https://www.oreilly.com/library/view/strata-hadoop/9781491944608/video244677.html">accidentally misbuilt a database</a>.</p>
<p>Real-time streaming message brokers are a great tool for managing high-velocity data. But you will still need a traditional DBMS for isolating transactions. The best reference architecture for ‚Äúturning your database inside out‚Äù is to use OLTP databases for admission control, use CDC for event generation, and model downstream copies of the data as materialized views.</p>

<p>If you‚Äôre interested in getting fully consistent views of your Kafka data updated in realtime, <a href="https://materialize.com/quickstart/">try Materialize out</a>&nbsp;to see if it‚Äôs the right solution for you!</p>
<div><h3>Subscribe to our Newsletter</h3>
        
        

        </div></div></div>]]>
            </description>
            <link>https://materialize.com/kafka-is-not-a-database/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25346851</guid>
            <pubDate>Tue, 08 Dec 2020 15:52:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Little Tasks, Little Trust]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 81 (<a href="https://news.ycombinator.com/item?id=25346460">thread link</a>) | @aard
<br/>
December 8, 2020 | http://adamard.com/little_tasks.html | <a href="https://web.archive.org/web/*/http://adamard.com/little_tasks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>{<br>&nbsp;&nbsp;&nbsp;&nbsp;Adam Ard<br>}</h2><br>
  <h2>Little Tasks, Little Trust</h2>
  <h3>How Delegating Responsibilities is Better Than Managing By Tasks</h3>
  <blockquote>
    Trust is the highest form of motivation. It brings out the very
    best in people.
  </blockquote>
  <blockquote>
    --Stephen R. Covey, The 7 Habits of Highly Effective People
  </blockquote>
  <p>
It‚Äôs basically a sacred project management mantra by
now: <strong>divide your work into tasks that are as small as
possible</strong>. Estimate them with your team. Then drop them into
the all-knowing product backlog. But no one seems to be looking very
critically at how this practice has affected the software engineering
profession. Back in the 90‚Äôs, when I started programming, this was not
how it worked. It was, dare I say, a little more
professional.</p><p>Back then, your boss had a dozen or more things
they were responsible for and when you got hired they breathed a deep
sigh of relief.</p><p>‚ÄúFinally, now that Vincent is here, I can make
him do A and B; and with Ted doing C, D, and E and Jan doing F, G, and
H, I can finally get to I, J, K, L, and M.‚Äù</p><p>Most importantly, A
and B were big things, like whole products or large system
libraries. Building and maintaining them consumed all of your
time. They were your delegated responsibilities, not mere tasks. It
wasn‚Äôt that hard to manage people this way either. If you weren‚Äôt
doing a good job, the boss would let you know.</p><p>‚ÄúHey, Vincent, A
isn‚Äôt turning out quite like I was imagining. Can you do a little more
of this‚Ää‚Äî‚Ääand definitely more cowbell.‚Äù</p><p>Then you went back to
your private office (I sure miss private offices, but that is a topic
for another day) and fixed a few things. Later, in a weekly status
meeting you would tell people how it went‚Ää‚Äî‚Ääyep, that‚Äôs right, no
daily stand-ups where you look mournfully at your shoes and admit that
you didn‚Äôt make any notable progress yet.</p><p>No backlog grooming
meetings or burn-down charts either. Your manager simply looked at
how <em>your </em>products were coming along. A little trust, some
accountability, and a healthy portion of ‚Äúgive me some space to do my
work.‚Äù</p><p>The way we work now is different. Sadly, it‚Äôs less
motivating, less efficient, and profoundly less respectful of
individual abilities.</p><h3>whose vision is it again?</h3><p>As I
see it, little tasks are born of a fundamentally different management
attitude. Small tasks are a not-so-subtle way of saying that all the
product vision lies with management. Keep away. Don‚Äôt
touch.</p><p>While larger tasks send a completely different
message. Here, management is giving you bigger pieces to chew on,
inviting you to mix some of your own creativity with the end
product. You get to do some design work, think about what the customer
needs, and take pride in what comes out the other end. Sure, the
organization has an overarching strategy, but they still want people
to take on responsibilities, not just errands. They trust you to align
with the overall vision and because you feel like you are part of the
‚Äúclub‚Äù, you actually want to.</p><h3>too much love for the
metrics</h3><p>Small tasks have also taken hold because they fit
nicely with the age-old assembly-line mentality. Sadly, there are
armies of managers that still live by that dogma. For them, it is all
about picking <em>metrics and optimizing them‚Ää</em>‚Äî‚Äämanagement by
chart and graph.</p><p>Unfortunately, little tasks in Jira (or any of
the dozens of other issue tracking systems out there) bring the
promise of a whole host of tasty new charts and graphs: burn-down,
burn-up, velocity, lead-time, cycle time, task age, throughput, failed
deployment, flow and control. It‚Äôs as irresistible as candy to a
baby.</p><p>But, assigning responsibilities instead of tasks takes
away an assembly-line manager‚Äôs favorite tools. Because they are
larger, responsibilities can‚Äôt be so easily measured and tracked. So
metrics-managers will fight both tooth and nail to keep your work divided
and cataloged in tiny, traceable instructions.</p><h3>when will I get some design
experience?</h3><p>Sadly, as developers, we do it to ourselves as
well. Once someone gives us a better title, we are right on board with
the program. When a regular developer might have had a chance to do
some research or design, we immediately snatch it away for
ourselves.</p><p>As technical management, we standardize our
frameworks, languages, deployment operating systems, and cloud service
providers. We write wrappers around networking, logging, and
monitoring libraries and demand they always be used. Then, after we
have taken the task of designing and researching the CI/CD tools and
pipeline, we write coding standards for our coding
standards.</p><p>Worse yet, we design every product‚Äôs architecture,
and expect any deviation to be approved by us first. All that is left
are tiny morsels. Grunt work for the foot soldiers once the fun has
been stripped away.</p><p>Poor front-line programmers are left
wide-eyed with empty bowls, asking ‚Äúplease sir, can I have some more?
I just wanted to design one little service. I know I am not worthy,
but can I please just write my own sql queries without using that
awful ORM?  PLEASE?‚Äù</p><p>Sadly, when those poor programmers finally
seek promotion, hoping for their first real shot at higher level
engagement, they are rebuffed: ‚ÄúYou don‚Äôt really have any design
experience I am afraid. We are looking for someone who has designed
large systems.‚Äù</p><p>To their managers they could rightfully reply,
‚Äúthat was your doing, not mine!‚Äù</p><h3>estimation is never
free</h3><p>There is a grave misconception circulating that if you
just sit down, in a comfy conference room chair, and split a project
into tiny tasks, small enough to be individually estimated,
then when you add them up, Viola! You‚Äôll have a accurate
estimate for the whole project! Easy peasy.</p><p>There are two
problems with this delusion. First, no task, even a small one,
is easy to estimate. I have seen many ‚Äútiny‚Äù, one-day tasks blow up
into week long campaigns. All because of hidden complexity that comes
popping out like a Pandora‚Äôs box once you start coding on
it.</p><p>Second, when you divide work into little tasks, before
actually working on any of them, you are making untested
assumptions. Many of them. The more tasks you define, the more facets
of a hypothetical design you must assume (implicitly of course, since
no one ever writes design assumptions in task descriptions). Soon,
you‚Äôve created a long chain of design choices, all depending on
previous ones, sitting on sticky notes on the wall.</p><p>The problem
is, as soon as you start working on one of them, you will
realize that your implicit design decisions are wrong. Now, you will spend MUCH more time than was
previously estimated for this task and all other tasks that depend on
its faulty design are invalid. The whole house of cards comes
tumbling down. Time for another all-day backlog grooming session? What
a waste!</p><h3>conclusion</h3><p>Back in the day, before everyone
realized that software companies were positioned to make lots of
money, we had some elbow room. We had a lot of responsibility and the
ability to make a lot of decisions. But now, a lot more people have
piled onto the island. Unfortunately, some of them have slowly chipped
away at the domain of the software engineer. One by one, descending
from their vessels they planted their flags:</p><p>‚ÄúI am Amerigo, the
product guy. Heretofore, no developer will make product decisions, for
they are mine.‚Äù</p><p>‚ÄúAnd I am Ferdinand, process guy. Heretofore,
no developer will make process decisions, for they are
mine.‚Äù</p><p>‚ÄúI Bartolomeu will enforce compliance.‚Äù</p><p>‚ÄúI Vasco
used to be pretty good at Microsoft Access, I guess I‚Äôll be the
database guy.‚Äù</p><p>One by one, until every responsibility that
wasn‚Äôt actual open-up-emacs-and-start-typing-stuff programming was
taken away, forbidden even. And then, the remaining, purely technical
tasks were carved up by architecture/standard hoarding engineers,
hungry for something of substance. Only dry, broken carcasses were
left scattered on the ground.</p><p>Of course, there is a solution to
this predicament‚Ää‚Äî‚Äädelegate <em>responsibilities</em> to everyone,
all the way down to the bottom of the hierarchy. Or better yet,
flatten or abolish the hierarchy all together. But until that
happens, you‚Äôll just have to content yourself with measly for-loops
and if-statements‚Ää‚Äî‚Ääfollowing the coding standard of
course.</p></div></div>]]>
            </description>
            <link>http://adamard.com/little_tasks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25346460</guid>
            <pubDate>Tue, 08 Dec 2020 15:29:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built this selfie-based cyberpunk avatar creator for all of the impatient fans]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25346453">thread link</a>) | @ttoke
<br/>
December 8, 2020 | https://readyplayer.me/cyberpunk | <a href="https://web.archive.org/web/*/https://readyplayer.me/cyberpunk">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Built with<span>√¢ÔøΩ¬§√Ø¬∏ÔøΩ </span>by</p><!-- --> <p><a href="https://wolf3d.io/">Wolf3D</a></p><p>Ready Player Me is not affiliated, associated, authorized, endorsed by, or in any way officially connected with CD Projekt S.A., or any of its subsidiaries or its affiliates. Cyberpunk 2077 as well as related names, marks, emblems and images are registered trademarks of their respective owners.</p></div></div>]]>
            </description>
            <link>https://readyplayer.me/cyberpunk</link>
            <guid isPermaLink="false">hacker-news-small-sites-25346453</guid>
            <pubDate>Tue, 08 Dec 2020 15:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Humor Becomes Horror]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25346392">thread link</a>) | @leoschwartz
<br/>
December 8, 2020 | https://restofworld.org/2020/when-humor-becomes-horror/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/when-humor-becomes-horror/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>F</span>eel-good moments are difficult to come by on Twitter in Pakistan. In between the political infighting and trolls, though, there was a brief moment where the ugliness the platform often brings out in people gave way to the app‚Äôs potential for humanity.&nbsp;</p>



<p>In October, a Karachi school teacher, Aimun Faisal, tweeted questions from her students about space and space travel. ‚ÄúDo you get scared that your space shuttle might get lost?‚Äù one 10-year-old asked. Ms. Faisal tagged NASA and other space agencies in the post, encouraging readers to retweet it and bring it to their attention. <a href="https://gulfnews.com/world/asia/pakistan/nasa-astronauts-scientists-answer-pakistani-fourth-graders-science-questions-on-twitter-1.1602755591289">It worked</a>.</p>



<p>A Canadian astronaut who has flown in a space shuttle twice replied that he wasn‚Äôt scared because Earth was nearby, and he could use the stars to find his way. ‚ÄúI felt especially comforted when I flew over home,‚Äù <a href="https://twitter.com/Cmdr_Hadfield/status/1316390465277767682?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1316390465277767682%7Ctwgr%5E%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fgulfnews.com%2Fworld%2Fasia%2Fpakistan%2Fnasa-astronauts-scientists-answer-pakistani-fourth-graders-science-questions-on-twitter-1.1602755591289">he tweeted</a>. ‚ÄúHere‚Äôs a photo I took of Karachi ‚Äî can you find your school?‚Äù</p>



<p>It‚Äôs the kind of interaction that leads one to believe that perhaps all you need in life is a Twitter account and a heart that still beats. The media ate it up too: Ms. Faisal and her tweet were in all the major newspapers and even on TV. We were gushy over Ms. Faisal; we wished there were more teachers like her.&nbsp;</p>



<p>Just a few weeks later, people were suggesting that Ms. Faisal should go jump into a river or move to another country.&nbsp;</p>



<p>It all turned after ‚Äî what else? ‚Äî a series of tweets.&nbsp;</p>



<p>One evening this past September, a woman set out in her car on a motorway outside Lahore, her two children in tow. Motorways in Pakistan are safer than most roads there; they have their own police, who have a reputation, unlike other police units, for being well-dressed and resistant to corruption.&nbsp;</p>



<p>That evening, the woman‚Äôs car ran out of fuel. She locked her car doors and made some phone calls, but the rescue service didn‚Äôt answer, and she couldn‚Äôt get through to her family. By now, it was past midnight. She made more calls and waited for a friend to come pick her up. While she waited, two men emerged from the darkness, broke her car window, and when she fought back, took her children into some nearby bushes. She scrambled to save them, and while she fought, she was gang-raped.&nbsp;</p>



<p>In the pre‚Äìsocial media age, if a rape story ever got more than a couple of column inches on the inside pages of a newspaper, the victim not only had asked for it but, by reporting it and making it public, was asking for something more.&nbsp;</p>



<p>In an interview with the <em>Washington Post</em>, Pakistan‚Äôs former president and army chief Pervez Musharraf (now absconded from the country) once said <a href="https://www.washingtonpost.com/archive/politics/2005/09/19/musharraf-denies-rape-comments/5f2e0d4c-5ff2-4273-81e5-878cd59a1744/">Pakistani women get themselves raped so they can get a Canadian visa</a>. He probably thought he was being funny or insightful. When his office denied his having said it, the <em>Post</em> made the audio public. You can hear one of his aides laughing in the background.&nbsp;</p>



<p>Attitudes toward rape haven‚Äôt changed much since the Musharraf days, but there was something about the awfulness of a woman trapped with her children on a motorway at night that struck a chord with the Pakistani public. As the news rippled through Twitter, #LahoreMotorwayIncident became a trending hashtag. The details of the crime were so grotesque that, for a few days, it <a href="https://www.bbc.com/news/world-asia-54186609">seemed the nation actually believed that rape was a crime</a> and that the woman hadn‚Äôt asked for it.&nbsp;</p>



<p>Pakistan‚Äôs traditional and social media go into this kind of outrage cycle when children get raped, or get raped and then killed, which happens more often than one can stomach. There was genuine fury across the country when a 7-year-old girl was raped, strangled, and left in a rubbish heap two years ago. <a href="https://www.dawn.com/news/1439587">Her name was Zainab</a>. On Twitter and Facebook, users argued over whether her rapist and killer should be hanged in public, quartered, doused in acid, or just locked up for life.</p>



<p>After the motorway incident, the usual bloodlust was on display. There were calls for public hangings and for chopping up the culprits. Prime Minister Imran Khan even appeared on a TV interview saying <a href="https://www.cnn.com/2020/09/16/asia/imran-khan-chemical-castration-rapists-intl/index.html">he has been contemplating chemical castration as a punishment for such crimes</a>.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-1228489392-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-1228489392-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-1228489392-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1228489392-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1228489392-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1228489392-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1228489392-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="People protesting in Karachi after the gang rape of a woman on a motorway near Lahore.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Rizwan Tabassum/AFP via Getty Images</span>
			</figcaption>
		</figure>


<p>And while the Lahore rapists were still on the loose, the newly appointed Lahore police chief appeared on one of the nightly news shows during the wall-to-wall media coverage. In effect, he said he was surprised that a mother of two had decided to take the motorway when another road would have sufficed for her journey. And if she had to take the motorway, he went on to ask, couldn‚Äôt she at least have checked her gas tank?&nbsp;</p>



<p>Ms. Faisal, the teacher we had fawned over just weeks prior for her tweets about space travel, was outraged. On Twitter, she was one of many to demand the police chief‚Äôs resignation, tweeting in disgust at the craven responses to the news she and others were seeing, rhetorical questions as to why the woman had failed to prevent her own assault.&nbsp;</p>



<p>In return, our beloved Ms. Faisal was met with a flood of insults; trolls suggested she leave Pakistan if she had a problem with it. Being stuck on the motorway without gas became an internet meme that small-time politicians and social media trolls lobbed at one another. Somewhere along the way, ‚ÄúWhy didn‚Äôt she check her petrol tank before leaving her home?‚Äù replaced the original question: ‚ÄúWhat kind of beasts would rape a woman in front of her children?‚Äù&nbsp;</p>



<p>How did this horror morph into a meme? Does every one of us carry inside us a bit of General Musharraf, smirking while his aides giggle?&nbsp;</p>



<p>Long before we had social media, Pakistan swam through its sea of miseries on the backs of jokes. The mausoleum of Pakistan‚Äôs longest-serving dictator, General Zia‚Äôul Haq, is jokingly referred to as Jaws Square. Guess why? Because, after ruling over us for 11 years, he died in a plane crash, and only his teeth survived.&nbsp;</p>



<p>Jokes back then went viral before we ever began to call them ‚Äúviral.‚Äù You would hear one about the dictator in Urdu in Karachi one day, and the next day in Peshawar, someone would tell you it in Pashto. Jokes eased us out of our terror.&nbsp;</p>



<p>But now the jokes themselves have become the terror. You can make a joke about a dead dictator, or Osama bin Laden becoming fish food, but how do you laugh at a joke about a woman raped in front of her children on the side of the motorway in the dead of night? Jokes were meant to subvert the powerful, not kick the poor to the ground.&nbsp;</p>



<p>For a brief moment, social media in Pakistan made it easy to laugh at despots and oppressors. They answered with troll farms, indoctrinating the youth to be subservient to power. Even in the midst of incidents so nauseating that they capture the attention of our fractured social media, the horrors of which seem undeniable, the trolls find ways to mock and belittle.&nbsp;</p>



<p>In November, another shocking piece of news roiled Pakistan‚Äôs social media: A 4-year-old rape survivor told her gut-wrenching story in a video that went viral. It was so harrowing, I couldn‚Äôt bring myself to watch it, even for reporting purposes. In another video, also shared widely online, the doctor who treated her after the assault broke down crying.&nbsp;</p>



<p>On Twitter, it‚Äôs easy to find redemption in the narrative too. In the middle of the outrage cycle, social media made a hero of the policeman <a href="https://www.gulftoday.ae/news/2020/11/14/pakistani-policeman-uses-own-daughter-as-bait-to-nab-rapists">who had found the girl‚Äôs rapist by enlisting his own daughter to lure him</a>. The rapist was killed in a police encounter.&nbsp;</p>



<p>The policeman and his underage daughter were forced to take this extreme step because there were no women officers in his district. The prime minister called to congratulate the man, and his daughter was awarded a million rupees as a prize along with a guaranteed college scholarship.&nbsp;</p>



<p>Ms. Faisal, who by now has endured a litany of abuses online, questioned the collective satisfaction on social media. As proud as we are of the police officer, she tweeted, the story said more about the country‚Äôs broken system than it did about heroism. ‚ÄúNo police officer should be forced to risk his family to perform his duty,‚Äù<a href="https://twitter.com/bluemagicboxes/status/1327209635594588165"> she wrote</a>.</p>



<p>‚ÄúTum kabhi khush na hona,‚Äù someone tweeted back. ‚ÄúYou‚Äôll never be happy.‚Äù</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/when-humor-becomes-horror/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25346392</guid>
            <pubDate>Tue, 08 Dec 2020 15:25:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FedEx and UPS hit companies with unexpected holiday shipping limits]]>
            </title>
            <description>
<![CDATA[
Score 209 | Comments 198 (<a href="https://news.ycombinator.com/item?id=25346386">thread link</a>) | @mooreds
<br/>
December 8, 2020 | https://www.modernretail.co/retailers/this-is-going-to-ruin-us-fedex-and-ups-hit-companies-with-unexpected-holiday-shipping-limits/ | <a href="https://web.archive.org/web/*/https://www.modernretail.co/retailers/this-is-going-to-ruin-us-fedex-and-ups-hit-companies-with-unexpected-holiday-shipping-limits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Johnny Galbraith, co-founder of Salt Lake City-based e-commerce company Letterfolk, knew that it was going to be difficult to get orders to customers in a timely manner this holiday season, with more people ordering online than ever before.</p><p>He thought he had come up with a solution: to hold his Black Friday sale a week earlier this year. That way, he would be shipping out his products before carriers like FedEx ‚Äî which he estimates ships 75% of Letterfolk‚Äôs packages ‚Äî would be under the most strain.</p><div id="piano-cta">
<p>But on the Saturday before Thanksgiving, Galbraith got a call from his FedEx representative: through the holidays, FedEx would only pick up 110 Letterfolk packages per day ‚Äî something that has never happened to Galbraith in the five years he‚Äôs been in business. It was a number that was calculated based on the average number of packages FedEx was picking up from Letterfolk per day in September, plus 10%. But thanks to his early Black Friday sale, Galbraith had a queue of 3,000 orders waiting to go out.</p>

<p>‚ÄúIt was like, ‚Äòthis is going to ruin us as a business,'‚Äù said Galbraith, whose company sells letterboards and other home decor. ‚ÄúWe are being told that just to ship out our existing queue ‚Äî without any other orders coming it ‚Äî it would take us up until the holidays to get them out to customers.‚Äù</p>
<p>Carriers like FedEx and UPS have been warning for months to <a href="https://www.wsj.com/articles/this-holiday-crunch-starts-early-with-more-packages-than-means-to-deliver-them-11603013401">expect holiday shipping delays</a>. But some retail executives, like Galbraith, say they were not given advanced notice by carriers that they could face package pickup limits this holiday. It‚Äôs an issue that‚Äôs affecting companies both big and small ‚Äî the Wall Street Journal <a href="https://www.wsj.com/articles/ups-slaps-shipping-limits-on-gap-nike-to-manage-e-commerce-surge-11606926669">reported</a> last week that UPS had temporarily stopped accepting shipments from major retailers like Nike and Macy‚Äôs.</p>
<p>Some executives who spoke with Modern Retail said that they feel like their carriers did not give them enough advance notice before applying a limit, and are frustrated by the fact that limits seem to be arbitrarily applied. In the meantime, they‚Äôre scrambling to find often expensive alternatives, including renting their own trucks or trying to find space with other carriers.</p>
<p>Representatives from FedEx and UPS would not provide details to Modern Retail about how they calculate package pickup limits.</p>
<p>FedEx has been ‚Äúproactively working with our customers to understand their expected volume,‚Äù a spokeswoman told Modern Retail, and said the company has been preparing for the holidays by hiring more than 70,000 seasonal workers this year, and for the first time, picking up packages seven days a week.</p>

<p>‚Äú<span>UPS</span>&nbsp;continues to work closely with our largest customers to steer volume to capacity and ensure the&nbsp;<span>UPS</span> network is reliable for all customers,‚Äù a UPS spokesman said. ‚ÄúAgreed upon strategies for our largest customers include shifting package volume away from the heaviest demand shipping days, fully utilizing weekend capacity, and aligning promotional strategies with capacity.‚Äù</p>
<p><strong>Making their own deliveries<br>
</strong>For the most part, UPS and FedEx first started imposing shipping limits after Black Friday. Helena Price Hambrecht, founder of aperitif brand Haus, <a href="https://www.nytimes.com/2020/12/05/business/ecommerce-shipping-holiday-season.html?referringSource=articleShare">told the New York Times</a> that FedEx informed her that starting on Wednesday, its drivers would only pick up 500 packages from Haus per week day, through the holidays. FedEx however, did give Haus a larger cap on the weekends. In a follow-up email to Modern Retail, Price Hambrecht did not say exactly when FedEx informed her of the limit, only that ‚ÄúFedEx has been great about communicating changes to us as soon as possible.‚Äù</p>
<p>David Malka, chief sales officer of returns processing company goTRG ‚Äî which works with major retailers like Target, Walmart and Lowe‚Äôs to process some of their returns ‚Äî told Modern Retail that shipping limits of roughly 200 packages per day had been imposed at four of the company‚Äôs warehouses. Though he added that the company is getting ‚Äúconflicting reports‚Äù from FedEx about what exactly the limit is at some facilities. Malka, like Gilbraith said that goTRG received no advanced notice from FedEx that package pickup limits would be applied.</p>
<p>The most immediate way that retailers are trying to deal with pickup limits imposed by UPS or FedEx is to redirect some shipments to another carrier. Shortly after Galbraith‚Äôs FedEx representative informed him of Letterfolk‚Äôs new limit, he immediately set up deliveries through UPS ‚Äî something he said he hadn‚Äôt done previously because he had a good relationship with FedEx.</p>
<p>That‚Äôs helped Letterfolk get through some of the 3,000 order backlog, though its <a href="https://www.letterfolk.com/pages/holiday-shipping-info">website is still advising customer</a>s that most orders placed during its Black Friday sale will ship within one to three business weeks. However, he said that it‚Äôs more expensive right now for Letterfolk to ship through UPS, because his company didn‚Äôt have time to negotiate discounted rates.</p>
<p>Some companies are setting up other contingency plans to ensure their packages get into customers hands more quickly. Price Hambrecht told Modern Retail that Haus will be relying on Ohi, a last-mile delivery provider, to deliver more of its packages in the Bay Area and Southern California.</p>
<p>Jay Sauceda, founder of Austin-based 3PL Sauceda Industries, said that his company rented its own truck for the first time for the holidays. Sauceda ‚Äî which works with companies including apparel brand Rowing Blazers and bra startup Pepper ‚Äî has yet to be hit with a package pickup per day limit. But if it does, the plan then is to load packages onto the truck and deliver them directly to a FedEx or UPS sorting facility.</p>
<p>Sauceda is also advising its customers to try and encourage customers to get orders in two to three days ahead of shipping cutoffs given by FedEx, UPS and other carriers to ensure packages arrive in time for Christmas and other key dates.</p>
<p>‚Äú[The carriers] are in a very unenviable position,‚Äù Sauceda said. ‚ÄúSo the biggest thing that we are trying to do this year to try to take the tension off.‚Äù</p>
<p><em>This story has been updated to clarify that FedEx has capped the number of Haus packages it will pick up at 500 per week day, not per day as previously stated.&nbsp;</em></p>
</div></div>]]>
            </description>
            <link>https://www.modernretail.co/retailers/this-is-going-to-ruin-us-fedex-and-ups-hit-companies-with-unexpected-holiday-shipping-limits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25346386</guid>
            <pubDate>Tue, 08 Dec 2020 15:25:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adaptive Request Concurrency: Resilient Observability at Scale]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25346094">thread link</a>) | @zhs
<br/>
December 8, 2020 | https://vector.dev/blog/adaptive-request-concurrency/ | <a href="https://web.archive.org/web/*/https://vector.dev/blog/adaptive-request-concurrency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Observability pipelines have become critical infrastructure in the current technological landscape, which is why we've built <a href="https://vector.dev/">Vector</a> to provide extremely high throughput with the tiniest resource footprint we can manage (<a href="https://rust-lang.org/">Rust</a> is a huge help here). But this is not enough in the real world: your observability pipeline needs to provide optimal performance and efficiency while <em>also</em> being a good infrastructure citizen and playing nicely with services like <a href="https://vector.dev/docs/reference/sinks/elasticsearch">Elasticsearch</a> and <a href="https://vector.dev/docs/reference/sinks/clickhouse">Clickhouse</a>.</p><p>And so we're excited to announce that Vector version 0.11 includes support for <strong>Adaptive Request Concurrency</strong> (ARC) in all of its HTTP-based <a href="https://vector.dev/docs/reference/sinks">sinks</a>. This feature does away with static rate limits and automatically optimizes HTTP concurrency limits based on downstream service responses. The underlying <a href="#how-it-works">mechanism</a> is a feedback loop inspired by TCP congestion control algorithms.</p><h2>The lead-up</h2><p>One of the most common support questions we get about Vector involves logs like this:</p><div><div><pre><div><p><span>TRACE tower_limit::rate::service: rate limit exceeded, disabling service</span></p></div></pre></div></div><p>Users typically have two questions about this:</p><ol><li>What does it mean?</li><li>How can I fix it?</li></ol><p>The answer to the first question is simple: Vector has <em>internally</em> rate-limited processing to respect user-configured limits‚Äî<a href="https://vector.dev/docs/reference/sinks/http/#rate_limit_duration_secs"><code>request.rate_limit_duration_secs</code></a>, <a href="https://vector.dev/docs/reference/sinks/http/#rate_limit_num"><code>request.rate_limit_num</code></a>, and <a href="https://vector.dev/docs/reference/sinks/http/#in_flight_limit"><code>request.in_flight_limit</code></a>‚Äîfor that particular <a href="https://vector.dev/docs/reference/sinks">sink</a>. In other words, Vector has intentionally reduced performance to stay within static limits.</p><p>The answer to the second question‚Äîhow to fix it‚Äîis more complex because it depends on a variety of factors that change over time (covered in more detail <a href="#the-second-problem-rate-limiting-is-not-a-panacea">below</a>). Telling the user to raise their limits would be irresponsible since we'd then risk overwhelming the downstream service and causing an outage; but not changing them could mean limiting performance in a dramatic way.</p><blockquote><p>"In one case, we found that rate limits were limiting performance by over 80%."</p></blockquote><p>The crux of the matter is that Vector's high throughput presents a major challenge for HTTP-based sinks like <a href="https://vector.dev/docs/reference/sinks/elasticsearch">Elasticsearch</a> because those services can't always handle event payloads as quickly as Vector can send them. And when data services are heavily interdependent‚Äîwhich is almost always!‚Äîletting Vector overhwelm one of them can lead to system-wide performance degradation or even cascading failures.</p><p>In versions of Vector prior to 0.11, you could address this problem by setting <a href="https://vector.dev/docs/reference/sinks/http/#rate-limits"><strong>rate limits</strong></a> on outbound HTTP traffic to downstream services. Rate limiting certainly <em>does</em> help prevent certain worst-case scenarios but customer feedback and our own internal QA has revealed that this approach also has deep limitations.</p><h2>The problem: rate limiting is not a panacea</h2><p>Rate limiting is nice to have as a fallback but it's a blunt instrument, a static half-solution to a dynamic problem. The core problem is that configuring your own rate limits locks you into a perpetual loop:</p><p><img src="https://vector.dev/img/rate-limiting-loop.png" alt="The rate limiting decision loop"></p><p>Within this vicious loop, you need to constantly avoid two outcomes:</p><ul><li>You set the limit too high and thus <strong>compromise system reliability</strong> by overwhelming your services. Time to lower the limit and re-assess.</li><li>You set the limit too low and <strong>waste resources</strong>. Your Elasticsearch cluster may be capable of handling more concurrency than you're providing‚Äîat least for now. Time to raise the limit and re-assess.</li></ul><p>Not only do you need to perform this balancing act on a per-sink basis and on each Vector instance‚Äîthat may be a <em>lot</em> of application points in your system‚Äîbut the optimal rate is an elusive target that shifts along with changes in a number of factors:</p><ul><li>The number of Vector instances currently sending traffic</li><li>The current capacity of downstream services</li><li>The volume of data you're currently sending</li></ul><p>These changes are especially pronounced in highly elastic environments, like <a href="https://kubernetes.io/">Kubernetes</a>, that are essentially <em>designed</em> to let you tweak cluster topologies, configuration, and much more with very little friction, which compounds the problem.</p><p>And don't forget, of course, that this chasing-the-dragon decision loop has its own cognitive and operational costs.</p><h2>The solution: Adaptive Request Concurrency</h2><p>We feel strongly that Vector's <strong>Adaptive Request Concurrency</strong> (ARC) feature provides a qualitatively better path than rate limiting. With ARC <a href="#the-role-of-configuration">enabled</a> on any given sink, Vector determines the optimal network concurrency based on current environment conditions and continuously re-adjusts in light of new information.</p><p>Here's how that plays out in some example scenarios:</p><table><thead><tr><th>Change</th><th></th><th>Response</th></tr></thead><tbody><tr><td><strong><em>You deploy more Vector instances</em></strong></td><td>‚ûî</td><td>Vector automatically redistributes HTTP throughput across both current and new instances</td></tr><tr><td><strong><em>You scale up your Elasticsearch cluster</em></strong></td><td>‚ûî</td><td>Vector automatically increases concurrency to take full advantage of the new capacity</td></tr><tr><td><strong><em>You scale your Elasticsearch cluster back down</em></strong></td><td>‚ûî</td><td>Vector lowers concurrency to avoid any risk of destabilizing the cluster (while still taking full of advantage of the now-decreased bandwidth)</td></tr><tr><td><strong><em>Your Elasticsearch cluster experiences a temporary outage</em></strong></td><td>‚ûî</td><td>Vector lowers concurrency dramatically and provides backpressure by <a href="https://vector.dev/docs/reference/sinks/http/#buffer">buffering</a> events</td></tr></tbody></table><p>With ARC, these scenarios require no human intervention. Vector quietly hums along making these decisions for you with a speed and granularity that rate limits simply cannot provide.</p><h2>How it works</h2><p>ARC in Vector is based on a decision-making process that‚Äôs fairly simple at a high level. When Vector POSTs data to downstream services via HTTP, it continuously keeps track of downstream service performance and uses that information to make precise concurrency decisions.</p><p>The diagram below shows Vector's decision chart:</p><p><img src="https://vector.dev/img/adaptive-concurrency.png" alt="The Adaptive Request Concurrency decision chart"></p><p>With ARC enabled, Vector watches for significant movements in two things: the round-trip time (RTT) of requests and HTTP response codes (failure vs. success).</p><ul><li>If the RTT is declining/constant and/or response codes are consistently successful (200-299), Vector sees üü¢ and increases the throughput linearly. This is the "additive increase" in AIMD.</li><li>If the RTT is increasing and/or response codes consistently indicate failure‚Äîcodes like <code>429 Too Many Requests</code> and <code>503 Service Unavailable</code>‚ÄîVector sees üü° and exponentially decreases concurrency. This is the "multiplicative decrease" in AIMD.</li></ul><p>This decision tree is always active and Vector always "knows" what to do, even in extreme cases like total service failure.</p><h3>The role of configuration</h3><p>Vector never stops quietly making the linear up vs. exponential down decision in the background, and it works out of the box with zero configuration beyond enabling the feature, which is currently on an opt-in basis in version 0.11. You can enable ARC in an HTTP sink by setting the <a href="https://vector.dev/blog/adaptive-request-concurrency/request_concurrency"><code>request.concurrency</code></a> parameter to <code>adaptive</code>. Here's an example for a Clickhouse sink:</p><div><div><pre><div><p><span>[</span><span>sinks.clickhouse_internal</span><span>]</span><span></span></p><p><span></span><span>type</span><span> </span><span>=</span><span> </span><span>"clickhouse"</span><span></span></p><p><span></span><span>inputs</span><span> </span><span>=</span><span> </span><span>[</span><span>"log_stream_1"</span><span>,</span><span> </span><span>"log_stream_2"</span><span>]</span><span></span></p><p><span></span><span>host</span><span> </span><span>=</span><span> </span><span>"http://clickhouse-prod:8123"</span><span></span></p><p><span></span><span>table</span><span> </span><span>=</span><span> </span><span>"prod-log-data"</span><span></span></p><p><span></span><span>request.concurrency</span><span> </span><span>=</span><span> </span><span>"adaptive"</span></p></div></pre></div></div><p>There's also room for fine-tuning if you find yourself needing additional knobs:</p><ul><li><strong>Buffering</strong>. What happens when Vector needs to lower concurrency and thus throttle the output? What happens to data that needs to be sent later? Vector lets you choose between an on-disk and an in-memory <a href="https://vector.dev/docs/reference/sinks/http/#buffer">buffer</a> and to set a <a href="https://vector.dev/docs/reference/sinks/http/#max_size">max_size</a> for that buffer. The <code>memory</code> buffer is the default, which maximizes performance, but you can always choose <code>disk</code> if your use case requires stronger durability guarantees. As always, this can be configured on a per-sink basis.</li><li><strong>The adaptive concurrency algorithm itself</strong>. In general, you shouldn't need to adjust the algorithm, but in case you need to resort to that, there are three parameters available:<ul><li><code>decrease_ratio</code> ‚Äî This determines how rapidly Vector lowers the limit in response to failures or higher latency.</li><li><code>ewma_alpha</code> ‚Äî Vector uses an exponentially weighted moving average (EWMA) of past RTT measurements as a reference to compare with the current RTT. The <code>ewma_alpha</code> parameter determines how heavily new measurements are weighted compared to older ones.</li><li><code>rtt_threshold_ratio</code> ‚Äî The minimal change in RTT necessary for the algorithm to respond and adjust concurrency; changes below that threshold are ignored.</li></ul></li></ul><p>The defaults should work just fine for these parameters in most cases, but we know that some scenarios may call for a highly targeted approach.</p><h2>How we built it</h2><p>The development process behind ARC was highly methodical and data-driven. To summarize:</p><ul><li>Customer feedback has pinpointed concurrency management as a pain point since very early in the life of Vector.</li><li>The initial foray in addressing the problem came in <a href="https://github.com/timberio/vector/blob/master/rfcs/2020-04-06-1858-automatically-adjust-request-limits.md">RFC 1858</a>, which called for a qualitatively better option for users and <a href="https://github.com/timberio/vector/blob/master/rfcs/2020-04-06-1858-automatically-adjust-request-limits.md#prior-art">gestured toward</a> some possible inspirations.</li><li>Our engineers ultimately opted for a solution deeply inspired by analogous work on the Netflix engineering team, which is beautifully summarized in the <a href="https://medium.com/@NetflixTechBlog/performance-under-load-3e6fa9a60581">Performance Under Load</a> piece on their blog. Our respective approaches utilize an <a href="https://en.wikipedia.org/wiki/Additive_increase/multiplicative_decrease">additive-increase/multiplicative-decrease</a> (AIMD) algorithm inspired by TCP <a href="https://en.wikipedia.org/wiki/TCP_congestion_control">congestion control</a> algorithms. We'll have a lot more to say about this here on the blog next week. If you want to see the in-depth discussion that drove this process, see GitHub <a href="https://github.com/timberio/vector/issues/3255">issue #3255</a> on the Vector repo. There you'll see a pretty epic back and forth within our engineering team along with a slew of visualizations. It's quite the read.</li><li>As Netflix is largely a Java shop and there was nothing immediately usable "off the shelf" in the Rust ecosystem, we needed to create our own Rust implementation, which you can see in the <a href="https://github.com/timberio/vector/tree/master/src/sinks/util/adaptive_concurrency">adaptive_concurrency</a> module. Of special importance is the concurrency <a href="https://github.com/timberio/vector/blob/master/src/sinks/util/adaptive_concurrency/controller.rs#L23-L31">Controller</a>, which is responsible for the linear up/exponential down decision that I alluded to above.</li><li>For testing, the team mostly relied on our in-house <a href="https://github.com/timberio/http_test_server">http_test_server</a>, a pretty straightforward but highly customizable HTTP server written in Go.</li></ul><p>It took several months, some hefty PRs, and even a handful of <a href="https://github.com/timberio/vector/pull/3671">dead ends</a>, but we think that both the process and the end result are wholly consistent with the fastidious approach we strive for in building Vector.</p><h2>More to come</h2><p>Next week, we'll follow up on this announcement with a post from Timber's <a href="https://github.com/bruceg">Bruce Guenter</a>‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vector.dev/blog/adaptive-request-concurrency/">https://vector.dev/blog/adaptive-request-concurrency/</a></em></p>]]>
            </description>
            <link>https://vector.dev/blog/adaptive-request-concurrency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25346094</guid>
            <pubDate>Tue, 08 Dec 2020 15:06:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[StackHawk Launches Free Developer Plan for Application Security Testing]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25345114">thread link</a>) | @sevs
<br/>
December 8, 2020 | https://www.stackhawk.com/blog/free-plan-announcement/ | <a href="https://web.archive.org/web/*/https://www.stackhawk.com/blog/free-plan-announcement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="795a82f" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>Today we are excited to announce the launch of StackHawk‚Äôs free Developer Plan. With this launch, engineering teams or individual developers can take ownership of security in the development and delivery of their applications. Read on to learn a bit more about why we are so excited to launch this, or jump right in to <a href="https://auth.stackhawk.com/signup">sign up for a free account</a>.</p>



<h3 id="h-application-security-s-new-paradigm">Application Security‚Äôs New Paradigm</h3>



<p>It is no secret that the speed of application delivery has rapidly accelerated over the past decade. Most companies are pushing to production several times per week, or even multiple times per day. Originally, security struggled to keep up, with the dated models of quarterly penetration tests or manual scans by security teams clearly <a href="https://www.stackhawk.com/blog/application-security-is-broken/">no longer cutting it</a>.</p>



<p>These legacy models were predicated on finding vulnerabilities in production, often awhile after code had been deployed. This is at best, inefficient, and at worst a security issue. Once a vulnerability was found, it then had to navigate internal silos to actually get a fix released.</p>



<p>Modern engineering teams, however, have not only accelerated delivery speed, but have also improved security in the process. Here is how.</p>



<h4 id="h-find-vulnerabilities-with-ci-cd-automation">Find Vulnerabilities with CI/CD Automation</h4>



<p>Companies using modern approaches check for security vulnerabilities on every pull request (or even every commit) in the same way that they run unit tests and integration tests. With automated testing in CI/CD, developers can catch vulnerabilities early in the software development lifecycle, and fix issues while they are still in the context of the code.</p>



<p>After an initial triage of any existing security bugs, application security tooling should at least be configured to break the build if any new high criticality vulnerabilities are identified. This doesn‚Äôt mean that every vulnerability should prevent a deploy to production, but that deploy should be done eyes wide open to the risk it presents.</p>



<h4 id="h-triage-and-initial-risk-decisions-live-with-developers">Triage and Initial Risk Decisions Live with Developers</h4>



<p>When a vulnerability is found, the developer(s) who were recently working on the application are best equipped to review the finding and make risk-based decisions. Should this block the deploy to production? Can this be added to a backlog and addressed later? Is this low enough risk that it isn‚Äôt worth fixing?</p>



<p>The individuals who are intimately involved in creating the application are best equipped as the first-line of defense for these decisions. Internal security teams are undoubtedly called upon for clarification and support (‚Ä¶and are often reviewing historical decisions as well), but modern teams are empowering developers to make these triage decisions themselves.</p>



<h4 id="h-fast-developer-fixes">Fast Developer Fixes</h4>



<p>When a security bug requires a fix, the responsibility for the fix squarely lives with the developer who introduced the vulnerability in modern teams. This individual is in the codebase, familiar with the context of the recent vulnerability addition. Not only are they best equipped to implement the fix, but by democratizing this responsibility across the team, no person or team bears the burden of interrupt driven work.</p>



<h3 id="h-taking-ownership-of-application-security">Taking Ownership of Application Security</h3>



<p>Ever since we embarked upon building StackHawk, we have been laser focused on building a tool for developers. The market is rife with security tools built for the CISO that no developer wants to use, and these tools typically start at six-figure contracts. StackHawk is different, and we are excited to equip engineers to own the security of their application. This shows up in our product, and with our new free Developer Plan, it also shows up in our pricing.</p>



<p>Now individuals or teams can start running application security tests against their first application for free. There is no longer an excuse not to be looking at the security of your application.&nbsp;</p>



<p>Getting started with StackHawk is easy, with most developers completing their first security test in under 20 minutes. You can get the full details in <a href="https://docs.stackhawk.com/">our docs</a>, but in short it is as simple as building a yaml config, pointing the scanner at your application, and taking a look at the results.&nbsp;<br><a href="https://auth.stackhawk.com/signup">Sign up</a> for a free account and give it a try today!</p>
		</div>
				</div></div>]]>
            </description>
            <link>https://www.stackhawk.com/blog/free-plan-announcement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25345114</guid>
            <pubDate>Tue, 08 Dec 2020 13:59:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rethinking Social Media]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25344928">thread link</a>) | @dubeyaayush07
<br/>
December 8, 2020 | https://dubeyaayush07.github.io/deliberate-mistakes/rethinking-social-media/ | <a href="https://web.archive.org/web/*/https://dubeyaayush07.github.io/deliberate-mistakes/rethinking-social-media/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p>December 05, 2020</p></header><section itemprop="articleBody"><h2>Introduction</h2>
<p>The harmful effects of the algorithms employed by social networking platforms like Twitter and Facebook has been well documented: polarisation, privacy issues, you name it. Even though I share a lot of these concerns between all the petty tribalism there is potential for having deep and meaningful conversations too. But I do not think it is possible to improve existing social networks, as even though these networks are not inherently evil they are a result of a bad business model. Their main objective is maximising user engagement the more time you spend glued to your screen the better. With this model at the core it is hard for these companies to implement change. In certain cases taking initiatives for improving the mental well being of users or for promoting productive discourse might be impractical too. The quality of the experience is secondary to the screen time.</p>
<p>The solution in my opinion is to build networks with strong core values that promote productive conversations. Start with a small community with a solid foundation then gradually expand keeping the values intact. What would such a network look like? Well like anything great it will have to take what is good about its predecessors and improve on their shortcomings. The improvements should be significant so as to provide a reason for people to actually switch. But improvements is a vague term to see how social networks can be improved I think it is better to analyse and think about the components that make up these networks from first principles.</p>
<h2>Moderation</h2>
<p>If we have learned anything from <a href="https://www.pbs.org/newshour/nation/right-wing-users-flock-to-parler-as-social-media-giants-rein-in-misinformation">Parler</a> it is that sometimes it becomes necessary to infringe upon people‚Äôs free speech rights especially when these privileges come at the cost of civilised discourse. Still banning people is a slippery slope for example if you ban a terrorist account then what do you do when China asks you to ban accounts of Hong Kong protesters? You have given them the precedent. I think the solution is to have strict moderation but with strong foundational principles and make them clear early on. A good strategy is to only censor people if they are disrespecting other people not when they are expressing their opinions or ideas. Even if you think that the earth is not flat you should let other people talk it out if they are being civil about it.</p>
<p>If you look at communities like <a href="https://news.ycombinator.com/">Hacker News</a>, <a href="https://stackoverflow.com/">Stack Overflow</a>, or the <a href="https://www.reddit.com/r/AskHistorians/">Ask Historians subreddit</a> where the moderators rule with an iron hand you can notice that the posts and comments in these forums are of much higher quality. But still it is anecdotal evidence and these communities are small when you compare them to giants like Facebook and Twitter. Also how would you moderate millions of post? Even if it was possible for human to do it can you rely on them to look at these posts objectively and report them only if they violate the guidelines? I believe if you start a community with strong core values it is possible to motivate people with a little bit of algorithm ingenuity to act in good faith.</p>
<h2>Feed</h2>
<p>Feeds and Algorithms are inextricably linked, feeds serve content curated by algorithms. Feeds can be finite or infinite providing an endless stream of posts and the algorithms used by these can range from simple algorithms that serve posts in chronological order to relatively complex machine learning based recommender systems. Most of the big platforms nowadays use recommender systems coupled with infinite feeds. It can get really messy if a single feed is used to serve both recommended content and the content that the user is subscribed to. YouTube is a good example of this even though they have great recommendations the content that the user has actually subscribed to gets lost in the feed of recommended videos. You might argue that they have a different feed for subscriptions but its not the one they show first when the user enters their app/website and that is the one that actually counts.</p>
<p>For our ideal social network I think it will be better to use two different feed one main finite feed solely for the subscribed/followed content and one infinite feed that recommends content based on the the interests of the user. For the subscription feed I do not think a purely chronological algorithm will work as a post about an important event like a friend‚Äôs birthday might get trapped between relatively trivial posts but between the posts of similar importance chronological information can be taken into account. A more complex algorithm will be required for the recommendation feed I will talk about it more in the monetisation section. The goal of the feeds should be to maximise signal from noise and not waste the time of its users.</p>
<h2>Monetisation</h2>
<p>Advertising is a bad and unsustainable business model for social networks, if your main source of revenue are advertisements you will be incentivised to increase user engagement and sometimes even at the cost of the actual experience. The best business model for social networks I think is the Wikipedia model. Ask people who can afford to to pay a nominal subscription to keep the servers running. The success of the company will actually depend how happy its users are with the platform.</p>
<p>You might have noticed that I have used vague terms like ‚Äòalgorithmic ingenuity‚Äô and statements like ‚Äòbuild a system that recommends people posts based on their interests‚Äô without mentioning the specifics of the algorithm that is because I do not know and when it comes to moderation algorithms neither does Twitter. Learning based algorithms are not completely transparent and it is difficult to predict what they are going to do and it becomes even more difficult to come up with good algorithms when the goals of the networks are misaligned with the public good. What my argument is that in social networks that do not depend on advertising money engineers will be actually motivated to come up with better algorithms for moderation and recommendation.</p>
<h2>Interface and Posts</h2>
<p>The whole social network revolves around posts these are the primary content that people use to interact with their subscribers/followers. For Twitter these are limited length messages, for Quora these are questions, for Instagram images, for YouTube videos, etc. The format of these posts is important. They can be designed such that people come up with clever ways to use them (example tweets) and they can also be designed in a more restrictive way such that people struggle to get across what they mean (example tweets).</p>
<p>The ideal post in my opinion is a mixture of these two we could allow people to post both a restricted length post and a full fledged article but nothing in between this leaves space for creativity and does not hamper conversation. An option could be given to the users to sort their feed by articles, shorter posts or both. And instead of like and dislike buttons we can use recommend and not recommend buttons the functions might be same but change in name might help people make conscious decision about whether they want similar content recommended to them or not.</p>
<p>Another way we can improve conversations I think is by giving people a small break between writing a post and actually posting it. This might seem counter-intuitive but I think if given a chance to reflect on things people generally take right decisions and it can also give them time to calm down so that they do not engage in pointless name calling. We can implement it by an optional 15 seconds timer which is enabled by default.</p>
<h2>Conclusion</h2>
<p>The goal of the post is to start a conversation about what an ideal social network might look like. But these are just abstract ideas and musings there is no evidence a social networks like this will be successful but instead of conjecturing about whether things will work or not it is better to try to implement it and see for yourself. In that spirit I am going to try to implement a social network based on these principles. But I am a lone programmer and I need help if some part of my post resonated with you and you think that implementing such a network is worth a try contact me at <a href="mailto:dubeyaayush08@gmail.com">dubeyaayush08@gmail.com</a> and maybe we could team up.</p></section><hr></article></div>]]>
            </description>
            <link>https://dubeyaayush07.github.io/deliberate-mistakes/rethinking-social-media/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25344928</guid>
            <pubDate>Tue, 08 Dec 2020 13:46:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your Network Increases Optionality]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25344916">thread link</a>) | @mooreds
<br/>
December 8, 2020 | https://letterstoanewdeveloper.com/2020/12/07/your-network-increases-optionality/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/12/07/your-network-increases-optionality/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><em>This is a guest post from Karl Hughes. Enjoy.</em></p>



<p>Dear new developer,</p>



<p>I was in your shoes in 2011. I was finishing up a degree in mechanical engineering that I would never use and looking for a way to join a startup as a software developer.</p>



<p>Maybe it was the entrepreneur in me, and maybe it was just naivety, but instead of applying for jobs, I decided to start emailing interesting companies instead. I made a list of technology startups in the education industry and emailed each of them my pitch.</p>



<p>Two of them got back to me and one (<a href="https://www.uloop.com/">Uloop</a>) had an office three hours away in Nashville. I drove to meet their CEO and after a few conversations, they brought me on as a freelancer. When I graduated a few months later, they offered me a full-time role managing their blog and writing custom WordPress plugins.</p>



<p>Since then, I‚Äôve worked at three different edtech startups and never once had a formal ‚Äújob interview.‚Äù Every company I‚Äôve worked for has hired me because I met someone there and stayed in touch for months. When a job opened up, they reached out to me to see if I was interested.</p>



<p>My first job hunt showed me that your strength as a software developer is not in your resume, your knowledge of algorithms, your ability to keep up with the hottest frameworks, or even your problem-solving skills. <strong>The most powerful tool you have is your network.</strong></p>



<h2>The Employer‚Äôs Perspective</h2>



<p>As a job-seeker, you know that looking for a job is scary, but from an employer‚Äôs perspective, hiring is scary too.</p>



<p>After sitting in the hiring manager‚Äôs seat several times in the past few years, I can tell you that I‚Äôm as scared of hiring the wrong person as you are of screwing up the job interview. If I make a bad hire, I look bad to my boss, and my team‚Äôs productivity will suffer. Having to fire someone kills morale and hurts the manager‚Äôs reputation, so nobody wants to do it.</p>



<p>This fear is why managers look for people in their networks or work with recruiters. <strong>The very last place employers look for applicants is the cold resume bin.</strong></p>



<h2>How I Built My Network</h2>



<p>If you want to avoid the black hole of submitting your resume online, you need to build a network. I don‚Äôt know you well enough to give you a perfect formula for your situation, so I‚Äôll just tell you how I built my network. I hope some of these ideas resonate.</p>



<p>First, I started as a freelancer before I ever had a ‚Äúreal‚Äù job as a programmer. Most people don‚Äôt recommend this approach for new developers, but it forced me to learn to ‚Äúsell‚Äù myself really well. When I started with Uloop, I often had no idea how to accomplish a task, but I bet that I could learn it before they discovered I was making it up.</p>



<p>After getting that first job, I started attending meetups and conferences regularly. Uloop was a small company, so there wasn‚Äôt much opportunity to network within the organization, but I had moved to Chicago, where there were plenty of programming meetups and tech events to attend.</p>



<p>I tried meeting people at these events, but it was hard. I‚Äôm not that outgoing, so instead, I would email the event‚Äôs speaker or organizer afterward and invite them to a one-on-one coffee or lunch. Some of the people I met like this are among my closest mentors and friends today.</p>



<p>As I attended more meetups and got to know speakers and leaders, people started inviting me to give back. I was little more than a junior developer at the time, but I was asked to speak at bootcamps, meetups, and even a couple of small conferences because of my network.</p>



<p>Naturally, I was nervous the first few times I got up in front of a group to share my experience. I knew there were people in the crowd with decades of experience on me, and I expected them to stand up and call me out if I made any mistakes. I found that practice and gradually increasing the stakes helped me. By trying a talk out at a local meetup and slowly working up to larger audiences at a conference, I gained confidence over time.</p>



<p>Giving a talk at a meetup or conference is a lot of work, and you don‚Äôt typically get paid for it. That said, I knew how helpful it was hearing developers who were more experienced than me back when I was first learning to code, so I have always enjoyed the opportunity to give back.</p>



<p>One side effect of speaking is that you get even more opportunities to increase your network. At some point, I switched from being the one asking speakers to meet with me to the one that attendees were asking to speak with. I always enjoy these interactions with new developers, and the opportunity to encourage or help others is my primary motivation for speaking and writing this letter.</p>



<h2>Keeping in Touch</h2>



<p>Everyone who talks about networking tells you to go out and meet more people, but that‚Äôs <a href="https://www.karllhughes.com/posts/the-key-to-networking-keeping-in-touch">worthless if you don‚Äôt keep in touch with anyone</a>. As I started to meet more people in Chicago, I realized that I needed to come up with a way to have more encounters with each of them.</p>



<blockquote><p>‚ÄúIt takes on average about 3 encounters ‚Äî and by that I mean intentional rather than passing interactions where you‚Äôve gotten together primarily to just hang out ‚Äî to really see if there‚Äôs potential for a relationship with someone.‚Äù ‚Äì <a href="https://www.artofmanliness.com/articles/the-3-encounter-rule/">Brett McKay</a></p></blockquote>



<p>The first step was to start a spreadsheet of people I wanted to keep up with. Most of them were more experienced than me, but many were peers or newer developers I ‚Äúclicked‚Äù with or found interesting.</p>



<p>Next, I made a reminder to reach out to 1-2 people on the list every week. I‚Äôd ask how they were doing and see if they wanted to get lunch or coffee sometime. I tried to find organic reasons to connect (birthdays, an article related to their industry, etc.) and ask them questions about their lives. One of the easiest ways to make someone like you is to get them talking about something they like. <a href="https://www.psychologytoday.com/us/blog/positive-prescription/201703/why-we-love-talking-about-ourselves">People love talking about themselves</a>.</p>



<p>While this sounds calculated, I do genuinely enjoy these conversations. We‚Äôre all busy, but having a system like this ensures that I don‚Äôt forget to maintain my network. If I ever feel like I‚Äôm no longer getting along with someone, I remove them from my list and no harm is done.</p>



<p>The reason most people don‚Äôt do this is that it takes a lot of time. I still spend 4-6 hours per week keeping in touch with or expanding my network. It may seem like a lot, but the investment has paid dividends and afforded me many interesting conversations and relationships along the way. This strategy of intentionally staying in touch with people has led to friendships, co-workers, job offers, and clients.</p>



<h2>Make It Yours</h2>



<p>No career advice will work for everyone.</p>



<p>I didn‚Äôt write this letter to give you a formula for networking, but rather to let you know that unconventional approaches can work. My network has been an invaluable asset, but luck and privilege played a huge part too.</p>



<p>If I hadn‚Äôt been able to drive three hours to take a meeting with my future boss, would he have hired me? If I needed to be home after work to help care for a family member, would I have been able to network at Meetups? If I weren‚Äôt a white male in an industry dominated by white males, would people have taken the time to meet with me?</p>



<p>I don‚Äôt know.</p>



<p>I have no idea what your career path will look like, but I hope my story gives you the courage to build a path that works for you.</p>



<p>Signed,<br><a href="https://twitter.com/KarlLHughes">Karl</a></p>



<p><em>Karl is a former CTO and freelance writer. He‚Äôs currently the founder of <a href="https://draft.dev/">Draft.dev</a> where he helps companies create content that reaches software developers.</em></p>
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/12/07/your-network-increases-optionality/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25344916</guid>
            <pubDate>Tue, 08 Dec 2020 13:46:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Qt 6.0]]>
            </title>
            <description>
<![CDATA[
Score 444 | Comments 355 (<a href="https://news.ycombinator.com/item?id=25344826">thread link</a>) | @milliams
<br/>
December 8, 2020 | https://www.qt.io/blog/qt-6.0-released | <a href="https://web.archive.org/web/*/https://www.qt.io/blog/qt-6.0-released">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            

                            <p>
                                Tuesday December 08, 2020 by <a href="https://www.qt.io/blog/author/lars-knoll">Lars Knoll</a> | <a href="#commento">Comments</a>
                            </p>
                            
                            <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><span>I am really excited to announce today‚Äôs release of Qt 6.0. It is the first release of a new major version, and marks a major milestone for Qt. </span><strong><em>We started working on the initial ideas a few years ago, and since then, have put a massive effort into creating the next generation of Qt. </em></strong></p>
<!--more-->
<p><a href="https://www.qt.io/product/qt6/" rel="noopener" target="_blank"><span><img src="https://www.qt.io/hubfs/Qt%206%20email%20launch%20hero%201-png-1.png" alt="Qt 6"></span></a></p>

<p><span>Qt 5 has been a fantastic success over the years, and we have seen an enormous growth of our user base and Qt usage over eight years since we released Qt 5.0. But the world&nbsp; has undergone significant changes since 2012. Qt usage in embedded systems has skyrocketed, C++ has evolved, and new 3D graphics APIs have emerged. These are examples of factors that have directly affected Qt.</span></p>
<p><span>As a cross-platform framework, Qt needs to adjust to those changing requirements. We have managed to adapt very well to many of those requirements during the lifetime of Qt 5. However, maintaining full source and binary compatibility within the Qt 5 series made certain things impossible to fix within its lifetime. With Qt 6, we now have the opportunity to make changes and build Qt to be better suited for the years to come.</span><span></span></p>
<div>
<p>Thus, the mission of Qt 6 is to enable Qt to be the productivity platform for the future. Qt 6.0, as a major release of Qt, gave us a higher degree of freedom to implement new features, functionality, and better support today and tomorrow's requirements. Qt 6.0 is a continuation of the Qt 5 series, and we have focused on making migration non-disruptive for users. I published a <a href="https://www.qt.io/blog/2019/08/07/technical-vision-qt-6" rel="noopener">Qt 6 vision blog post</a> capturing those ideas around 18 months ago.</p>
<p>When creating Qt 6, we ensured that Qt‚Äôs core values have been adhered to and upheld, including:</p>
<ul>
<li>Its cross-platform nature, allowing users to deploy their applications to all desktop, mobile, and embedded platforms using one technology and from a single codebase</li>
<li>Its scalability from low-end, single-purpose devices to high-end complex desktop applications or connected system</li>
<li>Its world-class APIs and tools and <a href="https://doc.qt.io/" rel="noopener">documentation</a>, simplifying the creation of applications and devices</li>
<li>Its maintainability, stability, and compatibility, allowing users to maintain large codebases with minimal effort</li>
<li>Its large developer ecosystem with more than 1.5 million users</li>
</ul>
<p>Qt 6.0 is the first release of the Qt 6 series addressing new market demands while keeping the core values at the heart of what we do.</p>
<p>When developing Qt 6, we had an in-depth look at some of Qt's most central parts to identify how we could improve them. We discovered a couple of core focus areas that we invested considerable time in improving. Those areas include:</p>
<div>
<ul>
<li>Leveraging C++17</li>
<li>Next generation QML</li>
<li>New graphics architecture</li>
<li>Unified 2D and 3D for Qt Quick</li>
<li>CMake build system (with qmake still supported for applications)</li>
</ul>
</div>
<p>We have of course also spent time doing numerous improvements in other areas, too many to mention them all here, and I suggest you look at the more detailed <span><span><a href="https://wiki.qt.io/New_Features_in_Qt_6.0" rel="noopener">wiki page</a>. We are also hosting Meet Qt 6.0 webinar sessions covering the <a href="https://www.qt.io/events/meet-qt-6-1607340244" rel="noopener">Americas/EMEIA</a> and <a href="https://www.qt.io/events/meet-qt-6-1607339968" rel="noopener">EMEIA/APAC</a> time zones. But let's take a look at some of the highlights.</span></span></p>
</div>
<h3><span>C++17</span></h3>
<p><span><img src="https://www.qt.io/hs-fs/hubfs/cpp_logo-png.png?width=168&amp;name=cpp_logo-png.png" width="168" alt="C++ 17 in Qt 6" srcset="https://www.qt.io/hs-fs/hubfs/cpp_logo-png.png?width=84&amp;name=cpp_logo-png.png 84w, https://www.qt.io/hs-fs/hubfs/cpp_logo-png.png?width=168&amp;name=cpp_logo-png.png 168w, https://www.qt.io/hs-fs/hubfs/cpp_logo-png.png?width=252&amp;name=cpp_logo-png.png 252w, https://www.qt.io/hs-fs/hubfs/cpp_logo-png.png?width=336&amp;name=cpp_logo-png.png 336w, https://www.qt.io/hs-fs/hubfs/cpp_logo-png.png?width=420&amp;name=cpp_logo-png.png 420w, https://www.qt.io/hs-fs/hubfs/cpp_logo-png.png?width=504&amp;name=cpp_logo-png.png 504w" sizes="(max-width: 168px) 100vw, 168px"></span></p>
<p><span>With Qt 6 we now require a C++17 compatible compiler enabling the use more modern C++ language constructs when developing Qt and also allows for integration points on the API side.</span></p>
<h3><span>Core libraries and APIs</span></h3>
<p><span>Much work has gone into Qt Core, as it is the module that implements the most central parts of Qt. We've gone through many areas there and made improvements. To name some of the most central ones:</span></p>
<ul>
<li><span>The new <a href="https://www.qt.io/blog/property-bindings-in-qt-6" rel="noopener">property and binding system</a>: This system now brings the concept of bindings that made QML such a huge success in Qt 5 available from C++. </span></li>
<li><span>Strings and Unicode: With Qt 5, we started aligning Qt fully with Unicode, where we completed a lot of the work, but a few items remained that we now cleaned up for Qt 6. More details will come in a separate blog post later on.</span></li>
<li><span>QList has been a class that was often criticized in Qt 5, as it was heap allocating objects stored in there that were larger than a pointer, leading to pressure on heap allocation methods. In Qt 6, we changed this and unified QList and QVector into one class. See our <a href="https://www.qt.io/blog/qlist-changes-in-qt-6" rel="noopener">blog post about QList</a> in Qt 6 for details.</span></li>
<li><span>QMetaType and QVariant are fundamental to how our Qt‚Äôs meta-object system works. Signals and slots would not be possible without QMetaType and QVariant is required for dynamic invocations. Those two classes got an almost complete rewrite with Qt 6, and you can read about the details <a href="https://www.qt.io/blog/whats-new-in-qmetatype-qvariant" rel="noopener">here</a>.</span></li>
</ul>
<p><span>Other parts of Qt that are not related to graphics have also seen large changes. For example, Qt Concurrent has undergone an almost complete rewrite and now makes development of multi-threaded applications more effortless than ever. Qt Network has seen lots of clean-up and improvements. See this <a href="https://www.qt.io/blog/qt-network-in-qt-6" rel="noopener">blog post</a> for details.</span></p>
<h3><span>New graphics architecture</span><span>&nbsp;</span><span></span></h3>
<p><span>The graphics architecture of Qt 5 was very much dependent on OpenGL as the underlying 3D graphics API. While this was the right approach in 2012 when we created Qt 5, the market around us has changed significantly over the last couple of years with the introduction of Metal and Vulkan. We now have a large set of different graphics APIs that are commonly being used on different platforms. For Qt as a cross-platform framework, this, of course, meant that we had to adjust to this and ensure our users can run Qt on all of them with </span>maximum performance.</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/image-png-Nov-03-2020-07-47-23-41-AM-png-2.png?width=367&amp;name=image-png-Nov-03-2020-07-47-23-41-AM-png-2.png" width="367" alt="New graphics architecture in Qt 6" srcset="https://www.qt.io/hs-fs/hubfs/image-png-Nov-03-2020-07-47-23-41-AM-png-2.png?width=184&amp;name=image-png-Nov-03-2020-07-47-23-41-AM-png-2.png 184w, https://www.qt.io/hs-fs/hubfs/image-png-Nov-03-2020-07-47-23-41-AM-png-2.png?width=367&amp;name=image-png-Nov-03-2020-07-47-23-41-AM-png-2.png 367w, https://www.qt.io/hs-fs/hubfs/image-png-Nov-03-2020-07-47-23-41-AM-png-2.png?width=551&amp;name=image-png-Nov-03-2020-07-47-23-41-AM-png-2.png 551w, https://www.qt.io/hs-fs/hubfs/image-png-Nov-03-2020-07-47-23-41-AM-png-2.png?width=734&amp;name=image-png-Nov-03-2020-07-47-23-41-AM-png-2.png 734w, https://www.qt.io/hs-fs/hubfs/image-png-Nov-03-2020-07-47-23-41-AM-png-2.png?width=918&amp;name=image-png-Nov-03-2020-07-47-23-41-AM-png-2.png 918w, https://www.qt.io/hs-fs/hubfs/image-png-Nov-03-2020-07-47-23-41-AM-png-2.png?width=1101&amp;name=image-png-Nov-03-2020-07-47-23-41-AM-png-2.png 1101w" sizes="(max-width: 367px) 100vw, 367px"></p>
<p><span>So while Qt 5 relied on OpenGL for hardware-accelerated graphics, the picture completely changes with Qt 6. All of our 3D graphics in Qt Quick is now built on top of a new abstraction layer for 3D graphics called RHI (Rendering Hardware Interface). RHI makes it possible for Qt to use the native 3D graphics API of the underlying OS/platform. So Qt Quick will now use Direct3D on Windows and Metal on macOS by default. For details, have a look at the <a href="https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d" rel="noopener">blog post series about the RHI</a>.</span><span>&nbsp;</span></p>
<p><span>The OpenGL specific classes in Qt still exist, but are now moved out of QtGui in the <a href="https://doc.qt.io/qt-6/qtopengl-index.html" rel="noopener">QtOpenGL</a> module. We also added a new module called <a href="https://doc.qt.io/qt-6/qtshadertools-index.html" rel="noopener">QtShaderTools</a> to deal with the different shading languages of those APIs in a cross-platform way.</span></p>
<h3><span>Qt Quick 3D and Qt 3D</span></h3>
<p><span>Qt Quick 3D is a relatively new module. It seamlessly extends Qt Quick with 3D capabilities. With Qt Quick 3D, our focus was to create an API that is as easy to use as the existing parts of Qt Quick (for 2D user interfaces) while providing full support for creating complex 3D scenes. The main goal behind this effort has been to enable seamless integration between 2D and 3D content.</span><span></span></p>
<p><span>This module has seen significant improvements with Qt 6 that we wouldn‚Äôt have been able to do in the Qt 5 series. Most importantly it is now always using the RHI abstraction layer to make optimal use of the underlying graphics API and Hardware. Additionally, it now features a much deeper and more performant integration between 2D and 3D content, allowing you to place 2D items into a 3D scene. It also has vastly improved support for glTF2 and physics-based rendering, making it trivial to import assets created in other design tools. There are many other major improvements in the module, a more in-depth description can be found in a <a href="https://www.qt.io/blog/what-is-new-in-qt-quick-3d-6.0" rel="noopener">separate blog post</a>.</span></p>
<p><span>Qt 3D is now also based on top of the RHI abstraction layer, has seen some performance improvements and cleanups. You can find more details in two blog posts by our partner KDAB (<a href="https://www.kdab.com/qt-3d-changes-in-qt-6/" rel="noopener">here</a> and <a href="https://www.kdab.com/qt3d-renderer-qt6/" rel="noopener">here</a>).</span></p>
<h3><span>Desktop styling for Qt Quick</span></h3>
<p><span><img src="https://www.qt.io/hubfs/Qt%206%20Desktop%20Styling-png.png" alt="Desktop Styling in Qt 6"></span></p>
<p><span>When we created the set of controls for Qt Quick, our focus was to make them lightweight and performant. For that reason, they did not support desktop styling in Qt 5. However, in Qt 6, we found a way to make them look &amp; feel native on desktop operating systems. With 6.0, Qt Quick now supports native styling on both macOS and Windows. See this <a href="https://www.qt.io/blog/desktop-styling-with-qt-quick-controls" rel="noopener">blog post for details</a>.</span><span> Native look &amp; feel for Android and Linux already existed with the Material and Fusion styles in Qt 5. We are improving those for future Qt releases and are also planning to implement a native style for iOS.</span></p>
<h3><span>Interfacing with platform specific functionality</span></h3>
<p><span>Even with Qt offering most functionality required to develop your application platform-independently, there is sometimes a need to interface with platform-specific functionality. In Qt 5, we provided a set of add-on modules (QtX11Extras, QtWinExtras, QtMacExtras) to help with this purpose. But this full separation from the rest of Qt has led to a couple of architectural issues, inconsistencies and code duplication within Qt. In Qt 6, we made an effort to clean this up and fold the functionality offered by those add-on modules into platform specific APIs offered directly in Qt. This will make interfacing with OS/platform-specific APIs much easier in Qt 6. Have a look <a href="https://www.qt.io/blog/platform-apis-in-qt-6" rel="noopener">here</a>&nbsp;for more details.</span></p>
<h3><span>Build system and&nbsp;</span><span>Packaging</span></h3>
<p><span><img src="https://www.qt.io/hs-fs/hubfs/600px-Cmake-svg-png.png?width=189&amp;name=600px-Cmake-svg-png.png" width="189" srcset="https://www.qt.io/hs-fs/hubfs/600px-Cmake-svg-png.png?width=95&amp;name=600px-Cmake-svg-png.png 95w, https://www.qt.io/hs-fs/hubfs/600px-Cmake-svg-png.png?width=189&amp;name=600px-Cmake-svg-png.png 189w, https://www.qt.io/hs-fs/hubfs/600px-Cmake-svg-png.png?width=284&amp;name=600px-Cmake-svg-png.png 284w, https://www.qt.io/hs-fs/hubfs/600px-Cmake-svg-png.png?width=378&amp;name=600px-Cmake-svg-png.png 378w, https://www.qt.io/hs-fs/hubfs/600px-Cmake-svg-png.png?width=473&amp;name=600px-Cmake-svg-png.png 473w, https://www.qt.io/hs-fs/hubfs/600px-Cmake-svg-png.png?width=567&amp;name=600px-Cmake-svg-png.png 567w" sizes="(max-width: 189px) 100vw, 189px"></span></p>
<p><span>We also made some considerable changes in how we build and distribute Qt.&nbsp; Worth mentioning is that Qt 6 itself is now <a href="https://www.qt.io/blog/qt-6-build-system" rel="noopener">built using CMake</a>. This has also led to significant improvements for all our users that use CMake to build their projects. We will continue to support qmake for the lifetime of Qt 6, so there is no need to make any changes to your build system if you're using it, but we recommend to use CMake for all new projects.</span></p>
<p><span>Qt 6 also comes with a much smaller default package, and many of the add-ons are now distributed as separate packages through a package manager. This gives us more flexibility in adapting release schedules of add-ons to market requirements, allowing, for example, for more frequent feature releases as the core Qt packages or making them available for multiple Qt versions at the same time. In addition, we can use the package manager as a delivery channel for 3rd party content. And finally, it gives our users more flexibility as they can choose to download only what they really need. </span></p>
<p><span>Currently, we are using the existing Qt ‚Ä¶</span></p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.qt.io/blog/qt-6.0-released">https://www.qt.io/blog/qt-6.0-released</a></em></p>]]>
            </description>
            <link>https://www.qt.io/blog/qt-6.0-released</link>
            <guid isPermaLink="false">hacker-news-small-sites-25344826</guid>
            <pubDate>Tue, 08 Dec 2020 13:39:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dataform (YC W18) is joining Google Cloud]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25344703">thread link</a>) | @oliver101
<br/>
December 8, 2020 | https://dataform.co/blog/dataform-is-joining-google-cloud | <a href="https://web.archive.org/web/*/https://dataform.co/blog/dataform-is-joining-google-cloud">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Today we're excited to announce that we've joined Google Cloud. Over the course of the past several months, our partnership with Google Cloud has deepened and we believe that our new combined efforts can make our customers and partners even more successful.</p><div><div><p>To our customers, users, supporters and contributors - today, we are extremely excited to share that Dataform is joining Google Cloud!</p>
<p>Before we jump into the story, let us quickly answer what we think will be the most important questions for existing and new users:</p>
<ul>
<li>Dataform Web will continue to be run and maintained by us, as part of Google Cloud.</li>
<li>Dataform Web will be free for all new users as of today, December 8th 2020.</li>
<li>Existing customers will be transitioned onto the free plan immediately.</li>
<li>Dataform Web will focus on support for BigQuery going forward.</li>
<li>We√¢‚Ç¨‚Ñ¢ll be working closely with the rest of the Google Cloud Data Analytics team over the next year to deliver our vision for Dataform within Google Cloud.</li>
</ul>
<p>Three years ago we started Dataform with a mission to <strong>empower analysts to manage the entire flow of data in the warehouse, using a single, unified workflow</strong>. Throughout our journey we√¢‚Ç¨‚Ñ¢ve been focused on giving data analysts and data engineers the tools they need to take raw, messy data, transform it, and put it into the hands of their organization. We√¢‚Ç¨‚Ñ¢ve only just scratched the surface of this problem and solving it will continue to be our core mission and focus going forward.</p>
<p>We√¢‚Ç¨‚Ñ¢ve followed Google√¢‚Ç¨‚Ñ¢s products and successes within analytics closely over the past few years, and always felt that they were a product leader when it came to cloud data warehousing, SQL, and now business intelligence; with products such as Looker that inspired us significantly in our own journey. After several conversations with the Google Cloud team it became clear that we are deeply aligned on the importance of serving analysts with the right tools and technology in order to fill what we all perceive as a missed opportunity in existing solutions.</p>
<p>At the same time, as a team of just 7, in a complex, competitive and rapidly changing market, we had more ideas than we had people or resources to accomplish. There has always been so much more we wanted to do each quarter than we could achieve. With the support of the BigQuery and Cloud Analytics teams and our combined thought leadership and efforts, we felt that together we could achieve something bigger than we could separately.</p>
<p>There will inevitably be some changes to the product and how we operate over the coming years, but one thing that will not change is our commitment to the principles that we feel have gotten us this far: working closely with our customers, making sure we continue to collect and act upon your feedback, and a laser focus on doing one thing and doing it well.</p>
<p>At Dataform we always felt we were delivering a unique and innovative product to our customers and the data community. With Google√¢‚Ç¨‚Ñ¢s support, we have even more confidence in our ability to build and deliver a product that can truly change the way that all companies, large and small, work with data. </p>
<p>In the coming months we√¢‚Ç¨‚Ñ¢ll be able to share more details of our product roadmap. In the meantime please reach out to us if you have any questions. Thank you again for joining us on this journey. We√¢‚Ç¨‚Ñ¢re uncomfortably excited about what we can accomplish together over the coming years!</p>
<p>Guillaume-Henri Huon &amp; Lewis Hemens, co-founders of Dataform</p></div></div></div>]]>
            </description>
            <link>https://dataform.co/blog/dataform-is-joining-google-cloud</link>
            <guid isPermaLink="false">hacker-news-small-sites-25344703</guid>
            <pubDate>Tue, 08 Dec 2020 13:24:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are people with dark personality traits more likely to succeed?]]>
            </title>
            <description>
<![CDATA[
Score 213 | Comments 206 (<a href="https://news.ycombinator.com/item?id=25344640">thread link</a>) | @known
<br/>
December 8, 2020 | https://psyche.co/ideas/are-people-with-dark-personality-traits-more-likely-to-succeed | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/are-people-with-dark-personality-traits-more-likely-to-succeed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>√¢‚Ç¨ÀúDark√¢‚Ç¨‚Ñ¢ personalities come in</strong> various shades, but at the core of all of them is a tendency to callously use others for personal gain. What is it that these types of people are really gaining, though? Might a benevolent approach to life and others be even more advantageous?</p>
<p>For <span>15 years,</span> research into dark personality traits (including narcissism, psychopathy and Machiavellianism) has been rapidly <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/spc3.12018" rel="nofollow noreferrer noopener">expanding</a>. We now know that these traits are far more <a href="https://europepmc.org/article/med/32484407" rel="nofollow noreferrer noopener">evident</a>, on average, in men than women. We know that <a href="https://pubmed.ncbi.nlm.nih.gov/19243821/" rel="nofollow noreferrer noopener">approximately</a> <a href="https://psycnet.apa.org/record/2008-13625-018" rel="nofollow noreferrer noopener"><span>1-2 per cent</span></a> of individuals in the general population display extremely dark personality features √¢‚Ç¨‚Äú enough to meet the clinical threshold for a personality disorder √¢‚Ç¨‚Äú and about <span>10-20 per</span> cent of individuals <a href="https://pubmed.ncbi.nlm.nih.gov/22996170/" rel="nofollow noreferrer noopener">have</a> moderately elevated levels. We know that even people with moderate levels of dark traits can wreak havoc: they are more likely to <a href="https://journals.sagepub.com/doi/10.1177/1745691616666070" rel="nofollow noreferrer noopener">lie and cheat</a>, show <a href="https://www.sciencedirect.com/science/article/pii/S0191886920305468" rel="nofollow noreferrer noopener">racist</a> attitudes, and be <a href="https://psycnet.apa.org/record/2014-04417-005" rel="nofollow noreferrer noopener">violent</a> towards others.</p>
<p>As researchers, we have studied these traits ourselves. But in a bid to balance out the extensive literature on dark traits, we have recently started to <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00467/full" rel="nofollow noreferrer noopener">focus</a> on the light side of human personality instead √¢‚Ç¨‚Äú the √¢‚Ç¨Àúeveryday saints√¢‚Ç¨‚Ñ¢ among us. These people are genuinely interested in others and treat them well without question, not as a means to an end. They applaud the success of others, believe in the fundamental goodness of humans, and respect the dignity of everyone. Our recent <a href="https://www.sciencedirect.com/science/article/pii/S019188692030310X" rel="nofollow noreferrer noopener">study</a> of more than 36,000 adults suggests that these traits are common: around <span>30-50 per cent</span> of people show prominent light personality trait profiles, depending on world region, and these traits are particularly common in women.</p>
<p>We wanted to understand which personality profile √¢‚Ç¨‚Äú dark or light √¢‚Ç¨‚Äú leads to more success and happiness in the long run. There is an oft-touted saying that √¢‚Ç¨ÀúNice guys finish last√¢‚Ç¨‚Ñ¢ and, on the face of it, this might seem correct. If you√¢‚Ç¨‚Ñ¢re always expending your energy caring about others, perhaps you√¢‚Ç¨‚Ñ¢re bound to get left behind. If you√¢‚Ç¨‚Ñ¢re willing to deceive and exploit others without worrying about their feelings, you can look after √¢‚Ç¨Àúnumber one√¢‚Ç¨‚Ñ¢ and rise faster to the top. But does the research back this up?</p>
<p>Experimental studies support the idea of a √¢‚Ç¨Àúsuccessful√¢‚Ç¨‚Ñ¢ dark personality, but only up to a point. One <a href="https://psycnet.apa.org/record/2015-11168-026" rel="nofollow noreferrer noopener">study</a> found that people with psychopathic personality traits win more points on a negotiation task where they are required to compete with a partner, but fewer points on a task that involves cooperation. Those with dark traits are <a href="https://link.springer.com/article/10.1007%2Fs12144-018-9823-9" rel="nofollow noreferrer noopener">more</a> likely to √¢‚Ç¨Àúdefect√¢‚Ç¨‚Ñ¢ in the classic Prisoner√¢‚Ç¨‚Ñ¢s Dilemma task √¢‚Ç¨‚Äú an approach that means maximising your own outcome while duping the other participant.</p>
<p>But their success in the real world is questionable. In corporate settings, those with dark personality traits are slightly more likely to <a href="https://psycnet.apa.org/record/2018-51219-001" rel="nofollow noreferrer noopener">emerge</a> as leaders and are seen as <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/bsl.925" rel="nofollow noreferrer noopener">charismatic</a> but, when it comes to getting the job done, they tend to achieve less and are considered poor team players. Our recent study also found that political figures with dark personality traits are more likely to get elected and hold their positions, but other studies <a href="https://journals.sagepub.com/doi/abs/10.1177/0956797615611922" rel="nofollow noreferrer noopener">show</a> that they are much poorer at getting legislation passed. Hedge fund managers with these traits generally <a href="https://journals.sagepub.com/doi/abs/10.1177/0146167217733080" rel="nofollow noreferrer noopener">obtain</a> significantly lower financial returns on the investment funds they manage. Overall, individuals with dark traits <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2Fa0025679" rel="nofollow noreferrer noopener">engage</a> in more counterproductive work behaviour, such as theft and abusive supervision. Perhaps unsurprisingly, they don√¢‚Ç¨‚Ñ¢t end up with higher average incomes than their peers with light personalities.</p>
<p>Through deceitful manipulation and callous use of others, these individuals are cutting off the very (social) branch they√¢‚Ç¨‚Ñ¢re sitting on</p>
<p>On top of this, those with dark personality traits don√¢‚Ç¨‚Ñ¢t have much luck outside of work. Even if they manage to avoid prison (imprisonment being a <a href="https://pubmed.ncbi.nlm.nih.gov/18837606/" rel="nofollow noreferrer noopener">high</a> possibility for those with extreme traits), they are at increased risk of <a href="https://pubmed.ncbi.nlm.nih.gov/19243821/" rel="nofollow noreferrer noopener">suicide</a> and <a href="https://pubmed.ncbi.nlm.nih.gov/28556964/" rel="nofollow noreferrer noopener">violent death</a>. They are also not particularly happy: people with dark traits tend to report poor self-image, an inability to intimately connect with others, and little life satisfaction. In contrast, we found that those with light personality trait profiles have fulfilling, intrinsically rewarding lives: they generally have a more positive view of themselves, more positive connections with others and find life more satisfying.</p>
<p>The key factor here seems to be empathy: the capacity to resonate with √¢‚Ç¨‚Äú and understand the perspective of √¢‚Ç¨‚Äú the emotional experiences of others. Individuals with light personality traits show a great deal of empathy for others, while those with dark personality traits tend to show very little. In our new research, we found that this seems to be what leads to a more satisfying life. Similarly, being prosocial √¢‚Ç¨‚Äú acting kindly, cooperatively and with compassion toward others √¢‚Ç¨‚Äú is also significantly <a href="https://psycnet.apa.org/record/2020-65092-001" rel="nofollow noreferrer noopener">linked</a> with higher wellbeing.</p>
<p>As a species, we√¢‚Ç¨‚Ñ¢re fundamentally built for social connectedness, and we depend on cooperation and <a href="https://www.aeaweb.org/articles?id=10.1257/jep.14.3.137" rel="nofollow noreferrer noopener">trust</a>. When those with dark personalities try to take advantage of this for their own personal gain, they do so at their own peril. In essence, through deceitful manipulation and callous use of others, these individuals are cutting off the very (social) branch they√¢‚Ç¨‚Ñ¢re sitting on. While those with dark traits might initially capture the attention of others, their social behaviour ultimately leads to limited success in work or politics, and little satisfaction with their lives.</p>
<p><strong>So far, we have</strong> made it seem as though people fall into one of two binary groups: dark or light. But in reality, there√¢‚Ç¨‚Ñ¢s a third group: we found that about <span>40 per cent</span> of individuals show a balance of dark and light traits. People in this mixed group are similar to the light group when it comes to critical variables involving empathy and social connectedness, but they still show some dark tendencies √¢‚Ç¨‚Äú hampering their relationships to some degree with deceitful, self-absorbed or hurtful behaviour toward others.</p>
<p>Some might think that the mixed group is the optimal place to be: you√¢‚Ç¨‚Ñ¢re able to have some connection with others, but won√¢‚Ç¨‚Ñ¢t be taken as a pushover. But compared with those with a light personality, mixed individuals have lower levels of life satisfaction and a less positive self-image. It seems that the mixed group are on the way to the light personality profile, so to speak, but fall short of the full expression √¢‚Ç¨‚Äú and the added dark traits are what√¢‚Ç¨‚Ñ¢s holding them back.</p>
<p>As people age √¢‚Ç¨‚Äú particularly from 30 to 40 √¢‚Ç¨‚Äú they become more likely to display light personality trait profiles</p>
<p>Regardless of where you fall on these dimensions of personality, we <a href="https://scottbarrykaufman.com/books/transcend/" rel="nofollow noreferrer noopener">believe</a> in the fundamental ability to grow and change. Large-scale studies have <a href="https://doi.apa.org/doiLanding?doi=10.1037%2Fa0024950" rel="nofollow noreferrer noopener">documented</a> that your general personality (eg, neuroticism, extraversion, conscientiousness) continues to change throughout your lifetime, and we√¢‚Ç¨‚Ñ¢ve found the same to be true when it comes to light and dark traits.</p>
<p>Specifically, we found that the extent to which you exhibit light or dark personality traits tends to shift as you get older. As people age √¢‚Ç¨‚Äú particularly as they progress from 30 to 40 √¢‚Ç¨‚Äú they become more likely to display light personality trait profiles. Other <a href="https://content.apa.org/record/2014-34008-001" rel="nofollow noreferrer noopener">research</a> has shown that moral character traits, such as conscientiousness and self-control, are generally more common in older people. Age doesn√¢‚Ç¨‚Ñ¢t completely account for the results √¢‚Ç¨‚Äú younger people can display light personality traits √¢‚Ç¨‚Äú but the research suggests that what can fundamentally differentiate light and dark profiles is a process of psychological maturation.</p>
<p>We are <a href="https://journals.sagepub.com/doi/10.1177/0963721417734875" rel="nofollow noreferrer noopener">born</a> with an innate sense of fairness, though this is a limited ability. Thus, like language, it is a skill that requires further development. Our research, and studies of our closest relatives, nonhuman primates, both show that moral behaviour can emerge and change across development √¢‚Ç¨‚Äú in large part through cooperative social interactions. Thus, by embracing and trusting social connections, we can progress toward a light personality trait profile √¢‚Ç¨‚Äú a pathway that appears to lead to healthy self-actualisation and even transcendence.</p>
<p>If you√¢‚Ç¨‚Ñ¢re curious about where you fall on the light vs dark personality spectrum, you can answer the <a href="https://scottbarrykaufman.com/lighttriadscale/" rel="nofollow noreferrer noopener">questions</a> we used in our study. We have now tested more than 250,000 individuals from across the globe, and you can see how your responses compare with the average. And remember, there is always scope for change: we believe in the fundamental ability to grow and transcend self-centredness through deliberate and sustained changes in our patterns of behaviour and thinking.</p>
<p>The most important thing is to <em>want</em> to change. Unfortunately, most people with extreme levels of dark personality traits don√¢‚Ç¨‚Ñ¢t want to change who they are. Despite not being particularly happy with their lives, they remain fixated on what they think they need: more and more power, wealth and domination over others.</p>
<p>Of course, some days we√¢‚Ç¨‚Ñ¢re all motivated to shut out other people, and simply look out for ourselves. This can be especially true when it seems that those who cheat, deceive and take advantage of others are somehow getting ahead. But rest assured that this doesn√¢‚Ç¨‚Ñ¢t seem to be the case. We have found that being empathic and connected to others √¢‚Ç¨‚Äú capitalising on our fundamentally social nature √¢‚Ç¨‚Äú is ultimately the pathway to a more rewarding life.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/are-people-with-dark-personality-traits-more-likely-to-succeed</link>
            <guid isPermaLink="false">hacker-news-small-sites-25344640</guid>
            <pubDate>Tue, 08 Dec 2020 13:17:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Content Security Policy ‚Äì protect your website from XSS attacks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25344439">thread link</a>) | @championshuttle
<br/>
December 8, 2020 | https://championshuttler.in/content-security-policy-protect-your-website-from-xss-attacks | <a href="https://web.archive.org/web/*/https://championshuttler.in/content-security-policy-protect-your-website-from-xss-attacks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://championshuttler.in/content-security-policy-protect-your-website-from-xss-attacks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25344439</guid>
            <pubDate>Tue, 08 Dec 2020 12:48:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Elixir Skills for Junior Developers to Learn in 2021]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25344114">thread link</a>) | @szsoppa
<br/>
December 8, 2020 | https://curiosum.dev/blog/elixir-key-skills-junior | <a href="https://web.archive.org/web/*/https://curiosum.dev/blog/elixir-key-skills-junior">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://curiosum.dev/blog/elixir-key-skills-junior</link>
            <guid isPermaLink="false">hacker-news-small-sites-25344114</guid>
            <pubDate>Tue, 08 Dec 2020 11:50:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[API for Editing Videos]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25344099">thread link</a>) | @sabbakeynejad
<br/>
December 8, 2020 | https://www.veed.io/api#hn | <a href="https://web.archive.org/web/*/https://www.veed.io/api#hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div id="w-node-1e5e5906b9c0-6422a266"><div><div id="w-node-1e5e5906b9c2-6422a266"><h3>Build fast &amp; reliable video experiences with well-documented APIs</h3><p>Having processed <strong>over a million</strong> videos to date, we are making it possible for you to do the same. Through our well documented APIs, you can build a wide range of video experiences on the web quickly and reliably.</p><ul role="list"><li><p>Video editing</p></li><li><p>Transcoding and compression</p></li><li><p>Auto-subtitling</p></li></ul><a href="https://veed.readme.io/docs/making-first-render"><p>VEED API&nbsp;Quickstart</p><img src="https://global-uploads.webflow.com/5fb54d297dbd1e8a953dcea9/5fb54d297dbd1efe633dcf9d_arrow.svg" loading="lazy" alt=""></a></div><div id="w-node-1e5e5906b9d8-6422a266"><p><img src="https://global-uploads.webflow.com/5fb54d297dbd1e8a953dcea9/5fb54d297dbd1e55733dcfc0_Subtitle%20Image.png" loading="lazy" alt=""></p></div></div></div><div id="w-node-f964c72a8ee6-6422a266"><h3>Build awesome products</h3><p>What can you build with Veed? Here‚Äôs a few creative things for you!</p><div data-duration-in="300" data-duration-out="100"><div><div data-w-tab="Tab 1"><div><div id="w-node-4a212a4e2e46-6422a266"><p><img src="https://global-uploads.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5fb7b990f7f122c956e9a330_BrandKit.svg" loading="lazy" alt=""></p><h4>Asset management</h4><p>You can store and process your videos, images and audio files as assets, using our API.</p><p><a href="https://docs.veed.io/use-cases/creating-an-asset">Learn more</a></p></div><div id="w-node-cae6855cebfe-6422a266"><p><img src="https://global-uploads.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5fb7b9907adc7962695f158a_Scissors2.svg" loading="lazy" alt=""></p><h4>Video trimming</h4><p>If you want to trim the beginning or end from a video, the API Video Trimming functionality is what you're looking for.</p><p><a href="https://docs.veed.io/use-cases/trimming-a-video">Learn more</a></p></div><div id="w-node-1e68831bb48c-6422a266"><p><img src="https://global-uploads.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5fb7b9d1b459b8fe5504d403_Subtitle2.svg" loading="lazy" width="48" alt=""></p><h4>Transcribing and subtitling</h4><p>Following modern trends, subtitles have never been more important. Our API can transcribe and subtitle your videos automatically.</p><p><a href="https://docs.veed.io/use-cases/transcribing-and-subtitling-a-video">Learn more</a></p></div></div></div><div data-w-tab="Tab 2"><div><div id="w-node-c692ca4ce845-6422a266"><h4>Video cropping</h4><p>Make the video fit your format</p></div><div id="w-node-c692ca4ce84d-6422a266"><h4>Watermark Video</h4><p>For example TikTok watermark</p></div><div id="w-node-c692ca4ce855-6422a266"><h4>Transcoding</h4><p>Make any file play and make it the right size</p></div></div></div><div data-w-tab="Tab 3"><div><div id="w-node-5590a8ff75b1-6422a266"><h4>Transcribing and subtitling</h4><p>Following modern trends, subtitles have never been more important. Our API can transcribe and subtitle your videos automatically.</p><p><a href="https://docs.veed.io/use-cases/transcribing-and-subtitling-a-video">Learn more</a></p></div></div></div><div data-w-tab="Tab 4"><div><div id="w-node-c1244a8e9ab5-6422a266"><h4>SDK</h4><p>Editor light, Editor Pro, Video Recorder</p></div></div></div></div></div><p><a href="https://veed.readme.io/" target="_blank">Browse entire API documentation</a></p></div><div id="w-node-a474301ee60e-6422a266"><h3>A seamless integration <span>guaranteed</span></h3><p>Enjoy a stress-free and easy integration on your next project.</p></div><div id="w-node-e23a9130e867-6422a266"><div><div data-duration-in="300" data-duration-out="100"><div><div data-w-tab="Tab 1"><div><div><p>curl \<br> &nbsp;-X POST \<br> &nbsp;--header "Authorization: <br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;veed_test_oEnZhnd3vg0LEoTs6Z9Ij" \<br> &nbsp;--data @render.json \<br> &nbsp;https://api.veed.dev/render</p></div></div></div></div></div></div></div><div id="w-node-75332b20435c-6422a266"><div><h3>Ready to integrate with VEED?</h3><p>Our engineers are available to pair-program with you for FREE.</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.veed.io/api#hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25344099</guid>
            <pubDate>Tue, 08 Dec 2020 11:48:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dangers of Believing in Freedom]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25343562">thread link</a>) | @Ninroot
<br/>
December 8, 2020 | https://reflexio.debec.eu/danger-of-believing-in-freedom | <a href="https://web.archive.org/web/*/https://reflexio.debec.eu/danger-of-believing-in-freedom">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
        <figure>
            <img alt="cover" src="https://reflexio.debec.eu/assets/panoptique.svg">
            <figcaption><a href="http://ferbos.jeanfrancois.free.fr/psychanalyse-et-creation/spip.php?article137" target="_blank">credit</a></figcaption>
            
        </figure>
        
        <p>A fraction of our behaviors are governed by patterns that, upon closer examination, reveal significant steps in personal development. This article is intended for those who wish to introspect and recognize their patterns as part of the necessary step to grow and prevent becoming an oppressor.</p>

<p>In common use, to believe oneself free is to deny the existence of the causes that explain one‚Äôs behavior. To say ‚ÄúI was free to go by the left or by the right‚Äù actually means ‚ÄúI don‚Äôt know the reasons that make me take one path rather than another‚Äù, the reasons exist, we just don‚Äôt know them<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. This is the principle of <a href="https://en.wikipedia.org/wiki/Causality_(physics)">causality</a>.</p>

<p>Those who believe they are free tend to believe that others are free for the same reasons. Believing that others act freely is then equivalent to denying the existence of causes in their actions. To say ‚Äúthis person is free to become an engineer or an artist‚Äù actually means ‚ÄúI don‚Äôt know why this person is in this career rather than another‚Äù.</p>

<h2 id="deny">Deny</h2>

<p>Denying the existence of causes is not an isolated problem and Etienne Klein illustrates this very well through a funny anecdote (video in French):</p>

<iframe src="https://www.youtube-nocookie.com/embed/Fj5r1ry2TTU?start=217" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<blockquote>
  <p>The other day [‚Ä¶], I was giving a lecture at Central [Grande √âcole in France] on relativity and I was doing the same calculation of Einstein‚Äôs 1905 calculation in which they show that the duration of a phenomenon depends on the speed of the observer in relation to this phenomenon [‚Ä¶]. At the end of the demonstration a pupil asks to speak and says to everyone ‚ÄúSir, I do not agree with Einstein‚Äù. I was happy, I had a student who had a critical mind, I ask him to argue. I was expecting him to talk about Poincar√© who restores the luminiferous aether‚Ä¶ in short, to argue. That he would argue from arguments that come from physics and the guy says ‚ÄúSir I don‚Äôt believe the dilation of time because I don‚Äôt feel it‚Äù. In other words, this young man who was accepted in Centrale, <em>thought that his feeling, his subjectivity, had a power great enough to be able to discredit what a century of objectification has made it possible to establish</em>. - Etienne Klein</p>
</blockquote>

<p>In our case, it is not about physical phenomena but about human behavior. People denying (consciously or not) the deterministic character on which our behavior depends, oppose the theories that are more than a century old, such as the social determinism of Emile Durkeim for example. This attitude, in addition to being obsolete, is dangerous.</p>

<h2 id="dangers">Dangers</h2>

<p>Omitting the reasons for human behavior leads to difficult situations that are encountered in many different contexts:</p>
<ul>
  <li>A bad parent gets angry at its child without trying to understand the reasons for its child‚Äôs misbehavior. In fact, the child felt lonely throughout dinner and wanted to get someone‚Äôs attention.</li>
  <li>A bad manager blames an employee without trying to find the reasons for the delay. In fact, what was asked for in the first place didn‚Äôt make much sense when looking at it more closely and a redesign was required, making the delivery as late as necessary.</li>
  <li>A bad engineer denigrates the misuse of a system by a user without ever trying to meet the person. In fact, no user input control was implemented, leaving the system capable of harming itself.</li>
  <li>etc.</li>
</ul>

<p>Getting rid of the need to understand others generates a lot of frustration, especially if it involves a hierarchical relationship. If at the level of a team, ‚Äúfirst accountability and then blame‚Äù is disastrous, imagine at the level of a nation.</p>

<blockquote>
  <p>Moreover, the frequency of torture is always a sign of faith or laziness in the Government. There is no evil that cannot be made good for something. Jean-Jacques Rousseau ‚Äî Du contrat social (1762)</p>
</blockquote>

<h2 id="reasons">Reasons</h2>

<p>So where does this trend come from? There are many reasons. Etienne Klein explains it by laziness and narcissism: ‚ÄúI find that this relativism, when it is too strong, is a perfect legitimization of <em>intellectual laziness</em>, that you can judge what is going on in Nature from your subjectivity alone, sometimes even from your narcissism alone. It relieves you of having to learn a couple of things about quantum mechanics, particle physics or the Higgs boson‚Äù.</p>

<p>Confirmation bias or <em>conflict of interest</em> stem also that tendency. This is why, a manager of a team prefers to believe that another team is intrinsically incompetent rather than investing some of my resources in training them.</p>

<p>Last example: <em>who would boast of not being free?</em> It is even the first term of the French national motto ‚Äúliberty, equality, fraternity‚Äù.</p>

<p>Although these reasons can be explained, they are no less dangerous. So what can be done?</p>

<h2 id="solution">Solution</h2>

<p>Recognize that <em>freedom is limited</em>. Don‚Äôt see this as a fatality; on the contrary, it is the essential point for growing up. Consider this as a constraint of the system you are designing, which hidden, cannot help to find the appropriate solution.</p>

<p>Once acknowledged, areas for improvement will come naturally. Some disciplines such as UX design have understood this early on. A designer will adjust the interface if many users interact in unexpected ways. User behaviors prevail over the designer‚Äôs wishes or predictions. Thanks to the trends in human behavior that UX has been able to establish principles, evaluate them, refine them, etc.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Are we free? Should we fight for our freedom? This article does not pretend to answer these questions. On the other hand, a fraction of our behaviors seem to be governed by patterns that, if we take the time to look into them, reveal actionable steps for personal development. Denying these patterns and neglecting the need to understand them is a lost opportunity to improve and may turn into oppression.</p>

<p>Assuming our behavior as the result of an unpredictable phenomenon is firstly a sign of narcissism, but above all a denial of the ability to introspect, to recognize our patterns, to understand ourselves, in other words, to grow. Expanding that idea to others is dangerous. Considering the behavior of others as absolutely unforeseeable is first naive toward the social sciences, but it is above all to rid ourselves of the responsibility to understand, to empathize, in fact to free the other. <a href="https://twitter.com/arnaud_debec/status/1332434506112970753">So acknowledge you live in a cage before planning to escape</a>.</p>

<hr>



    </div></div>]]>
            </description>
            <link>https://reflexio.debec.eu/danger-of-believing-in-freedom</link>
            <guid isPermaLink="false">hacker-news-small-sites-25343562</guid>
            <pubDate>Tue, 08 Dec 2020 09:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating a HomeKit Accessory]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25343507">thread link</a>) | @mpweiher
<br/>
December 8, 2020 | https://sampo3k.github.io/2020/12/08/pcb.html | <a href="https://web.archive.org/web/*/https://sampo3k.github.io/2020/12/08/pcb.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="overview">Overview</h2>

<p>Over the past 8 weeks, I built a HomeKit accessory to open and close the gate at the end of my driveway.  The project was really fun, and this document outlines the process of creating it, from concept to working prototype.</p>

<h3 id="additional-background">Additional Background</h3>

<p>Programming examples for microcontrollers will be in C++.  For the most part, we‚Äôll be sticking essentially to ‚ÄúC with Classes‚Äù, which is typical of most Arduino and other microcontroller projects.</p>

<p>The data in this document is by no means meant to be comprehensive.  I am not an electrical engineer, and welcome any corrections or other feedback.  Where possible, I‚Äôve cited references or resources I found useful at each step.  For the most part, extensive googling served as the primary research tool.</p>

<p>The swing gate in question is a Sentex Crown Jewel, which was available in the early 2000s. It interfaces with a home phone system to control 1 or 2 relays.  Programming is performed either via the gate keypad, or via 300 baud modem connected to a Windows program.  Later in this document we‚Äôll show how to use a listening modem to eavesdrop on the communication to reverse engineer the app-only commands which are not in the publicly available references.</p>

<p>Further data for those interested can be found</p>
<ul>
  <li><a href="https://p.widencdn.net/51eik7/6001141">Crown Jewel Programming manual</a></li>
  <li><a href="https://p.widencdn.net/np06ng/6001145">Crown Jewel Installation manual</a></li>
</ul>

<h2 id="concept">Concept</h2>

<p>The problem I aimed to solve was to interface the gate microcontroller to HomeKit.  The only interfaces to the gate are a keypad (outside the gate) and a home phone line.  The previous owners did not install the manual operation switch, so I would frequently forget to open the gate when walking into town, get to the gate, then go back inside to dial the phone access code.  It would be great to just pull out a phone or say ‚Äúhey Siri open the gate‚Äù.</p>

<p>First thing to do is to decompose the goal into tasks small enough that each can have easily understandable requirements and success criteria.  Another benefit of this process is that having many small tasks to complete will give us a sense of accomplishment and provide motivation as we complete them üôÇ</p>

<h3 id="problem-1---phone-interface-to-swing-gate">Problem 1 - Phone Interface to Swing Gate</h3>

<p>Objective: Implement software library that can send and receive phone number tones, and communicate with a 300 baud modem.</p>

<p>Success Criteria:</p>

<ul>
  <li>Detect when phone is off hook, and listen for DTMF tones to keep HomeKit state in sync when other users control the gate from the phone line.</li>
  <li>Take phone off hook and dial numbers to control gate relay.</li>
  <li>Communicate via 300 baud modem (Bell 103) protocol.</li>
</ul>

<h3 id="problem-2---homekit-support">Problem 2 - HomeKit Support</h3>

<p>Objective: The microcontroller + phone line interface should appear as a home kit accessory.</p>

<p>Success Criteria:</p>

<ul>
  <li>Successfully pair the device with HomeKit</li>
  <li>Implement a service that  allows opening and closing the gate</li>
  <li>Demonstrate control via ‚ÄúHey Siri open the gate‚Äù</li>
</ul>

<h3 id="problem-3---physical-prototype">Problem 3 - Physical prototype</h3>

<p>Objective: Combine the proofs of concept of the phone interface, and homekit device, into a single logic board, have that board manufactured, and enclose it in a case.</p>

<p>Success Criteria:</p>

<ul>
  <li>Capture a schematic which contains all necessary circuits for correct operation of the system.</li>
  <li>Arrange the physical design of those components and signals into a printed circuit board using a CAD program.</li>
  <li>Manufacture the board.</li>
  <li>Enclose the assembled board in a case so we can handle it safely and easily.</li>
</ul>

<h2 id="phone-interface-to-swing-gate">Phone Interface to Swing Gate</h2>

<p>The first piece of the project is the phone line interface.  Reviewing the requirements from earlier, our first requirement is ‚ÄúDetect when phone is off hook, and listen for DTMF tones‚Äù.</p>

<p>Decomposing this further, we need to:</p>

<ul>
  <li>Understand how to interface a microcontroller to a phone line</li>
  <li>Understand how to take the phone ‚Äúoff hook‚Äù</li>
  <li>Do some signal processing to detect tones, for example, someone pressing the number ‚Äú9‚Äù on a phone keypad.</li>
</ul>

<h3 id="digital-access-arrangement">Digital Access Arrangement</h3>

<p>In the United States, home phone lines usually consist of a pair of wires, Tip and Ring, with a nominal -48VDC between them.  These wires carry the signal (voice or data), and the voltage and resistance between them indicates various states (on hook, off hook, ringing, etc.) <a href="https://en.wikipedia.org/wiki/Plain_old_telephone_service" title="Wikipedia Plain Old Telephone Service">Additional info at Wikipedia</a>.</p>

<p>Since the voltage on the lines (48v) is well above that typically interfaced to a microcontroller (1.8-5.0v), we need some circuitry to extract the signal from the phone line, convert it to a voltage compatible with our processor.  Additionally, this circuitry should provide isolation of our circuitry from the phone circuit, to protect against transient voltage spikes.  A nice discussion of isolation is <a href="https://www.silabs.com/documents/public/application-notes/AN1167.pdf" title="Safety Considerations for Silicon Labs Series Capacitor Isolators">here</a>.  In this application we‚Äôve chosen to use a surge suppression capacitor that will fail open but magnetic isolation via a small transformer is also common in modem designs.</p>

<p>Since there are quite a few components in even simplified / cost reduced DAA‚Äôs (see page 21, &lt;&gt;) I opted to buy a reference board for the <a href="https://ixysic.com/Products/LITELINK.htm">Ixys CPC5622 Litelink III DAA</a>. Additional info can be found in the <a href="https://www.ixysic.com/home/pdfs.nsf/www/UG-LLIII-EB.pdf/$file/UG-LLIII-EB.pdf">CPC5622-EVAL Evaluation Board Users Guide</a>.</p>

<h3 id="integration-with-arduino-uno">Integration With Arduino Uno</h3>

<p>Connecting the Eval board for the Litelink DAA to the Arduino so that we can start looking at phone line signals is pretty straight forward.  Looking at the Fritzing diagram below, we‚Äôve connected an I2C oled to the Uno so we can see what‚Äôs happening.  The eval board implements DC-blocking capacitors on the TX/RX lines, so we implement a voltage divider with a pair of resistors, and connect the RX line (pink) from the 5622 to A0 on the Uno, putting the ‚Äúzero point‚Äù at 1.65V (3.3/2).  We wire up a phone jack to the J1 header on the eval board, and we connect 3.3v through a 10k resistor to AREF on the Uno, setting the analog reference for ADC measurements at 3.3 * 32/(32+10) == 2.5v.  Since the Uno doesn‚Äôt have a differential ADC, the Vpp (peak to peak voltage) on the RX+ line from the eval board should be &lt;1V so we shouldn‚Äôt clip under normal operation, and get more precision out of the ADC by using more of its range vs. the standard 0-5V.  ‚ÄúOff Hook‚Äù (orange) is pulled up as required by the 5622.</p>

<p><img src="https://sampo3k.github.io/images/fritzing.jpg" alt="5622EVAL Fritzing"></p>

<p>Success!  At this point, we can read A0, and see the voltage held roughly constant at 1.65v when on hook, and if you pick up a receiver on the phone line connected to the 5622, you will start seeing the voltage vary as the call progress (dial) tone is received, or connect an oscilloscope and visualize it.</p>
<h3 id="digital-signal-processing">Digital Signal Processing</h3>

<p>Now we have an analog signal into our Uno, and can move on to the next requirement: decode DTMF tones. <a href="https://en.wikipedia.org/wiki/Dual-tone_multi-frequency_signaling" title="Link to Wikipedia article on DTMF">Dual-tone multi-frequency</a> (DTMF) is way each key on a phone key pad is converted into analog signals.  The wikipedia article does a really good job summarizing what‚Äôs going on.</p>

<p>At this point we need to do some Digital Signal Processing (DSP) to figure out which frequencies are present in the signal we‚Äôre receiving, and then see if there are exactly two strong signals that happen to be one of the 16 DTMF pairs.</p>

<p>I‚Äôm not going to go too deeply into DSP here, but for a better understanding of what we‚Äôre trying to do, I cannot recommend these two resources highly enough.</p>

<ol>
  <li>
    <p><a href="https://jackschaedler.github.io/circles-sines-signals/">Intro to DSP</a>: This website has amazing interactive tutorials that explains some of the fundamentals of digital signal processing in a really neat and useful way.</p>
  </li>
  <li>
    <p><a href="http://www.dspguide.com/">DSP book</a>: This book is a wealth of information on DSP techniques, and the PDFs of each chapter are available for free.  With some effort, you can even concatenate them together into the entire book :)</p>
  </li>
</ol>

<h3 id="tone-detection">Tone Detection</h3>

<p>For DTMF, the typical sequence we are looking for is &gt;=100ms of tone and &gt;=100ms of silence repeated for however many digits we are listening for.</p>

<p>The common approach to frequency detection is an FFT.  However, the performance of the 16MHz ATMega328P makes this difficult.  For example, we need the FFT bins about 70Hz apart or less to discriminate the DTMF tones.  So that means at 8KHz we need roughly  8000/70 = 114 samples or more.  Rounding up to a convenient power of 2 for the FFT, we‚Äôll say 256/2 = 128 FFT bins. The bins will be 8KHz / 128 = 62.5Hz apart.</p>

<p>To do a 256 sample FFT, in addition to a reasonable amount of memory, we‚Äôd need something on the order of ~8k multiplies and ~8k additions, which given the performance of 16x16+32 MAC is around 50 cycles, our most wildly optimistic projection here if we hand coded a great FFT is like 25-30ms, or about 0.5x realtime. This seems to line up well with the results on this <a href="https://www.norwegiancreations.com/2019/03/arduino-fft-pt-2-improving-the-hardware-for-real-time-analysis/" title="Arduino FFT pt. 2: Improving the Hardware for Real-time Analysis">Arduino FFT post</a>. We also use the same performance hack noted there to reduce the ADC prescaler on the ATMega328 so that ADC reads don‚Äôt take so long.</p>

<p>An alternative approach is to use <a href="https://en.wikipedia.org/wiki/Goertzel_algorithm">Goertzel algorithm</a> which is essentially a single-frequency digital filter.  Doing 8 applications of the Goertzel algorithm including the ADC reads only takes about 12ms, which is about 1.2x realtime.  I think, based on the output of <a href="https://godbolt.org/">https://godbolt.org</a> that AVR GCC is generating full 32x32 multiplies for 16x16+32 -&gt; 32 MAC so some hand assembly could probably make this go faster.</p>

<p>In order to generate some test cases for our code, I used this <a href="https://www.audiocheck.net/audiocheck_dtmf.php">DTMF WAV file generator</a> and converted the resulting WAV files into virtual ADC samples in the range of our analog circuit.  I then ran our detection code, to verify the algorithm correctness before moving it to the Uno.  A reasonable sample Goertzel implementation can be found <a href="https://www.st.com/resource/en/design_tip/dm00446805-the-goertzel-algorithm-to-compute-individual-terms-of-the-discrete-fourier-transform-dft-stmicroelectronics.pdf" title="The Goertzel algorithm to compute individual terms of the discrete Fourier transform (DFT)">here</a></p>

<h3 id="bell-103">Bell 103</h3>

<p>Programming the gate microcontroller is done via the 300 baud modem protocol <a href="https://en.wikipedia.org/wiki/Bell_103_modem">Bell 103</a>.  The RX side of this seems well within the Uno‚Äôs capabilities, as we can likely count the number of zero crossings in every 3ms baud window to discriminate between the mark and space frequencies used by the <a href="http://edge.rit.edu/content/P09141/public/FSK.pdf">FSK</a> encoding.</p>

<p>The TX side however, seems much trickier on the Uno.  The Uno lacks a DAC, and while you can create one using PWM on a digital pin and then put it through a low pass filter, this seemed like a lot of work.  About this time I also wanted to get going on HomeKit portion of the project, and I took the easy way out: using an actual modem.</p>

<h3 id="cmx865a-modem">CMX865A ‚Ä¶</h3></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sampo3k.github.io/2020/12/08/pcb.html">https://sampo3k.github.io/2020/12/08/pcb.html</a></em></p>]]>
            </description>
            <link>https://sampo3k.github.io/2020/12/08/pcb.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25343507</guid>
            <pubDate>Tue, 08 Dec 2020 09:45:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A package for presenting person names]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25343112">thread link</a>) | @robinvdvleuten
<br/>
December 8, 2020 | https://robinvdvleuten.nl/blog/package-for-presenting-person-names/ | <a href="https://web.archive.org/web/*/https://robinvdvleuten.nl/blog/package-for-presenting-person-names/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div itemscope="" itemtype="https://schema.org/Blog"><article itemscope="" itemtype="https://schema.org/BlogPosting"><div itemprop="articleBody"><p>When building applications, you‚Äôll probably have to show an user‚Äôs name in one or more formats (first, last, initials, etc.). I‚Äôve created a package called <a href="https://github.com/webstronauts/php-person-name">php-person-name</a>, that will make this a lot easier in Laravel (or any PHP framework).</p><p>It is based on the <a href="https://github.com/basecamp/name_of_person">name_of_person</a> gem from the awesome people at <a href="https://basecamp.com/">Basecamp</a>. They had a similar issue in their application; how do we present a person‚Äôs name in different formats if we only have a first and a last name.</p><p>It‚Äôs public API is quite simple and can be summarized in the following snippet.</p><div><pre><code data-lang="php"><span>&lt;?php</span>

<span>$name</span> <span>=</span> <span>new</span> <span>PersonName</span><span>::</span><span>make</span><span>(</span><span>'David Heinemeier Hansson'</span><span>)</span>

<span>echo</span> <span>$name</span><span>-&gt;</span><span>full</span>        <span>// "David Heinemeier Hansson"
</span><span></span><span>echo</span> <span>$name</span><span>-&gt;</span><span>first</span>       <span>// "David"
</span><span></span><span>echo</span> <span>$name</span><span>-&gt;</span><span>last</span>        <span>// "Heinemeier Hansson"
</span><span></span><span>echo</span> <span>$name</span><span>-&gt;</span><span>initials</span>    <span>// "DHH"
</span><span></span><span>echo</span> <span>$name</span><span>-&gt;</span><span>familiar</span>    <span>// "David H."
</span><span></span><span>echo</span> <span>$name</span><span>-&gt;</span><span>abbreviated</span> <span>// "D. Heinemeier Hansson"
</span><span></span><span>echo</span> <span>$name</span><span>-&gt;</span><span>sorted</span>      <span>// "Heinemeier Hansson, David"
</span><span></span><span>echo</span> <span>$name</span><span>-&gt;</span><span>mentionable</span> <span>// "davidh"
</span><span></span><span>echo</span> <span>$name</span><span>-&gt;</span><span>possessive</span>  <span>// "David Heinemeier Hansson's"
</span></code></pre></div><p>Need integration with Laravel? Just use the following to add a <code>name</code> attribute to your models.</p><div><pre><code data-lang="php"><span>&lt;?php</span>

<span>use</span> <span>Webstronauts\PersonName\PersonName</span><span>;</span>

<span>class</span> <span>User</span> <span>extends</span> <span>Model</span>
<span>{</span>
    <span>/**
</span><span>     * The attributes that are mass assignable.
</span><span>     *
</span><span>     * @var array
</span><span>     */</span>
    <span>protected</span> <span>$fillable</span> <span>=</span> <span>[</span>
        <span>'name'</span><span>,</span> <span>'first_name'</span><span>,</span> <span>'last_name'</span><span>,</span>
    <span>];</span>

    <span>/**
</span><span>     * Return a PersonName instance composed from the `first_name` and `last_name` attributes.
</span><span>     *
</span><span>     * @return PersonName
</span><span>     */</span>
    <span>public</span> <span>function</span> <span>getNameAttribute</span><span>()</span>
    <span>{</span>
        <span>return</span> <span>new</span> <span>PersonName</span><span>(</span><span>$this</span><span>-&gt;</span><span>first_name</span><span>,</span> <span>$this</span><span>-&gt;</span><span>last_name</span><span>);</span>
    <span>}</span>

    <span>/**
</span><span>     * Sets the `first_name` and `last_name` attributes from a full name.
</span><span>     *
</span><span>     * @param  string $name
</span><span>     * @return void
</span><span>     */</span>
    <span>public</span> <span>function</span> <span>setNameAttribute</span><span>(</span><span>$name</span><span>)</span>
    <span>{</span>
        <span>$fullName</span> <span>=</span> <span>PersonName</span><span>::</span><span>make</span><span>(</span><span>$name</span><span>);</span>
        <span>[</span><span>$this</span><span>-&gt;</span><span>first_name</span><span>,</span> <span>$this</span><span>-&gt;</span><span>last_name</span><span>]</span> <span>=</span> <span>$fullName</span> <span>?</span> <span>[</span><span>$fullName</span><span>-&gt;</span><span>first</span><span>,</span> <span>$fullName</span><span>-&gt;</span><span>last</span><span>]</span> <span>:</span> <span>[</span><span>null</span><span>,</span> <span>null</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div><p>As you can see, you‚Äôll just have to store the <code>first_name</code> and <code>last_name</code> attributes and you‚Äôll can generate all those variants through <code>name</code>.</p><div><pre><code data-lang="php"><span>&lt;?php</span>

<span>$user</span> <span>=</span> <span>new</span> <span>User</span><span>([</span><span>'first_name'</span> <span>=&gt;</span> <span>'Robin'</span><span>,</span> <span>'last_name'</span> <span>=&gt;</span> <span>'van der Vleuten'</span><span>])</span>

<span>echo</span> <span>$user</span><span>-&gt;</span><span>name</span><span>-&gt;</span><span>full</span> <span>// Robin van der Vleuten
</span></code></pre></div><p>A small but nifty helper that could be useful in almost any application. Go check it out on <a href="https://github.com/webstronauts/php-person-name">Github</a> and don‚Äôt forget to star it.</p></div><section><hr><h2>Webmentions</h2><ol><li></li><li><p>A package for presenting person names robinvdvleuten.nl/blog/package-f‚Ä¶</p></li><li><p>A package for presenting person names robinvdvleuten.nl/blog/package-f‚Ä¶</p></li><li><p>A package for presenting person names
L: robinvdvleuten.nl/blog/package-f‚Ä¶
C: news.ycombinator.com/item?id=253431‚Ä¶</p></li><li><p>A package for presenting person names: robinvdvleuten.nl/blog/package-f‚Ä¶ Comments: news.ycombinator.com/item?id=253431‚Ä¶</p></li></ol></section></article></div></div></div>]]>
            </description>
            <link>https://robinvdvleuten.nl/blog/package-for-presenting-person-names/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25343112</guid>
            <pubDate>Tue, 08 Dec 2020 08:23:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Functors ‚Äì Redux]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25343022">thread link</a>) | @l0lpalme
<br/>
December 8, 2020 | https://functional.christmas/2020/8 | <a href="https://web.archive.org/web/*/https://functional.christmas/2020/8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Last year I wrote <a href="https://functional.christmas/2019/20">an article</a> explaining functors in simple terms and show why they are useful. It has well received, but some felt it was lacking in details which is true and by design. There is more to be said and some crucial details that I glossed over so I will try to address some of them now. Let‚Äôs get nerdy!</p>
</section><article><section><h2>Functor as a context</h2>
<p>In the previous article I said you could think of a functor as a structure or container that has a mapping function. This is not strictly wrong as it is one way of thinking about the concept, but can be a bit misleading and confusing as it does not fit all situations. For example a functions can in some cases be a functor. A structure might give us thoughts about data structures or types. Container is fitting when talking about lists or other types that can contain data. Is a function a structure or container? For this reason it is common to refer to some of the general concepts and abstractions we use in FP (functor, monad etc.) as contexts which has some properties.</p>
<h2>The functor laws</h2>
<p>Unlike my vague explanation in the previous article a functor is actually a very specific thing, and is defined by rules or properties the context has to adhere to. These laws come from mathematics, specifically a branch called Category Theory. This is an area that I will not claim much knowledge of but great minds have found similarities between this particular part of mathematics and what we do in programming. </p>
<p>In addition to having the <code>map</code> function, functors needs to follow some rules.
The rules for functors are often called the functor laws. I'm not completely sure why. It might have something to do with math and also its sounds very sophisticated. :P Let‚Äôs get in on the sophistication!</p>
<h3>1. Law of preservation of identity</h3>
<p>The first law or rule of functors is that if the <code>map</code> function is given the identity function as its mapping function it will return the same functor.
The identity function is just a function that has one argument which it returns right back (<code>\x -&gt; x</code> in Elm or <code>function(x){return x;}</code> in JS).</p>
<p>Let‚Äôs use lists to visualize this a bit more. Elm actually has the identity function in its standard library so we will just use that one:</p>
<div data-language="elm"><pre><code><span>List.map</span> <span>identity</span> <span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>]</span> <span>==</span> <span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>]</span></code></pre></div>
<p>For the javascript example we will add the identify function inline:</p>
<div data-language="javascript"><pre><code><span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>]</span><span>.</span><span>map</span><span>(</span><span>(</span><span>x</span><span>)</span> <span>=&gt;</span> x<span>)</span> <span>==</span> <span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>]</span></code></pre></div>
<p>When following this law the functor can not make any weird changes to the result. <code>List.map someFunction [1,2,3,4]</code> can never return an empty list. It can only map the function over the values. When mapping over a 4 item list, the returning list will always be a 4 item list. </p>
<h3>2. Law of composition</h3>
<p>The second law is not very complicated either but assumes that you know about composition. Lets quickly go through composition before looking at the next law.</p>
<h4>Composition</h4>
<p>Composition in functional programming (FP) is the ability to compose multiple functions into one single function. This is not often used in object oriented programming (OOP) but quite common in FP. </p>
<p>Composition is "gluing" functions together into one function. This is such a common thing to do that many languages have dedicated operators for this. Lets look at an example to see it in action to see why this might be useful. I'll be doing the examples in Elm as composition is a bit awkward in javascript and not that common.</p>
<p>Lets say you have a user record that has the fields name and age:</p>
<div data-language="elm"><pre><code><span>type</span> <span>alias</span> <span>User</span> <span>=</span> 
    <span>{</span> <span>name</span> <span>:</span> <span>String</span>
    <span>,</span> <span>age</span><span>:</span> <span>Int</span>
    <span>}</span></code></pre></div>
<p>To get the age of a User record we can in Elm use an accessor function which is available for every field defined in a record.<sup><sup id="fnref-1"><a href="#fn-1">1</a></sup></sup> For the <code>age</code> field this function is called <code>.age</code> and has the type signature <code>User -&gt; Int</code>. It takes a <code>User</code> type as an argument and returns a <code>Int</code>. In this case it is the content of the age field.</p>
<p>Go get the age from a user you would to: </p>
<div data-language="elm"><pre><code>
<span>user</span> <span>=</span> <span>{</span> <span>name</span> <span>=</span> <span>"John"</span><span>,</span> <span>age</span> <span>=</span> <span>20</span> <span>}</span>


<span>.</span><span>age</span> <span>user</span>
</code></pre></div>
<p>At some point in your program you might have a <code>User</code> and need to display the age on a webpage, print it in a log or anything else that needs the age to be a string. To convert a <code>Int</code> into a <code>String</code> we can use the built-in function <code>fromInt</code> in the String module. </p>
<p>So where you have a user and need the age as a string you can use the compose operator in Elm to create a new function that gives you the user age as a string. I will write the type signatures for the functions as well so we can see how they fit together: </p>
<div data-language="elm"><pre><code><span>.</span><span>age</span> <span>:</span> <span>User</span> <span>-&gt;</span> <span>Int</span>

<span>fromInt</span><span>:</span> <span>Int</span> <span>-&gt;</span> <span>String</span>

<span>ageAsString</span> <span>:</span> <span>User</span> <span>-&gt;</span> <span>String</span>
<span>ageAsString</span> <span>=</span> <span>.</span><span>age</span> <span>&gt;&gt;</span> <span>fromInt</span></code></pre></div>
<p>When the output of a function matches the input of another we can compose them together and make a new function that has the input of the first and output of the second. Note that <code>&gt;&gt;</code> is the rightwards compose operator.<sup><sup id="fnref-2"><a href="#fn-2">2</a></sup></sup></p>
<h4>The second law</h4>
<p>Now that you hopefully know a bit about function composition lets look at the second law of functors. The rule says that composing functions into a single function and then mapping that function over the functor should produce the same result as mapping the individual functions over the functor in sequence. Lets look as some code to make sense of it:</p>
<div data-language="elm"><pre><code><span>users</span> <span>:</span> <span>List</span> <span>User</span>
<span>users</span> <span>=</span> 
    <span>[</span> <span>{</span> <span>name</span> <span>=</span> <span>"John"</span><span>,</span> <span>age</span> <span>=</span> <span>20</span> <span>}</span>
    <span>,</span> <span>{</span> <span>name</span> <span>=</span> <span>"Mary"</span><span>,</span> <span>age</span> <span>=</span> <span>22</span> <span>}</span>
    <span>,</span> <span>{</span> <span>name</span> <span>=</span> <span>"Kevin"</span><span>,</span> <span>age</span> <span>=</span> <span>30</span> <span>}</span>
    <span>]</span>

<span>agesThroughMaps</span> <span>:</span> <span>List</span> <span>String</span>
<span>agesThroughMaps</span> <span>=</span> 
    <span>users</span>
        <span>|&gt;</span> <span>List.map</span> <span>.</span><span>age</span>
        <span>|&gt;</span> <span>List.map</span> <span>String.fromInt</span>

<span>agesThroughComposeAndMap</span> <span>:</span> <span>List</span> <span>String</span>
<span>agesThroughComposeAndMap</span> <span>=</span> 
	<span>List.map</span> <span>(</span><span>.</span><span>age</span> <span>&gt;&gt;</span> <span>String.fromInt</span><span>)</span> <span>users</span></code></pre></div>
<p>In the example above we have a list of users and two constants<sup id="fnref-3"><a href="#fn-3">3</a></sup> that both are a list of the users‚Äô ages as strings. </p>
<p>The first constant, <code>agesThroughMaps</code>, is defined using two map operations. The first run passes the <code>.age</code> accessor function to <code>map</code> and gives us a list of ages (of type <code>Int</code>). In the second map operation the <code>String.fromInt</code> is used to create a list of the users‚Äô ages as <code>String</code>. </p>
<p>For the last constant, <code>agesTthroughMaps</code>, the list of the users age is created with one map operation where the function passed in to <code>map</code> is composed of the <code>.age</code> and <code>fromInt</code> functions with the compose operator (<code>&gt;&gt;</code>). </p>
<p>And this is the result of the second law: the values in the two constants should be equal. A list of strings: <code>["20", "22", "30"]</code></p>
<p>See full example in Ellie: <a href="https://ellie-app.com/bKhq8M4vyjYa1">https://ellie-app.com/bKhq8M4vyjYa1</a></p>
<h2>The consequences of the laws</h2>
<p>The laws might seem a bit random and not very helpful at first glance, but it can actually help us a lot. To be a functor the structure/container/context has to follow these laws. It can not do anything weird with the value/values in it or the function that is passed inn. The only thing it can do is apply the function to the value in the context. The functor might have some extra logic around when to apply the function. A list might be empty so there would be nothing to apply the function to and similarly with <code>Maybe</code>. Take a look at <a href="https://functional.christmas/2019/20">last years article</a> to see a more complex example.</p>
<p>With these rules for what constitutes a functor in place the behavior of functors become predictable. So if we see it in code or talk about it with fellow coders we know exactly how it should behave! üòÑ</p>
</section></article></div>]]>
            </description>
            <link>https://functional.christmas/2020/8</link>
            <guid isPermaLink="false">hacker-news-small-sites-25343022</guid>
            <pubDate>Tue, 08 Dec 2020 08:02:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[10.000 commits later ‚Äì Switching to React Native in 2017]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25342980">thread link</a>) | @selbekk
<br/>
December 7, 2020 | https://react.christmas/2020/8 | <a href="https://web.archive.org/web/*/https://react.christmas/2020/8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section><p>To make matters worse: the company behind the app were in the middle of a perfect storm. The business was being changed by regulation. The core business idea were changing. This meant large changes coming to the digital side, including the app.</p>
<p>Naturally, we had quite mixed feelings about our ability to meet delivery expectations from the business side, given the bad state of the app codebase. We were at a crossroads, and felt we had to pick one of the following:</p>
<ol>
<li>Negotiate a feature timeout while we frantically renovate the core code, or</li>
<li>Start a long-term migration plan towards a hybrid app, or</li>
<li>Write new features in React Native and eventually move all the JS code over to a new app shell</li>
</ol>
<p>We decided to try out React Native. Roughly three years later, the app is now 100% JavaScript. The big business transformation has come a long way, and I‚Äôve experienced that React Native as a technology has played a key role in that success.</p>
<p>This article contains some reflections on <em>why</em> switching from pure native technologies to React Native worked so well for us.</p>
<h2>Starting Out Small Felt Really Safe</h2>
<p>We gave React Natives two tests. First, we wrote a small feature with a few developers. Futhermore, we did a larger, several-month feature where the entire team participated. A critical part of the tests was making sure that React Native would work as the small cogwheel it would necessarily start out as, inside of the large legacy app monster.</p>
<p>The people involved in each phase would evaluate the React Native developer experience, carefully considering if moving forward with React Native would be the right choice for us. After all, continuing with RN would mean a long migration process. Lots of our features would exist in the old, smelly native code for a long time, we would have to manually ensure backwards compatibility, handle (deep) navigation from old to new code (and vice verca), and lots of other things.</p>
<p>Even with these challenges in mind, the team were crystal clear post-testing. React Native made work easier, faster and more fun! In case we‚Äôd conclude differently, the investment made was so low that we could safely discard the effort as a proof-of-concept, where the learnings were enough to justify the time spent.</p>
<p>Trying out new technology this way just seems like a very smart way to do it. It was also key that it was the voice of the developers spending all day with the technology that weighed the most.</p>
<h2>We Actually Did Develop New Features Much Faster</h2>
<p>They say React Native save you half the work. Since your code will run on both iOS and Android, it eliminates the need to develop separate code &nbsp;for each platform. Write code once ‚Äì not twice. Neat!</p>
<p>In our experience, this was mostly true. We did end up doing minor platform customizations here and there. Shadows don‚Äôt work as well on Android as iOS. Sometimes you‚Äôd want different UI behaviours to adhere to platform guidelines. And as with web development, you‚Äôll encounter visual bugs for each platform that need special attention.</p>
<p><strong>I‚Äôd say we saved about 45% of the work involved.</strong> It‚Äôs not half - but it still makes a tremendous difference on productivity!</p>
<p>It‚Äôs also hard to not talk about the productivity boost obtained by Hot Reload (now Fast Refresh). Seeing the effect of my last code edit presented visually on screen immediately (with state preserved) is simply marvelous. Scale up the time saved for each little change with the amount of the developers involved and the amount of time spent‚Ä¶ it‚Äôs just huge!</p>
<p><img src="https://microsoft.github.io/react-native-windows/blog/assets/fastrefresh.gif" alt="animation showing how react-native's &quot;Fast Refresh&quot; works" title="React Native's &quot;Fast Refresh&quot;"></p>
<h2>All Developers Code For Both Platforms</h2>
<p>I‚Äôve met hundreds of fine developers, if not thousands. But those skilled and efficient in both native iOS and native Android development - I can count them on one hand. And they‚Äôre not exactly looking for work.</p>
<p>With React Native, we experienced that the entire team could do work for both platforms. It‚Äôs hard to overstate the importance of this fact. Instead of having dedicated iOS and Android teams, we‚Äôd have a feature being made by the same person (or small group) on both platforms, reducing the overhead involved in coordination and organization between devs and designers, business folks, product owners, etc. Also, fewer people needed to learn the ins and outs of that particular feature in a quite complex domain.</p>
<p>This provides great flexibility and robustness for a development team, and was much needed in our setting.</p>
<h2>Recruitment and Onboarding</h2>
<p>Not too many people are familiar with native mobile technologies. In comparison, capable JavaScript/React-developers come a dime a dozen. We found that finding talent was easier, and the newcomers found themselves productive way quicker than we‚Äôd expect. In a period with frantic scaling and expansion, this was critical.&nbsp;</p>
<p>I can imagine recruiting top-notch mobile development specialists is easier if you‚Äôre a huge company with infinite resources. In that case, you could staff the necessary amount of specialist teams for iOS and Android and just steamroll whatever you‚Äôre making.&nbsp;</p>
<p>In the Norwegian market, with finite resources, easing your requirements from <em>¬´five years of Swift¬ª</em> to <em>¬´five years of JavaScript experience¬ª</em> makes all the difference. The programming language in itself is one thing, but there‚Äôs also the ecosystem, development enviroment, IDE, etc. Apple make a lot of really sweet products, but XCode surely isn‚Äôt one of them.</p>
<h2>Team Organization</h2>
<p>Our old codebase was.. entangled. I imagine it would be challenging to attempt doing distributed development on the same codebase across several teams. At least when aiming for near-continuous delivery. Doing a Spotify-like product team organization with an app dev in each team seemed utopian at the time.</p>
<p>Over the course of a few years, we went from a dedicated mobile team of five to a product team organization with near 20 mobile developer spread across all teams. This would be much harder without the flexibility and familiarity of <em>¬´it‚Äôs just JavaScript¬ª</em> or <em>¬´it¬¥s just React¬ª</em>. Not having to invest as much time and energy in specialist competencies for iOS or Android, app devs have more cognitive surplus to work on other things as well - web, cloud stuff, backend, UX-collaboration, etc.</p>
<h2>Deploy To Production At Will</h2>
<p>Mobile apps have always had a longer way to production. The <em>¬´quality control¬ª</em> mechanism with manual app reviews adds several days to the pipeline. The Apple App Store was alone responsible for up to a 14-day delay at it‚Äôs worst, although the wait times have been vastly reduced since then. Now they‚Äôre averaging at about a day.</p>
<p>A good dev team in 2020 will deploy to production many times each day. Looking at some of the biggest Norwegian apps today, it is not uncommon to see two-three-four week old builds as the most recent one.&nbsp;</p>
<p>The negative effects of not releasing your code often, and not even having the possibility to release at will, are well documented. React Native with it‚Äôs <em>over the air</em>-update called <em>CodePush</em> allows for continous delivery, even for mobile apps!&nbsp;</p>
<p>CodePush allows your app code to download the latest version of the compressed JavaScript bundle from a third-party server. When a user opens the app, the new bundle is downloaded and immediately installed. Voil√† ‚Äì immediate deploy to production!</p>
<p>Our app‚Äôs release cycle went from semi-monthly to several releases per day. Paired with great monitoring, this reduces the need for testing. Non-critical bugs can be tolerated to a larger degree if they don‚Äôt reach your entire audience before they‚Äôre automatically detected and shortly fixed.&nbsp;</p>
<p>Product development is also way faster. The team can iterate on small changes on real customers in production as a part of the development process, instead of lengthy sketching and laboratory user testing. This made the entire organization more customer-focused and impatient for real customer feedback.</p>
<h2>A Note On The Rewrite</h2>
<p>The whole codebase transformation to React Native took about two years. We only wrote already-planned new features in React Native, allowing us to be productive and produce new features during the process. The business transformation underway meant that most of the features would have required changes anyway, and it could actually be faster to implement them from scratch in React Native than to modify the legacy code.&nbsp;</p>
<p>This meant that we didn‚Äôt need a feature-freeze period with the team stuck on unproductive rewrite work. However, when most of the old app was rewritten, we needed a month-long cleanup to move all the separate features in the old app over to a new, fresh React Native repo.&nbsp;</p>
<p>From around March 2017 until June 2019 the app was in a state where some features existed in the old codebase and others in the new codebase. That wasn‚Äôt a pleasant situation, but not more unpleasant than working in the old legacy codebase before.</p>
<h2>Status As We‚Äôre Looming On 2021</h2>
<p>A total of <strong>10,000 commits</strong> have been made by <strong>33 contributors</strong> across <strong>5 teams.</strong>. Nearly 50 pull-requests from 14 authors was merged the past week. Our ability to deliver on business requirements have been strengthened. Looking back on our big choice of 2017, it‚Äôs truly awe-inspiring to see how big an effect a simple technology choice can have on helping teams reach lofty goals.</p>
<p>No technology is a silver bullet. React Native surely isn‚Äôt either. But it does have some truly wonderful effects on an impatient, agile, modern development organization that Swift, Kotlin or C# currently can‚Äôt offer, in my opinion.</p></section></article></div>]]>
            </description>
            <link>https://react.christmas/2020/8</link>
            <guid isPermaLink="false">hacker-news-small-sites-25342980</guid>
            <pubDate>Tue, 08 Dec 2020 07:55:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The secretive history of modern encryption]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25342978">thread link</a>) | @henrikwm
<br/>
December 7, 2020 | https://security.christmas/2020/8 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Cryptography is the science of secret writing with the goal of hiding the meaning of a message. When a message is encrypted with a secure algorithm, i.e. an encryption cipher, no one should be able to read it without the decryption key. However, the promise of security falls apart if the encryption algorithm is weak, or if someone has created a backdoor. In this article we‚Äôll examine the modern history of encryption. We‚Äôll learn that while the mathematical underpinnings of modern encryption is stronger than ever, government agencies have a history of thwarting efforts to reach the goal of truly secure communication. </p>
</section><article><section><p>The world‚Äôs first encryption ciphers often used algorithms that were themselves secret. The rather intuitive belief that security increases if the encryption details are hidden is a misconception, and is often referred to as <em>security by obscurity</em>. The algorithms that dominate the modern era rely on full openness, in accordance with <em>Kerckhoffs's principle</em>:</p>
<blockquote>
<p>A cryptosystem should be secure even if everything about the system, except the key, is public knowledge.</p>
</blockquote>
<p>This transparency allows the rest of the world to attempt to break the cipher. Every failed attempt at breaking a cipher reinforces the belief that it is secure. While there is a chance that someone breaks a cipher and does not report it, there is a far greater chance that a homemade algorithm will be broken easily.</p>
<h2>A big moment in cryptographic history</h2>
<p>Up until 1972 there was no standard cipher for encrypting secret messages. The US <em>National Bureau of Standards (NBS)</em>, which later became the <em>National Institute for Standards and Technology (NIST)</em>, started an initiative for finding a single secure algorithm. This was rather revolutionary. The American government had traditionally kept their knowledge of cryptography to themselves - they considered it to be crucial to national security. As a result of the NIST initiative, several ciphers were proposed as candidates for the first encryption standard.</p>
<p>The most promising candidate was contributed by a team of cryptographers working at IBM. They developed a refined version of an earlier encryption cipher called Lucifer, which was first developed by Horst Feistel in the late 1960s. Their candidate was a block cipher with a key size of 128 bits. A block cipher is an algorithm that encrypts several bits at a time, i.e. a block of bits, as opposed to stream ciphers that encrypts bit by bit. A sufficiently large key size is necessary for a cipher to withstand brute force attacks, since these attacks generate all possible decryption keys. In context of a brute force attack, one would say that the larger the key size the more robust the cipher.</p>
<h2>Speculation of NSA backdoors</h2>
<p>When the NIST examined the security of the cipher candidates, they reached out to the <em>National Security Agency (NSA)</em> for assistance. At this point in time the NSA did not even admit their own existence. The involvement of the NSA lead to speculation and rumors, since the cipher went through a couple of peculiar alterations during the cooperation between NSA and IBM. </p>
<p>The most worrying change was that the key size was reduced from 128 bits to 56 bits. This made the cipher considerably less resistant to brute force attacks. Concerns were raised that this change was motivated by the NSA, in order to provide themselves with a backdoor. Maybe their computers were powerful enough to brute force a key size of 56 bits ‚Äì but not quite powerful enough to brute force a key size of 128 bits? </p>
<p>The cipher was also altered to be resistant to attacks using differential cryptanalysis. That doesn‚Äôt sound too bad, but this particular attack was not known to the public until 1990 ‚Äì almost 20 years later! If the NSA were familiar with an attack the world would need 20 more years to discover, it is not hard to believe that they might be able to brute force a 56 bit key. However, it should be noted that none of these claims have been proven. </p>
<p>In 1977, the NIST presented an altered version of the IBM cipher as the new standard, which they named the <em>Data Encryption Standard (DES)</em>. It became the first modern, public, freely available encryption algorithm. All details regarding DES were made public, which is good practice since it allows researchers to scrutinize the mathematical details. However, the motivation for the design criteria remained secret. The public never learned why the key size was reduced, and this was the main cause for suspicion regarding the involvement of the NSA.</p>
<h2>DES cracked through brute force attack</h2>
<p>DES was initially meant to be the standard cipher for encryption for 10 years; from 1977 to 1987. But no serious weakness was found, and DES went on to reign as the standard algorithm for more than a decade past its due; until 1999.
In the final years of DES, several attempts were made to design and build a machine to brute force it. Building such a machine would cost millions of dollars. It was speculated that only government agencies would have the necessary financial resources to build it, and by this time it was widely believed that the NSA could in fact crack DES.</p>
<p>As the price of hardware fell, the <em>Electronic Frontier Foundation (EFF)</em> built the machine
<a href="https://en.wikipedia.org/wiki/EFF_DES_cracker">Deep Crack</a>.
In 1998 Deep Crack was able to brute force DES in 56 hours. This event demonstrated that it was time to select a new standard cipher for encryption.</p>
<p>In 1997, the NIST initiated an open competition to find a new standard encryption cipher. The competition had five finalists:
<a href="https://www.cs.miami.edu/home/burt/learning/Csc688.012/rijndael/rijndael_doc_V2.pdf">Rijndael</a>,
<a href="http://cryptosoft.de/docs/Mars.pdf">Mars</a>,
<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.2.1151&amp;rep=rep1&amp;type=pdf">RC6</a>,
<a href="http://www.networkdls.com/Articles/serpent.pdf">Serpent</a> and
<a href="http://gazizova.net/pub/Library/ihtik_Library/dvd_(%D0%A0%D0%B0%D0%B4%D0%B8%D0%BE)%D0%AD%D0%BB%D0%B5%D0%BA%D1%82%D1%80%D0%BE%D1%82%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B0/rea_2/Schneider%20B.Twofish.A%20128-bit%20block%20cipher.1998.pdf">Twofish</a>.
This time the selection process was completely transparent. In 2001, after three competitive rounds and intense cryptanalysis by the world‚Äôs foremost experts, the decision was made. The cipher Rijndael, designed by the Belgian cryptographers Joan Daemen and Vincent Rijmen, was declared as the new standard. It was given the name <em>Advanced Encryption Standard (AES)</em>. This cipher has three possible key sizes: 128 bit, 192 bit and 256 bit. All these key sizes were sufficiently large to withstand brute force attacks.</p>
<p>AES is widely regarded as the most secure encryption cipher invented. It has been battle-tested for decades and is expected to remain the standard cipher for many years to come. So far there are neither any known critical weaknesses, nor suspicion of backdoors.</p>
<h2>Attempts at legalizing government backdoors</h2>
<p>Algorithms have matured to be practically unbreakable, but current legislative measures attempt to undermine the basic purpose of cryptography. There are recurrent proposals for allowing government backdoors. For instance, the recently proposed <a href="https://www.judiciary.senate.gov/press/rep/releases/graham-cotton-blackburn-introduce-balanced-solution-to-bolster-national-security-end-use-of-warrant-proof-encryption-that-shields-criminal-activity"><em>Lawful Access to Encrypted Data Act</em></a> aims to force technology companies to implement backdoors. The right to privacy ends when the government institutions deem it useful to their own agenda. If such a law were to pass, the consequences would be immediate and severe. It would grant immense power to the government, and if a key is leaked or stolen, all encrypted communications are out in the open. Lawmakers argue that having a backdoor would help fight crime and terrorism, but this view assumes that criminals play by the rules and communicate through services using government issued encryption. </p>
<p>In the modern era the goal of private digital communication is, from a technological standpoint, a solved problem. It remains to see if future citizens will be able to enjoy digital privacy in their lives. It‚Äôs a question of balancing power between the government and the people ‚Äì and problems of that nature are not solved as elegantly as cryptographic puzzles.</p>
<p><em>If you want to go further down the rabbit hole, I highly recommend listening to the following episode of the Darknet Diaries podcast: <a href="https://darknetdiaries.com/episode/12/">Episode 12 - Crypto Wars</a>.</em></p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/8</link>
            <guid isPermaLink="false">hacker-news-small-sites-25342978</guid>
            <pubDate>Tue, 08 Dec 2020 07:54:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git Cheat Sheet ‚Äì Commands]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25342886">thread link</a>) | @jimmyk99
<br/>
December 7, 2020 | https://qirolab.com/posts/git-cheat-sheet-commands-1606211793 | <a href="https://web.archive.org/web/*/https://qirolab.com/posts/git-cheat-sheet-commands-1606211793">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="data-content" v-pre=""> <figure><p><img src="https://qirolab.com/images/202011UfPvdWswXRHFigUjiYnqoM8644TXmWdA0NjmoFIr.png" loading="lazy" alt="Git Cheat Sheet - Commands"></p></figure><h2><p>GIT BASICS</p></h2><p><b><code>git init &lt;directory&gt;</code>:</b>&nbsp; Create empty Git repo in the specified directory. Run with no arguments to initialize the current directory as a git repository.</p><p><b><code>git clone &lt;repo&gt;</code>:&nbsp;</b>Clone repo located at <i>&lt;repo&gt;</i> onto the local machine. The original repo can be located on the local filesystem or on a remote machine via HTTP or SSH.</p><p><b><code>git config user.name &lt;name&gt;</code>:</b> Define author name to be used for all commits in the current repo. Devs commonly use --global flag to set config options for the current users.</p><p><b><code>git add &lt;directory&gt;:</code></b> Stage all changes in <i>&lt;directory&gt;</i> for the next commit. Replace <i>&lt;directory&gt;</i> with a <i>&lt;file&gt;</i> to change a specific file.</p><p><b><code>git commit -m "&lt;message&gt;"</code>: </b>Commit the staged snapshot, but instead of launching a text editor, use <i>&lt;message&gt;</i> as the commit message.</p><p><b><code>git status</code>:</b> List which files are staged, unstaged, and untracked.</p><p><b><code>git log</code>:</b> Display the entire commit history using the default format. For customization see additional options.</p><p><b><code>git diff</code>:</b> Show unstaged changes between your index and working directory.</p><h2><p>UNDOING CHANGES</p></h2><p><code>git revert &lt;commit&gt;</code>: Create a new commit that undoes all of the changes made in <i>&lt;commit&gt;</i>, then apply it to the current branch.</p><p><code>git reset &lt;file&gt;</code>: Remove <i>&lt;file&gt;</i> from the staging area, but leave the working directory unchanged. This unstaged a file without overwriting any changes.</p><p><code>git clean -n</code>: This shows which files would be removed from the working directory. Use the -f flag in place of the -n flag to execute the clean.</p><h2><p>REWRITING GIT HISTORY</p></h2><p><code>git commit --amend</code>: Replace the last commit with the staged changes and last commit combined. Use with nothing staged to edit the last commit‚Äôs message</p><p><code>git rebase &lt;base&gt;</code>: Rebase the current branch onto <i>&lt;base&gt;</i>. <i>&lt;base&gt;</i> can be a commit ID, branch name, a tag, or a relative reference to HEAD.</p><p><code>git reflog</code>: Show a log of changes to the local repository‚Äôs HEAD. Add --relative-date flag to show date info or --all to show all refs.</p><h2><p>GIT BRANCHES</p></h2><p><code>git branch</code>: List all of the branches in your repo. Add a <i>&lt;branch&gt;</i> argument to create a new branch with the name <i>&lt;branch&gt;</i>.</p><p><code>git checkout -b &lt;branch&gt;</code>: Create and check out a new branch named <i>&lt;branch&gt;</i>. Drop the -b flag to checkout an existing branch.</p><p><code>git merge &lt;branch&gt;</code>: Merge <i>&lt;branch&gt;</i> into the current branch.</p><h2><p>REMOTE REPOSITORIES</p></h2><p><code>git remote add &lt;name&gt; &lt;url&gt;</code>: Create a new connection to a remote repo. After adding a remote, you can use <i>&lt;name&gt;</i> as a shortcut for <i>&lt;url&gt;</i> in other commands.</p><p><code>git fetch &lt;remote&gt; &lt;branch&gt;</code>: Fetches a specific <i>&lt;branch&gt;</i>, from the repo. Leave off <i>&lt;branch&gt;</i> to fetch all remote refs.</p><p><code>git pull &lt;remote&gt;</code>: Fetch the specified remote‚Äôs copy of the current branch and immediately merge it into the local copy.</p><p><code>git push &lt;remote&gt; &lt;branch&gt;</code>: Push the branch to <i>&lt;remote&gt;</i>, along with necessary commits and objects. Creates named branch in the remote repo if it doesn‚Äôt exist</p><h2><p>GIT CONFIG</p></h2><p><code>git config --global user.name &lt;name&gt;</code>: Define the author name to be used for all commits by the current user.</p><p><code>git config --global user.email &lt;email&gt;</code>: Define the author email to be used for all commits by the current user.</p><p><code>git config --global alias. &lt;alias-name&gt; &lt;git-command&gt;</code>: Create a shortcut for a Git command. E.g. alias.glog ‚Äúlog --graph --oneline‚Äù will set ‚Äùgit glog‚Äù equivalent to ‚Äùgit log --graph --oneline.</p><p><code>git config --system core.editor &lt;editor&gt;</code>: Set text editor used by commands for all users on the machine. <i>&lt;editor&gt;</i> arg should be the command that launches the desired editor (e.g., vi).</p><p><code>git config --global --edit</code>: Open the global configuration file in a text editor for manual editing.</p><h2><p>GIT LOG</p></h2><p><code>git log -&lt;limit&gt;</code>: Limit the number of commits by <i>&lt;limit&gt;</i>. E.g. ‚Äùgit log -5‚Äù will limit to 5 commits.</p><p><code>git log --oneline</code>: Condense each commit to a single line.</p><p><code>git log -p</code>: Display the full diff of each commit.</p><p><code>git log --stat</code>: Include which files were altered and the relative number of lines that were added or deleted from each of them.</p><p><code>git log --author= ‚Äù&lt;pattern&gt;‚Äù</code>: Search for commits by a particular author.</p><p><code>git log --grep=‚Äù&lt;pattern&gt;‚Äù</code>: Search for commits with a commit message that matches &lt;pattern&gt;.</p><p><code>git log &lt;since&gt;..&lt;until&gt;</code>: Show commits that occur between <i>&lt;since&gt;</i> and <i>&lt;until&gt;</i>. Args can be a commit ID, branch name, HEAD, or any other kind of revision reference.</p><p><code>git log -- &lt;file&gt;</code>: Only display commits that have the specified file.</p><p><code>git log --graph --decorate</code>: --graph flag draws a text-based graph of commits on the left side of commit msgs. --decorate adds names of branches or tags of commits shown.</p><h2><p>GIT DIFF</p></h2><p><code>git diff HEAD</code>: Show the difference between the working directory and the last commit.</p><p><code>git diff --cached</code>: Show the difference between staged changes and last commit</p><h2><p>GIT RESET</p></h2><p><code>git reset</code>: Reset staging area to match most recent commit, but leave the working directory unchanged.</p><p><code>git reset --hard</code>: Reset staging area and working directory to match the most recent commit and overwrites all changes in the working directory</p><p><code>git reset &lt;commit&gt;</code>: Move the current branch tip backward to <i>&lt;commit&gt;</i>, reset the staging area to match, but leave the working directory alone.</p><p><code>git reset --hard &lt;commit&gt;</code>: Same as previous, but resets both the staging area &amp; working directory to match. Deletes uncommitted changes, and all commits after <i>&lt;commit&gt;</i>.</p><h2><p>GIT REBASE</p></h2><p><code>git rebase -i &lt;base&gt;</code>: Interactively rebase current branch onto <i>&lt;base&gt;</i>. Launches editor to enter commands for how each commit will be transferred to the new base.</p><h2><p>GIT PULL</p></h2><p><code>git pull --rebase &lt;remote&gt;</code>: Fetch the remote‚Äôs copy of the current branch and releases it into the local copy. Uses git rebase instead of the merge to integrate the branches.</p><h2><p>GIT PUSH</p></h2><p><code>git push &lt;remote&gt; --force</code>: Forces the git push even if it results in a non-fast-forward merge. Do not use the --force flag unless you‚Äôre absolutely sure you know what you‚Äôre doing.</p><p><code>git push &lt;remote&gt; --all</code>: Push all of your local branches to the specified remote.</p><p><code>git push &lt;remote&gt; --tags</code>: Tags aren‚Äôt automatically pushed when you push a branch or use the --all flag. The --tags flag sends all of your local tags to the remote repo.</p> </div></div>]]>
            </description>
            <link>https://qirolab.com/posts/git-cheat-sheet-commands-1606211793</link>
            <guid isPermaLink="false">hacker-news-small-sites-25342886</guid>
            <pubDate>Tue, 08 Dec 2020 07:39:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Road to Rome: Fundraising and Project Goals]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25342500">thread link</a>) | @terabytest
<br/>
December 7, 2020 | https://rome.tools/funding/ | <a href="https://web.archive.org/web/*/https://rome.tools/funding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content"> <section>  <section> <h2 id="introduction">Introduction <a href="#introduction" aria-label="introduction"></a></h2>  <p>I‚Äôm Sebastian McKenzie, the creator of <a href="https://babeljs.io/">Babel</a> and <a href="https://yarnpkg.com/">Yarn</a>. These tools have both inspired me to create Rome, a new project that aims to simplify and improve JavaScript and web development.</p> <p>Rome consolidates dozens of separate tools into one. Rome can install your dependencies, check your code for errors, run your tests, bundle your code, and more, all via a single CLI. Rome will be able to replace Babel, ESLint, Prettier, Yarn, and webpack. <a href="https://rome.tools/">Learn more</a>.</p> <p>It‚Äôs been three months since we announced our initial <a href="https://rome.tools/blog/2020/08/08/introducing-rome.html">beta release</a>. Since then, we‚Äôve received a tremendous amount of enthusiasm from the community. As that enthusiasm has grown, it‚Äôs become clear that Rome will require a full-time developer to be successful and deliver on our ambitious goals and release a stable v1.0.</p> <p><strong>I need your help to make it a reality.</strong></p> </section> <section> <h2 id="funding">Funding <a href="#funding" aria-label="funding"></a></h2> <p>I have left my job so I can work independently and focus on what the community needs. This includes a <a href="#allow-users-to-extend-functionality-with-plugins">plugin system</a>, <a href="#add-more-configuration-and-have-less-opinions">more configuration</a>, and <a href="#integrate-with-existing-tools">dedicated integrations for existing tools</a>.</p> <p>We have an initial goal of <strong>$100,000</strong>. This will allow myself to work independently on our first stable release. Additional funding would allow us to expand upon our release goals, fund future maintenance, and compensate other contributors.</p> <p>If you‚Äôre passionate about what we‚Äôre building, or have otherwise benefited from my work, I would appreciate your financial support.</p>    <section> <h3 id="recent-contributions">Recent Contributions <a href="#recent-contributions" aria-label="recent-contributions"></a></h3> <ul> <li>Loading...</li> </ul> </section> <section> <h3 id="contribute">Contribute <a href="#contribute" aria-label="contribute"></a></h3> <p>Prices are in USD. Includes sales tax and international shipping. Refer to <a href="#questions-and-answers">Questions and Answers</a> for more information.</p> <p> Loading... </p> <div> <h4>Custom</h4> <p>Want to donate under $10? Something else? Select your own amount!</p>  </div> <section> <h4 id="business">Business <a href="#business" aria-label="business"></a></h4> <p>These tiers include dedicated support, migration assistance, and website advertisement. I‚Äôll make sure Rome works well for you and your organization.</p> <p>Migration support is where I personally help your organization adopt and use Rome. This could include porting configuration, integrating with CI, or even adding new features and configuration to Rome.</p> <p>Interested in something else or have questions? Get in touch at <a href="https://rome.tools/cdn-cgi/l/email-protection#aeddcbcccfdddac7cfc0eedcc1c3cb80dac1c1c2dd"><span data-cfemail="1a697f787b696e737b745a6875777f346e75757669">[email&nbsp;protected]</span></a>!</p> <p> Loading... </p> </section> </section> </section> <section> <h2 id="goals">Goals <a href="#goals" aria-label="goals"></a></h2> <p>Funding will allow us to focus on usage and labor-intensive goals. We can make Rome easier to use and work for more people.</p> <section> <h3 id="add-more-configuration-and-have-less-opinions">Add more configuration and have less opinions <a href="#add-more-configuration-and-have-less-opinions" aria-label="add-more-configuration-and-have-less-opinions"></a></h3> <p>We have deliberately tried to keep configuration to a minimum. While this does produce a minimal API surface, it makes it almost impossible to easily migrate without losing functionality or changing conventions.</p> <p>We should aim to reduce the functional differences between Rome and other tools by introducing additional configuration and supported languages. This could include:</p> <ul> <li>Code formatting options</li> <li>Ability to customize expected filenames and directories</li> <li>Support for other configuration languages such as YAML and TOML</li> <li>More CLI flags</li> <li>Public JavaScript API</li> <li>Dynamic configuration (as opposed to static JSON-only configuration files)</li> <li><a href="#allow-users-to-extend-functionality-with-plugins">Allow extending functionality with plugins</a></li> </ul> <p>We have so far kept configuration light, as by reducing the amount of configuration options supported, we reduce maintenance cost and the potential for internal bugs.</p> <p>While this makes it easier for us as maintainers, it makes it drastically more difficult for users. No matter how persuasive our arguments may be for why you should use hard tabs instead of spaces, they seem like artificial and arbitrary constraints and introduces excessive prerequisites for adoption.</p> <p>Strong defaults and guided documentation for new users can provide the experience we ultimately want to offer, while removing our existing adoption restrictions.</p> </section> <section> <h3 id="integrate-with-existing-tools">Integrate with existing tools <a href="#integrate-with-existing-tools" aria-label="integrate-with-existing-tools"></a></h3> <p>Rome attempts to replace many tools. However we should still strive to support scenarios where another tool is better situated or preferred. This can also help during a migration where Rome is used in conjunction with another tool. We can do this in a couple of ways:</p> <p><strong>Integrating Rome as a first-class plugin in tools such as Babel, eslint, and webpack</strong></p> <p>Rome could be exposed as a plugin for those tools to allow you to adopt the Rome compiler without having to adopt the bundler first. This would reduce adoption prerequisites and allow easier experimentation inside of existing setups.</p> <p><strong>Seamlessly integrate other tools into Rome</strong></p> <p>We can introduce compatibility layers to have ESLint, Babel, and other tools run inside of Rome itself. ESLint errors could be displayed alongside Rome linter errors with the same UI and output format Instantly you could benefit from Rome‚Äôs file caching and parallelisation without needing a major migration.</p> </section> <section> <h3 id="assist-in-migrating-from-existing-tools">Assist in migrating from existing tools <a href="#assist-in-migrating-from-existing-tools" aria-label="assist-in-migrating-from-existing-tools"></a></h3> <p>It should be easy to migrate from other tools to Rome. First we need to ensure popular configuration options from other tools are supported. Then, offer automated tools to migrate basic setups without users needing to it manually.</p> <p>This needs to be accompanied with dedicated documentation and guides that can explain the differences between the tools, why you might want to use one over the other, similar concepts, new terminology, and equivalent config options.</p> </section> <section> <h3 id="allow-users-to-extend-functionality-with-plugins">Allow users to extend functionality with plugins <a href="#allow-users-to-extend-functionality-with-plugins" aria-label="allow-users-to-extend-functionality-with-plugins"></a></h3> <p>One of the fears with Rome is creating a monoculture where it‚Äôs impossible to innovate and experiment with new ideas. While it‚Äôs extremely optimistic to think we‚Äôll ever get into any sort of monopolistic position, not allowing extensions does stiffle innovation regardless of our market position by restricting the viability and adoption of new ideas.</p> <p>Plugins allow us to avoid supporting functionality that we might not want, while still giving users a choice. It reduces our role as an arbiter and allows new languages, non-standard JavaScript features, code conventions, and ideas that interact with Rome to be viable, receive support, and proliferate.</p> <p>We need to be extremely careful not to get into the position where Babel and Webpack are today, where they‚Äôre heavily restricted by the usage of internal APIs. We need to be able to maintain our autonomy when it comes to making architectural changes. Balancing this with a powerful plugin API will be a challenge and will likely require several iterations.</p> </section> <section> <h3 id="release-undocumented-features">Release undocumented features <a href="#release-undocumented-features" aria-label="release-undocumented-features"></a></h3> <p>Rome currently does a lot more than linting. It‚Äôs a major challenge today to market and explain Rome when so much of the project isn‚Äôt officially supported. While we strive to make each individual component of Rome competitive on it‚Äôs own, to some the biggest advantage and compelling reason for using Rome might be the reduction in dependencies.</p> <p>We should focus on releasing and maturing basic versions of all core functionality. This would increase user confidence in our architecture and show that Rome is viable as the comprehensive replacement that we want to be.</p> </section> <section> <h3 id="provide-accessible-and-comprehensive-documentation">Provide accessible and comprehensive documentation <a href="#provide-accessible-and-comprehensive-documentation" aria-label="provide-accessible-and-comprehensive-documentation"></a></h3> <p>Documentation for developer tools is generally quite obtuse and relies a lot on prerequisite knowledge. This can make it intimidating and inaccessible for developers new to the ecosystem. Further complicating that is the broad scope of what Rome is trying to do.</p> <p>We have tried to address some of this by making our documentation a single page. This makes it easy to search, and it can be read from top to bottom without needing to jump around to learn about different concepts. However as our supported features grow, it will be more difficult to use this structure without oversimplifcation and doesn‚Äôt allow different paths for different demographics.</p> <p>We need to invest in a more scalable approach for our documentation. We can offer dedicated sections that explain features like linting end-to-end without needing to introduce other components like the compiler and bundler that contain significantly more concepts and overwhelm the reader. Separate guides can be offered for new users and those already experienced with other tools to properly cater for multiple audiences.</p> </section> <section> <h3 id="regularly-release-new-versions">Regularly release new versions <a href="#regularly-release-new-versions" aria-label="regularly-release-new-versions"></a></h3> <p>One of the reasons Babel was successful is how quickly I was able to quickly fix bugs and release new versions. I would regularly have releases out within minutes of a bug report. This was critical during the early days when adoption was low. Being able to unblock users quickly would often make them more excited to use Babel even though they ran into a bug.</p> <p>Similarly, we should try and replicate this by building out our release infrastructure to allow the rapid testing and release of versions. We need to maintain momentum as the scope of supported features grow.</p> <p>We can achieve this with automated releases that can be manually triggered or deployed on a schedule. Automatic changelog generation would also take a lot of the manual work out of producing releases. Nightly releases would allow users to test experimental features and provide early feedback.</p> </section> </section> <section> <h2 id="questions-and-answers">Questions and Answers <a href="#questions-and-answers" aria-label="questions-and-answers"></a></h2> <section> <h3 id="when-will-physical-rewards-be-shipped">When will physical rewards be shipped? <a href="#when-will-physical-rewards-be-shipped" aria-label="when-will-physical-rewards-be-shipped"></a></h3> <p>We are tentatively aiming for the end of April 2021, however due to COVID delays or order volume this could be extended. We‚Äôll make sure to keep you updated via email.</p> </section> <section> <h3 id="what-is-my-email-used-for">What is my email used for? <a href="#what-is-my-email-used-for" aria-label="what-is-my-email-used-for"></a></h3> <p>We use your email address to send information about your order such as order questions, shipping status and delays. We may also send a survey to decide on customization options for rewards.</p> <p>Your email address will not be used for any other purpose or be displayed publicly.</p> </section> <section> <h3 id="how-is-payment-information-stored">How is payment information stored? <a href="#how-is-payment-information-stored" aria-label="how-is-payment-information-stored"></a></h3> <p>Payment information is entered and stored via Stripe. We do not have access to full payment details. Your billing address is used if we need to calculate and pay sales tax in your jurisdiction.</p> </section> <section> <h3 id="what-do-tier-prices-include">What do tier prices include? <a href="#what-do-tier-prices-include" aria-label="what-do-tier-prices-include"></a></h3> <p>Prices include processing fees, international shipping, and sales tax. This does mean the effective donation is reduced if you live in a country with import duty or high shipping cost.</p> <p>You have the option to add an additional donation in the order review screen if you would like to cover those costs.</p> </section> <section> <h3 id="why-do-you-need-my-usernames">Why do you need my usernames? <a href="#why-do-you-need-my-usernames" aria-label="why-do-you-need-my-usernames"></a></h3> <p>Usernames are used to allocate tier rewards. They are not required and you can ‚Ä¶</p></section></section></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rome.tools/funding/">https://rome.tools/funding/</a></em></p>]]>
            </description>
            <link>https://rome.tools/funding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25342500</guid>
            <pubDate>Tue, 08 Dec 2020 06:28:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alzheimer‚Äôs: New protein found in spinal fluid indicates stage of the disease]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25342434">thread link</a>) | @finphil
<br/>
December 7, 2020 | https://nuadox.com/post/636913398485073920/alzheimers-new-protein-in-spinal-fluid | <a href="https://web.archive.org/web/*/https://nuadox.com/post/636913398485073920/alzheimers-new-protein-in-spinal-fluid">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="636913398485073920">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/636913398485073920/alzheimers-new-protein-in-spinal-fluid"><h2>Alzheimer‚Äôs: New protein found in spinal fluid indicates stage of the disease</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1322"><img src="https://64.media.tumblr.com/a98b1861b351c0e344a0b741a8dbb2e4/a732b01a66a4a7cb-bd/s1280x1920/7ada61fe5c6d735e94585f0e12fc1d58f842e15d.jpg" alt="image" data-orig-width="1920" data-orig-height="1322" width="1280" height="881"></figure><p><b>- By <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedicine.wustl.edu%2Fnews%2Fauthor%2Ftbhandari%2F&amp;t=ZTM3M2U5MmM2NjNhMGVmY2I2MWQ5MWFkMDNiMzVlMGIzYmE1ZDZiOSxES3V5WjNqTQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F636913398485073920%2Falzheimers-new-protein-in-spinal-fluid&amp;m=0&amp;ts=1607735586">Tamara Bhandari</a> ,&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedicine.wustl.edu%2F&amp;t=YTI4OWMzNmM2ZGMzMzFlMGU1Yzc0NDMwMmMzY2U1ZDZmNzY1MmE3MCxES3V5WjNqTQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F636913398485073920%2Falzheimers-new-protein-in-spinal-fluid&amp;m=0&amp;ts=1607735586">Washington University School of Medicine</a> -</b></p><p>A novel form of an Alzheimer‚Äôs protein found in the fluid that surrounds the brain and spinal cord indicates what stage of the disease a person is in, and tracks with tangles of tau protein in the brain, according to a study from researchers at Washington University School of Medicine in St. Louis.&nbsp;</p><p>Tau tangles are thought to be toxic to neurons, and their spread through the brain foretells the death of brain tissue and cognitive decline. Tangles appear as the early, asymptomatic stage of Alzheimer‚Äôs develops into the symptomatic stage.</p><p>The discovery of so-called microtubule binding region tau (MTBR tau) in the cerebrospinal fluid could lead to a way to diagnose people in the earliest stages of Alzheimer‚Äôs disease, before they have symptoms or when their symptoms are still mild and easily misdiagnosed. It also could accelerate efforts to find treatments for the devastating disease, by providing a relatively simple way to gauge whether an experimental treatment slows or stops the spread of toxic tangles.</p><p>The study is published Dec. 7 in the journal <i><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Facademic.oup.com%2Fbrain%2Fadvance-article%2Fdoi%2F10.1093%2Fbrain%2Fawaa373%2F6024973&amp;t=NGViNDhhZjc3NjgyMjcxZjA0YmI0MTEyMzUxZDkxNzAxMTdmNzlmZSxES3V5WjNqTQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F636913398485073920%2Falzheimers-new-protein-in-spinal-fluid&amp;m=0&amp;ts=1607735586">Brain</a></i>.</p><p>‚ÄúThis MTBR tau fluid biomarker measures tau that makes up tangles and can confirm the stage of Alzheimer‚Äôs disease by indicating how much tau pathology is in the brains of Alzheimer‚Äôs disease patients,‚Äù said senior author <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwuphysicians.wustl.edu%2Ffor-patients%2Ffind-a-physician%2Frandall-j-bateman&amp;t=OWEyZTZiMzg1NzE5ZGRiY2ZmYjNiNmVmNmFkNjA0MmRiMWI4ZTcyNSxES3V5WjNqTQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F636913398485073920%2Falzheimers-new-protein-in-spinal-fluid&amp;m=0&amp;ts=1607735586">Randall J. Bateman, MD</a>, the Charles F. and Joanne Knight Distinguished Professor of Neurology. Bateman treats patients with Alzheimer‚Äôs disease on the Washington University Medical Campus. ‚ÄúIf we can translate this into the clinic, we‚Äôd have a way of knowing whether a person‚Äôs symptoms are due to tau pathology in Alzheimer‚Äôs disease and where they are in the disease course, without needing to do a brain scan. As a physician, this information is invaluable in informing patient care, and in the future, to guide treatment decisions.‚Äù</p><figure data-orig-height="467" data-orig-width="700"><img src="https://64.media.tumblr.com/fc417759120d05f3ed2b3f3c88456b16/a732b01a66a4a7cb-5b/s1280x1920/833d10cd4ac25b6179bb912ffe11c36eb2e47a6d.jpg" data-orig-height="467" data-orig-width="700" width="700" height="467" alt="image"></figure><p><i>Image:&nbsp;A ‚Äúheat map‚Äù of the brain of a person with mild Alzheimer‚Äôs dementia shows where tau protein has accumulated, with areas of higher density in red and orange, and lower density in green and blue. Researchers at Washington University School of Medicine in St. Louis have found a form of tau in spinal fluid that tracks with tau tangles in the brain and indicates what stage of the disease a person is in. Credit: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedicine.wustl.edu%2Fnews%2Fnovel-form-of-alzheimers-protein-found-in-spinal-fluid-indicates-stage-of-the-disease%2F&amp;t=ZGU4MWM2Nzc0YTczYWQxODE0MjgyNjU2NGE0ZjExMmMxZWIxNDNlYSxES3V5WjNqTQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F636913398485073920%2Falzheimers-new-protein-in-spinal-fluid&amp;m=0&amp;ts=1607735586">Tammie Benzinger/Knight ADRC</a>.</i></p><p>Alzheimer‚Äôs begins when a brain protein called amyloid starts forming plaques in the brain. During this amyloid stage, which can last two decades or more, people show no signs of cognitive decline. However, soon after tangles of tau begin to spread in the neurons, people start exhibiting confusion and memory loss, and brain scans show increasing atrophy of brain tissue.</p><p>Tau tangles can be detected by positron emission tomography (PET) brain scans, but brain scans are time-consuming, expensive and not available everywhere. Bateman and colleagues are developing diagnostic blood tests for Alzheimer‚Äôs disease based on <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedicine.wustl.edu%2Fnews%2Fblood-test-is-94-accurate-at-identifying-early-alzheimers-disease%2F&amp;t=NWFiYTJkNDU1MzQ1OTAzNDA0YjZmYWIwNjViMjgxY2I4OGQ4OTA1NSxES3V5WjNqTQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F636913398485073920%2Falzheimers-new-protein-in-spinal-fluid&amp;m=0&amp;ts=1607735586">amyloid</a> or a different <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedicine.wustl.edu%2Fnews%2Falzheimers-protein-in-blood-indicates-early-brain-changes%2F&amp;t=Mjc5NTFjMTllYWRhY2E3NThmZmY5OTJjMDZkZTZiYmY0NTc1MDA3NyxES3V5WjNqTQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F636913398485073920%2Falzheimers-new-protein-in-spinal-fluid&amp;m=0&amp;ts=1607735586">form of tau</a>, but neither test can pin down the amount of tau tangles across the stages of disease.</p><p>MTBR tau is an insoluble piece of the tau protein, and the primary component of tau tangles. Bateman and first author Kanta Horie, PhD, a visiting scientist in Bateman‚Äôs lab, realized that specific MTBR tau species were enriched in the brains of people with Alzheimer‚Äôs disease, and that measuring levels of the species in the cerebrospinal fluid that bathes the brain might be a way to gauge how broadly the toxic tangles have spread through the brain. Previous researchers using antibodies against tau had failed to detect MTBR tau in the cerebrospinal fluid. But Horie and colleagues developed a new method based on using chemicals to purify tau out of a solution, followed by mass spectrometry.</p><p>Using this technique, Horie, Bateman and colleagues analyzed cerebrospinal fluid from 100 people in their 70s. Thirty had no cognitive impairment and no signs of Alzheimer‚Äôs; 58 had amyloid plaques with no cognitive symptoms, or with mild or moderate Alzheimer‚Äôs dementia; and 12 had cognitive impairment caused by other conditions. The researchers found that levels of a specific form ‚Äî MTBR tau 243 ‚Äî in the cerebrospinal fluid were elevated in the people with Alzheimer‚Äôs and that it increased the more advanced a person‚Äôs cognitive impairment and dementia were.</p><p>The researchers verified their results by following 28 members of the original group over two to nine years. Half of the participants had some degree of Alzheimer‚Äôs at the start of the study. Over time, levels of MTBR tau 243 significantly increased in the Alzheimer‚Äôs disease group, in step with a worsening of scores on tests of cognitive function.</p><figure data-orig-height="467" data-orig-width="700"><img src="https://64.media.tumblr.com/b80f5e6d9222f0044e0c36a76f464ec8/a732b01a66a4a7cb-da/s1280x1920/353cb72a4ec9acf360e43a1eb0a68bb6998b1887.jpg" data-orig-height="467" data-orig-width="700" width="700" height="467" alt="image"></figure><p><i>Image:&nbsp;Researchers at Washington University School of Medicine in St. Louis have found a novel form of the Alzheimer‚Äôs protein tau in the fluid surrounding the brain and spinal cord. This form of tau ‚Äî known as MTBR tau ‚Äî indicates what stage of Alzheimer‚Äôs a person is in and tracks with tangles of tau protein in the brain. Credit: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedicine.wustl.edu%2Fnews%2Fnovel-form-of-alzheimers-protein-found-in-spinal-fluid-indicates-stage-of-the-disease%2F&amp;t=ZGU4MWM2Nzc0YTczYWQxODE0MjgyNjU2NGE0ZjExMmMxZWIxNDNlYSxES3V5WjNqTQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F636913398485073920%2Falzheimers-new-protein-in-spinal-fluid&amp;m=0&amp;ts=1607735586">Sara Moser</a>.</i></p><p>The gold standard for measuring tau in the living brain is a tau-PET brain scan. The amount of tau visible in a brain scan correlates with cognitive impairment. To see how their technique matched up to the gold standard, the researchers compared the amount of tau visible in brain scans of 35 people ‚Äî 20 with Alzheimer‚Äôs and 15 without ‚Äî with levels of MTBR tau 243 in the cerebrospinal fluid. MTBR tau 243 levels were highly correlated with the amount of tau identified in the brain scan, suggesting that their technique accurately measured how much tau ‚Äî and therefore damage ‚Äî had accumulated in the brain.</p><p>‚ÄúRight now there is no biomarker that directly reflects brain tau pathology in cerebrospinal fluid or the blood,‚Äù Horie said. ‚ÄúWhat we‚Äôve found here is that a novel form of tau, MTBR tau 243, increases continuously as tau pathology progresses. This could be a way for us to not only diagnose Alzheimer‚Äôs disease but tell where people are in the disease. We also found some specific MTBR tau species in the space between neurons in the brain, which suggests that they may be involved in spreading tau tangles from one neuron to another. That finding opens up new windows for novel therapeutics for Alzheimer‚Äôs disease based on targeting MTBR tau to stop the spread of tangles.‚Äù</p><p>‚Äì</p><p><b>Source:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedicine.wustl.edu%2Fnews%2Fnovel-form-of-alzheimers-protein-found-in-spinal-fluid-indicates-stage-of-the-disease%2F&amp;t=ZGU4MWM2Nzc0YTczYWQxODE0MjgyNjU2NGE0ZjExMmMxZWIxNDNlYSxES3V5WjNqTQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F636913398485073920%2Falzheimers-new-protein-in-spinal-fluid&amp;m=0&amp;ts=1607735586">Washington University School of Medicine</a></b></p><p><b>Full study:</b>&nbsp;‚ÄúCSF tau microtubule binding region identifies tau tangle and clinical stages of Alzheimer‚Äôs disease‚Äù, <i>Brain</i>.</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fdoi.org%2F10.1093%2Fbrain%2Fawaa373&amp;t=NWY1MjJkMzNiYTkyZTY1NWI2NTIxZjg3N2UyMzM4ZTgyZWI1NjE5YyxES3V5WjNqTQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F636913398485073920%2Falzheimers-new-protein-in-spinal-fluid&amp;m=0&amp;ts=1607735586">https://doi.org/10.1093/brain/awaa373</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/625031181195509760/new-blood-test-alzheimers">Novel blood test could greatly improve diagnosis of Alzheimer‚Äôs</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/alzheimers">alzheimers</a>
                                    
                                        <a href="https://nuadox.com/tagged/neuroscience">neuroscience</a>
                                    
                                        <a href="https://nuadox.com/tagged/brain">brain</a>
                                    
                                        <a href="https://nuadox.com/tagged/medicine">medicine</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                        <a href="https://nuadox.com/tagged/biology">biology</a>
                                    
                                        <a href="https://nuadox.com/tagged/aging">aging</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/636913398485073920/alzheimers-new-protein-in-spinal-fluid</link>
            <guid isPermaLink="false">hacker-news-small-sites-25342434</guid>
            <pubDate>Tue, 08 Dec 2020 06:14:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Evolution of my role as a founder CTO]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25342265">thread link</a>) | @kwindla
<br/>
December 7, 2020 | https://miguelcarranza.es/cto | <a href="https://web.archive.org/web/*/https://miguelcarranza.es/cto">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <p>There is a lot written about the importance of scaling as a founder in a fast-growing startup. Most of it focused on the CEO role. The generic advice on leadership also applies to other non-CEO roles, but I could not find a lot of content targeted to technical founders. In fact, after reading a <a href="https://twitter.com/elwatto/status/1230977002192031744?s=20" target="_blank">bunch of S-1 forms</a>, <strong>it was hard to find first-time CTOs going all the way from MVP to IPO</strong> (as opposed to founding CEOs). I found this fact really intriguing, and I wanted to dig deeper to try to understand the reasons. It was also stressing me out to some degree: <em>what if I don‚Äôt manage to scale fast enough? What does scaling even mean? I‚Äôd rather prepare before it becomes a real problem! I want to be the CTO who makes <a href="https://revenuecat.com/" target="_blank">RevenueCat</a> a public company!</em><sup>1</sup></p>

<p>Is it really much harder for non-CEO founders to scale quickly? Or perhaps it is that CEOs have a stronger support network. These could be the reasons. Or maybe I was asking the wrong question. After talking to a lot of founder CTOs, there was something clear: <strong>there is no standard definition for the CTO role</strong>, responsibilities will totally change <strong>depending on the company and the stage</strong>. At inception, the CTO is probably a glorified individual contributor, but this can escalate very quickly. Everyone‚Äôs experiences are different. Unfortunately, I don‚Äôt have the answers for other non-CEO founder roles, and maybe I don‚Äôt even have it for first-time CTOs either. However, I thought it would be a good self-awareness exercise to reflect on the things I‚Äôve learned and how my responsibilities have changed during the first 3 years at <a href="https://revenuecat.com/" target="_blank">RevenueCat</a>.</p>

<h3 id="the-cto-vs-vp-of-engineering-dilemma">The CTO vs VP of Engineering dilemma</h3>
<p>Simplifying, we could say that the CTO role is closer to architecture and code; whereas the VPE would be in charge of processes and management. A simple analogy could be the Senior/Staff Engineer path versus the Engineering Management career path.</p>

<p>During the early days, you need a CTO to architect and coordinate a small group of ICs hacking the minimum viable product. At this stage, being a founder is extremely helpful to set the vision of the product and the engineering culture. Ideally, the CTO is a domain expert in the problem that the startup is trying to solve.</p>

<p>But what if the product becomes successful? What if you reach product-market fit? You will need to hire a lot more engineers to satisfy customer demands. That‚Äôs a great problem to have. You might get lucky and get funding, or you might even be profitable already. But a higher headcount means more polished processes. At some point, somebody will inevitably need to start wearing the VP of Engineering hat. It will happen, and it will become quite obvious as the previous (or lack of) processes start to break. You have a couple of options at this stage. The CTO can start acting as VPE, or you can hire externally. It is probably a matter of personal preference or previous management experience. But <strong>it is a totally different set of skills</strong>, which might be difficult to acquire in a hyper-growth environment. Therefore, most commonly, the VP of Engineering is <a href="https://www.saastr.com/makes-bad-cto/" target="_blank">hired externally</a>.</p>

<p>If you are a founder you have some flexibility. You might have control to decide which way you want to go. Perhaps you hate people management and want to keep using your technical skills and problem knowledge to influence the technology directly. Or maybe you want to improve your management skills. Early employees tend to be more forgiving about founder managerial flaws. They joined because they trusted the founders, believed in the vision, and know they have good intentions. In the beginning, they might even prefer you as a direct manager than an external person. But eventually, there will be several layers of management, so you better learn fast if you want to follow this path and don‚Äôt have the experience.</p>

<p>Bryan Helmig, Zapier‚Äôs co-founder and CTO, says you need to <a href="https://zapier.com/engineering/startup-cto/" target="_blank"><em>figure out where you get your dopamine hits</em></a>. Personally, I have always been more of a <em>computer person</em> than a <em>people person</em>. 
I was not sure which path I should take, but I would have bet on the one involving computers. I‚Äôve always loved them, and I would say I am a better, more experienced engineer than I am a manager. I feel  more energized after shipping a new feature than during a one-on-one meeting.</p>

<p>However, as a founder, <strong>I get the dopamine hits when the company is doing well</strong>. When a customer recommends our product. When we hit the revenue goal. When we hire engineers that are better than me. When these engineers are happy and successfully shipping ambitious features. When code review is exhaustive but collaborative, not adversarial.</p>

<p>So, ultimately, I‚Äôve taken the approach to not simply follow my personal preference, but to <strong>do whatever is more impactful for the company at each stage</strong>. I am a problem solver after all. That is how I have been thinking about my role. My <strong>founder identity should be more important than my CTO title</strong>. In the long run, as a major shareholder, I need to do whatever is best for the company.</p>

<p>Typically breaking points start happening <strong>somewhere between 8 and 12 engineers</strong>. But it can be different depending on the product and the environment. In our case, as a fully distributed company, we encountered several breaking points as we were adding new time zones. During this <em>no man‚Äôs land stage</em> most technical founders are temporarily forced to wear both CTO and VPE hats simultaneously. Being flexible turned out to be very advantageous. I tried to step up and (poorly and temporarily) do work that nobody had the bandwidth to do. This helped me to identify the pain points and tweak the process or hire somebody to take over these tasks.</p>

<figure>
  <img src="https://miguelcarranza.es/assets/posts/notebooks.jpeg" alt="RevenueCat journals">
</figure>

<p>One thing that helped me a lot to navigate my role was to learn how other founders were spending their time at each stage. I have been journaling since we started the company. Based on these notes, I will briefly describe the tasks I‚Äôve been focused on and how my role has evolved.</p>

<table>
  <thead>
    <tr>
      <th>Metrics (EOY)</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Product Engineers</td>
      <td>2</td>
      <td>4</td>
      <td>8</td>
      <td>~18</td>
    </tr>
    <tr>
      <td>Total team size</td>
      <td>5</td>
      <td>9</td>
      <td>19</td>
      <td>~45</td>
    </tr>
    <tr>
      <td>Number of cities</td>
      <td>1</td>
      <td>5</td>
      <td>14</td>
      <td>??</td>
    </tr>
    <tr>
      <td>Number of time zones</td>
      <td>1</td>
      <td>3</td>
      <td>6</td>
      <td>??</td>
    </tr>
  </tbody>
</table>

<h2 id="2018-yc-mvp-and-first-hires">2018: YC, MVP, and first hires</h2>
<p>When we did Y-Combinator it was only <a href="https://twitter.com/jeiting" target="_blank">Jacob</a> and me. Jacob would write SDK and frontend code and I would focus on the backend and infrastructure. After YC we hired our first two engineers to take over Jacob‚Äôs coding responsibilities full time. We were all based in San Francisco and these hires were people we already knew. Easy (almost inexistent) management. <strong>There was no process overhead</strong>, we had one-week sprints and <strong>we were moving really fast</strong>.</p>

<p>These days were stressful but fun. We were setting the foundations of the engineering culture and seeing customers signing up one by one. Most of my time was spent architecting the initial version of features, listening to customers, and building their requests as fast as we humanly could. <strong>We would ship most requests on the same day</strong>.</p>

<p>My biggest concern here was making sure we were building something people wanted and the ability to keep growing to justify our <a href="https://techcrunch.com/2018/10/24/revenuecat-seed-funding/" target="_blank">$1.5M seed round</a>.</p>

<p><strong>Main learnings</strong>: Too many, impossible to summarize. We learned a lot while doing Y-Combinator. The main thing would be that talking to customers, building what they want, and making them happy was paramount. We even made this and shipping fast two of our <a href="https://www.revenuecat.com/blog/values" target="_blank">core values</a>.</p>

<h2 id="2019-keeping-up-with-customers-and-scaling-the-tech">2019: Keeping up with customers and scaling the tech</h2>
<p>It looks like we had achieved some kind of product-market fit. <strong>Customers were coming to us, support tickets started piling up and our API throughput would increase every day</strong>. We added our first remote engineer, located in Taiwan. The time zone difference was hard initially and we needed to adapt processes. But it all worked out fine. We got better coverage for customer requests and monitoring.</p>

<p><strong>Onboarding was a complete, one-off manual process</strong>. I started doing one-on-ones (not very regularly, maybe once a month), but <strong>management was still pretty light</strong>. Most conversations were still very technical. I was still an individual contributor. I was also on booth duty at a couple of conferences.</p>

<figure>
  <img src="https://miguelcarranza.es/assets/posts/boothduty.JPG" alt="Booth Duty, AltConf 2019">
</figure>

<p>My main concern at this stage was purely technical: <strong>the scalability of our systems</strong>. All of our engineers had a more product-oriented background, and we had some clear single points of failure. Not going down was constantly in my mind. The scale was outgrowing my comfort zone every single day. We did a decent job optimizing the most common scenarios, <a href="https://www.revenuecat.com/blog/aurora-migration-zero-downtime" target="_blank">migrating infrastructure before reaching breaking points</a>, and <strong>paying down the technical debt we took the year before</strong>.</p>

<p>Up until Q4, I was the de-facto on-call engineer. I did not want to disturb other team members outside working hours, and I felt reliability was my ultimate responsibility as a technical founder. I would carry my laptop literally everywhere. Eventually, <strong>we implemented an on-call rotation, and in retrospect, we should have done it earlier</strong>.</p>

<p><strong>Main learnings</strong>: Do not stress over scalability, but monitor as much as possible and always look out for the next bottleneck and single point of failure. Again, these are stressful but great problems to have. Establish an on-call policy as soon as possible, train engineers, and document resolution for known incidents. Rely on your team. <a href="https://miguelcarranza.es/technical-debt" target="_blank">Technical debt is actually good</a> if taken responsibly while trying to find product-market fit.</p>

<h2 id="2020-delegation-and-planning-the-future-organization">2020: Delegation and planning the future organization</h2>
<p>In 2020 we doubled the team again. We added engineers in Europe and Latin America. By the end of the year, we had multiple members in every team (SDK, frontend, backend‚Ä¶). We were able to work on several projects at the same time, and finally tackle more ambitious features. But we needed more coordination. <strong>A little bit of management structure was unavoidable at this stage.</strong></p>

<p>During Q1 and Q2 I spent most of my time reviewing code, providing architectural guidance, and coding a little bit on the side. I was still the person who had more context about our systems. By mid-year, it became very obvious that I was the bottleneck for ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://miguelcarranza.es/cto">https://miguelcarranza.es/cto</a></em></p>]]>
            </description>
            <link>https://miguelcarranza.es/cto</link>
            <guid isPermaLink="false">hacker-news-small-sites-25342265</guid>
            <pubDate>Tue, 08 Dec 2020 05:35:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY Covid-19 Vaccine]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25341719">thread link</a>) | @alfongj
<br/>
December 7, 2020 | https://radvac.org/vaccine/ | <a href="https://web.archive.org/web/*/https://radvac.org/vaccine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content">

<div>
	<div id="primary">
		<main id="main" role="main">

			
<article id="post-9" class="page">
	<!-- .entry-header -->
	<div>
		




<ul><li><strong>Intranasally delivered.</strong> Very simple to self administer. No injection, no needles. </li><li><strong>Synthetic peptide epitopes / antigens</strong>. These peptides are small synthetically produced portions of viral sequences. A peptide-based vaccine is not infectious. We have selected these peptides as the basis for our vaccine against SARS-CoV-2. The antigen portion of the vaccine can be substituted by other antigens; for example, recombinant SARS-CoV-2 Spike RBD. By appropriate selection of antigens, the intranasal vaccine design described here can also be adapted for use against other viruses, especially respiratory viruses, such as influenza or non-SARS coronaviruses.</li><li><strong>Chitosan nanoparticle delivery</strong>. Chitosan is a form of chitin, which is found in mushrooms and the shells of crustaceans such as shrimp and crabs (seafood allergies are not allergies to chitin). Chitosan acts as both delivery vehicle and immunostimulatory adjuvant.</li><li><strong>Extremely simple and inexpensive preparation</strong> with easily obtained materials.</li><li><strong>Short-term safety. </strong>This type of vaccine has shown excellent safety in animal studies and human clinical trials. The RaDVaC vaccine has been used repeatedly over several months,  by over 100 self-experimenters, with the most extreme complication in some recipients of stuffy noses. </li></ul>



<p>Protocols for the simple and robust production of chitosan nanoparticle vaccines for intranasal delivery have been published for over two decades. Intranasal delivery of chitosan-based vaccines have shown mild side effects and high levels of efficacy of both mucosal and systemic immunity, when delivered in a prime-boost regimen (in both animal models and human trials). </p>



<p>Click <a href="https://radvac.org/materials-and-equipment/">here to see a list of essential <strong>Materials and equipment</strong></a></p>



<p>Click <a href="https://radvac.org/protocols-for-making-and-taking-the-vaccine">here to access <strong>Protocols for making and taking the vaccine</strong></a></p>



<p>Click <a href="https://radvac.org/white-paper/">here for access to our <strong>White Paper</strong></a>, which contains all relevant scientific details, methods and protocols</p>
	</div><!-- .entry-content -->
</article><!-- #post-9 -->

		</main><!-- #main -->
	</div><!-- #primary -->
</div><!-- .wrap -->


		</div><!-- #content -->

		<!-- #colophon -->
	</div></div>]]>
            </description>
            <link>https://radvac.org/vaccine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25341719</guid>
            <pubDate>Tue, 08 Dec 2020 04:18:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Game of Life ‚Äì Hexagonal Version]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25340971">thread link</a>) | @pjama
<br/>
December 7, 2020 | http://pjama.github.io/projects/life/ | <a href="https://web.archive.org/web/*/http://pjama.github.io/projects/life/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Although similar to the original Game of Life, the rules of these <a href="https://en.wikipedia.org/wiki/Cellular_automaton">cellular automata</a> allow cell state to take a continuous value between 0 and 1. Furthermore, the cell state depends on the state of its 6 neighbours, using averages and thresholds. Time remains discrete generations, and exhibits looping (cyclicity) after some initial sequence (depending on the initial conditions and the threshold values).</p><hr><p><a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Wikipedia</a>:</p><quote>The <em>Game of Life</em>, also known simply as <em>Life</em>, is a cellular automaton devised by the British mathematician John Horton Conway in 1970.</quote><quote>The game is a zero-player game, meaning that its evolution is determined by its initial state, requiring no further input. One interacts with the Game of Life by creating an initial configuration and observing how it evolves, or, for advanced players, by creating patterns with particular properties.</quote>
</div></div>]]>
            </description>
            <link>http://pjama.github.io/projects/life/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25340971</guid>
            <pubDate>Tue, 08 Dec 2020 02:33:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thinking in analogies is a powerful technique]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25340681">thread link</a>) | @satvikpendem
<br/>
December 7, 2020 | https://satvikpendem.com/blog/analogies | <a href="https://web.archive.org/web/*/https://satvikpendem.com/blog/analogies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Analogies are everywhere. Take from different fields to increase your perception of your own field.</p>
<p>I recently talked to a company growing and selling in-home hydroponic kits to grow crops in an apartment in the city for example, where most people do not have gardens like in suburbia. Given my experience in the startup world as well as in technology, I thought of their idea for some time and realized that there are quite a few business models that they can go towards, as they had the tech but didn't know how to progress it into an actual business.</p>
<p>Here's the list I came up with:</p>
<ul>
<li><strong>Infrastructure as a Service (IaaS)</strong> - Selling access to the infrastructure (but not the infrastructure itself) with which customers can then do whatever they want
<ul>
<li>Sell access to hydroponics kits (kits) for individuals, restaurants, companies (groups) to grow their own crops, but they have to maintain it themselves</li>
</ul>
</li>
<li><strong>Platform as a Service (PaaS)</strong> - Selling infrastructure with less control over the details but more ease of use for customers
<ul>
<li>Sell access to kits with certain crops already available, and groups can pick what they want to grow, and perhaps customize the crops and crop choice</li>
<li><em>Serverless</em> - Grow crops on demand based on needed capacity</li>
</ul>
</li>
<li><strong>Software as a Service (SaaS)</strong> - Selling access to the product without selling the infrastructure itself to run the product
<ul>
<li>Sell the crops themselves to groups so that they don't need to grow crops themselves</li>
<li>Boutique grocery stores</li>
<li>Delivery of crops on a regular basis</li>
<li>Delivery of meal kits on a regular basis with additional included groceries such as pasta or rice</li>
</ul>
</li>
<li><strong>Desktop as a Service (DaaS)</strong> - Sell remote access to the product
<ul>
<li>Monitor crops from anywhere with a web app or mobile app. The app could show crop yields, stats, expected time to delivery, expected time to expiration, et cetera</li>
<li>Complementary to the other models, not a replacement</li>
</ul>
</li>
<li><strong>On-premise</strong> - Sell the product to be deployed directly on the property of the customer, and sometimes maintain it for them
<ul>
<li>Grow the crops on the premises of the groups and maintain it for them</li>
</ul>
</li>
<li><strong>Self Service</strong> - Selling the infrastructure itself, not just access to it
<ul>
<li>Sell the kits themselves</li>
</ul>
</li>
<li><strong>Distributed Computing</strong> - Selling where the product usage occurs, oftentimes taking a percentage of every sale
<ul>
<li>Allow other people to grow crops and sell them locally</li>
<li>The crowdsourced Uber/Airbnb model</li>
</ul>
</li>
</ul>
<p>This list came up due to my experience in business and technology, but if I had expertise in other fields, then this list would've been different. Learn from different domains and create analogies between them to think of new ideas and combinations of those ideas.</p>
</div></div>]]>
            </description>
            <link>https://satvikpendem.com/blog/analogies</link>
            <guid isPermaLink="false">hacker-news-small-sites-25340681</guid>
            <pubDate>Tue, 08 Dec 2020 01:56:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5 Reasons Why the Live Video Meeting is Dead]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25340666">thread link</a>) | @Weet
<br/>
December 7, 2020 | https://beeweet.com/the-live-video-meeting-is-dead/ | <a href="https://web.archive.org/web/*/https://beeweet.com/the-live-video-meeting-is-dead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-skin="light"><div><div><div><div><div><div><div><div><div><div><div>


<div><div>
<div><div><div><p><img data-bg="false" data-imgratio="800:800" data-aspectratio="1" srcset="[&quot;.jpg https://beeweet.com/the-live-video-meeting-is-dead/800w%22,&quot;300x300.jpg https://beeweet.com/the-live-video-meeting-is-dead/300w%22,&quot;150x150.jpg https://beeweet.com/the-live-video-meeting-is-dead/150w%22,&quot;768x768.jpg https://beeweet.com/the-live-video-meeting-is-dead/768w%22]" data-src="https://mk0beeweetm91xp81pca.kinstacdn.com/wp-content/uploads/2020/10/Najette-fellache-300x300.jpg" data-path="https://beeweet.com/wp-content/uploads/2020/10/Najette-fellache" data-dims="[&quot;.jpg 800w&quot;,&quot;300x300.jpg 300w&quot;,&quot;150x150.jpg 150w&quot;,&quot;768x768.jpg 768w&quot;]" data-sizes="auto" data-parent-fit="cover" alt="Najette-fellache" src="https://mk0beeweetm91xp81pca.kinstacdn.com/wp-content/uploads/2020/10/Najette-fellache-300x300.jpg"></p></div></div></div></div></div>


<div><div>
<div><div><div><p><img data-bg="false" data-imgratio="1412:1084" data-aspectratio="1.3026" srcset="[&quot;.png https://beeweet.com/the-live-video-meeting-is-dead/1412w%22,&quot;300x230.png https://beeweet.com/the-live-video-meeting-is-dead/300w%22,&quot;1024x786.png https://beeweet.com/the-live-video-meeting-is-dead/1024w%22,&quot;768x590.png https://beeweet.com/the-live-video-meeting-is-dead/768w%22]" data-src="https://mk0beeweetm91xp81pca.kinstacdn.com/wp-content/uploads/2020/11/nolivevideomeeting-300x230.png" data-path="https://beeweet.com/wp-content/uploads/2020/11/nolivevideomeeting" data-dims="[&quot;.png 1412w&quot;,&quot;300x230.png 300w&quot;,&quot;1024x786.png 1024w&quot;,&quot;768x590.png 768w&quot;]" data-sizes="auto" data-parent-fit="cover" alt="nolivevideomeeting" src="https://mk0beeweetm91xp81pca.kinstacdn.com/wp-content/uploads/2020/11/nolivevideomeeting-300x230.png"></p></div></div></div></div></div><div><div><div><div><p><span>Let‚Äôs be frank : The live video meeting is dead !!!&nbsp;</span></p>
<p><span>The world has changed and nothing will be the same: Companies all around the world are shifting to remote work, employees have been adopting new work habits for more than 8 months now. So let‚Äôs be honest, employees won‚Äôt return to the office as before. Remote work is no longer a temporary situation. You have to create your future environment of work right now because it‚Äôs the new norm.&nbsp;</span></p>
<p><span>So when companies shift suddenly from a 100% office environment to a home environment, what do they do? They shift all their in person meetings to video meetings! Really?? Some even double down on it to be sure their employees are working!!</span></p>
<p><span>What happened? Zoom fatigue became the new popular hashtag and people were less productive and less engaged. And we are not talking about ‚ÄúZoom bombing‚Äù!</span></p>
<p><span>I think we have to completely reinvent the way of working, communicating, collaborating and learning in this new world and not just duplicate what we do in person in a digital form.</span></p>
<p><strong>I BELIEVE THAT THE FUTURE OF WORK IS ASYNC VIDEO COMMUNICATION.</strong></p>
<p><span>Async video meetings are all about optimizing your team‚Äôs time, and they are a great way to get information in front of people who don‚Äôt have availability for a meeting, or who are working remotely across multiple time zones. When you work in the way I do,having time to think on and internalize information before acting is critical.</span></p>
<p><span>Instead of coordinating schedules, opt to send a quick async video with key info that your remote colleagues can view during normal work hours.</span></p>
<p><span>Asynchronous communication allows people to first absorb and then act on information when they are able to, rather than the moment a piece of information is put in front of them.&nbsp;</span></p>
<p><span>Here are my 5 beliefs to embrace this new world&nbsp; :&nbsp;</span></p>
</div></div></div></div>


<div><div><div><p><h2>1. The remote worker is FREE, completely FREE</h2></p></div></div></div>


<div><div><div><div><p><span>Your employees are working remotely, they decide where and when. They are working from their personal environment, so you don‚Äôt oversee how they want to manage their time and where they can or want work. You don‚Äôt offer them a work environment anymore so you have to admit that you also lost this power.</span></p>
<p><span>If an employee wants to work from 5am and go hiking or kayaking by 2pm, he can do that!! Why not? Trust me, he will be much more productive.&nbsp;</span></p>
<p><span>Let‚Äôs talk about children: When you are working from home, you are sharing the same family space and property. You cannot ask them everyday ‚ÄúPlease be quiet, Iwill be on a zoom meeting.‚Äù</span></p>
<p><span>Seriously!! I am sure this generation will hate zoom meetings. They are synonyms to online school and now‚Äúmom and dad are not available‚Äù! You are physically here but not really here, it‚Äôs difficult for our loved ones. We need to take that in consideration and not impose our timing on others.&nbsp;</span></p>
<p><span>I encourage your people to work the hours that suit them and their lives, in the middle of what is a stressful time for everyone.</span></p>
<p><span>I think we need to be more respectful of each other‚Äôs time and not interrupt with alive meeting each time we need it.&nbsp;</span></p>
<p><span>We need to be more respectful of each others‚Äô home life: We enter each other‚Äôs personal space. It‚Äôs why weet captures a small portion of your background and you can even blur it.</span></p>
</div></div></div></div>


<div><div><div><p><h2>2. The remote worker is MORE PRODUCTIVE</h2></p></div></div></div>


<div><div><div><div><p><span>With asynchronous communication you allow yourself ‚Äì or your employees ‚Äì to put all energy into what you do each time and have better control over your workload.</span></p>
<p><span>In workplaces where asynchronous collaboration is reinforced and enabled with technology, productivity is higher. People can follow their agenda and complete daily tasks more easily when they are able respond to their colleagues‚Äô requests based on bandwidth or set up time slots throughout the week to prepare feedback for specific projects. Plus, by focusing their attention on one task at a time they have a more detailed look and bring in better results.</span></p>
</div></div></div></div>


<div><div><div><p><h2>3. Working remotely = HUMAN &amp; EMOTION</h2></p></div></div></div>


<div><div><div><div><p><span>It‚Äôs important to keep a human and emotional connection with our team and clients even if we cannot see them in person. I personally attach great importance to emotional communication where I can see facial expressions, hear a warm voice, and feel others‚Äô mood.&nbsp;</span></p>
<p><span>A lot can be lost in translation in writing, including empathy, body and facial language, and often the attention of the reader when it‚Äôs a long note.</span></p>
<p><span>Async videos accomplish a number of things that emails or text chat cannot. They create more of a human connection, which makes it easier to understand each other and makes it clear to the recipient that the ideas being shared are well understood. Async meetings are ideal for giving feedback, because empathy comes through much more clearly when you can see face-to-face or hear a warm voice.</span></p>
<p><span>You‚Äôll be surprised by the power of emojis in a video or just how a voice tonality can say a lot!&nbsp;</span></p>
<p><span>Every person is different and some are not comfortable with the camera. For this reason, we offer the capability to&nbsp; record without the camera but we always show a profile picture in all the videos: It‚Äôs a good way to keep a human connection.</span></p>
<p><span>And Weet offers the ability to add filters on your webcam to create a fun environment&nbsp; and make your teammates smile üòâ</span></p>
<p><span>We also discovered that&nbsp; async video gives a voice to those who are quieter. Contributing to live meetings can often rely on speaking skills of speed and volume, while async videos let people share their thoughts at their own pace.</span></p>
<p><span>While some people prefer reacting spontaneously others need time to think and video recordings accommodate both approaches to produce a clear ‚Äúleave-behind‚Äù that allows everyone to review feedback at their own speed. </span></p>
</div></div></div></div>


<div><div><div><p><h2>4. STOP CHAT &amp; LONG MEETINGS</h2></p></div></div></div>


<div><div><div><div><p><span>Working remotely equals working alone. It can be difficult to motivate yourself to concentrate.&nbsp;</span></p>
<p><span>Have you ever found it difficult to concentrate on your daily job duties after being interrupted by an unexpected casual chit-chat about a project your colleague is working on? It‚Äôs fine if this happens sometimes because mutual support and camaraderie is a critical part of being a team. But what if it interferes with your productivity?</span></p>
<p><span>Avoid being interrupted and interrupted for just asking a question.&nbsp; Divide your time between working time and communicating time.</span></p>
<p><a href="https://blog.doist.com/asynchronous-communication/"><span>Recent research</span></a><span> has shown that we live in a more collaborative era; We schedule our working day around meetings, Slack conversations and emails with our colleagues and sometimes these events could take up </span><a href="https://hbr.org/2016/01/collaborative-overload"><span>80% of a full working day</span></a><span>:&nbsp;</span></p>
<p><span>This can be detrimental to our performance; Technically we spend more time hopping from one meeting to another or replying to messages than focusing solely and mindfully on our tasks.</span></p>
<p><span>For example, I shut down all my notifications and connect only 4 times in the day to check my emails and my weets. What is great is that if someone needs to ask me a question and would need to do it in a live meeting, he can record it and I answer when I am available. You cannot imagine the freedom that it gives me and above all, the time I gain!&nbsp;</span></p>
<p><span>Why async video meetings are so effective : We talk faster than we type and we retain more information when delivery is via video. Plus people can review recorded videos at their own convenience.</span></p>
<p><span>I want to make a clarification : I am not saying to cut off all the live meetings (at least 2/3) but for those that are necessary, put 30min max in your agenda settings. It seems sometimes too short but you will see people will accomodate.</span></p>
</div></div></div></div>





<div><div><div><div><p><span>2020 has been a challenging year, no doubt. But one thing is clear ‚Äì the way we have adapted will inform how we work for years to come, empowering us all to do the best work of our lives. Allowing people to work at a time and a pace that suits them is key to this.</span></p>
<p><span>In this new remote world, we can hire anywhere in the globe. Embracing async collaboration allows companies to access a wider range of candidates and freelancers all around the world;</span></p>
</div></div></div></div>





<div><div><div><div><p><b>5 tips to embrace async video meetings :&nbsp;</b></p>
<p><span>1- the most important: Emphasize trust, organization &amp; independence: Evaluate people based on their results, not the number of hours spent online or number of emails.</span></p>
<p><span>2 ‚Äì Be cool with the video as a media: Not everyone is comfortable with a camera, communicate that it‚Äôs ok to cut off the webcam. You are not looking for perfection, just authenticity; Your employees can record their video as they talk in a real conversation.</span></p>
<p><span>3 ‚Äì Create an async culture mindset: Explain how it works, share the benefits, share some examples and ask top management to begin by creating some enthusiastic video messages and above all, share that in async communication, we don‚Äôt wait for an immediate answer.</span></p>
<p><span>4 ‚Äì Ask your employees and teammates for feedback: Does it work? What are their feelings?&nbsp;</span></p>
<p><span>5 ‚Äì Minimize the number of meetings you have, but don‚Äôt blacklist them.&nbsp; The async work communication stack looks something like this:</span></p>
<p><span>80% async video </span></p>
<p><span>15% live video meetings </span></p>
<p><span>5% physical meetings, e.g., annual company or team retreats</span></p>
</div></div></div></div><div><div>
<div><div><div><p><img data-bg="false" data-imgratio="960:540" data-aspectratio="1.7778" srcset="[&quot;.png https://beeweet.com/the-live-video-meeting-is-dead/960w%22,&quot;300x169.png https://beeweet.com/the-live-video-meeting-is-dead/300w%22,&quot;768x432.png https://beeweet.com/the-live-video-meeting-is-dead/768w%22]" data-src="https://mk0beeweetm91xp81pca.kinstacdn.com/wp-content/uploads/2020/11/Vision-Future-of-work-300x169.png" data-path="https://beeweet.com/wp-content/uploads/2020/11/Vision-Future-of-work" data-dims="[&quot;.png 960w&quot;,&quot;300x169.png 300w&quot;,&quot;768x432.png 768w&quot;]" data-sizes="auto" data-parent-fit="cover" alt="Vision Future of work" src="https://mk0beeweetm91xp81pca.kinstacdn.com/wp-content/uploads/2020/11/Vision-Future-of-work-300x169.png"></p></div></div></div></div></div><div><div><div><div><p>If you enjoyed this article we would love to you share it with others üôÇ</p>
<p><a href="https://beeweet.com/collaborating-effectively-a-guide-to-asynchronous-communication/">Discover our guide to async communication</a></p>
</div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://beeweet.com/the-live-video-meeting-is-dead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25340666</guid>
            <pubDate>Tue, 08 Dec 2020 01:54:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Drive My Robot]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25340599">thread link</a>) | @tomjacobs
<br/>
December 7, 2020 | http://teleportconnect.com/teleport.html | <a href="https://web.archive.org/web/*/http://teleportconnect.com/teleport.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

  <div>

    <center>
    <a href="http://teleportconnect.com/"><img src="http://teleportconnect.com/img/teleport_logo.png"></a>
    &nbsp;<a href="http://teleportconnect.com/">About</a> | 
    &nbsp;<a href="https://www.tindie.com/products/teleport/teleport">Buy a Teleport</a>
    </center>

    <!--
    <script>
    	var player = new WSAudioAPI.Player({
        server: {
            host: window.location.hostname,
            port: 5000
	}});
    </script>

    <script>
    	var streamer = new WSAudioAPI.Streamer({
        server: {
            host: window.location.hostname, 
            port: 5000 
	}});
    </script>
    <button onclick="player.start()">Play stream</button>
    <button onclick="player.stop()">Stop playing</button>
    <button onclick="streamer.start()">Start stream</button>
    <button onclick="streamer.stop()">Stop stream</button>
    -->

    <div>

      <!-- Asleep? -->
      

      <div>

        <!-- Video canvas -->
        

      </div>

      <div>
       

    <!-- List of tracks -
    <div id="tracksTitle" style="background:#AAFDCC;">Tracks</div>
    <div id="tracks" style="background:#DDFFDD;"></div><br>-->

    <!-- List of devices online -->
    
    

    </div>

    </div>

    

</div></div>]]>
            </description>
            <link>http://teleportconnect.com/teleport.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25340599</guid>
            <pubDate>Tue, 08 Dec 2020 01:47:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cemetery of Soviet Computers]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25340452">thread link</a>) | @detaro
<br/>
December 7, 2020 | https://rusue.com/cemetery-of-soviet-computers/ | <a href="https://web.archive.org/web/*/https://rusue.com/cemetery-of-soviet-computers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>The building did not stand out. Unremarkable industrial building, which was built in hundreds of Soviet cities.<span id="more-10215"></span></p>
<p>Non-broken glass, burning lights, live plants inside, modern plastic entrance doors. Except for one floor.</p>
<!-- WP QUADS Content Ad Plugin v. 2.0.17.1 -->


<p>Despite the twilight, the floor remained lifelessly dark. Somewhere in the depths, there was a dim glow of electric light, hardly penetrating through old glass blocks.</p>
<p>Inside the floor was empty and black, but not completely.&nbsp;Inside burned several fluorescent lamps, spotlighting dozens of silhouettes of tall cabinets.</p>
<p>Some of them were covered with darkened translucent film.</p>
<p>The surface of the floor, tables and enclosures covered with black spots of soot, sometimes diluted with white stains of dried extinguishing mixture.</p>
<p>The air felt a persistent, but not strong smell of burning.&nbsp;The fire walked here a few years ago but did not touch the equipment.</p>
<p>Part of the cabinets were antique electronic computers. Others served to measure signals, and computers controlled this process. Dozens of terminals froze on the tables with extinct screens.</p>

<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?resize=360%2C270&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?resize=1050%2C1438&amp;ssl=1" alt="" width="1050" height="1438" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?resize=219%2C300&amp;ssl=1 219w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?resize=768%2C1052&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?resize=748%2C1024&amp;ssl=1 748w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?resize=360%2C493&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?resize=545%2C746&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?resize=360%2C270&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p>Suddenly it became clear that before them the legendary machine ‚ÄúSaratov-2‚Äù.&nbsp;The machine, which was massively placed on many enterprises of the Soviet Union in the 70s, but at the same time, not a single high-quality (I‚Äôm not talking about color) photos remained. Not on the Internet, not even in the museum of the enterprise developer.</p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/4-1.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/4-1.jpg?resize=1050%2C1400&amp;ssl=1" alt="" width="1050" height="1400" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/4-1.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/4-1.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/4-1.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/4-1.jpg?resize=360%2C480&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/4-1.jpg?resize=545%2C727&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/5.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/5.jpg?resize=1050%2C1400&amp;ssl=1" alt="" width="1050" height="1400" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/5.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/5.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/5.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/5.jpg?resize=360%2C480&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/5.jpg?resize=545%2C727&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p>This computer did not even have a traditional microprocessor. Domestic clone of the popular American PDP-8, Saratov-2 was produced in two versions.</p>
<p>Steel frame, like a chest of drawers, filled with drawers.&nbsp;Different boxes responded to various computer nodes ‚Äî a twelve-bit computing unit, input-output device interfaces, and RAM.</p>
<p>The memory was ferromagnetic ‚Äì two boxes of four cubes in each. Reading or writing programs occurred through punched tapes, and to display the results of calculations used electric typewriter CONSUL-260.</p>
<p>The monitor and keyboard in that era were not yet a much-needed</p>
<p>part of the computer. The necessary input of programs into the operative memory was carried out in binary codes, manually using a group of switches on the front panel. Bulbs controlled the correctness of the input.</p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?resize=360%2C270&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?resize=1050%2C773&amp;ssl=1" alt="" width="1050" height="773" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?resize=300%2C221&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?resize=768%2C565&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?resize=1024%2C754&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?resize=360%2C265&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?resize=545%2C401&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?resize=1050%2C774&amp;ssl=1" alt="" width="1050" height="774" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?resize=300%2C221&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?resize=768%2C566&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?resize=1024%2C755&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?resize=360%2C265&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?resize=545%2C402&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?ssl=1"><img loading="lazy" src="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?resize=1050%2C1088&amp;ssl=1" alt="" width="1050" height="1088" srcset="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?w=1050&amp;ssl=1 1050w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?resize=290%2C300&amp;ssl=1 290w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?resize=768%2C796&amp;ssl=1 768w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?resize=988%2C1024&amp;ssl=1 988w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?resize=360%2C373&amp;ssl=1 360w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?resize=545%2C565&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?resize=1050%2C828&amp;ssl=1" alt="" width="1050" height="828" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?resize=300%2C237&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?resize=768%2C606&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?resize=1024%2C807&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?resize=360%2C284&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?resize=545%2C430&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?resize=360%2C270&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p>The next generation of computers was Electronics 100/25. These machines were clones of American PDP-11.</p>
<p>They thought faster, had more memory, allowed them to work with magnetic tape drives and punched tapes, but the general principle remained the same.</p>
<p>It was possible to connect a monitor and a keyboard to this computer, while still having the ability to enter programs through the front switches.</p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?resize=1050%2C778&amp;ssl=1" alt="" width="1050" height="778" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?resize=300%2C222&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?resize=768%2C569&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?resize=1024%2C759&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?resize=360%2C267&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?resize=545%2C404&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?ssl=1"><img loading="lazy" src="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?w=1050&amp;ssl=1 1050w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?resize=768%2C576&amp;ssl=1 768w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?resize=200%2C150&amp;ssl=1 200w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?resize=360%2C270&amp;ssl=1 360w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<!-- WP QUADS Content Ad Plugin v. 2.0.17.1 -->


<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?resize=1050%2C801&amp;ssl=1" alt="" width="1050" height="801" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?resize=300%2C229&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?resize=768%2C586&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?resize=1024%2C781&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?resize=360%2C275&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?resize=545%2C416&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p>Electronics-60 ‚Äì the further development of Electronics 100/25. The same architecture, but bulky tape drives are a thing of the past.</p>
<p>They were replaced by flexible eight-inch floppy disks. The new chipset, allowed to fit the processor module, power supply and control devices, in a very compact size.</p>
<p>I note that all these computers were managers, that is, they worked with a bunch of external equipment. It could be machine tools, laboratory complexes, measuring devices.</p>
<p><a href="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?ssl=1"><img loading="lazy" src="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?resize=1050%2C779&amp;ssl=1" alt="" width="1050" height="779" srcset="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?w=1050&amp;ssl=1 1050w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?resize=300%2C223&amp;ssl=1 300w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?resize=768%2C570&amp;ssl=1 768w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?resize=1024%2C760&amp;ssl=1 1024w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?resize=360%2C267&amp;ssl=1 360w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?resize=545%2C404&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a> <a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?resize=1050%2C1385&amp;ssl=1" alt="" width="1050" height="1385" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?resize=227%2C300&amp;ssl=1 227w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?resize=768%2C1013&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?resize=776%2C1024&amp;ssl=1 776w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?resize=360%2C475&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?resize=545%2C719&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?ssl=1"><img loading="lazy" src="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?resize=1050%2C1418&amp;ssl=1" alt="" width="1050" height="1418" srcset="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?w=1050&amp;ssl=1 1050w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?resize=222%2C300&amp;ssl=1 222w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?resize=768%2C1037&amp;ssl=1 768w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?resize=758%2C1024&amp;ssl=1 758w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?resize=360%2C486&amp;ssl=1 360w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?resize=545%2C736&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p>15VM16-1 some early version of Electronics-60, having a control panel of light bulbs and switches. Assembled on the element base of the previous Electronics 100/25. I occupied a small nightstand built into the table on which the controlled equipment was placed.</p>
<p><a href="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?ssl=1"><img loading="lazy" src="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?resize=1050%2C858&amp;ssl=1" alt="" width="1050" height="858" srcset="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?w=1050&amp;ssl=1 1050w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?resize=300%2C245&amp;ssl=1 300w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?resize=768%2C628&amp;ssl=1 768w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?resize=1024%2C837&amp;ssl=1 1024w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?resize=360%2C294&amp;ssl=1 360w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?resize=545%2C445&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a> <a href="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?ssl=1"><img loading="lazy" src="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?resize=1050%2C814&amp;ssl=1" alt="" width="1050" height="814" srcset="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?w=1050&amp;ssl=1 1050w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?resize=300%2C233&amp;ssl=1 300w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?resize=768%2C595&amp;ssl=1 768w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?resize=1024%2C794&amp;ssl=1 1024w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?resize=360%2C279&amp;ssl=1 360w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?resize=545%2C423&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p>DVK-2M or Interactive Computing Complex. Massive, stylish in appearance, the computer of the 80s, which could be considered a personal computer.</p>
<p>It consisted of two desktop blocks ‚Äì processor and pairing. A set of interchangeable interface cards allowed connecting drives of various types, a monochrome monitor on an openwork leg, and a keyboard.</p>
<p>Back in 1993, when we were studying, one teaching DVK could distribute programs for a couple of dozen Spectrums through the network.</p>
<p><a href="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?ssl=1"><img loading="lazy" src="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?w=1050&amp;ssl=1 1050w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?resize=768%2C576&amp;ssl=1 768w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?resize=200%2C150&amp;ssl=1 200w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?resize=360%2C270&amp;ssl=1 360w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?ssl=1"><img loading="lazy" src="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?w=1050&amp;ssl=1 1050w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?resize=768%2C576&amp;ssl=1 768w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?resize=200%2C150&amp;ssl=1 200w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?resize=360%2C270&amp;ssl=1 360w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?ssl=1"><img loading="lazy" src="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?w=1050&amp;ssl=1 1050w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?resize=768%2C576&amp;ssl=1 768w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?resize=200%2C150&amp;ssl=1 200w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?resize=360%2C270&amp;ssl=1 360w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p>The DVK-3 in the monoblock plastic case is the next stage of the DVK-2M.</p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?resize=1050%2C790&amp;ssl=1" alt="" width="1050" height="790" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?resize=768%2C578&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?resize=1024%2C770&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?resize=360%2C270&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?resize=545%2C410&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?ssl=1"><img loading="lazy" src="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?resize=1050%2C811&amp;ssl=1" alt="" width="1050" height="811" srcset="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?w=1050&amp;ssl=1 1050w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?resize=300%2C232&amp;ssl=1 300w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?resize=768%2C593&amp;ssl=1 768w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?resize=1024%2C791&amp;ssl=1 1024w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?resize=360%2C278&amp;ssl=1 360w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?resize=545%2C421&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a> <a href="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?ssl=1"><img loading="lazy" src="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?resize=1050%2C740&amp;ssl=1" alt="" width="1050" height="740" srcset="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?w=1050&amp;ssl=1 1050w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?resize=300%2C211&amp;ssl=1 300w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?resize=768%2C541&amp;ssl=1 768w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?resize=1024%2C722&amp;ssl=1 1024w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?resize=360%2C254&amp;ssl=1 360w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?resize=545%2C384&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://ralphmirebs.livejournal.com/226286.html" target="_blank" rel="noopener noreferrer">Source</a></p>
<div><!--Yasr Visitor Votes Shortcode--><div id="yasr_visitor_votes_10215"><p>Our Reader Score</p><p><span data-postid="10215" id="yasr-total-average-dashicon-10215"></span><span id="yasr-total-average-text-1f9d49f182765">Total: <span id="yasr-vv-votes-number-container-1f9d49f182765">83</span>  Average: <span id="yasr-vv-average-container-1f9d49f182765">4.8</span></span></p></div><!--End Yasr Visitor Votes Shortcode--></div>
<!-- WP QUADS Content Ad Plugin v. 2.0.17.1 -->


</div></div>]]>
            </description>
            <link>https://rusue.com/cemetery-of-soviet-computers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25340452</guid>
            <pubDate>Tue, 08 Dec 2020 01:29:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: In-App Purchases API for web apps]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25340219">thread link</a>) | @ent101
<br/>
December 7, 2020 | https://www.outpan.com/docs/monetization/in-app-purchases | <a href="https://web.archive.org/web/*/https://www.outpan.com/docs/monetization/in-app-purchases">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In-App Purchases (IAP) allow you to build customized purchase experiences for your apps. Using our dead-simple JavaScript API you can ask the user to make purchases dynamically based on your own requirements.</p>
<h2>Adding In-App Products</h2>
<p>To enable IAPs in your app, first, you need to define at least one In-App Product for your app,</p>
<ol>
<li>Go to your <a href="https://www.outpan.com/dev/apps">Developer Dashboard</a>.</li>
<li>Choose the app you would like to enable In-App Purchases for.</li>
<li>From the dashboard page for the selected app, choose <strong>In-App Products</strong>. </li>
<li>Select <strong>New Product</strong> and enter your product's <strong>Name</strong>, <strong>SKU</strong>, and <strong>Price</strong>. Then select <strong>Add Product</strong>.</li>
</ol>
<h2>In-App Purchases in your app</h2>
<ol>
<li>
<p>Add the Outpan JS library to the <code>&lt;head&gt;</code> element of your HTML:</p>
<pre><code>&lt;script type="text/javascript" src="https://js.outpan.com/v1/"&gt;&lt;/script&gt;</code></pre>
</li>
<li>
<p>At the desired point in your application, call the <code>OPRequestPayment</code> function to ask for payment from the user:</p>
<pre><code>OPRequestPayment('SKU-0001', function(resp){
  if(resp.success)
    alert('Payment succeeded.');
  else
    alert('Payment failed.');
});</code></pre>
</li>
</ol></div></div>]]>
            </description>
            <link>https://www.outpan.com/docs/monetization/in-app-purchases</link>
            <guid isPermaLink="false">hacker-news-small-sites-25340219</guid>
            <pubDate>Tue, 08 Dec 2020 01:07:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spend your money where you spend your time]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25339736">thread link</a>) | @mcrittenden
<br/>
December 7, 2020 | https://critter.blog/2020/12/07/spend-your-money-where-you-spend-your-time/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/12/07/spend-your-money-where-you-spend-your-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-4015">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>5 years ago, I bought some new glasses. I found a cheap $60 frame and I was proud. I‚Äôve worn those glasses every waking hour for the last 5 years, which adds up to about 30,000 hours. They‚Äôre slightly uncomfortable and I have to push them back up on my nose a few times an hour, but I make do because you can‚Äôt argue with that price!</p>



<p>Meanwhile, I recently bought a new minivan to lug the kids around. I could have made do with one for $10,000-ish less, but I wanted a nice shiny one with a DVD player and all that. I use it maybe 30 minutes a day. </p>



<p>I‚Äôm realizing lately how backwards that logic is. I saved a couple hundred bucks on glasses and <a href="https://critter.blog/2020/11/06/all-self-help-boils-down-to-choose-long-term-over-short-term/">cursed myself with 30,000 hours</a> of discomfort and annoyance. And I spent an extra $10,000 on something that I barely even use compared to those dang glasses.</p>



<p>I think it makes sense to spend our money where we spend our time. What are the things we spend the most time with? Glasses, shoes, a computer and desk and chair, a bed, a belt, whatever it is. Even if one of those things is <em>slightly</em> worse than it could be, when you multiply that by <a href="https://critter.blog/2020/11/04/what-we-have-left/">a bajillion hours of usage</a>, it explodes.</p>



<p>Say that I had spent $500 on a pair of glasses that felt great. That‚Äôs an increase of $440. Divide $440 by 30,000 hours, and it turns out that I‚Äôd be paying about 1 penny per hour for that added comfort. No brainer, right? </p>



<p>Now let‚Äôs look at the car. If I use that car for 7 years that‚Äôs about 1300 hours of driving time. That means that the extra $10,000 comes out to about $7.70 per hour. I‚Äôm paying minimum wage to no one in exchange for access to a DVD player we barely use and a van that looks a little nicer.</p>



<p>Never again. Never again will I skimp on glasses and splurge on a car. I don‚Äôt even have a commute!</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/12/07/spend-your-money-where-you-spend-your-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25339736</guid>
            <pubDate>Tue, 08 Dec 2020 00:23:08 GMT</pubDate>
        </item>
    </channel>
</rss>
