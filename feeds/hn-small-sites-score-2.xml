<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 28 Aug 2020 12:31:10 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 28 Aug 2020 12:31:10 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Thoughts on 2 Years as a Remote Robotics Consultant]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24280204">thread link</a>) | @msadowski
<br/>
August 26, 2020 | https://msadowski.github.io/2-years-remote-consulting/ | <a href="https://web.archive.org/web/*/https://msadowski.github.io/2-years-remote-consulting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
            <p><img src="https://msadowski.github.io/images/M_consulting_cropped.png" alt="Thoughts on 2 Years as a Remote Robotics Consultant">
              
            </p>
        
      
      <p>It’s that time of year again when I’m thinking back on the journey I set up for myself by deciding to go into Robotics Consulting. This article is a follow up to the blog post I wrote <a href="https://msadowski.github.io/one-year-of-robotics-consulting/">last year</a>. This year, I’ve decided to try and cover the most important aspects of what I’m doing, and how it has been working out for me.</p>

<!-- more -->

<h2 id="the-work-i-had">The work I had</h2>

<p>I’m very grateful for the kind of work that I do - it feels amazing doing what I love and getting paid for it. I would never change my work for anything else. Every single one of my clients has an interesting problem to solve, and I’m yet to get my first negative experience working with someone. Looking back on all my clients, I’ve worked with many interesting people all around the world, mostly helping them to develop software for mobile robots and drones.</p>

<figure>
    <img src="https://msadowski.github.io/images/2_yr_consulting/clients.png" alt="Map with 22 Clients I had all over the world">
    <figcaption>A world map of the 22 clients I've worked with over the past 2 years</figcaption>
</figure>

<figure>
    <img src="https://msadowski.github.io/images/2_yr_consulting/clients_europe.png" alt="Image showing 8 of my clients in Europe">
    <figcaption>My European clients</figcaption>
</figure>

<p>The duration of the projects I take on are between half a day and 2.5 years long. Everything depends on the client and what they require. Most of my projects kick off with a consultation - helping the client to solve a particular problem by sharing my expertise and experience. After this initial phase, some of the clients decide to hire me as a contractor, helping their technical team solve the challenges they face, while others are happy to carry on working by themselves with the advice received.</p>

<p>As a tangent to the consultations, I also help evaluate robotics funding proposals, as a reviewer in EU technological funding projects <a href="http://www.esmera-project.eu/welcome/">ESMERA</a> and <a href="https://trinityrobotics.eu/">TRINITY</a>, making sure your tax euros are spent on truly cutting-edge projects.</p>

<h3 id="putting-myself-in-my-clients-shoes">Putting myself in my clients’ shoes</h3>

<p>Every project I take on, I treat as my own. This results in me trying to solve issues before they happen, and sometimes even pushing back on client’s decisions - “How about we don’t remove this safety feature?”. Another side effect of treating the project as my own is that I put the client first, before my own business interest, meaning I might earn less for the project overall.</p>

<p>As an example, I was hired to test the idea a client had for a robotic project. The idea turned out to be borderline feasible, with currently available technology, but potentially requiring lots of R&amp;D work. If I sold the project as “no problem, it’s totally doable”, I would definitely get more work supporting the R&amp;D work required. By putting the project and client’s interests first, however, we finished the project after the feasibility study, having realised the extent of R&amp;D work needed.</p>

<p>Since terminating such a project before going to an R&amp;D phase is something I would do, I’m content and the client is most likely even more so, since they don’t have to spend lots of money, not understanding the R&amp;D effort required. Instead, they can decide whether to pursue the idea further. If the client does decide to take a risk, they know that I’ll be there, ready to treat their project as my own, and providing honest advice, even if it means I get less work from it.</p>

<h3 id="the-hardware">The hardware</h3>

<p>Working with hardware is one of the most enjoyable parts of my job. This year, I’ve been focusing a lot on RTK solutions (I have one blog post in the works on a neat RTK setup). Also this year, I finally got my hands on a multi-plane LiDAR, something I’ve been very keen on ever since Velodyne revealed their first multi-plane units.</p>

<figure>
    <img src="https://msadowski.github.io/images/2_yr_consulting/hardware.png" alt="Hardware units I've worked with">
    <figcaption> Some of the hardware I've worked with since I started working as a Remote Robotics Consultant</figcaption>
</figure>

<h2 id="the-work-i-did-not-win">The Work I Did Not Win</h2>

<h3 id="the-dream-project">The dream project</h3>

<p>At one point, I was approached by a client who wanted to create a certain type of robot that I’ve always dreamt of working with. The task would require me to liaise with manufacturers and developers to get the robot ready, and enable support for autonomous navigation in various terrain types. In short, a hugely challenging project that would immensely help me grow, whilst being super fun at the same time. When discussing the project in more detail, I noticed that the budget for this client was not an issue - any platform for any price was OK, as long as it met the requirements. However, when asking follow up questions, it became clear that the project target was to equip robots with weapons.</p>

<figure>
<video controls="controls">
    <source src="https://msadowski.github.io/images/2_yr_consulting/bd.mp4" type="video/mp4">
</video>
<figcaption>The kind of project I’m not keen to work on. Source: <a href="https://www.youtube.com/watch?v=y3RIHnK0_NE">Bosstown Dynamics</a> (Corridor Digital)
</figcaption>
</figure>

<p>When I was applying to University, I promised myself I would not work on weapons, even if these projects have a virtually unlimited budget. I figured that even if I was to fold my consultancy, I would rather do that than compromise on my values.</p>

<h3 id="the-bargain">The bargain</h3>

<p>In the two years working as a Robotics Consultant, I’ve noticed a pattern: the more a potential client bargains before starting the job, the more bargaining and complaining will follow, resulting in an unpleasant experience for everyone involved. In the same bucket as bargaining clients are the UpWork projects that want you to create a SLAM library from scratch for a fixed price of $50. These days, I tend to reject these types of clients and contracts straight away, saving everyone’s time.</p>

<h3 id="watch-out-for-the-legal-stuff">Watch out for the legal stuff</h3>

<p>If I’m receiving 25 pages of legal documents to review before engaging with a customer, it’s a  potential red flag. I don’t mind reading legal documents, but I would rather not involve a lawyer before even starting a project. For me, a huge red flag is when a potential client adds a very vaguely described 3-year non-compete clause, covering a whole industry. I find such terms too restrictive and would never take a project on like this, unless the project also paid for a 3 year holiday after wrapping everything up!</p>

<h3 id="the-lack-of-expertise">The lack of expertise</h3>

<p>As much as I would love to know everything about Robotics, it’s not likely to happen anytime soon. I will never take on projects that fall outside of my expertise (for example, algorithms for soft robotics), unless the client is persistent and understands an R&amp;D process. My go-to advice in such cases is that it’s not feasible to pay my high rates for me to catch up on the topic. In a hypothetical situation, if the project falls outside of my expertise, but it’s in an area I’m planning to pursue, I’d offer a very low rate for the project, highlighting that I will need to do some catching up.</p>

<h2 id="remote-robotics">Remote Robotics</h2>

<p>People often ask me how I work on robotics projects remotely (I’ve been doing this since day 1 of my consultancy). When I’m doing some high level work, it’s usually not an issue. It only becomes slightly more problematic with hardware-oriented projects. The options I’ve tested so far are:</p>

<ul>
  <li>For ROS systems, working with bag files, and in the case of drones, working with log files</li>
  <li>Clients shipping the hardware to me</li>
  <li>Travelling to the client’s location</li>
  <li>Remote control</li>
</ul>

<figure>
    <img src="https://msadowski.github.io/images/2_yr_consulting/office.jpg" alt="My office in the times of pandemic">
    <figcaption>Me and my partner's office in the time of the COVID-19 pandemic</figcaption>
</figure>

<p>ROS is absolutely the best thing that happened to people like me - I can easily review things online and even develop software with just <a href="http://wiki.ros.org/rosbag">bagfiles</a>. However, it’s not always feasible to work with bags, especially if you need to do some work related to sensors and actuators. In these cases, clients will often ship their hardware to me, so that I can integrate it locally. A very convenient way to work with clients in this way is to use a temporary import - it saves you the risk of paying taxes and duties for the expensive robotics parts, and as far as I know when doing a temporary import, you can keep the items for up to a year.</p>

<p>Travelling to the client’s location usually results in a couple of days of a hackathon solving issue. I love these, as it allows me to put the faces to Slack usernames, and I like the dynamics of these kinds of projects. On the flip side, the last time I did it, I ended up doing about 60 hours of work in 5 days - not very feasible, especially as you need to rest for a couple of days afterwards, but I would do it again!</p>

<p>Remote control of the client’s desktop is something that I try to avoid as much as possible when working with hardware. I find that not having physical access to the components is often very limiting (“can you please unplug the cable for me?”) and I estimate that in the worst cases, you are 20-40% less productive by working on robotics in this way.</p>

<h2 id="other-thoughts-on-consultancy-and-self-employment">Other Thoughts on Consultancy and Self-Employment</h2>

<h3 id="freedom">Freedom</h3>

<p>Freedom is one of the most important aspects of what I do. If I don’t work with hardware for a project, then I can usually work from whatever place I want. If I have a day when I don’t feel like working, or can’t work, then taking a day off is not an issue. To an extent, I can choose whichever projects to work on (or at least to which I can say “no” to).</p>

<figure>
    <img src="https://msadowski.github.io/images/2_yr_consulting/outdoors.jpg" alt="A mountain view">
    <figcaption>Having a possibility to go out into the mountains in the middle of the week is something I appreciate a lot</figcaption>
</figure>

<p>This freedom, however, comes with a price attached to it - if I’m not working, then I’m not making money. I don’t get bank holidays and if I get sick and can’t work, then I’m not earning either. These are the main reasons why I think working for oneself is not for everybody, especially when having no projects lined up, as it can become quite stressful.</p>

<p>Being self-employed means that you are at the centre of your business. For me, this means that my physical and mental health are my number one priorities. Examples of how I exercise these are:</p>
<ul>
  <li>Three times a week, around 4pm, I do sports (normally, I go to the gym, but during the pandemic, I’ve been going for a run)</li>
  <li>Practising meditation as the first thing I do in the morning</li>
  <li>In case of health issues, I look to fix them without thinking twice about the money (being located in Europe is a huge advantage here as I know no doctor’s visit will ruin me, financially)</li>
</ul>

<h3 id="upwork">Upwork</h3>

<p>Over the past year, most of my work has come from Upwork (you can see my profile <a href="https://www.upwork.com/freelancers/~0196b3ccb97605e632">here</a>). I won’t repeat the things I said <a href="https://msadowski.github.io/one-year-of-robotics-consulting/#upwork">last year</a> - I’ve grown to appreciate the service. I realised that the 20% fee for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://msadowski.github.io/2-years-remote-consulting/">https://msadowski.github.io/2-years-remote-consulting/</a></em></p>]]>
            </description>
            <link>https://msadowski.github.io/2-years-remote-consulting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280204</guid>
            <pubDate>Wed, 26 Aug 2020 07:57:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[High-Resolution Controllable Face Aging with Generative Adversarial Networks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24280145">thread link</a>) | @Despoisj
<br/>
August 26, 2020 | https://despoisj.github.io/AgingMapGAN/ | <a href="https://web.archive.org/web/*/https://despoisj.github.io/AgingMapGAN/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <h2 id="agingmapgan-amgan-high-resolution-controllable-face-aging-with-spatially-aware-conditional-gans">AgingMapGAN (AMGAN): High-Resolution Controllable Face Aging with Spatially-Aware Conditional GANs</h2>



<p>
  <img width="40%" src="https://despoisj.github.io/AgingMapGAN/img/loreal_research.png">
</p>

<h2 id="video-summary">Video Summary</h2>
<iframe width="840" height="472.5" src="https://www.youtube.com/embed/HMZiSVKXkWo" frameborder="0" allow="encrypted-media; picture-in-picture" allowfullscreen=""></iframe>

<h2 id="abstract">Abstract</h2>
<p>Existing approaches and datasets for face aging produce results skewed towards the mean, with individual variations and expression wrinkles often invisible or overlooked in favor of global patterns such as the fattening of the face. Moreover, they offer little to no control over the way the faces are aged and can difficultly be scaled to large images, thus preventing their usage in many real-world applications. To address these limitations, we present an approach to change the appearance of a high-resolution image using ethnicity-specific aging information and weak spatial supervision to guide the aging process. We demonstrate the advantage of our proposed method in terms of quality, control, and how it can be used on high-definition images while limiting the computational overhead.</p>

<h3 id="paper--supplementary-materials">Paper &amp; Supplementary Materials</h3>
<div>
    <p><a href="https://arxiv.org/abs/2008.10960" target="_blank">
            <img src="https://despoisj.github.io/AgingMapGAN/img/paper_thumbnail.jpg">
        </a>
    </p>
    <div>
        <p><span>J. Despois, F. Flament, M. Perrot</span><br>
            <span>
                <b>AgingMapGAN (AMGAN): High-Resolution Controllable Face Aging with Spatially-Aware Conditional GANs.</b>
            </span>
            <br>
            <span>ECCV, 2020 (AIM Workshop Oral)</span>
            <span><a href="https://arxiv.org/abs/2008.10960" target="_blank">[arXiv]</a>&nbsp;<a href="https://despoisj.github.io/AgingMapGAN/bibtex.txt" target="_blank">[BibTeX]</a>&nbsp;<a href="https://despoisj.github.io/AgingMapGAN/supplementary_materials.pdf" target="_blank">[Supplementary Materials]</a></span>
        </p>
    </div>
</div>

<h2 id="model">Model</h2>
<p>Our model takes a patch <em>p</em> from the input image <em>I</em>, a target aging map <em>A</em>, and two orthonogal gradient images <em>X</em> and <em>Y</em>. The image patch <em>I<sub>p</sub></em> is then transformed according to the local aging information contained in the map <em>A<sub>p</sub></em>, while the orthogonal gradients <em>X<sub>p</sub></em> and <em>Y<sub>p</sub></em> provide the coordinates of the patch in a fully-convolutional manner. The conditions are injected in the generator via the SPADE block to preserve the spatial information. Finally, the generator uses an attention mechanism to only change relevant parts of the image, thus preserving the clothes, earrings and other facial features unrelated to aging.</p>

<p>
  <img width="70%" src="https://despoisj.github.io/AgingMapGAN/img/model_hd.jpg">
</p>

<h2 id="training">Training</h2>
<p>To train our model, we use four different losses: <em>L<sub>Age</sub></em> to penalize the aging map estimation, <em>L<sub>Loc</sub></em> for the patch localization, <em>L<sub>WGAN</sub></em> for the realism of the generated images, and <em>L<sub>Cyc</sub></em> for the fidelity to the original image.</p>

<p>
  <img width="70%" src="https://despoisj.github.io/AgingMapGAN/img/training_hd.jpg">
</p>

<h2 id="results">Results</h2>
<h3 id="supervised-high-resolution-standardized-dataset">Supervised: High-Resolution Standardized Dataset</h3>
<p>We have labeled 7000 images, using 15 clinical aging signs for each image, in order to build accurate ethnicity-specific aging maps for each individual. On this dataset, our model is able to generate aged and rejuvenated faces with complete control over the localization and amount of aging.</p>

<p>We recommend viewing the videos in full-screen to see the generated HD images (1024px).</p>
<p>
    <video controls="">
      <source src="https://despoisj.github.io/AgingMapGAN/img/cau.mov">
    Your browser does not support the video tag.
    </video>
    <video controls="">
      <source src="https://despoisj.github.io/AgingMapGAN/img/ind.mov">
    Your browser does not support the video tag.
    </video>
    <video controls="">
      <source src="https://despoisj.github.io/AgingMapGAN/img/aam.mov">
    Your browser does not support the video tag.
    </video>
    <video controls="">
      <source src="https://despoisj.github.io/AgingMapGAN/img/chi.mov">
    Your browser does not support the video tag.
    </video>
</p>

<p>We recommend opening the images in a new tab to see the details.</p>
<p>
  <img width="100%" src="https://despoisj.github.io/AgingMapGAN/img/ours_chi1_cropped.jpg">
</p>
<p>
  <img width="100%" src="https://despoisj.github.io/AgingMapGAN/img/ours_cau1_cropped.jpg">
</p>

<h3 id="weakly-supervised-ffhq">Weakly-Supervised: FFHQ</h3>
<p>To train our model on the FFHQ dataset, we have created labels in a weakly-supervised fashion, using regression models trained on our labeled dataset. Despite this and the challenging poses, occlusions and lighting conditions of the dataset, our approach successfully ages and rejuvenates images in high-definition.</p>

<p>We recommend opening the images in a new tab to see the details.</p>
<p>
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_cau1.jpg">
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_chi1.jpg">
</p>
<p>
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_afr1.jpg">
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_cau5.jpg">
</p>
<p>
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_cau3.jpg">
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_afr2.jpg">
</p>

<h3 id="other-works">Other works</h3>
<p>Check out our other paper presented at AIM (ECCV 2020): <a href="https://robinkips.github.io/CA-GAN/" target="_blank">https://robinkips.github.io/CA-GAN/</a></p>


      
    </section></div>]]>
            </description>
            <link>https://despoisj.github.io/AgingMapGAN/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280145</guid>
            <pubDate>Wed, 26 Aug 2020 07:47:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YC Software Startups: Value and Initial Programming Language Used]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24279611">thread link</a>) | @charliereese
<br/>
August 25, 2020 | https://charliereese.ca/article/top-50-y-combinator-tech-startups | <a href="https://web.archive.org/web/*/https://charliereese.ca/article/top-50-y-combinator-tech-startups">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

			<div>

				<p>This article contains a list of the top 50 YC software startups (sourced from the October 2019 <a href="https://www.ycombinator.com/topcompanies/">YC Top Companies</a> page). It also contains aggregated statistics for valuations and back-end programming languages used.</p>
<p>Values in this article are sourced, but I cannot guarantee their accuracy.</p>
<p>Follow me on Twitter <a href="https://twitter.com/charlieinthe6">@charlieinthe6</a> for similar content. <a href="https://news.ycombinator.com/item?id=24279611">View article comments on HackerNews</a>.</p>
<p>☕</p>
<p><strong>Table of Contents:</strong></p>
<ol>
<li><a href="#top-50">Top 50 Software Startups</a></li>
<li><a href="#stats">Aggregated Stats</a></li>
</ol>
<h3 id="top-50">1. Top 50 Software Startups:</h3>
<table>
<thead>
<tr>
<th>Company</th>
<th>Latest val ($MM)</th>
<th>Initial back-end language(s)</th>
<th>DataSci / LowLv</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://stripe.com/">Stripe</a>: <br>Payment / economic infrastructure for internet</td>
<td>36,000 <small> <a href="https://detroit.cbslocal.com/2020/08/11/general-motors-cfo-exits-suddenly-for-silicon-valley/">source</a> </small></td>
<td>Ruby <small> <a href="https://qr.ae/pN2pJk">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://getcruise.com/">Cruise</a>: <br>Building self-driving car tech</td>
<td>19,000 <small> <a href="https://www.thedrive.com/tech/27872/gm-cruise-divisions-new-1b-investment-sets-valuation-at-staggering-19b">source</a> </small></td>
<td>C++, Python <small> <a href="https://angel.co/company/cruise-automation/jobs/757823-staff-deep-learning-optimization-engineer">source</a>, <a href="https://angel.co/company/cruise-automation/jobs/841627-staff-software-engineer-c-frameworks">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://airbnb.com/">Airbnb</a>: <br>Marketplace to rent someone’s room</td>
<td>18,000 <small> <a href="https://sanfrancisco.cbslocal.com/2020/08/11/airbnb-ipo-reportedly-close-to-filing-wsj/">source</a> </small></td>
<td>Ruby <small> <a href="https://www.forbes.com/sites/quora/2018/02/20/what-technology-stack-does-airbnb-use/#448ff4184025">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://doordash.com/">DoorDash</a>: <br>Food delivery</td>
<td>16,000 <small> <a href="https://www.cnn.com/2020/06/18/tech/doordash-funding-valuation/index.html">source</a> </small></td>
<td>Python <small> <a href="https://medium.com/@DoorDash/implementing-rest-apis-with-embedded-privacy-a2394dc4dceb">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://twitch.tv/">Twitch</a>: <br>Gaming video platform / community</td>
<td>15,000 <small> <a href="https://www.cnbc.com/2020/06/16/amazon-media-assets-worth-500-billion-almost-as-much-as-aws-needham.html#:~:text=To%20get%20to%20%24500%20billion,business%20is%20at%20%243.8%20billion.">source</a> </small></td>
<td>C++, Ruby <small> <a href="https://blog.twitch.tv/en/2015/12/18/twitch-engineering-an-introduction-and-overview-a23917b71a25/">source</a> (founded before Go)</small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://instacart.com/">Instacart</a>: <br>Grocery pick-up / delivery</td>
<td>13,700 <small> <a href="https://techcrunch.com/2020/06/11/instacart-raises-225-million-at-13-7-billion-valuation/">source</a> </small></td>
<td>Ruby <small> <a href="https://stackshare.io/posts/the-tech-behind-instacarts-grocery-delivery-service">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://dropbox.com/">Dropbox</a>: <br>File hosting / syncing</td>
<td>8000 (market cap @ Aug 2020) <small> <a href="https://finance.yahoo.com/quote/DBX?p=DBX">source</a> </small></td>
<td>Python <small> <a href="https://eranki.tumblr.com/post/27076431887/scaling-lessons-learned-at-dropbox-part-1">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://coinbase.com/">Coinbase</a>: <br>Cryptocurrency exchange</td>
<td>8,000 <small> <a href="https://www.coindesk.com/coinbase-existing-valuation-doesnt-need-ipo-lawyer-says">source</a> </small></td>
<td>Ruby <small> <a href="https://blog.coinbase.com/scaling-connections-with-ruby-and-mongodb-99204dbf8857">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://gusto.com/">Gusto</a>: <br>Employee payroll and benefits</td>
<td>3,800 <small> <a href="https://www.forbes.com/sites/donnafuscaldo/2019/07/24/gusto-amasses-3-8-billion-valuation-with-latest-fundraising-round/#50e7fa8d2820">source</a> </small></td>
<td>Ruby <small> <a href="https://boards.greenhouse.io/gusto/jobs/1337386?t=bae6d7cd1">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rappi.com/">Rappi</a>: <br>On-demand delivery</td>
<td>3,500 <small> <a href="https://techcrunch.com/2020/04/08/ifood-merges-with-delivery-heros-domicilios-com-to-challenge-rappi-in-colombia/">source</a> </small></td>
<td>Go, Node, Python, Java <small> <a href="https://www.rappi.com/jobs/position-detail?id=b88ad33f-7ad5-4e3b-8ecb-f13a3cce3a6a&amp;lang=lang">source</a> (may have used PHP - no source)</small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://flexport.com/">Flexport</a>: <br>Freight forwarding platform</td>
<td>3,200 <small> <a href="https://www.joc.com/technology/wework-spanner-flexports-works_20191021.html">source</a> </small></td>
<td>Ruby <small> <a href="https://stackshare.io/posts/how-flexport-builds-software-to-move-over-1-billion-dollars-in-merchandise">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://reddit.com/">Reddit</a>: <br>Online network of communities</td>
<td>3,000 <small> <a href="https://techcrunch.com/2019/02/11/reddit-300-million/">source</a> </small></td>
<td>Lisp <small> <a href="http://www.aaronsw.com/weblog/rewritingreddit">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://about.gitlab.com/">GitLab</a>: <br>DevOps platform</td>
<td>2,750 <small> <a href="https://www.forbes.com/sites/alexkonrad/2019/09/17/gitlab-doubles-valuation-to-nearly-3-billion/#483591ce1794">source</a> </small></td>
<td>Ruby <small> <a href="https://about.gitlab.com/blog/2018/10/29/why-we-use-rails-to-build-gitlab/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://brex.com/">Brex</a>: <br>Corporate credit cards</td>
<td>2,750 <small> <a href="https://techcrunch.com/2020/05/19/brex-brings-on-150m-in-new-cash-in-case-of-an-extended-recession/">source</a> </small></td>
<td>Elixir <small> <a href="https://medium.com/brexeng/why-brex-chose-elixir-fe1a4f313195">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://pagerduty.com/">PargerDuty</a>: <br>SaaS incident response platform</td>
<td>2,270 <small> <a href="https://www.google.com/search?tbm=fin&amp;q=NYSE:+PD&amp;stick=H4sIAAAAAAAAAONgecRowS3w8sc9YSn9SWtOXmPU5OIKzsgvd80rySypFJLmYoOyBKX4uXj10_UNDdOyCwszkotLeBaxcvhFBrtaKQS4AAASRGHASAAAAA&amp;sa=X&amp;ved=2ahUKEwjCtra68ZbrAhUYXc0KHdn_DoAQ3ecFMAB6BAhqEBc&amp;biw=1278&amp;bih=968#scso=_Z4c0X5TmCsjOtQbEu5zQAQ1:0">source</a> </small></td>
<td>Ruby <small> <a href="https://www.pagerduty.com/blog/elixir-at-pagerduty/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://checkr.com/">Checkr</a>: <br>Background checks</td>
<td>2,200 <small> <a href="https://www.forbes.com/sites/bizcarson/2019/09/19/checkr-background-funding-round/#552c8c845460">source</a> </small></td>
<td>Ruby <small> <a href="https://engineering.checkr.com/yet-another-attempt-at-faster-builds-caching-db-schema-efe63d367f5">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://podium.com/">Podium</a>: <br>Interaction management platform</td>
<td>1,500 <small> <a href="https://techcrunch.com/2020/04/07/utahs-podium-raises-125m-series-c-led-by-yc-after-reaching-100m-arr/">source</a> </small></td>
<td>Ruby <small> <a href="https://devchat.tv/elixir-mix/emx-072-people-centered-solutions-with-travis-elnicky/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://segment.com/">Segment</a>: <br>Customer data platform</td>
<td>1,500 <small> <a href="https://www.bloomberg.com/news/articles/2019-04-02/startup-segment-is-worth-1-5-billion-thanks-to-companies-troves-of-customer-data">source</a> </small></td>
<td>Go, JS <small> <a href="https://www.workatastartup.com/companies/88">source</a>, <a href="https://angel.co/company/segment/jobs/348613-senior-software-engineer">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://docker.com/">Docker</a>: <br>Build / deliver software in containers</td>
<td>1000 est. <small> <a href="https://techcrunch.com/2019/11/13/mirantis-acquires-docker-enterprise/">source</a>, <a href="https://techcrunch.com/2018/10/15/docker-has-raised-92-million-in-new-funding/">source</a> </small></td>
<td>Go <small> <a href="https://thenewstack.io/go-programming-language-helps-docker-container-ecosystem/">source</a>, <a href="https://techcrunch.com/2019/11/13/after-selling-enterprise-biz-docker-lands-35m-investment-and-new-ceo/">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://scale.com/">Scale</a>: <br>Training / validation data for ML</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/stevenli1/2019/12/22/scale-ai-growth-story/#3360214b6f4a">source</a> </small></td>
<td>Python, JS <small> <a href="https://scale.com/careers/41e05b90-7e65-4dac-8676-50be9c1afc27">source</a>, <a href="https://scale.com/careers/37b0c485-cd77-4170-ac07-a8521b9a10fc">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://amplitude.com/">Amplitude</a>: <br>Product / customer analytics</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/davidjeans/2020/05/20/amplitude-now-valued-1-billion-backed-sequoia-benchmark/#68a1ad2041c7">source</a> </small></td>
<td>Python, Java <small> <a href="https://news.ycombinator.com/item?id=13301832&amp;p=2">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://zapier.com/">Zapier</a>: <br>Connect apps and automate workflows</td>
<td>1000 est. (20x 2018 ARR) <small> <a href="https://www.drift.com/blog/how-zapier-grew/">source</a> </small></td>
<td>Python <small> <a href="https://zapier.com/blog/zapier-tech-stack/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://faire.com/">Faire</a>: <br>B2B wholesale marketplace</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/laurendebter/2019/10/30/faire-wholesale-marketplace-series-d-1-billion-valuation/#21c2bdfb7aa9">source</a> </small></td>
<td>Java <small> <a href="https://boards.greenhouse.io/faire/jobs/4187498002">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://plangrid.com/">PlanGrid</a>: <br>Construction software</td>
<td>875 <small> <a href="https://techcrunch.com/2018/11/20/autodesk-agrees-to-buy-plangrid-for-875-million/#:~:text=Autodesk%20announced%20plans%20to%20acquire%20PlanGrid%20for%20%24875%20million%20today.">source</a> </small></td>
<td>Python <small> <a href="https://stackoverflow.com/jobs/companies/plangrid">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://mixpanel.com/">Mixpanel</a>: <br>User analytics</td>
<td>865 <small> <a href="https://www.forbes.com/pictures/feki45efhmk/mixpanel/#71dc3892190f">source</a> </small></td>
<td>Python<small> <a href="https://boards.greenhouse.io/mixpanel/jobs/1545756?gh_jid=1545756">source</a> (founded before Go)</small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://benchling.com/">Benchling</a>: <br>Biotech research</td>
<td>850 <small> <a href="https://www.forbes.com/sites/amyfeldman/2020/05/28/biotech-rd-software-startup-benchling-started-by-mit-undergrads-scores-850-million-valuation-amid-coronavirus-pandemic/#5de0e0c61dcd">source</a> </small></td>
<td>Python <small> <a href="https://www.workatastartup.com/companies/445">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://meesho.com/">Meesho</a>: <br>Social commerce platform</td>
<td>700 <small> <a href="https://economictimes.indiatimes.com/small-biz/startups/newsbuzz/meesho-raised-125-mn-from-naspers-and-others/articleshow/70641492.cms">source</a> </small></td>
<td>Java <small> <a href="https://angel.co/company/meesho/jobs/596045-software-development-engineer-iii">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://optimizely.com/">Optimizely</a>: <br>Digital experience optimization / testing</td>
<td>600 <small> <a href="https://pitchbook.com/newsletter/optimizely-brings-in-50m#:~:text=Optimizely%2C%20which%20operates%20an%20optimization,with%20participation%20from%20Accenture%20Ventures">source</a> </small></td>
<td>Python <small> <a href="https://news.ycombinator.com/item?id=2647003">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://algolia.com/">Algolia</a>: <br>Search service</td>
<td>578 <small> <a href="https://www.bizjournals.com/sanfrancisco/news/2019/10/15/fast-growing-san-francisco-search-company-scores.html">source</a> </small></td>
<td>C++, Ruby <small> <a href="https://www.algolia.com/doc/faq/why/what-architecture-does-algolia-use-to-provide-an-high-performance-search-engine/">source</a>, <a href="https://stackshare.io/posts/how-algolia-built-their-realtime-search-as-a-service-product">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://goat.com/">Goat</a>: <br>Sneaker marketplace</td>
<td>550 <small> <a href="https://www.forbes.com/sites/kurtbadenhausen/2019/02/07/foot-locker-invests-100-million-in-secondary-sneaker-firm-goat/#3b07b65e568d">source</a> </small></td>
<td>Ruby <small> <a href="https://www.workatastartup.com/jobs/20990">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://standard.ai/">StandardCognition</a>: <br>Autonomous checkout</td>
<td>535 <small> <a href="https://techcrunch.com/2019/07/25/standard-cognition-lands-35m-at-535m-valuation-to-battle-amazon-go/">source</a> </small></td>
<td>Python <small> <a href="https://jobs.lever.co/standard/9b874041-7cfe-4e0a-a459-fcd66451ee75">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://people.ai/">People.ai</a>: <br>Intelligent CRM</td>
<td>500 <small> <a href="https://techcrunch.com/2019/05/21/people-ai-the-predictive-sales-startup-raises-60m-at-around-500m-valuation/#:~:text=People.ai%2C%20the%20predictive%20sales,around%20%24500M%20valuation%20%7C%20TechCrunch">source</a> </small></td>
<td>Python <small> <a href="https://www.workatastartup.com/companies/1299">source</a>, <a href="https://news.ycombinator.com/item?id=16974829">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://razorpay.com/">Razorpay</a>: <br>Digital payments</td>
<td>450 <small> <a href="https://www.pymnts.com/news/investment-tracker/2019/razorpay-sequoia-india-ribbit-capital/#:~:text=With%20the%20funding%2C%20Razorpay%20is,Razorpay%20X%20neo%2Dbanking%20platform.">source</a> </small></td>
<td>PHP <small> <a href="https://news.ycombinator.com/item?id=12407955">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://equipmentshare.com/">EquipmentShare</a>: <br>Equipment rentals</td>
<td>400 est. <small> <a href="https://www.forbes.com/sites/alexkonrad/2019/11/18/softbank-looks-to-invest-equipmentshare-unicorn/#48a6b2d779b8">source</a> </small></td>
<td>Python <small> <a href="https://news.ycombinator.com/item?id=16492994&amp;p=2">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://weebly.com/">Weebly</a>: <br>Website builder</td>
<td>365 <small> <a href="https://techcrunch.com/2018/04/26/square-acquires-weebly/">source</a> </small></td>
<td>PHP <small> <a href="https://news.ycombinator.com/item?id=2839742">source</a>, <a href="https://news.ycombinator.com/item?id=5729035">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://webflow.com/">Webflow</a>: <br>Website builder</td>
<td>350 <small> <a href="https://growthhackers.com/articles/how-webflow-quietly-grew-without-vc-money?r=latest">source</a> </small></td>
<td>JS <small> <a href="https://boards.greenhouse.io/webflow/jobs/1838218">source</a>, <a href="https://www.workatastartup.com/companies/566">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://matterport.com/">Matterport</a>: <br>3D technology platform</td>
<td>325 <small> <a href="https://techcrunch.com/2019/03/05/matterport-2/#:~:text=Matterport%20had%20raised%20just%20under,DCM%2C%20Qualcomm%20Ventures%20and%20more.">source</a> </small></td>
<td>C++ <small> <a href="https://news.ycombinator.com/item?id=3300290">source</a>, <a href="https://news.ycombinator.com/item?id=5186626">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://influxdata.com/">InfluxData</a>: <br>InfluxDB creator</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/influxdb/company_financials">source</a> </small></td>
<td>Go <small> <a href="https://github.com/influxdata/influxdb">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://embarktrucks.com/">Embark</a>: <br>Self-driving trucks</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/embark-trucks/company_financials">source</a> </small></td>
<td>Python, C++ <small> <a href="https://jobs.lever.co/embark/25999d12-5d82-45fc-b3e4-0ebc335f6f59">source</a> </small></td>
<td>Y / Y</td>
</tr>
<tr>
<td><a href="https://sendbird.com/">SendBird</a>: <br>Chat / calls as a service</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/sendbird/company_financials">source</a> </small></td>
<td>Python <small> <a href="https://sendbird.com/careers/4317963002">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rescale.com/">Rescale</a>: <br>Cloud simulation platform</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/rescale/company_financials">source</a> </small></td>
<td>Java, Python <small> <a href="https://news.ycombinator.com/item?id=5828217">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://gocardless.com/">GoCardless</a>: <br>Direct debit payments</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/gocardless/company_financials">source</a> </small></td>
<td>Ruby <small> <a href="https://news.ycombinator.com/item?id=14978103">source</a>, <a href="https://news.ycombinator.com/item?id=16283469">source</a>, <a href="https://news.ycombinator.com/item?id=4596703">source</a>, <a href="https://boards.greenhouse.io/gocardless/jobs/2282283">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rigetti.com/">Rigetti Computing</a>: <br>Quantum computing</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/rigetti-computing/company_financials">source</a> </small></td>
<td>Python, Lisp, C <small> <a href="https://news.ycombinator.com/item?id=16968407">source</a> </small></td>
<td>Y / Y</td>
</tr>
<tr>
<td><a href="https://messagebird.com/">MessageBird</a>: <br>Omnichannel customer communication</td>
<td>300 <small> <a href="https://www.fool.com/investing/2020/03/13/twilio-investors-keep-tabs-on-startup-messagebird.aspx">source</a> </small></td>
<td>Go, PHP, Python, Java <small> <a href="https://careers.sh/uk/kompaniya/messagebird/robochi-mistsya/71009">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://ironcladapp.com/">Ironclad</a>: <br>Digital contracting platform</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/ironclad/company_financials">source</a> </small></td>
<td>JS, Java <small> <a href="https://jobs.lever.co/ironcladapp/2d6616e3-27b8-4138-a6fc-238e46757822">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://sift.com/">Sift</a>: <br>Digital safety and fraud detection</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/sift-science/company_financials">source</a> </small></td>
<td>Java, Ruby <small> <a href="https://news.ycombinator.com/item?id=6657091">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://mattermost.com/">Mattermost</a>: <br>Open source Slack alternative</td>
<td>250 est. <small> <a href="https://app.dealroom.co/companies/mattermost">source</a> </small></td>
<td>Go <small> <a href="https://github.com/mattermost/mattermost-server">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://xendit.co/">Xendit</a>: <br>Digital payments</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>JS <small> <a href="https://www.workatastartup.com/companies/938">source</a>, <a href="https://www.xendit.co/en/careers/job-application/?gh_jid=4114942003">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://easypost.com/">EasyPost</a>: <br>Logistics software</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>Ruby <small> <a href="https://news.ycombinator.com/item?id=6231587">source</a>, <a href="https://news.ycombinator.com/item?id=13542390">source</a>, <a href="https://www.linkedin.com/jobs/view/senior-software-engineer-at-easypost-1669977835/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://newfrontinsurance.com/">Newfront</a>: <br>Insurance platform</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>JS, Go <small> <a href="https://www.keyvalues.com/newfront">source</a>, <a href="https://news.ycombinator.com/item?id=21683554">source</a> </small></td>
<td>N / N</td>
</tr>
</tbody>
</table>
<p><small>
<p>Note: Ginkgo Bioworks, Boom Supersonic, Grin, Memebox, Helion Energy, North, RelativitySpace, and The Athletic were excluded from the below list; I didn't feel they were primarily software businesses. Feel free to disagree with my judgement.</p>
<p>Note: values current as of August 15, 2020.</p>
<p>Note: if one language was the primary language used to build the initial product, one language is listed above. If it was not clear which language was primary, multiple languages are listed above.</p>
<p>Note: if I couldn't find which language was used to build the startup initially, I referenced the oldest job posting I could find.</p>
<p>Note: valuations are approximate and predominantly sourced from recent articles online. Where I couldn't find an indication of value, ~$150M is assumed; startups listed above were all worth +$150M as of October 2019, as per the <a href="https://www.ycombinator.com/topcompanies/">YC Top Companies</a> page.</p>
<p>Note: "Y" and "N" values in the "DataSci / LowLv" column describe a startup's primary product (i.e. ML startups would have a "Y" for DataSci). It was included to provide additional colour on why initial back-end language(s) may have been used / selected. The values in this column are based entirely on my own judgement. Feel free to disagree with them or ignore them.</p>
<p>Note: Ruby and ruby on rails was a popular choice for YC startups around 2010 - 2012. Anecdotally, ~40% of YC startups used ruby during its peak popularity.</p>
</small></p>

<h3 id="stats">2. Aggregated Stats:</h3>

<p><strong>Startups with one (initial) primary back-end language:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>35 (70%)</td>
<td>132.1 (75%)</td>
</tr>
<tr>
<td>Ruby</td>
<td>13 (26%)</td>
<td>92.4 (52%)</td>
</tr>
<tr>
<td>Python</td>
<td>11 (22%)</td>
<td>29.9 (17%)</td>
</tr>
<tr>
<td>Lisp</td>
<td>1 (2%)</td>
<td>3.0 (2%)</td>
</tr>
<tr>
<td>Elixir</td>
<td>1 (2%)</td>
<td>2.8 (2%)</td>
</tr>
<tr>
<td>Java</td>
<td>2 (4%)</td>
<td>1.7 (1%)</td>
</tr>
<tr>
<td>Go</td>
<td>3 (6%)</td>
<td>1.6 (1%)</td>
</tr>
<tr>
<td>PHP</td>
<td>2 (4%)</td>
<td>0.8 (0%)</td>
</tr>
<tr>
<td>JS</td>
<td>2 (4%)</td>
<td>0.5 (0%)</td>
</tr>
<tr>
<td>C++</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>

<p><strong>Startups with multiple (initial) primary back-end languages:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>15 (30%)</td>
<td>44.4 (25%)</td>
</tr>
<tr>
<td>C++ is one</td>
<td>4 (8%)</td>
<td>34.9 (20%)</td>
</tr>
<tr>
<td>Python is one</td>
<td>8 (16%)</td>
<td>25.7 (15%)</td>
</tr>
<tr>
<td>Ruby is one</td>
<td>3 (6%)</td>
<td>15.9 (9%)</td>
</tr>
<tr>
<td>JS is one</td>
<td>5 (10%)</td>
<td>6.5 (4%)</td>
</tr>
<tr>
<td>Java is one</td>
<td>6 (12%)</td>
<td>5.7 (3%)</td>
</tr>
<tr>
<td>Go is one</td>
<td>4 (8%)</td>
<td>5.5 (3%)</td>
</tr>
<tr>
<td>Lisp is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
<tr>
<td>C is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
<tr>
<td>PHP is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>
<p><small>Note: "Startups with multiple (initial) primary back-end languages" table doesn't add to 100% because multiple languages were used for startups.</small></p>

<p><strong>All startups:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>50 (100%)</td>
<td>176.5 (100%)</td>
</tr>
<tr>
<td>Ruby is one</td>
<td>16 (32%)</td>
<td>108.3 (61%)</td>
</tr>
<tr>
<td>Python is one</td>
<td>19 (38%)</td>
<td>55.6 (32%)</td>
</tr>
<tr>
<td>C++ is one</td>
<td>5 (10%)</td>
<td>35.2 (20%)</td>
</tr>
<tr>
<td>Java is one</td>
<td>8 (16%)</td>
<td>7.4 (4%)</td>
</tr>
<tr>
<td>Go is one</td>
<td>7 (14%)</td>
<td>7.0 (4%)</td>
</tr>
<tr>
<td>JS is one</td>
<td>7 (14%)</td>
<td>7.0 (4%)</td>
</tr>
<tr>
<td>Lisp is one</td>
<td>2 (4%)</td>
<td>3.3 (2%)</td>
</tr>
<tr>
<td>Elixir is one</td>
<td>1 (2%)</td>
<td>2.8 (2%)</td>
</tr>
<tr>
<td>PHP is one</td>
<td>3 (6%)</td>
<td>1.1 (1%)</td>
</tr>
<tr>
<td>C is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>
<p><small>Note: "All startups" table doesn't add to 100% because multiple languages were used for some startups.</small></p>
				
			</div>

		</article></div>]]>
            </description>
            <link>https://charliereese.ca/article/top-50-y-combinator-tech-startups</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279611</guid>
            <pubDate>Wed, 26 Aug 2020 06:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast.ai Released a New Free Deep Learning Course]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24279146">thread link</a>) | @yadavrohit
<br/>
August 25, 2020 | https://www.analyticsdrift.com/a-new-free-deep-learning-course-by-fast-ai/ | <a href="https://web.archive.org/web/*/https://www.analyticsdrift.com/a-new-free-deep-learning-course-by-fast-ai/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <!-- .entry-header -->

                
                        <div>
                                    <p><img width="740" height="474" src="https://i0.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/deep-learning-courses-online.jpg?fit=740%2C474&amp;ssl=1&amp;is-pending-load=1" alt="deep learning course" loading="lazy" data-lazy-srcset="https://i0.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/deep-learning-courses-online.jpg?w=740&amp;ssl=1 740w, https://i0.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/deep-learning-courses-online.jpg?resize=300%2C192&amp;ssl=1 300w" data-lazy-sizes="(max-width: 740px) 100vw, 740px" data-lazy-src="https://i0.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/deep-learning-courses-online.jpg?fit=740%2C474&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">                </p>
            
                                            </div>

            

        <!-- end slider-section -->
                                    

    <div>
        <div>
            
<p>fast.ai — an independent research center that makes superior solutions for easy accessibility of deep learning — has released a free course, along with the book. The course — <a href="https://course.fast.ai/videos/?lesson=1" target="_blank" rel="noreferrer noopener">Practical Deep Learning for Coders</a> — is aimed at the introduction to machine learning and deep learning, and production and deployment of models.</p>



<p>Practical Deep Learning Course by fast.ai covers the material from the book <a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527" target="_blank" rel="noreferrer noopener">PyTorch: AI Applications Without a PhD</a>. Every video lesson covers one chapter of the book that is also freely available if you do not want to purchase it from Amazon. PyTorch: AI Applications Without a PhD. is hosted on GitHub, where you can access the book in a freely available interactive <a href="https://github.com/fastai/fastbook" target="_blank" rel="noreferrer noopener">Jupyter Notebooks</a>.</p>



<p><strong>Also Read:</strong> <a href="https://www.analyticsdrift.com/amazon-makes-its-machine-learning-course-free-for-all/" target="_blank" rel="noreferrer noopener">Amazon Makes Its Machine Learning Course Free For All</a></p>



<p>However, the entire book is not covered in this Practical Deep Learning for Coders course. In the future, fast.ai will release the second part of the course that will complete the book’s remaining lessons.</p>



<p>Unlike most of the free courses and short-term courses, this deep learning course by fast.ai covers an end-to-end data science workflow as it also provides lessons on the deployment of models and data ethics. This makes it a must for aspirants who want to learn advanced techniques and make themselves relevant to the industry.</p>



<p><strong>What you will learn:</strong></p>



<p>1.<strong> </strong>Optimize models to get exceptional results in computer vision, NLP, recommenders, and more</p>



<p>2. How to turn your models into web applications, and deploy them</p>



<p>3. How to enhance your models’ accuracy, speed, and reliability&nbsp;</p>



<p>4. Ethical implementation while making models</p>



<p>5. Other techniques such as random forests and gradient boosting, parameters and activations, random initialization and transfer learning, among others</p>



<p>Over the years, fast.ai has been releasing some of the best deep learning courses online for aspirants to learn for free; Last week, it released a course on ethics — <a href="https://ethics.fast.ai/videos/?lesson=1" target="_blank" rel="noreferrer noopener">Practical Data Ethics</a>.</p>



<p><strong>Note:</strong> Please do not make the <a href="https://github.com/fastai/fastbook" target="_blank" rel="noreferrer noopener">Jupyter Notebook</a> version of the book into PDF and distribute it to respect the provider’s generosity. Use it only for your education or learning if you cannot buy it on Amazon.</p>



<p><strong>Subscribe to our newsletter for free to get the most-read stories every week.</strong>&nbsp;<strong>Provide your email id below.</strong>&nbsp;<strong>We never sell your information.</strong></p>


  <!-- .wpforms-container -->                <div>
                    
                                        
        <div>

                <p><a href="https://www.analyticsdrift.com/author/analyticsdriftgmail-com/"><img alt="" src="https://secure.gravatar.com/avatar/b4013be20eaee509a78cd792d7474854?s=150&amp;r=g" srcset="https://secure.gravatar.com/avatar/b4013be20eaee509a78cd792d7474854?s=300&amp;r=g 2x" height="150" width="150" loading="lazy" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a>
                </p>
                
        </div>

                                            </div>
                                            
                        
	<nav role="navigation" aria-label="Continue Reading">
		<h2>Continue Reading</h2>
		
	</nav>                    </div><!-- .entry-content -->
    </div>
                        </div></div>]]>
            </description>
            <link>https://www.analyticsdrift.com/a-new-free-deep-learning-course-by-fast-ai/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279146</guid>
            <pubDate>Wed, 26 Aug 2020 04:33:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PCI Express Retimers vs. Redrivers: An Eye-Popping Difference (2019)]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24278760">thread link</a>) | @tragiclos
<br/>
August 25, 2020 | https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/ | <a href="https://web.archive.org/web/*/https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Retimers and redrivers have enabled longer physical channels in servers and storage systems since Peripheral Component Interface Express (PCIe) 3.0 was first introduced almost 10 years ago. Now that PCIe 4.0 is ramping up and PCIe 5.0 is just around the corner, how do these reach extension tools stack up in the face of new challenges in high-speed connectivity?</p>
<p>A redriver is a mostly analog reach extension device designed to boost the high-frequency portions of a signal to counteract the frequency-dependent attenuation caused by the interconnect: the central processing unit (CPU) package, system board, connectors and so on. A redriver’s data path typically includes a continuous time linear equalizer (CTLE), a wideband gain stage and a linear driver. In addition, redrivers often have input loss-of-signal threshold and output receiver (Rx) detection capability. Figure 1 illustrates a typical redriver block diagram.</p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer"><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block.jpg" alt="" width="731" height="419" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block.jpg 731w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-300x172.jpg 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-260x150.jpg 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-523x300.jpg 523w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-200x115.jpg 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-564x323.jpg 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-600x344.jpg 600w" sizes="(max-width: 731px) 100vw, 731px"></a></p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">Figure 1: Redriver block diagram [1]</a></p>
<p>A retimer is a mixed signal analog/digital device that is protocol-aware and has the ability to fully recover the data, extract the embedded clock and retransmit a fresh copy of the data using a clean clock. In addition to the CTLE and wideband gain stages also found in a redriver, retimers contain a clock and data recovery (CDR) circuit, a decision feedback equalizer (DFE) and a transmit (Tx) finite impulse response (FIR) driver. Finite state machines (FSMs) and/or a microcontroller typically manage the automatic adaptation of the CTLE, wideband gain, DFE and FIR driver, and implement the PCIe link training and status state machine (LTSSM). Figure 2 illustrates a typical retimer block diagram.</p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer"><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block.jpg" alt="retimer-block" width="787" height="440" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block.jpg 787w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-300x168.jpg 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-768x429.jpg 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-260x145.jpg 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-537x300.jpg 537w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-200x112.jpg 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-564x315.jpg 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-600x335.jpg 600w" sizes="(max-width: 787px) 100vw, 787px"></a></p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">Figure 2: Retimer block diagram [1]</a></p>
<p>In simple terms, a redriver amplifies a signal, whereas a retimer retransmits a fresh copy of the signal. Figure 3 illustrates this and shows how an attenuated eye opening is boosted by a redriver and completely regenerated by a retimer.</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1024x238.png" alt="eye-attenuated" width="1024" height="238" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1024x238.png 1024w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-300x70.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-768x178.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1536x357.png 1536w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-260x60.png 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-800x186.png 800w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-200x46.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-564x131.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-600x139.png 600w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated.png 1658w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
<p>Figure 3: Example of an eye attenuated by a channel (left), the eye after a redriver (middle) and the eye after a retimer (right)</p>
<p>The PCIe 4.0 specification took the unprecedented step of formally defining the terms “retimer,” “redriver” and the superset term “repeater,” all of which are types of extension devices or components whose purpose is to extend the physical length of a link. The definitions are:</p>
<ul>
<li><strong>Repeater</strong>: An imprecise term for an extension device [2]. (This term causes confusion … please don’t use it!)</li>
<li><strong>Redriver</strong>: A non-protocol-aware software-transparent extension device [2].</li>
<li><strong>Retimer</strong>: A physical layer protocol-aware, software-transparent extension device that forms two separate electrical link segments [2].</li>
</ul>
<h3>Use Cases for Retimers and Redrivers</h3>
<p>Reach extension devices are necessary whenever the channel – the electrical path between the root complex (RC) and endpoint (EP) – is longer than the PCIe specification allows. The specification defines the maximum channel length in terms of insertion loss at the Nyquist frequency (an informative specification, but easy to validate) and in terms of a reference receiver’s ability to sufficiently equalize and recover the data assuming a worst-case link partner transmitter (a normative specification, but time-consuming to validate).</p>
<p>Suffice it to say, at PCIe 4.0 speeds, reach extension devices are necessary for:</p>
<ul>
<li>Multiconnector topologies.</li>
<li>Cabled topologies.</li>
<li>Single-connector add-in card (AIC) topologies with baseboard channels longer than 9.5 inches.</li>
</ul>
<p>Figure 4 shows an example of a two-connector “riser card” topology, which ordinarily would exceed the PCIe 4.0 loss budget of 28 dB. A redriver or retimer will enable reliable, error-free communication between the RC and EP. But how do you choose which one is the right tool for the job? Well, it helps to know more about the fundamental differences in their capabilities.</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-1024x391.png" alt="redriver" width="1024" height="391" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-1024x391.png 1024w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-300x115.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-768x293.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-260x99.png 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-785x300.png 785w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-200x76.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-564x216.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-600x229.png 600w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver.png 1120w" sizes="(max-width: 1024px) 100vw, 1024px"><br>
Figure 4: Example of redriver (top) and retimer (bottom) used in a two-connector topology</p>
<h3>Comparing Retimer and Redriver Capabilities</h3>
<p>Not all redrivers and retimers are the same. There are many distinctions between the two, which are universally true for all PCIe reach extension devices. For example:</p>
<p><strong>Retimers actively participate in the PCIe protocol; redrivers do not.</strong> The PCIe base specification spells out how and to what extent retimers participate in the protocol during Detect, Recovery, L0 and other LTSSM states. Equalization to the L0 and L1 link states requires value-added functionality from the retimer (handshakes, timeouts, bit manipulation, etc.). Redrivers are unaware of and unparticipating in the protocol. If the link works reliably the first time, that’s great! But if the link experiences marginality of any sort, it becomes exceedingly difficult to pinpoint whether the problem is physically before the redriver or after it, since the redriver’s role in link formation is undefined and unknown to its link partners.</p>
<p><strong>Retimers reset the jitter and insertion loss budgets; redrivers do not.</strong> A retimer’s CDR fully recovers the data stream and retransmits it on a clean clock. Starting with a fresh copy of the data enables the extension of the channel to twice the original specification. Without a CDR, the best a redriver can do is attenuate (not reset) the data-dependent jitter (DDJ) caused by intersymbol interference (ISI). A redriver cannot attenuate uncorrelated or random jitter (RJ). In fact, a redriver will always add to RJ due to its own device thermal noise in a root-mean-square (RMS) manner <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>.</p>
<p><strong>Retimers have a DFE; redrivers do not.</strong> A DFE compensates for reflections in the channel response caused by impedance discontinuities in board vias, connectors and package socket-board interfaces. The nice thing about a DFE is that it is unaffected by crosstalk. The DFE equalizes just as well in the presence of crosstalk, and once the data is sampled by the retimer’s CDR, crosstalk is eliminated for good. Redrivers use a CTLE that boosts both the signal and the noise <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>. Crosstalk is not eliminated or even attenuated through a redriver; in fact, it gets amplified.</p>
<p><strong>Retimers automatically adapt their receive and transmit equalizers to match the characteristics of the channel and the link partner’s needs; redrivers do not.</strong> A retimer will examine the signal it receives and adjust the CTLE and DFE to minimize its own bit error rate (BER). Likewise, the retimer’s transmitter will adjust its de-emphasis and pre-shoot equalization to minimize the link partner’s BER according to PCIe equalization protocol. A redriver, conversely, operates with a static equalizer setting. The optimal setting (which can be different for every channel in the system) is often painstakingly selected following an exhaustive search in Input/Output Buffer Information Specification (IBIS) algorithmic modeling interface (AMI) simulations and again in lab testing – a process fondly referred to as “tuning.”</p>
<p><strong>Retimers have built-in features to help diagnose link issues (both electrical and protocol); redrivers do not.</strong> Retimers have tools for assessing the electrical performance (internal eye monitors, pattern generators, pattern checkers) and protocol performance (link state history monitors, timeout adjustments). Redrivers cannot offer such diagnostic features because they are neither protocol-aware nor aware of the actual data passing through. Redrivers do not know what state the link is in.</p>
<p><strong>Retimers correct for lane-to-lane skew; redrivers do not.</strong> PCIe has a tight requirement on the physical skew between lanes on a board (1.6 ns for PCIe 4.0), typically caused by mismatches in channel routing length [3]. Retimers are required to compensate and reset any lane-to-lane skew, effectively doubling the specification budget. Redrivers cannot compensate for lane-to-lane skew, and what’s worse is that they may degrade the skew depending on how symmetric the redriver package is across all lanes.</p>
<p><strong>Retimers can be placed anywhere between two PCIe-compliant channels; redrivers cannot.</strong> By definition, retimers extend the total PCIe channel reach by two times the specification. A redriver’s reach extension, however, depends on where it is placed in the channel – how much loss is before the redriver versus how much is after <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>. The specific placement of a redriver must be carefully determined by IBIS-AMI simulation and experimentation. Too close to the root complex transmitter, and the redriver’s CTLE will enter nonlinear operation and will have limited benefit. Placed too far from the transmitter, the redriver’s device noise may significantly degrade the signal-to-noise ratio (SNR) of the data signal.</p>
<p>It’s not all bad news for redrivers. They do have lower power consumption and lower input-to-output latency compared to retimers. But if the link does not form in the first place or if the BER is too high, none of that matters!</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/comparision.png" alt="comparision" width="809" height="527" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/comparision.png 809w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-300x195.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-768x500.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-230x150.png 230w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-461x300.png 461w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-200x130.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-564x367.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-600x391.png 600w" sizes="(max-width: 809px) 100vw, 809px"></p>
<p>Table 1: Comparison of retimer and redriver capabilities and usage</p>
<h3>Outlook for PCIe 4.0 Systems</h3>
<p>Looking ahead to the upcoming PCIe 4.0 systems, all signs are pointing to an increased need for reach extension devices – and retimers in particular – due to several trends and challenges:</p>
<ul>
<li>CPUs have more PCIe lanes per socket (&gt;100 in some cases [4]) compared to PCIe 3.0. This leads to a greater number of PCIe slots and riser cards, denser routing, and an increased use of multiconnector topologies.</li>
<li>PCIe is shifting from an I/O bus to a multipurpose system interconnect. This means that more servers will be designed to be modular, allowing an array of compute, storage and networking resources to plug in to an increasing number of PCIe slots. This type of open, “plug anything in and it will work” server architecture requires a reach extension solution that is PCIe compliant with plug-and-play interoperability.</li>
<li>The disaggregation of resources such as modular servers, storage trays and accelerator trays is pushing endpoints physically away from CPUs, requiring cables or carrier cards to connect everything together. These longer physical topologies will increasingly need reach …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/">https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/</a></em></p>]]>
            </description>
            <link>https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278760</guid>
            <pubDate>Wed, 26 Aug 2020 03:20:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1930s Household Refrigerators (2013)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278184">thread link</a>) | @userbinator
<br/>
August 25, 2020 | https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/ | <a href="https://web.archive.org/web/*/https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p>The evolution of the household refrigerator is not a well known story. &nbsp;There seems to be few people interested in the subject. &nbsp;Perhaps it is not as romantic as the development of the automobile. &nbsp;Nonetheless, a concerted effort was put forth in the 1920s and 1930s to produce a cheap, reliable, efficient domestic refrigerator. &nbsp;From books I’m reading on the subject, the great diversity of refrigerator manufacturers in the United States that existed in the 1920s, seems to be boiled down to a handful of companies in the depression era. &nbsp;In the most recent book, “Household Electric Refrigeration” by John F. Wostrel and John G. Praetz 1938; the models described were made by manufacturers, many still around today (or owned by yet larger companies) including General Electric, Frigidaire, Kelvinator, Norge, Grunow, Crosley, Sparton, Hotpoint, Coldspot, Copeland, Ice-O-Matic and Westinghouse.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg"><img data-attachment-id="4086" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/norge_operation/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg" data-orig-size="2343,2202" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067280&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0012468827930175&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Norge_Operation" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=605" alt="Norge_Operation" src="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=605&amp;h=568" srcset="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=605&amp;h=568 605w, https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=1210&amp;h=1136 1210w, https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=150&amp;h=141 150w, https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=300&amp;h=282 300w, https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=768&amp;h=722 768w, https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=1024&amp;h=962 1024w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>One of the most noticeable differences between refrigerators in the mid 1930s and today was the refrigerants they used and the refrigerants charges required for operation. &nbsp;A very common refrigerant, Sulpher Dioxide had been in use fora number of years and still appeared to dominate the market at this time, not to say that proprietary chemical refrigerants weren’t beginning to take a large part of the market. &nbsp;F-12 was one of these proprietary substances that would later dominate the refrigerator industry. &nbsp;It was stable up to high temperatures, didn’t stink like SO2 when it leaked, was relatively safe if exposure to it was kept to a minimum, and it has a much lower boiling point than several common refrigerants at the time which means that systems operating F-12 remained in a positive pressure state throughout the cycle. &nbsp;Refrigerators with F-114, SO2, Isobutane and Methyl Formate required a vacuum in the low side of a vapor compression system. &nbsp;This was generally viewed as problematic seeing that if a leak formed in the low side of the system, for instance, around the packing seal of an open drive compressor, atmosphere would leak into the system, bringing non-condensable gases and water vapor. &nbsp;This leads to high head pressures, oil contamination, possible acid formation, corrosion and refrigerant control freeze ups. &nbsp;A curious refrigerant used rarely was Carrene, also known as Dichloromethane which has a boiling point of 104 degrees F at atmospheric pressure. &nbsp;This means both the suction and discharge sides of a system would operate in a vacuum state. &nbsp;Very curious. &nbsp;As I said, the refrigerant charges were unusual as well. &nbsp;The compressors of these systems were rated not much &nbsp;larger than modern day compressors from 1/16 HP up to 1/4 HP, but they had typical charges of 1# to perhaps 3.5# &nbsp;and more depending on the manufacturer. &nbsp;Modern refrigerators have charges measured in ounces, perhaps, 4 oz.. Most of these machines had liquid receivers that held excess refrigerant and ensured a pure liquid supply to the refrigerant control. &nbsp;That excess refrigerant would have allowed continued operation with minor leaks in the system. &nbsp;Another reason for the large charges is the construction of the evaporator which was commonly gravity flooded; a vessel and series of tubes holding refrigerant under low pressure, boiling away to vapor as heat is absorbed from the refrigerated cabinet.<span id="more-4087"></span></p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg"><img data-attachment-id="4080" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/frigidaire_lsf_evaporator/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg" data-orig-size="2219,1522" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067405&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.00095419847328244&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Frigidaire_LSF_Evaporator" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=605" alt="Frigidaire_LSF_Evaporator" src="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=605&amp;h=415" srcset="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=605&amp;h=415 605w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=1210&amp;h=830 1210w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=150&amp;h=103 150w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=300&amp;h=206 300w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=768&amp;h=527 768w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=1024&amp;h=702 1024w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>Above, is one of these low side float assemblies. &nbsp;These seemed to be falling out of favor by the mid 1930s for various reason having to do with expense and reliability. &nbsp;The float valve simply regulated the volume of liquid refrigerant within the evaporator shell which was maintained at suction pressure. &nbsp;As the refrigerant boiled away and was carried to the compressor, the ball would drop, valve open and additional high pressure liquid would be admitted. &nbsp;When implemented properly, the low side float gravity flooded evaporator has many advantages over the high side float or the dry type evaporator. &nbsp;It was very important that these machines were properly leveled when installed. &nbsp;They definitely had a minimum charge volume below which the float valve would continually call for more refrigerant and when it was not available, the valve would remain open, leaving very little pressure drop between the high and low side resulting in little to no refrigerating effect. &nbsp;A large refrigerant charge could simply be handled with a sufficiently sized liquid receiver. &nbsp;(Also read <a href="https://musingsonentropy.wordpress.com/2013/04/18/the-great-gravity-flooded-evaporator/" target="_blank">The Great Gravity Flooded Evaporator</a>)</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg"><img data-attachment-id="4079" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/frigidaire_low_side_float/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg" data-orig-size="2298,1181" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067395&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.00068870523415978&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Frigidaire_Low_Side_Float" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=605" alt="Frigidaire_Low_Side_Float" src="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=605&amp;h=310" srcset="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=603&amp;h=310 603w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=1206&amp;h=620 1206w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=150&amp;h=77 150w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=300&amp;h=154 300w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=768&amp;h=395 768w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=1024&amp;h=526 1024w" sizes="(max-width: 605px) 100vw, 605px"></a>Nearly the same valve assembly, but removed from the evaporator housing. &nbsp;The baffle plate depicted helped to prevent the violent, boiling liquid refrigerant from being carried back the suction tube to the compressor. &nbsp;Some compressor oils would form a thin film on top of the refrigerant and would need carried back to the compressor. &nbsp;Various methods for this were devised; this Frigidaire obviously had a carefully placed hole in the suction tube for the purpose.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg"><img data-attachment-id="4074" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/bucket_float_valve/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg" data-orig-size="2216,965" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067430&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0012787723785166&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Bucket_Float_Valve" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=605" alt="Bucket_Float_Valve" src="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=605&amp;h=262" srcset="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=602&amp;h=262 602w, https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=150&amp;h=65 150w, https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=300&amp;h=131 300w, https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=768&amp;h=334 768w" sizes="(max-width: 605px) 100vw, 605px"></a>Another low side float valve assembly. &nbsp;It’s a beautiful illustration isn’t it? &nbsp;I read a patent on this type, and one of the advantages cited was that with an open, floating pan, the whole device is under equal pressure, there is no worry of it’s reliable operation, unlike&nbsp;a sealed ball float. &nbsp;The other use of the pan, as I think is well illustrated, is it’s use to collect oil vapors and collect them in the bottom for return to the compressor via the suction tube. &nbsp;I believe this float valve needle and valve seat can be removed and serviced without taking out the entire float assembly.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg"><img data-attachment-id="4085" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/norge_cycle_color/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg" data-orig-size="2865,2300" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067913&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0012787723785166&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Norge_Cycle_Color" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=605" alt="Norge_Cycle_Color" src="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=605&amp;h=485" srcset="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=605&amp;h=485 605w, https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=1208&amp;h=970 1208w, https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=150&amp;h=120 150w, https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=300&amp;h=241 300w, https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=768&amp;h=617 768w, https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=1024&amp;h=822 1024w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>A color illustration from “Modern Electric and Gas Refrigeration” by Althouse and Turnquist, 1933. &nbsp;Notable features: &nbsp;Pan Type Low SIde Float, Open Drive Rotary Compressor.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg"><img data-attachment-id="4077" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/electrolux_cycle_color/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg" data-orig-size="2067,2794" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365068022&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0013227513227513&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Electrolux_Cycle_Color" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=222" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=605" alt="Electrolux_Cycle_Color" src="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=605&amp;h=817" srcset="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=605&amp;h=817 605w, https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=1210&amp;h=1634 1210w, https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=111&amp;h=150 111w, https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=222&amp;h=300 222w, https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=768&amp;h=1038 768w, https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=758&amp;h=1024 758w" sizes="(max-width: 605px) 100vw, 605px"></a>From the same 1933 book, this Electrolux diagram has some neat features. &nbsp;It’s an open drive reciprocating compressor probably with a fan cooled condenser. &nbsp;Most domestic units were fan cooled by this time. &nbsp;Early in the 20s, the higher head pressures associated with atmospheric condensers made water cooled condensers more common. &nbsp;WIth the addition of condenser cooling fins and the increased air flow from fans tied to higher speed electric motors, air cooling became more practical. &nbsp;This unit has a curious evaporator. &nbsp;All though it has a low side float, the evaporator coil is one continuous loop like a dry type evaporator. &nbsp;This could lead to vapor pockets forming and elevated pressures over the suction pressure, decreasing the rate of ebullition. &nbsp;Another interesting feature being the extra loop or two in the suction line to vaporize any liquid refrigerant in the suction line.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg"><img loading="lazy" data-attachment-id="4076" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/crane_ge_monitor_top/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg" data-orig-size="1237,2413" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067582&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.00074626865671642&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Crane_GE_Monitor_Top" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=154" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=525" alt="Crane_GE_Monitor_Top" src="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=314&amp;h=614" width="314" height="614" srcset="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=314&amp;h=614 314w, https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=628&amp;h=1225 628w, https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=77&amp;h=150 77w, https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=154&amp;h=300 154w" sizes="(max-width: 314px) 100vw, 314px"></a>A common GE Monitor Top type refrigerator. &nbsp;This “package type” construction was common where the entire refrigerating apparatus was modular in that it could be easily removed from the cabinet for service or replacement.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg"><img data-attachment-id="4075" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/coldspot_refrigerator_unit/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg" data-orig-size="2299,1912" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365066974&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0011627906976744&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Coldspot_Refrigerator_Unit" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=605" alt="Coldspot_Refrigerator_Unit" src="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=605&amp;h=503" srcset="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=605&amp;h=503 605w, https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=1210&amp;h=1006 1210w, https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=150&amp;h=125 150w, https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=300&amp;h=249 300w, https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=768&amp;h=639 768w, https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=1024&amp;h=852 1024w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>This Coldspot has some features worth discussing. &nbsp;For one, it is the package type as described before with the compressor and condensing unit mounted atop the insulated cabinet top with the motor and compressor supported my springs to dampen vibration and noise. &nbsp;The evaporator is of the dry type where the refrigerant is fed to a long coil of tube or series of tubes at approximately the rate in which it is vaporized by the heat of the refrigerated cabinet. &nbsp;Some of the more crude early versions of this used a fixed orifice called a “restrictor”, having a fixed, triangle shaped opening to pass high pressure liquid refrigerant to the evaporator. &nbsp;Before the capillary tube came into use (invented in the late 20s) was the Automatic Expansion Valve which is little more than a pressure regulating valve maintaing a constant pressure within the evaporator coil, often with an adjustable spring compression. &nbsp;This knob or screw would often go out of adjustment because of the constant freeze/thaw occurring at these valves. &nbsp;They were often equipped with a rubber cap or boot to keep moisture from interfering with the adjustment. &nbsp;These AXVs work well in constant load conditions, but under high load tend to starve the evaporator of refrigerant and risk slugging liquid back to the compressor under low load. &nbsp;The improvement to these valves came with the addition of a thermostatic element or “sensor bulb” strapped to the suction line, the temperature of which alters the pressure within the the bulb and in turn, operates a diaphragm inside the valve to properly feed the correct amount of refrigerant to the coil given the conditions. &nbsp;This type of valve would be called a Thermostatic Expansion Valve.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg"><img data-attachment-id="4073" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/axv_dry_type/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg" data-orig-size="2146,2484" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067368&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0011574074074074&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="AXV_Dry_Type" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=259" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=605" alt="AXV_Dry_Type" src="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=605&amp;h=700" srcset="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=605&amp;h=700 605w, https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=1210&amp;h=1400 1210w, https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=130&amp;h=150 130w, https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=259&amp;h=300 259w, https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=768&amp;h=889 768w, https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=885&amp;h=1024 885w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>A very simple dry type evaporator with and AXV. &nbsp;Notice the Thermostatic Control Switch. &nbsp;This has nothing to do with the refrigerant supply, but simply controls the electrical current to the compressor and allows the operator to adjust the cabinet temperature. &nbsp;These worked with a thermostatic bulb strapped to the evaporator, suction line or somewhere else in the cabinet. &nbsp;The Thermostat was a great improvement over the controls of the 20s which sometimes used a pressure operated switch tied into the suction line. &nbsp;The service or replacement of these complicated switches could involved breaking the sealed refrigerant line.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg"><img data-attachment-id="4072" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/axv_brine_chiller/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg" data-orig-size="2251,1545" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365066923&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;125&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="AXV_Brine_Chiller" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=605" alt="AXV_Brine_Chiller" src="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=605&amp;h=415" srcset="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=605&amp;h=415 605w, https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=1210&amp;h=830 1210w, https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=150&amp;h=103 150w, https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=300&amp;h=206 300w, https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=768&amp;h=527 768w, https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=1024&amp;h=703 1024w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>An AXV on a dry type coil, but rather than direct expansion, this is a brine tank. &nbsp;The refrigerant tube passes through of a low freezing point brine which in turn froze ice cubes and chilled the space. &nbsp;These had the advantage of having a holdover effect to keep the cabinet cold and prevent short cycling of the compressor and also had a more constant loading effect on the AXV which made for more consistent and predictable performance. &nbsp;The down side of a brine system is the possible corrosive effects of the brine, extra cabinet space taken and the lower evaporator temperatures possibly needed to chill the brine to a temperature that it could in turn chill the refrigerator.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg"><img data-attachment-id="4083" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/ge_ck/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg" data-orig-size="2176,2571" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067164&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0014285714285714&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="GE_CK" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=254" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=605" alt="GE_CK" src="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=605&amp;h=715" srcset="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=605&amp;h=715 605w, https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=1210&amp;h=1430 1210w, https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=127&amp;h=150 127w, https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=254&amp;h=300 254w, https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=768&amp;h=907 768w, https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=867&amp;h=1024 867w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>A GE Monitor Top style refrigerating unit. &nbsp;A hermetic system with what looks like a rotary compressor and oil pump lubricating pump. &nbsp;The …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/">https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/</a></em></p>]]>
            </description>
            <link>https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278184</guid>
            <pubDate>Wed, 26 Aug 2020 01:40:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alberta government to support feasibility study for Edmonton-Calgary hyperloop]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24278095">thread link</a>) | @GnarlyWhale
<br/>
August 25, 2020 | https://www.cbc.ca/news/canada/calgary/transpod-alberta-hyperloop-mou-1.5697848 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/calgary/transpod-alberta-hyperloop-mou-1.5697848">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Toronto-based TransPod has signed an agreement with the Alberta government that will see the province support the firm's early efforts to advance development of an&nbsp;ultra-high-speed transportation line between Calgary and Edmonton.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4443903.1513038371!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/transpod-hyperloop.jpg"></p></div><figcaption>An illustration of what TransPod's hyperloop system might look like running beside a highway.<!-- --> <!-- -->( Radio-Canada/TransPod Hyperloop)</figcaption></figure><p><span><p>Canadian hyperloop&nbsp;company TransPod has signed an agreement with the Alberta government that will see the province support the firm's early efforts to advance development of an&nbsp;ultra-high-speed transportation line between Calgary and Edmonton.</p>  <p>Though the concept may still sound like&nbsp;science fiction, the company's ultimate goal is&nbsp;to have Albertans shuttling between Calgary and Edmonton in train-like pods — at speeds up to 1,000 kilometres an hour — through&nbsp;magnetic tubes by 2030.</p>  <p>On Tuesday, Toronto-based TransPod&nbsp;took a step forward by&nbsp;announcing it's&nbsp;inked&nbsp;a memorandum of understanding (MOU) with the province&nbsp;that will support the company in further studying the feasibility of the technology in Alberta, share transportation data and identify suitable land for a test track.</p>  <p>Alberta Transportation will also take part&nbsp;in discussions with potential large institutional investors "where suitable," according to the company.</p>  <p>The government hasn't made any&nbsp;financial commitments or endorsements.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_300/sebastien-gendron.jpeg 300w,https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_460/sebastien-gendron.jpeg 460w,https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_620/sebastien-gendron.jpeg 620w,https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/sebastien-gendron.jpeg 780w,https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_1180/sebastien-gendron.jpeg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/sebastien-gendron.jpeg"></p></div><figcaption>Sebastien Gendron, co-founder and CEO of Transpod, says the new agreement signed with the Alberta government is a "huge" step.<!-- --> <!-- -->(Tony Seskus/CBC)</figcaption></figure></span></p>  <p>TransPod's&nbsp;chief&nbsp;executive said in an interview he sees the MOU as key. The announcement comes less than year after the company urged the UCP government <a href="https://www.cbc.ca/news/canada/calgary/alberta-hyperloop-calgary-edmonton-1.5375476">to climb aboard the idea.</a></p>  <p><em>"</em>It's actually the first, I would say,&nbsp;official support from the government of a province which belongs to a G7 country," said CEO Sebastien&nbsp;Gendron, "which is kind of a huge step to confirm the path to commercialization."</p>  <p>Transportation Minister Ric McIver said he's hopeful that TransPod's work will lead to the development of new technology that's put into&nbsp;practice in Alberta, creating new opportunities for job creation.</p>    <p>"I am excited about the possibilities," McIver said in an interview. <em>"</em>TransPod [wants] a chance to prove what they can do and I think Alberta is the place where we should let them prove it."</p>  <p>McIver said there's no commitment to provide&nbsp;government money, but he added that if TransPod&nbsp;proves the technology, they will "certainly help them tell their story<em>.</em>"</p>  <p>"We're going to try to be facilitators for them," he said.</p>  <p>If privately held TransPod realizes its vision, its hyperloop system&nbsp;could move passengers or cargo between Calgary and Edmonton in about&nbsp;half an hour. The cost of a one-way ticket would range between $40 to $60, Gendron said.</p>  <p>To build the full line, however, would cost between $6 billion and $10 billion, he said.&nbsp;The company's goal&nbsp;is to attract private investment by showing that it's economically viable, Gendron added.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/transpod-calgary-skyline.jpg 300w,https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/transpod-calgary-skyline.jpg 460w,https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/transpod-calgary-skyline.jpg 620w,https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/transpod-calgary-skyline.jpg 780w,https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/transpod-calgary-skyline.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/transpod-calgary-skyline.jpg"></p></div><figcaption>An artist's rendering of the TransPod hyperloop against the Calgary skyline. <!-- --> <!-- -->(TransPod)</figcaption></figure></span></p>  <p>TransPod&nbsp;aims to demonstrate to large institutional investors that there's<em>&nbsp;</em>enough ridership for passengers, as well as goods.</p>  <p>"The second aspect is to do a really detailed cost analysis of the infrastructure," Gendron said.&nbsp;</p>  <p>"That will confirm the amount of investment we need to build the full line, which includes not only the infrastructure, but also the stations and the land acquisition."</p>    <p>Should things progress, TransPod&nbsp;would like to begin construction of a $500-million test track in Alberta in 2022. The final step would be to start construction of the full line, currently targeted to begin&nbsp;in&nbsp;2025.</p>  <p>The former NDP government had allocated 10 kilometres of land between Calgary and Edmonton to&nbsp;TransPod to build a test track. Gendron said they're looking at using the same area but would need to confirm once the feasibility study is complete.</p>  <p>Gendron said the company is also&nbsp;in the design and development phase for a testing facility in France.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/ric-mciver.jpg 300w,https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/ric-mciver.jpg 460w,https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/ric-mciver.jpg 620w,https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ric-mciver.jpg 780w,https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/ric-mciver.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ric-mciver.jpg"></p></div><figcaption>Transportation Minister Ric McIver said he's hopeful that TransPod's work will lead to the development of new technology that's put into&nbsp;practice in Alberta, spurring further job creation. The company estimates the project would create 38,000 jobs over the next 10 years.<!-- --> <!-- -->(Mike Symington/CBC)</figcaption></figure></span></p>  <p>Unlike trains, hyperloop&nbsp;systems don't use rails. Instead, they propel&nbsp;vehicles through a vacuum&nbsp;in sealed tubes at high speeds&nbsp;made possible by the extremely low friction inside the tube.</p>  <p>Tesla founder&nbsp;Elon Musk first outlined his vision for the hyperloop concept in 2013. Since then, it's also attracted the attention of billionaire Richard Branson, founding chairman of&nbsp;<a href="https://www.reuters.com/article/us-virgin-spirit-aerosystm-hyperloop/floating-on-air-virgin-hyperloop-signs-deal-with-key-jet-parts-maker-idUSKBN23W1OJ">Virgin Hyperloop One</a>.</p>  <p>Virgin Hyperloop's goal is to launch commercial routes by 2029.</p>  <p>Transpod and Spain's Zeleros are also competing to&nbsp;upend traditional passenger and freight networks with&nbsp;technology they say will slash travel times and&nbsp;congestion.</p>  <p>The discussion around&nbsp;hyperloop technology&nbsp;has been received with both excitement and&nbsp;skepticism over the years.</p>  <p>A Boeing executive last year rejected the suggestion&nbsp;hyperloop travel&nbsp;<a href="https://www.cnbc.com/2019/11/18/hyperloop-to-threaten-aviation-not-in-my-lifetime-says-boeing-exec.html">could threaten aviation within his lifetime</a>. The&nbsp;cost, complexity, regulation and safety of hyperloop&nbsp;systems have also been identified as challenges.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/calgary/transpod-alberta-hyperloop-mou-1.5697848</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278095</guid>
            <pubDate>Wed, 26 Aug 2020 01:23:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The catalyst for the next speculative crypto bubble]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24277841">thread link</a>) | @simplertms
<br/>
August 25, 2020 | https://4thquadrant.io/freearticles/the-catalyst-for-the-next-speculative-crypto-bubble/ | <a href="https://web.archive.org/web/*/https://4thquadrant.io/freearticles/the-catalyst-for-the-next-speculative-crypto-bubble/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_28_910">

<div>
<p>In 2017/18 cryptocurrencies went through a speculative bubble that saw its flagship currency Bitcoin reach peaks of $20,089 and a market cap of $320 billion. At the height of euphoria, the total market cap of all cryptocurrencies reached $790 billion. While Bitcoin and other cryptocurrencies (known as altcoins) have been around since 2009, it was the consolidation of mindshare and public interest in 2017 and 2018 that has made it a mainstay for alternative investors. But the fact remains that we are yet to see the adoption event that will make it a mainstay for all investors.</p>



<p>Most recently Cryptocurrencies have once again found a place in the news cycle following two years of dormancy post the bubble. The central trend appears to be around the phenomenon of decentralised finance otherwise known as DeFi. The quantity of activity and community participation in DeFi and related activities have been pointed to as potential indicators of a return to the speculative mania that took place in 2017. By the end of July, the total value locked up in DeFi related projects was $4 billion. A somewhat marginal amount given that Bitcoin is now over $200 billion in valuation and the whole market for cryptocurrencies is approaching $350 billion.</p>



<p>Regardless, DeFi represents a strong use case for cryptocurrencies as a means to provide lending and borrowing capabilities and is also geared to attract significant speculative interest. One of the most basic and pervasively engaged features of DeFi at present is yield farming. Cryptocurrency assets can earn or ‘farm’ yields in three main forms:</p>



<ol><li>Participating in financial products as one would in traditional markets</li><li>Locking up some cryptocurrency liquidity in return for an interest-like reward.</li><li>Staking cryptocurrency (like collateral) to fortify the security of a Proof-of-Stake based blockchain platform, where ‘staking’ some tokens prevents malicious activity similar to how a collateralized loan prevents default risk.</li></ol>



<p>However, the attention decentralised finance (DeFi) is getting right now, looks more like a bubble than a catalyst for adoption, where volatility (price, scams, hacks etc) of the industry hasn’t been solved.</p>



<p>The question then is, what is a catalyst for adoption? Given that financial products (form 1) on any platforms, blockchain or otherwise, can provide yields through participation, let us focus on yield farming native to the nature of blockchain (forms 2 &amp; 3), Proof-of-Stake – where providing security/liquidity returns yields.</p>



<p>Proof-of-Stake is simply the mechanism whereby a decentralised platform is able to provide security against attacks on the immutability of the ledger on the blockchain. The name holds the key to understanding this mechanism where ‘staking’ (locking up) the currency on the platform, is the means by which you are able to validate transactions on the ledger (the state of the blockchain) and add to the ledger. The game theory of securing the chain via staking is tied to rewards for being a good actor and penalties for being a bad actor. These rewards represent the yields earned for securing the chain.</p>



<p>What is particularly interesting as the speculation starts to ramp up once more is that Proof-of-Stake based platforms are gaining more attention because of their ability to provide yields in return for a financial stake in the platform. Yields on a Proof-of-Stake network represents a passive income avenue for a spectrum of individual/retail investors all the way to institutional players. This differs from the Proof-of-Work mechanism, most popularly represented by Bitcoin, which consumes electricity (mining) to secure the ledger. Where mining BTC is more difficult and less accessible to the spectrum of investors (currently there are a few large mining farms that make this their primary occupation) most BTC investors will make capital gain returns based on price appreciation through adoption. In the absence of BTC becoming a true global currency it will depend on a series of consolidating speculative bubbles to edge toward adoption – a chicken and egg problem perhaps sped along by the more consistent rewards associated with Proof-of-Stake.</p>



<h3>Yields: A Ponzi scheme or a catalyst for cryptocurrency adoption?</h3>



<p>Thus far the speculation on the future potential of blockchain technology, and cryptocurrencies by extension, is what gives the industry the large valuation it holds, even as use cases seem scarce or utilised by few.</p>



<p>In such a case, providing yields for no inherent value due to lack of use case, appears more like a Ponzi scheme than investment in a nascent technology. The idea is that when more people take a financial stake in the platform and lock up those funds for yields, all the prior participants will continue to benefit, not only from the yields but also from the price appreciation of the currency and market capitalisation of the platform. Of course, the integrity of the platform will only be realised when the use cases are actualised at some point in the future. In the interim, the Ponzi characteristics are exacerbated by the lucrative yield returns (often ranging from 5-20% per annum) made available by Proof-of-Stake networks, in comparison to traditionally available yield/interest earning financial products. It’s important to note that platforms vary in risk and reliability, we can liken it to investing in financial products across different tranches – some more junk-like than others.</p>



<p>Bitcoin, on the other hand, provides an entirely different avenue of investment in blockchain but comes with its own set of challenges – namely the chicken and egg problem we discussed above. Bitcoin requires the expense of electricity through mining activities to secure the network and ‘earn’ Bitcoin. While the rewards for mining on a Proof-of-Work network can be equated to the yields earned for staking on a Proof-of-Stake network, the ‘work’ performed for Proof-of-Work (cost of time and initial investment) makes it impossible for it to operate like a Ponzi scheme. Essentially, this means that Bitcoin can’t propagate its adoption through the mechanism of mining, where mining does not lend itself to the low-effort traits of Proof-of-Stake currently attracting attention to the DeFi bubble.</p>



<p>The lower effort in work required to secure the Proof-of-Stake network allows more users to participate meaningfully and earn yields. This is the beginning of a solution to the chicken and egg problem, where increased participation can bolster the market capitalisation required for widespread traction. In summary, easier participation increases the likelihood of network effect for a platform, where earning yields becomes the initial use case for the platform – as risky or unreliable as it may seem. Increased traction over time is very capable of evolving the volatile and Ponzi-like DeFi space into a mature financial structure supporting the blockchain ecosystem.</p>



<p>During 2017/18 the prevailing narrative of Proof-of-Work and crypto’s use case as a currency was not substantiated and resulted in a bubble rather than an adoption event. While it gained attention on the global stage, the widely held perception was that there was no immediately apparent use case that could sustain and grow its valuation beyond pure speculation. In the last couple of years following the bust of the speculative bubble, Proof-of-Stake has become a more significant narrative for the industry. The most marked indicator being Ethereum (currently Proof-of-Work), the second largest cryptocurrency, indicating its intent to transition to a Proof-of-Stake network.</p>



<p>The narrative of Proof-of-Stake is ballooning out quite rapidly, popularly considered to be propagated by the perceived benefits for scaling transaction capacity. However, what we have identified is that the use case of earning yields has the potential to catalyse the next boom cycle similar to 2017/ 18, and perhaps even to a greater extent. Even in the absence of yields as a catalyst for the next boom cycle, it represents a solid use case as a financial ecosystem to sustain speculative value and drive cryptocurrencies closer to mainstream use.</p>



<div id="slimcalltoaction"><p>This is box title</p><p>If you enjoyed this article, take advantage of our 14 days free trial to explore our exclusive content. Or sign-up for our free weekly newsletters. View our subscription options <a href="https://4thquadrant.io/subscribe">here.</a></p></div>
</div></div><div data-td-block-uid="tdi_29_cc5">

<div><h3><span>CONTACT THE EDITOR</span></h3>
<p>We welcome thoughtful discourse on all our content. If you would like to further explore or discuss any of the ideas covered in this article please contact our editors directly.<br><span>Contact Details</span></p>
</div></div></div>]]>
            </description>
            <link>https://4thquadrant.io/freearticles/the-catalyst-for-the-next-speculative-crypto-bubble/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277841</guid>
            <pubDate>Wed, 26 Aug 2020 00:31:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Embrace Beginner's Mind; Avoid the Wrong Way to Be an Expert]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24277832">thread link</a>) | @7d7n
<br/>
August 25, 2020 | https://eugeneyan.com/writing/beginners-mind/ | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/beginners-mind/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>When we learn something new, such as a programming language, we start as beginners. We can learn and follow the rules and apply them in a narrow context. However, we don’t understand the bigger picture and get lost outside of that specific context.</p>

<p>Imagine that I enroll in a <a href="https://en.wikipedia.org/wiki/Massive_open_online_course" target="_blank">MOOC</a> on <code>R</code> and learn about statistical analysis, machine learning, and <a href="https://rstudio.github.io/shinydashboard/" target="_blank"><code>Shiny</code></a> dashboards. As part of machine learning, I learn that I should <a href="https://www.rdocumentation.org/packages/caret/versions/6.0-86/topics/createDataPartition" target="_blank">split the data into train and test</a> sets. I apply this in assignments and Kaggle and everything works fine—this is the <em>narrow</em> context.</p>

<p>Then, perhaps I get the opportunity to apply my new skills in a <em>wider</em> context—I build a model, validate it (via random train-test split), and deploy it. However, the offline and online (i.e., A/B test) metrics don’t match up. Eventually, I figure out that I should use a <a href="https://www.fast.ai/2017/11/13/validation-sets/" target="_blank">time-based split</a> so future data doesn’t <em>leak</em> into the training set.</p>

<p>With the benefit of the wider context, I encountered challenges and failures (read: lessons) that were not part of the MOOC assignments. As a result, I got to see the bigger picture; I know there’s still lots to learn. Thus, I continue to learn and progress through the stages of beginner, intermediate, and so on.</p>

<blockquote>
  <p>The more I learn, the more I realise how much I don’t know. – Albert Einstein</p>
</blockquote>

<h2 id="from-beginner-to--expert-beginner">From beginner to … expert beginner</h2>

<p>But what happens if I <em>don’t</em> see the bigger picture?</p>

<p>Let’s assume I work in the HR department of a widget manufacturer. Everything—from headcount to payroll to vacation balance—is run in Excel. I apply my newfound <code>R</code> skills to automate my work via one-off scripts. This involves calculating statistics on factory sites and displaying it via a <code>Shiny</code> dashboard on the department desktop. In the eyes of my manager and team, I’m an absolute rockstar ninja wizard. I get showered with praise and am promoted to manager of HR data science.</p>

<p>I might not know about proper ML validation, deployment, unit tests, or even version control. I certainly haven’t done any of that. But who cares? We don’t need it. I’m now the manager of HR data science. I’m now… an “expert”.</p>

<p>To those in the know, I’m clearly still a beginner. But my context is narrow and I don’t see the bigger picture. Thus, I don’t know that there’s still lots to learn, lots to do. However, because I’ve achieved a modicum of success (through <em>narrow</em> applications of what I learned) and others call me an expert, I now view myself as an expert. As a result, I stop learning. I’m now stuck at a local optima. <strong>I’ve become an <a href="https://daedtech.com/how-developers-stop-learning-rise-of-the-expert-beginner/" target="_blank">expert beginner</a></strong>.</p>

<p>Suppose I stay in that same role, within HR, for 10 years. At the end of it, do I have 10 years of experience, or one year of experience repeated 10 times?</p>

<details><summary>An army of expert beginners led by an expert beginner</summary>
<div>

<p>As head of HR data science, I hire a team of data scientists. Eventually, some team members will suggest new technology (e.g., Python, Docker) or practices (e.g., version control, unit testing).</p>

<p>However, I’m the most experienced (read: longest tenure) and the expert-est expert. I dismiss ideas and technology that I’m unfamiliar with. “Oh, I see you’re new here. Yes, Python sounds like a good idea but the Chief HR Officer really likes the <code><span>Shiny</span></code> dashboard that I built.” “Haha, we don’t need unit tests! I live and breathe this code every day—there’s no need to test it”.</p>

<p>Team members who can see the bigger picture are disappointed by the outdated technology and incorrect practices. They see no room for learning and growth. As a result, <strong>the most talented and ambitious leave</strong> (if they know what’s best for them). For those who stay—hurray! There’s less competition. They’ll toe the line and one day, they’ll be a <em>senior</em> expert beginner and teach new joiners their “expert” ways.</p>

<p>This leads to the <a href="http://brucefwebster.com/2008/04/11/the-wetware-crisis-the-dead-sea-effect/" target="_blank">Dead Sea effect</a> where you’re <strong>left with your least talented and effective</strong> people. They’re grateful to have a job and settle in for a couple of years (or decades). Now, the team has (d)evolved into an army of expert beginners who follow the directions of the top expert beginner.</p>

<p><img src="https://eugeneyan.com/assets/dead-sea.jpg" title="The expert beginners are entrenched and can’t be replace" alt="The expert beginners are entrenched and can’t be replace"></p>
<p>The expert beginners are entrenched and can’t be replaced (source: <a href="https://eugeneyan.com/writing/beginners-mind/(https://dilbert.com/strip/2010-12-02)">Scott Adams</a>)</p>

<p>Because expert beginners have learned “everything” there is to learn, tried “everything” there is to try, and done “everything” there is to do, there’s nothing new to learn, try, and do. The team stops trying new ideas—“Oh we don’t use Docker here. We have VMs!”—and the organization stops innovating.</p>

<p>This partly explains some industries getting disrupted. The iPhone disrupting Nokias and Blackberrys, AWS disrupting on-premise hardware, Stripe disrupting payment processing, Tesla disrupting… you get the idea.</p>

</div>
</details>

<p><img src="https://eugeneyan.com/assets/climbed-it-all.jpg" title="The expert beginner doesn't see the bigger picture and is thus stuck" alt="The expert beginner doesn't see the bigger picture and is thus stuck"></p>
<p>The expert beginner doesn't see the bigger picture; thus, he is stuck.</p>

<h2 id="the-beginners-mind-is-always-a-student">The beginner’s mind is always a student</h2>

<p>How do we prevent stagnation (and possibly becoming an expert beginner)? How do we stay open-minded and constantly learning and experimenting?</p>

<p><strong>One way is <a href="https://en.wikipedia.org/wiki/Shoshin" target="_blank">Shoshin</a> (beginner’s mind)</strong>. It’s a concept from Zen Buddhism on having an attitude of openness, eagerness, and no preconceptions, even when our knowledge of the subject is advanced. In other words, to think <em>just</em> like a beginner.</p>

<blockquote>
  <p>In the beginner’s mind there are many possibilities, but in the expert’s there are few. – Shunryu Suzuki</p>
</blockquote>

<p>With beginner’s mind, regardless of your experience and expertise, you <strong>stay curious and approach new ideas and experiences as a student</strong>. Even when new technology or methods don’t fit your paradigm, you’re open to learning and trying it. Students don’t say “That’s not how we do things here”.</p>

<p>Sometimes, when others view us as experts, we let it get to us. We stay within our narrow subject matter expertise and stop exploring new ideas and possibilities. We avoid newer, bigger challenges so we don’t make mistakes; we stick to what has worked in the past. This helps preserve our expert identity.</p>

<blockquote>
  <p>The most dangerous phrase in the language is, “We’ve always done it this way.” – Grace Hopper</p>
</blockquote>

<p>But this doesn’t make sense. In my field of data science, new tools (e.g., Spark, Docker, Airflow) and methods (e.g., embeddings, attention, pre-training) constantly improve on the state of the art (SOTA)—it’s useful, if not essential, to keep up to date. (That said, fundamental techniques like regression and decision trees are often a solid baseline.)</p>

<h2 id="the-beginners-mind-keeps-on-pedalling">The beginner’s mind keeps on pedalling</h2>

<p>Learning is like cycling. When we start pedalling (from a standstill), it takes effort and time to gain momentum. Nonetheless, we’ll pick up speed and begin gaining distance.</p>

<p>We might look back at where we started and think “Wow, I’ve come a long way. Perhaps I don’t have to pedal as hard; perhaps I don’t have to pedal at all.” If we stop pedalling, the initial momentum might carry us slightly further, but eventually, we’ll come to a standstill. While we don’t lose the distance covered, we’re not gaining distance either. (Though in fast-paced fields like tech, if you don’t move forward, <em>you begin to move backward</em>.)</p>

<p>Here, distance is knowledge (and achievements); momentum is learning. While distance is correlated with expertise, the relationship is not as strong as we think (e.g., one year of experience repeated 10 times). I think momentum (the ability to learn and adapt quickly) is part of expertise as well. The experts I know are often reading or hacking. At work, they can synthesize their mental prototypes and tailor solutions based on context.</p>

<p>To maintain momentum, <strong>the beginner’s mind continues to pedal regardless of the distance they’ve covered</strong>. It’s not surprising that many successful people are—and continue to be—voracious readers and learners. Warren Buffet, Bill Gates, Elon Musk, just to name a few. Do you know any successful person that doesn’t read or learn?</p>

<blockquote>
  <p>The illiterate of the 21st century will not be those who cannot read and write, but those who cannot learn, unlearn, and relearn. – Alvin Toffler</p>
</blockquote>

<details><summary>Note: Not all knowledge is the same</summary>
<div>

<p>There’s knowledge that we gain from books and courses—we’re tested on this in exams. Then, there’s <a href="https://commoncog.com/blog/the-tacit-knowledge-series/" target="_blank">(tacit) knowledge</a> that we gain from practice—we’re tested on this in life.</p>

<div>

<blockquote><div lang="en" dir="ltr"><p>You cannot get educated by this self-propagating system in which people study to pass exams, and teach others to pass exams, but nobody knows anything.</p><p>You learn something by doing it yourself, by asking questions, by thinking, and by experimenting. 🧠</p></div>— Richard Feynman (@ProfFeynman) <a href="https://twitter.com/ProfFeynman/status/1295411496407556096?ref_src=twsrc%5Etfw">August 17, 2020</a></blockquote>

</div>

<p>For example, learning to ride a bicycle. We can’t learn to ride a bike by reading a textbook. The <strong>only way to learn is by actually doing it</strong>. We’re going to lose balance and fall, but eventually, we’ll figure it out. Also, our ability to ride a bike is <strong>transferable</strong> to other two-wheeled transport. Once we learn how to ride a regular bike, we’ll have a gentler learning curve on mountains bikes, tandem bikes, and even e-scooters.</p>

<p>Similarly, some skills and knowledge <strong>can only be gained through practice</strong>. They’re usually <strong>transferable</strong> across multiple domains too. For example, what’s the most suitable way to <a href="https://bugra.github.io/posts/2020/5/25/how-to-serve-model/" target="_blank">serve models in production</a>? There are some common patterns: compute offline and cache, serve via microservice, embed in the main app. Do these patterns differ across domains? Not much. Which is the best approach for our use case? Well, it depends—knowing the answer is tacit knowledge.</p>



<p>Often, such skills and knowledge are <strong>fundamental</strong> and can be thought of as building blocks (or <a href="https://jamesclear.com/first-principles" target="_blank">first principles</a>). For example, in programming, we learn about conditionals, iteration, and data structures. In distributed data processing, we learn about map, reduce, and shuffle. Once we understand these fundamentals, it’s easier to pick up another programming language or distributed processing framework. It also helps us write more effective software and <a href="https://en.wikipedia.org/wiki/Extract,_transform,_load" target="_blank">ETL</a> jobs.</p>

<p>Mastering the fundamentals also helps with the <a href="https://commoncog.com/blog/to-get-good-go-after-the-metagame/" target="_blank">metagame</a>. The meta (i.e., higher-order factors) changes constantly. For example, <a href="https://eugeneyan.com/writing/nlp-supervised-learning-survey/" target="_blank">natural language processing</a> has evolved rapidly from recurrent models to embeddings to attention to …</p></div></details></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/beginners-mind/">https://eugeneyan.com/writing/beginners-mind/</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/beginners-mind/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277832</guid>
            <pubDate>Wed, 26 Aug 2020 00:28:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're not landing job interviews thanks to new technologies]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24277713">thread link</a>) | @hollaur
<br/>
August 25, 2020 | https://www.thevectorimpact.com/how-to-apply-for-jobs-online/ | <a href="https://web.archive.org/web/*/https://www.thevectorimpact.com/how-to-apply-for-jobs-online/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

						
						<article id="post-2564">

							
							<section itemprop="articleBody">

								
<span itemprop="reviewBody"><p><i><span><img title="how to apply for jobs online 2020 meme" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme.jpg" alt="meme: &quot;When does season 2 of 2020 start? I do not like season 1.&quot;" width="1200" height="1200" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme.jpg 1200w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme-300x300.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme-1024x1024.jpg 1024w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme-150x150.jpg 150w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme-768x768.jpg 768w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme-125x125.jpg 125w" sizes="(max-width: 1200px) 100vw, 1200px">Can I get an Amen?</span></i></p>
<p>Whether you’re lucky enough to be employed or currently out of work, it’s no secret that <strong>landing a job in 2020 is harder than ever before.</strong></p>
<p><span>And while it’s easy to blame coronavirus and wallow in our job-seeker sorrow—and believe me, I’m not ignoring the very real challenges of our current economy—my research suggests there’s more to it than that.</span></p>
<p><span>A friend of mine had been applying to jobs prior to the pandemic, and he hadn’t landed a single interview.&nbsp;</span></p>
<p><span>I thought I’d have the solution to his problem in all of five minutes (I used to be </span>p<span>retty good at applying for jobs online</span><span>), but it turns out he was already doing everything </span><i><span>“right.”</span></i><span>&nbsp;</span></p>
<p><span>His resume listed quantified bullet point after quantified bullet point. The formatting looked good. He tailored his cover letters to the position descriptions. His online presence is superb; he owns the front page of Google results for his name. And LinkedIn rated his profile as an “All-Star.” Oh yeah, he’s also gainfully employed.</span></p>
<p><span>You might be thinking, “Well, if he applied through job boards, that’s his first problem.”&nbsp;</span></p>
<p><span>And I’m thinking, “He used to apply through job boards and land interviews more than 60 percent of the time just a few years ago, so what’s changed?”&nbsp;</span></p>
<p><span>Turns out, A LOT. And I would’ve never known if it wasn’t for my friend stumping me with his seemingly simple quandary. I’m flabbergasted by how out of touch I was with the modern job hunt, which is why I couldn’t </span><b>not</b><span> write this post.&nbsp;</span></p>
<p><strong>With the average job tenure lasting just one year on average, it’s extremely likely you’ll need to understand <i>why</i> in the near future.&nbsp;</strong></p>
<p><span>I wrote this post to demystify the modern recruiting process and help qualified candidates figure out how to apply for jobs online. So if you’re ready to make it past the initial resume screening process and score an interview—and ultimately land the opportunity you deserve—then keep reading.</span></p>

<h2><span id="Why_is_landing_a_job_so_hard"></span><span>Why is landing a job so hard?</span><span></span></h2>
<p><span><img title="how to apply for jobs online landing a job is hard" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-landing-a-job-is-hard.jpg" alt="" width="1200" height="600" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-landing-a-job-is-hard.jpg 1200w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-landing-a-job-is-hard-300x150.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-landing-a-job-is-hard-1024x512.jpg 1024w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-landing-a-job-is-hard-768x384.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px">Yes, we’re in the midst of a <a href="https://www.npr.org/series/812054919/the-coronavirus-crisis">global pandemic</a> and <a href="https://fortune.com/2020/07/12/how-is-us-economy-doing-2020-recession-unemployment-rate-benefits-consumer-spending-job-losses-state-by-state-pmi-coronavirus-pandemic/">record unemployment</a>, and that undoubtedly makes the job market more competitive than ever.&nbsp;</span></p>
<p><span>Yet, even prior to the world turning upside down, the lamest of job ads received an insane amount of applications. The consensus seems to be about </span><a href="http://www.inc.com/peter-economy/19-interesting-hiring-statistics-you-should-know.html"><span>250 applications per job listing</span></a><span>, on average.&nbsp;</span></p>
<p><span><img title="how to apply for jobs online job applications 02" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02.png" alt="Breaking down job applications infographic. Out of 250 applications, 4-6 will be interviewed, and only 1 will receive an offer." width="2084" height="1244" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02.png 2084w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02-300x179.png 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02-1024x611.png 1024w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02-768x458.png 768w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02-1536x917.png 1536w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02-2048x1223.png 2048w" sizes="(max-width: 2084px) 100vw, 2084px">Of course, super-competitive positions get a lot more… supposedly anyway.&nbsp;</span></p>
<p><span><a href="https://twitter.com/jasonfried/status/1147166154089213953"><img title="how to apply for jobs online jason fried tweet" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-jason-fried-tweet.jpg" alt="tweet by Jason Fried: &quot;Out of everyone who applied for the Basecamp Head of Marketing job, only one person used an ad on LinkedIn to get an extra ounce of notice.&quot;" width="1000" height="802" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-jason-fried-tweet.jpg 1000w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-jason-fried-tweet-300x241.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-jason-fried-tweet-768x616.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a>And you know what they say… </span><b>ain’t no recruiter got time for that.</b></p>



<p><strong>But seriously, <i>they don’t</i></strong><span>—not in a metrics-driven world, where companies are obsessed with automating everything to do things as fast as possible, even at the cost of quality.&nbsp;</span></p>

<h3><span id="Applicant_Tracking_Systems_What_you_need_to_know"></span><span>Applicant Tracking Systems: What you need to know</span><span></span></h3>
<p><span><img title="how to apply for jobs online applicant tracking systems" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-applicant-tracking-systems.jpg" alt="" width="1000" height="667" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-applicant-tracking-systems.jpg 1000w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-applicant-tracking-systems-300x200.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-applicant-tracking-systems-768x512.jpg 768w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-applicant-tracking-systems-360x240.jpg 360w" sizes="(max-width: 1000px) 100vw, 1000px">Enter the </span><span><a href="https://www.reportsanddata.com/report-detail/applicant-tracking-system-ats-market">$1.3 billion recruiting technology/software industry</a>.&nbsp;</span></p>
<p><span>While there are a variety of modern recruitment tools for each stage of the hiring process, the one that will affect you the most is the </span><a href="https://fairygodboss.com/career-topics/applicant-tracking-systems"><span>Applicant Tracking System (ATS)</span></a><span>.&nbsp;</span></p>
<p><span><img title="how to apply for jobs online 2020 applicant tracking system process 02" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02.png" alt="Applicant tracking system process" width="2085" height="3088" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02.png 2085w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02-203x300.png 203w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02-691x1024.png 691w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02-768x1137.png 768w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02-1037x1536.png 1037w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02-1383x2048.png 1383w" sizes="(max-width: 2085px) 100vw, 2085px">It’s pretty much guaranteed that your application is going through an ATS any time you apply for a job online, since at least </span><a href="https://www.jobscan.co/blog/fortune-500-use-applicant-tracking-systems/"><span>98 percent of Fortune 500 companies use one</span></a><span>.&nbsp;</span></p>
<p><span>TLDR: ATS help recruiters/hiring managers collect, sort, and organize a large number of applications.&nbsp;</span></p>

<h4><span>Most Common ATS Features</span></h4>
<p><span>Rather than manually reviewing each resume, recruiters and hiring managers search for resumes based on keywords, or have the system filter or automatically rank applicants.&nbsp;</span></p>
<p><span>In many cases, recruiters use the technology to do a first pass of resumes, meaning you can be removed from consideration </span><b>by an algorithm without ever being reviewed by a human</b><span>.&nbsp;</span></p>
<p><span><img title="how to apply for jobs online what happens to your resume ats 02" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02.png" alt="Infographic: What happens to your resume in an applicant tracking system" width="2501" height="10553" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02.png 2501w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02-71x300.png 71w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02-243x1024.png 243w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02-768x3241.png 768w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02-364x1536.png 364w" sizes="(max-width: 2501px) 100vw, 2501px">While there </span><a href="https://blog.ongig.com/applicant-tracking-system/top-ats-systems-used-by-the-fortune-500-2019"><span>hundreds of ATS on the market</span></a><span>, most of them list the same features. Understanding them is key to landing an interview. Here are the big ones that will determine whether a human ever sees your resume.</span></p>

<h5><span>Automatic Applicant Ranking/Scoring</span></h5>
<p><span>Many ATS provide an automatic “match rank” or score for each applicant.&nbsp;</span><span><a href="https://www.jobscore.com/features/submit-resume/"><img title="how to apply for jobs online ats ranking scoring" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring.jpg" alt="candidate match score example on Job Score website" width="982" height="400" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring.jpg 982w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-300x122.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-768x313.jpg 768w" sizes="(max-width: 982px) 100vw, 982px"></a>The system will take and parse the information from your resume, and compare it with the job description, looking for specific keywords, then provide a score from 0 to 100, or one to 10, that tells recruiters how qualified a candidate is for said job, based on the criteria set by the hiring manager.&nbsp;</span></p>
<p><span><a href="https://www.jobscore.com/features/submit-resume/"><img title="how to apply for jobs online ats ranking scoring 02" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-02.jpg" alt="ATS extracts contact info, employment and education history from resumes" width="1000" height="420" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-02.jpg 1000w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-02-300x126.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-02-768x323.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a>They’ll also score you based on the answers you submit via the online form, aka “knockout questions.”&nbsp;</span></p>
<p><span><a href="https://www.jobscore.com/features/submit-resume/"><img title="how to apply for jobs online ats ranking scoring 03" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-03.jpg" alt="Job Score website, qualifying questions" width="1000" height="763" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-03.jpg 1000w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-03-300x229.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-03-768x586.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a></span></p>
<p><span>For example, job posts that ask for your location are likely using that information as a filter that will alter your overall qualification score.&nbsp;</span></p>

<h5><span>Comprehensive Candidate Profiles</span></h5>
<p><span>Many ATS will automatically create a comprehensive, wildly detailed profile of you based on your digital footprint and other “public” information. All they need is your email address to populate every piece of available content about you online.&nbsp;</span></p>
<p><span>According to </span><a href="https://resources.workable.com/tutorial/important-applicant-tracking-system-features"><span>Workable</span></a><span>, aggregating candidates’ public information is a way to “humanize” the process, and they list it as a must-have feature for today’s ATS. Here’s how they describe it:</span></p>
<p><i><span>“I want to see faces dammit. And tweets. And maybe other stuff that humanizes this record.”</span></i></p>
<p><span>(In my opinion, that’s just a recipe for complete and total bias, as we know </span><a href="https://www.crowdstaffing.com/blog/hidden-bias-that-affect-the-hiring-process"><span>there’s A LOT of it in recruiting</span></a><span>, even if it’s subconscious.)&nbsp;</span></p>
<p><span>Many <a href="https://www.entelo.com/products/platform/search/">recruitment tools</a> even go so far as to make predictions about candidates based on the information they surface about them online.&nbsp;</span></p>
<p><a href="https://www.entelo.com/products/platform/search/"><span><img title="how to apply for jobs online ats candidate profiles" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-candidate-profiles.png" alt="Profile of senior product designer at Acme and predictions about his performance, fit, and longevity." width="1010" height="958" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-candidate-profiles.png 1010w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-candidate-profiles-300x285.png 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-candidate-profiles-768x728.png 768w" sizes="(max-width: 1010px) 100vw, 1010px"></span></a></p>
<p><span>In </span><a href="https://recruitingtools.com/boolean-strings-network/"><span>one of the first posts I read by a recruiter</span></a><span> on this topic, she tells hiring managers to search data enrichment tools/databases, like Pipl, Jigsaw and Zoominfo.&nbsp;</span></p>
<p><span>Pipl’s main use case is for “investigations.”&nbsp;</span></p>
<p><i><span>“</span></i><a href="https://pipl.com/investigation-and-research"><i><span>Pipl’s identity resolution engine</span></i></a><i><span> cross-references global data from the Internet, public records, listings, directories, archives and exclusive sources to show the connections between people and the world.”</span></i></p>
<p><span>ZoomInfo is more for B2B data enrichment. Check out the screenshot below to see how they collect your information.&nbsp;</span></p>
<p><span><a href="https://www.zoominfo.com/business/our-data?utm_campaign=branded"><img title="how to apply for jobs online candidate profiles zoominfo 02" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-candidate-profiles-zoominfo-02.jpg" alt="ZoomInfo" width="1000" height="899" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-candidate-profiles-zoominfo-02.jpg 1000w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-candidate-profiles-zoominfo-02-300x270.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-candidate-profiles-zoominfo-02-768x690.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a>Pretty scary, huh?&nbsp;</span></p>

<h5><span>Resume Parsing</span></h5>
<p><span>This is sort-of a feature of the “Automatic Applicant Ranking/Score” section, but it’s also important to mention on its own.&nbsp;</span></p>
<p><span>Resume parsing refers to how ATS extracts and organizes your resume into “structured data,” so they can do stuff like rank/score you automatically.&nbsp;</span></p>
<p><span>This means that many times submitting a PDF, or using creative typography, will hurt you, because the ATS can’t read the data well, if at all.&nbsp;</span></p>

<h5><span>Resume Storage</span></h5>
<p><span>Even if you’re rejected for a position, the ATS will store your resume in its system, because every time there’s a new role to fill, they’ll start with searching their databases to see who might be a match, which leads me to the next feature.&nbsp;</span></p>

<h5><span>Search and Filters</span></h5>
<p><span>ATS allows hiring managers to search by any keyword, and often with </span><a href="https://recruitingtools.com/boolean-strings-network/"><span>Boolean search</span></a><span>, which connects keywords using AND, OR, NOT and NEAR.</span></p>
<p><span>Some tools will even let you filter by those it labels “not job hoppers,” etc.&nbsp;</span></p>
<p><span>Filters may include the job seeker’s location, application source, age of your profile, and whether or not you’re an employee referral.&nbsp;</span></p>

<h4><span>Recruiters’ dirty little secrets&nbsp;</span></h4>
<h5><span>Backchanneling / Backdoor references</span></h5>
<p><span>If the recruiter actually sees your resume and is interested in interviewing you, she’ll likely visit your LinkedIn profile to make sure everything checks out.&nbsp;</span></p>
<p><span>She may even message any mutual connections you have to see what they’ll say about you. This is illegal but it happens all the time from </span><a href="https://www.glassdoor.com/blog/8-secrets-recruiters-wont-tell-you/"><span>what I read</span></a><span>.</span></p>
<p><i><span>“This phenomenon is even more prevalent in the last five years or so because of LinkedIn’s growing popularity. Even if you choose not to give anybody there as a reference, backdoor references can reveal the skeletons in your closet. Backdoor references can be especially common when you’re looking for a job in sectors like tech.”</span></i></p>

<h5><span>Cyberstalking</span></h5>
<p><span>Another potentially discriminatory and sometimes illegal practice includes cyberstalking you.&nbsp;</span></p>
<p><i><span>“A lot of recruiters—most that I know—will Google candidates who make it pretty far [in the hiring process], and then use Google image results, and also blog posts, tweets, and open Facebook accounts to judge someone’s character and credibility.” (</span></i><a href="https://www.fastcompany.com/40441093/former-recruiters-reveal-the-industrys-dark-secrets-that-cost-you-job-offers"><i><span>Source</span></i></a><i><span>)</span></i></p>

<h5><span>[Subconscious] Bias</span></h5>
<p><span>Whether it’s subconscious or downright discriminatory, hiring managers usually have a </span><a href="https://www.fastcompany.com/40441093/former-recruiters-reveal-the-industrys-dark-secrets-that-cost-you-job-offers"><span>preconceived picture</span></a><span> of what the perfect candidate looks like, which often is based on stereotypes.</span></p>

<p><b>Bias 1: Being overweight</b></p>
<p><span>Weight bias is still especially prevalent, according to one recruiter, who says being overweight can make people think the person is lazy or lacks motivation.</span></p>

<p><b>Bias 2: “Diversity”</b></p>
<p><span>“Diversity in Silicon Valley’s mind is the picture of Phylicia Rashad,” (the actress who portrayed Clair Huxtable on The Cosby Show), said another recruiter </span><a href="https://www.fastcompany.com/40441093/former-recruiters-reveal-the-industrys-dark-secrets-that-cost-you-job-offers"><span>via the same article</span></a><span>.&nbsp;</span></p>
<p><span>According to the post, she sees African-American women considered more readily for roles as diversity/inclusion chiefs, while white men more often lead the pack to head up sales teams.</span></p>
<p><span>Another recruiter bolsters her experience:&nbsp;</span></p>
<p><i><span>“There’s a penchant to see more diversity, but the definition is narrow,” typically reduced to race and gender; it was common to tout a candidate for being a “visible minority.” “It’s the only way to highlight that for the client on a call,” he explains, since “we can’t put it in our documentation.”</span></i></p>

<p><b>Bias 3: Looking “too young”&nbsp;&nbsp;</b></p>
<p><span>The same recruiter from above said he also sees a lot of ageism in the hiring process.&nbsp;</span></p>
<p><span>For example, there’s kind-of a sweet spot in terms of age for C-level positions, he said.&nbsp;</span></p>
<p><span>“My boss would say things like, ‘Did they have enough gray hair?’—not literally, but are they seasoned enough, do they have enough experience where they could be credible?”&nbsp;</span></p>
<p><span>There were occasions when recruiters would nominate younger, well-qualified candidates for senior leadership roles, Mark recalls, but “I’d say 20% of the time they’re open to meeting with that person.”</span></p>

<p><b>Bias 4: Expensive degrees</b></p>
<p><span>At the beginning of the recruitment process, recruiters are dealing with so many resumes that they use a prestigious degree as a quick way to filter down the candidate pool.&nbsp;</span></p>
<p><span>According to a recruiter from that FastCompany article I mentioned …</span></p></span></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thevectorimpact.com/how-to-apply-for-jobs-online/">https://www.thevectorimpact.com/how-to-apply-for-jobs-online/</a></em></p>]]>
            </description>
            <link>https://www.thevectorimpact.com/how-to-apply-for-jobs-online/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277713</guid>
            <pubDate>Wed, 26 Aug 2020 00:06:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's it like as a Senior Engineer?]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24277414">thread link</a>) | @benkwokcy
<br/>
August 25, 2020 | https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/ | <a href="https://web.archive.org/web/*/https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->


				<div>
					<p>When I started working at Microsoft, fresh out of college, coding was my life. Writing code was the easiest way to build any cool thing that my brain could imagine. &nbsp;When I thought about what I’d want to do for the rest of my life I thought that I just wanted to keep coding. </p><p>During the next 11 years I became a Senior Engineer at Microsoft and moved on to work at Google and later Stripe. At these higher levels I still get to build, but I use a very different set of tools to do it. There’s a huge mindset shift needed when you go from junior to senior. Writing code becomes a minor part of the job. </p><p>Ever built a tool no one used? I have. It sucked. At the senior levels most of your time goes into identifying <strong>what </strong>needs to be built and <strong>how </strong>to build it. You have to research what the problem looks like. You talk to others and get everyone to agree on what needs to be done. </p><p>These are your new tools:</p><ul><li>Research the problem</li><li>Design the solution</li><li>Build consensus</li></ul><h2 id="research-like-a-detective">Research like a Detective</h2><p>Fresh out of college you get handed tasks where the right answer is pretty straightforward. There isn’t much disagreement on what to do other than the occasional feedback in code reviews.</p><p>As you get more experienced your problems become more ambiguous. The path looks hazy. There are multiple routes you could take, but each one hides its own dragons. It’s not about coding anymore. Most of your work goes into research, and you can’t google the answer.</p><p>Research can take many forms. It usually involves a combination of reading code, reading documentation, and talking to people. Yes, actual human beings. In fact, that’s where most of the information you’ll need is locked away. Did you ever see Sherlock Holmes using search engines? </p><figure><img src="https://lh3.googleusercontent.com/8zyhAq2HSKAYAzysnJfbR_m6ZCBloCL5jbUmlwLEnJnmErsiHzd6gOEPtMpJZIp961AlNxUrdloY4B3cFFpVca5iH7Xb3wJgj0rFG7TLO60IGey4TaOJGZITimTXGv7U9hXqh-Pp" alt=""></figure><p>There often is no single person who knows the answer you need. Five different people might hold five different pieces of the puzzle you’re assembling. And you don’t know who those five people are. And they don’t know which pieces you need.</p><p><em>You </em>have to find them. Find them and ask the right questions to sift through their brains, uncovering the nuggets you need.</p><h6 id="sifting-for-nuggets">Sifting for nuggets</h6><p>At Google Cloud Platform, customers would often contact the Technical Solutions Engineers for help when they ran into issues. Those TSEs dug into the problems and fixed them. </p><p>My manager had an idea: “Wouldn’t it be great if we could use AI to automate that process?” We had no clue how to do it. Didn’t even know if it was possible. Heck, we weren’t even sure what kind of problems customers were asking for help with. But that was the challenge my manager offered.</p><p>I accepted.</p><p>Now any AI solution for this kind of a problem requires lots of data. The AI needs to see many broken environments to understand what they look like. And as I searched around I realized we didn’t have that data, it was all locked away in the brains of those TSEs. You can’t train AI with that. </p><p>I had to find the patterns. Maybe chatting with the TSEs would reveal something...</p><p>Me: “So, what type of problem do you usually face?”</p><p>TSE: “Eh, it’s something different every time”</p><p>Darn it, The AI future was looking bleak. </p><p>Me: “Well, what do you do to solve it?”</p><p>TSE: “It depends. Based on the problem, we’ll query one database or another. Then that’ll point us somewhere else, and we keep digging until we find what’s wrong. Then we fix it.”</p><p>No solid data on what problems they solve. No repeatable way to fix them. I was ready to give up.</p><p>Wait a second.</p><p>“Tell me more about these queries you run?”</p><p>What if I changed the problem? Maybe I didn’t have to fix those customer issues right off the bat. What if I helped TSEs debug the problems faster? I could automatically run the hundreds of queries they might run and suggest “Hey, this one had a suspicious result. Maybe dig a bit deeper there?” That’s a lot of debugging the TSEs could avoid.</p><p>I could even extend this to collect the data needed for an actual an AI system. This had potential! The TSEs were excited. My team was excited. My manager was excited. We began coding.</p><h2 id="design-the-art-of-balance">Design: The Art of Balance</h2><p>With ambiguous problems there is no single right answer anymore. There might not be any answer. What you have is a pain point. It could be your customers’s pains, your team’s pains, or even your own pain. The existence of that pain is the problem. Your job is to remove that pain without introducing even greater pains.</p><p>There’s a funny thing about ambiguous problems: they don’t have a clear right answer. Every solution offers certain benefits and has certain downsides. The more of those you discover, the better you’ll be at balancing the tradeoffs you have to make. Some common trade offs to consider:</p><ul><li>How long will it take to develop the solution?</li><li>What’s the opportunity cost?</li><li>How risky is it? What happens if that thing fails?</li><li>How much work will it be to maintain this going forwards?</li><li>How far will it scale? How far does it need to?</li></ul><p>With these ambiguous problems, sometimes the best answer can be “keep doing the thing we’ve been doing.” That was a tough lesson to learn. </p><h6 id="young-and-naive">Young and Naive</h6><p>When I was a wee lad four years out of college, I had been asked to come up with a way to make our database upgrades less risky. The team would manually review all the planned changes to make sure they were safe, but once in a while a bug would slip though and the sound of pagers going off would fill the room as everyone frantically tried to fix it.</p><p>“Can we build a tool to catch those risky changes?” my manager asked me. Woah, this was a super open ended problem. Sweet! I was determined to not let him down. This required digging deep into database upgrade best practices (I even read a whole <a href="https://martinfowler.com/books/refactoringDatabases.html">book on it</a> cover to cover). I spent the winter holidays toiling away developing a prototype that could do upgrades safely. And it worked! Kinda.</p><p>When I showed my creation to my manager he was worried: “You know what, let’s just stick with doing things the way we do right now.” </p><p>Ouch. </p><p>It was a tough lesson on risk management, but he made the right call. A bug in my tool could have brought our entire service down. It wasn’t worth the risk.</p><figure><img src="https://lh6.googleusercontent.com/-SpPwF1sWOPZD0HnYx0IqqluusAVritix1g7_NToe3s93jEmkPTsYhCTHJdPh7axMdLIN6gZ0fJ1_01AiPDputH2wPnMBXTDmgfxYIFAicsQeyAlq8Y9fRTxBFljmx9FZYi1Pdcy" alt=""></figure><p>There were multiple lessons I learned that day:</p><ul><li>Consider how much risk any new project might add to the system</li><li>It’s okay to fail. If you never fail then you’re not stretching yourself</li><li>Get feedback early! </li></ul><p>To get that feedback communication is crucial. Tell people what you’re going to build before you build it and let them warn you about any pitfalls before you step into one. If I had shared that design with my manager before building it we would have cancelled the project weeks earlier. And I would have had a relaxing winter break.</p><p>But collecting feedback requires a soft skill: empathy.<strong> </strong>Can you understand why people disagree with you? What are they valuing differently?</p><p>You may not always agree with the feedback, but you have to understand it. Only then can you move forward with a new vision that everyone can get behind.</p><h2 id="build-consensus">Build Consensus</h2><p>Getting that feedback and agreeing on the plan grows more important as your projects get bigger.</p><p>You may start off just having to get your manager to agree (he’s the one who gave you that ambiguous task). But you’ll need to build consensus with the rest of your team and even people outside your team who have a stake in your work. </p><p>This requires communication skills, both to understand and be understood.</p><p>Once I was tasked with creating the next generation of our internal database management system. This was something many teams depended on, and our current solution would stop scaling a year or two down the line. My team had seven different people with eight different opinions about what the system should look like. That included my manager and skip level. Oy vey. </p><p>First step was talking to them all to really understand their concerns and priorities. But there was another voice I wanted to hear from: our customers! This was meant to be a system for other engineering teams, how could I build a solution for them without understanding their problems? &nbsp;It took a bit of digging to even figure out who those users were. This required another soft skill: The art of finding the person you need to talk to.</p><p>Eventually I got into a room with them. There they dropped the bombshell “We can’t really justify the work to migrate to any new system. The current one works well enough for us right now and we have more urgent problems to fix.” I talked to three different teams and got the same answer each time. Damn, what’s the point of building a solution if no one will use it?</p><p>A migration had to happen, soon the current system would stop meeting our reliability standards. There were a couple routes forwards:</p><ul><li><em>Politics</em>: Get my management chain to convince their management chain to force the teams to migrate. Yuck</li><li><em>Persuasion</em>: Teach those teams why this pain that they won’t feel for a few years is more important to fix than the pains they’re facing today. That’s a hard thing to prove, and we’d have to make this case to many, many teams. That doesn’t scale well</li></ul><p>There was a third option: change the constraints. What if I said ‘no’ to some of the features I’d been asked to add? Removing that let me design the system in a way that we could migrate all our customers automatically. There would be zero work required from them to migrate. We’d swap the engine with the car still zooming down the highway.</p><p>This was much more palatable. And by highlighting our user’s push back I convinced the other stakeholders to change drop those constraints as well.</p><figure><img src="https://lh5.googleusercontent.com/uQ8pUq_dwFP6BBDO1d66HKZNGs5DrxtbLCoKc0NxnrsvpHOlh_C_Pi9yUcoU7XLi9TiYkRKy_4QItN3s3pWBVlNCfm2MZYyECTrdEHaJsQVTVxqmV4GPVzEFXJaRxpS5wqloltjj" alt=""></figure><p>That’s the general flow of any project you work on at the senior levels: You research the problem, gather the pieces, understand the world better. You design a solution, collect feedback and adjust course as needed. Then the implementation begins.</p><p>So how do you learn all these skills? Experience. Jump out of the nest and flap your wings. If an opportunity shows up, take it. You won’t feel ready, no one does, but that’s what makes it a learning experience.</p><p>Ask for help. Listen to the answers you get. Keep trying. At the end of the project ask for …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/">https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/</a></em></p>]]>
            </description>
            <link>https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277414</guid>
            <pubDate>Tue, 25 Aug 2020 23:20:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You want people to do the right thing? Save them the guilt trip]]>
            </title>
            <description>
<![CDATA[
Score 212 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24277190">thread link</a>) | @canada_random1
<br/>
August 25, 2020 | https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>Major global problems </strong>such as racial injustice or climate change often seem insurmountable. Itâ€™s hard to believe that our individual actions can make any real difference. Yet we know that many social dilemmas are overcome only through collective action. They call for people to make behavioural changes without any direct personal benefits â€“ in fact, these changes often come at a personal cost. So what might motivate people to adopt such a â€˜prosocialâ€™ mindset?</p>
<p>Researchers have explored a range of answers to this puzzle. A central line of enquiry relates to emotions and self-perception. Thereâ€™s a close link between emotions and behaviour: feelings motivate us to pursue goals, seek positive reinforcement and avoid punishment. But which emotional route is the most promising â€“ to make people feel bad about their shortcomings, or to encourage them to have a positive self-image because theyâ€™ve done â€˜the right thingâ€™?</p>
<p>There are good arguments both ways. Guilt can be a powerful motivator for action; the feeling of wanting to â€˜make upâ€™ for something can lead to reparative action. On the other hand, feeling good about our actions and what they reflect about who we are can elicit positive emotions. These feelings can then provide us with the energy and mental resources to engage in difficult problems, or to â€˜give to othersâ€™.</p>
<p>Itâ€™s important to distinguish here between guilt that arises internally, and guilt thatâ€™s externally induced. If we feel guilty about failing to recycle our plastics or adopt a vegetarian diet, we might be motivated to engage in reparative action. But if someone buttonholes us over dinner and tries to make us feel bad about our lifestyle choices, the picture might look very different; we might become defensive and try to justify our actions, which drives us further away from changing the way we behave. These scenarios then raise doubts about whether negative self-directed emotional appeals will be effective at promoting prosociality.</p>
<p>In a <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0188781">study</a> that my colleagues and I conducted at Columbia University in New York, we set out to test the consequences of positive versus negative self-directed emotions. Participants were prompted to think about either how guilty they felt about non-environmentally friendly behaviour, or how proud they might be for acting to preserve the environment. They were then asked a range of questions, such as whether they would pay increased rent to have more energy-efficient appliances, how likely they were to take public transport, and whether theyâ€™d be willing to use reusable shopping bags and mugs. Those participants who had been thinking of how proud they would feel about themselves chose to have a higher number of energy-efficient appliances compared with those participants who had been asked to think about personal guilt. Furthermore, participants in the pride group expressed higher intentions to engage in green behaviours compared with those in the guilt group. These findings suggest that inducing people to consider positive rather than negative self-directed emotions might recruit more people to a climate-change mitigation agenda, and to prosocial behaviour more broadly.</p>
<p>This potential advantage â€“ of appealing to positive emotions over negative ones â€“ links up with what we know about human self-perception. Having a positive self-image about who we are and what we do is a fundamental human need. When weâ€™re balanced and on good terms with ourselves, we are more energetic and have greater cognitive and emotional resources. By contrast, when we feel bad about ourselves, itâ€™s much more difficult to be prosocial â€“ especially if those feelings and actions arenâ€™t geared towards friends and family, but a removed, impersonal â€˜greater goodâ€™. Satisfying our important internal needs as emotional creatures can help us free up prosocial resources for others.</p>
<p>Research on self-affirmation supports this picture. In one <a href="https://academiccommons.columbia.edu/doi/10.7916/D84J1XJH">study</a>, we prompted one set of participants to engage in a self-affirming exercise. This involved reflecting on the values and behaviours that were important to them, and that they appreciated in themselves. Another group completed an unrelated exercise, describing the layout of the store at which they shop most frequently. This second â€˜controlâ€™ group allowed us to quantify the effect of the self-affirmation exercise.</p>
<p>Feeling good about ourselves can translate into acts of kindness towards others, for the benefit of society at large</p>
<p>Both groups were entered into a raffle to win a $10 bonus, and were given the option to either keep the money for themselves or to donate all or a portion to a selection of charities with varying missions and beneficiaries. The â€˜affirmationâ€™ group reported feeling more positively about themselves and more at peace with themselves â€“ and whatâ€™s more, these positive self-directed emotions translated into increased levels of charitable giving compared with those participants who had engaged in the unrelated exercise.</p>
<p><strong>My colleagues and</strong> I were curious about whether the effects of a positive self-image would extend to more challenging contexts, such as when the beneficiaries of prosociality were members of a marginalised group. In a field <a href="https://spssi.onlinelibrary.wiley.com/doi/full/10.1111/josi.12374">study</a> in Nigeria, we investigated how the public felt about enhanced social support for ex-prisoners. Like many other nations, Nigeria has high rates of recidivism. Social stigma means that those released from prison often struggle to secure jobs or have a supportive social network, which feeds into a cycle of reoffending. Interventions that reduce stigma and enhance social support can help ex-offenders to successfully reintegrate into society.</p>
<p>For the study, members of the general public in Nigeria were asked to engage in the self-affirming exercise prior to answering a range of survey questions. The results were striking. The self-affirmed participants showed more prosocial intentions and decreased discriminatory tendencies, compared with participants in the control group. They were more comfortable with having an ex-prisoner as their neighbour, for instance, and indicated stronger intentions to help an ex-prisoner whose employer was discriminating against them. They also expressed more willingness to invest personal time and effort to provide social support, such as participating in a tutoring programme for ex-prisoners.</p>
<p>Follow-up research in the United States replicated these results. Obtaining these findings in two studies and two different countries suggests that these effects can be generalised. The fact that a positive self-image can enhance prosociality doesnâ€™t seem to depend on a particular culture but could be an intrinsic part of human behaviour more generally. Feeling good about ourselves doesnâ€™t just enhance individual wellbeing by fulfilling a fundamental human psychological need; it can also translate into acts of kindness towards others, for the benefit of society at large.</p>
<p>A positive self-image can create a flywheel effect, in which the resulting prosocial behaviour sends a social signal to others. If others discriminate less, we are less likely to do so; if people in our social groups recycle more and watch their carbon footprint, we are more likely to do so. Getting a critical mass to â€˜join inâ€™ and acknowledging problems can, over time, help to shift norms â€“ which are drivers, not just inhibitors, of human behaviour.</p>
<p>The potential of positive self-directed emotions has largely not been embraced by activists. The worry could be that it might make those engaging in the cause appear self-satisfied or selfish. But these studies suggest that, instead of focusing on â€˜doom and gloomâ€™ messaging that zooms in on peopleâ€™s shortcomings and risks alienating them, policymakers and strategists might find that positive messaging, speaking to peopleâ€™s positive sense of self, might be a more powerful lever of behavioural change.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277190</guid>
            <pubDate>Tue, 25 Aug 2020 22:50:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Squeak Smalltalk on a PostmarketOS Cellphone]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24276883">thread link</a>) | @tonyg
<br/>
August 25, 2020 | https://eighty-twenty.org/2020/08/25/postmarketos-smalltalk | <a href="https://web.archive.org/web/*/https://eighty-twenty.org/2020/08/25/postmarketos-smalltalk">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Back in 2007, when <a href="https://en.wikipedia.org/wiki/Openmoko">Openmoko</a>
was first a thing, I
<a href="https://leastfixedpoint.com/tonyg/kcbbs/openmoko-info.html">wrote an Erlang-based userland</a>
that got to the point of being able to take and make calls and receive
and send SMS. The project stalled: the Openmoko GTA01 was too slow,
its power-management too primitive, and Erlang’s GUI facilities too
rudimentary to make further work worthwhile.</p>

<p>Modern cellphone hardware is <em>much</em> more capable. Is it time to have
another run at the idea of a mobile personal computer?</p>

<figure>
<p><a href="https://leastfixedpoint.com/pictures/openmoko-erlang-ui.png"><img src="https://leastfixedpoint.com/pictures/openmoko-erlang-ui.png" alt="Erlang OpenMoko userland (2008)"></a>
Erlang OpenMoko userland (2008)</p>

<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213231.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213231.jpg" alt="PostmarketOS on my cellphone"></a>
PostmarketOS on my cellphone</p>

<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213240.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213240.jpg" alt="PostmarketOS Weston demo"></a>
PostmarketOS <a href="https://wiki.postmarketos.org/wiki/Weston">Weston</a> demo</p>

</figure>

<h3 id="postmarketos-is-awesome">PostmarketOS is awesome</h3>

<p>Last week, I installed <a href="http://postmarketos.org/">PostmarketOS</a> on my
previous cellphone, a Samsung Galaxy S7 (using PostmarketOS’s
<a href="https://wiki.postmarketos.org/wiki/Samsung_Galaxy_S7_(samsung-herolte)">samsung-herolte</a>
configuration).</p>

<p>PostmarketOS turns out to be a beautifully engineered system that’s
easy to understand and modify. The basics of kernel and Alpine Linux
userland installed cleanly and easily on the phone, and it’s running
well as a development platform. I’m looking forward to getting into
PostmarketOS more deeply.</p>

<figure>
<p><a href="https://eighty-twenty.org/images/pm-htop-20200825.png"><img src="https://eighty-twenty.org/images/pm-htop-20200825.png" alt="htop running on my cellphone"></a>
<code>htop</code> running on my cellphone. Six cores!</p>
</figure>

<p>Running <code>htop</code> on the phone shows what an <em>amazing</em> little machine it
is! So much power. Loads of cores, lots of RAM. Plenty of space to
explore alternative visions of mobile personal computing.</p>

<p>However, the built-in demos, such as the
<a href="https://wiki.postmarketos.org/wiki/Weston">Weston</a> demo (shown above
at right), currently leave quite a bit to be desired. Perhaps some of
the other
<a href="https://wiki.postmarketos.org/wiki/User-Interfaces">user interface options</a>
included with PostmarketOS could get me closer to a day-to-day usable
cellphone - but I’m interested in running my own software! Let’s get
hacking.</p>

<h3 id="running-my-own-programs">Running my own programs</h3>

<p>PostmarketOS is a plain, clean Alpine Linux distribution. You can SSH
into it initially
<a href="https://wiki.postmarketos.org/wiki/USB_Network">via USB networking</a>.
From there, you can
<a href="https://wiki.postmarketos.org/wiki/WiFi#Using_NetworkManager">configure wifi using nmcli</a>,
set up SSH keys, and then access it directly using SSH over wifi.</p>

<figure>
<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213419.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213419.jpg" alt="lflow: Framebuffer demo"></a>
<code>lflow</code>: Framebuffer demo</p>
</figure>

<p>Building software is just as simple:</p>

<figure><pre><code data-lang="shell"><span></span>apk add alpine-sdk</code></pre></figure>

<p>To experiment with drawing to the framebuffer and reading touchscreen
input via <code>/dev/input</code>, I compiled and ran an old
<a href="https://github.com/tonyg/mac-display-hacks/blob/a1fde2054f00588076218b76d7ecf34764e5f99e/lflow.c">quick and dirty framebuffer hack</a>
I wrote years ago. The results (shown at left) were encouraging: the
program effortlessly animates tens of thousands of points at 30 frames
per second, responding to touch inputs. Display is via brute-force
pixel output to the <code>mmap</code>‘d frame buffer. It doesn’t even use a full
core.</p>

<p>PostmarketOS turns a phone into a fully capable Linux machine, with
total control over the attached hardware, and with everything
accessible to the developer in the usual places using the usual tools.</p>

<p>But Unix tools are inappropriate for a mobile personal computing
platform. We’ll need something else.</p>

<h3 id="a-smalltalk-phone">A Smalltalk phone</h3>

<figure>
<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213500.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213500.jpg" alt="Squeak Smalltalk on PostmarketOS"></a>
Squeak Smalltalk
<a href="http://files.squeak.org/6.0alpha/Squeak6.0alpha-19812-64bit/">6.0-alpha</a>
on PostmarketOS</p>
</figure>

<p>Smalltalk could make an ideal basis for a mobile personal computing
platform.</p>

<p>I’ve <a href="https://eighty-twenty.org/tag/smalltalk">enjoyed</a> using,
developing with, and contributing to the
<a href="https://squeak.org/">Squeak Smalltalk</a> implementation since the mid
’00s.</p>

<p>So I compiled the
<a href="https://github.com/OpenSmalltalk/opensmalltalk-vm">Cog Smalltalk VM</a>
on the phone itself, making use of the 64-bit ARM support code that
landed extremely recently.</p>

<p>And lo and behold, it runs! Shown to the right is a bleeding-edge,
fully up-to-date Squeak 6.0-alpha image running on the phone itself.
(<a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213500.jpg">Click here or on the image to embiggen.</a>)</p>

<p>From here, I can experiment with new ideas using the full power of a
modern Smalltalk environment.</p>

<h3 id="what-next">What next?</h3>

<p>My previous Openmoko experiments foundered, in part, on the GUI aspect
of the system; GTK+ via Erlang was fine for quick prototyping but
wasn’t really up to the task for a day-to-day usable machine.</p>

<p>I recall getting Squeak running on my GTA01, in order to see if it
could provide a viable UI. However, I remember being stymied by the
mismatch between the expectations of the Smalltalk environment and the
realities of the phone.</p>

<p>Squeak wants a mouse and keyboard. It assumes a monitor-sized display,
in everything from widget and font sizes to window management. To work
well on a phone, it needs a touchscreen-based, high-DPI UI in addition
to its existing toolset.</p>

<p>Smalltalk, in both its language aspect and its system design aspect,
also <a href="https://eighty-twenty.org/2011/05/08/weaknesses-of-smalltalk-strengths-of-erlang">suffers from some weaknesses in areas where Erlang shines</a>.</p>

<p>However, in the years since the GTA01:</p>

<ul>
  <li>
    <p>the hardware is much better,</p>
  </li>
  <li>
    <p>the Squeak VM and image are better,</p>
  </li>
  <li>
    <p>I’ve learned a heck of a lot about
<a href="https://syndicate-lang.org/tonyg-dissertation/html/">some good ways to design interactive systems</a>,
and</p>
  </li>
  <li>
    <p>I’ve recently
<a href="https://tonyg.github.io/squeak-actors/">built some tools that help bring Erlang- and Syndicate-style architectural patterns for concurrency to Smalltalk</a>.</p>
  </li>
</ul>

<p>So I think using Erlang/Syndicate-style
<a href="https://tonyg.github.io/squeak-actors/">Actors</a> to structure a
Smalltalk-based phone userland, perhaps with <code>cgroups</code>-based
sub-virtual-machines and images, could work well.</p>

<p>My initial experiments have concentrated on</p>

<ul>
  <li>
    <p>fixing the tiny fonts (the DPI-change support code in the image
needs work, and the support in the VM seems to be absent (?)),</p>
  </li>
  <li>
    <p>reading from the touchscreen (probably
<a href="http://lists.squeakfoundation.org/pipermail/squeak-dev/2016-June/190051.html">like this</a>),</p>
  </li>
  <li>
    <p>thinking about how to structure Actor supervision hierarchies and
<a href="https://syndicate-lang.org/tonyg-dissertation/html/#sec:Syndicate's-approach-to-concurrency">Dataspaces</a>
for a mobile phone (probably borrowing some design elements from my
earlier
<a href="https://github.com/tonyg/erlang-openmoko">Openmoko Erlang-based userland</a>),
and</p>
  </li>
  <li>
    <p>thinking about how to layer a touchscreen (panel-based?) GUI atop
Squeak’s <a href="http://wiki.squeak.org/squeak/morphic">Morphic</a> UI.</p>
  </li>
</ul>

<p>I’ll write more on this blog as things develop.</p>

<hr>

<p><strong>Update:</strong> <a href="https://eighty-twenty.org/2020/08/27/squeak-postmarketos-update">Some progress on the font front!</a></p>

  </div></div>]]>
            </description>
            <link>https://eighty-twenty.org/2020/08/25/postmarketos-smalltalk</link>
            <guid isPermaLink="false">hacker-news-small-sites-24276883</guid>
            <pubDate>Tue, 25 Aug 2020 22:17:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rapier Physics Engine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24276785">thread link</a>) | @alex_hirner
<br/>
August 25, 2020 | https://www.dimforge.com/blog/2020/08/25/announcing-the-rapier-physics-engine/ | <a href="https://web.archive.org/web/*/https://www.dimforge.com/blog/2020/08/25/announcing-the-rapier-physics-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>In our announcement last week, we briefly mentioned this new physics engine we have been working on during the past 5 months.
Today we are officially releasing it for the first time: the project <a href="https://rapier.rs/" target="_blank" rel="noopener noreferrer"><strong>Rapier</strong></a>; a set of two 100%
rust libraries <strong>rapier2d</strong> and <strong>rapier3d</strong> for 2D and 3D physics simulations for games, animation, and robotics.</p><p><img src="https://www.dimforge.com/img/rapier_logo_color_textpath_dark.svg" alt="rapier logo"></p><p>This post will be quite long, so here are all the different sections:</p><ul><li><a href="#presenting-rapier">Presenting Rapier</a></li><li><a href="#reaching-out-to-other-communities-bevy-and-javascript">Reaching out to other communities: Bevy and JavaScript</a></li><li><a href="#feature-comparison-with-nphysics">Feature comparison with nphysics</a></li><li><a href="#benchmarks">Benchmarks</a><ul><li><a href="#3d-benchmark-rapier-vs-physx-vs-nphysics">3D Benchmark: Rapier vs. PhysX vs. nphysics</a></li><li><a href="#3d-benchmark-conclusion">3D Benchmark: Conclusion</a></li><li><a href="#2d-benchmark-rapier-vs-box2d-vs-nphysics">2D Benchmark: Rapier vs. Box2D vs. nphysics</a></li><li><a href="#2d-benchmark-conclusion">2D Benchmark: Conclusion</a></li><li><a href="#running-the-benchmarks-yourself">Running the benchmarks yourself</a></li></ul></li><li><a href="#conclusion">Conclusion</a></li></ul><h3>Presenting Rapier</h3><p><strong>Rapier</strong> is the successor of <a href="https://nphysics.org/" target="_blank" rel="noopener noreferrer">nphysics</a> and focuses on performance first.
Just like <strong>nphysics</strong> it is split into two crates: <strong>rapier2d</strong> and <strong>rapier3d</strong> for 2D and 3D physics respectively. It
is designed to be fast and multithreaded right from the beginning. It is also designed to require less incremental compilation
times because the data structures it defines are not generic.</p><p>In release mode, <strong>Rapier</strong> runs 5 to 8 times faster than <strong>nphysics</strong> , making it close to the performance of (the CPU version of) NVidia PhysX
and slightly faster than Box2D as you will see in the <a href="#benchmarks">benchmark sections</a>. <strong>Rapier</strong> is only at its beginning, so many features
are still missing. However some performance optimizations like parallelism, and SIMD have been integrated right from the start.</p><p>There already are a few key features that makes Rapier stand out. Since they may affect compilation times and/or performance,
they are disabled by default and need to be enabled explicitly through cargo features:</p><ol><li><strong>Serialization</strong>: if the <code>serde-serialize</code> feature of <strong>Rapier</strong> is enabled, every physics component will be serializable using <code>serde</code>.
This means that you can take a deep snapshot of the physics state and restore it later. This snapshot can even be saved on
disk or sent through network.</li><li><strong>Cross-platform determinism</strong>: if the <code>enhanced-determinism</code> feature of <strong>Rapier</strong> is enabled, it will behave in
a <em>bit-level cross-platform deterministic</em> way in all platforms that comply with the IEEE 754-2008 floating point standard.
This means that if you run the same simulation with the same initial states on two different machines (or browsers)
you will get the exact same results. Here "bit-level" determinism means that if you serialize the physics state after the
same number of timesteps on two different machines, you will obtain the exact same byte array for both: you may compute a checksum
of both snapshots and they will be identical. All this doesn't apply to platforms with pointer size smaller than 32-bit, and on
platforms that don't comply to IEEE&nbsp;754-2008 strictly.</li></ol><p>See <a href="#feature-comparison-with-nphysics">that section</a> for a comparison between Rapier and nphysics features.</p><h3>Reaching out to other communities: Bevy and JavaScript</h3><p><img src="https://www.dimforge.com/img/bevy_wasm_js.svg" alt="Bevy WASM JS"></p><p>Writing a physics engine is hard. There are not a lot of choices out there and most of them are written in C++. With
<strong>nphysics</strong> we wanted to provide an open-source 100% rust physics solution for the Rust community.
With <strong>Rapier</strong> we want to go one step further by contributing to as many communities in need of a physics engine as we can. This is why we are
starting, right at the beginning of the <strong>Rapier</strong> story, by providing:</p><ul><li>Official <strong>JavaScript bindings</strong> for the WASM version of <strong>Rapier</strong>. These binding are generated using <code>wasm_bindgen</code> and
are published to NPM as the packages <a href="https://www.npmjs.com/package/@dimforge/rapier3d" target="_blank" rel="noopener noreferrer">@dimforge/rapier3d</a> and
<a href="https://www.npmjs.com/package/@dimforge/rapier2d" target="_blank" rel="noopener noreferrer">@dimforge/rapier2d</a>. While multiple physics solutions already exist
for JavaScript they are either slow (because they are manually written in JS like <strong>cannon.js</strong> or <strong>oimo.js</strong>), or not
officially maintained by their original developers (because they are ported from C++ using Emscripten, like <strong>box2d.wasm</strong>,
<strong>ammo.wasm</strong>, or <strong>physx.wasm</strong>). By providing official wasm builds and JS bindings, we are making sure to provide the
best support, documentation, and continuous updates to the JS community.</li><li>Official <strong>plugins for the <a href="https://bevyengine.org/" target="_blank" rel="noopener noreferrer">Bevy</a></strong> game engine. They are available as the
<a href="https://crates.io/crates/bevy_rapier2d" target="_blank" rel="noopener noreferrer">bevy_rapier2d</a> and <a href="https://crates.io/crates/bevy_rapier3d" target="_blank" rel="noopener noreferrer">bevy_rapier3d</a>
crates. The <strong>Bevy</strong> game engine has recently been released as an efficient, fast-to-compile, and easy to use, data-oriented
game engine. It is still at its early state and is lacking any physics feature. We believe physics support is a very high-value
feature to have in a game engine. By providing official plugins we want to make sure the <strong>Bevy</strong> community can benefit from the
<strong>Rapier</strong> physics engines quickly and easily.</li></ul><p>There are so many more communities we would like to contribute to but don't have manpower to support all of them just now.
Other integrations and languages will come in the future.</p><p>We also plan to create official plugins for the <strong>Amethyst</strong> game engine but have not started yet. We are waiting
for the migration of <strong>Amethyst</strong> to the <a href="https://crates.io/crates/legion" target="_blank" rel="noopener noreferrer">legion</a> ECS solution before starting to work
on this.</p><div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></p><p>Examples using the 2D JS bindings are available on GitHub:
<a href="https://github.com/dimforge/rapier.js/tree/master/testbed2d/src/demos" target="_blank" rel="noopener noreferrer">2D</a> and
<a href="https://github.com/dimforge/rapier.js/tree/master/testbed3d/src/demos" target="_blank" rel="noopener noreferrer">3D</a>. You can see these demos running
<a href="https://rapier.rs/demos2d/index.html" target="_blank" rel="noopener noreferrer">there for 2D</a> and <a href="https://rapier.rs/demos3d/index.html" target="_blank" rel="noopener noreferrer">there for 3D</a>.
In these demos, the physics simulation runs inside of a web worker and the rendering is performed by
<a href="https://www.pixijs.com/" target="_blank" rel="noopener noreferrer">PixiJS</a> and <a href="https://threejs.org/" target="_blank" rel="noopener noreferrer">Three.js</a>.</p></div><h3>Feature comparison with nphysics</h3><p><strong>Rapier</strong> does not have as many features as <strong>nphysics</strong> yet, but it also has a few features <strong>nphysics</strong> does not have.
Here are comparative tables of both physics engines: </p><center><table><thead><tr><th>Dynamics features</th><th>Rapier</th><th>nphysics</th></tr></thead><tbody><tr><td>Rigid-body physics</td><td>✅</td><td>✅</td></tr><tr><td>Kinematic bodies</td><td>✅</td><td>✅</td></tr><tr><td>Rigid-body islands and sleeping</td><td>✅</td><td>✅</td></tr><tr><td>Joint constraints</td><td>✅</td><td>✅</td></tr><tr><td>Joint constraint limits and motors</td><td>❌</td><td>❌</td></tr><tr><td>Reduced-coordinate joints</td><td>❌</td><td>✅</td></tr><tr><td>Reduced-coordinates joint limits and motors</td><td>❌</td><td>✅</td></tr><tr><td>Conveyor belts</td><td>❌</td><td>✅</td></tr><tr><td>Deformable bodies</td><td>❌</td><td>✅</td></tr><tr><td>Fluids (integration with <a href="https://salva.rs/" target="_blank" rel="noopener noreferrer">Salva</a>)</td><td>❌</td><td>✅</td></tr></tbody></table></center><center><table><thead><tr><th>Geometry features</th><th>Rapier</th><th>nphysics</th></tr></thead><tbody><tr><td>Colliders</td><td>✅</td><td>✅</td></tr><tr><td>Sensors</td><td>✅</td><td>✅</td></tr><tr><td>Contact/proximity events</td><td>✅</td><td>✅</td></tr><tr><td>Contact graph</td><td>✅</td><td>✅</td></tr><tr><td>Continuous Collision Detection</td><td>❌</td><td>✅</td></tr><tr><td>Ray-casting</td><td>❌</td><td>✅</td></tr><tr><td>Convex-casting</td><td>❌</td><td>✅</td></tr></tbody></table></center><center><table><thead><tr><th>Performance and portability features</th><th>Rapier</th><th>nphysics</th></tr></thead><tbody><tr><td>Floating-point cross-platform determinism</td><td>✅</td><td>❌</td></tr><tr><td>Parallelization</td><td>✅</td><td>❌</td></tr><tr><td>SIMD</td><td>✅</td><td>❌</td></tr><tr><td>Serialization</td><td>✅</td><td>❌</td></tr><tr><td><strong>JavaScript</strong> bindings</td><td>✅</td><td>❌</td></tr><tr><td>Integration to <strong>Bevy</strong></td><td>✅</td><td>❌</td></tr><tr><td>Integration to <strong>Amethyst</strong></td><td>❌</td><td>❌</td></tr><tr><td>Fixed-point cross-platform determinism</td><td>❌</td><td>✅</td></tr><tr><td>64-bits physics</td><td>❌</td><td>✅</td></tr></tbody></table></center><p>Today <strong>nphysics</strong> is more mature than <strong>Rapier</strong>. Our first goal during the next few months is to bring <strong>Rapier</strong> at the
same level as <strong>nphysics</strong> featurewise, while keeping the significant performance improvements and better accuracy.</p><h3>Benchmarks</h3><p>Alright, we claimed that <strong>Rapier</strong> is nearly as fast as the CPU version of PhysX, 5 to 10 times faster than nphysics, and
slightly faster than Box2D. It is now time to prove these claims using benchmarks.</p><div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</h5></p><p>Keep in mind that <strong>Rapier</strong> is still at a early development stage. It does not have as many features as the ofther
physics engines involved in this benchmark. However, our objective is to ensure that the future addition of new features
to <strong>Rapier</strong> don't reduce the level of perfomance you see here.</p></div><p>In the subsequent benchmarks we ran a set of stress tests using four different physics engines:</p><ol><li><strong>Rapier</strong> using our <a href="https://crates.io/crates/rapier3d" target="_blank" rel="noopener noreferrer">rapier3d</a> crate for 3D and <a href="https://crates.io/crates/rapier2d" target="_blank" rel="noopener noreferrer">rapier2d</a> for 2D.</li><li><strong>PhysX 4</strong> using the <a href="https://crates.io/crates/physx" target="_blank" rel="noopener noreferrer">physx</a> crate.</li><li><strong>Box2d</strong> using the <a href="https://crates.io/crates/wrapped2d" target="_blank" rel="noopener noreferrer">wrapped2d</a> crate.</li><li><strong>nphysics</strong> using our <a href="https://crates.io/crates/nphysics3d" target="_blank" rel="noopener noreferrer">nphysics3d</a> crate for 3D and <a href="https://crates.io/crates/nphysics2d" target="_blank" rel="noopener noreferrer">nphysics2d</a> for 2D</li></ol><p>Independently of the chosen physics engine, all scenes are always initialized in the
exact same way (same bodies, same colliders at the same initial positions) and with the following
parameters:</p><ul><li><strong>Rust compiler and flags</strong>: <code>rustc 1.46.0-nightly</code>, <code>--release</code>, <code>--features simd-nightly</code>, <code>codegen-units = 1</code>.</li><li><strong>Timestep length</strong>: 0.016 (i.e. 16 milliseconds).</li><li><strong>Number of velocity iterations</strong>: 4 for Rapier, nphysics, and Box2D. 1 for PhysX.</li><li><strong>Number of position iterations</strong>: 1 from Rapier, nphysics, and Box2D. 4 for PhysX.</li><li><strong>Targets</strong>: native CPU (WebAssembly versions and PhysX on GPU have not been benchmarked.)</li><li><strong>Solvers</strong>: variations of PGS. (The PhysX 4.0 TGS solver has not been benchmarked. We used the default <code>ePGS</code> solver.)</li><li><strong>Number of threads</strong>: 1.</li></ul><div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></p><p>In this benchmark we don't use multithreading. A benchmark with multithreading enabled, involving only multithread physics
engine will be the subject of another blog post.</p></div><p>Each 3D benchmark is run on two different machines because we observed performance differences between
PhysX and Rapier depending on the processor:</p><ol><li>A desktop computer, running Ubuntu, equipped with an AMD Ryzen 9 3900X CPU, 3.8GHz.</li><li>A MacBook Pro (plugged to a power outlet), running Mac OS, equipped with an Intel Core i7 7920HQ, 3.1GHz.</li></ol><p>The 2D benchmarks are run only on the AMD Ryzen 9 3900X CPU (the relative performance remain the same with
the Inter Core i7 CPU).</p><h3>3D Benchmark: Rapier vs. PhysX vs. nphysics</h3><p>A few notes are in order regarding PhysX in this benchmark. First, we don't use the same number of iterations for Rapier and PhysX.
For Rapier and nphysics we use 4 velocity iterations and 1 position iteration. It is the other way round for PhysX: 1 velocity
iteration and 4 position iterations. This is the most sensible configuration because:</p><ul><li>PhysX developers <a href="http://www.codercorner.com/blog/?p=2072" target="_blank" rel="noopener noreferrer">advise to increase</a> the number of position iterations for
better stability, and leave to 1 the number of velocity iterations.</li><li>PhysX itself (independently from this benchmark) uses 1 velocity iteration and 4 position iterations by default.
It yields more stable simulations than using 4 velocity and 1 position without performance difference.</li><li>Rapier and nphysics use a solver different from PhysX's. With our solver, it is recommended to increase the number of
velocity iterations instead of position iterations, and leave the number of position iterations to 1.</li></ul><p>The PhysX benchmarks will include two performance curves:</p><ol><li>One performance curve using their default <code>ePATH</code> friction model. This is a simplified friction model, faster to
compute, but less realistic. Rapier and nphysics don't implement a similar model yet.</li><li>One performance curve using their <code>eTWO_DIRECTIONAL</code> friction model. This is similar to the friction model used by Rapier
and nphysics.</li></ol><h4>8.000 stacked balls</h4><p>In this benchmark there are 8000 balls falling on a ground also composed of balls. In the end, they form 400
independent small stacks of balls.
<img src="https://www.dimforge.com/img/bench_balls.png" alt="bench balls">
<img src="https://www.dimforge.com/img/bench_ryzen_balls.svg" alt="bench balls">
<img src="https://www.dimforge.com/img/bench_intel_balls.svg" alt="bench balls"></p><h4>3.000 falling boxes</h4><p>In this benchmark, there are about 3000 small cubes falling on a large cube floor in a completely …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dimforge.com/blog/2020/08/25/announcing-the-rapier-physics-engine/">https://www.dimforge.com/blog/2020/08/25/announcing-the-rapier-physics-engine/</a></em></p>]]>
            </description>
            <link>https://www.dimforge.com/blog/2020/08/25/announcing-the-rapier-physics-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24276785</guid>
            <pubDate>Tue, 25 Aug 2020 22:08:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tipe raises $2.1M seed round to build a customizable CMS for developers]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24275948">thread link</a>) | @tmvnty
<br/>
August 25, 2020 | https://tipe.io/blog/tipe-raises-seed | <a href="https://web.archive.org/web/*/https://tipe.io/blog/tipe-raises-seed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Today we're excited to announce that tipe has raised $2.1m in seed funding led by CRV and joined by investors YC, M Ventures, and Precursor Ventures. This investment will help tipe deliver an excellent experience for developers and teams who need a better workflow for managing content. Since graduating from YC's Winter 18 batch, we've been building prototypes, talking with users, and learning from the community. We're finally ready to show everyone what we've learned.  </p><p>Teams are shifting away from legacy site builders to more sophisticated builds with frameworks like Next.js and Gatsby. Cloud computing, crawlers, and JavaScript have all approved and come together to enable this shift. Jamstack offers so many benefits for low effort but also introduces more decision making. Teams must now decide on a content workflow, and developers are on the hook to figure it out.</p><p>We want to make this decision easy for developers. </p><h2>Make it your own, together</h2><p>They always say, "...never build a CMS". We know every team has different needs and use cases when it comes to content workflows. Customization and extendability are at the core of tipe's design.  That's why tipe is open-source and has a simple plugin features that make it easy for you to create your own CMS.</p><p>We invest in the open-source community and all the efforts to create and maintain the fantastic projects leading the Jamstack wave. We encourage developers to use plugins and extensions for tipe created by the community. One of our goals is to make sure we're not another app devs have to maintain, so we'll be working with developers to make sure working with tipe stays lean and fast. </p><p>We can't do this alone, so today we're launching the <a href="https://join.slack.com/t/tipe-hq/shared_invite/zt-gfesfzxf-9KHj1Q3GPhUbUOa6PjNpTA">tipe community slack</a>ðŸŽ‰. You can interact with the tipe team more closely, see what the community is cooking up, or even get help for anything that comes up. </p><h2>Roadmap to the best experience</h2><p>Developer and user experience are our main focuses here at tipe. As we grow, we want to move towards a minimal and straightforward product to use but powerful when combined with plugins and extensions. To achieve this goal, we plan on maintaining transparency about the direction of tipe and what's coming next. We'll also be leaning on our users and the community to help us build something that they would love. </p><p>To start, we have support for Jamstack frameworks like Next.js and Gatsby, a CLI to get started without ever visiting our web app, and SDKs to query content. As the community grows and improves tooling, we'll support all that comes from it. Open-source is are core, well before tipe, and will remain that way as we grow. </p><h2>Perfect timing</h2><p>The web is transitioning into another era with all the moving pieces seeing significant enhancements. Now is the time to build a fast experience for your users. You can't do that if your team is slow, because of content changes or any reason.</p><p>We look forward to helping teams stay fast as they deliver amazing journeys for their users. Also, <a href="https://tipe.io/jobs">we're hiring</a>! If anything you read here resonates with you, we'd love to hear from you. </p></div></div></div>]]>
            </description>
            <link>https://tipe.io/blog/tipe-raises-seed</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275948</guid>
            <pubDate>Tue, 25 Aug 2020 20:51:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DevOps, DataOps, and MLOps: the three waves of operationalization]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275856">thread link</a>) | @mvartak
<br/>
August 25, 2020 | https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops | <a href="https://web.archive.org/web/*/https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Using machine learning models in products is hard. Most companies fail at extracting value from them because they can't operationalize models properly.</p>
<!--more-->
<p>We have gotten good at creating models and iterating on them, but <a href="https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/"><span>most companies still don't use them well</span></a>. A model with acceptable performance that you can use is better than a great model that you can't. Then why are companies having so many issues leveraging them?</p>
<p>In this blog post, we show that some challenges are analogous to those before DevOps. We’ll also show that others introduce a new level in the development and operation process that requires a new stack.</p>
<p>The lessons here come from building ML products and platforms at companies like Twitter, NVIDIA, Cloudera, Google, and others. These companies have invested heavily in building their in-house ML platforms or external products for a variety of scenarios.</p>

<h2><span>Moving development closer to operations</span></h2>
<p>Two decades ago, software development was painful. Developers and operators were silos, and making any changes was an adventure. DevOps helped us fix that with a simple shift in mindset: developers should own their software end-to-end, and operators should support them. Operators could focus on building robust IT infrastructure instead of handling each application individually. Meanwhile, developers could speed their development practices by using the tools as their product demanded. This change was the first wave of operationalization, and it changed how we do software.</p>
<p><img src="https://lh5.googleusercontent.com/AzBl9kIU1PCLQLTZQ91tKPpn7bAmjghns_vNHPdloZ-V3XytDuyTemoZn96xA_QEgwuxrVG5vxqSBFixSx2hEtOhiawWdwQ_Ix7TYS_sQ1A5pxbrFhGtT4cWw7rewEymlJqtQ1ya" width="453" height="283"></p>
<p><span>Around the same time, data started to become more relevant via analytics. The goal was to understand the data companies had available. Seeing the success of DevOps, analytics professionals partnered with their operators to create DataOps. In this case, analysts could focus on their business use case while operators made their use reliable.</span></p>
<p><span>Today, machine learning faces a similar challenge. The goal of ML is to help products make decisions on the spot. For example, which messages to show from a search query. These applications focus on actively improving the business instead of just providing insights. However, these more complex applications also have requirements we had never seen, and the operations world is just starting to adjust.</span></p>
<p><span>We now face a similar challenge for model developers that we have encountered before in software development:</span></p>
<ul>
<li><span>Data scientists don't own their work end-to-end. Instead, they send their models to a software developer and data engineer to build the machinery on a case by case basis.</span></li>
<li><span>Data scientists are frequently blocked, waiting for other developers to help them.</span></li>
<li><span>Data scientists are blind to the processes required to satisfy operations until it's too late. In which case, the work is dropped or re-done.</span></li>
</ul>
<h2><span>Why MLOps is so hard</span></h2>
<p><span>Using ML models in products is a quantum leap in their value, and every such significant change comes with paradigm shifts. Not only MLOps is hard on itself, but most companies are not prepared to practice it today if done naively. The challenges of adopting MLOps boils down to:</span></p>
<ul>
<li><span>You have to support multiple pre-existing tools in two isolated ecosystems;</span></li>
<li><span>Models have more dimensions in their requirements, and operate on a broader range of each trade-off;</span></li>
<li><span>You need to provide a self-service ecosystem for data scientists that currently don't have the operations skills that developers do;</span></li>
<li><span>Companies' processes on using ML must start where they're at today and adapt as their use advances;</span></li>
<li><span>ML adds an entirely new layer to the operations stack.</span></li>
</ul>

<h4><span>MLOps challenge 1: pre-existing ecosystems</span></h4>
<p>Software development and model development have pretty mature ecosystems today, with constant and fast improvements. However, these ecosystems are mostly isolated. Consider a core piece of infrastructure: the workflow system. Software engineers will most likely use Jenkins, GitLab, CircleCI, or any similar tools. However, data scientists use Airflow, Kubeflow, and other ML-targeted workflow systems. These two ecosystems might eventually combine, but this can take years and a lot of effort. Instead, we need to meet them where they are today.</p>

<p><img src="https://lh4.googleusercontent.com/GV0KR8tRUGnuk80NmXXCdUuZPwkoupXwKLisbeq2e8-wpmyqjKY0CMMmx6QwafOC61QboUsIC58ZegUYS4hSrfM8VO1Gbv7fgULTyuFPcH14hM_uQGgp1kFchIqQFEfJsAapbInQ" width="277" height="305"></p>
<p>From the data scientist's perspective, they need the infrastructure to be reliable. It should work in the way that they want almost always and provide all the functionality they want to use but not develop. The researcher isn't concerned with which tools achieve this goal, as long as it works with their current solutions.</p>
<p>On the other hand, IT provides a vibrant ecosystem of productivity tools, but they require applications to behave in a particular way. The challenge operators face with data science today is that adapting all those practices to the ML ecosystem is difficult and time-consuming. So they need the ML applications to look like applications they already support.</p>
<p>This golden standard is hard to achieve. Therefore most companies end up with multi-year migration projects that change how everyone does their job simultaneously. As you can imagine, these projects fail most of the time. Instead, we need to figure out how to get these two personas to collaborate first and get value from each other.</p>

<h4><span>MLOps challenge 2: dimensions of model requirements</span></h4>
<p>In modern software development, the system's requirements are usually pretty narrow, so tools can be more focused. Models not only have more dimensions, but the placement of a solution is also fuzzier.</p>
<p><img src="https://lh6.googleusercontent.com/6emah1WRzYxr97IHXpSJzKyeweuXtc3weSwUWtwBrXYJpVhg3keKrtaH_OszAh_Y6UYcaTXYX_OuqPw8DpncM_VmISOvpy58jzleK1VWUoMWV0nezh2doT64UeF0B-gvBwS_UhWX" width="487" height="426"></p>
<p>These are just a few examples of standard dimensions considered and it’s by no means an exhaustive list. Note how software usually lies on clear points in the spectrum. For instance, you know if the application provides an HTTP endpoint or runs in the user's device. Unsurprisingly, that is generally not the case for models. During the lifecycle of the model, from conception to use in a product, the same model might be at different places in the requirements balance. Using the same example, we might not use the end device for computing our test metrics due to speed concerns, but use the model as a library instead.</p>
<p>Most companies start to deploy models by building a solution for a particular case and ignoring others. Then they patch it a little bit to adapt to another model or another use case of the same model. And again, until they end up with a system that is hard to use, change, and maintain.</p>
<p>In which case, new users might consider it's easier to build their own from scratch for their use case. That's how many companies, including big tech ones, end up with multiple internal ML platforms if they're not careful. Keeping in mind the diversity of requirements, even within a single project, is an essential but challenging effort.</p>

<h4><span>MLOps challenge 3: self-service operations for data scientists</span></h4>
<p>One of the core tenets of DevOps is that developers should own their applications end-to-end. To do this properly, operators needed to provide mechanisms for their users to self-service. It allows IT to scale to multiple customers and removes delays waiting on someone else to provide some tooling.</p>

<p><img src="https://lh6.googleusercontent.com/hcT3ffqnaPw9OltYcczXKEgqjt2IHm1xB0O6vuPt2THWRmkHK62dKJ3dwdlm2UajB3mdtN4RskM3CbCJ_L9nh0cU-1pA56x9PtBziPQitU28STuw5NQMpJXaBXOxZFlQmfHLEr1i" width="499" height="326"></p>
<p>The image above covers a few of the functionalities most companies will have in their self-service platform. IT provides tools and processes for core functionalities, focusing on providing a solid foundation. Meanwhile, developers define customizations on top of the platform or perform integration for their particular application. Companies have been reducing the distance between developers and operators for many years now, which allowed lower-level constructs to be used. However, that is not enough for researchers.</p>
<p><img src="https://lh6.googleusercontent.com/4zjcm39V61mB1y4PWkJvzrrkHAVzBG6R9KKwChTHJUe81tr87ppMc2aq1DrppBgbnUXdkbJWVQUvQP0PdMlk5xpMZommxEkhKsSxmWoaZLoQ_lrv4yE2a3dFGnv79oguFTUL4yqD" width="499" height="326"></p>

<p>As we have argued before, data scientists' current skill set is very distinct from bringing up and operating one of their models in production. Hence the platform provided for researchers needs to be at a higher level than for software developers. For example, developers know how to define their systems' behavior to ensure it meets a particular SLA. But data scientists want to specify what those SLAs are and rely on a platform to handle the complexities to achieve that.</p>
<p>Thankfully the industry started to make higher-level constructs available for software engineers too. As anybody would suspect, operating low-level definitions is a considerable overhead. However, the further away you get from the specifics, the more domain knowledge you need to embed in the platform. Unfortunately, not every operations team has this knowledge at hand to support ML applications.</p>

<h4><span>MLOps challenge 4: adapt to existing processes and grow with the company</span></h4>
<p>Every big software company has a set of processes in place for software development. These processes took years and many iterations to develop correctly, potentially including expensive mistakes. When thinking about using models in production, teams frequently face the challenge of building these processes from scratch.</p>

<p><img src="https://lh5.googleusercontent.com/755p1w0mxyZwNwQFrwm_C2OLPIfMS-OAoOrRN5DjfAx2Z_70kHhNRvDRQk4L-Ygu3bnZRBkweEyRrtr8AlGKKQVQFFES7-yXnceVLGkI8VkBLNVh5yhrn5eyNDjmNTcrUvw_Yky9" width="452" height="285"></p>

<p>However, at the start of the ML journey, most operations constraints will look similar to doing software engineering. Operationalizing ML has higher success at places that first adapt their current processes the best they can. Once they have that initial version, the team iterates on the process as they identify improvements related to the new application domain or new product requirements.</p>
<p>This evolution of processes means that platforms and infrastructure must be able to adapt along with their teams. As new regulations and customer requests evolve, so will the requirements and limitations on model development and execution. Switching to a new system every time that happens is expensive. But relying on external enforcement is prone to misalignment failures. Hence production ML needs to meet users where they are today to bring immediate value while supporting the evolution of their ML methodologies.</p>

<h4><span>MLOps challenge 5: new layer at the operations stack</span></h4>
<p>This challenge is potentially the most undervalued one for MLOps: adding models creates an entirely new layer to the operations stack. In a simplified way, each level of the operation stack covers the unit of computation, how …</p></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops">https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops</a></em></p>]]>
            </description>
            <link>https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275856</guid>
            <pubDate>Tue, 25 Aug 2020 20:43:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If Humans Spoke in Vectors]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275741">thread link</a>) | @KhoomeiK
<br/>
August 25, 2020 | https://rohan.bearblog.dev/humans-spoke-vectors/ | <a href="https://web.archive.org/web/*/https://rohan.bearblog.dev/humans-spoke-vectors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>Would we be as successful as we are now? I'd say no.</p>
<h3 id="what-are-semantic-vectors">What are Semantic Vectors</h3>
<p>But first, what does it even mean to communicate with vectors? Communication can be defined as the transfer of an idea from one person to another, and a semantic vector essentially tries to capture an idea in a numerical representation. Vectors have grown vastly in popularity in Natural Language Processing in the past decade, and now virtually all research in the field revolves around a basic assumption that vectors can effectively convey ideas.</p>
<p>The first commonly used semantic vector model, generally known as word embedding (as in embedding a word in a vector space), was <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> in 2013. Word2vec learns vector representations of words by encouraging words that occur in similar contexts to have similar vector representations. So, for example, if we have a corpus with examples like "the dog chased the cat", "the canine chased the cat", and "the rat feared the cat", word2vec would learn to represent "dog" and "canine" with similar embeddings. The generated vectors are generally hundreds of dimensions, but the embeddings for "dog", "canine", and "rat" in our example might look something like [0.3, 0.1, 0.8], [0.3, 0.2, 0.8], and [0.4, 0.6, 0.7], respectively. Notice the similarity of "dog" and "canine" due to occurrence in similar contexts in our corpus.</p>
<p>These were known as "distributional embeddings", because they were found to distribute semantic categories across vector dimensions. A commonly cited example points out how if you subtract the word embedding for "man" from "king", and then add "woman", you get "queen". So these high-dimensional vectors that learn word representations just from context are able to pretty accurately understand the relationships between words. Sure, they might not know what a king looks like, what he does, and his historic relevance, but they do know that he's similar to a man in some ways and similar to a queen in other ways.</p>
<h3 id="word-relations-and-differance">Word Relations and Différance</h3>
<p>These relations are what many of us will resort to when asked about the structure of language. A dictionary, after all, just refers us to other words when asked for any definition. The implicit conclusion here that without grounding in the real world, all words are purely relational, bears striking resemblance to <a href="https://en.wikipedia.org/wiki/Differance">Derrida's Différance</a>. The core of Différance, which became fundamental to Deconstruction and the Postmodernism that now dominates humanities, is the idea that words gain meaning only through their difference with (and deference to) others. Only in the real world, with speech, outside of the realm of paper, would Derrida acknowledge that an uttered symbol can present real meaning.</p>
<p>But virtually all Machine Learning research in Natural Language Understanding focuses on written text, so can any real meaning be derived? Again, I'd say no. All the colossal Deep Learning architectures that seem to dominate NLP these days don't actually understand language—they've just learned correlations between words in manners ultimately quite similar to the original word2vec. This is quite obvious with <a href="https://arxiv.org/abs/2005.14165">OpenAI's GPT-3</a>, which is able to produce text that sounds very realistically written by a human, but doesn't form any coherent meaning. The model has essentially memorized all the relationships between words from a huge corpus of internet text, but it can't know what those words mean without some kind of grounding in the physical world.</p>
<p>Some meanings can be largely summed up in these simple vector relationships, but others are quite a bit more complex. The relationship between "predator" and "prey", for example, is abstract enough that I'd pretty confidently say their meanings can be captured in some kind of vector representation. But the relationship between "knife" and "onion"? You as a reader probably know how those words are related, but I can't even begin to capture the nature of their relationship in language. Yes, we can "cut an onion with a knife" (and <a href="https://transformer.huggingface.co/doc/gpt2-large">GPT-2</a>) is actually capable of predicting "knife" here), but how does this action actually work? What is the purpose it serves? What do the words really mean?</p>
<h3 id="grounding-meaning">Grounding Meaning</h3>
<p>But we might be confusing two things here. Though these language models learn the meanings of words through their relationships and co-occurence with one another, we can think about definitions on their own as well. A classic example from Indian philosophy is that of the pot. What does it mean to be a pot? As humans, we're great at generating <a href="https://en.wikipedia.org/wiki/Theory_of_forms">Platonic Forms</a> from our real world experiences. Once we've seen a few pots, our brains are able to construct a pretty accurate generalized Form for pots, and when we see one again, we're easily able to recognize that it's another instance of this Form. This representation our brain learns is so much more information dense than what can be gleaned from language. It's imbued with an innate understanding of visual and physical attributes.</p>
<p><a href="https://arxiv.org/abs/1810.04805">Google's BERT</a> might read an article about pots and then tell us that pots are often made of clay, can be used as cooking vessels, and have been found in China from 20,000 BC. But ask BERT whether a pot with holes would be able to hold water and it'd have no idea. This could certainly be construed as a language issue instead of a grounding issue. Maybe we could find some more textual data that relates pots to holes and holes to water so that BERT can learn better semantic representations for them. The real solution to me though, would be to ground the language model in the physical world, perhaps with some kind of Reinforcement Learning strategy. If a picture is worth a thousand words and a video is worth a million, the ability to interact with a physical environment must carry a tremendous amount of semantic information.</p>
<h3 id="composing-and-comprehending-meaning">Composing and Comprehending Meaning</h3>
<p>While grounding is vital for learning accurate word representations, something even more elementary to me is the <a href="https://en.wikipedia.org/wiki/Principle_of_compositionality">compositionality of language</a>. Compositionality is the idea that the meaning of a sentence is a unique, synergistic result of combining the constituent words within it. It's closely related to Noam Chomsky's <a href="https://en.wikipedia.org/wiki/Recursion#In_language">Recursion</a>, which he asserts is the fundamental element underlying all human language. Recursion is the ability for us to infinitely nest expressions in language, much like this very sentence, where I can just continue chaining on clauses, again and again, until I desire to stop, at which point I may place a period in writing, or a pause in speech, and then continue on to present yet another idea.</p>
<p>And upon the conclusion of that sentence, there is a moment of understanding, where the meaning that I intend to express bursts forth in its entire form in your mind. Bhartrhari, an Indian linguistic philosopher of the 5th century, termed this "bursting forth" as "<a href="https://en.wikipedia.org/wiki/Sphota">sphoṭa</a>". The symbols, whether as letters on paper or sounds in speech, agglomerate together to create a unified meaning that is entirely comprehended in a single moment. Later on, the Mimamsakas built on this idea to emphasize that a sphoṭa is not indivisible as originally conceptualized, but rather is the result of the hierarchical composition of sounds, words, and clauses through grammatical structures.</p>
<p>The ability to compose words to generate coherent moments of understanding is vital to language in my opinion, and I'm skeptical of the ability of word vector embeddings to do this effectively. There has certainly been progress on this front in ML with <a href="https://arxiv.org/abs/1706.03762">Transformer architectures</a>. Previously, RNNs dominated the NLP landscape. These neural nets linearly process language one word at a time, feeding the collective representation of the sentence so far forward until an entire representation is outputted at the end.</p>
<p>The problem here, of course, is the severe loss of information due to the lack of syntax trees. While you may not actively think about parsing syntax trees of sentences, it's an essential prior for proper understanding of any language. Some languages like Japanese put their verbs at the end of the sentence ("cat mouse chased") whereas others like English put our verbs between the subject and object ("cat chased mouse"). It might seem trivial, but syntax has wide-reaching consequences for language understanding. If you were reading a text in an Object-Verb-Subject language ("mouse chased cat") without knowledge of the syntax and the consequent relations constructed in the sentence, you'd be very confused.</p>
<p>An interesting side-note here is that speakers of left-branching languages (which put the verb at the end of a clause) have been <a href="https://www.nature.com/articles/s41598-018-37654-9">shown</a> to have better short-term memories than right-branching speakers. This is theorized to be because speakers must maintain the multiple elements in their memory for longer before their related together by the verb. In a right-branching language, the sphoṭa builds from a subject, to the subject's relationship, to the subject's relationship to the object. But with a left-branching language, one first perceives the sphoṭa of the subject, remembers it while perceiving the sphoṭa of the object, then composes those sphoṭas in the final verbal relation.</p>
<p>The true nature of a sentence is more like a graph/network or a tree, and the fact that we communicate it linearly is more of an evolutionary hack we've developed to speak out of our single mouth. So when attentional models and Transformers came along, they blew RNNs out of the water because they were implicitly capable of understanding tree structures. The attention mechanism of a Transformer is much what it sounds like, it learns to pay attention to the right things at the right time. When given a sentence "the cat chased the mouse", for the first "the" it might attend to "cat", and for "chased" it might attend to "cat" and "mouse" in unique ways (which are the verb's subject and object). Attention learns how to correctly identify the syntax relationships for sentences, thereby arriving at better semantic representations.</p>
<h3 id="logic-or-statistics">Logic or Statistics</h3>
<p>Transformers, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rohan.bearblog.dev/humans-spoke-vectors/">https://rohan.bearblog.dev/humans-spoke-vectors/</a></em></p>]]>
            </description>
            <link>https://rohan.bearblog.dev/humans-spoke-vectors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275741</guid>
            <pubDate>Tue, 25 Aug 2020 20:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Impact of Parallel Disk Access]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275722">thread link</a>) | @pkolaczk
<br/>
August 25, 2020 | https://pkolaczk.github.io/disk-parallelism/ | <a href="https://web.archive.org/web/*/https://pkolaczk.github.io/disk-parallelism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
  
  <time datetime="2020-08-24T00:00:00+00:00">August 24, 2020</time>
</header>

  <p>One of the well-known ways of speeding up a data processing task is partitioning the data into smaller
chunks and processing the chunks in parallel. Let’s assume we can partition the task easily, or the input data is already 
partitioned into separate files which all reside on a single storage device. Let’s also assume the algorithm we run on those
data is simple enough so that the computation time is not a bottleneck. How much performance can we gain by reading the files in parallel? 
Can we lose any?</p>

<!--more-->



<p>While working on <a href="https://github.com/pkolaczk/fclones">fclones</a> duplicate file finder,
I’ve put a lot of effort into making it as fast as possible by leveraging capabilities of modern hardware.
That’s why I designed my program in a way that all data processing stages can be easily parallelized. 
The newest version at the moment of writing this post (0.7.0) allows to set thread pools for random I/O 
and sequential I/O separately, and can adapt the settings to different types of storage devices.</p>

<p>In this blog post I’m presenting the results of a few experiments I’ve made separately on SSD and HDD.
All the experiments were perfomed on either a Dell Precision 5520 laptop with a 4-core Xeon and a 512 NVMe SSD, from 2016, 
running Ubuntu Linux 20.04, or an older Dell M4600 with a 7200 RPM Toshiba HDD running Mint Linux 19.03.</p>


<p>The most time-consuming part of the job is actually reading
the data from disk into memory in order to compute hashes. The number of files is typically large (thousands or even millions) 
and the problem of computing their hashes is embarrassingly parallel. 
The first thing my duplicate finder does is scanning directory tree and fetching file metadata like file lenghts and inode identifiers. 
This process issues a lot of random I/O requests. As expected, the performance gains from multithreading were huge, 
which is illustrated in Fig.&nbsp;1.</p>

<div>
    
    
    <p><span> Fig.1: Time to fetch metadata of ~1.5 million file entries on an SSD</span>
</p></div>

<p>In the next stage, the files matching by size are compared by hashes of their initial 4 kB block. This involves a lot of random I/O as well – 
for each file, <code>fclones</code> opens it, reads the first 4 kB of data, computes the hash and closes the file, then moves to the next file. 
SSDs are great at random I/O, and high parallelism level leads to big wins here as well (Fig.&nbsp;2). It was surprising to me
that even 64 threads, which are far more than the number of CPU cores (4 physical, 8 virtual), still improved the performance.
I guess that with requests of such a small size to such a fast storage, you need to submit really many of them to keep 
the SSD busy.</p>

<div>
    
    
    <p><span> Fig.2: Time to hash initial blocks of ~1.2 million files on an SSD</span>
</p></div>

<p>Let’s look at <code>iostat</code>. With only 1 thread, <code>iostat</code> reports CPU to be mostly idle, but
the SSD utilization is at 100%.</p>

<pre>avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           2,39    0,00    5,03    5,03    0,00   87,55

Device            r/s     rMB/s   rrqm/s  %rrqm r_await rareq-sz   aqu-sz  %util
nvme0n1       5458,00     21,32     0,00   0,00    0,11     4,00     0,00 100,00
</pre>

<p>Does it mean the SSD is already at its 100% performance? No, because 
<code>%util</code> is calculated as the ratio of <em>wall clock time</em> the device is serving requests. 
This doesn’t account for effects of submitting multiple requests at the same time.
It looks like my SSD is very happy to receive more load. With 64 threads,
<code>%util</code> is still at 100%, but the served read request rate went up by over 40 times:</p>

<pre>avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          28,46    0,00   66,92    4,62    0,00    0,00

Device            r/s     rMB/s   rrqm/s  %rrqm r_await rareq-sz   aqu-sz  %util
nvme0n1     223974,00    874,90     0,00   0,00    0,17     4,00     0,00 100,00
</pre>

<p>BTW: why the average queue size <code>aqu-sz</code> remains 0,00 even under 64 threads remain a mystery to me. 
Feel free to drop any clues in the comments.</p>

<p>How do I known the CPU is not the main bottleneck here then? The CPU load numbers given by <code>iostat</code> are pretty high, aren’t they?
I measured how much time it takes to do the task when all the data were cached, by running it again, without prior dropping caches. 
When all cached, the metadata scanning took 1.5&nbsp;s and the partial hashing took 1.7&nbsp;s. This is still
significantly faster than when physical reads were involved, so nope, 
I/O is still the major bottleneck, even with 64 threads.</p>



<p>And what about the sequential I/O reads? Does parallelizing the sequential I/O improve speed as well?
It looks like it does, although not by as much as for random I/O (Fig.&nbsp;3).
The last stage of <code>fclones</code> algorithm is hashing full files – in this experiment the files were mostly JPG and RAW images, 
about 10 MB large on average. Gains seem to hit a plateau a bit earlier – after 8 threads. In this case the operating 
system has an opportunity to prefetch data, so
it can keep the SSD busy even when my application is not asking for data for a while.</p>

<div>
    
    
    <p><span> Fig. 3: Time to hash 21.6 GB of data read from an SSD in function of number of threads</span>
</p></div>


<p>Contrary to an SSD, a spinning drive has a large seek-latency and it can serve I/O requests
at much lower rate. Hence, we can definitely expect random I/O to be much slower on an HDD than on an SSD. 
But can we expect any performance gains from reading in parallel? 
My initial thought was there shouldn’t be any visible gains, because a single HDD can only serve 
a single read request at a given time, then it has to reposition the heads to “jump” to another file, and 
this looks very “sequentially” in principle. Having a large number of requests piled up in the queue 
shouldn’t change anything: the HDD would handle them in a sequence anyways. 
An HDD is also slow enough that even a single fast thread should keep it fully busy with at 
least one request ready to serve at any time.</p>

<p>I was wrong. It turns out that for small, random I/O requests there are noticeable gains from parallelism 
even on an HDD (Fig. 4). But this happens for a different reason than on SSD. 
The seek latency depends heavily on the <em>order</em> of the I/O requests. If the process submits more
I/O requests from multiple threads, the operating system can <em>reorder</em> them by physical data location, thus minimizing
the distance the HDD heads have to travel.</p>

<div>
    
    
    <p><span> Fig.4: Time to hash initial blocks of 46,165 files on a 7200 RPM HDD</span>
</p></div>


<p>Unfortunately, when reading larger chunks of data sequentially, using multi-threding actually hurts the throughput (Fig.&nbsp;5).
This is because the operating system interleaves the I/O requests coming from different threads and the HDD would have
to reposition the heads frequently jumping from one file to another. How much throughput is lost depends heavily on the operating
system and its configuration, but generally I’d expect this to be a factor 2x-10x.</p>

<div>
    
    
    <p><span> Fig.5: Time to hash 1.7 GB of data on a 7200 RPM HDD</span>
</p></div>

<p>One way of solving this problem in an application is to not allow many threads to contend for the same HDD device at the OS level, and 
instead make the application take some control over the I/O request scheduling by itself.
You can use a dedicated single thread to handle all I/O to a single spinning drive (this is what <code>fclones</code> does since version 0.7.0),
or guard I/O operations by a critical section (mutex) associated with each HDD and locked at a granularity coarse enough that
seek time doesn’t matter. I don’t recommend making the whole application single-threaded, because that would disallow
issuing parallel requests to multiple devices and it wouldn’t allow the gains outlined above.</p>

<p>Additionally, many operating systems allow to tell the kernel that the application will be reading the file data sequentially. 
For example in Linux, after opening the file, just call <a href="https://man7.org/linux/man-pages/man2/posix_fadvise.2.html"><code>posix_fadvise</code></a> with <code>POSIX_FADV_SEQUENTIAL</code>:</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>fs</span><span>::</span><span>*</span><span>;</span>
<span>use</span> <span>nix</span><span>::</span><span>fcntl</span><span>::</span><span>*</span><span>;</span>
<span>let</span> <span>file</span> <span>=</span> <span>File</span><span>::</span><span>open</span><span>(</span><span>"foo.txt"</span><span>)</span><span>?</span><span>;</span>
<span>let</span> <span>errno</span> <span>=</span> <span>posix_fadvise</span><span>(</span><span>file</span><span>.as_raw_fd</span><span>(),</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>PosixFadviseAdvice</span><span>::</span><span>POSIX_FADV_SEQUENTIAL</span><span>)</span><span>?</span><span>;</span>
</code></pre></div></div>

<p>Internally this option increases the size of the read-ahead buffer, so the system can fetch data in larger chunks, 
potentially reducing the number of seeks. The effects of this flag are clearly visible and it improves performance of parallel access, 
but it is not strong enough to reduce the seek overhead to zero. Interestingly, I haven’t observed any effects 
of this flag on single-threaded throughput in my test, but YMMV.</p>


<ul>
  <li>Random I/O and reading metadata benefits from parallelism on both types of drives: SSD and HDD</li>
  <li>SSDs generally benefit from parallelism much more than HDDs</li>
  <li>Parallel access to HDD when reading large chunks of data sequentially can deteriorate performance</li>
  <li>Calling <code>posix_fadvise</code> to inform the system about sequential access pattern improves read throughput slightly
when sharing the device between multiple threads on Linux</li>
</ul>


  
    <hr>
    
        
      
      
       
    
    
  
</article></div>]]>
            </description>
            <link>https://pkolaczk.github.io/disk-parallelism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275722</guid>
            <pubDate>Tue, 25 Aug 2020 20:27:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thinking Scientifically to Get Rid of Acne: The SkinTheory Method]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275521">thread link</a>) | @jealousgelatin
<br/>
August 25, 2020 | https://blog.skintheory.app/skintheorys-birth/ | <a href="https://web.archive.org/web/*/https://blog.skintheory.app/skintheorys-birth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Click <a href="#acne-method">here</a> to skip to my acne solution section if you’d like. Read on if you’d like the whole story!</p>



<p>Hey there, I’m Conor. I’m a software engineer, I like to make indie music, and I’m an alumnus of suffering from some pretty bad acne.</p>



<p>Living with acne has been a humbling test of confidence. Talking about it this openly on the internet is something I don’t find easy, even though I no longer really have any acne. I’d like to share my success story in hopes of inspiring you guys to solve your acne with a new mindset.</p>



<h2>Here’s what I used to look like</h2>







<p>So, here I am on April 25, 2017. I’m 21 years old and a junior in University of Pittsburgh. My face hurts me, both mentally and physically. I had intense cystic acne that was deep enough to continue causing new pimples. Some days, I would leave class early because I felt gross and my face hurt.</p>



<h2>Bad Acne Can Be Hard To Get Rid Of</h2>



<div><figure><img loading="lazy" width="580" height="447" src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=580%2C447&amp;ssl=1" alt="" srcset="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1024%2C789&amp;ssl=1 1024w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=300%2C231&amp;ssl=1 300w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=768%2C592&amp;ssl=1 768w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1536%2C1184&amp;ssl=1 1536w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1200%2C925&amp;ssl=1 1200w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?w=1650&amp;ssl=1 1650w" sizes="(max-width: 580px) 100vw, 580px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1024%2C789&amp;ssl=1 1024w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=300%2C231&amp;ssl=1 300w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=768%2C592&amp;ssl=1 768w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1536%2C1184&amp;ssl=1 1536w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1200%2C925&amp;ssl=1 1200w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?w=1650&amp;ssl=1 1650w" data-lazy-src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=580%2C447&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Tons and Tons of different acne medications</figcaption></figure></div>



<p>I was looking for anything that would solve my acne. I was constantly trying new regimens and routines: regimens I’d found online, advice from my dermatologist, regimens that I’d concocted out of thin air, etc. There are an enormous amount of resources/communities online where I ‘d sourced these ideas from acne.org, <a href="https://www.reddit.com/r/skincareaddiction">reddit.com/r/skincareaddiction</a>, bloggers/youtube. While these communities were great for inspiration, they also created an information overload.</p>



<p>Each community would have their own regimens to try, some of which would contradict one another, some regimens were straight up paid celebrity/blogger propaganda, some regimens were just placebos. Forums could be filled with people saying, “This product is a miracle cure!”, while others said the product had flared up their acne. It was tough to find scientific, unbiased reviews of regimens to try on my own skin.</p>



<p>To compound this, trying a new routine on skin is a frustratingly slow process. Unfortunately, overnight cures don’t yet exist for acne. Changes in skin from a new regimen can take days or weeks to be seen and sometimes the skin will get worse before it gets better. There are also external forces working on your skin, like stress in school or work, sweating from working out, and climate (like warmer weather). <strong>I needed to experiment with my own skin and environment to accurately understand what was causing my acne.</strong></p>



<h2>Solving My Acne Scientifically</h2>



<div><figure><img loading="lazy" src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?resize=405%2C348&amp;ssl=1" alt="" width="405" height="348" srcset="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?w=540&amp;ssl=1 540w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?resize=300%2C258&amp;ssl=1 300w" sizes="(max-width: 405px) 100vw, 405px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?w=540&amp;ssl=1 540w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?resize=300%2C258&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?resize=405%2C348&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The handy dandy scientific method</figcaption></figure></div>



<p>It’s an understatement to say that tackling my acne seemed like a daunting challenge. It felt hopeless some days. I would try different regimens, my acne would flare, and I’d have no clue as to why. So I’d switch to a different regimen after a few days and still have no luck. Eventually I would return, cyclically to the same non-working regimens and never get anywhere.</p>



<p>I was still in college at this time, studying mainly Computer Science. I really dug my CS degree. Everyone has seen all the wild stuff that comes out of CS like machine learning and what not, but I think CS gave me something something else: a process for solving complex problems.</p>



<p>In the abstract, students of Computer Science are taught logical ways of problem solving. We are taught multiple sets of <a href="https://medium.com/@codingfreak/top-algorithms-data-structures-concepts-every-computer-science-student-should-know-e0549c67b4ac">rules</a> which we will use for transforming raw data inputs into our ideal and repeatable data outputs. What started as completely impossible problems (i.e <a href="https://www.geeksforgeeks.org/reverse-a-linked-list/">reversed linked list problems</a>) became trivial with these processes of algorithmic thinking. <a href="#note-1">[1]</a></p>



<h3 id="acne-method">My Acne Management Method</h3>



<p><em>Side Note: See the below section: <a href="#making-method-easier">Making The Method Easier</a> for a better experience.</em></p>



<p>With these newfound algorithmic ways of thinking, it was time logically get rid of my acne. Using the scientific method as a guideline, I decided to narrow down what factors affected my skin and try different product regimens to find my cure. The process looked like so:</p>



<ol><li><strong>Create a Hypothesis</strong>: I would choose a regimen to follow for some amount of time. Maybe I’d try a regimen I’d found on acne.org.<ul><li>e.g “Benzoyl Peroxide on left side of face, 1x a day; Moisturize 1x a day for 2 weeks.”</li></ul></li><li><strong>Run the Experiment</strong>: Every day or two I would:<ol><li>Take pictures of the affected areas with my new regimen.</li><li>Write a log in a private Google Doc the status of my skin and how the experiment was going. This log includes how my skin looks and feels, and any externalities that could affect the experiment. These logs would allow me to pinpoint how I felt about my skin over time.<ul><li>e.g “I have 10 pimples today and a good bit of redness. Mostly on the right side of my face. They do feel a bit less inflamed today. I also forgot to shower after working out yesterday, and woke up feeling sweaty. OOF 😕”</li></ul></li></ol></li><li><strong>Analyze the Results</strong>: After a solid time period (and 2 weeks may not always be enough!), I would compare my photos and logs from today to before I began this regimen’s experiment. If I showed some improvement, I would keep up the regimen. If I was getting worse, I would tweak the regimen or completely change to a new one with a day or 2 of buffer in between.</li></ol>



<p>I began to take a secret joy in doing this method. Firstly, I felt like I was actively working towards clearing my acne every night. I would come up with new ideas through the week and save them for later to try. Secondly, I felt like I wasn’t completely lost with my acne anymore. I used to get overwhelmed trying to keep all of my past treatments and externalities (food, sleep schedules, stress, etc.) together in my head. I would recurrently try regimens that I’d already attempted and forgot about to see if they’d work this time. Now, I had a mental map, process, and actual log of what worked and what didn’t.</p>



<h4>Issues</h4>



<p>The above method worked, but it is definitely rudimentary and so I’d found a few annoyances.</p>



<ul><li><a href="https://docs.google.com/">Google Docs</a> and <a href="https://blog.skintheory.app/skintheorys-birth/Flickr.com">Flickr</a> (where I stored my photos) were completely unlinked. They are 2 different apps. I would have to date entries in the Google Doc and find them in another tab on Flickr to find the photos.</li><li>I had to use Flickr to store my photos because I now had nightly acne selfies showing up in my phone’s gallery. If I were then trying to show a friend another picture, all these acne photos would pop up. 😐 Also, Flickr, now has a 1k picture upload limit. 😐</li></ul>



<h2 id="making-method-easier">Making The Method Easier: The SkinTheory App</h2>







<p>As someone who was able to beat their acne by thinking this way, I wanted to share this scientific process with kindred spirits who I knew were suffering as well. Unfortunately, my home-brewed process felt kinda janky.</p>



<p>In my free time I decided to learn React-Native to make an app (with some help of course) to streamline this process. It took loads of work between coding, making art assets, making a website, etc. but I think the acne solving method above is now much more straight forward. Especially for people who don’t consider themselves “technical”. Anyone with problem skin can now find a solution using this <a href="https://www.skintheory.app/">SkinTheory Method</a> without the <a href="https://www.urbandictionary.com/define.php?term=pita">PITA</a> overhead of managing a huge Google Doc and Flickr Library. Also, photos are sneakily hidden away in the app in order to not peskily show up in the phone gallery when you’re showing friends your cute dog pics.</p>



<h2>Skin Success</h2>



<p>So, if you like to see the results of my “Before &amp; After pics” here’s a pic with some of the fam below. I’ve moved to Ireland since I graduated so we’re out on my cousin’s farm.</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1.jpg?resize=512%2C384&amp;ssl=1" alt="" width="512" height="384" srcset="https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1980%2C1485&amp;ssl=1 1980w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?w=1740&amp;ssl=1 1740w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1980%2C1485&amp;ssl=1 1980w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?w=1740&amp;ssl=1 1740w" data-lazy-src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1.jpg?resize=512%2C384&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>I’m completely clear now and most of the scarring has healed. It’s a liberating feeling to be past acne but it did take time to find the correct regimen.</p>



<p>To wrap up what worked for me, I have crazy sensitive skin. The normal benzoyl peroxides and salicylic acids for solving acne would irritate my skin and cause more acne. I learned that I had to be moisturizing daily (thanks <a href="http://acne.org/">Acne.org</a>!), using gentle <a href="https://www.acne.org/comedogenic-list.html">non-comedogenic</a> moisturizers and soaps, and managing my stress. College caused huge stress and also affected my sleeping/eating habits which seemed to be causing more acne for me.</p>



<p>In the end, the SkinTheory Method helped me act as a scientist, testing and isolating factors affecting my own skin. It gave me the peace of mind that I was doing something at each step to control my acne. It paid off. <strong>Best of luck with your</strong> <strong>own experiments. 🔬</strong></p>



<h2 id="notes">Extra Notes</h2>



<p>[1]: Whether you have Computer Science know-how or not: I highly recommend this book on thinking about algorithms in day-to-day life (non-affiliate link): <a href="https://www.goodreads.com/book/show/25666050-algorithms-to-live-by">Algorithms to Live By: The Computer Science of Human Decisions by Brian Christian</a></p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://blog.skintheory.app/skintheorys-birth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275521</guid>
            <pubDate>Tue, 25 Aug 2020 20:07:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloudflare Warp Beta for macOS and Windows]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275292">thread link</a>) | @0xbkt
<br/>
August 25, 2020 | https://1.1.1.1/beta/ | <a href="https://web.archive.org/web/*/https://1.1.1.1/beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-depth-perspective-root=""><div><div><div data-depth="3"><div><h2 data-js-balance-text="">Thank you for helping us make a safer and faster internet for the desktop</h2><div data-js-balance-text=""><p>Select the appropriate link to download the desktop app for your system. This is a Beta release, so remember to provide feedback and learn about known issues using the link below.</p><p><a href="https://support.cloudflarewarp.com/hc/en-us/articles/360051891794-Beta-Known-issues" target="_blank">Learn more about known issues</a></p></div></div></div></div><div><div><p>macOS Catalina</p><div><p>Minimum system <br> requirements</p><p>10.15 or higher <br> 64 bit only</p></div><p><a href="https://support.cloudflarewarp.com/hc/en-us/articles/360051891814-Beta-Install-Instructions">macOS installation Instructions</a></p><p>Windows 10</p><div><p>Minimum system <br> requirements</p><p>1909 or higher <br> 64 bit only</p></div><p>Windows Installation instructions</p></div></div><div data-depth-perspective-scroll-anchor="" data-depth="3"><div><div><div><div><div><div><p>Minimum system <br> requirements</p></div><div> <p>10.15 or higher <br> 64 bit only</p></div><div><p>1909 or higher <br> 64 bit only</p></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://1.1.1.1/beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275292</guid>
            <pubDate>Tue, 25 Aug 2020 19:49:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python libraries to make your code readable, reliable and maintainable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275037">thread link</a>) | @makaimc
<br/>
August 25, 2020 | https://isaak.dev/2020/08/python-libraries-to-make-your-code-readable-and-maintainable | <a href="https://web.archive.org/web/*/https://isaak.dev/2020/08/python-libraries-to-make-your-code-readable-and-maintainable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Experienced programmers understand perfectly well that in development they spend most of the time reading code 
and therefore they treat the process of writing code with the deepest trepidation (and sometimes with fanaticism). 
To write quality and maintainable code, you need to take the time to write tests and integrate QA tools. There is a 
whole technique aimed at test-driven development (<a href="https://en.wikipedia.org/wiki/Test-driven_development">TDD</a>) and I will not devote this article to the topic of testing as 
such. Tests are absolutely necessary and there is nothing to discuss. In this article, we are going to talk about tools 
that help you write quality Python code.</p>

<p>Table of content:</p>

<ul>
  <li><a href="#testing-frameworks">Testing Frameworks</a></li>
  <li><a href="#test-runners">Test Runners</a></li>
  <li><a href="#e2e-testing-gui--frontend">E2E Testing</a></li>
  <li><a href="#fake-data">Fake Data</a></li>
  <li><a href="#mocking">Mocking</a></li>
  <li><a href="#code-coverage">Code coverage</a></li>
  <li><a href="#object-factories">Object Factories</a></li>
  <li><a href="#code-style">Code Style</a></li>
  <li><a href="#typing">Typing</a></li>
</ul>


      <h2 id="testing-frameworks">
        
        <a href="#testing-frameworks">Testing Frameworks</a>
        
      </h2>

<p><a href="https://github.com/pytest-dev/pytest/"><strong>pytest</strong></a> is a framework that makes it easy to write small tests, yet scales to support complex functional testing for applications and libraries.</p>

<p>Features</p>

<ul>
  <li>Detailed info on failing assert statements (no need to remember self.assert* names);</li>
  <li>Auto-discovery of test modules and functions;</li>
  <li>Modular fixtures for managing small or parametrized long-lived test resources;</li>
  <li>Can run <code>unittest</code> (including trial) and nose test suites out of the box;</li>
  <li>Python 3.5+ and PyPy 3;</li>
  <li>Rich plugin architecture, with over 315+ external plugins and thriving community;</li>
</ul>



<p><a href="https://github.com/HypothesisWorks/hypothesis"><strong>Hypothesis</strong></a>  is a family of testing libraries that let you write 
tests parametrized by a source of examples. A Hypothesis implementation then generates simple and comprehensible 
examples that make your tests fail. This simplifies writing your tests and makes them more powerful at the same time, 
by letting software automate the boring bits and do them to a higher standard than a human would, freeing you to focus 
on the higher-level test logic.</p>



<p><a href="https://github.com/robotframework/robotframework"><strong>Robot Framework</strong></a> is a generic open-source automation framework 
for acceptance testing, acceptance test-driven development (ATDD), and robotic process automation (RPA). 
It has simple plain text syntax and it can be extended easily with libraries implemented using Python or Java.</p>



<p><a href="https://docs.python.org/3/library/unittest.html"><strong>unittest</strong></a> is a unit testing framework from Python’s stdlib, 
which was originally inspired by JUnit and has a similar flavor as major unit testing frameworks in other languages. 
It supports test automation, sharing of setup and shutdown code for tests, aggregation of tests into collections, 
and independence of the tests from the reporting framework.</p>




    
      <h2 id="test-runners">
        
        <a href="#test-runners">Test Runners</a>
        
      </h2>

<p><a href="https://github.com/tox-dev/tox"><strong>tox</strong></a> is a command-line driven CI frontend and development task automation tool.</p>

<p>tox creates virtual environments for all configured so-called <code>testenvs</code>, it then installs the project and other necessary dependencies and runs the configured set of commands:</p>

<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598270513268/Q1-E6b6nw.png" alt="image.png"></p>




    
      <h2 id="e2e-testing-gui--frontend">
        
        <a href="#e2e-testing-gui--frontend">E2E Testing (GUI / Frontend)</a>
        
      </h2>

<p><a href="https://github.com/SeleniumHQ/selenium/"><strong>Selenium</strong></a> is an umbrella project encapsulating a variety of tools and 
libraries enabling web browser automation. Selenium specifically provides an infrastructure for the W3C WebDriver 
specification — a platform and language-neutral coding interface compatible with all major web browsers.</p>



<p><a href="https://github.com/locustio/locust"><strong>Locust</strong></a> is an easy to use, scriptable, and scalable performance testing tool.
 You define the behavior of your users in regular Python code, instead of using a clunky UI or domain-specific 
 language. This makes Locust infinitely expandable and very developer-friendly.</p>



<p><a href="https://github.com/DevExpress/testcafe"><strong>TestCafe</strong></a> is a Node.js tool to automate end-to-end web testing. Write 
tests in JS or TypeScript, run them, and view results.</p>

<ul>
  <li><strong>Works on all popular environments</strong>: TestCafe runs on Windows, MacOS, and Linux. It supports desktop, mobile, remote and cloud <a href="https://devexpress.github.io/testcafe/documentation/using-testcafe/common-concepts/browsers/browser-support.html">browsers</a> (UI or headless).</li>
  <li><strong>1 minute to set up</strong>: You <a href="https://devexpress.github.io/testcafe/faq/#i-have-heard-that-testcafe-does-not-use-selenium-how-does-it-operate">do not need WebDriver</a> or any other testing software. Install TestCafe with one command, and you are ready to test: <code>npm install -g testcafe</code></li>
  <li><strong>Free and open source</strong>: TestCafe is free to use under the <a href="https://github.com/DevExpress/testcafe/blob/master/LICENSE">MIT license</a>. <a href="#plugins">Plugins</a> provide custom reports, integration with other tools, launching tests from IDE, etc. You can use the plugins made by the GitHub community or make your own.</li>
</ul>

<p>Usage example:</p>

<p><img src="https://raw.githubusercontent.com/DevExpress/testcafe/master/media/install-and-run-test.gif" alt="Install TestCafe and Run a Test"></p>



<p><a href="https://github.com/asweigart/pyautogui"><strong>PyAutoGUI</strong></a> is a cross-platform GUI automation Python module for human beings. 
Used to programmatically control the mouse &amp; keyboard.</p>




    
      <h2 id="fake-data">
        
        <a href="#fake-data">Fake Data</a>
        
      </h2>

<p><a href="https://github.com/lk-geimfari/mimesis"><strong>Mimesis</strong></a> is a high-performance fake data generator for Python, which
provides data for a variety of purposes in a variety of languages. The
fake data could be used to populate a testing database, create fake API
endpoints, create JSON and XML files of arbitrary structure, anonymize
data taken from production and etc.</p>

<p>The key features are:</p>

<ul>
  <li><strong>Performance</strong>: The <a href="https://mimesis.name/foreword.html#performance">fastest</a> data generator available for Python.</li>
  <li><strong>Extensibility</strong>: You can create your own data providers and use them with Mimesis.</li>
  <li><strong>Generic data provider</strong>: The <a href="https://mimesis.name/getting_started.html#generic-provider">simplified</a> access to all the providers from a single object.</li>
  <li><strong>Multilingual</strong>: Supports data for <a href="https://mimesis.name/getting_started.html#locales">a lot of languages</a>.</li>
  <li><strong>Data variety</strong>: Supports <a href="https://mimesis.name/api.html">a lot of data providers</a> for a variety of purposes.</li>
  <li><strong>Schema-based generators</strong>: Provides an easy mechanism to generate data by the schema of any complexity.</li>
  <li><strong>Country-specific data providers</strong>: Provides data specific only for <a href="https://mimesis.name/api.html#builtin-data-providers">some countries</a>.</li>
</ul>




    
      <h2 id="mocking">
        
        <a href="#mocking">Mocking</a>
        
      </h2>

<p><a href="https://docs.python.org/3/library/unittest.mock.html"><strong>unittest.mock</strong></a> is a library from Python’s stdlib for mocking. 
It allows you to replace parts of your system under test with mock objects and make assertions about how they have been used.</p>

<p><code>unittest.mock</code> provides a core <code>Mock</code> class removing the need to create a host of stubs throughout your test suite. 
After performing an action, you can make assertions about which methods / attributes were used and arguments they
were called with. You can also specify return values and set needed attributes in the normal way.</p>



<p><a href="https://github.com/spulec/freezegun"><strong>FreezeGun</strong></a> is a library that allows your Python tests to travel through time
 by mocking the datetime module.</p>

<p>Once the decorator or context manager have been invoked, all calls to <code>datetime.datetime.now()</code>, 
<code>datetime.datetime.utcnow()</code>, <code>datetime.date.today()</code>, <code>time.time()</code>, <code>time.localtime()</code>, <code>time.gmtime()</code>, and <code>time.strftime()</code>
will return the time that has been frozen.</p>



<p><a href="https://github.com/patrys/httmock"><strong>HTTPretty</strong></a> is an HTTP client mocking tool for Python - inspired by Fakeweb for Ruby.</p>

<p>Common use cases:</p>

<ul>
  <li>Test-driven development of API integrations</li>
  <li>Fake responses of external APIs</li>
  <li>Record and playback HTTP requests</li>
</ul>



<p><a href="https://github.com/getsentry/responses"><strong>responses</strong></a> is a utility library for mocking out the requests Python library.</p>

<p>Example of usage:</p>

<div><div><pre><code><span>import</span> <span>responses</span>
<span>import</span> <span>requests</span>

<span>@</span><span>responses</span><span>.</span><span>activate</span>
<span>def</span> <span>test_simple</span><span>():</span>
    <span>responses</span><span>.</span><span>add</span><span>(</span><span>responses</span><span>.</span><span>GET</span><span>,</span> <span>'http://twitter.com/api/1/foobar'</span><span>,</span>
                  <span>json</span><span>=</span><span>{</span><span>'error'</span><span>:</span> <span>'not found'</span><span>},</span> <span>status</span><span>=</span><span>404</span><span>)</span>

    <span>resp</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>'http://twitter.com/api/1/foobar'</span><span>)</span>

    <span>assert</span> <span>resp</span><span>.</span><span>json</span><span>()</span> <span>==</span> <span>{</span><span>"error"</span><span>:</span> <span>"not found"</span><span>}</span>

    <span>assert</span> <span>len</span><span>(</span><span>responses</span><span>.</span><span>calls</span><span>)</span> <span>==</span> <span>1</span>
    <span>assert</span> <span>responses</span><span>.</span><span>calls</span><span>[</span><span>0</span><span>].</span><span>request</span><span>.</span><span>url</span> <span>==</span> <span>'http://twitter.com/api/1/foobar'</span>
    <span>assert</span> <span>responses</span><span>.</span><span>calls</span><span>[</span><span>0</span><span>].</span><span>response</span><span>.</span><span>text</span> <span>==</span> <span>'{"error": "not found"}'</span>
</code></pre></div></div>




    
      <h2 id="code-coverage">
        
        <a href="#code-coverage">Code coverage</a>
        
      </h2>

<p><a href="https://github.com/nedbat/coveragepy"><strong>Coverage.py</strong></a> measures code coverage, typically during test execution. It uses 
the code analysis tools and tracing hooks provided in the Python standard library to determine which lines are 
executable, and which have been executed.</p>




    
      <h2 id="object-factories">
        
        <a href="#object-factories">Object Factories</a>
        
      </h2>

<p><a href="https://github.com/FactoryBoy/factory_boy"><strong>factory_boy</strong></a> is a fixtures replacement based on thoughtbot’s factory_bot.</p>

<p>As a fixtures replacement tool, it aims to replace static, hard to maintain fixtures with easy-to-use 
factories for complex objects.</p>




    
      <h2 id="code-style">
        
        <a href="#code-style">Code Style</a>
        
      </h2>

<p><a href="https://github.com/wemake-services/wemake-python-styleguide"><strong>wemake-python-styleguide</strong></a> is is strictest and most 
opinionated python linter ever.</p>

<p>Goals of WPS:</p>

<ol>
  <li>Enforce <code>Python 3.6+</code> usage</li>
  <li>Significantly reduce complexity of your code and make it more maintainable</li>
  <li>Enforce “There should be one– and preferably only one –obvious way to do it” rule</li>
  <li>Create consistent coding and naming style</li>
</ol>



<p><a href="https://github.com/PyCQA/pycodestyle"><strong>pycodestyle</strong></a> is a tool to check your Python code against some of the style 
conventions in PEP8.</p>

<p>Features:</p>

<ul>
  <li>Plugin architecture: Adding new checks is easy.</li>
  <li>Parseable output: Jump to error location in your editor.</li>
  <li>Small: Just one Python file, requires only <code>stdlib</code>. You can use just the <code>pycodestyle.py</code> file for this purpose.</li>
  <li>Comes with a comprehensive test suite.</li>
</ul>



<p><a href="https://github.com/psf/black"><strong>Black</strong></a> is the uncompromising Python code formatter. By using it, you agree to cede
control over minutiae of hand-formatting. In return, <em>Black</em> gives you speed,
determinism, and freedom from <code>pycodestyle</code> nagging about formatting. You will save time
and mental energy for more important matters.</p>



<p><a href="https://github.com/google/yapf"><strong>yapf</strong></a> is a formatter for Python files.</p>

<p>YAPF takes a different approach. It’s based off of <code>clang-format</code>, developed by Daniel Jasper. In essence, 
the algorithm takes the code and reformats it to the best formatting that conforms to the style guide, even if the 
original code didn’t violate the style guide. The idea is also similar to the ‘gofmt’ tool for the Go programming 
language: end all holy wars about formatting - if the whole codebase of a project is simply piped through YAPF 
whenever modifications are made, the style remains consistent throughout the project and there’s no point 
arguing about style in every code review.</p>




    
      <h2 id="typing">
        
        <a href="#typing">Typing</a>
        
      </h2>

<p><a href="https://github.com/python/mypy"><strong>mypy</strong></a> is an optional static type checker for Python. You can add type 
hints (PEP 484) to your Python programs, and use <code>mypy</code> to type check them statically. Find bugs in your 
programs without even running them!</p>

<p>Here is a small example to whet your appetite (Python 3):</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Iterator</span>

<span>def</span> <span>fib</span><span>(</span><span>n</span><span>:</span> <span>int</span><span>)</span> <span>-&gt;</span> <span>Iterator</span><span>[</span><span>int</span><span>]:</span>
    <span>a</span><span>,</span> <span>b</span> <span>=</span> <span>0</span><span>,</span> <span>1</span>
    <span>while</span> <span>a</span> <span>&lt;</span> <span>n</span><span>:</span>
        <span>yield</span> <span>a</span>
        <span>a</span><span>,</span> <span>b</span> <span>=</span> <span>b</span><span>,</span> <span>a</span> <span>+</span> <span>b</span>
</code></pre></div></div>



<p><a href="https://github.com/facebook/pyre-check"><strong>Pyre</strong></a> is a performant type checker for Python compliant with PEP 484. 
Pyre can analyze codebases with millions of lines of code incrementally – providing instantaneous feedback to 
developers as they write code.</p>

<p>Pyre ships with Pysa, a security-focused static analysis tool we’ve built on top of Pyre that reasons about data flows 
in Python …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://isaak.dev/2020/08/python-libraries-to-make-your-code-readable-and-maintainable">https://isaak.dev/2020/08/python-libraries-to-make-your-code-readable-and-maintainable</a></em></p>]]>
            </description>
            <link>https://isaak.dev/2020/08/python-libraries-to-make-your-code-readable-and-maintainable</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275037</guid>
            <pubDate>Tue, 25 Aug 2020 19:25:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Do We Debug?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274930">thread link</a>) | @iamflimflam1
<br/>
August 25, 2020 | https://blog.cmgresearch.com/2020/08/25/how-do-we-debug.html | <a href="https://web.archive.org/web/*/https://blog.cmgresearch.com/2020/08/25/how-do-we-debug.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2 id="a-programming-classic">A programming classic</h2>

<p>There’s a classic programmer joke - the stages of debugging:</p>

<ol>
  <li>That can’t happen</li>
  <li>That doesn’t happen on my machine</li>
  <li>That shouldn’t happen</li>
  <li>Why does that happen</li>
  <li>Oh, I see…</li>
  <li>How did that ever work?</li>
</ol>

<p>It’s funny because it’s true.</p>

<p>But why do we laugh at this? It’s a pretty terrible state of affairs.</p>

<p>There’s a lot to unpack in this joke.</p>

<h3 id="that-cant-happen">“That can’t happen”</h3>

<p>First off why is our reaction immediately to deny the very existence of the bug? It’s unlikely that someone will have gone to the effort of cooking up an elaborate lie to waste our time looking for a non-existent bug.</p>

<p>Bugs are a violation of expectation, someone expected the system to behave in a certain way and it didn’t.</p>

<p>From a developers point of view, our expectations have also been violated. We told the computer to do one thing, and it has decided to something completely different.</p>

<p>This leads to the classic - “there must be a bug in the compiler” or “must be user error” and the equally popular blame the tools: “it’s because we’re using XYZ language or framework - everyone knows it’s buggy/broken”.</p>

<p>Developers take a lot of pride in their work - we’re generally compensated well because we are considered to be experts in our field - suddenly we’re exposed as being just as fallible as the next person.</p>

<p>Obviously the “That can’t happen” is a foolish response. A computer just does what it is told to do. It is not an evil mischievous imp that is deliberately trying to sabotage our work.</p>

<p>We need to change our immediate response to one of acceptance - there’s a bug, no point in pretending it doesn’t exist.</p>

<h3 id="that-doesnt-happen-on-my-machine">“That doesn’t happen on my machine”</h3>

<p>What kind of a developer just chucks code over the wall without testing it? Of <em>course</em> it works on my machine!</p>

<p>Well, what can we say about this one? We could just lump this in with the denial of the bug existence, but it’s worth breaking it out into its own discussion.</p>

<p>In complex systems this is a remote possibility, code that works in isolation may not work when deployed. Interactions between different parts of a system can cause the behaviour to change in unexpected ways.</p>

<p>However, in a well-architected system this should be rare, and if it’s really happening then it’s a sign that something is wrong.</p>

<p>There’s no point saying “it works on my machine” until you’ve actually gone and tried to reproduce the bug on your machine.</p>

<p>Once you can prove categorically that it works on your machine then you can add that to the evidence pile for debugging the problem.</p>

<h3 id="that-shouldnt-happen">“That shouldn’t happen”</h3>

<p>“Umm, yes, that’s why I’ve reported it as a bug” would be the facetious reply.</p>

<p>But this is another facet of the “I told the computer to do this, but instead it’s doing that”. It’s a violation of expectations on the developer’s side of things.</p>

<p>This is usually the phase of acceptance. We’ve now reached the point where we agree that something is wrong, we’ve seen the bug with our own eyes, it’s something wrong with what we’ve done, there’s no more excuses to hide behind.</p>

<h3 id="why-does-that-happen">“Why does that happen?”</h3>

<p>This is where things start to get interesting. This is the fun part bug bashing.</p>

<p>Why is this bug happening? What’s our hypothesis for what we are seeing and how do we test it?</p>

<h3 id="oh-i-see">“Oh, I see”</h3>

<p>The lightbulb moment of insight, through investigation you’ve developed a hypothesis of why the bug is happening and you have an idea on how to fix it.</p>

<p>The problem now becomes impossible not to see. It’s obvious. How did this code ever ship? Which moves up nicely onto the next stage.</p>

<h3 id="how-did-that-ever-work">“How did that ever work?”</h3>

<p>Hindsight is a wonderful thing.</p>

<p>Now that you know how to create the bug, and you know how the code is wrong, you’re wondering which idiot wrote it (spoiler alert - git blame will point the finger at you).</p>

<p>The code could never have worked properly. You’ll start to wonder how many other bits of the codebase are complete nonsense.</p>

<h2 id="adjusting-our-approach">Adjusting our approach</h2>

<p>Let’s turn the programming classic on its head and rewrite the stages of debugging:</p>

<ol>
  <li>This is happening</li>
  <li>Research</li>
  <li>Create a hypothesis</li>
  <li>Test hypothesis</li>
  <li>Fix the problem</li>
  <li>How do we stop this happening again?</li>
</ol>

<h3 id="this-is-happening">“This is happening”</h3>

<p>No point denying it - there’s a bug, I’m glad you found it.</p>

<h3 id="research">Research</h3>

<p>We need to gather information on the bug:</p>

<ul>
  <li>how do we reproduce it?</li>
  <li>what test data do we need?</li>
  <li>how much of the system do we need to run recreate it?</li>
  <li>what’s the minimum I need to recreate to debug it?</li>
  <li>which part of the codebase is it happening in?</li>
  <li>which bit of code is the likely problem?</li>
  <li>do we have any relevant logs from when the problem occurred?</li>
</ul>

<p>The more information we can gather the better.</p>

<h3 id="create-a-hypothesis">Create a hypothesis</h3>

<p>Our research should have pointed us at the potential problem, we should have developed enough knowledge to form a working hypothesis on what the bug is caused by. We should hopefully be looking at the bit of code that is wrong and have an idea on how to fix it.</p>

<h3 id="test-hypothesis">Test hypothesis</h3>

<p>How are you going to test your fix works?</p>

<p>Before jumping in and changing code can you definitely recreate the bug? Does it happen consistently in your test environment?</p>

<p>Can you write a unit test to recreate the bug?</p>

<p>When you apply your fix does the test now pass? When you run through the steps to recreate does it now consistently work?</p>

<h3 id="fix-the-problem">Fix the problem</h3>

<p>If we’re lucky the previous step proves that our thinking was correct, we’ve changed the code and everything works.</p>

<p>Clean up any debugging code go through code reviews and deploy - everyone is happy!</p>

<p>Don’t forget to check that you’ve not broken anything else…</p>

<p>The bug is fixed when the person who raised the bug in the first place is happy.</p>

<h3 id="how-do-we-stop-this-happening-again">How do we stop this happening again?</h3>

<p>This is the real value in finding and fixing bugs. The bug should never have happened in the first place.</p>

<ul>
  <li>Are we missing unit tests for this part of the codebase?</li>
  <li>Have we missed a whole class of unit tests across the codebase that make this kind of bug more likely?</li>
  <li>Are we missing integration tests?</li>
  <li>Do we have automated tests to catch these bugs?</li>
  <li>Is there something wrong in our process that allowed this bug to slip through the net?</li>
</ul>

<h2 id="types-of-bugs">Types of Bugs</h2>

<p>What kind of bugs do we encounter? And how do we fix them?</p>

<h3 id="easy-bugs">Easy(?) Bugs</h3>

<p>There’s a set of bugs that can be classed as “easy(?)”. There’s a question mark next to the easy as a bug being obvious or repeatable does not necessarily mean the finding the underlying cause and fixing it is necessarily easy.</p>

<ul>
  <li>UI Bugs</li>
  <li>Bugs of Omission or Misinterpretation</li>
  <li>Repeatable bugs</li>
</ul>

<h3 id="ui-bugs">UI Bugs</h3>

<p>It functions but it doesn’t look right.</p>

<p>UI bugs tend to revolve around the styling and positioning of elements.</p>

<p>Well organised companies will have wireframes and high definition mockups that you should be working from. They should have style guides and component libraries that tell you how things should look and behave.</p>

<p>Sometimes, we are working in the dark, there may not have been time or resources to design wireframes and mockups, you may be working from some scribbles on a napkin - make sure you fit with the rest of the application. Don’t break people’s expectations!</p>

<p>Another source of these bugs are different device formats - maybe it’s fine on your large desktop monitor, but on small laptops or mobile devices the UI you’ve created just doesn’t work.</p>

<p>There’s also a class of bugs around accessibility issues - these often get overlooked and unless attention is paid to this area it’s easy to forget about it only to have it flagged by a diligent QA person.</p>

<p>Solving these bugs should be straightforward:</p>

<ul>
  <li>What is it supposed to look like?</li>
  <li>Make it look right</li>
  <li>Test on the correct target devices and sizes</li>
</ul>

<p>There may be some fundamental process issues to be addressed here - someone knows what it should look like as they have raised the bug.</p>

<p>Why didn’t you know what it was supposed to look like when you built it?</p>

<h3 id="bugs-of-omission-or-misinterpretation">Bugs of Omission or Misinterpretation</h3>

<p>You thought you’d built the right thing.</p>

<p>You didn’t…</p>

<p>In theory, this should be an easy one to fix - find out what was supposed to be built, build it…</p>

<p>There are some questions to be asked around what went wrong in this situation - was the task not specified in enough detail, is there a communication gap between the product managers and the dev team that leads to the wrong thing being built?</p>

<p>Or did you just fundamentally misunderstand what was being asked of you?</p>

<p>Sometimes it’s simply a case of trying to hit a moving target. By the time you’ve finished building something everyone’s understanding of what should be built has changed. Expectations have changed and someone forgot to tell you…</p>

<p>Something is broken in your process - it’s important to work out what it is if this class of bug keeps occurring.</p>

<h3 id="repeatable-bugs">Repeatable bugs</h3>

<p>Every time I do these steps, this thing happens, it’s not what I expect to happen, it should do this instead.</p>

<p>This is a nice class of bugs - repeatable with a clear set of steps to recreate the problem.</p>

<p>Should be an easy fix:</p>

<ul>
  <li>Look at the application logs whilst recreating the bug</li>
  <li>Inspect any relevant crash logs and stack traces</li>
  <li>Run through the steps with a debugger attached and have it break on exceptions</li>
  <li>Simply walk through the code and sanity check it - does it make sense?</li>
</ul>

<p>However, for new developers or people unfamiliar with the codebase these can also be extremely frustrating bugs.</p>

<p>I can happily recreate the bug, it breaks on my machine, I have no idea where to even start looking in the codebase for where to fix it.</p>

<p>Senior developer strolls over, takes one look at the bug and immediately brings up the line of code that is the problem.</p>

<p>Someone who knows the codebase intimately will probably know where most data in the system is coming from and will appear to have some magical power for identifying where a bug it.</p>

<p>This is why bug fixing a few simple bugs can be such a good onboarding process.</p>

<p>What can we do if we don’t know the codebase?</p>

<p>We’ll need to start employing our powers of detection and deduction.</p>

<p>Look at the architecture of the system, how does data flow from one place to another. What are good …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cmgresearch.com/2020/08/25/how-do-we-debug.html">https://blog.cmgresearch.com/2020/08/25/how-do-we-debug.html</a></em></p>]]>
            </description>
            <link>https://blog.cmgresearch.com/2020/08/25/how-do-we-debug.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274930</guid>
            <pubDate>Tue, 25 Aug 2020 19:16:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open source platform for making synthetic data, sharing it]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24274535">thread link</a>) | @watson1008
<br/>
August 25, 2020 | https://gretel.ai/blog/readme-v2 | <a href="https://web.archive.org/web/*/https://gretel.ai/blog/readme-v2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><div><div><h2>We founded Gretel based on our beliefs that data shouldn’t be scary.</h2><figure><img src="https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f45361b7ebe7f6e8e7ed9cd_Readmev2.png" alt="" sizes="(max-width: 767px) 100vw, 586.95654296875px" srcset="https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f45361b7ebe7f6e8e7ed9cd_Readmev2-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f45361b7ebe7f6e8e7ed9cd_Readmev2.png 1440w"></figure><div><p><strong>It’s way too hard- sometimes seemingly impossible- to safely share and collaborate with sensitive data.</strong> We have a solution to this problem that we and every developer faces each day. We founded Gretel based on our beliefs that data shouldn’t be scary, and for you to compete in today’s world, you need to be able to use and learn from your data. </p><p>Companies like Amazon, Google, and Apple have the resources to give the developers the best of both worlds- data privacy and streamlined access to data. We’re here to make that possible for any developer.</p><p>In February we published our first <a href="https://gretel.ai/blog/gretel-readme">README</a> and started laying out our goal of enabling developers to safely share and collaborate with sensitive data, and our vision of democratizing building with data so everyone can use it. We asked for your feedback and ideas, and promised to share research, open source code, and provide examples. </p><p>In the 6 months since then, we have had conversations with nearly 100 developers and companies to understand the barriers to working with sensitive data and how we can apply privacy-enhancing technology to break down those barriers. Here is what we learned:</p><ul role="list"><li><strong>It can take developers months to get access to sensitive data to test an idea</strong>. Often this requires PM and legal approvals, snap-shots of production databases, and manual anonymization of sensitive fields. </li><li><strong>Privacy is an engineering problem, not a policy problem</strong>. Policies are open to interpretation, lack enforceability at different stages of a workflow, and eventually get abused. </li><li><strong>Fairness and ethics in AI is incredibly important. Datasets used to power AI in our lives are often limited and imbalanced, leading to bias against users and groups. &nbsp;</strong>‍</li></ul><p>In the past year, we have built a set of open-source SDKs that enable developers to label and share access to data, composable APIs to enable transformations to streaming data, and an &nbsp;open-source AI-based synthetic data library that can generate artificial datasets from sensitive data with <a href="https://gretel.ai/blog/using-generative-differentially-private-models-to-build-privacy-enhancing-synthetic-datasets-from-real-data">provable privacy guarantees</a>, and automatically boost minority classes in datasets to <a href="https://gretel.ai/blog/reducing-ai-bias-with-synthetic-data">reduce AI bias</a>.</p><p>Today, we are thrilled to release <a href="https://console.gretel.cloud/login">Gretel’s public beta to any developer</a>. It’s free, and you can get started in minutes with one of our guides for <a href="https://gretel.ai/gretel-cloud-faqs/how-do-i-get-started">labeling and sharing a dataset in 2 minutes</a>, or even generating <a href="https://www.youtube.com/watch?v=gS7kpR-LJTs&amp;t=144s">your first synthetic dataset</a> with differential privacy guarantees.</p><p>We are building Gretel for developers like you, so don’t be shy. Please follow us here, <a href="https://twitter.com/gretel_ai">Twitter</a>, and <a href="https://github.com/gretelai/gretel-synthetics">Github</a>. Want to see for yourself? <a href="https://console.gretel.cloud/login">Get started now!</a> We’re <a href="https://gretel.ai/cdn-cgi/l/email-protection#ea8283aa8d988f9e8f86c48b83"><span data-cfemail="cda5a48daabfa8b9a8a1e3aca4">[email&nbsp;protected]</span></a>.<br></p></div><a href="https://gretel.ai/blog"><p>View all posts</p></a></div></div></div></div>]]>
            </description>
            <link>https://gretel.ai/blog/readme-v2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274535</guid>
            <pubDate>Tue, 25 Aug 2020 18:40:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manifesto on the Teaching of Mathematics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274186">thread link</a>) | @noch
<br/>
August 25, 2020 | http://intellectualmathematics.com/manifesto/ | <a href="https://web.archive.org/web/*/http://intellectualmathematics.com/manifesto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<div id="primary">
		<main id="main" role="main">

		
<article id="post-31" class="page">
	

	
	<div>
		<p>My general teaching philosophy can be summarised in three principles or axioms regarding learning. They concern the source, the process, and the goal of learning respectively.</p>
<p>My first axiom is this: In a perfect world students pursue learning not because it is prescribed to them but rather out of a genuine desire to figure things out. We must therefore teach as if our students were of this kind. Only by aspiring to this ideal can we bring it closer to being realised.</p>
<p>It follows that we must not introduce any topic for which we cannot first convince the students that they should want to pursue it. This is a standard very rarely met in mathematics. Everyone likes to tell themselves that they are giving motivations for what they teach, but very little of what passes for motivation stands up to critical scrutiny as a motivation in the sense of the learning ideal outlined above. In all such cases, therefore, the student has no reason to pursue the topic in question other than obedience to the dictatorial authority of the teacher. In my view we cannot fault a student who hates mathematics in such circumstances; if anything, I would sooner fault a student who did not.</p>
<p>My second axiom concerns the process of learning. It says: We learn when we are challenged, when we push ourselves. If you’re not stuck you’re not learning. If it’s not a struggle you’re not doing it right.</p>
<p>It follows that we must always look for new points of view and pursue open-ended questions. The role of the teacher is not to make life easy for the student by giving crystal clear lectures and predictable tests. Instead the role of the teacher is to guide and encourage the student’s own process of learning by setting suitable challenges and by stimulating thought and reflection.</p>
<p>The final axiom of my teaching philosophy is that the goal of teaching is independent thought. We want students to be able to think and reason and apply what they know in new situations. We do not want to create robots or parrots or one-trick ponies.</p>
<p>It follows that when we learn something we must always inquire why it is so, and that we must answer this question according to our own judgement, not by mimicking some external standards of rigour and proof. It also follows that we must always seek out the broader meaning of what we are studying through its applications and interconnections with other ideas.</p>
<p>* &nbsp; &nbsp; * &nbsp; &nbsp; *</p>
<p>I have coined the phrase “Intellectual Mathematics” for the teaching philosophy I have in mind, because its fundamental principle is to treat students with the greatest possible intellectual respect.</p>
<p>This is the opposite of traditional mathematics teaching, which treats students like circus animals who need to be taught to jump through hoops by means of mindless drill training.</p>
<p>In the traditional approach the essence of the teacher’s role is authority. The teacher holds the carrot and the stick and that’s why you have to do as he says.</p>
<p>In the Intellectual Mathematics approach the essence of the teacher’s role is inspiration, and the goal of teaching is to stimulate thought and reflection. The teacher disavows the notion that he has the right to boss people around. Instead he considers it his responsibility to nourish in the students a desire to pursue their studies out of their own intrinsic motivation and interest.</p>
<p>It follows that in Intellectual Mathematics a topic is introduced only when the student can be convinced of the value of doing so. This is the opposite of the traditional approach where topics are routinely introduced at a stage where they serve no credible purpose whatsoever, simply because some curriculum designer decided that the students “need to have seen it” a year or two down the line.</p>
<p>Traditional curriculum designers butcher mathematics the way colonialists used to divide conquered continents: with crude and clinical cuts that are profoundly insensitive to any and all organic connections between the constituent parts. Such an approach makes sense for those who take their own authority for granted.</p>
<p>Intellectual Mathematics does not use such totalitarian techniques. Borders are not drawn where they do not belong and organic connections are respected. Mathematics is not severed from physics, nor differential equations from calculus, and so on, regardless of the administrative efficiencies of such compartmentalisation. You do not read every other line of a Shakespeare play in one class, and then the remaining lines in another class the following year. But in mathematics we routinely do precisely this. Such an approach is incompatible with intellectual respect for the students.</p>
<p>In traditional mathematics, things are taught because they are replicable and testable. The teacher is so dependent on the drillmaster paradigm that only topics that fit it can be taught. If a topic doesn’t allow for fifty-eight near-identical drill problems at the end of the section, then that topic is unteachable in traditional mathematics. It will not be taught no matter how important or crucial for understanding the true purpose of the entire subject. Conversely, topics that do lend themselves to endless drill problems will often be taught for this reason alone, despite being utterly pointless and contrived.</p>
<p>In Intellectual Mathematics, presenting topics in an inherently interesting and meaningful way is the first and foremost consideration. The purpose of the problems at the end of the section is not to force students through a repetitive obstacle course, but to convince the students of the value and importance of what they are studying.</p>
<p>The traditional approach fosters robotic, unthinking students. It selects for obedience and punishes independent and critical thought. Intellectual Mathematics does the opposite.</p>
<p>I say with Rousseau: “Let the child do nothing because he is told; nothing is good for him but what he recognises as good. When you are always urging him beyond his present understanding, you think you are exercising a foresight which you really lack. To provide him with useless tools which he may never require, you deprive him of man’s most useful tool — common-sense. You would have him docile as a child; he will be a credulous dupe when he grows up. You are always saying, ‘What I ask is for your good, though you cannot understand it. ...’ All these fine speeches with which you hope to make him good, are preparing the way, so that … every kind of fool may catch him in his snare or draw him into his folly.”</p>
<p>* &nbsp; &nbsp; * &nbsp; &nbsp; *</p>
<p>Intellectual Mathematics should not be confused with what passes for “reform” teaching. Everything we have said about the traditional approach applies equally well to “reform” approaches, because what is called “reform” pertains almost exclusively to surface form, not substance.</p>
<p>The basic fault of the modern “reform” movement is that it does not have the courage and confidence and ability to challenge the mathematical establishment on matters of substance. It assumes that the traditional approach is mathematically infallible, though pedagogically flawed. It therefore busies itself with concocting pedagogical schemes to make the same old medicine go down more easily. Group work! Use of technology! Inquiry learning! Flipping the classroom!</p>
<p>Modern “reform” efforts start at the wrong end. They put the cart before the horse, lipstick on the pig. The enterprise is doomed because it is predicated on the false assumption that the underlying curriculum is beyond rebuke. It doesn’t matter what pedagogical tricks you use if the substance you are trying to teach is poorly conceived in the first place. It is impossible to teach bad material well. That is why any reform worthy of its name needs to actually reform mathematical substance.</p>
<p>The Intellectual Mathematics approach starts with content and substance. It is not primarily about how to teach, but what to teach. It does not start with the question: “How can we make students understand concept X?” Rather it starts with the question: “Should we even teach concept X in the first place? If so, why?” This should be the guiding question of true reform.</p>
<p>* &nbsp; &nbsp; * &nbsp; &nbsp; *</p>
<p>Intellectual Mathematics is written for the intellectual fulfilment of the reader. This means that it seeks the most satisfying explanations, the most vivid illustrations, and the most compelling motivations. It also means that it engages our intuition whenever possible.</p>
<p>Traditional mathematics is written for robots and nitpickers. It is obsessed with being technically correct at the expense of all else. Again and again the ugliest proofs and the most contrived order of presentation are favoured in the traditional approach on the sole grounds that they are the easiest to write down in a manner that cannot be faulted with respect to logical correctness.</p>
<p>In Intellectual Mathematics, when facing a new concept, our primary goal is to understand how and why it works. The standard by which this is judged is our own sense of satisfaction and understanding. Emotion, passion, and the joy of insight are therefore essential components of Intellectual Mathematics.</p>
<p>In traditional mathematics, when facing a new concept, the goal is to reach the requisite results without making any technical errors. Crossing the t’s and dotting the i’s are the alpha and omega of traditional mathematics. Traditional mathematics is anti-human. It fetishises robotic manipulation of symbols and involves no emotions except a crippling fear of genuine and free human thought.</p>
<p>In traditional mathematics, the character and bulk of any given proof usually has next to nothing to do with why that particular theorem is true and everything to do with incidental technicalities. Students soon get the hint that mathematics is not about actually thinking and trying to figure stuff out; rather it is clearly a formal game completely divorced from common sense.</p>
<p>Indeed, formal proofs are sometimes accompanied by an informal heuristic argument, only to be followed …</p></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://intellectualmathematics.com/manifesto/">http://intellectualmathematics.com/manifesto/</a></em></p>]]>
            </description>
            <link>http://intellectualmathematics.com/manifesto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274186</guid>
            <pubDate>Tue, 25 Aug 2020 18:08:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SQL Templates for Common Product, Sales, Marketing, and Analytics Questions]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274045">thread link</a>) | @rahilsondhi
<br/>
August 25, 2020 | https://popsql.com/sql-templates | <a href="https://web.archive.org/web/*/https://popsql.com/sql-templates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>From startups to enterprises, SQL is more powerful when used across teams. Here are foundational templates we've battle-tested at PopSQL. Try them in our <a href="https://popsql.com/sql-templates/analytics/exploring-sample-dataset">sample DB</a>.</p><header><h2>Product</h2></header><div><a href="https://popsql.com/sql-templates/product/monitoring-a-feature-launch-with-sql"><div><h2><img src="https://popsql.com/static/docs/icons/inspect.svg" alt="icon"><div><p>Monitoring a Feature Launch with SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/product/how-has-customer-used-your-product"><div><h2><img src="https://popsql.com/static/docs/icons/inspect.svg" alt="icon"><div><p>Auditing a Customer's Usage of Your Product</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/product/product-most-used-features"><div><h2><img src="https://popsql.com/static/docs/icons/inspect.svg" alt="icon"><div><p>Ranking the Most Used Features in Your Product</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/product/finding-your-most-engaged-users"><div><h2><img src="https://popsql.com/static/docs/icons/inspect.svg" alt="icon"><div><p>Finding Your Product's Most Engaged Users</p><p>-&gt;</p></div></h2></div></a></div><hr><header><h2>Engineering</h2></header><div><a href="https://popsql.com/sql-templates/engineering/filtering-users-by-version-number-with-sql-regex"><div><h2><img src="https://popsql.com/static/docs/icons/schema.svg" alt="icon"><div><p>Filtering Users by Version Number with Regex in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/engineering/filtering-users-by-platform-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/schema.svg" alt="icon"><div><p>Filtering Users by Platform in SQL</p><p>-&gt;</p></div></h2></div></a></div><hr><header><h2>Support</h2></header><div><a href="https://popsql.com/sql-templates/support/analyzing-nps-responses-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/troubleshooting.svg" alt="icon"><div><p>Analyzing NPS Responses in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/support/finding-customers-at-risk-of-churning"><div><h2><img src="https://popsql.com/static/docs/icons/troubleshooting.svg" alt="icon"><div><p>Finding Customers at Risk of Churning</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/support/detecting-spikes-in-issues-from-support-tickets"><div><h2><img src="https://popsql.com/static/docs/icons/troubleshooting.svg" alt="icon"><div><p>Detecting Spikes in Issues from Support Tickets</p><p>-&gt;</p></div></h2></div></a></div><hr><header><h2>Sales</h2></header><div><a href="https://popsql.com/sql-templates/sales/tagging-sign-up-emails-as-work-vs-personal"><div><h2><img src="https://popsql.com/static/docs/icons/grow.svg" alt="icon"><div><p>Tagging Sign Up Emails as Work vs Personal</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/sales/creating-lead-scores-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/grow.svg" alt="icon"><div><p>Creating Lead Scores in SQL</p><p>-&gt;</p></div></h2></div></a></div><hr><header><h2>Marketing</h2></header><div><a href="https://popsql.com/sql-templates/marketing/calculating-daily-active-users-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/announce.svg" alt="icon"><div><p>Calculating Daily Active Users (and digging deeper)</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/marketing/running-a-funnel-analysis"><div><h2><img src="https://popsql.com/static/docs/icons/announce.svg" alt="icon"><div><p>Running a Funnel Analysis in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/marketing/marketing-attribution-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/announce.svg" alt="icon"><div><p>Marketing Attribution in SQL</p><p>-&gt;</p></div></h2></div></a></div><hr><header><h2>Analytics</h2></header><div><a href="https://popsql.com/sql-templates/analytics/how-to-create-histograms-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/analyze.svg" alt="icon"><div><p>Creating Histograms in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/analytics/detecting-skewness-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/analyze.svg" alt="icon"><div><p>Detecting Skewness in a Dataset in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/analytics/linear-regression-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/analyze.svg" alt="icon"><div><p>Calculating Linear Regression in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/analytics/exploring-sample-dataset"><div><h2><img src="https://popsql.com/static/docs/icons/analyze.svg" alt="icon"><div><p>Exploring our Sample Dataset</p><p>-&gt;</p></div></h2></div></a></div><hr><p>Want to write or request a new SQL template? <a href="https://airtable.com/shr37S7ciAObk7yk1">Let's talk!</a></p></section></div>]]>
            </description>
            <link>https://popsql.com/sql-templates</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274045</guid>
            <pubDate>Tue, 25 Aug 2020 17:57:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding self-supervised/contrastive learning w Bootstrap Your Own Latent]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24273792">thread link</a>) | @christinakim
<br/>
August 25, 2020 | https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html | <a href="https://web.archive.org/web/*/https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    

<p>Unlike prior work like SimCLR and MoCo, the recent paper <a href="http://arxiv.org/abs/2006.07733">Bootstrap Your Own Latent</a> (BYOL) from <a href="https://deepmind.com/">DeepMind</a> demonstrates a state of the art method for self-supervised learning of image representations without an explicitly contrastive loss function. This simplifies training by removing the need for negative examples in the loss function. We highlight two surprising findings from our work on reproducing BYOL:</p>

<p><strong>(1) BYOL generally performs no better than random when batch normalization is removed, and</strong></p>

<p><strong>(2) the presence of batch normalization implicitly causes a form of contrastive learning</strong>.</p>

<p>These findings highlight the importance of contrast between positive and negative examples when learning representations and help us gain a more fundamental understanding of how and why self-supervised learning works.</p>

<p>The code used for this post can be found at <a href="https://github.com/untitled-ai/self_supervised">https://github.com/untitled-ai/self_supervised</a>.</p>

<!--more-->



<p>Machine learning is typically done in a <em>supervised</em> fashion: we use a dataset consisting of the inputs and “right answers” (outputs) to find the best function that maps from the input data onto the right answers. By contrast, in <em>self-supervised</em> <sup id="fnref:ssup" role="doc-noteref"><a href="#fn:ssup">1</a></sup>  learning, no right answers are provided in the data set. Instead, we learn a function that maps the input data onto itself (ex: using the right half of an image to predict the left half of an image).</p>

<p>This approach has proven successful in everything from language to images and audio. In fact, most recent language models, from <a href="http://jalammar.github.io/illustrated-word2vec/">word2vec</a> to <a href="http://jalammar.github.io/illustrated-bert/">BERT</a> and <a href="https://arxiv.org/abs/2005.14165">GPT-3</a>, are examples of self-supervised approaches. More recently, this approach has had some incredible results for audio and images as well, and <a href="https://cacm.acm.org/news/244720-yann-lecun-yoshua-bengio-self-supervised-learning-is-key-to-human-level-intelligence/fulltext">some believe</a> that it may be an important component of human-like intelligence. This post focuses on self-supervised learning for image representations. For more background on self-supervised learning, see the resources below <sup id="fnref:resources" role="doc-noteref"><a href="#fn:resources">2</a></sup>.</p>



<h3 id="contrastive-learning">Contrastive learning</h3>

<p>Until <a href="https://arxiv.org/abs/2006.07733">BYOL</a> was published a few months ago, the best performing algorithms were <a href="http://arxiv.org/abs/1911.05722">MoCo</a> and <a href="http://arxiv.org/abs/2002.05709">SimCLR</a>. MoCo and SimCLR are both examples of <em>contrastive learning</em>.</p>

<p>Contrastive learning is the process of training a classifier to distinguish between “similar” and “dissimilar” input data. For MoCo and SimCLR specifically, the classifier’s positive examples are modified versions of the same image, while negative examples are other images in the same data set. For example, suppose there is a picture of a dog. In that case, the positive examples could be different crops of that image (see below figure), while the negative examples could be crops from entirely different images.</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/dog_aug.png" alt="Dog augmentations">
  <figcaption>Augmented versions of the original picture of a dog (a). Any two of these could be used as a positive example pair. Image from the <a href="https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html">SimCLR post</a>.</figcaption>
</figure>

<h3 id="byol-self-supervised-learning-without-contrastive-learning-not-exactly">BYOL: self-supervised learning without contrastive learning? Not exactly.</h3>

<p>While MoCo and SimCLR use contrastive learning between positive and negative examples in their loss functions, BYOL uses only positive examples in the loss function. At first glance, BYOL appears to be doing self-supervised learning without contrasting between different images at all. However, it appears that the primary reason BYOL works is that it is doing a form of contrastive learning — just via an indirect mechanism.</p>

<p>To more deeply understand this indirect contrastive learning in BYOL, we should first review how each of these algorithms works. See <a href="https://untitled-ai.github.io/appendix-for-understanding-self-supervised-contrastive-learning.html#appendix-a">Appendix A</a> for a table that shows the notation used in each of the papers. In this post, we use the notation from BYOL for consistency.</p>

<h3 id="simclr">SimCLR</h3>

<p>SimCLR is a particularly elegant self-supervised algorithm that managed to simplify previous approaches to their essential core and improve upon their performance. Two transformations <em>v</em> and <em>v’</em> of the same image <em>x</em> are fed through the same network to produce two projections <em>z</em> and <em>z’</em>. The contrastive loss aims to maximize the similarity of the two projections from the same input $x$ while minimizing the similarity to projections of other images within the same mini-batch. Continuing our dog example, projections of different crops of the same dog image would hopefully be more similar than crops from other random images in the same batch.</p>

<p>The multilayer perceptron (MLP) used for projection in SimCLR uses batch normalization after each linear layer.</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/simclr_arch.png" alt="SimCLR architecture">
  <figcaption>SimCLR architecture.</figcaption>
</figure>

<h3 id="moco">MoCo</h3>

<p>Relative to SimCLR, MoCo v2 manages to both decrease the batch size (from 4096 to 256) and improve the performance. Unlike SimCLR, where the top and bottom row in the diagram represent the same network (parameterized by $\theta$), MoCo splits the single network into an <em>online network</em> (top row) parameterized by $\theta$ and a <em>momentum network</em> (bottom row) parameterized by $\xi$. The online network is updated by stochastic gradient descent, while the momentum network is updated based on an exponential moving average of the online network weights. The momentum network allows MoCo to efficiently use a memory bank of past projections as negative examples for the contrastive loss. This memory bank is what enables the much smaller batch sizes. In our dog image illustration, the positive examples would be crops of the same image of a dog. The negative examples are completely different images that were used in past mini-batches, projections of which are stored in the memory bank.</p>

<p>The MLP used for projection in <a href="http://arxiv.org/abs/2003.04297">MoCo v2</a> does not use batch normalization</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/moco_v2_arch.png" alt="MoCo v2 architecture">
  <figcaption>MoCo v2 architecture. Top row is online encoder, bottom row is momentum encoder.</figcaption>
</figure>

<h3 id="byol">BYOL</h3>

<p>BYOL builds on the momentum network concept of MoCo, adding an MLP $q_\theta$ to predict z’ from z. Rather than using a contrastive loss, BYOL uses the L2 error between the normalized prediction p and target z’. Using our dog image example, BYOL tries to convert both crops of the dog image into the same representation vector (make p and z’ equal.) Because this loss function does not require negative examples, there is no use for a memory bank in BYOL.</p>

<p>Both MLPs in BYOL use batch normalization after the first linear layer only.</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/byol_arch.png" alt="BYOL architecture">
  <figcaption>BYOL architecture.</figcaption>
</figure>

<p>By the above description, it appears that BYOL can learn without explicitly contrasting between multiple different images. <strong>Surprisingly, however, we found that BYOL is not only doing contrastive learning, but that contrastive learning is essential to its success</strong>.</p>



<p>We originally implemented BYOL in PyTorch using code we had written for MoCo. When we began training our network, we found that <strong>our network performed no better than random</strong>. Comparing our code to <a href="https://github.com/sthalles/PyTorch-BYOL">another available implementation</a> (thanks sthalles!), we discovered we were missing batch normalization in the MLP. We were quite surprised that batch normalization was critical to training BYOL, while MoCo v2 did not require it at all.</p>

<p>For our initial testing, we trained a ResNet-18 with BYOL on the STL-10 unsupervised dataset using SGD with momentum and a batch size of 256 <sup id="fnref:opt" role="doc-noteref"><a href="#fn:opt">3</a></sup>. See <a href="https://untitled-ai.github.io/appendix-for-understanding-self-supervised-contrastive-learning.html#appendix-b">Appendix B</a> for details on data augmentation. Below are the first ten epochs of training for the same BYOL algorithm with and without batch normalization in the MLPs</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/surprising_stl10_10e.png" alt="MoCo v2 architecture">
  <figcaption>Linear evaluation accuracy on a validation set during early training of a ResNet-18 on STL10. When BYOL was trained without batch normalization in the MLP, the performance remained no better than a random baseline.</figcaption>
</figure>

<h3 id="why-did-this-happen">Why did this happen?</h3>

<p>To investigate the cause of this dramatic change in performance, we performed some additional experiments.</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/contrastive_loss_arch.png" alt="Contrastive loss architecture">
  <figcaption>Configuration used for experiments with contrastive loss, enabling better comparison to BYOL results.</figcaption>
</figure>

<p>Because the prediction MLP q changes the network depth compared to MoCo, we wondered if batch normalization might be needed to regularize this network. That is, while MoCo <em>does not</em> require batch normalization, it could be that MoCo <em>does</em> require batch normalization when paired with an additional prediction MLP. To test this, we started training the network shown above with a contrastive loss function. We found that the network was able to perform significantly better than random within ten epochs. This result made us suspect that something about <strong>not using a contrastive loss function</strong> causes the dependence of training on batch normalization.</p>

<p>We then wondered whether another type of normalization would have the same effect. We applied Layer Normalization to the MLPs instead of batch normalization and trained the network with BYOL <sup id="fnref:layernorm" role="doc-noteref"><a href="#fn:layernorm">4</a></sup>. As in the experiments where MLPs had no normalization, the performance was no better than random. This result told us that <strong>the activations of other inputs in the same mini-batch</strong> are essential in helping BYOL find useful representations.</p>

<p>Next, we wanted to know whether batch normalization is required in the projection MLP $g$, the prediction MLP $q$, or both. Our experiments showed that batch normalization is most useful in the projection MLP, but the network can learn useful representations with batch normalization in either MLP. A <strong>single batch normalization layer</strong> in one of the MLPs is sufficient for the network to learn.</p>

<h3 id="performance-for-each-variation">Performance for each variation</h3>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Projection MLP Norm</th>
      <th>Prediction MLP Norm</th>
      <th>Loss Function</th>
      <th>Contrastive</th>
      <th>Performance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Contrastive Loss</td>
      <td>None</td>
      <td>None</td>
      <td>Cross Entropy</td>
      <td>Explicit</td>
      <td>44.1</td>
    </tr>
    <tr>
      <td>BYOL</td>
      <td>Batch Norm</td>
      <td>Batch Norm</td>
      <td>L2</td>
      <td>Implicit</td>
      <td>57.7</td>
    </tr>
    <tr>
      <td>Projection BN Only</td>
      <td>Batch Norm</td>
      <td>None</td>
      <td>L2</td>
      <td>Implicit</td>
      <td>55.3</td>
    </tr>
    <tr>
      <td>Prediction BN Only</td>
      <td>None</td>
      <td>Batch Norm</td>
      <td>L2</td>
      <td>Implicit</td>
      <td>48</td>
    </tr>
    <tr>
      <td>No Normalization</td>
      <td>None</td>
      <td>None</td>
      <td>L2</td>
      <td>None</td>
      <td>28.3</td>
    </tr>
    <tr>
      <td>Layer Norm</td>
      <td>Layer Norm</td>
      <td>Layer Norm</td>
      <td>L2</td>
      <td>None</td>
      <td>29.4</td>
    </tr>
    <tr>
      <td>Random</td>
      <td>—</td>
      <td>—</td>
      <td>—</td>
      <td>None</td>
      <td>28.8</td>
    </tr>
  </tbody>
</table>

<p>To summarize the findings so far: in the absence of a contrastive loss function, the success of BYOL training hinges on something about a single batch normalization layer related to the activations from other inputs in the mini-batch.</p>

<h3 id="why-batch-normalization-is-critical-in-byol-mode-collapse">Why batch normalization is critical in BYOL: mode collapse</h3>

<p>One purpose of negative examples in a contrastive loss function is to prevent mode collapse<sup id="fnref:collapse" role="doc-noteref"><a href="#fn:collapse">5</a></sup>. An example of mode collapse would be a network that always outputs [1, 0, 0, 0, …] as its projection vector <em>z</em>. If all projection vectors <em>z</em> are the same, then the network only needs to learn the identity function for $q$ in order to …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html">https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html</a></em></p>]]>
            </description>
            <link>https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273792</guid>
            <pubDate>Tue, 25 Aug 2020 17:33:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experimenting with QUIC and WebTransport in Go]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24273371">thread link</a>) | @FZambia
<br/>
August 25, 2020 | https://centrifugal.github.io/centrifugo/blog/quic_web_transport/ | <a href="https://web.archive.org/web/*/https://centrifugal.github.io/centrifugo/blog/quic_web_transport/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article>
              

                
                  <a href="https://github.com/centrifugal/centrifugo/edit/master/docs/content/blog/quic_web_transport.md" title="Edit this page">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
                  </a>
                
                
                  
                
                
                
<p><img alt="post-cover" src="https://i.imgur.com/sH9zfhe.jpg"></p>
<h2 id="overview">Overview<a href="#overview" title="Permanent link">¶</a></h2>
<p>WebTransport is a new browser API offering low-latency, bidirectional, client-server messaging. If you have not heard about it before I suggest to first read a post called <a href="https://web.dev/quictransport/">Experimenting with QuicTransport</a> published recently on web.dev – it gives a nice overview to WebTransport and shows client-side code examples. Here we will concentrate on implementing server side.</p>
<p>Some key points about WebTransport spec:</p>
<ul>
<li>WebTransport standard will provide a possibility to use streaming client-server communication using modern transports such as <a href="https://en.wikipedia.org/wiki/QUIC">QUIC</a> and <a href="https://en.wikipedia.org/wiki/HTTP/3">HTTP/3</a></li>
<li>It can be a good alternative to <a href="https://en.wikipedia.org/wiki/WebSocket">WebSocket</a> messaging, standard provides some capabilities that are not possible with current WebSocket spec: possibility to get rid of head-of-line blocking problems using individual streams for different data, the possibility to reuse a single connection to a server in different browser tabs</li>
<li>WebTransport also defines an unreliable stream API using UDP datagrams (which is possible since QUIC is UDP-based) – which is what browsers did not have before without a rather complex <a href="https://en.wikipedia.org/wiki/WebRTC">WebRTC</a> setup involving ICE, STUN, etc. This is sweet for in-browser real-time games.</li>
</ul>
<p>To help you figure out things here are links to current WebTransport specs:</p>
<ul>
<li><a href="https://tools.ietf.org/html/draft-vvv-webtransport-overview-01">WebTransport overview</a> – this spec gives an overview of WebTransport and provides requirements to transport layer</li>
<li><a href="https://tools.ietf.org/html/draft-vvv-webtransport-quic">WebTransport over QUIC</a> – this spec describes QUIC-based transport for WebTransport</li>
<li><a href="https://tools.ietf.org/html/draft-vvv-webtransport-http3">WebTransport over HTTP/3</a> – this spec describes HTTP/3-based transport for WebTransport (actually HTTP/3 is a protocol defined on top of QUIC)</li>
</ul>
<p>At moment Chrome only implements <a href="https://web.dev/quictransport/#register-for-ot">trial possibility</a> to try out WebTransport standard and only implements WebTransport over QUIC. Developers can initialize transport with code like this:</p>
<div><pre><span></span><code><span>const</span> <span>transport</span> <span>=</span> <span>new</span> <span>QuicTransport</span><span>(</span><span>'quic-transport://localhost:4433/path'</span><span>);</span>
</code></pre></div>

<p>In case of HTTP/3 transport one will use URL like <code>'https://localhost:4433/path'</code> in transport constructor. All WebTransport underlying transports should support instantiation over URL – that's one of the spec requirements. </p>
<p>I decided that this is a cool possibility to finally play with QUIC protocol and its Go implementation <a href="https://github.com/lucas-clemente/quic-go">github.com/lucas-clemente/quic-go</a>.</p>
<div>
<p>Danger</p>
<p>Please keep in mind that all things described in this post are work in progress. WebTransport drafts, Quic-Go library, even QUIC protocol itself are subjects to change. You should not use it in production yet.</p>
</div>
<p><a href="https://web.dev/quictransport/">Experimenting with QuicTransport</a> post contains links to a <a href="https://googlechrome.github.io/samples/quictransport/client.html">client example</a> and companion <a href="https://github.com/GoogleChrome/samples/blob/gh-pages/quictransport/quic_transport_server.py">Python server implementation</a>.</p>
<p><img alt="client example" src="https://i.imgur.com/Hty00aG.png"></p>
<p>We will use a linked client example to connect to a server that runs on localhost and uses <a href="https://github.com/lucas-clemente/quic-go">github.com/lucas-clemente/quic-go</a> library. To make our example work we need to open client example in Chrome, and actually, at this moment we need to install Chrome Canary. The reason behind this is that the  <code>quic-go</code> library supports QUIC draft-29 while Chrome &lt; 85 implements QuicTransport over draft-27. If you read this post at a time when Chrome stable 85 already released then most probably you don't need to install Canary release and just use your stable Chrome.</p>
<p>We also need to generate self-signed certificates since WebTransport only works with a TLS layer, and we should make Chrome trust our certificates. Let's prepare our client environment before writing a server and first install Chrome Canary.</p>
<h2 id="install-chrome-canary">Install Chrome Canary<a href="#install-chrome-canary" title="Permanent link">¶</a></h2>
<p>Go to <a href="https://www.google.com/intl/en/chrome/canary/">https://www.google.com/intl/en/chrome/canary/</a>, download and install Chrome Canary. We will use it to open <a href="https://googlechrome.github.io/samples/quictransport/client.html">client example</a>.</p>
<div>
<p>Note</p>
<p>If you have Chrome &gt;= 85 then most probably you can skip this step.</p>
</div>
<h2 id="generate-self-signed-tls-certificates">Generate self-signed TLS certificates<a href="#generate-self-signed-tls-certificates" title="Permanent link">¶</a></h2>
<p>Since WebTransport based on modern network transports like QUIC and HTTP/3 security is a keystone. For our experiment we will create a self-signed TLS certificate using <code>openssl</code>. </p>
<p>Make sure you have <code>openssl</code> installed:</p>
<div><pre><span></span><code>$ which openssl
/usr/bin/openssl
</code></pre></div>

<p>Then run:</p>
<div><pre><span></span><code>openssl genrsa -des3 -passout pass:x -out server.pass.key <span>2048</span>
openssl rsa -passin pass:x -in server.pass.key -out server.key
rm server.pass.key
openssl req -new -key server.key -out server.csr
</code></pre></div>

<p>Set <code>localhost</code> for Common Name when asked.</p>
<p>The self-signed TLS certificate generated from the <code>server.key</code> private key and <code>server.csr</code> files:</p>
<div><pre><span></span><code>openssl x509 -req -sha256 -days <span>365</span> -in server.csr -signkey server.key -out server.crt
</code></pre></div>

<p>After these manipulations you should have <code>server.crt</code> and <code>server.key</code> files in your working directory.</p>
<p>To help you with process here is my console output during these steps (click to open):</p>
<details><summary>My console output generating self-signed certificates</summary><div><pre><span></span><code>$ openssl genrsa -des3 -passout pass:x -out server.pass.key <span>2048</span>
Generating RSA private key, <span>2048</span> bit long modulus
...........................................................................................+++
.....................+++
e is <span>65537</span> <span>(</span>0x10001<span>)</span>

$ ls
server.pass.key

$ openssl rsa -passin pass:x -in server.pass.key -out server.key
writing RSA key

$ ls
server.key      server.pass.key

$ rm server.pass.key

$ openssl req -new -key server.key -out server.csr
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter <span>'.'</span>, the field will be left blank.
-----
Country Name <span>(</span><span>2</span> letter code<span>)</span> <span>[]</span>:RU
State or Province Name <span>(</span>full name<span>)</span> <span>[]</span>:
Locality Name <span>(</span>eg, city<span>)</span> <span>[]</span>:
Organization Name <span>(</span>eg, company<span>)</span> <span>[]</span>:
Organizational Unit Name <span>(</span>eg, section<span>)</span> <span>[]</span>:
Common Name <span>(</span>eg, fully qualified host name<span>)</span> <span>[]</span>:localhost
Email Address <span>[]</span>:

Please enter the following <span>'extra'</span> attributes
to be sent with your certificate request
A challenge password <span>[]</span>:

$ openssl x509 -req -sha256 -days <span>365</span> -in server.csr -signkey server.key -out server.crt
Signature ok
<span>subject</span><span>=</span>/C<span>=</span>RU/CN<span>=</span>localhost
Getting Private key

$ ls
server.crt server.csr server.key
</code></pre></div>

</details>
<h2 id="run-client-example">Run client example<a href="#run-client-example" title="Permanent link">¶</a></h2>
<p>Now the last step. What we need to do is run Chrome Canary with some flags that will allow it to trust our self-signed certificates. I suppose there is an alternative way making Chrome trust your certificates, but I have not tried it.</p>
<p>First let's find out a fingerprint of our cert:</p>
<div><pre><span></span><code>openssl x509 -in server.crt -pubkey -noout <span>|</span> openssl pkey -pubin -outform der <span>|</span> openssl dgst -sha256 -binary <span>|</span> openssl enc -base64
</code></pre></div>

<p>In my case base64 fingerprint was <code>pe2P0fQwecKFMc6kz3+Y5MuVwVwEtGXyST5vJeaOO/M=</code>, yours will be different.</p>
<p>Then run Chrome Canary with some additional flags that will make it trust out certs (close other Chrome Canary instances before running it):</p>
<div><pre><span></span><code>$ /Applications/Google<span>\ </span>Chrome<span>\ </span>Canary.app/Contents/MacOS/Google<span>\ </span>Chrome<span>\ </span>Canary <span>\</span>
    --origin-to-force-quic-on<span>=</span>localhost:4433 <span>\</span>
    --ignore-certificate-errors-spki-list<span>=</span>pe2P0fQwecKFMc6kz3+Y5MuVwVwEtGXyST5vJeaOO/M<span>=</span>
</code></pre></div>

<p>This example is for MacOS, for your system see <a href="https://www.chromium.org/developers/how-tos/run-chromium-with-flags">docs on how to run Chrome/Chromium with custom flags</a>.</p>
<p>Now you can open <a href="https://googlechrome.github.io/samples/quictransport/client.html">https://googlechrome.github.io/samples/quictransport/client.html</a> URL in started browser and click <code>Connect</code> button. What? Connection not established? OK, this is fine since we need to run our server :)</p>
<h2 id="writing-a-quic-server">Writing a QUIC server<a href="#writing-a-quic-server" title="Permanent link">¶</a></h2>
<p>Maybe in future we will have libraries that are specified to work with WebTransport over QUIC or HTTP/3, but for now we should implement server manually. As said above we will use <a href="https://github.com/lucas-clemente/quic-go">github.com/lucas-clemente/quic-go</a> library to do this.</p>
<h3 id="server-skeleton">Server skeleton<a href="#server-skeleton" title="Permanent link">¶</a></h3>
<p>First, let's define a simple skeleton for our server:</p>
<div><pre><span></span><code><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
    <span>"errors"</span>
    <span>"log"</span>

    <span>"github.com/lucas-clemente/quic-go"</span>
<span>)</span>

<span>// Config for WebTransportServerQuic.</span>
<span>type</span> <span>Config</span> <span>struct</span> <span>{</span>
    <span>// ListenAddr sets an address to bind server to.</span>
    <span>ListenAddr</span> <span>string</span>
    <span>// TLSCertPath defines a path to .crt cert file.</span>
    <span>TLSCertPath</span> <span>string</span>
    <span>// TLSKeyPath defines a path to .key cert file</span>
    <span>TLSKeyPath</span> <span>string</span>
    <span>// AllowedOrigins represents list of allowed origins to connect from.</span>
    <span>AllowedOrigins</span> <span>[]</span><span>string</span>
<span>}</span>

<span>// WebTransportServerQuic can handle WebTransport QUIC connections according</span>
<span>// to https://tools.ietf.org/html/draft-vvv-webtransport-quic-02.</span>
<span>type</span> <span>WebTransportServerQuic</span> <span>struct</span> <span>{</span>
    <span>config</span> <span>Config</span>
<span>}</span>

<span>// NewWebTransportServerQuic creates new WebTransportServerQuic.</span>
<span>func</span> <span>NewWebTransportServerQuic</span><span>(</span><span>config</span> <span>Config</span><span>)</span> <span>*</span><span>WebTransportServerQuic</span> <span>{</span>
    <span>return</span> <span>&amp;</span><span>WebTransportServerQuic</span><span>{</span>
        <span>config</span><span>:</span> <span>config</span><span>,</span>
    <span>}</span>
<span>}</span>

<span>// Run server.</span>
<span>func</span> <span>(</span><span>s</span> <span>*</span><span>WebTransportServerQuic</span><span>)</span> <span>Run</span><span>()</span> <span>error</span> <span>{</span>
    <span>return</span> <span>errors</span><span>.</span><span>New</span><span>(</span><span>"not implemented"</span><span>)</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
    <span>server</span> <span>:=</span> <span>NewWebTransportServerQuic</span><span>(</span><span>Config</span><span>{</span>
        <span>ListenAddr</span><span>:</span>     <span>"0.0.0.0:4433"</span><span>,</span>
        <span>TLSCertPath</span><span>:</span>    <span>"server.crt"</span><span>,</span>
        <span>TLSKeyPath</span><span>:</span>     <span>"server.key"</span><span>,</span>
        <span>AllowedOrigins</span><span>:</span> <span>[]</span><span>string</span><span>{</span><span>"localhost"</span><span>,</span> <span>"googlechrome.github.io"</span><span>},</span>
    <span>})</span>
    <span>if</span> <span>err</span> <span>:=</span> <span>server</span><span>.</span><span>Run</span><span>();</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>log</span><span>.</span><span>Fatal</span><span>(</span><span>err</span><span>)</span>
    <span>}</span>
<span>}</span>
</code></pre></div>

<h3 id="accept-quic-connections">Accept QUIC connections<a href="#accept-quic-connections" title="Permanent link">¶</a></h3>
<p>Let's concentrate on implementing <code>Run</code> method. We need to accept QUIC client connections. This can be done by creating <code>quic.Listener</code> instance and using its <code>.Accept</code> method to accept incoming client sessions.</p>
<div><pre><span></span><code><span>// Run server.</span>
<span>func</span> <span>(</span><span>s</span> <span>*</span><span>WebTransportServerQuic</span><span>)</span> <span>Run</span><span>()</span> <span>error</span> <span>{</span>
    <span>listener</span><span>,</span> <span>err</span> <span>:=</span> <span>quic</span><span>.</span><span>ListenAddr</span><span>(</span><span>s</span><span>.</span><span>config</span><span>.</span><span>ListenAddr</span><span>,</span> <span>s</span><span>.</span><span>generateTLSConfig</span><span>(),</span> <span>nil</span><span>)</span>
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>return</span> <span>err</span>
    <span>}</span>
    <span>for</span> <span>{</span>
        <span>sess</span><span>,</span> <span>err</span> <span>:=</span> <span>listener</span><span>.</span><span>Accept</span><span>(</span><span>context</span><span>.</span><span>Background</span><span>())</span>
        <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
            <span>return</span> <span>err</span>
        <span>}</span>
        <span>log</span><span>.</span><span>Printf</span><span>(</span><span>"session accepted: %s"</span><span>,</span> <span>sess</span><span>.</span><span>RemoteAddr</span><span>().</span><span>String</span><span>())</span>
        <span>go</span> <span>func</span><span>()</span> <span>{</span>
            <span>defer</span> <span>func</span><span>()</span> <span>{</span>
                <span>_</span> <span>=</span> <span>sess</span><span>.</span><span>CloseWithError</span><span>(</span><span>0</span><span>,</span> <span>"bye"</span><span>)</span>
                <span>log</span><span>.</span><span>Println</span><span>(</span><span>"close session"</span><span>)</span>
            <span>}()</span>
            <span>s</span><span>.</span><span>handleSession</span><span>(</span><span>sess</span><span>)</span>
        <span>}()</span>
    <span>}</span>
<span>}</span>

<span>func</span> <span>(</span><span>s</span> <span>*</span><span>WebTransportServerQuic</span><span>)</span> <span>handleSession</span><span>(</span><span>sess</span> <span>quic</span><span>.</span><span>S…</span></code></pre></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://centrifugal.github.io/centrifugo/blog/quic_web_transport/">https://centrifugal.github.io/centrifugo/blog/quic_web_transport/</a></em></p>]]>
            </description>
            <link>https://centrifugal.github.io/centrifugo/blog/quic_web_transport/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273371</guid>
            <pubDate>Tue, 25 Aug 2020 16:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LiquidHaskell Is a GHC Plugin]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24273161">thread link</a>) | @Tehnix
<br/>
August 25, 2020 | https://ucsd-progsys.github.io/liquidhaskell-blog/2020/08/20/lh-as-a-ghc-plugin.lhs/ | <a href="https://web.archive.org/web/*/https://ucsd-progsys.github.io/liquidhaskell-blog/2020/08/20/lh-as-a-ghc-plugin.lhs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            <!-- Post Header -->


<!-- Post Content -->
<article>
    <div>
        <div>
            <div>

            <br>

            

            
			            
<p>I enjoy working with LH. However, I’d be the very first to confess that it has been incredibly tedious to get to work on <em>existing</em> code bases, for various reasons.</p>
<ol type="1">
<li><p>LH ran <em>one file at a time</em>; it was a hassle to <strong>systematically analyze</strong> all the modules in a single package.</p></li>
<li><p>LH had <em>no notion of packages</em>; it was impossible to <strong>import specifications</strong> across packages.</p></li>
<li><p>LH had <em>no integration</em> with the standard compilation cycle; it was difficult to get robust, <strong>development-time feedback</strong> using <code>ghci</code> based tools.</p></li>
</ol>
<p>I’m delighted to announce the release of <a href="http://ucsd-progsys.github.io/liquidhaskell/">LH version 0.8.10.2</a>.</p>
<p>Thanks to the ingenuity and tireless efforts of our friends <a href="http://www.alfredodinapoli.com/">Alfredo Di Napoli</a> and <a href="https://www.andres-loeh.de/">Andres Loh</a> at <a href="http://www.well-typed.com/">Well-Typed</a> this new version solves all three of the above problems in a single stroke, making it vastly simpler (dare I say, quite straightforward!) to run LH on your Haskell code.</p>
<!-- more -->
<p>Alfredo and Andres’ key insight was that all the above problems could be solved if LH could be re-engineered as a <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/extending_ghc.html#compiler-plugins">GHC Compiler Plugin</a> using hooks that GHC exposes to integrate external checkers during compilation. I strongly encourage you to check out Alfredo’s talk at the <a href="https://icfp20.sigplan.org/details/hiw-2020-papers/1/Liquid-Haskell-as-a-GHC-Plugin">Haskell Implementor’s Workshop</a> if you want to learn more about the rather non-trivial mechanics of how this plugin was engineered. However, in this post, lets look at <em>how</em> and <em>why</em> to use the plugin, in particular, how the plugin lets us</p>
<ol type="1">
<li><p>Use GHC’s dependency resolution to analyze entire packages with minimal recompilation;</p></li>
<li><p>Ship refined type specifications for old or new packages, and have them be verified at client code;</p></li>
<li><p>Use tools like <code>ghci</code> based IDE tooling (e.g.&nbsp;<code>ghcid</code> or <code>ghcide</code> to get interactive feedback),</p></li>
</ol>
<p>all of which ultimately, I hope, make Liquid Haskell easier to use.</p>
<h2 id="analyzing-packages">1. Analyzing Packages</h2>
<p>First, lets see a small “demo” of how to <em>use</em> the plugin to compile a small <a href="https://github.com/ucsd-progsys/lh-plugin-demo"><code>lh-plugin-demo</code></a> package with two modules</p>

<p>which defines a function <code>incr</code> that consumes and returns positive integers, and</p>

<p>which imports <code>Demo.Lib</code> and uses <code>incr</code>.</p>
<h3 id="updating-.cabal-to-compile-with-the-lh-plugin">Updating <code>.cabal</code> to compile with the LH plugin</h3>
<p>To “check” this code with LH we need only tell GHC to use it as a plugin, in two steps.</p>
<ol type="1">
<li>First, adding a dependency to LH in the <code>.cabal</code> file (or <code>package.yaml</code>)</li>
</ol>
<pre><code>  build-depends:
      liquid-base,
      liquidhaskell &gt;= 0.8.10</code></pre>
<ol start="2" type="1">
<li>Second, tell GHC to use the plugin</li>
</ol>
<pre><code>  ghc-options: -fplugin=LiquidHaskell</code></pre>
<p>That’s it. Now, everytime you (re-)build the code, GHC will <em>automatically</em> run LH on the changed modules! If you use <code>stack</code> you may have to specify a few more dependencies, as the various packages are not (yet) on stackage, as shown in the <a href="https://github.com/ucsd-progsys/lh-plugin-demo/blob/main/stack.yaml">demo <code>stack.yaml</code></a>. No extra dependencies are needede if you use <code>cabal-v2</code>. In both cases, you can use the respective files <a href="https://github.com/ucsd-progsys/lh-plugin-demo/blob/main/stack.yaml.github"><code>stack.yaml</code></a> and <a href="https://github.com/ucsd-progsys/lh-plugin-demo/blob/main/cabal.project.github"><code>cabal.project</code></a> point to specific git snapshots if you want to use the most recent versions. If you clone the repo and run, e.g.&nbsp;<code>cabal v2-build</code> or <code>stack build</code> you’ll get the following result, after the relevant dependencies are downloaded and built of course…</p>
<pre><code>rjhala@khao-soi ~/r/lh-demo (main)&gt; stack build
lh-plugin-demo&gt; configure (lib)
Configuring lh-plugin-demo-0.1.0.0...
lh-plugin-demo&gt; build (lib)
Preprocessing library for lh-plugin-demo-0.1.0.0..
Building library for lh-plugin-demo-0.1.0.0..
[1 of 2] Compiling Demo.Lib

**** LIQUID: UNSAFE ************************************************************

/Users/rjhala/research/lh-demo/src/Demo/Lib.hs:7:1: error:
    Liquid Type Mismatch
    .
    The inferred type
      VV : {v : GHC.Types.Int | v == x - 1}
    .
    is not a subtype of the required type
      VV : {VV : GHC.Types.Int | 0 &lt; VV}
    .
    in the context
      x : {v : GHC.Types.Int | 0 &lt; v}
  |
7 | incr x = x - 1
  | ^^^^^^^^^^^^^^</code></pre>
<p>oops, of course that <code>(-)</code> should be a <code>(+)</code> if we want the output to also be <em>positive</em> so lets edit the code to</p>

<p>and now we get</p>
<pre><code>rjhala@khao-soi ~/r/lh-plugin-demo (main)&gt; stack build
lh-plugin-demo&gt; configure (lib)
Configuring lh-plugin-demo-0.1.0.0...

lh-plugin-demo&gt; build (lib)
Preprocessing library for lh-plugin-demo-0.1.0.0..
Building library for lh-plugin-demo-0.1.0.0..
[1 of 2] Compiling Demo.Lib

**** LIQUID: SAFE (2 constraints checked) *****************************
[2 of 2] Compiling Demo.Client

**** LIQUID: UNSAFE ***************************************************

/Users/rjhala/lh-plugin-demo/src/Demo/Client.hs:6:15: error:
    Liquid Type Mismatch
    .
    The inferred type
      VV : {v : GHC.Types.Int | v == n}
    .
    is not a subtype of the required type
      VV : {VV : GHC.Types.Int | 0 &lt; VV}
    .
    in the context
      n : GHC.Types.Int
  |
6 | bump n = incr n
  |               ^</code></pre>
<p>That is, during the build, LH complains that <code>incr</code> is being called with a value <code>n</code> that is not strictly positive as required by <code>incr</code>. To fix the code, we can edit it in various ways, e.g.&nbsp;to only call <code>incr</code> if <code>n &gt; 0</code></p>

<p>and now the code builds successfully</p>
<pre><code>rjhala@khao-soi ~/r/lh-plugin-demo (main)&gt; stack build
lh-plugin-demo&gt; configure (lib)
Configuring lh-plugin-demo-0.1.0.0...
lh-plugin-demo&gt; build (lib)
Preprocessing library for lh-plugin-demo-0.1.0.0..
Building library for lh-plugin-demo-0.1.0.0..
[2 of 2] Compiling Demo.Client

**** LIQUID: SAFE (2 constraints checked) ****************************
lh-plugin-demo&gt; copy/register
Installing library in ... 
Registering library for lh-plugin-demo-0.1.0.0..</code></pre>
<h3 id="benefits">Benefits</h3>
<p>There are a couple of benefits to note immediately</p>
<ul>
<li><p>A plain <code>stack build</code> or <code>cabal v2-build</code> takes care of all the installing <em>and</em> checking!</p></li>
<li><p>No need to separately <em>install</em> LH; its part of the regular build.</p></li>
<li><p>GHC’s recompilation machinery ensures that only the relevant modules are checked, e.g.&nbsp;the second time round, LH did not need to analyze <code>Lib.hs</code> only <code>Client.hs</code></p></li>
</ul>
<h2 id="shipping-specifications-with-packages">2. Shipping Specifications with Packages</h2>
<p>While the above is nice, in principle it could have been done with some clever <code>makefile</code> trickery (perhaps?). What I’m much more excited about is that now, for the first time, you can <em>ship refinement type specifications within plain Haskell packages</em>.</p>
<p>For example, consider a different <a href="https://github.com/ucsd-progsys/lh-plugin-demo-client">lh-plugin-demo-client</a> package that uses <code>incr</code> from <code>lh-plugin-demo</code>:</p>

<p>Again, the <code>lh-plugin-demo-client.cabal</code> file need only specify the various dependencies:</p>
<pre><code>  build-depends:
      liquid-base,
      liquidhaskell,
      lh-plugin-demo</code></pre>
<p>and that GHC should use the plugin</p>
<pre><code>  ghc-options: -fplugin=LiquidHaskell</code></pre>
<p>and lo! a plain <code>stack build</code> or <code>cabal v2-build</code> takes care of all the rest.</p>
<pre><code>rjhala@khao-soi ~/r/lh-plugin-demo-client (main)&gt; stack build
lh-plugin-demo-client&gt; configure (lib)
Configuring lh-plugin-demo-client-0.1.0.0...

lh-plugin-demo-client&gt; build (lib)
Preprocessing library for lh-plugin-demo-client-0.1.0.0..
Building library for lh-plugin-demo-client-0.1.0.0..
[1 of 1] Compiling Demo.ExternalClient

**** LIQUID: UNSAFE ****************************************************

/Users/rjhala/lh-plugin-demo-client/src/Demo/ExternalClient.hs:8:22: error:
    Liquid Type Mismatch
    .
    The inferred type
      VV : {v : GHC.Types.Int | v == 0 - n}
    .
    is not a subtype of the required type
      VV : {VV : GHC.Types.Int | VV &gt; 0}
    .
    in the context
      n : GHC.Types.Int
  |
8 |   | otherwise = incr (0 - n)
  |                      ^^^^^^^</code></pre>
<p>(Whoops another off by one error, lets fix it!)</p>

<p>and now all is well</p>
<pre><code>rjhala@khao-soi ~/r/lh-plugin-demo-client (main)&gt; stack build --fast
lh-plugin-demo-client&gt; configure (lib)
Configuring lh-plugin-demo-client-0.1.0.0...
lh-plugin-demo-client&gt; build (lib)
Preprocessing library for lh-plugin-demo-client-0.1.0.0..
Building library for lh-plugin-demo-client-0.1.0.0..
[1 of 1] Compiling Demo.ExternalClient

**** LIQUID: SAFE (3 constraints checked) *****************************

lh-plugin-demo-client&gt; copy/register
Installing library in ... 
Registering library for lh-plugin-demo-client-0.1.0.0..</code></pre>
<h3 id="prelude-specifications">Prelude Specifications</h3>
<p>Did you notice the strange <code>liquid-base</code> dependency in the cabal files?</p>
<p>Previously, LH came installed with a “built-in” set of specifications for various <code>prelude</code> modules. This was <em>hacked</em> inside LH in a rather unfortunate manner, which made these specifications very difficult to extend.</p>
<p>Moving forward, all the refinement specifications e.g.&nbsp;for <code>GHC.List</code> or <code>Data.Vector</code> or <code>Data.Set</code> or <code>Data.Bytestring</code> simply live in packages that <em>mirror</em> the original versions, e.g.&nbsp;<code>liquid-base</code>, <code>liquid-vector</code>, <code>liquid-containers</code>, <code>liquid-bytestring</code>. Each <code>liquid-X</code> package directly <em>re-exports</em> all the contents of the corresponding <code>X</code> package, but with any additional refinement type specifications.</p>
<p>Thus, all the refined types for various prelude operations like <code>(+)</code> or <code>(-)</code> or <code>head</code> and so on, now ship with <code>liquid-base</code> and we add that dependency <strong>instead of</strong> base. Similarly, if you want to verify that <em>your</em> code has no <code>vector</code>-index overflow errors, you simply build with <code>liquid-vector</code> <strong>instead of</strong> <code>vector</code>! Of course, in an ideal, and hopefully not too distant future, we’d directly include the refinement types inside <code>vector</code>, <code>containers</code> or <code>bytestring</code> respectively.</p>
<h3 id="benefits-1">Benefits</h3>
<p>So to recap, the plugin offers several nice benefits with respect to <em>shipping specifications</em></p>
<ul>
<li><p>Refined signatures are bundled together with packages,</p></li>
<li><p>Importing packages with refined signatures automatically ensures those signatures are checked on client code,</p></li>
<li><p>You can (optionally) use refined versions of <code>prelude</code> signatures, and hence, even write refined versions of your favorite <em>custom preludes</em>.</p></li>
</ul>

<p>I saved <em>my</em> favorite part for the end.</p>
<p>What I have enjoyed the most about the plugin is that now (almost) all the GHC-based tools that I use in my regular Haskell development workflow, automatically incorporate LH too! For example, reloading a module in <code>ghci</code> automatically re-runs LH on that file.</p>
<h3 id="ghcid"><code>ghcid</code></h3>
<p>This means, that the mega robust, editor-independent <code>ghcid</code> now automatically produces LH type errors when you save a file. Here’s <code>ghcid</code> running in a terminal.</p>
<figure>
<img src="https://ucsd-progsys.github.io/liquidhaskell-blog/static/img/plugin-ghcid.gif" alt="ghcid"><figcaption>ghcid</figcaption>
</figure>
<h3 id="vscode"><code>vscode</code></h3>
<p>Editor plugins now produce little red squiggles for LH errors too. Here’s <code>code</code> with the <code>Simple GHC (Haskell) Integration</code> plugin</p>
<p><img src="https://ucsd-progsys.github.io/liquidhaskell-blog/static/img/plugin-vscode.gif"></p>
<h3 id="emacs"><code>emacs</code></h3>
<p>H…</p></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ucsd-progsys.github.io/liquidhaskell-blog/2020/08/20/lh-as-a-ghc-plugin.lhs/">https://ucsd-progsys.github.io/liquidhaskell-blog/2020/08/20/lh-as-a-ghc-plugin.lhs/</a></em></p>]]>
            </description>
            <link>https://ucsd-progsys.github.io/liquidhaskell-blog/2020/08/20/lh-as-a-ghc-plugin.lhs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273161</guid>
            <pubDate>Tue, 25 Aug 2020 16:37:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to achieve career growth: opportunities, skills and sponsors]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24273025">thread link</a>) | @yenkel
<br/>
August 25, 2020 | https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors | <a href="https://web.archive.org/web/*/https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>I recently started mentoring someone that works at another company. Their goal is to become a “tech lead”: at their company, this is a person that others look for technical advice, and that can influence teams’ technical decisions. Because this person does not work where I do, I was forced to think generically about the matter of growth, rather than jumping to specific advice I would be able to provide a coworker.</p><p>In general, you might want to grow in your software engineering career, but:</p><ul><li>what does growth mean? </li><li>how can you achieve it?</li><li>who decides if you are ready to grow?</li><li>where do you start?</li></ul><p>Years ago I read a phrase in <a href="https://www.forbes.com/sites/daviatemin/2016/04/04/what-theyre-saying-about-you-when-youre-not-in-the-room-and-what-you-can-do-to-influence-it/#4cb99ee771ac" target="_blank" rel="nofollow noopener noreferrer">this article</a> that made many things click for me:</p><blockquote><p>The biggest decisions about your career are often made when you’re not in the room</p></blockquote><p>For example, when I was working at a consulting company I did not decide which projects I was involved in. It depended on the contracts we closed, customers’ budget and other’s allocations.</p><p>Whenever I’m thinking about career growth I keep that in mind.  It helped me put together a mental model for professional growth. This blog post shares my growth model and how you can use it to carve your career growth path.</p><p>Let’s introduce some terms first:</p><ul><li>Growth: access to more challenging and/or new opportunities. Growth is multidimensional.</li><li>Opportunity: a possibility for improving and/or displaying your skills. They might be accompanied by financial rewards, recognition, etc.</li><li>Skills: what you can do, including knowledge required to do it</li></ul><p>From those three definitions a couple of questions arise:</p><ol><li>Who are you displaying your skills to?</li><li>Who gets you access to opportunities?</li></ol><p>To answer those questions and complete the model we need to define <strong>Sponsors</strong>:</p><ul><li>Sponsors: People that are aware of available opportunities and can grant them to you. </li></ul><p>Applying <a href="https://lethain.com/systems-thinking/" target="_blank" rel="nofollow noopener noreferrer">systems thinking</a> to the model we come up with this diagram:
<img src="https://yenkel.dev/media/2020-08-25/growth.png"></p><ol><li>Your opportunities increase as new opportunities are granted to you. This rate depends on your sponsors.</li><li>Your skills improve depending on how fast you learn from your opportunities.</li><li>You get more sponsors the more people have a positive perception of your skills. These displays depend on your skills, e.g.: when you are given the opportunity to present you are displaying your presentation skills. If you are good at presenting, sponsors will perceive that.</li></ol><h2 id="takeaways"><a href="#takeaways" aria-label="takeaways permalink"></a>Takeaways</h2><p>Our <em>growth</em> definition means you want to maximize <em>your opportunities</em>. The most important takeaway is:</p><p><strong>Skill alone doesn’t matter. If no one but yourself knows about your skills, you won’t get any opportunities.</strong></p><p>What you want is to:</p><ol><li>Maximize <strong>Available Opportunities</strong></li><li>Maximize <strong>Sponsors</strong></li></ol><h2 id="your-energy"><a href="#your-energy" aria-label="your energy permalink"></a>Your energy</h2><p>To keep the model simple and the post short I am not including “Your energy” as a stock. Modeling energy is complex:
When you take new opportunities your energy decreases. When you run out of energy you <a href="https://medium.com/hackernoon/why-theres-so-much-burnout-in-software-and-what-to-do-about-it-4ef0297ca7cc" target="_blank" rel="nofollow noopener noreferrer">burnout</a>.
When you do things you enjoy doing or rest (take fewer opportunities) your energy replenishes.
Your energy levels affect your skill learning/improvement rate.
And there are many ways in which your energy levels change that are not part of the system model I propose but impact the system nevertheless…</p><p>You can easily see how this would make the model more complex. However, just because it is harder to model it doesn’t mean you shouldn’t consider energy as part of your approach to growth.</p><p>Opportunities come in different flavors, not all of them are “being tasked to do something”. All of these are opportunities:</p><ul><li>Changing teams to work on a different problem set</li><li>Being picked to technically lead an initiative larger than you have ever lead before</li><li>Speaking at a conference</li><li>Attending a workshop</li><li>Frequently being mentored by a more senior person</li></ul><p><img src="https://yenkel.dev/media/2020-08-25/opportunity.jpg"></p><p>If there are few <strong>Available Opportunities</strong>, it doesn’t matter how good you are, it is very unlikely you will be granted new ones. <strong>Available Opportunities</strong> are also contextual: they depend on your seniority, team, company’s financial situation, etc. You are also not interested in ANY opportunity. There are specific things that you’ll be interested in doing and/or learning.</p><p>With those things in mind, these are some tips for maximizing <strong>Available Opportunities</strong>.</p><ol><li><strong>Pick opportunities based on your growth goals</strong>: If you want to grow as a distributed systems engineer, opportunities related to building mobile applications are likely to help you less than opportunities related to building databases. I recommend avoiding short term goals related to “titles” and instead prioritized improving your skills over time.</li></ol><p>Goals don’t necessarily need to be getting a better title/promoted. A goal in your career can just be “maximizing learning”, which means you need to “maximize learning opportunities” and your “improve rate”.</p><p><a href="https://lethain.com/forty-year-career/" target="_blank" rel="nofollow noopener noreferrer">This article</a> by Will Larson does a great job of explaining how to plan for a long term career.
<a href="https://medium.com/@bellmar/why-is-this-idiot-running-my-engineering-org-c6e815790cdb" target="_blank" rel="nofollow noopener noreferrer">This article</a> by Marianne Belloti talks about some drawbacks of making career decisions based on just looking for higher titles and admiration</p><ol><li><p><strong>Determine how to best get those opportunities</strong>, ideally minimizing <em>“investment”</em> required to get them: </p><p>If you can get the opportunities you are interested in by staying in your current team, that’s great. If that’s not the case: are there other teams in the engineering organization doing what you want? Are there teams in other departments in the organization doing it? If not, then it might be time to change companies.</p><p>The same applies to conference speaking. If there are two similar conferences on the same date, and one of them requires you to fly 14 hours and the other one only 2 hours, you probably want to pick the latter.</p><p>Large companies that have a strict process for granting opportunities based on just “years at the company” are reducing the amount of <strong>Available Opportunities</strong>, regardless of your skills. This is why high growth startups are sometimes so popular for people that want to grow, there are plenty of opportunities.</p></li><li><p><strong>Create your opportunities</strong>: Proactively propose opportunities to sponsors, adding them to the <strong>Available Opportunities</strong> stock. </p><p>Want to get better at automated testing? Do some research to explain how more testing would help the team/company, explain that to the right sponsor (more on that later), and pitch to work on a project related to that next quarter. Simultaneously, reach out to someone in your organization that you believe is great at automated testing and ask them to mentor you.</p></li></ol><h2 id="reorganizations"><a href="#reorganizations" aria-label="reorganizations permalink"></a>Reorganizations</h2><p>Reorganizations might change the <strong>Available Opportunities</strong> a lot, especially at Senior Engineer (or higher) roles. Depending on the reorganization type and size you might get a heads up and be asked for feedback on options regarding where you will land. During those conversations consider the future <strong>Available Opportunities</strong> to decide what to do.</p><p>Having determined the kind of opportunity you want, the next thing is to get the sponsors for those opportunities to think of your skills as a good fit for them. This involves:</p><ol><li>Finding the right sponsor</li><li>Make your skills visible to them</li></ol><p>When you begin your career as a developer, your team’s Manager or Tech Lead is likely your main sponsor. They are aware of opportunities for tasks/work inside the team and they are the ones assigning work.</p><p>As you grow the situation changes, but you <a href="https://staffeng.com/guides/staying-aligned-with-authority" target="_blank" rel="nofollow noopener noreferrer">always need sponsors</a>. Senior Engineer role (or higher) related opportunities might be discussed at a cross-team level, maybe in a forum involving multiple Managers and/or Directors. Principal level engineers might also have a say in nudging decisions about critical initiatives. People’s titles stop being a good indicator of “sponsorship ability”. <strong>In essence, you need to understand the <a href="https://en.wikipedia.org/wiki/Informal_organization" target="_blank" rel="nofollow noopener noreferrer">informal organization</a> and how it relates to the opportunities you are interested in.</strong></p><p>If you are lost, ask someone you trust and is influential for help. This person doesn’t necessarily need to be a coworker. They should be able to provide guidance. </p><p><img src="https://yenkel.dev/media/2020-08-25/sponsors.jpg"></p><h2 id="visibility"><a href="#visibility" aria-label="visibility permalink"></a>Visibility</h2><p>After identifying the right sponsor(s) you need to make your skills (and interest) visible to them (“skill displays”). Remember: this is not about “lying” or “faking it”. This is about generating awareness. </p><p>You can do this in different ways:</p><ol><li><strong>1:1s</strong>: if you can get a 1:1 with the sponsor to chat about opportunities, do it. In general, when you reach out to people asking them to help you grow and learn, their reactions will be helpful and positive. In these situations, it helps to <a href="#self-awareness">be self-aware</a>.</li><li><strong>Generate content</strong>: internal or external content (conference talks, blog posts) allows you to share your skills. If you want more opportunities to work with Kafka maybe doing a Kafka brown bag and inviting the infrastructure tech leads can help.</li><li><strong>Share accomplishments</strong>: The parallel to: “If a tree falls in a forest and no one is around to hear it, does it make a sound?” is “If you reduce AWS expenses by 25% but no one knows about it, did it happen?“. Make sure the right sponsors know what you have achieved. Whenever you do this, make sure you give credit where credit is due.</li></ol><p>The more senior your sponsor the more things they have on their mind. It is hard for them to pay attention and keep in mind the skills and goals of multiple people. </p><p>Make sure you provide visibility in an easy to consume format. There are some specific approaches that you can use to provide visibility about your work:
<a href="https://jvns.ca/blog/brag-documents/" target="_blank" rel="nofollow noopener noreferrer">Brag documents</a> by Julia Evans
<a href="https://lethain.com/career-narratives/" target="_blank" rel="nofollow noopener noreferrer">Career narratives</a> by Will Larson</p><p>Periodically remind sponsors of your skills and goals. Following up with your sponsors and repeating yourself once in a while is fine.</p><p>Some potential sponsors might be biased. If they are negatively biased towards you, you will need a much higher “skill display rate” than a person they aren’t biased against would need to get them to be YOUR sponsor. There might even be cases when they will never become sponsors, no matter how high your “skill display rate”.</p><p>Lara Hogan has a <a href="https://larahogan.me/blog/what-sponsorship-looks-like/" target="_blank" rel="nofollow noopener noreferrer">great blog post</a> on this topic.</p><p>Consider sponsor bias whenever you are looking to decide if a person is “the right sponsor” for you.</p><h3 id="outside-your-company"><a href="#outside-your-company" aria-label="outside your company permalink"></a>Outside your company</h3><p>Sharing your skills in public sites (LinkedIn, Twitter, conference talks, blogs, etc.) creates …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors">https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors</a></em></p>]]>
            </description>
            <link>https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273025</guid>
            <pubDate>Tue, 25 Aug 2020 16:25:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimal Peanut Butter and Banana Sandwiches]]>
            </title>
            <description>
<![CDATA[
Score 285 | Comments 99 (<a href="https://news.ycombinator.com/item?id=24272814">thread link</a>) | @ethanahte
<br/>
August 25, 2020 | https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/ | <a href="https://web.archive.org/web/*/https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <section>
          <section>
              

              
              
              
              
              


              <article>
                  <div>
<video autoplay="" muted="" loop="loop">
    <source src="https://www.ethanrosenthal.com/videos/optimal-peanut-butter-and-banana/banana_small.mp4" type="video/mp4">
</video>

<p>I was personally useless for most of the Spring of 2020. There was a period of time, though, after the peak in coronavirus cases here in NYC and before the onslaught of police violence here in NYC that I managed to scrounge up the motivation to do something other than drink and maniacally refresh my Twitter feed. I set out to work on something completely meaningless. It was almost therapeutic to work on a project with no value of any kind (<em>insert PhD joke here</em>).</p>
<p>A side effect of having spent 10 years with limited income in college and grad school, 6 of those here in expensive ass NYC, is that I eat of lot of cheap sandwiches, even though I now have a nice Tech™ job. While my sandwich consumption was quite formidable pre-covid, sheltering in place cemented this staple in my diet. I am particularly fond of peanut butter and banana sandwiches, having been introduced to them as a child by my maternal grandfather who ate them regularly.</p>
<p>I start a peanut butter and banana sandwich by spreading peanut butter on two slices of bread. I then slice circular slices of the banana, starting at the end of the banana, and place each slice on one of the pieces of bread until I have a single layer of banana slices. Every time I do this, the former condensed matter physicist in me starts to twitch his eye. You see, I have this urge, this desire, this <em>need</em> to maximize the <a href="https://en.wikipedia.org/wiki/Atomic_packing_factor">packing fraction</a> of the banana slices. That is, I want to maximize the coverage of the banana slices on the bread. Just as bowl-form food is perfect because you get every ingredient in every bite, each bite of my sandwich should yield the same golden ratio of bread, peanut butter, and banana.</p>
<p>If you were a machine learning model (or my wife), then you would tell me to just cut long rectangular strips along the long axis of the banana, but I’m not a sociopath. If life were simple, then the banana slices would be perfect circles of equal diameter, and we could coast along looking up optimal configurations on <a href="http://packomania.com/">packomania</a>. But alas, life is not simple. We’re in the middle of a global pandemic, and banana slices are elliptical with varying size.</p>
<p>So, how do we make optimal peanut butter and banana sandwiches? It’s really quite simple. You take a picture of your banana and bread, pass the image through a deep learning model to locate said items, do some nonlinear curve fitting to the banana, transform to polar coordinates and “slice” the banana along the fitted curve, turn those slices into elliptical polygons, and feed the polygons and bread “box” into a 2D nesting algorithm.</p>
<p>You may have noticed that I supposedly started this project in the Spring, and it’s now August. Like most idiot engineers, I had no idea how complicated this stupid project was going to be, but time’s meaningless in quarantine, so here we are. And here you are! Because I made a pip installable python package <a href="https://github.com/EthanRosenthal/nannernest">nannernest</a> if you want to optimize your own sandwiches, and I’m going to spend the rest of this post describing how this whole godforsaken thing works.</p>
</div>
<div>
<h2 id="sandwich-segmentation">Sandwich Segmentation</h2>
<p>I know that deep learning has been properly commoditized when the easiest part of this project was identifying every pixel that belongs to a banana or slice of bread in an image. Seriously, this step was super easy. I used a pretrained Mask-RCNN torchvision <a href="https://pytorch.org/docs/stable/torchvision/models.html#torchvision.models.detection.maskrcnn_resnet50_fpn">model</a> with a Resnet backbone. The model was pretrained on the COCO <a href="https://cocodataset.org/">dataset</a>, and thankfully the dataset has “banana” as segmentation category, along with “sandwich” and “cake” which were close enough categories for suitable detection of most slices of bread.</p>
<p>Passing an image through the model outputs a bunch of detected objects, where each detected object has an associated <code>label</code>, <code>score</code>, <code>bounding box</code>, and <code>mask</code>, where the mask identifies the pixels that correspond to the object with a weight at each pixel corresponding to the model’s confidence in that pixel’s label.</p>
<p>Because there could be multiple bananas and slices of bread in the image, I pick out the banana and slice of bread with the highest score. Below, you can see the model is clearly able to identify the banana and bread, with the mask overlaid in a semi-transparent, radioactive green.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>%</span><span>config</span> <span>InlineBackend</span><span>.</span><span>figure_format</span> <span>=</span> <span></span><span>'</span><span>retina</span><span>'</span>

<span>from</span> <span>pathlib</span> <span>import</span> <span>Path</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>nannernest</span>

<span>_RC_PARAMS</span> <span>=</span> <span>{</span>
    <span></span><span>"</span><span>figure.figsize</span><span>"</span><span>:</span> <span>(</span><span>8</span><span>,</span> <span>4</span><span>)</span><span>,</span>
    <span></span><span>"</span><span>axes.labelsize</span><span>"</span><span>:</span> <span>16</span><span>,</span>
    <span></span><span>"</span><span>axes.titlesize</span><span>"</span><span>:</span> <span>18</span><span>,</span>
    <span></span><span>"</span><span>axes.spines.right</span><span>"</span><span>:</span> <span>False</span><span>,</span>
    <span></span><span>"</span><span>axes.spines.top</span><span>"</span><span>:</span> <span>False</span><span>,</span>
    <span></span><span>"</span><span>font.size</span><span>"</span><span>:</span> <span>14</span><span>,</span>
    <span></span><span>"</span><span>lines.linewidth</span><span>"</span><span>:</span> <span>2</span><span>,</span>
    <span></span><span>"</span><span>lines.markersize</span><span>"</span><span>:</span> <span>6</span><span>,</span>
    <span></span><span>"</span><span>legend.fontsize</span><span>"</span><span>:</span> <span>14</span><span>,</span>
<span>}</span>
<span>for</span> <span>k</span><span>,</span> <span>v</span> <span>in</span> <span>_RC_PARAMS</span><span>.</span><span>items</span><span>(</span><span>)</span><span>:</span>
    <span>plt</span><span>.</span><span>rcParams</span><span>[</span><span>k</span><span>]</span> <span>=</span> <span>v</span>

<span>DPI</span> <span>=</span> <span>160</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>image</span><span>,</span> <span>banana</span><span>,</span> <span>bread</span> <span>=</span> <span>nannernest</span><span>.</span><span>segmentation</span><span>.</span><span>run</span><span>(</span><span>Path</span><span>(</span><span></span><span>"</span><span>pre_sandwich.jpg</span><span>"</span><span>)</span><span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span><span>image</span><span>,</span> <span>banana</span><span>=</span><span>banana</span><span>,</span> <span>bread</span><span>=</span><span>bread</span><span>,</span> <span>show</span><span>=</span><span>True</span><span>,</span> <span>dpi</span><span>=</span><span>DPI</span><span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_4_0.png"> </figure>

</div>
<div>
<h2 id="what-shape-does-a-banana-makehttpswwwyoutubecomwatchv3o1ad4lzygk"><a href="https://www.youtube.com/watch?v=3O1ad4lZYGk">What shape does a banana make?</a></h2>
<p>Now that we have identified the banana in the image, we need to virtually “slice” it. This is where we are first introduced to the universal pain of computer vision:</p>
<p><em>By eye, I can see exactly what I want to do; by code, it’s so damn difficult.</em></p>
<p>I could ask you to draw lines on the banana identifying where you would slice it, and you could easily draw well-spaced, somewhat parallel slices. It’s not so easy to do this with code. However, I would also argue that this is the fun part of the problem. There are many ways to solve this, and it feels creative, as opposed to using a pre-trained deep learning model. On the other hand, “creatively” solving these problems likely leads to more brittle solutions compared to deep learning models trained on millions of examples. There’s a tradeoff here.</p>
<p>I tried a bunch of analytical solutions based on ellipses, but nothing seemed to work quite right. I ended up landing on a somewhat simpler solution that may not be robust to straight bananas, but who cares – this is a silly project anyway. Using the wonderful <a href="https://scikit-image.org/">scikit-image</a> library, I first calculate the <a href="https://scikit-image.org/docs/dev/auto_examples/edges/plot_skeleton.html">skeleton</a> of the banana segmentation mask. This reduces the mask to a one pixel wide representation which effectively creates a curve that runs along the long axis of the banana.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>slices</span><span>,</span> <span>banana_circle</span><span>,</span> <span>banana_centroid</span><span>,</span> <span>banana_skeleton</span> <span>=</span> <span>nannernest</span><span>.</span><span>slicing</span><span>.</span><span>run</span><span>(</span>
    <span>banana</span><span>.</span><span>mask</span>
<span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span><span>image</span><span>,</span> <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span> <span>show</span><span>=</span><span>True</span><span>,</span> <span>dpi</span><span>=</span><span>DPI</span><span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_7_0.png"> </figure>

</div>
<p>I then fit a circle to the banana skeleton using a nice scipy-based least squares optimization I found <a href="https://scipy-cookbook.readthedocs.io/items/Least_Squares_Circle.html#Using-scipy.optimize.leastsq">here</a>. I actually originally tried to fit this with PyTorch and totally failed, likely due to the fact that this is actually a nonlinear optimization problem.</p>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span>
    <span>image</span><span>,</span>
    <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span>
    <span>banana_circle</span><span>=</span><span>banana_circle</span><span>,</span>
    <span>show</span><span>=</span><span>True</span><span>,</span>
    <span>dpi</span><span>=</span><span>DPI</span><span>,</span>
<span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_9_0.png"> </figure>

</div>
<div>
<h2 id="rad-coordinate-transformations">Rad Coordinate Transformations</h2>
<p>With the circle fit to the banana, the goal is to now draw radial lines out from the center of the circle to the banana and have each radial line correspond to the slice of a knife. Again, while it’s easy to visualize this, it’s much harder in practice. For example, we need to start slicing at one end of the banana, but how do we find an end of the banana? Also, there are two ends, and we have to differentiate between them. Contrary to the behavior of <a href="https://www.thekitchn.com/why-you-should-peel-your-banana-like-a-monkey-206322">monkeys</a>, I start slicing my bananas at the stem end, and that’s what we’re going to do here.</p>
<p>Crucially, because we now have this circle and want to cut radial slices, we must transform from cartesian to polar coordinates and orient ourselves both radially and angularly with respect to the banana. As a start for orienting ourselves angularly, we calculate the <em>centroid</em> of the banana mask, which corresponds to the center of mass of the banana mask if the banana mask were a 2D object. The centroid is shown below as a red dot.</p>
<p>We now draw a radial line originating from the banana circle and passing through the centroid, shown as the dashed white line below. We will consider that line to mark our <em>reference</em> angle which orients us to the center of the banana.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>ax</span> <span>=</span> <span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span>
    <span>image</span><span>,</span>
    <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span>
    <span>banana_circle</span><span>=</span><span>banana_circle</span><span>,</span>
    <span>banana_centroid</span><span>=</span><span>banana_centroid</span><span>,</span>
    <span>show</span><span>=</span><span>False</span><span>,</span>
    <span>dpi</span><span>=</span><span>DPI</span><span>,</span>
<span>)</span>

<span>dy</span> <span>=</span> <span>banana_centroid</span><span>[</span><span>0</span><span>]</span> <span>-</span> <span>banana_circle</span><span>.</span><span>yc</span>
<span>dx</span> <span>=</span> <span>banana_centroid</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>banana_circle</span><span>.</span><span>xc</span>
<span>reference_angle</span> <span>=</span> <span>np</span><span>.</span><span>arctan2</span><span>(</span><span>dy</span><span>,</span> <span>dx</span><span>)</span>
<span>radius</span> <span>=</span> <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>dx</span> <span>*</span><span>*</span> <span>2</span> <span>+</span> <span>dy</span> <span>*</span><span>*</span> <span>2</span><span>)</span>

<span>radial_end_point</span> <span>=</span> <span>(</span>
    <span>banana_circle</span><span>.</span><span>xc</span> <span>+</span> <span>2</span> <span>*</span> <span>radius</span> <span>*</span> <span>np</span><span>.</span><span>cos</span><span>(</span><span>reference_angle</span><span>)</span><span>,</span>
    <span>banana_circle</span><span>.</span><span>yc</span> <span>+</span> <span>2</span> <span>*</span> <span>radius</span> <span>*</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>reference_angle</span><span>)</span><span>,</span>
<span>)</span>

<span>ax</span><span>.</span><span>plot</span><span>(</span>
    <span>(</span><span>banana_circle</span><span>.</span><span>xc</span><span>,</span> <span>radial_end_point</span><span>[</span><span>0</span><span>]</span><span>)</span><span>,</span>
    <span>(</span><span>banana_circle</span><span>.</span><span>yc</span><span>,</span> <span>radial_end_point</span><span>[</span><span>1</span><span>]</span><span>)</span><span>,</span>
    <span>color</span><span>=</span><span></span><span>"</span><span>white</span><span>"</span><span>,</span>
    <span>linestyle</span><span>=</span><span></span><span>"</span><span>--</span><span>"</span><span>,</span>
    <span>linewidth</span><span>=</span><span>1</span><span>,</span>
<span>)</span>
<span>None</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_11_0.png"> </figure>

</div>
<p>Using <code>scikit-image</code>, we calculate the segmentation <code>mask</code> intensity along this radial line using the <code>profile_line</code> function. Because our line is passing at an angle along discrete <code>mask</code> pixels (aka matrix entries), we take an average of neighboring points along the radial line cut using the <code>linewidth</code> arguments. As you can see, the banana mask pops out a little over 100 points from the banana circle center.</p>
<div>
<div>
<div><pre><code data-lang="python"><span>from</span> <span>skimage</span> <span>import</span> <span>measure</span>

<span>profile_line</span> <span>=</span> <span>measure</span><span>.</span><span>profile_line</span><span>(</span>
    <span>banana</span><span>.</span><span>mask</span><span>.</span><span>T</span><span>,</span> <span>banana_circle</span><span>.</span><span>center</span><span>,</span> <span>radial_end_point</span><span>,</span> <span>linewidth</span><span>=</span><span>2</span><span>,</span> <span>mode</span><span>=</span><span></span><span>"</span><span>constant</span><span>"</span>
<span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>fig</span><span>,</span> <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplots</span><span>(</span><span>)</span>
<span>ax</span><span>.</span><span>plot</span><span>(</span><span>profile_line</span><span>)</span>
<span>ax</span><span>.</span><span>set_xlabel</span><span>(</span><span></span><span>"</span><span>Distance from banana circle center</span><span>"</span><span>)</span>
<span>ax</span><span>.</span><span>set_title</span><span>(</span><span></span><span>"</span><span>Mask Intensity</span><span>"</span><span>)</span>
<span>None</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_14_0.png"> </figure>

</div>
<p>This profile line is what allows us to orient ourselves radially. You can clearly see where the banana starts and ends, in the radial direction. As always, just seeing it is not good enough. We need code to define the start and end of the banana in this direction. The <code>mask</code> tends to be monotonically increasing and then monotonically decreasing along the start and end, respectively. Using this information, there are a couple ways …</p></article></section></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/">https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/</a></em></p>]]>
            </description>
            <link>https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272814</guid>
            <pubDate>Tue, 25 Aug 2020 16:10:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[But does it help you ship?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272630">thread link</a>) | @misternugget
<br/>
August 25, 2020 | https://thorstenball.com/blog/2020/08/25/but-does-it-help-you-ship/ | <a href="https://web.archive.org/web/*/https://thorstenball.com/blog/2020/08/25/but-does-it-help-you-ship/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p>25 Aug 2020</p>

  <p>Whenever I’m not sure whether I’m spending my time on the right thing I ask
myself: <em>does it help me ship?</em></p>

<p>If what I consider working on is not the thing we want to ship itself, but lies
in the vast grey area of software projects where I could write code all day long
without the user ever noticing, this question helps me decide whether to drop it
or invest some time in it.</p>

<p>Let me illustrate.</p>

<p>One imaginary Friday afternoon I notice that we have a few <code>// TODO</code> comments in our
codebase. Hmm, I could create a bot that looks for those comments whenever a new
commit is pushed. It could use <code>git blame</code> to see who the author is and create a
ticket assigned to them, saying that they should fix their TODO in line X in
file Y, please. And, cherry on top, when a pull request that touches a TODO is
opened, the bot would mark the corresponding ticket as work-in-progress. And
when the pull request is merged, the bot closes the ticket. And when a pull
request merely changes the <code>TODO:</code> into a <code>TODO(poorsoul):</code> then it assigns the
ticket to <code>poorsoul</code>.</p>

<p>Sounds pretty good, right? Turn those TODOs into tickets and never lose a TODO
again.</p>

<p>The problem is: it’s not free. It looks like it is, because the code is quickly
written and it runs as a GitHub action we don’t have to pay for, but it’s not.</p>

<p>It’s <em>another</em> process, <em>another</em> tool, <em>another</em> automated piece in our
machinery. Another thing that needs to be fixed when it ultimately breaks
down, another bit of automation that works 99% of the time, but starts making
funny noises when you slip into the 1% and, say, moved a TODO down five lines by
accident and don’t want the bot to close and re-open tickets, kicking off
another wave of notifications.</p>

<p><em>That’s</em> the actual cost of adding that bot.</p>

<p>The question is do we want to pay it? Does it help me ship? Does it help me ship
<em>more</em>? Or does it help me ship <em>faster</em>, or with less friction, more safely?</p>

<p>If our imaginary codebase has more TODOs than test cases, for example, and these
TODOs are holding us back from shipping because we can’t make a change without
having to ask colleagues what this TODO we just discovered means, then it might
be a good idea to add the bot. Even if we don’t intend to fix all of the TODOs,
but only to finally get an overview and a peek at hidden part of the iceberg. It
helps us ship.</p>

<p>If the code contains more than one <code>TODO: make sure this works</code> and we can’t
ship because changing the code is playing a game of Russian roulette, where
every change could kick off an avalanche of bugs, then yes, this bot would
probably help us ship.</p>

<p>But what if we’re <em>not</em> held back by TODOs? What if we have a total of 18 of them,
and 12 of those have been in the codebase longer than you and I have been at the
company, and, generally speaking, our codebase is in an okay state — is the cost
worth it?</p>

<p>If what’s holding you back from shipping is, say, getting more customer input,
or a brittle release process, or flaky monitoring, or missing tests, then all
the bot does is to add noise. It doesn’t help you ship.</p>

</div></div>]]>
            </description>
            <link>https://thorstenball.com/blog/2020/08/25/but-does-it-help-you-ship/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272630</guid>
            <pubDate>Tue, 25 Aug 2020 15:56:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unpopular Opinion – Data Scientists Should Be More End-to-End]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24272617">thread link</a>) | @importantbrian
<br/>
August 25, 2020 | https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Recently, I came across a <a href="https://www.reddit.com/r/datascience/comments/i48b5q/for_those_that_work_for_a_team_that_has_both_data/" target="_blank">Reddit thread</a> on the different roles in data science and machine learning: data scientist, decision scientist, product data scientist, data engineer, machine learning engineer, machine learning tooling engineer, AI architect, etc.</p>

<p>I found this <em>worrying</em>. It’s difficult to be effective when the data science process (problem framing, data engineering, ML, deployment/maintenance) is split across different people. It leads to coordination overhead, diffusion of responsibility, and lack of a big picture view.</p>

<p>IMHO, <strong>I believe data scientists can be more effective by being end-to-end</strong>. Here, I’ll discuss the <a href="#from-start-identify-the-problem-to-finish-solve-it">benefits</a> and <a href="#but-we-need-specialist-experts-too">counter-arguments</a>, <a href="#the-best-way-to-pick-it-up-is-via-learning-by-doing">how to</a> become end-to-end, and the experiences of <a href="#end-to-end-in-stitch-fix-and-netflix">Stitch Fix and Netflix</a>.</p>

<h2 id="from-start-identify-the-problem-to-finish-solve-it">From start (identify the problem) to finish (solve it)</h2>

<p>You may have come across similar <em>labels</em> and definitions, such as:</p>
<ul>
  <li><a href="https://towardsdatascience.com/why-you-shouldnt-be-a-data-science-generalist-f69ea37cdd2c" target="_blank">Generalist</a>: Focused on roles (<a href="https://en.wikipedia.org/wiki/Product_manager" target="_blank">PM</a>, <a href="https://en.wikipedia.org/wiki/Business_analyst" target="_blank">BA</a>, <a href="https://www.oreilly.com/content/data-engineering-a-quick-and-simple-definition/" target="_blank">DE</a>, <a href="https://en.wikipedia.org/wiki/Category:Data_scientists" target="_blank">DS</a>, <a href="https://www.quora.com/What-exactly-does-a-machine-learning-engineer-do" target="_blank">MLE</a>); some negative connotation</li>
  <li><a href="https://skillcrush.com/blog/front-end-back-end-full-stack/" target="_blank">Full-stack</a>: Focused on tech (Spark, Torch, Docker); popularized by full-stack devs</li>
  <li><a href="https://www.infoworld.com/article/3429185/stop-searching-for-that-data-science-unicorn.html" target="_blank">Unicorn</a>: Focused on mythology; believed not to exist</li>
</ul>

<p>I find these definitions to be more prescriptive than I prefer. Instead, I have a simple (and pragmatic) definition: An end-to-end data scientist can <strong>identify and solve problems with data, to deliver value</strong>. To achieve the goal, they’ll wear as many (or as little) hats as required. They’ll also learn and apply whatever tech, methodology, and process that works. Throughout the process, they ask questions such as:</p>
<ul>
  <li>What is the problem? Why is it important?</li>
  <li>Can we solve it? How should we solve it?</li>
  <li>What is the estimated value? What was the actual value?</li>
</ul>

<details><summary>Data Science Processes</summary>
<div>
<p>Another way of defining end-to-end data science is via processes. These processes are usually complex and I’ve left them out of the main discussion. Nonetheless, here are a few in case you’re curious:</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining" target="_blank">CRISP-DM</a>: Cross-Industry Standard Process for Data Mining (1997).</li>
  <li><a href="https://en.wikipedia.org/wiki/Data_mining#Process" target="_blank">KDD</a>: Knowledge Discovery in Databases.</li>
  <li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview" target="_blank">TDSP</a>: Team Data Science Process, proposed by Microsoft in 2018.</li>
  <li><a href="https://github.com/dslp/dslp" target="_blank">DSLP</a>: Data Science Lifecycle Process.</li>
</ul>

<p>Don’t worry if these processes seem heavy and overwhelming. You don’t have to adopt them wholesale—start bit by bit, keep what works and adapt the rest.</p>
</div>

</details>

<h2 id="more-context-faster-iteration-greater-satisfaction">More context, faster iteration, greater satisfaction</h2>

<p>For most data science roles, being more end-to-end improves your ability to make meaningful impact. (Nonetheless, there are <a href="https://nvidia.wd5.myworkdayjobs.com/en-US/NVIDIAExternalCareerSite/job/US-CA-Santa-Clara/Senior-Deep-Learning-Data-Scientist--RAPIDS---AI_JR1929838" target="_blank">roles</a> that focus on machine learning.)</p>

<p><strong>Working end-to-end provides increased context.</strong> While specialized roles can increase efficiency, it reduces context (for the data scientist) and leads to suboptimal solutions.</p>

<blockquote>
  <p>The trick to forgetting the big picture is to look at everything close-up. – Chuck Palahniuk</p>
</blockquote>

<p>It’s hard to design a holistic solution without full context of the upstream problem. Let’s say conversion has decreased and a PM raises a request to improve our search algorithm. However, what’s causing the decrease in the first place? There could be various causes:</p>
<ul>
  <li>Product: Is fraudulent/poor quality product reducing customer trust?</li>
  <li>Data pipelines: Has data quality been compromised or are there delays/outages?</li>
  <li>Model refresh: Is the model not refreshing regularly/correctly?</li>
</ul>

<p>More often than not, the problem—and solution—lies <em>outside</em> of machine learning. A solution to <em>improve the algorithm</em> would miss the root cause.</p>

<p>Similarly, it’s risky to develop a solution without awareness of downstream engineering and product constraints. There’s no point:</p>
<ul>
  <li>Building a near-real time recommender if infra and engineer cannot support it</li>
  <li>Building an infinite scroll recommender if it doesn’t fit in our product and app</li>
</ul>

<p>By working end-to-end, data scientists will have the full context to identify the right problems and develop usable solutions. It can also lead to innovative ideas that specialists, with their narrow context, might miss. Overall, it increases the ability to deliver value.</p>

<p><strong>Communication and coordination overhead is reduced.</strong> With multiple roles comes additional overhead. Let’s look at an example of a data engineer (DE) cleaning the data and creating features, a data scientist (DS) analysing the data and training the model, and a machine learning engineer (MLE) deploying and maintaining it.</p>

<blockquote>
  <p>What one programmer can do in one month, two programmers can do in two months. – Frederick P. Brooks</p>
</blockquote>

<p>The DE and DS need to <em>communicate</em> on what data is (and is not) available, how it should be cleaned (e.g., outliers, normalisation), and which features should be created. Similarly, the DS and MLE have to discuss how to deploy, monitor, and maintain the model, as well as how often it should be refreshed. When issues occur, we’ll need three people in the room (likely with a PM) to triage the root cause and next steps to fix it.</p>

<p>It also leads to additional coordination, where schedules need to be aligned as work is executed and passed along in a sequential approach. If the DS wants to experiment with additional data and features, we’ll need to wait for the DE to ingest the data and create the features. If a new model is ready for A/B testing, we’ll need to wait for the MLE to (convert it to production code) and deploy it.</p>

<p>While the actual development work may take days, the communication back-and-forth and coordination can take weeks, if not longer. With end-to-end data scientists, we can minimize this overhead as well as prevent technical details from being lost in translation.</p>

<p>(But, can an end-to-end DS really do all that? I think so. While the DS might not be as proficient in some tasks as a DE or MLE, they will be able to perform most tasks effectively. If they need help with scaling or hardening, they can always get help from specialist DEs and MLEs.)</p>

<details><summary>The Cost of Communication and Coordination</summary>
<div>
<p>Richard Hackman, a Harvard psychologist, showed that the number of relationships in a team is <code><span>N</span><span>(</span><span>N</span><span>-</span><span>1</span><span>)</span> <span>/</span> <span>2</span></code>, where <code><span>N</span></code> is the number of people. This leads to exponential growth in links, where:</p>

<ul>
  <li>A start-up team of 7 has 21 links to maintain</li>
  <li>A group of 21 (i.e., three start-up teams) has 210 links</li>
  <li>A group of 63 has almost 2,000 links.</li>
</ul>

<p>In our simple example, we only had three roles (i.e., six links). But as a PM, BA, and additional members are included, this leads to greater than linear growth in communication and coordination costs. Thus, while each additional member increases total team productivity, the increased overhead means productivity grows at a decreasing rate. (Amazon’s <a href="https://buffer.com/resources/small-teams-why-startups-often-win-against-google-and-facebook-the-science-behind-why-smaller-teams-get-more-done/" target="_blank">two-pizza teams</a> are a possible solution to this.)</p>
</div>
</details>

<p><strong>Iteration and learning rate is increased.</strong> With greater context and lesser overhead, we can now iterate, fail (read: learn), and deliver value faster.</p>

<p>This is especially important for developing data and algorithmic products. Unlike software engineering (a far more mature craft), we can’t do all the learning and design before we start building—our blueprints, architectures, and design patterns are not as developed. Thus, rapid iteration is essential for the design-build-learn cycle.</p>

<p><strong>There’s greater ownership and accountability.</strong> Having the data science process split across multiple people can lead to diffusion of responsibility, and worse, social loafing.</p>

<p>A common anti-pattern observed is “<a href="https://wiki.c2.com/?ThrownOverTheWall" target="_blank">throw over the wall</a>”. For example, the DE creates features and throws a database table to the DS, the DS trains a model and throws <code>R</code> code over to the MLE, and the MLE translates it to <code>Java</code> to production.</p>

<p>If things get lost-in-translation or if results are unexpected, who is responsible? With a strong culture of ownership, everyone steps up to contribute in their respective roles. But without it, work can degenerate into ass-covering and finger-pointing while the issue persists and customers and the business suffers.</p>

<p>Having the end-to-end data scientist take ownership and responsibility for the entire process can mitigate this. They should be empowered to take action from start to finish, from the customer problem and input (i.e., raw data) to the output (i.e., deployed model) and measurable outcomes.</p>

<details><summary>Diffusion of Responsibilty &amp; Social Loafing</summary>
<div>

<p><a href="https://en.wikipedia.org/wiki/Diffusion_of_responsibility" target="_blank">Diffusion of responsibility</a>: We are less likely to take responsibility and act when there are others present. Individuals feel less responsibility and urgency to help if we know that there are others also watching the situation. </p>

<p>One form of this is the <a href="https://en.wikipedia.org/wiki/Diffusion_of_responsibility#Bystander_effect" target="_blank">Bystander effect</a>, where <a href="https://en.wikipedia.org/wiki/Murder_of_Kitty_Genovese" target="_blank">Kitty Genovese</a> was stabbed outside the apartment building across the street from where she lived. While there were 38 witnesses who saw or heard the attack, none called the police or helped her.</p>

<p><a href="https://en.wikipedia.org/wiki/Social_loafing" target="_blank">Social loafing</a>: We exert less effort when we work in a group vs. working alone. In the 1890s, Ringelmann made people pull on ropes both separately and in groups. He measured how hard they pulled and found that members of a group tended to exert less effort in pulling a rope than did individuals alone.</p>

</div>
</details>

<p><strong>For (some) data scientists, it can lead to increased motivation and job satisfaction</strong>, which is <a href="https://www.clearpointstrategy.com/how-employees-are-motivated-autonomy-mastery-purpose/" target="_blank">closely tied</a> to autonomy, mastery, and purpose.</p>
<ul>
  <li><strong>Autonomy:</strong> By being able to solve problems independently. Instead of waiting and depending on others, end-to-end data scientists are able to identify and define the problem, build their own data pipelines, and deploy and validate a solution.</li>
  <li><strong>Mastery:</strong> In the problem, solution, outcome from end-to-end. They can also pick up the domain and tech as required.</li>
  <li><strong>Purpose</strong>: By being deeply involved in the entire process, they have a more direct connection with the work and outcomes, leading to an increased sense of <em>purpose</em>.</li>
</ul>

<h2 id="but-we-need-specialist-experts-too">But, we need specialist experts too</h2>

<p>Being end-to-end is not for everyone (and every team) though, for reasons such as:</p>

<p><strong>Wanting to specialize</strong> in machine learning, or perhaps a specific niche in machine learning such as neural text generation (read: <a href="https://mc.ai/the-subtle-art-of-priming-gpt-3/" target="_blank">GPT-3 primer</a>). While being end-to-end is valuable, we also need such world-class experts in research and industry who push the envelope. Much of what we have in ML came from academia and pure research efforts.</p>

<blockquote>
  <p>No one achieves greatness by …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D">https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272617</guid>
            <pubDate>Tue, 25 Aug 2020 15:54:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Slack Hacks: 14 Ideas for Dev and DevOps Workflows in Slack via AWS, Twilio]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24272333">thread link</a>) | @jacksonpollock
<br/>
August 25, 2020 | https://cto.ai/blog/slack-hacks-14-ideas-for-developer-devops-workflows-slack-aws-twilio-lyft/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/slack-hacks-14-ideas-for-developer-devops-workflows-slack-aws-twilio-lyft/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<p>Increasingly companies are bringing their entire workflows and data streams into Slack via apps, integrations, and APIs. Slack is currently reporting over <a href="https://kommandotech.com/statistics/slack-statistics/#:~:text=135%2C983%20companies%20are%20currently%20using,million%20people%20daily%20in%202019.">135,000 active companies</a> and that’s just the beginning amid a global rise of remote-first work.</p><p>Why this move to Slack? For millions of users, Slack is THE place for communication and collaboration. Slack is not just an email killer because it’s a novel form of communication. We already had SMS and WhatsApp. What Slack brings to the table is deeper-seated in company transparency and velocity.</p><p>Slack is seamlessly synchronous and asynchronous. It allows you to reduce context switching by creating a space for both short-form communication and long-form with a sprinkle of emoji-led authentic conversations and interactions. It also is beautifully designed.</p><p>Most importantly though, Slack brings in streams of information out of the countless siloed data sources in your consoles and Chrome browser tabs. It surfaces real-time and important metrics, queries, customer support tickets, PagerDuty downtime pings, and so much more. It’s become your dashboard for your company, team, and everything in between.</p><p>The average company loses <a href="https://slack.com/resources/why-use-slack/software-development-teams-and-slack">more than 20%</a> of its productive power to organizational drag. Put Slack in the picture though and development teams using Slack deliver 5% more output overall, with 23% faster time to market, 27% less time needed to test and iterate, and faster identification and resolution of engineering-related bugs, <a href="https://slack.com/resources/why-use-slack/software-development-teams-and-slack#">according to IDC research</a>.</p><p>Here at CTO.ai, we use a plethora of Slackbots and SlackOps to run our company. From our <a href="https://cto.ai/platform">Slack-first DevOps workflow automation platform</a> to Geekbot for company standups to the <a href="https://ops-community.slack.com/apps/A2RPP3NFR-jira-cloud">Jira chatbot</a> for our product roadmap to Greetbot to welcome new members of <a href="https://w.cto.ai/community">our Slack developer community</a>, we are believers that Slack is the key to fluid, meshed flow states that increase productivity and observability.</p><p>To say the least, we are big fans of Slack, but don’t take our word for it. Below are some Slack hacks, tips and tricks for developers and engineering teams of all ilks to get the most out of Slack. In no particular order, here are what DevOps and engineering workflows technical leaders are using in Slack:</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-1-send-delayed-messages">#1 Send Delayed Messages</h2><h3 id="lizzie-sigal-developer-evangelist-twilio"><em><a href="https://www.linkedin.com/in/elsiegle/">Lizzie Sigal</a>, Developer Evangelist, Twilio</em></h3><p>“The <a href="https://ops-community.slack.com/apps/ANPGHD2F8-gator">Gator Slack app</a> lets you send delayed messages at 9am in the recipient's time zone so as to not notify them if they've logged off for the day. Convenient, more thoughtful, simple.”</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-2-team-celebrations">#2 Team Celebrations</h2><h3 id="fletcher-richman-co-founder-ceo-halp-senior-product-manager-atlassian"><em><a href="https://twitter.com/fletchrichman?lang=en">Fletcher Richman</a>, Co-Founder/CEO Halp; Senior Product Manager, Atlassian</em></h3><p>“Every time a new customer signs up for Halp via Stripe, we post a gif to #halp-wins.” </p><p><em>Atlassian, <a href="https://techcrunch.com/2020/05/12/atlassian-acquires-halp-to-bring-slack-integration-to-the-forefront/">which acquired Halp</a>, also has <a href="https://statuspage.io/">Statuspage</a>, a chatbot with a full Slack integration that allows updating and maintaining your status page directly inside your ops chatroom.</em></p><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="daniel-hochman-platform-engineer-lyft"><em><a href="https://www.linkedin.com/in/danielhochman/">Daniel Hochman</a>, Platform Engineer, Lyft</em></h3><p>“<a href="https://eng.lyft.com/announcing-clutch-the-open-source-platform-for-infrastructure-tooling-143d00de9713">Clutch</a> ships with authentication and authorization components. OpenID Connect (OIDC) authentication flows for single-sign on, resource-level role-based access control (RBAC) via static mapping, and automatic auditing of all actions with the ability to run additional sinks for output, e.g., a Slackbot.”</p><!--kg-card-begin: html--><br><!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://lh4.googleusercontent.com/s0GcOYpOtfDNhE-jH7RyDcXo-uZQubyEZAyrdtTWYKpKibznvl4QezGLiTrhbNa4U_2XR2k_MHE8gKcyo2G2XM01ErSixY5k6kxU8Q2nj9NDp6T00ifdJo04qla74pph5DOfoS8"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-4-reminders">#4 Reminders</h2><h3 id="don-burks-technical-lead-sphere"><em><a href="https://donburks.com/">Don Burks</a>, Technical Lead, Sphere</em></h3><p>“/remind is one of the biggest ones. Instead of having to break flow from my keyboard and write something down, I can get Slack to remind me.”</p><p>(I personally enjoy CMD K for quick searching and /collapse for minimizing all those extra pop-ups from Slack integrations.)</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-5-wins-failure-alerts-retros-standups">#5 Wins, Failure Alerts, Retros, Standups</h2><h3 id="brice-pollock-senior-ios-engineer-betterup"><em><a href="http://www.bricepollock.com/">Brice Pollock</a>, Senior iOS Engineer, BetterUp</em></h3><ul><li>Looking for a way to give sales organizations more visibility to product teams? Use the <a href="https://slack.com/help/articles/227838227-Salesforce-for-Slack">Salesforce integration</a> for closed opportunities in #general.</li><li>Looking for a way to get more insight into build failures? Use a CircleCI integration in a Slack channel that reports build failures.</li><li>Looking for a way to get more insight into runtime failures? Use a <a href="https://support.google.com/firebase/answer/9005934">Firebase integration</a> in a Slack channel that reports changes in thresholds for fatals and non-fatals.</li><li>Looking for a way to help with Team Retros? Pin a poll to a Slack channel and use a slash reminder command (/remind) to get the team to enter responses prior to retro.</li><li>Looking for a way to automate standup? Integrate Jira and Confluence so a new standup doc is generated every day with a random ice breaker question in a randomized standup order.</li><li>Looking for a way to highlight SWAT or blocking issues? Create a macro that like reminders will print all blockers right before standup and anyone on the team can add a blocker or discussion topic.</li></ul><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-6-website-metrics">#6 Website Metrics</h2><h3 id="frances-coronel-executive-director-techqueria"><em>Frances Coronel, Executive Director, <a href="https://techqueria.org/">Techqueria</a></em></h3><p>“Website metrics are a way we measure impact and we use Arc to bring Google Analytics to us automatically each week and with a cumulative monthly update instead of having to manually go into there. It's so easy to update our partnerships deck and impact report with the latest numbers.”</p><!--kg-card-begin: image--><figure><img src="https://lh4.googleusercontent.com/fZKgM1bwrrtm8o2ui1T4kaeC35c9wNGB0VkNYkGybp0uykh1npMX-OUkZRo7r-bMriqc6htXbzs18wqFdxqj-rhnOLo_DMCpt_yESqGehTop-bSqN5zYgpfC6NIJ-swfC5LyxSk"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-7-product-support">#7 Product Support</h2><h3 id="vlad-shlosberg-ceo-foqal-io"><em>Vlad Shlosberg, CEO, <a href="https://www.foqal.io/">Foqal.io</a></em></h3><p>“Immediate access to your customers and conversion to become a customer. With this Slack bot, it made our support process a lot more manageable.”</p><!--kg-card-begin: html--><br>
<!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://lh3.googleusercontent.com/XnpvjRt1iYXctHd7CaW37kjYjb4D4QIa7odG70yyBqOBaxbdrHdV6aF4eqI_hzxyaebD7WtFnYOWSxge1iGCho-BK6pbCFP3RySDCYR_ynHGfSvXqJdKtBwL83cJV-ePNbuEV1A"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><br>
<!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://lh6.googleusercontent.com/y8ah1JRLFkMxexXrK9uMy9q8UaRsxjRU4zPW7IEhwUZI_T-XxL3x1i8toFgkzAK9DOhV3EIK2JtnpsHjYnNQ4aI1ED-jH4pP-DaBn2HulFwcAmzUH58HxKSJDemdnuCDjfe1deU"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><br>
<!--kg-card-end: html--><p><a href="https://medium.com/swlh/creating-a-sentiment-bot-in-slack-with-node-js-and-symantos-text-analytics-api-560e854a090d">Symanto</a> built a chatbot with Node.js in Slack using their text analytics API and sentiment models.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-9-status-aggregation-status-gator">#9 Status Aggregation — Status Gator</h2><p><a href="https://statusgator.com/">Status Gator</a> aggregates almost 700 status pages into Slack and you can query the status of any page on demand.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-10-devops-monitoring-aws-chatbot">#10 DevOps Monitoring — AWS Chatbot</h2><p><a href="https://docs.aws.amazon.com/chatbot/latest/adminguide/what-is.html?sc_channel=sm&amp;sc_campaign=Docs&amp;sc_publisher=TWITTER&amp;sc_country=Global&amp;sc_geo=GLOBAL&amp;sc_outcome=awareness&amp;trk=Docs_TWITTER&amp;sc_content=Docs&amp;linkId=87843477">AWS Chatbot</a> enables DevOps and software development teams to use Slack chat rooms to monitor and respond to operational events in their AWS Cloud.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-11-pipeline-notifications-spinnaker">#11 Pipeline Notifications — Spinnaker</h2><p>Configure the <a href="https://blog.opsmx.com/configure-slack-notifications-for-spinnaker-pipelines/">Spinnaker</a> software to receive pipeline notifications through Slack.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-12-azure-boards-pipelines-repos-microsoft">#12 Azure Boards, Pipelines, Repos — Microsoft</h2><p>Post messages to Slack in response to events in your Azure DevOps organization, such as completed builds, code changes, pull requests, releases, work items changes, and more. <a href="https://docs.microsoft.com/en-us/azure/devops/service-hooks/services/slack?view=azure-devops">Details here</a>.</p><p>There are also <a href="https://zapier.com/apps/azure-devops/integrations/slack">Zapier “zaps” for Azure</a> (and many other <a href="https://zapier.com/apps/categories/developer-tools">dev tools</a>).</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-13-infrastructure-notifications-terraform">#13 Infrastructure Notifications — Terraform</h2><p><a href="https://www.terraform.io/docs/cloud/workspaces/notifications.html">Terraform Cloud</a> can use Slack webhooks to notify external systems about the progress of runs.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Don’t forget the preprogrammed apps made just for Slack. Use the <a href="https://ops-community.slack.com/apps/category/At0EFRCDNY-developer-tools">Slack app marketplace</a> to connect your development tools to Slack and raise visibility into builds, errors, or anything else that needs your attention.</p><p>Some Slack apps to call out for DevOps: <a href="https://ops-community.slack.com/apps/A0F7VRE7N-circleci">CircleCI</a>, <a href="https://ops-community.slack.com/apps/A0F81FP4N-travis-ci">Travis CI</a>, <a href="https://gitlab.com/profile/slack/edit">Gitlab</a>, <a href="https://slack.github.com/">Github</a>, <a href="https://cto-ai.slack.com/apps/A0F7VRFKN-jenkins-ci">Jenkins</a>, and <a href="https://www.atlassian.com/software/opsgenie">Atlassian Opsgenie</a>.</p><p><em>Learn more about using Slack for dev teams with their <a href="https://slack.com/resources/why-use-slack/software-development-teams-and-slack">handy handbook</a>.</em></p><p><em>Of course, you also have <a href="https://slack.com/intl/en-ca/features/workflow-automation">Workflow Builder</a> and the <a href="https://slack.dev/">Slack API</a> at your disposal.</em></p><!--kg-card-begin: html--><br><!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://lh5.googleusercontent.com/FTsHIO7yuWQV8WeYinn4_LGFkKSZy8o4lDe-SFgc7PljWTlxAlCqvoc1-Ce4YTwXhl5fDIMhtEqgbnLw4_bH1VGfIPPCCGcsWNWiv3HQT6QefotRGBZY30FwJwPEb4wd0rhdDfk"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><!--kg-card-end: html--><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>Now the power of Slack is within you. Take to the channels and reinvent your developer and DevOps workflows with the tools above or in a <a href="https://cto.ai/blog/slack-control-plane-for-devops-workflows/">single control plane within Slack</a>.</p><p>And if you’d like to make your life easier and want to take the CTO.ai Slack-first DevOps workflow platform for a free spin, just <a href="https://w.cto.ai/contact-us">let us know</a>.</p>
			</div><!-- .post-content -->
			<!-- .post-footer -->
		</article></div>]]>
            </description>
            <link>https://cto.ai/blog/slack-hacks-14-ideas-for-developer-devops-workflows-slack-aws-twilio-lyft/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272333</guid>
            <pubDate>Tue, 25 Aug 2020 15:28:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Global Mass Surveillance – The Fourteen Eyes]]>
            </title>
            <description>
<![CDATA[
Score 316 | Comments 133 (<a href="https://news.ycombinator.com/item?id=24272244">thread link</a>) | @latexr
<br/>
August 25, 2020 | https://www.privacytools.io/providers/#ukusa | <a href="https://web.archive.org/web/*/https://www.privacytools.io/providers/#ukusa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <nav id="breadcrumb" aria-label="breadcrumb">
  
  <ol itemscope="" itemtype="https://schema.org/BreadcrumbList">
    <li>
      <a href="https://www.privacytools.io/"> <span>Home</span></a>
    </li>
    
    
    <li aria-current="page" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
      
      <span itemprop="name">Providers 
      </span>
      <meta itemprop="position" content="1">
    </li>
    
    
  </ol>
</nav>


<div>
  
  <p>There's a ton of people providing services online. Discover which ones you should avoid and our recommendations for a variety of services.</p>
</div>



<p>Click on whatever service you need to view our recommendations.</p>





<img src="https://www.privacytools.io/assets/img/svg/layout/ukusa.svg" width="260" height="115" alt="UKUSA Agreement">

<p>The UKUSA Agreement is an agreement between the United Kingdom, United States, Australia, Canada, and New Zealand to cooperatively collect, analyze, and share intelligence. Members of this group, known as the <a href="https://www.giswatch.org/en/communications-surveillance/unmasking-five-eyes-global-surveillance-practices">Five Eyes</a>, focus on gathering and analyzing intelligence from different parts of the world. While Five Eyes countries have agreed to <a href="https://www.pbs.org/newshour/world/an-exclusive-club-the-five-countries-that-dont-spy-on-each-other">not spy on each other</a> as adversaries, leaks by Snowden have revealed that some Five Eyes members monitor each other's citizens and <a href="https://www.theguardian.com/uk/2013/jun/21/gchq-cables-secret-world-communications-nsa">share intelligence</a> to <a href="https://www.theguardian.com/politics/2013/jun/10/nsa-offers-intelligence-british-counterparts-blunkett">avoid breaking domestic laws</a> that prohibit them from spying on their own citizens. The Five Eyes alliance also cooperates with groups of third-party countries to share intelligence (forming the Nine Eyes and Fourteen Eyes); however, Five Eyes and third-party countries can and do spy on each other.</p>

<div>
  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Australia </li>
    <li>Canada </li>
    <li>New Zealand </li>
    <li>United Kingdom </li>
    <li>United States of America </li>
  </ol>
  
        </div>
    </div>
</div>


  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Denmark </li>
    <li>France </li>
    <li>Netherlands </li>
    <li>Norway </li>
  </ol>
  
        </div>
    </div>
</div>


  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Belgium </li>
    <li>Germany </li>
    <li>Italy </li>
    <li>Spain </li>
    <li>Sweden </li>
  </ol>
  
        </div>
    </div>
</div>

</div>




<h3>Who is required to hand over the encryption keys to authorities?</h3>

<p>Mandatory <a href="https://en.wikipedia.org/wiki/Key_disclosure_law">key disclosure laws</a> require individuals to turn over encryption keys to law enforcement conducting a criminal investigation. How these laws are implemented (who may be legally compelled to assist) vary from nation to nation, but a warrant is generally required. Defenses against key disclosure laws include steganography and encrypting data in a way that provides plausible deniability.</p>  <p><a href="https://en.wikipedia.org/wiki/Steganography">Steganography</a> involves hiding sensitive information (which may be encrypted) inside of ordinary data (for example, encrypting an image file and then hiding it in an audio file). With plausible deniability, data is encrypted in a way that prevents an adversary from being able to prove that the information they are after exists (for example, one password may decrypt benign data and another password, used on the same file, could decrypt sensitive data).</p>



<p> * (people who know how to access a system may be ordered to share their knowledge, <strong>however, this doesn't apply to the suspect itself or family members.</strong>)</p>

<h3>Related Information</h3>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Key_disclosure_law">Wikipedia page on key disclosure law</a></li>
  <li><a href="https://law.stackexchange.com/questions/1523/can-a-us-citizen-be-required-to-provide-the-authentication-key-for-encrypted-dat">law.stackexchange.com question about key disclosure law in US</a></li>
  <li><a href="https://peertube.mastodon.host/videos/watch/e09915eb-5962-4830-a02f-8da5c2b59e71">DEFCON 20: Crypto and the Cops: the Law of Key Disclosure and Forced Decryption</a></li>
</ul>

<h3 id="usa">Why is it not recommended to choose a US-based service?</h3>

<img src="https://www.privacytools.io/assets/img/svg/layout/great_seal_of_the_united_states_obverse.svg" width="200" height="200" alt="USA">

<p>Services based in the United States are not recommended because of the country's surveillance programs and use of <a href="https://www.eff.org/issues/national-security-letters/faq">National Security Letters</a> (NSLs) with accompanying gag orders, which forbid the recipient from talking about the request. This combination allows the government to <a href="https://www.schneier.com/blog/archives/2013/08/more_on_the_nsa.html">secretly force</a> companies to grant complete access to customer data and transform the service into a tool of mass surveillance.</p>

<p>An example of this is <a href="https://en.wikipedia.org/wiki/Lavabit#Suspension_and_gag_order">Lavabit</a> – a secure email service created by Ladar Levison. The FBI <a href="https://www.vice.com/en_us/article/nzz888/lavabit-founder-ladar-levison-discusses-his-federal-battle-for-privacy">requested</a> Snowden's records after finding out that he used the service. Since Lavabit did not keep logs and email content was stored encrypted, the FBI served a subpoena (with a gag order) for the service's SSL keys. Having the SSL keys would allow them to access
communications (both metadata and unencrypted content) in real time for all of Lavabit's customers, not just Snowden's.</p>

<p>Ultimately, Levison turned over the SSL keys and <a href="https://www.theguardian.com/commentisfree/2014/may/20/why-did-lavabit-shut-down-snowden-email">shut down</a> the service at the same time. The US government then <a href="https://www.cnbc.com/id/100962389">threatened Levison with arrest</a>, saying that shutting down the service was a violation of the court order.</p>

<h3>Related Information</h3>

<ul>
  <li><a href="https://www.bestvpn.com/the-ultimate-privacy-guide/#avoidus">Avoid all US and UK based services</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Surespot#History">Proof that warrant canaries work based on the surespot example.</a></li>
  <li><a href="https://en.wikipedia.org/wiki/UKUSA_Agreement">The United Kingdom – United States of America Agreement (UKUSA)</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Lavabit#Suspension_and_gag_order">Lavabit: Suspension and gag order</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Key_disclosure_law">Key disclosure law</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Portal:Mass_surveillance">Wikipedia Portal: Mass_surveillance</a></li>
</ul>




<img src="https://www.privacytools.io/assets/img/svg/layout/warrant_canary_example.svg" width="450px" alt="Warrant Canary Example">

<p>A warrant canary is a posted document stating that an organization has not received any secret subpoenas during a specific period of time. If this document fails to be updated during the specified time then the user is to assume that the service has received such a subpoena and should stop using the service.</p>

<h4>Warrant Canary Examples:</h4>

<ol>
  <li><a href="https://proxy.sh/canary">https://proxy.sh/canary</a></li>
  <li><a href="https://www.ivpn.net/resources/canary.txt">https://www.ivpn.net/resources/canary.txt</a></li>
  <li><a href="https://www.bolehvpn.net/canary.txt">https://www.bolehvpn.net/canary.txt</a></li>
  <li><a href="https://www.ipredator.se/static/downloads/canary.txt">https://www.ipredator.se/static/downloads/canary.txt</a></li>
</ol>

<h4>Related Warrant Canary Information</h4>

<ul>
  <li><a href="https://www.eff.org/deeplinks/2014/04/warrant-canary-faq">Warrant Canary Frequently Asked Questions</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Warrant_canary#Companies_and_organizations_with_warrant_canaries">Companies and organizations with warrant canaries</a></li>
  <li><a href="https://www.schneier.com/blog/archives/2015/03/australia_outla.html">Warrant canary criticism by Bruce Schneier and an example of a law against warrant canaries.</a></li>
</ul>



  </div></div>]]>
            </description>
            <link>https://www.privacytools.io/providers/#ukusa</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272244</guid>
            <pubDate>Tue, 25 Aug 2020 15:20:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Psychologists confront impossible finding, triggering a revolution in the field]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272198">thread link</a>) | @colinprince
<br/>
August 25, 2020 | https://www.cbc.ca/radio/ideas/psychologists-confront-impossible-finding-triggering-a-revolution-in-the-field-1.5344467 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/ideas/psychologists-confront-impossible-finding-triggering-a-revolution-in-the-field-1.5344467">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>In 2011, American psychologist Daryl Bem proved the impossible. He showed that precognition — the ability to sense the future — is real. His study was explosive, and shook the very foundations of psychology. Contributor Alexander B. Kim in Vancouver explores the ‘replication crisis’ and what it means for the field and beyond.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5344852.1572640305!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/data-analysis.jpg"></p></div><figcaption>Psychology’s ‘replication crisis’ inspired major changes in how researchers conduct their work across the social sciences and beyond.<!-- --> <!-- -->(SolStock/iStock)</figcaption></figure><p><span></span><span>Listen<!-- --> to the full episode</span><span>53:59</span></p><p><span><p><em>*Originally published on November 1, 2019.</em></p>  <p>In 2011, an American psychologist named Daryl Bem proved the impossible. He showed that precognition&nbsp;—&nbsp;the ability to sense the future — is real. His study was explosive, and shook the very foundations of psychology.&nbsp;</p>  <p>"This would probably be the most important research paper I would say ever published in any field, if it were true," said Jeff Galak, psychologist at Carnegie Mellon University.&nbsp;</p>  <p>"If this paper were true, our understanding of the entire world, the universe, physics, [and] psychology, for sure, would be completely different," Galak said.</p>  <p>"We would no longer see time as this linear thing that we move through, but instead something that can go forwards and backwards. And we could reach into the future and pull information from that — if it were true. And 'if 'is a big part of that statement."&nbsp;&nbsp;</p>  <h2>Replication crisis</h2>  <p>Daryl Bem is a professor emeritus of psychology at Cornell University. His paper, <em>Feeling the Future: Experimental Evidence for Anomalous Retroactive Influences on Cognition and Affect,</em>&nbsp;was published in the Journal of Personality and Social Psychology&nbsp;—&nbsp;a top-tier journal for the field.</p>  <p>"The [paper's] conclusion was ridiculous," said Chris Chambers, a professor of cognitive neuroscience at Cardiff University in Wales. He's the author of the book<em> The Seven Deadly Sins of Psychology.&nbsp;</em></p>  <p>"And this is really interesting because if a paper like this that's doing everything normally and properly can end up producing a ridiculous conclusion, then how many other papers that use those exact same methods that didn't reach ridiculous conclusions are similarly flawed?"</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>You have a right to scrutinize and verify and correct.​​​​<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Simine Vazire, psychologist&nbsp;</cite></span></blockquote>    <p>After <em>Feeling the Future</em>&nbsp;was published, a group called the Open Science Collaboration organized a massive replication study. And 270 scientists from 17 countries signed up. They picked 100 studies published in the year 2008 as their test sample — all from reputable, peer-reviewed psychology journals.&nbsp;</p>  <p>The plan was to repeat all 100 experiments exactly as described, and then see what happens. The findings came out in 2015. The results were stunning: only 36 percent of replications were successful.</p>  <h2>The ripple effect</h2>  <p>University of Toronto psychologist Michael Inzlicht was shocked to find that research papers in his own area of research no longer held water. They could not be replicated under the filter of more rigorous methodology.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_300/michael-inzlicht.jpeg 300w,https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_460/michael-inzlicht.jpeg 460w,https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_620/michael-inzlicht.jpeg 620w,https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/michael-inzlicht.jpeg 780w,https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_1180/michael-inzlicht.jpeg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/michael-inzlicht.jpeg"></p></div><figcaption>Michael Inzlicht is the principal investigator at the Toronto Laboratory for Social Neuroscience.<!-- --> <!-- -->(Submitted by Michael Inzlicht )</figcaption></figure></span></p>  <p>"I had grown up a scientist believing in the scientific method and the tools that we used, and all of a sudden, this one replication just made me question everything," said Inzlicht.&nbsp;</p>  <p>"What was real, what could I trust? The things I was studying... were they real? Could I trust them?"</p>  <p>Inzlicht is one of the psychologists leading the way to set new research standards. He attributes the lapse in his field to the tremendous pressure researchers face to produce new, high-impact research.</p>  <p>"Basic science is not always about chasing the new," said Inzlicht.&nbsp;</p>  <p>"It's not always about chasing something groundbreaking. It's about building a house. And if the foundations of the house are rotten, if from the beginning a discipline was built on shoddy foundations, the entire enterprise can fall."</p>  <h2>Building a new foundation</h2>  <p>Since 2011, standards for psychology research have indeed changed.&nbsp;</p>  <p>What's known as 'pre-registration' is becoming more common: researchers writing up how they're going to conduct a study, what their hypotheses are, and how they intend to analyze the data before doing their experiment. This protocol prevents researchers from massaging the data and reporting a positive result until they actually find one.</p>  <p>More than 200 scientific journals, both inside and outside psychology, now publish "registered reports," reporting their decision whether to accept or reject studies that are submitted before the experiments have actually been performed. So the decision is based on the proposed methodology and not how exciting the results are.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/alexander-b-kim.JPG 300w,https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/alexander-b-kim.JPG 460w,https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/alexander-b-kim.JPG 620w,https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/alexander-b-kim.JPG 780w,https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/alexander-b-kim.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/alexander-b-kim.JPG"></p></div><figcaption>Alexander Kim is a journalist and radio producer based in Vancouver.<!-- --> <!-- -->(Submitted by Alexander B. Kim)</figcaption></figure></span></p>  <p>Researchers also formed formed organizations like the Centre for Open Science and the <a href="https://improvingpsych.org/" target="_blank">Society for the Improvement of Psychological Science</a>.</p>  <p>"If you're signing up to be a scientist, you're signing up to say 'check my work'," said Simine Vazire,&nbsp;psychologist at the University of California at Davis and one of the co-founders of the Society for the Improvement of Psychological Science.&nbsp;</p>  <p>"Don't just take my word for it. Don't just trust me," said Vazire.&nbsp; "You have a right to scrutinize and verify and correct."<br> &nbsp;</p>  <p><strong>Guests in this episode:</strong></p>  <ul>   <li><strong><a href="http://www.jeffgalak.com/" target="_blank">Jeff Galak</a></strong>&nbsp;is a&nbsp;professor of marketing at Carnegie Mellon University.&nbsp;</li>   <li><strong><a href="https://psychology.cornell.edu/daryl-bem" target="_blank">Daryl Bem</a>&nbsp;</strong>is professor emeritus of psychology at Cornell University.&nbsp;</li>   <li><strong><a href="https://www.cardiff.ac.uk/people/view/133632-chambers-chris" target="_blank">Chris Chambers</a>&nbsp;</strong>is a professor of psychology specializing in cognitive neuroscience at Cardiff University in Wales. He's also the author of the book,<em> The Seven Deadly Sins of Psychology</em>.</li>   <li><strong><a href="http://http//michaelinzlicht.com/#lab-view" target="_blank">Michael Inzlicht</a></strong>&nbsp;is a professor of psychology at the University of Toronto. He's also a principal investigator at the Toronto Laboratory for Social Neuroscience.</li>   <li><strong><a href="http://https//www.simine.com/" target="_blank">Simine Vazire</a></strong>&nbsp;is an&nbsp;associate professor of psychology at U.C. Davis where she studies personality. She is one of the co-founders of the <a href="https://improvingpsych.org/&amp;nbsp;" target="_blank">Society for the Improvement of Psychological Science</a>.</li>   <li><strong><a href="https://www.cardiff.ac.uk/people/view/38108-collins-harry" target="_blank">Harry Collins</a></strong>&nbsp;is a&nbsp;distinguished research professor of social science at Cardiff University, specializing in scientific knowledge. He's the author of <a href="http://sites.cardiff.ac.uk/harrycollins/main-books/" target="_blank">several books</a> including <em>Forms of Life: The method and meaning of sociology.</em></li>   <li><strong><a href="http://https//atullett.people.ua.edu/" target="_blank">Alexa Tullet </a></strong>is an&nbsp;assistant professor of social psychology at the University of Alabama and co-founder of the Society for the Improvement of Psychological Science.</li>   <li><strong><a href="https://psychology.ucdavis.edu/people/aml" target="_blank">Alison Ledgerwood </a></strong>is a professor of psychology at U.C. Davis.<p>  <em>Special thanks to Dr. Ed Kroc, for help with statistics; Dr. Candis Callison, for help with philosophy of science; Tom Lowe, for recording Professor Collins in Wales; Emma Partridge, for booking Professor Bem; and Cited Media Productions, for supporting the making of this programme.</em></p></li>  </ul>  <hr>  <p><br> <em>** This episode was written and produced by<a href="https://alexanderbkim.wordpress.com/" target="_blank"> Alexander B. Kim</a> of <a href="https://citedpodcast.com/&amp;nbsp;" target="_blank">Cited Podast</a>,&nbsp;with support from Ideas Senior Producer&nbsp;Nicola&nbsp;Luksic.</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/ideas/psychologists-confront-impossible-finding-triggering-a-revolution-in-the-field-1.5344467</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272198</guid>
            <pubDate>Tue, 25 Aug 2020 15:15:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rip.com: Here's What Happens to Your Domains When You Die]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272178">thread link</a>) | @KaiserSanchez
<br/>
August 25, 2020 | https://www.kubera.com/blog/what-happens-to-your-domains-when-you-die | <a href="https://web.archive.org/web/*/https://www.kubera.com/blog/what-happens-to-your-domains-when-you-die">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Even experienced domainers may not know the name Igal Lichtman. The legendary domain investor was better known by his business name, Mrs Jello.<br></p><p>Over a career spanning decades, Lichtman acquired a vast portfolio of investment domains, many worth tens of thousands of dollars. But it was what happened after Lichtman passed away in 2013 that should serve as a cautionary tale to <em>all</em> domainers.</p><h2>What Happens to Your Domains When You Die?<br></h2><p>What happens to your domains <a href="https://www.kubera.com/blog/what-important-financial-information-should-my-family-know">when you die</a> depends on how you prepare for the inevitable.</p><p>In Lichtman’s case, there wasn’t nearly enough preparation, if any. When Lichtman died from cancer complications in February of 2013, his family was left with the difficult task of trying to organize and gain access to his vast portfolio of investment domains.<br></p><p>But as his family learned, Lichtman hadn’t created a clear path for his beneficiaries to take ownership of his domains. As they expired, they were <a href="https://www.thedomains.com/2013/02/22/after-75k-in-lost-domains-igal-in-death-teaches-us-we-need-an-after-life-plan/" target="_blank">auctioned off by their registrars</a>.&nbsp;<br></p><p>The same month that Lichtman died, Vodka.net sold for $20,000. Penis.net was auctioned for $5,015. And in one of the biggest sales from Lichtman’s portfolio, Vegans.com sold for $48,000.<br></p><p>This is all money that could have gone to Lichtman’s beneficiaries. They could have kept those domains as investments, or sold them for an immediate payout for Lichtman’s family. Instead, those big payouts went to the domain registrars and auction companies that facilitated the sales.<br></p><h2>What Happened To Igal Lichtman Could Happen To Anyone<br></h2><p>Igal Lichtman made a career out of investing in domains, so his death (and the subsequent loss of his entire portfolio) made waves in the domainer world.<br></p><p>But this isn’t something that only happens to professional domain investors.<br></p><p>Jane Both, a lifelong entrepreneur from Milford, Pennsylvania, was just 50 years old when she <a href="https://www.recordonline.com/article/20170331/obituaries/303319989" target="_blank">died suddenly</a> while walking her dogs in her neighborhood in late March of 2017. Both was involved in all kinds of business ventures, including Streamline Management of Port Jervis, a home inspection service. But she was also savvy when it came to domain investing. In 2013, long before many people were considering the potential of blockchain domains, Both was buying as many as she could find.<br></p><p>Her portfolio eventually consisted of more than 100 domains containing the “blockchain” keyword — including appealing domains like BlockchainManagement.com, BlockchainAssets.com, BlockchainFinance.com, BlockchainPro.com, and BlockchainTools.com.<br></p><p>But you can probably guess where this story is going. Like Lichtman, Both didn’t plan for what would happen to her domains after her death. And so, in 2018, they <a href="https://www.thedomains.com/2018/01/18/100-expiring-blockchain-domain-auctions-next-5-days/" target="_blank">began to expire and head to auction.</a><br></p><figure id="w-node-eb256527c8e9-ac468d02"><p><img src="https://uploads-ssl.webflow.com/5ded36b5e942e74b13468d23/5f32b6a8e3394406d2d74bf9_01-Image%402x.png" alt="what happens to your domains when you die"></p></figure><p>Of the more than 100 blockchain domains Both owned, many sold for thousands of dollars, and many more for hundreds. In all, her beneficiaries missed out on tens of thousands of dollars that resulted from the sale of all of Both’s domains — money that should have gone to her loved ones, but instead went to registrars and auction companies.<br></p><h2>It’s Time to Treat Domains Like Any Other Wealth Asset<br></h2><p>These stories make one thing clear: Whether you purchase domains for the express purpose of investing in them, or just own the domains for your business or personal websites, domains can be valuable and sentimental, and they should be treated like any other digital wealth asset. In the digital age, anyone who owns a domain needs a plan in place for someone to take ownership of and manage it after their death.<br></p><p>Most domain registrars have a process in place for when an account owner dies. For example, GoDaddy, one of the world’s largest domain registrars, <a href="https://www.godaddy.com/help/how-to-gain-access-to-domainsaccounts-after-owners-death-8356" target="_blank">outlines steps</a> for what to do and how to gain access to domains or accounts after their owner’s death.<br></p><p>But even when a registrar has a process in place, it can be complicated for beneficiaries who aren’t well versed in domains and digital assets. And then there’s the question of whether your beneficiaries will even <em>know</em> what domains you own, whether they have value, and how to seek access to them.<br></p><p>You can’t leave this process to chance, or just assume that your beneficiaries will know to follow your registrar’s steps to take control of your domains. You have to be proactive to protect your domain investments.<br></p><h2>How to Protect Your Domain Investments: Step By Step<br></h2><p>Ready to make sure your domains are protected in case of the worst? Here’s what you need to do.<br></p><h3>Create a Digital Inventory<br></h3><p>We rarely think about how many online accounts we create all the time. From social media, to streaming sites and Spotify, ecommerce sites, food delivery, and, of course, our domains — there are <em>tons</em> of sites that have our personal information and, oftentimes, payment information stored. Making sure your beneficiaries have access to all these accounts will greatly simplify the process of organizing and closing them after your death.<br></p><p>That’s why, for domains, but also <em>all</em> other digital assets and accounts, <a href="https://www.kubera.com/blog/using-excel-or-google-sheets-for-tracking-net-worth">everyone should have a digital inventory</a>. This should include every account you own, passwords, associated phone numbers and email addresses, and, for any accounts that require payments or renewals, the dates and costs for renewal.<br></p><p>Your digital inventory should be available <a href="https://www.kubera.com/blog/which-important-financial-documents-should-you-safekeep">both online and offline</a> (like in a safe deposit box that a trusted beneficiary can access) and should be updated regularly.<br></p><h3>Write a Digital Will<br></h3><p>If you’re a sole trader or proprietor, your business assets, including domains and other digital assets, are legally indistinguishable from you, and would be distributed <a href="https://www.kubera.com/blog/wills-trusts-and-estate-planning-not-enough-to-protect-wealth">according to your will</a>.<br></p><p>However, it’s becoming a more common practice for people who hold a variety of digital wealth assets to write a digital will, specifying exactly how they want things like their domains passed on after their death. It’s also becoming a more common practice to name a digital executor for that will — someone who has the knowledge and experience to ensure that digital assets are transferred safely and correctly.<br></p><h3>Use a Portfolio Manager That’s Made for the Digital Age<br></h3><p>It’s long been standard practice to use a portfolio manager for tracking net worth and organizing investments in one place — a good practice that makes them easier to distribute after you’re gone.<br></p><p>But as we move forward in the digital age, wealth and investments are becoming more complex, and most traditional portfolio managers aren’t up to the task of <a href="https://www.kubera.com/blog/portfolio-manager-to-track-fiat-currency-crypto-portfolios">tracking digital wealth like crypto wallets, multi-currency accounts, and domains</a>. That’s why you need a portfolio manager that’s made for the digital age. That’s why <a href="https://www.kubera.com/">you need Kubera</a>.<br></p><p>Not only does Kubera allow you to track <em>all</em> your wealth assets — from the traditional, like stocks, bonds, bank accounts, cash, and real estate, to the modern, like collectibles, crypto exchanges and wallets, domains, and other digital assets. Kubera is also made to ensure safe and secure transfer of <em>all</em> your wealth to a beneficiary in the event something happens to you. You can even set a beneficiary to receive access to your portfolio automatically if your account becomes inactive for a set period of time.<br></p><p>Kubera is the only way to manage and protect your wealth in the digital age. Ready to see for yourself? <a href="https://app.kubera.com/signup">Try all our features free for 100 days</a>.<br></p></div></div>]]>
            </description>
            <link>https://www.kubera.com/blog/what-happens-to-your-domains-when-you-die</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272178</guid>
            <pubDate>Tue, 25 Aug 2020 15:14:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Social Media Posting and Scheduling APIs of 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271513">thread link</a>) | @gbourne
<br/>
August 25, 2020 | https://www.ayrshare.com/best-social-media-posting-and-scheduling-apis-of-2020/ | <a href="https://web.archive.org/web/*/https://www.ayrshare.com/best-social-media-posting-and-scheduling-apis-of-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-node="5f340663d99e7">
	<div>
		
<p>When you manage your social media presence there are two distinct types of posts: manual and automated. </p>



<p>Manual posting and scheduling is when you type up a post and choose a time for it to be published, usually via a <a href="https://www.techradar.com/best/best-social-media-management-tools">scheduling tool</a> (there are some great ones out there). </p>



<p>Automated posting and scheduling is when system generated data automatically posts to your social media networks via your back-end system using an API. </p>



<p>For example, a game company might auto-post when a gamer enters the top-ten leaderboard. Or a news company’ back-end system sees a new breaking headline and automatically schedules the post without manual intervention. If your system has unique dynamic data you should consider publishing to your networks.</p>







<p>Ideally, all scheduling tools would provide an API to programmatically schedule post, but unfortunately most don’t or have <a href="https://buffer.com/developers/api">removed</a> their API access.</p>



<p>When building <a href="https://www.ayrshare.com/">Ayrshare</a> as an API-first social media posting and scheduling tool, we did a lot of research on the APIs available in the market. We would like to share what we have found. </p>



<p>Each tool is broken down by the site name, tagline, API documentation, and pricing. Pricing will vary depending upon the features selected.</p>







<h2>Top Social Media Network APIs</h2>



<h3>1. <a href="https://www.ayrshare.com/"><span><strong>Ayrshare</strong></span></a></h3>



<p><strong>Tagline:</strong> Powerful APIs that enable you to send social media posts effortlessly.</p>



<p><strong>API Documentation</strong>: <a href="https://docs.ayrshare.com/rest-api/overview">link</a></p>



<p><strong>Pricing</strong>: <a href="https://www.ayrshare.com/#pricing">$4.99</a> a month for full access</p>







<h3>2. <a href="https://hootsuite.com/"><span><strong>HootSuite</strong></span></a></h3>



<p><strong>Tagline:</strong> Easily manage all your social media and get results with Hootsuite.</p>



<p><strong>API Documentation</strong>: <a href="https://platform.hootsuite.com/docs/api/index.html#section/Introduction">link</a></p>



<p><strong>Pricing</strong>: <a href="https://hootsuite.com/plans">$29 to $599</a> a month</p>







<h3>3. <a href="https://hootsuite.com/"><span><strong>Buffer</strong></span></a></h3>



<p><strong>Tagline:</strong> Tell your brand’s story and grow your audience with a publishing, analytics, and engagement platform you can trust.</p>



<p><strong>API Documentation</strong>: <a href="https://buffer.com/developers/api">link</a> – no new developer accounts after 2019</p>



<p><strong>Pricing</strong>: <a href="https://buffer.com/pricing/publish">$15 to $99</a> a month</p>







<h3>4. <strong><a href="https://www.socialoomph.com/"><span>SocialOomph</span></a></strong></h3>



<p><strong>Tagline:</strong> Boost your productivity with advanced post scheduling tools.</p>



<p><strong>API Documentation</strong>: <a href="https://www.socialoomph.com/developers/api/">link</a></p>



<p><strong>Pricing</strong>: <a href="https://www.socialoomph.com/pricing/">$20 to $83</a> a month</p>







<h3>5. <strong><strong><a href="https://amplifr.com/"><span>Amplifr</span></a></strong></strong></h3>



<p><strong>Tagline:</strong> In&nbsp;all social networks from one window, metrics from posts to&nbsp;projects, collaboration and automation of&nbsp;routine.</p>



<p><strong>API Documentation</strong>: <a href="https://amplifr.docs.apiary.io/#">link</a></p>



<p><strong>Pricing</strong>: <a href="https://amplifr.com/en/prices/">$30 to $500 a month</a></p>







<p>If you have thoughts on these tools or know of others we didn’t mention, drop us a <a href="https://www.ayrshare.com/cdn-cgi/l/email-protection#b2c1c7c2c2ddc0c6f2d3cbc0c1dad3c0d79cd1dddf">line</a> to let us know.</p>




	</div>
</div></div>]]>
            </description>
            <link>https://www.ayrshare.com/best-social-media-posting-and-scheduling-apis-of-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271513</guid>
            <pubDate>Tue, 25 Aug 2020 14:12:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Avo Eliminates Biases in Hiring]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271434">thread link</a>) | @kelseyfecho
<br/>
August 25, 2020 | https://www.avo.app/blog/how-we-hire-at-avo | <a href="https://web.archive.org/web/*/https://www.avo.app/blog/how-we-hire-at-avo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Every application is reviewed blind to ensure fairness.</p><p>Avo is committed to hiring talent of diverse backgrounds because not only does <a href="https://www.weforum.org/agenda/2019/04/business-case-for-diversity-in-the-workplace/">the data now demonstrate the business validity</a> of having an inclusive workplace, but because it’s the right thing to do.&nbsp;</p><h3>With Systematic Structures Against Bias</h3><p>It is one of my deep passions to combat the unconscious bias that most of us have (I recommend taking the <a href="https://implicit.harvard.edu/implicit/takeatest.html">Harvard managed test for unconscious bias</a>). Unfortunately, as Iris Bohnet discusses in In <a href="https://www.goodreads.com/book/show/27311743-what-works#:~:text=Gender%20equality%20is%20a%20moral%20and%20a%20business%20imperative.&amp;text=Presenting%20research%2Dbased%20solutions%2C%20Iris,and%20the%20lives%20of%20millions.">What Works: Gender Equality by Design</a>, it’s difficult to rewire our brains. She even refers to research showing how we subject ourselves to our pendulum swinging backwards whenever we try to educate ourselves (much like we think we deserve a break from being unbiased after the hard work of learning how not to be biased). Instead, the most efficient tool to combat bias is to structure hiring and compensation processes so we remove any opportunity to act on bias.&nbsp;</p><p>When we looked into how we could make this a reality for hiring at Avo, we found <a href="https://www.beapplied.com/">Applied</a>. It’s a&nbsp; platform designed following best practices to prevent the opportunity for unconscious bias. Instead of focusing on the person’s background, the Applied process asks the candidate to reflect on situations related to the role, and enables a structured, unbiased review of the person’s potential and ability.</p><h3>How We Use Applied At Avo</h3><p>These questions outline situations that may come up – directly or indirectly related to the role. Some of the situations are complicated, and this is a great opportunity to shed a light on how aligned Avo and the candidate are in how to handle them. The answers are then anonymized and randomized for a blind review.. It means that each answer is reviewed individually, without us knowing anything about the candidate, or their other answers.&nbsp;&nbsp;</p><p>When hiring for <em>Growth Marketing</em> we asked what recent campaign for a technical product stood out to them. When hiring for <em>Product Designer</em> we ask how to respond to a customer feature request or inconsiderate feedback from someone in a leadership position. When hiring for <em>Infrastructure Developer</em> we ask how they’d address a design issue in the core data model.&nbsp;&nbsp;</p><p>It’s our job as founders to find highly skilled individuals for each and every role. It’s hard to adequately account for one’s own biases, even when acknowledged and worked against. And as a data scientist, I believe in a systematic solution. That’s why Avo chose Applied’s blind process as a way to ensure fairness throughout the process, which is really important to me, personally.&nbsp;</p><p>Working against bias is more than addressing the obvious gender and race discrimination we face in the tech industry. It’s also a matter of making sure our culture is accessible to anyone who does good work, and good work will be celebrated no matter who does it. There are also those who feel like they might not fit a stereo-type of the industry, or those who live far away from tech-centric cities. And even still, some feel like they may have never been given the opportunity to demonstrate their skills.&nbsp;</p><p>We find that with this process, we’re able to really get a sense of the person’s fit for the role; removing any bias we might have had, consciously or subconsciously, on the person’s age, gender, sexuality, race, nationality, location, or background.&nbsp;</p><p><strong>What ultimately matters is we’re able to hire the right people, fast, and that the people we want to work with are willing to go through this process with us.&nbsp;</strong></p><h3>What do the applicants think?&nbsp;</h3><p>The feedback we’ve received so far has been outstanding. 9 out of 10 would recommend this process – and that includes a lot of people we could not hire. To exemplify, here are a few anonymous quotes from people who have gone through this process:</p><p>"I wish more companies assessed their candidates this way. I hope this eliminates bias."<br></p><p>“Just applied, I LOVED that application process"</p><p>"That fact y'all are actually testing their knowledge is amazing and not just judging a book by the cover, or <em>well</em> – <em>person</em> by a piece of paper (resume!). I like the alternative approach of blind question-answer review and screening for hiring bias!"<br></p><p>"I totally enjoyed this application process compared to other application formats. I'm reflecting and thinking based on the given scenarios. I have learned a lot and I love it."</p><p>We find this dive into our candidates’ problem-solving skills, which ultimately is what we’re hiring them for, has been a huge success. Aligning on ability seems fairer than judging someone based on what they look like or the logos on their CVs. And we found that the people we’ve met in our hiring process love that we let their work stand for itself; regardless of their background, where they’re from, or what they’ve done in the past.&nbsp;</p><div><p>My personal goal for 2020 was to maintain a gender balance in Avo through our 2020 hiring. Now we’ve succeeded in making sure more than 50% of our team is female identifying. This is a rare feat, which I’m proud of. I also understand that this means it’s time to set more aggressive goals. It is imperative to my co-founder, Solvi, and myself, to continue to build inclusive culture at Avo. </p><p>– Stefania Olafsdottir<br>Avo CEO and co-founder</p></div><p><strong>What are you waiting for, we are hiring for two roles!&nbsp;</strong></p><p><a href="https://www.avo.app/jobs"><strong>Now is the time to apply. We want you to join us &gt;&gt;&nbsp;</strong></a></p></div></div>]]>
            </description>
            <link>https://www.avo.app/blog/how-we-hire-at-avo</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271434</guid>
            <pubDate>Tue, 25 Aug 2020 14:02:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You Need a Nemesis]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271340">thread link</a>) | @thinking_slow_
<br/>
August 25, 2020 | https://www.animalz.co/blog/you-need-a-nemesis/ | <a href="https://web.archive.org/web/*/https://www.animalz.co/blog/you-need-a-nemesis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2280" role="article" itemscope="" itemtype="http://schema.org/BlogPosting">

	

	<div>

		<div>
			<section>
														<p><img src="https://2l4ff1gokdmn317w442ckjyu-wpengine.netdna-ssl.com/wp-content/uploads/intervention/cache/attentie-attentie-ig7vN6OkGNE-unsplash-scaled-e1598344745396-2048x1234-2212294583.jpg">
					</p>
								<!-- wp:paragraph -->
<div><p>It isn’t always enough to cast your company as the hero—sometimes, you also need a villain. </p><p>DHH’s recent spat with Apple turned a pedestrian product launch into an epic battle between a corporate juggernaut and the plucky underdogs of Basecamp. A <a href="https://twitter.com/dhh/status/1275070000814948353?s=20">hundred thousand product sign-ups</a> followed.</p><p>Much of Box’s earliest press coverage can be traced back to a <a href="https://techcrunch.com/2015/01/22/box-has-always-been-about-reshaping-enterprise-software/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAFl7N1icsmzGQEIAh-x7jAIvo5TOrq1tC3fuAZy3v6HFQf0EJcKKYAC1gGUZ_FQ5rE4faMDZBouACHEgy4i-eIi8ZQkqZOrbDWNAMa1kckujCUYiOEQ9nHFU2q4Q9KxaFRQ4oQEAggxM_KG3Wll7xxAx_dB2tUUFhfKO-Spsa_Hf">towering billboard</a> on California’s Route 101, proudly proclaiming: <em>“Box.net is like Sharepoint, but without the servers, setups costs, manuals, downtime, firewall restrictions . . .”</em></p><p>To this day, I can’t think of HubSpot without imagining a shadowy “<a href="https://blog.hubspot.com/blog/tabid/6307/bid/2989/inbound-marketing-vs-outbound-marketing.aspx">outbound marketer</a>” physically cramming spam mail through my letter box.</p><p>These brands are case studies in what Paul Graham called “<a href="https://twitter.com/paulg/status/1273233413261209600?s=20">beef marketing</a>”: find the adversary you have a strategic, beneficial beef with, and cast them as the villain in your story.</p></div>
<!-- /wp:paragraph -->

<!-- wp:more -->
			</section>
		</div>

	</div>

	<div>

		<div>
			<section>
				
<!-- /wp:more -->

<!-- wp:heading -->
<h2>Villains Make Heroes Look Better</h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<div><p>HubSpot, Basecamp, and Box understand a core tenet of storytelling: villains exist to make heroes look better.</p><p>Without a force to fear, fight, and eventually overcome, your story isn’t worth telling. Remove Sauron from <em>The Lord of the Rings </em>and you have a flaccid tale of Frodo’s privilege and family squabbles. Without the nemesis of “outbound marketing,” the redemption offered by inbound marketing is meaningless.</p><p>There’s a lot going for the hero vs. nemesis dynamic:</p></div>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul><li><strong>Build empathy.</strong> A day in the life of your target customer is fraught with frustration, like—in the case of HubSpot’s target audience—an inbox of junk mail, obnoxious telesales callers and internet-ruining pop-up ads. Vilification allows you to call out the struggle, empathize with the reader, and nudge your product into view:<em> “You’re sick of this. So are we. Here’s the product we built to fix it.”</em></li><li><strong>Differentiate. </strong>Most marketing is pretty saccharine. Measured criticism and, heaven forbid, acknowledging the existence of your competitors, can cut through the mix like nothing else. Picking a fight—albeit in a measured, strategic way—is just downright interesting.</li><li><strong>Change your industry.</strong> DHH’s critique of Apple gained traction because of its valid concern: monopoly power. Many of the story’s loudest amplifiers were other company founders who had fallen afoul of seemingly arbitrary judgments from Apple. Criticizing Apple led to Hey’s approval and, according to DHH, it “<a href="https://twitter.com/dhh/status/1276158293375934470?s=20">paves an illuminated path</a>” for other apps to follow.</li></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p>HubSpot, Basecamp, and Box illustrate three different approaches to “beef marketing,” and three different ways you can cast a villain in your own story. They are (in order of ascending spiciness):</p>
<!-- /wp:paragraph -->

<!-- wp:image {"id":2285,"sizeSlug":"large"} -->
<figure><img src="https://2l4ff1gokdmn317w442ckjyu-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/You-Need-a-Nemesis-2.png" alt=""></figure>
<!-- /wp:image -->

<!-- wp:heading -->
<h2>You vs. the Legacy Solution</h2>
<!-- /wp:heading -->

<!-- wp:heading {"level":4} -->
<h4>Spice Level: 🌶️</h4>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<div><p>HubSpot’s vocal opposition to “outbound marketing” is an example of squaring off with a legacy solution—an older, dated, and relatively inefficient way of achieving the same goals as your product.</p><p>Spreadsheets are the classic legacy solution.<a href="https://twitter.com/thinking_slow/status/1255874409086287879?s=20"> As this viral tweet posits</a>, the chances are high that someone, somewhere, is using the humble spreadsheet to achieve pretty much the same thing your product does. In the same way, outbound marketing is just an amalgamation of lots of legacy marketing tactics—like cold calling and direct mail.</p></div>
<!-- /wp:paragraph -->

<!-- wp:html -->
<blockquote><p lang="en" dir="ltr">*spreadsheets* are the main competitor for 90% of software startups</p>— Ryan Law (@thinking_slow) <a href="https://twitter.com/thinking_slow/status/1255874409086287879?ref_src=twsrc%5Etfw">April 30, 2020</a></blockquote> 
<!-- /wp:html -->

<!-- wp:paragraph -->
<div><p>Legacy solutions are soft targets for vilification because they’re often processes or products so old as to be virtually faceless. You can criticize spreadsheets freely: they’re slow, prone to human error, and difficult to scale, and Excel’s board members won’t take offense at the critique. Similarly, outbound marketing is a total straw man: it isn’t a person, or a company, or really even a single process, so there’s nobody to resist the critique.</p><p>As a result, any company can cast a legacy solution as the villain of their story. Many do:</p></div>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul><li>Coda’s entire go-to-market messaging is built around its opposition to spreadsheets, epitomized by the tagline <em>“</em><a href="https://coda.io/welcome" target="_blank" rel="noreferrer noopener"><em>Enough of this sheet</em></a>.<em>”</em></li><li>Vyond’s animation software <a href="https://www.vyond.com/resources/the-6-best-business-presentation-software-alternatives-to-powerpoint/" target="_blank" rel="noreferrer noopener">takes aim at PowerPoint</a>, another last-generation product in the same vein as Excel.</li><li>Greenlight Guru pits itself against old-fashioned processes and “<a href="https://www.greenlight.guru/blog/legacy-quality-management-systems" target="_blank" rel="noreferrer noopener"><em>the lure of legacy quality management systems</em></a>,<em>”</em> highlighting the pitfalls of using paper or <em>“digital paper”</em> solutions like Google Docs.</li></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p>These legacy solutions are easy enough to find. They’re the products and processes your product is bought to replace, discussed in every sales call and likely still used by laggardly hold-outs. If in doubt—trash-talk the spreadsheet.</p>
<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2><strong>You vs. the Big Guy/Gal</strong></h2>
<!-- /wp:heading -->

<!-- wp:heading {"level":4} -->
<h4>Spice Level: 🌶️🌶️</h4>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<div><p>Basecamp vs. Apple is an example of taking up arms against your industry’s biggest players. It works because most of us <a href="https://hbr.org/2010/11/capitalizing-on-the-underdog-effect">enjoy rooting for the underdog</a>. We like to see small, plucky startups overcoming the odds and beating faceless corporate behemoths.</p><p>In the Apple example, DHH used the ubiquity of a globally recognized brand to raise awareness for a less famous product. His bombastic <a rel="noreferrer noopener" href="https://twitter.com/dhh/status/1272968382329942017?s=20" target="_blank">tweetstorms</a> and <a rel="noreferrer noopener" href="https://m.signalvnoise.com/on-apples-monopoly-power-to-destroy-hey/" target="_blank">blog posts</a> garnered coverage from media outlets like Wired, TechCrunch, and Engadget. By piggybacking on the vaunted Apple brand, Basecamp turned a pedestrian problem—app store regulation—into a huge PR coup.</p></div>
<!-- /wp:paragraph -->

<!-- wp:html -->
<blockquote><p lang="en" dir="ltr">Like any good mafioso, they paid us a visit by phone. Stating that, firstly, that smashing our windows (by denying us the ability to fix bugs) was not a mistake. Then, without even as much of a curtesy euphemism, said they'd burn down our store (remove our app!), lest we paid up.</p>— DHH (@dhh) <a href="https://twitter.com/dhh/status/1272969688507539457?ref_src=twsrc%5Etfw">June 16, 2020</a></blockquote> 
<!-- /wp:html -->

<!-- wp:paragraph -->
<div><p>Like legacy solutions, huge companies are relatively easy targets. A company of Apple’s size is used to criticism and weathers it on a regular basis (as <a href="https://twitter.com/Austen/status/1273236329178869761?s=20">Austen Allred</a> points out, <em>“Apple has plenty of experience with ‘I don’t care what you think’ as a stance”</em>). The blow is softened further by the decision to attack a nebulous, unsexy part of the bigger Apple business—App Store regulation instead of, say, the iPhone.</p><p><a rel="noreferrer noopener" href="https://wistia.com/" target="_blank">Wistia</a> is another company that’s adopted a strategic beef with an industry giant: YouTube. The giant video platform is referred to as a<em> “<a rel="noreferrer noopener" href="https://wistia.com/learn/marketing/where-to-share-your-brands-video-content-besides-youtube" target="_blank">legacy social network</a>,”</em> with warnings made to avoid a<em> “world where Google keeps your traffic, owns your subscribers, and controls their viewing experience.”</em> There’s even a guide that walks the reader through the steps required to <a rel="noreferrer noopener" href="https://wistia.com/learn/marketing/how-to-delete-your-youtube-channel" target="_blank">delete their YouTube channel</a>.</p></div>
<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2><strong>You vs. your Competitors</strong></h2>
<!-- /wp:heading -->

<!-- wp:heading {"level":4} -->
<h4>Spice Level: 🌶️🌶️🌶️</h4>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<div><p>Box took beef marketing to its logical conclusion by leveling criticism at the company’s direct competitors. Instead of tip-toeing, Box went<a href="https://techcrunch.com/2015/01/22/box-has-always-been-about-reshaping-enterprise-software/"> straight for the jugular</a>.</p><p>Many companies are reluctant to acknowledge the existence of their competitors, but loyal customers are not the product of information asymmetry. Most customers already know about your competitors.</p></div>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Against that backdrop, Box understands that an honest critique of the competition is a powerful differentiator. It’s a chance to make the comparison on your terms. It raises awareness for your product among the very customer base you’re trying to court. It’s useful for the customer, and it oozes confidence.<br></p>
<!-- /wp:paragraph -->

<!-- wp:image {"id":2283,"sizeSlug":"large"} -->
<figure><img src="https://2l4ff1gokdmn317w442ckjyu-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/image-10.png" alt="box-billboard.jpg"></figure>
<!-- /wp:image -->

<!-- wp:paragraph -->
<div><p><a href="https://techcrunch.com/2015/01/22/box-has-always-been-about-reshaping-enterprise-software/">Source</a></p><p>Box was able to make these feature comparisons because they took pains to offer a truly competitive product. You can likely do the same: most founders aim to build products that are better and different than anything that’s come before. There’s no need to be coy when you’ve built a best-in-class product—calling out the limitations of competitors is fair game.</p></div>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<div><p>Even without feature parity, direct comparisons can work in your favor: if you’re not strictly <em>better, </em>highlight how you’re <em>different.</em></p><p><a rel="noreferrer noopener" href="https://www.podia.com/" target="_blank">Podia</a> is an example for competitor critique done well. They harness a strategy we call “competitor alternative” content: using the natural search volume for keywords like “<a rel="noreferrer noopener" href="https://www.podia.com/clickfunnels-alternative" target="_blank">clickfunnels alternative</a>” or “<a rel="noreferrer noopener" href="https://www.podia.com/teachable-alternative" target="_blank">teachable alternative</a>” to create search-friendly comparison pages. Each page includes testimonials from post-switch users, a direct feature comparison, and a clear product call-to-action.</p></div>
<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2>Crying Wolf</h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<div><p>The power of a beef marketing strategy stems largely from its rarity; few companies call out their rivals, so we take notice when one does. We don’t follow brands that cry wolf, because the strategy loses efficacy with each subsequent crusade (case in point: I’m starting to develop cynicism around Basecamp’s ongoing feud with </p><a href="https://www.animalz.co/blog/thought-leadership-content/"><s>offices</s> <s>meetings</s> <s>email</s> big tech</a><p>).</p><p>If you want to incorporate the power of beef into your marketing, use it sparingly and deliberately.</p></div>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<div><p>Each of the companies covered here—HubSpot, Box, Basecamp, Coda, Wistia, and Podia—spend far more time and energy on the “hero” part of their marketing (building incredible products, adding value through content) than they do the “nemesis” portion. They use villains as a point of contrast—a way of bringing their great work into sharp relief.</p><p><em>H/T to Benyamin Elias for introducing me to the term beef marketing <a rel="noreferrer noopener" href="https://masters.substack.com/p/oatly-picking-a-fight-marketing" target="_blank">in his newsletter</a>.</em></p></div>
<!-- /wp:paragraph -->				<div>
	
	<p><img src="https://2l4ff1gokdmn317w442ckjyu-wpengine.netdna-ssl.com/wp-content/uploads/2019/06/ryanlaw-125x125.png" width="125" height="125" alt="Ryan Law"></p><h5><a href="https://www.animalz.co/blog/author/ryan-law/">
		Ryan Law	</a></h5>

			<a href="https://twitter.com/thinking_slow" target="_blank">
			<svg><use xlink:href="#icon-twitter"></use></svg> Follow @thinking_slow		</a>
	
	<p>Ryan is the Director of Marketing at Animalz, an agency that provides high-end content marketing solutions to SaaS and tech companies.</p>
</div>			</section>
		</div>

		
	</div>

	

</article></div>]]>
            </description>
            <link>https://www.animalz.co/blog/you-need-a-nemesis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271340</guid>
            <pubDate>Tue, 25 Aug 2020 13:52:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I set my own salary, it blows peoples minds]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24271143">thread link</a>) | @LatteLazy
<br/>
August 25, 2020 | https://granttree.co.uk/i-set-my-own-salary-it-blows-peoples-minds/ | <a href="https://web.archive.org/web/*/https://granttree.co.uk/i-set-my-own-salary-it-blows-peoples-minds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>Happy Bossâ€™s Day! Or is it Merry Bossâ€™s day? Come to think about it, what even is Bossâ€™s day? It sounds like a holiday invented by a search engine or a particularly cloying batch of Hallmark interns.</span></p><p><span>It shouldnâ€™t bother me, I suppose. I’m my own boss, like everyone else at GrantTree. Itâ€™s my day too. So let’s just pretend todayâ€™s a nice excuse for me to buy myself a new mug. We’ll ignore the fact that asking people to thank their boss for being nice is…well…absurd.<br> </span></p><p><span>In truth, there are no â€˜bossesâ€™ at GrantTree. We embrace a unique organisational philosophy called Open Culture, where there are no managers, no subordinates, no hierarchy of personnel. Each employee has autonomous control, or â€˜domainâ€™, over their specific responsibilities. The companyâ€™s functions are assigned to employees (we call them partners) who are interested and qualified to manage them. </span></p><p><span>For example, Iâ€™m in charge of writing GrantTreeâ€™s blog posts. While I can ask my colleagues for their input, Iâ€™m under no obligation to change what I write. There are ways for my colleagues to intervene if I publish something that could damage the company. But otherwise I have free rein. Iâ€™m trusted to do a good job. </span></p><p><span>This isnâ€™t to say thereâ€™s no hierarchy at GrantTree. There is a hierarchy of work. Writing blog posts is part of the work of Marketing, which is part of the work of our Tax Credits business. In this model, work is subordinate to other kinds of work. Blog posts ultimately serve our Tax Credits business, for instance. While still relatively flat, this organisation creates structure.</span></p><p><span>The lack of a â€˜personnel hierarchyâ€™ means each person can make important decisions within their sphere of influence and accountability. We call this system self-management. Self-management has some interesting consequences, aside from the fact I have to write my own Bossâ€™s Day card. For one thing, I canâ€™t get promoted. Not in the traditional sense. Thereâ€™s no â€˜ladderâ€™ to climb. I can choose to take on more responsibility by signing up for more duties, but thereâ€™s no top-down system of appraisal and reward. No one will sit me down in a yearâ€™s time and give me a raise. </span></p><p><span>So what do I do if I deserve a raise? Simple. I give myself one. </span></p><p><span>At GrantTree, we set our own pay. </span></p><p><b>Yes, I really do set my own pay</b></p><p><span>Having partners set their own pay is the ultimate expression of the self-management philosophy. Companies often use self-management as a millennial-baiting euphemism for a handful of fairly superficial freedoms like working remotely or wearing shorts in the office. </span></p><p><span>True self-management goes far beyond relaxing company etiquette. It requires taking control from the upper echelons of management and sewing it into the primary responsibilities of every single employee. Thereâ€™s no better (or more challenging) example of this than empowering staff to adjust their own pay. </span></p><p><span>When I talk to my friends and family about GrantTreeâ€™s radical practices, they give me a suspicious look. But when it comes to the idea of setting my own salary, they look almost aghast. Then they’ll usually ask me â€˜why donâ€™t you just quadruple your salary and be done with it?â€™</span></p><p><span>The simple answer is I, like most people, wouldnâ€™t do that. GrantTree expects partners to act responsibly. Our hiring process thoroughly tests a candidateâ€™s development and maturity. If someone were short-sighted enough to raise their pay to exorbitant levels, they probably wouldn’t be hired in the first place.</span></p><p><span>But moving past this silly example, what would happen if I felt I deserved a reasonable raise? </span></p><p><b>How I change my pay </b></p><p><span>In most jobs, salaries are set by negotiation – a tug of war between company and employee. Salaries are reflections of more than an employeeâ€™s development or market value. They incorporate the strength of both sidesâ€™ bargaining positions and their ability to argue their case. GrantTree removes negotiation from the procedure and places the decision entirely on the shoulders of the partner, via a process called Pay Self-Assessment (PSA for short). Hereâ€™s how it works.</span></p><p><span>There are four stages: We collect data relevant to our salary and performance, we write a proposal for a new salary based on this data, we receive feedback on our proposal and we make a final decision about our pay. </span></p><p><span>1) Data Collection </span></p><p><span>This is where I collect data that will inform my decision about what my salary should be, including information about my performance, my career progression, the market value of my role (i.e. what I could be earning given my skills and experience), and an analysis of the impact my raise will have on the companyâ€™s budgets. Then I look at what this data says. If, for example, the evidence shows I have grown professionally and that the market value for my skills has increased, I can work out a numerical value for my wage increase. Of course, the data could also could lead me to conclude that I should be paid less. PSA isnâ€™t just about raises. Pay decreases are also possible.</span></p><p><span>2) PSA Proposal</span></p><p><span>I then compile this information into a PSA Proposal; a form in which I state my current pay, my proposed new salary, and an explanation for how the data and evidence I have collected supports my proposal for a pay raise. For example, I would point to how the data I have collected indicates professional growth and my market value has increased.</span></p><p><span>3) PSA Feedback</span></p><p><span>A number of my colleagues – those who supplied evidence in the data collection stage – will then review my PSA Proposal to provide feedback and ask questions about the data Iâ€™ve provided. For example, they could suggest that Iâ€™ve misinterpreted the budgetary impact of my proposed wage increase, and that I should lower it. This feedback isnâ€™t binding. Itâ€™s there to advise me on the best course of action, for both me and the company. Â&nbsp;</span></p><p><span>4) PSA Decision</span></p><p><span>Finally, I publish my Pay Decision. This confirms my new salary and also allows me the opportunity to answer questions or concerns my colleagues posed in their feedback to my PSA Proposal. My new salary will take effect the next pay cycle. And voila. Thatâ€™s it. I have my pay raise.</span></p><p><span>The PSA process might seem strange. It did to me, at first. I used to work for a large PR firm where the process for granting raises and promotions was both inscrutable and strictly controlled. But now I can see the benefits of this approach. While a lot of companies underpay employees that have been with them a long time, the PSA process allows us to set our wage at a level that reflects our value to the company.</span></p><p><span>However you prefer to be managed, I hope you feel valued and fairly paid. If you do have a nice manager, maybe get them a card for Bossâ€™s day. Or not. Itâ€™s a silly idea, anyway. </span></p></div></div>]]>
            </description>
            <link>https://granttree.co.uk/i-set-my-own-salary-it-blows-peoples-minds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271143</guid>
            <pubDate>Tue, 25 Aug 2020 13:35:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gitpod is now Open Source]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24271090">thread link</a>) | @henningcash
<br/>
August 25, 2020 | https://www.gitpod.io/blog/opensource/ | <a href="https://web.archive.org/web/*/https://www.gitpod.io/blog/opensource/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As of today Gitpod is open source under the AGPL license at <a href="https://github.com/gitpod-io/gitpod" target="_blank" rel="nofollow noopener noreferrer">github.com/gitpod-io/gitpod</a>. This allows the community to participate in the development of Gitpod, provides more transparency and makes it even easier for developers to use and integrate Gitpod in their workflows.</p>
<p>For those of you who know us, this probably does not come as a big surprise. Working in open source is in our DNA and everything we’ve created over the past 10 years, including <a href="https://github.com/eclipse-theia/theia" target="_blank" rel="nofollow noopener noreferrer">Theia</a>, <a href="https://github.com/eclipse/xtext" target="_blank" rel="nofollow noopener noreferrer">Xtext</a>, <a href="https://github.com/eclipse/openvsx" target="_blank" rel="nofollow noopener noreferrer">Open VSX</a> and many other projects have been open source. In fact, Gitpod was our only closed-source project and it is a relief to change that going forward.</p>

<p>Contributing to Gitpod should be easy and accessible for everyone. All contributions are welcome, including pull requests, issues, documentation as well as updates and tweaks, blog posts, tutoials, and more. Please head over to <a href="https://github.com/gitpod-io/gitpod" target="_blank" rel="nofollow noopener noreferrer">Github</a> to find out about the various ways you can contribute and join our <a href="https://community.gitpod.io/" target="_blank" rel="nofollow noopener noreferrer">Gitpod Community</a>.</p>
<p>Over the past year, Gitpod has simplified contributions to many open source projects (see <a href="https://contribute.dev/" target="_blank" rel="nofollow noopener noreferrer">contribute.dev</a> for examples). Today, everyone in our team is excited to share our own streamlined development pipeline including Kubernetes preview deployments, an aggressively cached build system, our own slim and fast CI system and of course Gitpod, which continuously beams us into ready-to-code (and debug) dev environments. <a href="https://github.com/csweichel" target="_blank" rel="nofollow noopener noreferrer">Chris</a> gave a great talk about this setup earlier this year 👇</p>
<div> <p> <iframe title="" src="https://www.youtube.com/embed/dFMpXUsJcGM?rel=0" allowfullscreen=""></iframe> </p> </div>
<p>Naturally, we develop Gitpod in Gitpod. This allows the  whole team  to spin up fully initialized, remote dev environments on any branch at any time. </p>
<p>In line with the <a href="http://cloudscaling.com/blog/cloud-computing/the-history-of-pets-vs-cattle/?utm_source=thenewstack&amp;utm_medium=website&amp;utm_campaign=platform" target="_blank" rel="nofollow noopener noreferrer">pets vs. cattle</a> analogy of the cloud-native world, we treat dev environments as automated (yet customizable) resources you can spin up when you need them and close down (and forget about) when you are done with your task. Once you experience the peace of mind of automated, ephemeral dev environments you never want to go back.</p>
<p>Sven will run a webinar next week on Thursday, where we will showcase how we use Gitpod internally at Gitpod and how much it improves our workflow. Hope to see you there! </p>



<p>The <a href="https://www.gitpod.io/pricing/#" target="_blank" rel="nofollow noopener noreferrer">SaaS offering of gitpod.io</a> remains the easiest way to streamline your development workflows with continuously prebuilt dev environments. </p>
<p>In case you want to host Gitpod on your own infrastructure or private cloud, starting today, Gitpod Self-Hosted is free for unlimited users. Organizations using Gitpod Self-Hosted can purchase an enterprise license in order to get additional features like:</p>
<ul>
<li><a href="https://www.gitpod.io/features/#snapshot" target="_blank" rel="nofollow noopener noreferrer">Snapshots</a> (share a reproducible workspace with your team)</li>
<li><a href="https://www.gitpod.io/features/#share" target="_blank" rel="nofollow noopener noreferrer">Live Share</a> (invite others into your running workspace)</li>
<li><a href="https://www.gitpod.io/features/#prebuilt" target="_blank" rel="nofollow noopener noreferrer">Unlimited Prebuilds</a> (making ephemeral dev environments possible)</li>
<li>Admin Dashboard</li>
</ul>
<p>Offering a paid plan for enterprises makes it possible for us to keep working towards building a new category in developer tooling, which completes modern DevOps pipelines. In the future we will add additional functionality to both the open source code as well our paid offering.</p>
</div></div></div>]]>
            </description>
            <link>https://www.gitpod.io/blog/opensource/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271090</guid>
            <pubDate>Tue, 25 Aug 2020 13:28:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mathematical Structure of Particle Collisions Comes into View]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24270579">thread link</a>) | @rbanffy
<br/>
August 25, 2020 | http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view | <a href="https://web.archive.org/web/*/http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span><br></span><span>W</span>hen particle physicists try to model experiments, they confront an impossible calculation—an infinitely long equation that lies beyond the reach of modern mathematics.&nbsp;<br></p>

<p>Fortunately, they can generate largely accurate predictions without seeing this arcane math all the way through. By cutting the calculation short, scientists at CERNâ€™s Large Hadron Collider in Europe make forecasts that match events they actually observe when they send subatomic particles barreling toward each other around a nearly 17-mile track.</p>
<p>Unfortunately, the era of agreement between forecast and observation may be ending. As measurements grow more precise, the approximation schemes theorists use to make predictions may not be able to keep up.</p>
<p>â€œWeâ€™re getting close to exhausting what can be done,â€� said&nbsp;<a href="https://theory.cern/roster/duhr-claude" target="_blank">Claude Duhr</a>, a particle physicist at CERN.&nbsp;</p>
<p>But&nbsp;<a href="https://link.springer.com/article/10.1007/JHEP02(2019)139" target="_blank">three</a>&nbsp;<a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.123.201602" target="_blank">papers</a>&nbsp;from a group of physicists led by&nbsp;<a href="https://amplitudesatpadova.wixsite.com/amplitudes-at-padova" target="_blank">Pierpaolo Mastrolia</a>&nbsp;of the University of Padua in Italy and&nbsp;<a href="https://www.ias.edu/scholars/sebastian-mizera" target="_blank">Sebastian Mizera</a>&nbsp;of the Institute for Advanced Study in Princeton, New Jersey, have revealed an underlying mathematical structure in the equations. The structure provides a new way of collapsing interminable terms into just dozens of essential components. Their method may help bring about new levels of predictive accuracy, which theorists desperately need if they are to move beyond the leading but incomplete model of particle physics.</p>
<p>â€œThey have delivered lots of proof-of-concept results which show that this is a very promising technique,â€� Duhr said.</p>
<p>There could be a bigger payoff than improved predictions.&nbsp;</p>
<p>The new method skirts the traditional mathematical slog by directly computing â€œintersection numbers,â€� which some hope could eventually lead to a more elegant description of the subatomic world.&nbsp;</p>
<p>â€œThis is something thatâ€™s not just mathematics,â€� said&nbsp;<a href="https://www.physics.mcgill.ca/~schuot/" target="_blank">Simon Caron-Huot</a>&nbsp;of McGill University, a quantum theorist who is studying the implications of Mastrolia and Mizeraâ€™s work.&nbsp;â€œItâ€™s something thatâ€™s deeply baked into quantum field theory.â€�&nbsp;</p>
<p><strong>An Infinite Loop</strong></p>
<p>When physicists model particle collisions they use a tool called a Feynman diagram, a simple schematic invented by Richard Feynman in the 1940s.</p>
<p>To get a feel for these diagrams, consider a simple particle event: Two quarks streak in, exchange a single gluon as they â€œcollide,â€� then bounce away on their separate trajectories.</p>
<p>In a Feynman diagram the quarksâ€™ paths are represented by â€œlegs,â€� which join to form â€œverticesâ€� when particles interact. Feynman developed rules for turning this cartoon into an equation which calculates the probability that the event actually takes place: You write a specific function for each leg and vertex—generally a fraction involving the particleâ€™s mass and momentum—and multiply everything together. For straightforward scenarios like this one, the calculation might fit on a cocktail napkin.&nbsp;</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/abstractions_5242dbae24adf53fee012a27d96504f9.jpg" alt="nautilus gluon"><figcaption><br><span>Samuel Velasco/Quanta Magazine</span></figcaption></figure>
<p>But the golden rule of quantum theory is to consider all possibilities, and exchanging a simple gluon represents just one among a vast landscape of scenarios that could unfold when two quarks collide. The exchanged gluon might momentarily split into a â€œvirtualâ€� quark pair, for instance, before reconstituting itself in a flash. Two quarks enter and two quarks leave, but a lot can happen in the middle. A full accounting, implying a perfect prediction, would demand an infinite number of diagrams. No one expects perfection, but the key to improving a calculationâ€™s precision is getting further along in the infinite line of events.<strong>&nbsp;</strong><br></p>
<p>And thatâ€™s where physicists are getting stuck.&nbsp;</p>
<p>Zooming in to that hidden center involves virtual particles—quantum fluctuations that subtly influence each interactionâ€™s outcome. The fleeting existence of the quark pair above, like many virtual events, is represented by a Feynman diagram with a closed â€œloop.â€� Loops confound physicists—theyâ€™re black boxes that introduce additional layers of infinite scenarios. To tally the possibilities implied by a loop, theorists must turn to a summing operation known as an integral. These integrals take on monstrous proportions in multi-loop Feynman diagrams, which come into play as researchers march down the line and fold in more complicated virtual interactions.&nbsp;</p>
<p>Physicists have algorithms to compute the probabilities of no-loop and one-loop scenarios, but many two-loop collisions bring computers to their knees. This imposes a ceiling on predictive precision—and on how well physicists can understand what quantum theory says.&nbsp;</p>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/qe7atm1x6Mg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""><span id="selection-marker-1" class="redactor-selection-marker"></span></iframe>
</center>
<p>But there is one small mercy: Physicists donâ€™t need to calculate every last integral in a complicated Feynman diagram because the vast majority can be lumped together.<br></p>
<p>Thousands of integrals can be reduced to just dozens of â€œmaster integrals,â€� which are weighted and added together. But exactly which integrals can be subsumed under which master integrals is itself a hard computational question. Researchers use computers to essentially guess at millions of relationships and laboriously extract the combinations of integrals that matter.</p>
<p>But with intersection numbers, physicists may have found a way of elegantly plucking out the essential information from a sprawling calculation of Feynman integrals.</p>
<p><strong>A Geometric Fingerprint&nbsp;</strong></p>
<p>Mastrolia and Mizeraâ€™s work is rooted in a branch of pure math called algebraic topology, which classifies shapes and spaces. Mathematicians pursue this classification with â€œcohomologyâ€� theories, which allow them to extract algebraic fingerprints from complicated geometric spaces.</p>
<p>â€œItâ€™s kind of a summary, an algebraic gadget that incorporates the essence of the space you want to study,â€� said&nbsp;<a href="https://imag.umontpellier.fr/~dupont/" target="_blank">ClÃ©ment Dupont</a>, a mathematician at the University of Montpellier in France.</p>
<p>Feynman diagrams can be translated into geometric spaces that are amenable to analysis by cohomology. Each point within these spaces might represent one of a multitude of scenarios that could play out when two particles collide.</p>
<p>You might hope, naively, that by taking the cohomology of this space—finding its algebraic structure—you could calculate the weights for the master integrals that support it. But the type of geometric space that characterizes most Feynman diagrams is warped in a way that resists many cohomology calculations.</p>
<p>In 2017, Mizera was struggling to analyze how objects in string theory collide when he stumbled upon tools pioneered by Israel Gelfand and Kazuhiko Aomoto in the 1970s and 1980s as they worked with a type of cohomology called â€œtwisted cohomology.â€� Later that year Mizera met Mastrolia, who realized that these techniques could work for Feynman diagrams too. In 2019,&nbsp;they published three papers that used this cohomology theory to streamline calculations involving simple particle collisions.</p>
<p>Their method takes a family of related physical scenarios, represents it as a geometric space, and calculates the twisted cohomology of that space. â€œThis twisted cohomology has everything to say about the integrals we are interested in,â€� Mizera said.</p>
<p>In particular, the twisted cohomology tells them how many master integrals to expect and what their weights should be. The weights emerge as values they call â€œintersection numbers.â€� In the end, thousands of integrals shrink to a weighted sum of dozens of master integrals.</p>
<p>The cohomology theories that produce these intersection numbers may do more than just ease a computational burden—they could also point to the physical significance of the most important quantities in the calculation.</p>
<p>For example, when a virtual gluon splits into two virtual quarks, the quarksâ€™ possible lifetimes can vary. In the associated geometric space, each point can stand for a different quark lifetime. When researchers compute the weights, they see that scenarios with the longest-lasting virtual particles—that is, cases in which the particles become essentially real—shape the outcome the most.</p>
<p>â€œThatâ€™s the amazing thing about this method,â€� said Caron-Huot. â€œIt reconstructs everything starting from just these rare, special events.â€�</p>
<p>In August 2020,&nbsp;Mizera, Mastrolia and colleagues published&nbsp;<a href="https://arxiv.org/abs/2008.04823" target="_blank">another preprint</a>&nbsp;showing that the technique has matured enough to handle real-world two-loop diagrams. A forthcoming paper by Caron-Huot will push the method further, perhaps bringing three-loop diagrams to heel.</p>
<p>If successful, the technique could help usher in the next generation of theoretical predictions. And, a few researchers suspect, it may even foreshadow a new perspective on reality.</p>

<ul><li> is a journalist covering developments in the physical sciences both on and off the planet. His work has appeared in <span>Scientific American, The Christian Science Monitor</span> and <span>LiveScience</span>, among other publications. Previously, he taught physics and English in Mozambique and Japan, and he has a bachelorâ€™s in physics from Brown University.</li></ul>
<p>Lead image:&nbsp;<a href="https://www.istockphoto.com/video/animation-of-particles-collision-in-hadron-collider-astrophysics-concept-gm1151477191-312085198" target="_blank" rel="noreferrer nofollow" data-is-link="https://www.istockphoto.com/video/animation-of-particles-collision-in-hadron-collider-astrophysics-concept-gm1151477191-312085198">vchal</a></p>
<p>Video: The brilliant physicist Richard Feynman devised a system of line drawings that simplified calculations of particle interactions and helped rescue the field of quantum electrodynamics.&nbsp;Directed by&nbsp;<a href="http://www.bonscifilms.com/" target="_blank">Emily Driscoll</a>&nbsp;and animated by&nbsp;<a href="http://metteilene.com/" target="_blank">Mette Ilene Holmriis&nbsp;</a>for Quanta Magazine.<br></p>





                    <p>Reprinted with permission from <a href="https://www.quantamagazine.org/">Quanta Magazine</a>'s <a href="https://www.quantamagazine.org/category/abstractions/">Abstractions blog</a>.</p>
            </article></div>]]>
            </description>
            <link>http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270579</guid>
            <pubDate>Tue, 25 Aug 2020 12:23:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Low adoption of features and the sad realization]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270576">thread link</a>) | @damandloi
<br/>
August 25, 2020 | https://agyam.com/low-adoption-and-sad-realization/ | <a href="https://web.archive.org/web/*/https://agyam.com/low-adoption-and-sad-realization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><main id="main" role="main"> <article id="post-778"><div><div><p>Early in my career, I used to get so excited from hearing client’s complaints that I would instantly start to conceptualize solutions and put them in the backlog, ready to be discussed and pushed in the roadmap. Only later, I started realizing that none of the solutions were getting used as much as I had thought. It would break my heart – How can something I believed in so strongly would not get used by customers?</p><figure><img loading="lazy" width="700" height="467" src="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash.jpg?resize=700%2C467&amp;ssl=1" alt="New feature, no usage" srcset="https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=300%2C200&amp;ssl=1 300w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=768%2C512&amp;ssl=1 768w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1536%2C1024&amp;ssl=1 1536w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=2048%2C1365&amp;ssl=1 2048w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=434%2C289&amp;ssl=1 434w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=868%2C579&amp;ssl=1 868w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1736%2C1157&amp;ssl=1 1736w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?w=1400&amp;ssl=1 1400w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?w=2100&amp;ssl=1 2100w" sizes="(max-width: 700px) 100vw, 700px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=300%2C200&amp;ssl=1 300w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=768%2C512&amp;ssl=1 768w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1536%2C1024&amp;ssl=1 1536w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=2048%2C1365&amp;ssl=1 2048w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=434%2C289&amp;ssl=1 434w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=868%2C579&amp;ssl=1 868w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1736%2C1157&amp;ssl=1 1736w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?w=1400&amp;ssl=1 1400w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?w=2100&amp;ssl=1 2100w" data-lazy-src="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash.jpg?resize=700%2C467&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure><p>I would also try for all sorts of marketing tactics to make it noticeable to users, only to find temporary blip in the adoption. And, when the adoption rate reverts to the mean or does not show significant improvement, I would be worried about its impact on my performance evaluation and promotion.</p><p>After going to multiple phases of this sad realization of low adoption rates, here is how I now think about it:</p><p><strong>Building for adoption</strong></p><ul><li>Customers tell the right problem, but never the right solution.</li><li>Understanding the problem without the context won’t help in adoption. We should not build what the customers have asked or wanted to tell, but what helps them do their job.</li><li>If building what customers did not even know they needed, make sure they have a great experience with the aha moment.</li></ul><p><strong>Increasing adoption</strong></p><ul><li>Guestimate an adoption rate, and keep working towards it after the initial release. No feature/product is perfect in the first release.</li><li>Make a conscious decision of working towards increasing adoption or building a new feature. Sometimes a feature can increase the adoption of a product, and sometimes that feature won’t even get used for the low adoption of the product. Know the minimum feature set required for adoption.</li><li>Recognize that problem lies somewhere else if adoption isn’t increasing after multiple efforts.</li></ul><p><strong>Not all features are equal</strong></p><ul><li>Adoption seems to have an inverse relationship with the type of clients your product has.</li></ul><figure><img loading="lazy" width="700" height="487" src="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=700%2C487&amp;ssl=1" alt="" srcset="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=1024%2C713&amp;ssl=1 1024w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=300%2C209&amp;ssl=1 300w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=768%2C535&amp;ssl=1 768w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=434%2C302&amp;ssl=1 434w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=868%2C604&amp;ssl=1 868w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?w=1257&amp;ssl=1 1257w" sizes="(max-width: 700px) 100vw, 700px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=1024%2C713&amp;ssl=1 1024w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=300%2C209&amp;ssl=1 300w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=768%2C535&amp;ssl=1 768w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=434%2C302&amp;ssl=1 434w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=868%2C604&amp;ssl=1 868w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?w=1257&amp;ssl=1 1257w" data-lazy-src="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=700%2C487&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Small clients can easily adopt whereas enterprises take their own time.</figcaption></figure><ul><li>It is ok to have some features build for limited enterprise clients having a disproportionate ratio of product revenue. However, only if the team agrees on the tradeoffs of increased complexity and tech debt.</li><li>Feature adoption also seems to have an inverse relationship with the depth of the product. Features for advanced users can be good differentiators and add to the marketing arsenal, but they remain least used.</li></ul><p><strong>Adoption is breaking inertia</strong></p><ul><li>Customers become habitual to their flows and often ignore new features. We need to break their inertia by making them realize the value and reducing the effort required.</li><li>Consider adoption as an onboarding strategy:<ul><li>`Attract them with multi-channel launch announcements</li><li>Interest them with contextual nudges and making it easy to find</li><li>Increase desire with use cases and testimonials</li><li>Reduce anxiety with upfront help</li><li>Make it easy to perform an action or use the feature</li></ul></li></ul><figure><blockquote><p>Adoption is breaking inertia. It happens when users realize the value outweighs the efforts invested.</p></blockquote></figure><ul><li>For features that increase the overall product value, keep educating customers until new habits are formed. For advanced and specific features, hide them slowly to make way for new features.</li></ul><p>As years go by, I started realizing another truth – Adoption is necessary but not a sufficient condition for the product’s success.</p><hr><pre>Image by <a href="https://unsplash.com/@jonasjacobsson?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jonas Jacobsson</a>.

* These pointers are applicable equally for feature and product adoption.</pre></div> </div> <nav> « <a href="https://agyam.com/good-product-manager-bad-product-manager/" rel="prev">Good Product Manager and Bad Product Manager by Ben Horowitz</a> </nav></article></main></div></div>]]>
            </description>
            <link>https://agyam.com/low-adoption-and-sad-realization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270576</guid>
            <pubDate>Tue, 25 Aug 2020 12:22:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't marry your design after the first date]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270554">thread link</a>) | @todsacerdoti
<br/>
August 25, 2020 | https://tomgamon.com/posts/2020-08-25-dont-marry-your-design/ | <a href="https://web.archive.org/web/*/https://tomgamon.com/posts/2020-08-25-dont-marry-your-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Prudent dating advice would be to get to know someone first, before making an everlasting commitment to them. The same advice holds when designing software systems. Don’t marry yourself to your design decisions before at least getting to learn more about them first. Once you have learned their quirks and seen how they act under pressure, you can make a much more informed decision about whether you want to commit. When I am designing new software from scratch I often think about this quote from Uncle Bob.</p><div><blockquote><p>Good architecture allows major architectural decisions to be deferred. The job of an architect is not to make decisions, but to defer those decisions for as long as possible, To allow the program to be built in the absence of decisions so that decisions can be made later with the most possible information</p></blockquote></div><p>At the point you start a new project, you have the least amount of possible knowledge about that project. As The Project Paradox states, this is the worst possible time to be committing to major decisions.</p><blockquote><p lang="en" dir="ltr">The project paradox: making the biggest decisions when knowledge is at it's absolute lowest. <a href="https://t.co/b7zBa4Aq7m">pic.twitter.com/b7zBa4Aq7m</a></p>— Tobias Fors (@tofo) <a href="https://twitter.com/tofo/status/512666251055742977?ref_src=twsrc%5Etfw">September 18, 2014</a></blockquote><p>The more time you spend in the problem space, the more information you can gather and the better decision you can make when the time comes. For example, you can probably start working on your domain logic without knowing how the data is going to be served to the client, or what particular flavour of database you are going to use. Once you have chosen a database, by carefully encapsulating the access logic, if it turns out that this database isn’t the one, it is much easier to part ways amicably.</p><p>Structure your code in such a way that you don’t have to commit to major decisions up front, and perhaps you too can live happily ever after.</p></section></div>]]>
            </description>
            <link>https://tomgamon.com/posts/2020-08-25-dont-marry-your-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270554</guid>
            <pubDate>Tue, 25 Aug 2020 12:19:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practical tips for better microcopy]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24270552">thread link</a>) | @jrdnbwmn
<br/>
August 25, 2020 | https://learnuxd.io/posts/7-practical-tips-for-better-microcopy/ | <a href="https://web.archive.org/web/*/https://learnuxd.io/posts/7-practical-tips-for-better-microcopy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">
        
        <p>Good microcopy is one of the fastest ways to improve an interface. Try doing an audit on your UI with these tips to see how it stands up.</p>

<h2 id="1-use-personal-pronouns">1) Use personal pronouns</h2>

<p>Address the reader instead of just talking out loud. Use the word <em>you</em>. People pay more attention when you talk directly to them.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post1.png">
</figure>

<h2 id="2-start-with-a-verb">2) Start with a verb</h2>

<p>Names for interactive elements should begin with an action verb. The same goes for important copy. Starting with a verb is more direct and engaging.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post2.png">
</figure>

<h2 id="3-prevent-concerns">3) Prevent concerns</h2>

<p>Point out concerning actions before your user can worry about your motives. Be transparent<span>—</span>make sure they understand what they’re doing and why.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post3.png">
</figure>

<h2 id="4-use-natural-language">4) Use natural language</h2>

<p>Write conversationally, like you’re one-on-one. Be professional but get rid of jargon. Use familiar, simple words with a friendly, relaxed tone.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post4.png">
</figure>

<h2 id="5-default-to-active-voice">5) Default to active voice</h2>

<p>Most of the time, active voice is the way to go. It’s easier to understand than passive voice, feels more personal, and is often shorter and stronger.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post5.png">
</figure>

<h2 id="6-show-useful-error-messages">6) Show useful error messages</h2>

<p>Avoid negative, threatening, or overly technical words. Be friendly, show empathy, take the time to explain what’s going on, and be helpful.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post6.png">
</figure>

<h2 id="7-write-iteratively">7) Write iteratively</h2>

<p>We write code iteratively, so why everything else? Things probably won’t be perfect the first time around. Test, refine, ship again. It adds up.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post7.png">
</figure>

<p>Thanks for reading. If you enjoyed the article, sharing on Twitter is really appreciated:</p>

<div>
    <div>
        <blockquote><div lang="en" dir="ltr"><p>Good microcopy is one of the fastest ways to improve an interface. </p><p>Try doing an audit on your UI with these tips to see how it stands up. 👇 <a href="https://t.co/DqRSmVTIvt">pic.twitter.com/DqRSmVTIvt</a></p></div>— Learn UXD (@learn_uxd) <a href="https://twitter.com/learn_uxd/status/1298228761771552773?ref_src=twsrc%5Etfw">August 25, 2020</a></blockquote> 
    </div>
</div>


    </article></div>]]>
            </description>
            <link>https://learnuxd.io/posts/7-practical-tips-for-better-microcopy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270552</guid>
            <pubDate>Tue, 25 Aug 2020 12:19:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealing local files using Safari Web Share API]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24270538">thread link</a>) | @doener
<br/>
August 25, 2020 | https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html | <a href="https://web.archive.org/web/*/https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270538</guid>
            <pubDate>Tue, 25 Aug 2020 12:16:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flutter vs. React Native, writing an app with each one: Part 1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270496">thread link</a>) | @pixo
<br/>
August 25, 2020 | https://pixo.sh/flutter-vs-react-native-an-app-with-each-one-part-1/ | <a href="https://web.archive.org/web/*/https://pixo.sh/flutter-vs-react-native-an-app-with-each-one-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure><img loading="lazy" width="1024" height="675" src="https://pixo.sh/wp-content/uploads/flutter-vs-react-native-1024x675.jpg" alt="Flutter vs React Native" srcset="https://pixo.sh/wp-content/uploads/flutter-vs-react-native-1024x675.jpg 1024w, https://pixo.sh/wp-content/uploads/flutter-vs-react-native-300x198.jpg 300w, https://pixo.sh/wp-content/uploads/flutter-vs-react-native-768x506.jpg 768w, https://pixo.sh/wp-content/uploads/flutter-vs-react-native.jpg 1489w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<p>Flutter vs React Native, two widely used cross platform tools, but what should I use?. In this “experiment”, Im going to try to develop the same app, in both frameworks, the goal is to spot differences between them.</p>
<p>No framework is better than the other, they work in different ways, and they fit different developer requirements</p>
<h2>Main differences</h2>
<p>For me the main difference between them, is that React Native run using a Javascript bridge, while Flutter is compiled to native code. This is strictly reflected in the performance of each one.</p>
<figure><table><tbody><tr><td></td><td>Flutter</td><td>React Native</td></tr><tr><td>Language</td><td>Dart</td><td>Javascript</td></tr><tr><td>Compiles native code</td><td>Yes</td><td>No</td></tr><tr><td>Maintained by</td><td>Google</td><td>Facebook</td></tr></tbody></table></figure>
<h2>What im going to build and test</h2>
<p>I will write an app in both frameworks, will be a simple app using the <a aria-label="Rick and Morty API (opens in a new tab)" href="https://rickandmortyapi.com/" target="_blank" rel="noreferrer noopener">Rick and Morty API</a>.</p>
<p>I’m going to test:</p>
<p>Part 1</p>
<ul><li>How fast is to install each framework create and run an app</li><li>Reloading time, both frameworks have hot reloading, a fast one is needed for a seamlessly development workflow</li><li>Development experience, which one offers a better development experience</li></ul>
<p>Part 2</p>
<ul><li>Writing the app in React Native</li><li>Writing the app in Flutter</li></ul>
<p>Part 3</p>
<ul><li>Testability, how easy is to test each app</li><li>Stress test and benchmarking </li></ul>
<h2>Installing Flutter and React Native</h2>
<p>Before I start, i have already installed in my computer Android Studio and Xcode, since they are not related directly to any framework, I won’t include their installation process.</p>
<h3>Flutter process</h3>
<ol><li>Install the <a aria-label="Flutter SDK (opens in a new tab)" href="https://flutter.dev/docs/get-started/install" target="_blank" rel="noreferrer noopener">Flutter SDK</a> (2min)</li><li>Add the Flutter SDK PATH (20s)</li><li>Create the app with flutter create (1min)</li></ol>
<p>The whole process to install Flutter took me 3 minutes, not including the downloading time, also Flutter provides a tool called flutter doctor, which for first installs is really useful it scans our system to check if we have all the needed tools for flutter development (Xcode, Android Studio, Dart plugins, VScode extensions…)</p>
<h3>React Native process</h3>
<p>You can use Expo, but I will use React Native CLI</p>
<ol><li>Install Node.js (3min)</li><li>Install watchman (2min</li><li>Create our app with typescript support (2min)</li></ol>
<p>Total time, 7 mins, and i needed to fix my nvm versions, also first build took about 3 minutes to start.</p>
<p>The Flutter installation process was smoother and faster than the React Native one, probably because RN needs to deal with Node.js under the hood…</p>
<h2>Development experience</h2>
<h3>Hot reloading</h3>
<p>Hot reloading is a must feature for me in web and app development, both, React Native and Flutter have the same feature.</p>
<p>I tested both with the default app which each framework creates</p>
<p>Flutter took 47ms to hot reload the app</p>
<p>React Native took 630ms, because it needs to compile javascript and inject it again with Metro.</p>
<p>Also a note on this, Flutter hot reloading only worked for me if I run my app from VScode, if i run the flutter app from an external terminal, the <strong>automatic hot reloading</strong> doesn’t work, I need to type r to hot reload the app, while in React Native you only need to save the file. I guess this is the only tradeoff. </p>
<h3>Extensions</h3>
<p>I installed Flutter extension for VScode, which is very recommended from the dev team. It adds an extension icon in your sidebar, and you can view your project structure from that tab.</p>
<p>For React Native I added React Native Tools, you can run React Native commands directly from your VScode command palette, but if you run your app from a terminal i don’t find it very useful</p>
<h3>Debugging</h3>
<p>Both frameworks come with their own debugging tools, however, for me Flutter ones are more useful.</p>
<p>One thing I don’t like about React Native debugger is that you can’t see directly your network requests, you need to do some tweaks in order to do that, you can see more info about that <a aria-label="here (opens in a new tab)" href="http://One thing I don't like about React Native debugger is that you can't see directly your network requests, you need to do some tweaks in order to do that, you can see more info about that here" target="_blank" rel="noreferrer noopener">here</a></p>
<p>Here you can see each one debugger GUI</p>
<p>React Native:</p>
<figure><img loading="lazy" width="1024" height="611" src="https://pixo.sh/wp-content/uploads/react-native-debugger-1024x611.png" alt="Flutter vs React Native: React Native debugger" srcset="https://pixo.sh/wp-content/uploads/react-native-debugger-1024x611.png 1024w, https://pixo.sh/wp-content/uploads/react-native-debugger-300x179.png 300w, https://pixo.sh/wp-content/uploads/react-native-debugger-768x458.png 768w, https://pixo.sh/wp-content/uploads/react-native-debugger.png 1452w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>React Native Debugger in Chrome devtools</figcaption></figure>
<p>Flutter:</p>
<figure><img loading="lazy" width="1024" height="610" src="https://pixo.sh/wp-content/uploads/dart-devtools-1024x610.png" alt="Flutter vs React Native: Dart DevTools" srcset="https://pixo.sh/wp-content/uploads/dart-devtools-1024x610.png 1024w, https://pixo.sh/wp-content/uploads/dart-devtools-300x179.png 300w, https://pixo.sh/wp-content/uploads/dart-devtools-768x458.png 768w, https://pixo.sh/wp-content/uploads/dart-devtools.png 1448w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Dart DevTools, running in Chrome</figcaption></figure>
<h2>Conclusion on Part 1</h2>
<p>In terms of development experience, Flutter is the winner for me, the whole process from 0 to app running in my emulator didn’t took more than 10 minutes.</p>
<p>With React Native, compilation took a lot of time (I’m running each one in a 16″ 2019 Macbook Pro), also i had some Node.js issues.</p>
</div></div>]]>
            </description>
            <link>https://pixo.sh/flutter-vs-react-native-an-app-with-each-one-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270496</guid>
            <pubDate>Tue, 25 Aug 2020 12:07:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure Modular Runtimes]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24270195">thread link</a>) | @ispivey
<br/>
August 25, 2020 | https://guybedford.com/secure-modular-runtimes.html | <a href="https://web.archive.org/web/*/https://guybedford.com/secure-modular-runtimes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I recently posted the following Tweet with regards to the current state of the third-party security problem in the JavaScript ecosystem:

</p><blockquote><div lang="en" dir="ltr"><p>Having worked on and followed modules standards from TC39 and WhatWG to Node.js, it's so so clear that security was, is, and always will be an afterthought.</p><p>Where are the secure-by-default open platform developments? Crypto is the only community I see doing it.</p></div>— Guy Bedford (@guybedford) <a href="https://twitter.com/guybedford/status/1296935308445900801?ref_src=twsrc%5Etfw">August 21, 2020</a></blockquote> 

<p>I wanted to fill in some of the background to this from my own work on Node.js modules and security concepts, following the Agoric SES and compartment models, and from a growing feeling of the inadequacy of the Node.js, Deno and browser runtimes for supporting the third-party security needs of the ecosystem.

</p><p><em>TLDR; I think we need to think about new more secure runtimes for JS, and it should be a collaborative effort, with the components being modules, adding isolated scopes to import maps, and a careful security model plus compatibility with the existing ecosystem. <a href="#secure-modular-runtime-proposal">Skip ahead to the proposal here.</a></em>

</p><p><em>Update: Since posting this, I see that <a rel="noopener" target="_blank" href="https://github.com/Agoric/SES-shim/tree/master/packages/endo">Endo</a> and <a rel="noopener" target="_blank" href="https://github.com/LavaMoat/LavaMoat">LavaMoat</a> provide techniques very close to these directions, although neither has quite yet taken the leap that I argue is necessary that such a security system should be integrated into the primary runtime itself.</em></p>

<h2><a href="#third-party-security-problem">#</a>The Third-Party Security Problem</h2>

<p>The underlying issue is the <code>npm install</code> one. As the registry and our dependence on it continues to expand, the security gap here continues to grow in terms of the amount of untrusted code we are running on a daily basis.

</p><p>Maintainers giving up their time freely now find themselves obliged to respond to regular security issues or risk having unpatchable advisories released for their packages, which may or may not even be genuine escalations of privilege.
  We engage in security theatre to create the illusion of safety, and yet all the while everything remains highly unsecure.

</p><p>Rather than simply accepting the status quo, many companies are actively working on mitigating these security properties. The problem is that they end up creating side ecosystems or patches to the existing ecosystem, security measures that are never fundamentally designed into the ecosystem itself. Third-party security remains a huge if not impossible effort, that only dedicated teams can afford to tackle, as we see for example with these intiatives by <a rel="noopener" target="_blank" href="https://www.figma.com/blog/how-we-built-the-figma-plugin-system/">Figma</a> or <a rel="noopener" target="_blank" href="https://developer.salesforce.com/blogs/developer-relations/2017/02/lockerservice-lightning-container-third-party-libraries-lightning-components.html">Salesforce</a>.

</p><p>The <a rel="noopener" target="_blank" href="https://github.com/tc39/proposal-realms">Realms proposal</a> may give us the tools for constructing a secure runtime, but the JavaScript ecosystem conventions themselves work against supporting security restrictions.

</p><p>The general view from Chrome/v8, is that this type of third-party per-package security within the same process isn't possible:

</p><blockquote><p lang="en" dir="ltr">how is this possible post spectre</p>— Sathya Gunasekaran (@_gsathya) <a href="https://twitter.com/_gsathya/status/1297121933004353536?ref_src=twsrc%5Etfw">August 22, 2020</a></blockquote> 

<p>Now I admit I have fully bought in to the elegance of the the OCAP, SES and compartment models, the ideas shared by those at Agoric (who are long-time members of TC39). I gave a session on these concepts at the Node.js Collaboration summit.

</p><p>For all the tremendous benefits of the concept of modular security, there are certainly important questions, but I believe we should actively tackle this work and these questions, and not abandon the same-process modular security models unless they can be fully disproved.

<a name="compartment-model"></a>
</p><h2><a href="#compartment-model">#</a>The Compartment Model</h2>

<p>The gist of the compartment model builds on top of SES (<a rel="noopener" target="_blank" href="https://github.com/Agoric/ses-shim">Secure ECMAScript</a>), as proposed by Agoric, something like the following:

</p><ol>
  <li>All capabilities are imported through the module system (<code>import fetch from 'fetch'</code> kind of thing) - <em>the module resolver acts as the capability system, enforcing permissions</em>.</li>
  <li>The consequence of (1) is that <em>all global capabilities should be disabled / carefully controlled.</em></li>
  <li>JavaScript needs a whole bunch of patching to prevent prototype mutations and unintentional side channels such as <code>return { toString() {} }</code> object hooks. You have to manage package interfaces very carefully and freeze the entire global object from prototype mutation.</li>
</ol>

<p>See the talk by Mark Miller on <a rel="noopener" target="_blank" href="https://www.youtube.com/watch?v=9WdbTucMaRo">Extremely Modular Distributed JavaScript</a>, or my presentation from the Node.js Collaboration Summit,
<a rel="noopener" target="_blank" href="https://docs.google.com/presentation/d/1VUpxoxitZCINJI7jXec4i87YiYZsXr8pCSHdHY5pW30/edit?usp=sharing">Security, Modules and Node.js</a>, for a more in-depth coverage of the full model.

</p><p>The result of this model is, in theory, the ability to restrict destructive code. The date time library you npm install cannot install a trojan horse on your computer, which seems a pretty useful property to have.

</p><p>Towards (3) we already <a rel="noopener" href="https://nodejs.org/dist/latest-v14.x/docs/api/cli.html#cli_frozen_intrinsics">shipped the `--frozen-intrinsics` flag in Node.js</a>. (1) and (2) clearly require breaking changes to what we have in any existing runtimes today.</p>

<h2><a href="#criticisms">#</a>Criticisms</h2>

<p>The criticisms of this model include the Spectre class of vulnerabilities, the difficulty in providing secure cross-package interfaces, and that these ideas might sound good in theory but are impractical in real JS environments.

<a name="spectre"></a>
</p><h3><a href="#spectre">#</a>Spectre</h3>

<p>The Spectre class of attacks means that code running on the same process can use CPU reverse engineering and timing information to read secret information
used by other separate code in the same process. Think - passwords, secure tokens, etc.

</p><p>The first thing to note is that Spectre is the ability to steal secrets and not the ability to install a trojan horse on your computer. Even if we can't fully mitigate Spectre (and we can certainly try), we are still limiting destructive capabilities such as giving full disk and network access
  to random people on the internet, which is a huge win. What we are comparing this model against, is having no separate security for third-party libraries at all, which is the case in Node.js, Deno and browsers today. <em>In the case of an attack, it is better to just lose a credit card, than to lose a credit card AND have your house burnt down.</em>

</p><p>The second thing to note here is that if you have a true capability system and can carefully control network access, then the capability to exfiltrate (basically to use <code>fetch</code>), can itself be treated as a critical permission. Secrets might be discovered but not as easily shared.

</p><p>The counterargument to controlling the capability to exfiltrate is that there are always side channels to be found - the blinking of a light through whatever complex window to share the information of the secret token. It's a complex boundary to mitigate.

</p><p>Finally, in terms of genuine Spectre mitigations, Cloudflare have this same problem for their same-process deployment of Cloudflare Workers, which they recently discussed here - <a rel="noopener" target="_blank" href="https://blog.cloudflare.com/mitigating-spectre-and-other-security-threats-the-cloudflare-workers-security-model/">Mitigating Spectre and Other Security Threats: The Cloudflare Workers Security Model</a>.

</p><p>Their mitigations are summarized at the end, and roughly involve:

</p><ul>
<li>Restricting Date.now() and multi-threading via new Worker (which allows custom timer creation) to attempt to disable the time measurements necessary to initiate the attack.
</li><li>Proactively detecting the attack behaviour based on monitoring and initiating full isolation.
</li><li>Exploring memory shuffling techniques so that secret information does not remain static.
</li></ul>

<p>As Cloudflare mention, this is an active mitigation space that can continue to be developed. In theory, these similar mitigations could apply to new runtime development as well.

</p><p>The important thing to note is that these mitigation techniques do not apply to the Web platform at all as they are simply not possible (at least not without <a rel="noopener" target="_blank" href="https://github.com/tc39/proposal-realms">Realms</a>). The Google / v8 position completely makes sense, given this angle,
  but the focus I want to make is on <strong>new JavaScript runtimes</strong>, like successors to Node.js such as Deno and others, <em>which should really be exploring these security properties today</em>.

<a name="insecure-module-interfaces"></a>
</p><h3><a href="#insecure-module-interfaces">#</a>Insecure Module Interfaces</h3>

<p>The next major problem comes down to the complex interface boundary between third-party packages. For example, consider the following code:

</p><pre><code>
import { renderer } from 'renderer';
import { renderGraph } from 'graph';
import { renderTitle } from 'title';

renderer.render([renderGraph, renderTitle]);
</code></pre>

<p>In theory, <code>renderGraph</code> doesn't need any other capabilities other than the ability to call into the renderer so it can be treated as low-trust code.

</p><p>But now consider a malicious implementation of <code>renderGraph</code>:

</p><pre><code>
export function renderGraph () {
  this[1].setTitle('Changed the title');
}
</code></pre>

<p><code>renderGraph</code> knows the renderer will call it via <code>renderArray[i]()</code>, which in JavaScript will set the <code>this</code> binding to the array itself, thus giving access to the title component from the graph component.

</p><p>Yes, it's a contrived example, but it demonstrates how easily you can get capability spillage in JavaScript, and that's before we even get to information spillage eg via <code>toString()</code>.

</p><p>Locking down these sorts of inadvertant side channels means making all package interfaces out of <code>SafeFunction</code> and <code>SafeObject</code> objects that don't have these sorts of awful flaws, and it's not an easy problem to solve - this is where the bulk of the effort needs to be made.

</p><p>The other side of this to consider is that Web Assembly module interfaces don't have these same sorts of capability and information spillage that we have in JavaScript, which certainly gives hope for future ecosystems dealing with these problems.

<a name="impractical-constraints"></a>
</p><h3><a href="#impractical-constraints">#</a>Impractical Constraints</h3>

<p>The third argument is that the security requirements are simply too much of a constraint on JavaScript and its ecosystems. That there exists no path from the ecosystems today to this kind of secure ecosystem. As a result, secure runtimes will always be a fringe effort
  adopted by the few who can invest in the time and effort to support them.

</p><p>This, I believe, is the most crucial problem to solve. The ability to run third-party libraries with less risk should be fully democratized.

<a name="secure-modular-runtime-proposal"></a>
</p><h2><a href="#secure-modular-runtime-proposal">#</a>Secure Modular Runtime Proposal</h2>

<p>I'd like to propose a hypothetical runtime for JavaScript, as a strawman, and to invite scrutiny as to whether this solves the following problems:

</p><ol>
<li>That this runtime can fully restrict high-level capability access from packages for third-party code running in the same process than we have in Node.js, Deno and browsers today.
</li><li>That this runtime can support …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://guybedford.com/secure-modular-runtimes.html">https://guybedford.com/secure-modular-runtimes.html</a></em></p>]]>
            </description>
            <link>https://guybedford.com/secure-modular-runtimes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270195</guid>
            <pubDate>Tue, 25 Aug 2020 11:25:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finnish logistics giant uses predictive database for intelligent automation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24270164">thread link</a>) | @arauhala
<br/>
August 25, 2020 | https://aito.ai/blog/posti-boosts-their-rpa-with-aito/ | <a href="https://web.archive.org/web/*/https://aito.ai/blog/posti-boosts-their-rpa-with-aito/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Posti boosts purchase invoice automation with Aito</h2><p>The RPA team of Posti has moved to the next level by adding machine learning into their toolbox. Using Aito has allowed Posti to utilize machine learning independently and the first Aito implementation is now live in production, tirelessly churning through thousands of purchase invoices and saving their finance team countless of hours worth of mechanical work.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/posti_quote.png" alt="Aito has provided Posti a fast and easy tool to implement machine learning to business processes, adding new opportunities to our Intelligent Automation toolkit."></p></div></div><h2>Automation in the Finnish logistics giant</h2><p>As the largest postal service operator in Finland, Posti delivers hundreds of thousands of parcels and envelopes daily around the country. This naturally involves much more behind the scenes than just the logistics though, and automation has been at the core of Posti for years.</p><p>To streamline its operations, Posti’s RPA Center of Excellence has been automating countless business processes within the company. With Aito now in their toolbox, the RPA team can conquer even complex processes without having to go through the data science pipeline. No custom code or scripts are needed either since interaction with Aito happens directly through standard UiPath activities.</p><h2>Handling purchase invoices</h2><p>By using Aito and in collaboration with Sisua Digital, Posti has automated their purchase invoice handling processing. Processing the 3000 new invoices every month requires several cognitive decisions, making automation impossible with traditional RPA methods. Before storing the final version in their invoice management system, each digital invoice needs to be:</p><ol><li>Assigned to the right reviewer</li><li>Allocated to the right cost center</li><li>Tagged for the right category</li><li>Corrected in case of missing information</li></ol><p>Visualizing the problem with some mock data, this is how a new invoice looks like entering the system. A correct value needs to be selected for the empty fields.</p><table><thead><tr><th>Vendor_Code</th><th>Inv_Amt</th><th>VAT_Code</th><th>Item_Description</th><th>Product_Category</th><th>Reviewer</th><th>CC_Code</th><th></th><th></th><th></th></tr></thead><tbody><tr><td>VENDOR-1676</td><td>83.24</td><td></td><td>Artworking/Typesetting ...</td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><p>Posti has automated this process by creating a software robot with UiPath and having it interact with Aito. The robot reads the information in each new invoice and asks Aito to predict the right values.</p><table><thead><tr><th>Vendor_Code</th><th>Inv_Amt</th><th>VAT_Code</th><th>Item_Description</th><th>Product_Category</th><th>Reviewer</th><th>CC_Code</th><th></th><th></th><th></th></tr></thead><tbody><tr><td>VENDOR-1676</td><td>83.24</td><td>VAT-24</td><td>Artworking/Typesetting ...</td><td>CLASS-1593</td><td>R-085</td><td>CC-164</td><td></td><td></td><td></td></tr></tbody></table><h2>Launching the robot</h2><p>To test the performance of the new automation, it was first operated in parallel with the manual process for one month and all the predictions of Aito were recorded for evaluation. During the simulation, Aito’s predictions fulfilled the accuracy requirement of 95% set by the project steering group, giving it the green light for production. The first version of the robot includes a few of types of purchase invoices in one legal company. Later during this the fall, more companies and invoice types will be added.</p><p>During its first couple of months in production, more than 7,000 purchase invoices have been processed automatically. The new automation has reduced the workload on the Accounts Payable team at Posti while boosting the speed of invoice review. But even more importantly, the RPA team of Posti now has the ability to replicate the technology for countless other business processes. After the initial learning curve, they found Aito very straightforward to use with standard UiPath functionality.</p><a href="https://aito.ai/blog">Back to blog list</a></div></div>]]>
            </description>
            <link>https://aito.ai/blog/posti-boosts-their-rpa-with-aito/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270164</guid>
            <pubDate>Tue, 25 Aug 2020 11:20:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code-first GraphQL server by Prisma]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269944">thread link</a>) | @oczek
<br/>
August 25, 2020 | https://blog.graphqleditor.com/graphql-nexus-codefirst-graphql-server/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/graphql-nexus-codefirst-graphql-server/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>GraphQL schema is a set of rules describing the functionality available to the client, including specification of operations (queries and mutations) that can be executed to execute against your data graph. When building a GraphQL service, there is a choice that needs to be made whether you want to follow the code-first or schema-first path: </p>
<ul>
<li>Schema-first - which prioritizes process of designing the schema which puts schema as your source of truth and forces your code to follow the definitions stored in your schema,</li>
<li>Code-first (resolver-first) - is an approach where the GraphQL schema is implemented programmatically.</li>
</ul>
<p>In either case, we will end up with a fully functional GraphQL service, but this choice will influence your project in terms of the amount of work you will need to put to introduce some features (but it’s a topic that deserves to be covered in a separate post).</p>
<h2>Code-first framework for GraphQL Server development</h2>
<p>The rapid growth of GraphQL’s popularity generated the natural need for different tools, both schema-first and code-first oriented, facilitating GraphQL working experience. One of the tools representing the code-first approach is <a href="https://nexus.js.org/">GraphQL Nexus framerwork</a>.</p>
<p>GraphQL Nexus is a GraphQL framework for building your GraphQL Server, where the schema is defined and implemented programmatically. GraphQL Nexus relies on a Node.js and TypeScript thanks to which it can provide features such as:</p>
<ul>
<li><strong>Type-Safety</strong> -  type-definitions are being generated as you proceed with the development process &amp; inferred in your code, providing you with auto-completion and error catching,</li>
<li><strong>Compatibility with GraphQL Ecosystem</strong> - GraphQL Nexus relies heavily on graphql-js and works well with its existing types when constructing the schema which makes the auto-generated schema compatible with most popular tools like Apollo Server etc.,</li>
<li><strong>Data-Agnostic</strong> - GraphQL Nexus is a declarative syntax layered on the top of the graphql-js library which basically means that you can achieve with it all that you can do with graphql-js or apollo-tools.</li>
</ul>
<p>Having figured out all the types you need for your schema all you need to do is simply use <code>makeSchema</code> function to create the schema instance that would be used as the foundation for your GraphQL server.</p>
<div data-language="tsx"><pre><code><span>const</span> schema <span>=</span> <span>makeSchema</span><span>(</span><span>{</span>
  
  types<span>:</span> <span>[</span>User<span>,</span> Query<span>,</span> Mutation<span>]</span><span>,</span>

  
  outputs<span>:</span> <span>{</span>
    typegen<span>:</span> __dirname <span>+</span> <span>'/generated/typings.ts'</span><span>,</span>
    schema<span>:</span> __dirname <span>+</span> <span>'/generated/schema.graphql'</span><span>,</span>
  <span>}</span><span>,</span>

  
  nonNullDefaults<span>:</span> <span>{</span>
    input<span>:</span> <span>true</span><span>,</span>
    output<span>:</span> <span>true</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span>

</code></pre></div>
<h2>Getting started</h2>
<p>As previously mentioned GraphQL Nexus relies heavily on <code>graphql-js</code> and it’s also required for the installation:</p>
<div data-language="text"><pre><code>npm install nexus
npm install graphql # required as a peer dependency</code></pre></div>
<p>The best way to begin with GraphQL Nexus is of course the <a href="https://nexus.js.org/docs/getting-started">official documentation</a>. After familiarizing with it the next step could be playing around with their <a href="https://github.com/prisma/nexus/tree/develop/examples">official examples</a> and the <a href="https://nexus.js.org/playground">online Playground</a>. Have fun!</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/graphql-nexus-codefirst-graphql-server/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269944</guid>
            <pubDate>Tue, 25 Aug 2020 10:46:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Seamless head tracking for games using the TrueDepth camera (iOS)]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24269925">thread link</a>) | @epaga
<br/>
August 25, 2020 | http://www.inflightassistant.com/smoothtrack/index.html | <a href="https://web.archive.org/web/*/http://www.inflightassistant.com/smoothtrack/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <h2>
          <p><a href="https://apps.apple.com/de/app/smoothtrack/id1528839485?l=en"><img src="http://www.inflightassistant.com/img/appstore.svg" height="45/"></a></p>
            
            <p><b><a href="https://testflight.apple.com/join/ytc1tAdA">Click here to join a free public beta</a> which runs on ANY iOS 13 device, not only ones with TrueDepth!</b></p>
            
          <p>SmoothTrack is the best input source for the free OpenTrack software which enables you to use head tracking in your Mac or PC games.</p>
<br>
<div>
  <div>
    <div>
      <p>
        <h6>
          "Just flew a few patterns with this - it genuinely works better for me than TrackIR ever did, at a fraction of the cost." - /u/yawnyprawny
        </h6>
      </p>
    </div>
  </div>
</div>

          <p>SmoothTrack provides you with 6 degrees-of-freedom head tracking for beautiful head tracking for your games.</p>
          

            <p>No headset or extra equipment of any kind is required! Simply set up your device so that it can see your face. Using the on-screen controls, you can shift your perspective in-game.</p>
            

              <p>It's an amazing experience to seamlessly move your head and have your game perspective play along.</p>
              <br>
              <div>
                <div>
                  <div>
                    <p>
                      <h6>
                        "This worked perfectly and way better than expected! Totally enhanced my experience with MFS 2020!" - /u/lexpert1
                      </h6>
                    </p>
                  </div>
                </div>
              </div>
              
              
                <p>Any game that supports the FreeTrack or TrackIR protocol will work with this, including Flight Simulator, Elite: Dangerous, FSX, IL2: Sturmovik, and many, many others!</p>
                

                  <p>INSTRUCTIONS (included in the app):</p>
                  <br>

                    <ol><li>On your computer, install and run the free program "OpenTrack".</li>
                      <li>In OpenTrack, as Input source, choose "UDP over network". As Output, choose "freetrack 2.0 Enhanced".</li>
                        <li>Make sure the UDP port OpenTrack is using is open both on your firewall and router.</li>
                          <li>Find the IP address of your PC</li>
                            <li>Now, in SmoothTrack, set up your IP address and port in the settings</li>
                              <li>Tap Play and you should see the OpenTrack octopus move around, which means any game that supports TrackIR will now be supporting your head tracking!</li>
</ol>
<p>Email support is provided if there are any issues.</p>

    
  
</h2></div></div></div>]]>
            </description>
            <link>http://www.inflightassistant.com/smoothtrack/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269925</guid>
            <pubDate>Tue, 25 Aug 2020 10:43:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Incident updates, interruptions and the 30 minute window]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24269804">thread link</a>) | @vinnyglennon
<br/>
August 25, 2020 | https://www.unixdaemon.net/sysadmin/incident-updates-and-interruptions/ | <a href="https://web.archive.org/web/*/https://www.unixdaemon.net/sysadmin/incident-updates-and-interruptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>For most companies Incident Commander or Incident Manager is not a
specific job, it’s a role you may take on when something has gone, often
horribly, wrong and you need to quickly unite an adhoc group into a team
to resolve it. The incident commander should be the point of contact,
and source of truth, about your incident and to do that successfully
they’ll need to be updated and kept informed about what’s happening.
Depending on how experienced they are in the role this can be a very
light touch experience or it can feel like being constantly nagged to
put the washing away while someone burns money nearby.</p>
<p>I’ve been involved in a fair few incidents over the years and one of the
best approaches I’ve seen to handling updates and interruptions was from
someone who had an amazing internal clock; or a watch we never noticed.
When handling an incident he’d essentially give himself a 30 minute,
reset-able, window of time. Once he’d been given the initial
introduction to the incident he’d step back, handle the communication
and anything else the incident responders has asked for and wait for
about 30 minutes.</p>
<p>If no one gave him any new information or status updates he’d consider
it an invitation to interrupt and ask what was going on. Once he’d been
updated he’d move back and let the team run with the problem. If someone
gave him an update before the 30ish minutes were up he’d reset his
timer, leave you alone and try to get whatever you’d asked for. I don’t
know if it was just a well chosen period based on experience or the
limit of his patience but 30 minutes was often enough to stop people
rabbit holing while the fires were raging.</p>
<p>Once I’d left the team he often managed incidents for and became one of
his internal customers I began to notice that everyone in his area
developed the subconscious habit of delivering their status updates
every 25 minutes or so, even when he wasn’t the incident manager for
a specific incident. I never discovered if this was all a deliberate
attempt to set the culture he wanted or he was just being himself but as
someone handling an incident I always appreciated the time and
predictability of his involement. Thanks to LinkedIn and Twitter I could
probably track him down and ask but I’ve always liked the idea it was
just him being himself.</p>
</div></div>]]>
            </description>
            <link>https://www.unixdaemon.net/sysadmin/incident-updates-and-interruptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269804</guid>
            <pubDate>Tue, 25 Aug 2020 10:18:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing good software comments (Part I/2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269760">thread link</a>) | @juanorozcov
<br/>
August 25, 2020 | https://www.brainstobytes.com/writing-good-software-comments-i/ | <a href="https://web.archive.org/web/*/https://www.brainstobytes.com/writing-good-software-comments-i/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<!--kg-card-begin: markdown--><p>Comments are, to put it mildly, a controversial topic.</p>
<p>There are two very strong opinions in software development, both extremely popular and widespread. The first one states that comments are evil, and you should not use them under any circumstance. The main argument is that instead of using comments, you should try to make the code as readable as possible. If the code is written in an expressive way using best practices, comments are not needed.</p>
<p>The second group thinks that comments are a necessity. The code can't hold all the information needed to properly maintain a solution, and comments are an effective way of communication for fellow developers. If all we needed was the code, we could grab the binaries and work from them.</p>
<p>I think both groups have something valuable to teach. It's true that comments can be dangerous, some of the reasons why you might be wary of them are:</p>
<ul>
<li>Comments easily become outdated, and it's unreasonable to expect everyone to update every comment when code changes. It would be an ideal thing, but it rarely happens in reality.</li>
<li>Code is the sole source of truth that is guaranteed to be true at any given point through the lifecycle of software.</li>
<li>A bad comment is worse than no comments at all, as it misleads you into wrong assumptions.</li>
<li>When overused, comments clutter our code and make it harder to find the things we are looking for.</li>
</ul>
<p>Comments are essentially there because we weren't able to perfectly express our ideas in code. Every single time you write a comment, think if it's possible to refactor your code in a way that makes it obvious to the reader. With effort and experience, you can remove most of the unnecessary comments from your projects.</p>
<p>Despite their downsides, comments can be used to effectively communicate with fellow developers. The trick is not to repeat your code, but to clarify its intent and provide valuable extra information that you can't represent in code. If you can keep your comments at a higher level of abstraction, you will have a powerful tool for making your code more maintainable.</p>
<p>Let's take a look at 5 scenarios where using comments can help improve the readability of our code:</p>
<h4 id="explainingtheintentandansweringwhy">Explaining the intent and answering why</h4>
<p>Explaining why things are done in a specific way in the code is one of the most accepted uses for comments.</p>
<p>The reason is simple: code itself only tells you <strong>what</strong> is there, not <strong>why</strong> it is there. The motivations behind seemingly arbitrary choices in design and development are usually found in the documentation, but if you need to keep this information in the source code, comments are the best way of doing it.</p>
<p>Feel free to add comments if you feel that something looks too arbitrary, or to let other developers know why you are doing things the way you are doing them. Don't write a huge essay supporting the choice, a quick one-liner is enough to convey information. Other developers will appreciate this valuable information.</p>
<h4 id="clarifyingdetails">Clarifying details</h4>
<p>Sometimes you need to write small clarifications for input arguments or data returned from a function, in this case, a comment might make things easier to understand.</p>
<p>It's also useful for summarizing a series of complicated operations: writing a small comment that explains the intent of the following lines is useful to understand how they work together.</p>
<p>Another common usage is specifying the units of a variable: is this meant to be a distance in meters or feet?</p>
<p>This might be the weakest use case of the list because comments of this type are rendered useless by giving variables and functions good names. If you want some guidelines for naming variables, you can read the <a href="https://www.brainstobytes.com/writing-good-variable-names/">previous article on the topic</a>.</p>
<h4 id="warningtheuserofamethodaboutsideeffects">Warning the user of a method about side effects</h4>
<p>There are methods with 'dangerous' side effects. Some of them will perform actions that are hard or impossible to revert or will remove records from an important record.</p>
<p>You could have in place some special naming conventions to make this clear. The Ruby community, for example, has a convention for appending a '!' character at the end of methods that perform this type of action. If there is a need for a more detailed explanation, feel free to add a comment explaining the possible dangers of calling a specific method.</p>
<pre><code># Warning!: This method will stop the pipeline and all unprocessed data will be lost, 
# ensure the queue is empty before calling it, otherwise, you might lose data. 
def perform_teardown():
#    Implementation of this method
   return
</code></pre>

<p>You can add little reminders for things you need to improve or refactor later. There are lots of changes that don't merit a new ticket in the issue tracking system, and those little reminders can be useful for not forgetting about these little improvements.</p>
<p>Most modern text editors and IDEs have tools for finding those TODOs, and I have the feature enabled in every single one I use (actually, it's one of the first things I do when setting up a new system). Use them with confidence, TODO comments are ok.</p>
<pre><code># TODO: Find out if there's an efficient alternative for linear algebra and make this method a wrapper around it
def transpose_matrix(matrix)
# code for transposing a matrix
end

</code></pre>
<h4 id="publicapidocumentation">Public API documentation</h4>
<p>Documenting the public interface of your classes is a very important part of software development. You want other users (and well, you too) to know how to use your classes and code. There are many tools that let you convert comments into documentation (PDF, HTML, and other formats), as long as you write your comments with a specific format. The tool will scan your code and extract all the required information for the documents.</p>
<p>Some popular examples are Javadoc for Java and YARD for Ruby, the comments on top of methods look like this:</p>
<p>Javadoc:</p>
<pre><code>/**
 * &lt;p&gt;Translates text from English to alienspeak
 * &lt;/p&gt;
 * @param textInEnglish the text in English I want to translate
 * @return the text after being translated into alienspeak
 */
public String translateToAlienspeak(String textInEnglish) {
    // contents of the function
}
</code></pre>
<p>YARD:</p>
<pre><code># Translates a text from English to alienspeak
#
# @param text_in_english [String] the text in English I want to translate
# @return [String] the text after being translated into alienspeak
def translate_to_alienspeak(text_in_english)
  # content of the function
end
</code></pre>

<p>These are just a couple of cases where comments are helpful, but there are many other scenarios where using a comment is the right thing.</p>
<p>The trick for writing good comments is asking yourself why you are writing them in the first place. Is it to fix a deficiency in the clarity of your code? if that's the case, stop and refactor your code to make it more readable. As we said before, most comments can be omitted in favor of a better-written piece of code.</p>
<p>On the other hand, if you are providing information that your colleagues will find helpful, and there is no way to embed that info in the code, then go for a comment. Good comments can be extremely helpful. Just make sure they are <em>good</em> comments, not lazy patches for code that can still improve.</p>
<p>In the next article, we will see scenarios where comments are definitely a bad choice.</p>
<h2 id="whattodonext">What to do next:</h2>
<ul>
<li>Share this article with friends and colleagues. Thank you for helping me reach people who might find this information useful.</li>
<li>You can find more information about creating good function arguments in chapter 4 of Clean Code, and in chapter 32 of Code Complete. This and other very helpful books can be found in the <a href="https://www.brainstobytes.com/recommended-books/">recommended reading list</a>.</li>
<li>Send me an email with questions, comments or suggestions (it's in the <a href="https://www.brainstobytes.com/about">About Me page</a>). Come on, don't be shy!</li>
</ul>
<!--kg-card-end: markdown-->
					</div></div>]]>
            </description>
            <link>https://www.brainstobytes.com/writing-good-software-comments-i/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269760</guid>
            <pubDate>Tue, 25 Aug 2020 10:11:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Umash: A fast and universal enough hash]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24269645">thread link</a>) | @gbrown_
<br/>
August 25, 2020 | https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/ | <a href="https://web.archive.org/web/*/https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>We accidentally a whole hash function… but we had a good reason!
Our
<a href="https://github.com/backtrace-labs/umash">MIT-licensed UMASH hash function</a>
is a decently fast non-cryptographic hash function that guarantees
a worst-case bound on the probability of collision
<a href="https://en.wikipedia.org/wiki/Universal_hashing#Mathematical_guarantees">between any two inputs generated independently of the UMASH parameters</a>.</p><p>On the
<a href="https://en.wikichip.org/wiki/intel/xeon_platinum/8175m">2.5 GHz Intel 8175M</a>
servers that power <a href="https://backtrace.io/">Backtrace</a>’s hosted
offering, UMASH computes a 64-bit hash for short cached inputs of up
to 64 bytes in 9-22 ns, and for longer ones at up to 22 GB/s, while
guaranteeing that two distinct inputs of at most \(s\) bytes collide
with probability less than \(\lceil s / 2048 \rceil \cdot 2^{-56}\).
If that’s not good enough, we can also reuse most of the parameters to
compute two independent UMASH values. The resulting 128-bit
<a href="https://en.wikipedia.org/wiki/Fingerprint_(computing)">fingerprint function</a>
offers a short-input latency of 9-26 ns, a peak throughput of 11.2
GB/s, and a collision probability of \(\lceil s / 2048 \rceil^2 \cdot
2^{-112}\) (better than \(2^{-70}\) for input size up to 7.5 GB).
These collision bounds hold for all inputs constructed without any
feedback about the randomly chosen UMASH parameters.</p><p>The latency on short cached inputs (9-22 ns for 64 bits, 9-26 ns for
128) is somewhat worse than the state of the art for non-cryptographic
hashes—
<a href="https://github.com/wangyi-fudan/wyhash">wyhash</a> achieves
8-15 ns and <a href="http://fastcompression.blogspot.com/2019/03/presenting-xxh3.html">xxh3</a>
8-12 ns—but still in the same ballpark. It also
compares well with latency-optimised hash functions like
<a href="https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function#FNV-1a_hash">FNV-1a</a>
(5-86 ns) and
<a href="https://en.wikipedia.org/wiki/MurmurHash#MurmurHash2">MurmurHash64A</a>
(7-23 ns).</p><p>Similarly, UMASH’s peak throughput (22 GB/s) does not match
the current best hash throughput (37 GB/s with
<a href="https://github.com/Cyan4973/xxHash">xxh3</a>
and <a href="https://github.com/gamozolabs/falkhash">falkhash</a>, apparently
10% higher with <a href="https://github.com/cmuratori/meow_hash">Meow hash</a>),
but does comes within a factor of two; it’s actually higher than that of
some performance-optimised hashes, like
<a href="https://github.com/wangyi-fudan/wyhash">wyhash</a> (16 GB/s) and
<a href="https://github.com/google/farmhash">farmhash32</a>
(19 GB/s). In fact, even the 128-bit fingerprint (11.2 GB/s) is
comparable to respectable options like
<a href="https://github.com/aappleby/smhasher/blob/master/src/MurmurHash2.cpp#L89">MurmurHash64A</a>
(5.8 GB/s) and
<a href="https://burtleburtle.net/bob/hash/spooky.html">SpookyHash</a> (11.6 GB/s).</p><p>What sets UMASH apart from these other non-cryptographic hash
functions is its proof of a collision probability bound. In the
absence of an adversary that adaptively constructs pathological inputs
as it infers more information about the randomly chosen parameters, we
know that two distinct inputs of \(s\) or fewer bytes will have the
same 64-bit hash with probability at most \(\lceil s / 2048 \rceil
\cdot 2^{-56},\) where the expectation is taken over the random
“key” parameters.</p><p>Only one non-cryptographic hash function in
<a href="https://github.com/rurban/smhasher">Reini Urban’s fork of SMHasher</a>
provides this sort of bound: <a href="https://github.com/lemire/clhash">CLHash</a>
<a href="https://arxiv.org/abs/1503.03465">guarantees a collision probability \(\approx 2^{-63}\)</a>
in the same
<a href="https://en.wikipedia.org/wiki/Universal_hashing#Mathematical_guarantees">universal hashing</a>
model as UMASH. While CLHash’s peak throughput (22 GB/s) is
equal to UMASH’s, its latency on short inputs is worse (23-25 ns
instead of 9-22ns). We will also see that its stronger collision
bound remains too weak for many practical applications. In order to
compute a <a href="https://en.wikipedia.org/wiki/Fingerprint_(computing)">fingerprint</a>
with CLHash, one would have to combine multiple hashes, exactly like
we did for the 128-bit UMASH fingerprint.</p><p>Actual cryptographic hash functions provide stronger bounds in a much
more pessimistic model; however they’re also markedly slower than
non-cryptographic hashes. <a href="https://github.com/BLAKE3-team/BLAKE3">BLAKE3</a>
needs at least 66 ns to hash short inputs, and achieves a peak throughput
of 5.5 GB/s. Even the <a href="https://github.com/rust-lang/rust/issues/29754">reduced-round SipHash-1-3</a>
hashes short inputs in 18-40 ns and longer ones at a peak throughput
of 2.8 GB/s. That’s the price of their pessimistically adversarial
security model. Depending on the application, it can make sense to
consider a more restricted adversary that must prepare its dirty deed
before the hash function’s parameters are generated at random, and
still ask for provable bounds on the probability of collisions.
That’s the niche we’re targeting with UMASH.</p><p>Clearly, the industry is comfortable with no bound at all.
However, even in the absence of
<a href="https://www.131002.net/siphash/#at">seed-independent collisions</a>,
timing side-channels in a data structure implementation could
theoretically leak information about colliding inputs, and iterating
over a hash table’s entries to print its contents can divulge even more
bits. A sufficiently motivated adversary could use something like
that to learn more about the key and deploy an algorithmic denial of
service attack. For example, the linear structure of UMASH (and of
other polynomial hashes like CLHash) makes it easy to combine known
collisions to create exponentially more colliding inputs. There is no
universal answer; UMASH is simply another point in the solution space.</p><p>If reasonable performance coupled with an actual bound on collision
probability <em>for data that does not adaptively break the hash</em> sounds
useful to you,
<a href="https://github.com/backtrace-labs/umash">take a look at UMASH on GitHub</a>!</p><p>The <a href="#but-why">next section</a> will explain why we found it useful to
design another hash function. The rest of the post
<a href="#umash-high-level">sketches how UMASH works</a> and
<a href="#implementation-tricks">how it balances short-input latency and strength</a>,
before <a href="#usage">describing a few interesting usage patterns.</a></p><p><small>The latency and throughput results above were all measured on
the same unloaded 2.5 GHz Xeon 8175M. While we did not disable
frequency scaling (#cloud), the clock rate seemed stable at 3.1
GHz during our run.</small></p><h2 id="a-idbut-whyahow-did-we-even-get-here"><a id="but-why"></a>How did we even get here?</h2><p>Engineering is the discipline of satisficisation: crisply defined
problems with perfect solutions rarely exist in reality, so we must
resign ourselves to satisfying approximate constraint sets “well
enough.” However, there are times when all options are not only
imperfect, but downright sucky. That’s when one has to put on a
different hat, and question the problem itself: are our constraints
irremediably at odds, or are we looking at an under-explored
solution space?</p><p>In the former case, we simply have to want something else. In the
latter, it might make sense to spend time to really understand the
current set of options and hand-roll a specialised approach.</p><p>That’s the choice we faced when we started caching intermediate
results in
<a href="https://help.backtrace.io/en/articles/2428859-web-console-overview">Backtrace’s database</a>
and found a dearth of acceptable hash functions. Our in-memory
columnar database is a core component of the backend, and, like most
analytics databases, it tends to process streams of similar queries.
However, a naïve query cache would be ineffective: our more heavily
loaded servers handle a constant write load of more than 100 events
per second with dozens of indexed attributes (populated column values)
each. Moreover, queries invariably select a large number of data
points with a time windowing predicate that excludes old data… and
the endpoints of these time windows advance with each wall-clock
second. The queries evolve over time, and must usually consider newly
ingested data points.</p><p><a href="https://www.gsd.inesc-id.pt/~rodrigo/slider_middleware14.pdf">Bhatotia et al’s Slider</a>
show how we can specialise the idea of
<a href="http://adapton.org/">self-adjusting or incremental computation</a>
for repeated MapReduce-style queries over a sliding window.
The key idea is to split the data set at stable boundaries (e.g., on
date change boundaries rather than 24 hours from the beginning of the
current time window) in order to expose memoisation opportunities, and
to do so recursively to repair around point mutations to older data.</p><p>Caching fully aggregated partial results works well for static
queries, like scheduled reports… but the first step towards creating
a great report is interactive data exploration, and that’s an activity
we strive to support well, even when drilling down tens of millions of
rich data points. That’s why we want to also cache intermediate
results, in order to improve response times when tweaking a saved
report, or when crafting ad hoc queries to better understand how and
when an application fails.</p><p>We must go back to a
<a href="http://www.umut-acar.org/self-adjusting-computation">more general incremental computation strategy</a>:
rather than only splitting up inputs, we want to stably partition the
data dependency graph of each query, in order to identify shared
subcomponents whose results can be reused. This finer grained
strategy surfaces opportunities to “resynchronise” computations, to
recognize when different expressions end up generating a subset of
identical results, enabling reuse in later steps. For example, when
someone updates a query by adding a selection predicate that only
rejects a small fraction of the data, we can expect to reuse some of
the post-selection work executed for earlier incarnations of the
query, if we remember to key on the selected data points rather than
the predicates.</p><p>The complication here is that these intermediate results tend to be
large. Useful analytical queries start small (a reasonable query
coupled with cache/transaction invalidation metadata to stand in for
the full data set), grow larger as we select data points, arrange them
in groups, and materialise their attributes, and shrink again at the
end, as we summarise data and throw out less interesting groups.</p><p>When caching the latter shrinking steps, where resynchronised reuse
opportunities abound and can save a lot of CPU time, we often
find that storing a fully materialised representation of the cache key
would take up more space than the cached result.</p><p>A classic approach in this situation is to fingerprint cache keys with
a cryptographic hash function like
<a href="https://en.wikipedia.org/wiki/BLAKE_(hash_function)">BLAKE</a>
or <a href="https://en.wikipedia.org/wiki/SHA-3">SHA-3</a>, and store a
compact (128 or 256 bits) fingerprint instead of the cache key: the
probability of a collision is then so low that we might as well assume
any false positive will have been caused by a bug in the code or a
hardware failure. For example,
<a href="https://users.ece.cmu.edu/~omutlu/pub/memory-errors-at-facebook_dsn15.pdf#page=3">a study of memory errors at Facebook</a>
found that uncorrectable memory errors affect 0.03% of servers each
month. Assuming a generous clock rate of 5 GHz, this means each
clock cycle may be afflicted by such a memory error with probability
\(\approx 2.2\cdot 10^{-20} &gt; 2^{-66}.\) If we can guarantee that
distinct inputs collide with probability significantly less than
\(2^{-66}\), e.g., \(&lt; 2^{-70},\) any collision is far
more likely to have been caused by a bug in our code or by
hardware failure than by the fingerprinting algorithm itself.</p><p>Using cryptographic hashes is certainly safe enough, but requires a lot of
CPU time, and, more importantly, worsens latency on smaller keys (for
which caching may not be that …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/">https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/</a></em></p>]]>
            </description>
            <link>https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269645</guid>
            <pubDate>Tue, 25 Aug 2020 09:51:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My AI Timelines Have Sped Up]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24269316">thread link</a>) | @T-A
<br/>
August 25, 2020 | https://www.alexirpan.com/2020/08/18/ai-timelines.html | <a href="https://web.archive.org/web/*/https://www.alexirpan.com/2020/08/18/ai-timelines.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>For this post, I’m going to take artificial general intelligence (AGI) to mean
an AI system that matches or exceeds humans at almost all (95%+)
economically valuable work. I prefer this definition because it focuses on what
causes the most societal change, rather than how we get there.</p>

<p>In 2015, I made the following forecasts about when AGI could happen.</p>

<ul>
  <li>10% chance by 2045</li>
  <li>50% chance by 2050</li>
  <li>90% chance by 2070</li>
</ul>

<p>Now that it’s 2020, I’m updating my forecast to:</p>

<ul>
  <li>10% chance by 2035</li>
  <li>50% chance by 2045</li>
  <li>90% chance by 2070</li>
</ul>

<p>I’m keeping the 90% line the same, but shifting everything else to
be faster. Now, if you’re looking for an argument of why I picked these particular
years, and why I shifted by 10 years instead of 5 or 15, you’re going to be
disappointed. Both are driven by a gut feeling.
What’s important is why parts of my thinking have changed - you can choose
your own timeline adjustment based on that.</p>

<p>Let’s start with the easy part first.</p>

<h2 id="i-should-have-been-more-uncertain">I Should Have Been More Uncertain</h2>

<p>It would be incredibly weird if I was never surprised by machine learning (ML)
research.
Historically, it’s very hard to predict the trajectory a research field will
take, and if I were never surprised, I’d take that as a personal failing to
not consider large enough ideas.</p>

<p>At the same time, when I think back on the past 5 years, I believe I was
surprised more often than average. It wasn’t all in a positive direction.
Unsupervised learning got better way faster than I expected. Deep reinforcement
learning got better
a little faster than I expected. Transfer learning has been slower than
expected. Combined, I’ve decided I should widen the distribution of outcomes,
so now I’m allocating 35 years to the 10%-90% interval instead of 25 years.</p>

<p>I also noticed that my 2015 prediction placed 10% to 50% in a 5 year range,
and 50% to 90% in a 20 year range. AGI is a long-tailed event, and there’s
a real possibility it’s never viable, but a 5-20 split is absurdly skewed.
I’m adjusting accordingly.</p>

<p>Now we’re at the hard part. Why did I choose to shift the 10% and 50% lines
closer to present day?</p>



<p>Three years ago, I was talking to someone who mentioned
that <a href="https://intelligence.org/2017/10/13/fire-alarm/">there was no fire alarm for AGI</a>.
I told them I knew Eliezer Yudkowsky had written another post about AGI, and
I’d seen it shared among Facebook friends, but I hadn’t gotten around to reading it.
They summarized it as, “It will never be obvious when AGI is going to occur.
Even a few years before it happens, it will be possible to argue AGI is far
away. By the time it’s common knowledge that AI safety is the most
important problem in the world, it’ll be too late.”</p>

<p>And my reaction was, “Okay, that matches what I’ve gotten from my Facebook
timeline. I already know the story of
Fermi predicting <a href="https://books.google.com/books?id=aSgFMMNQ6G4C&amp;pg=PA813&amp;lpg=PA813&amp;dq=weart+fermi&amp;source=bl&amp;ots=Jy1pBOUL10&amp;sig=c9wK_yLHbXZS_GFIv0K3bgpmE58&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjNofKsisnWAhXGlFQKHbOSB1QQ6AEIKTAA#v=onepage&amp;q=%22ten%20per%20cent%22&amp;f=false">a nuclear chain reaction was very likely
to be impossible</a>, only a few years before he worked on the
Manhattan Project. More recently, we had
<a href="https://www.wired.com/2014/05/the-world-of-computer-go/">Rémi Coulom state that superhuman Go was about 10 years away</a>,
one year before <a href="https://arxiv.org/abs/1412.6564">the first signs it could happen</a>,
and two years before <a href="https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol">AlphaGo</a> made it official.
I <em>also</em> already know the <a href="https://en.wikipedia.org/wiki/Common_knowledge_(logic)">common knowledge</a>
arguments for AI safety.”
I decided it wasn’t worth my time to read it.</p>

<p>(If you haven’t heard the common knowledge arguments, here’s the quick
version: it’s possible for the majority to believe AI safety is
worthwhile, even if no one says so publicly, because each individual could be
afraid everyone else will call them crazy if they argue for drastic action. This can happen
even if literally everyone agrees, because they don’t know that everyone agrees.)</p>

<p>I read the post several years later out of boredom, and
I now need to retroactively complain to all my Facebook friends who only
shared the historical events and common knowledge arguments. Although
that post summary is <em>correct</em>, the ideas I found useful were all
<em>outside that summary</em>. I trusted you, filter bubble! How could you let me
down like this?</p>

<p>Part of the fire alarm post proposes hypotheses for why people claim AGI is
impossible. One of the hypotheses is that researchers pay too much attention
to the difficulty of getting something working with their current tools,
extrapolate that difficulty to the future, and conclude we could never create
AGI because the available tools aren’t good enough.
This is a bad argument, because your extrapolation needs to account for
research tools also improving over time.</p>

<p>What “tool” means is a bit fuzzy. One clear example is our coding libraries.
People used to write neural nets in Caffe, MATLAB, and Theano. Now it’s mostly
TensorFlow and PyTorch. A less obvious example is
feature engineering for computer vision. When was the
last time anyone talked about <a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">SIFT features</a> for computer vision? Ages ago,
they’re obsolete. But feature engineering didn’t disappear, it just turned into
<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural net</a> architecture tuning instead.
For a computer vision researcher, SIFT features were the old tool,
convolutional neural nets are the new tool, and computer vision is the application
that’s been supercharged by the better tool.</p>

<p>Whereas for me, I’m not a computer vision person. I think ML for control is a much
more interesting problem. However, you have to do computer vision to do control
in image-based environments, and if you want to handle the real world, image-based
inputs are the way to go. So for me, computer vision is the tool, robotics
is the application, and the improvements in computer vision have driven many
promising robot learning results.</p>

<p><img src="https://www.alexirpan.com/public/ai-timelines/filters.png" alt="AlexNet conv filters"></p>

<p>(Filters automatically learned by <a href="https://en.wikipedia.org/wiki/AlexNet">AlexNet</a>, which has
itself been obsoleted by the better tool, <a href="https://en.wikipedia.org/wiki/Residual_neural_network">ResNets</a>.)</p>

<p>I’m a big advocate for research tools. I think on average, people underestimate
their impact. So after reading the hypothesis that people don’t forecast
tool improvement properly, I thought for a bit, and decided I hadn’t properly
accounted for it either. That deserved shaving off a few years.</p>

<p>In the more empirical sides of ML, the obvious components of progress are your
ideas and computational budget, but there are less obvious ones too, like
your coding and debugging skills, and your ability to utilize your compute.
It doesn’t matter how many processors you have per machine, if your code doesn’t
use all the processors available.
There are a surprising number of ML applications where the main value-add
comes from better data management and data summarizing,
because those tools free up decision making time for everything else.</p>

<p>In general, everyone’s research tools are deficient in some way.
Research is
about doing something new, which naturally leads to discovering new problems,
and it’s highly unlikely someone’s already made the perfect tool for a problem
that didn’t exist three months ago. So, your current
research tools will <em>always</em> feel janky, and you shouldn’t be using that to
argue anything about timelines.</p>

<p>The research stack has lots of parts, improvements continually happen across that
entire stack, and most of
these improvements have multiplicative benefits. Multiplicative factors
can be very powerful.
One simple example is that to get 10x better results, you can either make one
thing 10x better with a paradigm shift, or you can make ten different
things
<a href="https://www.google.com/search?&amp;q=1.26^10">1.26x better</a>, and they’ll combine
to a 10x total improvement.
The latter is just as transformative, but can be much easier,
especially if you get 10 experts with different skill sets
to work together on a common goal. This is how corporations become a thing.</p>

<p><img src="https://www.alexirpan.com/public/ai-timelines/tiny-gains-graph.jpg" alt="Tiny gains graph"></p>

<p>(From <a href="https://jamesclear.com/marginal-gains">JamesClear.com</a>)</p>

<h2 id="semi-supervised-and-unsupervised-learning-are-getting-better">Semi-Supervised and Unsupervised Learning are Getting Better</h2>

<p>Historically, unsupervised learning has been in this weird position where it is
obviously the right way to do learning, and also a complete waste of time if
you want something to work ASAP.</p>

<p>On the one hand, humans don’t have labels for most things they learn,
so ML systems shouldn’t need labels either. On the other hand, the
deep learning boom of 2015 was mostly powered by supervised learning on
large, labeled datasets.
Richard Socher made a notable tweet at the time:</p>

<div>
<blockquote><p lang="en" dir="ltr">Rather than spending a month figuring out an unsupervised machine learning problem, just label some data for a week and train a classifier.</p>— Richard Socher (@RichardSocher) <a href="https://twitter.com/RichardSocher/status/840333380130553856?ref_src=twsrc%5Etfw">March 10, 2017</a></blockquote> 
</div>

<p>I wouldn’t say unsupervised learning has always been useless. In 2010, it was
common wisdom that deep networks should go through an unsupervised pre-training
step before starting supervised learning. See <a href="https://jmlr.csail.mit.edu/papers/volume11/erhan10a/erhan10a.pdf">(Erhan et al, JMLR 2010)</a>.
In 2015, self-supervised word vectors like <a href="https://nlp.stanford.edu/projects/glove/">GloVe</a>
and <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> were automatically
learning interesting relationships between words.
As someone who started ML around 2015,
these unsupervised successes felt like exceptions to the rule. Most other
applications relied on labels. Pretrained ImageNet features
were the closest thing to general behavior, and those features were learned
from scratch through only supervised learning.</p>

<p>I’ve long agreed that unsupervised learning is the future, and the right way
to do things, as soon as we figure out how to do so.
But man, we have spent a long time trying to do so.
That’s made me
pretty impressed with the semi-supervised and unsupervised learning papers from
the past few months.
Momentum Contrast from <a href="https://arxiv.org/abs/1911.05722">(He et al, CVPR 2020)</a>
was quite nice, SimCLR from <a href="https://arxiv.org/abs/2002.05709">(Chen et al, ICML 2020)</a> improved
on that, and Bootstrap Your Own Latent <a href="https://arxiv.org/abs/2006.07733">(Grill, Strub, Altché, Tallec, Richemond et al, 2020)</a>
has improved on that. And then there’s <a href="https://arxiv.org/abs/2005.14165">GPT-3</a>,
but I’ll get to that later.</p>

<p>When I was thinking through what made ML hard, the trend lines were pointing to larger
models and larger labeled datasets. They’re still pointing that way now.
I concluded that future ML progress would be bottlenecked by labeling requirements.
Defining a 10x bigger model is easy. <em>Training</em> a 10x bigger model is harder, but
it doesn’t need 10x as many people to work on it. Getting 10x as many labels
does. Yes, data labeling tools are getting better, <a href="https://en.wikipedia.org/wiki/Amazon_Mechanical_Turk">Amazon Mechanical Turk</a> is very popular, and there are even
startups whose missions are to provide fast data labeling …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alexirpan.com/2020/08/18/ai-timelines.html">https://www.alexirpan.com/2020/08/18/ai-timelines.html</a></em></p>]]>
            </description>
            <link>https://www.alexirpan.com/2020/08/18/ai-timelines.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269316</guid>
            <pubDate>Tue, 25 Aug 2020 08:41:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY Single-Chip 2D Retro Game Console]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24268585">thread link</a>) | @0xmarcin
<br/>
August 24, 2020 | http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm | <a href="https://web.archive.org/web/*/http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <td rowspan="4">
      <div>
			<iframe width="420" height="315" src="//www.youtube.com/embed/VbTwWFwbsE4" frameborder="0" allowfullscreen=""></iframe>
			<p>
			<img height="420" src="http://www.voja.rs/PROJECTS/GAME_HTM/console.jpg" width="600"></p>
			<p>This 
			DIY project offers the
            simple stand-alone VGA game console which is based on <b> PIC24EP512GP202</b>  microcontroller.
            As the video signal and the corresponding sync signals are generated by software, 
			the console contains a
            minimum of hardware. There is also an audio signal output with five binary tone channels, mixed by 
			a 
			passive resistor network. Two of those channels are used for sound effects,  
			similar to ones used in video games of that time (early eighties) and 
			three for background music. This output is capable of driving line 
			output for PC speakers or headphones.</p>
			<p>
			It should be noted that there is no video processing unit, PGA or 
			any special purpose chips, and that PIC microcontrollers are not 
			designed for video signal generation. Everything is achieved by a 
			series of different design tricks and some compromises.</p>
			<p>
			This is an open hardware and open software project. Video 
			and audio generators, which are the vital parts of the firmware, are 
			the parts of the operating system, which will soon be documented, and can be used 
			for any other game or application. As the timings are critical, those parts 
			are written in assembly language, but all the other parts of the 
			program (scenario for some other games or any other application) may 
			also be written in some other programming language, preferably 
			Microchip's C. In this case all parts are written in Assembler, but 
			only as a result of author's preference.</p>
			<p>
			At the moment, only the game Jumping Jack is written for the 
			platform, well known to those who played with the Spectrum personal 
			computer back in the day. However, once a new game is created, it is 
			easy to download it from the computer, via 
			the serial port. The console has a USB connector, but it is used 
			only for 5V power supply. Unfortunately, microcontrollers which are 
			packed in DIP packages (with thru-hole soldering, convenient for DIY 
			projects and workshops) do not have USB interface but only serial ports, so 
			you have to use RS 232 to download the new game instead of Jumping 
			Jack, which is deafult in this project.</p>
			<p>
			If you want to build this console, you need the PCB and components 
			which are listed <span><strong>
			<a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm#BOM">here</a></strong></span>. 
			To program the microcontroller, you should need a PIC programmer (e.g. 
			<strong>PICKIT3</strong>, avaliable <span><strong>
			<a href="http://www.microchipdirect.com/ProductSearch.aspx?Keywords=PG164130">here</a></strong></span>) and
			<strong>MPLAB X IDE</strong> software, available <span><strong>
			<a href="http://www.microchip.com/pagehandler/en-us/family/mplabx/">here</a></strong></span>. 
			But if you want to know how PIC generates video and audio signals by 
			software in real time, or even if you feel ambitious enough to 
			create your own game for this platform, please visit the
			<span>
			<strong><a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm">next page</a></strong></span></p>
          </div>
    </td>
  </div></div>]]>
            </description>
            <link>http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268585</guid>
            <pubDate>Tue, 25 Aug 2020 06:23:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Renaissance of the Shell?]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24268533">thread link</a>) | @dwmkerr
<br/>
August 24, 2020 | https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/ | <a href="https://web.archive.org/web/*/https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This is the first of the “interludes” which end each section of the book. They don't teach any specific skills but instead give a little flavour and background about the world of the shell, Linux and modern computing.</p><p>In this first interlude we'll look at just why the shell is experiencing something of a renaissance in the modern age of IT.</p><p>To be honest, it is hard to know whether there is an increase in popularity of the use of the shell and command-line tooling in general. There are data sources which indicate there is more widespread usage amongst the technical community - Stack Overflow tag popularity is one. LinkedIn data on desired skillsets is another. However, disassociating whether there is a general increase in the need for diverse technical skillsets and whether there is a <em>specific</em> increase in the popularity of keyboard and script operated systems is a challenge.</p><p>For the purposes of this chapter, we'll instead examine changes in the technology landscape over the last few decades and consider what those changes might mean for the shell, the command-line and similar tools.</p><p>We'll look at three specific developments in technology:</p><ul><li>Diversity of programming languages</li><li>Convergence of operating platforms</li><li>DevOps</li></ul><p>Each of these developments has a potentially profound impact on how we work with computers, and might hint at the long term need for shell skills.</p><p>So let's look at some of the key changes in the technology landscape over recent years and consider how they might affect the popularity and importance of the shell.</p><h2 id="the-diversity-of-programming-languages">The Diversity of Programming Languages</h2><p>There have been many programming languages and platforms over the years. But in recent years it is possible that the diversity has increased at a greater rate than ever before.</p><p>With the advent of the internet and the increase in the size of the online technical community, programming has in a sense become more democratised (which we will discuss a little more in the ‘citizen coder’ section). When in the past it was necessary to find physical books or teachers and tutors to learn a programming language, students can now find a wealth of resources online.</p><p>It is perhaps this democratisation which has led to a startlingly diverse world of programming languages. For many years, there were a small number of ‘general purpose’ languages, and a larger number of highly specialised languages (and associated platforms).</p><p>“C”, and later, “C++” were the go-to languages for systems programming (sometimes backed up by assembly language). This was the language which kernels and compilers were written in.</p><p>“Java” become the ‘general purpose’ language of choice for applications which had to run on many systems. “Basic” and later “C#” were the standards for Windows platform development. PHP was a staple for web development.</p><p>Alongside these giants were the workhorses for specific use cases. Erlang was (and is) a language which is highly popular in the telecommunications industry, where high availability and reliability were paramount. COBOL was the language for the financial industry, where mission critical systems ran on mainframes (and many still do).</p><p>Of course there were many other languages, but many of these other languages were highly specific, in a sense C, Java, PHP and later C# dominated the landscape.</p><p>Transition to the time of writing. In the Stack Overflow 2020 Technology Survey[^1], the top ten languages most wanted by employers are:</p><ul><li>Python</li><li>JavaScript</li><li>Go</li><li>TypeScript</li><li>Rust</li><li>Kotlin</li><li>Java</li><li>C++</li><li>SQL</li><li>C#</li></ul><p>Some of our old friends are there, but there are many new languages, languages which are evolving quickly. Later on in the list we will see Swift, Dart, Ruby, Haskell, Scala. There are many programming languages which are extremely popular today.</p><p>Why does this matter for the shell? The answer is that for <em>many</em> new languages, developer tooling is not as mature (some might say bloated) as it is for the ‘Workhorse’ languages. Java developers are likely very familiar with the Eclipse IDE, Microsoft shops will be familiar with Visual Studio. These are products which have been evolving for years (or decades) to support developers with rich integrated development environments.</p><p>For server-side JavaScript, Golang, Rust, Python and other languages, the development environment really is the shell. Modern editors like Visual Studio Code, Atom and so on provide a vast amount of support and tooling, encompassing the features of a full fledged IDE if the user wants. But for modern programming languages, users often have <em>had</em> to rely on the shell to compile, transpile, manage packages, bundle and so on. The average developer today is perhaps much more likely to have to use the shell - to manage Python virtual environments one day, to run Node.js another, to install packages for Golang another.</p><p>In time tooling will likely catch up and provide a ‘friendly’ interface on top of these operations, but many engineers have realised (or always known) that direct access to simple command line tools can be <em>extremely efficient</em> when working, and that overly featured IDEs can get in the way and hide complexity.</p><p>The modern programming is often polyglot - having to be at least familiar in a number of languages. The shell provides a common environment and interface for tooling, which is accessible by all, without installing many complex components, for both development and runtime environments.</p><h2 id="convergence-of-operating-platforms">Convergence of Operating Platforms</h2><p>Whilst the variety in programming languages and developer tooling may have increased, in many ways the <em>operating platforms</em> engineers use have become more homogeneous.</p><p>In the early days of computing, each operating environment was highly diverse. There were many systems which were used for production and many of them were highly proprietary. Even popular application servers were often closed source and highly specialised.</p><p>The modern execution environment however is often fairly uniform. A Linux-like system, with few customisations, which the developer or operator can tweak to suit their needs.</p><p>More and more enterprise users have moved away from proprietary Unix platforms to Linux platforms (whether commercial or non-commercial). The earliest cloud environments were using open-source Linux distributions as the available operating systems.</p><p>Even Windows has increasing support for Linux-like operation, in the form of the Windows Subsystem for Linux.</p><p>Perhaps the greatest movement in this area has been the rapid adoption of Docker as a common container technology. Containers, or container-like systems have been around for a long time, but Docker brought containers to the masses. With Docker, engineers expect operating environments to be even more uniform and Linux-like.</p><p>This has made knowledge of the shell extremely valuable. For any containerised workloads, Linux and shell skills are crucial. Kubernetes (as an execution environment) has standardised things even more.</p><p>Whilst there are still many workloads which run on proprietary systems, modern solutions are often built to run in containers on Linux. The shell has historically been the most common way to manage Linux systems, and the standardisation of operating environments around Linux, or Linux-like systems has made shell skills even more critical.</p><h2 id="devops">DevOps</h2><p>Love it or hate it, DevOps has exploded in popularity. DevOps engineers, site-reliability engineers, these kinds of roles may have been unheard of in companies not that long ago and are now becoming ubiquitous.</p><p>In attempting to unify the goals of development and operation of software, DevOps represents an organisational and cultural change. Rather than having one group focus on feature development and another group focus on reliable software operations, a single group is responsible for both. The theory is that this encourages software engineers to also consider security, reliability, maintainability etc, and operators to also consider speed of delivery.</p><p>Regardless of whether teams are genuinely combined, or specialised roles are added to teams, or even if teams are still separated, the lines between development and operations blur somewhat. Software developers are expected to build and plan with knowledge of the execution environment, operators are expected to work with developers to build features which support reliability.</p><p>The intersection of these two roles often is in the realm of automation. Automated deployments after testing, automated failover in case of errors, automated alerting when potential issues are discovered, automated provisioning of environments, automated scaling of systems when load increases.</p><p>The world of automation is intimately linked to the world of the shell and in particular shell scripting. Many tasks which require automation can be easily achieved using shell scripts. Many aspects of modern environments (such as cloud environments) support provisioning and management of services via scripting. In fact, services which <em>cannot</em> be managed via shell scripts or simple interfaces are increasingly becoming obsolete. If it cannot be scripted, it cannot be automated, and the increasingly complex systems we build <em>require</em> automation.</p><p>In practice, this means software engineers are far more likely to have to build shell scripts (or at least understand how to interface with systems via the shell) than they perhaps might have been. Similarly, operators are far more likely to have to <em>program</em> automated routines to manage high availability and so on. Again, the shell and shell scripts are a common way to manage this (even if they are simply entrypoints to more complex systems, such as scripts which execute programs).</p><p>The rise in popularity of DevOps as a set of practices and beliefs has perhaps made the shell more popular, and more important, than any other recent developments in software engineering.</p><p>And for these reasons and many more, learning how to use the shell effectively has never been more relevant or practical.</p></article></div>]]>
            </description>
            <link>https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268533</guid>
            <pubDate>Tue, 25 Aug 2020 06:13:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cyph and PGP – An Alternative to Keybase]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24268298">thread link</a>) | @LaSombra
<br/>
August 24, 2020 | https://www.cyph.com/blog/cyph-pgp | <a href="https://web.archive.org/web/*/https://www.cyph.com/blog/cyph-pgp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main><article><div><div><p><img src="https://www.cyph.com/wp-content/uploads/2020/06/AdobeStock_296619919.png?ef8fdd9eb11b8a5b7c39e3671fa0de8da9750a94d0c5b7339c6f8a91bd5dd134b356d2c31d8f0742a87b385c263376447a98a62bed24dfa27e7dfaa20e370124" alt="Cyph + PGP"></p></div></div></article><section><div><p><span>One of our major competitors, Keybase, was </span><a href="https://news.ycombinator.com/item?id=23102430"><span>acquired by Zoom</span></a><span> last month.</span></p><p><span>Many Keybase users are now </span><a href="https://news.ycombinator.com/item?id=23103386"><span>looking for alternatives</span></a><span> as a result, primarily due to a lack of trust in the new ownership to maintain high privacy standards, as well as speculation that the service is now doomed to ultimately be shut down. However, no single solution has so far stood out from the crowd; instead, users are faced with the prospect of setting up a hodgepodge of independent solutions.</span></p><p><span>Keybase is great, but a full alternative is clearly needed. That’s why we’ve spent the past month building new features to make Cyph more of a direct replacement.</span></p><p><img src="https://www.cyph.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-10-at-4.38.11-PM-1024x640.png?9e56b59e17dd8d0c24ced228ed7ea88c2bcabfe24b86ae53a95ba06df0fb6d2b2fa818ab92622828b0eba4e32774328f7715ea8cc2eb380f2f14521decd6842b" alt="" width="560" height="350"></p><p><span>Cyph’s features and general architecture are similar in many ways to Keybase, plus/minus a few features:</span></p><ul><li><span>On the plus side, our features include voice/video calling (with group support), Bitcoin, and social networking (like Twitter, but all posts are signed + optionally encrypted for a subset of your contacts).</span></li><li><span>On the minus side, Keybase offers some awesome niche features (like encrypted git repos) that we currently do not.</span></li><li><span>And now, with our latest release, we’ve built out a set of PGP key management and utility features to make Cyph more immediately useful for users coming from Keybase.</span></li></ul><p><img src="https://www.cyph.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-10-at-4.39.49-PM-1024x640.png?f0bd1ee3132c87cc78b8cedeb60710eeb23fd5a7f872ad008ea828201a5fddb2fc486aab5a5ddcc0f006233616219034b2a9fb46fd4f93ec95de99dc175143cc" alt="" width="560" height="350"></p><p><span>Additionally, the architecture of Cyph yields some </span><i><span>significant</span></i><span> broader advantages:</span></p><ul><li><span>Full web support</span><ul><li><span>Whereas Keybase splits up its features between the web UI, the CLI, GPG, and the native apps, thanks to </span><a href="https://www.cyph.com/websign"><span>WebSign</span></a><span> Cyph is able to provide a consistent experience across all platforms. The full functionality is available regardless of whether you use </span><a href="https://cyph.app/"><span>https://cyph.app</span></a><span> or the desktop and mobile apps, with no need to worry about degraded security on the web.</span></li></ul></li><li><a href="https://www.cyph.com/agse"><span>Automatic strong public key authentication</span></a><span> for all users</span><ul><li><span>No need to verify keys or usernames out of band, meet up in person to compare fingerprints or “Safety Numbers”, etc.</span></li></ul></li><li><a href="https://www.cyph.com/blog/quantum-resistance"><span>Quantum-resistant cryptography</span></a><ul><li><span>Post-quantum encryption, key exchange, and signing algorithms are used throughout the application (in combination with classical crypto such as elliptic curves). Whereas others are still planning long-term migrations to post-quantum crypto, Cyph was built with it in mind from the start, meaning that your private data is theoretically protected from future QC attacks </span><i><span>today</span></i><span>.</span></li></ul></li></ul><p>We encourage you to submit a response to <a href="https://docs.google.com/forms/d/e/1FAIpQLSdMOdjPKf1O3jb2vBURF5N-UGsr08XLO6GJazlUOy1r_sCnKQ/viewform">our poll</a><span> to vote on the missing features you’d like us to add. And if you’re a Keybase user, just include your username and email address to skip the line and get a free invite to the Cyph beta!</span></p></div></section><section></section></main></div></div></div>]]>
            </description>
            <link>https://www.cyph.com/blog/cyph-pgp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268298</guid>
            <pubDate>Tue, 25 Aug 2020 05:15:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Animal behavior during a solar eclipse]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24268252">thread link</a>) | @everbody
<br/>
August 24, 2020 | https://readwildness.com/23/poli-eclipse | <a href="https://web.archive.org/web/*/https://readwildness.com/23/poli-eclipse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				
				<p><span>The farm dimmed mid-afternoon</span>, dipping into dusk-light. Beside the parked tractors, we passed around a block of green glass from a welder’s helmet and took turns looking through it up at the sky. I chewed a single pebble of a snap pea in my mouth. That was the size of the sun through the glass, I thought, no bigger than a pea, a sliver missing as if chewed by a caterpillar or potato beetle.</p>
				
				<p>In a total solar eclipse, photosynthesis slows down. Plants, which turn to face the sun throughout the day, may change direction, feeling for the light. Without the sun, they become unmoored. Lost in the dark. In the 2017 eclipse, changes in light intensity were attributed to bees going temporarily still. Observers in the path of totality—the stretch of land where the sun goes fully dark—reported fireflies emerging, crickets chirping. Night behavior bleeding into day.</p>
				
				<p>I stared through the glass. Sun the size of a blueberry. Size of a chrysanthemum bud.</p>
				
				<p>We wouldn’t get to see the total eclipse—that dramatic upheaval of the afternoon’s forward march, an ebb when there should be flow. The path of totality was south of us, stretching from Oregon to South Carolina. Still, the light waned at our small farm. Contrast became muted, the sky and hayfields feeling duller, softer. The zinnia patch still sparked with its shocks of red, orange, pink, yellow, but the flowers seemed unsure of themselves. The shadows from the trees did strange things, cast crescent-shaped spells on the ground, reminding me of the light funneled through a dime-store kaleidoscope. Someone arrived with a pair of glasses—the kind made from plastic and cardboard that they’d been selling at gas stations for months, running out in the final few days. We passed them around, but <span>I preferred the welding glass, the way it turned the sliver of sun goblin-green.</span></p>
				
				<p>Sun the size of a kernel of the summer’s first sweet corn; the size of a worm, coiled inside an ear from the later crop, chewing on its silky tassel.</p>
				
				<p>During a total solar eclipse, dairy cows have been known to return to their barn as the sun and sky darken. Orb-weaving spiders have been observed taking down their webs during totality, then rebuilding them <span>when the sun reappears. Some species of birds will sing out their night calls,</span> then go to their roosts, falling silent; when the sun reappears, they start their morning rituals. In this sense, the eclipse is a microcosm of night, the dark sped up, the hour hand spinning around a clock at a horse’s trot.</p>
				
				<p>Sun the size of a pepper seed. Size of a flea beetle. A ladybug resting on a windowsill. A thistle bur stuck to a coat.</p>
				
				<p>There is no evidence that an eclipse affects the behavior of horses, but nevertheless, there will be some owners who usher them into the safety of the barn before the sky goes dark. This is a form of love which happens to involve a kind of captivity.</p>
				
				<p>Sun the size of a nostril, size of a belly button, a baby’s tooth, a fingertip. Size of the chunk of flesh I’d sliced off the top of my thumb one day when I was careless with a head of cauliflower. It bled so much and so steadily that I ran to the back of the farm stand where someone sat me down on a bench to bandage the cut. I remember they held my hand so carefully, tilting it one direction then the other, saying twice, maybe three times, <i>You need to be more careful</i>.</p>
				
				<p>Once we’d passed around the glass, we scattered to our different jobs. I drove back to the snap pea patch, where I continued filling a bucket with round, ripe pods. I heard a tractor starting, the exhaust clearing its throat, then watched from where I was crouched as someone connected a hay rake to the back and pulled back onto the road, headed for one of the higher fields, leaving a cloud of dust and acres of silence behind. I realized then that the birds, which were usually a constant chorus, had gone quiet—the small snapping of my hands plucking peas from their vines, the only noise that reached me. I stood, stretching, and looked at the sky, the familiar fields—their flat, muted light. I stood there looking at the farm that for years I had grown to know and care for, and I thought of scale—of how the land surrounding me had come to feel like it was my own body, a breathing, pulsing creature that could weep or swell; and, at the same time, how the land felt unthinkably large—a roaring sun—the weight of it and of the people who worked it reaching deep into the smallest cracks and crevasses of my life like the tendrilled arms of solar flares bursting.</p>
				
				<p>I thought of all of this as I rolled another snap pea over my tongue, biting down, tasting the small eruption of green. Then I bent down, knees to dirt, to finish my work.</p>
				
				<hr>
				
				<p>Read more from <a href="https://readwildness.com/23">Issue No. 23</a> or share  on <a href="http://www.facebook.com/share.php?u=http://readwildness.com/23/poli-eclipse">Facebook</a> and <a href="https://twitter.com/share?url=http://readwildness.com/23/poli-eclipse&amp;via=platypuspress&amp;related=twitterapi%2Ctwitter&amp;hashtags=wildnessjournal&amp;text=Check%20this%20out">Twitter</a>.</p>
				
			</section></div>]]>
            </description>
            <link>https://readwildness.com/23/poli-eclipse</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268252</guid>
            <pubDate>Tue, 25 Aug 2020 05:02:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Economic Cost of Oil Spills]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24268051">thread link</a>) | @amrrs
<br/>
August 24, 2020 | https://finshots.in/archive/the-economic-cost-of-oil-spills/ | <a href="https://web.archive.org/web/*/https://finshots.in/archive/the-economic-cost-of-oil-spills/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">

    <div>

        <article>

            

            <figure>
                <img srcset="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/oilsp-min.jpg 300w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/oilsp-min.jpg 600w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/oilsp-min.jpg 1000w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/oilsp-min.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/oilsp-min.jpg" alt="The Economic Cost of Oil Spills">
            </figure>

            <section>
                <div>
                    <p><em>A few days ago, a cargo vessel MV Wakashio ran aground off Pointe d’Esny, on the south-east coast of Mauritius and started spilling oil.</em></p><p><em>Needless to say, we need to talk about it.</em></p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="the-story">The Story</h3><p>Imagine thousands of gallons of oil pouring into a water body somewhere along the coast of a small island nation. Your first order of business is to contain and clean up the spill — in that order specifically.</p><p>Because when oil does spill, it forms a thick film that floats on top of the water body slowly spreading out and thinning as time progresses. More time means more coverage area. More coverage means a more elaborate cleanup effort. So in theory, if a cleanup crew can reach a spill quickly, they could contain it more efficiently and reduce costs across the board.</p><p>With the MV Wakashio oil spill, things didn’t exactly go as planned. The ship <a href="https://gcaptain.com/wakashio-breached-oil-leaks-from-grounded-bulk-carrier-in-mauritius-police-investigation-launched/#:~:text=The%20Indian%20Ocean%20island%20nation,Brazil%20via%20Singapore%20on%20ballast.">struck</a> a reef on July 25th and its body began to crack after days of pounding waves. At the time, the Mauritius government could have averted the crisis altogether by emptying the ship of its fuel. But that did not happen. Instead, the ship kept taking the beating and finally started leaking fuel on August 6th. Now the ship’s owners contest that oil prevention measures were in place by then. But clearly, it wasn’t helping a lot.</p><!--kg-card-begin: image--><figure><img src="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/5f2bf41a78a54_wakashio_ecosud-1443924.jpg"><figcaption><a href="https://la1ere.francetvinfo.fr/reunion/naufrage-du-wakashio-il-y-breche-fuite-huile-859552.html">Source: France Info</a></figcaption></figure><!--kg-card-end: image--><p>The Mauritius government could have taken some initiative here. But they waited for a whole day before finally taking stock of the situation and <a href="https://www.bbc.com/news/world-africa-53702877#:~:text=The%20island%20nation%20of%20Mauritius,and%20its%20crew%20was%20evacuated.&amp;text=The%20French%20island%20of%20Reunion%20lies%20near%20Mauritius%20in%20the%20Indian%20Ocean.">declaring emergency</a> late on Aug 7th. Thankfully the people of Mauritius stepped up. As an article in the New York Times <a href="https://www.nytimes.com/2020/08/14/world/africa/mauritius-oil-spill.html">notes</a> —</p><blockquote><em>“Immediately after the accident, individuals, civil society organizations and environmental groups mobilized to save the mangrove forest and coral reefs that give Mauritian waters their rich biodiversity.<p>Thousands of volunteers pulled all-nighters gathering plastic bottles and skimming oil into barrels, while salons donated hair and <a href="https://www.instagram.com/p/CDt2gpzg133/?igshid=1uidpqls8erlm" rel="noopener noreferrer noopener">children collected straw</a> from fields to help soak up the oil. Mauritians abroad began <a href="https://www.instagram.com/savemauritiusreef/" rel="noopener noreferrer noopener">social media campaigns</a> to raise awareness, and hundreds of thousands of dollars <a href="https://www.crowdfund.mu/mauritius-oil-spill-cleaning-2020-mv-wakashio-306.html" rel="noopener noreferrer noopener">were collected</a> on fund-raising platforms.”</p></em></blockquote><p>However, despite the collective effort, the size of the oil slick had already <a href="https://twitter.com/UrsaSpace/status/1293587048344047621?s=20" rel="noopener">expanded 10x</a> within just one week and the cleanup effort could now take months costing the shipping company and the Mauritius government millions of dollars.</p><p>How many millions? That’s difficult to calculate.</p><p>The Exxon Valdez case— a spill of approximately 10.8 million gallons in Alaska in 1989 cost <a href="https://media.rff.org/archive/files/sharepoint/WorkImages/Download/RFF-BCK-Cohen-DHCosts_update.pdf">$2.1 Billion</a> (in cleanup efforts). The MV Wakashio, on the other hand, was only carrying ~127,000 gallons of oil. The reason for the disparity — Exxon Valdez was a cargo ship ferrying oil. Wakashio was an empty ship travelling to pick cargo. The leak was from the fuel tank and the oil it was carrying to propel the vessel. Also, the cleanup team emptied the ship of its fuel before everything could spill out. So it’s safe to say the cleanup effort won’t cost billions.</p><p>But the impact will probably be severe either way.</p><p>Beyond the cleanup costs, we also have to contend with the ecological devastation that almost inevitably follows. Four years after the Exxon Valdez spill, a population of forage fish called herring <a href="https://www.history.com/topics/1980s/exxon-valdez-oil-spill">disappeared</a> entirely from the location where the vessel broke. Scientists still aren’t sure why this happened. They can’t even ascertain fully if the oil spill was to blame. But the impact of this disappearance was catastrophic. It spelt the death of an 8-million-dollar-a-year fishery industry. Although most fishermen never explicitly sought herrings, these small forage fishes are preyed on by larger fish for food. Once the population of herrings collapsed, it left a gaping hole in the middle of the marine food chain. 25 years later, herrings are yet to return and the fishery industry has all but vanished.</p><p>With the Wakashio oil spill, we have the same concerns. Blue Bay — The place where the ship ran aground was <a href="https://www.bloombergquint.com/opinion/why-mauritius-oil-spill-is-a-very-big-problem-for-the-oil-industry">declared</a> a marine park back in 1997. It’s perhaps one of the last remaining areas which still harbours undamaged coral reefs and an abundance of underwater life. The oil spill might have spelt the death of the ecological balance in the area. What will it cost the local population? We don’t know yet. But it’s a tragedy that we still have to contend with oil spills this day and age.</p><p>Share this Finshots on <a href="https://api.whatsapp.com/send?text=What%20happens%20when%20there%27s%20an%20oil%20spill?%20https://bit.ly/3llY8AL">WhatsApp</a>, <a href="https://twitter.com/intent/tweet?url=https://bit.ly/3jdaCsa&amp;via=finshots&amp;text=What%20happens%20when%20there%27s%20an%20oil%20spill?">Twitter</a>, or <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://finshots.in/archive/the-economic-cost-of-oil-spills">LinkedIn</a>.</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="an-inside-scoop">An Inside Scoop</h3><p>A few days back we wrote about the legal battle brewing between Apple and Epic Games. Since then, news websites have managed to access the email correspondence between the two companies before Epic Games decided to file the lawsuit. And considering it’s not always you get to read internal emails from top companies, we urge you to read the full correspondence <a href="https://www.theverge.com/2020/8/21/21396313/apple-fortnite-lawsuit-emails-app-store-ban-epic">here</a>. It’s quite revealing to be honest.</p><p>P.S. The actual correspondence is located in the exhibit at the bottom of the article.</p><p><em>Until next time...</em></p>
                </div>
            </section>


            

            
            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://finshots.in/archive/the-economic-cost-of-oil-spills/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268051</guid>
            <pubDate>Tue, 25 Aug 2020 04:02:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[rc.d belongs in libexec, not etc]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24267933">thread link</a>) | @Khaine
<br/>
August 24, 2020 | https://jmmv.dev/2020/08/rcd-libexec-etc.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/08/rcd-libexec-etc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article>

<p>Let’s open with the controversy: the scripts that live under <code>/etc/rc.d/</code> in FreeBSD, NetBSD, and OpenBSD are in the wrong place. They all should live in <code>/libexec/rc.d/</code> because they are code, <em>not</em> configuration.</p>

<p>This misplacement is something that has bugged me for ages but I never had the energy to open this can of worms back when I was very involved in NetBSD. I suspect it would have been a draining discussion and a very difficult thing to change.</p>

<p>But… what am I talking about anyway?</p>

<p>If you have administered a BSD system, you have certainly encountered the <code>/etc/rc.d/</code> directory; and if you have administered pre-systemd Linux systems, you have dealt with <code>/etc/init.d/</code>. These directories contain startup scripts to configure the system at boot time and are immutable. Their code is parameterized to allow changing their behavior via configuration files, not via code edits. And that’s the base of my critique.</p>

<p>But before getting into why the current state is problematic and how things should look like, let’s first dig into how we got here. And, for that, we need to go back in history.</p>



<p>4.4BSD’s (1993) boot process was rather simple: the kernel started <code>init</code> which in turn ran the <code>/etc/rc</code> script before starting <code>getty</code> on each console. The <code>/etc/rc</code> monolith was in charge of configuring the machine’s file systems and processes, and delegated to two other scripts: <code>/etc/netstart</code> for network configuration and <code>/etc/rc.local</code> for locally-added services. Current BSD systems are more advanced in this area as we shall see later, but the core boot process remains the same: <code>/etc/rc</code> is the primary entry point and bootstraps a collection of shell scripts.</p>

<p>In the early days, package management and file provenance tracking, like we are used to having in popular Linux distributions, was not a thing. You were expected to tune the systems’ behavior by <em>editing</em> files which might or might not have been designed to support edits. If you had to edit <code>/etc/rc</code>, which was a script shipped by the system, that was alright.</p>

<p><code>/etc/rc.local</code>, on the other hard, was <em>not</em> shipped by the system, and it was up to you to create it if you wanted to add custom startup commands without modifying <code>/etc/rc</code>. And this is where things get interesting. <code>/etc/rc.local</code> didn’t need to be supported: if you were expected and able to edit <code>/etc/rc</code> anyway, why would you deal with a separate file? The reason is, most likely, to simplify system upgrades: during an upgrade, you want to benefit from any upstream changes made to <code>/etc/rc</code> (some of which might actually be <em>necessary</em> for proper system operation). Applying updates to a manually-modified file is tricky, so putting as many of your manual overrides into <code>/etc/rc.local</code> helped minimize this problem.</p>



<p>System V 4 (SVR4, 1988) also came with its own, and very different, boot process. The key difference was that System V had the concept of runlevels. As a result, configuring the boot process was a more convoluted endeavour because it was possible to select different services per runlevel.</p>

<p>To accomplish per-runlevel tuning, the system used <a href="https://jmmv.dev/2020/08/config-files-vs-directories.html">configuration directories rather than files</a>: there was a separate <code>/etc/rcX.d/</code> directory for each runlevel (where <code>X</code> was the number of the runlevel), and these directories contained one file per action to take at startup time. To avoid duplicates, these files were just symlinks to common files under <code>/etc/init.d/</code>—and the symlinks, not their targets, were named so that their lexicographical order determined startup execution order.</p>

<p>Once again, we can already observe issues here: the symlinks under <code>/etc/rcX.d/</code> <em>are</em> configuration because their presence indicates what to start and their names determine their startup order. But the files under <code>/etc/init.d/</code> are <em>not</em>: they are shell scripts shipped with the system and should not be manually modified.</p>



<p>NetBSD <a href="http://www.mewburn.net/luke/papers/rc.d.pdf">modernized the boot process</a> in its 1.5 release (2000), and it did so in two ways: first, it introduced <code>/etc/rc.d/</code> as a directory to contain separate scripts per action and service; and, second, it introduced <a href="https://netbsd.gw.com/cgi-bin/man-cgi?rcorder+8+NetBSD-9.0-STABLE">the <code>rcorder(8)</code> tool</a> to determine the order in which these services run. <code>rcorder(8)</code> uses dependency information encoded in the scripts as comments—not lexicographical ordering as System V did. FreeBSD <a href="https://www.freebsd.org/cgi/man.cgi?query=rc&amp;apropos=0&amp;sektion=8&amp;manpath=FreeBSD+12.1-RELEASE&amp;arch=default&amp;format=html">inherited this design</a> in its 5.0 release (2003) and OpenBSD reimplemented something similar in its 4.9 release (2011).</p>

<p>With these two pieces in place, the <code>/etc/rc</code> script in NetBSD and FreeBSD changed to execute all files from <code>/etc/rc.d/</code> based on the output of <code>rcorder(8)</code>. Among these scripts is <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.d/local"><code>/etc/rc.d/local</code></a>, whose purpose is to run <code>/etc/rc.local</code> if it exists. And that’s all, really. The <code>/etc/rc</code> script thus became <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc">trivial</a>.</p>

<p>The key thing to notice here is that the scripts shipped in <code>/etc/rc.d/</code> are <em>highly configurable</em> via the user-controlled <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.conf"><code>/etc/rc.conf</code></a> file. This essentially makes the scripts read-only, as it shifts local customizations to the configuration file. <em>System administrators are not supposed to edit the scripts.</em> Instead, they are supposed to: modify <code>/etc/rc.conf</code> to customize what gets run and how; add new scripts under <code>/etc/rc.d/</code> if they so choose; and edit <code>/etc/rc.local</code> to easily run arbitrary commands.</p>



<p>My main gripe is that the files under <code>/etc/rc.d/</code> are immutable scripts. They do not belong in <code>/etc/</code> and their presence there makes system upgrades harder for no good reason.</p>

<p>You see: in NetBSD and FreeBSD, system upgrades happen by unpacking new distribution sets in the root directory and then running a script to incorporate configuration updates. This script is interactive and helps highlight how new system-provided updates to configuration files conflict with previous manual edits. (This process might seem rudimentary to you, but it’s actually pretty robust and easy to understand—and you can use tooling like <a href="https://github.com/jmmv/sysupgrade/">sysupgrade</a> to make it trivial.)</p>

<p>So why is that a problem? Because you will <em>always</em> face merges like this:</p>
<div><pre><code data-lang="diff"><span>--- /etc/rc.d/npf               2019-08-09 19:09:42.800758233 -0400
</span><span></span><span>+++ /tmp/temproot/etc/rc.d/npf  2019-11-16 10:39:27.000000000 -0500
</span><span></span><span>@@ -1,6 +1,6 @@
</span><span></span> #!/bin/sh
 #
<span>-# $NetBSD: npf,v 1.3 2012/11/01 06:06:14 mrg Exp $
</span><span></span><span>+# $NetBSD: npf,v 1.4 2019/04/19 18:36:25 leot Exp $
</span><span></span> #
 # Public Domain.
 #
<span>@@ -36,7 +36,11 @@
</span><span></span>        echo "Enabling NPF."
        npf_cfg_check
        /sbin/npfctl reload
<span>-       /sbin/npfctl start
</span><span></span><span>+
</span><span>+       # The npf_boot script has enabled npf already.
</span><span>+       if [ "$autoboot" != "yes" ]; then
</span><span>+               /sbin/npfctl start
</span><span>+       fi
</span><span></span> }
 
 npf_stop()

File: /etc/rc.d/npf (modified)

Please select one of the following operations:

  d  Don't install the new file (keep your old file)
  i  Install the new file (overwrites your local modifications!)
  m  Merge the currently installed and new files
  s  Show the differences between the currently installed and new files
  su  Show differences in unified format ("diff -u")
  sc  Show differences in context format ("diff -c")
  ss  Show differences side by side ("sdiff -w187")
  scommand Show differences using the specified diff-like command
  v  Show the new file

What do you want to do? [Leave it for later]
</code></pre></div>
<p>And, really, who cares? Why are you being distracted to review a <em>code</em> change when what you are trying to do is assess <em>configuration</em> conflicts? How many times have you actually objected to these merges?</p>

<p>You might say: well, I want to know <em>exactly</em> how the boot process of my machine changes during an upgrade. Sure, that’s a fine goal, but then this procedure is flawed and completely insufficient to achieve such goal. In the example above, whatever <code>/etc/rc.d/npf</code> does can also be done from within the <code>/sbin/npfctl</code> binary it invokes… and you were never asked to review changes to the latter during an upgrade, were you? And <em>of course</em> you could review the binary’s code as part of your own system build, but if you did that, then you could have reviewed the startup script as well, right?</p>



<p>Startup scripts provided by the system need to live in a location that can contain executables—but we don’t want those executables to show up in the <code>PATH</code>. These requirements discard <code>bin</code> and <code>sbin</code>, and points us towards <code>libexec</code> on BSD systems and somewhere under <code>lib</code> on Linux.</p>

<p>Therefore, the read-only startup scripts should move from <code>/etc/rc.d/</code> to <code>/libexec/rc.d/</code> (which, by the way, also applies to <code>/etc/rc</code>, <code>/etc/rc.subr</code>, and <code>/etc/rc.shutdown</code>). And that’s it. <del><code>/etc/rc</code></del> <code>/libexec/rc</code> should continue to use <code>rcorder(8)</code> to check what’s needed to run, but it should read files from <code>/libexec/rc.d/</code>. You might even want to support a separate location for user-created services, which might still be <code>/etc/rc.d/</code> or, better yet, a more fitting location like <code>/usr/pkg/libexec/rc.d/</code> (though that quickly runs into problems if you have multiple file systems).</p>

<p>With this design, system upgrades would be much saner because the configuration merge process would focus, purely, on actual configuration changes and not on irrelevant code changes. All updates to <code>/libexec/rc.d/</code> would be applied by unpacking the new distribution sets (<code>base.txz</code> in this case) without disturbing you about how exactly they changed.</p>

<p>Does this relate to Linux distributions at all? I briefly mentioned <code>/etc/init.d/</code> at the beginning, and the problem there is similar. But it’s also an obsolete problem given that Linux distributions have moved onto systemd by now. That said, systemd still has to manage individual services and, like it or not, has gotten this right. If we look at the <a href="https://www.freedesktop.org/software/systemd/man/systemd.unit.html"><code>systemd.unit(5)</code></a> manual page, which describes where units are loaded from, the system first looks into various <code>/etc/</code> and <code>/run/</code> directories, but then also looks at <code>/usr/lib/systemd/system/</code> (a read-only location correctly controlled by the package manager)—and the vast majority of the scripts live inside the latter.</p>



<p>I currently don’t run BSD systems any more so my incentives to make this happen are low… but if this all makes sense and is something you’d like to pursue, by all means please do! I’m happy to help …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jmmv.dev/2020/08/rcd-libexec-etc.html">https://jmmv.dev/2020/08/rcd-libexec-etc.html</a></em></p>]]>
            </description>
            <link>https://jmmv.dev/2020/08/rcd-libexec-etc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267933</guid>
            <pubDate>Tue, 25 Aug 2020 03:35:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One-third of people with Covid-19 lie about their symptoms, study shows]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24267303">thread link</a>) | @9nGQluzmnq3M
<br/>
August 24, 2020 | https://www.cbc.ca/news/canada/hamilton/covid-19-1.5695230 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/hamilton/covid-19-1.5695230">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.cbc.ca/news/canada/hamilton/covid-19-1.5695230</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267303</guid>
            <pubDate>Tue, 25 Aug 2020 01:18:56 GMT</pubDate>
        </item>
    </channel>
</rss>
