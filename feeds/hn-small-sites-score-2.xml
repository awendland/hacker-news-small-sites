<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 16 Aug 2020 20:20:51 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 16 Aug 2020 20:20:51 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[HomeAssistant Temperature and Humidity Sensor with ESPHome]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24167895">thread link</a>) | @todsacerdoti
<br/>
August 15, 2020 | https://theorangeone.net/posts/esphome-dht-sensor/ | <a href="https://web.archive.org/web/*/https://theorangeone.net/posts/esphome-dht-sensor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The majority of England (where I live) is being hit by <a href="https://www.dailymail.co.uk/news/article-8610963/UK-weather-Britain-swelter-TEN-day-heatwave.html">quite a heatwave</a>. It’s hot here, like really hot!</p><figure><img src="https://theorangeone.net/posts/esphome-dht-sensor/grafana-graph_hue8817786cbb53c9e8bd4ad7a6a582421_100626_1500x0_resize_lanczos_2.png" alt="Temperature recordings from my bedroom this past few days"><figcaption><small>Temperature recordings from my bedroom this past few days</small></figcaption></figure><p>Us brits are incapable of handling the heat, and enjoy nothing more than telling each other how hot and unbearable it is. I’m definitely guilty of this, and as a ginger, I’m worse than most. When telling people quite how hot it is, wouldn’t it be great to have your own sensor in your room, plotting the temperature, and storing the data in home-assistant? Yes? Then you’re in the right place.</p><h2 id="requirements"><a href="#requirements">#</a> Requirements</h2><p>To build the sensor, you’ll need a few things:</p><ul><li><a href="https://www.home-assistant.io/">HomeAssistant</a></li><li><a href="https://esphome.io/">ESPHome</a> (installation instructions <a href="#install-esphome">below</a>)</li></ul><p>And a few components:</p><ul><li><a href="https://esphome.io/#devices">ESPHome-compatible</a> board (I’m using a NodeMCU from <a href="https://www.amazon.co.uk/MakerHawk-Internet-Development-Wireless-Micropython/dp/B07M8Q38LK">amazon.co.uk</a>)</li><li>DHT11 (DHT22 is significantly nicer, but more expensive)</li><li>Jumper cables (often come with the DHT)</li></ul><h2 id="steps"><a href="#steps">#</a> Steps</h2><h3 id="install-esphome"><a href="#install-esphome">#</a> Install ESPHome</h3><p>ESPHome has a few installation methods, however I recommend using <a href="https://hub.docker.com/r/esphome/esphome">Docker</a> as it presents an incredibly simple to use web UI, and makes interfacing much easier. When using the docker container, you’ll need to set <code>network_mode: host</code> to support OTA updates and detection.</p><div><pre><code data-lang="yaml"><span>  </span><span>esphome</span><span>:</span><span>
</span><span>    </span><span>image</span><span>:</span><span> </span>esphome/esphome<span>:</span>latest<span>
</span><span>    </span><span>restart</span><span>:</span><span> </span>unless-stopped<span>
</span><span>    </span><span>network_mode</span><span>:</span><span> </span>host<span>
</span><span>    </span><span>volumes</span><span>:</span><span>
</span><span>      </span>- ./esphome<span>:</span>/config<span>
</span></code></pre></div><p>I have it installed on the same machine HomeAssistant is, but that’s not necessary. ESPHome is just the UI - the communication is direct between HomeAssistant and the boards.</p><p>Once started, it should be accessible via <code>&lt;ip&gt;:6052</code>. Note this UI is unauthenticated, so probably shouldn’t be internet-accessible.</p><h3 id="construct-circuit"><a href="#construct-circuit">#</a> Construct circuit</h3><p>Constructing your sensor is very simple and doesn’t require any soldering.</p><p>The first step is to identify the right pins on the DHT sensor. There are 3 pins: ground, power and data. When connecting up your sensor, you’ll need to ensure the ground pin is connected to ground, 3.3V is connected to a 3.3v output, and data is connected to one of the data pins.</p><p>The pins labelled on the board are not necessarily all accessible to ESPHome, nor are the numbers correct. Be sure to check the <a href="https://esphome.io/devices/nodemcu_esp8266.html">documentation</a> for the specific board you’re using, and connect the pins correctly. In my case, I connected the data line to the pin labelled <code>D1</code>.</p><figure><img src="https://theorangeone.net/posts/esphome-dht-sensor/sensor-circuit_hu817a58996bc5fb0a48a17efd3e2b6009_368106_1500x0_resize_q75_lanczos.jpg" alt="My NodeMCU with connected DHT11"><figcaption><small>My NodeMCU with connected DHT11</small></figcaption></figure><h3 id="create-firmware"><a href="#create-firmware">#</a> Create firmware</h3><p>Next we need to write the config file which will be turned into our firmware. ESPHome configuration is just <code>yaml</code> files, which makes editing and updating simple. The web UI contains a helpful wizard to create the configuration files.</p><p>Go to ESPHome, and click the “+” button to start the setup wizard. This will walk you through naming your sensor and connecting it to WiFi. Once created, a card will appear on the homepage for your sensor, showing it as disconnected. Select “Edit” and you’ll be presented with a yaml file:</p><div><pre><code data-lang="yaml"><span>esphome</span><span>:</span><span>
</span><span>  </span><span>name</span><span>:</span><span> </span>test_sensor<span>
</span><span>  </span><span>platform</span><span>:</span><span> </span>ESP8266<span>
</span><span>  </span><span>board</span><span>:</span><span> </span>esp01_1m<span>
</span><span>
</span><span></span><span>wifi</span><span>:</span><span>
</span><span>  </span><span>ssid</span><span>:</span><span> </span><span>"test"</span><span>
</span><span>  </span><span>password</span><span>:</span><span> </span><span>"test"</span><span>
</span><span>
</span><span>  </span><span># Enable fallback hotspot (captive portal) in case wifi connection fails</span><span>
</span><span>  </span><span>ap</span><span>:</span><span>
</span><span>    </span><span>ssid</span><span>:</span><span> </span><span>"Test Fallback Hotspot"</span><span>
</span><span>    </span><span>password</span><span>:</span><span> </span><span>"oZkrj2ddgl3m"</span><span>
</span><span>
</span><span></span><span>captive_portal</span><span>:</span><span>
</span><span>
</span><span></span><span># Enable logging</span><span>
</span><span></span><span>logger</span><span>:</span><span>
</span><span>
</span><span></span><span># Enable Home Assistant API</span><span>
</span><span></span><span>api</span><span>:</span><span>
</span><span>  </span><span>password</span><span>:</span><span> </span><span>"my secure password"</span><span>
</span><span>
</span><span></span><span>ota</span><span>:</span><span>
</span><span>  </span><span>password</span><span>:</span><span> </span><span>"my secure password"</span><span>
</span></code></pre></div><p>There’s a lot of configuration in here which isn’t needed for use with HomeAssistant, so we can remove it. Once cleaned up, you should have something similar to this:</p><div><pre><code data-lang="yaml"><span>esphome</span><span>:</span><span>
</span><span>  </span><span>name</span><span>:</span><span> </span>test_sensor<span>
</span><span>  </span><span>platform</span><span>:</span><span> </span>ESP8266<span>
</span><span>  </span><span>board</span><span>:</span><span> </span>nodemcuv2<span>
</span><span>
</span><span></span><span>wifi</span><span>:</span><span>
</span><span>  </span><span>ssid</span><span>:</span><span> </span><span>"test"</span><span>
</span><span>  </span><span>password</span><span>:</span><span> </span>test<span>
</span><span>
</span><span></span><span># Enable logging</span><span>
</span><span></span><span>logger</span><span>:</span><span>
</span><span>
</span><span></span><span># Enable Home Assistant API</span><span>
</span><span></span><span>api</span><span>:</span><span>
</span><span>  </span><span>password</span><span>:</span><span> </span><span>"my secure password"</span><span>
</span><span>
</span><span></span><span>ota</span><span>:</span><span>
</span><span>  </span><span>password</span><span>:</span><span> </span><span>"my secure password"</span><span>
</span></code></pre></div><p>With this configuration, The ESPHome firmware will connect to your device WiFi network and expose an API which HomeAssistant can connect to. This API is password protected, and will be needed for the HomeAssistant setup later.</p><p>Next we need to set up the sensor. This is done with an additional section in the configuration:</p><div><pre><code data-lang="yaml"><span>sensor</span><span>:</span><span>
</span><span>  </span>- <span>platform</span><span>:</span><span> </span>dht<span>
</span><span>    </span><span>pin</span><span>:</span><span> </span>D1<span>
</span><span>    </span><span>temperature</span><span>:</span><span>
</span><span>      </span><span>name</span><span>:</span><span> </span><span>"My Temperature"</span><span>
</span><span>    </span><span>humidity</span><span>:</span><span>
</span><span>      </span><span>name</span><span>:</span><span> </span><span>"My Humidity"</span><span>
</span><span>    </span><span>update_interval</span><span>:</span><span> </span>60s<span>
</span><span>    </span><span>model</span><span>:</span><span> </span>DHT11<span>
</span></code></pre></div><p>The sensor names here will correspond to sensor names in HomeAssistant. Be sure to set the correct pin and model for your sensor. The <a href="https://esphome.io/components/sensor/dht.html">documentation</a> shows the possible values you can set for these.</p><h3 id="flash-firmware"><a href="#flash-firmware">#</a> Flash firmware</h3><p>ESPHome has a great feature where you can modify the configuration and update boards wirelessly over the network. Unfortunately, this doesn’t work for the initial flash. For this, we have to download the firmware and flash it ourselves.</p><p>Before the firmware can be flashed, it must be compiled. This takes the configuration yaml and turns it into a firmware file. To do this, click the 3 dots on the relevant device card and select “Compile”. This will take some time (30 seconds or so), after which you’ll be presented with <code>INFO Successfully compiled program.</code>. At this point, you can click “Download Binary” in the bottom right of the popup to download the <code>.bin</code> firmware.</p><p>The firmware can then be flased using the <a href="https://esphome.io/guides/faq.html#esphome-flasher"><code>esphome-flasher</code></a> utility (available on the <a href="https://aur.archlinux.org/packages/esphome-flasher">AUR</a>). Connect your board over USB, select both it and the downloaded firmware in the flasher UI and select “Flash ESP”. Give it a bit to fully upload, and you’ll then be met with the logs from the board, which now runs ESPHome.</p><h2 id="import-into-home-assistant"><a href="#import-into-home-assistant">#</a> Import into home-assistant</h2><p>Once your board starts up, it should automatically connect to your WiFi using the credentials you put in the config, and be detected by HomeAssistant as a new integration. Once selected, you’ll be prompted for a password. This will again be the same as what was defined in your config.</p><p>The NodeMCU should expose 2 sensors to HomeAssistant, “Temperature” and “Humidity”. If you visit the lovelace UI, you should be able to add cards for them.</p><figure><img src="https://theorangeone.net/posts/esphome-dht-sensor/ha-dashboard_hu6405e05c8bcb17795967ebb5f74820e4_28620_1500x0_resize_lanczos_2.png" alt="My Temperature / Humidity sensors being graphed by HomeAssistant"><figcaption><small>My Temperature / Humidity sensors being graphed by HomeAssistant</small></figcaption></figure><p>Once you’re happy it’s logging everything correctly, you can move it to where you want it to be deployed.</p></div></div>]]>
            </description>
            <link>https://theorangeone.net/posts/esphome-dht-sensor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24167895</guid>
            <pubDate>Sat, 15 Aug 2020 10:47:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[History of Epidemics in a Single Chart]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24167765">thread link</a>) | @Martin_Heinz
<br/>
August 15, 2020 | https://martinheinz.github.io/charts/horizontal-bar-chart/ | <a href="https://web.archive.org/web/*/https://martinheinz.github.io/charts/horizontal-bar-chart/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://martinheinz.github.io/charts/horizontal-bar-chart/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24167765</guid>
            <pubDate>Sat, 15 Aug 2020 10:26:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$200 PinePhone Linux smartphone comes with physical kill switch]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24167497">thread link</a>) | @vvpvijay
<br/>
August 15, 2020 | https://androidrookies.com/200-pinephone-linux-smartphone-comes-with-physical-kill-switch-to-turn-off-camera-microphone-bluetooth-and-wi-fi/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/200-pinephone-linux-smartphone-comes-with-physical-kill-switch-to-turn-off-camera-microphone-bluetooth-and-wi-fi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-10179"><div><div><div><h2>Pine64’s $199 PinePhone Linux smartphone comes with a physical kill switch in the back to turn off the camera, Wi-Fi, microphone, headphone, and Bluetooth transmitters</h2><p>Ever since Pine64 launched the PinePhone Linux smartphones, it has been a subject of debates, arguments, and counter-arguments. Some find the PinePhone Linux smartphone an experiment worth trying out while others critique its hardware which is closer to a budget Android smartphone. However, we have to handover to the Pine64 engineers for tackling privacy-related issues first hand.</p><p>Ever since <a href="https://androidrookies.com/taping-your-macbook-camera-to-prevent-it-from-spying-is-not-a-good-option-says-apple/">Apple issued an advisory to MacBook users</a> not to tape their webcam, many users have been demanding a physical kill switch to stop webcam/microphone/Wi-Fi/GPS being hacked or abused. The Pine64’s PinePhone smartphone comes with a neat physical kill switch to turn those on/off. Under the back cover of PinePhone users can find an array of kill switches that can be used to physically toggle the camera, Wi-Fi, microphone, and GPS transmitters on or off.</p><div id="attachment_10180"><p><img aria-describedby="caption-attachment-10180" src="https://androidrookies.com/wp-content/uploads/2020/08/physical-switch.jpg" data-src="https://androidrookies.com/wp-content/uploads/2020/08/physical-switch.jpg" alt="Pine64's $200 PinePhone Linux smartphone comes with a physical switch in the back to turn off the camera, Wi-Fi, microphone, headphone, and Bluetooth transmitters" width="657" height="371" data-srcset="https://androidrookies.com/wp-content/uploads/2020/08/physical-switch.jpg 657w, https://androidrookies.com/wp-content/uploads/2020/08/physical-switch-300x169.jpg 300w" data-sizes="(max-width: 657px) 100vw, 657px" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" srcset="https://androidrookies.com/wp-content/uploads/2020/08/physical-switch.jpg 657w, https://androidrookies.com/wp-content/uploads/2020/08/physical-switch-300x169.jpg 300w"></p><p id="caption-attachment-10180">Courtesy AndroidPolice</p></div><p>The neatly arranged stack of switches situated in the rear of the PinePhone lets you shut down the modem, Wi-Fi, Bluetooth, microphone, rear camera, front camera, and headphone with a small screwdriver.</p><h2>Specifications of Pine64’s PinePhone:</h2><p>The PinePhone comes with a 5.95-inch 1440×720 18:9 HD IPS capacitive touchscreen with 16M colors and runs on <a href="https://linux-sunxi.org/A64" target="_blank" rel="nofollow noopener noreferrer">Allwinner A64</a> (quad-core ARM Cortex A53, Mali 400 GPU) chipset. Many expected a better chip but then you are paying $200 for this smartphone. The PinePhone runs on 3GB RAM and has 32GB internal memory(eMMC) which can be extended up to 2TB via a microSD card. The PinePhone has a 5MP rear shooter with LED flash and a 2MP front camera for selfies.</p><p>For connectivity, the PinePhomes LTE, Wi-Fi 802.11 b/g/n, Bluetooth 4.0, and GPS. It also features other extras like Accelerometer, Gyro sensor, Proximity sensor, Ambient light sensor, Compass</p><p>The PinePhone comes with a removable 2,800mAh battery which is similar to the Samsung J7 battery. Unlike nano-SIM in the current lot of Android smartphones, PinePhone comes with a micro-SIM and has Type-C USB port for charging and data transfer.</p><p>The $199 PinePhone runs on PostmarketOS Linux distro and comes with a convergence package consisting of a compatible USB-C docking bar capable of charging, digital video output, dual USB 2.0 type-A host ports for peripherals (such as keyboard and mouse) and fast Ethernet.</p><p>You can place an order for the limited edition <a href="https://store.pine64.org/product/pinephone-community-edition-postmarketos-with-convergence-package-limited-edition-linux-smartphone/">PinePhone Community Edition: PostmarketOS with Convergence Package</a>&nbsp;bundle for $200. Or you can just<a href="https://store.pine64.org/product/pinephone-community-edition-postmarketos-limited-edition-linux-smartphone/"> order the phone itself for $150</a> which comes with 2GB RAM and 16GB internal memory. The Linux smartphone maker has promised deliveries by end of August 2020.</p><p>The $199 PinePhone “Community Edition: PostmarketOS With Convergence Package” does have a bit mid-range specs especially the 3GB RAM/32GB internal memory and the 5MP/2MP cameras but I did buy the PinePhone just for the physical kill switches to turn off the peripherals. If this physical security feature becomes popular we could one day be having it on flagship Android smartphones.</p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/200-pinephone-linux-smartphone-comes-with-physical-kill-switch-to-turn-off-camera-microphone-bluetooth-and-wi-fi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24167497</guid>
            <pubDate>Sat, 15 Aug 2020 09:40:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Types as axioms, or: playing god with static types]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24166594">thread link</a>) | @pcr910303
<br/>
August 14, 2020 | https://lexi-lambda.github.io/blog/2020/08/13/types-as-axioms-or-playing-god-with-static-types/ | <a href="https://web.archive.org/web/*/https://lexi-lambda.github.io/blog/2020/08/13/types-as-axioms-or-playing-god-with-static-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section role="main">
        <!-- Main column -->
        <div>



          <article>
  <header>
    
    
  </header>

<p>Just what exactly <em>is</em> a type?</p>

<p>A common perspective is that types are <em>restrictions</em>. Static types restrict the set of values a variable may contain, capturing some subset of the space of “all possible values.” Under this worldview, a typechecker is sort of like an oracle, predicting which values will end up where when the program runs and making sure they satisfy the constraints the programmer wrote down in the type annotations. Of course, the typechecker can’t <em>really</em> predict the future, so when the typechecker gets it wrong—it can’t “figure out” what a value will be—static types can feel like self-inflicted shackles.</p>

<p>But that is not the <em>only</em> perspective. There is another way—a way that puts you, the programmer, back in the driver’s seat. You make the rules, you call the shots, you set the objectives. You need not be limited any longer by what the designers of your programming language decided the typechecker can and cannot prove. You do not serve the typechecker; the typechecker serves <em>you.</em></p>

<p>…no, I’m not trying to sell you a dubious self-help book for programmers who feel like they’ve lost control of their lives. If the above sounds too good to be true, well… I won’t pretend it’s all actually as easy as I make it sound. Nevertheless, it’s well within the reach of the working programmer, and most remarkably, all it takes is a change in perspective.</p>
<!-- more-->



<p>Let’s talk a little about TypeScript.</p>

<p>TypeScript is a <em>gradually-typed</em> language, which means it’s possible to mix statically- and dynamically-typed code. The original intended use case of gradual typing was to <em>gradually</em> add static types to an existing dynamically-typed codebase, which imposes some interesting design constraints. For one, a valid JavaScript program must also be a valid TypeScript program; for another, TypeScript must be accommodating of traditional JavaScript idioms.</p>

<p>Gradually typed languages like TypeScript are particularly good illustrations of the way type annotations can be viewed as constraints. A function with no explicit type declarations<sup><a href="#2020-08-13-types-as-axioms-or-playing-god-with-static-types-footnote-1-definition" name="2020-08-13-types-as-axioms-or-playing-god-with-static-types-footnote-1-return">1</a></sup> can accept <em>any</em> JavaScript value, so adding a type annotation fundamentally restricts the set of legal values.</p>

<p>Furthermore, languages like TypeScript tend to have subtyping. This makes it easy to classify certain types as “more restrictive” than others. For example, a type like <code>string | number</code> clearly includes more values than just <code>number</code>, so <code>number</code> is a more restrictive type—a <em>subtype</em>.</p>

<p>An exceptionally concrete way to illustrate this “types are restrictions” mentality is to write a function with an unnecessarily specific type. Here’s a TypeScript function that returns the first element in an array of numbers:</p>

<div>
 <div>
  <pre><span></span><span>function</span> <span>getFirst</span><span>(</span><span>arr</span>: <span>number</span><span>[])</span><span>:</span> <span>number</span> <span>|</span> <span>undefined</span> <span>{</span>
  <span>return</span> <span>arr</span><span>[</span><span>0</span><span>];</span>
<span>}</span>
</pre></div>

</div>

<p>This function would work perfectly well given a list of strings, but if you write <code>getFirst(["hello", "world"])</code>, the typechecker will complain. Of course, in this example the restriction is thoroughly self-imposed—it would be easy to give this function a generic type—but sometimes it’s not quite so easy. For example, suppose we write a function where the return type depends upon the type of the argument:</p>

<div>
 <div>
  <pre><span></span><span>function</span> <span>emptyLike</span><span>(</span><span>val</span>: <span>number</span> <span>|</span> <span>string</span><span>)</span><span>:</span> <span>number</span> <span>|</span> <span>string</span> <span>{</span>
  <span>if</span> <span>(</span><span>typeof</span> <span>val</span> <span>===</span> <span>"number"</span><span>)</span> <span>{</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>return</span> <span>""</span><span>;</span>
  <span>}</span>
<span>}</span>
</pre></div>

</div>

<p>Now if we write <code>emptyLike(42) * 10</code>, the typechecker will once again complain, claiming the result could be a string—it can’t “figure out” that when we pass a number, we always get a number back.</p>

<p>When type systems are approached from this perspective, the result is often frustration. The programmer knows that the equivalent untyped JavaScript is perfectly well-behaved, so the typechecker comes off as being the highly unfortunate combination of stubborn yet dim-witted. What’s more, the programmer likely has little mental model of the typechecker’s internal operation, so when types like the above are inferred (not explicitly written), it can be unclear what solutions exist to make the error go away.</p>

<p>At this point, the programmer may give up. “Stupid typechecker,” they grumble, changing the return type of <code>emptyLike</code> to <code>any</code>. “If it can’t even figure this out, can it <em>really</em> be all that useful?”</p>

<p>Sadly, this relationship with the typechecker is all too common, and gradually-typed languages in particular tend to create a vicious cycle of frustration:</p>

<ul>
 <li>
  <p>Gradual type systems are intentionally designed to “just work” on idiomatic code as much as possible, so programmers may not think much about the types except when they get type errors.</p></li>
 <li>
  <p>Furthermore, many programmers using gradually-typed languages are already adept at programming in the underlying dynamically-typed language, so they have working mental models of program operation in terms of the dynamic semantics alone. They are much less likely to develop a rich mental model of the static semantics of the type system because they are used to reasoning without one.</p></li>
 <li>
  <p>Gradually typed languages must support idioms from their dynamically-typed heritage, so they often include ad-hoc special cases (such as, for example, special treatment of <code>typeof</code> checks) that obscure the rules the typechecker follows and make them seem semi-magical.</p></li>
 <li>
  <p>Builtin types are deeply blessed in the type system, strongly encouraging programmers to embrace their full flexibility, but leaving little recourse when they run up against their limits.</p></li>
 <li>
  <p>All this frustration breeds a readiness to override the typechecker using casts or <code>any</code>, which ultimately creates a self-fulfilling prophecy in which the typechecker rarely catches any interesting mistakes because it has been so routinely disabled.</p></li></ul>

<p>The end result of all of this is a defeatist attitude that views the typechecker as a minor tooling convenience at best (i.e. a fancy autocomplete provider) or an active impediment at worst. Who can really blame them? The type system has (unintentionally of course) been designed in such a way so as to lead them into this dead end. The public perception of type systems settles into that of a strikingly literal nitpicker we endure rather than as a tool we actively leverage.</p>



<p>After everything I said above, it may be hard to imagine seeing types any other way. Indeed, through the lens of TypeScript, the “types are restrictions” mentality is incredibly natural, so much so that it seems self-evident. But let’s move away from TypeScript for a moment and focus on a different language, Haskell, which encourages a somewhat different perspective. If you aren’t familiar with Haskell, that’s alright—I’m going to try to keep the examples in this blog post as accessible as possible whether you’ve written any Haskell or not.</p>

<p>Though Haskell and TypeScript are both statically-typed—and both of their type systems are fairly sophisticated—Haskell’s type system is almost completely different philosophically:</p>

<ul>
 <li>
  <p>Haskell does not have subtyping,<sup><a href="#2020-08-13-types-as-axioms-or-playing-god-with-static-types-footnote-2-definition" name="2020-08-13-types-as-axioms-or-playing-god-with-static-types-footnote-2-return">2</a></sup> which means that every value belongs to exactly one type.</p></li>
 <li>
  <p>While JavaScript is built around a small handful of flexible builtin datatypes (booleans, numbers, strings, arrays, and objects), Haskell has essentially no blessed, built-in datatypes other than numbers. Key types such as booleans, lists, and tuples are ordinary datatypes defined in the standard library, no different from types users could define.<sup><a href="#2020-08-13-types-as-axioms-or-playing-god-with-static-types-footnote-3-definition" name="2020-08-13-types-as-axioms-or-playing-god-with-static-types-footnote-3-return">3</a></sup></p></li>
 <li>
  <p>In particular, Haskell is built around the idea that datatypes can be defined with multiple <em>cases</em>, and branching is done via pattern-matching (more on this shortly).</p></li></ul>

<p>Let’s look at a basic Haskell datatype declaration. Suppose we want to define a type that represents a season:</p>

<div>
 <div>
  <pre><span></span><span>data</span> <span>Season</span> <span>=</span> <span>Spring</span> <span>|</span> <span>Summer</span> <span>|</span> <span>Fall</span> <span>|</span> <span>Winter</span>
</pre></div>

</div>

<p>If you are familiar with TypeScript, this may look rather similar to a union type; if you’re familiar with a C-family language, this may remind you more of an enum. Both are on the right track: this defines a new type named <code>Season</code> with four possible values, <code>Spring</code>, <code>Summer</code>, <code>Fall</code>, and <code>Winter</code>.</p>

<p>But what exactly <em>are</em> those values?</p>

<ul>
 <li>
  <p>In TypeScript, we’d represent this type with a union of strings, like this:</p>
  <div>
   <div>
    <pre><span></span><span>type</span> <span>Season</span> <span>=</span> <span>"spring"</span> <span>|</span> <span>"summer"</span> <span>|</span> <span>"fall"</span> <span>|</span> <span>"winter"</span><span>;</span>
</pre></div>

</div>
  <p>Here, <code>Season</code> is a type that can be one of those four strings, but nothing else.</p></li>
 <li>
  <p>In C, we’d represent this type with an enum, like this:</p>
  <div>
   <div>
    <pre><span></span><span>enum</span> <span>season</span> <span>{</span> <span>SPRING</span><span>,</span> <span>SUMMER</span><span>,</span> <span>FALL</span><span>,</span> <span>WINTER</span> <span>};</span>
</pre></div>

</div>
  <p>Here, <code>SPRING</code>, <code>SUMMER</code>, <code>FALL</code>, and <code>WINTER</code> are essentially defined to be global aliases for the integers <code>0</code>, <code>1</code>, <code>2</code>, and <code>3</code>, and the type <code>enum season</code> is essentially an alias for <code>int</code>.</p></li></ul>

<p>So in TypeScript, the values are strings, and in C, the values are numbers. What are they in Haskell? Well… they simply <em>are</em>.</p>

<p>The Haskell declaration invents four completely new constants out of thin air, <code>Spring</code>, <code>Summer</code>, <code>Fall</code>, and <code>Winter</code>. They aren’t aliases for numbers, nor are they symbols or strings. The compiler doesn’t expose anything about how it chooses to represent these values at runtime; that’s an implementation detail. In Haskell, <code>Spring</code> is now a value <em>distinct from all other values</em>, even if someone in a different module were to also use the name <code>Spring</code>. Haskell type declarations let us play god, creating something from nothing.</p>

<p>Since these values are totally unique, abstract constants, what can we actually do with them? The answer is one thing and <em>exactly</em> one thing: we can branch on them. For example, we can write a function that takes a <code>Season</code> as an argument and returns whether or not Christmas occurs during it:</p>

<div>
 <div>
  <pre><span></span><span>containsChristmas</span> <span>::</span> <span>Season</span> <span>-&gt;</span> <span>Bool</span>
<span>containsChristmas</span> <span>season</span> <span>=</span> <span>case</span> <span>season</span> <span>of</span>
  <span>Spring</span> <span>-&gt;</span> <span>False</span>
  <span>Summer</span> <span>-&gt;</span> <span>True</span>  <span>-- southern hemisphere</span>
  <span>Fall</span>   <span>-&gt;</span> <span>False</span>
  <span>Winter</span> <span>-&gt;</span> <span>True</span>  <span>-- northern hemisphere</span>
</pre></div>

</div>

<p><code>case</code> expressions are, to a first approximation, a lot like C-style <code>switch</code> statements (though they can do a lot more than this simple example suggests). Using <code>case</code>, we can also define conversions from our totally unique <code>Season</code> constants to other types, if we want:</p>

<div>
 <div>
  <pre><span></span><span>seasonToString</span> <span>::</span> <span>Season</span> <span>-&gt;</span> <span>S…</span></pre></div></div></article></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lexi-lambda.github.io/blog/2020/08/13/types-as-axioms-or-playing-god-with-static-types/">https://lexi-lambda.github.io/blog/2020/08/13/types-as-axioms-or-playing-god-with-static-types/</a></em></p>]]>
            </description>
            <link>https://lexi-lambda.github.io/blog/2020/08/13/types-as-axioms-or-playing-god-with-static-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24166594</guid>
            <pubDate>Sat, 15 Aug 2020 06:44:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using an old BlackBerry as a portable SSH or Telnet terminal]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24166402">thread link</a>) | @todsacerdoti
<br/>
August 14, 2020 | https://rqsall.com/posts/using-an-old-blackberry-as-a-portable-ssh-terminal | <a href="https://web.archive.org/web/*/https://rqsall.com/posts/using-an-old-blackberry-as-a-portable-ssh-terminal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-copy">


<h2 id="using-an-old-blackberry-as-a-portable-ssh-or-telnet-terminal">Using an old BlackBerry as a portable SSH (or Telnet) terminal</h2>
<p>You used to see BlackBerries everywhere. Sites such as CrackBerry detailed sightings of celebrities using them constantly. Nowadays, not so much. However, I believe they still have some usecases today. One of these is as a portable terminal. Here's why one might want to use one of these devices as a terminal:</p>
<ul>
<li>Nice built-in physical keyboard</li>
<li>Long standby battery life
<ul>
<li>Easily swappable batteries (see my Altoids tin filled with batteries below!)</li>
<li>The 7290 I'm using reportedly has a 216 hour standby battery life, and unlike modern phones this number seems to hold up relatively well even with network enabled</li>
</ul></li>
<li>Affordable
<ul>
<li>You can easily find these devices for ~$20 on eBay</li>
<li>You can get a 100 MB data plan from US Mobile for $2/mo. not including fees (closer to $5/mo. with fees)</li>
</ul></li>
<li>Extremely portable
<ul>
<li>Much smaller than other devices one might use for this kind of thing
<ul>
<li>OpenPandora</li>
<li>GPD Pocket</li>
<li>etc.</li>
</ul></li>
<li>Much shorter than most modern phones</li>
<li>Cellular connection means you don't need a wireless router around</li>
</ul></li>
<li>Decently rugged
<ul>
<li>Not nearly as prone to failure after drops as modern smartphones (in my experience)
<ul>
<li>The screen is recessed, so it doesn't take the brunt of falls</li>
</ul></li>
</ul></li>
<li>Easy to setup
<ul>
<li>You can simply browse to <a href="http://xk72.com/wap">http://xk72.com/wap</a> on the phone itself to install an SSH client (MidpSSH) over the air</li>
</ul></li>
</ul>
<p>I've been using a BlackBerry 7290 on the US Mobile network, which still supports GSM for now. It's notable that the SSH negotiation is decently slow (~30-45 seconds), but is decently usable after connected (things are still a little sluggish however). Furthermore, I had to reenable the weak DSA public key algorithm as well. This doesn't bother me so much as I basically have a middleman server that allows this weak standard that I talk to everything else through rather than enabling it on every server.</p>
<p>To make things easier on myself, I wrote an <a href="https://rqsall.com/posts/files/postlogin.txt">interactive script</a> that is sourced by <code>.bashrc</code> upon logging in that asks what I actually want to connect to and then does so for me.</p>
<p>In the future, I might move to a BlackBerry 8700(c/g) as they support EDGE (much faster network speed), have much faster CPUs, and a higher standby time. I am not sure what I am going to do in the long run, as 2G networks in the US will probably all be shut down by the end of the year with 3G soon to follow. I guess I can just enjoy it while it lasts.</p>
<p>Here are the lines I added to my <code>sshd</code> config for the BlackBerry to be able to connect:</p>
<pre><code>HostKeyAlgorithms +ssh-dss
PubkeyAcceptedKeyTypes +ssh-dss
KexAlgorithms +diffie-hellman-group1-sha1
Ciphers +3des-cbc
</code></pre>
<p>And here are some pictures!</p>
<p><img src="https://rqsall.com/posts/files/connected.jpg"></p>
<p><em>Connected and at the interactive prompt</em></p>
<p><img src="https://rqsall.com/posts/files/top.jpg"></p>
<p><em><code>top</code> output from one server</em></p>
<p><img src="https://rqsall.com/posts/files/htop.jpg"></p>
<p><em><code>htop</code> output from another server</em></p>
<p><img src="https://rqsall.com/posts/files/altoids.jpg"></p>
<p><em>Spare batteries kept in an Altoids tin</em></p>


</div></div>]]>
            </description>
            <link>https://rqsall.com/posts/using-an-old-blackberry-as-a-portable-ssh-terminal</link>
            <guid isPermaLink="false">hacker-news-small-sites-24166402</guid>
            <pubDate>Sat, 15 Aug 2020 06:06:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mozilla’s Uncertain Future]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 138 (<a href="https://news.ycombinator.com/item?id=24166385">thread link</a>) | @jonathankoren
<br/>
August 14, 2020 | https://civilityandtruth.com/2020/08/13/mozillas-uncertain-future/ | <a href="https://web.archive.org/web/*/https://civilityandtruth.com/2020/08/13/mozillas-uncertain-future/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <figure>
  <p><a href="https://civilityandtruth.com/assets/images/mozilla-revenues-vs-expenses.png"><img src="https://civilityandtruth.com/assets/images/mozilla-revenues-vs-expenses.png" alt="Graph of Mozilla revenues compared to expenses"></a></p>
  <figcaption>The graph above shows the consolidated revenues and
expenses of the Mozilla Foundation and Mozilla Corporation from the
Foundation’s founding in 2003 through 2018. Almost all of the revenues
and expenses are associated with the Mozilla Corporation, and almost
all of the revenues of the Mozilla Corporation are from Google and
other search engine providers. Graph © 2020 Frank Hecker, made
available under the <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons
Attribution 4.0 International license</a>.</figcaption>
</figure>

<p><em>tl;dr: Some thoughts on Mozilla for people who don’t know Mozilla.</em></p>

<p>By now everyone in the tech world has heard of the major layoffs at
the Mozilla Corporation, the organization that creates and distributes
the Firefox web browser. (For those who haven’t heard, about 250
people were laid off, about a quarter of the work force.) Lots of
people in the tech world have spoken their piece about the
significance of this event and what it means for the future of
Mozilla, the web, and so on.</p>

<p>Rather than write something of and for the tech world, I wanted to
briefly explain what’s going on for those of my readers who don’t know
HTML from XML, and who are more familar with the worlds of nonprofits
and regular old businesses. I used to work for Mozilla, and have more
knowledge of it and (I hope) insight into it than most people, but
I’ve been gone from Mozilla for ten years now. Thus what I write below
is based on observing it from a distance, like seeing an old friend
whose life has long since diverged from mine.</p>

<p>Disclaimer: I work for a tech company, and I don’t usually write about
other tech companies. So I will strongly emphasize that what I write
here are my personal opinions only, and do not represent the positions
of my present employer or past employers.</p>

<h2 id="what-is-mozilla">What is Mozilla?</h2>

<p>Mozilla is actually two things, the Mozilla Foundation and the Mozilla
Corporation, which are often confused and conflated in public
discourse. (There’s actually at least one other piece, but these two
are the main ones.) The Mozilla Foundation, founded in 2003 to take
over development of the source code for the Netscape web browser, is a
501(c)(3) tax-exempt nonprofit organization, with a staff of 80 people
and a budget of about $27 million in 2018, the last year for which
figures are available. The Mozilla Corporation, founded in 2005, is a
for-profit business, wholly owned by the Mozilla Foundation, with a
staff of about a thousand and revenue of about $440 million, again
from the 2018 financials.</p>

<p>This organizational structure was designed to allow the Mozilla
Corporation to engage in business activities which would be
incompatible with 501(c)(3) status, with a portion of the revenues
from those activities directed to the Mozilla Foundation to help fund
its activities. Having a nonprofit parent also means that the
management and employees of the Mozilla Corporation can help serve the
public benefit goals of the Mozilla Foundation, while still having
interesting jobs, being paid reasonably well, and feeling themselves
to be part of the overall Silicon Valley high-tech milieu.</p>

<p>Second: The customers of the Mozilla Corporation are not the users of
Firefox (among whom you may count yourself). The Mozilla Corporation’s
customers are large corporations like Google that pay for things that
will help them make money, most notably having their Internet search
service be the default in the Firefox browser. And to complete the old
saying, “If you’re not the customer…”, then the 200+ million Firefox
users are the product, potential viewers of ads served up by Google or
others.</p>

<p>(The existence of the Firefox browser as a competitor to Google’s
Chrome browser also supposedly helps Google avoid unwelcome antitrust
attention, especially now that Microsoft has abandoned its own browser
development efforts to base its own browser on the Chrome code. But
it’s unclear how important this consideration actually is to Google
senior management.)</p>

<p>In the early days of the Mozilla Corporation these search engine
relationships proved extremely lucrative, jumping from less than $5
million in 2004 to over $50 million in 2005, the first year in which
the Mozilla Corporation reported financial results, and eventually
growing to a high of about $540 million in 2017.</p>

<p>But as the number of Firefox users decreases (due to the growing
market dominance of the Chrome browser), and those users click on
fewer online ads (for example, because they’re spending less during
the COVID-19 pandemic), the willingness of Google and other customers
to pay the Mozilla Corporation for those users decreases
accordingly. Thus the Mozilla Corporation cutting a quarter of its
workforce.</p>

<p>(In contrast, to my knowledge the Mozilla Foundation itself is not
laying off anyone, at least at this time. It gets its funding from a
combination of royalties from the Mozilla Corporation for use of the
Firefox and Mozilla trademarks, government and foundation grants, and
individual donations. For 2018 the royalties accounted for about half
of the Mozilla Foundation’s budget, with grants and individual donations
each accounting for about a quarter of the budget.)</p>

<p>So, if you’re an avid user of the Firefox browser and want to chip in
a few dollars to help support its development, there’s actually no way
for you to do so, at least not at present. Your donations will go to
the Mozilla Foundation, which will use them to help fund its outreach
and advocacy initiatives, of which it has several. The Mozilla
Foundation itself does not develop Firefox—or any other software, to
my knowledge.</p>

<h2 id="whence-mozilla">Whence Mozilla?</h2>

<p>How has Mozilla (or, more correctly, the Mozilla Corporation) come
to its present pass? The best way I can explain it is that the Mozilla
Corporation is not really a business in the way we’d normally think of
a business, profit-focused and subject to market discipline.</p>

<p>Instead you can think of the Mozilla Corporation as being analogous to
the Bell Labs or Xerox PARC of yore, R&amp;D organizations funded by a
seemingly-unending stream of profits earned by other businesses that
enjoyed dominant positions in their respective markets. In this sense
Google is to Mozilla as AT&amp;T was to Bell Labs, or Xerox to Xerox
PARC.</p>

<p>Like Bell Labs and Xerox PARC, the Mozilla Corporation provided a home
for some of the smartest software developers around. Like those
organizations, the Mozila Corporation has initiated a myriad of
projects ranging from the mundane and useful (like the Firefox
browser) to the esoteric and speculative. Like those organizations,
the Mozilla Corporation has given away much of what it has produced in
the form of public goods available to everyone at no charge.</p>

<p>Like Bell Labs and Xerox PARC, the Mozilla Corporation has indulged a
taste for “build it yourself” vertical integration, and in particular
for creating its own bespoke development tools and software stack. For
example, like those organizations the Mozilla Corporation has created
its own operating system (FirefoxOS), its own programming language
(Rust), and (of course) its own graphical user environment in the form
of the Firefox browser (not to mention yet another web browser, this
one more research-oriented, and various experiments in software for
virtual reality environments).</p>

<p>And finally, the Mozilla Corporation is engaged in the same struggle
that Bell Labs and Xerox PARC found themselves in: trying to convert a
research-oriented organization into an actual business, and capture
for itself more of the value that it has been providing to the world
(and to its past, present, and future competitors) for free.</p>

<h2 id="whither-mozilla">Whither Mozilla?</h2>

<p>What will happen to Mozilla, and to the Mozilla Corporation in
particular? The basic situation is that Mozilla has tried to be at
least three things simultaneously: an advocacy organization, a
developer and distributor of mass market consumer software and related
services, and (as noted above) a research lab.</p>

<p>Being an advocacy organization is relatively inexpensive, but the
other two functions are not: software development (including
research-related activities) and branding and marketing together
consumed almost three quarters of the combined Mozilla Corporation and
Foundation expense budget of $450 million in 2018. Thus when COVID-19
hit and the Mozilla Corporation hit a brick wall in terms of search
engine revenue, its choice was apparently either to stop being a
consumer software and services company, or to stop being a research
lab.</p>

<p>In the end Mozilla Corporation senior management apparently decided to
go for being a consumer software and services company, and to ditch
any activities not related to that, including research projects.
Having done so, the Mozilla Corporation faces a number of problems:</p>

<p>First, as noted above the Mozilla ethos is arguably more like that of
an R&amp;D lab than of a business proper. Just getting Mozilla
employees to think of themselves as working in the service of a
profit-driven business, and to act in accordance with that thought
every single day, may be an uphill battle.</p>

<p>Second, Mozilla is arguably becoming superfluous, at least as far as
its own largest customer, Google, is concerned. Google has its own
browser and browser development team, its own research lab, and
presumably an inclination to want to spend its R&amp;D money on things
it can control and direct itself. Google also has the ability and the
opportunity to capture the remaining base of Firefox users, at least
those that are monetizable.</p>

<p>There will always be a core of enthusiastic Firefox users, but a lot
of them switch their search engine to something other than Google, run
ad blockers, and don’t click on online ads. Thus they are for the most
part irrelevant from Google’s point of view. At some point the major
value Firefox has for Google will be as presumed insulation from
antitrust enforcement efforts targeting Chrome, but such insurance,
even if it’s of value to Google, doesn’t necessarily require a large
Firefox user base.</p>

<p>Finally, it’s …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://civilityandtruth.com/2020/08/13/mozillas-uncertain-future/">https://civilityandtruth.com/2020/08/13/mozillas-uncertain-future/</a></em></p>]]>
            </description>
            <link>https://civilityandtruth.com/2020/08/13/mozillas-uncertain-future/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24166385</guid>
            <pubDate>Sat, 15 Aug 2020 06:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write Your Own Virtual Machine]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24166137">thread link</a>) | @ChankeyPathak
<br/>
August 14, 2020 | https://justinmeiners.github.io/lc3-vm/ | <a href="https://web.archive.org/web/*/https://justinmeiners.github.io/lc3-vm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<section>

<a name="1:1"></a>
<a name="1:2"></a><div><a name="1:2"><h4>2. Introduction</h4></a>
<p>In this tutorial, I will teach you how to write your own virtual machine (VM) that can run assembly language programs, such as my friend's <a href="https://github.com/rpendleton/lc3-2048">2048</a> or my <a href="https://github.com/justinmeiners/lc3-rogue">Roguelike</a>. If you know how to program, but would like to gain a deeper understanding of what is going on inside a computer and better understand how programming languages work, then this project is for you. Writing your own VM may sound a little scary, but I promise that you will find it to be surprisingly simple and enlightening.
</p>
<p>The final code is about 250 lines of C (<a href="https://justinmeiners.github.io/lc3-vm/src/lc3.c">unix</a>, <a href="https://justinmeiners.github.io/lc3-vm/src/lc3-win.c">windows</a>).
All you need to know is how to read basic C or C++ and how to do <a href="https://www.swarthmore.edu/NatSci/echeeve1/Ref/BinaryMath/BinaryMath.html">binary arithmetic</a>.
</p>
<blockquote><p> <strong>Note:</strong> This VM is a <a href="https://en.wikipedia.org/wiki/Literate_programming">literate program</a>. This means you are reading the source code right now! Each piece of code from the project will be shown and explained thoroughly, so you can be sure nothing is left out. The final code was created by <a href="https://github.com/zyedidia/Literate">"weaving"</a> the blocks of code together.
</p>
</blockquote>
<h3> What is a virtual machine?</h3>
<p>A VM is a program that acts like a computer. It simulates a CPU along with a few other hardware components, allowing it to perform arithmetic, read and write to memory, and interact with I/O devices, just like a physical computer. Most importantly, it can understand a machine language which you can use to program it.
</p>
<p>The amount of computer hardware the VM attempts to simulate depends on its purpose. Some VMs are designed to reproduce the behavior of some particular computer, such as video game emulators. Most people don't have an NES lying around anymore, but we can still play NES games by simulating the NES hardware in a program. These emulators must <a href="http://wiki.nesdev.com/w/index.php/Tricky-to-emulate_games">faithfully recreate</a> every <a href="http://wiki.nesdev.com/w/index.php/Emulator_tests">detail</a> and major hardware component of the original device.
</p>
<p>Other VMs don't act like any real computer and are entirely made up! This is primarily done to make software development easier. Imagine you wanted to create a program that ran on multiple computer architectures. A VM could offer a standard platform which provided portability for all of them. Instead of rewriting a program in different dialects of assembly for each CPU architecture, you would only need to write the small VM program in each assembly language. Each program would then be written only once in the VM's assembly language.
</p>
<p><img src="https://justinmeiners.github.io/lc3-vm/img/no_vm.gif" alt="architecture specific implementation">
</p>
<p><img src="https://justinmeiners.github.io/lc3-vm/img/vm.gif" alt="vm for each architecture">
</p>
<blockquote><p> <strong>Note:</strong> A compiler solves a similar problem by compiling a standard <em>high-level language</em> to several CPU architectures. A VM creates one standard <em>CPU architecture</em> which is simulated on various hardware devices. One advantage of a compiler is that it has no runtime overhead while a VM does. Even though compilers do a pretty good job, writing a new one that targets multiple platforms is very difficult, so VMs are still helpful here. In practice, VMs and compilers are mixed at various levels.
</p>
</blockquote>
<p>The <a href="https://en.wikipedia.org/wiki/Java_virtual_machine">Java Virtual Machine (JVM)</a> is a very successful example. The JVM itself is a moderately sized program that is small enough for one programmer to understand. This has made it possible to be written for thousands of devices including phones. Once the JVM is implemented on a new device, any Java, Kotlin, or Clojure program ever written can run on it without modification. The only cost is the overhead of the VM itself and the <a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/">further abstraction</a> from the machine. Most of the time, this is a pretty good tradeoff.
</p>
<p>A VM doesn't have to be large or pervasive to provide a similar benefit. Old <a href="https://fabiensanglard.net/anotherWorld_code_review/">video games</a> often used small VMs to provide simple <a href="https://sf2platinum.wordpress.com/page/1/">scripting systems</a>.
</p>
<p>VMs are also useful for executing code in a secure or isolated way. One application of this is garbage collection. There <a href="https://www.lua.org/pil/24.2.html">is no trivial way</a> to implement automatic garbage collection on top of C or C++ since a program cannot see its own stack or variables. However, a VM is “outside” the program it is running and can observe all of the <a href="https://en.wikipedia.org/wiki/Tracing_garbage_collection">memory references</a> on the stack.
</p>
<p>Another example of this behavior is demonstrated by <a href="https://solidity.readthedocs.io/en/v0.4.24/introduction-to-smart-contracts.html">Ethereum smart contracts</a>. Smart contracts are small programs which are executed by each validating node in the blockchain network. This requires the node operators to run programs on their machines that have been written by complete strangers, without any opportunity to scrutinize them beforehand. To prevent a contract from doing malicious things, they are run inside a <a href="http://ethdocs.org/en/latest/introduction/what-is-ethereum.html#ethereum-virtual-machine">VM</a> that has no access to the file system, network, disc, etc. Ethereum is also a good application of the portability features that result when using a VM. Since Ethereum nodes can be run on many kinds of computers and operating systems, the use of a VM allows smart contracts to be written without any consideration of the many platforms they run on.
</p>

</div>
<a name="1:3"></a><div><a name="1:3"><h4>3. LC-3 Architecture</h4></a>
<p>Our VM will simulate a fictional computer called the <a href="https://en.wikipedia.org/wiki/Little_Computer_3">LC-3</a>. The LC-3 is popular for teaching university students how to program in assembly language. It has a simplified instruction set <a href="http://ref.x86asm.net/coder64.html">compared to x86</a>, but contains all the main ideas used in modern CPUs.
</p>
<p>First, we need to simulate the essential hardware components of the machine. Try to understand what each component is, but don't worry right now if you are unsure of how it fits into the larger picture. Start by creating a C file. Each of the code snippets in this section should be placed in the global scope of this file.
</p>
<h3> Memory</h3>
<p>The LC-3 has 65,536 memory locations (the maximum that is addressable by a 16-bit unsigned integer <code>2^16</code>), each of which stores a 16-bit value. This means it can store a total of only 128kb, which is a lot smaller than you may be used to! In our program, this memory will be stored in a simple array:
</p>

<div>
<p><span>{Memory Storage <a href="https://justinmeiners.github.io/lc3-vm/index.html#1:3">3</a>}</span></p><pre>/* 65536 locations */
uint16_t memory[UINT16_MAX];
</pre>


<p>Used in section <a href="https://justinmeiners.github.io/lc3-vm/index.html#1:11">11</a></p>
</div>
<h3> Registers</h3>
<p>A register is a slot for storing a single value on the CPU. Registers are like the "workbench" of the CPU. For the CPU to work with a piece of data, it has to be in one of the registers. However, since there are just a few registers, only a minimal amount of data can be loaded at any given time. Programs work around this by loading values from memory into registers, calculating values into other registers, and then storing the final results back in memory.
</p>
<p>The LC-3 has 10 total registers, each of which is 16 bits. Most of them are general purpose, but a few have designated roles.
</p>
<ul>
<li>8 general purpose registers  (<code>R0</code>-<code>R7</code>)
</li>
<li>1 program counter (<code>PC</code>) register
</li>
<li>1 condition flags (<code>COND</code>) register
</li>
</ul>
<p>The general purpose registers can be used to perform any program calculations. The program counter is an unsigned integer which is the address of the next instruction in memory to execute. The condition flags tell us information about the previous calculation.
</p>

<div>
<p><span>{Registers <a href="https://justinmeiners.github.io/lc3-vm/index.html#1:3">3</a>}</span></p><pre>enum
{
    R_R0 = 0,
    R_R1,
    R_R2,
    R_R3,
    R_R4,
    R_R5,
    R_R6,
    R_R7,
    R_PC, /* program counter */
    R_COND,
    R_COUNT
};
</pre>



</div>
<p>Just like the memory, we will store the registers in an array:
</p>

<div>
<p><span>{Register Storage <a href="https://justinmeiners.github.io/lc3-vm/index.html#1:3">3</a>}</span></p><pre>uint16_t reg[R_COUNT];
</pre>


<p>Used in section <a href="https://justinmeiners.github.io/lc3-vm/index.html#1:11">11</a></p>
</div>
<h3> Instruction Set</h3>
<p>An instruction is a command which tells the CPU to do some fundamental task, such as add two numbers. Instructions have both an <strong>opcode</strong> which indicates the kind of task to perform and a set of <strong>parameters</strong> which provide inputs to the task being performed.
</p>
<p>Each <strong>opcode</strong> represents one task that the CPU "knows" how to do. There are just 16 opcodes in LC-3. Everything the computer can calculate is some sequence of these simple instructions. Each instruction is 16 bits long, with the left 4 bits storing the opcode. The rest of the bits are used to store the parameters.
</p>
<p>We will discuss, in detail, what each instruction does later. For now, define the following opcodes. Make sure they stay in this order so that they are assigned the proper enum value:
</p>

<div>
<p><span>{Opcodes <a href="https://justinmeiners.github.io/lc3-vm/index.html#1:3">3</a>}</span></p><pre>enum
{
    OP_BR = 0, /* branch */
    OP_ADD,    /* add  */
    OP_LD,     /* load */
    OP_ST,     /* store */
    OP_JSR,    /* jump register */
    OP_AND,    /* bitwise and */
    OP_LDR,    /* load register */
    OP_STR,    /* store register */
    OP_RTI,    /* unused */
    OP_NOT,    /* bitwise not */
    OP_LDI,    /* load indirect */
    OP_STI,    /* store indirect */
    OP_JMP,    /* jump */
    OP_RES,    /* reserved (unused) */
    OP_LEA,    /* load effective address */
    OP_TRAP    /* execute trap */
};
</pre>



</div>
<blockquote><p> <strong>Note:</strong> The Intel x86 architecture has hundreds of instructions, while others such as ARM and LC-3 have very few. Small instruction sets are referred to as <a href="https://en.wikipedia.org/wiki/Reduced_instruction_set_computer">RISCs</a> while larger ones are called <a href="https://en.wikipedia.org/wiki/Complex_instruction_set_computer">CISCs</a>. Larger instruction sets typically do not provide any fundamentally new possibilities, but they <a href="https://cs.stanford.edu/people/eroberts/courses/soco/projects/risc/risccisc/">often make it more convenient</a> to write assembly for. A single instruction in CISC might take the place of several in RISC. However, they tend to be more complex and expensive for engineers to design and manufacture. This and other tradeoffs cause the designs to come <a href="https://cs.stackexchange.com/questions/269/why-would-anyone-want-cisc">in and out of style</a>.
</p>
</blockquote>
<h3> Condition Flags</h3>
<p>The <code>R_COND</code> register stores condition flags which provide information about the most recently executed calculation. This allows programs to check logical conditions such as <code>if (x &gt; 0) { ... }</code>.
</p>
<p>Each CPU has a variety of condition flags to signal various situations. The LC-3 uses only 3 condition flags which indicate the sign of the previous calculation.
</p>

<div>
<p><span>{Condition Flags <a href="https://justinmeiners.github.io/lc3-vm/index.html#1:3">3</a>}</span></p><pre>enum
{
    FL_POS = 1 &lt;&lt; 0, /* P */
    FL_ZRO = 1 &lt;&lt; 1, /* Z */
    FL_NEG = 1 &lt;&lt; 2, /* N */
};
</pre>



</div>
<blockquote><p> <strong>Note:</strong> (The <code>&lt;&lt;</code> symbol is called the <a href="https://msdn.microsoft.com/en-us/library/336xbhcz.aspx">left bitshift operator</a>. <code>(n &lt;&lt; k)</code> shifts the bits of <code>n</code> to the left <code>k</code> places. Thus <code>1 &lt;&lt; 2</code> will equal <code>4</code>. Read that link if you are not familiar. It will be important.)
</p>
</blockquote>
<p>We are finished setting up the hardware components of our VM! After adding standard includes (see reference), your file should look something like this:
</p>

<div>
<p><span>{<strong>lc3.c</strong> <a href="https://justinmeiners.github.io/lc3-vm/index.html#1:3">3</a>}</span></p><pre><span>{Includes, <a href="https://justinmeiners.github.io/lc3-vm/index.html#1:12">12</a>}</span>

<span>{Registers, <a href="https://justinmeiners.github.io/lc3-vm/index.html#1:3">3</a>}</span>
<span>{Opcodes, <a href="https://justinmeiners.github.io/lc3-vm/index.html#1:3">3</a>}</span>
<span>{Condition Flags, <a href="https://justinmeiners.github.io/lc3-vm/index.html#1:3">3</a>}</span>
</pre>
<p>Added to in section <a href="https://justinmeiners.github.io/lc3-vm/index.html#1:11">11</a></p>


</div>
</div>
<a name="1:4"></a><div><a name="1:4"><h4>4. Assembly Examples</h4></a>
<p>Now let's look at an LC-3 assembly program to get an idea of what the VM actually runs. You don't need to know how to program assembly or understand everything that is going on. Just try to get a general idea of what is going on. Here is a simple "Hello World":
</p>

<div>
<p><span>{Hello World Assembly <a href="https://justinmeiners.github.io/lc3-vm/index.html#1:4">4</a>}</span></p><pre>.O…</pre></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://justinmeiners.github.io/lc3-vm/">https://justinmeiners.github.io/lc3-vm/</a></em></p>]]>
            </description>
            <link>https://justinmeiners.github.io/lc3-vm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24166137</guid>
            <pubDate>Sat, 15 Aug 2020 05:10:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. & COVID19 – Less Tests, More Deaths, No End in Sight]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24166077">thread link</a>) | @lettergram
<br/>
August 14, 2020 | https://austingwalters.com/u-s-covid19-less-tests-more-deaths-no-end-in-sight/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/u-s-covid19-less-tests-more-deaths-no-end-in-sight/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3461">

<div>
<p><a href="https://austingwalters.com/covid-19-u-s-fatalities-june-2020-update/" target="_blank" rel="noopener noreferrer">In June</a>, I made the prediction that it’s likely we’ll see hundreds of thousands dead by July from COVID-19.</p>
<p>According to official data, my prediction <span><em>was not entirely accurate</em></span>, being closer to the lower bound of my simulation(s) (a hundred thousand).</p>
<p>Today, we have more information about the virus and importantly improved data on death rates (via the CDC) – <strong>it appears the official death toll from COVID19 may be under reported</strong>. Perhaps more terrifying, it also appears <strong>if you are 25-85+ years old you have a 20-50% increased risk of dying in 2020 than you did in 2015-2019</strong> (given COVID19’s current penetration rate).</p>
<p>Some key takeaways from this analysis:</p>
<ul>
<li>Official death COVID19 related deaths are likely higher than official count(s)</li>
<li>Testing capacity appears to be shrinking or not being reported</li>
<li>Age groups over 25 are seeing a 20-50% increased number of deaths in 2020 (over 2015-2019)</li>
<li>It is likely the increased fatality rate over prior years will continue as COVID19 prevalence increases</li>
<li>By year end 2020, it’s likely we will see over one million deaths in the U.S.</li>
<li>By April 2021, it’s likely we will see over two million deaths in the U.S.</li>
</ul>
<p>For transparency:</p>
<ul>
<li>Code (&amp; Graphics): <a href="https://github.com/lettergram/covid19-analysis">Github</a></li>
<li>Data
<ul>
<li>Covidtracking.com: <a href="https://covidtracking.com/api/states/daily" rel="nofollow">https://covidtracking.com/api/states/daily</a></li>
<li>CDC: <a href="https://www.cdc.gov/nchs/nvss/vsrr/covid19/excess_deaths.htm">https://www.cdc.gov/nchs/nvss/vsrr/covid19/excess_deaths.htm </a></li>
<li>CDC data is only [mostly] accurate up to the week of July 20 – 26, 2020</li>
</ul>
</li>
</ul>

<p>First and foremost, we aren’t testing enough to capture all cases. People are not being tested for various reasons: desire to work, no/minor symptoms, can’t receive a test, etc. Unfortunately, this will leave us vulnerable.</p>
<p>On a whole, the nation wide positive rate is still hovering well above lows, with around 7% tests coming back positive.</p>
<figure id="attachment_3464" aria-describedby="caption-attachment-3464"><a href="https://austingwalters.com/wp-content/uploads/2020/08/us-test-ratios.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/us-test-ratios-1024x765.png" alt="US Test Ratios (Aug 14)" width="650" height="486" srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-test-ratios-1024x765.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-test-ratios-300x224.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-test-ratios-768x574.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-test-ratios-1536x1147.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-test-ratios-2048x1529.png 2048w" sizes="(max-width: 650px) 100vw, 650px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/us-test-ratios-1024x765.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-test-ratios-1024x765.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-test-ratios-300x224.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-test-ratios-768x574.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-test-ratios-1536x1147.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-test-ratios-2048x1529.png 2048w"></a><figcaption id="caption-attachment-3464">US Ratio of Positive COVID19 Test Results</figcaption></figure>
<p>More interesting, testing capacity (or reporting) is declining:</p>
<figure id="attachment_3465" aria-describedby="caption-attachment-3465"><a href="https://austingwalters.com/wp-content/uploads/2020/08/us-counts.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/us-counts-1024x765.png" alt="U.S. COVID19 Testing Per Day" width="650" height="486" srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-counts-1024x765.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-counts-300x224.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-counts-768x574.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-counts-1536x1147.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-counts-2048x1529.png 2048w" sizes="(max-width: 650px) 100vw, 650px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/us-counts-1024x765.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-counts-1024x765.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-counts-300x224.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-counts-768x574.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-counts-1536x1147.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-counts-2048x1529.png 2048w"></a><figcaption id="caption-attachment-3465">U.S. COVID19 Testing Per Day</figcaption></figure>
<p>It is not clear if the reduction in tests are from collection errors, reduced testing capacity, issues with the data provider or some other unknown factor.</p>

<p>Overall, our accounting of deaths from the <a href="https://www.cdc.gov/nchs/nvss/vsrr/covid19/excess_deaths.htm" target="_blank" rel="noopener noreferrer">CDC</a> is only accurate up to the week of July 20 – 26, 2020, from week 1 to week 30 there has been 216,569 more deaths in 2020 over 2019.</p>
<figure id="attachment_3472" aria-describedby="caption-attachment-3472"><a href="https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-week-of-year.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-week-of-year-1024x762.png" alt="US deaths per week of year" width="650" height="484" srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-week-of-year-1024x762.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-week-of-year-300x223.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-week-of-year-768x571.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-week-of-year-1536x1143.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-week-of-year-203x150.png 203w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-week-of-year.png 1574w" sizes="(max-width: 650px) 100vw, 650px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-week-of-year-1024x762.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-week-of-year-1024x762.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-week-of-year-300x223.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-week-of-year-768x571.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-week-of-year-1536x1143.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-week-of-year-203x150.png 203w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-week-of-year.png 1574w"></a><figcaption id="caption-attachment-3472">U.S. Deaths per Week of Year, per CDC</figcaption></figure>
<p>For reference, the <a href="https://www.cdc.gov/nchs/nvss/vsrr/covid19/index.htm" target="_blank" rel="noopener noreferrer">CDC</a> as of writing this (Aug 14, 2020) has only indicated 150k COVID19 related deaths:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-45-57.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-45-57.png" alt="" width="675" height="194" srcset="https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-45-57.png 984w, https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-45-57-300x86.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-45-57-768x221.png 768w" sizes="(max-width: 675px) 100vw, 675px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-45-57.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-45-57.png 984w, https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-45-57-300x86.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-45-57-768x221.png 768w"></a></p>
<p><a href="https://www.worldometers.info/coronavirus/country/us/" target="_blank" rel="noopener noreferrer">Worldometer</a> is showing 170k deaths (on Aug 14, 2020):</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-49-57.png" target="_blank" rel="https://www.worldometers.info/coronavirus/country/us/ noopener noreferrer"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-49-57.png" alt="" width="650" height="446" srcset="https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-49-57.png 747w, https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-49-57-300x206.png 300w" sizes="(max-width: 650px) 100vw, 650px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-49-57.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-49-57.png 747w, https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-01-49-57-300x206.png 300w"></a></p>
<p>It’s important to note, that it is not an entirely fair to compare 2019 to 2020, as each year has variance in deaths. With this in mind, I also created a simple regression model, then compared the predicted death count to the actual 2020 deaths and came to figure of <strong>178,598.40 deaths over the predicted number</strong> (remember, this is for the week of July 20, 2020):</p>
<figure id="attachment_3473" aria-describedby="caption-attachment-3473"><a href="https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-year.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-year.png" alt="" width="502" height="420" srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-year.png 915w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-year-300x251.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-year-768x643.png 768w" sizes="(max-width: 502px) 100vw, 502px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-year.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-year.png 915w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-year-300x251.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-year-768x643.png 768w"></a><figcaption id="caption-attachment-3473">Real Yearly Deaths with Trend Line – Accurate to Week 30 of Specified Year.</figcaption></figure>
<p>Currently, in August — nearly three weeks passed the CDC numbers cut off and deaths are still increasing. At this point, it is likely we are well over 200,000+ deaths beyond the prediction. Further, it is quite possible we are now 250,000+ deaths above the 2019 figures. If true, we are likely under counting COVID related deaths by 40-60%.</p>
<p>This analysis doesn’t take into account mitigating factors (such as less car accidents) as it also doesn’t take into account confounding factors (such as more suicides).</p>
<h2><span>States Under Reporting COVID-19 Related Fatalities</span></h2>
<p>To highlight the clear under reporting of pandemic related fatalities, we can review states, where the issue becomes more pronounced.</p>
<p>Take <strong>Texas</strong>, for instance:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-TX.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-TX-1024x765.png" alt="" width="650" height="485" srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-TX-1024x765.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-TX-300x224.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-TX-768x574.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-TX-1536x1147.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-TX-2048x1529.png 2048w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-TX-203x150.png 203w" sizes="(max-width: 650px) 100vw, 650px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-TX-1024x765.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-TX-1024x765.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-TX-300x224.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-TX-768x574.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-TX-1536x1147.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-TX-2048x1529.png 2048w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-TX-203x150.png 203w"></a>The deaths one standard deviation above the norm (norm being deaths in 2015-2019) are highly correlate with the number of <em>new cases </em>of COVID19, rather than that of COVID19 related <em>deaths</em>.</p>
<p>This implies one of the following:</p>
<ol>
<li>COVID19 deaths are being attributed to another illness</li>
<li>Hospitals are focusing on the COVID19 patients and other critically ill patients are dying (at an alarming rate)</li>
<li>Some other catastrophe is happening</li>
</ol>
<p>Regardless, as more people test positive, more people are dying and there is a high correlation between the two. If I had to guess, this really means people aren’t being tested until after they are dead or critically ill &amp; in the hospital.</p>
<h2><span>Decreased Testing</span></h2>
<p>It’s also important to bring attention to the <span>decreasing number of tests from July 9, 2020 and August 13, 2020</span>. Time will tell if the rate of fatalities will drop (or if just the COVID19 related deaths will), the decreased testing volume correlates exactly with the declining positive cases (as one would suspect).</p>
<p>This holds true for many states, including <strong>Florida</strong>:<a href="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-FL.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-FL-1024x769.png" alt="" width="650" height="488" srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-FL-1024x769.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-FL-300x225.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-FL-768x577.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-FL-1536x1153.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-FL-2048x1538.png 2048w" sizes="(max-width: 650px) 100vw, 650px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-FL-1024x769.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-FL-1024x769.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-FL-300x225.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-FL-768x577.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-FL-1536x1153.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-FL-2048x1538.png 2048w"></a>Testing capacity in Florida has dropped 40% in the past six weeks. At the same time, the death toll is rising. Frankly, I wouldn’t be surprised if reduced testing was a ploy related to opening schools.</p>
<p>There are some examples where the figures do appear to be <em>generally</em> accurate, such as <strong>New York</strong>:<a href="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-NY.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-NY-1024x765.png" alt="" width="650" height="485" srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-NY-1024x765.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-NY-300x224.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-NY-768x574.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-NY-1536x1147.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-NY-2048x1529.png 2048w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-NY-203x150.png 203w" sizes="(max-width: 650px) 100vw, 650px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-NY-1024x765.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-NY-1024x765.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-NY-300x224.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-NY-768x574.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-NY-1536x1147.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-NY-2048x1529.png 2048w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-NY-203x150.png 203w"></a>Another example is <strong>Illinois </strong>(although initially there was likely under-reporting due to lack of testing):</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-IL.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-IL-1024x765.png" alt="" width="650" height="485" srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-IL-1024x765.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-IL-300x224.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-IL-768x574.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-IL-1536x1147.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-IL-2048x1529.png 2048w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-IL-203x150.png 203w" sizes="(max-width: 650px) 100vw, 650px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-IL-1024x765.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-IL-1024x765.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-IL-300x224.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-IL-768x574.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-IL-1536x1147.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-IL-2048x1529.png 2048w, https://austingwalters.com/wp-content/uploads/2020/08/us-stats-in-IL-203x150.png 203w"></a>In terms of which states are more prone to under-reporting vs others, there doesn’t appear to be a clear pattern. Under-reporting appears to be a signal that there is not enough testing – aka the system is overwhelmed. This makes logical sense, as the system becomes overwhelmed, resources are diverted on saving lives over identifying community spread. There’s also a question if the test results are being reported federally and outside my dataset for some reason.</p>

<p>It is difficult mid-pandemic with a lack of testing to determine the case <a href="https://newslit.org/updates/case-fatality-rate-vs-mortality-rate/" target="_blank" rel="noopener noreferrer">fatality rate (CFR) or mortality rate</a>, which is typically what is being reported. Unfortunately, we don’t know the infection rate. With that in mind, it’s probably more accurate to track the “increased risk of dying in 2020”.</p>
<p>In other words:</p>
<blockquote><p>How much greater are my risks of dying in 2020 over 2019?</p></blockquote>
<p>Infection rate is included as part of metric, we don’t know the extent. COVID19 penetration is <em>maybe</em> 10% across the U.S. population (studies vary wildly). Regardless, as the year progresses, we are sure this number will increase.</p>
<p>With that in mind, on average all age groups over 25, are seeing roughly 10-15% increased risk of dying in 2020 over 2019 (again, this will likely increase):<a href="https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-age-group.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-age-group-1024x678.png" alt="" width="750" height="497" srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-age-group-1024x678.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-age-group-300x199.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-age-group-768x509.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-age-group-1536x1017.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-age-group-2048x1357.png 2048w" sizes="(max-width: 750px) 100vw, 750px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-age-group-1024x678.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-age-group-1024x678.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-age-group-300x199.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-age-group-768x509.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-age-group-1536x1017.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/us-deaths-by-age-group-2048x1357.png 2048w"></a>Focusing on <strong>New York</strong>, which appears to have kept decent records &amp; has a decent infection rate – the data looks stark:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/08/NY-deaths-by-age-group.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/NY-deaths-by-age-group-1024x678.png" alt="" width="750" height="497" srcset="https://austingwalters.com/wp-content/uploads/2020/08/NY-deaths-by-age-group-1024x678.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/NY-deaths-by-age-group-300x199.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/NY-deaths-by-age-group-768x509.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/NY-deaths-by-age-group-1536x1017.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/NY-deaths-by-age-group-2048x1357.png 2048w" sizes="(max-width: 750px) 100vw, 750px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/NY-deaths-by-age-group-1024x678.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/NY-deaths-by-age-group-1024x678.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/NY-deaths-by-age-group-300x199.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/NY-deaths-by-age-group-768x509.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/NY-deaths-by-age-group-1536x1017.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/NY-deaths-by-age-group-2048x1357.png 2048w"></a>New Yorkers have a 25-30% increased risk of death for everyone over the age of 25.</p>
<p>It’s been estimated that &gt;20% of New Yorkers have been infected by the virus[<a href="https://www.cnbc.com/2020/06/30/roughly-25percent-of-new-york-city-has-probably-been-infected-with-coronavirus-dr-scott-gottlieb-says.html" target="_blank" rel="noopener noreferrer">1</a>]. While the exact infection rate is debatable, it’s clear these numbers will increase.</p>
<p><strong>New Jersey</strong> which saw a similar situation to <strong>New York</strong> has seen close to a 30-50% increased risk of dying in 2020 over prior years:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/08/NJ-deaths-by-age-group.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/NJ-deaths-by-age-group-1024x678.png" alt="" width="750" height="497" srcset="https://austingwalters.com/wp-content/uploads/2020/08/NJ-deaths-by-age-group-1024x678.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/NJ-deaths-by-age-group-300x199.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/NJ-deaths-by-age-group-768x509.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/NJ-deaths-by-age-group-1536x1017.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/NJ-deaths-by-age-group-2048x1357.png 2048w" sizes="(max-width: 750px) 100vw, 750px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/NJ-deaths-by-age-group-1024x678.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/NJ-deaths-by-age-group-1024x678.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/NJ-deaths-by-age-group-300x199.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/NJ-deaths-by-age-group-768x509.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/NJ-deaths-by-age-group-1536x1017.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/NJ-deaths-by-age-group-2048x1357.png 2048w"></a>Presumably, this would imply more of the population has come into contact with COVID19.</p>
<p>In contrast, <strong>Illinois </strong>is seeing less deaths over the norm, particularly in the older age groups :<a href="https://austingwalters.com/wp-content/uploads/2020/08/IL-deaths-by-age-group.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/IL-deaths-by-age-group-1024x678.png" alt="" width="750" height="497" srcset="https://austingwalters.com/wp-content/uploads/2020/08/IL-deaths-by-age-group-1024x678.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/IL-deaths-by-age-group-300x199.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/IL-deaths-by-age-group-768x509.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/IL-deaths-by-age-group-1536x1017.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/IL-deaths-by-age-group-2048x1357.png 2048w" sizes="(max-width: 750px) 100vw, 750px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/IL-deaths-by-age-group-1024x678.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/IL-deaths-by-age-group-1024x678.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/IL-deaths-by-age-group-300x199.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/IL-deaths-by-age-group-768x509.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/IL-deaths-by-age-group-1536x1017.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/IL-deaths-by-age-group-2048x1357.png 2048w"></a>The difference in Illinois appears to be older populations have seen a muted increase in deaths. Arguably, this can be attributed to better nursing home isolation and the <a href="https://abc7chicago.com/coronavirus-covid-19-illinois-coroanvirus/6238032/" target="_blank" rel="noopener noreferrer">stricter lock down conditions</a>.</p>
<p>It should be noted, <strong>Texas</strong> on the other hand has seen a muted increase in fatalities in all age groups (less than Illinois or New York):<a href="https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-age-group.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-age-group-1024x678.png" alt="" width="792" height="524" srcset="https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-age-group-1024x678.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-age-group-300x199.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-age-group-768x509.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-age-group-1536x1017.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-age-group-2048x1357.png 2048w" sizes="(max-width: 792px) 100vw, 792px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-age-group-1024x678.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-age-group-1024x678.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-age-group-300x199.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-age-group-768x509.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-age-group-1536x1017.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-age-group-2048x1357.png 2048w"></a>The largest increase has been in the 25-44 year old age range. It’s probably Texas hasn’t had as much of a proliferation of COVID19 yet and most of the spread has been related to young gathers. Leading to our next section…</p>
<h2><span>COVID19 Spread due to Gatherings</span></h2>
<p>It’s important to acknowledge, that as people gather Coronavirus spreads more easily. Particularly, in <strong>Texas</strong>, <strong>Florida</strong>, <strong>Illinois</strong> and others started to see a rise in fatalities (and infections) following rises in heat (pushing gatherings in doors), protests, and generally opening bars.</p>
<p>Particularly, the rise of deaths in <strong>Texas</strong> coincide directly with the protests (Starting week 22 and rising to the present):</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-week-of-year.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-week-of-year-1024x762.png" alt="" width="650" height="484" srcset="https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-week-of-year-1024x762.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-week-of-year-300x223.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-week-of-year-768x571.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-week-of-year-1536x1143.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-week-of-year-203x150.png 203w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-week-of-year.png 1574w" sizes="(max-width: 650px) 100vw, 650px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-week-of-year-1024x762.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-week-of-year-1024x762.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-week-of-year-300x223.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-week-of-year-768x571.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-week-of-year-1536x1143.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-week-of-year-203x150.png 203w, https://austingwalters.com/wp-content/uploads/2020/08/TX-deaths-by-week-of-year.png 1574w"></a>This also makes sense as to why the group seeing the largest increase in “risk of dying in 2020” are those 25-44 years of age.</p>
<p><strong>Florida</strong> has seen the same effect, in the exact same time range:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/08/FL-deaths-by-week-of-year.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/FL-deaths-by-week-of-year-1024x762.png" alt="" width="650" height="484" srcset="https://austingwalters.com/wp-content/uploads/2020/08/FL-deaths-by-week-of-year-1024x762.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/FL-deaths-by-week-of-year-300x223.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/FL-deaths-by-week-of-year-768x571.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/FL-deaths-by-week-of-year-1536x1143.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/FL-deaths-by-week-of-year-203x150.png 203w, https://austingwalters.com/wp-content/uploads/2020/08/FL-deaths-by-week-of-year.png 1574w" sizes="(max-width: 650px) 100vw, 650px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/FL-deaths-by-week-of-year-1024x762.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/FL-deaths-by-week-of-year-1024x762.png 1024w, https://austingwalters.com/wp-content/uploads/2020/08/FL-deaths-by-week-of-year-300x223.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/FL-deaths-by-week-of-year-768x571.png 768w, https://austingwalters.com/wp-content/uploads/2020/08/FL-deaths-by-week-of-year-1536x1143.png 1536w, https://austingwalters.com/wp-content/uploads/2020/08/FL-deaths-by-week-of-year-203x150.png 203w, https://austingwalters.com/wp-content/uploads/2020/08/FL-deaths-by-week-of-year.png 1574w"></a>It’s difficult to attribute these increased fatalities directly to events, as there are many factors co-mingling to create the situation. Personally, I suspect heat is the largest factor. People gathered outside to protest or celebrate (July 4th) and ended up congregating inside, without masks. This lead to an increase in spread and fatalities, as moving indoors confines people together, in air conditioning, with minimal mask protection or UV to kill the virus.</p>

<p>Finally, in prior discussions I’ve made predictions. Largely, these predictions came from running simulations (both on my own and available to me). As it stands, I continue to stand by my prior prediction:</p>
<ul>
<li>3 million COVID-19 deaths in the United States is likely (April 1, 2021)</li>
<li>25% [true] unemployment in the United States is likely</li>
<li>15% reduction in GDP is within reason</li>
</ul>
<p>Rerunning prior simulation(s) with some minor adjustments to account for new information (such as mask use) and assuming moderately widespread school reopening(s) (and assuming children spread COVID19). The <a href="https://covid19-scenarios.org/?q=~(ageDistributionData~(data~(~(ageGroup~%270-9~population~39721484)~(ageGroup~%2710-19~population~42332393)~(ageGroup~%2720-29~population~46094077)~(ageGroup~%2730-39~population~44668271)~(ageGroup~%2740-49~population~40348398)~(ageGroup~%2750-59~population~42120077)~(ageGroup~%2760-69~population~38488173)~(ageGroup~%2770-79~population~24082598)~(ageGroup~%2780*2b~population~13147180))~name~%27United*20States*20of*20America)~scenarioData~(data~(epidemiological~(hospitalStayDays~3~icuStayDays~14~infectiousPeriodDays~3~latencyDays~3~overflowSeverity~2~peakMonth~0~r0~(begin~4.08~end~4.98)~seasonalForcing~0)~mitigation~(mitigationIntervals~(~(color~%27*23cccccc~name~%27Lockdown*20*231~timeRange~(begin~%272020-03-24T00*3a00*3a00.000Z~end~%272020-06-01T17*3a00*3a00.000Z)~transmissionReduction~(begin~75~end~85))~(color~%27*23a114c9~name~%27Loosening*20*231~timeRange~(begin~%272020-06-01T17*3a00*3a00.000Z~end~%272020-08-18T17*3a00*3a00.000Z)~transmissionReduction~(begin~70~end~80))~(color~%27*239801b0~name~%27Schools*20Reopen~timeRange~(begin~%272020-08-18T17*3a00*3a00.000Z~end~%272020-10-01T17*3a00*3a00.000Z)~transmissionReduction~(begin~40~end~80))~(color~%27*23d64ef8~name~%27Semi-Lockdown~timeRange~(begin~%272020-10-01T17*3a00*3a00.000Z~end~%272020-12-31T18*3a00*3a00.000Z)~transmissionReduction~(begin~60~end~80))))~population~(ageDistributionName~%27United*20States*20of*20America~caseCountsName~%27United*20States*20of*20America~hospitalBeds~798288~icuBeds~100000~importsPerDay~0.1~initialNumberOfCases~1~populationServed~327167434)~simulation~(numberStochasticRuns~30~simulationTimeRange~(begin~%272020-02-08T00*3a00*3a00.000Z~end~%272021-04-01T17*3a00*3a00.000Z)))~name~%27United*20States*20of*20America*20*28edited*29)~schemaVer~%272.1.0~severityDistributionData~(data~(~(ageGroup~%270-9~confirmed~5~critical~5~fatal~30~isolated~0~palliative~0~severe~1)~(ageGroup~%2710-19~confirmed~5~critical~10~fatal~30~isolated~0~palliative~0~severe~3)~(ageGroup~%2720-29~confirmed~10~critical~10~fatal~30~isolated~0~palliative~0~severe~3)~(ageGroup~%2730-39~confirmed~15~critical~15~fatal~30~isolated~0~palliative~0~severe~3)~(ageGroup~%2740-49~confirmed~20~critical~20~fatal~30~isolated~0~palliative~0~severe~6)~(ageGroup~%2750-59~confirmed~25~critical~25~fatal~40~isolated~0~palliative~0~severe~10)~(ageGroup~%2760-69~confirmed~30~critical~35~fatal~40~isolated~0~palliative~0~severe~25)~(ageGroup~%2770-79~confirmed~40~critical~45~fatal~50~isolated~0~palliative~0~severe~35)~(ageGroup~%2780*2b~confirmed~50~critical~55~fatal~50~isolated~0~palliative~0~severe~50))~name~%27China*20CDC))&amp;v=1" target="_blank" rel="noopener noreferrer">simulation framework</a> (click to alter simulation parameters) I’ve been using from <a href="https://neherlab.org/" target="_blank" rel="noopener noreferrer">Research group of Richard Neher</a> at the <a href="https://www.biozentrum.unibas.ch/home/" target="_blank" rel="noopener noreferrer">Biozentrum, University of Basel</a> shows the following:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-00-59-06.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-00-59-06.png" alt="" width="906" height="641" srcset="https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-00-59-06.png 906w, https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-00-59-06-300x212.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-00-59-06-768x543.png 768w" sizes="(max-width: 906px) 100vw, 906px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-00-59-06.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-00-59-06.png 906w, https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-00-59-06-300x212.png 300w, https://austingwalters.com/wp-content/uploads/2020/08/Screenshot-from-2020-08-14-00-59-06-768x543.png 768w"></a></p>
<p>That’s an estimated 180k to 1.85m dead by October 14th. Personally, for the officially count, I’d err on the side of the lower values, perhaps 250k. However, I suspect deaths will be under counted due to lack of testing, I suspect the real figures will be closer to 500k-800k after analysis, this would more closely matching the findings above (which indicate we are already over 200k).</p>

<p>There are still plenty of unknowns related to COVID19. Only time will well, but we can see most people “checking out” so to speak. It’s important to keep up to date regarding COVID19 (and politics) in general. A disaster is …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://austingwalters.com/u-s-covid19-less-tests-more-deaths-no-end-in-sight/">https://austingwalters.com/u-s-covid19-less-tests-more-deaths-no-end-in-sight/</a></em></p>]]>
            </description>
            <link>https://austingwalters.com/u-s-covid19-less-tests-more-deaths-no-end-in-sight/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24166077</guid>
            <pubDate>Sat, 15 Aug 2020 04:57:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brain Oriented Programming]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 35 (<a href="https://news.ycombinator.com/item?id=24165893">thread link</a>) | @pbw
<br/>
August 14, 2020 | https://tobeva.com/articles/brain-oriented-programming/ | <a href="https://web.archive.org/web/*/https://tobeva.com/articles/brain-oriented-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        
        
        <main role="main">
          
<div>
	
	<p>Write code that’s compatible with how your brain works.</p>
	
	<p><strong>Video</strong>: <a href="https://youtu.be/D8Pb8TvYsCE">Philip reading this essay</a>.</p>
<p>The 1956 paper <em><a href="http://psychclassics.yorku.ca/Miller/">The Magical Number Seven, Plus or Minus
Two</a></em> is the most widely cited paper
in the 126 year history of the journal <em><a href="https://en.wikipedia.org/wiki/Psychological_Review">Psychological
Review</a></em>. The author
<a href="https://en.wikipedia.org/wiki/George_Armitage_Miller">George A. Miller</a> is
considered one of the founders in the field of cognitive science. His
historic claim is that you can only juggle <strong>between 5 and 9 things</strong> in
your brain at any one time.</p>
<p>To my knowledge, despite some
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4486516/">controversy</a> over
the years, this 7 ± 2 figure has withstood the ongoing
<a href="https://www.nature.com/news/1-500-scientists-lift-the-lid-on-reproducibility-1.19970">reproducibility
crisis</a>
and it appears to capture a deep truth about how our brains actually
function.</p>
<p>Many people are skeptical of the claim because seven sounds like an
absurdly small number, surely if you are doing something complex like
writing software, or planning a wedding for that matter, you are juggling
dozens to hundreds of things? As it turns out you are not. At least not at
once.</p>







<div>
	<p><img src="https://tobeva.com/articles/brain-oriented-programming/pi_hu91e4edcab74d735c218b5a61e20b8fdd_76318_250x0_resize_q75_catmullrom.jpg" width="250" height="188"></p><p>
The first 225 digits of <a href="https://dancohen.org/2010/03/08/the-last-digit-of-pi/">Pi</a>.
</p>
	
</div>
<p>In 2005 <strong>Lu Chao</strong> recited <a href="https://www.livescience.com/50134-pi-day-memory-experts.html">67,890
digits</a> of
Pi, a mind-boggling demonstration of a gifted and well-trained mind. Yet
given a series of random single-digit numbers he can on average recall less
the than nine of them, to be exact he’s been measured to have a <a href="https://en.wikipedia.org/wiki/Memory_span#Digit-span">digit
span</a> of 8.83 which
fits perfectly within Miller’s finding. Amazing!</p>
<p>Chao memorizes Pi the same way story tellers once memorized long tales
about <a href="https://en.wikipedia.org/wiki/Gilgamesh">Gilgamesh</a>, yet he can only
juggle a handful of things at one time. I find this actually to be very
comforting, he is not a freak of nature, at least not as freaky as you
first thought.</p>
<p>The illusion we can hold many things in mind is almost identical to the
illusion that our field of view is high resolution everywhere. It’s
incredibly compelling because the instant we wonder <em>what’s over there</em> we
do a quick <a href="https://en.wikipedia.org/wiki/Saccade">saccade</a> and are
immediately rewarded with a high resolution view of exactly <em>what’s over
there</em>. We ask the question and we get an instant answer, so it feels like
the answer was there the whole time.</p>







<div>
	<p><img src="https://tobeva.com/articles/brain-oriented-programming/fovea_hu32924f3118f640732af8b68aadca9340_30500_512x0_resize_q75_catmullrom.jpg" width="512" height="227"></p><p> This picture exaggerates how big the
fovea is, it's actually only about as big as quarter held at arm's length.
</p>
	
</div>
<p>Thinking in general works very much like vision. This is not surprising
since it’s implemented using the same brain hardware. As we rapidly flit
from idea to idea, from concept to concept, we page in the necessary
details, but at no time do we have more than about nine individual things
in the front of our minds.</p>
<p>How do we navigate a complex world with this seemingly crippling limit on
the size of our working memory? Two of the primary tools that we use are
<a href="https://en.wikipedia.org/wiki/Chunking_(psychology)">chunking</a> and
<a href="https://en.wikipedia.org/wiki/Hierarchy">hierarchy</a>.</p>
<p>When we think of a car we naturally divide the car into a handful of high
level chunks like the <em>engine</em>, the <em>dashboard</em>, the <em>seats</em>, the <em>wheels</em>.
When we mentally zoom into the engine, however, it effortlessly resolves
into more parts: the <em>engine block</em>, the <em>pistons</em>, the <em>spark plugs</em>. And
we can keep zooming in, although how far we can zoom in highly depends on
how much we know about cars and the world in general.</p>
<p>In <a href="https://en.wikipedia.org/wiki/Object-oriented_programming">Object Oriented
Programming</a> one
of the simplest ways to tame complexity is to limit your objects to around
seven <em>attributes</em>. In some languages attributes are called <em>member
variables</em> or <em>fields</em>. Many programmers immediately balk at this
suggestion. Sure, that works for toy examples, but I’m writing serious
software and my objects sometimes need 10, 20 or 50 attributes. You must be
working on easy stuff, they will say. My problems are special, so my code
has to be different.</p>
<p>The biggest trap of software development is that it’s easy, trivial in
fact, to write software that you yourself cannot understand, and in turn no
one else can understand. Even a novice, <em>especially</em> a novice, can in a few
weeks write software that literally no one on the planet can easily think
or reason about. That’s depressing, but also kind of impressive in a way.
With great power comes great responsibility.</p>
<p>Objects which have too many attributes are a major cause of software that’s
too complicated to understand. Some people conclude the problem is Object
Oriented Programming itself. This is not a crazy idea, there are <a href="https://tobeva.com/resources/technical/programming/functional/">other
ways</a> to program, and they do
have advantages, but in my experience most of the flaws attributed to
Object Oriented Programming stem from having done it poorly, and boy is it
easy to do poorly.</p>







<div>
	<p><img src="https://tobeva.com/articles/brain-oriented-programming/complex_hua73d922edef0eeb6c3d75f190e4c0729_39455_350x0_resize_q75_catmullrom.jpg" width="350" height="197"></p><p>
Complexity grows without bound.
</p>
	
</div>
<p>The key thing to realize is a single object with a lot of attributes is
itself <em>not</em> Object Oriented. Instead, it’s a 1970s style <a href="https://en.wikipedia.org/wiki/Structured_programming">Structured
Program</a> in disguise.
The attributes of the object are the <strong>global variables</strong> of the program,
and the object’s methods are the program’s <strong>functions</strong>. Every function
can freely access every global variable which is what causes many of the
problems.</p>
<p>A structured program with more than seven global variables is trouble, and
if many objects in your program are effectively messy structured programs
themselves, you are in serious trouble indeed. At a high level you are
doing Object Oriented Programming, but at a low level you are right back in
the 1970s struggling to deal with one confusing program after the next.</p>
<p>How do we save this sinking ship? We save it by actively and aggressively
keeping the number of attributes per object <strong>at or below seven</strong>. If you
fail to do this you are punting the problem <em>to your future self</em>, a
problem that by definition your future self is going to have a hard time
solving.</p>
<p>Just today I had a <a href="https://www.python.org/">Python</a> class called
<code>PerfEvent</code> with these attributes:</p>
<div><pre><code data-lang="python">        <span>self</span><span>.</span><span>name</span> <span>=</span> <span>name</span>
        <span>self</span><span>.</span><span>start_ns</span> <span>=</span> <span>start_ns</span>
        <span>self</span><span>.</span><span>end_ns</span> <span>=</span> <span>end_ns</span>
        <span>self</span><span>.</span><span>category</span> <span>=</span> <span>category</span>
        <span>self</span><span>.</span><span>process_id</span> <span>=</span> <span>process_id</span>
        <span>self</span><span>.</span><span>thread_id</span> <span>=</span> <span>thread_id</span>
        <span>self</span><span>.</span><span>args</span> <span>=</span> <span>kwargs</span>
        <span>self</span><span>.</span><span>phase</span> <span>=</span> <span>phase</span></code></pre></div>
<p>That’s eight attributes, since eight is only one over the limit, should we
wait until the object grows bigger? No, let’s deal with it <em>now</em>. To reduce
the number of attributes we introduce two new classes or structs: <code>Span</code>
and <code>Origin</code>. Each only has two attributes, but now the original object has
been slimmed down to six attributes, all is well again:</p>
<div><pre><code data-lang="python">        <span>self</span><span>.</span><span>name</span> <span>=</span> <span>name</span>
        <span>self</span><span>.</span><span>span</span> <span>=</span> <span>Span</span><span>(</span><span>start_ns</span><span>,</span> <span>end_ns</span><span>)</span>
        <span>self</span><span>.</span><span>category</span> <span>=</span> <span>category</span>
        <span>self</span><span>.</span><span>origin</span> <span>=</span> <span>Origin</span><span>(</span><span>process_id</span><span>,</span> <span>thread_id</span><span>)</span>
        <span>self</span><span>.</span><span>args</span> <span>=</span> <span>kwargs</span>
        <span>self</span><span>.</span><span>phase</span> <span>=</span> <span>phase</span></code></pre></div>
<p>Although it’s a minor change, compare the two versions, the improved one
simply <em>looks</em> better, even if you stand far back and squint.</p>
<p>It seems minor, but if you don’t make these types of changes as you go it
will eventually lead to <em>intractable</em> complexity, the type of complexity
that causes projects and companies to fail, the type of complexity that
seduces humans into wasting <a href="https://spectrum.ieee.org/computing/software/why-software-fails">billions of
dollars</a>
every year writing software that does not work.</p>
<p>The benefits of introducing sub-objects goes far beyond just reducing the
number of attributes. While accessing the attributes is slightly more
verbose, I like the sound of <code>self.span.start_ns</code> compared to just
<code>self.start_ns</code>, but more importantly we can now pass <code>Span</code>'s and
<code>Owner</code>'s to functions, slimming down and chunking <em>their</em> argument lists.</p>
<p>We’ve introduced two natural and useful concepts that will pay ongoing
dividends, but even better don’t just think of how your code is today,
think about how it’s going to grow over time. Your single monolithic object
has sprouted two buds. You can now push functionality down into these buds,
and they can grow into branches, which later can sprout buds of their own.</p>
<p>For example we can now give <code>Span</code> a <code>get_duration_ns()</code> method. Again it seems
minor, but writing <code>span.get_duration_ns()</code> is better than writing
<code>span.end_ns - span.start_ns</code> especially if you are going to do that in
many different places.</p>
<p>The real magic though is that the benefits of being disciplined will accrue
like <a href="https://youtu.be/GtaoP0skPWc">compound interest</a> as you convert your
monolithic object into an intricately structured tree which buds and
sprouts and branches organically. You will benefit from this better design
every minute you are working on the software, and the software will benefit
greatly from your improved mood and ability to sustain focus.</p>







<div>
	<p><img src="https://tobeva.com/articles/brain-oriented-programming/featured-tree_hu59909ef0ac042e2e36ece8869e025722_141987_512x0_resize_q75_catmullrom.jpg" width="512" height="256"></p><p> 
A carefully tended <a href="https://en.wikipedia.org/wiki/Bonsai">Bonsai</a> tree.
</p>
	
</div>
<p>Code, like most human created artifacts, can be beautiful, so there is an
aesthetic pay off here, but the real jackpot is that if you assiduously
tend and groom this tree you will create a software design that slides into
your head with minimal fuss and friction, and slides similarly into the
heads of other people.</p>
<p>It’s no accident that we find natural environments to be more soothing than
the made world, than the concrete jungle. The design of the natural world
tends to be more in harmony with how our brains think about that world.
Game recognizes game.</p>
<p>Over time, you will grow a system that you and others can <strong>understand</strong>,
<strong>maintain</strong>, <strong>debug</strong> and <strong>extend</strong>. When people look at your code years
from now, maybe even in the <a href="https://archiveprogram.github.com/">far
future</a>, they will benefit from your
diligence and hard work. And the punchline is doing all this is not hard.
In fact, it’s <em>much easier</em> to do this work than not to not do it.</p>
<p>It’s easier and more pleasant to work with something that’s well crafted
and simpatico with your thinking. It’s hard and unpleasant to constantly
wrestle with something you don’t understand. Trim, prune and shape your
objects early and often. Your brain will thank you.</p>
<hr>
<p><strong>See Also:</strong></p>
<ul>
<li>Hacker News <a href="https://news.ycombinator.com/item?id=24165893">comments</a> on this article.</li>
<li>Find your own digit span with this <a href="https://www.memorylosstest.com/digit-span/">Digit Span Memory Test</a>.</li>
<li>Some Chimpanzees have <a href="https://youtu.be/nTgeLEWr614?t=7">better working memory</a> than humans!</li>
</ul>
<p><strong>Postscript on APIs:</strong></p>
<p><em>The article discusses objects and attributes, not methods and APIs. NumPy’s</em>
<em><a href="https://numpy.org/doc/stable/reference/arrays.ndarray.html">ndarray</a> has</em>
<em>15 attributes but 50 methods. That’s totally fine, but imagine the</em>
<em>opposite, if it had 50 attributes? That would probably be a mess.</em></p>
<p><em>Attributes are global variables in the structured program that is the</em>
<em>object, so each additional attribute potentially complicates the</em>
<em>implementation of every other method in the object, present and future.</em></p>
<p><em>In contrast, adding a new …</em></p></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tobeva.com/articles/brain-oriented-programming/">https://tobeva.com/articles/brain-oriented-programming/</a></em></p>]]>
            </description>
            <link>https://tobeva.com/articles/brain-oriented-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24165893</guid>
            <pubDate>Sat, 15 Aug 2020 04:18:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Statistics and Probability]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24165286">thread link</a>) | @vectorcrumb
<br/>
August 14, 2020 | https://rinterested.github.io/statistics/ | <a href="https://web.archive.org/web/*/https://rinterested.github.io/statistics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="notes-on-statistics-and-probability">
<h2><strong>NOTES ON STATISTICS AND PROBABILITY:</strong></h2>



<gcse:search></gcse:search>



<div id="inference">
<h3>INFERENCE:</h3>
<p><a href="http://rinterested.github.io/statistics/one_sample_mean_test.html">One-Sample Mean compared to Population &amp; Confidence Intervals</a></p>
<p><a href="http://rinterested.github.io/statistics/independent_sample_means_test.html">Independent Samples Means Test</a></p>
<p><a href="http://rinterested.github.io/statistics/paired_differences.html">Paired t Test</a></p>
<p><a href="http://rinterested.github.io/statistics/power.html">Statistical Power</a></p>
<p><a href="http://rinterested.github.io/statistics/sample_size.html">Sample Size</a></p>
<p><a href="http://rinterested.github.io/statistics/mle.html">Maximum Likelihood estimation</a></p>
<p><a href="http://rinterested.github.io/statistics/method_of_moments.html">Method of moments</a></p>
</div>
<div id="distributions">
<h3>DISTRIBUTIONS:</h3>
<p><a href="http://rinterested.github.io/statistics/distributions_stories.html">Ditributions and their stories</a></p>
<p><a href="http://rinterested.github.io/statistics/t_distribution.html">Gosset’s t Distribution</a></p>
<p><a href="http://rinterested.github.io/statistics/chi_square.html">Chi Square Distribution</a></p>
<p><a href="http://rinterested.github.io/statistics/CLT.html">CTL</a></p>
<p><a href="http://rinterested.github.io/statistics/inverse_transform.html">Uniform Distribution and the Probability Integral Transform</a></p>
<p><a href="http://rinterested.github.io/statistics/moments.html">Moments</a></p>
<p><a href="http://rinterested.github.io/statistics/moment_generating_functions.html">Moment Generating Functions (MGF)</a></p>
<p><a href="http://rinterested.github.io/statistics/probability_generating_functions.html">Probability Generating Functions (PGF)</a></p>
<p><a href="http://rinterested.github.io/statistics/characteristic_function.html">Characteristic Functions (CF)</a></p>
<p><a href="http://rinterested.github.io/statistics/multivariate_gaussian.html">Multivariate Gaussian Distribution</a></p>
<p><a href="http://rinterested.github.io/statistics/multivariate_normal_draws.html">Multivariate Gaussian Distribution: Random Sampling and the Cholesky</a></p>
<p><a href="http://rinterested.github.io/statistics/dirichlet.html">Dirichlet distribution</a></p>
<p><a href="http://rinterested.github.io/statistics/power_law.html">Power law and heavy tailed distributions</a></p>
<p><a href="http://rinterested.github.io/statistics/copulas.html">Copulas</a></p>
</div>
<div id="proportions">
<h3>PROPORTIONS:</h3>
<p><a href="http://rinterested.github.io/statistics/proportion_standard_error.html">Proportion Standard Error</a></p>
<p><a href="http://rinterested.github.io/statistics/confidence_interval_and_margin_of_error.html">Confidence Interval and Margin of Error</a></p>
<p><a href="http://rinterested.github.io/statistics/sample_proportion_to_population.html">Comparing Sample Proportion to Population: Z test of proportions and Binomial test</a></p>
<p><a href="http://rinterested.github.io/statistics/multinomial_exact.html">Comparing Sample Proportions to Population: Exact Multinomial (Goodness of Fit)</a></p>
<p><a href="http://rinterested.github.io/statistics/tests_of_proportions.html">Comparing Sample Proportions: Fisher Exact; Chi square; G-test; Z-test</a></p>
<p><a href="http://rinterested.github.io/statistics/chi_square_GOF.html">Chi Square: Goodness of Fit</a></p>
<p><a href="http://rinterested.github.io/statistics/chi_square_test_independence_homogeneity.html">Chi Square: Test of Independence and Homogeneity</a></p>
<p><a href="http://rinterested.github.io/statistics/standard_deviation_chi_square.html">Chi Square: Testing Standard Deviation (Variance)</a></p>
<p><a href="http://rinterested.github.io/statistics/monte_carlo_option_chi_square.html">Chi Square Test in R: Monte Carlo Option</a></p>
<p><a href="http://rinterested.github.io/statistics/grading_on_a_curve.html">Grading on the curve: detectable with GoF test</a></p>
<p><a href="http://rinterested.github.io/statistics/monte_carlo_to_validate_test_proportions.html">Monte Carlo Validation of the Z Test of Proportions</a></p>
<p><a href="http://rinterested.github.io/statistics/contingency_tables.html">Contingency Tables</a></p>
<p><a href="http://rinterested.github.io/statistics/three_way_contingency_tables.html">Three Way Contingency Tables</a></p>
<p><a href="http://rinterested.github.io/statistics/monte_carlo_chi_square.html">Monte Carlo alternative to Chi Square</a></p>
<p><a href="http://rinterested.github.io/statistics/chi_square_same_as_z_test.html">Chi Square of Proportions is the Same as a z-test</a></p>
<p><a href="http://rinterested.github.io/statistics/relative_risk_and_odds_ratio.html">RR and OR</a></p>
</div>

<div id="anova">
<h3>ANOVA:</h3>
<p><a href="http://rinterested.github.io/statistics/anova_interpretation.html">ANOVA Results Interpretation</a></p>
<p><a href="http://rinterested.github.io/statistics/ANOVA_is_regression.html">ANOVA Is Just a form of Regression</a></p>
<p><a href="http://rinterested.github.io/statistics/ANOVA.html">ANOVA Regression Equivalents</a></p>
<p><a href="http://rinterested.github.io/statistics/ANOVA_summary_statistics.html">ANOVA with Summary Statistics</a></p>
<p><a href="http://rinterested.github.io/statistics/contrasts.html">ANOVA Contrasts</a></p>
<p><a href="http://rinterested.github.io/statistics/stats_me_me_cry.html">ANOVA Alphabet Soup</a></p>
</div>

<div id="regression">
<h3>REGRESSION:</h3>
<p><a href="http://rinterested.github.io/statistics/OLS.html">OLS</a></p>
<p><a href="http://rinterested.github.io/statistics/p_values_regression_model_anova.html">Global and individual predictors p-values of explained variance in a linear model</a></p>
<p><a href="http://rinterested.github.io/statistics/model_selection.html">Model Selection</a></p>
<p><a href="http://rinterested.github.io/statistics/OLS_no_linear_algebra.html">OLS without Linear Algebra</a></p>
<p><a href="http://rinterested.github.io/statistics/OLS_linear_algebra.html">Linear Algebra of OLS</a></p>
<p><a href="http://rinterested.github.io/statistics/a_transpose_a.html">Variance-Covariance Matrix and A transpose A</a></p>
<p><a href="http://rinterested.github.io/statistics/cost_function.html">Optimization: Cost Function </a></p>
<p><a href="http://rinterested.github.io/statistics/rsquare.html">R Squared, SST, SSR, SSE </a></p>
<p><a href="http://rinterested.github.io/statistics/standard_errors_betas.html">Calculating Sts. Error, t value and Pr(&gt;|t|) of coefficients</a></p>
<p><a href="http://rinterested.github.io/statistics/anova_of_OLS_models.html">Manual calculation ANOVA OLS lm Models </a></p>
<p><a href="http://rinterested.github.io/statistics/confidence_intervals_and_p_value_in_OLS.html">Confidence Intervals &amp; p-values of OLS</a></p>
<p><a href="http://rinterested.github.io/statistics/df_betas.html">OLS Diagnostics</a></p>
<p><a href="http://rinterested.github.io/statistics/vif.html">OLS Diagnostics: VIF</a></p>
<p><a href="http://rinterested.github.io/statistics/dummy_coding.html">Dummy Coding in Regression</a></p>
<p><a href="http://rinterested.github.io/statistics/lm_interactions_output_interpretation.html">Interpretation of Output in Linear Model with Interactions</a></p>
<p><a href="http://rinterested.github.io/statistics/logistic_regression.html">Logistic Regression</a></p>
<p><a href="http://rinterested.github.io/statistics/survival_analysis.html">Survival Analysis</a></p>
<p><a href="http://rinterested.github.io/statistics/random_effects_simulation.html">Random Effects Simulation</a></p>
<p><a href="http://rinterested.github.io/statistics/mixed_effects_comparison.html">Comparing Models with Mixed Effects</a></p>
<p><a href="http://rinterested.github.io/statistics/predict_mixed_models.html">Predict Function in Mixed Effects</a></p>
<p><a href="http://rinterested.github.io/statistics/model_matrices_mixed_models.html">Model Matrices in Mixed Effects</a></p>
<p><a href="http://rinterested.github.io/statistics/omitted_variable_bias.html">Omitted Variable Bias (OLS)</a></p>
<p><a href="http://rinterested.github.io/statistics/endogenous_confounder.html">Confounders, Control Variables, Endogeneity</a></p>
<p><a href="http://rinterested.github.io/statistics/variance_estimated_parameters.html">Variance of Estimated Parameters</a></p>
<p><a href="http://rinterested.github.io/statistics/Ridge-and-Lasso.html">Ridge and Lasso regression</a></p>
</div>

<div id="non parametric">
<h3>NON-PARAMETRIC:</h3>
<p><a href="http://rinterested.github.io/statistics/parametric_non_parametric.html">On the meaning of Parametric v Nonparametric</a></p>
<p><a href="http://rinterested.github.io/statistics/wilkoxon_rank_sum.html">Wikoxon Rank-Sum Test or Mann-Whitney U</a></p>
<p><a href="http://rinterested.github.io/statistics/wilkoxon_signed_rank_test.html">Wikoxon Signed Rank Test</a></p>
</div>

<div id="other">
<h3>MACHINE LEARNING:</h3>
<p><a href="http://rinterested.github.io/statistics/perceptron.html">Perceptron</a></p>
<p><a href="http://rinterested.github.io/statistics/gradient_descent.html">Neural Nets</a></p>
<p><a href="http://rinterested.github.io/statistics/backpropagation.html">Backpropagation</a></p>
<p><a href="http://rinterested.github.io/statistics/neural_net_non_linear_classification.html">Neural Nets and Transistor Gates</a></p>
<p><a href="http://rinterested.github.io/statistics/lagrange.html">Lagrange review</a></p>
<p><a href="http://rinterested.github.io/statistics/svm.html">Support Vector Machines (SVM)</a></p>
<p><a href="http://rinterested.github.io/statistics/softmax.html">Softmax</a></p>
<p><a href="http://rinterested.github.io/statistics/unconstrained_optimization.html">Unconstrained Optimization</a></p>
<p><a href="http://rinterested.github.io/statistics/lstm.html">Backpropagation in LSTM</a></p>
</div>

<div id="other">
<h3>TIME SERIES:</h3>
<p><a href="http://rinterested.github.io/statistics/random_walk.html">Random walk - Return to origin</a></p>
<p><a href="http://rinterested.github.io/statistics/time_series.html">Time Series</a></p>
<p><a href="http://rinterested.github.io/statistics/time_series_var_cov.html">Time Series: Variance, Covariance and Correlation</a></p>
<p><a href="http://rinterested.github.io/statistics/acf_pacf.html">How to calculate manually ACF and PACFs</a></p>
<p><a href="http://rinterested.github.io/statistics/arima.html">Reading ACF and PACF plots</a></p>
<p><a href="http://rinterested.github.io/statistics/climate_change.html">Time series: Climate Change</a></p>
<p><a href="http://rinterested.github.io/statistics/financial.html">Time series: Financial</a></p>
<p><a href="http://rinterested.github.io/statistics/vti.html">Time series: VTI</a></p>
</div>

<div id="other">
<h3>PROBABILITY TOPICS:</h3>
<p><a href="http://rinterested.github.io/statistics/independence_correlation_orthogonality.html">Independence, Correlation and Orthogonality</a></p>
<p><a href="http://rinterested.github.io/statistics/conditional_probability.html">Conditional Probability</a></p>
<p><a href="http://rinterested.github.io/statistics/generating_functions.html">Counting with Generating Functions</a></p>
</div>
  
 <div id="other">
<h3>BAYES:</h3>
<p><a href="http://rinterested.github.io/statistics/bayes.html">Bayesian Paradigm</a></p>
<p><a href="http://rinterested.github.io/statistics/bayes_coin.html">Using Bayes to Assess Fairness of a Coin</a></p>
</div>

 <div id="other">
<h3>OTHER:</h3>
<p><a href="http://rinterested.github.io/statistics/variance_alternate.html">Alternate formula variance (raw moments)</a></p>
<p><a href="http://rinterested.github.io/statistics/measure_theory.html">Measure Theory</a></p>
<p><a href="http://rinterested.github.io/statistics/PCA.html">PCA</a></p>
<p><a href="http://rinterested.github.io/statistics/PCA_derivation.html">PCA linear algebra derivation</a></p>
<p><a href="http://rinterested.github.io/statistics/roc.html">ROC Curves and AUC</a></p>
<p><a href="http://rinterested.github.io/statistics/convolution.html">Convolution or pdf of Z = X + Y</a></p>
<p><a href="http://rinterested.github.io/statistics/simpsons_paradox.html">Simpson's Paradox and Random Effects</a></p>
<p><a href="http://rinterested.github.io/statistics/normal_log_normal.html">Natural phenomena are not Gaussian</a></p>
<p><a href="http://rinterested.github.io/statistics/markov_chain.html">Markov or Stochastic Matrices</a></p>
<p><a href="http://rinterested.github.io/statistics/MCMC.html">A Practical Example of Markov Chain Monte Carlo (MCMC)</a></p>
<p><a href="http://rinterested.github.io/statistics/order_stats.html">Order statistics</a></p>
<p><a href="http://rinterested.github.io/statistics/fourier.html">Discrete Fourier transform (DFT)</a></p>
<p><a href="http://rinterested.github.io/statistics/fft.html">Fast Fourier transform (FFT)</a></p>
<p><a href="http://rinterested.github.io/statistics/newton_raphson_method.html">Newton Raphson Method</a></p>
<p><a href="http://rinterested.github.io/statistics/manifolds_and_distributions.html">Manifolds and distributions</a></p>
</div>

 <div id="other">
<h3>LINEAR ALGEBRA:</h3>
<p><a href="http://rinterested.github.io/statistics/gauss_jordan.html">Systems of linear equations and basis for the four spaces</a></p>
<p><a href="http://rinterested.github.io/statistics/matrix.html">It's all about the MATRIX</a></p>
<p><a href="http://rinterested.github.io/statistics/change_of_basis.html">Ax is a change of basis</a></p>
<p><a href="http://rinterested.github.io/statistics/covariance.html">A transpose A ; covariance matrix; projection matrix</a></p>
<p><a href="http://rinterested.github.io/statistics/matrix_decompositions.html">LU, LDL' and Cholesky</a></p>
<p><a href="http://rinterested.github.io/statistics/linear_algebra.html">Fun wih linear algebra</a></p>
<p><a href="http://rinterested.github.io/statistics/riemannian_geom.html">Riemannian geometry</a></p>
</div>

 <div id="other">
<h3>TENSORS:</h3>
<p><a href="http://rinterested.github.io/statistics/motivation_tensors.html">Motivation for tensors</a></p>
<p><a href="http://rinterested.github.io/statistics/tensors3.html">Tensors as multilinear maps</a></p>
<p><a href="http://rinterested.github.io/statistics/exterior_algebra.html">Exterior algebra</a></p>
<p><a href="http://rinterested.github.io/statistics/dx.html">dx as a covector (linear functional)</a></p>
<p><a href="http://rinterested.github.io/statistics/one_forms_as_gradients.html">covectors, 1-forms and gradient</a></p>
<p><a href="http://rinterested.github.io/statistics/tensor_examples.html">Examples of tensor products</a></p>
<p><a href="http://rinterested.github.io/statistics/tensors.html">Tensors in physics</a></p>
<p><a href="http://rinterested.github.io/statistics/covariant_change_basis_gradient.html">Covariant gradient field transformation</a></p>
<p><a href="http://rinterested.github.io/statistics/covariant_contravariant_metric_tensor.html">Covariant, Contravariant Forms and Metric Tensor</a></p>
<p><a href="http://rinterested.github.io/statistics/metric_tensor.html">Tensors in physics: The Metric Tensor</a></p>
<p><a href="http://rinterested.github.io/statistics/tensors2.html">Tensors in physics: Lorentz transformations</a></p>
<p><a href="http://rinterested.github.io/statistics/statistical_manifolds.html">Statistical manifolds</a></p>
</div>


</div></div>]]>
            </description>
            <link>https://rinterested.github.io/statistics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24165286</guid>
            <pubDate>Sat, 15 Aug 2020 02:05:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[To Dam or Not to Dam: Exploring the Failure Risk of the Three Gorges Dam]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24165152">thread link</a>) | @schmatz
<br/>
August 14, 2020 | http://thinking.farm/research/three-gorges-dam/ | <a href="https://web.archive.org/web/*/http://thinking.farm/research/three-gorges-dam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="body-container"><div id="content">
<section id="main-single">
    <article>

        <h2><a href="http://thinking.farm/research/three-gorges-dam/">To Dam or Not to Dam: Exploring the Failure Risk of the Three Gorges Dam </a></h2>
            
            <section id="single-content">
                <p><em>This research explores the risk that the Three Gorges dam will experience failure.
I believe the risk that the dam becomes structurally compromised, and requires the government to drain the reservoir to undertake repairs, is  <strong>20-25%</strong>. In the case that there is a seismic event, that likelihood would be closer to <strong>80%</strong>. I put the chance of a dam failure during this summer’s ongoing floods at <strong>5-10%</strong>, rising to <strong>30%</strong> in the case of a seismic event.</em></p>
<h2 id="introduction">Introduction</h2>
<p>Did Wuhan commit a great crime in 2019? How else to explain the cityâ€™s bad luck in 2020, beginning with the COVID-19 world pandemic and continuing with recent worries that the Three Gorges Dam (TGD), the worldâ€™s largest, might burst and flood the city? News reports about the dam have primarily been journalists repeating the opinions of various experts, with some quotes dating back to the 1990s. Predictably, this has encouraged the formation of two camps: those primed towards conspiratorial speculation that the Chinese Communist Party is lying about a looming catastrophe, and those that repeat state media lines that rumors about the dam are the work of Chinaâ€™s foreign enemies.</p>
<p>Nonetheless, I think that clear thinking about risk can help us assess the likelihood of disaster at the TGD. The dam is subject to three types of risks:</p>
<ol>
<li>structural integrity risk, which originates in the damâ€™s construction and maintenance</li>
<li>foundation risk, which reflects the geologic stability of the damâ€™s foundation</li>
<li>shock risk, which the likelihood that an external shock occurs, like an earthquake or landslide.</li>
</ol>
<p>Structural integrity risk is hard to assess, but we can obtain relatively clear information to assess foundation and shock risk, if we make use of valuable geologic data gathered by the Three Gorges Development Corporation in the 1990s. Moreover, the changing rhetoric of press releases from the Chinese government can reveal how the authorities themselves, who have live access to the state of the dam, are mitigating these risks. The governmentâ€™s behavior can then further calibrate our sense of how large and realized these risks actually are.</p>
<p>I have been unable to come by reliable information to assess the structural integrity of the dam. The major risk to the dam comes from foundation risk. As can be ascertained from geologic data, Sections 1-5 of the left powerhouse lie on top of a low-dipping joints with high connectivity, meaning that there is elevated sliding risk. The damâ€™s recent deformation on July 21 means previously calculated safety ratios are likely inflated. Moreover, changes in government rhetoric support this suspicion. In contrast to years past, the government claims that the dam was never mean to control floods and that each region should figure out their own solution.</p>
<p>In terms of shock risk, the dam is susceptible to seismic activity, instability arising from the sheer weight of the TGD reservoir, and flood waves large enough to overwhelm the damâ€™s sluice gates. As of writing (July 26), the 3rd flood wave has officially formed in the Yangtze, and a 4th might appear in short succession. Overall, I think there is a 20-25% chance that the dam is further structurally impaired, prompting the government to continue draining the reservoir as fast as possible. There is something like a 5-10% chance that multiple flood waves overwhelm the dam and raise the reservoir level. These would weaken the dam or its foundation and cause a sliding failure. Were an earthquake to happen this month, these risks would be something more like 80% and 30%.</p>
<h2 id="anatomy-of-a-dam">Anatomy of a dam</h2>
<p>There are several types of dam design: arch dams, buttress dams, embankment dams, and gravity dams.</p>
<p>Arch dams hold back the water partially through the strength of their structural shape. The Hoover Dam is an example of an arch dam. The arch is convex facing upstream, which distributes water pressure along the structure to the abutments at each end.</p>
<figure>
    <img src="http://thinking.farm/hoover-dam.jpg" width="100%"> <figcaption>
            <h4>The Hoover Dam, Arizona-Nevada border</h4>
        </figcaption>
</figure>

<p>Buttress dams consist of a face slab which angles away from the upstream, and is supported on the downstream side by buttress structures. These structures are attached to a base slab foundation. Buttress dams are built in areas with looser soil foundations.</p>
<figure>
    <img src="http://thinking.farm/daniel-johnson.jpg" width="100%"> <figcaption>
            <h4>The Daniel-Johnson Buttress Dam, Canada</h4>
        </figcaption>
</figure>

<p>Embankment dams are built up by the piling up of soil, rocks, or synthetic materials. These are usually porous on their outside but have an impervious core. Their main advantage is their low cost and flexibility, which allows them to adjust to shifts in the embankment or settlement of the foundation over time.</p>
<p>Gravity dams resist water flow through their sheer weight, which pulls them vertically down and allows them to resist the horizontal force of water pressure along their surface. This is similar to what a child does when he blocks a stream or rivulet by piling rocksâ€”they divert the water flow not through any structural design but through their weight. This is the origin of the name â€œgravity dam.â€�</p>
<p>A U.S. Department of the Interior report in 1998 explored various dam â€œeventsâ€�. These include four gravity dams in the United States and one in France<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. All five suffered damage due to sliding, and two of them failed entirely. The remaining three required additional drainage, reinforcements, and the release of reservoir waters to keep water depths low. For example, the Morris Shepherd Dam suffered sliding because the initial loading of the reservoir changed the stability of the bedrock foundation such that the safety ratio fell below 1.0. In other words, the load that the dam could support before failing had fallen below the regular load the dam was supposed to hold.</p>
<h2 id="foundation-risk-is-sliding-risk">Foundation risk is sliding risk</h2>
<p>The most important factor in sliding events is the nature of the bedrock on which a gravity dam is built. In failures of this type, the part of the foundation on which the dam rests slides downstream. We have reliable data to study this phenomenon, though media and news commentators have not put in the work.</p>
<p>In 2003 scientists from the Chinese Academy of Sciences and the Yangtze River Scientific Research Institute received data and support from the Three Gorges Development Corporation, the Changjiang Water Resources Commission, and the Chinese Academy of Sciences to conduct a stability assessment of the damâ€™s foundation using physical and numerical modeling.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<p>The study incorporated a variety of techniques for the stability assessment, including conventional methods of geological mapping such as borehole drilling and shaft exploration, geophysical prospecting such as acoustic emission, remote sensing, seismic reflection and refraction, electromagnetic techniques, and physical-chemical analysis and micro-structural analysis. Most of these data are recorded in expensive studies commissioned in 1998 and 1999, when the dam was being built.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p>
<p>They conclude that the â€œmajor factor influencing the foundation stability would come from the pre-existing discontinuities. However, among these discontinuities the faults mostly have steep dip angles, thin thickness, and well-cemented tectonite, so they would not play important roles in the foundation stability.â€�</p>
<h2 id="foundation-faults-and-joints">Foundation, faults, and joints</h2>
<p>The foundation is plagioclase granite which is homogenous and of high strength, and with various degrees of weathering, though the dam itself is on the moderately and lightly weathered parts.</p>
<p>The are 886 faults in the granite, most of which have steep angles (i.e. they go down more than sideways). 90% of these are shorter than 300 meters and narrower than 1 meter. Most of the faults are filled in with tectonite, a metamorphic type of rock.</p>
<p>The granite also has a very large number of joints. Joints are fractures where the two sides, unlike in a fault, lack visible or detectable movement relative to each other. 13% of joints have dip angles less than 30 degrees, 10% are between 30-60, and 77% are greater than 60 degrees.</p>
<p>The low-dipping joints have been studied more than the others because they dip downstream at an angle low enough to create sliding surfaces in the damâ€™s foundation. This was determined to be the greatest risk to foundation stability.</p>
<p>As we can see in the illustration below, the area of greatest risk is labeled â€œrelative developed regions of gently dipping joints,â€� which is where these low dipping joints are present in both long and short form, and in high densities. This area crosses the dam around the left powerhouse, which also overlaps with one of the large faults.</p>
<figure>
    <img src="http://thinking.farm/rock-joint-distribution.png" width="100%"> <figcaption>
            <h4>Rock joint distribution along the foundation of Three Gorges Dam (Liu et al)</h4>
        </figcaption>
</figure>

<p>Another risk factor is connectivity: the percentage of joints that could form a potential sliding path. The higher the connectivity, the higher the probability that a disturbance will link the joints into a fracture that produces a sliding event.</p>
<figure>
    <img src="http://thinking.farm/layout-of-tgd.png" width="100%"> <figcaption>
            <h4>Layout of the TGD and the numbered left powerhouse-dam sections (Liu et al)</h4>
        </figcaption>
</figure>

<p>Sections 1-5 of the left powerhouse dam are the weakest links. As can be seen below, the density of low-dipping joints is highest under Section No. 3 of the left powerhouse dam. Even more unfortunately, Section No. 3 also has the highest joint connectivityâ€”80% of the joints are in a potential sliding path!</p>
<figure>
    <img src="http://thinking.farm/avg-linear-density.png" width="100%"> <figcaption>
            <h4>Avg. linear density of low-dipping joints, and connectivity, for Sections No. 1-5 (Liu et al)</h4>
        </figcaption>
</figure>

<p>We can appreciate the high connectivity of the joints under Section No. 3 through the geological sketches from Liu et al.</p>
<figure>
    <img src="http://thinking.farm/geological-sketch.png" width="100%"> <figcaption>
            <h4>Geological sketch of the foundation of Section No. 3, with joints and their angles (Liu et al.)</h4>
        </figcaption>
</figure>

<h2 id="what-is-the-dams-official-safety-ratio">What is the dam’s official safety ratio?</h2>
<p>The Chinese Design Criterion of Concrete Gravity Dams sets the safety factor against sliding at 3.0. This …</p></section></article></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://thinking.farm/research/three-gorges-dam/">http://thinking.farm/research/three-gorges-dam/</a></em></p>]]>
            </description>
            <link>http://thinking.farm/research/three-gorges-dam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24165152</guid>
            <pubDate>Sat, 15 Aug 2020 01:26:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview with Aubrey de Grey]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24164822">thread link</a>) | @hackernewsreadr
<br/>
August 14, 2020 | https://podofjake.com/2020/08/10/1-aubrey-de-grey/ | <a href="https://web.archive.org/web/*/https://podofjake.com/2020/08/10/1-aubrey-de-grey/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-60">
			<!-- .entry-header -->		<!-- .entry-meta -->
	
	<div>
		
<p>Aubrey is the Chief Science Officer and Co-founder of the <em>SENS Research Foundation</em> and author of the book <em>Ending Aging</em>.&nbsp;He is working on undoing the damage of aging in order to help humans live much longer and healthier lives than most have ever imagined could be possible.</p>



<p><span>Listen on:</span></p>



<p><em>Apple</em> – <a href="https://podcasts.apple.com/us/podcast/1-aubrey-de-grey/id1525087226?i=1000486095003" rel="nofollow">https://podcasts.apple.com/us/podcast/1-aubrey-de-grey/id1525087226?i=1000486095003</a></p>



<p><em>Spotify</em> – <a href="https://open.spotify.com/episode/5jHo9s5ursqbC4IaUk6OIz?si=NdmPRslCTtG8TDlu7hh1gg" rel="nofollow">https://open.spotify.com/episode/5jHo9s5ursqbC4IaUk6OIz?si=NdmPRslCTtG8TDlu7hh1gg</a></p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	<div>
				<p><strong>Published</strong>
			<time datetime="2020-08-10T16:44:19-04:00">August 10, 2020</time><time datetime="2020-08-10T17:04:43-04:00">August 10, 2020</time>		</p><!-- .site-posted-on -->
	</div>
</article></div>]]>
            </description>
            <link>https://podofjake.com/2020/08/10/1-aubrey-de-grey/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24164822</guid>
            <pubDate>Sat, 15 Aug 2020 00:26:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Starlink Daily Coverage Estimates]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24164250">thread link</a>) | @trothamel
<br/>
August 14, 2020 | https://sebsebmc.github.io/starlink-coverage/index.html | <a href="https://web.archive.org/web/*/https://sebsebmc.github.io/starlink-coverage/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <p>
        I am now providing two different data sets: one that is calculated witha 25 degree minimum user terminal angle
        and one with a 35 degree minimum user terminal angle. The more recent SpaceX filings show that they are capable
        of using the 25 degree minimum but that they eventually want to increase that. The previous datasets were
        calculated with a 35 degree minimum as that was what I had found on file at the time. With the lower minimum
        angle and about 100 more satellites at operational altitudes the 25 degree dataset now shows bands with
        continuous coverage.
    </p>
    <p>
        Furthermore, I plan to calculate what I call the <em>satellite multiplicity</em>, the number of satellites
        overhead at any given time on average, since the number of overlapping satellites is relevant to some
        calculations for routing and bandwith.
    </p>
    <p>
        New Features: You can now double-click a cell to toggle showing more granular data.
        Cells with 100% uptime now display a gold star. Faster parsing, reduced battery drain,
        hopefully.
    </p>
    <p><label for="minAngleSelect">Choose a minimum angle to load the dataset:</label>
        
    </p>
    
    
    <div>
        <p>This renders the percentage of the day that a portion of the earth is covered by a Starlink satellite. (Red
            is no
            coverage, blue is all day coverage).</p>
        <p>Click on a cell to see how many minutes in a day a cell is covered by at least one satellite. Note that
            currently
            for performance reasons the cells are much larger than the resolution the data was simulated at. As such the
            error within a cell can be quite large, especially near the poles where the coverage drops off rapidly.
        </p>
        <p>In my opinion anything less than 1440 minutes (aka continuous coverage) means that SpaceX <em>should not</em>
            provide service in that area.</p><p>
        For more info about how it's calculated:
        <a href="https://github.com/sebsebmc/starlink-coverage">https://github.com/sebsebmc/starlink-coverage</a></p><h2> Changelog:</h2>
        <ul>
            <li>6-20-20 - Removed satellites that had low altitudes because they are not believed to be in operational
                orbits.</li>
            <li>6-21-20 - Fixed remaining issues with calculations at the antimerdian.</li>
            <li>7-31-20 - <ul>
                    <li>Added a double-click option to view higher resolution data. Double-click again to revert.</li>
                    <li>Added a 25 minimum degree dataset</li>
                    <li>Use gold star to mark cells with 100% uptime</li>
                    <li>Switched to new format and explicit rendering</li>
                </ul>
            </li>
        </ul>
        <p>
            Star image: Yakiv Gluck / CC BY-SA (https://creativecommons.org/licenses/by-sa/3.0)
        </p>
    </div>


</div>]]>
            </description>
            <link>https://sebsebmc.github.io/starlink-coverage/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24164250</guid>
            <pubDate>Fri, 14 Aug 2020 22:58:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hosting a personal website free of charge and JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24163960">thread link</a>) | @corytheboyd
<br/>
August 14, 2020 | https://corytheboyd.com/posts/inside-my-personal-website/ | <a href="https://web.archive.org/web/*/https://corytheboyd.com/posts/inside-my-personal-website/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
    

<p>
  <span>
H</span>
  ello and welcome to my website! Given all of this extra time I have had at home recently, I figured it was finally time to stand up a website to publish some blog posts I have been meaning to write. As any self respecting software engineer would do in this case, my plan was to build it all myself.


</p>

<p>Having not considered the ecosystem of static content generation sites for quite some time, I hit the books to figure what my options are.</p>
<h2 id="wait-its-all-javascript">Wait, it’s all JavaScript?!</h2>
<p>The very first first thing I noticed was that almost every solution required JavaScript, either at build time or on the client. JavaScript has no business being involved in static text based context, HTML and CSS already do an amazing job.</p>
<p>At the end of the day, there was only a single viable solution that passed the test of being relevant and not using JavaScript, <a href="https://gohugo.io/">Hugo</a>.</p>
<h2 id="styling">Styling</h2>
<p>Hugo at its core is really nothing more than a very feature rich HTML template renderer, which is exactly the right tool for the job of generating markup, but what about styling?</p>
<p>I chose to just use <a href="https://sass-lang.com/">SASS</a>. Using nothing but SASS is amazing for a project this small. I wrote all of the styling myself, which for text based content, really isn’t that bad.</p>
<p>Hugo offers a library of themes, but I personally find the usage of themes to be a bit tacky. I wanted something that is uniquely mine, and more importantly, doesn’t add a bunch of shit I will never use.</p>
<h2 id="hosting--deployment">Hosting &amp; deployment</h2>
<p>Hosting static content in 2020 is so easy it should be <em>illegal</em>. I use <a href="https://pages.github.com/">GitHub Pages</a> as the host, which really is as simple as turning it on in the repository settings.</p>
<p>Similarly, deployment is disgustingly easy with <a href="https://github.com/features/actions">GitHub Actions</a>. My configuration file is triggered by every push to master, which then:</p>
<ol>
<li>Downloads the <code>hugo</code> binary</li>
<li>Builds the site from source with <code>hugo</code></li>
<li>Pushes the build to the <code>gh-pages</code> branch</li>
</ol>
<p>And that’s it, every push of my website source code immediately triggers a build and deployment, all for free.</p>
<p>Here is my configuration for reference:</p>


<h2 id="thats-it-we-have-a-website">That’s it, we have a website</h2>
<p>It really is this simple to build your own custom corner of the internet and serve it for free. I left out some details, specifically my configuration in Cloudflare, but if there is demand I can dive deeper into it.</p>
<h2 id="less-javascript">Less JavaScript</h2>
<p>I hope you’ll join me in adding less unnecessary JavaScript to the internet. It will make you a stronger web developer, and your websites are nearly guaranteed to be faster. There are still of course valid use cases for JavaScript, and perhaps I will explore this topic more in the future as well.</p>


  </section></div>]]>
            </description>
            <link>https://corytheboyd.com/posts/inside-my-personal-website/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24163960</guid>
            <pubDate>Fri, 14 Aug 2020 22:16:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Seth Godin's the Marketing Seminar Review]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24163930">thread link</a>) | @brendancahill
<br/>
August 14, 2020 | https://brendancahill.io/resources/themarketingseminar | <a href="https://web.archive.org/web/*/https://brendancahill.io/resources/themarketingseminar">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-4c2bf5f3f9d470fa7504"><div><p><strong>The Marketing Seminar (TMS)</strong></p><p>Last Fall I did Seth Godin’s <a href="https://themarketingseminar.com/"><span>This Is Marketing Seminar</span></a>. I was on the fence about going in on this course. I had taken a few courses previously for hefty sums of money that didn’t pan out but after continually reusing the lessons Seth taught in this course over the past year, I can say truly it is 10X more valuable than the price they charge for it.&nbsp;</p><p>I think one of the biggest problems with learning online today is ensuring quality control. Any shmo can slap together a course, market it and sell it, but it is the nature of learning to not truly know if it was <em>worth</em> it until after you’ve completed the experience. Yet, the team at Akimbo and Seth worked hard to create an online community that was not just about learning but engagement.&nbsp;</p><p>Here is my review of it. Enjoy.&nbsp;</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597442244962_4307"><div><p><strong>Here is what TMS did well:</strong></p><ol data-rte-list="default"><li><p><strong>Action Oriented:</strong> Seth and Akimbo designed a course architecture where it was basically impossible for you <em>not</em> to take some type of action daily, and per course. I suggest, if you take this course, to create a dedicated Google Drive folder with each module’s work that you upload.&nbsp;</p></li><li><p><strong>Platform Performance: </strong>The platform used was <a href="https://www.discourse.org/about"><span>Discourse</span></a>. Until TMS I had never come across them but Discourse provided ways to comment, communicate, award participation, offer personal connection and breakout groups in ways that were easier to navigate than I expected.&nbsp;</p></li><li><p><strong>Deep Dives: </strong>TMS is largely based off of Seth’s book <em>This is Marketing</em> but each module is a deep dive down a marketing rabbit hole mentioned in his book. I guess you can think of <a href="https://www.amazon.com/dp/B07DBR1V9S/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1"><span><em>This is Marketing</em></span></a> as this course’s assigned textbook (although you need not have read it).&nbsp;</p></li><li><p><strong>Moderators/Coaches:</strong> While Seth personally hops in from time to time to host office hours, the real coaching came in the form of Seth’s moderators that the course deputized to help stir debate, push thinking and ensure all students’ work received some type of feedback each time. Naturally, given the 80/20 rule not all posts are going to stir lively debate. These coaches were my favorite part.&nbsp;</p></li><li><p><strong>Material:</strong> The material was accessible for about six months after the course had initially finished. I found myself going back over into the course material numerous times as I applied what I was learning to my business and job. I think Seth could easily charge money for continual access to the course materials for alumni like myself and I’d gladly pay.&nbsp;</p></li><li><p><strong>ROI:</strong> Seth and TMS can’t take action for you, but they can make you feel like you’re not alone and supported. In the months during and after the course I found my business network and revenue grew in proportion to the amount of TMS ideas I rolled out. Is that the case with everyone? Not necessarily. But ROI is a combination of how much action one is willing to take plus timing. Action is the only one of these two you can control.&nbsp;</p></li><li><p><strong>Crystal Clear Directions:</strong> Learning how to use Discourse, navigate the platform, course material and course culture all at once can be daunting. People don’t like to feel afraid. They like to feel smart. Seth’s team covers every atomic bit of how-to information in getting you set up to participate fully in this course.&nbsp;</p></li></ol><p><strong>What I could have done better</strong><br></p><ol data-rte-list="default"><li><p><strong>Consistency</strong>: I would post in sporadic bursts, writing tombs sometimes and other times not visiting in on the discussion board for a week or so at a time. I would fall out of the loop with threads that I had commented on and would find it tough to get back into a posting rhythm.&nbsp;</p></li><li><p><strong>Vision</strong>: I didn’t start TMS with a clear goal for how I wanted it to help in my job or business. While this helped me be more open about the course material, I think I lost focus without having a clear goal to work towards.&nbsp;</p></li><li><p><strong>Connection</strong>: I didn’t take even 1% advantage of “finding the others” with shared interests in the course like me. Using Discourse it would have been easy, looking back, to have found a few folks geographically close with similar interests to build friendships with. Looking back, most of the value of this course is that Seth has aggregated 100+ people <em>just like you</em> in some way. All you need to do is say hi.&nbsp;</p></li><li><p><strong>Saving My Work</strong>: You do lose access to the course materials after about six months after completion of the course. And, initially I did a good job of keeping records of my work, I did fall off about halfway through the course, not in work ethic, but in just keeping things organized.&nbsp;</p></li></ol><p><strong>Why might you consider The Marketing Seminar?</strong></p><ol data-rte-list="default"><li><p><strong>If you’re an entrepreneur:</strong> This course will give you the fire power to position your brand to reach the people that you want to reach. It will force you to clearly think about who you are for, who you are not for, the change you are promising, and the story your product needs to tell.&nbsp;</p></li><li><p><strong>If you’re an employee:</strong> This course will give you all the tools you need to better market <em>yourself</em> as a change agent within your organization, how to tell a better story about your vision, resonate with your superiors, build trust and take your next career steps. If you think about the decision makers in most organizations, they possess the best marketing skills.&nbsp;</p></li><li><p><strong>If you feel stuck:</strong> If you are a solopreneur (most of this audience) it is easy to feel stale and stuck. TMS will reinvigorate your business planning with more ideas that you will know what to do with. It will help you see your business is a different like. It will help you become more empathic towards those you seek to serve. And, most of all, it will help you believe in your own work.&nbsp;</p></li></ol><p><strong>The Most Important Person To Market To</strong></p><p>The irony of marketing is that the most important person to market to is you, the marketer. “Drowning people make lousy lifeguards”, as Seth would say, and so it is hard to feel like you are performing a generous act towards another person when marketing if you aren’t feeling generous towards yourself.&nbsp;</p><p>The real magic of The Marketing Seminar is that in crafting the narrative of your business you are simultaneously crafting the narrative that you wish to live your life by. Similar to the narrative of your business, you can change the narrative of your life at any point. Seth just shows you how.&nbsp;</p><p>Bren</p><p>P.S. I am not affiliated in anyway with The Marketing Seminar. I just believe it’s a great product. </p></div></div></div>]]>
            </description>
            <link>https://brendancahill.io/resources/themarketingseminar</link>
            <guid isPermaLink="false">hacker-news-small-sites-24163930</guid>
            <pubDate>Fri, 14 Aug 2020 22:12:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Path to Managing Managers]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24163713">thread link</a>) | @jstanier
<br/>
August 14, 2020 | https://www.theengineeringmanager.com/managing-managers/the-path-to-managing-managers/ | <a href="https://web.archive.org/web/*/https://www.theengineeringmanager.com/managing-managers/the-path-to-managing-managers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="primary" role="main">
		
<article id="post-1355">

			<!-- end .entry-header -->

		<div>
		
		<div>
			
<p>How do you end up being one of those people that manages managers?&nbsp;</p>



<p>This is the beginning of a <a href="https://www.theengineeringmanager.com/managing-managers/">series of articles</a> looking at how you can start working on progressing up the management track beyond an <a href="https://www.theengineeringmanager.com/management-101/">Engineering Manager</a>, and into the world of important-sounding job titles. And meetings. Don’t forget meetings. There’s lots of those.</p>



<p>But those job titles, huh?&nbsp;</p>



<p>You may have looked at roles such as <a href="https://docs.google.com/spreadsheets/d/1weNoeSUfHYOHy9sHKad_ax6qrVXNFlP4ieTwaRll70M/edit#gid=1999769114">Director of Engineering or VP Engineering</a> from afar and imagined just how prestigious it must be to see it shining at the bottom of your email signature as you send a terse and impactful decision to your large organization.</p>



<blockquote><p><em>Yes. Let’s commit to this.</em></p><p><em>——</em></p><p><em>A. Genius, PhD</em></p><p><em>Senior Vice President of Data Science and Engineering</em></p></blockquote>



<p>Maybe you’ve even edited your Twitter profile to see what it would look like in your bio. Don’t worry, we’ve all done it. Hopefully you didn’t accidentally hit save.</p>



<p>Anyway, to that question. How do <em>you</em> get one of these roles?</p>



<p>No doubt you’ve seen <em>Director of…</em>, <em>Head of…</em>, and <em>VP</em> roles advertised externally, especially at large software companies. However, often there’s a Catch-22 situation that you’ll face: they’re typically looking for people who have had experience in doing it before. Or even if they say that they aren’t, what chance are you going to have in the recruitment process if you’re up against others who’ve been there and done that? Now, of course, you might get lucky. But maybe there are ways of preparing to make yourself even more lucky.</p>



<p>Let’s think about getting yourself prepared for making the leap to managing managers. I believe that you stand the most chance of being able to make the next progression step if you find yourself at the union of a majority of the following characteristics and situations:</p>



<ul><li><strong>You’ve been an Engineering Manager for a decent amount of time</strong> (say, 2-5 years) and have a provable track record of shipping and people management, with references that can back you up. After all, if you’re going to be running multiple teams, you’re going to need to know how to run one team inside out. (If you’re still working on that, there’s plenty of material on the rest of this site to help you skill up.)</li><li><strong>You’re already working for a company with a strong management culture</strong> that has clear career progression tracks for managers as well as individual contributors. This means that if the role opens up where you already work, it’s clear how to put yourself forward for it. It’ll also mean you’re learning and practicing the right skills.</li><li><strong>You’re at a company that is changing fast</strong> and has a tendency to not quite be able to keep up with the chaos. This often occurs during periods of rapid growth, or even via shake-up – through downsizing, mergers and acquisitions – any event that begins to question the current shape of the org chart being correct for the foreseeable future.</li><li><strong>You have a good presence online</strong> via the usual social channels: LinkedIn, Twitter, Github, and so on. This way if people are trying to find people like you elsewhere, then they can.</li></ul>



<p>Now, of course, it is entirely plausible that you may apply cold for a Director of Engineering role as an external applicant whilst currently being an Engineering Manager. That’s what I meant by getting lucky above. Quite often more senior engineering management positions are either specifically headhunted or promoted from within.&nbsp;</p>



<p>But why is this?</p>



<ul><li><strong>The more senior the managerial position, the more risky a bad hire is</strong>. That’s why excellent internal candidates always have the upper hand: they are a known entity that likely already has domain knowledge. They’re also far more likely to have the company take a chance on the new gig working out. Even better: smart companies will do a 30-60-90 plan that allows the promoted member of staff to revert back to their old role amicably if it’s not working out.</li><li><strong>Good companies will look out for their own staff first</strong> and seize opportunities to offer career progression in order to retain existing talent. I don’t have any statistics on how many manager of manager roles that get filled and are never advertised externally, but I’d reckon it’s maybe in the 70%+ region. If you hire good people consistently, you’ll always have someone great progressing up through the ranks. Why look elsewhere, unless you specifically need to bring in someone specific, such as a candidate with key domain knowledge that is lacking at the company?</li><li><strong>The need to find a manager of managers (in my experience) is rarely something that undergoes extensive planning</strong>. During periods of rapid growth, the number of staff in the department may start stacking up to the point that existing teams need to be split into smaller ones, thus greating opportunities for a node in the org chart above those teams. Sometimes an existing manager of managers will quit and filling that void internally, on a tight timeline, is much easier than reaching outside of the company. Or perhaps two organizations merging together create a bunch of empty nodes in the org chart needing urgently to be filled. Often you look within.</li></ul>



<p>These are all opportunities that you can more likely seize if you make sure you’re already working for an ambitious, high growth company and are doing a stellar job of running a team. This is no small feat in itself, mind you.</p>



<p>Start-ups, or smaller high growth companies in general, are great for giving yourself this opportunity, especially ones that have just received a new venture capital investment. An injection of money means an injection of people, and that then creates more opportunities for leading them as the org chart adapts. <a href="https://www.theengineeringmanager.com/book/">I advocated strongly for the managerial opportunities that high growth start-ups can offer you in the penultimate chapter of my book</a>. After all, how do you reckon many CTOs became CTOs for the first time?</p>



<p>So where am I going with this? To use the cheesiest quote, you’ve gotta skate where the puck is going. (Thanks Wayne.) Yes, you can keep an eye on external adverts and apply to anything and everything and hope that you land the job. However, depending on where you currently work, it may be more fruitful to change role sooner at your <em>current</em> level – which is often easier – in order to stand more of a chance of upward growth over time.</p>



<p>There are parallels here with the early stages of an individual contributor’s career. It’s often really hard to land that first job because the applicant has yet to be able to prove themselves. However, once they’ve stuck around for a few years and have gained experience by shipping lots of code, they find themselves having to bat the recruiters away.</p>



<p>The exact same thing is true about progressing further up the management track. Getting your first management role is tough, but you only have to do it once to prove you can do it again. The same is true about the next step of managing managers. People often grow from within by being excellent performers and then working their way upwards.</p>



<p>If you’re looking to grow from managing individual contributors to managing managers, have a think about the following points.</p>



<ul><li><strong>How likely is it that this will be possible at your current company within a reasonable timeframe?</strong> If it’s not, you might need to look elsewhere sooner rather than later.</li><li><strong>Is your current Engineering Manager role defined similarly to how other notable companies in the industry define it?</strong> If not, why not? The more your current EM role fits that of the best employers in the industry, the better chance you have of moving sideways and upwards.</li><li><strong>How many years of experience in this role do you have?</strong> I would expect a manager of managers to be a high growth EM with at least a few years of tenure.</li><li><strong>What notable infrastructure, features or products have you shipped whilst being an EM?&nbsp;</strong></li><li><strong>Are you seen as an influential person in your current department?</strong> Do people outside your team seek your advice? If not, why not?</li><li><strong>Have you coached anyone outside of your team?</strong> If not, then I’d advise you to start giving it a go.</li><li><strong>Have you found anyone else doing this role, either in your existing company, your network or online?</strong> Get in touch with them to see if they’ll have a chat with you about what it’s like to do that job, and ask them how they got into it. What changed for them when compared to just running one team? What happened to their time to contribute technically? </li></ul>



<p>What’s your current story? Does it feel like you’re ready for the next step? Have you already been working at the level of your next promotion?</p>



<p>If you’re not familiar with the management career progression path in general then you can check out the career tracks of other companies, <a href="https://docs.google.com/spreadsheets/u/1/d/1weNoeSUfHYOHy9sHKad_ax6qrVXNFlP4ieTwaRll70M/edit#gid=1999769114">including our own</a> from Brandwatch, on <a href="https://www.progression.fyi/">progression.fyi</a>.</p>



<p>If you’re seeking out others to talk to about it, then you could use LinkedIn, Twitter, or Slack communities such as <a href="https://lead-dev-slack.herokuapp.com/">The Lead Developer</a>, <a href="https://ctocraft.com/community/">CTO Craft,</a> or the <a href="https://randsinrepose.com/welcome-to-rands-leadership-slack/">Rands’ Leadership group</a> to do so. </p>



<p>While you ruminate on these, I’ll be expanding out my own thoughts and experiences of doing the job for a number of years in the forthcoming series of articles that I’ll be hosting under the <a href="https://www.theengineeringmanager.com/managing-managers/">Managing Managers</a> section of the website.</p>



<p>Until the next one, good luck!&nbsp;</p>



<p><a href="http://eepurl.com/cSMExr">You can sign up to my mailing list to hear when new posts are published.</a></p>
					</div><!-- end .entry-content -->

			</div><!-- end .entry-wrap -->

</article><!-- end .post-1355 -->
	<!-- #comments .comments-area -->
	</div></div>]]>
            </description>
            <link>https://www.theengineeringmanager.com/managing-managers/the-path-to-managing-managers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24163713</guid>
            <pubDate>Fri, 14 Aug 2020 21:49:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My best SEO tactic so far]]>
            </title>
            <description>
<![CDATA[
Score 200 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24163658">thread link</a>) | @AlchemistCamp
<br/>
August 14, 2020 | https://questinglog.com/my-best-seo-tactic-so-far/ | <a href="https://web.archive.org/web/*/https://questinglog.com/my-best-seo-tactic-so-far/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Over the years, I've worked on building search traffic for two kinds of sites.</p> <p>The first, was working for companies that already had hundreds of thousands or millions of monthly users and were trying to build their traffic via a team of writers. I did this first for Verbling (as a side component to my work as a full-time dev), and then later for Codementor, as a remote growth consultant.</p> <p>The second, was my own sites or apps where 100% of the content was produced by me. I've also helped several other independent solo-founders do essentially the same for their own projects. Today's advice is for 2nd type of site—the ones with just one writer.</p> <p>For a quick point of reference, I'll what I'm currently working on so you can get an idea of how applicable my experience is or isn't to you:  <a href="https://alchemist.camp/" target="_blank" rel="noopener noreferrer">Alchemist Camp</a>. It targets an extremely small programming niche and is hovering around Alexa 700k (10-15k uniques/month with decent visit time). I add new content about once a week. Previously, I built a considerably larger personal blog that peaked at about Alexa 300k, but it's no longer up.</p> <h2 id="work-with-the-search-engine"><a href="#work-with-the-search-engine">#</a> Work <em>with</em> the search engine</h2> <p>There's a lot of competition for attention from search engines and an entire industry of people trying to game them. It's possible to do that successfully in the short term, but people who do that generally get crushed when new search ranking updates. The more egregious marketers sometimes get penalized or banned entirely.</p> <p>There are certain technical SEO basics to pay attention to, such as having a reasonable site structure, a sitemap and appropriate meta-tags. I'm going to assume you've got that covered. WordPress or any other modern CMS will do an adequate job out of the box.</p> <p>So with the above assumptions, what's a good way to cut through the competition?</p> <h2 id="pay-attention-when-a-search-is-frustrating"><a href="#pay-attention-when-a-search-is-frustrating">#</a> Pay attention when a search is frustrating</h2> <p>The single most successful strategy I've found for getting search engine traffic for a more niche site has been to pay very close attention when something is difficult to find online. This isn't very difficult to do, since it's easy to notice when something is frustrating. The key is to be aware and take notes.</p> <p>Look at your browser history and write down <em>the exact queries</em> you typed into Google, Duckduckgo or your search engine of choice. Ask yourself <em>what</em> you were hoping to find online and why you tried each query after the first.</p> <h2 id="create-what-you-hoped-your-search-would-find"><a href="#create-what-you-hoped-your-search-would-find">#</a> Create what you hoped your search would find</h2> <p>Then, after you've learned what you were trying to learn during your frustrating search, create the very thing you were trying to find.</p> <p>Usually a search is difficult because the ideal answer doesn't exist in a single document online or video. Instead, finding the answer involves piecing the information together from numerous sources. If that was the case with your frustrating search, then the next step is to create the answer to the search and publish it.</p> <p>Occasionally after a long and frustrating search, you <em>will</em> find a single resource that answers exactly what you wanted. In this case the question is, "Why didn't my first several searches return this document?" Maybe it used different terminology than you did. Maybe it was comment on an ancient forum post. Maybe it was on an extremely slow site. Make your own version of the resource you finally found, but fix whatever issue made it difficult to find.</p> <h3 id="an-example"><a href="#an-example">#</a> An example</h3> <p>One direct example of using this strategy was when it took me about 20 minutes of searching to find out how to do a certain kind of query with Elixir's main DB-related library, Ecto. Elixir maps are stored in Postgres as JSONB fields, and I wanted to query fields within the JSONB.</p> <p>I saw I'd made 8 searches, starting with <em>"query nested fields of a map ecto"</em>. Ultimately the whole answer to what I was looking for was split between a Thoughtbot post, a Stack Overflow answer and a Postgres documentation page.</p> <p>Then I wrote a short article called, <a href="https://alchemist.camp/articles/querying-nested-map-ecto" target="_blank" rel="noopener noreferrer">Querying nested fields of a map with Ecto</a> that contained exactly the information I'd been looking for, and it's since brought in a thousand visitors from search in under a year.</p> <h2 id="why-does-this-work"><a href="#why-does-this-work">#</a> Why does this work?</h2> <p>This strategy tends to be stable because it works with the search engine and doesn't tend to get crushed by updates the way more aggressive techniques do. It leads to creating genuinely helpful resources for people to find online and Google has every incentive to return them in its results.</p> <p>Content created this way tends to rank well because the entire strategy revolves around escaping competition. If there is a lot of competition around a query, it's generally well-answered and you'll find an adequate (though possibly spammy, advertising-stuffed) result within a search or two. The searches that are <em>really</em> frustrating are usually not going to have much competition.</p> <p>Unless your interests are <strong>truly</strong> rare, others will search for what you did and find your page.</p>  <br></div></div>]]>
            </description>
            <link>https://questinglog.com/my-best-seo-tactic-so-far/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24163658</guid>
            <pubDate>Fri, 14 Aug 2020 21:44:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made 1M (!) syntax highlighting themes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24163353">thread link</a>) | @boronine
<br/>
August 14, 2020 | https://www.syntaxenvy.com/0782664 | <a href="https://web.archive.org/web/*/https://www.syntaxenvy.com/0782664">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <p><a href="https://www.syntaxenvy.com/"><img src="https://www.syntaxenvy.com/static/logo.svg"> </a></p><p>Procedurally generated syntax highlighting themes.</p>
            <p>Use in your favorite IDE or text editor, or pick a theme to suit your blog or website.</p>
            <p>Unlimited downloads for the price of a coffee.</p>
        </div>
        
        <div id="x">
            
<div><pre><span></span><span>import</span> <span>re</span>

<span>def</span> <span>hello</span><span>(</span><span>name</span><span>):</span>
    <span># Example comment</span>
    <span>return</span> <span>f</span><span>"hello, </span><span>{name}</span><span>\n</span><span>how are you?"</span>

<span>class</span> <span>Demo</span><span>(</span><span>object</span><span>):</span>
    <span>def</span> <span>xyz_to_luv</span><span>(</span><span>self</span><span>,</span> <span>_hx_tuple</span><span>):</span>
        <span>x</span> <span>=</span> <span>float</span><span>(</span><span>_hx_tuple</span><span>[</span><span>0</span><span>])</span>
        <span>y</span> <span>=</span> <span>float</span><span>(</span><span>_hx_tuple</span><span>[</span><span>1</span><span>])</span>
        <span>z</span> <span>=</span> <span>float</span><span>(</span><span>_hx_tuple</span><span>[</span><span>2</span><span>])</span>
        <span>divider</span> <span>=</span> <span>x</span> <span>+</span> <span>15</span> <span>*</span> <span>y</span> <span>+</span> <span>3</span> <span>*</span> <span>z</span>
        <span>var_u</span> <span>=</span> <span>4</span> <span>*</span> <span>x</span>
        <span>var_v</span> <span>=</span> <span>9</span> <span>*</span> <span>y</span>
        <span>if</span> <span>divider</span> <span>!=</span> <span>0</span><span>:</span>
            <span>var_u</span> <span>=</span> <span>var_u</span> <span>/</span> <span>divider</span>
            <span>var_v</span> <span>=</span> <span>var_v</span> <span>/</span> <span>divider</span>
        <span>else</span><span>:</span>
            <span>var_u</span> <span>=</span> <span>float</span><span>(</span><span>"nan"</span><span>)</span>
            <span>var_v</span> <span>=</span> <span>float</span><span>(</span><span>"nan"</span><span>)</span>
        <span>l</span> <span>=</span> <span>_y_to_l</span><span>(</span><span>y</span><span>)</span>
        <span>if</span> <span>l</span> <span>==</span> <span>0</span><span>:</span>
            <span>return</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]</span>
        <span>u</span> <span>=</span> <span>13</span> <span>*</span> <span>l</span> <span>*</span> <span>(</span><span>var_u</span> <span>-</span> <span>refU</span><span>)</span>
        <span>v</span> <span>=</span> <span>13</span> <span>*</span> <span>l</span> <span>*</span> <span>(</span><span>var_v</span> <span>-</span> <span>refV</span><span>)</span>
        <span>return</span> <span>[</span><span>l</span><span>,</span> <span>u</span><span>,</span> <span>v</span><span>]</span>
</pre></div>


        </div>
    </div></div>]]>
            </description>
            <link>https://www.syntaxenvy.com/0782664</link>
            <guid isPermaLink="false">hacker-news-small-sites-24163353</guid>
            <pubDate>Fri, 14 Aug 2020 21:13:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FPGA Pong: Write Pong in Verilog]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24163298">thread link</a>) | @homarp
<br/>
August 14, 2020 | https://projectf.io/posts/fpga-pong/ | <a href="https://web.archive.org/web/*/https://projectf.io/posts/fpga-pong/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Welcome back to <em>Exploring FPGA Graphics</em> with Project F. In this series, we’ll be experimenting with FPGA graphics of all kinds, from a simple square, through Pong, sprites, and the Mandelbrot set, to 2D drawing, and even simple 3D modelling. New to the series? Start with <a href="https://projectf.io/posts/fpga-graphics/">Exploring FPGA Graphics</a>.</p>
<p>In the previous part, we got an <a href="https://projectf.io/posts/fpga-graphics/">introduction to FPGA graphics</a>, now we’re ready to put our graphical skills to work, by recreating the arcade classic: Pong.</p>
<p><em>Revised 2020-08-14. Get in touch with <a href="https://twitter.com/WillFlux">@WillFlux</a> or open an <a href="https://github.com/projf/projf-explore/issues">issue on GitHub</a>.</em></p>
<h3 id="requirements">Requirements</h3>
<p>For this series, you need an FPGA board with video output. We’ll be working at 640x480, so pretty much any video output will do. You should be comfortable with programming your FPGA board and reasonably familiar with Verilog.</p>
<p>We’ll be demoing with these boards (FPGA type):</p>
<ul>
<li><strong><a href="https://github.com/icebreaker-fpga/icebreaker">iCEBreaker</a></strong> (Lattice iCE40) with <strong><a href="https://github.com/icebreaker-fpga/icebreaker">12-Bit DVI Pmod</a></strong></li>
<li><strong><a href="https://reference.digilentinc.com/reference/programmable-logic/arty-a7/reference-manual">Digilent Arty A7-35T</a></strong> (Xilinx XC7) with <strong><a href="https://reference.digilentinc.com/reference/pmod/pmodvga/reference-manual">Pmod VGA</a></strong>
<ul>
<li>The Arty version of Pong is still being tested and will be released soon</li>
</ul>
</li>
</ul>
<p>Follow the source <a href="https://github.com/projf/projf-explore/tree/master/fpga-pong">README</a> to quickly build a project for either of these boards.</p>
<blockquote>
<p><strong>iCEBreaker with VGA Pmod</strong><br>
The first part of this series included VGA designs for iCEBreaker. Maintaining three sets of designs was a significant overhead, so the iCEBreaker VGA version has been dropped from the examples.</p>
</blockquote>
<h3 id="source">Source</h3>
<p>All the Verilog designs featured in this series are available in the <a href="https://github.com/projf/projf-explore/">Exploring FPGAs repo</a>, and source links are included throughout the blog. The designs are open source under the permissive MIT licence, but this blog is subject to normal copyright restrictions.</p>
<h2 id="invading-the-living-room">Invading the Living Room</h2>
<p><img src="https://projectf.io/img/posts/fpga-pong/pong_living_room.jpg" alt="70s gaming room in Computerspielemuseum, Berlin" title="So 70s it hurts"></p>
<p><em>Photograph by Sergey Galyonkin via <a href="https://commons.wikimedia.org/wiki/File:70s_gaming_room_in_Computerspielemuseum,_Berlin.jpg">Wikimedia</a> under Creative Commons <a href="https://creativecommons.org/licenses/by-sa/2.0/deed.en">Attribution-Share Alike</a> licence.</em></p>
<p><strong>Pong</strong> may not have been the first computer game, but it has an excellent claim to being the first to break into public consciousness when it was released in 1972. Originally an arcade cabinet, it was quickly adapted to be played at home attached to a television. If you’d like to learn more about the early history of Atari, including Pong, I recommend <em><a href="https://mitpress.mit.edu/books/racing-beam">Racing the Beam</a></em> by Nick Montfort and Ian Bogost.</p>
<p><em>ProTip: If you’re unfamiliar with Pong gameplay, check out this <a href="https://www.youtube.com/watch?v=it0sf4CMDeM">Pong video</a> on YouTube.</em></p>
<h2 id="ball--paddles">Ball &amp; Paddles</h2>
<p>In the <a href="https://projectf.io/posts/fpga-graphics/">previous part</a> of this series, we learnt how to draw animated squares and perform collision detection. This gives us all we need to implement a square Pong ball:</p>
<div><pre><code data-lang="verilog">    <span>localparam</span> B_SIZE <span>=</span> <span>8</span>;          <span>// size in pixels
</span><span></span>    <span>logic</span> [CORDW<span>-</span><span>1</span><span>:</span><span>0</span>] bx, by;       <span>// position
</span><span></span>    <span>logic</span> dx, dy;                   <span>// direction: 0 is right/down
</span><span></span>    <span>logic</span> [CORDW<span>-</span><span>1</span><span>:</span><span>0</span>] spx <span>=</span> <span>10</span><span>'d1</span>;  <span>// horizontal speed
</span><span></span>    <span>logic</span> [CORDW<span>-</span><span>1</span><span>:</span><span>0</span>] spy <span>=</span> <span>10</span><span>'d1</span>;  <span>// vertical speed
</span><span></span>
    <span>always_ff</span> @(<span>posedge</span> clk_pix) <span>begin</span>
        <span>if</span> (animate) <span>begin</span>
            <span>if</span> (bx <span>&gt;=</span> H_RES <span>-</span> (spx <span>+</span> B_SIZE)) <span>begin</span>  <span>// right edge
</span><span></span>                dx <span>&lt;=</span> <span>1</span>;
                bx <span>&lt;=</span> bx <span>-</span> spx;
            <span>end</span> <span>else</span> <span>if</span> (bx <span>&lt;</span> spx) <span>begin</span>  <span>// left edge
</span><span></span>                dx <span>&lt;=</span> <span>0</span>;
                bx <span>&lt;=</span> bx <span>+</span> spx;
            <span>end</span> <span>else</span> bx <span>&lt;=</span> (dx) <span>?</span> bx <span>-</span> spx <span>:</span> bx <span>+</span> spx;

            <span>if</span> (by <span>&gt;=</span> V_RES <span>-</span> (spy <span>+</span> B_SIZE)) <span>begin</span>  <span>// bottom edge
</span><span></span>                dy <span>&lt;=</span> <span>1</span>;
                by <span>&lt;=</span> by <span>-</span> spy;
            <span>end</span> <span>else</span> <span>if</span> (by <span>&lt;</span> spy) <span>begin</span>  <span>// top edge
</span><span></span>                dy <span>&lt;=</span> <span>0</span>;
                by <span>&lt;=</span> by <span>+</span> spy;
            <span>end</span> <span>else</span> by <span>&lt;=</span> (dy) <span>?</span> by <span>-</span> spy <span>:</span> by <span>+</span> spy;
        <span>end</span>
    <span>end</span>

    <span>logic</span> b_draw;
    <span>always_comb</span> <span>begin</span>
        b_draw <span>=</span> (sx <span>&gt;=</span> bx) <span>&amp;&amp;</span> (sx <span>&lt;</span> bx <span>+</span> B_SIZE)
              <span>&amp;&amp;</span> (sy <span>&gt;=</span> by) <span>&amp;&amp;</span> (sy <span>&lt;</span> by <span>+</span> B_SIZE);
    <span>end</span>
</code></pre></div><p>Next, we need to add some paddles. The paddles are simple rectangles that move vertically on the left and right sides of the screen. These paddles have a crude AI that compares their vertical position to the ball and moves them in the direction of the ball. We check if the paddles have reached the screen edge, but not whether they’ve have collided with the ball.</p>
<div><pre><code data-lang="verilog">    <span>localparam</span> P_HEIGHT <span>=</span> <span>40</span>;       <span>// height in pixels
</span><span></span>    <span>localparam</span> P_WIDTH  <span>=</span> <span>10</span>;       <span>// width in pixels
</span><span></span>    <span>localparam</span> P_SPEED  <span>=</span> <span>1</span>;        <span>// speed
</span><span></span>    <span>localparam</span> P_OFFSET <span>=</span> <span>32</span>;       <span>// offset from screen edge
</span><span></span>    <span>logic</span> [CORDW<span>-</span><span>1</span><span>:</span><span>0</span>] p1y, p2y;     <span>// vertical position of paddles 1 and 2
</span><span></span>
    <span>always_ff</span> @(<span>posedge</span> clk_pix) <span>begin</span>
        <span>if</span> (animate) <span>begin</span>
            <span>// "AI" paddle 1
</span><span></span>            <span>if</span> ((p1y <span>+</span> P_HEIGHT<span>/</span><span>2</span>) <span>&lt;</span> by) <span>begin</span>  <span>// top of ball is below
</span><span></span>                <span>if</span> (p1y <span>&lt;</span> V_RES <span>-</span> (P_HEIGHT <span>+</span> P_SPEED)) p1y <span>&lt;=</span> p1y <span>+</span> P_SPEED;  <span>// screen bottom?
</span><span></span>            <span>end</span>
            <span>if</span> ((p1y <span>+</span> P_HEIGHT<span>/</span><span>2</span>) <span>&gt;</span> (by <span>+</span> B_SIZE)) <span>begin</span>  <span>// bottom of ball is above
</span><span></span>                <span>if</span> (p1y <span>&gt;</span> P_SPEED) p1y <span>&lt;=</span> p1y <span>-</span> P_SPEED;  <span>// screen top?
</span><span></span>            <span>end</span>

            <span>// "AI" paddle 2
</span><span></span>            <span>if</span> ((p2y <span>+</span> P_HEIGHT<span>/</span><span>2</span>) <span>&lt;</span> by) <span>begin</span>
                <span>if</span> (p2y <span>&lt;</span> V_RES <span>-</span> (P_HEIGHT <span>+</span> P_SPEED)) p2y <span>&lt;=</span> p2y <span>+</span> P_SPEED;
            <span>end</span>
            <span>if</span> ((p2y <span>+</span> P_HEIGHT<span>/</span><span>2</span>) <span>&gt;</span> (by <span>+</span> B_SIZE)) <span>begin</span>
                <span>if</span> (p2y <span>&gt;</span> P_SPEED) p2y <span>&lt;=</span> p2y <span>-</span> P_SPEED;
            <span>end</span>
        <span>end</span>
    <span>end</span>

    <span>logic</span> p1_draw, p2_draw;
    <span>always_comb</span> <span>begin</span>
        p1_draw <span>=</span> (sx <span>&gt;=</span> P_OFFSET) <span>&amp;&amp;</span> (sx <span>&lt;</span> P_OFFSET <span>+</span> P_WIDTH)
               <span>&amp;&amp;</span> (sy <span>&gt;=</span> p1y) <span>&amp;&amp;</span> (sy <span>&lt;</span> p1y <span>+</span> P_HEIGHT);
        p2_draw <span>=</span> (sx <span>&gt;=</span> H_RES <span>-</span> P_OFFSET <span>-</span> P_WIDTH) <span>&amp;&amp;</span> (sx <span>&lt;</span> H_RES <span>-</span> P_OFFSET)
               <span>&amp;&amp;</span> (sy <span>&gt;=</span> p2y) <span>&amp;&amp;</span> (sy <span>&lt;</span> p2y <span>+</span> P_HEIGHT);
    <span>end</span>
</code></pre></div><p>We compare paddle positions with the top or bottom of the ball to prevent them being too twitchy.</p>
<h3 id="pong-v1">Pong v1</h3>
<p>We can use the ball and paddle logic to create a first version of the top module for Pong:</p>
<ul>
<li>Xilinx XC7: <em>coming soon</em></li>
<li>Lattice iCE40: <strong><a href="https://github.com/projf/projf-explore/blob/master/fpga-pong/ice40/top_pong_v1.sv">ice40/top_pong_v1.sv</a></strong></li>
</ul>
<p>To build this example, you’ll also need the display timings, clock generation, and constraints, that we created in the first part of the series. All these files are available in the <a href="https://github.com/projf/projf-explore/tree/master/fpga-pong">FPGA Pong repo</a> together with a makefile for iCEBreaker, and Vivado project for Arty.</p>
<h2 id="collision">Collision</h2>
<p>It’s briefly fun to watch the ball crawl around the screen with the paddles, but this isn’t exactly a game, even a demo of one: the ball shows a blatant disregard for the paddles.</p>
<p>To test for paddle collision, we take advantage of the drawing signals: if we’re drawing the ball and a paddle at the same time, then there’s a collision. The collision occurs during the drawing process, so we need to store it and use it when we next animate.</p>
<div><pre><code data-lang="verilog"><span>logic</span> p1_col, p2_col;
<span>always_ff</span> @(<span>posedge</span> clk_pix) <span>begin</span>
    <span>if</span> (animate) <span>begin</span>
        p1_col <span>&lt;=</span> <span>0</span>;
        p2_col <span>&lt;=</span> <span>0</span>;
    <span>end</span> <span>else</span> <span>if</span> (b_draw) <span>begin</span>
        <span>if</span> (p1_draw) p1_col <span>&lt;=</span> <span>1</span>;
        <span>if</span> (p2_draw) p2_col <span>&lt;=</span> <span>1</span>;
    <span>end</span>
<span>end</span>
</code></pre></div><p>We reset the collision detection when we receive the <code>animate</code> signal. However, the value of <code>col_p1</code> and <code>col_p2</code> is available until the next clock tick, so the ball animation can always use it.</p>
<p>Update the horizontal ball animation to check for paddle collisions:</p>
<div><pre><code data-lang="verilog">    <span>always_ff</span> @(<span>posedge</span> clk_pix) <span>begin</span>
        <span>if</span> (animate) <span>begin</span>
            <span>if</span> (p1_col) <span>begin</span>  <span>// left paddle collision
</span><span></span>                dx <span>&lt;=</span> <span>0</span>;
                bx <span>&lt;=</span> bx <span>+</span> spx;
            <span>end</span> <span>else</span> <span>if</span> (p2_col) <span>begin</span>  <span>// right paddle collision
</span><span></span>                dx <span>&lt;=</span> <span>1</span>;
                bx <span>&lt;=</span> bx <span>-</span> spx;
            <span>end</span> <span>else</span> <span>if</span> (bx <span>&gt;=</span> H_RES <span>-</span> (spx <span>+</span> B_SIZE)) <span>begin</span>  <span>// right edge
</span><span></span>                dx <span>&lt;=</span> <span>1</span>;
                bx <span>&lt;=</span> bx <span>-</span> spx;
            <span>end</span> <span>else</span> <span>if</span> (bx <span>&lt;</span> spx) <span>begin</span>  <span>// left edge
</span><span></span>                dx <span>&lt;=</span> <span>0</span>;
                bx <span>&lt;=</span> bx <span>+</span> spx;
            <span>end</span> <span>else</span> bx <span>&lt;=</span> (dx) <span>?</span> bx <span>-</span> spx <span>:</span> bx <span>+</span> spx;
</code></pre></div><p>We can also speed up the ball and paddles by editing the following values:</p>
<div><pre><code data-lang="verilog">    <span>logic</span> [CORDW<span>-</span><span>1</span><span>:</span><span>0</span>] spx <span>=</span> <span>10</span><span>'d6</span>;  <span>// horizontal speed
</span><span></span>    <span>logic</span> [CORDW<span>-</span><span>1</span><span>:</span><span>0</span>] spy <span>=</span> <span>10</span><span>'d4</span>;  <span>// vertical speed
</span><span></span>
    <span>localparam</span> P_SPEED <span>=</span> <span>4</span>;
</code></pre></div><h3 id="pong-v2">Pong v2</h3>
<p>Build and test the updated version with paddle collisions:</p>
<ul>
<li>Xilinx XC7: <em>coming soon</em></li>
<li>Lattice iCE40: <strong><a href="https://github.com/projf/projf-explore/blob/master/fpga-pong/ice40/top_pong_v2.sv">ice40/top_pong_v2.sv</a></strong></li>
</ul>
<h2 id="controls">Controls</h2>
<p>So far the FPGA has been playing against itself. If you want to get in on the action, we need to add some controls. We’re going to use three buttons: up, control, and down.</p>
<p>Add the buttons to the top module ports:</p>
<div><pre><code data-lang="verilog">    <span>input</span>  <span>wire</span> <span>logic</span> btn_up,       <span>// up button
</span><span></span>    <span>input</span>  <span>wire</span> <span>logic</span> btn_ctrl,     <span>// control button
</span><span></span>    <span>input</span>  <span>wire</span> <span>logic</span> btn_dn,       <span>// down button
</span></code></pre></div><p>We need to map these buttons to FPGA pins in the constraints file. You’ll be happy to hear I’ve already done this for you:</p>
<ul>
<li>Xilinx XC7: <em>coming soon</em></li>
<li>Lattice iCE40: <strong><a href="https://github.com/projf/projf-explore/blob/master/fpga-pong/ice40/icebreaker.pcf">ice40/icebreaker.pcf</a></strong></li>
</ul>
<p>To safely use buttons in our design, we need to debounce them. Debouncing ensures we get a single, clean, transition from button presses. The debounce module looks like this:</p>
<div><pre><code data-lang="verilog"><span>module</span> debounce (
    <span>input</span>  <span>wire</span> <span>logic</span> clk,  <span>// clock
</span><span></span>    <span>input</span>  <span>wire</span> <span>logic</span> in,   <span>// signal input
</span><span></span>    <span>output</span>      <span>logic</span> out,  <span>// signal output (debounced)
</span><span></span>    <span>output</span>      <span>logic</span> ondn, <span>// on down (one tick)
</span><span></span>    <span>output</span>      <span>logic</span> onup  <span>// on up (one tick)
</span><span></span>    );

    <span>// sync with clock and combat metastability
</span><span></span>    <span>logic</span> sync_0, sync_1;
    <span>always_ff</span> @(<span>posedge</span> clk) sync_0 <span>&lt;=</span> in;
    <span>always_ff</span> @(<span>posedge</span> clk) sync_1 <span>&lt;=</span> sync_0;

    <span>logic</span> [<span>16</span><span>:</span><span>0</span>] cnt;  <span>// 2^17 = 1.3 ms counter at 100 MHz
</span><span></span>    <span>logic</span> idle, max;
    <span>always_comb</span> <span>begin</span>
        idle <span>=</span> (out <span>==</span> sync_1);
        max  <span>=</span> <span>&amp;</span>cnt;
        ondn <span>=</span> <span>~</span>idle <span>&amp;</span> max <span>&amp;</span> <span>~</span>out;
        onup <span>=</span> <span>~</span>idle <span>&amp;</span> max <span>&amp;</span> out;
    <span>end</span>

    <span>always_ff</span> @(<span>posedge</span> clk) <span>begin</span>
        <span>if</span> (idle) <span>begin</span>
            cnt <span>&lt;=</span> <span>0</span>;
        <span>end</span> <span>else</span> <span>begin</span>
            cnt <span>&lt;=</span> cnt <span>+</span> <span>1</span>;
            <span>if</span> (max) out <span>&lt;=</span> <span>~</span>out;
        <span>end</span>
    <span>end</span>
<span>endmodule</span>
</code></pre></div><p>We want continuous signals for up and down, but a one-off event for the control button:</p>
<div><pre><code data-lang="verilog">    <span>logic</span> sig_ctrl, move_up, move_dn;
    debounce deb_btn_ctrl (.clk(clk_pix), .in(btn_ctrl), .out(), .ondn(), .onup(sig_ctrl));
    debounce deb_btn_up (.clk(clk_pix), .in(btn_up), .out(move_up), .ondn(), .onup());
    debounce deb_btn_dn (.clk(clk_pix), .in(btn_dn), .out(move_dn), .ondn(), .onup());
</code></pre></div><p>The <code>onup()</code> and <code>ondown()</code> outputs work like traditional UI events. In this case, <code>sig_ctrl</code> will be high for one tick when the control button is released.</p>
<p>We start with two states:</p>
<ul>
<li><strong>IDLE</strong> - both paddles are controlled by the AI (demo)</li>
<li><strong>PLAY</strong> - enable player paddle</li>
</ul>
<p>Pressing the control button switches between these states, while the up and down buttons are used to control the paddle.</p>
<p>We define the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://projectf.io/posts/fpga-pong/">https://projectf.io/posts/fpga-pong/</a></em></p>]]>
            </description>
            <link>https://projectf.io/posts/fpga-pong/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24163298</guid>
            <pubDate>Fri, 14 Aug 2020 21:09:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sea of Nodes (2015)]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24163263">thread link</a>) | @ingve
<br/>
August 14, 2020 | https://darksi.de/d.sea-of-nodes/ | <a href="https://web.archive.org/web/*/https://darksi.de/d.sea-of-nodes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://darksi.de/d.sea-of-nodes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24163263</guid>
            <pubDate>Fri, 14 Aug 2020 21:05:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[^ NightShow HN: Have you seen this? The Real Real Good Product/Market fit.]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24162710">thread link</a>) | @martingalovic
<br/>
August 14, 2020 | https://pmfguru.com/superhuman-pmf-engine | <a href="https://web.archive.org/web/*/https://pmfguru.com/superhuman-pmf-engine">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<h4>TL;DR</h4>
<div><p>
Sean Ellis (early Dropbox, Eventbrite) found leading indicator for product/market fit.
<b>Just ask users "How would you feel if you could no longer use our product?" and measure the percent who answer "Very disappointed"</b></p><p>

If the percentage is above the 40%, you did it — you got to product/market fit.
</p></div>
<div>
<p>
<h4>
Start measuring your Product/Market Fit
</h4>
<h5>
<small>Built for startups. Setup in 2 minutes.</small>
</h5>
</p>

</div>

</div>
<p>
This article is by <a target="_blank" rel="noopener nofollow" href="https://www.linkedin.com/in/rahulvohra/">Rahul Vohra</a>, the founder and CEO of <a target="_blank" href="https://superhuman.com/">Superhuman</a> — a startup building the fastest email experience in the world.
</p>
<p>
We’ve all heard that product/market fit drives startup success — and that the lack thereof is what’s lurking behind
almost every failure.
</p>
<p>
For founders, achieving product/market fit is an obsession from day one. It’s both the hefty hurdle we’re racing
to clear and the festering fear keeping us up at night, worried that we’ll never make it.
But when it comes to understanding what product/market fit really is and how to get there, most of us quickly realize that
there isn’t a battle-tested approach.
</p>
<p>
In the summer of 2017, I was waist-deep in my search for a way to find product/market fit for my startup, Superhuman.
Turning to the classic blog posts and seminal thought pieces, a few observations stuck out to me.
Y Combinator founder Paul Graham described product/market fit as when you’ve <a target="_blank" href="http://www.paulgraham.com/13sentences.html">made something that people want</a>,
while Sam Altman <a href="http://blog.samaltman.com/before-growth">characterized</a> it as when users spontaneously tell other people to use your product.
But of course, the most cited description comes from this passage in Marc Andreessen’s 2007 blog post:
</p>
<p>
“You can always feel when product/market fit is <b>not</b> happening.
The customers aren't quite getting value out of the product, word of mouth isn't spreading, usage isn't growing that
fast, press reviews are kind of ‘blah,’ the sales cycle takes too long, and lots of deals never close.
</p>
<p>
And you can always feel product/market fit when it is happening. The customers are buying the product just as
fast as you can make it — or usage is growing just as fast as you can add more servers. Money from customers
is piling up in your company checking account. You're hiring sales and customer support staff as fast as you can.
Reporters are calling because they've heard about your hot new thing and they want to talk to you about it.
You start getting entrepreneur of the year awards from Harvard Business School.
Investment bankers are staking out your house.”
</p>
<p>
For me, this was the most vivid definition — and one that I stared at through tears.
</p>
<p>
We had set up shop and started coding Superhuman in 2015. A year later, our team had grown to seven and we were still furiously coding. By the summer of 2017, we had reached 14 people — and we were still coding. I felt intense pressure to launch, from the team and also from within myself. My previous startup, <a target="_blank" rel="noopener nofollow" href="http://rapportive.com/">Rapportive</a>, had launched, scaled and been acquired by LinkedIn in less time. Yet here we were, two years in, and we had not passed go.
</p>
<p>
But no matter how intense the pressure, I wasn’t ready to launch. Common practice would be to "throw it out there and see what sticks,” which may be fine after a few months of effort when the sunk cost is low. But the “launch and see what happens” method seemed irresponsible and reckless to me — especially given the years that that we had invested.
</p>
<p>
<img alt="Rahul Vohra, Founder of Superhuman" src="https://pmfguru.com/assets/blog/Rahul-Vohra-22cbde9d5bf1eefdec11bb9c0b818b2347fbfba9465266a1c73df5333c710d03.jpg">
</p><p><small>Handsome Rahul Vohra, Founder of Superhuman</small>
</p>

<p>
Further compounding the pressure, as a founder, I couldn’t just tell the team how I felt. These super-ambitious engineers had poured their hearts and souls into the product. I had no way of telling the team we weren’t ready, and worse yet, no strategy for getting out of the situation — which is not something they would want to hear. I wanted to find the right language or framework to articulate our current position and convey the next steps that would get us to product/market fit, but was struggling to do so.
</p>
<p>
That’s because the descriptions of product/market fit I found were immensely helpful for companies <em>post-launch</em>. If, after launch, revenue isn’t growing, raising money is tough, the press doesn't want to talk to you and user growth is anemic, then you can safely conclude you don't have product/market fit. But in practice, because of my previous success as a founder, we didn’t have problems raising money. We could have gotten press, but we were actively avoiding it. And user growth wasn't happening because we deliberately choosing not to onboard more users. We were pre-launch — and we didn’t have any indicators to clearly illustrate our situation.
</p>
<p>
The descriptions of product/market fit all seemed so post hoc, so unactionable. I had a clear understanding of where we stood, but I had no way of conveying that to others — and no plan for the part that should come next.
</p>
<p>
So I racked my brain for an answer on how to travel the distance between where Superhuman was and the high bar that we needed to hit. And I eventually started to wonder: <b>what if you could measure product/market fit?</b> Because if you could measure product/market fit, then maybe you could optimize it. And then maybe you could systematically increase product/market fit until you achieved it.
</p>
<p>
Reoriented around this purpose and reinvigorated by the new direction, I set out to reverse engineer a process for getting to product/market fit. Below, I outline the findings that followed, specifically unpacking the clarifying metric that made everything fall into place and the four-step process we used to build an engine that propelled Superhuman forward on the path to finding our fit.
</p>
<h5>
ANCHORING AROUND A METRIC: A LEADING INDICATOR FOR PRODUCT/MARKET FIT
</h5>
<p>
On my quest to understand product/market fit, I read all I could and spoke with every expert I could find. Everything changed when I found Sean Ellis, who ran early early growth in the early days of Dropbox, LogMeIn, and Eventbrite and later coined the term “growth hacker.”
</p>
<div>
<div>
<p>
<h4>
Start measuring your Product/Market Fit
</h4>
<h5>
<small>Built for startups. Setup in 2 minutes.</small>
</h5>
</p>

</div>

</div>
<p>
The product/market fit definitions I had found were vivid and compelling, but they were <em>lagging</em> indicators — by the time investment bankers are staking out your house, you already have product/market fit. Instead, Ellis had found a <em>leading</em> indicator: <b>just ask users “how would you feel if you could no longer use the product?” and measure the percent who answer “very disappointed.”</b>
</p>
<p>
After benchmarking nearly a hundred startups with his customer development survey, Ellis found that the magic number was 40%. Companies that struggled to find growth almost always had less than 40% of users respond “very disappointed,” whereas companies with strong traction almost always exceeded that threshold.
</p>
<p>
... Rest of the story on <a href="https://firstround.com/review/how-superhuman-built-an-engine-to-find-product-market-fit/?utm_source=pmf.guru" target="_blank" rel="noopener nofollow">FirstRound.com</a>
</p>
</div></div>]]>
            </description>
            <link>https://pmfguru.com/superhuman-pmf-engine</link>
            <guid isPermaLink="false">hacker-news-small-sites-24162710</guid>
            <pubDate>Fri, 14 Aug 2020 20:14:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Passed AWS Solutions Architect Associate]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24162669">thread link</a>) | @rishabkumar7
<br/>
August 14, 2020 | https://blog.rishabkumar.com/how-i-passed-aws-solutions-architect-associate-ckdn7bk2200ds3bs1dhgx7kyo | <a href="https://web.archive.org/web/*/https://blog.rishabkumar.com/how-i-passed-aws-solutions-architect-associate-ckdn7bk2200ds3bs1dhgx7kyo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1596984458210/ePpOB5nid.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p><strong>Tick tock. Tick tock.🕐</strong></p>
<p>As the clock ticks on, with a deafening silence we have never known before, like many of us, I didn't want to sit and count those seconds scrolling by.</p>
<p>Time ain't really money (I mean we should have been rich by that logic long time back) but it sure is an opportunity.</p>
<p>So, I decided to put this period of lockdown to unlock more of my potential, by diving into the clouds!</p>
<p>The World of Big Data and Cloud Services</p>
<p>By the end of this sentence, millions and billions of bytes of data would have been sent and received. And every time that happens, there are curious minds waiting to listen to what the data is saying.</p>
<p>This ever-growing avenue led to the concept of Big Data and Cloud Services, which is becoming not just a capability, but a necessity in all fields today.
Cloud is the Captain America version of Steve Rogers, basically on-premise services on steroids. </p>
<p>Like a nineties kid, I watched the big bang of bits and bytes and revolution of the internet.
The next wave is gonna be of big data and cloud services, and this time I want to be right at the centre of it rather than being a kid staring at it with jaw-dropping to the floor.</p>
<p>Becoming an AWS Ninja!</p>
<p>When I decided to jump in the world of cloud services, the first question was to go with which tech on offer?</p>
<p>Simple. I chose AWS.</p>
<h2 id="why-">Why? 🤔</h2>
<p>Well, it's like asking why Tesla is the talk of the town and not GM anymore.
Gartner's famous Magic Quadrant released in July 2019 paints a clear picture that AWS is the lead runner in race of cloud technology.
Azure and Google are definitely catching up, but so is GM and Ford for Tesla (not yet there!)</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/uw4loiyleu6n4c521l3s.png" alt="Alt Text"></p>
<p>Even if you are working towards a promotion, or churn some more dollars, AWS is the skill to have right now.</p>
<h2 id="my-journey-of-aws-certifications-">My journey of AWS Certifications 🚴‍♀️:</h2>
<h3 id="step-1-">Step 1:</h3>
<p>My baby steps on the journey to becoming a certified developer on AWS started with the AWS Cloud Practitioner certification back in November 2019.</p>
<p>So, if you are still working towards that, this article might not be for you. You can check this article out to ace the Practitioner certification.</p>
<h3 id="step-2-">Step 2:</h3>
<p>From thereon, the next thing you need to do is practice. Try to experience AWS first hand. Explore around, learn new stuff and implement what all you need.</p>
<p>For me, working in an environment where the work revolves around cloud services was a blessing as I spent good part of the last year honing my skills on the platform before feeling ready to step up the game.</p>
<p>You can also use the <a target="_blank" rel="noopener" href="https://aws.amazon.com/free/">Free Tier</a>, Amazon provides on AWS to further brush your skills before you jump into the advance stuff.</p>
<h3 id="step-3">Step 3</h3>
<p>Resources I used 📘:</p>
<p>As much as one would love to have a single source for all there is to learn, more often than not we need to club multiple sources to get the most out of them.
For AWS, <a target="_blank" rel="noopener" href="https://acloud.guru/learn/aws-certified-solutions-architect-associate">ACloud Guru's Solutions Architect Associate</a> course and another one by <a target="_blank" rel="noopener" href="https://youtu.be/Ia-UEYYR44s">Andrew Brown on freecodecamp's youtube channel</a> worked the best for me.</p>
<h3 id="step-4">Step 4</h3>
<p>One of the biggest add on for me, was to go through the FAQ's provided by AWS for service's like <a target="_blank" rel="noopener" href="https://aws.amazon.com/s3/faqs/">S3</a>, <a target="_blank" rel="noopener" href="https://aws.amazon.com/ec2/faqs/">EC2</a>, <a target="_blank" rel="noopener" href="https://aws.amazon.com/elasticloadbalancing/faqs/">Load Balancers</a>, <a target="_blank" rel="noopener" href="https://aws.amazon.com/vpc/faqs/">VPC</a>and <a target="_blank" rel="noopener" href="https://aws.amazon.com/route53/faqs/">Route53</a>.
This will help to clear all your doubts and get you better prepared for the test.</p>
<h3 id="step-5-practice-tests">Step 5: Practice Tests</h3>
<p>Nothing sets you up nicely for the real test than the practice tests.
It might be boring, but believe me, they will go a long way as a reality check for you.</p>
<p><a target="_blank" rel="noopener" href="https://www.whizlabs.com/">Whizlabs</a> provides the best tests out there at a minimal cost at $17(may have changed). The 7 practice tests are the seven steps to clearing your test.
In case you have passed the previous AWS certificate for Cloud Practitioner, you are provided with a free practice test and 50% off for the exam fee as well.</p>
<h3 id="step-6-support">Step 6: Support</h3>
<p>I would recommend to join the <a target="_blank" rel="noopener" href="https://www.freecodecamp.org/news/awscertified-challenge-free-path-aws-cloud-certifications/">#AWSCertified</a> challenge and the #100DaysOfCloud. Here is the <a target="_blank" rel="noopener" href="https://discord.gg/dvUh79v">discord for #100DaysOfCloud</a>.
I am available for any doubt clarification or any other stuff you might need.</p>
<h3 id="step-7-notes">Step 7: Notes</h3>
<p>If you just want to refresh your concepts or want to just go through concise notes before the tests, I have posted them <a target="_blank" rel="noopener" href="https://rishabkumar7.github.io/CloudNotes/">here</a> for your reference.</p>
<h3 id="step-8-the-t-day">Step 8: The T-Day</h3>
<p>Well, if you are here, it means you are ready for the test!
Just fill up for the test and in no time you will be a certified AWS Solution Architect.</p>
<p>I took around 15 days to brush up my skills, go through practice tests before I went ahead to ace my test.
It might take a little longer/shorter for you, but following these steps will certainly set you up for the test.</p>
<p>And you can follow me on <a target="_blank" rel="noopener" href="https://twitter.com/rishabk7">Twitter</a> to see my journey in the Cloud☁</p>
<p><strong>Good Luck 👍</strong></p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.rishabkumar.com/how-i-passed-aws-solutions-architect-associate-ckdn7bk2200ds3bs1dhgx7kyo</link>
            <guid isPermaLink="false">hacker-news-small-sites-24162669</guid>
            <pubDate>Fri, 14 Aug 2020 20:10:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Colorize Old Photos with DeOldify]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24162561">thread link</a>) | @aliabd
<br/>
August 14, 2020 | https://www.gradio.app/hub/hub-deoldify | <a href="https://web.archive.org/web/*/https://www.gradio.app/hub/hub-deoldify">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.gradio.app/hub/hub-deoldify</link>
            <guid isPermaLink="false">hacker-news-small-sites-24162561</guid>
            <pubDate>Fri, 14 Aug 2020 20:01:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C# Compiler Strict Mode]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24161969">thread link</a>) | @nwah1
<br/>
August 14, 2020 | https://www.meziantou.net/csharp-compiler-strict-mode.htm | <a href="https://web.archive.org/web/*/https://www.meziantou.net/csharp-compiler-strict-mode.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The C# compilers has some hidden features. Today I've discovered a new compiler option. The author of a <a href="https://github.com/dotnet/runtime/issues/27005">recent issue on GitHub<i></i></a> indicates that the C# compiler allows to compare an <code>IntPtr</code> with <code>null</code>, which at runtime is always false. He suggests the compiler should raise an error in this case. The answer of <a href="https://github.com/sharwell">Sam Harwell<i></i></a> describes a compiler option, <code>/features:strict</code>, to detect this <em>error</em> and a few other potential errors in your code.</p><p>To enable it, you must add <code>&lt;Features&gt;strict&lt;/Features&gt;</code> to your csproj file:</p><pre><code><span><span><span>&lt;</span>Project</span> <span>Sdk</span><span><span>=</span><span>"</span>Microsoft.NET.Sdk<span>"</span></span><span>&gt;</span></span>
  <span><span><span>&lt;</span>PropertyGroup</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>OutputType</span><span>&gt;</span></span>Exe<span><span><span>&lt;/</span>OutputType</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>TargetFramework</span><span>&gt;</span></span>netcoreapp2.1<span><span><span>&lt;/</span>TargetFramework</span><span>&gt;</span></span>
<ins>    <span><span><span>&lt;</span>Features</span><span>&gt;</span></span>strict<span><span><span>&lt;/</span>Features</span><span>&gt;</span></span></ins>
  <span><span><span>&lt;/</span>PropertyGroup</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>Project</span><span>&gt;</span></span></code></pre><p>If your solution has many projects and you want to enable this compiler option for all projects, you can create a file named <code>Directory.Build.props</code> at the root of your solution with the content (<a href="https://docs.microsoft.com/en-us/visualstudio/msbuild/customize-your-build#directorybuildprops-and-directorybuildtargets">MSBuild documentation<i></i></a>):</p><pre><code><span><span><span>&lt;</span>Project</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>PropertyGroup</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>Features</span><span>&gt;</span></span>strict<span><span><span>&lt;/</span>Features</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>PropertyGroup</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>Project</span><span>&gt;</span></span></code></pre><p>Here are some errors that will be reported by using this feature <code>strict</code>:</p><pre><code><span>IntPtr</span> ptr <span>=</span> IntPtr<span>.</span>Zero<span>;</span>
<span>if</span> <span>(</span>ptr <span>==</span> <span>null</span><span>)</span> <span>// Warning CS8073 The result of the expression is always 'false' since a value of type 'IntPtr' is never equal to 'null' of type 'IntPtr?'</span></code></pre><pre><code><span>lock</span> <span>(</span><span>null</span><span>)</span> <span>// Error CS0185 '&lt;null&gt;' is not a reference type as required by the lock statement</span>
<span>{</span>
<span>}</span></code></pre><pre><code><span><span>var</span></span> o <span>=</span> <span>new</span> <span><span>object</span></span><span>(</span><span>)</span><span>;</span>
<span>if</span> <span>(</span>o <span>is</span> <span>Math</span><span>)</span> <span>// Error CS7023 The second operand of an 'is' or 'as' operator may not be static type 'Math'</span>
<span>{</span>
<span>}</span></code></pre><pre><code><span>// In assembly A</span>
<span>public</span> <span>struct</span> <span>S</span>
<span>{</span>
    <span>private</span> <span><span>object</span></span> _f<span>;</span>
<span>}</span>

<span>// In assembly B</span>
<span>public</span> <span>class</span> <span>C</span>
<span>{</span>
   <span><span>void</span></span> <span>M</span><span>(</span><span>)</span>
   <span>{</span>
      <span>S</span> s<span>;</span> <span>// Error CS0165: Use of unassigned local variable 's' (https://github.com/dotnet/roslyn/blob/master/docs/compilers/CSharp/Definite%20Assignment.md#definite-assignment-of-structs-across-assemblies)</span>
   <span>}</span>
<span>}</span></code></pre><pre><code><span>enum</span> <span>Color</span> <span>{</span> Black<span>,</span> Yellow<span>,</span> Red<span>,</span> White <span>}</span>
<span>static</span> <span><span>void</span></span> <span>Bar</span><span>(</span><span>)</span>
<span>{</span>
    _ <span>=</span> <span>1</span> <span>-</span> Color<span>.</span>Red<span>;</span> <span>// Error CS0019: Operator '-' cannot be applied to operands of type 'int' and 'Color'</span>
<span>}</span></code></pre><pre><code><span><span>var</span></span> func <span>=</span> <span>new</span> <span>Func<span>&lt;</span><span>string</span><span>,</span> <span>string</span><span>&gt;</span></span><span>(</span>x <span>=&gt;</span> x<span>)</span><span>;</span>
_ <span>=</span> <span>new</span> <span>Func<span>&lt;</span><span>string</span><span>,</span> <span>string</span><span>&gt;</span></span><span>(</span><span>ref</span> func<span>)</span><span>;</span> <span>// Error CS0149: Method name expected</span></code></pre><pre><code><span>static</span> <span><span>void</span></span> <span>Demo</span><span>(</span><span>out</span> <span>ImmutableArray<span>&lt;</span><span>string</span><span>&gt;</span></span> result<span>)</span> <span>// Error CS0177: The out parameter 'result' must be assigned to before control leaves the current method</span>
<span>{</span>
<span>}</span>

<span>// For more information: https://github.com/dotnet/roslyn/issues/13203</span></code></pre><p>I really hope this flag will be the default behavior in a next release of C#. Maybe they can enable it by default based on the language version of the project. But at the moment you must enable it manually…</p><p>Note that this flag is not documented and not well-known. After the comment on GitHub, the CoreCLR has started a new pull request to use this option in their codebase (<a href="https://github.com/dotnet/coreclr/pull/19191">Fix invalid IntPtr == null comparisons, set strict mode for Roslyn<i></i></a>). It also helps detecting issues in <a href="https://github.com/PowerShell/PowerShell/pull/13383">PowerShell Core<i></i></a>.</p><p>Do you have a question or a suggestion about this post? <a href="https://www.meziantou.net/contact.htm?utm_medium=social&amp;utm_source=web">Contact me!</a></p></div></div>]]>
            </description>
            <link>https://www.meziantou.net/csharp-compiler-strict-mode.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24161969</guid>
            <pubDate>Fri, 14 Aug 2020 19:06:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faster queries on Parquet/ORC nested data in Presto]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24161857">thread link</a>) | @nitramt
<br/>
August 14, 2020 | https://prestosql.io/blog/2020/08/14/dereference-pushdown.html | <a href="https://web.archive.org/web/*/https://prestosql.io/blog/2020/08/14/dereference-pushdown.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article itemscope="" itemtype="http://schema.org/BlogPosting">

<div itemprop="articleBody">
<p><a href="https://prestosql.io/docs/current/release/release-334.html">Presto 334</a>
adds significant performance improvements for queries
accessing nested fields inside struct columns. They have been optimized through
the pushdown of dereference expressions. With this feature, the query execution
prunes structural data eagerly, extracting the necessary fields.</p>

<p><code>RowType</code> is a built-in data type of Presto, storing the in-memory
representation of commonly used nested data types of the connectors, eg.
<code>STRUCT</code> type in Hive. Datasets often contain wide and deeply nested structural
columns, i.e. a struct column having hundreds of fields, with the fields being
nested themselves.</p>
<p>Although such <code>RowType</code> columns can contain plenty of data, most of the
analytical queries access just a few fields out of it. Without dereference
pushdown, Presto scans the whole column, and shuffles all that data around
before projecting the necessary fields. This suboptimal execution causes higher
CPU usage, higher memory usage and higher query latencies, than required. The
unnecessary operations get even more expensive with wider/deeper structs and
more complex query plans.</p>
<p>LinkedIn’s data ecosystem makes heavy usage of nested columns. It is common to
have 2-3 levels of nesting, and up to 50 fields in most of our tracking tables.
Because of the query execution inefficiency for nested fields, ETL pipelines
were set up at LinkedIn to copy the nested columns as a set of top-level columns
corresponding to subfields. This step added overhead in our ingestion process
and delayed data availability for analytics. It also caused ORC schemas to be
inconsistent with the rest of the infrastructure, making it harder to migrate
from existing flows on row-oriented formats.</p>
<p>Similarly, Lyft’s schemas make heavy use of nested data to decompose a ride
into its routes, riders, segments, modes, and geo-coordinates. Prior to the
performance improvements, analytical queries would either need to be run on
clusters with very long timeouts, or the data would have to be flattened before
being analyzed, adding an extra ETL step. Not only would this be costly, it
would also cause the original schema to diverge in our data warehouse making it
more difficult for data scientists to understand.</p>
<p>The dereference pushdown optimization in Presto is having a massive impact on
the ingestion story at both LinkedIn and Lyft. Nested data is now being made
available faster for consumption with a consistency of structure across all
stores, while maintaining performance parity for analytical queries.</p>

<p>Say we have a Hive table <code>jobs</code>, with a struct-typed column <code>job_info</code> in the
schema. The column <code>jobs</code> is wide and deeply nested, i.e. <code>ROW(company
varchar, requirements ROW(skills array(...), education ROW(...), salary ...) ,
...)</code>. Most queries would access a small percentage of data from this struct
using the dereference projection (the <code>.</code> operation). Consider such a query <code>Q</code>
below.</p>
<div><div><pre><code><span>SELECT</span> <span>A</span><span>.</span><span>appid</span> <span>id</span><span>,</span> <span>J</span><span>.</span><span>job_info</span><span>.</span><span>company</span> <span>c</span>
<span>FROM</span> <span>applications</span> <span>A</span> <span>JOIN</span> <span>jobs</span> <span>J</span>
<span>ON</span> <span>A</span><span>.</span><span>jobid</span> <span>=</span> <span>J</span><span>.</span><span>jobid</span>
<span>LIMIT</span> <span>100</span>
</code></pre></div></div>
<p>It should suffice to scan only one field <code>company</code> from <code>J.job_info</code> for
executing this query. But, without dereference pushdown, Presto scans and
shuffles everything from <code>job_info</code>, only to project a single field at the end.</p>
<p><img src="https://prestosql.io/assets/blog/dereference-pushdown/original_plan.png" alt=""></p>

<p>With dereference pushdown, Presto optimizes queries by extracting the sufficient
fields from a <code>ROW</code> as early as possible. This is enforced by modifying the
query plan through a set of optimizers, and can be broadly divided into two
parts.</p>
<p>First, dereference projections are extracted in the query plan and pushed as
close to the table scan as possible. This happens independent of what the
connector is. Secondly, there is a further improvement for Hive tables. The
Hive Connector and ORC/Parquet readers have been optimized to scan only the
sufficient subfield columns.</p>
<p>Pushdown of predicates on the subfields is also a crucial optimization. For
example, if a query has filters on subfields (i.e. <code>a.b &gt; 5</code>), they should be
utilized by ORC/Parquet readers while scanning files. The pushdown helps with
the pruning of files, stripes and row-groups based on column-level statistics.
This optimization is achieved as a byproduct of the above two optimizations.</p>
<p>With the dereference pushdown, queries observe significant performance gains in
terms of CPU/memory usage and query runtime, roughly proportional to the
relative size of nested columns compared to the accessed fields.</p>
<h2 id="pushdown-in-query-plan">Pushdown in Query Plan</h2>
<p>The goal here is to execute dereference projections as early as possible. This
usually means performing them right after the table scans.</p>
<p>A projection operation that performs dereferencing on input symbols (i.e.
<code>job_info.company</code>) reduces the amount of data going up the plan tree. Pushing
dereference projections down means that we are pruning data early. It reduces
the amount of data being processed and shuffled in query execution. For the
example query <code>Q</code>, the query plan looks like the following when dereference
pushdown is enabled.</p>
<p><img src="https://prestosql.io/assets/blog/dereference-pushdown/transformed_plan.png" alt=""></p>
<p>The projection <code>job_info.company</code> now directly follows the scan of <code>jobs</code> table,
avoiding the propagation the <code>job_info</code> through <code>Limit</code> and <code>Join</code> nodes. Note
that all of <code>job_info</code> is still being scanned, and pruning it in the reader
requires connector-dependent optimizations.</p>
<h2 id="pushdown-in-the-hive-connector">Pushdown in the Hive Connector</h2>
<p>In columnar formats like ORC and Parquet, the data is laid out in a columnar
fashion even for subfields. If we have a column <code>STRUCT(f1, f2, f3)</code>, the
subfields <code>f1</code>, <code>f2</code> and <code>f3</code> are stored as independent columns. An optimized
query engine should only scan the required fields through its ORC reader,
skipping the rest. This optimization has been added for Hive connector.</p>
<p>Dereference projections above a <code>TableScanNode</code> are pushed down in the Hive
connector as “virtual” (or “projected”) columns. The query plan is modified to
refer to these new columns. For the query <code>Q</code>, <code>jobs</code> table would be scanned
differently with this optimization, as shown below. The projection is now
embedded in the Hive connector. Here, <code>job_info#company</code> can be thought of as
a virtual column representing the subfield <code>job_info.company</code>.</p>
<p><img src="https://prestosql.io/assets/blog/dereference-pushdown/connector_pushdown.png" alt=""></p>
<p>The Hive connector handles the projections before returning columns to Presto’s
engine. It provides the required virtual columns to format-specific readers.
ORC and Parquet readers optimize their scans based on subfields required,
increasing their read throughput. Subfield pruning is not possible for
row-oriented format readers (e.g. AVRO). For them, Hive connector performs
adaptation to project the required fields.</p>
<h2 id="pushdown-of-predicates-on-subfields">Pushdown of Predicates on Subfields</h2>
<p>Columnar formats store per-column statistics in the data files, which can be
used by the readers for filtering. eg. if a query contains filter <code>y = 5</code> for a
top-level column <code>y</code>, Presto’s ORC reader can skip ORC stripes and files by
looking at the upper and lower bounds for <code>y</code> in the statistics.</p>
<p>The same concept of predicate-based pruning can work for filters involving
subfields, since the statistics are also stored for subfield columns. i.e.
Presto’s ORC/Parquet reader should be able to filter based on a constraint like
<code>x.f1 = 5</code> for more optimal scans. Good news! In the final optimized plan,
predicates on a subfield are pushed down to the hive connector as a constraint
on the corresponding virtual column, and later used for optimizing the scan.
The complete logic is a bit complicated to explain here, but can be illustrated
through the following example.</p>
<p>Given an initial plan with a predicate on a dereferenced field (<code>x.f1 = 5</code>), a
chain of optimizers transform it to a more optimal plan with reader-level
predicates. In the future, the same optimization will be added to the Parquet
reader.</p>
<p><img src="https://prestosql.io/assets/blog/dereference-pushdown/predicate_pushdown.png" alt=""></p>
<p>In the final plan, Hive connector knows to scan the column <code>y</code> and the subfield
<code>x.f1</code>. It also takes advantage of the “virtual” column constraint <code>x#f1 = 5</code>
for reader-level pruning.</p>
<h2 id="performance-improvement">Performance Improvement</h2>
<p>Dereference pushdown improves performance for queries accessing nested fields
in multiple ways. First, it increases the read throughput for table scans,
reducing the CPU time. The pruning of fields during the scan also means lesser
data to process for all downstream operators and tasks. So the early
projections result in more optimal execution for any operations that involve
shuffle or copy of data. Moreover, for ORC/Parquet, the read performance
improves in the case of selective filters on subfields.</p>
<p>Below are some experimental results on a production dataset at LinkedIn which
contains 3 <code>STRUCT</code> columns, having ~20-30 small subfields in each. The
example queries used in the analysis access only a few subfields. The queries
have been listed as their approximate query shape for the sake of brevity. The
plots compare CPU usage, peak memory usage and averaged query wall time.</p>

<p><img src="https://prestosql.io/assets/blog/dereference-pushdown/runtime_perf.png" alt=""></p>
<p>CPU usage and peak memory usage show orders-of-magnitude improvement in
presence of dereference pushdown. Query wall times also reduce considerably,
and this improvement is more drastic for the relatively complex <code>JOIN</code> query,
as expected.</p>
<p>Please note that these are not benchmarks! The performance improvement you’ll
see will vary depending on how many columns are contained in your nested data
versus how many you’ve referenced. At Lyft we saw improvements of <code>50x</code> for some
queries!</p>
<h2 id="future-work">Future Work</h2>
<p>The pushdown of dereference expressions can be extended to arrays. i.e.
dereference operations applied after unnesting an array should also get pushed
down to the readers. For example, using our jobs table from before, our
<code>jobs.job_info</code> structure may contain a repeating structure such as
<code>required_skills</code>. With the following query, the entire required_skills
structure would be read even though only a small part of it is being referenced.</p>
<div><div><pre><code><span>SELECT</span> <span>S</span><span>.</span><span>description</span>
<span>FROM</span> <span>jobs</span> <span>J</span>
<span>CROSS</span> <span>JOIN</span> <span>UNNEST</span> <span>(</span><span>job_info</span><span>.</span><span>required_skills</span><span>)</span> <span>S</span>
<span>WHERE</span> <span>S</span><span>.</span><span>years_of_experience</span> <span>&gt;=</span> <span>2</span>
</code></pre></div></div>
<p>The work for this improvement is being tracked in <a href="https://github.com/prestosql/presto/issues/3925">this issue</a>.</p>
<p>Similar to Hive Connector, connector-level dereference pushdown can be extended
to other connectors supporting nested types.</p>
<p>Another future improvement will be the pushdown of …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://prestosql.io/blog/2020/08/14/dereference-pushdown.html">https://prestosql.io/blog/2020/08/14/dereference-pushdown.html</a></em></p>]]>
            </description>
            <link>https://prestosql.io/blog/2020/08/14/dereference-pushdown.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24161857</guid>
            <pubDate>Fri, 14 Aug 2020 18:58:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[8 Tips for Attending Virtual Conferences]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24161519">thread link</a>) | @vmbrasseur
<br/>
August 14, 2020 | https://www.fosslife.org/8-tips-attending-virtual-conferences | <a href="https://web.archive.org/web/*/https://www.fosslife.org/8-tips-attending-virtual-conferences">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              <div>
                <div id="region--article-content">
                  <div>

  <div>
          
            
              
      <div>
              <div>  <div>
          
            <div><p>It's conference season…virtually speaking. The health and safety of our community are more important than anything else, which means in-person events are a no-go in 2020 (and likely beyond). Rather than canceling, most tech events in 2020 have decided to go online. These very virtual venues aren't the only change. If you've attended conferences before, you're in for a completely different experience with an online event.</p>

<p>How can you make the most of this new world of virtual conferences? We have eight tips to help get you started.</p>

<ol><li><strong>Understand your goals.</strong> Before attending, make sure you know what you want to get out of the event. So many people attend conferences on autopilot. "It's just what you do" is not a valid reason for spending your valuable time. Think it through first.</li>
	<li><strong>Be selective.</strong> If you're there for training, select talks that will be most helpful for moving you toward your goals. This isn't different from an in-person event, but it's something I find few people actually do. Plan to spend your time on the things that matter most for you.</li>
	<li><strong>Adjust your expectations.</strong> If you're there for networking, you might be disappointed. Most online conferences fall short on this element. It's nearly impossible for online events to duplicate the serendipitous experience of walking around and hanging out at an in-person event. Most attempts to do so feel contrived at best and worryingly like Chatroulette at worst, leaving them ripe for abuse.</li>
	<li><strong>Be respectful.</strong> Speaking of abuse, don't be That Guy in the session chatroom. Just because typing in the chat may not interrupt the speaker's delivery, it doesn't give you license to type a bunch of “well actually”s during their session. The session chat is not the place to show off your knowledge or bring up a pet project that you feel the speaker should have mentioned. Just like at in-person events, legitimate questions are welcome but comments are not. If you want to show off your knowledge, do it the way the speaker did: by doing the hard work of getting a proposal accepted then writing and delivering a good talk.</li>
	<li><strong>Branch out.</strong> Because nearly every conference seems to be going virtual right now, you may find that these online events give you the opportunity to test the waters in a conference you'd never otherwise attend. Want to learn more about technical writing? Accessibility? Product management? HR? Robotics? Whatever the topic, you can find an online conference for it. A few introductory sessions may give you a lot of valuable perspective on other roles and industries.</li>
	<li><strong>Take a break.</strong> Many people find all-day video conferences even more exhausting than the real-life version of the event. Remember: You don't need to attend a session in every time slot. Take care of yourself by taking breaks to go for a walk, play with your pets or kids, stretch, read comic books, or whatever helps you relax. You'll get a lot more out of the event this way.</li>
	<li><strong>Make the format work for you.</strong> A lot of video conferencing systems allow you to join the video on one device and the audio on another, such as your phone. This can be really helpful to battle conference fatigue because, by using your phone for the audio, you're no longer chained to your workspace and can move around without missing much. At a real-life conference, it's typically bad form to move around a lot in the middle of a session, but not so when the event is virtual, and using your phone for the audio can maximize your flexibility in this regard. In a virtual conference, it's perfectly fine to go get another cup of tea, walk around the room, or take a bathroom break (just make sure you're on mute).</li>
	<li><strong>Choose wisely.</strong> The best conference may be the one you never attend. If you don't feel you'll be able to meet your goals or have a good experience at an online event, don't attend it. You may be able to select the content that's best for your needs by viewing recordings of talks or by setting up online networking video chats with colleagues and fellow community members.</li>
</ol></div>
      
      </div>
</div>
          </div>
  
      </div>
</div>
                </div>
              </div>
            </div>
          </div></div>]]>
            </description>
            <link>https://www.fosslife.org/8-tips-attending-virtual-conferences</link>
            <guid isPermaLink="false">hacker-news-small-sites-24161519</guid>
            <pubDate>Fri, 14 Aug 2020 18:31:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vectorized mentoring students in Distributed Systems]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24161249">thread link</a>) | @rusrushal13
<br/>
August 14, 2020 | https://vectorized.io/scholarship/ | <a href="https://web.archive.org/web/*/https://vectorized.io/scholarship/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div color="hsla(0, 0%, 100%, 1.0)"><section><p>Starting in September we are formally launching our Hack The Planet Scholarship. This scholarship is intended for Black, Latinx and all other underrepresented groups in technology wanting to work on distributed systems. The scholarship program is meant to support people hacking on a distributed-systems related project over a 4 month period.</p><p>The most valuable part of our scholarship will be your support system. Scholarship recipients will receive $1500/month, weekly 1-1 mentorship from our most senior staff engineers (some of us have worked on the largest systems in the world), monthly 1-1 with the CEO, code review and design review to hack on any project you want, preferably open source projects.</p><h2>h4x::73h::pl4n37 Process</h2><p>Scholarship requirements:</p><p>Must know basic programming in any of C++, Go, C, Javascript, Java (the programming languages our team is highly skilled in)</p><p>Write a proposal for a project that you want to hack on for 3-4 months and answer the following questions:</p><ol><li>Why you - Tell us your story (Github profile encouraged)</li><li>How/Where we can help you the most<ol><li>Project</li><li>Summary</li></ol></li><li>Why you want to hack on this project</li><li>Send us the application to hacktheplanet@vectorized.io</li></ol><p>The project must involve 2 or more computers trying to achieve a task (save data, replicate files, etc). The project should be challenging for you and should scope 3-4 months of work. Most importantly, we want you to have fun on the project knowing you have an amazing network of mentors to help you when you get stuck.</p><p>Limited to US residents at the moment. Special Thanks to our friends Jaren Glover &amp; Chris Heller, as well as our team members Sarah, David, Noah &amp; Denis, for reviewing earlier drafts.</p><hr><small>[1] Check out our friends at seasons.nyc&nbsp;<a rel="stylesheet" href="https://blog.seasons.nyc/creative-project" target="_blank">https://blog.seasons.nyc/creative-project</a> to work on a design grant.</small></section></div></div>]]>
            </description>
            <link>https://vectorized.io/scholarship/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24161249</guid>
            <pubDate>Fri, 14 Aug 2020 18:09:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I am a Mozilla employee, AMAA]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24160924">thread link</a>) | @URfejk
<br/>
August 14, 2020 | https://tildes.net/~tech/ra8/i_am_a_mozilla_employee_amaa | <a href="https://web.archive.org/web/*/https://tildes.net/~tech/ra8/i_am_a_mozilla_employee_amaa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hi everybody, happy Friday! I am Aaron Klotz, a Staff Software Engineer on the GeckoView team at Mozilla Corporation.</p>
<p>I have worked at Mozilla since the fall of 2012 and have worked on three different teams across that time: Performance, Platform Integration &amp; Security Hardening, and finally GeckoView.</p>
<p>Given the recent news about layoffs, I thought it might be cathartic to do an AMA to share my experiences at Mozilla and try to set the record straight the best that I can. I would not dare try this in other forums, but since the Tildes community is capable of civil discussion, I'll do it here! I provided some proof a long time ago when I first joined Tildes, and I'd like to think that many people in this community are willing to vouch for me at this point, but if you want more, I can add it.</p>
<p>Obviously I cannot discuss issues that are covered by my NDA (but fortunately most issues are <em>not</em> covered), and some details I might want to avoid out of sensitivity for people who were laid off. AMAA!</p>
<p><strong>EDIT 1:</strong> Also to make clear (if it wasn't obvious): These opinions are mine and mine alone, do not reflect the opinion of any Mozilla entity, etc. etc.</p>
<p><strong>EDIT 2:</strong> I'm logging off for the night, but I'll try to follow up throughout the weekend if I have time. Thanks for all the questions! Hopefully I've cleared up some things for you!</p>
</div></div>]]>
            </description>
            <link>https://tildes.net/~tech/ra8/i_am_a_mozilla_employee_amaa</link>
            <guid isPermaLink="false">hacker-news-small-sites-24160924</guid>
            <pubDate>Fri, 14 Aug 2020 17:48:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[School District Affects Your Home's Value]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24160828">thread link</a>) | @dollartrak
<br/>
August 14, 2020 | https://www.dollartrak.com/are-school-districts-worth-it-when-buying-a-home/ | <a href="https://web.archive.org/web/*/https://www.dollartrak.com/are-school-districts-worth-it-when-buying-a-home/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>I remember shopping for my first house with my wife and ignoring the school zones and their ratings.  We were solely concentrating on price, square footage, location and appearance.  </p>



<p>While these are all important considerations to take when buying a house, the quality of the schools should have been a big part of it as well.  We didn’t really realize this until it was a bit too late and we had already made a purchase in a bad school district. </p>



<h2>Why would you even ignore school districts?</h2>



<p>Those of you that are new to real estate may wonder why we would ignore it at all.  The reason is simple, price!  It is not uncommon in my city to see a 20% price difference in identical houses in the same general area <a rel="noreferrer noopener" href="https://www.realtor.com/advice/buy/the-right-school-district-how-much-do-schools-affect-real-estate-prices/" target="_blank">based on the school district</a>.</p>



<p>The school district a house is in can be the difference between the house costing $400,000 and $500,000.  It is easy to say “I am not paying $100,000 extra for the same house in a different school district”.</p>



<p>This seems like the reasonable thing to do but it is a false economy.  Your house will become one of your most valuable <a href="https://www.dollartrak.com/2020/05/22/assets-explained/">assets</a> so you owe it to yourself to do a bit more research.  </p>



<h2>How Much Does That Savings Really Cost Me?</h2>



<p>I never asked myself this question until my oldest child was getting close to school age.  Then I sat down and did the math.</p>



<h4>Private School Tuition</h4>



<p>If you plan on having children then I would suggest calling a few of the local private schools and inquiring about their tuition.  In my case private school tuition was around $15,000 per year for each kid!  To make matters worse tuition was rising at rates over 5% a year.</p>



<p>I did some <a href="https://www.dollartrak.com/time-value-of-money/">time value of money</a> calculations on the tuition costs for my two children and 13 years of K-12 private school education for each.  Not accounting for the inflation of prices, each child was going to cost me $195,000 apiece in tuition.  With 5% growth the actual number was <em>over $265,000 for each child</em> through high school!</p>



<p><em>That $100,000 savings on the purchase price of the house was going to cost me over half a million dollars over 13 years.</em></p>



<p>This money would be far better utilized by <a href="https://www.dollartrak.com/college-529-savings-goal/">investing in a 529 plan</a> and using it to pay for a great college education.</p>



<h4>Education is always in demand</h4>



<p>We decided that the poor schools in my area were a cost we were not willing to bear.  We decided to change houses.  </p>



<p>Of course this comes with the huge expense of selling a house where you can lose up to 10% of your house value in fees, expenses, commissions, and closing costs.  This cost around $40,000 in our case.  </p>



<p>On top of that, we found out the hard way that houses in poor school districts are harder to sell while good school district homes can be somewhat recession proof.  In a cool market it took us longer and cost more discounts to unload our old house than expected.  At the same time we had to get into bidding wars on houses in top school districts.</p>



<h4>You can’t sell a diploma but you can sell a house</h4>



<p>When your kids graduate from high school you can always sell the house to get your money back.  Many people want to downsize by this point in their life anyhow.  Since education will still be in demand, you can always sell the house to recoup the extra money you spent.</p>



<p>As the population in our area grew but the number of quality schools stayed the same there was evidence that appreciation of home values were actually higher in good school district areas.  This is likely very local market oriented so you will need to do your own research here.</p>



<h4>What if I don’t and won’t have kids</h4>



<p>I would still consider it even if you don’t plan on needing schools.  Demand was more stable and appreciation rates higher in my area which made it a good financial decision for me even without the private school tuition savings.  </p>



<p>It has been my experience that when people buy into an area based on the quality of schools, parks, etc, they tend to be very motivated to maintain and improve the community.  This just means a better place to hang your hat.</p>



<h4>What if we want to do private school anyhow</h4>



<p>Many people will want to send their kids to private school regardless of the quality of public schools in their area.  What I found was that quality public schools in the area help control the price of private schools in the area.</p>



<p>In a community with bad public schools, private schools can charge whatever they want and people will pay it.  In a community with good public options, private schools have some limitations over what they can get away with.  </p>



<p>It is probably a good idea to do some basic research and check the tuition rates of some private school options.  For my situation they were significantly cheaper in the area with great public schools.</p>



<h4>What about risks to my investment</h4>



<p>Buying in a great school district is not totally risk free.  The schools could devolve in your district and change from an asset to a liability.  I personally don’t see this as a major risk though, as I mentioned earlier the people that buy there are invested in maintaining the community and schools.  If anything, I think the risk of the community falling apart while you live there is lower.</p>



<p>The other way you can be impacted is if you are re-zoned into a different district.  This can be a real risk if you have areas with poor schools adjacent to areas with good schools.  You can get rezoned into a poor school district.  Research how often the schools in the area redistrict.  Moving very close to the school itself can help reduce the risk you are rezoned.</p>



<h2>Conclusion</h2>



<p>I wish I had known then what I know now.  I could have saved myself a lot of hassle and tens of thousands of dollars.  While it may seem like a steep price to pay to get into a good school district, it is often worth it.  </p>



<p>If you don’t ever end up having kids you should at least break even on the purchase difference.  </p>



<p>If you do have kids it will probably save you hundreds of thousands of dollars over the course of their education as well as give you better and easier sales options when you decide to move on. </p>

			</div></div>]]>
            </description>
            <link>https://www.dollartrak.com/are-school-districts-worth-it-when-buying-a-home/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24160828</guid>
            <pubDate>Fri, 14 Aug 2020 17:38:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Foolproof, Hands-On Docker Tutorial – Hitchhiker's Guide to the Containers]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24160274">thread link</a>) | @fazlerocks
<br/>
August 14, 2020 | https://blog.antoniolofiego.com/the-hitchhikers-guide-to-the-containers-a-foolproof-hands-on-docker-tutorial-part-2-ckdlu8yge04y6zzs14qgz76go | <a href="https://web.archive.org/web/*/https://blog.antoniolofiego.com/the-hitchhikers-guide-to-the-containers-a-foolproof-hands-on-docker-tutorial-part-2-ckdlu8yge04y6zzs14qgz76go">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>Welcome to Part 2 of my shameless attempt at explaining Docker to beginners. I struggled so you don't have to!</p>
<p>In last week's <a target="_blank" rel="noopener" href="https://blog.antoniolofiego.com/the-hitchhikers-guide-to-the-containers-a-foolproof-hands-on-docker-tutorial-part-1-ckdc4tni0031759s14z0pdd2j">article</a> we covered what Docker is, some of its jargon, and why it outperforms VMs in many use cases in today's typical software development lifecycle. This week we'll go deeper into running Docker on our machines, all while figuring out the most interesting and useful underlying technicalities.</p>
<p><img src="https://media.giphy.com/media/3aGZA6WLI9Jde/giphy.gif" alt="Let's go!"></p>
<h2 id="getting-started-with-docker">Getting started with Docker</h2>
<p>If you don't have Docker installed on your machine, head over to the <a target="_blank" rel="noopener" href="https://docs.docker.com/get-docker/">Docker Download page</a> to get the version that will work on your system.</p>
<p>The Linux version is the easiest to install, given that Docker is built off of Linux utilities. On Mac and Windows, on the other hand, there are two main ways of using Docker:</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://docs.docker.com/desktop/">Docker Desktop</a>
The newer and recommended version of Docker. It is a native solution that works directly along with your OS's processes, so we are free to interface with Docker with your favorite terminal and your favorite IDE/text editors.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://docs.docker.com/toolbox/overview/">Docker Toolbox</a>
This is an old version for machines that don't meet the minimum requirements for Docker Desktop. It is not a native solution as it runs on VirtualBox, so we are forced to use the tools that the Toolbox comes packaged with, making everything more cumbersome and prone to errors.</p>
</li>
</ul>
<p>The main catch is that Docker Desktop is not easy to install on every system. While it is straightforward on macOS 10.13+ and Windows 10 Pro, the Windows 10 Home version needs extra attention.</p>
<p>Docker Desktop on Windows leverages Hyper-V, which is Microsoft's Type 1 hypervisor and only available on Windows 10 Pro, Enterprise, and Education. Fortunately, Windows Home supports <strong>Windows Subsystem for Linux</strong> (WSL), a Linux kernel developed by Microsoft that allows us to run Linux processes to run natively without emulation. Since March 2020, Docker Desktop supports WSL version 2 as a backend on Windows Home.</p>
<p>To install Docker Desktop on Windows Home we need to install WSL2 first, then install Docker Desktop specifying WSL2 as the backend during the installation process. we can find the whole process to install WSL2 <a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">here</a> and the subsequent Docker Desktop installation process <a target="_blank" rel="noopener" href="https://docs.docker.com/docker-for-windows/install-windows-home/">here</a>. If you would like to see a walkthrough video of the installation process, let me know and I will work on making one available.</p>
<p>Once installed, we can open our favorite terminal and check that the installation went smoothly by typing</p>
<pre><code>docker --version
</code></pre>
<p>If this returns something the likes of</p>
<pre><code>Docker version 19.03.12, build 48a66213fe
</code></pre>
<p>we are good to go!</p>
<p><strong>Note</strong>: In case you are unable to make it work on your machine or if you don't want to install anything yet, Docker also offers <a target="_blank" rel="noopener" href="https://www.docker.com/play-with-docker">online playgrounds</a> to run your code and everything you find in this tutorial would work the same.</p>
<h2 id="let-s-run-our-first-container-">Let's run our first container!</h2>
<p>As we saw last week, to run a container we first need to find an image on the Docker registry. Like everything in the programming, Docker has a Hello World container that we can easily get from its Docker Hub <a target="_blank" rel="noopener" href="https://hub.docker.com/_/hello-world">page</a>. As we can see on the website, the command we have to run is</p>
<pre><code>$ docker pull hello-world
</code></pre>
<p>which will welcome us with an unsightly wall of output which looks like</p>
<pre><code>Using default tag: latest
latest: Pulling from library/hello-world
0e03bdcc26d7: Pulling fs layer
0e03bdcc26d7: Verifying Checksum
0e03bdcc26d7: Download complete
0e03bdcc26d7: Pull complete
Digest: sha256:49a1c8800c94df04e9658809b006fd8a686cab8028d33cfba2cc049724254202
Status: Downloaded newer image for hello-world:latest
docker.io/library/hello-world:latest
</code></pre>
<p>We can see a few things that we need to cover, namely <strong>tags</strong> and <strong>layers</strong>.</p>
<p>We can check all the images that we have in our machine simply by running <code>$ docker images</code> and inspecting its output:</p>
<pre><code>REPOSITORY       TAG        IMAGE ID        CREATED           SIZE
hello-world      latest     bf756fb1ae65    7 months ago      13.3kB
</code></pre>
<p>We can see that we have a <code>hello-world</code> image tagged latest, with a unique image ID (yours may be different) and it weighs only 13.3KB! That is where the gold is! Running a similar basic job using a VM would entail installing an entire OS just to output "Hello world!".</p>
<p>The first column of the <code>docker images</code> output is called <strong>repository</strong>. If you have ever used Git or GitHub, the name might sound familiar. In a Docker Registry, a repository is a collection of different versions of images that share the same base name. Each of the versions is identified by a <strong>tag</strong>, but images can have multiple tags as well!</p>
<p>In general, Docker images follow the naming convention of <code>username/repository:tag</code>. As a quick example, let's suppose that I built an image called <code>mysimpleapp</code> and I shared version 1.0 on the Docker Hub. You could get that image by running</p>
<pre><code>$ docker pull antoniolofiego/mysimpleapplication:1.0
</code></pre>
<p>If we do not specify the tag portion, Docker will by default download the image that is tagged as <code>latest</code>. This is not a special tag, but just the one that Docker assigns by default to images when no other tags are specified at build time.</p>
<p>Now that we have the image locally, we want to run it, right? Surely enough, the command to run images is <code>$ docker run &lt;image&gt;</code>. There are mainly three ways to reference an image:</p>
<ul>
<li><strong>By repository</strong>, but it works only if we have a single version of the image (ex: if I have two versions from the same repository, Docker will be confused about which I am referring to).</li>
<li><strong>By repository/tag combination</strong>, which solves the previous problem.</li>
<li><strong>By image ID</strong>, the preferred way, given that every image will always have a unique ID. Note, we can use just the first few characters from the ID and Docker will pick up the correct one.</li>
</ul>
<p>Using the Image ID method, for our <code>hello-world</code> image example we will run</p>
<pre><code>$ docker run bf756
Hello from Docker!
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    (amd64)
 3. The Docker daemon created a new container from that image that runs the executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.

To try something more ambitious, you can run an Ubuntu container with:
 $ docker run -it ubuntu bash

Share images, automate workflows, and more with a free Docker ID:
 https://hub.docker.com/

For more examples and ideas, visit:
 https://docs.docker.com/get-started/
</code></pre>
<p>We have successfully pulled and run our first Docker Image! 🎉 Let's recap all we learned so far by visualizing a repository structure and all the ways to pull or run an image in a simple way</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1596760605560/zssexvySE.png?auto=format&amp;q=60" alt="Repo structure"></p>
<p>We know how to pull and run simple images! We just scratched the Docker surface, however. Are you ready to go to the next level?</p>
<p><img src="https://miro.medium.com/max/570/0*y8AuUHSoTGRqX40h.jpeg" alt="We need to go deeper!"></p>
<h2 id="breaking-down-a-docker-image">Breaking down a Docker Image</h2>
<p>We know from last week that a Docker Image starts as a Dockerfile, which is a recipe that Docker follows to package our application. It is composed of a series of <code>[action]</code> <code>[target]</code> commands, each of which specifies a command that Docker needs to run in sequential order.</p>
<p>Let's take a look at a Dockerfile that deploys a simple Node.js Express server and try to understand how it works.</p>
<p><strong>Note:</strong> You can download all the code from this example via <a target="_blank" rel="noopener" href="https://github.com/antoniolofiego/hashnode-dockerseries-expressapp">this</a> GitHub repository.</p>
<p>The folder structure for this example is as follows</p>
<pre><code>📦docker-express-app
 ┣ 📂src
 ┃ ┗ 📜server.js
 ┣ 📜.gitignore
 ┣ 📜Dockerfile
 ┣ 📜package-lock.json
 ┗ 📜package.json
</code></pre>
<p>As we can see, the Dockerfile sits at the root level of my project folder. Let's now look at its content.</p>
<pre><code>FROM node:11-alpine

RUN mkdir app

WORKDIR /app

COPY . .

RUN npm install

CMD ["npm", "run", "start"]
</code></pre>
<p>Let's go through each step one by one:</p>
<ol>
<li><p><code>FROM node:11-alpine</code> tells Docker to download the Docker image for Node.js version 11 running on Linux Alpine, a very lightweight Linux distribution. This will be the base image used by our container.</p>
</li>
<li><p><code>RUN mkdir app</code> creates a local folder named <code>app</code> at the root of the environment.</p>
</li>
<li><p><code>WORKDIR /app</code> changes the working directory for all subsequent commands to the <code>/app</code> folder that we created in step 2.</p>
</li>
<li><p><code>COPY . .</code> tells Docker to copy all the files in the current folder on my machine (my <code>docker-express-app</code> folder) in the current directory of the Docker image (the <code>/app</code> directory).</p>
</li>
<li><p><code>RUN npm install</code> installs all the dependencies that I specified in my <code>package.json</code> file, in this case only <code>express</code>.</p>
</li>
<li><p><code>CMD ["npm", "run", "start"]</code> is the command that the container will run at instantiation time, in this case, the <code>start</code> script defined in <code>package.json</code>.</p>
</li>
</ol>
<p>The next step is to build the image. As you can imagine, we have a <code>docker build</code> command that does just that! The standard usage for the build command is</p>
<pre><code>docker build -t &lt;username/repository:tag&gt; &lt;path/to/Dockerfile&gt;
</code></pre>
<p>Remember that, when tagging an image, if we only provide a repository name Docker will assign the <code>latest</code> tag to the image by default. Let's take a look at the output.</p>
<pre><code>$ docker build -t docker-express-app .
Sending build context to Docker daemon  2.013MB
Step 1/6 : FROM node:11-alpine
 ---&gt; f18da2f58c3d
Step 2/6 : RUN mkdir app
 ---&gt; Running in 37513fc60556
Removing intermediate container 37513fc60556
 ---&gt; 13ee4d6cccbc
Step 3/6 : WORKDIR /app
 ---&gt; Running in 45e51ade37c0
Removing intermediate container 45e51ade37c0
 ---&gt; 579c23501f62
Step 4/6 : COPY . .
 ---&gt; a3527fb353c6
Step 5/6 : RUN npm install
 ---&gt; Running in f4ab1726f363
audited 50 packages in 0.855s
found 0 vulnerabilities

Removing intermediate container f4ab1726f363
 ---&gt; 8f2c4645e536
Step 6/6 : CMD ["npm", "run", "start"]
 ---&gt; Running in b5739c39b3cf
Removing intermediate container b5739c39b3cf
 ---&gt; ac715302eade
Successfully built ac715302eade
Successfully tagged docker-express-app:latest
</code></pre>
<p>As we can see, each instruction is carefully followed. On each step, Docker creates a <strong>layer</strong>. Every image is built out of several read-only layers, with each layer corresponding to certain instructions in your Dockerfile. Each step builds …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.antoniolofiego.com/the-hitchhikers-guide-to-the-containers-a-foolproof-hands-on-docker-tutorial-part-2-ckdlu8yge04y6zzs14qgz76go">https://blog.antoniolofiego.com/the-hitchhikers-guide-to-the-containers-a-foolproof-hands-on-docker-tutorial-part-2-ckdlu8yge04y6zzs14qgz76go</a></em></p>]]>
            </description>
            <link>https://blog.antoniolofiego.com/the-hitchhikers-guide-to-the-containers-a-foolproof-hands-on-docker-tutorial-part-2-ckdlu8yge04y6zzs14qgz76go</link>
            <guid isPermaLink="false">hacker-news-small-sites-24160274</guid>
            <pubDate>Fri, 14 Aug 2020 16:55:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to write commit messages that will save you a lot of time]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24160024">thread link</a>) | @Rainymood
<br/>
August 14, 2020 | https://www.janmeppe.com/blog/good-commit-messages/ | <a href="https://web.archive.org/web/*/https://www.janmeppe.com/blog/good-commit-messages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          


  <p>

    

    

    
      
      

      
      
        1 minute read
      
    

  </p>

        </header>
      

      <section itemprop="text">
        
        <p>Writing good commit messages can save you a lot of time. In this blog post I
want to show you an example of that. At some point in the past I changed the
colours of the links on this blog from grey to blue, but where did I make
this change again? Commit messages to the rescue!</p>

<p><img src="https://www.janmeppe.com/assets/2020-07-10-good-commit-messages/img.png"></p>

<p>I was unable to recall where in the code I made the changes by browsing
through the files so I went over my commit history and… lo and behold.</p>

<p><img src="https://www.janmeppe.com/assets/2020-07-10-good-commit-messages/commit.png"></p>

<p>Thank you, past me, for writing these awesome commit messages!</p>

<h2 id="how-to-write-good-commit-messages">How to write good commit messages</h2>

<p>Writing good commit messages is a tricky thing and there are a
<a href="https://chris.beams.io/posts/git-commit/">lot</a> of
<a href="https://www.freecodecamp.org/news/writing-good-commit-messages-a-practical-guide/">different</a>
opinion on <a href="https://github.com/erlang/otp/wiki/writing-good-commit-message">this</a>.</p>

<p>What I like to do is follow a rule that I picked up somewhere. Sadly, I can’t
find the source for this but it has served me well. The rule is as follows. When you write a commit messages you think to yourself</p>

<blockquote>
  <p><em>When applied, this commit will…</em></p>
</blockquote>

<p>Here it is applied in action:</p>

<ul>
  <li>When applied this commit will <strong>makes links blue</strong></li>
  <li>When applied this commit will <strong>add logos and splash image</strong></li>
  <li>When applied this commit will <strong>add splash post, leetcode post, update tags</strong></li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>I never thought that my commit habits would save me this much time, but here we are. To summarize, to write good commit messages simply think to yourself:</p>

<blockquote>
  <p><em>When applied, this commit will…</em></p>
</blockquote>

<p>Thank you for reading!</p>



<!-- Begin Mailchimp Signup Form -->





<!--End mc_embed_signup-->

        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://www.janmeppe.com/blog/good-commit-messages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24160024</guid>
            <pubDate>Fri, 14 Aug 2020 16:34:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What it took to Reach $100 MRR]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24159986">thread link</a>) | @noahbragg
<br/>
August 14, 2020 | https://noahbragg.com/blog/what-it-took-to-reach-100-mrr/ | <a href="https://web.archive.org/web/*/https://noahbragg.com/blog/what-it-took-to-reach-100-mrr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
         <div>
  
  
  <p>August 14, 2020 | <span>7</span> Minute Read</p>
  
  <p>TLDR - Quite a lot!</p>

<p>I have reached my first goal with <a href="https://supportman.io/">Supportman</a> of $100 MRR (monthly recurring revenue)! I picked this number because at $100, <a href="https://supportman.io/">Supportman</a> would be profitable, as well as make enough money to pay for my wife and I’s weekly coffee dates.</p>

<p>I knew it would be tough to get my first paying customers, but I didn’t know it would be this hard! When you’re dreaming about starting a business, it can be difficult to forsee all the work and effort that will go into it. I wanted to share my experience so you could see an example of what it could take to reach $100 MRR.</p>

<h3 id="time">Time</h3>

<center><img src="https://media.giphy.com/media/jls5k3a7L1N0XRM9d0/giphy.gif" width="30%"></center>

<p>I started Supportman on January 1st, 2020. At that point, I started doing customer discovery and talking to people in the support industry.</p>

<p>I made the first commit for the project on March 27th and then I launched the product on June 12. It wasn’t until August 7th that I had reached $100 MRR.</p>

<p>So it took a little over three months to create the MVP. And it took just about two months to reach $100 MRR after launch. It took 7.5 months in total.</p>

<p>That’s a long time! Or at least it feels longer than what I was expecting. $100 really isn’t that much, but it definitely is a start!</p>

<p>I should also mention that I have been working on Supportman on the side while maintaining my full-time job. I probably spend somewhere from 10 to 20 hours per week, but that can vary some from week to week.</p>

<p>Remember, not every founder has the same experience and yours will most likely be different. Some markets are faster to get going and it will definitely vary widely depending on if you are doing B2B or consumer.</p>

<h3 id="selling-to-customers-and-building-rapport">Selling To Customers and Building Rapport</h3>

<center><img src="https://media.giphy.com/media/6o0jq0G2tfv7W/giphy.gif" width="40%"></center>

<p>Like most software developers, this is my least favorite part - selling to potential customers. I did quite a lot of direct sales.</p>

<p>It takes so much time to find potential customers, research them on LinkedIn, find their email address, and then message them a handcrafted, personal email.</p>

<p>One of the ways that I found lots of my potential customers was by being in customer support slack communities. I DM’ed quite a few people in these groups.</p>

<p>Overall I probably private messaged/emailed around 120 potential customers. Some of those ended up being helpful conversations to learn more and some just flat out said no. Of course, the large majority didn’t reply at all.</p>

<p>Out of all of that grueling time-consuming work, only one of my current paying customers came from a cold slack DM.</p>

<p>I knew sales would be hard but I didn’t know it would be this hard!</p>

<p>I think the other part of the pie in sales is building rapport. If I am a person that people trust in the customer support community, they are going to be more willing to chat with me.</p>

<p>I can see how entrepreneurs who have grown a big audience or network in their industry would really have an upper hand here. They could get off to a much quicker start.</p>

<p>On the other hand - I am starting my customer support relationships from zero. And it is a lot of work! I was able to start with some of the companies that I did customer discovery with but none of them ended up converting to paid customers.</p>

<p>I have a lot more work to do in regards to building rapport and I have some ideas to do this in the future. I think the bottom line is, be helpful to the communities your customers are in and you will start to be seen as an expert in the space.</p>

<h3 id="intercom-app-store">Intercom App Store</h3>

<center><img src="https://media.giphy.com/media/IffZTS1F0nR0T7PMgd/giphy.gif" width="40%"></center>

<p>The <a href="https://www.intercom.com/app-store">Intercom app store</a> was what I had hoped would be my main distribution channel. This was one of my reasons for wanting to create a <a href="https://noahbragg.com/blog/why-im-building-a-side-dish/">Side Dish</a>. I had hoped that I could build an app on a platform and that platform could bring me most of my leads.</p>

<p>So far this hasn’t really been the case. I have probably been getting about two sign ups a week from Intercom. And that is even with Supportman getting into the Intercom <a href="https://www.intercom.com/app-store/?category=new-and-noteworthy">New and Noteworthy</a> category. This is a category that shows Supportman on the front page of the app store!</p>

<p>There could be other problems causing this. It could mean that the problem I am solving or how I am showing it in my listing isn’t resonating with Intercom companies. Another problem is that it’s really hard to tell how many people are coming across my listing since Intercom doesn’t have any analytics.</p>

<p>So that being said, there is still a lot of work for me to do to figure the Intercom app store out and optimize it to help me find customers.</p>

<h3 id="twitter">Twitter</h3>

<center><img src="https://media.giphy.com/media/YAGcqpFNT5DXO/giphy.gif" width="50%"></center>

<p>So, where did my first customers come from then? As I mentioned already, one was from cold messaging. The other three came from Twitter!</p>

<p>I created a <a href="https://twitter.com/supportmanHQ">Supportman Twitter account</a> and started tweeting updates that I had made to the app. I also tried to create some value for Intercom customers by writing a couple of <a href="https://supportman.io/blog">how to blog posts</a>.</p>

<p>Every time that I made a new tweet, I would mention Intercom. A couple of these they liked and a couple of them they retweeted. Intercom customers saw the tweets and checked out Supportman.</p>

<p>This was great! There is definitely more I can do on Twitter to help push engagement and ultimately push users to Supportman. But again, creating valuable content takes time.</p>

<h3 id="building-more-features">Building More Features</h3>

<center><img src="https://media.giphy.com/media/hrRJ41JB2zlgZiYcCw/giphy.gif" width="40%"></center>

<p>I started Supportman out as a pretty basic MVP. It was very minimal. It could just send Intercom conversation ratings to a Slack channel and a weekly report of the metrics support teams care about. I thought this was all I would need to get started but I was only partially right. Some of my customers just wanted those features, but just about everyone started to ask for more.</p>

<p>They also wanted more preferences around the features I had already created. I pretty quickly learned that I needed to make these changes and add them to get my first paying customers.</p>

<p>It looked something like this… a customer would ask for something to be added and then I would do it and have it ready for them a day later. This allowed me to blow them away by my fast response times which helped convert them to paying customers.</p>

<p>That being said, I had to build more features and update my existing MVP more than I would have expected in the beginning. This is all good though since it is helping to make my product even better and push it in the right direction.</p>

<h3 id="conclusion">Conclusion</h3>

<p>You can probably already tell the conclusion and theme that I am pushing in this post. Building a SaaS business takes a lot of time and it is really hard to get to even something as little as $100 MRR! It was a lot harder than I expected.</p>

<p>But at the same time, I am excited that I have made it this far and feel like there is hope for Supportman in the future.</p>

<p>Just getting one paying customer is a pretty big deal because it means you have created something valuable for someone else.</p>

<p>Hopefully this gives you a glimpse of what it could take for you to reach this milestone as well!</p>

<h3 id="support">Support</h3>

<p>I hope this was helpful in some way. If you liked it, sharing the thread on Twitter is really appreciated!</p>
<center><a href="https://twitter.com/noahwbragg/status/1294309338266259457"><img src="https://noahbragg.com/assets/img/twitter-100-mrr.png" alt=""></a></center>


  <!-- Begin Mailchimp Signup Form -->
  
  
  
  <!--End mc_embed_signup-->

  <!-- POST NAVIGATION -->
  
</div>

      </div>
   </div></div>]]>
            </description>
            <link>https://noahbragg.com/blog/what-it-took-to-reach-100-mrr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24159986</guid>
            <pubDate>Fri, 14 Aug 2020 16:32:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Types as axioms, or: playing god with static types (2020)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24159856">thread link</a>) | @todsacerdoti
<br/>
August 14, 2020 | https://lexi-lambda.github.io/blog/2020/08/13/types-as-axioms-or-playing-god-with-static-types/ | <a href="https://web.archive.org/web/*/https://lexi-lambda.github.io/blog/2020/08/13/types-as-axioms-or-playing-god-with-static-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section role="main">
        <!-- Main column -->
        <div>



          <article>
  <header>
    
    
  </header>

<p>Just what exactly <em>is</em> a type?</p>

<p>A common perspective is that types are <em>restrictions</em>. Static types restrict the set of values a variable may contain, capturing some subset of the space of “all possible values.” Under this worldview, a typechecker is sort of like an oracle, predicting which values will end up where when the program runs and making sure they satisfy the constraints the programmer wrote down in the type annotations. Of course, the typechecker can’t <em>really</em> predict the future, so when the typechecker gets it wrong—it can’t “figure out” what a value will be—static types can feel like self-inflicted shackles.</p>

<p>But that is not the <em>only</em> perspective. There is another way—a way that puts you, the programmer, back in the driver’s seat. You make the rules, you call the shots, you set the objectives. You need not be limited any longer by what the designers of your programming language decided the typechecker can and cannot prove. You do not serve the typechecker; the typechecker serves <em>you.</em></p>

<p>…no, I’m not trying to sell you a dubious self-help book for programmers who feel like they’ve lost control of their lives. If the above sounds too good to be true, well… I won’t pretend it’s all actually as easy as I make it sound. Nevertheless, it’s well within the reach of the working programmer, and most remarkably, all it takes is a change in perspective.</p>
<!-- more-->



<p>Let’s talk a little about TypeScript.</p>

<p>TypeScript is a <em>gradually-typed</em> language, which means it’s possible to mix statically- and dynamically-typed code. The original intended use case of gradual typing was to <em>gradually</em> add static types to an existing dynamically-typed codebase, which imposes some interesting design constraints. For one, a valid JavaScript program must also be a valid TypeScript program; for another, TypeScript must be accommodating of traditional JavaScript idioms.</p>

<p>Gradually typed languages like TypeScript are particularly good illustrations of the way type annotations can be viewed as constraints. A function with no explicit type declarations<sup><a href="#2020-08-13-types-as-axioms-or-playing-god-with-static-types-footnote-1-definition" name="2020-08-13-types-as-axioms-or-playing-god-with-static-types-footnote-1-return">1</a></sup> can accept <em>any</em> JavaScript value, so adding a type annotation fundamentally restricts the set of legal values.</p>

<p>Furthermore, languages like TypeScript tend to have subtyping. This makes it easy to classify certain types as “more restrictive” than others. For example, a type like <code>string | number</code> clearly includes more values than just <code>number</code>, so <code>number</code> is a more restrictive type—a <em>subtype</em>.</p>

<p>An exceptionally concrete way to illustrate this “types are restrictions” mentality is to write a function with an unnecessarily specific type. Here’s a TypeScript function that returns the first element in an array of numbers:</p>

<div>
 <div>
  <pre><span></span><span>function</span> <span>getFirst</span><span>(</span><span>arr</span>: <span>number</span><span>[])</span><span>:</span> <span>number</span> <span>|</span> <span>undefined</span> <span>{</span>
  <span>return</span> <span>arr</span><span>[</span><span>0</span><span>];</span>
<span>}</span>
</pre></div>

</div>

<p>This function would work perfectly well given a list of strings, but if you write <code>getFirst(["hello", "world"])</code>, the typechecker will complain. Of course, in this example the restriction is thoroughly self-imposed—it would be easy to give this function a generic type—but sometimes it’s not quite so easy. For example, suppose we write a function where the return type depends upon the type of the argument:</p>

<div>
 <div>
  <pre><span></span><span>function</span> <span>emptyLike</span><span>(</span><span>val</span>: <span>number</span> <span>|</span> <span>string</span><span>)</span><span>:</span> <span>number</span> <span>|</span> <span>string</span> <span>{</span>
  <span>if</span> <span>(</span><span>typeof</span> <span>val</span> <span>===</span> <span>"number"</span><span>)</span> <span>{</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>return</span> <span>""</span><span>;</span>
  <span>}</span>
<span>}</span>
</pre></div>

</div>

<p>Now if we write <code>emptyLike(42) * 10</code>, the typechecker will once again complain, claiming the result could be a string—it can’t “figure out” that when we pass a number, we always get a number back.</p>

<p>When type systems are approached from this perspective, the result is often frustration. The programmer knows that the equivalent untyped JavaScript is perfectly well-behaved, so the typechecker comes off as being the highly unfortunate combination of stubborn yet dim-witted. What’s more, the programmer likely has little mental model of the typechecker’s internal operation, so when types like the above are inferred (not explicitly written), it can be unclear what solutions exist to make the error go away.</p>

<p>At this point, the programmer may give up. “Stupid typechecker,” they grumble, changing the return type of <code>emptyLike</code> to <code>any</code>. “If it can’t even figure this out, can it <em>really</em> be all that useful?”</p>

<p>Sadly, this relationship with the typechecker is all too common, and gradually-typed languages in particular tend to create a vicious cycle of frustration:</p>

<ul>
 <li>
  <p>Gradual type systems are intentionally designed to “just work” on idiomatic code as much as possible, so programmers may not think much about the types except when they get type errors.</p></li>
 <li>
  <p>Furthermore, many programmers using gradually-typed languages are already adept at programming in the underlying dynamically-typed language, so they have working mental models of program operation in terms of the dynamic semantics alone. They are much less likely to develop a rich mental model of the static semantics of the type system because they are used to reasoning without one.</p></li>
 <li>
  <p>Gradually typed languages must support idioms from their dynamically-typed heritage, so they often include ad-hoc special cases (such as, for example, special treatment of <code>typeof</code> checks) that obscure the rules the typechecker follows and make them seem semi-magical.</p></li>
 <li>
  <p>Builtin types are deeply blessed in the type system, strongly encouraging programmers to embrace their full flexibility, but leaving little recourse when they run up against their limits.</p></li>
 <li>
  <p>All this frustration breeds a readiness to override the typechecker using casts or <code>any</code>, which ultimately creates a self-fulfilling prophecy in which the typechecker rarely catches any interesting mistakes because it has been so routinely disabled.</p></li></ul>

<p>The end result of all of this is a defeatist attitude that views the typechecker as a minor tooling convenience at best (i.e. a fancy autocomplete provider) or an active impediment at worst. Who can really blame them? The type system has (unintentionally of course) been designed in such a way so as to lead them into this dead end. The public perception of type systems settles into that of a strikingly literal nitpicker we endure rather than as a tool we actively leverage.</p>



<p>After everything I said above, it may be hard to imagine seeing types any other way. Indeed, through the lens of TypeScript, the “types are restrictions” mentality is incredibly natural, so much so that it seems self-evident. But let’s move away from TypeScript for a moment and focus on a different language, Haskell, which encourages a somewhat different perspective. If you aren’t familiar with Haskell, that’s alright—I’m going to try to keep the examples in this blog post as accessible as possible whether you’ve written any Haskell or not.</p>

<p>Though Haskell and TypeScript are both statically-typed—and both of their type systems are fairly sophisticated—Haskell’s type system is almost completely different philosophically:</p>

<ul>
 <li>
  <p>Haskell does not have subtyping,<sup><a href="#2020-08-13-types-as-axioms-or-playing-god-with-static-types-footnote-2-definition" name="2020-08-13-types-as-axioms-or-playing-god-with-static-types-footnote-2-return">2</a></sup> which means that every value belongs to exactly one type.</p></li>
 <li>
  <p>While JavaScript is built around a small handful of flexible builtin datatypes (booleans, numbers, strings, arrays, and objects), Haskell has essentially no blessed, built-in datatypes other than numbers. Key types such as booleans, lists, and tuples are ordinary datatypes defined in the standard library, no different from types users could define.<sup><a href="#2020-08-13-types-as-axioms-or-playing-god-with-static-types-footnote-3-definition" name="2020-08-13-types-as-axioms-or-playing-god-with-static-types-footnote-3-return">3</a></sup></p></li>
 <li>
  <p>In particular, Haskell is built around the idea that datatypes can be defined with multiple <em>cases</em>, and branching is done via pattern-matching (more on this shortly).</p></li></ul>

<p>Let’s look at a basic Haskell datatype declaration. Suppose we want to define a type that represents a season:</p>

<div>
 <div>
  <pre><span></span><span>data</span> <span>Season</span> <span>=</span> <span>Spring</span> <span>|</span> <span>Summer</span> <span>|</span> <span>Fall</span> <span>|</span> <span>Winter</span>
</pre></div>

</div>

<p>If you are familiar with TypeScript, this may look rather similar to a union type; if you’re familiar with a C-family language, this may remind you more of an enum. Both are on the right track: this defines a new type named <code>Season</code> with four possible values, <code>Spring</code>, <code>Summer</code>, <code>Fall</code>, and <code>Winter</code>.</p>

<p>But what exactly <em>are</em> those values?</p>

<ul>
 <li>
  <p>In TypeScript, we’d represent this type with a union of strings, like this:</p>
  <div>
   <div>
    <pre><span></span><span>type</span> <span>Season</span> <span>=</span> <span>"spring"</span> <span>|</span> <span>"summer"</span> <span>|</span> <span>"fall"</span> <span>|</span> <span>"winter"</span><span>;</span>
</pre></div>

</div>
  <p>Here, <code>Season</code> is a type that can be one of those four strings, but nothing else.</p></li>
 <li>
  <p>In C, we’d represent this type with an enum, like this:</p>
  <div>
   <div>
    <pre><span></span><span>enum</span> <span>season</span> <span>{</span> <span>SPRING</span><span>,</span> <span>SUMMER</span><span>,</span> <span>FALL</span><span>,</span> <span>WINTER</span> <span>};</span>
</pre></div>

</div>
  <p>Here, <code>SPRING</code>, <code>SUMMER</code>, <code>FALL</code>, and <code>WINTER</code> are essentially defined to be global aliases for the integers <code>0</code>, <code>1</code>, <code>2</code>, and <code>3</code>, and the type <code>enum season</code> is essentially an alias for <code>int</code>.</p></li></ul>

<p>So in TypeScript, the values are strings, and in C, the values are numbers. What are they in Haskell? Well… they simply <em>are</em>.</p>

<p>The Haskell declaration invents four completely new constants out of thin air, <code>Spring</code>, <code>Summer</code>, <code>Fall</code>, and <code>Winter</code>. They aren’t aliases for numbers, nor are they symbols or strings. The compiler doesn’t expose anything about how it chooses to represent these values at runtime; that’s an implementation detail. In Haskell, <code>Spring</code> is now a value <em>distinct from all other values</em>, even if someone in a different module were to also use the name <code>Spring</code>. Haskell type declarations let us play god, creating something from nothing.</p>

<p>Since these values are totally unique, abstract constants, what can we actually do with them? The answer is one thing and <em>exactly</em> one thing: we can branch on them. For example, we can write a function that takes a <code>Season</code> as an argument and returns whether or not Christmas occurs during it:</p>

<div>
 <div>
  <pre><span></span><span>containsChristmas</span> <span>::</span> <span>Season</span> <span>-&gt;</span> <span>Bool</span>
<span>containsChristmas</span> <span>season</span> <span>=</span> <span>case</span> <span>season</span> <span>of</span>
  <span>Spring</span> <span>-&gt;</span> <span>False</span>
  <span>Summer</span> <span>-&gt;</span> <span>True</span>  <span>-- southern hemisphere</span>
  <span>Fall</span>   <span>-&gt;</span> <span>False</span>
  <span>Winter</span> <span>-&gt;</span> <span>True</span>  <span>-- northern hemisphere</span>
</pre></div>

</div>

<p><code>case</code> expressions are, to a first approximation, a lot like C-style <code>switch</code> statements (though they can do a lot more than this simple example suggests). Using <code>case</code>, we can also define conversions from our totally unique <code>Season</code> constants to other types, if we want:</p>

<div>
 <div>
  <pre><span></span><span>seasonToString</span> <span>::</span> <span>Season</span> <span>-&gt;</span> <span>S…</span></pre></div></div></article></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lexi-lambda.github.io/blog/2020/08/13/types-as-axioms-or-playing-god-with-static-types/">https://lexi-lambda.github.io/blog/2020/08/13/types-as-axioms-or-playing-god-with-static-types/</a></em></p>]]>
            </description>
            <link>https://lexi-lambda.github.io/blog/2020/08/13/types-as-axioms-or-playing-god-with-static-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24159856</guid>
            <pubDate>Fri, 14 Aug 2020 16:20:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decrypting HTTPS: How to Snoop on Your Own Requests]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24159847">thread link</a>) | @aecko
<br/>
August 14, 2020 | https://bitwiser.dev/2020/08/14/decrypting-https-how-to-snoop-on-your-own-requests/ | <a href="https://web.archive.org/web/*/https://bitwiser.dev/2020/08/14/decrypting-https-how-to-snoop-on-your-own-requests/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>14 Aug 2020</span></p><ul>
  <li><a href="#agenda">Agenda</a></li>
  <li><a href="#the-basics">The Basics</a>
    <ul>
      <li><a href="#what-is-https">What is HTTPS?</a></li>
      <li><a href="#what-is-a-tls-handshake">What is a TLS Handshake?</a></li>
    </ul>
  </li>
  <li><a href="#how-to-snoop-on-your-own-requests">How to Snoop on Your Own Requests</a>
    <ul>
      <li><a href="#capture-an-encrypted-request">Capture an Encrypted Request</a></li>
      <li><a href="#capture-a-decrypted-request">Capture a Decrypted Request</a></li>
    </ul>
  </li>
  <li><a href="#appendix">Appendix</a>
    <ul>
      <li><a href="#curl-vs-browser">curl vs. Browser</a></li>
      <li><a href="#wireshark-vs-browser-dev-tools">Wireshark vs. Browser Dev Tools</a></li>
    </ul>
  </li>
</ul>



<p>This post will teach you <strong>how to see HTTPS in-action</strong>, but not every detail of how HTTPS works. Instead, you’ll gain a <strong>real life example</strong> to reference if you ever want to study the nitty gritty details.</p>

<p>To do this, we’ll learn how to <strong>snoop on our own HTTPS requests via Wireshark</strong> and witness as your computer establishes a secure connection.</p>

<p>Although the nitty gritty details of HTTPS are outside the scope of this post, we’ll <strong>review the basics</strong> before embarking on this exercise to provide a bit of context.</p>

<p>If you’re already familiar with the basics of HTTPS and TLS, feel free to skip to the <a href="#how-to-snoop-on-your-own-requests">next section</a>.</p>



<h2 id="what-is-https">What is HTTPS?</h2>

<p>HTTP stands for <strong>Hypertext Transfer Protocol</strong>. And at the very least, you likely know that whenever you see <code>https://</code> in the address bar, the <strong>S</strong> in <strong>HTTPS</strong> stands for <strong>secure</strong>: ensuring that communication between your browser and the server is secure.</p>

<p>But how does HTTPS secure communication between you and the server? Your browser will perform a <strong>TLS handshake</strong> before sending any sensitive data.</p>

<h2 id="what-is-a-tls-handshake">What is a TLS Handshake?</h2>

<p>At the beginning of any <code>https://</code> request, your browser performs a TLS handshake: a protocol that ensures <strong>confidentiality</strong>, <strong>authentication</strong>, and <strong>integrity</strong> between your computer and the server it talks to.</p>

<p>Today, we’ll focus on confidentiality which promises to <strong>keep your data secret</strong> from snoopers by encrypting your request. To achieve confidentiality, your computer and the server perform a TLS handshake to negotiate the <strong>master secret</strong> used to derive keys that encrypt and decrypt messages sent between each other.</p>

<p>During this exercise, we’ll capture the “secret sauce” used to establish the master secret in order to decrypt our requests!</p>



<h2 id="capture-an-encrypted-request">Capture an Encrypted Request</h2>

<p>Now that we understand the basics of HTTPS and TLS, let’s see it in-action. To do so, we’ll snoop on our own HTTPS request. First, let’s capture a plain ol’ HTTPS request without any clever tricks yet:</p>

<ol>
  <li>Install the latest version of <a href="https://curl.haxx.se/">curl</a>*</li>
  <li>Install and boot up <a href="https://www.wireshark.org/">Wireshark</a></li>
  <li>Type <code>curl https://github.com</code> in the console (but don’t press enter yet!).</li>
  <li>Start a capture via Wireshark</li>
  <li>Execute our <code>curl</code> command</li>
  <li>Stop the capture</li>
</ol>

<p><em>*NOTE: Since v7.58.0, curl accepts a filename specified by the environment variable <code>SSLKEYLOGFILE</code>: this file logs secrets established during the TLS handshake. These logged secrets let us retroactively decrypt our HTTPS request in the next step– so be sure to install curl &gt;= v7.58.0. Be aware that curl installations may contain varying TLS libraries, and only some libraries support it. For example, MacOS’ default curl installation uses Apple’s Secure Transport library which does not support this flag– so you may need to <code>brew install curl-openssl</code> and rewire your path to prefer it.</em></p>

<p>Now that we captured the request via Wireshark, let’s inspect the relevant packets:</p>

<ol>
  <li>Type <code>tls.handshake</code> in Wireshark filter bar and press enter</li>
  <li>Locate packet labelled <code>Client Hello</code> in the <code>Info</code> field</li>
  <li>Copy IP address from the packet’s <code>Destination</code> field</li>
  <li>Type <code>ip.dst == foobar || ip.src == foobar</code> in Wireshark filter bar (where <code>foobar</code> is the IP address from previous step)*</li>
</ol>

<p><em>*NOTE: Wireshark captures any and all network traffic which produces a lot of noise in our capture. To reduce noise, we filter packets exclusively to and from the server we just curl’d.</em></p>

<p>With our packets filtered, let’s take a peak at the <code>Client Hello</code> packet:</p>

<p><img src="https://bitwiser.dev/public/imgs/client_hello.png" alt="client hello readable"></p>

<p><em>The contents of this Client Hello packet can be read clear as day.</em></p>

<p>This “Client Hello” packet is the first step of the TLS handshake. You may notice it’s readable while every packet afterwards is encrypted. Why?</p>

<p>One of the main selling points of HTTPS (and the underlying TLS handshake) is that it <strong>encrypts traffic so onlookers can’t snoop on data</strong> sent between your computer and the server. Unfortunately, that even includes <em>you</em> snooping on your own requests via Wireshark!</p>

<p><img src="https://bitwiser.dev/public/imgs/encrypted.png" alt="encrypted"></p>

<p><em>From this point on, TLS encrypts all data sent and received.</em></p>

<p>Perhaps you want to see the remaining traffic, decrypted and readable, for educational purposes. Hell, it’s your computer after all. This is indeed possible, and it’s only a quick 5 minute configuration away.</p>

<h2 id="capture-a-decrypted-request">Capture a Decrypted Request</h2>

<p>To do this, we must convince curl’s underlying TLS library to dump valuable secrets established during the handshake to decrypt the data. Repeat the initial steps from the <a href="#capture-an-encrypted-request">Capture an Encrypted Request</a> section but replace the <code>curl https://github.com</code> command with this:</p>

<p>Windows:</p>
<div><div><pre><code>cmd /c "set SSLKEYLOGFILE=%HOMEPATH%\sslkeylog&amp;&amp; curl https://github.com"
</code></pre></div></div>

<p>Unix:</p>
<div><div><pre><code>SSLKEYLOGFILE=~/sslkeylog curl https://github.com
</code></pre></div></div>

<p><em>NOTE: Notice we temporarily set <code>SSLKEYLOGFILE</code> for this one-off command. It’s not wise to set this variable permanently because someone could retroactively decrypt your traffic using this file. While you likely have bigger problems if someone has unauthorized access to your files, it’s best not to leave any trace regardless.</em></p>

<p>If you crack open that SSL key log file we just specified, you’ll see something like this:</p>

<div><div><pre><code>SERVER_HANDSHAKE_TRAFFIC_SECRET 1234567890abcdefghijklmnopqrstuvwxyz...
EXPORTER_SECRET 1234567890abcdefghijklmnopqrstuvwxyz...
SERVER_TRAFFIC_SECRET_0 1234567890abcdefghijklmnopqrstuvwxyz...
CLIENT_HANDSHAKE_TRAFFIC_SECRET 1234567890abcdefghijklmnopqrstuvwxyz...
CLIENT_TRAFFIC_SECRET_0 1234567890abcdefghijklmnopqrstuvwxyz...
</code></pre></div></div>

<p>You can essentially think of this data as the “secret sauce” used to negotiate our secure connection: this is exactly what Wireshark needs to decrypt our request!</p>

<p>With Wireshark containing the capture of our last <code>curl</code> request, do the following:</p>

<ol>
  <li>Go to Edit &gt; Preferences &gt; Protocols &gt; TLS</li>
  <li>Click “Browse” next to (Pre)-Master-Secret log filename</li>
  <li>Select and confirm the <code>SSLKEYLOGFILE</code> location</li>
  <li>Press “OK”</li>
</ol>

<p>Now, let’s take a look at that previously encrypted packet:</p>

<p><img src="https://bitwiser.dev/public/imgs/decrypted.png" alt="decrypted"></p>

<p><em>This previously encrypted packet is now decrypted and readable.</em></p>

<p>Voila! What was once labeled “Encrypted Application Data” is now readable– and we can see that this packet sent over additional TLS extension data.</p>

<p>Peaking even further in our capture, we can find the actual HTML response to our curl request!</p>

<p><img src="https://bitwiser.dev/public/imgs/html_response.png" alt="html response"></p>

<p><em>The HTML response to our curl request.</em></p>

<p>And there you have it. With this neat trick, you can capture and study the steps of the TLS handshake– or even just see the inner workings of an HTTPS request that your browser dev tools abstracts away from you.</p>

<p>Happy snooping! 🕵️</p>



<h2 id="curl-vs-browser">curl vs. Browser</h2>

<p>Why fire a request using curl instead of the browser? The simple answer is that curl produces less noise in your Wireshark capture.</p>

<p>When you request a URL via the browser, it scans the response and fires <strong>many more requests</strong> to fetch images, scripts, etc. defined in the HTML.</p>

<p>When you request a URL via curl, it fires a single request and returns the raw HTML: it does not subsequently request other resources defined in the HTML like your browser does.</p>

<p>Thus, the Wireshark capture is shorter and sweeter.</p>



<p>Why capture our request via Wireshark instead of just using our browser’s dev tools (which automatically decrypts the data for us)?</p>

<p>For 99.9% of web development, browser dev tools does the job because we mainly work on the level of HTTPS and above.</p>

<p>Though if you want to learn about the abstractions below HTTPS, Wireshark lets you see all the nitty gritty details that browser dev tools normally abstracts away from you– as it should, because it’s a lot of noise you often don’t need to worry about!</p>

</div>



      </div></div>]]>
            </description>
            <link>https://bitwiser.dev/2020/08/14/decrypting-https-how-to-snoop-on-your-own-requests/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24159847</guid>
            <pubDate>Fri, 14 Aug 2020 16:19:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Byteconf Flutter, a free live-streamed Flutter conference]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24159829">thread link</a>) | @kmf
<br/>
August 14, 2020 | https://bytesized.xyz/flutter-2020/live | <a href="https://web.archive.org/web/*/https://bytesized.xyz/flutter-2020/live">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bytesized.xyz/flutter-2020/live</link>
            <guid isPermaLink="false">hacker-news-small-sites-24159829</guid>
            <pubDate>Fri, 14 Aug 2020 16:17:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I got a list of 2000 Venture Capitalist Firms]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24159812">thread link</a>) | @artif4ct
<br/>
August 14, 2020 | https://blog.scraper.ai/getting-lists-of-venture-capitalist-firms/ | <a href="https://web.archive.org/web/*/https://blog.scraper.ai/getting-lists-of-venture-capitalist-firms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>When you're looking for funding, or you're looking to approach a VC it's always interesting to get a list of the different VCs out there. Now sadly enough this is not easy to find, or you need to manually select each record.</p><p>After looking a bit on the internet, I found a list of over <strong><a href="http://www.boogar.com/resources/venturecapital/index.htm">2.000 VC firms</a></strong> out there. So let's get started creating our up to date list!</p><p>I will name this list <a href="http://www.boogar.com/resources/venturecapital/angels.htm"><strong>"VC - All"</strong></a><strong> </strong>which I will update weekly.</p><p>Beside updating this list weekly, I also want to select all the records. So I utilize the pagination functionality to do just this!</p><figure><img src="https://blog.scraper.ai/content/images/2020/07/image-43.png" alt="" srcset="https://blog.scraper.ai/content/images/size/w600/2020/07/image-43.png 600w, https://blog.scraper.ai/content/images/size/w1000/2020/07/image-43.png 1000w, https://blog.scraper.ai/content/images/size/w1600/2020/07/image-43.png 1600w, https://blog.scraper.ai/content/images/2020/07/image-43.png 1920w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://blog.scraper.ai/content/images/2020/07/image-41.png" alt="" srcset="https://blog.scraper.ai/content/images/size/w600/2020/07/image-41.png 600w, https://blog.scraper.ai/content/images/size/w1000/2020/07/image-41.png 1000w, https://blog.scraper.ai/content/images/size/w1600/2020/07/image-41.png 1600w, https://blog.scraper.ai/content/images/2020/07/image-41.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>Finally I put the pagination limit on 30, click Finish and sit back and relax!</p><blockquote>The engine will automatically take care of getting the links behind this!</blockquote><figure><img src="https://blog.scraper.ai/content/images/2020/07/image-44.png" alt="" srcset="https://blog.scraper.ai/content/images/size/w600/2020/07/image-44.png 600w, https://blog.scraper.ai/content/images/size/w1000/2020/07/image-44.png 1000w, https://blog.scraper.ai/content/images/size/w1600/2020/07/image-44.png 1600w, https://blog.scraper.ai/content/images/2020/07/image-44.png 1920w" sizes="(min-width: 720px) 720px"></figure>
</div></div>]]>
            </description>
            <link>https://blog.scraper.ai/getting-lists-of-venture-capitalist-firms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24159812</guid>
            <pubDate>Fri, 14 Aug 2020 16:15:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mozilla’s Uncertain Future]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24159626">thread link</a>) | @sciurus
<br/>
August 14, 2020 | https://civilityandtruth.com/2020/08/13/mozillas-uncertain-future/ | <a href="https://web.archive.org/web/*/https://civilityandtruth.com/2020/08/13/mozillas-uncertain-future/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <figure>
  <p><a href="https://civilityandtruth.com/assets/images/mozilla-revenues-vs-expenses.png"><img src="https://civilityandtruth.com/assets/images/mozilla-revenues-vs-expenses.png" alt="Graph of Mozilla revenues compared to expenses"></a></p>
  <figcaption>The graph above shows the consolidated revenues and
expenses of the Mozilla Foundation and Mozilla Corporation from the
Foundation’s founding in 2003 through 2018. Almost all of the revenues
and expenses are associated with the Mozilla Corporation, and almost
all of the revenues of the Mozilla Corporation are from Google and
other search engine providers. Graph © 2020 Frank Hecker, made
available under the <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons
Attribution 4.0 International license</a>.</figcaption>
</figure>

<p><em>tl;dr: Some thoughts on Mozilla for people who don’t know Mozilla.</em></p>

<p>By now everyone in the tech world has heard of the major layoffs at
the Mozilla Corporation, the organization that creates and distributes
the Firefox web browser. (For those who haven’t heard, about 250
people were laid off, about a quarter of the work force.) Lots of
people in the tech world have spoken their piece about the
significance of this event and what it means for the future of
Mozilla, the web, and so on.</p>

<p>Rather than write something of and for the tech world, I wanted to
briefly explain what’s going on for those of my readers who don’t know
HTML from XML, and who are more familar with the worlds of nonprofits
and regular old businesses. I used to work for Mozilla, and have more
knowledge of it and (I hope) insight into it than most people, but
I’ve been gone from Mozilla for ten years now. Thus what I write below
is based on observing it from a distance, like seeing an old friend
whose life has long since diverged from mine.</p>

<p>Disclaimer: I work for a tech company, and I don’t usually write about
other tech companies. So I will strongly emphasize that what I write
here are my personal opinions only, and do not represent the positions
of my present employer or past employers.</p>

<h2 id="what-is-mozilla">What is Mozilla?</h2>

<p>Mozilla is actually two things, the Mozilla Foundation and the Mozilla
Corporation, which are often confused and conflated in public
discourse. (There’s actually at least one other piece, but these two
are the main ones.) The Mozilla Foundation, founded in 2003 to take
over development of the source code for the Netscape web browser, is a
501(c)(3) tax-exempt nonprofit organization, with a staff of 80 people
and a budget of about $27 million in 2018, the last year for which
figures are available. The Mozilla Corporation, founded in 2005, is a
for-profit business, wholly owned by the Mozilla Foundation, with a
staff of about a thousand and revenue of about $440 million, again
from the 2018 financials.</p>

<p>This organizational structure was designed to allow the Mozilla
Corporation to engage in business activities which would be
incompatible with 501(c)(3) status, with a portion of the revenues
from those activities directed to the Mozilla Foundation to help fund
its activities. Having a nonprofit parent also means that the
management and employees of the Mozilla Corporation can help serve the
public benefit goals of the Mozilla Foundation, while still having
interesting jobs, being paid reasonably well, and feeling themselves
to be part of the overall Silicon Valley high-tech milieu.</p>

<p>Second: The customers of the Mozilla Corporation are not the users of
Firefox (among whom you may count yourself). The Mozilla Corporation’s
customers are large corporations like Google that pay for things that
will help them make money, most notably having their Internet search
service be the default in the Firefox browser. And to complete the old
saying, “If you’re not the customer…”, then the 200+ million Firefox
users are the product, potential viewers of ads served up by Google or
others.</p>

<p>(The existence of the Firefox browser as a competitor to Google’s
Chrome browser also supposedly helps Google avoid unwelcome antitrust
attention, especially now that Microsoft has abandoned its own browser
development efforts to base its own browser on the Chrome code. But
it’s unclear how important this consideration actually is to Google
senior management.)</p>

<p>In the early days of the Mozilla Corporation these search engine
relationships proved extremely lucrative, jumping from less than $5
million in 2004 to over $50 million in 2005, the first year in which
the Mozilla Corporation reported financial results, and eventually
growing to a high of about $540 million in 2017.</p>

<p>But as the number of Firefox users decreases (due to the growing
market dominance of the Chrome browser), and those users click on
fewer online ads (for example, because they’re spending less during
the COVID-19 pandemic), the willingness of Google and other customers
to pay the Mozilla Corporation for those users decreases
accordingly. Thus the Mozilla Corporation cutting a quarter of its
workforce.</p>

<p>(In contrast, to my knowledge the Mozilla Foundation itself is not
laying off anyone, at least at this time. It gets its funding from a
combination of royalties from the Mozilla Corporation for use of the
Firefox and Mozilla trademarks, government and foundation grants, and
individual donations. For 2018 the royalties accounted for about half
of the Mozilla Foundation’s budget, with grants and individual donations
each accounting for about a quarter of the budget.)</p>

<p>So, if you’re an avid user of the Firefox browser and want to chip in
a few dollars to help support its development, there’s actually no way
for you to do so, at least not at present. Your donations will go to
the Mozilla Foundation, which will use them to help fund its outreach
and advocacy initiatives, of which it has several. The Mozilla
Foundation itself does not develop Firefox—or any other software, to
my knowledge.</p>

<h2 id="whence-mozilla">Whence Mozilla?</h2>

<p>How has Mozilla (or, more correctly, the Mozilla Corporation) come
to its present pass? The best way I can explain it is that the Mozilla
Corporation is not really a business in the way we’d normally think of
a business, profit-focused and subject to market discipline.</p>

<p>Instead you can think of the Mozilla Corporation as being analogous to
the Bell Labs or Xerox PARC of yore, R&amp;D organizations funded by a
seemingly-unending stream of profits earned by other businesses that
enjoyed dominant positions in their respective markets. In this sense
Google is to Mozilla as AT&amp;T was to Bell Labs, or Xerox to Xerox
PARC.</p>

<p>Like Bell Labs and Xerox PARC, the Mozilla Corporation provided a home
for some of the smartest software developers around. Like those
organizations, the Mozila Corporation has initiated a myriad of
projects ranging from the mundane and useful (like the Firefox
browser) to the esoteric and speculative. Like those organizations,
the Mozilla Corporation has given away much of what it has produced in
the form of public goods available to everyone at no charge.</p>

<p>Like Bell Labs and Xerox PARC, the Mozilla Corporation has indulged a
taste for “build it yourself” vertical integration, and in particular
for creating its own bespoke development tools and software stack. For
example, like those organizations the Mozilla Corporation has created
its own operating system (FirefoxOS), its own programming language
(Rust), and (of course) its own graphical user environment in the form
of the Firefox browser (not to mention yet another web browser, this
one more research-oriented, and various experiments in software for
virtual reality environments).</p>

<p>And finally, the Mozilla Corporation is engaged in the same struggle
that Bell Labs and Xerox PARC found themselves in: trying to convert a
research-oriented organization into an actual business, and capture
for itself more of the value that it has been providing to the world
(and to its past, present, and future competitors) for free.</p>

<h2 id="whither-mozilla">Whither Mozilla?</h2>

<p>What will happen to Mozilla, and to the Mozilla Corporation in
particular? The basic situation is that Mozilla has tried to be at
least three things simultaneously: an advocacy organization, a
developer and distributor of mass market consumer software and related
services, and (as noted above) a research lab.</p>

<p>Being an advocacy organization is relatively inexpensive, but the
other two functions are not: software development (including
research-related activities) and branding and marketing together
consumed almost three quarters of the combined Mozilla Corporation and
Foundation expense budget of $450 million in 2018. Thus when COVID-19
hit and the Mozilla Corporation hit a brick wall in terms of search
engine revenue, its choice was apparently either to stop being a
consumer software and services company, or to stop being a research
lab.</p>

<p>In the end Mozilla Corporation senior management apparently decided to
go for being a consumer software and services company, and to ditch
any activities not related to that, including research projects.
Having done so, the Mozilla Corporation faces a number of problems:</p>

<p>First, as noted above the Mozilla ethos is arguably more like that of
an R&amp;D lab than of a business proper. Just getting Mozilla
employees to think of themselves as working in the service of a
profit-driven business, and to act in accordance with that thought
every single day, may be an uphill battle.</p>

<p>Second, Mozilla is arguably becoming superfluous, at least as far as
its own largest customer, Google, is concerned. Google has its own
browser and browser development team, its own research lab, and
presumably an inclination to want to spend its R&amp;D money on things
it can control and direct itself. Google also has the ability and the
opportunity to capture the remaining base of Firefox users, at least
those that are monetizable.</p>

<p>There will always be a core of enthusiastic Firefox users, but a lot
of them switch their search engine to something other than Google, run
ad blockers, and don’t click on online ads. Thus they are for the most
part irrelevant from Google’s point of view. At some point the major
value Firefox has for Google will be as presumed insulation from
antitrust enforcement efforts targeting Chrome, but such insurance,
even if it’s of value to Google, doesn’t necessarily require a large
Firefox user base.</p>

<p>Finally, it’s …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://civilityandtruth.com/2020/08/13/mozillas-uncertain-future/">https://civilityandtruth.com/2020/08/13/mozillas-uncertain-future/</a></em></p>]]>
            </description>
            <link>https://civilityandtruth.com/2020/08/13/mozillas-uncertain-future/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24159626</guid>
            <pubDate>Fri, 14 Aug 2020 15:59:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to make your bash scripts more reusable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24158972">thread link</a>) | @waylonwalker
<br/>
August 14, 2020 | https://waylonwalker.com/blog/reusable-bash/ | <a href="https://web.archive.org/web/*/https://waylonwalker.com/blog/reusable-bash/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Bash is a language that is quite useful for automation no matter what language you write in. Bash can do so many powerful system-level tasks. Even if you are on windows these days you are likely to come across bash inside a cloud VM, Continuous Integration, or even inside of docker.</p>
<p>I have three techniques that help me write more composable bash scripts.</p>
<ol>
<li><a href="#functions">functions</a></li>
<li><a href="#arguments">Arguments</a></li>
<li><a href="#positional-arguments">positional arguments</a></li>
<li><a href="#all-arguments">All Arguments</a></li>
<li><a href="#error-handling">Error Handling</a></li>
<li><a href="#main-script">main script</a></li>
</ol>
<hr>
<h2>Functions</h2>
<p><em>Break scripts down into reusable components</em></p>
<p>Functions in bash are quite simple. They are something that I wish I would have started using long ago. They make your code much more reusable. I often use them in my aliases as well since they can simplify the process and allow more flexibility.</p>
<p><em><small></small><mark></mark>syntax</em></p>
<div data-language="bash"><pre><code><span>#!/bin/sh</span>

<span>hello_world</span> <span>(</span><span>)</span> <span>{</span>
    <span>echo</span> <span>"hello world"</span>
<span>}</span></code></pre></div>
<p>Source the file to load the function and run it from the terminal.</p>
<p><em><small></small><mark></mark>run it</em></p>
<div data-language="bash"><pre><code><span>source</span> hello_world
hello_world</code></pre></div>
<p><em><small></small><mark></mark>outputs</em></p>

<hr>
<h2>Arguments</h2>
<p><em>Make functions a little more flexible</em></p>
<p>Arguments and options are quite a bit more complex in bash. For now, we will focus on the basics which are not all that bad.</p>
<h3>positional arguments</h3>
<p><em>easiest and most common to use</em></p>
<p>Positional arguments can be pulled out quite easily using <code>$1</code> for the first one, <code>$2</code> for the second, and so on.</p>
<p><strong>note</strong> <code>$0</code> is the command that was called. You will see this often used to find the command called to open up your current shell.</p>
<p><em><small></small><mark></mark>syntax</em></p>
<div data-language="bash"><pre><code><span>#!/bin/sh</span>

<span>hello</span> <span>(</span><span>)</span> <span>{</span>
    <span>echo</span> <span>"hello <span>$1</span>"</span></code></pre></div>
<p><em><small></small><mark></mark>run it</em></p>
<div data-language="bash"><pre><code><span>source</span> hello
hello Waylon</code></pre></div>
<p>Now we have a function that accepts positional arguments and we can call it by passing things into it.</p>
<p><em><small></small><mark></mark>outputs</em></p>

<p>More than one argument would be ignored since we are only looking at <code>$1</code>.</p>
<p><em><small></small><mark></mark>run it</em></p>
<div data-language="bash"><pre><code><span>source</span> hello
hello Waylon Walker</code></pre></div>
<p><em><small></small><mark></mark>outputs</em></p>

<p>Just the same as before since we do not use the second argument.</p>
<h3>All Arguments</h3>
<p>Bash has another special variable <code>$@</code> that stores <strong>all arguments</strong> in one.</p>
<p><em><small></small><mark></mark>syntax</em></p>
<div data-language="bash"><pre><code><span>#!/bin/sh</span>

<span>hello</span> <span>(</span><span>)</span> <span>{</span>
    <span>echo</span> <span>"hello <span>$@</span>"</span>
<span>}</span></code></pre></div>
<p>Just the same as before.</p>
<p><em><small></small><mark></mark>run it</em></p>
<div data-language="bash"><pre><code><span>source</span> hello
hello Waylon Walker</code></pre></div>
<p>Now the function will output all arguments that are passed into it since we are using the <code>$@</code> variable.</p>
<p><em><small></small><mark></mark>outputs</em></p>

<hr>
<h2>Error Handling</h2>
<p><em>Super powers in a single line</em></p>
<p>The easiest and most common way to handle an error in bash is through the use of the logical operators <code>&amp;&amp;</code> (and) and <code>||</code> (or).</p>
<p>Here I have a concrete example from earlier today. I was creating a bash script to run a python script from cron. The bash script is there to make sure that we have the python environment, activate it, and run. If it doesn't have it, it should create it.</p>
<div data-language="bash"><pre><code>
<span>create_env</span><span>(</span><span>)</span> <span>{</span>
    conda create -n <span>"<span>$1</span>"</span> <span>python</span><span>=</span><span>3.8</span>
    conda activate <span>"<span>$1</span>"</span>
    pip <span>install</span> -r requirements.txt
<span>}</span>



<span>env_exists</span><span>(</span><span>)</span> <span>{</span>
conda info --envs <span>|</span> <span>awk</span> <span>'{print <span>$1</span>}'</span> <span>|</span> <span>tail</span> -n +3 <span>|</span> <span>grep</span> -w <span>"<span>$1</span>"</span> <span>&gt;</span> /dev/null
<span>}</span>


<span></span><span><span>create_if</span> <span>(</span><span>)</span> <span>{</span></span><span>env_exists <span>"<span>$1</span>"</span> <span>&amp;&amp;</span> <span>echo</span> <span>"environment exists"</span> <span>||</span> create_env <span>"<span>$1</span>"</span></span><span><span>}</span></span><span></span>create_if my_env</code></pre></div>
<p>If we look at the <code>create_if</code> function, it will check if the environment exists if there is a passing status code <code>0</code>, then it will run <code>echo "environment exists"</code> otherwise it will run <code>create_env $1</code>.</p>
<p><strong>note</strong> Inside of <code>env_exists</code> grep will look for whole words if there is a match it will give a status code 0 if it finds a match and not 0 if there is no match.</p>
<hr>
<h2>main script</h2>
<p>_<code>if __name__ == " __main__"</code>_</p>
<p>The last thing I want to discuss is making a bash script both runnable and sourceable. This makes it so that you can <code>source filename.sh</code> and run each function individually, or <code>bash filename.sh</code> to run the script. This is a similar concept to <code>if __name__ == " __main__"</code> from python.</p>
<p>I did try this from bash and zsh with success. The following is an example that would pass all arguments into a main function.</p>
<p><em><small></small><mark></mark>syntax</em></p>
<div data-language="bash"><pre><code><span>if</span> <span>[</span><span>[</span><span>"<span>${<span>BASH_SOURCE</span><span>[</span>0<span>]</span>}</span>"</span> <span>==</span> <span>"<span>${0}</span>"</span> <span>]</span><span>]</span><span>;</span> <span>then</span>
    main <span>"<span>$@</span>"</span>
<span>fi</span></code></pre></div>
<p>Extending the example above that created a python example if necessary we can create the env if necessary, activate the environment, and run the script.</p>
<p><em><small></small><mark></mark>syntax</em></p>
<div data-language="bash"><pre><code><span>if</span> <span>[</span><span>[</span><span>"<span>${<span>BASH_SOURCE</span><span>[</span>0<span>]</span>}</span>"</span> <span>==</span> <span>"<span>${0}</span>"</span> <span>]</span><span>]</span><span>;</span> <span>then</span>
create_if my_env
conda activate my_env
python script.py
<span>fi</span></code></pre></div>
<p>Using this syntax to run our "main" functions will allow us to both runs the script or source the script to utilize the functions that we created.</p></div><p>If you found value in this post <br>and want to send a tip.</p></div>]]>
            </description>
            <link>https://waylonwalker.com/blog/reusable-bash/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24158972</guid>
            <pubDate>Fri, 14 Aug 2020 15:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Should You Clarify Before Accepting a Job Offer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24158878">thread link</a>) | @toptopdude
<br/>
August 14, 2020 | https://catalins.tech/what-should-you-clarify-before-accepting-a-job-offer-ckdriw6i800l1gws1f086bltx | <a href="https://web.archive.org/web/*/https://catalins.tech/what-should-you-clarify-before-accepting-a-job-offer-ckdriw6i800l1gws1f086bltx">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1597246382317/_1gWA2FZu.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text">

<p>There are some essential points you should clarify before accepting a job offer. It is easy to miss them at the moment and take a job offer straight away. </p>
<p>As a result, in this article, I want to talk about some questions you should ask before accepting the offer. I suggest you make a small checklist because you might forget them in the interview.</p>
<p>Thus, the questions you could ask are as follows:</p>
<ol>
<li>Is the company claiming ownership if I release a side project?</li>
<li>Does the company have a clear progression path? </li>
<li>Does the company offer me a mentor?</li>
<li>Is the company allowing me to contribute to open source projects? </li>
</ol>

<p>The first question you might want to ask is "<strong>is the company claiming ownership if I release free/paid side projects?</strong>". There are many examples where companies claimed ownership of the employee's projects. That can happen even if you build the project in your free time and on your equipment.</p>
<p>Therefore, you do not want to invest your resources and time to have a company "take" your project away. Moreover, you can even have legal disputes, which is even worse.</p>
<p>As a result, before accepting a job offer, ensure that the company does not claim ownership of your projects. </p>

<p>Another important question is "<strong>do you have a clear progression path?</strong>". It is essential to know if you can progress in the company and what support is available for you.</p>
<p>The years of experience do not matter too much. The reason is that you can do a job for a long time without getting better at it. You have to try to improve actively.</p>
<p>As a result, your progress can stagnate. That means you do not improve as a developer and a person, and it is going to be difficult for you to find another job. Believe me; you do not want that to happen. Thus, ask the company how they support their employees to improve as developers and persons.</p>

<p>If the opportunity of contributing to an open-source project arises, can you do it? This is another point you want to clarify with your prospective employers.</p>
<p>Contributing to open-source projects is an excellent way of getting out a rut, and improve your programming skills. As long as the projects do not clash with the company, they should allow you to contribute to open-source projects. And of course, as long as you do it in your free time.</p>
<p>In conclusion, do not forget to ask your prospective employer if they allow you to contribute to OSS.</p>

<p>Having a mentor is super beneficial for you. Especially at the beginning of your career. Being able to go to someone when you struggle to give you a hand is instrumental. However, do not confuse a mentor with a person that should spoon-feed you.</p>
<p>The mentors should be there to give you pointers and guide you. A mentor is not a person that solves your problems. However, if mentoring is available and done right, it is beneficial for both persons.</p>
<p>In conclusion, make sure the company is offering you mentorship. Proper mentorship helps you develop faster.</p>

<p>The questions from the article are not exhaustive, and you can add more questions. In fact, I would like to hear and discover more questions. You can never be too careful with contracts.</p>
<p>Until then, do not forget to ask about the:</p>
<ol>
<li><strong>ownership of you side projects</strong></li>
<li><strong>progression paths</strong></li>
<li><strong>mentorship</strong></li>
<li><strong>contributing to OSS</strong></li>
</ol>
<p>I hope the article helps you understand what should you clarify before accepting a job offer!</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://catalins.tech/what-should-you-clarify-before-accepting-a-job-offer-ckdriw6i800l1gws1f086bltx</link>
            <guid isPermaLink="false">hacker-news-small-sites-24158878</guid>
            <pubDate>Fri, 14 Aug 2020 15:08:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning technology you don't need right now is a waste of time]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24158268">thread link</a>) | @mcrittenden
<br/>
August 14, 2020 | https://critter.blog/2020/08/14/learning-a-technology-you-dont-need-right-now-is-a-waste-of-time/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/08/14/learning-a-technology-you-dont-need-right-now-is-a-waste-of-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-688">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Just-In-Time learning means you learn a thing because you need to know it right then. Just-In-Case learning means you learn a thing because it may come in handy at some point in your life. This separation is <a href="https://hackernoon.com/just-in-case-vs-just-in-time-learning-c87f61d24360">already well documented</a>, even <a href="https://en.wikipedia.org/wiki/Just-in-time_learning">on Wikipedia</a>.</p>



<p>It gets more interesting when you combine it with <a href="https://www.collaborativefund.com/blog/expiring-vs-permanent-skills/">expiring skills vs. permanent skills</a>. Expiring skills will eventually stop being useful, and permanent skills will be just as useful decades from now as they are today. Permanent skills compound over time, and expiring skills don’t. So if you learn an expiring skill, and don’t end up using it right away, then it’s only a matter of time until that skill is irrelevant, and all your time spent learning it was wasted. </p>



<p>If you know a skill is going to eventually expire, then you should only learn it if you’re sure you can use it. <em>Expiring skills should only be learned Just-In-Time, but permanent skills are worthwhile to learn Just-In-Case</em>. But the tricky and somewhat disappointing bit is that the only skills we can consider permanent are soft skills – things like attitude, discipline, charisma. Hard skills like Typescript and Kubernetes will eventually be obsolete, so learning them Just-In-Case is a waste of time.</p>



<p>But then how can I ever become a well rounded technologist, you ask? You work really freaking hard to get on projects with technology you haven’t used before. If you get an opportunity to hop onto a project using some tech that’s new to you, then do it. </p>



<p>When someone asks for some help with a build system you’ve never used before, raise your hand. When a project needs realtime streaming data and you have no idea how to do it, raise your hand. When a client gets excited about creating an Alexa skill, raise your hand. </p>



<p>Raising your hand gets you the best of both worlds. You get to become a well rounded technologist <em>and</em> avoid wasting your time learning technology you won’t ever use.</p>



<p>So raise your hand to learn the hard skills when they’re needed, and spend your Just-In-Case learning on the stuff that will stick around. Put down the Python book (unless you’re working on a Python project) and pick up the book on habit forming, or dealing with difficult people, or taking ownership. That’s the stuff that will compound for the rest of your life.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/08/14/learning-a-technology-you-dont-need-right-now-is-a-waste-of-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24158268</guid>
            <pubDate>Fri, 14 Aug 2020 14:19:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using 'this' incorrectly in C#]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24158180">thread link</a>) | @jermaustin1
<br/>
August 14, 2020 | https://jeremyaboyd.com/post/you-are-using-this-incorrectly | <a href="https://web.archive.org/web/*/https://jeremyaboyd.com/post/you-are-using-this-incorrectly">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div>
            <div>
                <div>
                    <p>I'm a highly opinionated developer. I've been doing it a little while, and worked with a few other developers, and this is a pet peeve of mine. The <code>this</code> keyword, at least in C#, is oft misused and abused. From henceforth, the context of this post is C# development.</p>
<p>This post seems to have caused a bit of controversy. More to my point, even in base Visual Studio, there are warnings to remove <code>this</code> from your code:
<img src="https://i.imgur.com/9F6Lyx8.png" alt="visual studio 2019"></p>
<p>I've had managers want developers to use <code>this</code> to signify calling a base class's method, which is incorrect. You should be using <code>base</code>.</p>
<pre><code>public class MyClass : YourClass {
    public void MyMethod() {
        if(!base.YourMethod()) return;
    }
}</code></pre>
<p>I've had coworkers who would put <code>this</code> before every method call, because...? When calling your own method, in your own class, that inherits/implements no other classes, why on earth would you decorate your own method call with <code>this</code>?</p>
<p>The only time I have seen prepending <code>this</code> to anything as <em>kind of</em> acceptable, is when you have parameters in a method that are the same as fields/properties on your class, and you need to access those fields/properties inside said method. I am still not a fan of this, but the closest I will get to accepting it is in a constructor where you are passing values that will be stored as <strong>private</strong> fields.</p>
<pre><code>public class SomeClass {
    int maxAmount;
    SomeClass(int maxAmount) =&gt; this.maxAmount = maxAmount;
    ValidateMe(int someValue) =&gt; someValue &lt;= maxAmount;
}</code></pre>
<p>But even in this case, you should really be using Pascal casing as per <a href="https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/capitalization-conventions">Microsoft's Capitalization Conventions</a>. I know, capitalization conventions change over time, and I could have <strong>sworn</strong> there was a time when camel casing was the recommended approach for fields (specifically private fields), but times they are a changing, and cleaner code will hopefully prevail, especially cleaner code without the misuse/abuse of <code>this</code>.</p>
<p>Maybe I'm the only one this matters for, or maybe I'm just having a bad day and came across <code>this</code> too many times this morning. I do hope you agree though.</p>

                </div>
            </div>
        </div>
    </article></div>]]>
            </description>
            <link>https://jeremyaboyd.com/post/you-are-using-this-incorrectly</link>
            <guid isPermaLink="false">hacker-news-small-sites-24158180</guid>
            <pubDate>Fri, 14 Aug 2020 14:11:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Awesome Haskell Videos]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24158019">thread link</a>) | @andys8
<br/>
August 14, 2020 | https://andys8.github.io/awesome-haskell-videos | <a href="https://web.archive.org/web/*/https://andys8.github.io/awesome-haskell-videos">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>A collection of awesome Haskell videos</p>
      
<div><h3><a href="https://youtu.be/fty9QL4aSRc" target="_blank">Vladislav Zavialov - Haskell to Core: Understanding Haskell Features Through Their Desugaring</a></h3>
<div><p><a href="https://youtu.be/fty9QL4aSRc" target="_blank"><img src="https://i.ytimg.com/vi/fty9QL4aSRc/mqdefault.jpg"></a>
<small>2020 - 518 views - 20 likes</small></p><p>Vladislav Zavialov
Haskell programmer since 2012; GHC contributor since 2018. I’m interested in language design, programming language theory, and compiler engineering.

Haskell to Core: Understanding Haskell Features Through Their Desugaring
Haskell is an expressive language with many features. On one hand, it makes Haskell convenient, equipping the programmer with a rich arsenal of tools to get the job done and write high quality software. On the other hand, developing a thorough understandi...</p></div></div>


<div><h3><a href="https://youtu.be/bhhE2DxbrJM" target="_blank">Write a GHC extension in 30 minutes by Richard Eisenberg</a></h3>
<div><p><a href="https://youtu.be/bhhE2DxbrJM" target="_blank"><img src="https://i.ytimg.com/vi/bhhE2DxbrJM/mqdefault.jpg"></a>
<small>2020 - 1823 views - 70 likes</small></p><p>This live-coding session will witness a brand-new (mostly useless) extension to GHC. By watching, you will get a road map of how this is done and what the moving pieces in GHC's front end are: parsing, name resolution, type checking, and error messages.</p></div></div>
<div><h3><a href="https://youtu.be/FYTZkE5BZ-0" target="_blank">Making Music with Haskell From Scratch</a></h3>
<div><p><a href="https://youtu.be/FYTZkE5BZ-0" target="_blank"><img src="https://i.ytimg.com/vi/FYTZkE5BZ-0/mqdefault.jpg"></a>
<small>2020 - 53727 views - 2292 likes</small></p><p>Source Code: https://github.com/tsoding/haskell-music
Note Frequency Math: https://pages.mtu.edu/~suits/NoteFreqCalcs.html

Chapters:
0:00 Producing First Sounds
19:03 Frequency in Hertz
28:06 Semitones
34:10 Attack-Release
43:32 Tempo
46:06 Making Music</p></div></div>

<div><h3><a href="https://youtu.be/frM7GhBERAs" target="_blank">Type Inference from Scratch: A Workshop with Christoph Hegemann</a></h3>
<div><p><a href="https://youtu.be/frM7GhBERAs" target="_blank"><img src="https://i.ytimg.com/vi/frM7GhBERAs/mqdefault.jpg"></a>
<small>2020 - 409 views - 16 likes</small></p><p>Type checking and type inference in particular are often perceived as super-advanced topics, only reserved for specialists, witches, and wizards. In this workshop, Christoph Hegemann will show you that none of that is true, and type checking can be understood by everyone from first principles. To do so, we'll implement a type checker (with inference) for a small functional programming language in Kotlin. After familiarizing ourselves with our language for a few minutes, we'll dive right into ...</p></div></div>
<div><h3><a href="https://youtu.be/nkIMTc1wPaI" target="_blank">World-Building in Haskell with Tom Harding</a></h3>
<div><p><a href="https://youtu.be/nkIMTc1wPaI" target="_blank"><img src="https://i.ytimg.com/vi/nkIMTc1wPaI/mqdefault.jpg"></a>
<small>2020 - 581 views - 20 likes</small></p><p>Procedural generation in game design is becoming more and more common: rather than building thousands of maps or levels, programs generate them according to a set of pre-defined rules. So, now we’re all stuck inside, working on our next platinum indie game, why don’t we try it out?

In this talk, we’ll look at some of the techniques used in procedural generation, discuss how they translate to Haskell, and put it all together in time for our next best-seller.

Tom Harding lives in London and w...</p></div></div>
<div><h3><a href="https://youtu.be/WUDl7ciaYy8" target="_blank">HaskellerZ - April 2020 - Niklas Hambüchen - Asynchronous and Parallel Programming in Haskell</a></h3>
<div><p><a href="https://youtu.be/WUDl7ciaYy8" target="_blank"><img src="https://i.ytimg.com/vi/WUDl7ciaYy8/mqdefault.jpg"></a>
<small>2020 - 1980 views - 57 likes</small></p><p>Zurich Haskell meetup: https://www.meetup.com/HaskellerZ/events/270136648
Code repository: https://github.com/nh2/haskellerz-async-tutorial-2020

Niklas will give a tutorial on asynchronous and parallel programming using the `async` library.

It targets beginner to intermediate Haskellers, as well as anybody who has not used or does not understand `async` yet. If you understand how to do IO in Haskell, you are ready.

After this tutorial you will be able to write correct multi-threaded code e...</p></div></div>
<div><h3><a href="https://youtu.be/geiTNX7AYfI" target="_blank">Haskell in the City</a></h3>
<div><p><a href="https://youtu.be/geiTNX7AYfI" target="_blank"><img src="https://i.ytimg.com/vi/geiTNX7AYfI/mqdefault.jpg"></a>
<small>2020 - 388 views - 18 likes</small></p><p>As HUGE Functional Programming fans (and we know you are too) it was about time ventured our meet-up into Haskell.

Our speakers? They are awesome🤩 VP of FP Complete, Michael Snoyman and Simon Hafner, Functional Compiler Engineer, who are both passionate functional programmers.

📣Simon Hafner, Functional Compiler Engineer @ Input Output
Title: Row Row Row Your Type
Abstract: Every Haskell developer complained about record types at least once. I am here to offer hope of a brighter future.

�...</p></div></div>
<div><h3><a href="https://youtu.be/LEdEOlLlMfM" target="_blank">Your Second Haskell Web App—A Yesod Workshop with Michael Snoyman</a></h3>
<div><p><a href="https://youtu.be/LEdEOlLlMfM" target="_blank"><img src="https://i.ytimg.com/vi/LEdEOlLlMfM/mqdefault.jpg"></a>
<small>2020 - 1306 views - 37 likes</small></p><p>Learn how to build a web app in Haskell with the author of the Yesod framework, Michael Snoyman. Michael recently gave the talk, "Your First Haskell Web App With WAI And Warp" and this is going to be "Part Two with Yesod!"

Michael Snoyman is the Vice President of Engineering at FP Complete, and the founder and lead developer of multiple Haskell open source projects, including Yesod, Conduit, Stack, and Stackage. He regularly speaks about programming best practices and writes articles and tut...</p></div></div>
<div><h3><a href="https://youtu.be/M7NgCq_IaZY" target="_blank">HaskellerZ - March 2020 - Juri Chome &amp; Cazim Hysi - Workshop on building a webservice</a></h3>
<div><p><a href="https://youtu.be/M7NgCq_IaZY" target="_blank"><img src="https://i.ytimg.com/vi/M7NgCq_IaZY/mqdefault.jpg"></a>
<small>2020 - 282 views - 9 likes</small></p><p>Zurich Haskell meetup: https://www.meetup.com/HaskellerZ/events/269475956/
Slides: https://docs.google.com/presentation/d/1j1Yx7ewS-nbyJSwtH3-j6mkVGxfq7ZAViv22jrizthI/edit?usp=sharing

Juri Chome &amp; Cazim Hysi - Workshop on building a webservice

Hi Haskell friends,

So obviously we won't be holding any in-person meetups anytime soon, but that doesn't mean we can't hang out together! Therefore we decided to hold a remote video meetup this month.

We will have a small presentation/tutorial foll...</p></div></div>

<div><h3><a href="https://youtu.be/N9RUqGYuGfw" target="_blank">JSON Parser 100% From Scratch in Haskell (only 111 lines)</a></h3>
<div><p><a href="https://youtu.be/N9RUqGYuGfw" target="_blank"><img src="https://i.ytimg.com/vi/N9RUqGYuGfw/mqdefault.jpg"></a>
<small>2019 - 39295 views - 1276 likes</small></p><p>Twitch: https://www.twitch.tv/tsoding
GitHub Repo: https://github.com/tsoding/haskell-json
My Haskell Setup: https://www.youtube.com/watch?v=5p2Aq3bRuL0

Unusual video this time. This is a slightly edited recording of my Twitch stream. Initially I planned to make a regular video on this topic, but quickly realized that it's just way too much material for a single regular 10 minutes video. So I decided to make a Live Stream where I explain as much information as possible. And since the Stream ...</p></div></div>
<div><h3><a href="https://youtu.be/idU7GdlfP9Q" target="_blank">Lambda World 2019 - Painless software development with Haskell - Paweł Szulc</a></h3>
<div><p><a href="https://youtu.be/idU7GdlfP9Q" target="_blank"><img src="https://i.ytimg.com/vi/idU7GdlfP9Q/mqdefault.jpg"></a>
<small>2019 - 14659 views - 375 likes</small></p><p>In this Lambda World 2019 presentation, Paweł Szulc shows the benefit of programming with Haskell.

Full Presentation Description:

Developers interested in seeing Haskell being used as a general programming language. Engineers hoping to see Haskell as an environment in which one can quickly and effectively iterate between requirements, design and running, executable code - providing value to the business with an immediate feedback loop. Developers eager to see how they can rapidly create sof...</p></div></div>
<div><h3><a href="https://youtu.be/y5jZnMImbMY" target="_blank">Lambda World 2019 - A Series of Unfortunate Effects - Robert M. Avram</a></h3>
<div><p><a href="https://youtu.be/y5jZnMImbMY" target="_blank"><img src="https://i.ytimg.com/vi/y5jZnMImbMY/mqdefault.jpg"></a>
<small>2019 - 2751 views - 122 likes</small></p><p>In this Lambda World 2019 presentation, Robert M. Avram talks about the consequences of effect models.

Full Presentation Description

The very essence of functional programming relies on a fairly simple premise: write side-effectless programs, so that you can reason about them equationally. Side-effects however are predominant in every program that . . . well, does something useful. In light of this, the modelling of effects in functional programs has become a fairly active domain of study. ...</p></div></div>
<div><h3><a href="https://youtu.be/xcm_H36v_18" target="_blank">MuniHac 2019: The many faces of isOrderedTree</a></h3>
<div><p><a href="https://youtu.be/xcm_H36v_18" target="_blank"><img src="https://i.ytimg.com/vi/xcm_H36v_18/mqdefault.jpg"></a>
<small>2019 - 716 views - 14 likes</small></p><p>Title: MuniHac 2019: The many faces of isOrderedTree

Speaker: Joachim @nomeata Breitner, DFINITY Foundation

Abstract:
In this talk, we will look at a seemingly simple programming problem – checking whether the elements in a binary tree are in order – and not only explore many different approaches to solving this problem, but also show how they are all connected. As we do that, we will touch upon equational reasoning, defunctionalization, the worker-wrapper transformation, and more. We learn...</p></div></div>
<div><h3><a href="https://youtu.be/cijsaeWNf2E" target="_blank">MuniHac 2019: Making a Haskell IDE</a></h3>
<div><p><a href="https://youtu.be/cijsaeWNf2E" target="_blank"><img src="https://i.ytimg.com/vi/cijsaeWNf2E/mqdefault.jpg"></a>
<small>2019 - 6026 views - 135 likes</small></p><p>Title: MuniHac 2019: Making a Haskell IDE

Speaker: Neil Mitchell

Abstract:
I've always wanted a Haskell IDE. The absence of a simple and robust solution led me to build Ghcid, which I've been using for many years. However, I have moved on, now using a real Haskell IDE based on technology we developed at Digital Asset for the DAML programming language. It turns out building an IDE is harder than I expected, so in this talk I'll cover three topics:

1. The theory behind building an IDE. We us...</p></div></div>
<div><h3><a href="https://youtu.be/x3evzO8O9e8" target="_blank">Simon Peyton Jones how GHC type inference engine actually works</a></h3>
<div><p><a href="https://youtu.be/x3evzO8O9e8" target="_blank"><img src="https://i.ytimg.com/vi/x3evzO8O9e8/mqdefault.jpg"></a>
<small>2019 - 6450 views - 157 likes</small></p><p>Keynote at ZuriHac 2019

Simon is one of the designers of the Haskell language, an inspiring leader for the whole Haskell community, and the main developer of GHC, the de facto standard Haskell compiler. He also chairs the Computing At School group, which promotes the teaching of computer science at school

Link:
https://zfoh.ch/zurihac2019/#program

www.hsr.ch</p></div></div>
<div><h3><a href="https://youtu.be/2SAQNO46V3U" target="_blank">Brave New World: Tales of PureScript and Haskell in Production</a></h3>
<div><p><a href="https://youtu.be/2SAQNO46V3U" target="_blank"><img src="https://i.ytimg.com/vi/2SAQNO46V3U/mqdefault.jpg"></a>
<small>2019 - 16358 views - 354 likes</small></p><p>The rumours are true. Writing code in purely functional languages tends to produce code that is much easier to read, modify and reason about. This talk examines how an experienced Scala team transitioned into writing production code using PureScript in AWS lambda, and services using Haskell.

EVENT:

Typelevel Summit 2019

SPEAKER:

Felix Mulder

PUBLICATION PERMISSIONS:

Original video was published with the Creative Commons Attribution license (reuse allowed).

ATTRIBUTION CREDITS:

Origina...</p></div></div>
<div><h3><a href="https://youtu.be/4gJ9zsZLv0Y" target="_blank">Do Notation in Haskell</a></h3>
<div><p><a href="https://youtu.be/4gJ9zsZLv0Y" target="_blank"><img src="https://i.ytimg.com/vi/4gJ9zsZLv0Y/mqdefault.jpg"></a>
<small>2019 - 691 views - 11 likes</small></p><p>Code: https://github.com/mjgpy3/presentations/blob/master/lte-haskell/0-DoNotation.hs</p></div></div>
<div><h3><a href="https://youtu.be/qbDQdXfcaO8" target="_blank">Building Terminal User Interfaces with Haskell</a></h3>
<div><p><a href="https://youtu.be/qbDQdXfcaO8" target="_blank"><img src="https://i.ytimg.com/vi/qbDQdXfcaO8/mqdefault.jpg"></a>
<small>2018 - 4489 views - 117 likes</small></p><p>This webinar will explain how to get up and running with making your own TUI applications by live-coding example TUIs with the brick. Terminal User Interfaces are text-based user interfaces for use from a terminal. Great for Haskell programmers to enhance productivity.

This webinar was presented by Tom Sydney Kerckhove.</p></div></div>
<div><h3><a href="https://youtu.be/Xfu-Mt4YDWQ" target="_blank">GTK+ Programming with Haskell</a></h3>
<div><p><a href="https://youtu.be/Xfu-Mt4YDWQ" target="_blank"><img src="https://i.ytimg.com/vi/Xfu-Mt4YDWQ/mqdefault.jpg"></a>
<small>2018 - 6070 views - 174 likes</small></p><p>GTK+, or the GIMP Toolkit, is a multi-platform toolkit for creating user interfaces. In this video we will use the haskell-gi suite of packages to build a simple GTK+ application with Haskell.

Show notes: (coming soon)

Patreon: https://www.patreon.com/haskellatwork</p></div></div>
<div><h3><a href="https://youtu.be/NYjk1kaYIgk" target="_blank">Inspection Testing by Joachim Breitner</a></h3>
<div><p><a href="https://youtu.be/NYjk1kaYIgk" target="_blank"><img src="https://i.ytimg.com/vi/NYjk1kaYIgk/mqdefault.jpg"></a>
<small>2018 - 338 views - 9 likes</small></p><p>Die HSR Hochschule für Technik Rapperswil begrüsste zusammen mit Google, Adjoint, Digital Asset, DFINITY und TWEAG rund 400 …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andys8.github.io/awesome-haskell-videos">https://andys8.github.io/awesome-haskell-videos</a></em></p>]]>
            </description>
            <link>https://andys8.github.io/awesome-haskell-videos</link>
            <guid isPermaLink="false">hacker-news-small-sites-24158019</guid>
            <pubDate>Fri, 14 Aug 2020 13:59:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I'm all in on Circle for online community building]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24157612">thread link</a>) | @JayClouse
<br/>
August 14, 2020 | https://jayclouse.com/how-to-build-an-online-community/ | <a href="https://web.archive.org/web/*/https://jayclouse.com/how-to-build-an-online-community/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wtr-content" data-bg="#FFFFFF" data-fg="#00aeff" data-width="10" data-mute="" data-fgopacity="1.00" data-mutedopacity="0.80" data-placement="bottom" data-placement-offset="0" data-content-offset="0" data-placement-touch="bottom" data-placement-offset-touch="0" data-transparent="" data-touch="1" data-non-touch="1" data-comments="0" data-commentsbg="#ffcece" data-location="page" data-mutedfg="#00aeff" data-rtl=""><p>There’s never been a more relevant time to learn how to build an online community. I’ve spent a lot of time building community over the last seven years. It started in 2012 when I began attending, organizing, and facilitating dozens of Startup Weekend events across the country.</p>
<p>People <em>loved </em>Startup Weekend – especially in the days before the Techstars acquisition. And yes, some notable companies like Zaarly, Beardbrand, and Zapier were started at a Startup Weekend…but people didn’t love Startup Weekend for the “companies” that were started there.</p>
<p>People loved Started Weekend for the community.</p>
<p><picture><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-scaled.webp 2560w,https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-300x200.webp 300w,https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-1024x683.webp 1024w,https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-768x512.webp 768w,https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-1536x1024.webp 1536w,https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-2048x1366.webp 2048w,https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-100x67.webp 100w,https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-900x600.webp 900w,https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-1200x800.webp 1200w" sizes="(max-width: 2560px) 100vw, 2560px" type="image/webp"><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-scaled.jpg 2560w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-300x200.jpg 300w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-1024x683.jpg 1024w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-768x512.jpg 768w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-1536x1024.jpg 1536w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-2048x1366.jpg 2048w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-100x67.jpg 100w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-900x600.jpg 900w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-1200x800.jpg 1200w" sizes="(max-width: 2560px) 100vw, 2560px"><img src="https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-scaled.jpg" alt="Startup Weekend Group Photo 2018" height="1707" width="2560" srcset="https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-scaled.jpg 2560w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-300x200.jpg 300w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-1024x683.jpg 1024w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-768x512.jpg 768w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-1536x1024.jpg 1536w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-2048x1366.jpg 2048w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-100x67.jpg 100w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-900x600.jpg 900w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-1200x800.jpg 1200w" sizes="(max-width: 2560px) 100vw, 2560px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%202560%201707'%3E%3C/svg%3E" data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-scaled.jpg 2560w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-300x200.jpg 300w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-1024x683.jpg 1024w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-768x512.jpg 768w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-1536x1024.jpg 1536w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-2048x1366.jpg 2048w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-100x67.jpg 100w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-900x600.jpg 900w, https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-1200x800.jpg 1200w" data-lazy-src="https://jayclouse.com/wp-content/uploads/2020/08/10781_ES_103-1-scaled.jpg"></picture></p>
<p>And I loved what it felt like to create that space for people. So I kept creating community: from organizing Startup Weekends in the early 2010s to throwing house concerts in 2014-2016.</p>
<p>Then in 2017, I started an online accelerator program, Unreal Collective. That program gave rise to its own online community and <a href="https://unrealcollective.com/community">it’s my favorite place</a> to spend time online.</p>
<p>And that all led to this year, when I was given the opportunity to work with Pat Flynn and the Smart Passive Income team to create their paid, online membership community, <a href="https://www.smartpassiveincome.com/pro">SPI Pro</a>, using <a href="https://jayclouse.com/circle" target="_blank" rel="noopener noreferrer">Circle</a> (more about that <a href="https://www.smartpassiveincome.com/podcasts/taking-business-next-level-spi-pro/">on SPI episode 429</a>).</p>

<p><picture><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM.webp 2210w,https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-300x176.webp 300w,https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-1024x600.webp 1024w,https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-768x450.webp 768w,https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-1536x899.webp 1536w,https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-2048x1199.webp 2048w,https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-100x59.webp 100w,https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-900x527.webp 900w,https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-1200x703.webp 1200w" sizes="(max-width: 2210px) 100vw, 2210px" type="image/webp"><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM.png 2210w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-300x176.png 300w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-1024x600.png 1024w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-768x450.png 768w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-1536x899.png 1536w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-2048x1199.png 2048w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-100x59.png 100w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-900x527.png 900w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-1200x703.png 1200w" sizes="(max-width: 2210px) 100vw, 2210px"><img src="https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM.png" alt="I really studied how to build an online community with SPI Pro" height="1294" width="2210" srcset="https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM.png 2210w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-300x176.png 300w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-1024x600.png 1024w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-768x450.png 768w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-1536x899.png 1536w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-2048x1199.png 2048w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-100x59.png 100w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-900x527.png 900w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-1200x703.png 1200w" sizes="(max-width: 2210px) 100vw, 2210px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%202210%201294'%3E%3C/svg%3E" data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM.png 2210w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-300x176.png 300w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-1024x600.png 1024w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-768x450.png 768w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-1536x899.png 1536w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-2048x1199.png 2048w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-100x59.png 100w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-900x527.png 900w, https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM-1200x703.png 1200w" data-lazy-src="https://jayclouse.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-09-at-10.35.43-PM.png"></picture></p>
<p>This opportunity to build an online community from the ground up gave me the excuse to really study what it means to build community (both online and offline) and validate a lot of my own assumptions.</p>
<p>And tl;dr: I’m all in on <a href="https://jayclouse.com/circle" target="_blank" rel="noopener noreferrer">Circle</a>, and I’ll explain why below.</p>
<p>But before I can share all the lessons learned, we need to start from the beginning.</p>

<h2>What is community?<span></span></h2>
<p>Community means a lot of different things to different people. To me, community is a group of people with commonality – shared interests, values, or beliefs.</p>
<p>With Startup Weekend, we all shared an interest in technology, but we also shared values like ambition, kindness, and generosity too.</p>
<p>At any given Startup Weekend event, I knew I’d leave with some new, lifelong friendships. And the connection I felt with other people at a Startup Weekend is what made that community so special.</p>
<p>In fact, connection is what makes <em>any </em>community special.</p>
<p>I believe people are drawn to community for three core reasons:</p>
<ol>
<li>Human connection</li>
<li>Transformation</li>
<li>Finding a sense of identity</li>
</ol>
<p>Let’s break each of those down.</p>
<h3>Human connection</h3>
<p>The experience of community goes back to the beginning of humans. We’re a social species and we relied on cooperation to survive.</p>
<p>Community was built into our lives when we lived in a tribal setting. Our community was the people we lived around day in and day out – the people we hunted and gathered with!</p>
<p>We felt that we <strong>belonged </strong>to that tribe. And there’s a lot of comfort in belonging.</p>
<p>As civilization evolved, humans became more socially isolated. Forget about living in tribes – we want to move out of our parents’ house and into our own studio apartments as quickly as we can!</p>
<p>But our brains haven’t actually evolved past that desire for close social connections – our lifestyle has. Our cultural expectations have.</p>
<p>And so we seek out that missing human, social connection elsewhere. We seek out that sense of belonging that we’re missing.</p>
<p>We seek out community.</p>
<h4>Connection through shared experience</h4>
<p>Often, one of the easiest ways to find connection is through shared experience. When we share an experience together, whether it’s a tailgate, an escape room, or starting at a new school, we start from a known commonality.</p>
<p>Commonalities give humans something to talk about and bond over. It’s that shared experience that starts conversation, creates a relationship, and ultimately makes us feel connected to one another.</p>
<h3>Transformation</h3>
<p>We also look to other humans to help us grow.</p>
<p>And when we’re looking to make a change, there are communities there to help.</p>
<p>A great example here is the Crossfit or any fitness-based community. When you join a fitness community, you’re seeking very tangible, physical transformation.</p>
<p>Physical transformations (gaining muscle, losing weight) are easy to recognize in ourselves. We seek out psychological and knowledge transformations too – though they may be a little little harder to recognize.</p>
<p>But when you join a coding bootcamp and leave being able to build a web app, you see the transformation.</p>
<p><picture><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-scaled.webp 2560w,https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-300x200.webp 300w,https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-1024x683.webp 1024w,https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-768x512.webp 768w,https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-1536x1024.webp 1536w,https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-2048x1365.webp 2048w,https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-100x67.webp 100w,https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-900x600.webp 900w,https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-1200x800.webp 1200w" sizes="(max-width: 2560px) 100vw, 2560px" type="image/webp"><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-scaled.jpg 2560w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-300x200.jpg 300w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-1024x683.jpg 1024w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-768x512.jpg 768w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-1536x1024.jpg 1536w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-2048x1365.jpg 2048w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-100x67.jpg 100w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-900x600.jpg 900w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-1200x800.jpg 1200w" sizes="(max-width: 2560px) 100vw, 2560px"><img src="https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-scaled.jpg" alt="Crossfit can teach us a lot about how to build an online community" height="1706" width="2560" srcset="https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-scaled.jpg 2560w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-300x200.jpg 300w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-1024x683.jpg 1024w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-768x512.jpg 768w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-1536x1024.jpg 1536w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-2048x1365.jpg 2048w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-100x67.jpg 100w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-900x600.jpg 900w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-1200x800.jpg 1200w" sizes="(max-width: 2560px) 100vw, 2560px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%202560%201706'%3E%3C/svg%3E" data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-scaled.jpg 2560w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-300x200.jpg 300w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-1024x683.jpg 1024w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-768x512.jpg 768w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-1536x1024.jpg 1536w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-2048x1365.jpg 2048w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-100x67.jpg 100w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-900x600.jpg 900w, https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-1200x800.jpg 1200w" data-lazy-src="https://jayclouse.com/wp-content/uploads/2020/08/gym-connection-scaled.jpg"></picture></p>
<h3>A sense of identity</h3>
<p>Most of us are in a constant battle to understand ourselves. With social media and comparison traps around us all the time, a lot of us have a hard time really knowing who we are and what we care about.</p>
<p>When you ask someone to introduce themselves, they’ll probably launch right into their work. “I’m [position] at [company].”</p>
<p>Our work shouldn’t define our identity – but it gives us something to tether ourselves to when we don’t have a better sense of who we are.</p>
<p>Community provides an alternative.</p>
<p>When someone joins a community, connects with others or experiences transformation, they learn something about themselves. They learn more about their own interests, and those interests may be stronger than their day-to-day work.</p>
<p>That’s why we see so many people identify with Crossfit or Yoga or even volunteering for a nonprofit.</p>
<p><picture><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-scaled.webp 2560w,https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-300x169.webp 300w,https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-1024x576.webp 1024w,https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-768x432.webp 768w,https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-1536x864.webp 1536w,https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-2048x1152.webp 2048w,https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-100x56.webp 100w,https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-900x506.webp 900w,https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-1200x675.webp 1200w" sizes="(max-width: 2560px) 100vw, 2560px" type="image/webp"><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-scaled.jpg 2560w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-300x169.jpg 300w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-1024x576.jpg 1024w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-768x432.jpg 768w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-1536x864.jpg 1536w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-2048x1152.jpg 2048w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-100x56.jpg 100w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-900x506.jpg 900w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-1200x675.jpg 1200w" sizes="(max-width: 2560px) 100vw, 2560px"><img src="https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-scaled.jpg" alt="Social movements like the Womens March can teach us a lot about how to build an online community" height="1440" width="2560" srcset="https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-scaled.jpg 2560w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-300x169.jpg 300w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-1024x576.jpg 1024w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-768x432.jpg 768w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-1536x864.jpg 1536w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-2048x1152.jpg 2048w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-100x56.jpg 100w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-900x506.jpg 900w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-1200x675.jpg 1200w" sizes="(max-width: 2560px) 100vw, 2560px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%202560%201440'%3E%3C/svg%3E" data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-scaled.jpg 2560w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-300x169.jpg 300w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-1024x576.jpg 1024w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-768x432.jpg 768w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-1536x864.jpg 1536w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-2048x1152.jpg 2048w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-100x56.jpg 100w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-900x506.jpg 900w, https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-1200x675.jpg 1200w" data-lazy-src="https://jayclouse.com/wp-content/uploads/2020/08/Womens-March-Movement-scaled.jpg"></picture></p>
<h4>Finding identity in a movement</h4>
<p>Sometimes, community offers us the opportunity to identify with an idea bigger than ourselves. These communities go beyond shared values and actually call their community members to action.</p>
<p>These communities become a movement. People join a movement because they want to see change, and every member of the community powering a movement has the same shared goal.</p>
<p>When we are part of a movement, we feel that same belonging and connection of other communities, but may even begin to identify with that movement.</p>
<p>And, of course, the best movements exist to create change (transformation) too.</p>
<p>So, any way you slice it, the most thriving communities help us find connection, facilitate transformation, or help us to better understand ourselves and our identity.</p>
<h2>Building community in real life<span></span></h2>
<p>We’ve been part of communities throughout our whole lives. Your graduating class, the clubs you joined in high school or college, your college dorm, local meetup groups…</p>
<p>Any group that you’ve belonged to through shared interests or shared experience is, on some level, a community.</p>
<p>A graduating class is a social cohort with a shared goal: complete your courses, graduate on time. You have the shared experience of joining that cohort at the same time, and you’re pursuing the same transformation: becoming a graduate.</p>
<p>Meetup groups are built around shared interests like painting, anime, yoga, or anything else. We go to these meetups because we feel like we belong there.</p>
<p>We’ve gotten <em>really good </em>at creating in person, analog communities – we’ve had all of evolutionary history to figure it out!</p>
<p>As long as we have a reason for gathering people into a common space, it’s easy to convey that reason and create a sense of belonging.</p>
<p><picture><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community.webp 1836w,https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-300x200.webp 300w,https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-1024x683.webp 1024w,https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-768x512.webp 768w,https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-1536x1024.webp 1536w,https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-100x67.webp 100w,https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-900x600.webp 900w,https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-1200x800.webp 1200w" sizes="(max-width: 1836px) 100vw, 1836px" type="image/webp"><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community.jpg 1836w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-300x200.jpg 300w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-1024x683.jpg 1024w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-768x512.jpg 768w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-1536x1024.jpg 1536w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-100x67.jpg 100w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-900x600.jpg 900w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-1200x800.jpg 1200w" sizes="(max-width: 1836px) 100vw, 1836px"><img src="https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community.jpg" alt="GiveBackHack Community" height="1224" width="1836" srcset="https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community.jpg 1836w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-300x200.jpg 300w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-1024x683.jpg 1024w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-768x512.jpg 768w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-1536x1024.jpg 1536w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-100x67.jpg 100w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-900x600.jpg 900w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-1200x800.jpg 1200w" sizes="(max-width: 1836px) 100vw, 1836px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201836%201224'%3E%3C/svg%3E" data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community.jpg 1836w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-300x200.jpg 300w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-1024x683.jpg 1024w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-768x512.jpg 768w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-1536x1024.jpg 1536w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-100x67.jpg 100w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-900x600.jpg 900w, https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community-1200x800.jpg 1200w" data-lazy-src="https://jayclouse.com/wp-content/uploads/2020/08/givebackhack-community.jpg"></picture></p>
<p>But analog community is much easier than digital community, because <strong>physical space creates discomfort</strong>. When we show up to a space and may not immediately recognize anyone, we’re filled with equal parts fear and excitement.</p>
<p>We’re afraid to be alone. We’re afraid that the group will decide that we don’t belong. But at the same time, we’re eager for connection.</p>
<p>And that discomfort creates a healthy tension that we often solve by walking up to someone, extending our hand, and saying, “Hi, I’m Jay.”</p>
<p>That’s the magic of physical space. If we show up, we will usually push through the discomfort of feeling like we don’t belong until we feel like we do.</p>
<p>After all, it’s equally embarrassing to walk right back out the door in front of everyone. People who we may see again in our local community!</p>
<p>And in great communities, existing members will notice anyone feeling that discomfort and welcome them in.</p>
<h2><span id="why-many-online-communities-fail"></span>Why many online communities fail<span></span></h2>
<p>On its face, it seems like it should be easy to translate analog communities into digital communities. And even better, because they’re digital, they can scale! You don’t <em>need </em>to be in the same city to connect over your shared love of <em>Hamilton</em>.</p>
<p>But, very quickly, most online communities fall flat.</p>
<h3>The wrong motivation for building your online community</h3>
<p>Many online communities are started purely for selfish reasons. The creator thinks of it as purely an effort to build their audience.</p>
<p><em>If I create a community, it will self-govern, people will invite others in, and my brand will be at the center of their universe.</em></p>
<p>When creators follow <em>this </em>logic – when the online community is built to serve the creator – it’s doomed from the start.</p>
<p>Community has to be about serving people. If you aren’t serving people – if people aren’t finding connection, transformation, or identity within the space – then it will fail.</p>
<p>And any community managers will tell you, fostering online community is a LOT of time and a LOT of work.</p>
<p>If you aren’t planning to dedicate a huge amount of time and resources from the beginning…if you believe that the community will be so emergent that it will self-govern and thrive from day one, you’re wasting your time.</p>
<h3>Lack of intention in building your online community</h3>
<p>In the analog world, if we have a reason for gathering and a space to gather in, the hardest part is just bringing people into that space.</p>
<p>Because as I shared before, the discomfort of feeling like an outsider in a physical space will propel us into connecting with people until we no longer feel like an outsider.</p>
<p>So in the world of online communities, we overestimate the power of the platform. Tools like Discord, Discourse, Slack, Mighty Networks, and Facebook Groups all promise to give you the ROOM to gather your online community.</p>
<p>So creators pick their favorite tool and create an account.</p>
<p>Sometimes the creators of these communities do a really good job of configuring that digital space with specific channels and spaces for specific causes too.</p>
<p>In theory, that’s great! Of course a thriving online community would utilize all of these specific spaces so that they could have even more confidence that <em>this </em>area is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jayclouse.com/how-to-build-an-online-community/">https://jayclouse.com/how-to-build-an-online-community/</a></em></p>]]>
            </description>
            <link>https://jayclouse.com/how-to-build-an-online-community/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24157612</guid>
            <pubDate>Fri, 14 Aug 2020 13:24:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything I've learned From Morgan Housel]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24157212">thread link</a>) | @louischew
<br/>
August 14, 2020 | https://constantrenewal.com/morgan-housel/ | <a href="https://web.archive.org/web/*/https://constantrenewal.com/morgan-housel/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="2193" data-elementor-settings="[]"><div><div><section data-id="8884f17" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;}"></section><section data-id="8b707de" data-element_type="section"></section><section data-id="94d7fa9" data-element_type="section"><div><div><div data-id="58e3509" data-element_type="column"><div><div><div data-id="0846cd8" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Morgan Housel is one of the most fascinating people I know.</p><p>A former financial columnist, Morgan is now a partner at Collaborative Fund. I imagine his job involves identifying and investing in the companies of tomorrow, but I know him for the pithy wisdom he puts out weekly.&nbsp;</p><p>As expected, he writes about finance and investing. What’s unexpected is that a lot of the lessons that you can learn aren’t confined to just that field. There’s history, psychology, business, and pretty much anything you can apply to your own life.&nbsp;</p><p>I’ve went back in time to dig up his articles since his days as a columnist and put them into categories. You’ll find that they overlap, which is another sign that Morgan draws from multiple disciplines in his writing.&nbsp;</p><p>If you want more, check out his latest book,&nbsp;<a href="https://geni.us/KJixVU" target="_blank">The Psychology of Money.</a>&nbsp;</p></div></div></div></div></div></div></div></div></section><section data-id="004196a" data-element_type="section"></section><section data-id="c88a5d7" data-element_type="section"><div><div><div data-id="36df759" data-element_type="column"><div><div><div data-id="3f776d8" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Many Powerful Ideas Are Simple</p><p>Morgan’s&nbsp;<a href="https://www.fool.com/investing/2016/06/21/simple-financial-advice-for-new-grads.aspx" target="_blank" rel="noopener">lesson for newcomers</a>&nbsp;to finance that’s applicable to everything else:&nbsp;</p><blockquote><p>Simple almost always beats complex. That’s true for investing, mortgages, insurance, and everything else related to money. If there’s one thing I wish I knew when I graduated, it’s that.&nbsp;</p></blockquote><p>Simple rules triumph in a complex world. <a href="https://constantrenewal.com/boninis-paradox">Bonini’s Paradox</a> states that the more complete a model of a complex system, the less understandable it becomes. Morgan provides one more reason why we shouldn’t pursue complexity: you’re going to make mistakes:&nbsp;</p><blockquote><p><span data-token-index="0" data-reactroot="">If you’re going to act on a problem that is monstrously complex and uncertain, the stripped-down, rules-of-thumb response is not only good enough. It can be superior to tripping over yourself in pursuit of something that appears marginally more accurate.</span></p></blockquote><p><span>Complexity can also be misleading:</span></p><blockquote><p><em>The U.S. constitution is 7,591 words. A typical business management book covering a single topic is perhaps 250 pages, or something like 65,000 words. […]<br></em><em><br></em><em>Complexity gives a comforting impression of control, while simplicity is hard to distinguish from cluelessness. In most fields a handful of variables dictate the majority of outcomes. But only paying attention to those few variables can feel like you’re leaving too much of the outcome to fate. The more knobs you can fiddle with – the 100-tab spreadsheet, or the Big Data analysis – the more control you feel you have over the situation, if only because the impression of knowledge increases.</em></p></blockquote><p><span>There’s a simple idea in investing. If you want to know what stock to buy, look at Main Street instead of Wall Street. The power of taking this simple idea seriously might surprise you:&nbsp;</span></p><blockquote><p><span>J.M. Smucker makes jelly and instant coffee. Its stock is up 1,211% since 1995. Microsoft changed how almost every human on the planet processes information. Its stock is up less, 1,183% since 1995. McCormick makes garlic powder. Its stock is up 1,423% since 1995. Oracle has a near-monopoly database management software. Its stock is up 1,419% since 1995. V.F. Corp makes jeans and flip-flops. Its stock is up 1,444% since 1995. Cisco Systems connects the entire world together in one place. Its stock is up 1,018% since 1995. Valspar makes industrial coatings, and has returned 1,521% since 1995. Adobe makes some of the most popular software in the world, and has returned 1,230%. Google is one of the most exciting companies of all time. Its stock is up 345% since 2008. Altria makes cigarettes in the rapidly declining U.S. market. Its stock is up 494% since 2008.</span></p><p>The best-performing industry over the last 50 years, by far, is consumer staples – things like food, toothpaste, and toilet paper. The worst-performing industry, by far, is technology.</p></blockquote><p><span>Granted, this was in 2016, and technology stocks have since soared. But it’s amazing how such a simple idea has served as a reliable guide for investors who have decided to pick their own stocks.&nbsp;</span></p><p><span>And among the simple ideas shared by Morgan, this is my favourite. Nothing comes close to this mix of prose and math:&nbsp;</span></p><blockquote><p>What if Buffett got serious about investing when he was age 22 – just out of college – instead of age 10? Imagine he spends his 20s learning about investments, and his net worth at age 30 was in the still-impressive 90th percentile. Using today’s net worth percentiles and adjusting them for 1960s-era inflation, that would mean he’d be worth about $24,000 at age 30. Now we can do some fun calculations. If, at age 30, Buffett was worth $24,000 instead of the $1 million he actually accumulated, and went on to earn the same returns, how much would he be worth today? $1.9 billion. That’s 97.6% lower than his actual net worth of $81 billion.</p><p>The punchline is that 97.6% of Buffett’s current success can be directly tied to the base he built in his teens and 20s. Like World War II-era stuff. $1.9 billion is nothing sneeze at. But you’d need twice as much to make Bloomberg’s list of 500 richest people in the world. Which is to say: Without the capital base Buffett built before he could grow a beard, you’d probably never have heard of him.</p><p>[…] It is so easy to overlook how powerful it can be to take something small and hammer away at it, year after year, without stopping. Because it’s easy to overlook, we miss the key ingredients of what caused big things to get big. How can most of Buffett’s success be attributed to what he did as a teenager? It’s so crazy, so counterintuitive. And since it’s crazy and counterintuitive we overlook the right lessons. So we write 2,000 books on how Buffett sizes up management teams when the biggest and most practical takeaway from his success is, “Start investing when you’re in third grade.”</p></blockquote><p><span>It sounds simple. And it is. But don’t mistake simple for easy.&nbsp;</span></p><blockquote><span>Everyone wants a shortcut. It’s always been this way, but I suspect it’s getting worse as technology inflates our benchmark of how fast results should happen. Hacks are appealing because they look like paths to prizes without the effort. Which, in the real world, rarely exists.&nbsp;<br></span><span><br></span><span>There’s a scene in Lawrence of Arabia where one man puts out a match with his fingers, and doesn’t flinch. Another man watching tries to do the same, and yells in pain. “It hurts! What’s the trick?” he asks.&nbsp;<br></span><span><br></span><span>“The trick is not minding that it hurts”, the first man says. Another useful hack.</span></blockquote></div></div></div></div></div></div></div></div></section><section data-id="993a38d" data-element_type="section"><div><div><div data-id="7c2c60c" data-element_type="column"><div><div><div data-id="c445764" data-element_type="widget" data-widget_type="text-editor.default"><div><div><h2>Risk and Luck</h2><p>Risk means there’ll always be outcomes outside your control.</p><blockquote><p>Not every poor investment is the result of a poor decision. No matter your strategy, investing is a game of probabilities. And even really high-probability bets won’t always work out in your favor. Just as you can be right for the wrong reasons, you can be wrong for the right reasons. … You can be wrong half the time and still make a fortune … You shouldn’t play Russian Roulette even if the odds are in your favor.&nbsp;</p></blockquote><p>We lie to ourselves about risk.&nbsp;</p><blockquote><p><span data-token-index="0" data-reactroot="">Risk and luck are different sides of the same coin, but we treat one as critically important, and the other like it doesn’t exist – at least for you, when you succeed. This is partly about ego, but even more about the desire to identify patterns of what works, relishing the thought of repeating those actions to win again in the future. We love narratives that explain things, and the most comfortable narrative is, “I’m good at this and will continue to be good at it.”</span></p></blockquote><p><span data-token-index="0" data-reactroot=""><a href="http://.https//www.collaborativefund.com/blog/risk-is-what-you-dont-see/" target="_blank" rel="noopener">Risk is what you don’t see</a>:</span></p><blockquote><p><span data-token-index="0" data-reactroot=""><span data-token-index="0" data-reactroot="">Paying attention to known risks is smart. But we should acknowledge that what can’t see, aren’t talking about, and aren’t prepared for will likely be more consequential than all the known risks combined.&nbsp;That’s how history has worked.</span></span></p></blockquote><p><span data-token-index="0" data-reactroot=""><span data-token-index="0" data-reactroot="">There are normal consequences of risk, and then there are tail end consequences. The tails are all that matter.</span></span></p><blockquote>In investing, the average consequences of risk make up most of the daily news headlines. But the tail-end consequences of risk – like pandemics, and depressions – are what make the pages of history books.&nbsp;They’re all that matter. They’re all you should focus on. We spent the last decade debating whether economic risk meant the Federal Reserve set interest rates at 0.25% or 0.5%. Then 36 million people lost their jobs in two months because of a virus. It’s absurd.<p>Tail-end events are all that matter. Once you experience it, you’ll never think otherwise.</p></blockquote></div></div></div></div></div></div></div></div></section><section data-id="6cf5aa7" data-element_type="section"><div><div><div data-id="387b858" data-element_type="column"><div><div><div data-id="49547a3" data-element_type="widget" data-widget_type="text-editor.default"><div><div><h2>Perspective</h2><div><p>Morgan has an answer to why people disagree about economic data. His intuition is spot on in other areas too, whether it’s politics, social issues, or science.&nbsp;</p><blockquote>Most economic data references “the economy,” in the aggregate or average. But no one lives in the economy. They live in their economy. And the difference between “the” and “their” is now enormous, and growing.</blockquote></div><p>The world has improved over time, and that’s a reason to be optimistic. Why are people pessimistic then? What does that tell us?</p><blockquote>Pessimism comes across as smart because it appears to be cognisant of risks, appeals to those who believe that misery loves company, often provides a call for action, sounds like someone trying to help you, and is often based on an extrapolation of current trends. However, pessimists are the best indication of what’s unsustainable, and thus probably about to change, and thus the soil of what’s to be optimistic about.&nbsp;</blockquote><p>Keep your eye on the ball. Don’t lose sight of what’s important.</p><blockquote><span data-token-index="0" data-reactroot="">An owner walks a dog on a generally predictable route, though along its way, the dog jumps around randomly, stops to smell leaves, and barks at other dogs. The owner and the dog in this scene can be analogised to businesses and markets respectively. What is surprising]</span> <span data-token-index="2" data-reactroot="">is that almost all investors, big and small, seem to have their eye on the dog, and not the owner.</span> <span data-token-index="4" data-reactroot="">As you navigate your life as an investor, pay more attention to the owner (businesses) and less to the dog (markets).&nbsp;</span></blockquote><p>Options should always be weighed against their alternatives:</p><blockquote><span data-token-index="0" data-reactroot="">Awful decisions can be smart if the alternative is worse …</span> <span data-token-index="2" data-reactroot="">Chesley Sullenberger intentionally steered an Airbus A320 into the Hudson River with 150 passengers onboard. Which is something you should never, ever do. Unless your plane has lost power and the only other option is to crash into the world’s second largest city. Then it is absolutely the best thing to do, and will turn you into a hero.</span></blockquote><p>Another …</p></div></div></div></div></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://constantrenewal.com/morgan-housel/">https://constantrenewal.com/morgan-housel/</a></em></p>]]>
            </description>
            <link>https://constantrenewal.com/morgan-housel/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24157212</guid>
            <pubDate>Fri, 14 Aug 2020 12:52:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unicode in five minutes (2013)]]>
            </title>
            <description>
<![CDATA[
Score 263 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24157201">thread link</a>) | @jstanley
<br/>
August 14, 2020 | https://richardjharris.github.io/unicode-in-five-minutes.html | <a href="https://web.archive.org/web/*/https://richardjharris.github.io/unicode-in-five-minutes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <!-- /.post-info -->      <h2>Why</h2>
<p>One encoding covering <em>most</em> of the world’s writing systems. Standard
encoding of the web, most operating systems, Java and .NET.</p>
<p>Before Unicode, each script (or script family) had its own encoding, or
worse, lots of different incompatible encodings. Unicode is a superset
of almost all of them, so can be used for interchange.</p>
<p>It’s been around for <a href="http://www.unicode.org/history/unicode88.pdf">over 30 years</a>.</p>
<p><em>Note: code examples are Perl-centric so far, because it has really good Unicode
support and I know it; if you have examples for other languages, please do post
a comment!</em></p>
<h2>What</h2>
<p><img alt="Unicode character examples" src="https://richardjharris.github.io/static/images/unichar-examples.png"></p>
<p>Unicode defines a <em>code point</em> (number) for every character, such as <span><span data-code="0061" data-name="LATIN SMALL LETTER A" title="LATIN SMALL LETTER A (U+0061)">a</span></span>, <span><span data-code="00E3" data-name="LATIN SMALL LETTER A WITH TILDE" title="LATIN SMALL LETTER A WITH TILDE (U+00E3)">ã</span></span>,
<span><span data-code="06D0" data-name="ARABIC LETTER E" title="ARABIC LETTER E (U+06D0)">ې</span></span>, <span><span data-code="4E0D" data-name="CJK UNIFIED IDEOGRAPH-4E0D" title="CJK UNIFIED IDEOGRAPH-4E0D (U+4E0D)">不</span></span> and <span><span data-code="2603" data-name="SNOWMAN" title="SNOWMAN (U+2603)">☃</span></span>. As of <a href="http://www.unicode.org/versions/Unicode6.2.0/">Unicode 6.2</a> there are <strong>109,976</strong> code points!
<em>(You can mouseover any highlighted character for more information.)</em></p>
<p>It also includes <em>combining characters</em> such as <span><span data-code="0300" data-name="COMBINING GRAVE ACCENT" title="COMBINING GRAVE ACCENT (U+0300)">◌̀</span></span> which can be added to
other characters; this way, Unicode does not need a code point for every possible
combination of letter and accent. On the other hand, Unicode <em>generally</em> doesn’t care
about fonts or stylistic differences: it gives <img alt="a (double-story)" src="https://richardjharris.github.io/static/images/a1.png">
and <img alt="a (single-story)" src="https://richardjharris.github.io/static/images/a2.png"> the same codepoint.</p>
<p>It’s <em>more than just a character set</em>: it also covers standard encodings such
as UTF-8; <nobr>lower/upper/title</nobr> case mapping; collation (sorting); line breaks;
rendering; right-to-left script handling, and more.</p>
<h2>Normalization</h2>
<p>For compatibility with other encodings Unicode sometimes includes <em>precomposed</em>
versions of characters, for example, these three:</p>
<ul>
<li><span><span data-code="00C5" data-name="LATIN CAPITAL LETTER A WITH RING ABOVE" title="LATIN CAPITAL LETTER A WITH RING ABOVE (U+00C5)">Å</span><span> LATIN CAPITAL LETTER A WITH RING ABOVE (U+00C5)</span></span></li>
<li><span><span data-code="212B" data-name="ANGSTROM SIGN" title="ANGSTROM SIGN (U+212B)">Å</span><span> ANGSTROM SIGN (U+212B)</span></span></li>
<li><span><span data-code="0041" data-name="LATIN CAPITAL LETTER A" title="LATIN CAPITAL LETTER A (U+0041)">A</span><span> LATIN CAPITAL LETTER A (U+0041)</span></span> + <span><span data-code="030A" data-name="COMBINING RING ABOVE" title="COMBINING RING ABOVE (U+030A)">◌̊</span><span> COMBINING RING ABOVE (U+030A)</span></span></li>
</ul>
<p>For these to be treated as the same string in equality tests etc. you should
run all input through <a href="http://unicode.org/reports/tr15/">Unicode normalisation</a>. The most common form is
<abbr title="Normalisation Form C (canonical decomposition + canonical composition)">NFC</abbr>, which uses pre<strong>C</strong>omposed characters where possible, and defines a strict ordering
of diacritics if more than one exists. <abbr title="Normalization Form D (canonical decomposition)">NFD</abbr> <strong>D</strong>ecomposes characters where possible.<sup id="fnref:gory"><a href="#fn:gory" rel="footnote">1</a></sup></p>
<p>It doesn’t matter what form you use as long as you are consistent; NFD is
faster in general (fewer codepoints) and <a href="http://stackoverflow.com/a/6163129/74496">tchrist</a> suggests running input
through NFD and output through NFC.</p>
<p><strong>Compatibility decomposition</strong> also maps characters such as <span><span data-code="FB03" data-name="LATIN SMALL LIGATURE FFI" title="LATIN SMALL LIGATURE FFI (U+FB03)">ﬃ</span></span>, <span><span data-code="2168" data-name="ROMAN NUMERAL NINE" title="ROMAN NUMERAL NINE (U+2168)">Ⅸ</span></span>
and even <span><span data-code="2075" data-name="SUPERSCRIPT FIVE" title="SUPERSCRIPT FIVE (U+2075)">⁵</span></span> to ‘ffi’, ‘IX’ and ‘5’ respectively. This <abbr title="Normalization Form KC (compatibility decomposition + canonical composition)">NFKC</abbr> normalisation
helps when searching for text.</p>
<div><pre><span>#!/usr/bin/perl</span>
<span>use</span> <span>Unicode::</span><span>Normalize</span><span>;</span>
<span>my</span> <span>$norm</span> <span>=</span> <span>NFD</span><span>(</span><span>$str</span><span>);</span>
</pre></div>


<hr>
<div><pre><span>#!/usr/bin/python</span>
<span>import</span> <span>unicodedata</span>
<span>norm</span> <span>=</span> <span>unicodedata</span><span>.</span><span>normalize</span><span>(</span><span>'NFC'</span><span>,</span> <span>string</span><span>)</span>
</pre></div>


<hr>
<div><pre><span>#!/usr/bin/ruby</span>
<span># gem install unicode_utils</span>
<span>require</span> <span>"unicode_utils/nfc"</span>
<span>norm</span> <span>=</span> <span>UnicodeUtils</span><span>.</span><span>nfc</span><span>(</span><span>string</span><span>)</span>
</pre></div>


<h2>Casefolding</h2>
<p>Casing is not so simple in the Unicode world:</p>
<ul>
<li>
<p>Some strings actually change length when they change case: <span><span data-code="00DF" data-name="LATIN SMALL LETTER SHARP S" title="LATIN SMALL LETTER SHARP S (U+00DF)">ß</span></span> uppercases
  to ‘SS’.</p>
</li>
<li>
<p><span><span data-code="017F" data-name="LATIN SMALL LETTER LONG S" title="LATIN SMALL LETTER LONG S (U+017F)">ſ</span><span> LATIN SMALL LETTER LONG S</span></span> should be seen as equal to ‘s’ and ‘S’ in case-insensitive comparisons.</p>
</li>
<li>
<p><span><span data-code="03A3" data-name="GREEK CAPITAL LETTER SIGMA" title="GREEK CAPITAL LETTER SIGMA (U+03A3)">Σ</span><span> GREEK CAPITAL LETTER SIGMA</span></span> has <em>two</em> lowercase forms: <span><span data-code="03C3" data-name="GREEK SMALL LETTER SIGMA" title="GREEK SMALL LETTER SIGMA (U+03C3)">σ</span></span> at the beginning or middle of the
  word, and <span><span data-code="03C2" data-name="GREEK SMALL LETTER FINAL SIGMA" title="GREEK SMALL LETTER FINAL SIGMA (U+03C2)">ς</span></span> at the end of a word.</p>
</li>
<li>
<p>Casing is <em>mostly</em> consistent across locales, but Turkish is an exception: it
  has both a <a href="https://en.wikipedia.org/wiki/Dotted_and_dotless_I">Dotted and dotless I</a>, in both lower and upper cases.</p>
</li>
</ul>
<p>To ensure your code handles these cases, and any new ones, Unicode provides a
<em>one-way</em> ‘casefold’ operation that allows case-insensitive comparison:</p>
<div><pre><span>#!/usr/bin/perl</span>
<span>use</span> <span>Unicode::</span><span>CaseFold</span><span>;</span>   <span># or: use v5.16;</span>
<span>sort</span> <span>{</span> <span>fc</span><span>(</span><span>$a</span><span>)</span> <span>cmp</span> <span>fc</span><span>(</span><span>$b</span><span>)</span> <span>}</span> <span>@stuff</span><span>;</span>
</pre></div>


<p>Casefolding does <em>not</em> include normalization, so do that too.</p>
<h2>Sorting</h2>
<p>Sorting (or <em>collation</em>) is <strong>locale specific</strong> and just as riddled with
pecularities as casing:</p>
<ul>
<li>
<p>German and Swedish both have ä and ö but sort them differently - German
    treats them as variants of the same letters without umlauts (i.e. ‘a<strong>ä</strong>bcdefghijklmno<strong>ö</strong>pqrstuvwxyz’)
    whereas Swedish considers them new letters, and puts them at the end (‘abcdefghijklmnopqrstuvwxyz<strong>äö</strong>‘)</p>
<p>It’s important that things are sorted in the order the user expects.</p>
</li>
<li>
<p>Sorting varies by application too; phonebooks are often sorted differently to book
    indices, for example.</p>
</li>
<li>
<p>For Chinese characters and other ideographs, there are many possible orders, e.g.
    pinyin (phonetic), by stroke count, etc.</p>
</li>
<li>
<p>Collations can be <em>tailored</em> based on user preferences, e.g. lower or upper-case first?</p>
</li>
</ul>
<p>It’s not enough to just sort by binary comparison. And codepoints aren’t generally in any
sensible order either. Fortunately Unicode specifies a <a href="http://www.unicode.org/reports/tr10/">Collation Algorithm</a>
that is immensely customisable, covers all the edge-cases, and does clever things to make
it reasonably fast. Here’s an example:<sup id="fnref:locale"><a href="#fn:locale" rel="footnote">2</a></sup></p>
<div><pre><span>#!/usr/bin/perl</span>
<span>use</span> <span>Unicode::Collate::</span><span>Locale</span><span>;</span>
<span>my</span> <span>$collator</span> <span>=</span> <span>Unicode::Collate::</span><span>Locale</span><span>-&gt;</span><span>new</span><span>(</span><span>locale</span> <span>=&gt;</span> <span>'DE'</span><span>);</span>
<span>my</span> <span>@sorted</span> <span>=</span> <span>$collator</span><span>-&gt;</span><span>sort</span><span>(</span><span>@array</span><span>);</span>
<span>$collator</span><span>-&gt;</span><span>cmp</span><span>(</span><span>$word</span><span>,</span> <span>$another_word</span><span>);</span>  <span># -&gt; -1, 0 or 1</span>
</pre></div>


<p>The <abbr title="Unicode Collation Algorithm">UCA</abbr> can do other clever things, such as sort ‘10’ after ‘2’ numerically, or sort
the character ‘?’ as if it was the string ‘question mark’.</p>
<h2>Encodings</h2>
<p>The big ones are <code>UTF-8</code>, <code>UTF-16</code> and <code>UTF-32</code>. Each one guarantees a reversible
mapping of almost every codepoint<sup id="fnref:every"><a href="#fn:every" rel="footnote">3</a></sup> to a byte sequence.</p>
<ul>
<li>
<p><strong>UTF-32</strong> is dead simple: each codepoint gets four bytes. Takes up tons of space,
  not recommended for interchange.</p>
</li>
<li>
<p><strong>UTF-8</strong> is very common the web. It’s byte-oriented (no endianness issues),
  handles corruption well, is ASCII-compatible and takes up minimal space for text
  that is mostly ASCII (e.g. HTML).</p>
<ul>
<li>
<p>Code points between U+0800 and U+FFFF, which includes commonly used <abbr title="Chinese, Japanese, Korean and Vietnamese">CJKV</abbr>
  characters, will take up 3 bytes instead of 2. So UTF-16 may be more space
  efficient.</p>
</li>
<li>
<p>ASCII-compatibility is helpful to allow UTF-8 to stealth its way through
  scripts and processes that are not Unicode-aware. But if such a system tries to
  do anything with the data (casing, sub-strings, regex), that data may be
  corrupted.</p>
</li>
</ul>
</li>
<li>
<p><strong>UTF-16</strong> is used by Java, .NET and Windows. It uses 2 bytes (16-bit) to
  represent the most common 63K codepoints, and 4 bytes for the less common 1M
  codepoints (using two ‘surrogate’ codepoints).</p>
<ul>
<li>
<p>Contrary to popular belief, UTF-16 is not a fixed-width encoding. But as
  long as it contains no surrogates, it can be treated as one, which can speed
  up string operations.</p>
</li>
<li>
<p>UTF-16 streams typically begin with <span><span data-code="FEFF" data-name="ZERO WIDTH NO-BREAK SPACE" title="ZERO WIDTH NO-BREAK SPACE (U+FEFF)">U+FEFF</span></span><sup id="fnref:bomnote"><a href="#fn:bomnote" rel="footnote">4</a></sup> to detect the endianness
  (byte order) of the stream. Otherwise, you can explicitly encode or decode
  via ‘UTF-16BE’ or ‘UTF-16LE’ to specify the endianness.</p>
</li>
</ul>
</li>
</ul>
<h2>Unicode and internationalised domain names</h2>
<p>International characters create a <a href="http://en.wikipedia.org/wiki/IDN_homograph_attack">big problem</a>
for domain names. Just as <span><span data-code="0049" data-name="LATIN CAPITAL LETTER I" title="LATIN CAPITAL LETTER I (U+0049)">I</span></span> and <span><span data-code="006C" data-name="LATIN SMALL LETTER L" title="LATIN SMALL LETTER L (U+006C)">l</span></span> look similar, Unicode multiplies that problem
by 1,000, in addition to adding numerous invisible control characters, spacing characters
and right-to-left text.</p>
<p>Browsers and registrars have implemented several measures against this:</p>
<ul>
<li>Many TLDs restrict which characters can be used in domain names.</li>
<li>Browsers may display the domain in Punycode (see below) if the domain includes characters
  from multiple scripts and/or characters not belonging to one of the user’s preferred languages.</li>
<li>Internationalised country codes such as .рф (Russia) only accept Cyrillic names.</li>
</ul>
<h3>nameprep/stringprep</h3>
<p><a href="http://tools.ietf.org/html/rfc3491">RFC 3491</a> defines <em>nameprep</em>, a mechanism
to case-fold, normalize and sanitize strings before they can be used in domain names. This
removes many invisible characters and throws an error if prohibited code points are in use.</p>
<p>It is implemented in terms of a wider framework called <em>stringprep</em>. In Perl, one can use
<a href="https://metacpan.org/module/Net::IDN::Encode">Net::IDN::Encode</a> which will also perform Punycode conversion.</p>
<h3>Punycode</h3>
<p>For legacy reasons DNS does not allow extended characters outside of ASCII, so Punycode
is an ASCII-compatible encoding scheme. For example, <code>café.com</code> becomes <code>xn--caf-dma.com</code>.
All Punycode-encoded domain components are instantly recognisable by their <code>xn--</code> prefix.</p>
<p>This goes for TLDs too: .中国 is really known as <em>xn—fiqs8s</em>.</p>
<h2>The problem of ‘user characters’</h2>
<p>In Perl at least, everything (<code>substr</code>, <code>length</code>, <code>index</code>, <code>reverse</code>…) works on the level
of codepoints. This is often not what you want, because what a user considers to be a
character such as ў is actually two codepoints (<span><span data-code="0079" data-name="LATIN SMALL LETTER Y" title="LATIN SMALL LETTER Y (U+0079)">y</span></span> + <span><span data-code="0306" data-name="COMBINING BREVE" title="COMBINING BREVE (U+0306)">◌̆</span></span>). Here’s a <a href="http://www.nntp.perl.org/group/perl.perl5.porters/2011/10/msg178687.html">really good
usenet post</a> on the subject.</p>
<p>Even seemingly innocuous things like <code>printf "%-10s", $str</code> breaks completely for combining characters,
double-width characters (e.g. Chinese/Japanese) or zero-width characters.</p>
<p>Fortunately Perl provides the <code>\X</code> regular expression metachar which matches exactly one
‘extended grapheme cluster’, i.e. what a user would consider a character to be. A more robust
solution is to install <a href="https://metacpan.org/module/Unicode::GCString">Unicode::GCString</a>:</p>
<div><pre><span>#!/usr/bin/perl</span>
<span>use</span> <span>Unicode::</span><span>GCString</span><span>;</span>
<span>use</span> <span>Unicode::</span><span>Normalize</span><span>;</span>
<span>use</span> <span>utf8</span><span>;</span>
<span>use</span> <span>open</span> <span>qw(:std :encoding(UTF-8))</span><span>;</span>

<span>my</span> <span>$s</span> <span>=</span> <span>NFD</span><span>(</span><span>"crème brûlée"</span><span>);</span>  <span># ensure combining marks get their own codepoint</span>
<span>my</span> <span>$g</span> <span>=</span> <span>Unicode::</span><span>GCString</span><span>-&gt;</span><span>new</span><span>(</span><span>$s</span><span>);</span>

<span>print</span> <span>$g</span><span>-&gt;</span><span>length</span><span>,</span> <span>"\n"</span><span>;</span>       <span># 12, not 15</span>
<span>print</span> <span>reverse</span><span>(</span><span>@$g</span><span>),</span> <span>"\n"</span><span>;</span>     <span># 'eélûrb emèrc', not 'éel̂urb em̀erc'</span>
<span>print</span> <span>$g</span><span>-&gt;</span><span>substr</span><span>(</span><span>0</span><span>,</span><span>5</span><span>),</span> <span>"\n"</span><span>;</span>  <span># 'crème', not 'crèm'</span>
<span>print</span> <span>$g</span><span>-&gt;</span><span>substr</span><span>(</span><span>0</span><span>,</span><span>3</span><span>),</span> <span>"\n"</span><span>;</span>  <span># 'crè', not 'cre'</span>

<span>print</span> <span>"1234512345123451234512345|\n"</span><span>;</span>
<span>printf</span> <span>"%s%*s|\n"</span><span>,</span> <span>$g</span><span>,</span> <span>(</span><span>25</span> <span>-</span> <span>$g</span><span>-&gt;</span><span>columns</span><span>),</span> <span>''</span><span>;</span>  <span># 25 columns long (ᵔᴥᵔ)</span>

<span>printf</span> <span>"%-25s|\n"</span><span>,</span> <span>$s</span><span>;</span>                          <span># 22 columns long (╯°□°）╯︵ ┻━┻</span>
</pre></div>


<h3>Line breaks</h3>
<p>Line breaking (or word wrapping) is another thing that becomes <a href="http://www.unicode.org/reports/tr14/">insanely complicated</a>
once Unicode is involved. You have to account for various non-breaking and breaking control
and spacing characters, punctuation in every language (e.g. <span><span data-code="00AB" data-name="LEFT-POINTING DOUBLE ANGLE QUOTATION MARK" title="LEFT-POINTING DOUBLE ANGLE QUOTATION MARK (U+00AB)">«</span></span> and <span><span data-code="00BB" data-name="RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK" title="RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK (U+00BB)">»</span></span> quotes, or the
full stop or comma being used in numerics such as <code>2,140</code>) and the width of each character.</p>
<p>In Perl, this has all been handled for you - just use <a href="https://metacpan.org/module/Unicode::LineBreak">Unicode::LineBreak</a>.</p>
<h2>Regular expressions</h2>
<p>Some useful Perl regular expression syntax:</p>
<dl>
<dt><code>\R</code></dt>
<dd>Match any Unicode linebreak sequence (including <code>\n</code>, <code>\r\n</code> and six others)</dd>
<dt><code>\p</code>, <code>\P</code></dt>
<dd>Match any codepoint possessing (or not possessing) a Unicode property.</dd>
<dd>Common ones are <code>\pL</code> (Letter), <code>\pU</code> (Uppercase), <code>\pS</code> (Symbol), or even <code>\p{script=Latin}</code>,
<code>\p{East_Asian_Width=Wide}</code>, <code>\p{Numeric_Value=4}</code>.</dd>
<dd>See <a href="http://perldoc.perl.org/perluniprops.html">perluniprops</a> for a big list.</dd>
<dd>Built-in character classes such as <code>\w</code>, <code>\b</code>, <code>\s</code> and <code>\d</code> are Unicode-aware since Perl
5.6 (though you need to make sure your string or pattern has the <code>UTF8</code> flag on!) Disable this
with the <code>/a</code> flag (see <a href="http://perldoc.perl.org/perlre.html#Character-set-modifiers">perlre</a>).</dd>
<dt><code>\X</code></dt>
<dd>Match an extended grapheme cluster, which is basically …</dd></dl></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://richardjharris.github.io/unicode-in-five-minutes.html">https://richardjharris.github.io/unicode-in-five-minutes.html</a></em></p>]]>
            </description>
            <link>https://richardjharris.github.io/unicode-in-five-minutes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24157201</guid>
            <pubDate>Fri, 14 Aug 2020 12:51:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the lack of feedback is the main reason you quit (everything)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24157013">thread link</a>) | @durmonski
<br/>
August 14, 2020 | https://durmonski.com/self-improvement/lack-of-feedback/ | <a href="https://web.archive.org/web/*/https://durmonski.com/self-improvement/lack-of-feedback/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><em>I lost count. That’s probably my 8th site. The other 7 are no longer present. And while I poured my soul in creating this particular website, and I continue to do so, the graph that measures my monthly visits and the number of <a aria-label=" (opens in a new tab)" href="https://durmonski.com/membership/" target="_blank" rel="noreferrer noopener">new members</a> I get remains disturbingly still. But it’s not the slow progress that upsets</em> <em>my focus. There is something else beneath the metrics that’s ruining</em> <em>my day – the lack of feedback.</em></p><p>Ever thought about why people stop working on their side hustles? Why artists who can transform a plain white paper into a colorful piece of art throw away their brushes? What unknown force convinces you that it’s no longer necessary to do your work obligations?</p><p>You haven’t?</p><p>Well, I did. A lot.</p><p>I wanted to understand why, despite my enormous efforts to create the <a href="https://durmonski.com/membership/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">go-to place</a> for <a href="https://durmonski.com/category/book-summaries/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">reading books</a> my mind was continuously shouting, “There’s no point of pushing further! Go do something else!”</p><p>Why was I feeling uninspired? Depressed?</p><p>I knew from the start that it will take time. That I’ll have to write for several years, at least, to get good returns. Yet, there I was, once again, questioning my efforts and <a href="https://durmonski.com/start-here/">my goals</a>. The more I thought about it, the more I realized how this thing that was trying to convince me that I should stop, is the same insidious force that was persuading millions of others around the world to abandon projects and/or end relationships.</p><h2>What Is The Main Reason You Abandon a Project?</h2><p>Most folks think it’s the lack of resources. Others are convinced that because they failed at product-market fit. A third group believes it’s because the competitor has a better product.</p><p>But often is something else.</p><p>Yes, you do need to have a good product. To satisfy a demand. To have an advantage over your competitors. But you also need emotional resilience.</p><p>The main reason you <a href="https://durmonski.com/book-summaries/bullshit-jobs/" target="_blank" aria-label="quit your boring 9 to 5 job (opens in a new tab)" rel="noreferrer noopener">quit your boring 9 to 5 job</a>, give up on the project you worked for years, and even file for divorce is the lack of feedback.</p><p>Allow me to explain…</p><p>Let’s imagine a typical relationship between a man and a woman. At first, the couple is constantly giving feedback to each other in forms of hugs and kisses. They talk for hours, go out, and are inseparable. At times, they even finish each other sentences – like in the movies.</p><figure><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/08/getting-positive-feedback-1024x512.jpg" alt="getting-positive-feedback" srcset="https://durmonski.com/wp-content/uploads/2020/08/getting-positive-feedback-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/08/getting-positive-feedback-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/08/getting-positive-feedback-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/08/getting-positive-feedback-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/08/getting-positive-feedback-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/08/getting-positive-feedback-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/08/getting-positive-feedback-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/08/getting-positive-feedback-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/08/getting-positive-feedback-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/08/getting-positive-feedback-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/08/getting-positive-feedback.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Getting positive feedback from others means that what you do is worth pursuing further.</figcaption></figure><p>But after the initial honeymoon phase, after the thrill of the relationship has disappeared, they start to feel irritated from the smallest thing. Yes, at this stage, even a single unwashed dish can cause an argument.</p><p>It’s not so much that they stopped caring for each other, they simply stopped showing it.</p><figure><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/08/getting-negative-feedback-1024x512.jpg" alt="getting-negative-feedback" srcset="https://durmonski.com/wp-content/uploads/2020/08/getting-negative-feedback-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/08/getting-negative-feedback-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/08/getting-negative-feedback-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/08/getting-negative-feedback-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/08/getting-negative-feedback-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/08/getting-negative-feedback-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/08/getting-negative-feedback-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/08/getting-negative-feedback-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/08/getting-negative-feedback-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/08/getting-negative-feedback-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/08/getting-negative-feedback.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>When you don’t get any good feedback from others, self-doubt consumes your mind.</figcaption></figure><p>Similar things happen when you start a project.</p><p>At first, you’re “in love” with the idea you want to materialize. You tell folks around you. You create mockups. You read stories of other people online who did similar things and, of course, succeeded.</p><p>All of these things are <em>feeding</em> your enthusiasm, giving you hope and more reasons to start the project. Invest money. And, even purchase online courses that promise to take your idea “to the next level”.</p><p>After the initial excitement, though, things start to take a different route. If you’re not part of the lucky 1% who are able to make it big on their product launch date, your passion slowly starts to decline.</p><p>Why?</p><p>Because not getting enough responses from other people about your work sucks.</p><p>While in the planning stage the feedback you received was mostly feed by your own desire to create what you wanted to create. When the project is live you now rely on outside people to give you boost. If such is not present – there are few or no orders, no one is liking your photos, people don’t reply to your emails – you start to lose motivation.</p><p>That’s why you want to quit and go do something else. Something more exciting. You convince yourself that this new thing will be “way better” and people will love it.</p><h2>Why Receiving Feedback is Important?</h2><p>As in a regular 9 to 5 job, if you work for a boss who doesn’t provide feedback, it’s easy to feel directionless. You start to wonder all sorts of things, “Is my performance good enough?”; “Should I focus more on A instead of B?”; “How can I get better at my work?”</p><p>Similar questions circle one’s mind when the caresses from their spouse stops, “Does he still loves me?”; “Why I’m no longer receiving lovely texts from him?”; “Am I getting older?”</p><p>In ancient times, when our ancestors first discovered fire, and even before that, tribes relied on cues from the environment to find food, useful tools, and avoid injuries from wild animals – a.k.a. losing an arm or being killed.</p><p>But not only this, from a biological standpoint, it makes sense to anticipate external feedback all the time. After all, the main function of the brain is to keep you well and alive.</p><p>During wars, people were constantly alarmed and conscious of their surroundings because they wanted to prevent themselves from being killed or badly injured.</p><p>This feedback loop is present all the time in different shapes and forms. Fortunately, getting caught in a crossfire or attacked by a wild animal is unlikely to happen nowadays. Our brains are now mainly worried about not getting validation from our own kind.</p><p>If you share a picture online and you get zero or not enough likes – whatever enough means for you – this translates into, “I’m not good enough.” The pressure to be socially accepted, online, can create a lasting feeling of unworthiness.</p><p>But measuring your self-worth by the number of likes is not a new discovery.<span id="easy-footnote-1-10677"></span><span><a href="#easy-footnote-bottom-1-10677" title="Validation seeking online has been around the block since social media was invented."><sup>1</sup></a></span> Yet, few people realize that the same thing carries over other important areas in our lives.</p><ul><li>Your spouse is no longer talking to you.</li><li>Your boss is rarely talking about your performance.</li><li>Your business is just a dusty place no one enters.</li></ul><p>No wonder you want to bail out. Go do something else to associate your I, <a aria-label="your ego (opens in a new tab)" href="https://durmonski.com/book-summaries/ego-is-the-enemy/" target="_blank" rel="noreferrer noopener">your ego</a>, with something “better” hoping that you’ll get recognition.</p><p>That’s also the reason people indulge in <a aria-label=" (opens in a new tab)" href="https://durmonski.com/well-being/internet-rabbit-holes/" target="_blank" rel="noreferrer noopener">careless scrolling</a>. If the project you’re working on is not getting the desired traction you start to doubt your own existence. That’s why we enter the artfully curated social media feeds to feel good about ourselves and escape the harsh reality.</p><p>But here’s the interesting part: The more time you can bear working on a project without getting external feedback the higher the chances of this thing to thrive and succeed.</p><p>The same applies to your relationships. If you can endure the arguments and don’t seek comfort in other people’s arms (i.e. cheat), you have a chance in creating a long-lasting marriage.</p><p>It’s quite a paradox. Half of the brain is logging for positive feedback to feed the ego while the other half is trying to stay reasonable and sane even when the first is not present.</p><h2>Getting Positive Feedback is The Main Desire of The Brain</h2><p>But it’s not only projects and relationships. Our brain is constantly seeking for positive cues. After all, the core goal of the whole body system is to keep you alive, make you feel good so you can survive for a longer period of time and pass your genes along.</p><p>What does all of this mean for our long term goals?</p><p>That if you want to make some positive changes in your life it will surely require enduring through long periods that are absent of any feedback – in a lot of cases both good and bad.</p><p>Want to lose weight and add a nice six-pack to your abs? It might take you months of starvation and hard exercises. During this transition period, the guy who stares at you back in the mirror is still going to be fat and asymmetrical.</p><p>Want to create a profitable online business? Despite praying to Google to show your content a bit higher in the search results you also have to write extremely good essays over a long period of time.</p><p>But I’m not here only to warn you about the loneliness and the years of hard work without immediate return. I’m here to help.</p><p>Here’s what you can do to make your journey to what you want to become, create, or whatever, a bit more bearable…</p><h2>How Can You Cope With Not Getting Feedback For Your Project?</h2><h3>Create Visual Feedback Loops</h3><p>“Don’t break the chain!” said Jerry Seinfeld when asked how he was able to keep delivering amazing jokes to people around the world.<span id="easy-footnote-2-10677"></span><span><a href="#easy-footnote-bottom-2-10677" title="A lot of people call it <a href=&quot;https://jamesclear.com/stop-procrastinating-seinfeld-strategy&quot; target=&quot;_blank&quot; aria-label=&quot;The Seinfeld Strategy (opens in a new tab)&quot; rel=&quot;noreferrer noopener&quot; class=&quot;ek-link&quot;>The Seinfeld Strategy</a>."><sup>2</sup></a></span></p><p>He’s famous for his practice of writing jokes daily and checking off boxes on a calendar.</p><p>Jerry Seinfeld famously said, “Do something related to your craft every day, no matter how small the action is.”</p><p>That’s the first tactic that will help you cope with the lack of feedback when you want to create a business or adopt a new habit.</p><p>The idea is to create a visual representation of the progress you’re making.</p><figure><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/08/Dont-break-the-chain-1024x512.jpg" alt="Don't-break-the-chain" srcset="https://durmonski.com/wp-content/uploads/2020/08/Dont-break-the-chain-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/08/Dont-break-the-chain-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/08/Dont-break-the-chain-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/08/Dont-break-the-chain-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/08/Dont-break-the-chain-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/08/Dont-break-the-chain-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/08/Dont-break-the-chain-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/08/Dont-break-the-chain-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/08/Dont-break-the-chain-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/08/Dont-break-the-chain-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/08/Dont-break-the-chain.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure><p>Writing or exercising regularly is a good idea on paper, but you can easily lose motivation when you feel tired or when the weather outside is giving you blues.</p><p>Things feel quite different once you have a graph that’s showing your progress. You’ll feel obligated to put another checkmark. After all, you don’t want to feel like the previous days were wasted, right?</p><p>That’s the simplest strategy you can create, today, to move the needle closer to where you want to go.</p><h3>Find a Support Group</h3><p>The second tactic that you can use to handle the dry periods that are absent of feedback is to join a group that will keep you accountable.</p><figure><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/08/support-group-1024x512.jpg" alt="support-group" srcset="https://durmonski.com/wp-content/uploads/2020/08/support-group-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/08/support-group-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/08/support-group-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/08/support-group-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/08/support-group-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/08/support-group-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/08/support-group-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/08/support-group-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/08/support-group-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/08/support-group-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/08/support-group.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure><p>I know. You probably heard it before. But having someone waiting for you to get the job done is a butt-kicker. You can handle disappointing yourself in most of the cases. But disappointing someone else? You don’t want to do that.</p><h3>Temper Your Emotions by Reminding Yourself Why You Started</h3><p>The reasons you started a project often fades after months or years of execution. You started because you wanted to make reading more available to others? Or, because you wanted to inspire more people to exercise?</p><p>Soon enough, though, you forget why your project exists. You are carried away by the daily tasks and “trendy” methods you obsessively try to grow your business.</p><figure><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/08/why-you-started-1024x512.jpg" alt="why-you-started" srcset="https://durmonski.com/wp-content/uploads/2020/08/why-you-started-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/08/why-you-started-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/08/why-you-started-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/08/why-you-started-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/08/why-you-started-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/08/why-you-started-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/08/why-you-started-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/08/why-you-started-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/08/why-you-started-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/08/why-you-started-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/08/why-you-started.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure><p>Your eagerness to <em>make it</em> consumes you thinking and you forget why …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://durmonski.com/self-improvement/lack-of-feedback/">https://durmonski.com/self-improvement/lack-of-feedback/</a></em></p>]]>
            </description>
            <link>https://durmonski.com/self-improvement/lack-of-feedback/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24157013</guid>
            <pubDate>Fri, 14 Aug 2020 12:30:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to Practical Software Design Patterns]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24156727">thread link</a>) | @sciencewolf
<br/>
August 14, 2020 | https://algodaily.com/lessons/an-introduction-to-software-design-patterns?view=article | <a href="https://web.archive.org/web/*/https://algodaily.com/lessons/an-introduction-to-software-design-patterns?view=article">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://algodaily.com/lessons/an-introduction-to-software-design-patterns?view=article</link>
            <guid isPermaLink="false">hacker-news-small-sites-24156727</guid>
            <pubDate>Fri, 14 Aug 2020 11:58:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Migrated My Blog from WordPress to Hashnode]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24156687">thread link</a>) | @fazlerocks
<br/>
August 14, 2020 | https://catalins.tech/i-migrated-my-blog-from-wordpress-to-hashnode-ckdsn5h4100h2a9s1crmv7a3q | <a href="https://web.archive.org/web/*/https://catalins.tech/i-migrated-my-blog-from-wordpress-to-hashnode-ckdsn5h4100h2a9s1crmv7a3q">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1597313376856/yGQnQpTIu.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text">

<p>If you are following me on Twitter, chances are you already know I migrated my blog from WordPress to Hashnode. The tweet below shows my announcement of moving to Hahshnode:</p>

<p>Therefore, in this article, I want to shine some light on why I chose to leave WordPress, and become part of the <a href="https://hashnode.com/@hashnode">Hashnode</a> community.</p>

<p>As you might know, or not, I am a big fan of WordPress. The reasons are that:</p>
<ul>
<li>it is easy to use</li>
<li>it is free</li>
<li>there are lots of free themes available</li>
<li>there are integrations with almost any service available on the internet</li>
</ul>
<p>... and many more.</p>
<p>However, it can be very bloated, slow, and overkill for a technical blog. For instance, to add code snippets to my articles, I had to install a special plugin. Then, every time I wanted to add a code snippet to an article, I had to:</p>
<ol>
<li>go to the plugin settings</li>
<li>select the language of the code snippet</li>
<li>create a name and a description for the snippet</li>
<li>choose a tag</li>
<li>write the code</li>
<li>save the snippet</li>
<li>embed the snippet into the article</li>
</ol>
<p>Thus, to add a snippet of code, I need to follow seven steps. Now let us say I have to embed five code snippets. As a result, I have to do thirty-five extra steps! Moreover, I did not have any control over my snippets, and I could not customise the design. </p>
<p>Anyway, the above is just an example to show you laborious some tasks can be in WordPress. I decided enough is enough, and I started to look for alternatives, as shown by the tweet below. </p>


<p>I believe there is not the best alternative because everyone has different needs and use cases. However, for my use case, I had to choose between:</p>
<ol>
<li>Hashnode</li>
<li>Gatsby + MDX</li>
</ol>
<p>Even though I love Gatsby blogs, and the level of customisation they allow, it can be very time-consuming to create such a blog. And then you have to maintain it too. Therefore, the only option left was Hashnode.</p>
<h3 id="why-hashnode-">Why Hashnode?</h3>
<p>The thing that attracts me the most to Hashnode is that it combines both worlds of a dynamic blog like a WordPress blog and a static site like a Gatsby blog. It has more features than a static blog, but it is less-bloated than a WordPress blog. </p>
<p>Besides that, you get to be part of an awesome and fantastic community. It is one of the most supportive communities I have ever been involved in, and they do not pay me to say this. It is my opinion. </p>
<p>Other reasons why I prefer Hashnode:</p>
<ul>
<li><strong>AMP pages</strong> =&gt; The blog is very fast on mobile, and poor internet.</li>
<li><strong>Publishing articles is swift and easy</strong> =&gt; You write your articles in Markdown. Also, you can easily embed YouTube videos, tweets, content from other sites, and so on. </li>
<li><strong>Free SSL certificate</strong> =&gt; How cool is that? You do not have to pay anything for the certificate.</li>
<li><strong>Your domain</strong> =&gt; You can use your domain for your blog. You are not tied to a blog URL like <code>pit.hashnode.dev</code>.</li>
<li><strong>Back up your articles on GitHub</strong> =&gt; Do you want to migrate to another platform? Well, you are not locked on Hashnode. They provide you with the opportunity of backing up your articles on GitHub in a JSON format. As a result, you can switch platforms without losing your content.</li>
<li><strong>I can talk straight to the founders</strong> =&gt; How cool is that I can speak straight with the people that founded the platform? I cannot do this with WordPress, Dev To, Medium, and other platforms. If I have feedback or ideas, I can pitch them. (<em>that does not mean I bother them all day long</em>)</li>
<li><strong>Discord server</strong> =&gt; I already said that they have a great, tight, supportive community. Thus, they have an exclusive Discord server with all the people using Hashnode, including the founders. You can exchange ideas, ask questions, and many more. Check it out! </li>
</ul>
<p>In conclusion, these are the reasons why I choose to use and become part of the Hashnode community. If you have other good reasons, feel free to drop them in the comments.</p>

<p>I hope the article makes it clear why I chose Hashnode and why it can be an excellent choice for anyone. I want to emphasise again that I did not get paid to move to Hashnode or write this article. </p>
<blockquote> If you enjoyed the article, consider sharing it so more people can benefit from it! Also, feel free to @ me on Twitter with your opinions. </blockquote>
</div></div></section></div></div>]]>
            </description>
            <link>https://catalins.tech/i-migrated-my-blog-from-wordpress-to-hashnode-ckdsn5h4100h2a9s1crmv7a3q</link>
            <guid isPermaLink="false">hacker-news-small-sites-24156687</guid>
            <pubDate>Fri, 14 Aug 2020 11:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JavaScript Code Plays Google Dinosaur/T-Rex Game Automatically]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24156685">thread link</a>) | @truly_furqan
<br/>
August 14, 2020 | https://www.edopedia.com/blog/javascript-code-plays-google-dinosaur-t-rex-game-automatically/ | <a href="https://web.archive.org/web/*/https://www.edopedia.com/blog/javascript-code-plays-google-dinosaur-t-rex-game-automatically/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.edopedia.com/blog/javascript-code-plays-google-dinosaur-t-rex-game-automatically/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24156685</guid>
            <pubDate>Fri, 14 Aug 2020 11:53:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Precise Higher-Order Meshing of Curved 2D Domains]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24156522">thread link</a>) | @wowsig
<br/>
August 14, 2020 | http://graphics.cs.uos.de/bezierguarding.html | <a href="https://web.archive.org/web/*/http://graphics.cs.uos.de/bezierguarding.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://graphics.cs.uos.de/bezierguarding.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24156522</guid>
            <pubDate>Fri, 14 Aug 2020 11:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redefining what sustainable fishing means]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 109 (<a href="https://news.ycombinator.com/item?id=24156319">thread link</a>) | @dnetesn
<br/>
August 14, 2020 | http://oceans.nautil.us/article/600/its-time-to-redefine-what-sustainable-fishing-means | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/article/600/its-time-to-redefine-what-sustainable-fishing-means">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>S</span>arah Dolman heard the porpoiseâ€™s cries not in the waters where the animalâ€™s voice was actually recorded, but on the sound system at a marine mammal conference held in late 2019. To Dolman, policy manager at the nonprofit UK-based conservation organization <a href="https://uk.whales.org/" target="_blank">Whale and Dolphin Conservation,</a> time and distance made the experience no less painful.</p>

<p>The porpoise was using its voice—which sounds alternately like a buzzing insect, a creaky door blowing open then clicking shut, and a high-frequency whistle that humans cannot hear without the aid of sound-amplifying technologies—to call to another porpoise who was caught in a fishing net. The entangled porpoise struggled to surface while trying to break free. That proved impossible, and the porpoise drowned. But the dead creatureâ€™s companion stayed nearby for hours, speaking in protracted clicks, buzzes and whistles—in mourning or perhaps confusion, alarmed by the sudden death of its friend.</p>
<p>Globally, fishing gear kills <a href="https://www.sciencedirect.com/science/article/pii/B9780123735539000444" target="_blank">at least 300,000 marine mammals</a> every year, and leaves many more individuals with scars both physical and psychological. Some governments, including those of the U.S. and E.U., may temporarily close fisheries or regulate gear after a specified number of marine mammals are killed, but those measures are limited. At a moment when the cruel captivity of several dozen orcas inspires public outrage and aquarium boycotts and new laws, the global fishing industry and its regulators generally accept the widespread killing and maiming of marine mammals as a part of doing business. And so we unwittingly continue to eat fish, in huge amounts, and marine mammals continue to suffer.</p>
<p>Dolman says present approaches, which focus on maintaining specific populations above a minimum size, still allow too much killing and preventable suffering. She says itâ€™s time for fisheries policies to consider the welfare of individual whales and dolphins and other marine mammals. â€œBeing caught in fishing gear is a horrible way to die,â€� says Dolman. â€œHow would the public feel about this when theyâ€™re eating fish and seafood, if they knew about these animalsâ€™ suffering? We need another solution.â€�</p>
<p>Dolman and her colleague Philippa Brakes, a research fellow at Whale and Dolphin Conservation, outlined their approach for regulating â€œbycatch,â€� as unintentionally caught animals are called, and preventing entanglement in fishing gear in a <a href="https://www.frontiersin.org/articles/10.3389/fvets.2018.00287/full" target="_blank">2018 paper</a> published in the journal <em>Frontiers in Veterinary Science</em>. They say that fisheries policies must account for the well-being of individuals, not just populations, ideally with zero tolerance for marine mammal bycatch.</p>
<p>They also argue for updating the definition of â€œsustainableâ€� fisheries, now set according to whether the exploitation of a given fish population can be continued without jeopardizing it, to include marine mammals killed as bycatch. In their paper, Dolman and Brakes point out that â€œbuying â€˜sustainableâ€™ fish or indeed some fish products labeled â€˜dolphin-friendlyâ€™ provide no guarantees that incidental bycatch of protected species does not occur alongside the targeted catch.â€�&nbsp; And not only should sustainability encompass mortality, but also the suffering of survivors—something thatâ€™s a bit more challenging to measure, though scientists acknowledge that itâ€™s real, and goes beyond the pain of scars and severed limbs caused by the constricting ropes of the gear they carry.</p><figure><img src="https://s3.amazonaws.com/nautilus-vertical/oceans_911411818e26b80488c996ad7cfe7d4d.jpg" alt="nautilus whale calf"><figcaption><span>A humpback whale mother swims with her newborn calf in their traditional breeding waters in the Hawaiian Islands Humpback Whale National Marine Sanctuary. </span><br><span>Credit: NOAA News</span></figcaption></figure><p>Even if we are quite far from fully understanding the experiences of animals who spend their lives primarily underwater, <a href="https://link.springer.com/chapter/10.1007/978-3-030-31011-0_10" target="_blank">research clearly reveals</a> that harbor porpoises like the one whose cries haunted Dolman and other marine mammals are, like us, highly intelligent and social creatures. Ecologist and author <a href="https://www.nytimes.com/2015/08/04/science/review-beyond-words-carl-safina.html" target="_blank">Carl Safina</a>, who has written extensively about the inner lives of nonhuman animals including orcas and sperm whales, says the loss of even one individual whale—particularly if she happens to be an adult female—can be catastrophic for others.<br></p>
<p>â€œSperm whales stay together their entire lives, very intentionally living together in a family the way elephants live together in a family,â€� says Safina. â€œIf you lose even one member of that female support group, you increase the risks and hazards to the young ones.â€�&nbsp;</p>
<p>Like baby humans, young marine mammals depend on their eldersâ€™ vigilance and protection, as well as their practical knowledge and cultural wisdom, for survival. Older animals in a family bestow younger members with all sorts of knowhow, such as what to eat and how to hunt for food. Scientists have discovered that <a href="https://science.sciencemag.org/content/337/6100/1313" target="_blank">orca grandmothers</a> play an outsized role in the lives of young orcas, boosting youngstersâ€™ chances of survival. Even for less family-oriented marine mammal species, like humpback whales, notes Safina, â€œthe death of a mother—or severe distress of a mother due to entanglement in fishing gear—can be, depending on age of a young one, completely devastating or very stressful.â€�
</p>
<p>Research like this â€œopens a rich seam of understanding,â€� Brakes says. â€œSuch understanding shows us that we can no longer treat marine mammals like a homogenous group or numbers on a spreadsheet.â€� She and Dolman propose a multi-pronged strategy of implementing fisheries closures and new fishing practices, as well as requiring new gear that minimizes bycatch and entanglements. Fisheries regulation would need to include enhanced monitoring and reporting systems that keep track of every harmed marine mammal. Right now basic data about bycatch and entanglements, much less the long-term physiological and psychological affects, are not being collected.</p>
<blockquote>â€œWe can no longer treat marine mammals like a homogenous group or numbers on a spreadsheet.â€�</blockquote>
<p>According to Dolman, the Marine Stewardship Council (MSC), a key independent labeler of sustainable seafood, has received much criticism in recent years about its inadequate consideration of bycatch. â€œMSC bycatch standards are under review at the moment,â€� Dolman said. â€œThis is something thatâ€™s long overdue. But, I have to say, Iâ€™m not feeling very positive about whatâ€™s coming. The fishing industry is very vocal and oppositional to regulatory change. Consumers and scientists must begin pushing for laws and certification schemes to seriously incorporate welfare into the â€˜sustainableâ€™ label. Most of the public feels comfortable when they see a dolphin-safe label—though really, right now, they shouldnâ€™t.â€�<strong>
</strong></p>
<p>Adding to marine mammalsâ€™ collective challenges is the fact that fishing isnâ€™t their only threat. In addition to depleting populations of the fish they eat, humans have made the oceans a much noisier place, with engine noise and seismic surveys and naval tests causing both chronic stress and acute damage. We push ship traffic into ever-more remote areas once only known to marine animals; disrupt marine life by developing coastlines and dredging channels; pollute with plastic and toxic chemicals; and cause ocean-warming climate change.
</p>
<p>These are not matters to frame purely in terms of populations and environments, but the lived experiences of animals who share many intellectual properties with us. â€œPeople need to understand that other living things can suffer and that these individuals donâ€™t want to suffer. They want to exist in a state of wellbeing. Thatâ€™s what they strive to do,â€� says Safina. â€œI think the big first step is for people to understand and talk about that and drive away from things that cause suffering.â€�</p>

<ul><li> is a writer, artist and wildlife rehabilitator who explores the intersection of the human and nonhuman worlds. She is currently writing a book about plastic pollution around the world and is a junior fellow at the not-for-profit conservation organization The Safina Center, with which Carl Safina is affiliated. See more of her work at <a href="https://www.ericacirino.com/">www.ericacirino.com</a>. </li></ul>
<p>Lead image:&nbsp;A male right whale entangled in heavy fishing rope off the coast of Florida. Biologists were able to remove the rope. Credit: Florida Fish and Wildlife Conservation Commission, taken under NOAA research permit #15488.</p>





            </article></div>]]>
            </description>
            <link>http://oceans.nautil.us/article/600/its-time-to-redefine-what-sustainable-fishing-means</link>
            <guid isPermaLink="false">hacker-news-small-sites-24156319</guid>
            <pubDate>Fri, 14 Aug 2020 10:54:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automate Database Backups with AWS Fargate, S3 and CDK]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24156194">thread link</a>) | @kiyanwang
<br/>
August 14, 2020 | https://a.l3x.in/blog/mongodb-backups-with-aws-cdk/ | <a href="https://web.archive.org/web/*/https://a.l3x.in/blog/mongodb-backups-with-aws-cdk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Even if I consider myself a Serverless fanboy I listen to all the arguments <em>against</em> it and I have to agree some of them are valid. Heck, that’s true for basically every technology: they all come with <em>pros</em> and <em>cons</em>.</p><p>One of the most valuable benefits I see in Serverless and I believe hard to confute though is, well… that less toil work dedicated to server administration means that as an engineer you can focus on arguably more valuable tasks at hand and, probably, the end result of what you build will be a more robust and reliable infrastructure too.</p><p>Take this case for example: perform daily backups of remote (i.e. fully managed, no shell access) MongoDB instance, store these archives somewhere offsite and delete them once they are older than a defined amount of time. I’m sure if you’ve ever did system administration (or call it <em>DevOps</em> if you prefer) this sounds like a very familiar kind of task, doesn’t it?</p><h2 id="a-conventional-approach">A conventional approach</h2><p>In the old days, when Serverless was not yet a thing, a common way to approach this was to:</p><ol><li>setup some <em>admin</em> or <em>ops</em> kind of server responsible for this and most probably other kind of similar back-office activities. No need to say you and your team also need to take good care of it for the forseeable future (i.e. have redundant storage drives in some kind of RAID scheme and replace them once they fail, keep the server itself backupped, monitor that it’s up and running 24/7, etc)</li><li>set up some kind of cronjob to do the above backup routine every evening (or every X amount of time, depending on the needs, etc)</li><li>in the same above cronjob or as an independent task, have some kind of <em>pruning</em> process that takes care of deleting old archives once their expiry date has passed</li></ol><h2 id="a-serverless-approach">A Serverless approach</h2><p>Instead, in this article I’m going to show you how this very same problem might be approached from a Serverless perspective. These are the tools I’m going to use:</p><ul><li>AWS S3 for storing the archives and automatically prune them after they are older than 7 days</li><li>AWS Fargate for executing a <code>mongodump</code> process (wrapped by a few lines of Bash) in a <em>Docker container</em> and upload the generated archive to an S3 bucket</li><li>AWS CloudWatch Events to trigger the routine in a <em>cron</em> fashion (in my case every day at 23:50)</li><li>AWS CDK to easily setup all the above, including ECS cluster and auto-generated <em>least-privilege</em> IAM policies and so forth</li></ul><h2 id="show-me-the-code">Show me the Code</h2><p>This is a slightly simplified overview of the application:</p><p><img src="https://a.l3x.in/blog/mongodb-backups-with-aws-cdk/mongodumper_stack.png" alt="Stack diagram"></p><p>The AWS CDK stack (including Dockerfile and Bash script) is <a href="https://github.com/shaftoe/api-l3x-in/tree/0.13.0/lib/stacks/mongodumper">available on GitHub</a>. I copy here the basic Bash script which is responsible for the actual work, all the rest is fairly simple <a href="https://github.com/shaftoe/api-l3x-in/tree/0.13.0/lib/stacks/mongodumper/__init__.py">CDK plumbing</a>:</p><div><pre><code data-lang="bash"><span>#!/bin/bash
</span><span></span>set -u
set -e
set -o pipefail

trap <span>"{ printf 'ERROR: catched non-zero exit code\n'; exit 1; }"</span> ERR

TODAY<span>=</span><span>"</span><span>$(</span>date +%Y-%m-%d<span>)</span><span>"</span>
DST_FILE<span>=</span><span>"s3://</span><span>${</span>S3_BUCKET<span>}</span><span>/mongodump-</span><span>${</span>TODAY<span>}</span><span>.gz"</span>

mongodump <span>\
</span><span></span>    --archive <span>\
</span><span></span>    --gzip <span>\
</span><span></span>    --ssl <span>\
</span><span></span>    --uri<span>=</span><span>"</span><span>${</span>MONGODB_URI<span>}</span><span>"</span> <span>\
</span><span></span>    | aws s3 cp - <span>"</span><span>${</span>DST_FILE<span>}</span><span>"</span>

printf <span>"INFO: All done, exiting with code 0\n"</span>
exit <span>0</span>
</code></pre></div><p>The command pipe at line 11 should already suffice as <code>CMD</code> for Docker (i.e. there’s no real need for a Bash wrapper to have it work) but in this way in case of failures I’m confident I’ll get an <code>ERROR:</code> string in the relative CloudWatch Logs Group and I’ll be notified about that.</p><p>For instance, I receive a daily email report with error logs present in every CloudWatch Log group and in my case I consider this enough as a form of monitoring but depending on your scenario you might want to setup some kind of specific monitoring for the S3 archive bucket.</p><p>You might want to also have a look at <a href="https://a.l3x.in/blog/add-pagespeed-check-with-serverless/">this older article</a> for hints and suggestions on how to develop a more detailed monitoring AWS-based solution.</p><h2 id="pitfalls-and-caveats">Pitfalls and Caveats</h2><p>The above solution took little time to be developed and it’s been working like a charm since it went into production. I list here the few pitfalls I stepped into during development and a few other recommendations:</p><ul><li><p>initially I used <code>alpine</code> as base Docker image but seems the shipped <code>mongodump</code> version doesn’t work when <code>--ssl</code> option is enabled, at the time I’m writing this article it’s easy to reproduce:</p><div><pre><code data-lang="sh">docker run --rm -it alpine:latest
apk add --quiet mongodb-tools
export URI<span>=</span><span>"mongodb://XXXXXXXXXXXXXXXXX@ds249233.mlab.com:49233/heroku_9pzlj109"</span>
mongodump --uri<span>=</span><span>"</span><span>${</span>URI<span>}</span><span>"</span>
2020-08-07T08:33:19.705+0000 writing heroku_9pzlj109.records to
2020-08-07T08:33:20.690+0000 <span>done</span> dumping heroku_9pzlj109.records <span>(</span><span>144</span> documents<span>)</span>
2020-08-07T08:33:20.947+0000 writing heroku_9pzlj109.domains to
2020-08-07T08:33:21.051+0000 writing heroku_9pzlj109.tokens to
2020-08-07T08:33:21.487+0000 <span>done</span> dumping heroku_9pzlj109.domains <span>(</span><span>1</span> document<span>)</span>
2020-08-07T08:33:21.632+0000 <span>done</span> dumping heroku_9pzlj109.tokens <span>(</span><span>1</span> document<span>)</span>
mongodump --uri<span>=</span><span>"</span><span>${</span>URI<span>}</span><span>"</span> --ssl
2020-08-07T08:34:02.318+0000 Failed: can<span>'</span>t create session: could not connect to server: server selection error: server selection timeout,    current topology: <span>{</span> Type: Unknown, Servers: <span>[{</span> Addr: ds249233.mlab.com:49233, Type: Unknown, State: Connected, Average RTT: <span>0</span> <span>}</span>, <span>]</span> <span>}</span>
</code></pre></div><p>I even tried to open a bug report on MongoDB official tracker but I couldn’t manage to have a working account: I could sign up but I can’t login, I even tried password resets with no luck… oh well, at least they can’t tell me I haven’t tried. By the way, I’ve worked around this using <code>debian:buster-slim</code> as Docker base image given that I don’t care that much about image size anyway, my AWS bill is basically unaffected by a few more MBs stored in the ECS registry so what the heck</p></li><li><p>every single time a Fargate task is executed without explicitly setting a security group <strong>will create a brand new one</strong> and, given that there’s a quota of <a href="https://docs.aws.amazon.com/vpc/latest/userguide/amazon-vpc-limits.html">maximum 2500 security groups per region</a>, this might very well cause a few headaches in the close future unless properly addressed. To avoid that I explicitly set the Fargate Task to use the default VPC security group which has open <code>EGRESS</code> rules and works fine in my scenario, it’s implemented at at <a href="https://github.com/shaftoe/api-l3x-in/tree/0.13.0/lib/stacks/mongodumper/__init__.py#L66">line 66</a> of the CDK stack. I believe this is a more sensible default behavior and I hope ECS developers will address this in the future, I bet some user might not be as lucky as I’ve been to notice it before deploying to production and discover it the hard way</p></li><li><p>another annoying default setting in ECS: when running a Fargate Task in a public VPC subnet the container won’t receive proper networking setup unless explicitly set, i.e. it will not be able to pull the image from the ECS registry, hence it will never reach the <code>RUNNING</code> stage and, even worse, no error log will be sent to CloudWatch Logs.</p><p>Unfortunately CDK doesn’t let you change this setting for CloudWatch Events yet, there’s an <a href="https://github.com/aws/aws-cdk/issues/9233">open feature request</a> for that and given the recent speed of development in the CDK project I expect this to be solved soon.</p><p>For the time being I worked around it manually changing the setting via the web console (yeah, I know, <em>the horror</em> 😱), another way around it that doesn’t require manual intervention and makes the solution 100% <em>Infra as Code</em> would have been to put a Lambda proxy between the CloudWatch Event and the Fargate task. It might be I’ve been either too lazy or too optimistic in CDK fixing this promptly, only time will tell</p></li><li><p>currently the above solution supports storing archives for a single (MongoDB) database, it should be fairly trivial to extend it to support multiple databases though (e.g. defining multiple CloudWatch Events, each one setting different <code>MONGODB_URI</code> value via <code>container_overrides</code> parameter)</p></li><li><p>for my simple need a <em>delete permanently after 7 days</em> bucket lifecycle policy is all right, you might want to consider more complex policies like storing old archives to Glacier instead, S3 is <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html">quite flexible</a> in that regard</p></li></ul><h2 id="wrapping-up">Wrapping Up</h2><p>Once more I’m delighted by how easy it is to work with CDK on AWS and I have the feeling those solutions I come up with are simple, robust, and basically require zero maintenance from my side (which is gold in itself).</p><p>Comparing the above solution to a more conventional approach which might require maintaining (and monitoring! and keeping secured! etc.) a server 24/7 for running actual work only for a few seconds per day is… wasteful, to say little.</p><p>Beside, I bet today there’s no way to come up with a cheaper production-ready solution: a few seconds of Fargate execution per day won’t even show up in the AWS monthly bill, and if it does it might be for just a few Euro (or Dollar) cents. Of course this might not be true in case of big datasets where the cost for S3 storage/data transfer might make an in-house solution (or even better, a fully managed solution, automated backups included) more cost effective, but I bet this is never going to be the case in many real scenarios where archives are relatively small sized (i.e. a few GBs or so).</p><p>That said, the current shortcomings in the integration between ECS and CDK are annoying and enforce the <em>Serverless is not 100% ready for production</em> argument validity, at least for the time being.</p><p>I hope you enjoyed reading this article at least a fraction of how much I did while working on it, and don’t forget to let me know what you think.</p></div></div>]]>
            </description>
            <link>https://a.l3x.in/blog/mongodb-backups-with-aws-cdk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24156194</guid>
            <pubDate>Fri, 14 Aug 2020 10:38:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Duality of Vector Spaces (2017)]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24156082">thread link</a>) | @hosolmaz
<br/>
August 14, 2020 | https://solmaz.io/notes/duality-vector-spaces/ | <a href="https://web.archive.org/web/*/https://solmaz.io/notes/duality-vector-spaces/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>



<p>When I was learning about Continuum Mechanics for the first time, the <em>covariance
and contravariance of vectors</em> confused the hell out of me. The concepts gain
meaning in the context of Riemannian Geometry, but it was surprising to find
that one doesn’t need to learn an entire subject to grasp the logic behind
co-/contravariance. An intermediate knowledge of linear algebra is enough—that
is, one has to be acquainted with the concept of vector spaces and one-forms.</p>
<p>The duality of co-/contravariance arises when one has to define vectors in terms
of a non-orthonormal basis. The reason such terminology doesn’t show up
in engineering education is that Cartesian coordinates are enough for most
engineering problems. But every now and then, a complex problem with funky
geometrical requirements show up, like one that requires measuring distances and
areas on non-flat surfaces. Then you end up with dual vector spaces. I’ll try to
give the basics of duality below.</p>
<p><strong>Definition:</strong> Let $\CV$ be a finite-dimensional real vector space.
The space $\CV^\ast = \CL(\CV,\IR)$,
defined as the
the space of all one-forms $\Balpha:\CV\to\IR$, is called the
<strong>dual space</strong> to $\CV$.</p>
<p>Let $B=\cbr{\Be_1,\dots,\Be_n}$ be a basis of $\CV$. Any vector $\Bv\in\CV$ can be written
in terms of $B$ as</p>

<p>with the components $a_1,\dots,a_n\in\IR$.
For any $i=1,\dots,n$, we can define the $i$-th component $a_i$ by a one-form as</p>

<p>These elements are linear and thus are in the space
$\CL(\CV,\IR)$<sup id="fnref:1"><a href="#fn:1">1</a></sup>.
Given any basis $B=\setveci{\Be}$, we call $B^\ast = \setveciup{\Be}$
the basis of $\CV^\ast$ <strong>dual</strong> to $B$.
The fact that $B^\ast$ really is a basis of $\CV^\ast$ can be proved
by showing that $\Be^i$ are linearly independent.
Then $\Bv$ has the following
representation</p>

<p>Instead of $a_i$, it is practical to denote the components of $\Bv$ as $v^i$,
lightface of the same symbol with a raised index corresponding to
the raised index of the dual basis:</p>

<p>In fact, this convention is more compatible with
the symmetry caused by the duality.
This point will be more clear after the introduction of
dual basis representation of one-forms.</p>
<p><strong>Proposition:</strong> Each $\Be^i \in \CL(\CV,\IR)$ can be identified by its action on the basis
$B$:</p>

<p><strong>Proof:</strong> For any $\Bv\in\CV$, $\Be^i(\Bv)$ must give $v^i$, the
$i$-th component of $\Bv$.
Setting $\Bv = \Be_j$, one sees that
$\Be^i(\Bv)=v^i = 1$ when $i=j$, and is zero otherwise.</p>
<p>Geometrically, \eqref{eq:dualbasis2} implies that a basis vector is
perpendicular to all the dual basis vectors, except its own dual.</p>
<h2 id="dual-basis-representation-of-one-forms">Dual Basis Representation of One-Forms</h2>
<p>Let $\Balpha$ be a one form in $\CV^\ast$ with the corresponding
dual basis $\setveciup{\Be}$. Then similar to a vector,
$\Balpha$ has the following representation</p>

<p>where the <strong>components of the one-form</strong> $\Balpha$
are defined as</p>

<p><strong>Proof:</strong> We substitute \eqref{eq:vectorrep2} and obtain</p>

<p>using $\Balpha$’s linearity.</p>
<p><strong>Notation:</strong>
Let $\CV$ be a finite-dimensional real vector space.
For $\Bv\in\CV$ and $\Balpha\in\CV^\ast$</p>

<p>denotes the action of $\Balpha$ on $\Bv$, and is called
a <strong>natural pairing</strong> or <strong>dual pairing</strong>
between a vector space and its dual.
<em>It is of the essence to understand that $\abrn{\cdot,\cdot}$ does not
denote an inner product in $\CV$</em>; that is,
$\abr{\Bv,\Balpha}$ means $\Balpha(\Bv)$.</p>
<p>With this notation, \eqref{eq:vectorrep2} can be written as</p>

<p>and \eqref{eq:dualbasis2} as</p>

<p>Using the convention that $\Be_i$ are column vectors and
$\Be^i$ are row vectors,
\eqref{eq:dualbasis1} can be rearranged in the following manner</p>

<p>which can be used to compute a dual basis.</p>
<p><strong>Example:</strong> Given a two-dimensional vector space $\CV$ with a basis
$\Be_1=[2,-0.5]\tra$, $\Be_2=[1,1]\tra$, we use
\eqref{eq:computedualbasis1} to compute</p>

<p>and obtain the dual basis vectors as
$\Be^1=[0.4,-0.4]$ and $\Be^2=[0.2,0.8]$.
The result is given in the
following figure,</p>
<figure>
<p><img src="https://solmaz.io/img/duality_vector_spaces/fig2.svg"></p>
</figure>
<p>where one can see that $\Be_1\perp\Be^2$, $\Be^1\perp\Be_2$.</p>
<figure>
<p><img src="https://solmaz.io/img/duality_vector_spaces/fig1.svg">
A body $\CB$ embedded in $\IR^2$ with curvilinear coordinates.
Every point $\CP$ at $\BX$ has an associated two-dimensional vector space,
called $\CB$’s tangent space at $\BX$, denoted $\tang_\BX\CB$. The basis
$\Be_i$ corresponding to coordinates $\theta_i$ are not necessarily
orthogonal and can admit corresponding duals $\Be^i$, due to
curvilinearity.
The coordinates appear to be affine at the point’s immediate vicinity,
and thus in the tangent space.</p>
</figure>
<p>The introduction of the dual space
allows us to reinterpret a one-form $\Balpha$
as an object residing in the dual space. In fact,
the <strong>canonical duality</strong> $\CV^{\ast\ast}=\CV$
states that every vector $\Bv$ can be interpreted as a functional
on the space $\CV^\ast$ via</p>


</article></div>]]>
            </description>
            <link>https://solmaz.io/notes/duality-vector-spaces/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24156082</guid>
            <pubDate>Fri, 14 Aug 2020 10:22:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to quickly create a Jamstack site]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24155601">thread link</a>) | @ndumai
<br/>
August 14, 2020 | https://www.stackbit.com/blog/create-a-jamstack-site-in-minutes/ | <a href="https://web.archive.org/web/*/https://www.stackbit.com/blog/create-a-jamstack-site-in-minutes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div id="page"><main id="content"><article><div><p><img src="https://www.stackbit.com/images/jamstack-site-minutes.png" alt="How to Create a Jamstack Website in Minutes!"></p><div><p>The Stackbit Site Builder created a CMS connected Jamstack site with just a few clicks and in just minutes. Let's explore how.</p><p>At Stackbit, we believe that the Jamstack can help make a better web for everyone because Jamstack sites are fast and secure. We want to make it easy for any developer to adopt the Jamstack for their next project. That's why one of the foundational elements that has defined Stackbit since day one has been the ability to generate a Jamstack site with just a few clicks. The basic steps are:</p><h2>1. Choose a theme</h2><p>We currently have eight themes to choose from, including our new, highly customizable theme called <a href="https://themes.stackbit.com/demos/starter/">Starter</a>. Plus, there are dozens of community themes available on GitHub, such as the popular <a href="https://github.com/snipcart/stackbit-theme-planty">Planty ecommerce theme</a> by Snipcart, or even more on <a href="https://jamstackthemes.dev/">JamstackThemes.dev</a>. You also have the ability to import a custom theme of your own (for details on how to configure that, you can <a href="https://docs.stackbit.com/site-builder/custom-themes/">check the docs</a>)</p><h2>2. Choose a static site generator (SSG)</h2><p>All of our themes can be generaed using Gatsby, Hugo or Jekyll (with additional support coming <em>very</em> soon...but I won't spoil the surprise). This gives you options to choose the tool and language you prefer to use for developing your Jamstack site. (Not sure which one to choose? <a href="https://www.stackbit.com/blog/choosing-your-ssg/">We have some advice here</a>.)</p><h2>3. Choose a headless content management system (CMS)</h2><p>One of the powerful things about buildng a site through the Stackbit site builder is that it is pre-configured for content management through your choice of <a href="https://www.stackbit.com/blog/what-is-a-headless-cms/">headless CMS</a>, including Sanity, Contentful, DataCMS, Forestry and NetilfyCMS. We've even added a new option for using files in your GitHub repository that can still get the full inline content editing features in Stackbit. (More on that in an upcoming post!)</p><p>One you've made these three choices, you are ready to go. Stackbit will build the site, place the source in GitHub and deploy to Netlify. Within minutes your site is ready and deployed!</p><p>Let's be honest though, telling you about this is far less exciting than simply showing you...so let's see what this looks like in action.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/d1Xlr4L44KE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><h2>Make the site your own</h2><p>The really important thing you should know about your new Jamstack site is that <strong>the code is yours.</strong> The code ends up in a GitHub respository you own. You can edit and customize it as you wish. In fact, we've made it easy to get your site running on your local machine and start editing by providing the instructions in the project's <code>README.md</code> or via Stackbit's online editor. This gives you the ability to do things like:</p><ul><li><a href="https://www.stackbit.com/blog/stackbit-gatsby-site-improvements/">Add a favicon, analytics, social sharing and a sitemap</a></li><li><a href="https://www.stackbit.com/blog/gatsby-search/">Add site search using Algolia</a></li><li><a href="https://www.stackbit.com/blog/jamstack-gatsby-mailchimp/">Add a mailing list form that connects to Mailchimp</a></li><li><a href="https://www.stackbit.com/blog/complete-guide-netlify-forms/">Customize how your form submissions are handled</a></li></ul><p>...and anything else you can think of!</p><p>The best part is that everything I have described to you here is also available at no cost. Just head on over to the <a href="https://app.stackbit.com/create">Stackbit Site Builder</a> and start creating your Jamstack site!</p></div></div></article></main></div></div></div></div>]]>
            </description>
            <link>https://www.stackbit.com/blog/create-a-jamstack-site-in-minutes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24155601</guid>
            <pubDate>Fri, 14 Aug 2020 09:11:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tell no-one: A century of secret deals between the NSA and the telecom industry]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24155374">thread link</a>) | @trymas
<br/>
August 14, 2020 | https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford#t=2215 | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford#t=2215">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><a href="https://media.ccc.de/c/31c3">
<img alt="conference logo" src="https://static.media.ccc.de/media/congress/2014/folder-2014.png">
</a>
</p>

<h2>
A century of secret deals between the NSA and the telecom industry
</h2>
</div>
<p>
<span></span>
<a href="https://media.ccc.de/search?p=James+Bamford">James Bamford</a>

</p>
<div data-aspect-ratio="16:9">

<!-- Mediaelement Player -->
<video controls="controls" data-id="2179" data-timeline="https://static.media.ccc.de/media/congress/2014/e8e29f6a-11df-491a-acae-1253879ae8f9-timeline.jpg" height="100%" poster="https://static.media.ccc.de/media/congress/2014/6600-hd_preview.jpg" preload="metadata" width="100%">
<source data-lang="eng" data-quality="high" src="https://cdn.media.ccc.de/congress/2014/webm-hd/31c3-6600-en-de-Tell_no-one_webm-hd.webm" title="eng 1080p" type="video/webm">
<source data-lang="eng" data-quality="high" src="https://cdn.media.ccc.de/congress/2014/h264-hd-web/31c3-6600-en-Tell_no-one_hd.mp4" title="eng 1080p" type="video/mp4">
<source data-lang="eng" data-quality="low" src="https://cdn.media.ccc.de/congress/2014/webm-sd/31c3-6600-en-de-Tell_no-one_webm-sd.webm" title="eng 576p" type="video/webm">
<source data-lang="eng" data-quality="low" src="https://cdn.media.ccc.de/congress/2014/h264-sd/31c3-6600-en-de-Tell_no-one_sd.mp4" title="eng 576p" type="video/mp4">
<source data-lang="eng" data-quality="high" src="https://cdn.media.ccc.de/congress/2014/h264-hd/31c3-6600-en-de-Tell_no-one_hd.mp4" title="eng 1080p" type="video/mp4">
<track kind="metadata" label="thumbnails" src="https://static.media.ccc.de/media/congress/2014/e8e29f6a-11df-491a-acae-1253879ae8f9-thumbnails.vtt" srclang="">

</video>


</div><p>
Playlists:
<a href="https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford/playlist">'31c3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford/audio">audio</a>
/
<a href="https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford/related">related events</a></p><ul>
<li>
<span></span>
62 min
</li>
<li>
<span title="event and release date"></span>
2014-12-28
</li>
<li>
<span></span>
6224
</li>
<li>
<span></span>
<a href="http://events.ccc.de/congress/2014/Fahrplan/events/6600.html">Fahrplan</a>
</li>
</ul>
<!-- %h3 About -->
<p>For nearly one hundred years, the NSA and its predecessors have been engaging in secret, illegal deals with the American telecom industry, with both virtually immune from prosecution.</p>

<h3>Download</h3>
<div>
<div>
<div>
<p>
<h4>Video</h4>
</p>
<div>
<ul role="tablist">
<li role="presentation">
<a aria-controls="mp4" data-toggle="tab" href="#mp4" role="tab">
MP4
</a>
</li>
<li role="presentation">
<a aria-controls="webm" data-toggle="tab" href="#webm" role="tab">
WebM
</a>
</li>
</ul>
<div>
<div id="mp4" role="tabpanel">
<div>
<a href="https://cdn.media.ccc.de/congress/2014/h264-hd/31c3-6600-en-de-Tell_no-one_hd.mp4">
<p>Download 1080p</p>
<span>eng</span>
<span>484 MB</span>
</a>
</div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/h264-sd/31c3-6600-en-de-Tell_no-one_sd.mp4">
<p>Download 576p</p>
<span>eng</span>
<span>253 MB</span>
</a>
</div>
</div>
<div id="webm" role="tabpanel">
<div>
<a href="https://cdn.media.ccc.de/congress/2014/webm-hd/31c3-6600-en-de-Tell_no-one_webm-hd.webm">
<p>Download 1080p</p>
<span>eng</span>
<span>486 MB</span>
</a>
</div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/webm-sd/31c3-6600-en-de-Tell_no-one_webm-sd.webm">
<p>Download 576p</p>
<span>eng</span>
<span>208 MB</span>
</a>
</div>
</div>
</div>
</div>
</div>
<div>
<p>
<h4>Subtitles</h4>
</p>
<div>
<p><a href="https://www.c3subtitles.de/talk/guid/e8e29f6a-11df-491a-acae-1253879ae8f9" target="_blank">
Help us to subtitle this talk!
</a>
</p></div>
</div>
<div>
<p>
<h4>Audio</h4>
</p>
<div>
<div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/mp3/31c3-6600-en-de-Tell_no-one_mp3.mp3">
<p>Download mp3</p>
<span>eng</span>
<span>85 MB</span>
</a>
</div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/opus/31c3-6600-en-de-Tell_no-one_opus.opus">
<p>Download opus</p>
<span>eng</span>
<span>43 MB</span>
</a>
</div>
</div>
</div>
</div>
</div>

</div>
<h3>Related</h3>
<div>
<div>
<p><a href="https://media.ccc.de/v/31c3_-_6602_-_en_-_saal_1_-_201412301130_-_the_case_of_chelsea_manning_-_alexa_o_brien_-_nancy_hollander_-_ahmed_ghappour_-_chase_strangio">
<img alt="The case of Chelsea Manning" src="https://static.media.ccc.de/media/congress/2014/6602-hd.jpg" title="The case of Chelsea Manning">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6595_-_en_-_saal_1_-_201412281900_-_hard_drive_punch_-_aram_bartholl">
<img alt="»Hard Drive Punch«" src="https://static.media.ccc.de/media/congress/2014/6595-hd.jpg" title="»Hard Drive Punch«">
</a>
</p>
<p><a href="https://media.ccc.de/v/MRMCD2014_-_6028_-_de_-_tiefbaustelle_s21_-_201409061830_-_geheimdienste_und_spione_-_vom_papst_bis_zur_nsa_-_herr_urbach">
<img alt="Geheimdienste und Spione - vom Papst bis zur NSA" src="https://static.media.ccc.de/media/conferences/mrmcd/mrmcd14/6028.jpg" title="Geheimdienste und Spione - vom Papst bi…">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6265_-_en_-_saal_6_-_201412281600_-_the_automobile_as_massive_data_gathering_source_and_the_consequences_for_individual_privacy_-_jimmy_schulz_-_dr_rudiger_hanig">
<img alt="The automobile as massive data gathering source and the consequences for individual privacy" src="https://static.media.ccc.de/media/congress/2014/6265-hd.jpg" title="The automobile as massive data gatherin…">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6112_-_en_-_saal_2_-_201412301715_-_tor_hidden_services_and_deanonymisation_-_dr_gareth_owen">
<img alt="Tor: Hidden Services and Deanonymisation" src="https://static.media.ccc.de/media/congress/2014/6112-hd.jpg" title="Tor: Hidden Services and Deanonymisation">
</a>
</p>
<p><a href="https://media.ccc.de/v/30C3_-_5255_-_en_-_saal_1_-_201312301400_-_through_a_prism_darkly_-_kurt_opsahl">
<img alt="Through a PRISM, Darkly" src="https://static.media.ccc.de/media/congress/2013/5255-h264-iprod.jpg" title="Through a PRISM, Darkly">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6571_-_en_-_saal_1_-_201412271130_-_31c3_keynote_-_alecempire">
<img alt="31C3 Keynote" src="https://static.media.ccc.de/media/congress/2014/6571-hd.jpg" title="31C3 Keynote">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6430_-_de_-_saal_2_-_201412291130_-_nsa_points_of_presence_in_at_-_erich_moechel">
<img alt="NSA Points of Presence in AT" src="https://static.media.ccc.de/media/congress/2014/6430-hd.jpg" title="NSA Points of Presence in AT">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6122_-_en_-_saal_1_-_201412271830_-_mobile_self-defense_-_karsten_nohl">
<img alt="Mobile self-defense" src="https://static.media.ccc.de/media/congress/2014/6122-hd.jpg" title="Mobile self-defense">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6308_-_en_-_saal_1_-_201412281245_-_beyond_pnr_exploring_airline_systems_-_saper">
<img alt="Beyond PNR: Exploring airline systems" src="https://static.media.ccc.de/media/congress/2014/6308-hd.jpg" title="Beyond PNR: Exploring airline systems">
</a>
</p>
</div>
</div>

<!-- %h3 Embed/Share -->

<h3>Tags</h3>
<div>
<p><a href="https://media.ccc.de/c/31c3/Ethics,%20Society%20&amp;%20Politics" rel="tag">Ethics, Society &amp; Politics</a>
</p></div>
</div></div>]]>
            </description>
            <link>https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford#t=2215</link>
            <guid isPermaLink="false">hacker-news-small-sites-24155374</guid>
            <pubDate>Fri, 14 Aug 2020 08:34:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Save Mozilla]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24155372">thread link</a>) | @caisah
<br/>
August 14, 2020 | http://dpk.io/savemozilla | <a href="https://web.archive.org/web/*/http://dpk.io/savemozilla">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  
</header>

<p><i>Disclaimer: I’m not a current or former Mozilla employee and have no other affiliation with Mozilla.</i> This is my own analysis of the publically-available information surrounding Mozilla’s decision to <a href="https://blog.mozilla.org/blog/2020/08/11/changing-world-changing-mozilla/">radically downsize</a> in a way that seems to further threaten Firefox’s future.

</p><p>A lot of people are very angry at Mozilla’s management for their decision to restructure the foundation, which is <a href="https://twitter.com/withoutboats/status/1217558588857544704">not unreasonable.</a> But seen in context, I think most people would, if in their position, make the same decision.

</p><p>Why is Mozilla cutting staff on its most popular product (Firefox) and refocusing on things that look like unsuccessful stunt projects? <a href="https://medium.com/swlh/could-google-crush-firefox-in-2020-13a55b5d4526">Because they’re about to lose the revenue from it.</a> <em>Google</em> is to blame for not renewing the contract that gives Mozilla a share of the ad revenue from the Firefox search bar. The web browser market has been walking on thin ice since 2008 when Chrome came out, because with Chrome available and under its own control, Google no longer had a reason to support the ecosystem with revenue-sharing deals. Now it seems like Google wants to see just how thin it can make the ice before Mozilla goes under.

</p><p>And why are they focussing on products nobody uses? Because they can make money by selling VPN subscriptions and premium bookmarking accounts without depending on the (obviously limited) goodwill of their competitors.

</p><p>What can you do about this? Here are some suggestions:

</p><ul>
  <li><strong>Buy one of Mozilla’s other products.</strong> It might seem like validating the bad decision made by Mozilla management, but it is reasonable to hope that income from, say, Mozilla VPN might be enough to keep a rag-tag Firefox team going.
  </li><li><strong>Just straight up <a href="https://donate.mozilla.org/">donate to Mozilla.</a></strong> Remember, Mozilla is a non-profit organization. While Google is developing Chrome to strengthen its bottom line and pay out more to shareholders, Mozilla’s interest in the Web platform is actually public-spirited. They fought against DRM in HTML and the mandatory use of patent-encumbered technologies on the open web, and when these efforts failed (largely for the same reasons Google is now able to crush Firefox entirely) they adopted laudable compromises, giving their users a genuine choice about using these technologies. And more than that&nbsp;—&nbsp;they’re actively participating in projects to create new, widely-supported and superior alternatives to these problematic technologies for the future. The web would be a worse place without Mozilla, and for that they deserve your goodwill.
  </li><li><strong>Write to your lawmaker urging an investigation into Google’s anti-competitive practices</strong> in the web browser and web markup space. This could be particularly effective if you live in the EU and write to your European Parliamentarians. Google is probably counting on the Trump administration not caring about their blatant repeat of Microsoft’s anti-trust violations&nbsp;— but other major jurisdictions which still have functioning regulatory systems can make a difference.
  </li><li><strong>Actually use Firefox, or one of its derivatives like the Tor Browser.</strong> One reason Google feels able to do this is probably because of Firefox’s shrinking market share. But Firefox is a vital part of the browser ecosystem, not least as the only major browser left that isn’t based on a WebKit-derivative engine, and as a hackable open-source browser that’s a vital component of equally-vital privacy projects like Tor. And Firefox still has really great features, especially for web developers. Switch back to Firefox&nbsp;— especially if you’re on Chrome!
  </li><li><strong>Switch away from Google products as much as possible.</strong> I know that other web search engines are still embarrassingly bad&nbsp;—&nbsp;I’m not here to guilt-trip anyone into using DuckDuckGo. But if you use Gmail, stop. There are <a href="https://www.fastmail.com/">fantastic</a> <a href="https://protonmail.com/">alternatives</a> out there which, yes, filter spam just as well as Gmail does these days. Use Apple Maps or OpenStreetMap or Yelp instead of Google Maps. Run an ad blocker that blocks YouTube ads, and support your favourite YouTubers directly over Patreon instead.
</li></ul>


</div>]]>
            </description>
            <link>http://dpk.io/savemozilla</link>
            <guid isPermaLink="false">hacker-news-small-sites-24155372</guid>
            <pubDate>Fri, 14 Aug 2020 08:34:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Epic fight against app store monopolies (Epic Games)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24154938">thread link</a>) | @simplertms
<br/>
August 14, 2020 | https://4thquadrant.io/snippets/snippet-the-epic-fight-against-app-store-monopolies/ | <a href="https://web.archive.org/web/*/https://4thquadrant.io/snippets/snippet-the-epic-fight-against-app-store-monopolies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_27_955">

<div>
<p>Epic Games introduced an update to their mobile (iOS and Android) version of Fortnite that allows users to buy directly from Epic Games at a 20% discount, removing incentives to pay with the officially sanctioned payment systems on the App Store and Play Store.&nbsp;</p>



<p>Soon after this update, Apple removed Fortnite from its App Store, Google was not far behind in doing the same. In response, Epic Games has filed individual suits against both tech giants claiming that their behaviour is monopolistic control over their respective ecosystems. However, there is some nuance and differences that we should explore between the two ecosystems that could have implications for the validity of the anti-trust lawsuits that Epic will have to contend with.&nbsp;</p>



<p>Looking at the two ecosystems holistically, it is perhaps more appropriate in this case to think of Android and iOS as marketplaces rather than solely focusing on their function as operating systems. The contention is that the marketplaces are being monopolised and controlled to the disadvantage of developers. This is especially true of Apple iOS, where the entire OS is a marketplace, where the App Store is the only access point for third-party applications to the ecosystem. If an application is removed from the App Store, the third-party application simply cannot exist on the iOS ecosystem.&nbsp;</p>



<p>Comparatively, Google’s Android OS functions a little differently. The OS acts as an open ecosystem which is augmented by the Play Store. The Play Store, not the OS, is the marketplace – the place for discovery. The Play Store as a standalone application can have comparative and competitive marketplaces on the Android OS, like the Samsung store. Further, the Android OS allows for third-party installs of applications albeit with security warnings.&nbsp;</p>



<p>Epic might have a hard time arguing that Google is being anti-competitive when it has avenues of access – albeit less direct – outside of the Google Play Store. Applications can still exist within the Android ecosystem even when the Play Store removes listings according to their marketplace rules.</p>



<p>Apple, on the other hand, has its entire ecosystem siloed as a marketplace, with no third-party marketplaces allowed and no ability to legally install third-party applications – placing them in a much more difficult position when it comes to anti-competitive claims. In recent months, Apple has come under increasing scrutiny as they butt heads with application developers, most notably Hey email client, Google’s Stadia platform and Microsoft’s xCloud platform.&nbsp;</p>



<div id="slimcalltoaction"><p>This is box title</p><p>If you enjoyed this article, take advantage of our 14 days free trial to explore our exclusive content. Or sign-up for our free weekly newsletters. View our subscription options <a href="https://4thquadrant.io/subscribe">here.</a></p></div>
</div></div><div data-td-block-uid="tdi_28_f29">

<div><h3><span>CONTACT THE EDITOR</span></h3>
<p>We welcome thoughtful discourse on all our content. If you would like to further explore or discuss any of the ideas covered in this article please contact our editors directly.<br><span>Contact Details</span></p>
</div></div></div>]]>
            </description>
            <link>https://4thquadrant.io/snippets/snippet-the-epic-fight-against-app-store-monopolies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154938</guid>
            <pubDate>Fri, 14 Aug 2020 07:33:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gadgetbridge (FLOSS gadget companion app) adding support for Mi Band 5 and TLW64]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24154628">thread link</a>) | @vanous
<br/>
August 13, 2020 | https://blog.freeyourgadget.org/release-0_46_0.html | <a href="https://web.archive.org/web/*/https://blog.freeyourgadget.org/release-0_46_0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Gadgetbridge 0.46.0 has been release and after a whole week of waiting it
landed in F-Droid.</p>
<p>This release, which adds TLW64 support contributed by Erik Bloß, also has
support for the new Mi Band 5, which is basically runnig on the Mi Band 4 code.</p>
<p>On the Huami front there are fixes for GTR/GTS activity data on newer
firmware version. There seems to be extra data which we ignore for now to make
the current code run with it. In the future we will look at making use of
the new data which unfortunately would need a new database schema.</p>
<p>Another quite big changes was contributed by Taavi Eomäe, who refactored the
device discovery activity which fixes tons of bugs and also new features,
like displaying already paired devices an notes about devices needing a
pairing key.</p>
<p>The release 0.45.0 did not have its own blog post, please refer to the list below
for details on what changed with the 0.45.0 and 0.45.1 releases.</p>
<p>But there is one thing I would like to highlight. There is a new,
experimental way of getting weather data from an new open source app developed
by Pawel Dube, that directly supports Gadgetbridge. No need for API keys.
The App is still alpha and work in progress, but we highly recommend trying it.
<a href="https://codeberg.org/Starfish/TinyWeatherForecastGermany">TinyWeatherForecast</a>
Don't be fooled by the name it supports a lot of locations worldwide.
If you like it please give it a star on Codeberg.org!</p>
<p>For all user-facing changes since the previous blog post, check the following list:</p>
<h4>0.46.0</h4>
<ul>
<li>Initial support for Mi Band 5</li>
<li>Initial support for TLW64</li>
<li>Amazfit GTR/GTS: Fix broken activity data on newer firmwares</li>
<li>Big refactoring of the device discovery activity (See PR #1927 description for details)</li>
<li>Add about screen</li>
<li>New icon for Amazfit Bip</li>
<li>Avoid duplicated entries in preferred media player selection</li>
<li>Avoid a lot of crashes and improve error handling in various places</li>
</ul>
<h4>0.45.1</h4>
<ul>
<li>Amazfit GTR/GTS: Fix connection issue with latest firmwares (probably other Huami devices also affected)</li>
<li>Add experimental support for TinyWeatherForecastGermany</li>
</ul>
<h4>0.45.0</h4>
<ul>
<li>Initial support for Amazfit T-Rex</li>
<li>Amazfit Bip S: Support installation of latest .res</li>
<li>Amazfit Bip S: Support longer notification messages</li>
<li>Huami: Limit weather forecast to 7 days to fix problems with weather notificaon 0.3.11</li>
<li>Huami: Improve music playback information</li>
<li>Huami: Ensure cutting strings on UTF-8 border</li>
<li>Stop incoming call notification when VoIP calls are missed</li>
<li>Fix a crash when with Farsi translation</li>
</ul></div></div>]]>
            </description>
            <link>https://blog.freeyourgadget.org/release-0_46_0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154628</guid>
            <pubDate>Fri, 14 Aug 2020 06:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Rust Lambdas in Production]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24154506">thread link</a>) | @lukastyrychtr
<br/>
August 13, 2020 | https://www.cvpartner.com/blog/using-rust-lambdas-in-production | <a href="https://web.archive.org/web/*/https://www.cvpartner.com/blog/using-rust-lambdas-in-production">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure id="w-node-c687bec1ed8c-01d6604b"><p><img src="https://assets.website-files.com/56d31f469aaa616f5089a267/5f23ffebdba110f2cab1d06d_Rust%20Lambda.png" alt=""></p></figure><div><p>Update:&nbsp;Join the discussion over at <a href="https://news.ycombinator.com/item?id=24154506">HackerNews</a>! </p><p>We’ve written in the past about how the CV Partner web application is written in Ruby on Rails. The web application isn’t the whole story, though. Surrounding it are many supporting services, and we are increasingly using Rust to write these services.</p></div><p>We’re also using more Lambdas in our architecture, and we want to use Rust in those as well. The landscape for Rust lambdas isn’t barren, but it’s not well-trodden either.<br></p><p>This post is going to cover how we write, build, and deploy our Rust lambdas. Our lambdas have the following qualities that we’re proud of and want to share with you:<br></p><ol role="list"><li><strong>Fast, standardised build.</strong> All of our lambdas use the same Dockerfile to build, and make good use of Docker’s layer caching. Incremental builds in CI take under a minute.</li><li><strong>Run locally. </strong>If you’re working on a lambda, you don’t want to have to sit through a CI build to see if your changes work. All of our lambdas can run locally and in AWS using the same code.</li><li><strong>Private GitHub dependencies. There aren’t many options out there for private Cargo repositories, so we use private GitHub repositories for our internal libraries.</strong></li></ol><h2>The code<br></h2><p>The starting point for writing a Lambda in Rust is to use the official <a href="https://github.com/awslabs/aws-lambda-rust-runtime">Rust lambda runtime</a>. At the time of writing, the last release of this library is version 0.2, which doesn’t support async/await. Async/await support is present in master, though. Here’s how it looks in practice:</p><div><pre><code>
use lambda::{lambda, Context};
use serde_json::Value;

type Error = Box<dyn std::error::error="" +="" send="" sync="" 'static="">;

#[lambda]
#[tokio::main]
async fn main(event: Value, _: Context) -&gt; Result<value, error=""> {
    Ok(event)
}

</value,></dyn></code></pre></div><p>The problem with this is that you can’t run it locally. The #[lambda] attribute wraps your main function in another main function that calls in to the AWS lambda API.<br></p><p>To get around this, we write two main functions:<br></p><div><pre><code>

#[cfg(feature = "with-lambda")]
use lambda::{lambda, Context};
use serde::{Deserialize, Serialize};

type Error = Box<dyn std::error::error="" +="" send="" sync="" 'static="">;

#[derive(Deserialize, Debug)]
struct Input {
    name: String
}

#[derive(Serialize, Debug)]
struct Output {
    greeting: String
}

async fn handler(input: Input) -&gt; Result<output, error=""> {
    Ok(Output { greeting: format!(“Hello, {}!”, input.name) })
}

#[cfg(feature = "with-lambda")]
#[lambda]
#[tokio::main]
async fn main(input: Input, _: Context) -&gt; Result<output, error=""> {
    handler(input).await
}

#[cfg(not(feature = "with-lambda"))]
#[tokio::main]
async fn main() -&gt; Result&lt;(), Error&gt; {
    let input_str = std::env::args().nth(1);
    if input_str.is_none() {
        panic!(
            "you must pass an input parameter as the first argument, and it must be a JSON string"
        );
    }
    let input = serde_json::from_str(&amp;input_str.unwrap())?;
    let output = handler(input).await?;
    println!("{}", serde_json::to_string(&amp;output)?);
    Ok(())
}

</output,></output,></dyn></code></pre></div><p>We’re making use of Rust’s “feature” flags to compile a different harness around the handle function depending on whether we want to run locally or in AWS.</p><p>Here’s the Cargo.toml file:</p><div><pre><code>
[package]
name = "rust-lambda-template"
version = "0.1.0"
authors = ["Sam Rose <sam@cvpartner.com>"]
edition = "2018"

[dependencies]
lambda = { git = "https://github.com/awslabs/aws-lambda-rust-runtime/", rev = "c8dbcd39e0b1cf9ecf395e2b2f9df6c6c0d97780" }
tokio = { version = "0.2", features = ["full"] }
serde = { version = "1", features = ["derive"] }
serde_derive = "1"
serde_json = "1"

[features]
with-lambda = []

</sam@cvpartner.com></code></pre></div><p>Two noteworthy things:<br></p><ol role="list"><li>We’re using a version of the aws-lambda-rust-runtime that hasn’t officially been released. This isn’t ideal, and we’re eagerly awaiting a 0.3 release.</li><li>We have a features section, which is where we define the with-lambda feature we use in the Rust code shown above.<br></li></ol><p>Running our lambda now gives us the following:</p><div><pre><code>
$ cargo run -- ‘{ “name”: “Sam” }’
{ “message”: “Hello, Sam!” }

</code></pre></div><h2><strong>The Dockerfile</strong></h2><p>All of our lambdas build with the same Dockerfile. I’ll show it in all of its glory and then explain what’s going on bit by bit. Brace yourself.</p><div><pre><code>
# syntax=docker/dockerfile:experimental

FROM rust:latest as cargo-build
ARG name

RUN apt-get update
RUN apt-get install musl-tools -y
RUN rustup target add x86_64-unknown-linux-musl

WORKDIR /usr/src/${name}
COPY Cargo.toml Cargo.toml
RUN mkdir src/
RUN echo "fn main() {println!(\"if you see this, the build broke\")}" &gt; src/main.rs
RUN mkdir -p $HOME/.ssh
RUN ssh-keyscan github.com &gt; $HOME/.ssh/known_hosts
RUN test "$(cat $HOME/.ssh/known_hosts | ssh-keygen -lf -)" = "2048 SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8 github.com (RSA)"
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

RUN rm src/main.rs
COPY src/* src
RUN touch src/**
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo test --features with-lambda --release --target=x86_64-unknown-linux-musl
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

FROM alpine:latest
ARG name
COPY --from=cargo-build /usr/src/${name}/target/x86_64-unknown-linux-musl/release/${name} /usr/local/bin/${name}

</code></pre></div><p>First of all, shout out to Shane Utt whose <a href="https://shaneutt.com/blog/rust-fast-small-docker-image-builds/">blog post</a> we used as a starting point for this.<br></p><p>The first line is a Docker directive that says we want to use some experimental Dockerfile syntax. The syntax in question is the --mount=type=ssh flag to the RUN commands, but we’ll talk about later.</p><div><pre><code>
FROM rust:latest as cargo-build
ARG name

</code></pre></div><p>This next bit says we want to use the latest Rust image, and we’re passing in a build arg called “name.” This is how we’re able to share this Dockerfile between all of our lambdas without having to modify it.</p><div><pre><code>
RUN apt-get update
RUN apt-get install musl-tools -y
RUN rustup target add x86_64-unknown-linux-musl

</code></pre></div><p>Next we run an update on the image, and we install <a href="https://musl.libc.org/">musl</a>. If you’re not familiar, musl is a libc replacement that you can link to statically. This means the resulting binary won’t depend on the system’s libc, which makes it more portable. It’s not a strict requirement for running on AWS Lambda, but it’s good practice.</p><div><pre><code>
WORKDIR /usr/src/${name}
COPY Cargo.toml Cargo.toml
RUN mkdir src/
RUN echo "fn main() {println!(\"if you see this, the build broke\")}" &gt; src/main.rs

</code></pre></div><p>The next few lines set up a pseudo project, where the only things we’re going to compile are our dependencies and a dummy main.rs. The idea behind this is to use Docker’s layer caching to avoid having to compile our dependencies every build. This leads to significantly faster incremental builds in Docker.</p><div><pre><code>
RUN mkdir -p $HOME/.ssh
RUN ssh-keyscan github.com &gt; $HOME/.ssh/known_hosts
RUN test "$(cat $HOME/.ssh/known_hosts | ssh-keygen -lf -)" = "2048 SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8 github.com (RSA)"

</code></pre></div><p>Up until now, we’ve done exactly what Shane Utt did in his version of this. These three lines, though, are new. Because we use SSH to fetch private dependencies (more on this later), we would sometimes find that our builds would fail with the error “host key verification failed.” To get around that we pull down GitHub’s host keys and make sure they’re what we expect them to be based on the values <a href="https://docs.github.com/en/github/authenticating-to-github/githubs-ssh-key-fingerprints">here</a>.</p><div><pre><code>
RUN mkdir -p $HOME/.ssh
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

</code></pre></div><p>Our first bit of experimental syntax! The --mount flag is a new thing introduced with the BuildKit engine for Docker, you can read about it in depth <a href="https://medium.com/@tonistiigi/build-secrets-and-ssh-forwarding-in-docker-18-09-ae8161d066">here</a>. The type=ssh bit is us telling Docker that we want to use an SSH agent for this command. In the docker build invocation, which we’ll see later, we can tell Docker what keys to add to this SSH agent.</p><p>The reason we do this is because it was the only way we could find that let us depend on private GitHub repositories in our Cargo.toml file, in a way that worked both locally and in CI. It means we can do this in our Cargo.toml file:</p><div><pre><code>
[dependencies]
private-library = { git = "ssh://github.com/cvpartner/private-library", tag = "1.0" }

</code></pre></div><p>And it Just Works<strong>™</strong>.</p><p>The rest of the RUN command is our first cargo build. It looks a lot scarier than it is. Most of it is us telling rustc to link against musl instead of the default libc. The only other interesting bit is the --features with-lambda. This matches up with the code we saw earlier to produce a binary that’s going to work properly when deployed in AWS.</p><div><pre><code>
RUN rm src/main.rs
COPY src/* src
RUN touch src/**
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo test --features with-lambda --release --target=x86_64-unknown-linux-musl
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

</code></pre></div><p>Next up, we’re copying over our actual source code. The touch command is necessary for cargo to realise the files are new, because when we created our dummy main.rs file earlier we created a new file with a timestamp later than the one on the real main.rs file. This is different to the approach taken by Shane Utt, as we found that approach would often result in builds where the dummy main.rs file was the one that ended up in the final build.</p><p>Another addition is the cargo test invocation. Tests are good!</p><div><pre><code>
FROM alpine:latest
ARG name
COPY --from=cargo-build /usr/src/${name}/target/x86_64-unknown-linux-musl/release/${name} /usr/local/bin/${name}

</code></pre></div><p>Lastly we create a new build stage and copy over the final executable. The new build stage is in order to keep the final image small. Ours tend to clock in at around 8MB.<br></p><h2><strong>The build script</strong><br></h2><p>Invoking Docker is done in a shell script which is also identical for all of our lambdas.</p><div><pre><code>
#!/usr/bin/env bash

set -e
set -x

DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" &amp;&amp; pwd )"
cd $DIR

NAME=$(cat Cargo.toml | grep "name" | head -n 1 | sed -E 's/name = "(.*)"/\1/')
DOCKER_NAME="cvpartner/$NAME"

if [[ -z $BUILD_ID ]];
then
  TAG=$DOCKER_NAME
  SSH="--ssh default"
else
  TAG="our.private.docker.registry/$DOCKER_NAME"
  SSH="--ssh default=/home/ci/.ssh/id_rsa"
fi

DOCKER_BUILDKIT=1 docker build $SSH --cache-from $TAG …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cvpartner.com/blog/using-rust-lambdas-in-production">https://www.cvpartner.com/blog/using-rust-lambdas-in-production</a></em></p>]]>
            </description>
            <link>https://www.cvpartner.com/blog/using-rust-lambdas-in-production</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154506</guid>
            <pubDate>Fri, 14 Aug 2020 06:39:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing a Type-safe printf in Rust]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24154263">thread link</a>) | @lukastyrychtr
<br/>
August 13, 2020 | https://willcrichton.net/notes/type-safe-printf/ | <a href="https://web.archive.org/web/*/https://willcrichton.net/notes/type-safe-printf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>
    
    Will Crichton
    
    &nbsp; — &nbsp;
    June 21, 2020
  </p>
  <p>I show how to use heterogeneous lists and traits to implement a type-safe printf in Rust. These mechanisms can ensure that two variadic argument lists share important properties, like the number of format string holes matches the number of printf arguments.</p>
  <p><em>Part of an ongoing series about type-level programming in Rust. Consider reading <a href="http://willcrichton.net/notes/type-level-programming/">part one</a> first! All code in this note can be found in <a href="https://gist.github.com/willcrichton/e7fcf1b0e84b4be7f172f0e0245cf149">this gist</a>.</em></p>

<p>Rust has a great printf function, <a href="https://doc.rust-lang.org/std/macro.println.html"><code>println!</code></a>. It has a rich formatting language, but also catches mistakes at compile-time. For example, <code>println!</code> will check that the number of arguments matches the number of holes in the format string:</p>

<div><div><pre><code>error: 2 positional arguments in format string, but there is 1 argument
  --&gt; src/printf.rs:36:13
   |
36 |   println!("{} {}", "Hello");
</code></pre></div></div>

<p>How does the Rust compiler make this check? Because both the format string and the argument are within the macro, Rust will check that the number of holes matches the number of arguments. Consequently, format strings <em>have</em> to be within the macro. If we write:</p>

<div><div><pre><code><span>let</span> <span>s</span> <span>=</span> <span>"{} {}"</span><span>;</span>
<span>println!</span><span>(</span><span>s</span><span>,</span> <span>"hi"</span><span>)</span>
</code></pre></div></div>

<p>This code fails to compile with the error:</p>

<div><div><pre><code>error: format argument must be a string literal
  --&gt; src/printf.rs:42:12
   |
42 |   println!(s, "hi");
</code></pre></div></div>

<p>I’ll show you how to implement type-safe printf without using procedural macros. More generally, this note contains a Rust recipe for functions where:</p>

<ol>
  <li>Arguments are variadic</li>
  <li>Each argument can be a different type (<code>Vec&lt;T&gt;</code> not allowed)</li>
  <li>Multiple variadic inputs share a parallel property, e.g. the number of arguments should match the number of format holes</li>
</ol>

<h2 id="core-mechanism-hlist">Core mechanism: HList</h2>

<p>First, we need to understand the main type-level mechanism: a heterogeneous list (or H-list). An H-list is a sequence of values of potentially different types. For example, <code>[1, "a", true]</code> is an H-list, but not a valid Rust vector. H-lists are implemented in Rust using a linked-list style:</p>

<div><div><pre><code><span>struct</span> <span>HNil</span><span>;</span>
<span>struct</span> <span>HCons</span><span>&lt;</span><span>Head</span><span>,</span> <span>Tail</span><span>&gt;</span> <span>{</span>
  <span>head</span><span>:</span> <span>Head</span><span>,</span>
  <span>tail</span><span>:</span> <span>Tail</span>
<span>}</span>

<span>let</span> <span>example</span><span>:</span> <span>HCons</span><span>&lt;</span><span>i32</span><span>,</span> <span>HCons</span><span>&lt;</span><span>bool</span><span>,</span> <span>HNil</span><span>&gt;&gt;</span> <span>=</span>
  <span>HCons</span><span>{</span><span>head</span><span>:</span> <span>1</span><span>,</span> <span>tail</span><span>:</span> <span>HCons</span><span>{</span><span>head</span><span>:</span> <span>true</span><span>,</span> <span>tail</span><span>:</span> <span>HNil</span><span>}};</span>
</code></pre></div></div>

<p>The key idea is that the type of an H-list changes every time you make a change to it. By contrast, if you push to a <code>Vec&lt;T&gt;</code>, the type of the vector stays the same.</p>

<p>Just like Rust has <code>vec![]</code>, we can use the <a href="https://github.com/lloydmeta/frunk#hlist">frunk</a> crate to get an <code>hlist!</code> macro.</p>

<div><div><pre><code><span>let</span> <span>example</span> <span>=</span> <span>hlist!</span><span>[</span><span>1</span><span>,</span> <span>true</span><span>];</span> <span>// same as above</span>
</code></pre></div></div>

<h2 id="setting-up-printf">Setting up printf</h2>

<p>Let’s go back to the ingredients of printf. We need a format string and an argument list. The key idea is to represent both with an H-list, and carefully use Rust’s traits to ensure our desired property: the number of arguments should match the number of holes.</p>

<p>First, to represent format strings, we will have a sequence of structs that represent each part of the string.</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>FString</span><span>(</span><span>&amp;</span><span>'static</span> <span>str</span><span>);</span>
<span>pub</span> <span>struct</span> <span>FVar</span><span>;</span>

<span>// Assume that we compile "Hello {}! The first prime is {}" into this code.</span>
<span>// That would be a simple syntactic transformation.</span>
<span>let</span> <span>example</span> <span>=</span> <span>hlist!</span><span>[</span>
  <span>FString</span><span>(</span><span>"Hello "</span><span>),</span> <span>FVar</span><span>,</span> <span>FString</span><span>(</span><span>"! The first prime is "</span><span>),</span> <span>FVar</span>
<span>];</span>
</code></pre></div></div>

<p>To represent arguments, we will use a matching H-list of values. For example:</p>

<div><div><pre><code><span>let</span> <span>args</span> <span>=</span> <span>hlist!</span><span>[</span><span>"world"</span><span>,</span> <span>2</span><span>];</span>
</code></pre></div></div>

<p>Then, our goal is to create a function <code>format</code> such that this is true:</p>

<div><div><pre><code><span>assert_eq!</span><span>(</span>
  <span>example</span><span>.format</span><span>(</span><span>args</span><span>),</span>
  <span>"Hello world! The first prime is 2"</span>
<span>);</span>
</code></pre></div></div>

<p>And this should be a compile-time (NOT run-time) error:</p>

<div><div><pre><code><span>example</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"Only one arg"</span><span>]);</span>
</code></pre></div></div>

<h2 id="the-format-trait">The Format trait</h2>

<p>In the spirit of type-level computation, we start by defining a trait.</p>

<div><div><pre><code><span>trait</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span> <span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>ArgList</span><span>)</span> <span>-&gt;</span> <span>String</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Here, <code>self</code> is the H-list of the format directives, and <code>ArgList</code> is the H-list of the variadic arguments. <code>Format</code> need to take <code>ArgList</code> as a type parameter, because its type will change as we remove elements from the <code>ArgList</code> list.</p>

<p>Now, we proceed to implement the <code>Format</code> trait by cases. First, the base case for reaching the end of the format list <code>HNil</code>:</p>

<div><div><pre><code><span>impl</span> <span>Format</span><span>&lt;</span><span>HNil</span><span>&gt;</span> <span>for</span> <span>HNil</span> <span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>_</span><span>args</span><span>:</span> <span>HNil</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>""</span><span>.to_string</span><span>()</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This impl says that when we reach the end of a format list, just return the empty string. And the only argument we will accept is an empty argument list. Combined with the next impls, this inductively ensures that extra arguments are not accepted.</p>

<p>Next, we will implement <code>FString</code>. This implementation should use the string constant contained in the <code>FString</code> struct, and combine it recursively with the rest of the format list. We don’t use variadic arguments for <code>FString</code>, so they get passed along. In Rust, this English specification becomes:</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>ArgList</span><span>,</span> <span>FmtList</span><span>&gt;</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span>
<span>for</span> <span>HCons</span><span>&lt;</span><span>FString</span><span>,</span> <span>FmtList</span><span>&gt;</span>
<span>where</span> <span>FmtList</span><span>:</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span>
<span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>ArgList</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>self</span><span>.head</span><span>.</span><span>0</span><span>.to_owned</span><span>()</span> <span>+</span> <span>&amp;</span><span>self</span><span>.tail</span><span>.format</span><span>(</span><span>args</span><span>)</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Note that we have to add <code>FmtList: Format&lt;ArgList&gt;</code> to ensure the recursive call to <code>self.tail.format</code> works. Also note that we aren’t implementing <code>Format</code> directly on <code>FString</code>, but rather on an H-list containing <code>FString</code>.</p>

<p>Finally, the most complex case, <code>FVar</code>. We want this impl to take an argument from the <code>ArgList</code>, then format the remaining format list with the remaining arguments.</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>,</span> <span>FmtList</span><span>&gt;</span> <span>Format</span><span>&lt;</span><span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;&gt;</span>
<span>for</span> <span>HCons</span><span>&lt;</span><span>FVar</span><span>,</span> <span>FmtList</span><span>&gt;</span>
<span>where</span>
  <span>FmtList</span><span>:</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span><span>,</span>
  <span>T</span><span>:</span> <span>ToString</span><span>,</span>
<span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>args</span><span>.head</span><span>.to_string</span><span>()</span> <span>+</span> <span>&amp;</span><span>self</span><span>.tail</span><span>.format</span><span>(</span><span>args</span><span>.tail</span><span>)</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Be careful to observe which H-list is being accessed by <code>head</code> and <code>tail</code>. Here, the <code>args</code> H-list provides the data to fill the hole via <code>args.head</code>.</p>

<h2 id="checking-our-properties">Checking our properties</h2>

<p>With this implementation, our correct example successfully compiles and runs:</p>

<div><div><pre><code><span>let</span> <span>example</span> <span>=</span> <span>hlist!</span><span>[</span>
  <span>FString</span><span>(</span><span>"Hello "</span><span>),</span> <span>FVar</span><span>,</span> <span>FString</span><span>(</span><span>"! The first prime is "</span><span>),</span> <span>FVar</span>
<span>];</span>
<span>assert_eq!</span><span>(</span>
  <span>example</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"world"</span><span>,</span> <span>2</span><span>]),</span>
  <span>"Hello world! The first prime is 2"</span>
<span>);</span>
</code></pre></div></div>

<p>What about our incorrect example? If we write this:</p>

<div><div><pre><code><span>example</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"just one arg"</span><span>]);</span>
</code></pre></div></div>

<p>This code fails to compile with the error:</p>

<div><div><pre><code>error[E0308]: mismatched types
  --&gt; src/printf.rs:48:18
   |
48 |   example.format(hlist!["just one arg"]);
   |                  ^^^^^^^^^^^^^^^^^^^^^^
   |                  expected struct `Cons`, found struct `HNil`
   |
   = note: expected struct `HCons&lt;_, HNil&gt;`
              found struct `HNil`
</code></pre></div></div>

<p>While the error is enigmatic, our mistake is at least correctly caught at compile-time. This is because Rust deduces that <code>example.format()</code> expects an H-list of the shape <code>HCons&lt;_, HCons&lt;_, HNil&gt;&gt;</code>, but it finds <code>HNil</code> too soon in our 1-element H-list. A similar error occurs when providing too many args.</p>

<p>Stupendous! We have successfully implemented a type-safe printf using H-lists and traits.</p>

<h2 id="extending-our-abstraction">Extending our abstraction</h2>

<p>Right now, our <code>Format</code> function just checks that the format list and argument list are the same length. We could extend our format structures, for example to ensure that an <code>FVar</code> must be a particular type, or must use <code>Debug</code> vs. <code>Display</code>. Here’s the sketch of such a strategy:</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>PhantomData</span><span>;</span>

<span>// Add flags for whether using Display or Debug</span>
<span>pub</span> <span>struct</span> <span>FDisplay</span><span>;</span>
<span>pub</span> <span>struct</span> <span>FDebug</span><span>;</span>

<span>// Use a type parameter with PhantomData to represent the intended type</span>
<span>pub</span> <span>struct</span> <span>FVar</span><span>&lt;</span><span>T</span><span>,</span> <span>Flag</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>(</span><span>T</span><span>,</span> <span>Flag</span><span>)</span><span>&gt;</span><span>);</span>

<span>// Now, T has to be the same between the format list and arg list</span>
<span>// Also, FDisplay flag requires that `T: Display`</span>
<span>impl</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>,</span> <span>FmtList</span><span>&gt;</span> <span>Format</span><span>&lt;</span><span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;&gt;</span>
<span>for</span> <span>HCons</span><span>&lt;</span><span>FVar</span><span>&lt;</span><span>T</span><span>,</span> <span>FDisplay</span><span>&gt;</span><span>,</span> <span>FmtList</span><span>&gt;</span>
<span>where</span>
  <span>FmtList</span><span>:</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span><span>,</span>
  <span>T</span><span>:</span> <span>Display</span><span>,</span>
<span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>// using format! is cheating, but you get the idea</span>
    <span>format!</span><span>(</span><span>"{}"</span><span>,</span> <span>args</span><span>)</span> <span>+</span> <span>&amp;</span><span>self</span><span>.tail</span><span>.format</span><span>(</span><span>args</span><span>.tail</span><span>)</span>
  <span>}</span>
<span>}</span>

<span>// Similar impl for `T: Debug` when `FDebug` is used</span>
</code></pre></div></div>

<p>With this approach, if our format list and arg list differ in type:</p>

<div><div><pre><code><span>let</span> <span>fmt</span> <span>=</span> <span>hlist!</span><span>[</span><span>FString</span><span>(</span><span>"n: "</span><span>),</span> <span>FVar</span><span>::</span><span>&lt;</span><span>i32</span><span>,</span> <span>FDisplay</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>)];</span>
<span>fmt</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"not a number"</span><span>]);</span>
</code></pre></div></div>

<p>Then the code will not compile with the error, <code>&amp;'static str is not i32</code>.</p>

<p>Shout-out to <a href="https://www.servant.dev/posts/2018-07-12-servant-dsl-typelevel.html">this blog post</a> from Haskell’s servant framework which got me thinking about adapting their strategy into Rust.</p>

</div></div>]]>
            </description>
            <link>https://willcrichton.net/notes/type-safe-printf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154263</guid>
            <pubDate>Fri, 14 Aug 2020 06:07:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startupschool Build Sprint Panic]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24153818">thread link</a>) | @100-xyz
<br/>
August 13, 2020 | https://toonclip.com/blog | <a href="https://web.archive.org/web/*/https://toonclip.com/blog">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://toonclip.com/blog</link>
            <guid isPermaLink="false">hacker-news-small-sites-24153818</guid>
            <pubDate>Fri, 14 Aug 2020 05:08:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Separating Concerns in React with the 'Named Children' Pattern]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24153729">thread link</a>) | @todsacerdoti
<br/>
August 13, 2020 | https://ncphi.dev/blog/react-named-children | <a href="https://web.archive.org/web/*/https://ncphi.dev/blog/react-named-children">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><article><p>React Components for wrapping content often use the <code>children</code> pattern. For example, this <code>&lt;Card&gt;</code> wraps the text "Hello World":</p><p>The size of the <code>&lt;Card&gt;</code> could be set with a prop:</p><div><pre><code><span>&lt;</span><span>Card</span><span> </span><span>size</span><span>=</span><span>"</span><span>large</span><span>"</span><span>&gt;</span><span>Hello World</span><span>&lt;/</span><span>Card</span><span>&gt;</span></code></pre></div><p>This pattern works if <code>&lt;Card&gt;</code> has just one content section but not if it has multiple. In that case the content might be provided by <code>props</code> instead of <code>children</code>:</p><div><pre><code><span>&lt;</span><span>Card</span><span>
</span><span>  </span><span>size</span><span>=</span><span>"</span><span>large</span><span>"</span><span>
</span><span>  </span><span>title</span><span>=</span><span>"</span><span>Hello World</span><span>"</span><span>
</span><span>  </span><span>subtitle</span><span>=</span><span>"</span><span>This is a basic example</span><span>"</span><span>
</span><span>  </span><span>body</span><span>=</span><span>"</span><span>Here is where a lot more text would go.</span><span>"</span><span>
</span><span></span><span>/&gt;</span></code></pre></div><p>Unfortunately this makes unfamiliar components hard to understand since prop might configure the appearance of the <code>&lt;Card&gt;</code> or defines it's content. It also becomes messy when the content is not plain text:</p><div><pre><code><span>&lt;</span><span>Card</span><span>
</span><span>  </span><span>size</span><span>=</span><span>"</span><span>large</span><span>"</span><span>
</span><span>  </span><span>title</span><span>=</span><span>"</span><span>Hello World</span><span>"</span><span>
</span><span>  </span><span>subtitle</span><span>=</span><span>{</span><span>
</span><span>    </span><span>&lt;</span><span>&gt;</span><span>
</span><span>      This is a basic </span><span>&lt;</span><span>strong</span><span>&gt;</span><span>example</span><span>&lt;/</span><span>strong</span><span>&gt;</span><span>
</span><span>    </span><span>&lt;/</span><span>&gt;</span><span>
</span><span>  </span><span>}</span><span>
</span><span>  </span><span>body</span><span>=</span><span>"</span><span>Here is where a lot more text would go.</span><span>"</span><span>
</span><span></span><span>/&gt;</span></code></pre></div><p>The <em>Named Children</em> pattern helps with the mixing of concerns. Instead of setting <code>children</code> as content it's set as an object that maps section names to content. This approach separates content from config making it easier to guess each prop's purpose.</p><div><pre><code><span>&lt;</span><span>Card</span><span> </span><span>size</span><span>=</span><span>"</span><span>large</span><span>"</span><span>&gt;</span><span>
</span><span></span><span>{</span><span>{</span><span>
</span><span>  title</span><span>:</span><span> </span><span>"Hello World"</span><span>
</span><span>  subtitle</span><span>:</span><span> </span><span>&lt;</span><span>&gt;</span><span>This is a basic </span><span>&lt;</span><span>strong</span><span>&gt;</span><span>example</span><span>&lt;/</span><span>strong</span><span>&gt;</span><span>&lt;/</span><span>&gt;</span><span>
</span><span>  body</span><span>:</span><span> </span><span>"Here is where a lot more text would go."</span><span>
</span><span></span><span>}</span><span>}</span><span>
</span><span></span><span>&lt;/</span><span>Card</span><span>&gt;</span></code></pre></div><p>The <code>children</code> can then be used inside <code>&lt;Card&gt;</code> as any other object:</p><div><pre><code><span>function</span><span> </span><span>Card</span><span>(</span><span>{</span><span> size </span><span>=</span><span> </span><span>"medium"</span><span>,</span><span> children </span><span>}</span><span>)</span><span> </span><span>{</span><span>
</span><span>  </span><span>return</span><span> </span><span>(</span><span>
</span><span>    </span><span>&lt;</span><span>div</span><span> </span><span>className</span><span>=</span><span>{</span><span>size</span><span>}</span><span>&gt;</span><span>
</span><span>      </span><span>&lt;</span><span>h2</span><span>&gt;</span><span>{</span><span>children</span><span>.</span><span>title</span><span>}</span><span>&lt;/</span><span>h2</span><span>&gt;</span><span>
</span><span>      </span><span>&lt;</span><span>h3</span><span>&gt;</span><span>{</span><span>children</span><span>.</span><span>subtitle</span><span>}</span><span>&lt;/</span><span>h3</span><span>&gt;</span><span>
</span><span>      </span><span>&lt;</span><span>p</span><span>&gt;</span><span>{</span><span>children</span><span>.</span><span>body</span><span>&lt;/</span><span>p</span><span>&gt;</span><span>
</span><span>    </span><span>&lt;/</span><span>div</span><span>&gt;</span><span>
</span><span>  </span><span>)</span><span>
</span><span></span><span>}</span></code></pre></div><p>The <em>Named Children</em> pattern is a promising approach to <a href="https://en.wikipedia.org/wiki/Separation_of_concerns">separating concerns</a> in React Components making them easier to read and easier to change.</p></article></div></div></div></div>]]>
            </description>
            <link>https://ncphi.dev/blog/react-named-children</link>
            <guid isPermaLink="false">hacker-news-small-sites-24153729</guid>
            <pubDate>Fri, 14 Aug 2020 04:59:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Save the USPS]]>
            </title>
            <description>
<![CDATA[
Score 192 | Comments 236 (<a href="https://news.ycombinator.com/item?id=24153311">thread link</a>) | @mooreds
<br/>
August 13, 2020 | https://2pml.com/2020/08/10/usps/ | <a href="https://web.archive.org/web/*/https://2pml.com/2020/08/10/usps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-12653">
	<!-- .entry-header -->

	<div>
		<p><img data-attachment-id="12682" data-permalink="https://2pml.com/2020/08/10/usps/cvbbjbi0/" data-orig-file="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?fit=1600%2C1144&amp;ssl=1" data-orig-size="1600,1144" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cVBbjbi0" data-image-description="" data-medium-file="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?fit=300%2C215&amp;ssl=1" data-large-file="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?fit=740%2C529&amp;ssl=1" loading="lazy" src="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=740%2C529&amp;ssl=1" alt="cVBbjbi0" width="740" height="529" srcset="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?w=1600&amp;ssl=1 1600w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=300%2C215&amp;ssl=1 300w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=1024%2C732&amp;ssl=1 1024w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=768%2C549&amp;ssl=1 768w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=1536%2C1098&amp;ssl=1 1536w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?w=1480&amp;ssl=1 1480w" sizes="(max-width: 740px) 100vw, 740px" data-recalc-dims="1"></p>
<p>There are three types of infrastructure. One is visible: roads, dams and bridges. The second is invisible: broadband internet provisions and the entirety of our cellular infrastructure. Both are still vital in building our present. The third form of infrastructure is one being rebuilt in order to be repurposed for future use. I explained in <em>J-Curves and Agglomeration</em>:</p>
<blockquote><p>The U.S. Postal Service is a key component of the eCommerce economy. Packages are just 5% of its shipping volume but eCommerce accounts for nearly 30% of the agency’s revenue. Partnerships with vendors like Amazon (or providers like FedEx and UPS) provide a majority of its package volume but small businesses and direct-to-consumer brands rely on USPS’ pricing. Raising costs on retailers may lead to more attrition. […]</p>
<p>By raising prices to combat Amazon’s growing influence over the economy, disrupting the postal economy is no different than digging up paved roads before a period of heightened freight transit. [<a href="https://2pml.com/2020/05/18/agglomeration/">2PM, 1</a>]</p></blockquote>
<p>The U.S. Postal Service is all three. When an American institution is 250 years old, it may as well be the ground that we stand on. The service has contributed services and innovations that we don’t readily attribute to it. Consider its contribution to the middle class: the U.S. Postal Service is one the country’s biggest employers with nearly 330,000 career employees and an average salary of $50,000. They are building the future of eCommerce, a still-nascent industry.</p>
<p>Critics of the USPS will cite cost of labor as a reason for the service’s obsolescence. A common refrain is “Why couldn’t Amazon takeover the service?” Consider that in the fourth quarter of 2019, eCommerce was just 11.9% of all retail. Amazon constituted right under half of that volume. And without the postal service, Amazon would not exist. The market costs of shipment subsidized a number of Amazon’s operations, allowing it to capture market share.</p>
<h2>“The Ground We Stand On”</h2>
<p>The postal service began before the founding of the United States. Benjamin Franklin was fired from his role as postmaster due to his involvement with the American Revolution. Just one year later in 1775, the Continental Congress appointed Franklin the Postmaster General of the “United Colonies.” His tenure left a mail system that offered service between the then-colonies and Great Britain. By 1802, the first African-Americans to work for the Postal Service were enslaved mail carriers. Senator James Jackson of Georgia, Chairman of the Committee of the Senate on the Post Office Establishment, once wrote:</p>
<blockquote><p>… The most active and intelligent [slaves] are employed as post riders. By travelling from day to day, and hourly mixing with people […] they will acquire information. They will learn that a man’s rights do not depend on his color. They will, in time, become teachers to their brethren.</p></blockquote>
<p>Within two months of Senator Jackson’s proclamation, African-Americans would be banned from the postal service, lasting from 1802 to March 1865, just one month before the conclusion of the Civil War. This disbarment ended by congressional decree.</p>
<blockquote><p>No person, by reason of color, shall be disqualified from employment in carrying the mails. (13 Stat. 515)</p></blockquote>
<p>The next decades would see an unparalleled push for African-American financial stability. Nearly 800 would serve as postal employees prior to the 20th century. More than 200 African Americans are known to have served in the high rank of postmaster prior to the conclusion of Reconstruction and the Progressive Era (1863-1920). Of them, nearly 20 were women. The postal service has always been politicized.</p>
<p>Soon after, the U.S. Government expanded on the postal service’s role in democratizing America, both literally and figuratively. President Theodore “Teddy” Roosevelt expanded on this with the <em>Square Deal</em> in 1902, communicating a fairness policy in hiring and leadership. The result was momentous for many. Roosevelt stated:</p>
<blockquote>
<p>It is and should be my consistent policy in every State, where their numbers warranted it, to recognize colored men of good repute and standing in making appointments to office. […] I can not consent to take the position that the door of hope – the door of opportunity – is to be shut upon any man, no matter how worthy, purely upon the grounds of race or color. <a href="https://about.usps.com/who-we-are/postal-history/african-american-workers-20thc.htm#_edn2" name="_ednref2">[2]</a></p>
</blockquote>
<p>Today, 21% (or nearly 70,000) of the agency’s employees are African-American. However, the postal service was consequential beyond matters of social equity. By 1823, the U.S. Postal Service and the U.S. Government established 80,000 miles of “post roads” to help carriers navigate new rural areas. By 1860, these roads connected nearly 28,000 post offices. Today, the postal service maintains nearly 40,000 post offices, clearing 212 billion letters and mail to 144 million homes.</p>
<blockquote data-card-controls="1" data-card-align="center" data-card-theme="light" data-card-key="3101080c845e4679b6077080f81a573e">
<h4><a href="https://twitter.com/web/status/1292117127055519744">No Title</a></h4>
<p>Save the @USPS.There is no institution more critical to the next phases of our commerce economy.</p>
</blockquote>

<p>Today, the service is tasked with another generational shift: supporting online retail. The pandemic shifted the American consumer towards online retail, this while reducing the number of units shipped. As such, companies like UPS and FedEx have responded by hiking prices. In response to USPS’ distress, FedEx recently stated:</p>
<blockquote>
<p>The COVID-19 pandemic has negatively impacted mail volumes and mix resulting in a further decrease in revenues and negative financial impact for the USPS. Additionally, the USPS continues to experience budgetary uncertainty as well as increased political debate regarding potential privatization or restructuring of its operations.</p>
</blockquote>

<figure id="attachment_12683" aria-describedby="caption-attachment-12683"><img data-attachment-id="12683" data-permalink="https://2pml.com/2020/08/10/usps/sleikjxu/" data-orig-file="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?fit=2048%2C1259&amp;ssl=1" data-orig-size="2048,1259" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sLEikjXU" data-image-description="" data-medium-file="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?fit=300%2C184&amp;ssl=1" data-large-file="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?fit=740%2C455&amp;ssl=1" loading="lazy" src="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=740%2C455&amp;ssl=1" alt="sLEikjXU" width="740" height="455" srcset="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?w=2048&amp;ssl=1 2048w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=300%2C184&amp;ssl=1 300w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=1024%2C630&amp;ssl=1 1024w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=768%2C472&amp;ssl=1 768w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=1536%2C944&amp;ssl=1 1536w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?w=1480&amp;ssl=1 1480w" sizes="(max-width: 740px) 100vw, 740px" data-recalc-dims="1"><figcaption id="caption-attachment-12683">The most popular government sites: June 18, 2020</figcaption></figure>
<p>Cost inflation is the most concerning obstacle ahead for digitally native retailers. Without the treatment that the United States’ oldest civilian service afforded Amazon in its infancy, it will be more difficult to build more businesses of Amazon’s scale. The economics were difficult enough as is; these added costs will only add pressure to pass along costs to consumers, many of whom are facing down one of the most economically vulnerable periods since 2008.We should consider the postal service an investment into our present and future and a monument to our past.</p>
<p>If our economy is to begin addressing the shortfalls caused by the overwhelming contraction in the traditional retail industry, it will need the support of the postal service. For eCommerce, their service is the industry’s last mile for thousands of direct-to-consumer small businesses. The postal service uniquely sits at the intersection of our physical roads and our digital infrastructure. There isn’t a direct substitute and we shouldn’t wait to find out the hard way. Save the USPS. We will need more companies like the the successful hundreds that were built on its 250 year old infrastructure. That includes Amazon.</p>
<p><strong>By Web Smith | Editor: Hilary Milnes | Art by Alex Remy | <a href="http://2pml.com/about">About 2PM</a></strong></p>
			</div><!-- .entry-content -->

	
	</article></div>]]>
            </description>
            <link>https://2pml.com/2020/08/10/usps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24153311</guid>
            <pubDate>Fri, 14 Aug 2020 04:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TikTok? Never]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24153225">thread link</a>) | @croom
<br/>
August 13, 2020 | https://kowabit.de/tiktok-2/ | <a href="https://web.archive.org/web/*/https://kowabit.de/tiktok-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-206408"><div><p><img width="720" height="250" src="https://kowabit.de/wp-content/uploads/2019/02/social.png" alt="" loading="lazy" srcset="https://kowabit.de/wp-content/uploads/2019/02/social.png 720w, https://kowabit.de/wp-content/uploads/2019/02/social-300x104.png 300w" sizes="(max-width: 720px) 100vw, 720px"></p><div><p>I’m sure you’ve read or heard it. Trump doesn’t like TikTok. He doesn’t like Tik-Tok because of the Chinese. Apparently, they use it for espionage. That’s why he wants the app banned in the United States. He also wants to ban the WeChat app. He has already issued a decree to do this. (<a href="https://www.tagesschau.de/ausland/trump-tik-tok-verfuegung-101.html" target="_blank" rel="noopener noreferrer">1</a>, <a href="https://www.heise.de/news/Analyst-Trump-Verfuegung-gegen-WeChat-schaedigt-iPhone-Geschaeft-4866876.html" target="_blank" rel="noopener noreferrer">2</a>)</p><p>TikTok is a video app. Entertainment on the go. WeChat is an app for communication and even with payment function. Mainly used in China.</p><p>I am over 40 years young. I had already heard TikTok. But I have never used it. I do not have the time for that. A few days ago, a visitor came to see my daughter. The girl had TikTok on her smartphone. She explained the app to me and I observed how it was used.</p><p>I had made a judgement very quickly. I have to test TikTok. Installed on my test phone and started. At the beginning you choose a few categories to get started. I chose humorous, learning and society. The consumption of videos should finally bring me some value. The good thing is that everyone of you can test the app that way. A registration beyond this level is not necessary for the consumption. Only those who want more would have to open an account.</p><p>I had planned to test TikTok for two hours. It should already be one movie length to make a judgement. If my daughter’s classmates use this app, she will sooner or later come across TikTok as well.</p><p>I have given myself the additional task of keeping a tally sheet. I wanted to know how many videos I watch in the two hours and how many videos I have to laugh or take something positive with me. It is not about casual laughter when there is a small funny scene, but hearty, beautiful laughter. Knowledge must trigger an eye-opening effect.</p><p>And so it began … and I was there for 24 minutes. After that I was completely exhausted.</p><p>I consumed 74 videos. I laughed once.</p><p>TikTok is continuous bombardment with short videos. The <a href="https://en.wikipedia.org/wiki/Katyusha_rocket_launcher" target="_blank" rel="noopener noreferrer">Stalin organ</a> of entertainment. You can really feel how big parts of your own brain explode and are useless afterwards.</p><p>TikTok is the cruelest app, the worst entertainment I have ever experienced. I have seen different actors performing the same sketch. I’ve seen German stars in bad performances. I’ve seen people acting as if they already have no brain at all. I’ve seen young people acting as if they were the children of adults who have no brains. It was a culture shock.</p><p>I can’t explain how bad, how underground, how primitive the content if TikTok is. Respect for every TikTok entertainer who produces trash every day and finds fans who give him presents for it. I don’t know if it should be the goal of life to produce trash, but 24 minutes showed me that nuclear waste is less toxic than the contents on TikTok.</p><p>TikTok does not exist in our household. The domains are blocked in the router. It is completely irresponsible to let underaged people use this app. At Apple and in the Google Play Store the app is listed from 12 years of age. And just like my daughter, however, the visitor was younger than 12 years. And according to her, many of her classmates use this app. Do parents buy their children smartphones to turn them into zombies on purpose? Terrifying. TikTok is proof that parents who don’t monitor their children’s online use must be severely punished.</p><p>TikTok should not be banned for fear of Chinese espionage. TikTok should be banned for being stupid on a massive scale. A realistic classification would be from the age of 18. Then it would be ensured that ex-minors can only go through this garbage dump of do-it-yourself entertainment when it can be assumed that they have developed a few brain cells.</p><p>If you have never tested TikTok, but there are people in the household who consume the contents, then inform yourself. Be prepared, however, that you will start to doubt the viability of some TikTokers and especially the users. And if not, I wish you a happy life, but please never go to a democratic election.</p><p>TikTok? Never!</p> <p><span>Tagged <a href="https://kowabit.de/tag/app/" rel="tag">App</a>, <a href="https://kowabit.de/tag/diy/" rel="tag">diy</a>, <a href="https://kowabit.de/tag/entertainment/" rel="tag">entertainment</a>, <a href="https://kowabit.de/tag/minors/" rel="tag">minors</a>, <a href="https://kowabit.de/tag/smartphone/" rel="tag">Smartphone</a>, <a href="https://kowabit.de/tag/tiktok/" rel="tag">tiktok</a></span></p></div></div></article></div>]]>
            </description>
            <link>https://kowabit.de/tiktok-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24153225</guid>
            <pubDate>Fri, 14 Aug 2020 04:06:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Ruby apps, same code, but different output: what's going on?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152544">thread link</a>) | @vaillancourtmax
<br/>
August 13, 2020 | https://maximevaillancourt.com/blog/debugging-ruby-casecmp-bug-using-gdb | <a href="https://web.archive.org/web/*/https://maximevaillancourt.com/blog/debugging-ruby-casecmp-bug-using-gdb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <p><img src="https://images.unsplash.com/photo-1522776851755-3914469f0ca2?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1000&amp;h=500&amp;q=80"></p>

<p>I noticed something odd today while working on two different Ruby codebases. This simple line of Ruby behaved differently in both applications:</p>

<div><div><pre><code><span>"luck"</span><span>.</span><span>casecmp</span><span>(</span><span>"L`auguste"</span><span>)</span>
</code></pre></div></div>

<p>Executing <code>"luck".casecmp("L`auguste")</code> in application A returned <code>-1</code>, while executing it in application B returned <code>1</code>.</p>

<p>â€œDid the alphabet change at some point and I didnâ€™t get the memo?â€�, I thought.</p>

<blockquote>
  <p><strong>Aside</strong></p>

  <p><a href="https://ruby-doc.org/core-2.7.1/String.html#method-i-casecmp"><code>String#casecmp</code></a> is a built-in Ruby method that returns <code>-1</code>, <code>0</code>, <code>1</code>, or <code>nil</code> depending on whether the object on which itâ€™s called is less than, equal to, or greater than the function argument, and it does so in case-insensitive fashion. Here are a few simple examples of how it behaves:</p>

  <div><div><pre><code><span>"aBcDeF"</span><span>.</span><span>casecmp</span><span>(</span><span>"abcde"</span><span>)</span>     <span>#=&gt; 1</span>
<span>"aBcDeF"</span><span>.</span><span>casecmp</span><span>(</span><span>"abcdef"</span><span>)</span>    <span>#=&gt; 0</span>
<span>"aBcDeF"</span><span>.</span><span>casecmp</span><span>(</span><span>"abcdefg"</span><span>)</span>   <span>#=&gt; -1</span>
<span>"abcdef"</span><span>.</span><span>casecmp</span><span>(</span><span>"ABCDEF"</span><span>)</span>    <span>#=&gt; 0</span>
</code></pre></div>  </div>
</blockquote>

<h2 id="looking-for-monkey-patches">Looking for monkey patches</h2>

<p>Seeing as one of the applications is built on top of Ruby of Rails and the other isnâ€™t, my first thought was that maybe there was a Rails and/or ActiveSupport patch on <code>String#casecmp</code> that would change the behavior of this line in one of the applications. However, I didnâ€™t find anything that pointed to this. I kept digging, hoping to maybe find a patch in the <em>other</em> application that could explain this difference in behavior. Again, I didnâ€™t find anything. ðŸ™ˆ</p>

<h2 id="different-rubies">Different Rubies</h2>

<p>Eventually, after exploring a bit more, I realized that both applications ran on different versions of Ruby: application A was on Ruby 2.6, while application B was using Ruby 2.7.</p>

<p>Running the same command on both versions of Ruby indeed gives us different results:</p>

<div><div><pre><code><span>$ </span>~/.rubies/ruby-2.6.6/bin/ruby <span>-e</span> <span>'puts "luck".casecmp("L`Auguste")'</span>
<span>-1</span>

<span>$ </span>~/.rubies/ruby-2.7.0/bin/ruby <span>-e</span> <span>'puts "luck".casecmp("L`Auguste")'</span>
1
</code></pre></div></div>

<p>Ah ha! Weâ€™re getting closer. While I could have called it a day here and simply updated application B to Ruby 2.7 to resolve the issue, I wanted to understand: what causes it?</p>

<h2 id="changelogs--bindingpry">Changelogs &amp; <code>binding.pry</code></h2>

<p>I then started to comb through Ruby changelogs, trying to find if anything changed between Ruby 2.6 and Ruby 2.7 for <code>String#casecmp</code>, or anything somehow related to string comparison. I didnâ€™t find anything.</p>

<p>Of course, it would be nice to debug this using <code>binding.pry</code> or other similar Ruby-level debugging tools by stepping into the <code>String#casecmp</code> call to see whatâ€™s going on inside. However, this doesnâ€™t get us very far, as trying to use Rubyâ€™s <code>Tracer</code> or <code>binding.pry</code> doesnâ€™t really help.</p>

<p>Running this:</p>

<div><div><pre><code><span>$ </span>ruby <span>-r</span> tracer <span>-e</span> <span>'"luck".casecmp("L`Auguste")'</span>
</code></pre></div></div>

<p>â€¦ returns this output:</p>

<div><div><pre><code>#0:-e:1::-: "luck".casecmp("L`Auguste")
</code></pre></div></div>

<p>â€¦ and not much else. Thatâ€™s because <code>String#casecmp</code> is implemented in C, directly inside MRIâ€™s <a href="https://github.com/ruby/ruby/blob/master/string.c"><code>string.c</code></a>, so thereâ€™s no actual Ruby code underneath <code>String#casecmp</code> that we can step into using Ruby-level debugging tools.</p>

<p>Here comes the GDB part: because weâ€™re essentially dealing with C code at this point, we can use GDB to understand what happens inside the call to <code>String#casecmp</code>. So with that, I fired up GDB for the first time in years (I typically work with Ruby, so GDB is not something I commonly use).</p>

<h2 id="identifying-the-root-cause-using-gdb">Identifying the root cause using GDB</h2>

<p>Letâ€™s see how to use GDB to understand why both Ruby 2.6 and Ruby 2.7 behave differently with the same input to <code>String#casecmp</code>.</p>

<p>I first prepared a simple Ruby file containing the source that replicates the issue:</p>

<div><div><pre><code><span># ~/casecmp.rb</span>
<span>puts</span> <span>"luck"</span><span>.</span><span>casecmp</span><span>(</span><span>"L`Auguste"</span><span>)</span>
</code></pre></div></div>

<p>Notice that the second character in the input to <code>casecmp</code> is a backtick (<code>`</code>), which has ASCII code 96. This is relevant for paragraphs below.</p>

<h3 id="in-ruby-270">In Ruby 2.7.0</h3>

<p>Letâ€™s start by firing up GDB with a self-compiled version of Ruby 2.7.0:</p>

<div><div><pre><code><span>$ </span><span>sudo </span>gdb /Users/maximevaillancourt/.rubies/ruby-2.7.0/bin/ruby
Reading symbols from /Users/maximevaillancourt/.rubies/ruby-2.7.0/bin/ruby...
</code></pre></div></div>

<p>Then, we add a breakpoint on the <code>str_casecmp</code> function so execution pauses once we reach it:</p>

<div><div><pre><code>(gdb) break str_casecmp
Breakpoint 1 at 0x1001fa766: file string.c, line 3371.
</code></pre></div></div>

<p>Perfect. Weâ€™re now ready to run the <code>casecmp.rb</code> Ruby script from above.</p>

<div><div><pre><code>(gdb) run casecmp.rb
Starting program: /Users/maximevaillancourt/.rubies/ruby-2.7.0/bin/ruby casecmp.rb
</code></pre></div></div>

<p>We eventually hit the breakpoint we just set:</p>

<div><div><pre><code>Thread 2 hit Breakpoint 1, str_casecmp (str1=4329352680, str2=4329352640) at string.c:3371
3371	    enc = rb_enc_compatible(str1, str2);
</code></pre></div></div>

<blockquote>
  <p><strong>Aside</strong></p>

  <p>Internally, <a href="https://github.com/ruby/ruby/blob/4318aba9c94ebff53e4168886e1a35a24013924f/string.c#L3467-L3468"><code>String#str_casecmp</code></a> is quite simple: it iterates over each character in both inputs by index starting from the first character, converting both characters to the same case so that the function behaves in a case-insensitive way, and returns early if the two currently considered characters from each input are different. In doing so, it determines which character is â€œbiggerâ€� than the other using the character code (an <a href="http://www.asciitable.com/">ASCII code table</a> is a useful asset to have nearby for the rest of this blog post).</p>
</blockquote>

<p>In Ruby 2.7.0, notice that the case conversion <a href="https://github.com/ruby/ruby/blob/e9e4f8430a62f56a4e62dd728f4498ee4c300c12/string.c#L3381-L3382">converts both inputs to lowercase using <code>TOLOWER</code></a>:</p>

<div><div><pre><code><span>while</span> <span>(</span><span>p1</span> <span>&lt;</span> <span>p1end</span> <span>&amp;&amp;</span> <span>p2</span> <span>&lt;</span> <span>p2end</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>*</span><span>p1</span> <span>!=</span> <span>*</span><span>p2</span><span>)</span> <span>{</span>
    <span>unsigned</span> <span>int</span> <span>c1</span> <span>=</span> <span>TOLOWER</span><span>(</span><span>*</span><span>p1</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>unsigned</span> <span>int</span> <span>c2</span> <span>=</span> <span>TOLOWER</span><span>(</span><span>*</span><span>p2</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>if</span> <span>(</span><span>c1</span> <span>!=</span> <span>c2</span><span>)</span>
      <span>return</span> <span>INT2FIX</span><span>(</span><span>c1</span> <span>&lt;</span> <span>c2</span> <span>?</span> <span>-</span><span>1</span> <span>:</span> <span>1</span><span>);</span>
  <span>}</span>
  <span>p1</span><span>++</span><span>;</span>
  <span>p2</span><span>++</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>After navigating in <code>str_casecmp</code> using <code>next</code> a few times, we enter the loop and arrive at a point where we can print <code>c1</code> and <code>c2</code>, which are the codes for the characters at the current index for both inputs:</p>

<div><div><pre><code>3382	                unsigned int c2 = TOLOWER(*p2 &amp; 0xff);
(gdb) print c1
$11 = 108
(gdb) next
3383	                if (c1 != c2)
(gdb) print c2
$12 = 108
</code></pre></div></div>

<p>Hereâ€™s a visual representation of the buffers:</p>

<div><div><pre><code>c1
 â†“
108  ?   ?   ?
 l   u   c   k

108  ?   ?   ?   ?   ?   ?   ?   ?
 l   `   a   u   g   u   s   t   e
 â†‘
c2
</code></pre></div></div>

<p>108 is the decimal ASCII character code representation for the first letter of both inputs: <code>l</code> (lowercase â€œLâ€�), so the loop continues to the next iteration because <code>c1</code> and <code>c2</code> are the same.</p>

<p>On the second iteration of the loop (on the second character of both inputs), we get the following results:</p>

<div><div><pre><code>3382	                unsigned int c2 = TOLOWER(*p2 &amp; 0xff);
(gdb) print c1
$14 = 117
(gdb) next
3383	                if (c1 != c2)
(gdb) print c2
$16 = 96
</code></pre></div></div>

<p>Hereâ€™s a visual representation of the buffers:</p>

<div><div><pre><code>    c1
     â†“
108 117  ?   ?
 l   u   c   k

108  96  ?   ?   ?   ?   ?   ?   ?
 l   `   a   u   g   u   s   t   e
     â†‘
     c2
</code></pre></div></div>

<p><code>c1</code> contains <code>117</code>, which is the decimal ASCII character code representation for <code>u</code>, while <code>96</code> (in <code>c2</code>) is the character code for a backtick (<code>`</code>). We then enter the <code>if (c1 != c2)</code> conditional, and the return value is <code>1</code> because <code>c1 &gt; c2</code> (<code>117 &gt; 96</code>).</p>

<p>Okay. So far so good. This lines up with the initial observation of the issue. How are things different in Ruby 2.6.6?</p>

<h3 id="in-ruby-266">In Ruby 2.6.6</h3>

<p>We do almost the same setup as above (same one-line Ruby script to replicate the issue, same breakpoint on <code>str_casecmp</code>), but we fire up GDB with Ruby 2.6.6:</p>

<div><div><pre><code><span>$ </span><span>sudo </span>gdb /Users/maximevaillancourt/.rubies/ruby-2.6.6/bin/ruby
Reading symbols from /Users/maximevaillancourt/.rubies/ruby-2.6.6/bin/ruby...

<span>(</span>gdb<span>)</span> <span>break </span>str_casecmp
...

<span>(</span>gdb<span>)</span> run casecmp.rb
Starting program: /Users/maximevaillancourt/.rubies/ruby-2.6.6/bin/ruby casecmp.rb

Thread 2 hit Breakpoint 1, str_casecmp ...
</code></pre></div></div>

<p>Letâ€™s look at the loop we presented above in Ruby 2.7.0, but <a href="https://github.com/ruby/ruby/blob/a9a48e6a741f048766a2a287592098c4f6c7b7c7/string.c#L3413-L3414">in Ruby 2.6.6</a> this time:</p>

<div><div><pre><code><span>while</span> <span>(</span><span>p1</span> <span>&lt;</span> <span>p1end</span> <span>&amp;&amp;</span> <span>p2</span> <span>&lt;</span> <span>p2end</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>*</span><span>p1</span> <span>!=</span> <span>*</span><span>p2</span><span>)</span> <span>{</span>
    <span>unsigned</span> <span>int</span> <span>c1</span> <span>=</span> <span>TOUPPER</span><span>(</span><span>*</span><span>p1</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>unsigned</span> <span>int</span> <span>c2</span> <span>=</span> <span>TOUPPER</span><span>(</span><span>*</span><span>p2</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>if</span> <span>(</span><span>c1</span> <span>!=</span> <span>c2</span><span>)</span>
      <span>return</span> <span>INT2FIX</span><span>(</span><span>c1</span> <span>&lt;</span> <span>c2</span> <span>?</span> <span>-</span><span>1</span> <span>:</span> <span>1</span><span>);</span>
  <span>}</span>
  <span>p1</span><span>++</span><span>;</span>
  <span>p2</span><span>++</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Notice that instead of using <code>TOLOWER</code> as in Ruby 2.7.0, Ruby 2.6.6 uses <code>TOUPPER</code>. Interesting.</p>

<p>Letâ€™s fast-forward to the part where we get to <code>c1</code> and <code>c2</code> for the second character in the input:</p>

<div><div><pre><code>3414			unsigned int c2 = TOUPPER(*p2 &amp; 0xff);
(gdb) next
3415	                if (c1 != c2)
(gdb) print c1
$5 = 85
(gdb) print c2
$6 = 96
</code></pre></div></div>

<p>Hereâ€™s a visual representation of the buffers:</p>

<div><div><pre><code>     c1
     â†“
108  85  ?   ?
 L   U   C   K

108  96  ?   ?   ?   ?   ?   ?   ?
 L   `   A   U   G   U   S   T   E
     â†‘
     c2
</code></pre></div></div>

<p><code>c1</code> is <code>85</code>, which is the character code for <code>U</code>, and <code>c2</code> is <code>96</code> (just like in Ruby 2.7.0), which is the character code for a backtick (<code>`</code>).</p>

<p>This time though, the comparison result is different, because <code>c1 &lt; c2</code> (<code>85 &lt; 96</code>), so <code>str_casecmp</code> returns <code>-1</code>.</p>

<p>There it is: because Ruby 2.6 uses <code>TOUPPER</code> and Ruby 2.7 uses <code>TOLOWER</code> before comparing the inputs, and because one of the characters to compare is a backtick (<code>`</code>, which canâ€™t be converted to uppercase or lowercase in any way), the other characterâ€™s code â€œmovesâ€� differently around the â€œfixedâ€� backtick character code, affecting the result of the <code>String#casecmp</code> function.</p>

<hr>

<p>To summarize, the root cause of the issue is that <code>String#casecmp</code> was updated in Ruby 2.7 to <strong>lowercase</strong> the two inputs before comparing them, while Ruby 2.6 used to <strong>uppercase</strong> the two inputs before comparing them. <a href="https://github.com/ruby/ruby/commit/082424ef58116db9663a754157d6c441d60fd101#diff-7a2f2c7dfe0bf61d38272aeaf68ac768">This is the commit where this change was introduced.</a></p>

<p>Fun debugging session. :)</p>

<p><em>Found a typo? Think I could clarify something? Reach out on Twitter (<a href="https://twitter.com/vaillancourtmax">@vaillancourtmax</a>).</em></p>

</article></div>]]>
            </description>
            <link>https://maximevaillancourt.com/blog/debugging-ruby-casecmp-bug-using-gdb</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152544</guid>
            <pubDate>Fri, 14 Aug 2020 02:32:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My electricity bill was wrong for two years]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152325">thread link</a>) | @PlanetLotus
<br/>
August 13, 2020 | https://planetlotus.github.io/2020/08/13/meter-mixup.html | <a href="https://web.archive.org/web/*/https://planetlotus.github.io/2020/08/13/meter-mixup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I’ve lived in my house for just under two years. Last summer, I noticed something strange. Our electricity bill increased by 40-90% depending on the month. This year, I finally tracked it down and discovered our meter was being mixed up with our neighbor’s. Here’s how I tracked this down and what you can do to prevent it from happening to you.</p>



<p>I have an amateur interest in electricity, conserving energy, and energy efficiency in general. I care about my carbon footprint, as well as my bill, and I’m passionate about innovation in this space. I’ve made it a habit to have a good idea of how much electricity different appliances use and, in general, I try to be aware of where my electricity is going. Years ago, I bought a simple <a href="https://en.wikipedia.org/wiki/Kill_A_Watt">Kill A Watt</a> to quickly get an idea of how much power things use.</p>



<p>The first time I noticed a problem was when we got our July bill in the summer of 2019. It was about 40% higher than usual. My grandparents stayed with us (in their motorhome) for a week that month, and their motorhome has a big air conditioner, so I chalked it up to that, though that still seemed high.</p>

<p>A couple months passed and the problem got worse. It went from 40% higher than normal, to a peak of about 90%. I couldn’t explain that. We don’t have central air conditioning. Most of our heavy appliances use natural gas. We did use a portable air conditioner briefly, but never for more than a couple hours a night. I also measured the power usage of the A/C and thought, there’s no way this adds up. This confusion continued until we got our October bill and it returned to normal, and I forgot about it for another year.</p>



<p>And…it came back! I first noticed this year in June when the bill jumped about 20%. I figure it’s reasonable for the bill to fluctuate a little, but not by that much. Plus, what made even less sense is that we used supplemental electric heating this winter, so if anything, our bill should’ve been higher in the winter! Again, no central air conditioning, so another unexplained bill. I tracked power usage on everything I could think of, to make sure I hadn’t missed something. For awhile, my big suspect was our fridge. It’s 18 years old, so I figured, maybe there’s a problem with it and it uses more power when it should, especially when the ambient temperature is higher. I cleaned the coils and played around with the fridge settings, then waited for our next bill. It got worse.</p>

<p>This year, I noticed our power company has a cool interface online where you can see your daily power usage. Very handy. I noticed that, in non-summer months, it was very consistent, ranging between 9-12 kWh per day. Then, in the summer months, it just goes all over the place. Sometimes it was 8, other days it went as high as 24! This seemed loosely correlated with the temperature but I just couldn’t explain that, due to a lack of central cooling in our house. I finally decided to call the power company at this point. Naturally, they did not take me too seriously, and were fairly insistent that it was my air conditioning (that I didn’t have). I was told to hire an electrician to investigate.</p>

<p>Then it got weirder. In late July, I noticed that in recent weeks, our daily power usage (according to the power company) dipped as low as 1 kWh per day! That’s just not possible, I thought. My electronics, combined, should use more than that per day, not even counting heavier users like the fridge. The power usage still fluctuated quite a bit, but there were several days where the power usage was as low as 1-3 kWh. I called the power company again and, no surprise, they took this much more seriously and agreed that wasn’t possible. I insisted that the peaks in usage didn’t make sense either, that I couldn’t explain those, but no luck there…they were really only interested in the low days and said they were opening an investigation that could take “at least a few weeks” to finish.</p>



<p>One night, I finally put it together. I wondered if my bill was mixed up with my neighbor’s. My neighbor had moved out in July, and that’s about when the daily power usage fell to almost nothing. I also happened to know that they have central air conditioning. I looked at my bill and noticed it actually has the meter number on it, very helpful! I looked at my meter and the number on the bill wasn’t even remotely close. It wasn’t off-by-one. The format looked consistent, but the values looked randomized. I was wondering whether I was even looking at the right number. So, the next morning, I took a look at my neighbor’s (vacant) house’s meter. Sure enough, it exactly matched what was on my bill.</p>

<p>A few frustrating phone calls later (not important), and the issue is fixed. We got the charges corrected and are enjoying a large credit on our account that ought to last us about 6 months (after having lived here only 2 years).</p>

<p>In any future house I live in, I will be sure to check that my bill’s meter number matches what’s on the property. I highly recommend everyone do the same, because I get the impression this is fairly common. A quick search online and I found about half a dozen news articles about this happening, often more egregious cases than my own. Most of us may not notice a mixup, either because the usage is fairly consistent or we just don’t know how much power we use. Thankfully, you should be able to check the accuracy of your bill in about 5 minutes if your meter is easily accessible. Simply look for the meter number on your bill (hopefully all power companies give this info), and then look physically at the meter for a sticker from your power company, and see if the numbers match.</p>

  </article>

  




</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://planetlotus.github.io/2020/08/13/meter-mixup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152325</guid>
            <pubDate>Fri, 14 Aug 2020 01:57:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning of Sets]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24152216">thread link</a>) | @akosiorek
<br/>
August 13, 2020 | http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html | <a href="https://web.archive.org/web/*/http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In machine learning, we typically work with input pairs (x, y), and we try to figure out how x and y depend on each other.
To do so, we gather many such pairs and hope that the dependence will reveal itself if a) we have enough data, b) our model is expressive enough to approximate this dependency, and c) we get the hyperparameters right.
In the simplest case, both x and y are just scalar values (or vectors \(\mathbf{x}, \mathbf{y}\)); for example, given some measurements of a plant’s shape, we might want to predict its species. The measurements here are real vectors \(\mathbf{x} \in \mathcal{X}\), where the input space \(\mathcal{X} = \mathbb{R}^d\) is usually Euclidean, and the species is a label \(\mathbf{y} \in \mathcal{Y}\) (usually an integer or a one-hot vector), but it is common for \(\mathbf{x}\) and \(\mathbf{y}\) to have more structure.</p>

<p>One of the main assumptions we rely on is that the pairs of (x, y) points are <a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">independent and identically distributed (i.i.d.) random variables</a>.
Let us unpack this a bit, starting from the end,</p>

<ul>
  <li><code>random variable</code>: there exists some stochastic generative process from which the variables were randomly sampled,</li>
  <li><code>identically</code>: all samples come from the same probability distribution,</li>
  <li><code>independent</code>: the generative process has no memory of generated samples, and hence any generated sample does not change the distribution over future generated samples.</li>
</ul>

<p>Any structure in \(\mathbf{x}, \mathbf{y}\), or both introduces constraints, and a successful application of an algorithm to a particular problem does heavily depend on whether or not this algorithm takes the relevant constraints into account.
A common constraint in image-related problems is translation equivariance<sup id="fnref:cnnequiv" role="doc-noteref"><a href="#fn:cnnequiv">1</a></sup>—the output of the algorithm should shift with any shifts applied to the image (you can read more about equvariances in <a href="https://fabianfuchsml.github.io/equivariance1of2/">this excellent blog post</a>).
In natural language-related problems, a typical constraint is causality: a token at position t can depend on any previous tokens at position 1:t-1, but it cannot depend on any future tokens<sup id="fnref:languecausality" role="doc-noteref"><a href="#fn:languecausality">2</a></sup>.</p>

<p>In the above examples, the dependencies between points (e.g., autoregressive dependence in NLP) are clear from the context.
However, if a data point is not a vector, matrix, or a sequence of vectors, but it is a <strong>set of vectors</strong>, these dependencies become less clear.
In particular, elements in an input set resemble elements in a dataset (i.e., lack of order), but the critical difference is that they are <strong>not independent</strong>, therefore breaking the i.i.d. assumption.
Accounting for this specific structure in inputs or outputs of an ML model leads to a family of set learning problems, which have recently gained considerable attention in the machine learning community.
I thought it would be useful to delve into the machine learning of sets.
In the following, we will consider set-to-vector, vector-to-set, and set-to-set problems and provide implementations of simple algorithms in <a href="https://github.com/google/jax">JAX</a> and <a href="https://github.com/deepmind/dm-haiku">haiku</a>.</p>

<p>First some imports:</p>

<div><div><pre><code>import jax
import jax.numpy as jnp
import haiku as hk
</code></pre></div></div>


<p>Before we start, it is useful to introduce some notation.
Let \(\mathbf{x} \in \mathbb{R}^d\) be an input vector, \(\mathbf{y} \in \mathbb{R}^k\) the output vector, and let \(X = \{\mathbf{x}_i\}_{i=1}^M\) and \(Y = \{\mathbf{y}_j\}_{j=1}^N\) be sets of \(M\) and \(N\) elements, respectively.
Note that, until now, \(y\) or \(\mathbf{y}\) were simply labels.
From now on, however, \(\mathbf{x}\) and \(\mathbf{y}\) can live in the same space, and simply be elements of different sets.
I will also use \(\mathcal{L}(X, Y)\) as a loss function operating on two sets, and \(l(\mathbf{x}, \mathbf{y})\) will be a loss function for pairs of elements.</p>


<p>This is perhaps the simplest set-learning problem since it only requires permutation invariance.
A function \(f\) is invariant to permutations \(\pi\) if \(\forall \pi\): \(f(X) = f(\pi X)\).
Permutation invariance has always been known in machine learning, as loss functions we use almost never<sup id="fnref:acn" role="doc-noteref"><a href="#fn:acn">3</a></sup> depend on the ordering of elements in our datasets or minibatches.
This is not for the lack of order: to create a minibatch, we stack multiple data elements in an array; this pairs every element in the minibatch with its minibatch index, therefore implicitly creating an order.
Loss functions tend to discard information about the order, usually by taking the mean over data examples.
We can create permutation-invariant functions by following a similar logic.</p>

<p>Examples in a minibatch are processed independently (which reflects their i.i.d. nature), but if each entry in the minibatch contains more than just a single data point (many pixels in an image, points in a point cloud, tokens in a language sentence), then flattening these points into a vector and feeding it into an MLP or a CNN results in different parameters being used for processing different data points, and hence order is used implicitly; feeding the points into an RNN reuses parameters, but introduces an explicit dependence on the order.</p>

<p>A straightforward solution to this issue is to treat points in a single example in the same way we treat examples in the minibatch: treat them independently.
This approach, followed by a permutation-invariant pooling operation such as max or mean pooling, is explored in <a href="https://arxiv.org/abs/1703.06114">Zaheer et al., “Deep Sets”, NeurIPS 2017</a> and is proven to be a universal set-function approximator<sup id="fnref:deepsetdim" role="doc-noteref"><a href="#fn:deepsetdim">4</a></sup>.</p>

<div><div><pre><code>class DeepSet(hk.Module):

  def __init__(self, encoder, decoder):
    super().__init__()
    self._encoder = encoder
    self._decoder = decoder
    
  def __call__(self, x):
    """Compute the DeepSet embedding.

    Args:
      x: Tensor of shape [batch_size, n_elems, n_dim].
    """
    return self._decoder(self._encoder(x).mean(1))
</code></pre></div></div>

<p>While newer approaches with better empirical performance exist, they all draw from the Deep Sets framework<sup id="fnref:setembeddings" role="doc-noteref"><a href="#fn:setembeddings">5</a></sup>.
Another factor contributing to the fact that the set-to-vector problem is quite easy is that pooling operations naturally work with variable-sized sets–there is nothing extra we have to do to handle sets of variable cardinality.
This is not the case in the following two problems, where we have to take the set size into account explicitly.</p>


<p>In vector-to-set, the task is to generate a set of real vectors from some (usually vector-valued) conditioning.</p>

<p>The majority of approaches out there focus on generating ordered sequences instead of unordered sets, and usually of fixed or at least known size.
This allows using MLPs<sup id="fnref:setae" role="doc-noteref"><a href="#fn:setae">6</a></sup> and RNNs<sup id="fnref:order_matters" role="doc-noteref"><a href="#fn:order_matters">7</a></sup> to predict fixed- and variable-length sets, respectively, but at the price of having to learn permutation-equivariance from data.
Learning permutation-equivariance can be induced by data augmentation. It is easy to generate different permutations, but usually comes at a decreased performance and/or longer training times compared to truly permutation-equivariant methods<sup id="fnref:data_augmentation" role="doc-noteref"><a href="#fn:data_augmentation">8</a></sup>.</p>

<div><div><pre><code>  def set_mlp(conditioning, decoder, n_elements):
    """Predicts a set.

    Args:
      conditioning: tensor of shape [batch_size, n_dim].
      decoder: callable, e.g. an MLP.
      n_elements: int.
    """
    z = decoder(conditioning)
    batch_size = conditioning.shape[0]
    # all we can do here is reshape!
    return z.reshape(batch_size, n_elements, -1)

  def set_rnn(conditioning, state, rnn, n_elements):
    """Predicts a set.

    Args:
      conditioning: tensor of shape [batch_size, n_dim].
      state: initial state for the rnn.
      rnn: rnn core.
      n_elements: int.
    """
    zs = []
    for _ in range(n_elements):
      z, state = rnn(conditioning, state)
      zs.append(z[:, None])  # add an axis

    return jnp.concatenate(zs, 1)
</code></pre></div></div>

<h4 id="permutation-invariant-loss-functions">Permutation-Invariant Loss Functions</h4>
<p>Learning to generate sets based on some conditioning typically requires scoring that set against the conditioning.
If we have ground-truth sets at our disposal, we can compare the generated sets against the ground-truth ones for the same conditioning.
This can take the form of supervised learning (think of detecting objects in an image, where we need to generate a set of bounding boxes) or unsupervised learning (autoencoding point-clouds, say).
Since we generally have no guarantee that the generated sets will obey any ordering (why should they?), we have to apply losses invariant to that ordering.
We have two options here:</p>

<ul>
  <li>We can find an optimal matching between two sets<sup id="fnref:bipartite_matching" role="doc-noteref"><a href="#fn:bipartite_matching">9</a></sup>, which comes down to finding a permutation \(\pi\) of one of the sets that minimizes the computed loss, that is: \(\pi^\star = \arg \min_\pi \mathcal{L}( \pi X, Y)\), with \(\mathcal{L}( \pi X, Y) = \sum_i l(\mathbf{x}_{\pi(i)}, \mathbf{y}_i)\). This can be done exactly using the cubic <a href="https://en.wikipedia.org/wiki/Hungarian_algorithm">Hungarian matching</a> algorithm, or approximately using e.g. <a href="https://arxiv.org/abs/1106.1925">optimal-transport</a>- or <a href="https://web.stanford.edu/~bayati/papers/bpmwmIT.pdf">message-passing</a>-based algorithms.</li>
  <li>Instead of finding a matching, we can find a lower bound on what the matched loss would be. A popular choice here is the Chamfer loss<sup id="fnref:chamfer" role="doc-noteref"><a href="#fn:chamfer">10</a></sup>, which computes \(\sum_{x \in X} \min_{y \in Y} l(x, y) + \sum_{y \in Y} \min_{x \in X} l(x, y)\). For every element in one set, it finds the element in the other set that results in the lowest pairwise loss. This loss does not work for multisets as elements can be repeated.</li>
</ul>

<p>If we do not have ground-truth for each conditioning (we have just sets), or if we have many possible sets for each conditioning (e.g., a group of possible sets for one of a few labels), we can instead learn by matching distributions e.g., in the GAN setting.
If we take this approach, we have two problems, really: that of vector-to-set for the generator and set-to-vector for the discriminator. 
Fortunately, we know how to solve the set-to-vector problem with a permutation-invariant neural net, and shortly I am going to describe some permutation-equivariant methods for generation.
This is precisely what we recently explored in <a href="https://oolworkshop.github.io/program/ool_32.html">Stelzner et al., “Generative Adversarial Set Transformers”, ICML 2020 Object-Oriented Learning Workshop</a>.</p>

<p>Coincidentally, sometimes we have to deal with a set of latent variables inside a model. For example in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html">http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html</a></em></p>]]>
            </description>
            <link>http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152216</guid>
            <pubDate>Fri, 14 Aug 2020 01:40:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[USPS Releases 2020 Ruth Asawa Stamp]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152035">thread link</a>) | @arunc
<br/>
August 13, 2020 | https://ruthasawa.com/usps-announces-2020-ruth-asawa-stamp/ | <a href="https://web.archive.org/web/*/https://ruthasawa.com/usps-announces-2020-ruth-asawa-stamp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tc-page-wrap">

  		
  	   	
  		                                                                                    <div id="main-wrapper">

    
    <div role="main">
        <div>

            
                <div id="content">

                    
                        
                                                                                                                              
                                                                    <article id="post-1462">
                                                
                  <section>
              <div id="attachment_1468"><p><img aria-describedby="caption-attachment-1468" src="https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200.jpg" alt="" width="1200" height="769" srcset="https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200.jpg 1200w, https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200-300x192.jpg 300w, https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200-1024x656.jpg 1024w, https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200-768x492.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px"></p><p id="caption-attachment-1468">© 2020 U.S. Postal Service. All rights reserved.</p></div><p>The U.S. Postal Service honors pioneering Japanese American artist Ruth Asawa (1926-2013). Showcasing Asawa’s wire sculptures, the pane includes 20 stamps, with two each of 10 designs, featuring photographs by Dan Bradica and Laurence Cuneo. The selvage features a photograph of Asawa taken by Nat Farbman in 1954 for <em>Life</em> magazine. Ethel Kessler served as art director and designer.</p>
<p>Customers may purchase stamps and other philatelic products through the Postal Store at <a href="https://store.usps.com/store/product/buy-stamps/ruth-asawa-S_476304" target="_blank" rel="noopener noreferrer">usps.com/shopstamps</a>, by calling 800-STAMP24 (800-782-6724), by mail through USA Philatelic, or at Post Office locations nationwide. Videos of most stamp ceremonies will be available on facebook.com/usps. </p>
<p>The pane includes 20 stamps, featuring photographs by Laurence Cuneo and Dan Bradica for David Zwirner. The selvage features a photograph of Asawa taken by Nat Farbman in 1954 for Life magazine. Ethel Kessler served as art director and designer for this issuance.</p>
<p><a href="https://store.usps.com/store/product/buy-stamps/ruth-asawa-S_476304" rel="noopener noreferrer" target="_blank">Stamps are available now &gt;</a></p>
<p>Information on ordering first-day-of-issue postmarks and covers is at <a href="https://usps.com/shopstamps" target="_blank" rel="noopener noreferrer">usps.com/shopstamps</a> under “Collectors.”</p>
<p>Paul Lanier, son of Ruth Asawa; George Takei of The Japanese American National Museum; and Jonathan Laib, of David Zwirner Gallery participated in the virtual opening event with USPS officials:</p>
<p>The Postal Service receives no tax dollars for operating expenses and relies on the sale of postage, products and services to fund its operations. All images are preliminary and are subject to change prior to printing.</p>
<p><a href="https://ruthasawa.com/art/">Explore galleries of Asawa’s art forms &gt;</a></p>
<p><a href="https://ruthasawa.com/life/">View a timeline of her life &gt;</a></p>
<p><a href="https://ruthasawa.com/view-installation/">Experience an Asawa installation virtually &gt;</a></p>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content -->                                                                                </section><!-- .entry-content -->
                                            </article>
                                
                                                                      
                        
                    
                </div><!--.article-container -->

           
        </div><!--.row -->
    </div><!-- .container role: main -->

    
</div><!-- //#main-wrapper -->

                                            		<!-- FOOTER -->
  		
    </div></div>]]>
            </description>
            <link>https://ruthasawa.com/usps-announces-2020-ruth-asawa-stamp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152035</guid>
            <pubDate>Fri, 14 Aug 2020 01:12:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Standards Are Simple]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24151909">thread link</a>) | @wyclif
<br/>
August 13, 2020 | https://portal.mozz.us/gemini/ebc.li/posts/open-standards-are-simple.gmi | <a href="https://web.archive.org/web/*/https://portal.mozz.us/gemini/ebc.li/posts/open-standards-are-simple.gmi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div><p><a href="https://portal.mozz.us/gemini/ebc.li/">Home</a></p>
<p>2020-08-13

If you want to create a truly open standard, you _need_ to make it simple.

There are no exceptions to this rule. When a standard becomes harder to fully implement than what your average motivated programmer can do in two months (max!), it _shouldn't_ be considered "open" anymore.

Why?

</p>
<h2>Complicated Standards Lead to Implementation Monopolies</h2>
<p>Since implementing a complex standard is hard, you will eventually end up with the implementation that started the earliest and maintained since, being the only implementation that is actually usable. And that implementation will most likely be the one created by the standard's creators.

In cases where the standard's creators don't maintain an implementation like "the web"⁰, the only choices are either the standard dying out because of it's complexity, or the actively maintained implementations requiring tons of effort, with (most likely) companies backing said implementations.

</p>
<h2>Implementation Monopolies Lead to Extensions</h2>
<p>If a big implementation just decides one day that your standard is lacking, they can just extend the parts they want. The two outcomes of this being that:

</p>
<ul><li>The other implementations copy their extensions</li>
<li>That one implementation getting more users, and eventually, a near monopoly because of a bigger feature set</li></ul>
<p>
At that point, the "standard" implemented by said implementations is longer the actual defined standard, but because people will inevitably use the said extensions, any new implementation that wants to be considered usable will eventually need to support said proprietary extensions.

</p>
<h2>Too Many Extensions Spoil The Standard</h2>
<p>Even if you have an "open" extension system, where implementations can all propose and agree on extensions to the standard, you need to be able to keep those implementations in check, so their extensions don't overcomplicate the standard.

Remember: Having a simple standard with a million extensions is no better than a complex standard with no extensions.

</p>
<h2>Examples</h2>
<p>Please note that I will be skipping the elephant in the room: "the web", as it has been discussed _to death_.

</p>
<h3>Matrix</h3>
<p>Matrix is _technically_ an open standard. But because of the complexity it has accumulated over the years, Synapse is the only usable server implementation. Even Dendrite, the new implementation by *the same folk that created the standard*, is barely usable after _years_.

The same applies to Matrix clients, with Element being the only usable client implementation. That space definitely seems healthier than the server space, but the same issues are there.

</p>
<h3>Various Programming Languages</h3>
<p>I will not be specifying any language, as I might get any specifics incorrect, but a general pattern I have seen is that most programming languages have only a few compiler/interpreter implementations, even though the language is standardized in some form.

This example actually has some interesting reasoning behind this issue on top of the complicated standards:

</p>
<ul><li>Writing a compiler/interpreter can be hard.</li>
<li>Especially if the current implementations do optimizations or other "clever" tricks.</li></ul>
<p>
These issues can devolve into arguments regarding seeing the complexity of these issues as a part of the standard, and other "technology is too complicated in general" arguments, which I will not dive into here.

</p>
<h3>X Display Server</h3>
<p>The X Display Server standard got so complicated, the people developing it decided to abandon it entirely and create Wayland.

It probably didn't help that most of the standard was no longer being used, and a lot of extensions are required for its use today.

Wayland probably will also suffer the "too many extensions" problem at some point, so I am looking forward to that too...

</p>
<h2>Footnotes</h2>
<p>0: Well, Google, Mozilla and Apple all had a hand in most of the "modern" parts of the standards...
</p></div>
        </div></div>]]>
            </description>
            <link>https://portal.mozz.us/gemini/ebc.li/posts/open-standards-are-simple.gmi</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151909</guid>
            <pubDate>Fri, 14 Aug 2020 00:52:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Valve Index HMD Detailed Teardown]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24151496">thread link</a>) | @adwi
<br/>
August 13, 2020 | https://www.thevrist.com//indexteardown | <a href="https://web.archive.org/web/*/https://www.thevrist.com//indexteardown">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>If you have ever wondered what is inside Valve Index, you might have stumbled upon my <a href="https://www.reddit.com/r/ValveIndex/comments/cpayc5/valve_index_disassembly/">reddit post from 2019</a>. I’ve decided to dive into the details of what makes Valve Index great and share my thoughts on tech inside.</p>

<p>Teardown should begin from the simplest parts - remove the face mask (held by just magnets), unplug the main cable, and remove headphones that are held in place by a single screw each. Next remove the rubber cover that is glued around lenses. It’s not that well glued, you can just pull it off.</p>

<p><img src="https://www.thevrist.com/assets/images/index1.jpg" alt="">
<em>Rubber cover that prevents dust from getting inside lenses</em></p>

<p>Let’s start with a front panel - glossy front panel is removed by hand, since it is only held by magnets (but you already knew that from all the numerous pictures of people shoving stuff in the frunk of the headset). The rest of the front panel can be easily split in two parts. First is the frunk section, it will give you access to the main circuit board of the headset. You can remove it quite painlessly if you have the correct screwdriver. This panel does not contain any electronics.</p>

<p><img src="https://www.thevrist.com/assets/images/index-face.jpg" alt="">
<em>Just look at this beauty</em></p>

<p>Second part of the front panel is more complex. It contains tracking points for the SteamVR tracking - you can see them by looking at the plastic at different angles - plastic covering tracking points is thinner so laser beams from base stations could shoot through it. SteamVR trackers are split in two independent parts, which are connected to the main circuit separately. Also this panel contains two front facing cameras, which makes the process of taking it off even more delicate. You have to disconnect two cameras and two halves of the tracking plate’s system to finally fully reveal the main circuit.</p>

<h2 id="main-circuit">Main Circuit</h2>

<p><img src="https://www.thevrist.com/assets/images/index2.jpg" alt="">
<em>The “meat” of Valve Index</em></p>

<p>Finally we get to the main computing power of the headset. You can identify the main points of the headset.</p>

<p><img src="https://www.thevrist.com/assets/images/index3-1.png" alt="">
<em>This is where all the cables connect to the HMD</em></p>

<p>On the top there is a metal connector with FPC cable going in. It is going to the smaller circuit in the top part of the headset where the cable plugs in the headset.</p>

<p><img src="https://www.thevrist.com/assets/images/index4.jpg" alt="">
<em>Circuit board with main cable and 3.5 mm audio port. It also connects to the proximity sensor</em></p>

<p>Same circuit has a 3.5 mm audio port for connecting headphones (I bet you didn’t know there is an audio jack) and proximity sensor between lenses. Last one is used for turning off the screens when the headset is not on the head.</p>

<p><img src="https://www.thevrist.com/assets/images/index2-1.png" alt="">
<em>SteamVR tracking points are connected here</em></p>

<p>On the sides of the main circuit board there are two black FPC cables. Those are going to the SteamVR tracking dots located in the sides of the headsets. Here is a picture of the tracking “web” when taken out of the headset.</p>

<p><img src="https://www.thevrist.com/assets/images/index5.jpg" alt="">
<em>One side of SteamVR tracking web taken out of the HMD</em></p>

<p>Final two FPC cables are orange color and located at the bottom of the main board. They are connecting to a pair of displays located right behind this circuit.</p>

<h2 id="microchips">Microchips</h2>

<p>Now it is time to dive in a wonderful world of microchips and circuit boards. I want to thank <a href="https://www.linkedin.com/in/popovs/">Sergejs Popovs</a> for helping to identify most of the components on the board.</p>

<p>Let’s start with simple chips. Here are two bluetooth <a href="https://www.nordicsemi.com/Products/Low-power-short-range-wireless/nRF52840">chips from Nordic Semiconductors</a>. Each of these chips is used for connecting one controller with the headset. That’s why there is a limitation of two devices connected to the HMD. If you want to connect more devices (Vive Trackers or other controllers) you will need to use a USB dongle with a separate Bluetooth chip.</p>

<p><img src="https://www.thevrist.com/assets/images/index6.jpg" alt="">
<img src="https://www.thevrist.com/assets/images/index7.jpg" alt="">
<em>Bluetooth microchips, each connects to one device</em></p>

<p>Do you remember the USB port in the frunk? Well, this is a <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/USB5744-Data-Sheet-DS00001855J.pdf">chip from Microchip</a> for that USB port - hence USB in the name.</p>

<p><img src="https://www.thevrist.com/assets/images/index4-4.jpg" alt="">
<em>USB chip for USB port next to it</em></p>

<p>Here is a <a href="https://www.via-labs.com/product_show.php?id=96">chip from Via-Labs</a>. It has a purpose of converting USB 3.1 signal to the 2.0 one. Some of the chips on the circuit are not advanced enough to understand 3.1 USB, so this chip “dumbs it down”. When the signal will need to go back to the PC, the chip will convert the signal back to the USB 3.1.</p>

<p><img src="https://www.thevrist.com/assets/images/index8.jpg" alt="">
<em>USB signal converter chip</em></p>

<p>This is a flash memory chip from <a href="https://www.digikey.com/products/en/integrated-circuits-ics/memory/774?k=w25q32jw">Winbond Electronics</a>.</p>

<p><img src="https://www.thevrist.com/assets/images/index9.jpg" alt="">
<em>Flash memory can be used for different kinds of tasks</em></p>

<p>Next are these two microchips. The smaller one is a <a href="https://www.analogix.com/en/products/dp-mipi-converters/anx7530">SlimPort® 4K receiver from Analogix</a>. It is capable of receiving Image in 4K at 60 Hz, but since screens in Valve Index are only 1440 by 1600 pixels it allows to process video at 90, 120, and even 144 Hz. It also splits the signal in two allowing each display to get its own image.</p>

<p><img src="https://www.thevrist.com/assets/images/index10.jpg" alt="">
<em>Video chips convert image that you see in your SteamVR mirror in beautiful VR image</em></p>

<p>Larger chip is a multipurpose <a href="https://www.digikey.com/products/en/integrated-circuits-ics/embedded-fpgas-field-programmable-gate-array/696?k=ICE40HX8K">FPGA (Field Programmable Gate Array) chip from Lattice Semiconductor</a>. It is used for tracking - all the data received from the tracking sensors is gathered here. This chip combined with the <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/Atmel-11289-32-bit-Cortex-M4-Microcontroller-SAM-G55_Summary-Datasheet.pdf">Atmel MCU</a> (located on the other side of the circuit board) are doing all the necessary tracking calculations.</p>

<p><a href="http://www.etron.com.tw/cn/products/webcam_detial.php?Product_ID=10">EtronTech microchip</a> is used for merging video feeds from external cameras and transmitting it to your PC.</p>

<p><img src="https://www.thevrist.com/assets/images/index11.jpg" alt="">
<em>Microchip for processing image from webcams</em></p>

<p>Last two chips on this side of the circuit from <a href="https://www.silabs.com/power/efp01-power-management-ic">SiliconLabs</a> are most likely related to power regulation. Both of them are located near the capacitors and an inductor (metal thingy with 150 written on it). These are making sure that nothing will get too hot on your face.</p>

<p><img src="https://www.thevrist.com/assets/images/index12.jpg" alt="">
<img src="https://www.thevrist.com/assets/images/index13.jpg" alt="">
<em>Power regulating microchips</em></p>

<p>Next step is to remove the main circuit board and look on its other side. Other side is less interesting and has very little information to offer. Most parts are related to the power regulation mentioned in the previous paragraph.</p>

<p><img src="https://www.thevrist.com/assets/images/index14.jpg" alt="">
<em>Back side of the main circuit board</em></p>

<p>Largest chip is an Atmel MCU, which I’ve already mentioned is related to the tracking system. On the left from it is a <a href="https://www.nxp.com/docs/en/data-sheet/LPC11U1X.pdf">microcontroller from NXP</a>. These are all the chips we managed to identify. One chip that is missing, is the additional Bluetooth module. Unlike Vive and Vive Pro, Index has bluetooth in the headset. It is used for connecting to the base stations, updating base station firmware, and sending them to sleep mode when the headset is turning off. Last one is completely optional - I prefer to keep my base stations 2.0 on all the time.</p>

<p><img src="https://www.thevrist.com/assets/images/index14-2.jpg" alt="">
<em>The only two chips worth noting on this side of the motherboard - larger one is for tracking calculations</em></p>

<p>Why there is no separate Bluetooth chip for this purpose is still a mystery for me. Only possible explanation is that two Bluetooth chips for controllers are capable of switching to different modes and control the base stations.</p>

<h2 id="screens">Screens</h2>

<p>After the circuit is removed you will reveal several key components. First - you can see two displays - quick search shows that those panels are made by BOE Technology - Chinese display manufacturer. Those are 1440×1600, 615PPI 3.5” <a href="https://www.panelook.com/VS035ZSM-NW0-69P0_BOE_3.5_LCM_overview_37926.html">panels</a>.</p>

<p><img src="https://www.thevrist.com/assets/images/index15.jpg" alt="">
<em>View of the HMD with main board removed</em></p>

<p>Note some key elements in this view. On the bottom there is a circular mechanism with a metal pin with springs going through the whole headset. Similar pin is barely visible on the top of the headset. This is an IPD adjustment system - movement of the knob at the bottom of the HMD will rotate circular element in the bottom center which will push screens apart.
On the left and right sides of HMD you can see black gears - this is a system for eye relief - rotating a knob on the side of the headset will move the facemask relatively to the screens. Gear system is making sure both sides are rotating simultaneously, without giving too much pressure to the mechanism.</p>

<p><img src="https://www.thevrist.com/assets/images/index16.jpg" alt="">
<em>IPD knob is actually a screw</em></p>

<p>In order to take the central part out from the headset, you will need to take the cap off the IPD adjustment knob and unscrew it.</p>

<p><img src="https://www.thevrist.com/assets/images/index17.jpg" alt="">
<em>Lens chambers with IPD mechanism still attached</em></p>

<p>Next was what I call the “wondering in the dark” part of teardown - for about 30 minutes we were trying to find a way of taking it apart without breaking anything, eventually using force to break one gear inside that was holding display chambers in place.</p>

<p><img src="https://www.thevrist.com/assets/images/index18.jpg" alt="">
<em>Right eye lens chamber removed</em></p>

<p>After this step you can easily take off separate lens chambers and view the details. Chambers are sealed shut so nothing will get inside - they are assembled in perfectly clean conditions with no dust particles. 
In order to take it apart you can probably try to melt glue or something like that. But we are no iFixit, we used good ol’ force. Here you can see the screen separated from the chamber.</p>

<p><img src="https://www.thevrist.com/assets/images/index19.jpg" alt="">
<img src="https://www.thevrist.com/assets/images/index20.jpg" alt="">
<em>BOE screen removed from the chamber</em></p>

<p>Screen has a polarised diffuser glued to it, which is particularly difficult to remove. It is made of very thin crystal glass and it cracks easily. You can see that the corners of it are cracked.</p>

<p><img src="https://www.thevrist.com/assets/images/index21.jpg" alt="">
<em>Crystal polarisation diffuser</em></p>

<p>Diffuser is added to blend pixels better, making the screen door effect even lower.</p>

<p><img src="https://www.thevrist.com/assets/images/index22.jpg" alt="">
<em>Fancy multilayered lens</em></p>

<p>Finally - the lenses. I was expecting them to be thicker with the effect that they create. Valve are saying “The custom lenses built into the Valve Index Headset maximize field of view without sacrificing edge-to-edge clarity. High geometric stability allows you to look around the scene by moving your eyes (not just your head) with minimal shape distortion”. I tend to agree that these are the most advanced lenses in modern mass produced HMD, even though they have their own flaws. Main issue is the light spill when using a headset, you can see the bright light’s reflections in spots where they shouldn’t be.</p>

<h2 id="final-thoughts">Final thoughts</h2>

<p>As you can clearly see, it is not possible to replace a damaged screen or scratched lens all by yourself (even though for latter one you might try to take the lens out using a suction cup, however I don’t think that is a good idea, as lenses and screens are calibrated in the factory).</p>

<p><img src="https://www.thevrist.com/assets/images/index-end.jpg" alt="">
<em>Sometimes… I feel like a monster…</em></p>

<p>I am going to put the high-resolution images of the teardown and of the motherboard <a href="https://photos.app.goo.gl/dhuPVWTu6P5XWo4HA">here</a> so you can see and check all the details by yourself. If you have any corrections, notes, or questions, shoot me an <a href="mailto:zegarsilya@gmail.com">email</a> or PM me on <a href="https://twitter.com/GamerToTheEnd">Twitter</a>.</p>

           …</div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thevrist.com//indexteardown">https://www.thevrist.com//indexteardown</a></em></p>]]>
            </description>
            <link>https://www.thevrist.com//indexteardown</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151496</guid>
            <pubDate>Fri, 14 Aug 2020 00:02:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding .NET Generic Host Model]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24151361">thread link</a>) | @sahan
<br/>
August 13, 2020 | https://sahansera.dev/dotnet-core-generic-host/ | <a href="https://web.archive.org/web/*/https://sahansera.dev/dotnet-core-generic-host/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this article, we will concentrate on how the Generic Host model hosts ASP.NET Core 3.x Web app and a Worker Service. We will first discuss the definition of a <em>Host</em> and its configuration. In the subsequent sections, we will dive into the implementation details from a higher level.</p>
<h3>So what’s the deal with the Generic Host</h3>
<p>With the separation of execution and initialisation, Generic Host provides us with a cleaner way to configure and start up our apps. By default, when you create an ASP.NET Core app now, your application will be hosted using the Generic Host model. If you create a new worker service app, it will be hosted the same way.</p>
<p>Not only that, but this model also provides you standardised configuration, DI, logging, and many more. You can even create a traditional console app, beef it up and make use of Generic Host.</p>
<blockquote>
<p>💡 Follow along with the code from this <a href="https://github.com/sahan91/dotnet-generic-host-example">repository</a></p>
</blockquote>
<h3>The Host</h3>
<p>According to the official documentation, a <code>Host</code> is,</p>
<blockquote>
<p>ASP.NET Core apps configure and launch a host. The host is responsible for app startup and lifetime management. At a minimum, the host configures a server and a request processing pipeline. The host can also set up logging, dependency injection, and configuration.</p>
</blockquote>
<p>Let’s create a new .NET 3.1 WebAPI and a Worker Service project</p>
<div data-language="bash"><pre><code>dotnet new webapi -n WebApplication
dotnet new worker -n WorkerService
dotnet new sln
dotnet sln <span>add</span> WebApplication WorkerService</code></pre></div>
<p>If you open up the solution in an IDE, you will see the following project structure.</p>
<p><span>
      <span></span>
  <img alt="dotnet-core-generic-host-1.png" title="dotnet-core-generic-host-1.png" src="https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/0c69d/dotnet-core-generic-host-1.png" srcset="https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/772e8/dotnet-core-generic-host-1.png 200w,
https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/e17e5/dotnet-core-generic-host-1.png 400w,
https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/0c69d/dotnet-core-generic-host-1.png 598w" sizes="(max-width: 598px) 100vw, 598px" loading="lazy">
    </span></p>
<p>They both have a <code>Program.cs</code> which takes care of setting up a host. In the case of the WebApplication project, it sets up a request processing pipeline defined in a <code>Startup.cs</code> and in the WorkerService project, sets a new hosted service which is an essentially an <code>IHostedService</code>.</p>
<p>In the WebApplication project, when you open up the Program.cs file, you will find the following boilerplate code has been added by the template:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span><span>void</span></span> <span>Main</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span>
<span>{</span>
    <span>CreateHostBuilder</span><span>(</span>args<span>)</span><span>.</span><span>Build</span><span>(</span><span>)</span><span>.</span><span>Run</span><span>(</span><span>)</span><span>;</span>
<span>}</span>

<span>public</span> <span>static</span> <span>IHostBuilder</span> <span>CreateHostBuilder</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span> <span>=&gt;</span>
    Host<span>.</span><span>CreateDefaultBuilder</span><span>(</span>args<span>)</span>
        <span>.</span><span>ConfigureWebHostDefaults</span><span>(</span>webBuilder <span>=&gt;</span>
        <span>{</span>
            webBuilder<span>.</span><span><span>UseStartup</span><span><span>&lt;</span>Startup<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>
        <span>}</span><span>)</span><span>;</span></code></pre></div>
<p>And, in the WorkerService project we have the following code:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span><span>void</span></span> <span>Main</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span>
<span>{</span>
    <span>CreateHostBuilder</span><span>(</span>args<span>)</span><span>.</span><span>Build</span><span>(</span><span>)</span><span>.</span><span>Run</span><span>(</span><span>)</span><span>;</span>
<span>}</span>

<span>public</span> <span>static</span> <span>IHostBuilder</span> <span>CreateHostBuilder</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span> <span>=&gt;</span>
    Host<span>.</span><span>CreateDefaultBuilder</span><span>(</span>args<span>)</span>
        <span>.</span><span>ConfigureServices</span><span>(</span><span>(</span>hostContext<span>,</span> services<span>)</span> <span>=&gt;</span>
        <span>{</span>
            services<span>.</span><span><span>AddHostedService</span><span><span>&lt;</span>Worker<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>
        <span>}</span><span>)</span><span>;</span></code></pre></div>
<p>Except for the <code>ConfigureWebHostDefaults()</code> and <code>ConfigureServices()</code>, everything else is the same.</p>
<h3>Host Configuration</h3>
<p>If you look at the <code>CreateHostBuilder</code> method in the above code, it calls a <code>CreateDefaultBuilder</code> static method from <a href="https://github.com/dotnet/runtime/blob/master/src/libraries/Microsoft.Extensions.Hosting/src/Host.cs">Host</a> coming from <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.host.createdefaultbuilder?view=dotnet-plat-ext-3.1">Microsoft.Extensions.Hosting</a> namespace. It looks like that when we scaffold an ASP.NET Core app, it gives us a <em>.NET Generic Host</em> by default now. We used to have Web Host in ASP.NET Core 2.x, which was made deprecated since ASP.NET Core 3.0. For any future applications, it is recommended to use the .NET Generic Host.</p>
<p>This does a few things under the covers by wrapping,</p>
<ul>
<li>Dependency Injection services</li>
<li>HTTP Server implementation (such as Kestrel)</li>
<li>Logging</li>
<li>Configuration etc.</li>
</ul>
<p>In order to get an idea what the above methods do, I looked into the <a href="https://github.com/dotnet/runtime/blob/master/src/libraries/Microsoft.Extensions.Hosting/src/Host.cs">source code on Github</a>.</p>
<p>We will start off with CreateDefaultBuilder method first.</p>
<p><strong><a href="https://github.com/dotnet/runtime/blob/6072e4d3a7a2a1493f514cdf4be75a3d56580e84/src/libraries/Microsoft.Extensions.Hosting/src/Host.cs">Host.CreateDefaultBuilder()</a></strong></p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span>IHostBuilder</span> <span>CreateDefaultBuilder</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span>
<span>{</span>
    
    <span><span>var</span></span> builder <span>=</span> <span>new</span> <span>HostBuilder</span><span>(</span><span>)</span><span>;</span>

    
    builder<span>.</span><span>UseContentRoot</span><span>(</span>Directory<span>.</span><span>GetCurrentDirectory</span><span>(</span><span>)</span><span>)</span><span>;</span>

    
    
    builder<span>.</span><span>ConfigureHostConfiguration</span><span>(</span>config <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span><span>;</span>

    
    
    builder<span>.</span><span>ConfigureAppConfiguration</span><span>(</span><span>(</span>hostingContext<span>,</span> config<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

    
    <span>.</span><span>ConfigureLogging</span><span>(</span><span>(</span>hostingContext<span>,</span> logging<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

    
    <span>.</span><span>UseDefaultServiceProvider</span><span>(</span><span>(</span>context<span>,</span> options<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span><span>;</span>

    <span>return</span> builder<span>;</span>
<span>}</span></code></pre></div>
<p>As you can see, it pretty much configures a <code>HostBuilder</code> object and returns it. There’s nothing really specific to web hosting in here. This is why it’s common to both HTTP and non-HTTP workloads.</p>
<p>Taking a step further, let’s look at how the web host gets configured. We will now look through <code>ConfigureWebHostDefaults</code> method.</p>
<p><strong><a href="https://github.com/dotnet/aspnetcore/blob/4d4f2fe00ffa7c1b9ea08164f9f26a51a392d007/src/DefaultBuilder/src/GenericHostBuilderExtensions.cs#L26">GenericHostBuilderExtensions.ConfigureWebHostDefaults()</a></strong></p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span>IHostBuilder</span> <span>ConfigureWebHostDefaults</span><span>(</span><span>this</span> <span>IHostBuilder</span> builder<span>,</span> <span>Action<span>&lt;</span>IWebHostBuilder<span>&gt;</span></span> configure<span>)</span>
<span>{</span>
    <span>return</span> builder<span>.</span><span>ConfigureWebHost</span><span>(</span>webHostBuilder <span>=&gt;</span>
    <span>{</span>
        WebHost<span>.</span><span>ConfigureWebDefaults</span><span>(</span>webHostBuilder<span>)</span><span>;</span>

        <span>configure</span><span>(</span>webHostBuilder<span>)</span><span>;</span>
    <span>}</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>Remember that <code>ConfigureWebHostDefaults</code> is used only for HTTP workloads and let’s see what we get as the default web host configuration.</p>
<p><strong><a href="https://github.com/dotnet/aspnetcore/blob/4d4f2fe00ffa7c1b9ea08164f9f26a51a392d007/src/DefaultBuilder/src/WebHost.cs#L215">WebHost.ConfigureWebDefaults()</a></strong></p>
<div data-language="csharp"><pre><code><span>internal</span> <span>static</span> <span><span>void</span></span> <span>ConfigureWebDefaults</span><span>(</span><span>IWebHostBuilder</span> builder<span>)</span>
<span>{</span>
	
    builder<span>.</span><span>ConfigureAppConfiguration</span><span>(</span><span>(</span>ctx<span>,</span> cb<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span><span>;</span>

	
    builder<span>.</span><span>UseKestrel</span><span>(</span><span>(</span>builderContext<span>,</span> options<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

	
    <span>.</span><span>ConfigureServices</span><span>(</span><span>(</span>hostingContext<span>,</span> services<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

	
    <span>.</span><span>UseIIS</span><span>(</span><span>)</span>
    <span>.</span><span>UseIISIntegration</span><span>(</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>So far, we have seen that both approaches use the same Generic Host paradigm in the two projects. If you are interested in customising the default configuration, head over to <a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.1#host-configuration">Microsoft Docs’ official documentation</a>.</p>
<h3>Finally, how does it all run?</h3>
<p>Now comes the interesting part.</p>
<p>In both cases, after the configuration sections, we finally call the <code>Run()</code> on <code>IHost</code> object implemented in <code>HostingAbstractionsHostExtensions</code>. This will run the app and block the calling thread until the host is shut down. This is enabled by <code>WaitForShutdownAsync</code> which is called at the beginning of the start-up process, which can be triggered by Ctrl+C/SIGTERM or SIGINIT.</p>
<p>Let’s look at how both web hosts and worker services run.</p>
<p>For a worker service, remember how we registered our Worker class by passing it into <code>ConfigureServices</code> method. This Worker class extends <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.backgroundservice?view=dotnet-plat-ext-3.1"><code>BackgroundService</code></a> which in turn implements <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.ihostedservice?view=dotnet-plat-ext-3.1"><code>IHostedService</code></a>. <code>IHostedService</code> provides 2 methods, namely, <code>StartAsync</code> and <code>StopAsync</code>. So when we run our host, it must be retrieving our Worker service and invoking these methods.</p>
<p><span>
      <span></span>
  <img alt="dotnet-core-generic-host-2.png" title="dotnet-core-generic-host-2.png" src="https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/5a190/dotnet-core-generic-host-2.png" srcset="https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/772e8/dotnet-core-generic-host-2.png 200w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/e17e5/dotnet-core-generic-host-2.png 400w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/5a190/dotnet-core-generic-host-2.png 800w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/c1b63/dotnet-core-generic-host-2.png 1200w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/29007/dotnet-core-generic-host-2.png 1600w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/575bd/dotnet-core-generic-host-2.png 1791w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
    </span></p>
<p><em>Source: <a href="https://devblogs.microsoft.com/cesardelatorre/implementing-background-tasks-in-microservices-with-ihostedservice-and-the-backgroundservice-class-net-core-2-x/">Microsoft</a></em></p>
<p>In the <code>Host.cs</code> there’s a separate <code>StartAsync</code> method and we can find the following lines inside it.</p>
<div data-language="csharp"><pre><code>_hostedServices <span>=</span> Services<span>.</span><span><span>GetService</span><span><span>&lt;</span>IEnumerable<span>&lt;</span>IHostedService<span>&gt;</span><span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>

<span>foreach</span> <span>(</span><span><span>var</span></span> hostedService <span>in</span> _hostedServices<span>)</span>
<span>{</span>
    
    <span>await</span> hostedService<span>.</span><span>StartAsync</span><span>(</span>combinedCancellationToken<span>)</span><span>.</span><span>ConfigureAwait</span><span>(</span><span>false</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>So our guess was correct. It certainly invokes the <code>StartAsync</code> method of <code>BackgroundService</code>, that calls <code>ExecuteAsync</code> method in which we have ultimately implemented in our <code>Worker</code> class.</p>
<p>For a web host, there’s a little bit of abstraction on top of this before it hits the above section. A summary of how it reaches this as follows;</p>
<ol>
<li>In Program.cs, configure a new webhost builder object in ConfigureWebHostDefaults</li>
<li>Register Startup class</li>
<li><code>GenericHostBuilderExtensions.ConfigureWebHostDefaults</code> method gets called</li>
<li><code>GenericHostWebHostBuilderExtensions.ConfigureWebHost</code> gets called</li>
<li>Register a <code>GenericWebHostService</code> service</li>
</ol>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span>IHostBuilder</span> <span>ConfigureWebHost</span><span>(</span><span>this</span> <span>IHostBuilder</span> builder<span>,</span> <span>Action<span>&lt;</span>IWebHostBuilder<span>&gt;</span></span> configure<span>)</span>
<span>{</span>
    <span><span>var</span></span> webhostBuilder <span>=</span> <span>new</span> <span>GenericWebHostBuilder</span><span>(</span>builder<span>)</span><span>;</span>
    <span>configure</span><span>(</span>webhostBuilder<span>)</span><span>;</span>
    builder<span>.</span><span>ConfigureServices</span><span>(</span><span>(</span>context<span>,</span> services<span>)</span> <span>=&gt;</span> services<span>.</span><span><span>AddHostedService</span><span><span>&lt;</span>GenericWebHostService<span>&gt;</span></span></span><span>(</span><span>)</span><span>)</span><span>;</span>
    <span>return</span> builder<span>;</span>
<span>}</span></code></pre></div>
<p>So what is a <code>GenericWebHostService</code> ? It’s an <code>IHostedService</code> 🤩. Rest of the story is as above as we looked at in the worker service scenario. Because of this nicely decoupled initialisation we are able to run both ASP.NET Core and Worker services on the Generic Host.</p>
<h3>Summary</h3>
<p>To summarise, we looked at what makes the Generic Host <em>generic</em> and dug deeper into the implementation details in .NET Github repo. We also looked at what makes an ASP.NET Core web application and a worker service different, configuration-wise. This post became a bit longer than I initially I thought it would be 😅 Nevertheless, hope you picked up a thing or two.</p>
<p>Cheers!</p>
<h3>References</h3>
<ol>
<li><a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view=aspnetcore-3.1&amp;tabs=visual-studio">https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view=aspnetcore-3.1&amp;tabs=visual-studio</a></li>
<li><a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.1">https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.1</a></li>
<li><a href="https://andrewlock.net/exploring-the-new-project-file-program-and-the-generic-host-in-asp-net-core-3/">https://andrewlock.net/exploring-the-new-project-file-program-and-the-generic-host-in-asp-net-core-3/</a></li>
</ol></div></div>]]>
            </description>
            <link>https://sahansera.dev/dotnet-core-generic-host/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151361</guid>
            <pubDate>Thu, 13 Aug 2020 23:49:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google play music shutting down]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24150597">thread link</a>) | @abuckenheimer
<br/>
August 13, 2020 | https://blog.youtube/news-and-events/youtube-music-will-replace-google-play-music-end-2020/ | <a href="https://web.archive.org/web/*/https://blog.youtube/news-and-events/youtube-music-will-replace-google-play-music-end-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="jump-content" tabindex="-1">
            
  <article>
    
    


<div>

<section>
    
    <div>
      
      <div>
        <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/GPM_15s_en_US_1.gif" alt="YouTube Music will replace Google Play Music by end of 2020">
        
        </p>
      </div>
      <p>
        <article>
          Today we're announcing two important updates.
        </article>
      </p>
    </div>
  </section>
</div>


    
      
        



<section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><p>Over the past couple of months, we’ve been welcoming Google Play Music listeners to YouTube Music as they <a href="https://youtube.googleblog.com/2020/05/youtube-music-transfer-google-play-music-library.html">effortlessly transfer</a> their music libraries, personal taste preferences and playlists to YouTube Music. Today we're announcing two important updates. First, YouTube Music will replace Google Play Music by December 2020. Users will have the opportunity to transfer their music libraries from Google Play Music to YouTube Music in that timeframe. Second, in the coming months, Google Play Music users will no longer be able to stream from or use the Google Play Music app. Additionally, we are making changes to the Google Play store and Music Manager.&nbsp;</p><p>Starting in September 2020 in New Zealand and South Africa — and in October for all other global markets — users will no longer be able to stream from or use the Google Play Music app. But don’t worry, we will be holding onto things like your playlists, uploads, purchases, likes and more until December 2020 to make your transfer to YouTube Music easier. Users who wish to transfer their music libraries from Google Play Music to YouTube Music, can do so through December 2020, after which their Google Play Music libraries will no longer be available.</p><h2>Simple transfer and additional changes to Music Manager</h2><p>Starting in late August, users will no longer be able to purchase and pre-order music or upload and download music from Google Play Music through Music Manager.&nbsp;</p><p>To ensure users don’t lose any of their content, they’ll need to use the simple<a href="http://music.youtube.com/transfer"> transfer tool</a> to migrate any purchases over to YouTube Music or use<a href="https://takeout.google.com/"> Google Takeout</a> to export data and download their purchased and uploaded music. Once the Music Store is no longer available, users will continue to be able to upload any tracks purchased elsewhere to YouTube Music.</p><p>For Google Play listeners that have not yet started the transfer process over to YouTube Music, now’s the time. Listeners can also choose to delete their Google Play Music data, and we will clearly notify all users before they lose access to their Google Play Music library and data.</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/unnamed_1_eb3YIiY.jpg" alt="GPM II">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><h2>Enhancements to your new home for music: YouTube Music&nbsp;&nbsp;&nbsp;</h2><p>Since<a href="https://youtube.googleblog.com/2020/05/youtube-music-transfer-google-play-music-library.html"> introducing the transfer tool in May</a>, we’ve continued to improve and add new features to YouTube Music for all music lovers to enjoy, including many that are important and familiar to Google Play Music users.&nbsp;</p><br><ul><li><p><b>Playlists: We’re continuously evolving the way listeners can create and enjoy playlists, including:</b></p></li><ul><li><p><b>Assistive Playlist Creation </b>- Quickly and easily create playlists by adding recommended songs based on existing songs in the playlist, as well as personalized signals, such as watch history and likes.</p></li><li><p><b>Collaborative Playlists</b> - Collaborate with other music fans to create shared playlists for any occasion.</p></li><li><p><b>New Programmed Playlists </b>- Explore newly launched programmed playlists like <a href="https://music.youtube.com/playlist?list=RDCLAK5uy_mu-BhJj3yO1OXEMzahs_aJVtNWJwAwFEE">Highline</a>, <a href="https://music.youtube.com/playlist?list=RDCLAK5uy_kUFCSc-grF3m-L_49W6p1QyGsMbueEbog">Caribbean Pulse</a>, <a href="https://music.youtube.com/playlist?list=RDCLAK5uy_m0Nsi5Jnn_g6qbvc7fywPRhEv1qN0PcMM">Conditions Underground</a>, and more.</p></li></ul><li><p><b>New Features and Improvements:&nbsp;</b></p></li><ul><li><p><b>Player Page Redesign</b> - Updates to the player page, available for Android mobile users, provides a more modern design that allows better playback controls and easier access to related music and other features like song lyrics.</p></li><li><p><b>Explore Tab</b> -&nbsp;The new Explore tab, available on both mobile and the web is the consistent destination to find new releases including albums, singles, and music videos, as well as browse our vast catalog of diverse playlists through the Moods &amp; Genre section</p></li></ul><li><p><b>More Ways to Enjoy YouTube Music:</b></p></li><ul><li><p><b>Android TV</b> - An update for Android TV brings YouTube Music to the big screen, letting listeners enjoy videos and live performances from their favorite artists, along with all their favorite music.</p></li><li><p><b>Google Maps</b> - The Android integration lets listeners seamlessly listen to music and get personalized music recommendations within the Google Maps interface.</p></li><li><p><b>Discover music with Google Assistant</b> - You can now ask your Google Home and Nest smart speakers, “Hey Google, play recommended music from YouTube Music.” Then, Google Assistant will share personalized recommendations based on your favorite artists and genres.&nbsp;</p></li></ul></ul></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><p>Over the last few years, we've worked to build a fantastic fan experience on YouTube Music, merging the very best of Google Play Music with the very best of YouTube. For users who decide not to transfer their Google Play Music account to YouTube music, we will be sure to cancel your subscription at the end of your billing cycle so you aren't paying for a subscription. This will happen in September in New Zealand and South Africa and in October for all other markets. And, of course, we will be sure to notify all users ahead of subscriptions being canceled.</p><p>We can’t wait for you to start exploring YouTube Music features and discovering new music favorites along the way. Have more questions or need help? Check out all of our support resources <a href="https://support.google.com/youtubemusic/answer/9698084">here</a>.</p><br></div>
      </div>
      
    </div>
  </div>
</section>

      
    

    


<section>
  <article>
    
  </article>
</section>


    
    
  


  </article>


        </div></div>]]>
            </description>
            <link>https://blog.youtube/news-and-events/youtube-music-will-replace-google-play-music-end-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24150597</guid>
            <pubDate>Thu, 13 Aug 2020 22:48:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JavaScript Face Detection and Recognition Libraries 2020]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24150436">thread link</a>) | @truly_furqan
<br/>
August 13, 2020 | https://www.edopedia.com/blog/javascript-face-detection-and-recognition-libraries/ | <a href="https://web.archive.org/web/*/https://www.edopedia.com/blog/javascript-face-detection-and-recognition-libraries/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
<p>Face detection, recognition and tracking are revolutionary technologies that have been deployed on mobile phones, webcams, and digital cameras. With the help of this advancement in technology, we are now able to detect human faces and recognize any specific person in a crowd.</p>
<p>This is a really superb and game changer innovation that has taken the technology world by storm. Now it’s only a matter of time for face detection technology to be deployed across different web applications in different sectors.</p>
<p>In digital cameras, face detection technology is used for the purpose of autofocus; in webcams, it is used to take an instant passport-sized photograph of you; and in mobile phones, it is one measure used for the authentication of its user.</p>
<p>The future of face detection and recognition technology is very promising. This is because it is successfully used by the police and other law enforcement agencies to detect and fight crime in many countries of the world.</p>
<p>Actually, the below-mentioned libraries are using Artificial Intelligence and Machine Learning algorithms/models to detect a face. This is not a simple or straightforward task but some highly professional programmers have created different JavaScript libraries and frameworks to help us use this new technology in our web applications.</p>
<p>Now, if you are like me who is curious to learn about the actual working of these libraries. Maybe you want to create a similar JavaScript library yourself. Then, I would highly recommend you to take this <strong><a href="https://click.linksynergy.com/deeplink?id=QSpACVN268M&amp;mid=39197&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fcourse%2Fmachine-learning-with-javascript%2F" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">“Machine Learning with Javascript Course”</a></strong> from Udemy.</p>
<p>Over 19,000 students are already enrolled in this course. Also, it has received 4.6 stars rating from 1,900+ students. So, this course can be a life-changer for you.</p>
<p>Anyways, let’s have a look at these amazing JavaScript face detection and recognition libraries.</p>
<hr>
<h2>tracking.js</h2>
<p>This JavaScript library is packed with a deluge of algorithms and capabilities for tackling different aspects of face detection and recognition within a web browser. It works very instinctively. Face detection, recognition and color tracking are done instantly. This is one of the best JavaScript face detection and recognition libraries.</p>
<p><a href="https://trackingjs.com/examples/face_tag_friends.html" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/eduardolundgren/tracking.js/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>face-api.js</h2>
<p>This is another JavaScript library for the detection and recognition of human faces. It makes use of the tensorflow.js core API for its proper working inside the web browser. You can use this library to track and detect a face in real-time.</p>
<p><a href="https://justadudewhohacks.github.io/face-api.js/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/justadudewhohacks/face-api.js" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>clmtrackr</h2>
<p>clmtrackr is also an open source face detection library like the ones I’ve mentioned above. You can download it from GitHub for free.</p>
<p>It makes use of Constrained Local Models to precisely identify and track the facial features. It then returns an array, which contains all the coordinates of a face model.</p>
<p>The interesting thing about clmtrackr is that it is capable of face swapping and masking. It really forms an all-in-one package.</p>
<p><a href="https://www.auduno.com/clmtrackr/examples/clm_image.html" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/auduno/clmtrackr" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>pico.js</h2>
<p>One of the JavaScript face detection and recognition libraries is pico.js. It is made up of roughly 200 lines of clean JavaScript code.</p>
<p>In its GitHub repository, you will find 3 major folders e.g. “img”, “cam” and “wasm”. All of these folders contain basic demo of how this library works. Its “img” folder has an example which clearly demonstrates how you can detect a human face in images. The “cam” folder contains a demo which shows the tracking of face in real-time. Basically “wasm” folder is there to provide an example about how you can compile pico.js to WebAssembly.</p>
<p><a href="https://tkv.io/posts/picojs-intro/demo/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/tehnokv/picojs" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>jeelizWeboji</h2>
<p>jeelizWeboji.js is a JavaScript/WebGL library that is used to detect and replicate different expressions on faces. It runs perfectly on typical webcams. The face detection is very effective because it can easily work in all kinds of lighting conditions.</p>
<p><a href="https://jeeliz.com/demos/weboji/demos/threejs/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/jeeliz/jeelizWeboji" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>jeelizFaceFilter</h2>
<p>This is another unique JavaScript/WebGL library that solely does real-time face tracking and detection in videos recorded using a webcam. Its features include face detection and tracking, mouth opening detection, face rotation detection, detect multiple faces, support for 3D engines like BABYLON.JS, THREE.JS, A-FRAME and many more. It is highly mobile-friendly too.</p>
<p><a href="https://jeeliz.com/demos/faceFilter/demos/threejs/headControls/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/jeeliz/jeelizFaceFilter" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>js-objectdetect</h2>
<p>This is an object detection JavaScript library that runs smoothly on any web browsers. It gives its output in real-time. It is well supported by all the latest web browsing applications. Basically the main purpose of using this library is to bring computer vision right inside your favorite web browser without any issues.</p>
<p><a href="http://mtschirs.github.io/js-objectdetect/examples/example_image.htm" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/mtschirs/js-objectdetect/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>face-recognition.js</h2>
<p>This is another face recognition program. It is both a JavaScript and a TypeScript API. It is available in the form of node.js package. Apart from face recognition and detection, it also identifies face landmarks.</p>
<p><a href="https://github.com/justadudewhohacks/face-recognition.js" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>jQuery Face Detection Plugin</h2>
<p>jQuery Face Detection Plugin helps to detect different human faces inside an image, canvas or video. It makes use of an advanced algorithm to get an array of all the objects found in a face. These objects include coordinates, height and width, offset, position, scale and confidence of a face.</p>
<p><a href="http://facedetection.jaysalvat.com/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/jaysalvat/jquery.facedetection" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>JS-face-tracking-demo</h2>
<p>This is a face tracking JavaScript library demo. This program consists of JavaScript, HTML and CSS.</p>
<p><a href="https://kdzwinel.github.io/JS-face-tracking-demo/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/kdzwinel/JS-face-tracking-demo" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>headtrackr</h2>
<p>This JavaScript package is specifically developed for tracking the face and head of a person. It works perfectly through a webcam. It basically tracks someone’s head position in proportion to the screen of the computer. This JavaScript library gives an accurate output when deployed on the modern web browsers.</p>
<p><a href="https://www.auduno.com/headtrackr/examples/facetracking.html" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/auduno/headtrackr" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>Kittydar</h2>
<p>This is very interesting, to say the least. Face detection functionality has gone beyond detecting the faces of humans; it is now used on animals. Kittydar is a face detection JavaScript library used for detecting the face of cats in an image/canvas. Once the cat is standing upright and facing forward, Kittydar will surely recognize it with a high level of accuracy.</p>
<p><a href="http://harthur.github.io/kittydar/" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/harthur/kittydar" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>ccv-purejs</h2>
<p>ccv-purejs is a great example of JavaScript face detection libraries that can be downloaded from GitHub. Actually this library makes use of node-canvas to work effectively with node and npm. Right now the package requires you to load an image inside a canvas object. But according to the developer, he has planned to add the support for directly using an image path in future.</p>
<p><a href="https://github.com/orls/ccv-purejs" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>videojs-faceDetection</h2>
<p>This JavaScript library works in different environments. It makes use of the video.js player achieve face detection. Having a distinct support for videojs player makes it very unique. It is built on the back of a combination of JavaScript and HTML5 using an intuitive algorithm as usual. Its features include a custom data structure, simple image processing, grayscale, box blur and many more.</p>
<p><a href="https://github.com/benjipott/videojs-faceDetection" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>facedetector</h2>
<p>This is yet another face detection and tracking JavaScript library that is supported by a node.js program. Its face detection functionality is similar to others and also it works in real-time. It has implemented a really simple yet effective algorithm for tracking faces. It is capable of detecting so many faces in one photograph. You can use and distribute it for free because it is open source and available under MIT license.</p>
<p><a href="https://riversun.github.io/facedetector/example/index.html" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Live Demo</a><a href="https://github.com/riversun/facedetector" target="_blank" rel="noopener noreferrer nofollow external" data-wpel-link="external">Download</a></p>
<hr>
<h2>Conclusion</h2>
<p>Face detection and tracking have come to stay. It can only get better as more advancement is made in the future. JavaScript face detection and recognition libraries have helped in no small ways in making facial detection and recognition a reality.</p>
<p>The fact that it helps in fighting crime and used for authentication of the real owner of a mobile phone makes it a lot more compelling.</p>
<p>In the nearest future, it will be used on web applications and its usefulness will become irresistible. It may be deployed in schools during examinations to detect and recognize the faces of students who are allowed to appear in exam. It can also be used during the recruitment process. The future is already here. Our lives can only get better and smarter with the passage of time.</p>

			
					</div></div>]]>
            </description>
            <link>https://www.edopedia.com/blog/javascript-face-detection-and-recognition-libraries/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24150436</guid>
            <pubDate>Thu, 13 Aug 2020 22:36:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Blocks of Every Machine Learning Solutions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24150088">thread link</a>) | @FHMS
<br/>
August 13, 2020 | https://datarevenue.com/en-blog/machine-learning-project-architecture | <a href="https://web.archive.org/web/*/https://datarevenue.com/en-blog/machine-learning-project-architecture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Machine learning solutions are used to solve a wide variety of problems, but in nearly all cases the core components are the same. Whether you simply want to understand the skeleton of machine learning solutions better or are embarking on building your own, understanding these components - and how they interact - can help.</p><p>Here’s a visual and written explanation of what these are and what they do.</p><figure id="w-node-1017d6fd20b2-018ecc93"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5f2d1b1667b2cfe2a3ceec18_Q5H2ISpXvST4SJ7rp6-MMChpY5W_Bxul_c1g2CGCSMFSRNT_wlI1PT7XoxABOu-ftF6reUZVHRMHAzRKz7wXgxMz7umLRlFYq6gahk-GdlPW2ZUEL1M8PSuPPnNQK1nXNDV6HP2Y.png" alt="A diagram showing the components of a machine learning solution."></p><figcaption>Machine learning consists of many components, not just an algorithm. (Want more content like this? <a href="https://datarevenue.com/signup">Subscribe</a> to our newsletter).</figcaption></figure><p>‍<strong>The components of a machine learning solution</strong></p><ol role="list"><li><strong>Data Generation: </strong>Every machine learning application lives off data. That data has to come from somewhere. Usually it’s generated by one of your core business functions.</li><li><strong>Data Collection: </strong>Data is only useful if it’s accessible, so it needs to be stored – ideally in a consistent structure and conveniently in one place.</li><li><strong>Feature Engineering Pipeline:</strong> Algorithms can't make sense of raw data. We have to select, transform, combine, and otherwise prepare our data so the algorithm can find useful patterns.</li><li><strong>Training:</strong> This is where the magic happens. We apply algorithms, and they learn patterns from the data. Then they use these patterns to perform particular tasks.</li><li><strong>Evaluation: </strong>We need to carefully test how well our algorithm performs on data it hasn’t seen before (during training). This ensures we don’t use prediction models that work well on “seen” data, but not in real-world settings.</li><li><strong>Task Orchestration:</strong> Feature engineering, training, and prediction all need to be scheduled on our compute infrastructure (such as AWS or Azure) – usually with non-trivial interdependence. So we need to reliably orchestrate our tasks.</li><li><strong>Prediction:</strong> This is the moneymaker. We use the model we’ve trained to perform new tasks and solve new problems – which usually means making a prediction.</li><li><strong>Infrastructure: </strong>Even in the age of the cloud, the solution has to live and be served somewhere. This will require setup and maintenance.&nbsp;</li><li><strong>Authentication:</strong> This keeps our models secure and makes sure only those who have permission can use them.</li><li><strong>Interaction:</strong> We need some way to interact with our model and give it problems to solve. Usually this takes the form of an API, a user interface, or a command-line interface.<strong>‍</strong></li><li><strong>Monitoring: </strong>We need to regularly check our model’s performance. This usually involves periodically generating a report or showing performance history in a dashboard.</li></ol><h2><strong>Building your own ML Architecture</strong></h2><p>Data generation and collection, training, and evaluation are must-haves, but you may need domain-specific components too.</p><p>A <a href="https://datarevenue.com/en-blog/building-ai-projects-or-hiltch-skyline-ai">common mistake we see</a> is people focussing too much on the prediction component and not enough on the feature engineering pipeline (or trying to skip this component completely).</p><p>Do you need a second opinion on how to set up the architecture for your ML applications? <a href="https://datarevenue.com/en-contact">Schedule a call</a> with us.</p></div></div></div></div>]]>
            </description>
            <link>https://datarevenue.com/en-blog/machine-learning-project-architecture</link>
            <guid isPermaLink="false">hacker-news-small-sites-24150088</guid>
            <pubDate>Thu, 13 Aug 2020 22:07:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: 33% Memory Reduction by Reordering Struct Fields]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24149637">thread link</a>) | @lanecwagner
<br/>
August 13, 2020 | https://qvault.io/2020/08/07/saving-a-third-of-our-memory-by-re-ordering-go-struct-fields | <a href="https://web.archive.org/web/*/https://qvault.io/2020/08/07/saving-a-third-of-our-memory-by-re-ordering-go-struct-fields">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>In past projects at <a href="https://classroom.qvault.io/">Qvault</a> we had an application that typically ran with <strong>~2GB</strong> in memory at any given time. By simply changing the order of some <code>uint</code> variables we managed to drop the memory usage to less than <strong>1.4GB</strong>. The vast majority of this allocated memory is due to an enormous slice of <code>stats</code> structs.</p>



<p>The <code>stats</code> struct has the following type definition:</p>



<pre><code lang="go">type stats struct {
	NumPosts uint8
	Reach    uint16
	NumLikes uint8
}</code></pre>



<p>In theory, this struct will use a measly 4 bytes. Each <code>uint8</code> uses 1 <code>byte</code>, and the single <code>uint16</code> needs 2. We began to suspect that we had some wasteful memory issues, so I built the following little program to show how memory is being used by our struct:</p>



<pre><code lang="go">package main

import (
	"fmt"
	"reflect"
	"runtime"
)

type stats struct {
	NumPosts uint8
	Reach    uint16
	NumLikes uint8
}

func main() {
	typ := reflect.TypeOf(stats{})
	fmt.Printf("Struct is %d bytes long\n", typ.Size())
	n := typ.NumField()
	for i := 0; i &lt; n; i++ {
		field := typ.Field(i)
		fmt.Printf("%s at offset %v, size=%d, align=%d\n",
			field.Name, field.Offset, field.Type.Size(),
			field.Type.Align())
	}

	allStats := []stats{}
	for i := 0; i &lt; 100000000; i++ {
		allStats = append(allStats, stats{})
	}

	printMemUsage()
}

func printMemUsage() {
	var m runtime.MemStats
	runtime.ReadMemStats(&amp;m)
	fmt.Printf("Alloc = %v MiB", bToMb(m.Alloc))
	fmt.Printf("\tTotalAlloc = %v MiB", bToMb(m.TotalAlloc))
	fmt.Printf("\tSys = %v MiB", bToMb(m.Sys))
	fmt.Printf("\tNumGC = %v\n", m.NumGC)
}

func bToMb(b uint64) uint64 {
	return b / 1024 / 1024
}</code></pre>



<p>On my MacBook using Go 1.14.1 the above program prints:</p>



<pre><code lang="bash">Struct is 6 bytes long
NumPosts at offset 0, size=1, align=1
Reach at offset 2, size=2, align=2
NumLikes at offset 4, size=1, align=1
Alloc = 1084 MiB        TotalAlloc = 3012 MiB   Sys = 2713 MiB  NumGC = 19</code></pre>



<p>Notice that even though <code>NumPosts</code> only has a size of 1 byte, the next field, <code>Reach</code>, still starts at offset 2. A whole byte is being wasted! The same thing happens with the <code>NumLikes</code> field, it starts at offset 4 with a size of 1, but the struct still takes up the full 6 bytes.</p>



<p>This may not seem like a big deal, but when you are storing millions of these structs in memory the bloat starts to add up quick.</p>



<p>If we change the <code>stats</code> struct such that the <code>uint16</code> isn’t defined between the <code>uint8</code>s:</p>



<pre><code lang="go">type stats struct {
	Reach    uint16
	NumPosts uint8
	NumLikes uint8
}</code></pre>



<p>Then the output of the program becomes:</p>



<pre><code lang="bash">Struct is 4 bytes long
Reach at offset 0, size=2, align=2
NumPosts at offset 2, size=1, align=1
NumLikes at offset 3, size=1, align=1
Alloc = 694 MiB TotalAlloc = 1927 MiB   Sys = 1391 MiB  NumGC = 19</code></pre>



<p>The total allocated memory drops from 3 GB to less than 2, and each instance of the struct now only uses 4 bytes.</p>



<h2>Why?</h2>



<p>Modern CPU hardware performs reads and writes to memory most efficiently when the data is&nbsp;<em><a href="https://en.wikipedia.org/wiki/Data_structure_alignment" target="_blank" rel="noreferrer noopener">naturally aligned</a></em>. The memory that is stored side by side should be accessible using a common multiple, so the Go compiler makes sure that it is.</p>



<p>With our first struct, the Reach field is between the NumPosts and NumLikes fields, which means that the compiler will add some padding to keep things nice and even. </p>



<figure><img loading="lazy" width="1024" height="645" src="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-1024x645.png" alt="golang memory usage struct alignment" srcset="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-1024x645.png 1024w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-300x189.png 300w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-768x484.png 768w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM.png 1194w" sizes="(max-width: 1024px) 100vw, 1024px" title="Screen Shot 2020 08 07 at 2.51.09 PM"></figure>



<p>In our updated struct however, we have grouped the smaller fields, and since they add up to the same amount of memory as the larger <code>Reach</code> field we can save some space!</p>



<figure><img loading="lazy" width="1024" height="624" src="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-1024x624.png" alt="golang memory usage struct alignment fixed" srcset="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-1024x624.png 1024w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-300x183.png 300w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-768x468.png 768w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM.png 1178w" sizes="(max-width: 1024px) 100vw, 1024px" title="Screen Shot 2020 08 07 at 2.54.26 PM"></figure>



<p>This was is a weird quirk, but making the smal optimizations has made a huge impact on some of our services.</p>



<div><div>
<h2>Thanks For Reading!</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault" rel="noopener">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe" rel="noopener">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>

		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/08/07/saving-a-third-of-our-memory-by-re-ordering-go-struct-fields</link>
            <guid isPermaLink="false">hacker-news-small-sites-24149637</guid>
            <pubDate>Thu, 13 Aug 2020 21:34:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Knurling-Rs Announcement]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24149469">thread link</a>) | @lukastyrychtr
<br/>
August 13, 2020 | https://ferrous-systems.com/blog/knurling-rs/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/knurling-rs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://ferrous-systems.com/images/knurling-rs.png" alt="Knurling-rs"></p>

<p>Today we're announcing <a href="https://github.com/knurling-rs">Knurling</a> - Ferrous' effort to sustainably build better tooling for developing and debugging Rust software for embedded systems.</p>

<p>To make this a reality, we are opening a <a href="https://github.com/knurling-rs/meta">GitHub organization</a> to collect these efforts, as well as making it possible to <a href="https://github.com/sponsors/knurling-rs">support our efforts through GitHub Sponsors</a>.</p>

<h2 id="the-mission">The Mission</h2>

<p>We believe that developing software for embedded systems should be no more difficult than developing for hosted platforms. It should be possible to use the same workflows and equally powerful tooling to develop applications and libraries for tiny embedded systems as well as server-class hardware.</p>

<p>To that end, we want to enable:</p>

<ul>
  <li>Learning embedded Rust with up to date and maintained teaching material</li>
  <li>Space-efficient and real-time capable logging</li>
  <li>Tools that integrate into your standard cargo run and cargo test workflows</li>
  <li>Execution tracing</li>
  <li>Simple data logging and visualization straight into your IDE or Browser</li>
</ul>

<p>We are already active contributors in the open source ecosystem, but we want to spend more time dedicated to building tools that improve the experience for the entire ecosystem, and we can't do that without <a href="https://github.com/sponsors/knurling-rs">your support</a>.</p>

<h2 id="release-model">Release Model</h2>

<p>We plan to make everything we develop under Knurling to be open source, in order to support the community. This includes all of the tooling, teaching material, and support libraries we develop.</p>

<p>The items we release will all be under <a href="https://opensource.org/licenses/MIT">MIT</a>+<a href="https://www.apache.org/licenses/LICENSE-2.0.html">Apache 2.0</a> licenses for code, and <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC-BY-SA 4.0</a> for written material.</p>

<p>Sponsors will also have early access to work in progress tools and libraries before they are released, as well as early access to our training material and exercises before they are made public.</p>

<p>Early Access is available for all sponsors, regardless of tier.</p>

<p>Let's take a quick tour of the things we plan to make possible with <a href="https://github.com/knurling-rs/meta">Knurling</a>:</p>



<blockquote>
  <p>EDIT: This blog post has been updated to reflect the rename of <code>binfmt</code> to <code>defmt</code>.</p>
</blockquote>

<p><img src="https://ferrous-systems.com/images/defmt-teaser.jpg" alt="defmt preview"></p>

<p>We'd like to spend time to make it easier to design, build, debug, and release software components with embedded Rust. This includes developing target-side libraries, as well as host-side applications that interact with these components.</p>

<p>We also want to make it possible to have best-in-class debugging tools, allowing you to monitor, graph, and visualize what your system is doing. We think that it's possible to make developing embedded systems painless through better and extensible tooling!</p>

<p>The first of these tools we plan to release is <code>defmt</code> (in the screenshot above), a tool for efficient logging and tracing in real-time, using a variety of different transport methods like Semihosting, RTT, or even a UART or radio. <code>defmt</code> will allow for logging of data without incurring expensive formatting costs on the device itself.</p>

<p>We'll be talking more about defmt next week on our blog, but you can check it out now if you <a href="https://github.com/sponsors/knurling-rs">become a sponsor today</a>!</p>

<h2 id="more-training-and-learning-examples">More Training and Learning Examples</h2>

<p><img src="https://ferrous-systems.com/images/emb-trainings.png" alt="embedded trainings"></p>

<p>We're already developing open source training material for embedded systems in Rust, including our training material for <a href="https://github.com/ferrous-systems/teaching-material/">basic Rust training</a>, the material for our <a href="https://github.com/ferrous-systems/embedded-trainings">2019 Embedded Trainings</a>, as well as our most recent <a href="https://github.com/ferrous-systems/embedded-trainings-2020">2020 Embedded Trainings</a>.</p>

<p>We plan to develop a new, continuously maintained set of training material that consists of two parts:</p>

<p>The first part is <strong>Knurling Books</strong>, which are written guides that teach general concepts of embedded systems and Rust, and come with associated sample projects demonstrating the concepts. This is a great place for folks to learn embedded systems or embedded systems with Rust!</p>

<p>The second part is <strong>Knurling Sessions</strong>, which are quarterly embedded projects that explore specific projects using generally available hardware, building full systems and components using microcontrollers, sensors, and actuators.</p>

<p>These will be guided, hands-on tutorials for building projects like a CO2 Sensor, Data Loggers, and even robots! For folks that want to learn in a more hands-on way, or want to know "what hardware should I buy to get started", Knurling Sessions are a great option!</p>

<p>Before each session, we'll announce the hardware we'll use and how we'll use it. If you want to follow along and build the project at home, we'll include links to purchase the hardware. We'll reuse components session to session, so you can start building your own collection of parts!</p>

<p>In the future, we plan to also offer video based training and Q&amp;A sessions where we explore the concepts in a deeper and more detailed way, great for learning how and why things are built.</p>

<p>As we mentioned, all of the <strong>Knurling Books</strong> and <strong>Knurling Sessions</strong> will be made public and open source, but <a href="https://github.com/sponsors/knurling-rs">Sponsors</a> will get early access to both!</p>

<p>We'll be announcing our first training books and sessions later in August, so stay tuned!</p>

<h2 id="more-experiments-and-ecosystem-improvements">More Experiments and Ecosystem Improvements</h2>

<p><img src="https://ferrous-systems.com/images/async-on-embedded.png" alt="async on embedded"></p>

<p>In the past, we've done a number of experiments and improvements towards the Rust and Rust Embedded ecosystems. Most recently, we <a href="https://ferrous-systems.com/blog/embedded-async-await/">wrote about</a> making <a href="https://ferrous-systems.com/blog/async-on-embedded/">async/await</a> possible <a href="https://ferrous-systems.com/blog/stable-async-on-embedded/">for embedded systems</a>, and were even able to contribute optimizations that sped up compilation and run time for all users of async/await!</p>

<p>We released these experiments as <a href="https://github.com/ferrous-systems/async-on-embedded">an open source project</a>, and it has already been <a href="https://github.com/rust-embedded-community/async-on-embedded">transferred to community ownership</a>.</p>

<p>We'd like to dedicate more time to these kinds of projects, exploring what could be possible with embedded Rust, bringing crates to a maintained 1.0 status, or improving the compiler to benefit embedded systems developers. You can help us make this happen by <a href="https://github.com/sponsors/knurling-rs">sponsoring our efforts</a>!</p>

<h2 id="thank-you-all">Thank you all!</h2>

<p>We think the embedded Rust ecosystem is already the best way to develop embedded software today, but we can make it even better and easier, whether you are a developer who has never touched a microcontroller before, or you are a developer that is already an expert in embedded Rust.</p>

<p>If you'd like to support these works as an individual or through your company, we'd <a href="https://github.com/sponsors/knurling-rs">appreciate it a lot</a>! If you're interested in more details, or there is something you'd like to see us do, <a href="mailto:knurling@ferrous-systems.com">just drop us an email</a>!</p>
</div></div>]]>
            </description>
            <link>https://ferrous-systems.com/blog/knurling-rs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24149469</guid>
            <pubDate>Thu, 13 Aug 2020 21:24:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Future of Automation: The End of Silos and Rise of Workflows]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24148532">thread link</a>) | @omi1997
<br/>
August 13, 2020 | https://cto.ai/blog/the-future-of-automation-the-end-of-silos-rise-of-workflows/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/the-future-of-automation-the-end-of-silos-rise-of-workflows/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<p>Tooling has always been a strategically important method for engineering teams to bolster efficiency. The latest research by <a href="https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/developer-velocity-how-software-excellence-fuels-business-performance?cid=soc-app">McKinsey &amp; Company</a>, where 440 senior engineering executives were surveyed, demonstrates that companies are 65% likely to be more innovative with better tooling. </p><p>There’s nothing new here, engineers have always looked at tooling as a source for automation. But with the report revealing that only 5% of executives listed tooling a top three method for software enablement. With technologies rapidly rising and falling, software companies need to be leaner than ever in their adoption of automation tools. </p><p>To master this accelerating shift, technical leaders need to look at automation adoption beyond engineering departments and view the software delivery process as a cross-departmental effort. If you’re one of the many forward-looking technical leads hoping to gain strategic advantages, here’s how to ensure automation success. </p><h2 id="devops-today-and-the-automation-of-tomorrow">DevOps Today and the Automation of Tomorrow</h2><p>Traditionally, the developer tooling market has always been geared towards engineers, where DevOps specialists would craft automation, pipelines, and processes by integrating different technologies for the developer, and the graphic below shows the current tools out there.</p><!--kg-card-begin: image--><figure><img src="https://lh3.googleusercontent.com/rT9GfCt5hb7rwD2AC_bDeFI-pDxKlW8a7SZ8MSQYywCh0hNXj8UxXfs7ZmEpEPeoMB5tWFsxgBr_UpjJrSfroqayELR9eVfvWco1bjr-jOH6P4-zF-Ct97DGJjmjD4cMSzveToM7"></figure><!--kg-card-end: image--><p>In essence, the automation that the tools above provide was built with developers in mind as the end-user. The end result yields greater developer satisfaction, as their talent and imagination are given the means to shine. </p><p>As evidenced by the <a href="https://services.google.com/fh/files/misc/state-of-devops-2019.pdf">2019 State of DevOps reports</a>, the software industry values speed and automation of delivery and tasks, and the report, in particular, asserts that strong tool-chains give developers a culture of “psychological safety,” effectively bolstering team productivity. With <a href="https://stripe.com/en-ca/reports/developer-coefficient-2018">$300 billion being lost annually in developer productivity</a>, we can see a real opportunity for automation to keep saving developers, and the overall business, precious time. </p><h2 id="a-movement-to-workflows">A Movement to Workflows</h2><p>There’s already been a movement in the software industry to streamline processes with automation. For example, GitOps is streamlining source control by tightly integrating it with CI/CD. But that just doesn’t go far enough. As the developer tooling market grows, more and more tools are now required to be integrated into the software delivery process, causing greater market fragmentation. Companies like Salesforce are even launching their own DevOps platforms, meaning vendor-specific integration is more of a challenge than ever before for DevOps teams who are looking to streamline their delivery across their technology portfolio.</p><p>So, as business toolchains grow, it has become more critical than ever to eliminate silos of automation creation and empower other functions across the business, especially that outside of engineering, to be able to automate on their own. Essentially the cost of automation ownership must be lowered to allow for a more frictionless process for automation to take place. In this scenario, we see the rise of the workflow – a set of tasks and processes whereby multiple tools can be seamlessly integrated. As such, businesses must see automation outside the lens of engineering, and look to democratize its extraordinary benefits across the entire business to other departments.</p><p>A great example of a company lowering the barriers to automation is Atlassian. The company announced a <a href="https://www.computerworld.com/article/3532328/atlassian-adds-no-code-automation-to-jira-cloud-products.html">no-code workflow creator</a> for any user across it’s Jira Cloud portfolio. &nbsp; </p><p>In parallel, an interesting insight provided by McKinsey, which was missing from other reports, is the growing benefits of low-code tools. The study reveals that low-code tools help organizations adopt automation advantages at a much lower cost of ownership and allow them to exponentially increase their leverage on their development talent. The study observed that teams were able to adopt automation much faster when the barrier to automation (i.e. code complexity) is lowered. This makes automation accessible to less technical team members and enhances self-service and cross-functional accessibility to automation through workflows that they can create to their own needs. </p><p>At CTO.ai, we rethought automation from the bottom up to address these challenges. We realized that the most obvious solution was not only to lower the cost of automation through low code, but also to bring these developer tools to the place where people meet across the entire organization – Slack – and more specifically, SlackOps or DevOps in Slack (often more generally called ChatOps in the industry).</p><p>We further realized that businesses need an easy platform that all employees can leverage. By bringing the ease of chat and automation in a shared and transparent environment such as Slack, there’s an opportunity for businesses to significantly reduce inefficiencies and turbocharge productivity. </p><h2 id="a-brave-new-automation">A Brave New Automation</h2><p>With automation changing form, there will be winners and losers concerning how businesses approach the new world we’re entering. Businesses that are unwilling to begin implementing changes in their software development tooling and wider business access to workflow creation will be left behind. </p><p>For technical leadership, this is an opportunity to export engineering-based concepts and ideas such as CI/CD, automation testing, and more to other departments. Engineering departments have, generally speaking, long been ahead of other departments in regards to optimization, and use of automation. After all, engineers can code, but other departments don’t have such requirements in their job descriptions. </p><p>We at CTO.ai continue to advocate for greater use of automation for DevOps and all departments. As we continue to iterate our cutting-edge technology for Slack workflows (SlackOps), not only does the rise of the workflow become an important factor in the accessibility of automation, but also the measurement of workflow efficacy becomes even more critical. As such, companies need to be cognizant of their workflow efficacy and therefore must continue to ever optimize for scale. This is why we’re also introducing a Workflow Metrics MVP, the first-concept measurement of workflow efficiency.</p><p><em>Want to see our private demo? Contact us by<a href="https://w.cto.ai/contact-us"> clicking here </a>to see the private Alpha of the MVP.</em></p>
			</div><!-- .post-content -->
			<!-- .post-footer -->
		</article></div>]]>
            </description>
            <link>https://cto.ai/blog/the-future-of-automation-the-end-of-silos-rise-of-workflows/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148532</guid>
            <pubDate>Thu, 13 Aug 2020 20:31:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Internationalization and Localization Matters]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148141">thread link</a>) | @gsilva49
<br/>
August 13, 2020 | https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html | <a href="https://web.archive.org/web/*/https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>According to the always trustworthy Wikipedia, there are approximately 360 million native English speakers in the world. We, as developers, are so used to write code and documentation in English that we may not realize that this number only represents 4.67% of the world population. It is very useful to have a common language for the communication between developers, but this doesn’t mean that the user shouldn’t feel a little bit more comfortable when using your product.</p>
<p>This post will start discussing the definition of internationalization and localization and why they matter for your application. Then we will go over some of the internationalization tools that developers have available to work on their Python and Django projects. Finally, we will present how we had to adapt our development flow to incorporate the internationalization step.</p>
<h2>Localization vs Internationalization</h2>
<p><strong>Localization (l10n</strong><sup id="fnref:1"><a href="#fn:1">1</a></sup><strong>)</strong> is the process of adapting an application, product or even a document to be more user-friendly to customers from different countries and cultures.</p>
<p>On the other hand, <strong>internationalization (i18n)</strong> is the process of enabling localization of the product on the application. Implementing a software in a way that it will know when and how to show different content depending on the costumer’s locale.</p>
<p>As the Django documentation perfectly summarizes: localization is done by translators and internationalization is done by developers<sup id="fnref:2"><a href="#fn:2">2</a></sup></p>
<p>However, this simplified definition of internationalization and localization may give the wrong impression that this is just about translation. This process entails several other adaptations needed to make users from different cultures feel more comfortable using your product, such as:</p>
<ul>
<li>Date and currency formatting</li>
<li>Currency conversion</li>
<li>Units of measurement conversion</li>
<li>Unicode characters and bidirectional text (see example below)</li>
<li>Time zones, calendar and special holidays</li>
</ul>
<p><img alt="Wikipedia homepage in English" src="https://labcodes.com.br/blog/images/internationalization/wikipedia_english.png">
<em>Wikipedia homepage in English</em></p>
<p><img alt="Wikipedia homepage in Arabic" src="https://labcodes.com.br/blog/images/internationalization/wikipedia_arabic.png">
<em>Wikipedia homepage in Arabic</em></p>
<p>With these adaptations, we can provide a better experience for the customer when using the application.</p>
<h2>How can we do that in Python?</h2>
<h3>GNU gettext</h3>
<p>There are some tools that can help localize your Python application. Starting with the GNU gettext package that is part of the Translation Project<sup id="fnref:3"><a href="#fn:3">3</a></sup>. This package offers:</p>
<ul>
<li>A runtime library that supports the retrieval of translated messages.</li>
<li>A set of conventions about how programs should be written to support message catalogs.</li>
<li>A library supporting the parsing and creation of files containing translated messages.</li>
</ul>
<p>The following code snippet is just a simple Hello World, a <code>app.py</code> file, where we are using the <code>gettext</code> Python module to create a translation object (<code>gettext.translation</code>) for our app domain, specifying a locale directory and the language that we want to translate our strings to. Then, we assign the gettext function to an underscore (a common practice to reduce the overhead of typing <code>gettext</code> for each translatable string) and, finally, we flag the string <code>“Hello World!”</code> to be translated.</p>
<div><pre><span></span><span>import</span> <span>gettext</span>

<span>gettext</span><span>.</span><span>bindtextdomain</span><span>(</span><span>"app"</span><span>,</span> <span>"/locale"</span><span>)</span>
<span>gettext</span><span>.</span><span>textdomain</span><span>(</span><span>"app"</span><span>)</span>
<span>t</span> <span>=</span> <span>gettext</span><span>.</span><span>translation</span><span>(</span><span>"app"</span><span>,</span> <span>localedir</span><span>=</span><span>"locale"</span><span>,</span> <span>languages</span><span>=</span><span>[</span><span>'en_US'</span><span>])</span>
<span>t</span><span>.</span><span>install</span><span>()</span>
<span>_</span> <span>=</span> <span>t</span><span>.</span><span>gettext</span>

<span>greeting</span> <span>=</span> <span>_</span><span>(</span><span>"Hello, world!"</span><span>)</span>
<span>print</span><span>(</span><span>greeting</span><span>)</span>
</pre></div>


<p>After flagging the translatable strings in the code, we can collect them using the GNU <code>xgettext</code> CLI tool. This tool generates a PO file containing all the strings that we have flagged.</p>
<p><code>xgettext -d app app.py</code></p>
<p>The PO file (which stands for Portable Object file) contains a list of entries and here is the basic structure of an entry:</p>
<div><pre><span></span>#  translator-comments
#. extracted-comments
#: reference…
#, flag…
#| msgid previous-untranslated-string
msgid untranslated-string
msgstr translated-string
</pre></div>


<p>We can add comments for translators, some references and flags for the string. Then we have the <strong>entry ID</strong> (<code>msgid</code>), which is the untranslated string flagged in the code and the <strong>entry string</strong> (<code>msgstr</code>) representing the translated version of the string.</p>
<p>When we run <code>xgettext</code> in the command line passing the <code>app.py</code> as input file, this is the PO file that is generated:</p>
<div><pre><span></span><span>"Project-Id-Version: PACKAGE VERSION\n"</span>
<span>"Report-Msgid-Bugs-To: \n"</span>
<span>"POT-Creation-Date: 2019-05-03 13:23-0300\n"</span>
<span>"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"</span>
<span>"Last-Translator: FULL NAME &lt;EMAIL@ADDRESS&gt;\n"</span>
<span>"Language-Team: LANGUAGE &lt;LL@li.org&gt;\n"</span>
<span>"Language: \n"</span>
<span>"MIME-Version: 1.0\n"</span>
<span>"Content-Type: text/plain; charset=UTF-8\n"</span>
<span>"Content-Transfer-Encoding: 8bit\n"</span>

<span>#</span><span>:</span> <span>app</span><span>.</span><span>py</span><span>:</span><span>7</span>
<span>msgid</span> <span>"Hello, world!"</span>
<span>msgstr</span> <span>""</span>
</pre></div>


<p>At the top of the file, we have some metadata about the file, the project and the translation process. Then, we have the untranslated string "Hello, world!" as the <strong>entry ID</strong> and an empty string for the <strong>entry string</strong>. If no translated string is provided for a certain entry, the entry ID will be used in the translation.</p>
<p>Once the PO file is generated, we can start translating our terms to different languages. It is important to notice that the GNU gettext library is going to look for translated PO files in a specific folder path structure (<code>&lt;localedir&gt;/&lt;language_code&gt;/LC_MESSAGES/&lt;domain&gt;.po</code>) and there must be one PO file for each language that you want to support.</p>
<div><pre><span></span>|-- app.py
|-- locale
   |-- en_US
   |   |-- LC_MESSAGES
   |       |-- app.po
   |-- pt_BR
       |-- LC_MESSAGES
       |   |-- app.po
</pre></div>


<p>Here is an example of the same PO file translated to Portuguese:</p>
<div><pre><span></span><span>"Project-Id-Version: PACKAGE VERSION\n"</span>
<span>"Report-Msgid-Bugs-To: \n"</span>
<span>"POT-Creation-Date: 2019-05-03 13:23-0300\n"</span>
<span>"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"</span>
<span>"Last-Translator: FULL NAME &lt;EMAIL@ADDRESS&gt;\n"</span>
<span>"Language-Team: LANGUAGE &lt;LL@li.org&gt;\n"</span>
<span>"Language: \n"</span>
<span>"MIME-Version: 1.0\n"</span>
<span>"Content-Type: text/plain; charset=UTF-8\n"</span>
<span>"Content-Transfer-Encoding: 8bit\n"</span>

<span>#</span><span>:</span> <span>app</span><span>.</span><span>py</span><span>:</span><span>7</span>
<span>msgid</span> <span>"Hello, world!"</span>
<span>msgstr</span> <span>"Olá, mundo!"</span>
</pre></div>


<p>In order to use the translated strings in the code, we need to compile the PO file into MO file using the <code>msgfmt</code> command.</p>
<p><code>msgfmt -o app.mo app.po</code></p>
<p>With the MO file in place, it is possible to change the language of the program to Portuguese in the languages input for the translation function. If we run the following code, the flagged string will get translated to “Olá, mundo!”:</p>
<div><pre><span></span><span>import</span> <span>gettext</span>

<span>gettext</span><span>.</span><span>bindtextdomain</span><span>(</span><span>"app"</span><span>,</span> <span>"/locale"</span><span>)</span>
<span>gettext</span><span>.</span><span>textdomain</span><span>(</span><span>"app"</span><span>)</span>
<span>t</span> <span>=</span> <span>gettext</span><span>.</span><span>translation</span><span>(</span><span>"app"</span><span>,</span> <span>localedir</span><span>=</span><span>"locale"</span><span>,</span> <span>languages</span><span>=</span><span>[</span><span>'pt_BR'</span><span>])</span>
<span>t</span><span>.</span><span>install</span><span>()</span>
<span>_</span> <span>=</span> <span>t</span><span>.</span><span>gettext</span>

<span>greeting</span> <span>=</span> <span>_</span><span>(</span><span>"Hello, world!"</span><span>)</span>
<span>print</span><span>(</span><span>greeting</span><span>)</span>
</pre></div>


<h3>Locale Module</h3>
<p>This module has access to POSIX locale database and is specially useful for handling dates, numbers and currencies format. The following example shows how to use the Locale library:</p>
<div><pre><span></span><span>import</span> <span>datetime</span>
<span>import</span> <span>locale</span>

<span>locale</span><span>.</span><span>setlocale</span><span>(</span><span>locale</span><span>.</span><span>LC_ALL</span><span>,</span> <span>locale</span><span>=</span><span>'en_US'</span><span>)</span>
<span>local_conv</span> <span>=</span> <span>locale</span><span>.</span><span>localeconv</span><span>()</span>
<span>now</span> <span>=</span> <span>datetime</span><span>.</span><span>datetime</span><span>.</span><span>now</span><span>()</span>
<span>some_price</span> <span>=</span> <span>1234567.89</span>
<span>formatted_price</span> <span>=</span> <span>locale</span><span>.</span><span>format</span><span>(</span><span>'</span><span>%1.2f</span><span>'</span><span>,</span> <span>some_price</span><span>,</span> <span>grouping</span><span>=</span><span>True</span><span>)</span>
<span>currency_symbol</span> <span>=</span> <span>local_conv</span><span>[</span><span>'currency_symbol'</span><span>]</span>

<span>print</span><span>(</span><span>now</span><span>.</span><span>strftime</span><span>(</span><span>'</span><span>%x</span><span>'</span><span>))</span>
<span>print</span><span>(</span><span>f</span><span>'{currency_symbol}{formatted_price}'</span><span>)</span>
</pre></div>


<p>In this example, we are importing the module, changing all locale settings to US English and retrieving the locale conventions. Using the <code>locale.format</code> method, we can format the number without worrying about decimal and thousands separator symbols. Using the <code>%x</code> directive to format the date, it will display day, month and year in the correct order for the locale. From the locale conventions, we are able to get the correct currency symbol.</p>
<p>This is the output of that Python code. We can see that the date is following the format of <code>Month/Day/Year</code>, tthe decimal separator is a dot while the thousands separator is a comma and there is a dollar sign to represent US currency.</p>
<div><pre><span></span>$ python format_example.py
<span>05</span>/03/2019
<span>$1</span>,234,567.89
</pre></div>


<p>Now using the same code, just changing the locale to Portuguese Brazil, we get a different output based on Brazilians conventions for formatting: the date is following <code>Day/Month/Year</code> format, we have comma as the decimal separator, dots as thousands separator and the R$ symbol to represent Brazilian currency Real.</p>
<div><pre><span></span><span>import</span> <span>datetime</span>
<span>import</span> <span>locale</span>

<span>locale</span><span>.</span><span>setlocale</span><span>(</span><span>locale</span><span>.</span><span>LC_ALL</span><span>,</span> <span>locale</span><span>=</span><span>'pt_BR'</span><span>)</span>
<span>local_conv</span> <span>=</span> <span>locale</span><span>.</span><span>localeconv</span><span>()</span>
<span>now</span> <span>=</span> <span>datetime</span><span>.</span><span>datetime</span><span>.</span><span>now</span><span>()</span>
<span>some_price</span> <span>=</span> <span>1234567.89</span>
<span>formatted_price</span> <span>=</span> <span>locale</span><span>.</span><span>format</span><span>(</span><span>'</span><span>%1.2f</span><span>'</span><span>,</span> <span>some_price</span><span>,</span> <span>grouping</span><span>=</span><span>True</span><span>)</span>
<span>currency_symbol</span> <span>=</span> <span>local_conv</span><span>[</span><span>'currency_symbol'</span><span>]</span>

<span>print</span><span>(</span><span>now</span><span>.</span><span>strftime</span><span>(</span><span>'</span><span>%x</span><span>'</span><span>))</span>
<span>print</span><span>(</span><span>f</span><span>'{currency_symbol}{formatted_price}'</span><span>)</span>
</pre></div>


<div><pre><span></span>$ python format_example.py
<span>03</span>/05/2019
R<span>$1</span>.234.567,89
</pre></div>


<h2>Does it get easier with Django?</h2>
<h3>Translations and Formatting</h3>
<p>Internationalization is enabled by default when you create your Django project. The translation module encapsulates the GNU library and provides the <code>gettext</code> function with translation setup based on the language received in the <strong>Accept-Language</strong> header, that is passed by the browser in the request object. So, all that Python code that we saw before is encapsulated in the django utils translation module so we can jump ahead and just use the gettext function in our view:</p>
<div><pre><span></span><span>from</span> <span>django.http</span> <span>import</span> <span>HttpResponse</span>
<span>from</span> <span>django.utils.translation</span> <span>import</span> <span>gettext</span> <span>as</span> <span>_</span>

<span>def</span> <span>my_view</span><span>(</span><span>request</span><span>):</span>
    <span>greetings</span> <span>=</span> <span>_</span><span>(</span><span>'Hello, World!'</span><span>)</span>
    <span>return</span> <span>HttpResponse</span><span>(</span><span>greetings</span><span>)</span>
</pre></div>


<p>For translations, we can flag translatable strings in both Python and template code (once we load the internationalization tags). The <code>trans</code> template tag translates a single string, while <code>blocktrans</code> tag is able to mark as translatable a block of strings, including variable content.</p>
<div><pre><span></span><span>&lt;</span><span>p</span><span>&gt;</span>{% trans "Hello, World!" %}<span>&lt;/</span><span>p</span><span>&gt;</span>
<span>&lt;</span><span>p</span><span>&gt;</span>{% blocktrans %}This string will have {{ value }} inside.{% endblocktrans %}<span>&lt;/</span><span>p</span><span>&gt;</span>
</pre></div>


<p>Besides the standard <code>gettext</code> function, in Django we can have lazy translations: the flagged string will only be translated when the value is used in a string context, such as in template rendering. This is specially useful for translating <code>help_text</code> and <code>verbose_name</code> attributes in the Django models.</p>
<p>Regarding GNU command line interface, django admin provides equivalent commands for the ones most used in the development process. To …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html">https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html</a></em></p>]]>
            </description>
            <link>https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148141</guid>
            <pubDate>Thu, 13 Aug 2020 20:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research Says Solo Founders Perform Better]]>
            </title>
            <description>
<![CDATA[
Score 218 | Comments 125 (<a href="https://news.ycombinator.com/item?id=24148113">thread link</a>) | @rmason
<br/>
August 13, 2020 | https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why | <a href="https://web.archive.org/web/*/https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-68erk"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label=""><p><img data-pin-url="https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why" data-pin-media="https://static.wixstatic.com/media/49c34c_add7b504cfd8464abddc1602dcb09c96~mv2.jpg/v1/fit/w_3508,h_1981,al_c,q_80/file.png" src="https://static.wixstatic.com/media/49c34c_add7b504cfd8464abddc1602dcb09c96~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt=""></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div><p><span>Better to be a Han Solo in startups? Credit: deviantart.com/dzikawa</span></p></div></div></div><p id="viewer-9t57p">A recent <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3107898" target="_blank" rel="noopener"><u>study</u></a> suggests that: </p><blockquote id="viewer-ah7c2">"Solo founders are <!-- -->more than twice as likely to own an ongoing, for-profit venture than two or more founders". </blockquote><p id="viewer-c6nq5">Or to put it in other words, ventures with solo founders are twice as likely to be profitable than ventures with 2 or more founders. See the graph below.</p><div id="viewer-5g984"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why" data-pin-media="https://static.wixstatic.com/media/49c34c_46bd6f501d98445cb0381d51c061589d~mv2.png/v1/fit/w_2560,h_1280,al_c,q_80/file.png" src="https://static.wixstatic.com/media/49c34c_46bd6f501d98445cb0381d51c061589d~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-bd3ie">How can that be true? And what could be the dangers of being a solopreneur that founders should watch out for? Let us explore!</p><h2 id="viewer-674bv">Why solo is better</h2><p id="viewer-bhfs4">As much as it may feel scary to go alone, there are good reasons to consider building a business alone, especially if you are spending a lot of time finding a co-founder.</p><h3 id="viewer-addh7">Reason #1: Speed</h3><p id="viewer-3mptm">As the famous African proverb goes, “If you want to go fast, go alone. If you want to go far, go together.” Solo founders move faster since they don't need to worry about the team alignment on every decision. And being fast can be argued to be the biggest advantage for a startup.</p><h3 id="viewer-d4jnc">Reason #2: Founder disagreements</h3><p id="viewer-bsbd7"><a href="https://www.cbinsights.com/research/startup-failure-reasons-top/#:~:text=Not%20pivoting%20away%20or%20quickly,by%20a%20lack%20of%20progress" target="_blank" rel="noopener"><u>Top 3 reason</u></a><u>s</u> why startups fail is the founder team in-fighting. Sounds wrong to say this, but no co-founders - no problems.</p><h3 id="viewer-8l2gn">Reason #3: Lower costs</h3><p id="viewer-6jfou">It seems like there is no big difference between one person on the team and three, but at the early stage, even small differences matter a lot. Whether you need an office, and how many salaries you need to pay are all crucial questions at the start.</p><h3 id="viewer-6su88">Reason #4: Taking risks</h3><p id="viewer-bg12b">Founding a startup is a big risk. Three people who've already sacrificed quite a bit tend to be more risk-averse and the chances of someone choosing the safer path are higher. </p><h2 id="viewer-f2gim">The dangers of going solo</h2><p id="viewer-fuou5">We will be honest - going solo is not for everyone. Consider the following dangers:</p><h3 id="viewer-3t7ks">Danger #1: Funding</h3><p id="viewer-cdd78">It's the sad truth that due to Y Combinator and Paul Graham's gospel, the Zeitgeist of our times is that being a solo founder means that you just couldn't convince your friends to join and therefore can't be trusted. Solo founders tend to receive considerably less funding, yet it could also play to their advantage, allow them to grow more organically and make fewer stupid mistakes.</p><h3 id="viewer-50pot">Danger #2: Lack of support </h3><p id="viewer-cte29">Loneliness and depression hit entrepreneurs harder and solo founders harder still. Solo founders might also miss on diverse perspectives. I would advise solo founders to get something called a hands-on advisor or joining a supportive community of solo founders like <a href="https://www.growthclub.online/?utm_source=growthclub&amp;utm_medium=solo_vs_team_article_body&amp;utm_campaign=content_promo" target="_blank" rel="noopener"><u>GrowthClub</u></a>. Both of those options are described in <a href="https://www.growthclub.online/post/advice-for-solo-founders?utm_source=growthclub&amp;utm_medium=solo_vs_team_article_body&amp;utm_campaign=content_promo" target="_blank" rel="noopener"><u>my previous article</u></a>.</p><h2 id="viewer-7kknt">In sum  </h2><p id="viewer-9mv3p">Solopreneurs move faster, avoid the drama of teams falling apart, reduce costs by default, and have an easier time taking risks. That being said, they should be aware of fewer funding opportunities and build their own support system.</p><p id="viewer-4an2c">Thanks for sticking till the end! I am a hands-on advisor at<a href="https://www.growthclub.online/?utm_source=growthclub&amp;utm_medium=solo_vs_team_article_footer&amp;utm_campaign=content_promo" target="_blank" rel="noopener"> <!-- -->GrowthClub</a>. GrowthClub is a community of founders with $5K+ MRR where founders exchange growth hacks and build genuine connections in 1-on-1 video calls.</p><p id="viewer-f6iut">I started with GrowthClub as a user. I liked it so much that I ended up helping the founder. Currently, after experiencing a great inflow of founders from our launch on <a href="https://www.producthunt.com/posts/growthclub" target="_blank" rel="noopener"><u>Product Hunt</u></a> and Indie Hackers <a href="https://www.indiehackers.com/post/community-the-new-business-model-for-indie-hackers-01908d3dc3" target="_blank" rel="noopener"><u>featured article</u></a>, we are signing up 30 hand-picked founders to form the core of our platform to actively iterate the product with them.</p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148113</guid>
            <pubDate>Thu, 13 Aug 2020 20:12:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comfortable C while Editing with Emacs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148112">thread link</a>) | @daptaq
<br/>
August 13, 2020 | https://zge.us.to/txt/emacs-c.html | <a href="https://web.archive.org/web/*/https://zge.us.to/txt/emacs-c.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://zge.us.to/txt/emacs-c.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148112</guid>
            <pubDate>Thu, 13 Aug 2020 20:12:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In search of the perfect pocket device]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148036">thread link</a>) | @todsacerdoti
<br/>
August 13, 2020 | https://isene.org/2020/08/Nerding.html | <a href="https://web.archive.org/web/*/https://isene.org/2020/08/Nerding.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>In my lock-down geekery, I have been searching for the perfect pocket computer setup.</p>

<p>Having been an <a href="https://youtu.be/czzuz1j364E">HP calculator collector</a> since a couple of decades, I have a passion for pocket computing power with really long battery life.</p>

<p>The <a href="https://isene.org/hp-41/">HP-41</a> is an amazing calculator with months of battery life. But it is still a calculator. I also want real computing power - with the ability to run <a href="https://en.wikipedia.org/wiki/Vim_(text_editor)">VIM</a> for editing text (with a decent keyboard) and as much of other goodies as I can cram into it.</p>

<p><img src="https://isene.org/assets/posts/nerdvana.png" alt=""></p>

<p>I started my quest for the perfect pocket computer with reviving my old <a href="https://en.wikipedia.org/wiki/HP_200LX">HP-200LX</a>. It’s a very early pocket computer running DOS 5.0 - and I have VIM running on it :-) Being a DOS device, it can run <a href="http://mizj.com/">lots of nice programs</a>. Yes, it is slow, but it is cool.</p>

<p>In search for a better keyboard, I got the <a href="http://phonedb.net/index.php?m=device&amp;id=840&amp;c=ericsson_mc218">Ericsson MC218</a> (a <a href="https://en.wikipedia.org/wiki/Psion_Series_5">Psion Series 5</a> pocket computer) up and running, hoping to make it boot Linux. While this is possible, it turns out that the CF card reader on the device was flaky, so I kept searching.</p>

<p>Some forums later, and I stumbled upon an interesting project - the <a href="https://n-o-d-e.net/zeroterminal.html">Zero Terminal</a>. Now we’re talking. A Raspberry PI Zero packed with all sorts of ports and expansion capabilities. But waiting for it? I’m not the patient type…</p>

<p>But wait a minute! I always carry my <a href="https://en.wikipedia.org/wiki/Samsung_Galaxy_S20">Samsung S20 Ultra</a> anyway. Couldn’t it serve all my needs? True, the battery life sucks. But as it is my cell phone, I always have it charged, so that shouldn’t be a problem. And with my <a href="https://www.aliexpress.com/item/33044680958.html?spm=2114.search0303.3.36.3e2f50e4kUuHVD&amp;ws_ab_test=searchweb0_0,searchweb201602_0,searchweb201603_0,ppcSwitch_0&amp;algo_pvid=c05d6fa4-cb6c-4b28-aaa8-9da88e98cd0f&amp;algo_expid=c05d6fa4-cb6c-4b28-aaa8-9da88e98cd0f-5">small, foldable bluetooth keyboard</a>, I have massive computing power with me at all times. An added benefit is that it can easily use a monitor or TV screen via the built-in <i>Smart View</i>.</p>

<p>The real kicker is that it runs VIM in all its galore - even with my <a href="https://isene.org/hyperlist/">HyperList</a> plugin. It runs <a href="https://www.ruby-lang.org/en/">Ruby</a> and my whole <a href="https://isene.org/2018/08/Amar-Tools.html">Amar Tools</a> <a href="https://github.com/isene/Amar-Tools">package</a>. And <a href="https://en.wikipedia.org/wiki/LaTeX">LaTeX</a> and <a href="https://www.ssh.com/ssh/">SSH</a> and <a href="https://weechat.org/">Weechat</a> and… you name it. Lots of terminal/console programs are readily available via <a href="https://termux.com/">Termux</a>.</p>

<p>But that’s not all you can do. With the X Server app <a href="https://play.google.com/store/apps/details?id=x.org.server&amp;hl=en">XSDL</a> and the <a href="https://play.google.com/store/apps/details?id=tech.ula&amp;hl=en">UserLand</a> app, you can in fact install a full Linux distro and fire it up on your Android phone. With the full glory of both terminals and graphical software. Run an <a href="https://i3wm.org/">i3</a> session with <a href="https://wiki.archlinux.org/index.php/Rxvt-unicode">urxvt</a> terminals running <a href="http://zsh.sourceforge.net/">zsh</a>, <a href="https://www.gimp.org/">Gimp</a>, <a href="https://www.libreoffice.org/">LibreOffice</a> and whatnot. Now, that’s Nerdvana!</p>

<p><img src="https://isene.org/assets/posts/userland.png" alt=""></p>

<p>So, from my HP-41, via the HP-200LX, the MC218 and looking at Zero Terminal, I found the answer right here in my pocket. Quite a detour. But ending in bliss :-)</p>

<hr>
<p>Link to this post: <a href="https://isene.org/2020/08/Nerding.html">https://isene.org/2020/08/Nerding.html</a></p>

            </div></div>]]>
            </description>
            <link>https://isene.org/2020/08/Nerding.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148036</guid>
            <pubDate>Thu, 13 Aug 2020 20:08:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GPT-3 to enrich NPC interactions in MUDs]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148003">thread link</a>) | @teebes
<br/>
August 13, 2020 | https://blog.writtenrealms.com/gpt3/ | <a href="https://web.archive.org/web/*/https://blog.writtenrealms.com/gpt3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>How Written Realms is using the latest generation of Artificial Intelligence to animate its fictional worlds.</p><div>
<p>We were fortunate enough to receive an invite to the <a href="https://openai.com/blog/openai-api/">OpenAI private beta</a> a few weeks ago, gaining an interface to their <a href="https://arxiv.org/abs/2005.14165">GPT-3</a> engine. Using AI for mob interactions within <a href="https://writtenrealms.com/">Written Realms</a> had been a long term goal of ours for many years, and we jumped at the opportunity to play with it.</p>
<h2 id="howtheopenaiapiworks">How the OpenAI API works</h2>
<p>The OpenAI API provides a 'completion' endpoint (also available as a Python binding) for interacting with the GPT-3 engine.</p>
<p>Given a text prompt, the API attempts to complete the pattern that you gave it. For example if you give it an input of <code>1 2 4 8</code> and request 1 token back, you will get a response of: <code>16</code>. The API understood the pattern to be a doubling function and gave the next result.</p>
<p>It's not limited to math. If you give as input <code>Barking is to dogs as meowing is to</code>, you will get as a result: <code>cats</code>.</p>
<p>Not only is GPT-3 good at reading comprehension, but it also good at tailoring its output to match the style of the input. Consider the following prompt:</p>
<pre><code>Tom went fishing all afternoon. He comes home to his wife at sunset, who asks him a question.

Question: What did you do today?
Answer:
</code></pre>
<p>The API returns <code>I went fishing.</code> </p>
<p>It is possible to get a more creative answer by providing more information in the prompt and turning up the <code>temperature</code> setting, which gives GPT-3 more of a creative license to make stuff up. For example, if after adding <code>Tom responds enthusiastically, providing many details.</code> to the prompt before the question and turning the temperature to its max value, here's how the API responded: </p>
<pre><code>I went fishing all day, and in the afternoon I fought the biggest fish that I have ever seen before. I just held on for as long as I could, because once I gave up there was no way I was getting the fish back again. I had to pull everything I could, and my catch ended up weighing 3 pounds of flounder and 4 pounds of bluegill.
</code></pre>
<p>Evidently, GPT-3 is quite proficient at making stuff up given the right temperature.</p>
<h2 id="howwereusinggpt3">How we're using GPT-3</h2>
<p>For our first foray into GPT-3, we created a Historian NPC (Non-Player Character) who is able to answer arbitrary questions about Edeus, our flagship world. All of our lore is original and it can be challenging to impart it all to the players at once. An AI able to answer the organic questions of a player in real-time seemed like a perfect use-case.</p>
<p>We already had a feature called 'Reactions' that allows NPCs to respond to something said in their room with predetermined commands. The adjustment made here was to add a <code>gpt</code> flag to the Historian which at reaction time forwards the user's input to OpenAI in order to get the response.</p>
<p>As with the fisherman above, we can use the dialog pattern, and precede it with a certain context, which explains to GPT-3 what the background is for the interactions. In this case, we gave it an excerpt from a fictional history book written by the NPC in question, and then provided a little bit of background about the NPC himself. Here is a sample interaction with him:</p>
<pre><code>You say 'hello there'
Grae the Historian says 'Greetings, traveler.'

You say 'Who are you?'
Grae the Historian says 'I am Historian Grae, a Priest of the Church of Thune.'

You say 'Where are we?'
Grae the Historian says 'You are in Bluefinch, a village in the realm of Saphrin.'

You say 'Is there anything I should be doing?'
Grae the Historian says 'You should be killing orcs.'

You say 'Why? What have the orcs ever done to us?'
Grae the Historian says 'The orcs are evil. They want to destroy us.'

You say 'Okay. Can you tell me more about our origin?'
Grae the Historian says 'Humans were created by Thune, the Allmighty God.'

You say 'Who rules this area?'
Grae the Historian says 'The King of Saphrin, Arctus Kerinin, rules this area.'

You say 'Thanks Grae! You've been very helpful'
Grae the Historian says 'You're welcome.'
</code></pre>
<p>If you want to test this out for yourself, Grae is located 3 north, 1 east of Bluefinch Square in Edeus. We're always tweaking his backstory and various settings so his outputs may (and should!) vary a bit.</p>
<h2 id="theknowledgeexclusionlimitation">The Knowledge Exclusion Limitation</h2>
<p>The main issue we've been running up against is that it's difficult to constrain the AI's knowledge to that of a fictional world. It cannot help knowing things about the real world. For example:</p>
<pre><code>You say 'When was JFK born?'
Grae the Historian says 'John Fitzgerald Kennedy was born on May 29, 1917.'
</code></pre>
<p>Ideally, the historian would not know about anything outside of Edeus. But even though we specify in the prompt's backstory that he only answers questions pertaining to his own world, that distinction is not always understood. It's difficult to exclude knowledge.</p>
<h2 id="futureimprovements">Future Improvements</h2>
<p>We plan to keep iterating and try to make the AI feel as human and authentic as possible. One issue is that currently each interaction with the NPC is its own isolated event. For example:</p>
<pre><code>You say 'What is the name of this village?'
Grae the Historian says 'This village is called Bluefinch.'

You say 'Where did it get its name from?'
Grae the Historian says 'Edeus is named after the two titans that fought in the First Age. Thune and Raeshyk.'
</code></pre>
<p>Clearly the NPC didn't connect that the second question was a follow-up from the first. This is because each time we do a call to OpenAI we append the user's query to the end of the same base prompt, making each a separate interaction. It could be improved upon by including a few of the previous back and forths when generating a new prompt, provided it was the same player.</p>
<p>There's also entirely different ways we could leverage GPT-3. For example, it could be used to generate content like room, character and item descriptions, or even dynamic quests. A text-based platform and a text-based AI share great synergy, and the possible applications of it seem endless to the imaginative.</p></div></div>]]>
            </description>
            <link>https://blog.writtenrealms.com/gpt3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148003</guid>
            <pubDate>Thu, 13 Aug 2020 20:06:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Windows 10 UX deep copy on Linux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24146508">thread link</a>) | @1337shadow
<br/>
August 13, 2020 | http://www.linuxfx.org/index.php/sistemas-operacionais/linuxfx-10-w | <a href="https://web.archive.org/web/*/http://www.linuxfx.org/index.php/sistemas-operacionais/linuxfx-10-w">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="g-page-surround">
                                    

                                            
                <section id="g-top">
                
        
    </section>
                
                                
                
    
                <section id="g-container-9688">
                <div>                    <div>                        

        <div>
             <section id="g-mainbar">
                                        <div>                        

        <div>
             <div>
                                                            <div><div><div itemscope="" itemtype="https://schema.org/Article">
	<meta itemprop="inLanguage" content="pt-BR">
	
		
			
					
		
	
	
		
								<div itemprop="articleBody">
		
<p><a href="https://www.youtube.com/watch?v=gFss_DliNPE" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/desktop_mini.jpg" alt=""></a></p>
<p><span><strong>LINUXFX 10.4.2 WX DESKTOP</strong></span></p>
<p><span><strong>LINUXFX NO TELEGRAM PT-BR :&nbsp;<a href="https://t.me/linuxfxbr">https://t.me/linuxfxbr</a></strong></span></p>
<p><span><strong>LINUXFX NO TELEGRAM EN :&nbsp;<a href="https://t.me/linuxfxen">https://t.me/linuxfxen</a></strong></span></p>

<p><span>O projeto Linuxfx / Windowsfx foi desenvolvido para ajudar usuários do Microsoft© Windows® a migrarem de maneira direta para o Linux, aproveitando toda sua curva de aprendizado. Aproveitar o hardware que não suporta a versão mais nova do&nbsp;Microsoft© Windows® também é uma diretiva do Linuxfx, assim como prover suporte a rede, Active Directory, programas .exe e .msi, navegação segura e proteção contra vírus. Utilizando o Linuxfx / Windowsfx no seu computador, você terá um sistema rápido, que consome pouca memória e é imune a vírus&nbsp;desenvolvido para a plataforma&nbsp;Microsoft© Windows®.</span></p>


<p><span>Linuxfx 10.4 WX Desktop System Core</span></p>
<ul>
<li><span><strong>Tema</strong>: WX Desktop (Windows 10 <a href="https://b00merang.weebly.com/windows-10.html" target="_blank" rel="noopener noreferrer">b00merang theme</a>)</span></li>
<li><span><strong>Gerenciamento de processos de núcleo</strong>: Linuxfx Pro System Pack</span></li>
<li><span><strong>Gerenciador de janelas</strong>: Cinnamon 4.6</span></li>
<li><span><strong>Compatibilidade com rede A.D</strong>: CID, PBIS (beyond trusty)</span></li>
<li><span><strong>Compatibilidade com rede Microsoft®</strong>: SAMBA + Linuxfx Pro Network Tools</span></li>
<li><span><strong>Desktop virtual</strong>: Citrix, Vmware, Rdesktop</span></li>
<li><span><strong>Assistência remota</strong>: Anydesk, Teamviewer</span></li>
<li><span><strong>Compatibilidade com Microsoft® Windows®</strong>: Wine + Linuxfx Pro Cross Specs</span></li>
<li><span><strong>Sistema base</strong>: Ubuntu 20.04 LTS</span></li>
</ul>


<p><span><a title="Download Etcher" href="https://etcher.io/" target="_blank" rel="noopener noreferrer"><img src="https://dl2.macupdate.com/images/icons256/57903.png?d=1524853176" alt="Resultado de imagem para etcher logo" width="125" height="125"></a></span></p>
<p><span><a title="Download Etcher" href="https://etcher.io/" target="_blank" rel="noopener noreferrer"><img src="http://resin.io/blog/content/images/2017/02/etcher-logo.jpg" alt="Resultado de imagem para etcher logo" width="424" height="77"></a></span></p>
<p><a title="Download Etcher" href="https://etcher.io/" target="_blank" rel="noopener noreferrer"><strong><span>UTILIZE O ETCHER PARA GRAVAR O LINUXFX</span><span>&nbsp;</span></strong></a></p>


<p><span><a href="https://sourceforge.net/projects/linuxfxdevil/" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/pc.png" alt=""></a></span></p>
<p><span><strong><a href="https://sourceforge.net/projects/linuxfxdevil/" target="_blank" rel="noopener noreferrer">DOWNLOAD X86-64 BITS PC</a></strong></span></p>
<p><span><strong>DUAL CORE + 2GB RAM MIN</strong></span></p>


<p><span><strong><a href="https://sourceforge.net/projects/linuxfxarm/" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/rasp.png" alt=""></a></strong></span></p>
<p><span><a href="https://sourceforge.net/projects/linuxfxarm/" target="_blank" rel="noopener noreferrer">DOWNLOAD 32 BITS ARMHF</a></span></p>
<p><span><strong>RASPBERRY PI - 2 - 3 - 4</strong></span></p>


<p><a href="https://sourceforge.net/projects/linuxfxtinker/" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/tinker.png" alt=""></a>&nbsp;</p>
<p><span><a href="https://sourceforge.net/projects/linuxfxtinker/" target="_blank" rel="noopener noreferrer">DOWNLOAD 32 BITS ARMHF</a></span></p>
<p><span><strong>ASUS&nbsp;TINKERBOARD</strong></span></p>


<p><a title="Linuxfx DistroWatch.com" href="https://distrowatch.com/table.php?distribution=linuxfx" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/dwbanner.png" alt=""></a></p> 	</div>

	
							</div></div></div>
    
            
    </div>
        </div>
            </div>
            
    </section>
        </div>
            </div>
    </div>
        
    </section>
    
                                
                
                                
                <section id="g-copyright">
                
        
    </section>
                                
                <section id="g-fixedside">
                <div>                                <div>                        

        <div>
             <p><a href="http://www.linuxfx.org/" title="" rel="">
        <img src="http://www.linuxfx.org/templates/rt_kraken/images/logo/logo.png" alt="Linuxfx">
        <span></span>
</a>
            </p>
        </div>
            </div>
                            
                            
            </div>
        
    </section>
            
                        

        </div></div>]]>
            </description>
            <link>http://www.linuxfx.org/index.php/sistemas-operacionais/linuxfx-10-w</link>
            <guid isPermaLink="false">hacker-news-small-sites-24146508</guid>
            <pubDate>Thu, 13 Aug 2020 18:26:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handmade Web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24146025">thread link</a>) | @cookingoils
<br/>
August 13, 2020 | https://handmade-web.net/fall20/index.html | <a href="https://web.archive.org/web/*/https://handmade-web.net/fall20/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
            “I evoke the term ‘handmade web’ to suggest slowness and smallness as forms of resistance.”<br>
            —— J. R. Carpenter
          </p><p>The hand has become increasingly less present in the web as we know it today. Websites are automated or built from templates, and the knowledge of how to make a website is relegated to a select few. It has only gotten easier to learn and make on the web, but the idea and perceived requirements for a website have become so convoluted and arcane that many avoid the subject. This course seeks to dispel these ideas and will emphasize the hand-quality of websites by developing an understanding of the best practices, language, history, and present context of the web. We will examine the space of the web at large and explore and challenge what a website is and can be with the hopes of reclaiming an important creative space.</p><p>The websites we will make may be small, but their hearts will be big.</p><p>The first half of the class will be technically focused. It will comprise of a series of lessons, readings, workshops, and small projects to develop familiarity and confidence with the language of the web. We will focus on the basic languages of web development: HTML, CSS, and a little Javascript. This class is designed for students with no programming experience at all, but should be friendly to any skill level. The second half will be focused on a larger project website.</p><div>

          
          <p>This class will place heavy emphasis on the hand, craft, and care of your design and code. We will learn how to borrow and learn from others’ code, but we will strive to understand how to code it ourselves. This class will question much of what is commonly understood about the web and technology in general.</p>
          <ul>
            <li>Is tech always the answer? (“There’s an app for that…”)</li>
            <li>Why put something on the web?</li>
            <li>How can we think about accessibility, legibility, efficiency, and speed on the web?</li>
          </ul>

          <hr>

          
          <p>The first goal of this class is to demystify and remove the barrier for entry into web development and programming. Any and all questions are welcome. I will not know every answer, but we can work together to find one (and there are always many when it comes to programming). Learning how to search is the programmer’s greatest tool.</p>
          <p>By the end of the class you will:</p>
            <ul>
              <li>Have a working knowledge of HTML, CSS, and basic Javascript</li>
              <li>Understand the design principles particular to the web and dynamic media</li>
              <li>Have a basic understanding of web publishing</li>
              <li>Have an understanding of the history and present context of web</li>
              
            </ul>

          <hr>

          
          <p>Early in the semester we will set up individual class websites to house all products of this class (projects, writing, anything else…). We will host them using Github Pages and purchase a domain name to attach to it. You can design and organize this however you like, so long all content is accessible and easily found——I will be grading from this!</p>

          <hr>

          
          <p>For assigned readings I will ask you to respond to the reading with a rough written/sketched website concept (or, if you want, a coded sketch of the website) that reacts to the concepts and topics of the reading. Then, upload this response to your class site. Use this as an opportunity to catalogue some ideas for future web projects (either in this class or beyond!).</p>
          <p>There will be some time for reading discussions, but class time will largely be reserved for work, review, and activities. However, these readings will help facilitate a common understanding about the history and present context of the web. Ideally, they will also serve as inspiration for you (as they have been for me!).</p>
          <p>For each week that we have a reading for, only choose 1 to respond to. For example: if there are 3 assigned readings in a week, only respond to one of those.</p>
          <p>More details can be found in the <a href="https://handmade-web.net/fall20/projects/reading.html">project page</a>.</p>

          <hr>

          
          <p>During the first half of the class we will work on a series of smaller projects to practice and experiment with designing for the web:</p>
            <ol>
              <li><a href="https://handmade-web.net/fall20/projects/article.html">Article</a></li>
              <li><a href="https://handmade-web.net/fall20/projects/screensaver.html">Screensaver</a></li>
              <li><a href="https://handmade-web.net/fall20/projects/secret.html">Secret</a></li>
              <li><a href="https://handmade-web.net/fall20/projects/aura.html">Aura</a></li>
            </ol>
          <p>Details for each project will be outlined on the <a href="https://handmade-web.net/fall20/projects/index.html">Projects</a> page.</p>

          <hr>

          
          <p>The final project will take up the last half of the class. It can be anything you like: a project you’ve had in mind for some time; an extension of your practice or an even larger project outside of this class. What is important is the craft, care, and concept of the project. It will be graded on these qualities. It should be unique, personal, and a world of its own.</p>

          <hr>

          
          <p>For each major project there will be an informal presentation and feedback session. As much of this class is focused on technical introduction and skill-building, the finished projects will likely still be works in progress (the web is always under construction). Treat these sessions as opportunities to ask technical or conceptual questions to push your projects further!</p>
          <p>Beyond these review sessions I would encourage everyone to regularly share work and code inside and out of class!</p>

          <hr>

          
          <p>
            40% —— Participation<br>
            40% —— Process<br>
            20% —— Execution
          </p>

          <hr>

          
          <p>This class will require a computer, a text-editor (I recommend <a href="https://atom.io/">Atom</a>), and a browser (<a href="https://www.google.com/chrome/">Chrome</a>). I would also suggest a sketchbook for much encouraged off-screen thinking, note-taking, sketching, and journaling.</p>

          <p>More details can be found in the <a href="https://handmade-web.net/fall20/library.html">Library</a>.</p>

          <hr>

          
          <p>This class will take place entirely online, with some flexibility on potentially meeting in person for individual meetings. Unless stated otherwise, we will regularly meet (synchronously) during the scheduled class times using Zoom.</p>
          <p>You will also have access to the scheduled class space in Pollak Room 317 if you want to use that space during class time, though we will still all collectively meet online through Zoom. One thing to note is that departmental policy, at the time, only allows 10 students in a classroom at a time and only during the scheduled class time. Please make sure to prioritize your own safety and the safety of others when using public spaces!</p>
          <p>We can consider this a feature rather than a hinderance for learning web design as we will inhabit and communicate within the environment that we will be making for!</p>

          <hr>

          
          <p>As this class will take place online, we will be using a <a href="https://discord.com/" target="_blank">Discord</a> server to centralize communication and announcements for the class. The Discord will also serve as a space for feedback and comments during feedback sessions. If there are any updates/changes to the class I will announce them on the Discord, so be sure to check often.</p>

          <hr>

          
          <p>The standard VCU attendance policy states that student absences during the semester are not expected to exceed the number of times the class meets in one week (2). This semester, because we are facing unprecedented circumstances, we will be following a revised policy that addresses larger issues of expected engagement in the course, articulated below. Consistent engagement is a vital component of successful completion of the course objectives.</p>
          <p>The progression of this course requires all participants to be present and actively engaged in class, both during synchronous on-screen meetings, in-person, and with asynchronous activities. Consistency of engagement is vital for a successful completion of the course objectives. Each of us carries different circumstances and capacities; we are accountable for our own agency. This is always true, but especially crucial now.</p>
          <p>If at any point during the semester you are unable to be present, communicate this with me as soon as you can. While presence in class is important, my primary concerns with this class are your wellbeing and an emphasis on not applying unnecessary pressure in an already difficult period. Please remember to prioritize your mental and physical health over school.</p>

          <hr>

          
          <p>The University requires all students and faculty to be aware of policies outlining expectations, requirements and student services related to  academic life. Please visit the following link and review these at the start of each semester: <a target="_blank" href="https://go.vcu.edu/syllabus">go.vcu.edu/syllabus</a>
          </p>

          <hr>

          
          <p>For information regarding institutional adjustments, policies, and safety precautions during COVID-19 please consult the web page for <a target="_blank" href="https://together.vcu.edu/students/">One VCU: Responsible Together</a>.
          </p>

          <hr>

          
          <p>This syllabus and class’s foundation has a number of sources to thank</p>
          <ul>
            <li><a href="http://laurelschwulst.com/">Laurel Schwulst</a> —— whose published syllabi and class portals served as my own unbidden introduction to web design. Much of the pacing and tone of this class is modeled after her approach.</li>
            <li><a href="http://mindyseu.com/">Mindy Seu</a> —— whose classes and workshops have helped expand my thought around digital pedagogy.</li>
            <li>Roy McKelvey —— whose generously provided syllabus has served as the organizational structure of this class.</li>
          </ul>

          <hr>
        </div></div>]]>
            </description>
            <link>https://handmade-web.net/fall20/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24146025</guid>
            <pubDate>Thu, 13 Aug 2020 17:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jira Is a Microcosm of What’s Broken in Software Development]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 171 (<a href="https://news.ycombinator.com/item?id=24145665">thread link</a>) | @davetwichell
<br/>
August 13, 2020 | https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>This blog is not about how project management tools are too complex and over-engineered with features dev teams don’t need.</p>



<p>Those complaints are well articulated by others like Justin James, Chief Architect at Cloud Development Resources.</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p><em>“Jira has *never once* made my life as a developer easier or better… It’s overly complicated and the workflow is painful.”&nbsp;</em></p>



<p>Justin goes on to say…&nbsp;</p>



<p><em>“Jira is Word when it had the toolbar filled with tiny little icons for formatting only paralegals or scientists or some other specialized author needed. It does *all this stuff* and none of it is easy or makes sense…”&nbsp;</em></p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>Most popular project management tools are highly configurable which can be a plus and a minus depending on how your company has it set up. </p>



<p>So if project tools have so much flexibility, why do so many organizations configure them in a way that causes their dev teams to complain? </p>







<h4><strong>Project management tools are not perfect but they’re not the problem. The root cause of most complaints devs have with project tools are rooted in bad culture, bad management or bad process. </strong></h4>



<p>Let’s examine 4 of the most common complaints I’ve heard about project management tools from software development teams. </p>







<h3>1. “<strong>Project tools are made with PMs in mind, not dev teams</strong>“</h3>



<p>Justin said <em>“I wish Atlassian would sit down with real-world developers and design this product the way we need it to work.”&nbsp;</em></p>



<p>I’ve heard this complaint from a lot of devs. “Project tools were made with project managers and product managers in mind. Not dev teams.” It is true. Project and product managers (collectively referred to as PMs going forward) are the usually primary buyers and owners of project management systems. Not engineers.&nbsp;</p>



<p>I’ve also heard “the development process is fluid, real-time, and doesn’t always follow a linear path. Project tools force you into a workflow that does not match that reality.” </p>



<p>So why do companies use a tool that works for a few PMs and business leaders when some engineers dislike it so much?&nbsp;</p>



<p><strong>The real issue: Executives force top-down decision making on dev teams</strong></p>



<p>Some companies embrace a mindset of decisions being made by a few people “at the top”. In their world, the planning process is king. The creating process is an afterthought.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>The current software delivery process revolves around pushing decisions down to dev teams and forcing engineers to push status updates back up. This system ensures executives are the only ones who have context and can see the bigger picture while engineers do all of the work.&nbsp;</p>



<p>This is backwards. It holds us back from building the best product and slows us down from delivering faster.&nbsp;</p>



<figure><blockquote><p>Join our mission to end useless status meetings.</p><p><a href="https://linearb.io/status-updates-on/" target="_blank" rel="noreferrer noopener">Click here for access</a>&nbsp;to the dev team dashboard of the future powered by Git data.</p></blockquote></figure>







<h3>2. “<strong>Project tools are plan-first tools, not a develop-first tool</strong>s”</h3>



<p>It makes sense. PM’s, who own Jira, spend a lot of time on ideas, strategy, prioritization, requirements gathering, and preparing for the future. They want a tool that helps them succeed in those areas. Once the iteration starts, PMs shift from being planners to being status communicators. Jira is designed this way. It’s pretty good when you’re in the planning phase and it works well if you’re the PM receiving the status update.</p>



<p>But when you’re in the development phase, it’s not as well suited to dev team tasks. If you’re the engineer who has to constantly manually update the status, it’s annoying. </p>



<p>I see the merit behind this argument. Dev teams live elsewhere like in Git and Slack.&nbsp;Stopping to login in to another system throughout the day is not ideal. </p>



<p>What PMs do is really important – being the voice of the customer, planning, prioritizing and communicating with the rest of the business.  They need tools for this. </p>



<p>I also think dev teams need tools that reflect the fluidity of the development process. It’s sort of like the famous Mike Tyson quote… <em>“Everybody has a plan until they get punched in the mouth.”</em> Once development starts, a million micro-decisions are being made every hour and things change quickly. Most project tools are not set up for this reality.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>The problem is we’re taking different groups of people who spend their time in different ways and forcing them in to one workflow. 80% of the people involved in software development spend 80% of their time in the development phase. In most companies, fewer people spend less time in the planning phase.&nbsp;</p>



<p>So why are we using a plan-first tool to manage the full development lifecycle?&nbsp;</p>



<p><strong>The real issue: Many execs get product strategy but not product development</strong></p>



<p>Most business leaders think like PMs, not like engineers. Executives understand ideas, strategy, and prioritization. They’re also familiar with the process and key metrics of sales and marketing. They know the vocabulary and speak the language.&nbsp;</p>



<p>They do not understand software development as well. They don’t know the terms. When it comes to the dev team, most just want to know “are we on track to deliver feature XYZ by the deadline?”&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>This is dangerous because it holds them back from understanding our process which holds them back from engaging in intelligent conversations with engineering leaders and teams.&nbsp;</p>



<p>If sales miss their number, the CEO has 100 questions ready to analyze what levers they can pull to right the ship. If the dev team misses a deadline, other than maybe asking “do we need to work more hours?”, all they can do is wait or apply (unhelpful) artificial pressure to finish.&nbsp;</p>



<p>How we work matters. Not just the output.&nbsp;</p>







<h3>3. <strong>“Project tools perpetuate synchronous communication, not asynchronous</strong>” </h3>



<p>Project management tools seems like it should encourage asynchronous communication. But in my experience they do the opposite. </p>



<p>When execs have a meeting with a customer or the sales team, they need information about product delivery timelines and they need it now. They ask the PM and the PM sends you an urgent Slack. Or worse, the PM calls you into a meeting to find out what’s going on. Those interruptions are costly.&nbsp;</p>











<p>Why doesn’t the exec or the PM just look at project board? Because it’s not up to date. Why? Things change so rapidly that, in order for the board to be up to date, engineers would need to constantly manually update tickets. One engineering manager told me recently that even teams he’s worked on that really care about project tool hygiene only capture about 60-70% of their real work activity. Most teams are closer to 50%.&nbsp;</p>



<p>Even if the project board was up to date, it’s still missing context.&nbsp;</p>



<p>Execs and PMs want to know:&nbsp;</p>



<ul><li>When is the bug going to be fixed?&nbsp;</li><li>When is the new feature being delivered?&nbsp;</li><li>What risks could stop us from hitting our date?&nbsp;</li><li>Which features are getting attention right now and which aren’t?&nbsp;</li><li>What % of the team is invested in features versus bugs versus non-functional?&nbsp;</li></ul>



<p>There’s nothing on the project board that answers those questions. So they pull you away from deep focus mode to ask you. And it takes you a while to get your focus back. Which slows you down from delivering the thing they want most of all – more features.&nbsp;</p>



<p><strong>The real issue: Companies run on a “manager’s schedule” not a “maker’s schedule”&nbsp;&nbsp;</strong></p>



<p>Paul Graham, computer programmer and co-founder of Y Combinator, explains the disconnect between the way developers and executives get work done in his 2009 essay <em>Maker’s Schedule, Manager’s Schedule</em>.&nbsp;</p>



<p>Here’s a summary:&nbsp;</p>



<ul><li>Bosses (managers) get stuff done through meetings – changing tasks every 60 minutes.</li><li>Developers (makers) and other creators need 3-4 hour blocks of time to get work done.</li><li>Each way of working is perfectly fine by itself but problems arise when the two collide.</li><li>For a maker, a single meeting at the wrong time can disrupt their entire day of work.</li><li>Most powerful people are on a manager schedule and they directly or indirectly force the makers in their company, like software engineers, to revolve around the way they work.&nbsp;</li></ul>







<p>I couldn’t agree more with Paul. The lack of understanding some execs have for the software development process, leads to a lack of empathy for software developers. Companies subject their engineers to the manager’s schedule which disrupts the flow of development.&nbsp;</p>



<p>When engineers point out they could ship more features faster if there were fewer meetings, business leaders hear that as a complaint versus what it really is, a cry for help.&nbsp;</p>







<h3>4. “Project tools <strong>create separation between engineers and PMs</strong>“</h3>



<p>Some devs describe their interactions with their PM in a way that reminds me of <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=Fy3rjQGc6lA&amp;feature=youtu.be" target="_blank">Peter from Office Space</a> when his boss asks him for the new cover sheet on the TPS report.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>In the real world, most devs I know really value their PMs. Great PMs allow engineers to do great work. I’ve worked with some awesome ones. </p>



<p>But the <a rel="noreferrer noopener" href="https://linearb.io/blog/vp-engineering-vp-product-how-to-keep-a-united-front/" target="_blank">PM + engineer relationship is hard to get right</a>. Having additional tension built-in makes it even harder.&nbsp;</p>



<p>It’s just not engineers that don’t like having to share status updates all day. PMs don’t want to bug us either! They feel like babysitters. Imagine what they could be doing instead… talking to customers, writing high-quality user stories… or actually spending their time with us on something useful like brainstorming ideas or sharing customer feedback. </p>



<p><strong>The real issue: Some companies are lacking empathy and understanding between different departments. </strong></p>



<p>I’m lucky to work at a company where our CEO (Ori Keren) and our COO (me) are software engineers. We ensure everyone in the company understands the development process which helps maintain tight alignment between our dev, marketing, customer success, and sales teams.&nbsp;</p>



<p>I think more start-ups should be led by programmers and more big companies should promote their CTOs to CEO.&nbsp;</p>



<p>In the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/">https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145665</guid>
            <pubDate>Thu, 13 Aug 2020 17:13:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HTTP – It's Simpler Than You Think. It's More Complex Than You Think]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24145502">thread link</a>) | @Crzymary15
<br/>
August 13, 2020 | http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/ | <a href="https://web.archive.org/web/*/http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <div>
                <article>
                    <header>
                        
                        <span>
                            
                                Posted in
                                
                                    <a href="http://bluegraybox.com/blog//categories/networking">networking</a>
                                
                            

                            
                        </span>
                         - 
                        <time>Friday, August 29, 2014</time>
                    </header>
                    <section>
                        

<p>I’ve been doing web development for a pretty long time, but just over the last few years I’ve come to really appreciate the fundamentals of HTTP, what’s going on under the hood when I’m building web applications. There are two sides of this. The first is that HTTP is in one sense a very simple protocol. It’s just little text messages going back and forth between your browser and the web server. Whether I’m using Node or Django or some huge WSDL-driven Java XML-Beans monstrosity, what it’s doing isn’t rocket science; it’s just taking care of a bunch of tedious, nit-picky bookkeeping that I don’t want to be bothered with. If I really wanted to, I could just type the messages myself (and we’ll get to that in a minute).</p>

<p>The practical upside of that is that you can use really simple tools to debug big, hairy, complex web applications. A few years ago, I was working in one of those Big Web Services systems with WSDL files and auto-generated Java code and layers and layers of middleware. We’d get some kind of error at the front end, and it’d be really hard to tell which piece had broken. So I ended up writing a bunch of really simple shell scripts to test the web services in isolation. I’d spackle together something using <code>curl</code>, <code>grep</code>, and <code>sed</code> that built up and picked apart the messages as text, without dragging in all that mess of Java code.</p>

<p>The flip side is that HTTP is actually a richer protocol than I’d realized. There’s a lot I didn’t know about it until I started building RESTful web services and trying to understand the “right” way to do it. There’s all this stuff you can do with status codes and headers that I’d been re-implementing at the application level.</p>

<p>To take a recent example, I’ve been working on a web service that talks to other web services. Someone would make a call to us, we’d call the back-end services, they’d time out or barf up some sort of error, and we’d pass back a 500 error to our client. They’d see it and email us asking what was wrong with our service. It’d be nice to let them know it’s not our fault and that they should pester the back-end systems people instead. We could send back a message body that says something like, “Back-end systems failure. Original error message follows,” but it turns out we can say that just by returning a different status code. Not only is there a 502 status code, which means that a back-end system failed, but there’s also a 504, which means that we timed out trying to contact it. That tells our client that they can try again in a little while and the request might go through.</p>

<p>Ok, enough talking. Now code.</p>

<h2 id="goin-all-mechanical-turk-on-this">Goin’ all Mechanical Turk on this</h2>

<p>To illustrate the first point, that this is all just text, I’m going to play human web server, using <code>netcat</code>. If you’re not familiar with it, it’s a standard unix utility that just opens a network connection. Anything you type gets sent along it; anything that comes back gets printed out on your screen. I open up a terminal and type:</p>

<pre><code>nc -l 3333
</code></pre>

<p>That starts up <code>netcat</code> listening on port 3333. Then I switch to my browser and tell it to go to <code>http://localhost:3333/</code>. The “page loading” indicator starts spinning. In the <code>netcat</code> terminal, I see:</p>

<pre><code>GET / HTTP/1.1
Host: localhost:3333
Connection: keep-alive
Cache-Control: max-age=0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
User-Agent: Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36
Accept-Encoding: gzip,deflate,sdch
Accept-Language: en-US,en;q=0.8
</code></pre>

<p>That’s Chrome telling me it wants the root resource (<code>/</code>, which Apache or whatever would normally interpret as <code>index.html</code>). It’s also telling me a lot about what kind of response it can handle. I’m going to ignore all that for now and just type:</p>

<pre><code>HTTP/1.1 200 OK 
Content-type: text/plain
Content-length: 7

Hello!
</code></pre>

<p>Pretty straightforward. The content length is 7 because it includes the return character after “Hello!” Here’s what we see in Chrome:</p>

<p><img src="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/img/hws-1.png" alt="" title="Chrome window with plain text &quot;Hello!&quot;"></p>

<p>Switch back to the browser and go to <code>http://localhost:3333/index.html</code>. In the <code>netcat</code> terminal, we get a request that’s much the same as before, except the first line is:</p>

<pre><code>GET /index.html HTTP/1.1
</code></pre>

<p>Since they asked for HTML, I’ll give them HTML. I type:</p>

<pre><code>HTTP/1.1 200 OK
Content-type: text/html
Content-length: 16

&lt;h1&gt;Hello!&lt;/h1&gt;
</code></pre>

<p>And in Chrome we see:</p>

<p><img src="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/img/hws-2.png" alt="" title="Chrome window with HTML H1 header &quot;Hello!&quot;"></p>

<p>So at some fundamental level, that’s all a web application is. It’s a program that listens for a connection, gets little text messages, interprets them, and sends back responses. How simple can we make that?</p>

<h2 id="restful-web-services-in-bash">RESTful Web Services in Bash</h2>

<p>How about this?</p>

<pre><code>#!/bin/bash

echo "Content-type:text/plain"
echo 
uptime
</code></pre>

<p><code>uptime</code> is a standard unix utility that reports how long the computer has been running and what the 1, 5, and 15 minute system load averages are. That’s marginally useful - I’ve actually used a script much like this for basic server monitoring. Put it in a file, make it executable, run it from the command line, and it’ll spit out something like:</p>

<pre><code>Content-type:text/plain

 21:29:32 up 9 days, 15:17,  5 users,  load average: 0.05, 0.10, 0.18
</code></pre>

<p>From here, if you want to follow along, you’ll need to have Apache set up and configured to let you run CGI scripts in the directory you’re working in. (That’s a whole tutorial on its own, but here’s some <a href="http://www.cgi101.com/book/connect/mac.html">instructions for Mac OS X</a>. Otherwise, Google for “apache enable cgi” and your operating system.)</p>

<p>On my machine, this script is saved as <code>public_html/api/v1/load/index.cgi</code>. That lets me access it as <code>http://localhost/~colin/api/v1/load/</code>, as we can see in Chrome:</p>

<p><img src="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/img/v1-load.png" alt="" title="Chrome showing uptime report"></p>

<p>We can also use <code>netcat</code> in place of Chrome. Instead of listening on a port, we open a connection to the web server’s port:</p>

<pre><code>$ nc -c localhost 80
</code></pre>

<p>Then I type:</p>

<pre><code>GET /~colin/api/v1/load/ HTTP/1.1
Host: localhost
</code></pre>

<p>And I get this back from Apache:</p>

<pre><code>HTTP/1.1 200 OK
Date: Wed, 27 Aug 2014 01:14:11 GMT
Server: Apache/2.4.7 (Ubuntu)
Vary: Accept-Encoding
Transfer-Encoding: chunked
Content-Type: text/plain

46
 21:14:19 up 9 days, 15:01,  5 users,  load average: 0.08, 0.18, 0.28

0
</code></pre>

<p>You can see that Apache includes a bunch of header fields that I didn’t bother to when I was playing web server. (I’ll trim most of these out of later examples to cut down on the clutter.) The more interesting thing is that it doesn’t have a <code>Content-length</code> header. What it has instead is <code>Transfer-Encoding: chunked</code>. That says that its content will be in chunks, prefixed by their size (in hexadecimal). 46 hex is 70, which is the length of the next line (again, counting the return character at the end). The ‘0’ for the next chunk says, “that’s all, folks!”</p>

<p>We can make this a little easier on ourselves by using <code>curl</code> instead of <code>netcat</code>. It’s a somewhat more custom tool for making HTTP requests. We can just run <code>curl -si http://localhost/~colin/api/v1/load/</code> from the command line, and get back:</p>

<pre><code>HTTP/1.1 200 OK
Transfer-Encoding: chunked
Content-Type: text/plain

 22:05:42 up 9 days, 15:53,  5 users,  load average: 0.14, 0.13, 0.19
</code></pre>

<p>That’s the same as what <code>netcat</code> gave us (minus the header clutter), but notice that it combined the chunked response for us. Even at this level, some of the details are being hidden.</p>

<h2 id="status-seeking">Status Seeking</h2>

<p>Let’s take this a step further. The <a href="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/v1/status/index.cgi">status script</a> gets a status message (“GREEN”, “YELLOW”, or “RED”) from a file, and prints it out like so:</p>

<pre><code>$ curl -si http://localhost/~colin/api/v1/status/
HTTP/1.1 200 OK
Content-Length: 4
Content-Type: text/plain

RED
</code></pre>

<p>It also lets us set a new status like so:</p>

<pre><code>$ curl -si -X PUT -d GREEN http://localhost/~colin/api/v1/status/
HTTP/1.1 204 No Content
Content-Length: 0
Content-Type: text/plain
</code></pre>

<p>Note that we used the same URL, but changed the HTTP method to <code>PUT</code> (instead of the default <code>GET</code> - don’t ask me why that’s the <code>-X</code> option) and specified “GREEN” as the data (<code>-d</code>) to be sent along with the request. We get back an exciting new response code: 204! Since we’re telling not asking, it doesn’t make much sense for the server to send anything back. The 204 status just says, “That thing you were doing? It worked.” No reason to have a message body saying “Success!” when the code already tells you that. I’ve definitely been guilty of reinventing that wheel before I ran across this.</p>

<p>What if we try to send a bad status, like ‘BLUE’?</p>

<pre><code>$ curl -si -X PUT -d BLUE http://localhost/~colin/api/v1/status/
HTTP/1.1 400 Bad Request
Content-Type: text/plain

Invalid status code
</code></pre>

<p>400 is the “your mistake” error code, which is pretty generic, so we include a descriptive message in the response body. Since it’s a user error, it’s reasonable to just have a human-readable message.</p>

<p>If you look at the script, you’ll see references to environment variables like <code>$REQUEST_METHOD</code>. That’s how Apache makes information about the request avaliable to the script (as part of the CGI standard). In case you want to see all of them, I’ve added an <a href="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/env/index.cgi">env script</a>, which dumps them all out, plus the content. You can hit it with Chrome or <code>curl</code>, or even <code>netcat</code>. See what’s different between them.</p>

<h2 id="api-documentation">API Documentation</h2>

<p>Ok, great! Now we have two simple yet useful web services. But they’re not so simple that they don’t need any documentation, so let’s add some. We could have some sort of parallel hierarchy for documentation, like <code>/api/docs/v1/load/</code>, etc., but that’s kinda clunky. Instead, let’s rework our services so they give you data when you ask for data, and text when you ask for text. For that, we take advantage of the <code>Accept</code> header. Take a …</p></section></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/">http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/</a></em></p>]]>
            </description>
            <link>http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145502</guid>
            <pubDate>Thu, 13 Aug 2020 16:59:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Llama Logs – Architecture Diagrams from Your Logs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24145223">thread link</a>) | @bakenator
<br/>
August 13, 2020 | https://llamalogs.com/docs/what | <a href="https://web.archive.org/web/*/https://llamalogs.com/docs/what">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    

    <p>Overview</p>
    <div>

        <p>Llama Logs is a brand new tool that turns distributed logs into a <b>real time interactive graph</b>.</p>
        <p>Llama Logs was created to help bring clarity to complex cloud architectures.</p>
        

        <p><img height="auto" width="600px" src="https://llamalogs.com/images/doc-examples/complexArch.gif"></p><p>With Llama Logs, <b>never again</b> will you need to:</p>
        <ul>
            <li>Create and update architecture diagrams by hand.</li>
            <li>Install agents onto your machines.</li>
            <li>Hunt down erors through mulitple machines and log files.</li>
            <li>Struggle to teach new team members your architecture.</li>
            <li>Limit your analytics to the machine level.</li>
        </ul> 

        <p>With <b>only a few log lines</b> in your code base, </p>
        <p><img height="auto" width="600px" src="https://llamalogs.com/images/codeScreenshot.png"></p><p>Llama Logs will instantly create a live visualization of the activity within your system. </p>
        
        <p>Llama Logs is <b>built for developers</b>, so the possibilities are endless!</p>
    </div>


    
    <p>The Llama Logs Graph</p>
    <div>
        <p>The graph is where all of the events from a system are visualized automatically by Llama Logs.</p>
        <p>Below is an example of a Llama Logs graph for a Cloud Architecture with Multiple Cloud Functions and a Database.</p>
        <p>Each one of the circles moving between components represents logged events occurring between those two components.</p>
        
        <p><img src="https://llamalogs.com/images/LlamaStartingDemo.gif"></p><p>Instantly we can see the structure and activity of the entire architecture in real time!</p>
        <p>The graph even shows errors in red that are occuring during the response from one of the modules in the first Cloud Function.</p>

        

        <p>See more examples of Llama Logs system visualizations on our <a href="https://llamalogs.com/docs/examples">examples page</a>.</p>
    </div>
    
    
    <p>Benefits</p>
    <div>
        <p>Llama Logs has tremendous benefits over other types of analytics:</p>
        <ul>
            <li>Aggregates distributed data into a single easy to understand graph.</li>
            <li>Seamlessly bridges the gap between application and infrastructure data layers.</li>
            <li>Handles millions of events per component with ease.</li>
            <li>Allows <b>You</b> to creatively define how your data will be visualized.</li>
        </ul>
    </div>


    
    
    <p>Supported Languages</p>
    
    
    
    <p>Demo</p>
    <div>
        <p>You are only 2 clicks away having a live Llama Logs graph to experiment with.</p>
        <p><a href="https://llamalogs.com/docs/demo" target="_blank">Start The Demo</a>
    </p></div>

    


    <p>Start Using Llama Logs</p>
    

    

    <p>More Info</p>
    

    </div></div>]]>
            </description>
            <link>https://llamalogs.com/docs/what</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145223</guid>
            <pubDate>Thu, 13 Aug 2020 16:35:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Architecture of Consoles – Nintendo DS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24145124">thread link</a>) | @bobbybabylon
<br/>
August 13, 2020 | https://www.copetti.org/projects/consoles/nintendo-ds/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/nintendo-ds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><div><ul><li><a href="#cover-model">Model</a></li><li><a href="#cover-motherboard">Motherboard</a></li><li><a href="#cover-diagram">Diagram</a></li></ul><div><div id="cover-motherboard"><figcaption>Showing first revision<br>Controllers are plugged using a separate daughterboard<br>Missing SRAM chips are on the back and there are four unpopulated SRAM slots</figcaption></div><div id="cover-diagram"><a href="https://www.copetti.org/images/consoles/nintendods/diagram.png"><picture>
<img alt="Diagram" src="https://www.copetti.org/images/consoles/nintendods/diagram.png" data-src="https://www.copetti.org/images/consoles/nintendods/diagram.png"></picture></a><figcaption>If you have trouble following the components: Top is only accessed by ARM9, bottom section is ARM7-only, middle section is shared</figcaption></div></div></div><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>This console is an interesting answer to many needs that weren’t possible to fulfil in the handheld ecosystem. There will be some innovation and a few compromises, but this combination may pave the way for new and ingenious content.</p><hr><h2 id="cpu">CPU</h2><p>As with Nintendo’s <a href="https://www.copetti.org/projects/consoles/game-boy-advance/">previous portable console</a>, the system revolves around a big chip named <strong>CPU NTR</strong>. ‘NTR’ is shorthand for ‘Nitro’, the codename of the original Nintendo DS.</p><p>Now, CPU NTR implements an interesting multi-processor architecture using two different ARM CPUs, this design was done before ARM Holdings officially released multi-processor solutions. So, their functioning may be considered a bit unorthodox taking into account the present technology available.</p><p>While this is not the first parallel system analysed for <a href="https://www.copetti.org/projects/consoles/">this series</a>, its design is very different from the rest. For instance, we are not talking about the ‘experimental’ master-slave configuration that the <a href="https://www.copetti.org/projects/consoles/sega-saturn/">Saturn</a> debuted or the ‘co-processor’ approach found on the <a href="https://www.copetti.org/projects/consoles/playstation/">PS1</a> or <a href="https://www.copetti.org/projects/consoles/nintendo-64/">N64</a>. The Nintendo DS includes two very independent computers that will perform exclusive operations, each one having a dedicated bus. This co-dependency will condition the overall performance of this console.</p><p>That being said, let’s take a look now at the two CPUs:</p><div><ul><li id="tab-1-1-arm7tdmi-link"><a href="#tab-1-1-arm7tdmi">ARM7TDMI</a></li><li id="tab-1-2-arm946e-s-link"><a href="#tab-1-2-arm946e-s">ARM946E-S</a></li></ul><div><div id="tab-1-1-arm7tdmi"><h4>ARM7TDMI</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"></picture></a><figcaption>ARM7 structure and components</figcaption></div><p>Starting with the more familiar one, the <strong>ARM7TDMI</strong> is the same CPU found on the <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#cpu">GameBoy Advance</a> but now running at <strong>~34 MHz</strong> (double its original speed). It still includes all its original features (especially <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#whats-new">Thumb</a>).</p><p>Now for the changes: Because Nintendo’s engineers placed the ARM7 next to most of the I/O ports, this CPU will be tasked with arbitrating and assisting I/O operations. In fact, no other processor can directly connect to the I/O. As you can see, this is not the ‘main’ processor that will be in charge of the system, but rather the ‘sub-processor’ offloading the main CPU by passing data around many components.</p></div><div id="tab-1-2-arm946e-s"><h4>ARM946E-S</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"></picture></a><figcaption>ARM9 structure and components</figcaption></div><p>Here is the ‘main’ CPU of the Nintendo DS running at <strong>~67 MHz</strong>. If you ignore the ill-fated ARM8 series, you could say the ARM946E-S is the ‘next-gen’ version of the ARM7. Part of the <strong>ARM9 series</strong>, this core in particular not only inherits all the features of the <strong>ARM7TDMI</strong> but also includes some additional bits:</p><ul><li>The <strong>ARMv5TE ISA</strong>: Compared to the previous v4, features some new instructions and a faster multiplier.<ul><li>If you take a look at the core name, the letter ‘E’ means <strong>Enhanced DSP</strong> which implies that lots of these new instructions have to do with applications for signal processing.</li></ul></li><li><strong>5-stage Pipeline</strong>: This is another increment from the previous 3-stage pipeline.</li><li><strong>12 KB of L1 Cache</strong>: The core now features cache, where 8 KB are allocated for instructions and 4 KB for data.</li><li><strong>48 KB of Tightly-Coupled Memory</strong> or ‘TCM’: Similar to <a href="https://www.copetti.org/projects/consoles/playstation/#cpu">Scratchpad memory</a>, however this one discriminates between instructions (32 KB) and data (16 KB).</li></ul><p>Nintendo also added the following components around it:</p><ul><li>A <strong>Divisor and Square root unit</strong> to speed up these type of operations (the ARM9 by itself is not capable of performing this type of math).</li><li>A <strong>Direct Memory Access Controller</strong>: Accelerates memory transfers without depending on the CPU. Combined with the use of cache, both CPU and DMA can potentially work concurrently.<ul><li>Cache and DMA can provide a lot of performance but also create new problems, such as data integrity. So programmers will have to manually maintain memory consistency by flushing the <a href="https://www.copetti.org/projects/consoles/playstation-2/#preventing-past-mishaps">write-buffer</a> before triggering DMA, for instance.</li></ul></li></ul></div></div></div><p>I guess with hardware like this, it’s easy to figure out the <em>real</em> reason kids loved this console, eh?</p><h4 id="interconnection">Interconnection</h4><p>So far I’ve talked about how the two CPUs work individually. But to work as a whole, they require to co-operate constantly. To accomplish this, both CPUs directly ‘talk’ to each other using a dedicated <strong>FIFO unit</strong>, this block of data holds two 64-byte queues (up to 16 elements) for <strong>bi-directional communication</strong>.</p><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"></picture></a><figcaption>Representation of FIFO unit</figcaption></div><p>This works as follows: The ‘sender’ CPU (that effectively needs to send the other a message) places a 32-bit block of data in the queue, the CPU acting as a ‘receiver’ can then pull that block from the queue and perform the required operations with it.</p><p>Whenever there’s a value written on the queue, either CPU can fetch it manually (<strong>polling</strong>) however, this requires to constantly check for new values (which can be expensive). Alternatively, an <strong>interrupt unit</strong> can be activated to notify the receiver whenever there’s a new value in the queue.</p><h4 id="main-memory">Main memory</h4><p>Just like its predecessor, RAM is spread around many different locations, enabling to prioritise data placement by speed of access. In summary, we have the following general-purpose memory available:</p><div><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"></picture></a><figcaption>RAM model of this console</figcaption></div><ul><li><strong>32 KB of WRAM</strong> (Work RAM) using a <strong>32-bit</strong> bus: To hold fast data shared between the ARM7 and ARM9.<ul><li>Bear in mind that only one CPU can access the same address at a time.</li></ul></li><li><strong>64 KB of WRAM</strong> using a <strong>32-bit</strong> bus: For fast data as well, but only accessible from the ARM7, like the GBA had.</li><li><strong>4 MB of PSRAM</strong> using a <strong>16-bit</strong> bus: A slower type, available from either CPU and it’s controlled by a memory interface unit.<ul><li>Pseudo SRAM or ‘PSRAM’ is a variant of DRAM which, by contrast, performs refreshes from within the chip. Therefore, behaving like SRAM (the faster, but more expensive alternative to DRAM). This design reminds me of <a href="https://www.copetti.org/projects/consoles/gamecube/#clever-memory-system">1T‑SRAM</a>.</li></ul></li></ul></div><h4 id="backwards-compatibility">Backwards compatibility</h4><p>Even though the architecture is significantly different from its predecessor, it still managed to maintain the critical bits that would grant it native compatibility with GameBoy Advance games.</p><p>But for the DS to revert to an ‘internal’ GBA, the former includes a set of software routines that set the console in <strong>AGB Compatibility Mode</strong>. In doing so, it effectively halts the ARM9, disables most of the ‘special’ hardware, redirects the buses, puts the ARM7 in charge and slows it down at 16.78 MHz. Finally, the ARM7 proceeds to boot the original AGB BIOS which bootstraps the GamePak cartridge (just like an original GameBoy Advance). This mode still exhibits some features not found in the original console, such as displaying the game with black margins (we’ll see in the next section that the new screen resolution happens to be bigger). Moreover, since the DS has two screens, users can set which screen will be used to display the GBA game.</p><p>Once in GBA mode <strong>there’s no going back</strong>, the console must be reset to re-activate the rest of the hardware.</p><h4 id="secrets-and-limitations">Secrets and limitations</h4><p>With so many sophisticated components fitted in a single and inexpensive chip, it’s no mystery that some issues emerged due to the way they were forced to work with each other.</p><div><ul><li id="tab-2-1-unused-power-link"><a href="#tab-2-1-unused-power">Unused Power</a></li><li id="tab-2-2-a-question-about-the-hardware-choice-link"><a href="#tab-2-2-a-question-about-the-hardware-choice">A question about the hardware choice</a></li></ul><div><div id="tab-2-1-unused-power"><h4>Unused Power</h4><p>Sometimes I wonder how Nintendo planned the way the two CPU’s would be used, and if they already assumed some performance would be hit by the design they chose.</p><p>Let me start with the ARM9, this CPU runs at twice the speed of the ARM7, but most (if not all) of the I/O depends on the ARM7, so the ARM9 is vulnerable to excessive stalling until the ARM7 answers. If that wasn’t enough, <strong>ARM9’s external bus runs at half the speed</strong>, so there are a few bottlenecks identified.</p><p>Additionally, the Main Memory bus is only <strong>16-bit wide</strong>. Thus, whenever any CPU needs to fetch a word (32-bit wide) from memory, the interface <strong>stalls the CPU</strong> (up to 3 ‘wait’ cycles) until a full world is reconstructed. The worst impact happens when memory access is not sequential, which makes it stall for every single access. This issue will also arise when instructions are fetched (unfortunately, ARM didn’t support sequential opcode fetching back then) which, to my dismay, also affects Thumb code (since every 16-bit fetch is done as a 32-bit block). On the other hand, this penalty (as some sources call it) can be alleviated by making full use of cache and TCM.</p><p>All in all, this means that in the worst case, the ‘whooping’ ARM9’s 66 MHz horsepower is practically reduced to a mere ~8&nbsp;MHz. That is if the program makes an abysmal use of cache/TCM.</p></div><div id="tab-2-2-a-question-about-the-hardware-choice"><h4>A question about the hardware choice</h4><p>Back when I read about the CPU of the GameBoy Advance, I was really surprised by the potential of the ARM7: The CPU not only performed its designated tasks, but could also assist with others, such as providing audio sequencing or pseudo-3D graphics.</p><p>Now, during the commercialisation ARM7, ARM Holdings joined forces with DEC to design a high-end version of ARM’s chips. For this, DEC grabbed the datapath design of their processor, <strong>Alpha</strong>, and mixed it with ARM’s. The result was a new series of CPUs called <strong>StrongARM</strong> which was surprisingly <em>fast</em>. At the expense of removing certain features (Thumb and debug), DEC managed to cross the megahertz threshold by reaching speeds of up to 233 MHz. As a normal user prepared to buy a new ARM PC (let’s say a <em>RiscPC</em>), you could either choose one with the old ARM710 at 40 MHz or another one with a StrongARM running ~582% faster. The impact of StrongARM was so disruptive that ARM Holdings absorbed some of StrongARMs features to produce their next line of CPUs, starting with ARM9. And the rest is history.</p><p>But here’s where my question resides: Considering the new developments in the ARM world, why did Nintendo ultimately choose an awfully slow ARM9 combined by an even slower ARM7, instead of a faster ARM9 (or even a StrongARM)? To give you an idea, other companies like Apple just adopted the StrongARM with their Newton PDA line.</p><p>I don’t mean to criticise Nintendo’s choice, but I believe the amount of emerging technology was just too great for me to ignore. I guess their choice was done in an effort to preserve battery life and maintain production costs (by using the same CPU found in the GBA).</p></div></div></div><hr><h2 id="graphics">Graph…</h2></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/nintendo-ds/">https://www.copetti.org/projects/consoles/nintendo-ds/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/nintendo-ds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145124</guid>
            <pubDate>Thu, 13 Aug 2020 16:27:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Q&A: How Eventbrite prioritizes developer productivity]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144790">thread link</a>) | @kklin
<br/>
August 13, 2020 | https://kelda.io/blog/eventbrite-interview/ | <a href="https://web.archive.org/web/*/https://kelda.io/blog/eventbrite-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><picture id="hero-thumbnail">
<source data-srcset="https://kelda.io/img/blog/interview%20microphone.webp" type="image/webp"></picture><p><h2>Published on Aug 11, 2020</h2></p></section><p>Deciding when to invest in developer productivity improvements is hard. If you’re on the ops side of things, you’re usually concerned about production and releases. If you’re a developer, you’re concerned about getting new features out as quickly as possible.</p><p>Usually, teams make development productivity improvements in two situations. Either the fix is so small that you can just do it in addition to your other work, or development is so painful that making changes has ground to a halt.</p><p>However, there’s still a large murky middle ground: how do you decide that it’s worth investing in a <strong>large change</strong> to your development workflow <strong>before development has ground to a halt?</strong></p><p><a href="https://medium.com/@remy.dewolf">Remy DeWolf</a> spent three years making these sorts of decisions as a <strong>principal engineer on the DevTools team at Eventbrite</strong>. He was part of the decision to build <code>yak</code>, which moved Eventbrite’s development environment into the cloud. This was a highly calculated decision since it cost a few EC2 instances per engineer and <code>yak</code> was built from scratch.</p><p>In this first post, we’ll dig into how Remy made this tough decision, and got buy-in from the rest of the company. In our next post, we’ll get into the nitty-gritty on how their remote development environment works, and what it’s been like for developers.</p><h2 id="how-is-the-eventbrite-application-architected">How is the Eventbrite application architected?</h2><p>This is a common story that you will find in a lot of startups. The founding engineers built a monolith and the strategy was to build features fast and capture the market. It was a very successful approach.</p><p>As the company grew over time, having a large team working on the monolith became challenging. And after a certain size, it was also harder to keep scaling the monolith vertically.</p><p>Over time, some of the monolith was migrated over to microservices. New services are generally containerized, and the monolith is containerized in development but not in production.</p><h2 id="whats-your-development-environment-setup-now">What’s your development environment setup now?</h2><p>Every engineer runs <strong>~50 containers</strong> which corresponds to the monolith, the microservices, the data stores (MySQL, Redis, Kafka…) and various tools (logging, monitoring).</p><p>Developers use <code>yak</code> (which we built internally) to deploy and manage their remote containers.</p><p>We use AWS EKS for the Kubernetes clusters, in which every developer has their own namespace. We have hundreds of developers and many EKS clusters.</p><p><code>yak</code> is very similar to <a href="https://kelda.io/blimp">blimp</a> since it enables the engineers to manage their remote containers without exposing them to the complexity of Kubernetes.</p><h2 id="how-did-you-decide-it-was-time-to-build-yak">How did you decide it was time to build yak?</h2><p>Before <code>yak</code>, each developer ran their development environment locally on their laptop. However, the development environment became so big that it slowed down developer laptops.</p><p>The main issue was that you might not realize that this was an issue because it was creeping one service at a time.</p><p>Once we added instrumentalization to our tools, we started to understand the scale of the problems. Moving to the cloud is expensive but when we were able to put it side by side with the wasted engineering time, the decision was easy for us.</p><p>Another goal of <code>yak</code> was to make Kubernetes easy for developers. We kept it as minimal as possible and the configuration files are plain Kubernetes manifest files. The intent was to feed developer curiosity so they learn more about Kubernetes over time.</p><h2 id="what-areas-do-you-recommend-tracking-regarding-developer-productivity">What areas do you recommend tracking regarding developer productivity?</h2><p>Whenever possible, align the developer productivity goals with the business. Every DevTool team should understand how they contribute to the company goals and vice versa. If this is unclear, I would start with that.</p><p>Next, make sure that developer productivity is part of the plan, not an afterthought. For example, some engineering teams move to microservices and only track the number of services and the uptime in production. These are great metrics, but they’re incomplete. They will generate inconsistency and the developer experience will suffer over time.</p><p>In terms of which metrics to pick, there is no general recommendation. It’s important to understand how developers work, understand how frequently they perform critical tasks, and instrument the tools that they use. With this data, you will be able to identify the most important areas to invest and track the progress over time.</p><p>I would also recommend having a metric about mean time to recovery (MTTR). If a developer is completely stuck, how would you bring them back to a clean state so they can resume their work? For this one, if you run the developer environment locally, you will have many different combinations of OS/tools/versions resulting in many different issues. If you are on the cloud and use a generic solution (e.g. Docker + Kubernetes), this problem will be much easier to solve.</p><h2 id="how-did-you-collect-feedback-at-eventbrite">How did you collect feedback at Eventbrite?</h2><p>We had many channels:</p><ul><li>Instrumentation into the tools. Every time a developer would build, run, or deploy docker images we would send metrics. Similarly, every CI job would do the same. Then we would generate some dashboards for the metrics to track and measure the progress over time. If you are using a tool like Sumologic or Datadog, it’s very easy to send custom metrics and build dashboards.</li><li>Quarterly engagement surveys.</li><li>Demos: invite other engineers to show them the progress and engage with them.</li><li>New hires: these new employees bring a fresh perspective and they are not afraid to ask questions and challenge the status quo.</li><li>Networking: build relationships with other developers (coffee breaks, office visits, lunches, etc..)</li></ul><h2 id="can-you-give-some-examples-of-developer-productivity-okrs">Can you give some examples of developer productivity OKRs?</h2><ol><li><p><strong>Time to start the developer environment is under x min</strong></p><p>This time is usually wasted time, so it’s important to track it and improve it. If the dev stack is unreliable or slow, it would be captured in this OKR.</p></li><li><p><strong>Engagement is over x%</strong></p><p>If you send an engagement survey every quarter, you can have an OKR to make sure the trend is upward. Seeing a drop would mean that the team might not be working on the most relevant projects.</p></li><li><p><strong>Average time from commit to QA/Prod</strong></p><p>This one will capture the CI/CD pipeline effectiveness. If you experience some flaky tests or deployment errors in the pipeline, it would negatively impact the key results.</p></li></ol><p>Over time, some OKRs will be exhausted, so consider renewing them over time. For example, if your survey always has the same questions, developers will eventually stop responding. Also if an OKR has been greatly improved, it’s a good time to shift priorities.</p><p>In my personal experience, I would focus on a few OKRs instead of having too many. Sometimes by trying to please everybody, you will not have a big impact. Some projects might require the full team focus, which can temporarily impact other OKRs. This would be a calculated strategy as these projects would bring huge improvements when delivered.</p><h2 id="are-there-any-warning-signs-people-should-look-out-for-in-order-to-know-their-developer-productivity-is-suffering">Are there any warning signs people should look out for in order to know their developer productivity is suffering?</h2><p>This is where it’s important to have good metrics and monitor them over time. You should be able to feel the pulse of your developers by looking at different data points. Ideally, you would tie these to your OKRs and review the progress every sprint and make adjustments.</p><p>If you don’t have this data there are still warning signs that productivity is suffering:</p><ul><li>Increase in support cases and/or requests for help. If developers need external help to do their work, this is a sign that a process is too hard to use or not well documented.</li><li>On the other hand, I’d be worried if you find out that some processes aren’t working properly but nobody reported them to your team. You want developers to be always looking for improvements and not accepting a broken process.</li></ul><p>Kelda has collaborated with Eventbrite for a long time. We first met when we were building the predecessor to <a href="https://kelda.io/blimp">Blimp</a>, which moves your Docker Compose development environment into the cloud. Eventbrite had already built <code>yak</code> internally, and we were trying to make a general solution. We’ve been trading ideas ever since.</p><p><a href="https://kelda.io/blimp">Check out Blimp</a> to get the benefits of <code>yak</code> without having to build it yourself!</p><h2 id="references">References</h2><p>See <a href="https://kelda.io/blimp/docs/#/usage">Blimp commands and usage</a> in the Docs</p><p>Read <a href="https://kelda.io/blog/common-docker-compose-mistakes/">5 common Docker Compose mistakes</a></p><p><a href="https://medium.com/@remy.dewolf">Remy DeWolf’s Medium</a></p><hr><p>By: Kevin Lin</p></div></div>]]>
            </description>
            <link>https://kelda.io/blog/eventbrite-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144790</guid>
            <pubDate>Thu, 13 Aug 2020 16:01:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Postgres Row-Level Security in Python and Django]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144405">thread link</a>) | @karlhughes
<br/>
August 13, 2020 | https://pganalyze.com/blog/postgres-row-level-security-django-python | <a href="https://web.archive.org/web/*/https://pganalyze.com/blog/postgres-row-level-security-django-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>
Postgres introduced <a href="https://www.postgresql.org/docs/9.5/ddl-rowsecurity.html">row-level security</a> in 2016 to give database administrators a way to limit the rows a user can access, adding an extra layer of data protection. What's nice about RLS is that if a user tries to select or alter a row they don't have access to, their query will return 0 rows, rather than throwing a permissions error. This way, a user can use <code>select * from table_name</code>, and they will only receive the rows they have access to with no knowledge of rows they don't.</p>
<p>Most examples of RLS limit row access by database user. This can be a powerful feature. In this article, we will have a look at how you can make this happen for your Django app. The problem most people run into when trying to implement row level security is that most web applications, including Django applications, connect to the database with a single user, which makes it hard to take advantage of row level security. </p>
<p>One way to get around this is to create a database user for each application user. We’ll start with just the database layer. We’ll build out our tables and create a couple of users, then write our first row level security policy to limit which rows those users can access. Once we have an understanding of how RLS works in Postgres, we’ll expand our project out into Django and see how we can handle working with policies and multiple database users in a web application. </p>

<p><span>
      <a href="https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/29114/postgres-row-level-security-django.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Postgres Row-Level Security in Python and Django" title="Postgres Row-Level Security in Python and Django" src="https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/8c557/postgres-row-level-security-django.png" srcset="https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/4edbd/postgres-row-level-security-django.png 175w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/13ae7/postgres-row-level-security-django.png 350w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/8c557/postgres-row-level-security-django.png 700w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/e996b/postgres-row-level-security-django.png 1050w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/2cefc/postgres-row-level-security-django.png 1400w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/29114/postgres-row-level-security-django.png 1920w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span></p>
<h2 id="how-to-use-rls-at-the-database-level"><a href="#how-to-use-rls-at-the-database-level" aria-label="how to use rls at the database level permalink"></a>How to use RLS at the database level</h2>
<p>Before we get to the Django side of things, let's take a look at how RLS works in Postgres. We'll keep it simple and say we are building an app to help our salespeople keep track of their clients, and we want to make sure no salesperson can access the clients of another salesperson. (These are very competitive, cutthroat salespeople). </p>
<p>First, let's set up our tables and populate them with some data:</p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>TABLE</span> salespeople <span>(</span>id <span>serial</span> <span>primary</span> <span>key</span><span>,</span> name <span>text</span><span>)</span><span>;</span>
<span>CREATE</span> <span>TABLE</span> clients <span>(</span>id <span>serial</span> <span>primary</span> <span>key</span><span>,</span> name <span>text</span><span>,</span> salesperson_id <span>integer</span><span>)</span><span>;</span>

<span>INSERT</span> <span>INTO</span> salespeople <span>(</span>name<span>)</span> <span>values</span> <span>(</span><span>'Picard'</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> salespeople <span>(</span>name<span>)</span> <span>values</span> <span>(</span><span>'Crusher'</span><span>)</span><span>;</span>

<span>INSERT</span> <span>INTO</span> clients <span>(</span>name<span>,</span> salesperson_id<span>)</span> <span>values</span> <span>(</span><span>'client1'</span><span>,</span> <span>1</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> clients <span>(</span>name<span>,</span> salesperson_id<span>)</span> <span>values</span> <span>(</span><span>'client2'</span><span>,</span> <span>2</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> clients <span>(</span>name<span>,</span> salesperson_id<span>)</span> <span>values</span> <span>(</span><span>'client3'</span><span>,</span> <span>2</span><span>)</span><span>;</span></code></pre></div>
<p>Now, we have two salespeople. <code>Picard</code> has one client, and <code>Crusher</code> has two clients.</p>
<p>Next, we are going to need some database users, one for each salesperson. Because two salespeople might share the same name, we are going to use the <code>id</code> to create Postgres users. We are also going to create a role called <code>salespeople</code>. This will be the role we grant permissions on, and all of our salespeople can inherit from it.</p>
<div data-language="sql"><pre><code><span>CREATE</span> ROLE <span>"1"</span><span>;</span>
<span>CREATE</span> ROLE <span>"2"</span><span>;</span>
<span>CREATE</span> ROLE salespeople<span>;</span>

<span>GRANT</span> <span>select</span><span>,</span> <span>insert</span> <span>ON</span> clients <span>TO</span> salespeople<span>;</span>
<span>GRANT</span> salespeople <span>TO</span> <span>"1"</span><span>;</span>
<span>GRANT</span> salespeople <span>TO</span> <span>"2"</span><span>;</span></code></pre></div>
<p>This setup will come in handy in the next section when we have to deal with Django's tables in addition to the ones we create for our models.</p>
<p>Now we are ready to set up RLS on our <code>clients</code> table. Our policy will limit access to the Postgres <code>current_user</code> so that they can only view rows where <code>current_user</code> matches <code>salesperson_id</code>. </p>
<div data-language="sql"><pre><code><span>ALTER</span> <span>TABLE</span> clients <span>ENABLE</span> <span>ROW</span> <span>LEVEL</span> SECURITY<span>;</span>
<span>CREATE</span> POLICY salesperson_clients <span>ON</span> clients <span>USING</span> <span>(</span>salesperson_id::<span>text</span> <span>=</span> <span>current_user</span><span>)</span><span>;</span></code></pre></div>
<p>When we create the policy, we give it a name, <code>salesperson_clients</code>, and enter the table we want to set the policy on, <code>clients</code>. Next, we define the policy. In this case, it is very simple: the <code>salesperson_id</code> on the table must be equal to the value of <code>current_user</code>. We have to convert the <code>salesperson_id</code> from an integer to text because our <code>current_user</code> must be a string (we can't create Postgres users with integers as names).</p>
<p>Right now, we are logged in as the <code>postgres</code> user.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>session_user</span><span>,</span> <span>current_user</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code> session_user  | current_user  
---------------+---------------
 postgres      | postgres
(1 row)</code></pre></div>
<p>If we query our <code>clients</code> table, we will be able to see all the rows because <strong>RLS policies do not apply to superusers.</strong></p>

<div data-language="text"><pre><code> id |  name   | salesperson_id 
----+---------+----------------
  1 | client1 |              1
  2 | client2 |              2
  3 | client3 |              2
(3 rows)</code></pre></div>
<p>But if we change the current user, we only get the rows that belong to that user. </p>
<div data-language="sql"><pre><code><span>SET</span> ROLE <span>"1"</span><span>;</span>
<span>SELECT</span> <span>session_user</span><span>,</span> <span>current_user</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code> session_user | current_user 
--------------+--------------
 postgres     | 1
(1 row)</code></pre></div>

<div data-language="text"><pre><code> id |  name   | salesperson_id 
----+---------+----------------
  1 | client1 |              1
(1 row)</code></pre></div>
<h2 id="how-to-use-postgres-row-level-security-in-django"><a href="#how-to-use-postgres-row-level-security-in-django" aria-label="how to use postgres row level security in django permalink"></a>How to Use Postgres Row-Level Security in Django</h2>
<p>Now, how can we translate this to a Django application?</p>
<p>First, we will need to create a database user for each app user we create. One way to accomplish this would be to override the <code>save</code> method on the Salesperson model, but this is a great opportunity to take advantage of <a href="https://docs.djangoproject.com/en/3.0/ref/signals/">Django signals</a> , so we'll create a signal that creates the database user after a new salesperson is saved.  </p>
<p>Next, we'll have to figure out how to switch to the correct user when a salesperson logs in. For this, we can use a middleware that gets the <code>salesperson_id</code> and sets the role in the database. </p>
<h3 id="models"><a href="#models" aria-label="models permalink"></a>Models</h3>
<p>Our models reflect exactly what we set up in our earlier database example. Here I chose to make Salesperson a proxy of Django's built-in <code>User</code> model, but this is not required.</p>
<div data-language="python"><pre><code><span>from</span> django<span>.</span>db <span>import</span> models
<span>from</span> django<span>.</span>contrib<span>.</span>auth<span>.</span>models <span>import</span> User

<span>class</span> <span>Salesperson</span><span>(</span>User<span>)</span><span>:</span>
    <span>class</span> <span>Meta</span><span>:</span>
        proxy <span>=</span> <span>True</span>
    
<span>class</span> <span>Client</span><span>(</span>models<span>.</span>Model<span>)</span><span>:</span>
    name <span>=</span> models<span>.</span>CharField<span>(</span>max_length<span>=</span><span>50</span><span>)</span>
    Salesperson <span>=</span> models<span>.</span>ForeignKey<span>(</span>Employee<span>,</span> on_delete<span>=</span>models<span>.</span>CASCADE<span>)</span></code></pre></div>
<h3 id="django-signals-creating-our-database-user"><a href="#django-signals-creating-our-database-user" aria-label="django signals creating our database user permalink"></a>Django Signals: Creating Our Database User</h3>
<p>We want to create a new database user every time a new salesperson record is created. We can use Django signals to execute some code after a new record is saved. If you're not familiar with signals, the Django docs on this topic are easy to understand. If this piqued your interest, <a href="https://simpleisbetterthancomplex.com/tutorial/2016/07/28/how-to-create-django-signals.html">this article</a> goes into more detail. </p>
<p>Here is the code for the signal itself, but you'll have to reference the above article to get it registered in your app: </p>
<div data-language="python"><pre><code><span>from</span> <span>.</span>models <span>import</span> Salesperson
<span>from</span> django<span>.</span>db<span>.</span>models<span>.</span>signals <span>import</span> post_save
<span>from</span> django<span>.</span>db <span>import</span> connection

<span>def</span> <span>create_db_user</span><span>(</span>sender<span>,</span> instance<span>,</span> created<span>,</span> <span>**</span>kwargs<span>)</span><span>:</span>
    <span>if</span> created<span>:</span>
        user_id <span>=</span> instance<span>.</span><span>id</span>
        <span>with</span> connection<span>.</span>cursor<span>(</span><span>)</span> <span>as</span> cursor<span>:</span>
            cursor<span>.</span>execute<span>(</span><span><span>f'CREATE ROLE "</span><span><span>{</span>user_id<span>}</span></span><span>"'</span></span><span>)</span>
            cursor<span>.</span>execute<span>(</span><span><span>f'GRANT salespeople TO "</span><span><span>{</span>user_id<span>}</span></span><span>"'</span></span><span>)</span>

post_save<span>.</span>connect<span>(</span>create_db_user<span>,</span> sender<span>=</span>Salesperson<span>)</span> </code></pre></div>
<p>The <code>post_save</code> signal can take a named argument <code>created</code>, which is a boolean. This avoids running the code every time we update the record and ensures it will only run when we create a new salesperson. From there, we can get the user id from the instance and use <code>django.db.connection</code> to run our SQL to create the role and grant permissions. </p>
<p>It's very important to note that if you want to use Django's built-in <code>User</code> model and the authentication that comes with it, you'll need to grant <code>salesperson</code> permissions on the <code>django_admin_log</code> and <code>auth_user</code> tables. That's why it's so helpful to have this parent role that all individual users inherit from.</p>
<h3 id="django-middleware-setting-current-user"><a href="#django-middleware-setting-current-user" aria-label="django middleware setting current user permalink"></a>Django Middleware: Setting Current User</h3>
<p>Now, we can write a <a href="https://docs.djangoproject.com/en/3.0/topics/http/middleware/">middleware</a> to switch the database user to the current application user making the request.</p>
<div data-language="python"><pre><code><span>from</span> django<span>.</span>db <span>import</span> connection

<span>class</span> <span>RlsMiddleware</span><span>(</span><span>object</span><span>)</span><span>:</span>
    <span>def</span> <span>__init__</span> <span>(</span>self<span>,</span> get_response<span>)</span><span>:</span>
        self<span>.</span>get_response <span>=</span> get_response
        
    <span>def</span> <span>__call__</span> <span>(</span>self<span>,</span> request<span>)</span><span>:</span>
        user_id <span>=</span> request<span>.</span>user<span>.</span><span>id</span>
        <span>with</span> connection<span>.</span>cursor<span>(</span><span>)</span> <span>as</span> cursor<span>:</span>
            cursor<span>.</span>execute<span>(</span><span><span>f'SET ROLE "</span><span><span>{</span>user_id<span>}</span></span><span>" '</span></span><span>)</span>

        response <span>=</span> self<span>.</span>get_response<span>(</span>request<span>)</span>
        <span>return</span> response</code></pre></div>
<p>We get the user id from the request object. After that, the code looks pretty similar to our signal. We use the Django <code>db</code> connection again to set the role to the corresponding database user, which should match the application user's id. Don't forget to <a href="https://docs.djangoproject.com/en/3.0/topics/http/middleware/#activating-middleware">register your middleware</a> in <code>settings.py</code>.</p>
<p>Now we can use all of Django's built-in query methods while maintaining row-level security in Postgres. What is particularly cool is that, with the role set, all we need to do to get all of a salesperson's clients is call <code>Client.objects.all()</code>, and we can be sure that only the clients related to the salesperson will be returned. If a salesperson tries to query for a client that doesn't belong to them, they'll get zero results.</p>
<h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2>
<p>In this article we were able to create a simple but powerful row level security policy and, with the help of Django middleware and Django signals, implement the policy at the application level. We saw how to create database users each time we created a new application user, and looked at setting the database role to the correct user after log in, ensuring each application user only had access to the rows that belonged to them. </p>
<p>There are a few caveats here. For one, using the ids <code>1, 2, 3</code> is probably not a good idea in production. You'd want to set up some kind of UUID or some other identifier. Also, creating a new database user for every application user becomes hard to scale at a certain point. Row level security can be a useful tool for limiting access at the database level, and we just scratched the surface of what's possible.</p>
<p>Still, you should be sure RLS is the right solution for your application before trying to implement it. In particular, the performance implications of row-level security, and how the Postgres planner treats it for query plans should not be overlooked. This has been <a href="https://medium.com/@cazzer/designing-the-most-performant-row-level-security-strategy-in-postgres-a06084f31945">significantly improved in Postgres 10</a>, but its still essential to <a href="https://pganalyze.com/postgres-explain">monitor your Postgres query plans</a> when using RLS.</p>
<p>In many cases, RLS is not needed, and you’ll be able to secure your data using the <a href="https://coderbook.com/@marcus/how-to-restrict-access-with-django-permissions/">security measures</a> already built into Django.</p>
<p><strong>Share this article:</strong> If you liked this article you might want to <a href="https://ctt.ac/K5png">tweet it to your peers</a>.</p>
<h2 id="about-the-author"><a href="#about-the-author" aria-label="about the author permalink"></a>About the Author</h2>
<p>Josh is a former educator turned developer with a proven ability to learn …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pganalyze.com/blog/postgres-row-level-security-django-python">https://pganalyze.com/blog/postgres-row-level-security-django-python</a></em></p>]]>
            </description>
            <link>https://pganalyze.com/blog/postgres-row-level-security-django-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144405</guid>
            <pubDate>Thu, 13 Aug 2020 15:33:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clear is kind, unclear is unkind]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143896">thread link</a>) | @mcrittenden
<br/>
August 13, 2020 | https://critter.blog/2020/08/13/clear-is-kind-unclear-is-unkind/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/08/13/clear-is-kind-unclear-is-unkind/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-663">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>I am terrified of awkwardness. I know nobody likes an awkward moment, but for me it’s downright crippling. I’ve walked out of the room during awkward moments on TV shows. I once faked internet issues to get out of an uncomfortable work call. I’m a huge fan of the Irish goodbye, because dealing with the not-sure-if-we-should-hug thing sucks. It’s been a serious problem in my life.</p>



<p>And wouldn’t you know it – I also hate giving people news that might upset them. Because that’s often pretty dang awkward. I’ve gotten good at figuring out ways to avoid it without feeling like I avoided it. For example:</p>



<ul><li>I’ve given negative feedback about something really tiny and specific in hopes that it would solve the bigger, much more critical problem, because talking about the critical problem may have been awkward. Spoiler: it never worked.</li><li>I’ve flat out avoided giving negative feedback because “they’re already dealing with a lot” or “I’m going to wait until I have a better example to use, or else it wouldn’t be fair to them” or who knows how many other reasons.</li><li>I’ve given negative feedback that really came from me, but I pitched it like “I don’t think this, but I’m wondering if &lt;a coworker&gt; may think it, from their point of view.”</li></ul>



<p>In that way, I convince my monkey brain that I’m being caring because I’m still “delivering feedback” just without the hurt feelings, right? But no, I’m being a jerk, because <a href="https://brenebrown.com/blog/2018/10/15/clear-is-kind-unclear-is-unkind/">clear is kind, and unclear is unkind</a>. </p>



<p>I don’t know where this first came from, but I heard it from Brené Brown and it was a smack in the face. If I’m not being clear, then I’m being unkind. Period. No matter how much I can try to convince myself that it’s not that simple, it really is.</p>



<p>I am changed. With this as my guiding principle, I feel confident in giving tough feedback no matter how awkward it might be, because anything else would be unkind. And even though I hate awkwardness, I hate being unkind even more.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/08/13/clear-is-kind-unclear-is-unkind/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143896</guid>
            <pubDate>Thu, 13 Aug 2020 14:50:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Even Unicorns Get the Blues]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143764">thread link</a>) | @StuntPope
<br/>
August 13, 2020 | https://outofthecave.io/articles/even-unicorns-get-the-blues/ | <a href="https://web.archive.org/web/*/https://outofthecave.io/articles/even-unicorns-get-the-blues/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Heretical Judge Rules that Uber Can’t Externalize its Labour Costs</h3>
<p><img loading="lazy" src="https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy.jpg" alt="" width="693" height="478" srcset="https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy.jpg 800w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-300x207.jpg 300w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-150x104.jpg 150w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-768x530.jpg 768w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-65x45.jpg 65w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-220x152.jpg 220w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-145x100.jpg 145w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-358x247.jpg 358w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-580x400.jpg 580w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-652x450.jpg 652w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-739x510.jpg 739w" sizes="(max-width: 693px) 100vw, 693px"></p>
<p>As I briefly covered <a href="https://axisofeasy.com/aoe/axisofeasy-158-hundreds-of-smartphone-apps-sell-your-location-data-to-government-connected-data-firms/">in my AxisOfEasy tech digest</a> this week, Uber and Lyft were bracing themselves for a ruling by a California judge that threatened to force them into treating their <span>wage slaves</span> drivers as employees. Lyft said if the ruling went against them it would cause “irreparable damage”. Uber CEO Dara Khosrowshahi penned an <a href="https://www.nytimes.com/2020/08/10/opinion/uber-ceo-dara-khosrowshahi-gig-workers-deserve-better.html">op-ed in the New York Times</a> that just so happened to run Monday, pining for a fair shake for gig economy <span>serfs</span> workers.<span id="more-1152"></span></p>
<p>Khosrowshahi, whose compensation package last year clocked in at $45,000,000 USD, waxed pensively,<em> ‘There has to be a “third way” for gig workers.’ .&nbsp;</em>Ideally one in which Uber wouldn’t be on the hook for their benefits and would be able to continue apace as a Silicon Valley unicorn: posting billions of dollars a quarter in losses and <a href="https://www.forbes.com/sites/janetwburns/2020/03/26/uber-and-airbnb-ask-for-bailouts-critics-arent-having-it/#2a5d61ff7639">jockeying for Federal bailouts.</a> Meanwhile the early stage backers, the VC’s and the private equity funds, would continue to live large off of financialization, not having to worry about the consequences of being <em>the&nbsp;</em>driving force in a race to the bottom for everybody else (even Uber’s lümpenvestors who bought into the IPO are still underwater).</p>
<p>As it turned out, <a href="https://www.theverge.com/2020/8/10/21362460/uber-lyft-drivers-employees-california-court-ruling">Judge Schulman ruled</a> that these gig economy workers are to be treated as employees in the State of California, and sure enough, Uber is now <a href="https://ktla.com/news/california/uber-lyft-threaten-to-leave-california-if-court-upholds-ruling-forcing-them-to-treat-drivers-as-employees/">threatening to pick up their ball and go home.</a></p>
<p>People following my writings may be surprised that I’m not approaching this as yet another government inflicted wound against capitalism, like how laws mandating higher minimum wages actually increase unemployment. It’s a fair point.</p>
<p>But we’re not talking about countless mom-and-pops and other main street businesses having their costs jacked up by economically illiterate career politicians. Even in a climate of government mis-micromanagement and overreach, the so called “free enterprise” participants should be competing under the same conditions. If an independently owned and operated driver service in the state has to operate under onerous taxation and terms, then being a Silicon Valley unicorn shouldn’t exempt you from suffering the same conditions.</p>
<p>In this case we’re talking <a href="https://outofthecave.io/articles/wait-why-is-the-fed-buying-my-biggest-competitors-bonds/">about Cantillonaires</a> who feel entitled to special privileges and exemptions but the reality is this:</p>
<h3>These companies were never intended to be economically viable.</h3>
<p><em>Uber and Lyft started the year with $11.3B and $2.8B in cash on their balance sheets respectively. They posted TTM losses of $10B and$ 2B respectively.&nbsp; They are valued around $54B and $9.2B</em></p>
<p>The only thing that mattered from the outset was to cannibilize the entire market, driving down prices and wages while operating at a loss so that they could garner the next financial event, be it a series D, E or F up-round and then eventually some monster acquisition or IPO. Within truly un-manipulated, free market competition, Uber and Lyft would have either had to compete, <em>viably</em>, with numerous entrants and competitors all fighting under their own steam, or else be snuffed out by economic reality.</p>
<p>The truth is that you can’t actually build a business where every transaction and input is subsidized, ultimately by central bank stimulus, while&nbsp; all normal course responsibilities of operations, like expenses, are externalized.</p>
<p>With the Everything Bubble <a href="https://outofthecave.io/articles/unicorn-winter/">finally looking to pop</a>, and pent up reality s-l-o-w-l-y <a href="https://outofthecave.io/articles/the-jackpot-chronicles-scenario-1-force-majeure/">beginning to reassert itself</a>, these Unicorns will have to face the same situation that every other non-unicorn, non Silicon Valley funded business has to face: Whatever your “boil-the-ocean” big idea is, you’re gonna have to do it in an economically viable way, or it’s not going to happen.</p>
<p><em>To follow my work sign up for the&nbsp;<a href="https://outofthecave.io/join/">Out Of The Cave mailing list</a>, or on&nbsp;<a href="https://nojack.easydns.ca/@stuntpope">Mastodon</a>&nbsp;or&nbsp;<a href="https://twitter.com/stuntpope">Twitter&nbsp;</a></em></p>
<p><a href="#" rel="nofollow" onclick="window.print(); return false;" title="Printer Friendly, PDF &amp; Email"><img src="https://cdn.printfriendly.com/buttons/printfriendly-button.png" alt="Print Friendly, PDF &amp; Email"></a></p></div></div>]]>
            </description>
            <link>https://outofthecave.io/articles/even-unicorns-get-the-blues/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143764</guid>
            <pubDate>Thu, 13 Aug 2020 14:37:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Getting F'ed by Technical Recruiters]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24143721">thread link</a>) | @tacomondays
<br/>
August 13, 2020 | https://scottturman.com/stop-getting-fcked-by-technical-recruiters/ | <a href="https://web.archive.org/web/*/https://scottturman.com/stop-getting-fcked-by-technical-recruiters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="69190526" data-element_type="column">
			<div>
					<div>
				<div data-id="11bdfd87" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:50}" data-widget_type="heading.default">
				<p>
			<h2>Get notified when we publish!</h2>		</p>
				</div>
				<div data-id="50628801" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:100}" data-widget_type="heading.default">
				<p>
			<h2>New Book -Stop Getting Fu*ked By Technical Recruiters</h2>		</p>
				</div>
				
				<div data-id="27158996" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:200}" data-widget_type="heading.default">
				<p>
			<h2>You probably never had anyone teach you how to negotiate your salary or benefits. Not your parents, school and certainly not your employer. Learning to negotiate how much you will charge for your labor may be one of the most important life skills you can ever develop as it will set the tone for how well you can live your life.</h2>		</p>
				</div>
				<section data-id="1bc4b15c" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;fadeIn&quot;,&quot;animation_delay&quot;:300}">
						<div>
				<div>
				<div data-id="1a9f3005" data-element_type="column">
			<div>
					<div>
				
				<div data-id="53e472ce" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>This book is a collection of what I have learned as to how to accomplish this. I hope you will see the value of this book when you stop and realize that for every $10 more per hour you are able to get from a recruiter/employer will translate into another $20,000’ish more per year to your salary. It is also important to understand that every salary can have an additive effect over the lifetime of your total career earnings.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="562d2017" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;fadeIn&quot;,&quot;animation_delay&quot;:300}">
						<div>
				<div>
				<div data-id="4bbccccc" data-element_type="column">
			<div>
					<div>
				
				<div data-id="61cdec01" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>This book is going to teach you to take the power back. You can negotiate a higher rate, as you are the prize. You are the one with the skills needed to make the technology go and the recruiting company is simply one of the many conduits for the work that exists out there in the world.&nbsp;</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div></div>]]>
            </description>
            <link>https://scottturman.com/stop-getting-fcked-by-technical-recruiters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143721</guid>
            <pubDate>Thu, 13 Aug 2020 14:33:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using JDK FlightRecorder and JDK Mission Control]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143664">thread link</a>) | @mfiguiere
<br/>
August 13, 2020 | https://blog.arkey.fr/2020/06/28/using-jdk-flight-recorder-and-jdk-mission-control/ | <a href="https://web.archive.org/web/*/https://blog.arkey.fr/2020/06/28/using-jdk-flight-recorder-and-jdk-mission-control/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>At some point we had an issue with application startup performance.
For a bit of context this app runs in a Kubernetes cluster, with k8s it’s possible
to define a <em>rollout policy</em> to avoid service disruption, that what we had, so there’s a
rollout, new pods (a pod is composed of the application container) get created,
new application are started, then Kubernetes has a mean to check when the application is
<strong>ready</strong>, it’s called the readiness probe. This probe can be a call to http endpoint or a script,
ours is an HTTP endpoint.</p>
<p>WHen the probe indicates the application is ready, the application starts receiving traffic,
from this moment latencies increased from 10-20 milliseconds to seconds.</p>
<p>Opening the recording JMC, it will start an automated analysis. Sometime it’s helpful
and warning should be looked at. In this case the issue was elsewhere.</p>
<p>To help in our case, I needed to go in the thread view, which as a <em>thread lanes</em>
which displays each thread as an horizontal bar, and JFR event are painted on the bar
at the time they happened and for how long. At the bottom there’s a the time axis.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-0-thread-lanes.png" alt="startup 0 thread lanes">
</p>
<p>Thread Lanes</p>
</div>
<p>The first things that catch our eyes will be the vertical patterns, especially the one with
yellow and red around 12:51:15. Let’s zoom (you can select and right click, or use arrow keys.).</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-0-threads-lanes-closer.png" alt="startup 0 threads lanes closer">
</p>
<p>Zooming on the problematic</p>
</div>
<p>The vertical pattern is more precise, these vertical pattern indicates a <em>cross
threads phenomena</em>. And we can notice that all thread are not affected the same way.</p>
<p>The lanes in green at the top indicates these threads are progressing normally, nothing’s
wrong with them. However, if we go down there especially, the pattern materialize around
12:51:11.</p>
<p>Each color indicate some events:</p>
<div>
<ul>
<li>
<p>Gray ⇒ the thread does nothing, it’s parked</p>
</li>
<li>
<p>Small dark point ⇒ The park event, the thread was scheduled but was eventually parked</p>
</li>
<li>
<p>Red ⇒ In this case it’s a <em>blocked lock</em></p>
</li>
<li>
<p>Yellow ⇒ Here the yellow events that interests us are thread waiting on a lock</p>
</li>
</ul>
</div>
<p>I’m not well versed in describing colors, so know that there are other events that use
a slightly different tone / shade of red, yellow or else. Just click on the event
to see what’s going on.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-threads-jedis-lock-event.png" alt="startup 1 threads jedis lock event">
</p>
<p>monitor blocked</p>
</div>
<p>The UI could be improved but going over the events shows a popup with its details,
for the Monitor Blocked event, there’s the duration this monitor was block, who held
this monitor before, and the monitor address in the heap.</p>
<p>This monitor was held for ~9s, that’s a big bottleneck !</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-threads-jedis-monitor-acquire-blocked.png" alt="startup 1 threads jedis monitor acquire blocked">
</p>
</div>
<p>In this case this application had ~200 thread competing for this lock in particular. And finding
the thread that acquired it is not automated, it’s a bit tedious, but in the end didn’t reveal
anything.</p>
<p>However, the Monitor Blocked event has another interesting element, the stacktrace. In the lower
pane of JMC, if the event is selected, we can see the stack trace where this event was emitted.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-threads-jedis-monitor-blocked-stack.png" alt="startup 1 threads jedis monitor blocked stack">
</p>
<p>jedis classloading</p>
</div>
<p>Here that’s the JDK classloader. I would never have thought that the JDK code would cause ~9s
contention. But looking at the stacktrace, there <em>jedis</em> (a Redis client) connection pool involved.
Maybe the class have static initialization that does IO, maybe it’s the agent that runs in production
that introduces latencies during this specific classloading.</p>
<p>But all the threads starts working again around 12:51:22, and redis bottleneck is not anymore an issue
afterward. Let’s look at the story on the IO side, open the Socket IO view.</p>
<p>Identify which one is related to redis, either via IP or via port (Redis is <code>6379</code>).</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-socketio-redis-port.png" alt="startup 1 socketio redis port">
</p>
<p>Socket IO with redis port selected</p>
</div>
<p>While we see a total time of 30s, it’s the accumulated time for all thread for the recording duration (6m).
So nothing fancy here. However, we see that actual IO happens later, around 12:51:22.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-socketio-redis.png" alt="startup 1 socketio redis">
</p>
<p>Socket IO actual Redis read / write</p>
</div>
<p>I’m not sure of the cause, we can definitely rule out Redis, the is either in the network, during
connection establishment, or actually during classloading.</p>
<p>In order to remediate that, we noticed this code is called once the application is ready.
So in order to avoid the contention the code was changed to pre-connect to redis during the
application startup before the application is considered ready. And it worked, this
specific issue disappeared.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-thread-lanes.png" alt="startup 2 thread lanes">
</p>
</div>
<p>The issue identified in the first recording showed some contention on redis, this is now gone.
There is however in this second iteration multiple other issues when flying the mouse pointer
over the yellow and red events.</p>
<div>
<p>Incriminating stack traces 1</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-01.png" alt="startup 2 stack 01">
</p>
<p>Jersey’s <code>ListMultiMap</code> classloading</p>
</div>
</div>
</div>
<div>
<p>2</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-02.png" alt="startup 2 stack 02">
</p>
<p>Jackson’s <code>SerializerCache</code> initialization</p>
</div>
</div>
</div>
<div>
<p>3</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-03.png" alt="startup 2 stack 03">
</p>
<p>Jersey’s <code>ImprovedAbstractMap</code> classloading</p>
</div>
</div>
</div>
<div>
<p>4</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-04.png" alt="startup 2 stack 04">
</p>
<p>Jackson’s <code>PropertySerializerMap</code> initialization</p>
</div>
</div>
</div>
<div>
<p>5</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-05.png" alt="startup 2 stack 05">
</p>
<p>Jackson’s <code>TypeFactory</code> initialization</p>
</div>
</div>
</div>
<div>
<p>6</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-06.png" alt="startup 2 stack 06">
</p>
<p>Jackson’s <code>DeserializerCache</code> initialization</p>
</div>
</div>
</div>
<div>
<p>7</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-07.png" alt="startup 2 stack 07">
</p>
<p>Guava’s <code>hash</code> function involving classloading</p>
</div>
</div>
</div>
<div>
<p>8</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-08.png" alt="startup 2 stack 08">
</p>
<p>Newrelic’s <code>SynchronizedCollection.size()</code></p>
</div>
</div>
</div>
<div>
<p>9</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-09.png" alt="startup 2 stack 09">
</p>
<p>Jackson’s <code>PropertySerializerMap</code> initialization</p>
</div>
</div>
</div>
<div>
<p>10</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-10.png" alt="startup 2 stack 10">
</p>
<p>Datastax cassandra driver’s <code>ChainedResultSetFuture</code> involving classloading</p>
</div>
</div>
</div>
<div>
<p>11</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-11.png" alt="startup 2 stack 11">
</p>
<p>Jersey’s <code>AbstractMapBasedMultimap</code> involving classloading</p>
</div>
</div>
</div>
<p>All the stacktraces above have one thing in common, a contention on a lock.
As thread were blocked, and new request appeared, this had the effects of increase the
queuing, and made tomcat creates new <em>http nio</em> worked threads until the maximum is reached
(200 by default). I applied the same trick: i.e before readiness, exercise code paths that
are lazy initialized. And it worked too. Most contention disappeared afterward.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-3-C2-compiler.png" alt="startup 3 C2 compiler">
</p>
<p>Better startup / C2 compiler event</p>
</div>
<p>There was still some potential gain however. I noticed a few C2 compiler related events.
If you don’t know C1 and C2, those are the compilers that transform bytecode to assembly.
C1 interprets the bytecode and may perform some tricks like escape
analysis, but its role is to be fast to execute bytecode and not about optimizing the machine
code assembly. In a second phase C2 may kick in for hot code path that is code that is executed
very often, and its job is to output highly optimized code at the cost of higher computation
resources.</p>
<p>Note this compilation event <strong>is not</strong> blocking threads !</p>
<p>As an experiment I used the Graal compiler, which I believe is the new
generation of compiler that have a chance to replace C2. <a href="https://github.com/oracle/graal/blob/master/compiler/README.md">Graal compiler</a>
is part of the <a href="https://github.com/oracle/graal">GraalVM</a> project.
It ships as an experimental option : <code>-XX:+UnlockExperimentalVMOptions -XX:+UseJVMCICompiler</code>.</p>
<p>And the result for this work load in particular, just activating the Graal compiler between
these two successive rollouts.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-3-grafana.png" alt="startup 3 grafana">
</p>
<p>Improved P99</p>
</div>
<p>This graph is falling under the <a href="https://latencytipoftheday.blogspot.com/2014/06/latencytipoftheday-most-page-loads.html"><em>percentlie</em></a>
but the improvement is still visible.</p>
<p>After that experiment when I analyzed the new profile I noticed that JVM was using a lot of time to
revoke bias locking. Note the events in fushia are custom JFR events that track HTTP requests.
(<a href="https://twitter.com/gunnarmorling">Gunnar Morling</a> has an inspiring
<a href="https://www.morling.dev/blog/rest-api-monitoring-with-custom-jdk-flight-recorder-events/">write up</a> about it).</p>
<p>This VM operation is done during safepoint during which the JVM is paused. At this time a lot of
bias revocation event appears, so we removed them, and it works too.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-4-threads-revoke-biased-locks.png" alt="startup 4 threads revoke biased locks">
</p>
<p>Revoke Bias locking</p>
</div>
<p>The graphic below shows the difference in startup time. Other consuming backend services had to timeout
and eventually perform retries during rollouts which increased the pressure on the application.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-5-before-after.png" alt="startup 5 before after">
</p>
<p>Before ⇒ after</p>
</div>
<p>Other smaller issues could be discovered and tackled, for example I noticed a few gaps
200ms wide at 30/1min intervals that were related to GC pauses.</p>
<div>
<p>GC gaps</p>
<p><span><img src="https://blog.arkey.fr/assets/jfr/startup-9-gc-pause-1.png" alt="startup 9 gc pause 1" title="GC gap 1"></span> <span><img src="https://blog.arkey.fr/assets/jfr/startup-9-gc-pause-2.png" alt="startup 9 gc pause 2" title="GC gap 2"></span></p>
</div>
<p>For this application the GC is working within 20ms excepts for a few larger pauses
during the early minutes of startup:</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-9-thread-lanes-gc-pauses-effect.png" alt="startup 9 thread lanes gc pauses effect">
</p>
<p>GC pauses causes new HTTP worker threads</p>
</div>
<p>Tuning GC is out of scope for this article, but JMC presents a nice view that could help identify GC
causes. In my opinion it’s currently a bit less powerful as GC logs because GC events lack
useful information only found in GC logs with appropriate tags and level.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/jmc-java-application-view.png" alt="jmc java application view">
</p>
<p>Java Application view</p>
</div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/jmc-garbage-collection-view.png" alt="jmc garbage collection view">
</p>
<p>Garbage Collection view</p>
</div>
<p>Anyway from there we could imagine a <em>setting</em> file in the JDK dedicated for GC events.
Instead of parsing log files whose <em>string format</em> that may change a bit over releases
(even with unified logging) GC events could be analyzed leveraging the included JFR schema.</p>
<p>Also, with JFR it’s even possible to record memory leak using the <code>profile</code> <em>settings</em> file,
I never tried that in a real situation though, but if this avoids the need to make a heap dump
and parse it then I’m all in.</p>
</div></div>]]>
            </description>
            <link>https://blog.arkey.fr/2020/06/28/using-jdk-flight-recorder-and-jdk-mission-control/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143664</guid>
            <pubDate>Thu, 13 Aug 2020 14:28:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eight Great DevOps Resources for Beginners]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143403">thread link</a>) | @savovaleks
<br/>
August 13, 2020 | https://microtica.com/great-devops-resources/ | <a href="https://web.archive.org/web/*/https://microtica.com/great-devops-resources/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p>The future of DevOps solutions is bright. The <a href="https://www.marketsandmarkets.com/Market-Reports/devops-824.html" target="_blank" rel="noreferrer noopener">global DevOps market size</a> is expected to <strong>increase from $2.90 billion in 2017 to $10.31 billion by 2023</strong>, at a Compound Annual Growth Rate (CAGR) of 24.7% during the forecast period.&nbsp;</p>



<p>The growing need for fast app delivery is driving the market growth, with organizations that want to achieve both speed and quality.&nbsp;</p>



<p>However, the world is facing <a href="https://www.shuttleops.io/the-shortage-of-devops-skills" target="_blank" rel="noreferrer noopener">a shortage of DevOps skills</a>. That’s why DevOps engineers are highly-paid, with <a href="https://www.glassdoor.com/Salaries/devops-engineer-salary-SRCH_KO0,15.htm" target="_blank" rel="noreferrer noopener">Glassdoor estimating</a> <strong>the average annual pay at around $100,000</strong>.&nbsp;</p>



<p>So, if you’re looking for a career switch or upgrade, learning DevOps is a good idea. From books to podcasts, <em>here are the best DevOps resources to start with:&nbsp;</em></p>



<h2><strong><a rel="noreferrer noopener" href="https://www.bookdepository.com/Phoenix-Project-Gene-Kim/9781942788294?ref=grid-view&amp;qid=1588577029418&amp;sr=1-1" target="_blank">The Phoenix Project</a></strong></h2>



<p>Who would have thought you could write a novel about DevOps? Well, Gene Kim, Kevin Behr, and George Spafford obviously did a great job!&nbsp;</p>



<p><strong>The Phoenix Project </strong>is an amazing novel about DevOps. The story revolves around a fictional company called “Parts Unlimited”, where the IT manager gets promoted into a senior position. Then, he gets a deadline of 90 days to repair “The Phoenix Project”, a failing and messy code project that’s crucial to the future of the company. If he fails, the CEO threatens to outsource the entire IT department and let go of the people working in it.</p>



<p>So, he starts working on it with the help of some board members. The most important thing here is his philosophy called The Three Ways. It consists of (obviously) three parts—maximizing the flow of work from left-to-right, starting from business to development to IT operations to the end-user; increasing the feedback loop from right to left, and developing and nurturing a culture of <a href="https://microtica.com/cracking-the-continuous-deployment-code/" target="_blank" rel="noreferrer noopener">continuous deployment</a> and learning.</p>



<p>This philosophy helps him create <strong>a streamlined workflow in the department</strong>, <a href="https://microtica.com/6-tips-to-solve-miscommunication-in-dev-teams/">improve </a><strong><a href="https://microtica.com/6-tips-to-solve-miscommunication-in-dev-teams/" target="_blank" rel="noreferrer noopener">communication</a> and effectiveness</strong>, and make the IT department really valuable to the company.&nbsp;</p>



<p>I think this is a really great book, especially for beginners. It gives a sense of what problems IT departments face every day, and offers realistic solutions.&nbsp;</p>



<h2><strong><a rel="noreferrer noopener" href="https://www.oreilly.com/library/view/infrastructure-as-code/9781491924334/" target="_blank">Infrastructure as Code</a></strong></h2>



<p>Coming from ThoughtWorks, this is another book that focuses on <strong>the entire DevOps movement from a more technical aspect</strong>. This book covers the principles of Infrastructure as Code, practical examples, dynamic infrastructure platforms, various cloud options, tools, patterns, software engineering practices, <a href="https://microtica.com/how-to-create-simple-ci-cd-pipeline/" target="_blank" rel="noreferrer noopener">creation and management of pipelines</a>, workflows, and infrastructure management. They are all divided into three sections—Foundations, Patterns, and Practices.&nbsp;</p>



<p>If you’re interested in similar books, you can check <a href="https://www.amazon.com/Evolutionary-Architecture-Nature-Basis-Design/dp/0471117269" target="_blank" rel="noreferrer noopener">Evolutionary Architecture</a> and <a href="https://www.amazon.com/Building-Microservices-Designing-Fine-Grained-Systems/dp/1491950358/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1508683865&amp;sr=1-1&amp;keywords=microservices" target="_blank" rel="noreferrer noopener">Building Microservices</a>, also by ThoughtWorks.&nbsp;</p>



<h2><a href="https://www.udemy.com/course/linux-academy-devops-essentials/?LSNPUBID=JVFxdTr9V80&amp;ranEAID=JVFxdTr9V80&amp;ranMID=39197&amp;ranSiteID=JVFxdTr9V80-BF4jpUPRiGZluHvCXXjptQ" target="_blank" rel="noreferrer noopener"><strong>DevOps Essentials</strong></a></h2>



<p>This Udemy course has hosted over 40,000 students who gave an average rating of 4.4/5. The course is completely free, covering 2 hours and 15 minutes of video lessons.&nbsp;</p>



<p>This course can give you an understanding of <strong>how DevOps impacts the IT world</strong>. You’ll learn the basic DevOps terminology, the evolution of DevOps, the most important processes, the most common tools used, and the most popular DevOps and cloud providers.&nbsp;</p>



<h2><strong><a rel="noreferrer noopener" href="https://www.udemy.com/course/docker-and-kubernetes-the-complete-guide/?ranMID=39197&amp;ranEAID=JVFxdTr9V80&amp;ranSiteID=JVFxdTr9V80-T3DyVhPcjn.KepO0Rg.oZg&amp;LSNPUBID=JVFxdTr9V80" target="_blank">Docker and Kubernetes: The Complete Guide</a></strong></h2>



<p>Another Udemy course with over 120,000 students enrolled and an average rating of 4.6. During 21.5 hours of video materials, you’ll learn everything you need to know about <strong>Docker and Kubernetes</strong>, even if you don’t have previous experience with these topics.&nbsp;</p>



<p>The course starts with a deep dive into the Docker world, showing you all the Docker fundamentals. Then, you’ll learn everything you need to know about setting up a <a href="https://microtica.com/how-to-create-simple-ci-cd-pipeline/" target="_blank" rel="noreferrer noopener">CI/CD pipeline</a> and implementing it on Github and AWS.&nbsp;</p>



<p>Then, you’ll learn to construct a multi-container application utilizing Node, React, Redis, and Postgres. After this, you should be able to <a href="https://microtica.com/start-creating-infrastructure-on-aws-like-a-pro/" target="_blank" rel="noreferrer noopener">deploy both single- and multi-container applications on AWS</a>.</p>



<p>Finally, you’ll learn how to build a <a href="https://microtica.com/deploy-your-first-microservice-on-kubernetes-in-10-mins/" target="_blank" rel="noreferrer noopener">Kubernetes Cluster</a>. This course even covers setting up HTTPS on Kubernetes.&nbsp;</p>



<p>In their reviews, students say how they loved the way the teacher explains all concepts step-by-step. All in all, it’s one of the best courses on Udemy.&nbsp;</p>



<h2><a href="https://www.udemy.com/course/learn-devops-continuously-deliver-better-software/?LSNPUBID=JVFxdTr9V80&amp;ranEAID=JVFxdTr9V80&amp;ranMID=39197&amp;ranSiteID=JVFxdTr9V80-ImNkBFHUPJQ04wh3qXOm9A" target="_blank" rel="noreferrer noopener"><strong>Learn DevOps: Continuously Deliver Better Software</strong></a></h2>



<p>One of the most detailed courses about DevOps that targets more experienced engineers, System Administrators, IT managers, IT operation members, and other IT professionals.&nbsp;</p>



<p>The lecturer explains how to <strong>improve software delivery with automation, configuration management, provisioning, and deployment.</strong> Docker and Kubernetes are also covered.&nbsp;</p>



<p>Although the course lasts about 4.5 hours, you can add much more by trying everything by yourself. The lecturer even offers support for people who get stuck. Students also have a Facebook group where they post questions and discuss.</p>



<h2><a href="https://netflixtechblog.com/" target="_blank" rel="noreferrer noopener"><strong>The Netflix Tech Blog</strong></a></h2>



<p>The Netflix Tech Blog is a great place where you can find out “how they build code at Netflix.” Developers share literally everything, going beyond DevOps. Here, you’ll learn <strong>how Netflix creates, builds, and manages its system and engineering organizations</strong>.&nbsp;</p>



<p>For example, in one of their blogs, they elaborated on how they applied <a href="https://netflixtechblog.com/applying-netflix-devops-patterns-to-windows-2a57f2dbbf79" target="_blank" rel="noreferrer noopener">Netflix DevOps patterns to Windows</a>, while another one is about their <a href="https://netflixtechblog.com/ready-for-changes-with-hexagonal-architecture-b315ec967749" target="_blank" rel="noreferrer noopener">hexagonal architecture</a>.&nbsp;</p>



<h2><a href="https://www.reddit.com/r/devops/" target="_blank" rel="noreferrer noopener"><strong>DevOps SubReddit</strong></a></h2>



<p>Although it’s not everyone’s first choice, the DevOps SubReddit has many interesting and useful information software engineers should check out. Here, you’ll find a lot of blog posts, articles, and news about DevOps.</p>



<p>Most importantly, you can <strong>engage in discussions with fellow DevOps enthusiasts </strong>and learn a lot from their knowledge and experience, sharing a lot of practical examples.&nbsp;</p>



<h2><strong><a rel="noreferrer noopener" href="https://www.arresteddevops.com/" target="_blank">Podcast: Arrested DevOps</a></strong></h2>



<p>Arrested DevOps is a podcast hosted by Joe Laha, Bridget Kromhout, Matt Stratton, Trever Hess, and Jessica Kerr. They’ve recorded over 130 episodes, with the goal to help developers evolve practices and manage teams that will help them take the maximum out of DevOps.&nbsp;</p>



<p>Listeners can learn more about <strong>DevOps strategies, best tools, and integrations</strong> from delightful guest speakers that come from different parts of the world. The episodes last about 40-45 minutes and are released on a monthly basis.</p>



<p><strong>Here are some other links with DevOps resources you might find useful:&nbsp;</strong></p>



<ul><li><a href="https://techbeacon.com/devops/53-essential-resources-devops-practitioners" target="_blank" rel="noreferrer noopener">53 essential resources for DevOps practitioners</a></li><li><a href="https://aws.amazon.com/devops/resources/" target="_blank" rel="noreferrer noopener">DevOps resources – AWS</a></li><li><a href="https://www.upguard.com/blog/devops-resources-online" target="_blank" rel="noreferrer noopener">The best DevOps resources online</a></li><li><a href="https://opensource.com/article/19/12/devops-resources" target="_blank" rel="noreferrer noopener">8 must-read DevOps articles for success in 2020</a></li></ul>




<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://microtica.com/great-devops-resources/"
    dc:identifier="https://microtica.com/great-devops-resources/"
    dc:title="8 Great DevOps Resources for Beginners &#038; Advanced"
    trackback:ping="https://microtica.com/great-devops-resources/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://microtica.com/great-devops-resources/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143403</guid>
            <pubDate>Thu, 13 Aug 2020 14:00:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Major Drivers of Corporate Reputation Management]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143280">thread link</a>) | @Gpetrium
<br/>
August 13, 2020 | https://gpetrium.com/drivers-of-corporate-reputation-management/ | <a href="https://web.archive.org/web/*/https://gpetrium.com/drivers-of-corporate-reputation-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="3258" data-elementor-settings="[]"><div><div><section data-id="73817750" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;shape_divider_bottom&quot;:&quot;opacity-tilt&quot;}"><div><div><div data-id="718d8d5a" data-element_type="column"><div><div><div data-id="141e8a6c" data-element_type="widget" data-widget_type="image.default"><div><p><img width="900" height="1200" src="https://gpetrium.com/wp-content/uploads/2020/08/joao-tzanno-G9_Euqxpu4k-unsplash-min-min.jpg" data-src="https://gpetrium.com/wp-content/uploads/2020/08/joao-tzanno-G9_Euqxpu4k-unsplash-min-min.jpg" alt="" loading="lazy" data-srcset="https://gpetrium.com/wp-content/uploads/2020/08/joao-tzanno-G9_Euqxpu4k-unsplash-min-min.jpg 900w, https://gpetrium.com/wp-content/uploads/2020/08/joao-tzanno-G9_Euqxpu4k-unsplash-min-min-225x300.jpg 225w, https://gpetrium.com/wp-content/uploads/2020/08/joao-tzanno-G9_Euqxpu4k-unsplash-min-min-768x1024.jpg 768w, https://gpetrium.com/wp-content/uploads/2020/08/joao-tzanno-G9_Euqxpu4k-unsplash-min-min-600x800.jpg 600w" data-sizes="(max-width: 900px) 100vw, 900px" srcset="https://gpetrium.com/wp-content/uploads/2020/08/joao-tzanno-G9_Euqxpu4k-unsplash-min-min.jpg 900w, https://gpetrium.com/wp-content/uploads/2020/08/joao-tzanno-G9_Euqxpu4k-unsplash-min-min-225x300.jpg 225w, https://gpetrium.com/wp-content/uploads/2020/08/joao-tzanno-G9_Euqxpu4k-unsplash-min-min-768x1024.jpg 768w, https://gpetrium.com/wp-content/uploads/2020/08/joao-tzanno-G9_Euqxpu4k-unsplash-min-min-600x800.jpg 600w"></p></div></div></div></div></div></div></div></section><section data-id="815ab48" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"></section><section data-id="b7d2cb0" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"></section><section data-id="2dbd7fe1" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="1f2c3d82" data-element_type="column"><div><div><div data-id="4c78fad6" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Reputation is oftentimes defined as a set of beliefs that are held regarding something or someone’s traits, values or activities. Reputation is often associated with trust and/ or quality and it can be attributed to individuals, products, services, groups or organizations. To many, it serves as a determining factor when it comes to individual engagement and decision making. Many organizations and individuals in competitive markets have realized the impact that reputation has on them, which led to greater expansions in reputation management. The practice aims to build, monitor and control the narrative surrounding one’s traits, values, professionalism/ quality and it can support their respective goals or interests.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Advances in globalization and technology, specially search engines and social media has led to the exponential growth in the importance and value of reputation management. Companies also benefit from vast data pools that are created once individuals go about their everyday online activities, which can serve as additional insight in the area. In this article, GPetrium will look at the types of reputation that may need management while applying business case scenarios that involve corporate and individual as examples.</p></div></div></div><div data-id="35a42c2d" data-element_type="widget" data-widget_type="heading.default"><p><h2>Types of Reputation to Manage</h2></p></div><div data-id="f3f8f8c" data-element_type="widget" data-widget_type="text-editor.default"><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In today’s environment, reputation is built, maintained, controlled and monitored in a variety of different mediums and spectrums. Understanding the different types of mediums in which reputation need to be managed and how such practice is important to ensure that organizations are well positioned for success.</p></div></div><div data-id="5246058" data-element_type="widget" data-widget_type="image.default"><div><p><img width="597" height="592" src="https://gpetrium.com/wp-content/uploads/2020/08/Reputation-Management.jpg" data-src="https://gpetrium.com/wp-content/uploads/2020/08/Reputation-Management.jpg" alt="" loading="lazy" data-srcset="https://gpetrium.com/wp-content/uploads/2020/08/Reputation-Management.jpg 597w, https://gpetrium.com/wp-content/uploads/2020/08/Reputation-Management-300x297.jpg 300w, https://gpetrium.com/wp-content/uploads/2020/08/Reputation-Management-150x150.jpg 150w, https://gpetrium.com/wp-content/uploads/2020/08/Reputation-Management-160x160.jpg 160w, https://gpetrium.com/wp-content/uploads/2020/08/Reputation-Management-50x50.jpg 50w" data-sizes="(max-width: 597px) 100vw, 597px" srcset="https://gpetrium.com/wp-content/uploads/2020/08/Reputation-Management.jpg 597w, https://gpetrium.com/wp-content/uploads/2020/08/Reputation-Management-300x297.jpg 300w, https://gpetrium.com/wp-content/uploads/2020/08/Reputation-Management-150x150.jpg 150w, https://gpetrium.com/wp-content/uploads/2020/08/Reputation-Management-160x160.jpg 160w, https://gpetrium.com/wp-content/uploads/2020/08/Reputation-Management-50x50.jpg 50w"></p></div></div><div data-id="78980c67" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><strong>Base Culture</strong><span> – Drives the main principles that one perceives to be important and aims to strive towards. Failure to live to its perceived culture or to build a culture that at least partially aligns with its surroundings (societal values and morals) can lead to reputation loss which subsequently impacts expected outcomes. Most often, companies post about the values that guide their general behaviour in their website and report on them in an annual basis. As an example, </span><span><a href="https://www.coca-cola.ca/our-company">Coca Cola</a></span><span> openly commit to partaking on sustainable practices in their operations when the company is described.</span></p><p><span>&nbsp;</span><strong>Social Media Presence</strong><span> – Aims to engage with others in virtual communities and networks to grow one’s relationships and reputation. Social media presence may range from employment-oriented networks such as Linkedin to Twitter, Facebook, forums and many more. Online reputation management in social media has become a growing trend and different companies take different approaches. Some companies choose to maintain a strictly professional relationship in which they simply advertise some of their operations and initiatives on their page and reply to urgent matters when necessary, as </span><span><a href="https://www.linkedin.com/company/hydro-one/">Hydro One</a></span><span>’s LinkedIn page for instance. Other companies such as </span><span><a href="https://www.linkedin.com/company/mckinsey/">McKinsey &amp; Company</a></span><span>, use social networks as an opportunity to practice brand development to further segment their expertise. </span><span><a href="https://twitter.com/Wendys?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor">Wendy’s</a></span><span> on the other hand, generate publicity by humorous popular content which ensures that they are engaging with clients in different levels across different platforms.</span><br><span><br></span></p><p><span>&nbsp;</span><strong>Crisis Management</strong><span>– As time passes, moments of intense difficulty, trouble, or even danger are brought forth by internal and external factors which may require immediate attention and responses. The way an organization handles moments of crisis, not only during the difficult moments, but also in preparation to such moments and post-activities can heavily influence perception and impact individual or organizational reputation. For instance, Airbnb’s CEO and cofounder, Brian Chesky, published an </span><span><a href="https://news.airbnb.com/a-message-from-co-founder-and-ceo-brian-chesky/">open letter during the Covid-19 pandemic</a></span><span> detailing the reasons the company was laying-off 25% of its workforce. Despite the hard news, the letter was received as an example of how to handle crisis in a humane way that is respectful of the consequences such actions may have on their employees.</span><br><span><br></span></p><p><span>&nbsp;</span><strong>Customer Experience</strong><span> – Associated to the end-to-end experience that customers face, customer experience is present throughout the customer’s purchase cycle – from their journey of discovery to acquisition and utilization of said products or services. It can often spill over on other mediums in which reputation is also managed such as social media platforms which can result in positive or negative impacts depending on how well the customer experience was delivered. Notoriously, in 2017 an </span><span><a href="https://en.wikipedia.org/wiki/United_Express_Flight_3411_incident">employee from United Airlines forcibly removed a passenger out</a></span><span> of a flight because the plane was overbooked. The incident resulted on the customer being seriously injured and was recorded by other passengers. The incident negatively impacted the company’s reputation and the CEO had to issue a public apology the day following the incident.</span></p><p><span>&nbsp;</span><strong>Financial Reputation or Credit Score</strong><span> – As the saying goes “Cash is King”, this motto drives the importance of fiscal health to organizations and individuals. In most cases, failure to maintain a certain level of financial reputation can impact a financial institution’s perception of a borrower, limiting their ability to finance or leverage their activities. It can also, in some cases, impact value perception of stakeholders and relationships.</span><br><span><br></span></p><p><span>&nbsp;</span><strong>Supplier Relations</strong><span> – Anyone that is dependent on suppliers to deliver a product or service that supports their activity will oftentimes understand the importance of maintaining good supplier relations. Even in a B2B environment, words can travel fast, specially if it is associated with a poor business-customer experience such as late/ no delivery, failure to pay, among others. Managing said reputation can be detrimental to long-term success and growth.</span><br><span><br></span></p><p><span>&nbsp;</span><strong>Online Reputation System</strong><span> – Is a reputation system, mostly found in e-commerce, that aims to give buyers and sellers a tool to comment on each other in areas that the platform deems important in relation to the product/ service. The information disparity between consumer and seller has significantly shifted over the years thanks to online review systems. Several customers will often research a product online, or hear about it online before a purchase. Sometimes, the research might not even be on the platform in which the customer will finalize the purchase. That can happen when the review database of the website does not contain a lot of customer review, the data is considered untrustworthy or the user UI is not friendly.</span><br><span><br></span></p><p><span>&nbsp;</span><strong>Societal Culture</strong><span> – Every culture has a subset of traits and beliefs that drive their attitude and activities. For an organization to succeed, it is essential to consider its reputation as it pertains to the markets that it intends to service. Failure to do so can often lead to backlashes from customers and employees that may impact the bottom line in that specific market. Further, companies need to also to be aware of shifting priorities and beliefs in their demographics as failure to change may also negatively impact the company. For instance, </span><span><a href="https://www.nytimes.com/2018/11/16/style/victorias-secret-bras-decline.html">in 2018 the brand Victoria’s Secret fell into hot waters with the public</a></span><span> for not having models with diverse shapes, colors, and sizes to model their clothing – which ignited body shaming complaints.</span><br><span><br></span></p><p><span>&nbsp;</span><strong>Legitimacy or Trustworthiness</strong><span> – Trust can be everything in relations and transactional deals. Failure to uphold the values and quality that others expect a brand to have can be detrimental to a brand’s reputation and sales may suffer. Famously</span><span><a href="https://www.cbsnews.com/news/30-years-ago-today-coca-cola-new-coke-failure/">, in 1985, Coca-Cola changed its beverage recipe</a></span><span>, customers soon came out with organized campaigns and petitions requesting that the classic Coke recipe be brought back into the market. which got customers so infuriated that they organize campaigns and petitions to bring the classic Coke recipe.</span></p></div></div></div><div data-id="610743cd" data-element_type="widget" data-widget_type="heading.default"><p><h2>Applications in Reputation Management</h2></p></div><div data-id="2a623dd" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Corporate Reputation Management is a continuous effort that organizations of all sizes have to contend to as they shape internal and external relations. When done right, stakeholder opinion may improve tremendously, driving increased revenue, recognition and other accolades. This segment will look at a few key examples of reputation management as it relates to the types talked about above.</p><p><strong>Organizational culture</strong><span> – Imagine an organization that proclaims in public to embody values of being innovative, people oriented and believes in equal pay for equal work. However, information comes out that its gender pay gap is a staggering 30% difference, employees have been poorly managed and it shows on the quality of service provided. Such factors are all compounded by the consistent lack of innovation in relation to peers in the industry. It is to be expected that in a highly competitive market, a company’s reputation could be severely impacted from a customer, employee and prospective stakeholders’ perspective.</span></p><p><strong>Social Media Presence</strong> – Users have come in droves on social media to complain about a product that company XYZK Ltd put on the market. XYZK never had any social media presence and customer support was not enough to pick-up the trend until a month later when major department stores began taking their products off the shelves and revenue suffered a dip. The issue arrives at the CEO’s desk and he requests the company to resolve the matter. The company is now a month late to the game, with limited to no expertise in social media management as it attempts to recuperate from its failure. On the other hand, it may mishandle its social media presence, leading to further reputational loss and even run the risk of getting swiped away in the <span><a href="https://www.dictionary.com/e/pop-culture/cancel-culture/">cancel culture</a></span><span> phenomenon</span>.</p><p><span>Social media gives organizations an opportunity to reach out to its stakeholders in a less formal environment, allowing it to build goodwill and presence. Internet use has grown exponentially throughout the years, with estimates showing a change of 1.36 billion in 2010 to 3.73 billion users in 2016 (</span><span><a href="https://data.worldbank.org/indicator/SP.POP.TOTL">Worldbank 1</a></span><span>, </span><span><a href="https://data.worldbank.org/indicator/it.net.user.zs">2</a></span><span>)</span><span> and social media use has accompanied this rapid expansion (</span><span><a href="https://ourworldindata.org/internet">OurWorldinData</a></span><span>). Companies that lack some sort of social media presence have …</span></p></div></div></div></div></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gpetrium.com/drivers-of-corporate-reputation-management/">https://gpetrium.com/drivers-of-corporate-reputation-management/</a></em></p>]]>
            </description>
            <link>https://gpetrium.com/drivers-of-corporate-reputation-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143280</guid>
            <pubDate>Thu, 13 Aug 2020 13:49:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decentralized Finance, the YAM fiasco and the road to DeFi sustainability]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143042">thread link</a>) | @bpierre
<br/>
August 13, 2020 | https://blog.rotki.com/2020/08/13/sustainable-defi/ | <a href="https://web.archive.org/web/*/https://blog.rotki.com/2020/08/13/sustainable-defi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>13 Aug 2020</span></p><ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#what-is-defi">What is DeFi</a>
    <ul>
      <li><a href="#decentralized-exchanges">Decentralized Exchanges</a></li>
      <li><a href="#lendingborrowing-protocols">Lending/Borrowing Protocols</a></li>
      <li><a href="#synthetic-assets">Synthetic Assets</a></li>
    </ul>
  </li>
  <li><a href="#what-new-possibilities-does-defi-unlock">What new possibilities does DeFi unlock?</a></li>
  <li><a href="#the-dark-side-of-defi">The dark side of DeFi</a>
    <ul>
      <li><a href="#yam-finance">YAM finance.</a></li>
    </ul>
  </li>
  <li><a href="#responsible-decentralized-finance">Responsible Decentralized Finance</a>
    <ul>
      <li><a href="#responsible-defi-user">Responsible DeFi user</a></li>
      <li><a href="#responsible-defi-founder">Responsible DeFi founder</a></li>
      <li><a href="#towards-a-sustainable-defi-ecosystem">Towards a sustainable DeFi ecosystem</a></li>
    </ul>
  </li>
  <li><a href="#closing--about-the-author">Closing / About the author</a></li>
</ul>

  

<p>This post explores what is the concept of Decentralized Finance (DeFi), what new possibilities does it unlock and why it’s so cool and hot right now. On the other side of the coin it touches on the dark side of DeFi with the YOLO farming and unaudited contracts most recently highlighted by the YAM fiasco. Finally it takes a look on the road ahead, the lessons that the community needs to learn in order to create sustainable and responsible DeFi for decades to come. Finacial instruments and tools that will not only be used by a few Twitter bros but permisionlessly by everyone around the world.</p>



<p>In one sentence, decentralized finance is the permissionless decentralized version of various traditional financial instruments such as exchanges, lending, borrowing, synthetic assets e.t.c. There has been a lot of innovation in the sector in the past 2 years.</p>

<h2 id="decentralized-exchanges">Decentralized Exchanges</h2>

<p>We have various decentralized exchanges such as:</p>

<ul>
  <li><a href="https://uniswap.org/">Uniswap</a></li>
  <li><a href="https://kyberswap.com/swap">Kyber</a></li>
  <li><a href="https://www.deversifi.com/">Deversifi</a></li>
</ul>

<p>They all operate in a decentralized way and are non-custodial in stark contrast with centralized exchanges such as Binance, Kraken to which you have to first deposit and give custody of your funds.</p>

<h2 id="lendingborrowing-protocols">Lending/Borrowing Protocols</h2>

<p>There are protocols such as <a href="https://app.compound.finance/">Compound</a> and <a href="https://app.aave.com/home">Aave</a> that allow users to lend their assets to earn interest or to borrow assets after staking some collateral. MakerDAO also offers a form of borrowing via <a href="https://oasis.app/borrow">vaults</a> that can mint the DAI stable token after depositing various forms of collateral.</p>

<h2 id="synthetic-assets">Synthetic Assets</h2>

<p>Synthetic asset protocols such as <a href="https://www.synthetix.io/">Synthetix</a> or <a href="https://www.tokensets.com/">Token Sets</a> combine a mix of different assets into a single asset. This way you can get exposure to multiple different assets by just holding a single synthetic asset.</p>



<p>What DeFi does is nothing new. All of this already exist in one form or another in the world of “traditional finance”. What is so amazing and revolutionary about DeFi is that it’s completely decentralized and permissionless. And that it is accessible to everyone regardless of location or background. It’s unlocking a ton of possibilities for people around the world, building a new permisionless financial system in the process.</p>



<p>Just like with everything involving money this sector also attracts short-termed myopic people and projects who are driven by greed.</p>

<p>There is the concept of a yield farmer, someone who provides liquidity or stakes in a protocol in return for interest, fees or some governance token. Yield farming is not bad per se. Everyone who provides liquidity in all the DeFi protocols is essentially yield farming. There is nothing wrong with that.</p>



<p><img src="https://blog.rotki.com/public/post8/defichad.jpeg"></p>



<p>The bad side of farming is the “DeFi chad” or “Defi Degen”. The kind of meme-driven farmer who jumps from protocol to protocol without any thought on contract safety, chasing the biggest yield, dumping their tokens to the new guys and then moving on. A practice that is obviously unsustainable.</p>

<h2 id="yam-finance">YAM finance.</h2>

<p>A very good example of the irresponsible approach to DeFi is YAM. An experiment that did not even manage to last 2 days. It <a href="https://medium.com/@yamfinance/yam-finance-d0ad577250c7">launched</a> in 19:00 UTC, August 11th, 2020 and <a href="https://medium.com/@yamfinance/yam-post-rescue-attempt-update-c9c90c05953f">died</a> 36 hours later.</p>

<h3 id="what-happened">What happened?</h3>

<p>YAM advertised itself as an experiment from the start. It was a mashup of code from various other DeFi projects, completely unaudited and without any safety hatches or deposit limits. For all intents and purposes a completely reckless enterprise. Despite that at its peak it had over $500m locked in it!</p>

<p>For a technical explanation of the bug read <a href="https://medium.com/@yamfinance/yam-post-rescue-attempt-update-c9c90c05953f">their post</a>. In short the bug made it impossible for the YAM holders to reach quorum on anything so essentially the governance part of the protocol was broken and without it the entire protocol could no longer function.</p>

<p>Once people realized that, the market cap of YAM went within minutes from $60m to 0. Everyone left holding YAM they bought took a loss as they can’t sell it, so did uniswap liquidity providers as they took a loss every time someone sold YAM through them.</p>

<h3 id="could-this-have-been-avoided">Could this have been avoided?</h3>

<p>ABSOLUTELY</p>

<p>There were multiple warnings from many prominet people in the crypto sector including myself that this is going to end in tears. The minimum precaution that could have been taken is:</p>

<ul>
  <li>Write contract tests</li>
  <li>Have some sort of security audit of the code</li>
  <li>IF you claim it’s an experiment then treat it as such by:
    <ul>
      <li>Putting deposit limits in the code to protect your users</li>
      <li>Put an escape hatch in the code to protect your users.</li>
    </ul>
  </li>
</ul>

<h3 id="ponzi">Ponzi</h3>

<p>What’s worse is that from the tokenomics of YAM it was obvious that this was a ponzi game. Note the difference between ponzi game and ponzi scheme as explained in <a href="https://jpkoning.blogspot.com/2018/05/ethereum-is-full-of-ponzis-is-that.html">this</a> article.</p>

<p>Every 12 hours the total supply of the token increased but the amount held by each user stayed the same through a process called rebasing. The first farmers were incentivized to pump and shill YAM via social media so they can find victims onto whom to dump their tokens after the rebase. The new holders had the exact same incentives to pump it even more so they can in turn dump their bags onto the poor sods after the second rebase. And so on and so forth.</p>

<p>It was a “fair” and transparent ponzi, but a ponzi nonetheless. And with the amount of due dilligence people do in Crypto I am 100% certain that most of the people who got shilled into it did not realize that and lost money as a result.</p>

<h3 id="shilling-in-twitter">Shilling in Twitter</h3>

<p>What I personally found <strong>absolutely disgusting</strong> was the incessant amount of shilling of YAM in Twitter by many people in the ethereum community whom I actually respect who were also farming it.</p>

<p>It’s inexcusable, reckless and irresponsible. They were shilling a protocol that had not seen any production use yet, had unaudited code, no tests, no deposit limits or anything. They were doing so only to get more people into the Ponzi game to sustain their profits and dump their bags onto them.</p>

<p>I sincerely hope lessons are now learned. If you are shilling an unaudited insecure ponzi you are part of the problem of why this sector is not taken seriously. We can’t have such irresponsible behavior if we are ever going to reach mass adoption.</p>

<h3 id="what-did-it-cost-us">What did it cost us?</h3>

<p><img src="https://blog.rotki.com/public/post8/yamcrash.jpeg"></p>

<p>Some people lost a lot of money</p>

<ul>
  <li>Marketcap dropped from $60m to $0.</li>
  <li>People who bought YAM are left holding a hot potato, got burned and lost everything they invested.</li>
  <li>Uniswap liquidity providers lost money due to providing liquidity for sellers of a dying token.</li>
  <li>Lots of money in gas fees (300+ gwei) for nothing</li>
</ul>

<p>The rest of the non yam farming ethereum users were left with 300 gwei gas prices and could not really use the ethereum blockchain.</p>

<p>And finally and most importantly, outsiders roll their eyes and we lose credibility. Every nocoiner I know that I tried to explain this to just get their view that crypto is only for scams and ponzi schemes reinforced. Can you blame them?</p>



<p>If you are to keep anything from this post as a take-home message let it be this section. DeFi is good and is here to stay. We just all need to be more responsible about it.</p>

<h2 id="responsible-defi-user">Responsible DeFi user</h2>

<p>As a user don’t rush into every new thing that pops up and promises amazing 100%+ returns. Do you due dilligence, demand audit reports, ask people in the community about the history and portfolio of the founders of the protocol and if possible read the code and understand the tokenomics. DYOR. If something sounds too good to be true that’s because it’s probably a scam or a ponzi.</p>

<h2 id="responsible-defi-founder">Responsible DeFi founder</h2>

<p>As a founder/developer for the love of god DO NOT TEST IN PRODUCTION. Be responsible. Users do not heed warnings, or disclaimers. If it’s an experiment and you want to experiment in the mainnet that’s fine. Then put deposit limits and centralized escape hatches for the first X months. The safety of your users is your responsibility. Avoiding that responsbility through the veil of “just an experiment” won’t be accepted.</p>

<h2 id="towards-a-sustainable-defi-ecosystem">Towards a sustainable DeFi ecosystem</h2>

<p>It is only through responsible development and professionalism that this sector can mature. We won’t get any new users with the YOLO yield farming memes. For DeFi to fullfill its goals of a new permisionless financial system it needs to go mainstream. And it will not achieve that through ponzi games and chad memes in Twitter. This will only be achieved when the ecosystem is perceived by normies to be mature enough so that they can also come in and participante in it. Let’s all then do our part to advance the ecosystem through responsible building and sustainable development and build a new financial system for the many and not for the few.</p>



<p>My name is <a href="https://twitter.com/LefterisJP">Lefteris Karapetsas</a>. I am the founder of <a href="https://rotki.com/">Rotki</a>. It is a project that deals with DeFi, among other things, and believes in the dream of a sustainable permissionless new financial system. We are a portfolio tracker and accounting tool that respect our users’ privacy and we are in this game for the long run and not to scam our users for short term gain.</p>

<p>Here is how you can help us:</p>

<ul>
  <li>Try out Rotki’s <a href="https://github.com/rotki/rotki/releases">latest release</a> and use it daily.</li>
  <li><a href="https://rotki.com/products/">Buy</a> a premium subscription to unlock awesome premium features and also support our development.</li>
  <li>Provide us with <a href="https://github.com/rotki/rotki/issues">feedback</a> in the form of bug reports and feature requests.</li>
  <li><a href="https://github.com/rotki/rotki">Star</a> our Github repo and <a href="https://twitter.com/rotkiapp">follow</a> us on Twitter.</li>
  <li>Chat with us and other users of Rotki in <a href="https://discord.gg/aGCxHG7">Discord</a> or in <a href="https://t.me/rotkiportfolio">Telegram</a>.</li>
  <li>Spread the word so that more people get to try and use Rotki and learn how to both manage their finances but also how to protect the privacy of their financial data.</li>
</ul>

</div>

    </div></div>]]>
            </description>
            <link>https://blog.rotki.com/2020/08/13/sustainable-defi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143042</guid>
            <pubDate>Thu, 13 Aug 2020 13:21:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YouTube's persistent flaws make it a hard app to love]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24142790">thread link</a>) | @whalabi
<br/>
August 13, 2020 | https://unlikekinds.com/article/youtubes-persistent-flaws-make-it-a-hard-app-to-love | <a href="https://web.archive.org/web/*/https://unlikekinds.com/article/youtubes-persistent-flaws-make-it-a-hard-app-to-love">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
      <div>
  <h2 id="the-ludicrousness-of-being-forced-to-watch-youtube-in-480p-on-a-4k-tv">The ludicrousness of being forced to watch YouTube in 480p on a 4K TV</h2>

<p>To watch YouTube videos from my phone, which is where I find them, on my TV, which is where I want to watch them, I’ve long since thrown up my hands and given up using the Cast function of the app. Every time I do, the video shows in 480p, even though I have a fiber connection on which YouTube never buffers. If I change the resolution to 1080p, YouTube stubbornly continues to play the video in a resolution that belongs in the 90s. The issue is <a href="https://support.google.com/chromecast/thread/2308994?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/chromecast/thread/2308994?hl=en">widespread</a>, and pre-dates YouTube’s limitations put in place during the pandemic. My TV is an Android TV, made for Google integration with a built-in YouTube app, and my phone is a Pixel phone. Partially chosen with the hope that they’d work well together.</p>

<p>My connection and TV are perfectly capable of playing the video in 1080p, as I learnt when I discovered a clumsy, irritating workaround: adding videos to my Watch Later list on my phone, then opening the YouTube app on my TV, and fumbling through its clumsy interface with a clumsy remote to pick them up again directly on the TV. Plays in 1080p just fine, no buffering.</p>

<figure><img alt="Thousands of YouTube users frustrated with a long-lived bug" width="840" height="593" src="https://i.imgur.com/zD5nKkS.png"><figcaption>Thousands of YouTube users frustrated with a long-lived bug</figcaption></figure>

<h2 id="have-some-captions-with-that">Have some captions with that</h2>

<p>Even when I’ve given in and kept casting blurry videos, a bizarre issue crops up. After watching for a lengthy period of time, maybe an hour or two, YouTube will decide to pop up English captions over an English video while watching on my English account. I’ll shake my head and switch them off; thankfully at least that setting works even if the quality setting doesn’t. Problem is, when the next video in the queue starts playing, the captions switch themselves back on, for every video thereafter. It’s only rectified by disconnecting my phone from my TV, which loses my queued videos, and starting again. This has been happening for many users, and shockingly, <a href="https://support.google.com/youtube/thread/38916902?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/thread/38916902?hl=en">since 2013</a>.</p>

<p>I can only imagine there’s some kind of complicated machine learning going on here - after all YouTube seems to apply fuzzy logic when it decides to turn captions on or off by itself - the captions come on for some non-English videos but not others. It works a lot of the time and seems fairly smart, but not smart enough: they come on only some of the time I watch a K-pop music video, even by the same artist, for example. Every time this happens, I turn off the captions and rewind the video, providing plenty of data, which I’m sure Google is dutifully recording, about my captioning habits, data it could be using to decide whether to override my choices and turn them back on incessantly.</p>

<p>In a pre-ML world, you might code the captions to come on for non-English videos on an English account, perhaps making a different decision based on music videos, and provide a setting, so the user can decide. This would perfectly suit my needs. The behaviour would be predictable, and in my control. This is a problem with the state of ML these days: the decision is completely opaque, inevitably flawed, and non-overridable.</p>

<h2 id="if-you-cant-guess-just-let-me-choose">If you can’t guess just let me choose</h2>

<p>Playing videos directly on my phone is just as frustrating. Much of the time (but not all of the time) I choose something to watch, it’s 480p on my fiber connection which never buffers. Sometimes the video plays in 1080p, but whether it does or not is completely unpredictable. Now everytime I play a video I immediately open the quality settings and change it over to 1080p and rewind, if it isn’t already. It appears to be happening to <a href="https://support.google.com/youtube/thread/14927224?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/thread/14927224?hl=en">plenty</a> of <a href="https://www.reddit.com/r/youtube/comments/ae5utz/auto_quality_setting_keeps_defaulting_to_the/" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://www.reddit.com/r/youtube/comments/ae5utz/auto_quality_setting_keeps_defaulting_to_the/">users</a>.</p>

<p>If this is the result of YouTube attempting to intelligently guess a resolution that won’t buffer, it’s failing miserably. Were they to provide an option to always stream at a minimum 1080p, users’ experience would be much better - they could even choose auto if they want to let YouTube decide for them. Instead YouTube makes a decision for me with an invisible process I have no say in.</p>

<figure><img alt="YouTube’s widely reviled video suggestions" width="775" height="530" src="https://i.imgur.com/WpPKYs4.jpg"><figcaption>YouTube’s widely reviled video suggestions</figcaption></figure>

<p>Users often take a back seat on YouTube. One of the issues in YouTube’s support forums with the <a href="https://support.google.com/youtube/thread/11285006?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/thread/11285006?hl=en">most upvotes</a> concerns the recommended video thumbnails which can overlap the last <a href="https://support.google.com/youtube/answer/6388789?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/answer/6388789?hl=en">5-20 seconds</a> of the video you chose to watch, causing what is often a significant interruption, or in the case of the support thread above, a critical penalty save in a soccer match. Some argue that it’s up to the uploader to add these or not. It’s up to YouTube whether they appear over the last 1 second or 20, or appear under a video rather in massive intrusive thumbnails over the video. I pay for YouTube, but I have no control over these. If it’s just being provided in the user’s interest, why not give us the option to switch them off?</p>

<h2 id="play-music-or-youtube-music">Play Music or YouTube Music</h2>

<p>Google Play Music is shutting down in favor of YouTube Music, both are services I’ve used for years and pay for. Play Music is different in that it stores your own uploaded music, from back when people had such things. As it’s shutting down, these uploads are being transferred across to YouTube Music. It turns out you <a href="https://support.google.com/youtubemusic/thread/45163028?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtubemusic/thread/45163028?hl=en">can’t transfer your uploaded music to a “Brand account”</a> - I’m not a brand, I have an account which doesn’t use my real name because I prefer to remain anonymous amongst, well, YouTubers. This was made possible when Google <a href="https://www.theguardian.com/technology/2014/jul/16/youtube-trolls-google-real-name-commenter-policy" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://www.theguardian.com/technology/2014/jul/16/youtube-trolls-google-real-name-commenter-policy">backtracked</a> after the disastrous ruckus that began when they tried to enforce a real-name policy.</p>

<p>But it also meant that users ended up with 2 YouTube accounts, unwittingly, one with their Google-set real name, and a so-called brand account. A problem arose. In YouTube Music, I have one account with all my music history, likes, favorites, and recommendations, and another with my substantial uploaded music library. Which means I can’t benefit from recommendations based on my history, without rebuilding it all over again with my real name account (which I’d rather not do, in any case, but have no power over.)</p>

<p>In the <a href="https://support.google.com/youtubemusic/thread/45163028?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtubemusic/thread/45163028?hl=en">YouTube support thread</a> announcing this, Hazel from TeamYouTube happily says “If you have any more questions, let us know in the comments below!”, then received a critical comment, and promptly locked the thread.</p>

<h2 id="let-users-have-some-control-in-the-apps-they-use">Let users have some control in the apps they use</h2>

<p>YouTube, like many big tech companies in the ML age, are using algorithms to govern the experience of their billions of users with inner workings that are invisible to their users, frequently work against their interest, and are unable to be overridden. Worse, whether it’s a bug that’s been around since 2013, a smart AI which isn’t so smart, or a crummy user experience decision, users aren’t being heard or their choices respected.</p>

</div>
</div>
    </div>

          

  </div></div>]]>
            </description>
            <link>https://unlikekinds.com/article/youtubes-persistent-flaws-make-it-a-hard-app-to-love</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142790</guid>
            <pubDate>Thu, 13 Aug 2020 12:51:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Social robots are here to manage our emotions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24142617">thread link</a>) | @donohoe
<br/>
August 13, 2020 | https://restofworld.org/2020/social-robots-are-here-to-hug-you/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/social-robots-are-here-to-hug-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>S</span>arah, an eight-year-old pneumonia patient at <a href="http://www.wigmoreclinic.am/">Wigmore Clinic</a>, had barely eaten for two days. She was scared and depressed; none of the medical staff’s pleas that she try a bite of salad or meat had worked. Then Robin entered her room. Robin made eye contact with Sarah, guessing her age and gender. Robin said hello. Sarah said hello back. They talked about their favorite colors and animals and played “I spy.”&nbsp;</p>



<p>After 20 minutes, Robin told her, “I need to recharge my battery.”&nbsp;</p>



<p>“No, no. Don’t go,” Sarah said. “I want to play more.”&nbsp;</p>



<p>“I will come back if you recharge yourself too,” Robin said.&nbsp;</p>



<p>Sarah picked up her plate and started to eat. Robin, a nearly 4-foot-tall robot, smiled and wheeled away.</p>



<p>In the hallway, Sarah’s parents approached <a href="https://www.linkedin.com/in/karenkhachikyan/">Karén Khachikyan</a>, CEO and co-founder of Expper Technologies, to give him a hug. The robot’s intervention had worked. “It was a very emotional and inspiring moment for us,” Khachikyan said. “We saw how important peer-to-peer connection and interactions are.”&nbsp;</p>



<p><a href="https://www.forbes.com/sites/jeffkart/2020/06/17/robin-the-robot-comforts-kids-in-hospitals-can-help-with-covid-19/">Robin</a>, an <a href="https://meaww.com/amp/robin-friendly-robot-companion-children-expper-tech-la-hospital-khachikyan-armenian-start-up">emotional-support robot</a> for hospitalized children designed by the Armenian startup <a href="https://www.expper.tech/">Expper Technologies</a>, launched earlier this year in four hospitals in Armenia and <a href="https://www.uclahealth.org/welcome-robin-the-ai-robot">expanded</a> to <a href="https://www.abckidsdentalla.com/">ABC Kids Dental Group</a> in Los Angeles and <a href="https://www.uclahealth.org/mattel/">UCLA Mattel Children’s Hospital</a> <a href="https://www.uclahealth.org/body.cfm?id=1397&amp;action=detail&amp;ref=7280&amp;fr=true">in July</a>. Robin can speak English and Armenian, though the team is considering adding Spanish to better serve patients in California. The robot is gender-neutral, roughly the size of an 8-year-old child, and ergonomically designed to be huggable. The robot’s face is an 11-inch display screen that can show various emotions through facial expressions as well as play cartoons, animations, or interactive games.&nbsp;</p>



<p>When he was a university student, then-26-year-old Khachikyan designed <a href="https://www.f6s.com/karenkhachikyan">Charlie</a>, an educational robot that was used by more than 300 children in Armenia. He theorized that, if children were emotionally connected to Charlie, they would be more motivated to learn. “We were creating a friend,” he said.</p>



<p>Now Khachikyan’s goal is to change the way that kids experience hospitalization — particularly, to ameliorate their feelings of loneliness and fear. Robin the robot automates emotional labor in a medical setting, not with the aim of replacing people but of augmenting them, filling in the gaps in emotional support. Why settle for a doctor, nurse, and occupational therapist when you could have all three — plus a robot to keep your fears at bay?&nbsp;</p>



<p>Hospital workers are often overwhelmed. <a href="https://www.researchgate.net/publication/326278803_The_emotional_labor_automation_model_Towards_the_unmanaged_heart">Ekaterina Pogrebtsova</a>, a psychology researcher at the University of Guelph in Ontario, focuses on the cognitive automation processes of emotional labor in humans. She said nursing professionals often suffer from burnout because they perform emotionally intensive tasks on a daily basis. While there are techniques for lessening the strain of this work, they take time to perfect. Pogrebtsova said AI technologies like Robin can “supplement a lot of the tedious, laborious work that employees have had to do for centuries now.”&nbsp;</p>



<p>There are some delightful (and odd) examples of robots that have tried to fulfill emotional needs in a medical setting. Many are furry and responsive. <a href="https://www.sproutel.com/products.html">My Special Aflac Duck</a> is a white duck that <a href="https://www.youtube.com/watch?v=4gbzcDJKxlI">comforts</a> children diagnosed with cancer. Kids can tap seven different cards to the duck’s chest, each of which prompts the duck to express the emotion displayed on the card. (If you put your finger in the duck’s mouth, it will pretend to eat.) PARO, a robotic <a href="https://vancouversun.com/news/robotic-seal-provides-emotional-support-for-alzheimers-patients-at-vancouver-general-hospital">baby harp seal</a>, is covered with tactile sensors on its body and whiskers. PARO is able to recognize its own name and uses AI to repeat behaviors that, in the past, have led to its being petted. There are over 6,000 PARO units in use worldwide, mostly in patient-care settings.&nbsp;</p>



<p>Other examples are even more surreal. <a href="https://www.youtube.com/watch?v=Ugv2LqlepGw">Qoobo</a>, a <a href="https://www.youtube.com/watch?v=-2TbYYXajNY">headless, tadpole-like cushion</a> developed by <a href="https://www.ux-xu.com/products-en">Yukai Engineering</a>, is designed to soothe. A robotic tail wags vigorously when the cushion is petted quickly, at a lackadaisical pace when petted slowly, and intermittently when left by itself. When the product launched in Japan in December 2018, the intended audience was women in their 20s and 30s who live alone and want a pet. Since then, Qoobo has found a market in nursing homes and among patients who have dementia or Alzheimer’s; 15,000 units have been sold in Japan and some 300 in the U.S. A smaller, more portable version, <a href="https://camp-fire.jp/projects/view/228513">Petit Qoobo</a>, is now available for preorder. Petit Qoobo even has a subtle heartbeat.</p>


    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/qoobo_016-40x27.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/qoobo_016-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/qoobo_016-400x267.png 400w, https://restofworld.org/wp-content/uploads/2020/08/qoobo_016-600x400.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="Qoobo, a headless, tadpole-like cushion.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Photo courtesy of Qoobo</span>
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/nursing-home-original-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/nursing-home-original-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/nursing-home-original-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/08/nursing-home-original-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/08/nursing-home-original-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/08/nursing-home-original-2800x1867.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="PARO, the seal robot from Japan.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Photo courtesy of AIST, Japan</span>
			</figcaption>
		</figure></li>
				</ul>
			</div>
      
    </figure>


<p>When Khachikyan and his team were researching the existing landscape of emotional-support robots, they noticed that many models were created as toys or tools of distraction. “There is a lack of communication,” he said. “They are not social.”&nbsp;</p>



<p>Khachikyan’s Expper Technologies focused on creating a robotic peer who lives in the hospital and behaves like a child. “When kids see Robin, it’s like they see another kid,” Khachikyan said. Many of the children put their arms around the robot for a hug. In preliminary tests, some children grew so affectionate toward Robin that they asked if they could get sick again, in order to see it again.&nbsp;</p>



<p>Rather than relying on preprogrammed dialogues providing generic answers to particular questions, the team at Expper trained Robin by studying the conversational patterns of two Armenian psychologists and an occupational therapist. The engineers then used behavior cloning — a machine-learning technique — to teach Robin how to mimic the professionals. The model learns the style of a psychologist’s speech and copies the way they interact with patients.&nbsp;</p>



<p>Robin’s front-facing camera is equipped with facial-recognition technology that analyzes a child’s facial expressions, mood, age, gender, and conversation in order to build a holistic understanding of a child’s emotional state. Based on this analysis, Robin can suggest games or ask questions, in order to improve a child’s mood. An embedded memory model allows Robin to remember particular details about a patient and build follow-up conversations based on that memory.&nbsp;</p>



<p>Mineh Badmagharian, an occupational therapist on the Expper team, described the algorithm directing Robin as a “two-player positive-sum game.” Robin and the child are working together. “The kid wants to receive positive emotions, and Robin’s objective is to maximize that,” she told <em>Rest of World. </em></p>



<p>Last year, Khachikyan and his team raised $200,000 in initial funding from <a href="https://www.smartgate.vc/portfolio">SmartGateVC</a>, <a href="https://hiveventures.co/">HIVE Ventures</a>, and angel investors. They are currently in seed funding to advance the technology and begin mass-producing Robins. The robots are manufactured in Armenia, though Khachikyan said they aim to move production to China. With the success of Robin among adolescent patients, Expper is considering expanding into the field of elder care.</p>



<p>We tend to hear about robots and AI working in less wholesome, less emotionally involved contexts; facial recognition, surveillance, self-driving cars, and customer-service chatbots can have an eldritch <a href="https://www.forbes.com/sites/cognitiveworld/2020/06/15/perfectly-imperfect-coping-with-the-flaws-of-artificial-intelligence-ai/">underbelly</a>. Robin and a generation of emotional-support robots show that AI can replace human <a href="https://howwegettonext.com/let-robots-handle-your-emotional-burnout-at-work-e09babbe81e8">emotional labor</a>, narrowing <a href="https://knowledge.insead.edu/blog/insead-blog/can-emotion-be-automated-11941">emotional literacy gaps</a> between robots and humans. “I believe that people need people,” Khachikyan said. “We don’t want to replace anyone with Robin. Our vision is to create a teammate.”</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/social-robots-are-here-to-hug-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142617</guid>
            <pubDate>Thu, 13 Aug 2020 12:23:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Significant JavaScript projects from 2006 to 2020]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24142462">thread link</a>) | @michaelrambeau
<br/>
August 13, 2020 | https://bestofjs.org/timeline | <a href="https://web.archive.org/web/*/https://bestofjs.org/timeline">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bestofjs.org/timeline</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142462</guid>
            <pubDate>Thu, 13 Aug 2020 12:04:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to tokenize Japanese in Python]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24142172">thread link</a>) | @polm23
<br/>
August 13, 2020 | https://www.dampfkraft.com/nlp/how-to-tokenize-japanese.html | <a href="https://web.archive.org/web/*/https://www.dampfkraft.com/nlp/how-to-tokenize-japanese.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Over the past several years there's been a welcome trend in NLP projects to be
broadly multi-lingual. However, even when many languages are supported, there's
a few that tend to be left out. One of these is Japanese. Japanese is written
without spaces, and deciding where one word ends and another begins is not
trivial. While highly accurate tokenizers are available, they can be hard to
use, and English documentation is scarce. This is a short guide to tokenizing
Japanese in Python that should be enough to get you started adding Japanese
support to your application.</p>
<figure><a href="https://www.dampfkraft.com/by-id/23543c9a/fugashi-sample.jpg"><img src="https://www.dampfkraft.com/by-id/23543c9a/img/fugashi-sample.jpg.l.jpg"></a><figcaption><span>Photo by <a href="https://unsplash.com/@skrowze?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Alexandre .L</a> on <a href="https://unsplash.com/s/photos/tokyo-tower?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></span>
</figcaption></figure>
<h2 id="getting-ready"> Getting Ready</h2>
<p>First, you'll need to install a tokenizer and a dictionary. For this tutorial
we'll use <a href="https://github.com/polm/fugashi">fugashi</a> with <a href="https://github.com/polm/unidic-lite">unidic-lite</a>, both projects I maintain. You can
install them like this:</p>
<pre><code>pip install fugashi[unidic-lite]
</code></pre>
<p>Fugashi comes with a script so you can test it out at the command line. Type in
some Japanese and the output will have one word per line, along with other
information like part of speech.</p>
<pre><code>&gt; fugashi
麩菓子は、麩を主材料とした日本の菓子。
麩      フ      フ      麩      名詞-普通名詞-一般
菓子    カシ    カシ    菓子    名詞-普通名詞-一般
は      ワ      ハ      は      助詞-係助詞
、                      、      補助記号-読点
麩      フ      フ      麩      名詞-普通名詞-一般
を      オ      ヲ      を      助詞-格助詞
主材    シュザイ        シュザイ        主材    名詞-普通名詞-一般
料      リョー  リョウ  料      接尾辞-名詞的-一般
と      ト      ト      と      助詞-格助詞
し      シ      スル    為る    動詞-非自立可能 サ行変格        連用形-一般
た      タ      タ      た      助動詞  助動詞-タ       連体形-一般
日本    ニッポン        ニッポン        日本    名詞-固有名詞-地名-国
の      ノ      ノ      の      助詞-格助詞
菓子    カシ    カシ    菓子    名詞-普通名詞-一般
。                      。      補助記号-句点
EOS
</code></pre>
<p>The <code>EOS</code> stands for "end of sentence", though fugashi is not actually
performing sentence tokenization; in this case it just marks the end of the
input.</p>
<h2 id="sample-code"> Sample Code</h2>
<p>Now we're ready to get started with converting plain Japanese text into a list
of words in Python.</p>
<pre><code>import fugashi

# This is our sample text.
# "Fugashi" is a Japanese snack primarily made of gluten.
text = "麩菓子は、麩を主材料とした日本の菓子。"

# The Tagger object holds state about the dictionary. 
tagger = fugashi.Tagger()

words = [word.surface for word in tagger(text)]
print(*words)
# =&gt; 麩 菓子 は 、 麩 を 主材 料 と し た 日本 の 菓子 。
</code></pre>
<p>This prints the original sentence with spaces inserted between words. In many
cases, that's all you need, but fugashi provides a lot of other information,
such as part of speech, lemmas, broad etymological category, pronunciation, and
more. This information all comes from <a href="https://unidic.ninjal.ac.jp/">UniDic</a>, a dictionary provided by the
<a href="https://www.ninjal.ac.jp/">National Institute for Japanese Language and Linguistics</a> (NINJAL).</p>
<p>fugashi is a wrapper for <a href="https://taku910.github.io/mecab/">MeCab</a>, a C++ Japanese tokenizer. MeCab is doing
all the hard work here, but fugashi wraps it to make it more Pythonic, easier
to install, and to clarify some common error cases.</p>
<p>You may wonder why part of speech and other information is included by default.
In the classical NLP pipeline for languages like English, tokenization is a
separate step before part of speech tagging. In Japanese, however, knowing part
of speech is important in getting tokenization right, so they're conventionally
solved as a joint task. This is why Japanese tokenizers are often referred to
as "morphological analyzers" (形態素解析器).</p>
<h2 id="notes-on-japanese-tokenization"> Notes on Japanese Tokenization</h2>
<p>There are several things about Japanese tokenization that may be surprising if
you're used to languages like English.</p>
<h3 id="lemmas-may-not-resemble-the-words-in-the-text-at-all"> Lemmas May Not Resemble the Words in the Text at All</h3>
<p>Here's how you get <a href="https://en.wikipedia.org/wiki/Lemma_(morphology)">lemma</a> information with fugashi:</p>
<pre><code>import fugashi
tagger = fugashi.Tagger()
text = "麩を用いた菓子は江戸時代からすでに存在していた。"

print("input:", text)
for word in tagger(text):
    # feature is a named tuple holding all the Unidic info
    print(word.surface, word.feature.lemma, sep="\t")
</code></pre>
<p>And here's the output of the script:</p>
<pre><code>input: 麩を用いた菓子は江戸時代からすでに存在していた。
麩      麩
を      を
用い    用いる
た      た
菓子    菓子
は      は
江戸    エド
時代    時代
から    から
すでに  既に
存在    存在
し      為る
て      て
い      居る
た      た
。      。
</code></pre>
<p>You can see that 用い has 用いる as a lemma, and that し has 為る and い has
居る, handling both inflection and orthographic variation. すでに is not
inflected, but the lemma uses the kanji form 既に.</p>
<p>These lemmas come from UniDic, which by convention uses the "dictionary form"
of a word for lemmas. This is typically in kanji even if the word isn't usually
written in kanji because the kanji form is considered less ambiguous. For
example, この ("this [thing]") has 此の as a lemma, even though normal modern
writing would never use that form. This is also true of 為る in the above
example.</p>
<p>This can be surprising if you aren't familiar with Japanese, but it's not a
problem. It is worth keeping in mind if your application ever shows lemmas to
your user for any reason, though, as it may not be in a form they expect.</p>
<p>Another thing to keep in mind is that most lemmas in Japanese deal with
orthographic rather than inflectional variation. This orthographic variation is
called "<a href="https://ja.wikipedia.org/wiki/%E8%A1%A8%E8%A8%98%E3%82%86%E3%82%8C">hyoukiyure</a>" and causes problems similar to spelling errors in
English.</p>
<h3 id="verbs-will-often-be-multiple-tokens"> Verbs Will Often Be Multiple Tokens</h3>
<p>Any inflection of a verb will result in multiple tokens. This can also affect
adjectives that inflect, like 赤い.  You can see this in the verbs at the end
of the previous example, or in this more compact example:</p>
<pre><code>input: 見た ("looked" or "saw")
output:
見      ミ      ミル    見る    動詞-非自立可能 上一段-マ行     連用形-一般
た      タ      タ      た      助動詞  助動詞-タ       終止形-一般
</code></pre>
<p>This would be like if "looked" was tokenized into "look" and "ed" in English.
This feels strange even to native Japanese speakers, but it's common to all
modern tokenizers. The main reason for this is that verb inflections are
extremely regular, so registering verb stems and verb parts separately in the
dictionary makes dictionary maintenance easier and the tokenizer implementation
simpler and faster. It also works better in the rare case an unknown verb shows
up. (Verbs are a <a href="https://en.wikipedia.org/wiki/Part_of_speech#cite_ref-2:~:text=closed%20classes%20(such%20as%20pronouns%20and%20conjunctions)%20acquire%20new%20members%20infrequently%2C%20if%20at%20all.">closed class</a> in Japanese, which means new verbs aren't
common.)</p>
<p>In the early 90s several tokenizers handled verb morphology directly, but that
approach has been abandoned over time because of the above advantages of the
fine-grained approach. Depending on your application needs you can use some
simple rules to lump verb parts together or just discard non-stem parts as stop
words.</p>
<h3 id="the-tagger-object-has-a-startup-cost"> The Tagger Object Has a Startup Cost</h3>
<p>It's fast enough that you won't notice for one invocation, but creating the
Tagger is a lot of work for the computer. When processing text in a loop it's
important you re-use the Tagger rather than creating a new Tagger for each
input.</p>
<pre><code># Don't do this
for text in texts:
    tagger = fugashi.Tagger()
    words = tagger(text)

# Do this instead
tagger = fugashi.Tagger()
for text in texts:
    words = tagger(text)
</code></pre>
<p>If you follow the second pattern MeCab shouldn't be a speed bottleneck for
normal applications.</p>
<h3 id="always-note-your-tokenizer-details"> Always Note Your Tokenizer Details</h3>
<p>If you publish a resource using tokenized Japanese text, always be careful to
mention what tokenizer and what dictionary you used so your results can be
replicated. Saying you used MeCab isn't enough information to reproduce your
results, because there are many different dictionaries for MeCab that can give
completely different results. Even if you specify the dictionary, it's critical
that you specify the version too, since popular dictionaries like UniDic may be
updated over time. If you want to know more you can read <a href="https://www.dampfkraft.com/nlp/japanese-tokenizer-dictionaries.html">my article about
Japanese tokenizer dictionaries</a>.</p>
<hr>
<p>Hopefully that's enough to get you started with tokenizing Japanese. If you
have trouble, feel free to <a href="https://github.com/polm/fugashi/issues">file an issue</a> or <a href="mailto:polm@dampfkraft.com">contact me</a>.
I'm glad to help out with open source projects as time allows, and for
commercial projects you can hire me to handle the integration directly. Ψ</p>
</div></div>]]>
            </description>
            <link>https://www.dampfkraft.com/nlp/how-to-tokenize-japanese.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142172</guid>
            <pubDate>Thu, 13 Aug 2020 11:25:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things I'm excited for in Neovim 0.5.0: Language Server Protocol]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24142041">thread link</a>) | @numToStr
<br/>
August 13, 2020 | https://nathansmith.io/posts/neovim-lsp | <a href="https://web.archive.org/web/*/https://nathansmith.io/posts/neovim-lsp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>The next major release of <a href="https://neovim.io/">Neovim</a>, 0.5.0, is currently in development and has five <a href="https://neovim.io/roadmap/">promised features</a>:</p>
<blockquote>
<ul>
<li>Lua remote plugin host</li>
<li>Lua user-config: init.lua</li>
<li>Treesitter syntax engine</li>
<li>LSP client for code navigation, refactoring</li>
<li>Extended marks (text properties, decorations, virtual text)</li>
</ul>
</blockquote>
<p>Enticed by offerings of the Neovim roadmap, I decided to install the nightly builds of Neovim and try them for myself. This post will be the first in a series where we focus on the features of Neovim 0.5.0. Today, we’ll look at Neovim’s Language Server Protocol.</p>
<h2 id="what-is-language-server-protocol">What is Language Server Protocol?<a href="#what-is-language-server-protocol" aria-label="what is language server protocol permalink"></a></h2>
<p>The <a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a>, or LSP, is a JSON RPC protocol introduced in 2016 by Microsoft that defines how an editor should talk to a language server. What is a language server? It’s a small program that runs locally on your computer that can provide information about the code you’re writing. The idea is that you tell the LSP where your project is, it scans all your files, and then has an understanding about your project. It can then provide go-to-definition, type info, compiler errors, completion suggestions, and more back to your editor. As the name implies, each language server generally supports only one language. There’s a <a href="https://langserver.org/">community maintained list</a> of major LSP implementations.</p>
<p>That’s cool, you say, but my editor already supports these features. Why should I start using a language server?</p>
<p>That’s a good question. If your editor already supports typo info, auto-completion, and everything else, you likely don’t need a language server. In fact, the LSP might slow you down – it’s likely a built-in editor feature would be faster than your editor making an RPC request to a server running on your computer.</p>
<p>However, the main advantage of the LSP is that it brings together developers who use different editors. The LSP is editor agnostic – if your editor speaks the protocol, it can talk to the server running. That is, instead of developers having to create an Emacs JavaScript plugin, and a Vim JavaScript plugin, and a VS Code JavaScript plugin, they need only create a single JavaScript language server and language server plugins for each editor.</p>
<p><a href="https://langserver.org/">Langserver.org</a> calls this problem “the matrix”, and it’s easy to see why. If we have <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> languages and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> editors, instead of making <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">n \times m</annotation></semantics></math></span></span> integrations we only have to create <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> language servers plus <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> editor LSP plugins.</p>
<figure>
    <span>
      <span></span>
  <img alt="The Matrix Problem. The Language Server Protocol ideally means we have to write less tools and can share tools across editors and environments more easily." title="The Matrix Problem. The Language Server Protocol ideally means we have to write less tools and can share tools across editors and environments more easily." src="https://d33wubrfki0l68.cloudfront.net/12005bad22eafa1b9bdcf4d1d17015b714bded83/b3443/static/96b7982529b79bd6a4f0b7a177abe150/c5bb3/matrix-problem.png" srcset="https://d33wubrfki0l68.cloudfront.net/f19838a5a467210f204603091fc65df562fb57e3/169f6/static/96b7982529b79bd6a4f0b7a177abe150/04472/matrix-problem.png 170w, https://d33wubrfki0l68.cloudfront.net/3424f4fbddec6d16f90e57176654b074aa5cbe2e/17ef2/static/96b7982529b79bd6a4f0b7a177abe150/9f933/matrix-problem.png 340w, https://d33wubrfki0l68.cloudfront.net/12005bad22eafa1b9bdcf4d1d17015b714bded83/b3443/static/96b7982529b79bd6a4f0b7a177abe150/c5bb3/matrix-problem.png 680w, https://d33wubrfki0l68.cloudfront.net/673668b2c637dfeded44b6dc09b1106f9110a2d6/f327d/static/96b7982529b79bd6a4f0b7a177abe150/b12f7/matrix-problem.png 1020w, https://d33wubrfki0l68.cloudfront.net/f2a86b00c660bf46bdd7561e959c2f3e33179bbb/fe4cf/static/96b7982529b79bd6a4f0b7a177abe150/b5a09/matrix-problem.png 1360w, https://d33wubrfki0l68.cloudfront.net/15df038d58e7fa53d1fcbcf5a31b8c4c7d70d78c/91c2c/static/96b7982529b79bd6a4f0b7a177abe150/f2f8c/matrix-problem.png 1490w" sizes="(max-width: 680px) 100vw, 680px" loading="lazy">
    </span>
    <figcaption>The Matrix Problem. The Language Server Protocol ideally means we have to write less tools and can share tools across editors and environments more easily.</figcaption>
  </figure>
<p>Okay, you tell me, so now you’ve just proved <a href="https://en.wikipedia.org/wiki/Conway%27s_law">Conway’s law</a> also applies to open source. But you didn’t answer my original question: why should I use a language server?</p>
<p>Since the community of all JavaScript developers is a superset of all JavaScript Vim developers, this means that you should see more developers working on a JavaScript language server as opposed to a JavaScript Vim plugin. This should ideally mean a generally better language server.</p>
<p>Additionally, since the community of all Vim developers is also better than all JavaScript Vim developers, this should mean better LSP integration support. Vim users can unite and benefit around building a common language server, even if the day-to-day languages they use are different.</p>
<p>While this may not necessarily be true for all editor plugins, it certainly is for Vim. Vim completion can be done for already existing keywords, dictionary words, ctags results, or omnicomplete. Of these, ctags and omnicomplete are the most IDE-like. In my experience, while ctags is pretty good, it can often give inaccurate results if the same name is used in different contexts across a codebase. And omnicomplete is often left neglected: JavaScript omnicomplete hasn’t been <a href="https://github.com/vim/vim/blob/5be4ceecea5520265066eac972460ebb1cdf05e7/runtime/autoload/javascriptcomplete.vim">updated since 2017</a>, a sign of the matrix problem.</p>
<h2 id="upgrading-to-neovim-nightly">Upgrading to Neovim Nightly<a href="#upgrading-to-neovim-nightly" aria-label="upgrading to neovim nightly permalink"></a></h2>
<p>Okay, so I’ve convinced you to try out an LSP. How does it work in Neovim?</p>
<p>Neovim has <a href="https://github.com/neovim/neovim/wiki/Installing-Neovim">great install instructions</a> for most systems (macOS, Windows, popular Linux distros). I’m on macOS, so I ran:</p>
<div data-language="text"><pre><code>brew install --HEAD neovim</code></pre></div>
<p>From there, you can confirm that the installed version of Neovim has LSP support with <code>:h lsp</code>.</p>
<h2 id="a-note-on-lua">A note on Lua<a href="#a-note-on-lua" aria-label="a note on lua permalink"></a></h2>
<p>Recall the first two features of 0.5.0:</p>
<blockquote>
<ul>
<li>Lua remote plugin host</li>
<li>Lua user-config: init.lua</li>
</ul>
</blockquote>
<p>Vimscript, or VimL, is the de facto configuration of Vim. However, it’s also <a href="https://www.reddit.com/r/vim/comments/1bf672/why_does_viml_suck/">not that great of a language</a>: there are lots of odd quirks and performance issues that come with it. As a result, the Neovim core developers decided to add support for Lua in Neovim. Justin M. Keyes goes over the rationale for this decision in a <a href="https://youtu.be/Bt-vmPC_-Ho">great VimConf presentation</a>. The tl;dr is that Lua is a fast language that already exists and is simpler to learn than Vimscript.</p>
<p>Why does this matter? We were going to go over the LSP today, not Lua, right?</p>
<p>Yes and no. Just as Vimscript is the language for which Vim apis are exposed, Lua is becoming the preferred language for which Neovim apis are being exposed. The LSP api is in Lua, meaning we’ll have to write a little bit of Lua to set it up.</p>
<p>If you haven’t written any Lua, don’t fear! Ample code examples will be provided for your copy/pasting pleasure. Lua is a fairly easy language to read if you know any programming language already. If you’re interested in more Lua, <a href="https://learnxinyminutes.com/docs/lua/">Learn X in Y minutes</a> is a great place to start.</p>
<p>However, most Vimmers don’t currently have any Lua configuration files lying around, so we need to cover the basics of going from an <code>init.vim</code> Vimscript file into triggering Lua code. There are a couple ways to do this.</p>
<h3 id="lua-in-your-vim">Lua in your vim<a href="#lua-in-your-vim" aria-label="lua in your vim permalink"></a></h3>
<p>You can put Lua code directly in vimscript files, like so:</p>
<div data-language="vim"><pre><code>lua <span>&lt;</span><span>&lt;</span> EOF
<span>print</span><span>(</span><span>"hello world"</span><span>)</span>
EOF</code></pre></div>
<p>This is great for small to medium snippets of Lua code.</p>
<h3 id="lua-in-a-file">Lua in a file<a href="#lua-in-a-file" aria-label="lua in a file permalink"></a></h3>
<p>You can also tell Neovim to source lua files, given that that fit a directory structure. In Vimscript:</p>

<p>This will look for the file: <code>nvim/lua/lsp/init.lua</code>. This is great for larger, self-contained chunks of Lua code. I prefer this approach and use it in <a href="https://github.com/nathunsmitty/.config">my dotfiles</a>, since it gives me access to Lua syntax highlighting, linters, etc. while editing.</p>
<h2 id="configuring-support-for-servers">Configuring Support for Servers<a href="#configuring-support-for-servers" aria-label="configuring support for servers permalink"></a></h2>
<p>Neovim provides the LSP client built-in, but it needs to which language servers to run and where on your machine they’re located. There’s a <a href="https://neovim.io/doc/user/lsp.html#lsp-core">Lua api</a> provided that allows you to do this; the following will trigger JavaScript LSP:</p>
<div data-language="lua"><pre><code><span>local</span> root_dir <span>=</span> <span>buffer_find_root_dir</span><span>(</span>bufnr<span>,</span> <span>function</span><span>(</span>dir<span>)</span>
  <span>return</span> <span>is_dir</span><span>(</span><span>path_join</span><span>(</span>dir<span>,</span> <span>'node_modules'</span><span>)</span><span>)</span>
<span>end</span><span>)</span>

<span>local</span> bufnr <span>=</span> vim<span>.</span>api<span>.</span><span>nvim_get_current_buf</span><span>(</span><span>)</span>
<span>local</span> javascript_lsp_config <span>=</span> <span>{</span>
  name <span>=</span> <span>"javascript"</span><span>;</span>
  cmd <span>=</span> <span>{</span> <span>path_join</span><span>(</span>os<span>.</span><span>getenv</span><span>(</span><span>"JAVASCRIPT_LANGUAGE_SERVER_DIRECTORY"</span><span>)</span><span>,</span> <span>"lib"</span><span>,</span> <span>"language-server-stdio.js"</span><span>)</span> <span>}</span><span>;</span>
<span>}</span>

<span>local</span> new_config <span>=</span> vim<span>.</span><span>tbl_extend</span><span>(</span><span>"error"</span><span>,</span> javascript_lsp_config<span>,</span> <span>{</span>
  root_dir <span>=</span> root_dir<span>;</span>
<span>}</span><span>)</span>
client_id <span>=</span> vim<span>.</span>lsp<span>.</span><span>start_client</span><span>(</span>new_config<span>)</span>
vim<span>.</span>lsp<span>.</span><span>buf_attach_client</span><span>(</span>bufnr<span>,</span> client_id<span>)</span></code></pre></div>
<p>(This is adapted from <a href="https://neovim.io/doc/user/lsp.html#lsp-extension-example">an example</a> in the LSP manual.)</p>
<p>However, this is a lot of configuration. Is there a better solution?</p>
<h3 id="nvim-lsp-common-server-configuration">nvim-lsp: Common Server Configuration<a href="#nvim-lsp-common-server-configuration" aria-label="nvim lsp common server configuration permalink"></a></h3>
<p>To give a higher level of abstraction for end users who just want to start using a LSP, Neovim provides an official plugin: <a href="https://github.com/neovim/nvim-lsp">nvim-lsp</a>. This is a collection of common LSPs with integrations ready to go. Let’s install it!</p>
<div data-language="vim"><pre><code>
Plug <span>'neovim/nvim-lsp'</span>

<span>call</span> minpac#<span>add</span><span>(</span><span>'neovim/nvim-lsp'</span><span>,</span> <span>{</span><span>'type'</span><span>:</span> <span>'opt'</span><span>}</span><span>)</span>
packadd nvim<span>-</span><span>lsp</span></code></pre></div>
<p>Note that if you’re using a Vim 8’s native package manager (or a package manager that leverages the native package manager, like <a href="https://github.com/k-takata/minpac">minpac</a>), then you need to add the line <code>packadd nvim-lsp</code>. This is because Neovim <a href="https://github.com/neovim/neovim/issues/12670">currently does not source Lua plugins before your <code>init.vim</code> file</a>, meaning that your LSP config will execute before nvim-lsp is loaded, giving errors. With an older <a href="https://neovim.io/doc/user/options.html#'runtimepath'">runtimepath</a>-based plugin manager like <a href="https://github.com/junegunn/vim-plug">vim-plug</a>, this is not an issue.</p>
<p>Now that we’ve downloaded nvim-lsp, we can configure a language server. To set up the <a href="https://github.com/theia-ide/typescript-language-server">TypeScript language server</a>, we simply need to add:</p>
<div data-language="vim"><pre><code>require<span>'nvim_lsp'</span><span>.</span>tsserver<span>.</span>setup<span>{</span><span>}</span></code></pre></div>
<p>There are also <a href="https://github.com/neovim/nvim-lsp#tsserver">configuration options</a> for which filetypes to run it on, how to detect your project’s root directory, etc.</p>
<p>While we’re configuring stuff, let’s add some nice, vim-like shortcuts for LSP features:</p>
<div data-language="vim"><pre><code>nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> <span>gd</span> <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>definition</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> gh     <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>hover</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> gD    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>implementation</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> <span>&lt;</span><span>c</span><span>-</span><span>k</span><span>&gt;</span> <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>signature_help</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> 1gD   <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>type_definition</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> <span>gr</span>    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>references</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> g0    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>document_symbol</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> gW    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>workspace_symbol</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span></code></pre></div>
<p>Note that these mappings override some Vim defaults, so in order to ensure they only work on</p>
<p>Awesome! However, unless you have the TypeScript language server already installed, you still won’t notice any LSP features. This is because you need to install the language server. The bad news is that each language server has its own installation instructions. The good news is the nvim-lsp takes care of it by providing a <code>LspInstall</code> command. All we have to do is run:</p>

<p>and we’re in business!</p>
<h3 id="even-more-abstractions">Even more abstractions<a href="#even-more-abstractions" aria-label="even more abstractions permalink"></a></h3>
<p>There are a few other optional plugins for Neovim that will improve your LSP quality-of-life. These are by no means necessary, you could implement them with a bit of Vimscript and Lua, but they do provide some more polish to the experience.</p>
<h4 id="completion-nvim">completion-nvim<a href="#completion-nvim" aria-label="completion nvim permalink"></a></h4>
<p><a href="https://github.com/nvim-lua/completion-nvim">completion-nvim</a>, as the name implies, is an autocompletion plugin. It’s similar to something like <a href="https://github.com/ycm-core/YouCompleteMe">YouCompleteMe</a> or <a href="https://github.com/Shougo/deoplete.nvim">Deoplete</a> in that it gives auto popup and other improvements on top of Neovim’s LSP api, as well as some other sources.</p>
<div data-language="vim"><pre><code><span>call</span> minpac#<span>add</span><span>(</span><span>'nvim-lua/completion-nvim'</span><span>,</span> <span>{</span><span>'type'</span><span>:</span> <span>'opt'</span><span>}</span><span>)</span>
packadd completion<span>-</span>nvim</code></pre></div>
<div data-language="lua"><pre><code><span>local</span> on_attach <span>=</span> <span>function</span><span>(</span><span>)</span>
  require<span>'completion'</span><span>.</span><span>on_attach</span><span>(</span><span>)</span>
  require<span>'diagnostic'</span><span>.</span><span>on_attach</span><span>(</span><span>)</span>
<span>end</span>
require<span>'nvim_lsp'</span><span>.</span>pyls<span>.</span><span>setup</span><span>{</span>on_attach<span>=</span>on_attach_vim<span>}</span></code></pre></div>
<h4 id="lsp-statusnvim-statusline-support">lsp-status.nvim: Statusline Support<a href="#lsp-statusnvim-statusline-support" aria-label="lsp statusnvim statusline support permalink"></a></h4>
<p><a href="https://github.com/nvim-lua/lsp-status.nvim">lsp-status.nvim</a> is a Lua plugin that allows you to display information from …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nathansmith.io/posts/neovim-lsp">https://nathansmith.io/posts/neovim-lsp</a></em></p>]]>
            </description>
            <link>https://nathansmith.io/posts/neovim-lsp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142041</guid>
            <pubDate>Thu, 13 Aug 2020 11:07:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Business logic is the weakest link in Low-Code security]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141927">thread link</a>) | @xiwenc
<br/>
August 13, 2020 | https://cinaq.com/post/2020/08/09/your-business-logic-is-the-weakest-link-in-low-code-security/ | <a href="https://web.archive.org/web/*/https://cinaq.com/post/2020/08/09/your-business-logic-is-the-weakest-link-in-low-code-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Over the past 5 years <a href="https://trends.google.com/trends/explore?date=2015-01-01%202020-08-02&amp;q=%2Fg%2F11c6cx4nrr">interest in low-code increased 100 folds</a> according to Google Trends:
<img src="https://cinaq.com/media/low-code-trends.png" alt="Low-code development trends">
This correlates with human psychology eager to optimise for efficiency in everything and building software solutions is no exception. As programming is becoming easier and more accessible, in the future, anyone should be able solve their own information automation challenges. Low-code is a relatively new movement that tries to enable those citizen developers with the right tooling lowering the barrier to build applications without writing traditional code. Because most of my professional experience with low-code is around <a href="https://www.mendix.com/">Mendix</a>, I will use it as reference through out this article.</p>

<p>First computer programs were written in machine code by few experts in the early days. This programming ability felt like a super power to many. Just like the Industrial age boosted the human civilisation, the Information Technology age we are currently in is helping the human race reach new heights. Programming languages are invented or improved to enable more efficient or better programming paradigms. This trend in <a href="https://en.wikipedia.org/wiki/History_of_programming_languages">programming languages timeline</a> is recently leading towards visual programming. In the industry this idea is marked as <a href="https://en.wikipedia.org/wiki/Low-code_development_platform">low-code platforms</a>. To me this is currently the highest programming level because of its high productivity characteristics. Low-code is in a nutshell an unification of deployment and composable building blocks nicely packed to play well together reducing the feedback loop at development and runtime.</p>

<p>The cost of higher abstraction which often correlates with higher productivity is <a href="https://en.wikipedia.org/wiki/High-level_programming_language#Abstraction_penalty">Abstraction penalty</a>. As we move up in the pyramid depicted below, we accomplish more with fewer efforts. That little effort however translates to more execute computing instructions. Due to this fact we loose optimisations and also unaware of the extra assumptions made in between. This problem increases more as applications grow larger and depend on libraries. No matter how well documented the libraries are, they are again abstractions of the actual implementation which might be inaccurate or the user of such library might not know or understand the full extends of the functionalities being leveraged on.</p>
<p><img src="https://cinaq.com/media/low-code-productivity-pyramid.png" alt="Higher programming languages result in higher computational instructions count"></p>

<p>A critical aspect of abstraction penalty is the unawareness of implied behaviours. Citizen developers (Low-code developers) leverage a lot from low-code platform itself; often with insufficient experience and knowledge of the underlaying runtime environment. This is a natural cause because these platforms were designed and promoted  for easy adoption. In the case of Mendix a typical security pitfall is negligence of <a href="https://docs.mendix.com/refguide/access-rules">entity access on attributes level</a>. Developers often focus on getting the program to work, in this particular case, a developer would grant access to all users. No matter the seniority, people make mistakes and forget access rule must be refined. In low-code platform like this, it’s very easy to make mistakes and leave open major security holes.</p>
<p>Platforms like Mendix already has <a href="https://www.mendix.com/evaluation-guide/enterprise-capabilities/security">security covered very well</a>. However with a strong platform, you can still build vulnerable applications because the platform does not know or understand your data risk levels. Therefore the weakest link is your business logic on a low-code platform.</p>
<p><img src="https://cinaq.com/media/low-code-mendix-security.png" alt="Business logic is weakest link with Mendix"></p>
<p>A typical example is: developer gives all access to credit card number attribute in the application model. The developer makes a remark to fine tune the access rules later but forgets to do so. Due to time pressure, testers mostly focussed on the happy use cases which did not reveal the CC information leak.</p>
<p>Therefore it’s crucial to have tooling to help detect these mistakes before they hit production. A tool that could reveal more that meets the eye for developers and testers alike. In Mendix, this would mean bypass the View (from <a href="https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller">Model View Controller</a>) showing all accessible data and function calls for a given user. There are few challenges here:</p>
<ul>
<li>How to extensively and automatically collect these data</li>
<li>How to make sense of the collected data to identify security weaknesses</li>
<li>Finally a repeatable and preferably incremental method to assess the security risk coverage</li>
</ul>
<p>Often pentest consultants are called in to assess the security risks of low-code applications. However this process is very labor intensive and error prone. As pointed out, higher generation languages like low-code has a bigger attack vector (related to number of computational instructions together with rapid feature building) requires extensive manual work.</p>

<p>In this article we learned low-code is an upcoming trend and it helps companies innovate faster by increasing the productivity of its developers. However, with the higher abstraction levels, it’s also easier to make security mistakes leaving the application vulnerable to attacks. As the citizen developers group grows, we need tooling in place to help identity security risks with the same low threshold as it requires to develop an app on a low-code platform.</p>

			</div></div>]]>
            </description>
            <link>https://cinaq.com/post/2020/08/09/your-business-logic-is-the-weakest-link-in-low-code-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141927</guid>
            <pubDate>Thu, 13 Aug 2020 10:50:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US Core Inflation Jumps by Most Since 1991]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24141694">thread link</a>) | @jules-jules
<br/>
August 13, 2020 | https://confoundedinterest.net/2020/08/12/us-core-inflation-jumps-by-most-since-1991-while-rent-inflation-fell-to-lowest-rate-since-2015/ | <a href="https://web.archive.org/web/*/https://confoundedinterest.net/2020/08/12/us-core-inflation-jumps-by-most-since-1991-while-rent-inflation-fell-to-lowest-rate-since-2015/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-12687">
			<!-- .entry-header -->		<div>
			<p>
							<span>
					<a href="https://confoundedinterest.net/category/bubble/" rel="category tag">#bubble</a>, <a href="https://confoundedinterest.net/category/banking/" rel="category tag">Banking</a>, <a href="https://confoundedinterest.net/category/bernanke/" rel="category tag">Bernanke</a>, <a href="https://confoundedinterest.net/category/cmbs/" rel="category tag">CMBS</a>, <a href="https://confoundedinterest.net/category/cre/" rel="category tag">CRE</a>, <a href="https://confoundedinterest.net/category/ecb/" rel="category tag">ECB</a>, <a href="https://confoundedinterest.net/category/economy/" rel="category tag">Economy</a>, <a href="https://confoundedinterest.net/category/fannie-mae/" rel="category tag">fannie mae</a>, <a href="https://confoundedinterest.net/category/fed/" rel="category tag">Fed</a>, <a href="https://confoundedinterest.net/category/freddie-mac/" rel="category tag">Freddie Mac</a>, <a href="https://confoundedinterest.net/category/gdp/" rel="category tag">GDP</a>, <a href="https://confoundedinterest.net/category/housing/" rel="category tag">Housing</a>, <a href="https://confoundedinterest.net/category/inflation/" rel="category tag">Inflation</a>, <a href="https://confoundedinterest.net/category/mortgage/" rel="category tag">Mortgage</a>, <a href="https://confoundedinterest.net/category/pension/" rel="category tag">Pension</a>, <a href="https://confoundedinterest.net/category/powell/" rel="category tag">Powell</a>, <a href="https://confoundedinterest.net/category/reits/" rel="category tag">REITs</a>, <a href="https://confoundedinterest.net/category/treasuries/" rel="category tag">Treasuries</a>, <a href="https://confoundedinterest.net/category/treasury/" rel="category tag">Treasury</a>, <a href="https://confoundedinterest.net/category/uncategorized/" rel="category tag">Uncategorized</a>, <a href="https://confoundedinterest.net/category/volatility/" rel="category tag">Volatility</a>, <a href="https://confoundedinterest.net/category/yellen/" rel="category tag">Yellen</a>				</span></p><!-- .cat-links -->
			
			
			<p><span>
				<time datetime="2020-08-12T12:46:59-04:00">August 12, 2020</time><time datetime="2020-08-12T14:36:15-04:00">August 12, 2020</time>			</span>

			<span>1 Minute</span>		</p></div><!-- .entry-meta -->
	
	<div>
		
<p>Well, The Federal Reserve finally got its wish: INFLATION!</p>



<p><em>U.S. consumer prices&nbsp;rose&nbsp;in July by more than expected on a bounce in auto and apparel costs. <strong>The so-called core figure, which excludes volatile food and fuel costs, climbed 0.6% from the prior month, the biggest surge in almost three decades</strong>, according to a Labor Department report Wednesday. The headline figure also increased 0.6%, following the same gain in June. The trend reflects a rebound in demand for goods and services from the depths of the pandemic-induced lockdowns earlier this year</em>.</p>



<figure><img data-attachment-id="12691" data-permalink="https://confoundedinterest.net/coreinf/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png" data-orig-size="736,530" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="coreinf" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>



<p>But on a YoY basis, core inflation rose only 1.6%.</p>



<figure><img data-attachment-id="12694" data-permalink="https://confoundedinterest.net/the-core-1/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png" data-orig-size="736,530" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="the-core-1" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>







<figure><img data-attachment-id="12697" data-permalink="https://confoundedinterest.net/indl-1/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png" data-orig-size="736,530" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="indl-1" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>



<p>But rent inflation fell to 2.8% YoY, the lowest since 2015.</p>



<figure><img data-attachment-id="12698" data-permalink="https://confoundedinterest.net/rentcpi-2/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png" data-orig-size="736,529" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rentcpi" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>



<figure><img data-attachment-id="12709" data-permalink="https://confoundedinterest.net/ogd-1/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg" data-orig-size="329,750" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ogd-1" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=132" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=329" src="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=329" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg 329w, https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=66 66w, https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=132 132w" sizes="(max-width: 329px) 100vw, 329px"></figure>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	<div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-08-12T12:46:59-04:00">August 12, 2020</time><time datetime="2020-08-12T14:36:15-04:00">August 12, 2020</time>		</p><!-- .site-posted-on -->
	</div>
</article></div>]]>
            </description>
            <link>https://confoundedinterest.net/2020/08/12/us-core-inflation-jumps-by-most-since-1991-while-rent-inflation-fell-to-lowest-rate-since-2015/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141694</guid>
            <pubDate>Thu, 13 Aug 2020 10:08:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Limiting Asynchronous Operations Concurrency in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141535">thread link</a>) | @ziir_hn
<br/>
August 13, 2020 | https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/ | <a href="https://web.archive.org/web/*/https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>Today's post is about a little trick I have learned about 2years ago, and that I have since used numerous times in short Node.js scripts I had to write.<br>
It really isn't much, but I guess it may be helpful to others, and probably is an alright first JavaScript post on this blog.</p>
<blockquote>
<p>Say one has a list of things, and for every of these things, one needs to perform an asynchronous operation that returns a Promise, and be notified when all operations have been performed.<br>
How does one limit the number of asynchronous operations being performed conccurently? Without 3rd party dependencies and just a few lines of code?</p>
</blockquote>
<p>Are you seeing the problem yet? Let's build some context:</p>
<h3 id="we-have-a-list-of-99-things%2C-say-resource-identifiers">We have a list of 99 things, say resource identifiers <a href="#we-have-a-list-of-99-things%2C-say-resource-identifiers">#</a></h3>
<pre><code><span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span><br><span>&gt;</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>...</span> <span>99</span><span>]</span></code></pre>
<h3 id="for-each-of-these-things%2C-we-need-to-perform-an-asynchronous-operation">For each of these things, we need to perform an asynchronous operation <a href="#for-each-of-these-things%2C-we-need-to-perform-an-asynchronous-operation">#</a></h3>
<p>First, let's define the function that will perform said asynchronous operation:</p>
<pre><code><br><br><span>function</span> <span>performAsyncOperation</span><span>(</span><span>id</span><span>)</span> <span>{</span><br>  <span>return</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve</span><span>)</span> <span>=&gt;</span> <span>{</span><br>    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>      console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Performed operation for resource </span><span><span>${</span>id<span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span><br>      <span>resolve</span><span>(</span><span>)</span><span>;</span><br>    <span>}</span><span>,</span> <span>300</span><span>)</span><span>;</span><br>  <span>}</span><span>)</span><span>;</span><br><span>}</span></code></pre>
<p>Now, we know that we need to call this function of every single thing out of our list of 99 things, every resource id we have in <code>ids</code>.<br>
Our first approach, would be to naively use <a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array/map">Array.prototype.map</a> and <a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Promise/all">Promise.all</a> and call it a day. But let's have a closer look to this innocent line of code and its implications:</p>
<pre><code><span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span><br>console<span>.</span><span>log</span><span>(</span><span>'All operations performed, moving on to something else now.'</span><span>)</span><span>;</span></code></pre>
<p><em>Note: we might arguably use <a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Promise/allSettled">Promise.allSettled</a> in a real world scenario, but let's assume our asynchronous operations cannot fail.</em></p>
<p>Which we would give us the following complete script:</p>
<pre><code><span>function</span> <span>performAsyncOperation</span><span>(</span><span>id</span><span>)</span> <span>{</span><br>  <span>return</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve</span><span>)</span> <span>=&gt;</span> <span>{</span><br>    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>    console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Performed operation for resource </span><span><span>${</span>id<span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span><br>    <span>resolve</span><span>(</span><span>)</span><span>;</span><br>    <span>}</span><span>,</span> <span>300</span><span>)</span><span>;</span><br>  <span>}</span><span>)</span><span>;</span><br><span>}</span><p><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span><br>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span><br>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></p><p>  <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span><br>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span><br>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span><br><span>}</span></p><p><span>run</span><span>(</span><span>)</span><span>;</span></p></code></pre>
<p>Now, let's run it:</p>
<pre><code>$ node async-operations-promise-all.js
</code></pre>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
All operations performed in 338ms, moving on to something else now.
</code></pre>
<p>As we can see, ~all the asynchronous operations were performed <strong>concurrently</strong>, and sometimes, that's perfectly fine and exactly what we want.</p>
<p><em>Note: <code>Promise.all</code> only waits for all the <code>Promise</code>s to be resolved. The actual asynchronous operation is triggered by the function call from <code>Array.prototype.map</code>, creating a new <code>Promise</code> on each call.</em></p>
<h3 id="the-problem-of-performing-operations-concurrently">The problem of performing operations concurrently <a href="#the-problem-of-performing-operations-concurrently">#</a></h3>
<p>Now, let's assume that our <code>performAsyncOperation</code> really performs an HTTP request, an API Call, a database query, or really anything else that would either suffer or punish us for the load we push on to it. It might be a rate-limited API, or a fragile host.</p>
<p><em>Note: in the actual case of an HTTP request, or database query, the Web/Node.js/etc... API being used will already probably limit concurrency, of which value may or may not configurable, but let's assume that we cannot or do not want to change such settings.</em></p>
<p>In such cases, we simply cannot allow our script to perform all these operations concurrently, as it risks getting our API key revoked, our IP blocked, or the target host/database responding unreliably, etc... Thus we will be searching for a way to limit this concurrency to avoid such scenario.</p>
<p><em>Note: depending on the actual work performed by the asynchronous operation, performing many of these concurrently may also make the process running it consuming significant amount of CPU and/or memory resources on the machine it runs.</em></p>
<h3 id="a-solution%3A-performing-asynchronous-operations-sequentially">A solution: performing asynchronous operations sequentially <a href="#a-solution%3A-performing-asynchronous-operations-sequentially">#</a></h3>
<p>The first solution that may come to mind, would be to perform each of these operations <strong>sequentially</strong>:</p>
<pre><code><span><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span></span><br><span>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></span><br><span></span><br><del>  <span>-</span> <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span></del><br><ins>  <span>+</span> <span>for</span> <span>(</span><span>const</span> id <span>of</span> ids<span>)</span> <span>{</span></ins><br><ins>  <span>+</span>   <span>await</span> <span>performAsyncOperation</span><span>(</span>id<span>)</span><span>;</span></ins><br><ins>  <span>+</span> <span>}</span></ins><br><span>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span></span><br><span><span>}</span></span></code></pre>
<p>Which, if we run this script, gives the following output:</p>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
All operations performed in 29825ms, moving on to something else now.
</code></pre>
<p>As we'd expect, every operation awaits for the previous one to be completed, and, in a way, we found a succesful solution to our problem.<br>
However, one would probably argue this being far from optimal, and that the system against which we run these asynchronous operations can safely withstand up to 3 concurrent operations, thus, our script could theoretically be ~3 times faster.</p>
<h3 id="the-solution%3A-limiting-concurrency-using-workers">The solution: limiting concurrency using workers <a href="#the-solution%3A-limiting-concurrency-using-workers">#</a></h3>
<p>Now, let's take a look at how we can update our script to perform at most 3 operations concurrently.<br>
For that, let's introduce a <code>worker</code> function, to which we will delegate the job of performing one asynchronous operation at a time.</p>
<pre><code><span>const</span> <span>worker</span> <span>=</span> <span>next_</span> <span>=&gt;</span> <span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>  <span>let</span> next<span>;</span><br>  <span>while</span> <span>(</span><span>(</span>next <span>=</span> <span>next_</span><span>(</span><span>)</span><span>)</span><span>)</span> <span>{</span><br>    <span>await</span> <span>performAsyncOperation</span><span>(</span>next<span>)</span><span>;</span><br>  <span>}</span><br><span>}</span><span>;</span></code></pre>
<p><em>Note: such a <code>worker</code> function can be implemented in various ways, this implementation is just an example of what I've used in the past.</em></p>
<p>However big the number of asynchronous operations we wish to perform, we will ever need at most, 3 concurrent <code>workers</code>.</p>
<pre><code><span>const</span> <span>CONCURRENT_WORKERS</span> <span>=</span> <span>3</span><span>;</span></code></pre>
<p>We will then want to give a way to our <code>workers</code> to retrieve the next resource identifier, or thing, to perform the asynchronous operation from.</p>
<pre><code><span>const</span> workers <span>=</span> <span>[</span><span>]</span><span>;</span><br><span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>CONCURRENT_WORKERS</span><span>;</span> i<span>++</span><span>)</span> <span>{</span><br>  <span>const</span> w <span>=</span> <span>worker</span><span>(</span>ids<span>.</span><span>pop</span><span>.</span><span>bind</span><span>(</span>ids<span>)</span><span>)</span><span>;</span><br>  workers<span>.</span><span>push</span><span>(</span><span>w</span><span>(</span>ids<span>)</span><span>)</span><span>;</span><br><span>}</span></code></pre>
<p>Let us update our script:</p>
<pre><code><span><span>function</span> <span>performAsyncOperation</span><span>(</span><span>id</span><span>)</span> <span>{</span></span><br><span>  <span>return</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve</span><span>)</span> <span>=&gt;</span> <span>{</span></span><br><span>    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span></span><br><span>    console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Performed operation for resource </span><span><span>${</span>id<span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span></span><br><span>    <span>resolve</span><span>(</span><span>)</span><span>;</span></span><br><span>    <span>}</span><span>,</span> <span>300</span><span>)</span><span>;</span></span><br><span>  <span>}</span><span>)</span><span>;</span></span><br><span><span>}</span></span><br><span></span><br><ins><span>const</span> <span>worker</span> <span>=</span> <span>next_</span> <span>=&gt;</span> <span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span></ins><br><ins>  <span>let</span> next<span>;</span></ins><br><ins>  <span>while</span> <span>(</span><span>(</span>next <span>=</span> <span>next_</span><span>(</span><span>)</span><span>)</span><span>)</span> <span>{</span></ins><br><ins>    <span>await</span> <span>performAsyncOperation</span><span>(</span>next<span>)</span><span>;</span></ins><br><ins>  <span>}</span></ins><br><ins><span>}</span><span>;</span></ins><br><ins></ins><br><ins><span>const</span> <span>CONCURRENT_WORKERS</span> <span>=</span> <span>3</span><span>;</span></ins><br><ins></ins><br><ins><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span></ins><br><ins>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></ins><br><ins>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></ins><br><ins></ins><br><ins>  <span>const</span> workers <span>=</span> <span>[</span><span>]</span><span>;</span></ins><br><ins>  <span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>CONCURRENT_WORKERS</span><span>;</span> i<span>++</span><span>)</span> <span>{</span></ins><br><ins>    <span>const</span> w <span>=</span> <span>worker</span><span>(</span>ids<span>.</span><span>pop</span><span>.</span><span>bind</span><span>(</span>ids<span>)</span><span>)</span><span>;</span></ins><br><ins>    workers<span>.</span><span>push</span><span>(</span><span>w</span><span>(</span>ids<span>)</span><span>)</span><span>;</span></ins><br><ins>  <span>}</span></ins><br><ins></ins><br><ins>  <span>await</span> Promise<span>.</span><span>all</span><span>(</span>workers<span>)</span><span>;</span></ins><br><span></span><br><span>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span></span><br><span><span>}</span></span><br><span></span><br><span><span>run</span><span>(</span><span>)</span><span>;</span></span></code></pre>
<p>And run it:</p>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
All operations performed in 9948ms, moving on to something else now.
</code></pre>
<h3 id="bonus-solution%3A-batching-concurrent-operations">Bonus solution: batching concurrent operations <a href="#bonus-solution%3A-batching-concurrent-operations">#</a></h3>
<p>There's one more way to look at the problem, and reach another solution: splitting the asynchronous operations to be performed in <strong>batches</strong>.<br>
In our case, if we have 99 operations to perform, we can split these into 33 batches of 3 operations.<br>
With batching, every operation within one batch will be performed conccurently, and the next batch will only be started once the previous one is finished.<br>
How does one implement concurrent operations batching with JavaScript?</p>
<pre><code><span><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span></span><br><span>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></span><br><span></span><br><del>  <span>-</span> <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span></del><br><ins>  <span>+</span> <span>let</span> i <span>=</span> <span>1</span><span>;</span></ins><br><ins>  <span>+</span> <span>while</span> <span>(</span>ids<span>.</span>length<span>)</span> <span>{</span></ins><br><ins>  <span>+</span>   <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>splice</span><span>(</span><span>0</span><span>,</span> <span>3</span><span>)</span><span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>;</span></ins><br><ins>  <span>+</span>   console<span>.</span><span>log</span><span>(</span><span>'Performed async operactions batch number'</span><span>,</span> i<span>)</span><span>;</span></ins><br><ins>  <span>+</span>   i<span>++</span><span>;</span></ins><br><ins>  <span>+</span> <span>}</span></ins><br><span>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span></span><br><span><span>}</span></span></code></pre>
<p>Which gives us the following output:</p>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
Performed async operactions batch number 1
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
Performed async operactions batch number 33
All operations performed in 9981ms, moving on to something else now.
</code></pre>
<h3 id="conclusion">Conclusion <a href="#conclusion">#</a></h3>
<p>Asynchronous JavaScript can be tricky, and though one may argue the language lacks high-level APIs to deal more efficiently with some of these tricky cases like the one we've just covered, it's always worth taking our chance at solving the problems leveraging the features that we're provided by the language.</p>
<p>In this post we've built and lived through a common scenario of managing asynchronous operations concurrency in JavaScript, along with a common pitfall associated with a naive approach, as well as an intermediary solution that is also very useful on some other cases, and finally the optimal solution for dealing with this problem, all without using third party modules. I hope this may be useful to some of you, and that I did not take too many shortcuts in the process.</p>
<p>If you liked this post, feel free to encourage me by saying so on <a href="https://twitter.com/tpillard">my Twitter</a> and/or by liking/retweeting the associated tweet or sharing the article around you.<br>
If, on the contrary, you did not like this post and think I should never write JavaScript and/or on a public medium again, keep it to yourself dude, I know already.<br>
Finally, feel free to share your feedback …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/">https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/</a></em></p>]]>
            </description>
            <link>https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141535</guid>
            <pubDate>Thu, 13 Aug 2020 09:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell to Core: Understanding Haskell Features Through Their Desugaring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141425">thread link</a>) | @NaeosPsy
<br/>
August 13, 2020 | https://serokell.io/blog/haskell-to-core | <a href="https://web.archive.org/web/*/https://serokell.io/blog/haskell-to-core">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>This article is based on <a href="https://www.youtube.com/watch?v=fty9QL4aSRc">my talk with the same title</a>, which I gave at the Haskell Love conference in 2020, where I give a cursory overview of GHC’s front-end pipeline, the internal Core language, and the desugaring pass.</em></p><p>Haskell is an expressive language with many features. On the one hand, it makes Haskell convenient, equipping the programmer with a rich arsenal of tools to get the job done and write high-quality software. On the other hand, developing a thorough understanding of these tools, of all the language features, takes time, effort, and experience.</p><p>One way to build an intuition for a language feature is to use it. Practice makes perfect, and by trial and error, you can discover the ins and outs of using certain parts of the language. However, the knowledge acquired this way may be superficial, and the mental model will only be as good as it was needed for the tasks at hand.</p><p>Deeper insight comes from a different perspective: you need to decompose a concept into its basic constituents. For example, what are multi-argument functions? In a curried language, we know that <code>\a b c -&gt; ...</code> is much the same as <code>\a -&gt; \b -&gt; \c -&gt; ...</code>. Thus we have reduced the concept of a multi-argument function into a simpler concept of a single-argument function.</p><p>For a more involved example: what is <code>do</code>-notation? To grasp it, you need to think about how it is desugared into <code>&gt;&gt;=</code> and <code>&gt;&gt;</code> (and also <code>&lt;*&gt;</code> with <code>-XApplicativeDo</code>).</p><p>What about infix operators, if-then-else expressions, list comprehensions, type classes, type families, GADTs? How much Haskell is essential, and how much is sugar on top?</p><p>This becomes clear if we start thinking about the way Haskell programs are desugared into GHC’s Core: a small, elegant language, used as an intermediate representation in GHC’s compilation pipeline. The many features of Haskell are reducible to the few constructs of Core.</p><p>Desugaring translates a program that uses many different language constructs into a program that uses only a few.</p><p>For example, consider this snippet:</p><pre><code><span>product</span> [a + b, c + d]
</code></pre><p>It uses several Haskell features:</p><ol>
<li>Lists literals: <code>[a, b, c, ...]</code></li>
<li>Operator application: <code>x # y</code></li>
<li>Function application: <code>f x</code></li>
</ol><p>But we can rewrite it in such a way that it uses only function application:</p><pre><code><span>product</span> (
  (:) ((+) a b) (
  (:) ((+) c d) (
  [])))
</code></pre><p>Granted, the end result is not as readable. But the building blocks used to write this program are simpler, and that’s the important bit.</p><p>Desugaring is not just an abstract idea: it’s a concrete step of GHC’s pipeline. Every Haskell program is desugared into Core during compilation. So, to see the full picture, it’s helpful to consider the steps that occur prior to desugaring.</p><p>The input to the compiler is a string, a sequence of characters:</p><center><img src="https://serokell.io/files/dy/dy2sc5q9.ParserInput.png" alt="Parser Input"></center><p>Where would one begin to process this sequence? Actually, this is fairly well known. The first step is <strong>lexical analysis</strong>, which groups subsequences of these characters into labeled tokens:</p><center><img src="https://serokell.io/files/mf/mfm4t5lo.LexerOutput.png" alt="Lexer Output"></center><p>Then the tokens are organized into a tree. That’s <strong>syntactic analysis</strong>:</p><center><img src="https://serokell.io/files/oa/oav0bml8.ParserOutput.png" alt="Parser Output"></center><p>The structure of this tree depends on the language we’re working with. In Haskell, a module contains declarations, such as data declarations, class declarations, function/variable definitions, and so on. In this example, we have two value bindings, marked as ‘bind’.</p><p>In a ‘bind’, there’s a pattern on the left-hand side and an expression on the right-hand side. In this example, the patterns are simply variable names, but we could also have as-patterns, view-patterns, matching on specific data constructors, and so on.</p><p>An expression can be one of many forms, but here we have:</p><ul>
<li>‘app’ – function application, consisting of a function and its argument;</li>
<li>‘op app’ – operator application, consisting of two operands and an operator;</li>
<li>‘var’ – references to other named values;</li>
<li>‘lit’ – numeric and string literals.</li>
</ul><p>Then we do <strong>name resolution</strong>, to figure out which name refers to what:</p><center><img src="https://serokell.io/files/8v/8vvt57kn.RenamerOutput.png" alt="Renamer Output"></center><p>Here, ‘print’, ‘+’, and ‘length’ are imported from other modules, whereas ‘x’ is defined in the same module.</p><p>And then, we analyse the program to <strong>check and infer the types</strong> of its expressions and subexpressions:</p><pre><code><span>main</span> :: <span>IO</span> ()
<span>x</span> :: <span>Int</span>
</code></pre><p>So that’s the GHC pipeline, or at least its front-end:</p><p><img src="https://serokell.io/files/sx/sxg6b87v.PipelineGHC.png" alt="sxg6b87v.PipelineGHC.png"></p><ul>
<li>text to tokens;</li>
<li>tokens to a syntax tree;</li>
<li>add scoping information to the syntax tree;</li>
<li>add type information to the syntax tree;</li>
</ul><p>This leaves us with a well-scoped, well-typed syntax tree. This is the input to desugaring. And the output is a Core program, where Core is a language like Haskell, but it’s much smaller and with fewer features.</p><p>To understand how Core is simpler, let’s first take a deeper look at Haskell. To represent a Haskell expression, GHC defines a type called <code>HsExpr</code>. If you open <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Expr.hs">compiler/GHC/Hs/Expr.hs</a></code> in GHC sources, you will see it:</p><pre><code><span><span>data</span> <span>HsExpr</span> p</span>
  = <span>HsVar</span> ...         
  | <span>HsLit</span> ...         
  | <span>HsApp</span> ...         
  | <span>OpApp</span> ...         
  | ...
</code></pre><p>Remember how syntactic analysis creates a node for each subexpression? And these nodes can be of different varieties, such as function application, operator application, variables, literals, etc.? <code>HsExpr</code> has a constructor for each node type: <code>HsVar</code>, <code>HsLit</code>, <code>HsApp</code>, <code>OpApp</code>, and so on.</p><p>And there are lots and lots of node types:</p><pre><code><span><span>data</span> <span>HsExpr</span> p</span>
  = <span>HsVar</span> ...         
  | <span>HsLit</span> ...         
  | <span>HsApp</span> ...         
  | <span>OpApp</span> ...         
  | <span>HsAppType</span> ...     
  | <span>HsLam</span> ...         
  | <span>HsLet</span> ...         
  | <span>ExprWithTySig</span> ... 
  | <span>ExplicitList</span> ...  
  | <span>SectionL</span> ...      
  | <span>SectionR</span> ...      
  | <span>ExplicitTuple</span> ... 
  | <span>HsCase</span> ...        
  | <span>HsLamCase</span> ...     
  | <span>HsIf</span> ...          
  | <span>HsMultiIf</span> ...     
  | <span>HsDo</span> ...          
  | <span>RecordCon</span> ...     
  | <span>RecordUpd</span> ...     
  | <span>ArithSeq</span> ...      
  | <span>HsPar</span> ...         
  | <span>NegApp</span> ...        
  | <span>HsBracket</span> ...     
  | <span>HsSpliceE</span> ...     
  | <span>HsProc</span> ...        
  | <span>HsStatic</span> ...      
  | <span>HsOverLabel</span> ...   
  | ...
</code></pre><p>And that’s just expressions. There are also patterns, defined in <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Pat.hs">compiler/GHC/Hs/Pat.hs</a></code>:</p><pre><code><span><span>data</span> <span>Pat</span> p</span>
  = <span>WildPat</span> ...       
  | <span>VarPat</span> ...        
  | <span>LazyPat</span> ...       
  | <span>BangPat</span> ...       
  | <span>AsPat</span> ...         
  | <span>ParPat</span> ...        
  | <span>ListPat</span> ...       
  | <span>TuplePat</span> ...      
  | <span>ConPat</span> ...        
  | <span>ViewPat</span> ...       
  | <span>LitPat</span> ...        
  | <span>SigPat</span> ...        
  | <span>NPat</span> ...          
  | <span>NPlusKPat</span> ...     
  | <span>SplicePat</span> ...     
  | ...
</code></pre><p>And types, defined in <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Type.hs">compiler/GHC/Hs/Type.hs</a></code>:</p><pre><code><span><span>data</span> <span>HsType</span> p</span>
  = <span>HsForAllTy</span> ...    
  | <span>HsQualTy</span> ...      
  | <span>HsTyVar</span> ...       
  | <span>HsAppTy</span> ...       
  | <span>HsAppKindTy</span> ...   
  | <span>HsFunTy</span> ...       
  | <span>HsListTy</span> ...      
  | <span>HsTupleTy</span> ...     
  | <span>HsOpTy</span> ...        
  | <span>HsParTy</span> ...       
  | <span>HsIParamTy</span> ...    
  | <span>HsStarTy</span> ...      
  | <span>HsKindSig</span> ...     
  | <span>HsSpliceTy</span> ...    
  | <span>HsTyLit</span> ...       
  | <span>HsWildCardTy</span> ...  
  | ...
</code></pre><p>In <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Decls.hs">compiler/GHC/Hs/Decls.hs</a></code> there are data declarations, classes, type families, instances, and so on:</p><pre><code><span><span>data</span> <span>TyClDecl</span> p</span>
  = <span>FamDecl</span> ...       
  | <span>SynDecl</span> ...       
  | <span>DataDecl</span> ...      
  | <span>ClassDecl</span> ...     

<span><span>data</span> <span>InstDecl</span> p</span>
  = <span>ClsInstD</span> ...      
  | <span>DataFamInstD</span> ...  
  | <span>TyFamInstD</span> ...    
</code></pre><p>That’s not all, of course. You can browse <code>compiler/GHC/Hs/...</code> to see more.</p><p>What about Core? Here’s the entirety of its syntax:</p><pre><code><span><span>data</span> <span>Expr</span></span>
  = <span>Var</span>   <span>Id</span>
  | <span>Lit</span>   <span>Literal</span>
  | <span>App</span>   <span>Expr</span> <span>Expr</span>
  | <span>Lam</span>   <span>Var</span> <span>Expr</span>
  | <span>Let</span>   <span>Bind</span> <span>Expr</span>
  | <span>Case</span>  <span>Expr</span> <span>Var</span> <span>Type</span> [<span>Alt</span>]
  | <span>Cast</span>  <span>Expr</span> <span>Coercion</span>
  | <span>Type</span>  <span>Type</span>
  | <span>Coercion</span> <span>Coercion</span>
  | <span>Tick</span>  ...  

<span><span>type</span> <span>Alt</span> = (<span>AltCon</span>, [<span>Var</span>], <span>Expr</span>)</span>

<span><span>data</span> <span>AltCon</span></span>
  = <span>DataAlt</span> <span>DataCon</span>
  | <span>LitAlt</span>  <span>Literal</span>
  | <span>DEFAULT</span>

<span><span>data</span> <span>Bind</span></span>
  = <span>NonRec</span> <span>Var</span> <span>Expr</span>
  | <span>Rec</span> [(<span>Var</span>, <span>Expr</span>)]

<span><span>data</span> <span>Type</span></span>
  = <span>TyVarTy</span> <span>Var</span>
  | <span>AppTy</span> <span>Type</span> <span>Type</span>
  | <span>TyConApp</span> <span>TyCon</span> [<span>Type</span>]
  | <span>ForAllTy</span> <span>TyCoVarBinder</span> <span>Type</span>
  | <span>FunTy</span> <span>Mult</span> <span>Type</span> <span>Type</span>
  | <span>LitTy</span> <span>TyLit</span>
  | <span>CastTy</span> <span>Type</span> <span>Coercion</span>
  | <span>CoercionTy</span> <span>Coercion</span>
</code></pre><p>Its expression syntax has only nine constructs:</p><ul>
<li>variables (<code>Var</code>)</li>
<li>literals (<code>Lit</code>)</li>
<li>function application (<code>App</code>)</li>
<li>lambdas (<code>Lam</code>)</li>
<li>let-bindings (<code>Let</code>)</li>
<li>case-expressions (<code>Case</code>)</li>
<li>casts (<code>Cast</code>)</li>
<li>coercions (<code>Coercion</code>)</li>
</ul><p>If you learn what these are, you know Core. And if you know both Core and how Haskell programs are desugared into it, then you can easily reason about the menagerie of Haskell language features.</p><p>At a first approximation, you can think of Core as a subset of Haskell plus coercions (and casts, these two are closely related). That’s not the full story, though. For example, there are also differences in strictness, as <code>case</code> in Core is always strict. Here are some resources if you want to delve deeper into this:</p><ul>
<li><a href="https://www.youtube.com/watch?v=uR_VzYxvbxg">“Into the Core - Squeezing Haskell into Nine Constructors"</a></li>
<li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2007/01/tldi22-sulzmann-with-appendix.pdf">“System F with Type Equality Coercions"</a></li>
<li><a href="https://repository.brynmawr.edu/cgi/viewcontent.cgi?article=1014&amp;context=compsci_pubs">“System FC with Explicit Kind Equality"</a></li>
<li><a href="https://github.com/ghc/ghc/blob/master/docs/core-spec/core-spec.pdf">“System FC, as implemented in GHC"</a></li>
<li>Read the GHC sources (e.g. <code>dsLExpr</code>) and <code>-ddump-simpl</code> output</li>
</ul><p>However, as a starting point, it’s sufficient to assume that Core is a subset of Haskell.</p><p>Now let’s see how Haskell programs are transformed into Core by looking at specific examples. We’ll start with the most basic features and progress to more complex ones.</p><h2 id="infix-operators">Infix Operators</h2><p>Infix operators are translated into function applications:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>a</span> &amp;&amp; b
</code></pre>
</td>
<td>
<pre><code>(&amp;&amp;) a b
</code></pre>
</td></tr></tbody></table><p>There isn’t much to it. But keep in mind that in Core, all variable occurrences have type information, so a more accurate translation would look like this:</p><pre><code>((&amp;&amp;) :: <span>Bool</span> -&gt; <span>Bool</span> -&gt; <span>Bool</span>)
  (a :: <span>Bool</span>)
  (b :: <span>Bool</span>)
</code></pre><p>However, more often than not, I will omit type annotations to save visual space.</p><h2 id="function-bindings">Function Bindings</h2><p>Bindings in Core always have a single variable name on the left-hand side. Function bindings are desugared into lambdas:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>f</span> x y = not x &amp;&amp; y
</code></pre>
</td>
<td>
<pre><code><span>f</span> =
  \(x :: <span>Bool</span>) -&gt;
  \(y :: <span>Bool</span>) -&gt;
     (&amp;&amp;) (not x) y
</code></pre>
</td></tr></tbody></table><p>Also, there are no separate type signatures. All type information is stored inline.</p><h2 id="multi-argument-function-bindings">Multi-Argument Function Bindings</h2><p>Multi-argument functions are translated into nested lambdas. In Core, all lambdas are single-argument:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>f</span> x y = not x &amp;&amp; y
</code></pre>
</td>
<td>
<pre><code><span>f</span> =
  \(x :: <span>Bool</span>) -&gt;
  \(y :: <span>Bool</span>) -&gt;
     (&amp;&amp;) (not x) y
</code></pre>
</td></tr></tbody></table><p>This is also true for hand-written multi-argument lambdas:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>f</span> = \x y -&gt; not x &amp;&amp; y
</code></pre>
</td>
<td>
<pre><code><span>f</span> =
  \(x :: <span>Bool</span>) -&gt;
  \(y :: <span>Bool</span>) -&gt;
     (&amp;&amp;) (not x) y
</code></pre>
</td></tr></tbody></table><p>This treatment of multi-argument functions may be familiar to you if you’ve heard of <a href="https://en.wikipedia.org/wiki/Currying">cu…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serokell.io/blog/haskell-to-core">https://serokell.io/blog/haskell-to-core</a></em></p>]]>
            </description>
            <link>https://serokell.io/blog/haskell-to-core</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141425</guid>
            <pubDate>Thu, 13 Aug 2020 09:22:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Go 1.15 improved converting small integer values to interfaces]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141174">thread link</a>) | @ngaut
<br/>
August 13, 2020 | https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>How Go 1.15 improved converting small integer values to interfaces</h2>

	<p><small>August 12, 2020</small></p>
</div><div><p>In Go, <a href="https://golang.org/ref/spec#Interface_types">interface values</a>
are famously implemented as a pair of pointers (see Russ Cox's <a href="https://research.swtch.com/interfaces">Go
Data Structures: Interfaces</a>);
a pointer to information about the type and a pointer to the value
itself. This generally means that the value must be dynamically
allocated in the <em>heap</em>, which means that it will contribute to the
work that Go's garbage collection does.</p>

<p>The <a href="https://golang.org/doc/go1.15">Go 1.15 release notes</a> mention
an intriguing improvement in <a href="https://golang.org/doc/go1.15#runtime">the runtime section</a>:</p>

<blockquote><p>Converting a small integer value into an interface value no longer
causes allocation.</p>
</blockquote>

<p>When I saw that, I immediately wondered how it works, and especially
if Go's runtime was now sometimes using the value pointer field in
interface values to directly store the value.
(There are a number of languages that do this, using various approaches
like <a href="https://wiki.c2.com/?TagBit">tag bits</a> to tell values from real
pointers.)</p>

<p>The answer turns out to be pretty straightforward, and is in <a href="https://go-review.googlesource.com/c/go/+/216401">Go
CL 216401</a> (merged
in <a href="https://github.com/golang/go/commit/9828c43288a53d3df75b1f73edad0d037a91dff8">this commit</a>,
which may be easier to read). The Go runtime has a special static
array of the first 256 integers (0 to 255), and when it would
normally have to allocate memory to store an integer on the heap
as part of converting it to an interface, it first checks to see
if it can just return a pointer to the appropriate element in the
array instead. This kind of static allocation of frequently used
values is common in languages with lots of dynamic allocation;
Python does something similar for small integers, for example
(<a href="https://utcc.utoronto.ca/~cks/space/blog/python/ObjectIdentityGotcha">which can sometimes surprise you</a>).</p>

<p>(It turns out that Go previously had an optimization where if you were
converting 0 to an interface value, it would return a pointer to a
special static zero value. This new optimization for 0-255 replaces
that.)</p>

<p>There is one special trick that Go plays here. The actual array is
an array of <code>uint64</code>, but it reuses the same array for smaller sized
values as well. On <a href="https://en.wikipedia.org/wiki/Endianness">little endian</a> systems like x86, this
is fine as it stands because a pointer to a 64-bit value is also a
valid pointer to that value interpreted as 32 or 16 bits (or 8
bits). But on big endian systems this isn't the case, so if Go is
running on a big endian machine it bumps up the pointer so that it
works properly (making it point to either the last two bytes or the
last four bytes of the 8-byte value).</p>

<p>(On a little endian machine, the pointer is to the low byte of the
value and the remaining bytes are all zero so it doesn't matter how
many more of them you look at. On a big endian machine, the pointer
is to the high byte, but the low byte is the thing that matters.)</p>

<p>As bonus trivia for this change, this new array of 0-255 <code>uint64</code>
values was then reused for avoiding allocating anything for one-byte
strings in another change (<a href="https://github.com/golang/go/commit/bda42a7a782dbcf4b123d617c5b60f3c848cbb82">this commit</a>,
<a href="https://go-review.googlesource.com/c/go/+/221979">CL 221979</a>).
Go previously had an array of bytes for this purpose, but why have
two arrays. Big endian machines need the same sort of pointer bumping
they did for small integers being converted to interface values,
but little endian machines can once again use the pointers as is.</p>

<p>PS: There are runtime functions for converting 16, 32, and 64 bit
values to interface values, in <a href="https://github.com/golang/go/blob/master/src/runtime/iface.go">runtime/iface.go</a>
(they can be inlined in actual code), but I was puzzled because
there is no runtime function for converting 8 bit values. It turns
out that 8-bit values are directly handled by the compiler in
<a href="https://github.com/golang/go/blob/master/src/cmd/compile/internal/gc/walk.go#L837">walk.go</a>,
where it generates inline code that uses the <code>staticuint64s</code> array.
This may be done directly in the compiler partly because it needs
no fallback path for larger values, unlike the 16, 32, and 64 bit
cases, since an 8 bit value will always be in <code>staticuint64s</code>.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141174</guid>
            <pubDate>Thu, 13 Aug 2020 08:35:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stopping phishing campaigns with Bash]]>
            </title>
            <description>
<![CDATA[
Score 451 | Comments 158 (<a href="https://news.ycombinator.com/item?id=24141127">thread link</a>) | @geek_at
<br/>
August 13, 2020 | https://blog.haschek.at/2020/stopping-phishing-campaigns-with-bash.html | <a href="https://web.archive.org/web/*/https://blog.haschek.at/2020/stopping-phishing-campaigns-with-bash.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    <div>
                        <div>
                            <div>
                            <p>A few days ago my wife got a text message that was obviously a bad phishing attempt</p>
<figure><img loading="lazy" src="https://pictshare.net/xcz7r5.jpg"><figcaption>It says: Our -bankname- system has noticed that your "pushTAN" service is not active. Click here to activate</figcaption></figure>
<p>I spun up a VM and took a look at the website it linked to, which is <a href="https://www.sso-meinelba.com/">https://www.sso-meinelba.com/</a> (almost like the real domain but with a typo) and of course it was just a copy of a banks login form that had only one change made to it.</p>
<figure><img loading="lazy" src="https://pictshare.net/0fuchr.png"><figcaption>The phishers added a "PIN" field to the logon page</figcaption></figure>
<p>The way these things work is that they act like they're the real login form, <code>steal your credentials</code> and usually send you off to the real bank so you think you made a typo or something.</p>

<p>These phishing backends are usually very simple PHP scripts that just take the data from the submitted form and save them to a file. The phishers then <a href="https://krebsonsecurity.com/2017/12/the-market-for-stolen-account-credentials/">sell them via hidden services</a> (trying real hard not to use the bullshit term <code>darknet</code> here).</p>
<p>If the phishers didn't think too hard about getting garbage data you can have a little fun and poison their loot with fake logins.</p>
<p>So with a few lines of Bash I was able to send a few thousand datapoints to their backend, filling it with garbage.</p>
<pre><code>while :; do

    # generate random numbers for login and password
    verf=$(cat /dev/urandom | tr -dc '0-9' | fold -w 7 | head -n 1)
    pin=$(cat /dev/urandom | tr -dc '0-9' | fold -w 5 | head -n 1)

    # send them to their server as your browser would
    curl 'https://www.sso-meinelba.com/files/index/identifier/verfueger/uz1.php' \
        -H 'authority: www.sso-meinelba.com' \
        -H 'origin: https://www.sso-meinelba.com' \
        -H 'content-type: application/x-www-form-urlencoded' \
        -H 'user-agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36' \
        -H 'referer: https://www.sso-meinelba.com/files/index/identifier/verfueger/' \
        --data-raw "verfueger=Wien&amp;Verf%C3%BCgernummer=$verf&amp;Pin=$pin&amp;submit=Weiter"

    echo "Sending $verf with pin $pin"
done</code></pre>
<figure>
<video id="video" poster="https://pictshare.net/i3khmn.mp4/preview/i3khmn.mp4" preload="auto" autoplay="autoplay" controls="" muted="muted" loop="loop" webkit-playsinline="">   
    <source src="https://pictshare.net/i3khmn.mp4/raw" type="video/mp4">
</video>
<figcaption>Which was running for about half an hour until I had an idea</figcaption>
</figure>
<h2>The form was limiting my input.. but does the backend too?</h2>
<p>The phishing form limited the account number to 7 digits and the pin to 5 digits but what if I would send a bit more?</p>
<p>So I edited the script to send 256 character account numbers and passwords and then this happened.</p>
<h2>It killed their site (?)</h2>
<figure><img loading="lazy" src="https://pictshare.net/rcr9g6.png"><figcaption>The site didn't like my input</figcaption></figure>
<p>After my first request with two times 256 characters, the site went down. I'm not sure what happened and if it was a big coincidence and they took it down in the exact second I sent the large strings or I activated self destruction but since this request the site is down.</p>
<figure><img loading="lazy" src="https://pictshare.net/b71byj.png"><figcaption>Site is down now. Did I do that?</figcaption></figure>
<p>The server seems up but the content is gone.</p>
<h2>Strange things</h2>
<p>What struck me as odd was that the fake domain <code>sso-meinelba.com</code> had a valid SSL Wildcard certificate from the italian company <a href="https://www.actalis.it/">Actalis</a>. Usually phishers only get free certificates like Let's encrypt but they really seemed to have bought one. Odd</p>
<figure><img loading="lazy" src="https://pictshare.net/1fiexe.png"><figcaption>The certificate</figcaption></figure>
<p>I also noticed that the website was hosted on webx1413.aruba.it. The scammers must have rented a small VPS that hosts the scamming site</p>
<h2>How do they hide their scamming site from being detected?</h2>
<p>Remember the <code>bitly.com</code> link from the screenshot? It actually doesn't point directly to <code>sso-meinelba.com</code> but rather to a sub folder on <a href="https://kls-study.com/">https://kls-study.com</a> which is (as far as I can tell) an old homepage of the italian <a href="http://klm.education/">KLM Education</a> language school.</p>
<p>Obviously the phishers found a bug in their website and used the subdirectory <code>https://kls-study.com/redi/ccui</code> (the last part of the path seems to be random) to forward users to their phishing campaigns.</p>

<p>On the local Austrian subreddit <a href="https://www.reddit.com/r/Austria/comments/i88imh/wei%C3%9F_jemand_wieso_mir_raiffeisen_das_geschickt/">I saw a post describing a similar</a> phishing campaign and I also took a look.</p>
<p>It was the same banking login page but the backend was much more professional. It seems they actively tried to use the login credentials in the backend before saving them because after entering login data I saw this and had to laugh.</p>
<figure><img loading="lazy" src="https://pictshare.net/qm3tsb.png"><figcaption>My IP address in a subfolder called "victims"</figcaption></figure>
<p>This txt file was called once per second and it had the value <code>0</code> in it. I assume they tried to login with the credentials I entered and if it was valid, they'd forward me to the real website of the bank.</p>
<p>Sadly the server didn't enable indexing otherwise I would have seen all victims, but it was funny nonetheless.</p>
<h2>Also attacking this phishing site</h2>
<p>I saw that every request to <code>http://elba-app.com/Raiffeisen/</code> seemed to create a folder with a random string on their server. (eg <code>http://elba-app.com/Raiffeisen/f5255513e44fa68/</code>) so I thought I'd spam them again and it worked well</p>
<figure>
<video id="video2" poster="https://pictshare.net/a1s52s.mp4/preview/a1s52s.mp4" preload="auto" autoplay="autoplay" controls="" muted="muted" loop="loop" webkit-playsinline="">   
                <source src="https://pictshare.net/a1s52s.mp4/raw" type="video/mp4">
</video>
<figcaption>With every request there is a folder generated on their server</figcaption>
</figure>
<p>until</p>
<figure><img loading="lazy" src="https://pictshare.net/dj72f5.png"><figcaption>They blocked my IP</figcaption></figure>
<p>Being a sysadmin this of course is not the only IP at my disposal so I tried the BOMB request (256 instead of 7 characters) again and what happened?</p>
<figure><img loading="lazy" src="https://pictshare.net/r33l7v.png"><figcaption>Their server was not happy with my input</figcaption></figure>
<p>This time the server didn't crash or self destruct, I just seem to produce a lot of error messages on their side.</p>
<p>Also their site is a bit more complex as they don't have a single form where to post login credentials but they have 3 steps:</p>
<p><strong>Step 1:</strong>
Go to <code>http://elba-app.com/Raiffeisen</code> and the server will respond with a 302 redirect to the folder they created for you</p>
<figure><img loading="lazy" src="https://pictshare.net/jilwi2.png"><figcaption>Redirect in the location header</figcaption></figure>
<p><strong>Step 2:</strong>
They send you to a sumbit.php that only takes the account name and redirects you to</p>
<p><strong>Step 3:</strong>
Now they want your pin on <code>/hundle-pin.php</code>. I'm not sure why they did leave in that typo but here we are.</p>

<p>I made a few changes to my script to handle all 3 steps and let it run over night from a dozen different ip addresses.</p>
<p>The result? They stopped their campaign from this Domain</p>
<figure><img loading="lazy" src="https://pictshare.net/17p4v8.png"><figcaption>This phishing site is gone too</figcaption></figure>
<p><a href="https://gist.github.com/geek-at/53768c6b7aee7a973032cfb7daf65107">Here's my updated script</a> for those playing along at home</p>

<p>We saw 2 phishing attacks in different quality. Both sent out as SMS to users who are customers of the same bank.</p>
<p>I wrote a script to poison their data and got both of the sites to stop working. Great success!</p>
                            </div>
                        </div>
                    </div></article></div>]]>
            </description>
            <link>https://blog.haschek.at/2020/stopping-phishing-campaigns-with-bash.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141127</guid>
            <pubDate>Thu, 13 Aug 2020 08:25:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nintendo DS Architecture]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141035">thread link</a>) | @charliechuck
<br/>
August 13, 2020 | https://www.copetti.org/projects/consoles/nintendo-ds/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/nintendo-ds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><div><ul><li><a href="#cover-model">Model</a></li><li><a href="#cover-motherboard">Motherboard</a></li><li><a href="#cover-diagram">Diagram</a></li></ul><div><div id="cover-motherboard"><figcaption>Showing first revision<br>Controllers are plugged using a separate daughterboard<br>Missing SRAM chips are on the back and there are four unpopulated SRAM slots</figcaption></div><div id="cover-diagram"><a href="https://www.copetti.org/images/consoles/nintendods/diagram.png"><picture>
<img alt="Diagram" src="https://www.copetti.org/images/consoles/nintendods/diagram.png" data-src="https://www.copetti.org/images/consoles/nintendods/diagram.png"></picture></a><figcaption>If you have trouble following the components: Top is only accessed by ARM9, bottom section is ARM7-only, middle section is shared</figcaption></div></div></div><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>This console is an interesting answer to many needs that weren’t possible to fulfil in the handheld ecosystem. There will be some innovation and a few compromises, but this combination may pave the way for new and ingenious content.</p><hr><h2 id="cpu">CPU</h2><p>As with Nintendo’s <a href="https://www.copetti.org/projects/consoles/game-boy-advance/">previous portable console</a>, the system revolves around a big chip named <strong>CPU NTR</strong>. ‘NTR’ is shorthand for ‘Nitro’, the codename of the original Nintendo DS.</p><p>Now, CPU NTR implements an interesting multi-processor architecture using two different ARM CPUs, this design was done before ARM Holdings officially released multi-processor solutions. So, their functioning may be considered a bit unorthodox taking into account the present technology available.</p><p>While this is not the first parallel system analysed for <a href="https://www.copetti.org/projects/consoles/">this series</a>, its design is very different from the rest. For instance, we are not talking about the ‘experimental’ master-slave configuration that the <a href="https://www.copetti.org/projects/consoles/sega-saturn/">Saturn</a> debuted or the ‘co-processor’ approach found on the <a href="https://www.copetti.org/projects/consoles/playstation/">PS1</a> or <a href="https://www.copetti.org/projects/consoles/nintendo-64/">N64</a>. The Nintendo DS includes two very independent computers that will perform exclusive operations, each one having a dedicated bus. This co-dependency will condition the overall performance of this console.</p><p>That being said, let’s take a look now at the two CPUs:</p><div><ul><li id="tab-1-1-arm7tdmi-link"><a href="#tab-1-1-arm7tdmi">ARM7TDMI</a></li><li id="tab-1-2-arm946e-s-link"><a href="#tab-1-2-arm946e-s">ARM946E-S</a></li></ul><div><div id="tab-1-1-arm7tdmi"><h4>ARM7TDMI</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"></picture></a><figcaption>ARM7 structure and components</figcaption></div><p>Starting with the more familiar one, the <strong>ARM7TDMI</strong> is the same CPU found on the <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#cpu">GameBoy Advance</a> but now running at <strong>~34 MHz</strong> (double its original speed). It still includes all its original features (especially <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#whats-new">Thumb</a>).</p><p>Now for the changes: Because Nintendo’s engineers placed the ARM7 next to most of the I/O ports, this CPU will be tasked with arbitrating and assisting I/O operations. In fact, no other processor can directly connect to the I/O. As you can see, this is not the ‘main’ processor that will be in charge of the system, but rather the ‘sub-processor’ offloading the main CPU by passing data around many components.</p></div><div id="tab-1-2-arm946e-s"><h4>ARM946E-S</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"></picture></a><figcaption>ARM9 structure and components</figcaption></div><p>Here is the ‘main’ CPU of the Nintendo DS running at <strong>~67 MHz</strong>. If you ignore the ill-fated ARM8 series, you could say the ARM946E-S is the ‘next-gen’ version of the ARM7. Part of the <strong>ARM9 series</strong>, this core in particular not only inherits all the features of the <strong>ARM7TDMI</strong> but also includes some additional bits:</p><ul><li>The <strong>ARMv5TE ISA</strong>: Compared to the previous v4, features some new instructions and a faster multiplier.<ul><li>If you take a look at the core name, the letter ‘E’ means <strong>Enhanced DSP</strong> which implies that lots of these new instructions have to do with applications for signal processing.</li></ul></li><li><strong>5-stage Pipeline</strong>: This is another increment from the previous 3-stage pipeline.</li><li><strong>12 KB of L1 Cache</strong>: The core now features cache, where 8 KB are allocated for instructions and 4 KB for data.</li><li><strong>48 KB of Tightly-Coupled Memory</strong> or ‘TCM’: Similar to <a href="https://www.copetti.org/projects/consoles/playstation/#cpu">Scratchpad memory</a>, however this one discriminates between instructions (32 KB) and data (16 KB).</li></ul><p>Nintendo also added the following components around it:</p><ul><li>A <strong>Divisor and Square root unit</strong> to speed up these type of operations (the ARM9 by itself is not capable of performing this type of math).</li><li>A <strong>Direct Memory Access Controller</strong>: Accelerates memory transfers without depending on the CPU. Combined with the use of cache, both CPU and DMA can potentially work concurrently.<ul><li>Cache and DMA can provide a lot of performance but also create new problems, such as data integrity. So programmers will have to manually maintain memory consistency by flushing the <a href="https://www.copetti.org/projects/consoles/playstation-2/#preventing-past-mishaps">write-buffer</a> before triggering DMA, for instance.</li></ul></li></ul></div></div></div><p>I guess with hardware like this, it’s easy to figure out the <em>real</em> reason kids loved this console, eh?</p><h4 id="interconnection">Interconnection</h4><p>So far I’ve talked about how the two CPUs work individually. But to work as a whole, they require to co-operate constantly. To accomplish this, both CPUs directly ‘talk’ to each other using a dedicated <strong>FIFO unit</strong>, this block of data holds two 64-byte queues (up to 16 elements) for <strong>bi-directional communication</strong>.</p><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"></picture></a><figcaption>Representation of FIFO unit</figcaption></div><p>This works as follows: The ‘sender’ CPU (that effectively needs to send the other a message) places a 32-bit block of data in the queue, the CPU acting as a ‘receiver’ can then pull that block from the queue and perform the required operations with it.</p><p>Whenever there’s a value written on the queue, either CPU can fetch it manually (<strong>polling</strong>) however, this requires to constantly check for new values (which can be expensive). Alternatively, an <strong>interrupt unit</strong> can be activated to notify the receiver whenever there’s a new value in the queue.</p><h4 id="main-memory">Main memory</h4><p>Just like its predecessor, RAM is spread around many different locations, enabling to prioritise data placement by speed of access. In summary, we have the following general-purpose memory available:</p><div><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"></picture></a><figcaption>RAM model of this console</figcaption></div><ul><li><strong>32 KB of WRAM</strong> (Work RAM) using a <strong>32-bit</strong> bus: To hold fast data shared between the ARM7 and ARM9.<ul><li>Bear in mind that only one CPU can access the same address at a time.</li></ul></li><li><strong>64 KB of WRAM</strong> using a <strong>32-bit</strong> bus: For fast data as well, but only accessible from the ARM7, like the GBA had.</li><li><strong>4 MB of PSRAM</strong> using a <strong>16-bit</strong> bus: A slower type, available from either CPU and it’s controlled by a memory interface unit.<ul><li>Pseudo SRAM or ‘PSRAM’ is a variant of DRAM which, by contrast, performs refreshes from within the chip. Therefore, behaving like SRAM (the faster, but more expensive alternative to DRAM). This design reminds me of <a href="https://www.copetti.org/projects/consoles/gamecube/#clever-memory-system">1T‑SRAM</a>.</li></ul></li></ul></div><h4 id="backwards-compatibility">Backwards compatibility</h4><p>Even though the architecture is significantly different from its predecessor, it still managed to maintain the critical bits that would grant it native compatibility with GameBoy Advance games.</p><p>But for the DS to revert to an ‘internal’ GBA, the former includes a set of software routines that set the console in <strong>AGB Compatibility Mode</strong>. In doing so, it effectively halts the ARM9, disables most of the ‘special’ hardware, redirects the buses, puts the ARM7 in charge and slows it down at 16.78 MHz. Finally, the ARM7 proceeds to boot the original AGB BIOS which bootstraps the GamePak cartridge (just like an original GameBoy Advance). This mode still exhibits some features not found in the original console, such as displaying the game with black margins (we’ll see in the next section that the new screen resolution happens to be bigger). Moreover, since the DS has two screens, users can set which screen will be used to display the GBA game.</p><p>Once in GBA mode <strong>there’s no going back</strong>, the console must be reset to re-activate the rest of the hardware.</p><h4 id="secrets-and-limitations">Secrets and limitations</h4><p>With so many sophisticated components fitted in a single and inexpensive chip, it’s no mystery that some issues emerged due to the way they were forced to work with each other.</p><div><ul><li id="tab-2-1-unused-power-link"><a href="#tab-2-1-unused-power">Unused Power</a></li><li id="tab-2-2-a-question-about-the-hardware-choice-link"><a href="#tab-2-2-a-question-about-the-hardware-choice">A question about the hardware choice</a></li></ul><div><div id="tab-2-1-unused-power"><h4>Unused Power</h4><p>Sometimes I wonder how Nintendo planned the way the two CPU’s would be used, and if they already assumed some performance would be hit by the design they chose.</p><p>Let me start with the ARM9, this CPU runs at twice the speed of the ARM7, but most (if not all) of the I/O depends on the ARM7, so the ARM9 is vulnerable to excessive stalling until the ARM7 answers. If that wasn’t enough, <strong>ARM9’s external bus runs at half the speed</strong>, so there are a few bottlenecks identified.</p><p>Additionally, the Main Memory bus is only <strong>16-bit wide</strong>. Thus, whenever any CPU needs to fetch a word (32-bit wide) from memory, the interface <strong>stalls the CPU</strong> (up to 3 ‘wait’ cycles) until a full world is reconstructed. The worst impact happens when memory access is not sequential, which makes it stall for every single access. This issue will also arise when instructions are fetched (unfortunately, ARM didn’t support sequential opcode fetching back then) which, to my dismay, also affects Thumb code (since every 16-bit fetch is done as a 32-bit block). On the other hand, this penalty (as some sources call it) can be alleviated by making full use of cache and TCM.</p><p>All in all, this means that in the worst case, the ‘whooping’ ARM9’s 66 MHz horsepower is practically reduced to a mere ~8&nbsp;MHz. That is if the program makes an abysmal use of cache/TCM.</p></div><div id="tab-2-2-a-question-about-the-hardware-choice"><h4>A question about the hardware choice</h4><p>Back when I read about the CPU of the GameBoy Advance, I was really surprised by the potential of the ARM7: The CPU not only performed its designated tasks, but could also assist with others, such as providing audio sequencing or pseudo-3D graphics.</p><p>Now, during the commercialisation ARM7, ARM Holdings joined forces with DEC to design a high-end version of ARM’s chips. For this, DEC grabbed the datapath design of their processor, <strong>Alpha</strong>, and mixed it with ARM’s. The result was a new series of CPUs called <strong>StrongARM</strong> which was surprisingly <em>fast</em>. At the expense of removing certain features (Thumb and debug), DEC managed to cross the megahertz threshold by reaching speeds of up to 233 MHz. As a normal user prepared to buy a new ARM PC (let’s say a <em>RiscPC</em>), you could either choose one with the old ARM710 at 40 MHz or another one with a StrongARM running ~582% faster. The impact of StrongARM was so disruptive that ARM Holdings absorbed some of StrongARMs features to produce their next line of CPUs, starting with ARM9. And the rest is history.</p><p>But here’s where my question resides: Considering the new developments in the ARM world, why did Nintendo ultimately choose an awfully slow ARM9 combined by an even slower ARM7, instead of a faster ARM9 (or even a StrongARM)? To give you an idea, other companies like Apple just adopted the StrongARM with their Newton PDA line.</p><p>I don’t mean to criticise Nintendo’s choice, but I believe the amount of emerging technology was just too great for me to ignore. I guess their choice was done in an effort to preserve battery life and maintain production costs (by using the same CPU found in the GBA).</p></div></div></div><hr><h2 id="graphics">Graph…</h2></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/nintendo-ds/">https://www.copetti.org/projects/consoles/nintendo-ds/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/nintendo-ds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141035</guid>
            <pubDate>Thu, 13 Aug 2020 08:05:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mozilla Is Dead]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 60 (<a href="https://news.ycombinator.com/item?id=24140547">thread link</a>) | @kowabit
<br/>
August 12, 2020 | https://kowabit.de/mozilla-is-dead/ | <a href="https://web.archive.org/web/*/https://kowabit.de/mozilla-is-dead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-206394"><div><p><img width="720" height="250" src="https://kowabit.de/wp-content/uploads/2019/02/software.png" alt="" loading="lazy" srcset="https://kowabit.de/wp-content/uploads/2019/02/software.png 720w, https://kowabit.de/wp-content/uploads/2019/02/software-300x104.png 300w" sizes="(max-width: 720px) 100vw, 720px"></p><div><p>If the official news and the unofficial information come true, I believe that Mozilla will die. Ciao Firefox, ciao Thunderbird. Sorry. Also goodbye to all other products that nobody ordered.</p><p>In an <a href="https://blog.mozilla.org/blog/2020/08/11/changing-world-changing-mozilla/" target="_blank" rel="noopener noreferrer">official blog post</a> and an e-mail (<a href="https://blog.mozilla.org/wp-content/uploads/2020/08/Message-to-Employees-Change-in-Difficult-Times.pdf" target="_blank" rel="noopener noreferrer">PDF</a>) Mozilla announces that a quarter of the employees are to be fired. The current Corona crisis have contributed to this. However, the explanation for this action is only PR-speech. In the message to all employees there is again talk of new products and they are supposed to adopt a new way of thinking. Mozilla has often been criticized in the past. Projects like pocket, Send, Lockwise, Firefox OS were/are either born dead and/or burned a lot of money and resources. I have never met anyone in my professional life who has used the additional products or features. Honestly. Me neither.</p><p>According to unofficial information e.g. via Twitter or Github the documentation team, the Firefox engine team (Gecko) and the security team are affected (<a href="https://twitter.com/MichalPurzynski/status/1293220570885062657" target="_blank" rel="noopener noreferrer">1</a>, <a href="https://twitter.com/gcpascutto/status/1293519587967983616" target="_blank" rel="noopener noreferrer">2</a>, <a href="https://github.com/servo/servo/discussions/27575" target="_blank" rel="noopener noreferrer">3</a>, <a href="https://twitter.com/SteveALee/status/1293487542382333952" target="_blank" rel="noopener noreferrer">4</a>). In a crisis never the responsible head of an organization saying goodbye. The head that should have made its own company crisis-proof. Now the most important organs of the whole body are apparently being removed.</p><p>Which products Mozilla wants to market without these teams remains the secret of the management floor. As an administrator in the main job and helper in the private sphere for some people, Firefox as a browser can no longer be an option. The danger of unpatched security holes and lack of further development in the core area endangers the infrastructure and systems. Decision makers also have to pay attention to this when it comes to equipping company networks with software. An organization that buries the most important committees for the maintenance of its products no longer has a product.</p><p>If Mozilla wants to survive, the management will be fired with unearned compensation, the most important departments will be strengthened, products that nobody ordered will be discontinued and the organization will be limited to its core competence. Browser, email, security, adaptability and the fight for a free Internet. And they work with all their might to ensure that the products will become an integral part of everyday life and all operating systems.</p><p>Three months. That’s all the time they have for a clear signal. After that, users have to make a decision. Unfortunately, it will probably only be something with chromium.</p><p>Poor Internet.</p> <p><span>Tagged <a href="https://kowabit.de/tag/firefox/" rel="tag">Firefox</a>, <a href="https://kowabit.de/tag/gecko/" rel="tag">gecko</a>, <a href="https://kowabit.de/tag/goodbye/" rel="tag">goodbye</a>, <a href="https://kowabit.de/tag/imho/" rel="tag">imho</a>, <a href="https://kowabit.de/tag/mozilla/" rel="tag">mozilla</a>, <a href="https://kowabit.de/tag/security/" rel="tag">security</a>, <a href="https://kowabit.de/tag/thunderbird/" rel="tag">thunderbird</a></span></p></div></div></article></div>]]>
            </description>
            <link>https://kowabit.de/mozilla-is-dead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24140547</guid>
            <pubDate>Thu, 13 Aug 2020 06:30:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can we do better than our C compiler?]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24139943">thread link</a>) | @signa11
<br/>
August 12, 2020 | https://briancallahan.net/blog/20200812.html | <a href="https://web.archive.org/web/*/https://briancallahan.net/blog/20200812.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
	<a name="top"></a>
	<div id="main">
	    
	    <p>academic, developer, with an eye towards a brighter techno-social life</p>
	    <hr>
		
	    <hr>
	</div>
<h5 id="prev"><a href="https://briancallahan.net/blog/20200808.html">[prev]</a></h5>
<h5 id="next">[next]</h5>
    <h2 id="title">2020-08-12: Can we do better than our C compiler?</h2>
<p>Today, I wanted to become a C compiler. I added a <a href="https://github.com/ibara/echo/blob/master/echo.s">hand-compiled assembly version of echo</a> from <a href="https://briancallahan.net/blog/20200808.html">our previous coding exercise</a> and added a new make target, <code>make asm</code>, that will assemble it. Let's look at our hand-compiled assembly and compare it to our C compiler and ask whether or not it was worth it.</p>
<h4>My hand-compiled assembly</h4>
<p>It's quite small.</p>
<pre>	.text
	.p2align 2
	.globl	main
	.type	main,@function
main:
	movq	%rdi, %r15	# Get argc from %rdi, put it in %r15
	movq	%rsi, %r14	# Get argv from %rsi, put it in %r14
loop:
	decl	%r15d		# 47: for (i = 0; i &lt; argc; i++) {
	jz	done		# Rewritten as: while (--argc) {
	addq	$8, %r14	# ++argv
	movl	$4, %eax	# Set up write(2)
	movl	$1, %edi	# First parameter is 1
	movq	(%r14), %rsi	# Second parameter is *argv
	leaq	-1(%rsi), %rdx	# Get *argv[0]
strlen:				# Note: strlen has been inlined
	cmpb	$0, 1(%rdx)	# 36: while (*t != '\0')
	leaq	1(%rdx), %rdx	# 37: t++;
	jne	strlen
	subq	%rsi, %rdx	# 39: return t - s;
	syscall			# 48: write(1, *argv, %rdx);
	cmpl	$1, %r15d	# 49: if (i + 1 != argc)
	je	done		# Rewritten as: if (argc != 1)
	movl	$4, %eax	# Set up write(2)
	movl	$1, %edi	# First parameter is 1
	movq	%r14, %rsi	# Set %rsi back to beginning of *argv
	movb	$32, (%rsi)	# Second parameter is " "
	movl	$1, %edx	# Third parameter is 1
	syscall			# 50: write(1, " ", 1);
	jmp	loop
done:
	movl	$4, %eax	# Set up write(2)
	movl	$1, %edi	# First parameter is 1
	movq	%r14, %rsi	# Set %rsi back to beginning of *argv
	movb	$10, (%rsi)	# Second parameter is "\n"
	movl	$1, %edx	# Third parameter is 1
	syscall			# 52: write(1, "\n", 1);
	xorl	%eax, %eax	# Return value is 0
	retq			# 54: return 0;
	.size	main,.-main
</pre>
<p>The whole source is annotated. Comments that begin with a number are for easy cross-referencing with our <a href="https://github.com/ibara/echo/blob/master/echo.c">C version of echo</a>.</p>
<h4>Better optimization for the C code</h4>
<p>The primary tricks are are a manual inlining of the strlen function and not needing the write and _syscall functions, instead being able to use syscall directly. We could inline strlen in the C code if we wanted, but the compiler is very likely to do that for us anyway. We probably can't avoid the write and _syscall functions in C, as we discussed previously.</p>
<p>There is also some rewriting of loops to avoid the use of variables: the <code>for (i = 0; i &lt; argc; i++)</code> is rewritten as <code>while (--argc)</code> and <code>if (i + 1 != argc)</code> becomes <code>if (argc != 1)</code>, which means that we can get rid of the <code>int i</code> variable and increment through argv with <code>++argv</code>. These changes can of course be applied to the C code as well.</p>
<p>Some other tricks include using *argv as scratch space for our space and newline characters. We don't actually care what the value of *argv is once we've written it out—we only use it the one time. So it becomes free memory space for us to overwrite it with whatever we want (as long as things fit; our space and newline characters are a single byte each so we're safe). We could do this one in C too if we wanted.</p>
<p>If we made these changes, our new main function in C might look like this.</p>
<pre>int
main(int argc, char *argv[])
{

	while (--argc) {
		++argv;
		write(1, *argv, strlen(*argv));
		if (argc != 1) {
			*argv[0] = ' ';
			write(1, *argv, 1);
		}
	}
	*argv[0] = '\n';
	write(1, *argv, 1);

	return 0;
}
</pre>
<h4>Even better assembly?</h4>
<p>If we let our C compiler (clang 10.0.0) compile this to assembly, we get the following.
</p><pre>	.text
	.file	"echo.c"
	.globl	main                    # -- Begin function main
	.type	main,@function
main:                                   # @main
# %bb.0:
	pushq	%r15
	pushq	%r14
	pushq	%r12
	movq	%rsi, %r14
	movl	%edi, %r15d
	pushq	$1
	popq	%r12
.LBB0_1:                                # =&gt;This Loop Header: Depth=1
                                        #     Child Loop BB0_3 Depth 2
	decl	%r15d
	je	.LBB0_6
# %bb.2:                                #   in Loop: Header=BB0_1 Depth=1
	movq	8(%r14), %rdi
	addq	$8, %r14
	leaq	-1(%rdi), %rsi
.LBB0_3:                                #   Parent Loop BB0_1 Depth=1
                                        # =&gt;  This Inner Loop Header: Depth=2
	cmpb	$0, 1(%rsi)
	leaq	1(%rsi), %rsi
	jne	.LBB0_3
# %bb.4:                                #   in Loop: Header=BB0_1 Depth=1
	subq	%rdi, %rsi
	callq	write
	cmpl	$1, %r15d
	je	.LBB0_1
# %bb.5:                                #   in Loop: Header=BB0_1 Depth=1
	movq	(%r14), %rax
	movb	$32, (%rax)
	movq	(%r14), %rdi
	movq	%r12, %rsi
	callq	write
	jmp	.LBB0_1
.LBB0_6:
	movq	(%r14), %rax
	movb	$10, (%rax)
	movq	(%r14), %rdi
	pushq	$1
	popq	%rsi
	callq	write
	xorl	%eax, %eax
	popq	%r12
	popq	%r14
	popq	%r15
	retq
.Lfunc_end0:
	.size	main, .Lfunc_end0-main
                                        # -- End function
	.type	write,@function         # -- Begin function write
write:                                  # @write
# %bb.0:
	movq	%rsi, %rcx
	movq	%rdi, %rdx
	pushq	$4
	popq	%rdi
	pushq	$1
	popq	%rsi
	xorl	%r8d, %r8d
	xorl	%r9d, %r9d
	jmp	_syscall                # TAILCALL
.Lfunc_end1:
	.size	write, .Lfunc_end1-write
                                        # -- End function
	.section	".note.GNU-stack","",@progbits
	.addrsig
</pre>
<p>It seems that both clang and I found very similar ways to optimize the program. According to size, I did a little bit better than clang: my hand-compiled assembly came out to a 104-byte object file whereas clang generated a very heavy 125-byte object file. When factoring in the necessary glue code (_start.s, crt,s, and _syscall.s for the C version), my hand-compiled assembly ended up 152 bytes whereas clang was a distant 197 bytes. But clang had the last laugh: running ls -l on the final binaries resulted in 848 bytes for the hand-compiled assembly and 840 bytes for clang. So there is clearly something else going on under the hood that I am losing out on with my hand-compiled assembly. Perhaps you can do better than me.</p>
<h4>Smarter than me</h4>
<p>As will come as little surprise, a production-ready compiler with large teams of developers and larger pools of money is smarter than I am. But I think I did a decent job at it. I believe that learning assembly for several different processors is worthwhile but I think I will stick to higher level languages for most of my work (unless you're paying me to do otherwise...). Because there is one cost we haven't mentioned yet: time. It took me all of 30 seconds, if that, to optimize the C code whereas it took maybe half an hour to write the assembly version.</p>
<h4>Conclusion</h4>
I enjoy assembly. I teach courses that require a deep knowledge of assembly. But I think I'm going to stick to optimizing higher level code rather than cranking out assembly by hand. Or maybe not. Even our original C code was honestly good enough. I'm glad to live in a world where we have a choice of smart compilers.
<p><a href="#top"><img alt="Top" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAICAYAAADJEc7MAAAABmJLR0QA/wD/AP+gvaeTAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH4wkWDyUKJxzXegAAAB1pVFh0Q29tbWVudAAAAAAAQ3JlYXRlZCB3aXRoIEdJTVBkLmUHAAAAUklEQVQY02Ocd/j/fwY0kGjDwMhACPz//5/h////DPMO//8PYxODWXAZOP8Iw39k22F8uBg2G7Gx0cWYGMgEWJ2aaMPAiO5UDOcTGxjogUe2UwHwdJDZUucW5QAAAABJRU5ErkJggg=="></a></p>
<a href="https://briancallahan.net/blog/feed.xml"><img src="https://briancallahan.net/blog/media/pic_rss.gif"></a>
	<br>
	<hr>
	
    

</div>]]>
            </description>
            <link>https://briancallahan.net/blog/20200812.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24139943</guid>
            <pubDate>Thu, 13 Aug 2020 04:28:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I'm 15 and made a bedtime calculator with React JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 310 | Comments 120 (<a href="https://news.ycombinator.com/item?id=24139339">thread link</a>) | @joshternyak
<br/>
August 12, 2020 | https://www.sleepsources.com/bed-time-calculator/ | <a href="https://web.archive.org/web/*/https://www.sleepsources.com/bed-time-calculator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.sleepsources.com/bed-time-calculator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24139339</guid>
            <pubDate>Thu, 13 Aug 2020 02:22:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being a generalist requires more sleep than specialists]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24138674">thread link</a>) | @searchableguy
<br/>
August 12, 2020 | https://hndex.org/1730462 | <a href="https://web.archive.org/web/*/https://hndex.org/1730462">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>

<a href="https://news.ycombinator.com/item?id=1730462" target="_blank">comments</a> <a href="https://andymckenzie.blogspot.com/2010/09/trade-off-10-plasticity-vs.html" target="_blank">original article</a></header>
<p>In college, I was constantly reading neuro lit extolling the
virtues of neural plasticity, which is the ability of neurons to
change based on feedback from the environment. Plasticity certainly
has huge benefits. Specifically, plasticity allows for a better
match between phenotype and environment across variable
environments than a single, constant phenotype would.</p>
<p>But after a while, the idolatry of plasticity began to annoy me,
in part because much of the lit discussed plasticity <i>as if it
had no downsides</i>, which seems impossible. (If there really were
no costs to plasticity, then evolution should have selected for it
like <i>woah</i>).</p>
<p>The general downside seems to be that plasticity hinders
specialization. That is, if a system has the ability to change
easily (i.e. it has high plasticity), then it will tend to expend
resources on a wide range of trait values, and will have fewer
resources to focus on the most important and relevant traits. A few
examples:</p>
<ul>
<li>Synaptic pruning and other mechanisms for synaptic plasticity
allow for learning and memory, but they are energetically costly.
Indeed, one hypothesis holds that sleep is the price we have to pay
for plasticity the previous day. (see here)</li>
<li>In an evolutionary framework, the major costs to more
plasticity are 1) actually sensing the current environmental
conditions, and 2) producing the actual trait in a less efficient
way. Both of these divert resources from other tasks. (see here and
here)</li>
<li>People with autism spectrum disorders often find it difficult
to parse novel stimuli, but can sometimes concentrate for
especially long periods of time on specific niches. So one might
think of the autistic cognitive style as shifted towards the
specialization side of this trade off. (see here)</li>
</ul>
<p>Despite the many applications, the members of the committee and
I are a bit wary about this trade off. First, its status depends
largely on one's particular definitions of plasticity and
specialization. Also, some think it might just be a specific case
of trade off #3, switching costs vs change gains.</p>
<p>But given our current working definitions (plasticity = the
ability, which is highly correlated with the tendency, for
context-dependent change; specialization = funneling energy
expenditures to a narrow purpose), and because it is sort of one
level "meta" to switching costs vs change gains, we are granting
this trade off its own place in the canon.</p>
<p>(Above photo taken by flickr user uncle beast. Plants are often
studied w/r/t genetic plasticity because they can't simply pack up
shop and move if the environment changes, like an animal or insect
could.)</p>
</article></div>]]>
            </description>
            <link>https://hndex.org/1730462</link>
            <guid isPermaLink="false">hacker-news-small-sites-24138674</guid>
            <pubDate>Thu, 13 Aug 2020 00:19:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vitamin D, part 1: back to basics]]>
            </title>
            <description>
<![CDATA[
Score 389 | Comments 143 (<a href="https://news.ycombinator.com/item?id=24138590">thread link</a>) | @conorh
<br/>
August 12, 2020 | https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics | <a href="https://web.archive.org/web/*/https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-cnct8"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/3e0600_d714cff5c2c346ca9f3f81a007aa2b44~mv2.jpg/v1/fit/w_900,h_597,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_d714cff5c2c346ca9f3f81a007aa2b44~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-dpa1h">Vitamin D is a big deal. Recent studies have shown that patients with low Vitamin D levels are more likely to die from Covid-19 than their Vitamin D-rich counterparts,(1) and deficiency in the vitamin has been linked to seven of the ten leading causes of death in the U.S.(2) These facts alone have been enough incentive for many people to start supplementing the vitamin. A common question from my patients is: how much Vitamin D should I take? This is a simple question, but there are a lot of assumptions built in. Before you order that case of Vitamin D for you and your family, let’s back up and look a little more at the data.
 </p><p id="viewer-49tlt">First, why I’m interested in Vitamin D: I’m a parathyroid surgeon, and the vitamin is something I track closely in my patients. For background, the parathyroid glands are tiny endocrine organs in your neck that regulate blood calcium levels. They do this partly through the activation of Vitamin D, which helps the intestines absorb calcium. Without Vitamin D, you will have difficulty getting enough calcium, even if you are taking calcium supplements. Your bones need calcium, so a severe deficiency in Vitamin D leads to bone deformities in children (rickets) and bone loss in adults (osteomalacia). </p><div id="viewer-bovng"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/3e0600_4a3a0724a42049019ad1182bcdb30d79~mv2.png/v1/fit/w_700,h_375,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_4a3a0724a42049019ad1182bcdb30d79~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-csmdc"><em> Normal child femurs compared to femurs of a child with rickets. Rickets is caused by a severe Vitamin D deficiency while bones are growing. This condition is now very rare in the U.S. due to the fortification of almost all milk with Vitamin D.* </em></p><p id="viewer-6lba0">The relationship between parathyroid hormone, calcium, and Vitamin D is complex and fascinating (at least to a parathyroid surgeon), but the vitamin appears to do much more than just influence calcium. We’re still figuring out all that it does, but we have some circumstantial evidence about its roles. Low Vitamin D levels are linked to a variety of illnesses including cancers, hypertension, diabetes, obesity, heart failure, stroke, dementia, autoimmune disease, and respiratory tract infections (including Covid-19). A simple search of the medical literature on PubMed produces page after page of articles on the harms of Vitamin D deficiency. </p><p id="viewer-5l5ac"><strong>Most studies follow this pattern:</strong> Two sets of people are evaluated. One set has a certain disease (diabetes, for example). The other set does not have the disease. Vitamin D levels are measured in both groups. Vitamin D deficiency is found to be much more common in the group of diseased individuals. </p><p id="viewer-4f52t">Using this study method, Vitamin D deficiency is correlated with many diseases. But correlation does not equal causation. The fact that two things are related does not imply that one caused the other. With regard to the vitamin and diabetes, it could be that diabetes causes low Vitamin D. Or it may be that some other health condition causes both low Vitamin D and diabetes. Obesity, for example, is a known risk factor for diabetes, and people who are obese also tend to have low Vitamin D levels, due mostly to the dilution of the fat-soluble vitamin in the larger mass of adipose tissue. The close association between Vitamin D and diabetes could be due simply to the association they both share with obesity. </p><p id="viewer-1plm0">Here is another example: Early interest in respiratory infections and Vitamin D was due to research on hospitalized children. Young children who were hospitalized with respiratory infections were found to have much higher rates of rickets than children hospitalized for other causes.(3) Rickets, of course, is caused by Vitamin D deficiency. If Vitamin D deficiency also causes immune dysfunction, we might come up with an explanation for how low Vitamin D in these children made them more susceptible to infection. But there are other explanations. Children with a serious vitamin deficiency are likely to be less healthy overall compared to non-deficient children. In addition, rickets can cause rib deformities, which are known to make it harder to cough and breathe deeply, leading to an increased risk of respiratory infections. Vitamin D itself is not necessary for explaining the infections in these children. 
 </p><p id="viewer-8d45v">Most researchers understand that correlation does not equal causation. The classic example of this involves the correlation between ice cream and violent crime. As ice cream consumption rises, so does the rate of violent crime. The association is strong, and puzzling, until you remember that more ice cream is sold during warmer months, which is also when violent crime rates rise. Ice cream has no causative connection to crime. </p><div id="viewer-8u104"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/3e0600_7750c8e0f0804ca7b241349a5caa3f6a~mv2.jpg/v1/fit/w_900,h_720,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_7750c8e0f0804ca7b241349a5caa3f6a~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-2muq9"><em>Children about to embark on a life of crime?</em></p><p id="viewer-i9b6"><strong>But the temptation to equate correlation and causation is strong.</strong> Many articles showing a correlation with Vitamin D will add an untested but completely plausible physiological explanation for how low vitamin levels could lead to the disease. Armed with a solid correlation and a reasonable argument for causation, they may feel justified in concluding that the evidence for causation is strong. And once you have made that leap, you are almost obligated in recommending Vitamin D supplementation for anyone affected by or concerned about your disease of interest. </p><p id="viewer-9rfi1">Assuming that the correlations between Vitamin D and various illnesses are accurate, the argument for supplementation then depends on the plausibility of the physiologic mechanism. The numerous conditions associated with the deficiency involve disparate organs and body systems. To understand how one vitamin could be involved in so much, and whether we can explain a disease state by the vitamin's deficiency, it helps to know the basics of what Vitamin D does on a molecular level.</p><p id="viewer-ccvgc"><strong>Vitamin D is a hormone that binds to the Vitamin D Receptor</strong>, a protein made by cells throughout your body. The vitamin acts like a key, while the receptor is a lock. A key and lock are pointless individually, but useful together. Vitamin D and its receptor are inactive until they combine, and then they interact with DNA to produce certain actions within the cell. Based on what we already know, it is easy to understand why the intestines, parathyroids, and bones make Vitamin D Receptors – these organs are all involved in regulating calcium levels, and we know Vitamin D regulates calcium metabolism. But those are not the only organs that have the receptors. We find these receptors all over the place, in the kidneys, lungs, pancreas, uterus, and blood cells involved in immune function, just to name a few.(4,5) </p><p id="viewer-5olt1">Our bodies like to conserve resources, so if an organ or cell uses energy and resources to make these receptors, we can assume that they use them. This is the first solid piece of evidence that Vitamin D is involved in many processes throughout multiple organs. The next goal is to figure out how the organs use Vitamin D. There are various ways to do this. One clever method involves the use of mutant mice called “knockout mice” that have been genetically modified to inactivate a specific gene. In this case, the gene for the Vitamin D Receptor is inactivated, to produce "VDR null" mice. Studies in these animals provide important clues about Vitamin D, since without the lock, or receptor, the key is useless. As expected, these knockout mice have problems with calcium absorption, and the most notable effect is stunted bone growth.(6) This can be mitigated by giving the mice lots of calcium, which makes sense, since it is possible but harder for calcium to be absorbed without Vitamin D.</p><div id="viewer-3qo09"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/a27d24_ea278d26b9924aa2b2b0105b816d4c62~mv2.jpg/v1/fit/w_887,h_377,al_c,q_80/file.png" src="https://static.wixstatic.com/media/a27d24_ea278d26b9924aa2b2b0105b816d4c62~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-75iel"><em>Knockout mice are mice that have been genetically modified to inactivate a specific gene. VDR null mice are knockout mice that do not make Vitamin D Receptors. (The mouse in the photo is just a random mouse. We don't actually grow them in petri dishes.)</em></p><p id="viewer-4s6nd">But we already knew about Vitamin D and calcium. What about those other effects? VDR null mice should be helpful in explaining Vitamin D’s other roles, and we do see some revealing changes: these mutant mice on average have higher blood pressure than normal mice, and mice lacking the receptor specifically on the heart have decreased cardiac function. Certain immune cells also seem to also be impaired in the mutant mice.</p><p id="viewer-fakeg">Following this out a few steps, we could come up with a logical explanation for how Vitamin D helps the immune system, and thus deficiency would lead to impaired immune function, which then lead to increased susceptibility to infections. It sounds reasonable. But there are a few assumptions we are making: 1. We assume that Vitamin D deficiency is similar to a complete absence of the receptor. This is questionable, since even people with severe Vitamin D deficiencies still have some amount of Vitamin D. 2. We also assume that the receptor works exactly the same in mice as it does in humans. Mice and humans are relatively close on the evolutionary tree (when compared to, say, shiitake mushrooms), so this could be true, but maybe not.</p><p id="viewer-5b36s">Maybe we need to go back to humans. Interestingly, there is a very rare condition in humans characterized by ineffective Vitamin D Receptors due to a genetic mutation, similar to the VDR null mice.(7) Like the mice, these individuals will develop severely abnormal bone growth if untreated. Thinking logically and using what we know about the receptor in mice, we might expect that these individuals who cannot process Vitamin D effectively would have immune dysfunction, and perhaps cardiac issues. So far, we have not seen this. They do not appear to have an increased risk of cancer, respiratory infections, diabetes, or any of the other conditions found to be associated with Vitamin D deficiency. This genetic defect is extremely rare, though, and we have not yet been able to study these patients over a lifetime, so we may have more to learn. </p><p id="viewer-1lu5r">Studying the Vitamin D Receptor in living bodies is not the only way to assess Vitamin D’s actions. We can also study Vitamin D in a lab, using living cells in a test tube or culture dish. Much of our evidence for a link between Vitamin D and immunity comes from these <em>in vitro</em> studies. Vitamin D Receptors are …</p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics">https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics</a></em></p>]]>
            </description>
            <link>https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics</link>
            <guid isPermaLink="false">hacker-news-small-sites-24138590</guid>
            <pubDate>Thu, 13 Aug 2020 00:07:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Memoization in Dynamic Programming Through Examples]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24138567">thread link</a>) | @algodaily
<br/>
August 12, 2020 | https://algodaily.com/lessons/memoization-in-dynamic-programming/?view=article | <a href="https://web.archive.org/web/*/https://algodaily.com/lessons/memoization-in-dynamic-programming/?view=article">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://algodaily.com/lessons/memoization-in-dynamic-programming/?view=article</link>
            <guid isPermaLink="false">hacker-news-small-sites-24138567</guid>
            <pubDate>Thu, 13 Aug 2020 00:03:33 GMT</pubDate>
        </item>
    </channel>
</rss>
