<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 14 Nov 2020 08:22:13 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 14 Nov 2020 08:22:13 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Essential Guide to Design Strategy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068234">thread link</a>) | @mmanja
<br/>
November 12, 2020 | https://designstrategy.guide/the-ultimate-design-strategy-e-book/ | <a href="https://web.archive.org/web/*/https://designstrategy.guide/the-ultimate-design-strategy-e-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">

	
	

	
	<main id="main">
<div id="content" role="main">
	<div>
		<div>
			<div>
				
				
														
							<section id="section_296537513">
		

		<div>
			
<div>
<p><img src="https://designstrategy.guide/wp-content/uploads/2020/03/white-layer.png"><br>
<img src="https://designstrategy.guide/wp-content/uploads/2020/10/bg-blurb.png"></p>
<div id="row-1107532592">

	

	

	<div id="col-1710250879">
		<div>
			
			
<h3>The Ultimate Design Strategy e-book</h3>
<p>Learn how to leverage design strategy to increase ROI, enhance your design‚Äôs value and much more.</p>
<p><a rel="noopener noreferrer" href="https://designstrategy.mykajabi.com/pl/237579" target="_blank">
    <span>CLAIM YOUR FREE COPY</span>
  </a>

		</p></div>
			</div>

	

	

	


</div>
		</div>

		

	</div></section>
	
	<section id="section_1883728336">
		

		<div>
			
	<div>

		<div>
						<p><img width="1200" height="890" src="https://designstrategy.guide/wp-content/uploads/2020/11/Ipad-with-hand-small.gif" alt="DesignStrategyEbook" loading="lazy">											</p>
					</div>

		
	</div>
	
<div id="row-127489978">

	<div id="col-1548646680">
		<div>
			
			
	<div id="image_1819398198">
								<p><img width="1020" height="427" src="https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-1024x429.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-1024x429.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-300x126.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-768x322.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-600x251.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white.png 1181w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1800934927">

	<div id="col-552287654">
		<div>
			
			
<h2>Why am I giving<br>you this eBook for free?</h2>
<p>Plenty of designers and product managers feel lost and frustrated while trying to prove their product design‚Äôs value and making a tangible impact. I will show you how to leverage design strategy to raise your profit.</p>
<p>I BELIEVE THAT THERE ARE 4 THINGS TO FOCUS ON:</p>
		</div>
			</div>

	
</div>

<div id="row-672414174">

	

	

	<div id="col-1745313949">
		<div>
			
			
<p>Embrace your<br>metrics and KPIs</p>

		</div>
			</div>

	


</div>
<div id="row-921065282">

	<div id="col-741255186">
		<div>
			
			
	<div id="image_1843436450">
								<p><img width="1020" height="505" src="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-300x148.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-768x380.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-600x297.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1.png 1144w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1636970527">

	<div id="col-808340790">
		<div>
			
			
<h3><img loading="lazy" src="https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL.png" alt="The Design Strategy E-book" width="325" height="462" srcset="https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL.png 500w, https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL-211x300.png 211w" sizes="(max-width: 325px) 100vw, 325px"></h3>
<h3><span>Why and how? </span></h3>
<p><span>That‚Äôs what I unpack in the ebook.</span></p>
<p>It‚Äôs a bull***-free guide that‚Äôll help you to create your design strategy, raise your conversion rates and implement better processes.</p>
		</div>
			</div>

	
</div>
<div id="row-568516417">

	<div id="col-1943768373">
		<div>
			
			
	<div id="image_1446842050">
								<p><img width="1020" height="445" src="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-300x131.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-768x335.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-600x262.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white.png 1199w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1492559956">

	<div id="col-494596946">
		<p>
			
			
<h2>Goodies that come with this book</h2>
		</p>
			</div>

	
</div>
<div id="row-369445464">

	

	

	<div id="col-657148562">
		<p>Research diagrams and insights</p>
		

	</div>

	
</div>
<div id="row-818094838">

	

	

	<div id="col-335714451">
		<p>Links that‚Äôll expand your knowledge</p>
		

	</div>

	
</div>

<div id="row-1968143342">

	<div id="col-1499491670">
		<div>
			
			
	<div id="image_773397282">
								<p><img width="1020" height="505" src="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-300x148.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-768x380.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-600x297.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1.png 1144w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	
	<section id="section_142922943">
		

		<div>
			

<div id="row-697523738">

	<div id="col-1769925133">
		<div>
			
			
<p><span>It is an eye-opener for every designer.<br>
</span></p>
<p><span>Claudia, UX designer</span></p>
		</div>
			</div>

	

	

	

	<div id="col-2135895161">
		<div>
			
			
<p><span>Too many startups fail because they don‚Äôt know which part they need to focus on (UX, dev, design). This e-book showed me new methods that I need to try out. </span></p>
<p><span>Jessica, Project Manager</span></p>
		</div>
			</div>

	
</div>
	
	
<div id="row-1114524930">

	<div id="col-1217658912">
		<div>
			
			
<p><span>This book challenged my knowledge and showed me how and where to level up my design knowledge. Romina, thanks for choosing me to be part of your UX testing group. Plus, the design is just wow.<br></span></p>
<p><span>Monika, CMO</span></p>
		</div>
			</div>

	

	

	

	<div id="col-1956540074">
		<div>
			
			
<p><span>Now I know how to choose Design metrics. üôÇ</span></p>
<p><span>Sara, Front-End Developer</span></p>
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	
	<section id="section_1437866319">
		

		<div>
			
<div id="row-264567360">

	<div id="col-164622068">
		<div>
			
			
	<div id="image_603184383">
								<p><img width="1020" height="445" src="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-300x131.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-768x335.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-600x262.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white.png 1199w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1173391370">

	<div id="col-210819593">
		<div>
			
			
<h3><span>Meet the author</span></h3>
	
	
<div id="row-1304714560">

	<div id="col-1388914297">
		<div>
			
			
	<div id="image_1260825357">
								<p><img width="682" height="1024" src="https://designstrategy.guide/wp-content/uploads/2020/11/03-682x1024.jpg" alt="Romina Kavcic Websi 2020" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/11/03-682x1024.jpg 682w, https://designstrategy.guide/wp-content/uploads/2020/11/03-200x300.jpg 200w, https://designstrategy.guide/wp-content/uploads/2020/11/03-768x1152.jpg 768w, https://designstrategy.guide/wp-content/uploads/2020/11/03-1024x1536.jpg 1024w, https://designstrategy.guide/wp-content/uploads/2020/11/03-600x900.jpg 600w, https://designstrategy.guide/wp-content/uploads/2020/11/03.jpg 1141w" sizes="(max-width: 682px) 100vw, 682px">						
					</p>
								

	</div>
	
		</div>
			</div>

	

	

	

	<div id="col-813177097">
		<p><span>Romina is an award-winning Design Strategist who holds a Master of Business Administration. She has 15+ years of career experience in design work and consulting across both tech startups and several marquee tech unicorns such as Stellar.org, Outfit7, Databox, Xamarin, Chipolo, Singularity.NET, etc. She is currently advising, coaching and consulting with companies on design strategy &amp; management, visual design and user experience. Her work has been published on Forbes, Hackernews, Blockgeeks, Newsbtc, Bizjournals, and featured on Apple Store.</span></p>
			</div>

	
</div>
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	

						
												</div>
		</div>
	</div>
</div>


</main><!-- #main -->

<!-- .footer-wrapper -->

</div></div>]]>
            </description>
            <link>https://designstrategy.guide/the-ultimate-design-strategy-e-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068234</guid>
            <pubDate>Thu, 12 Nov 2020 09:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neurohacking the World Sleep Championships]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068156">thread link</a>) | @pedalpete
<br/>
November 12, 2020 | https://soundmind.co/blog/neurohacking-the-world-sleep-championships | <a href="https://web.archive.org/web/*/https://soundmind.co/blog/neurohacking-the-world-sleep-championships">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-e2b9e06d42ac6600e580"><div><p>I‚Äôm the last person you‚Äôd expect to compete in the <a href="https://www.worldsleepchampionships.com/">World Sleep Championships</a>. A life-long insomniac with Central Sleep Apnea, I‚Äôve spent the last 10 months diving into the latest in neuroscience research with the goal of not only helping insomnia sufferers, but improving Sleep Performance for the greater population.&nbsp;</p><p>The competition used the data from Oura rings which classifies sleep as REM, light or deep, and factors in the number of hours you slept, how quickly you fell asleep, and how much time you spent in each sleep state.&nbsp;</p><h3>More people have died in their sleep than during any other activity, making this the most dangerous and extreme competition that has ever taken place! </h3><p>The organizers of the World Sleep Championships decided on a tournament type structure for the competition. We started with the seeding process to get our baseline sleep data, and build the competition tree. Seeding was followed by 5 alternating nights of head-to-head competition where the highest score for each pair of competitors made it through to the next round .</p><p>The only rule was that we couldn‚Äôt take sleeping pills, everything else was fair game. Rumour had it that sleep deprivation on non-competition nights was the strategy of choice for many competitors.</p><h3>I didn‚Äôt stoop to such tactics, instead relying on the SoundMind prototype to guide me through the competition.</h3><p>It started off very well, when I averaged the 2nd highest scores through seeding, and managed the 2nd highest score of 92 points on the first night of competition<br></p><p>I believed Oura was removing points for a low amount REM sleep as a percentage of my overall sleep, so I made an adjustment to the sounds played by SoundMind to promote more REM sleep. I had a hint that this would work, but, it was a bit like running a marathon in a new pair of sneakers. A wrong move and my competition would be over.</p><p>My competitor that night put in a very solid score of 93, and apparently began his celebrations early, before seeing the 96 points I achieved with the updated version of SoundMind. This turned out to be the highest score of the entire tournament.</p><p>This was followed-up by a score of 95 the next night of competition. Far above my pre-SoundMind average in the low 70s.</p><p>Going into the semi-finals, a win looked unlikely. At 2am, somebody rang the buzzer at my apartment, it was a food delivery guy who had the wrong address. When the buzzer rang a 2nd time at 2:30am, I was wondering if this was a new tactic my opponent had discovered as the only way to destroy my sleep and chances at winning the night. Waking up, I felt pretty good, but didn‚Äôt know if I‚Äôd have the high score to win with only 89 points. However, potentially my opponent's guilt over interfering in my sleep, if she actually had done this, kept her awake fretting, and I had a few points lead over her, which led me into the finals.</p><p>I felt confident going into the finals. Not only because of the high scores I had been seeing, but due to the consistency. Anybody can have one or two nights of great sleep, but to consistently be able to sleep great every night, that‚Äôs the real challenge, and also why the competition rewards the person who can get the high score night after night.</p><div><p>Potentially with a bit of nerves coming into play, I only managed to eke out a 93 on the final night, and I wasn‚Äôt sure if that would be enough to take the win from a man with a history of scoring in the low 90s. To add to the suspense, the competition takes place around the world, and living in Australia, we‚Äôre the 2nd country to be awake, so I had to wait a day to get the final results!</p><p>It was a close final, but I managed to win out by a mere 2 points! Though I don‚Äôt feel a strong need to give an acceptance speech or thank my sponsors, I do want to thank Damian and Todd for organizing the event, and to all my fellow competitors. </p><p>The most important result here for me is that we had a fun way to test out the SoundMind tech, and see it in action as more than just another score or another great night sleep. As I‚Äôve been using SoundMind it‚Äôs been interesting to see how quickly I‚Äôve adapted to just accepting that a good night sleep is what happens. I almost forget what it was like being awake all night, and the agony which comes with that.&nbsp;</p></div><p>We‚Äôll have more updates, and be sharing more data as we progress, and sign-up to the wait list to reserve your spot and get one of the first headbands so you can have amazing sleep too!</p><p>Soon we‚Äôll all be sleeping well with SoundMind.</p></div></div></div>]]>
            </description>
            <link>https://soundmind.co/blog/neurohacking-the-world-sleep-championships</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068156</guid>
            <pubDate>Thu, 12 Nov 2020 09:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pascal Implementation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067899">thread link</a>) | @z3phyr
<br/>
November 12, 2020 | https://homepages.cwi.nl/~steven/pascal/book/pascalimplementation.html | <a href="https://web.archive.org/web/*/https://homepages.cwi.nl/~steven/pascal/book/pascalimplementation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h2>The P4 Compiler and Interpreter</h2>
<p><em>by <a href="http://www.cwi.nl/~steven/">Steven Pemberton</a>, 
<a href="http://www.cwi.nl/~steven/amsterdam.html">Amsterdam</a>, 
and <a href="http://www.it.bton.ac.uk/staff/mcd/">Martin Daniels</a></em>
</p>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/0intro.html">Chapter 0: Preface and Introduction</a></p>
<h2>Part 1: The Compiler</h2>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/1lexical.html">Chapter 1: Input and Lexical Analysis</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/2syntax.html">Chapter 2: Syntax Analysis</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/3semantic.html">Chapter 3: Semantic Analysis</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/4codegen.html">Chapter 4: Code Generation</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/5expressions.html">Chapter 5: Compiling Expressions</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/6procfunc.html">Chapter 6: Compiling Procedures and Functions</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/7statements.html">Chapter 7: Compiling Statements</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/8declarations.html">Chapter 8: Compiling Declarations</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/9program.html">Chapter 9: Compiling the Program</a>
</p>
<h2>Part 2: The Interpreter</h2>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/10pcode.html">Chapter 10: The P-code Machine</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/11assembler.html">Chapter 11: The Assembler</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/12interpreter.html">Chapter 12: The Interpreter</a>
</p>
<h2>Appendices</h2>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/13appendices.html">Chapter 13: Appendices</a>
</p>
<p>Copyright ¬© 1982, 2002 Steven Pemberton and Martin Daniels, all rights reserved.</p>
<!--
<pre>
ok	recreate diags
ok	em F
ok	em equationvariables
ok	div
ok	p class=body
	` to '
	heading types
	pre for programs (done for 6)
li for numbered lists
	li for notes
dl's for class="Line" (to do for 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)
var
kw
&lt;code&gt;
line nos: make them links to the code

deal with single note ols
fix part 2 notes
italicise comments in program fragments
move labels diagrams to semantics
redate preface
add navigation to all chapters
</pre>
-->




</div>]]>
            </description>
            <link>https://homepages.cwi.nl/~steven/pascal/book/pascalimplementation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067899</guid>
            <pubDate>Thu, 12 Nov 2020 09:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating our dev-sec Ansible roles to a collection]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067897">thread link</a>) | @zufallsheld
<br/>
November 12, 2020 | https://dev-sec.io/blog/2020-10-11-ansible-collection/ | <a href="https://web.archive.org/web/*/https://dev-sec.io/blog/2020-10-11-ansible-collection/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <div>
    <article>
      
      

<p>In July 2020 we decided to move our existing Ansible roles for Linux, ssh, nginx and MySQL into an Ansible collection (<a href="https://docs.ansible.com/ansible/latest/user_guide/collections_using.html">what is a collection?</a>).</p>



<p>Having only one repository for all roles means we don‚Äôt have to duplicate code. We have one common test-suite for all roles that works the same for every role.
Also Collections are the future, as there is possibly no support for roles in the next version of Ansible Galaxy (see <a href="https://github.com/ansible/galaxy_ng/issues/58">ansible/galaxy_ng#58</a>).</p>



<p>Collections are only supported from Ansible 2.9 and onwards. However Ansible 2.8 is still supported (<a href="https://docs.ansible.com/ansible/latest/reference_appendices/release_and_maintenance.html#release-status">https://docs.ansible.com/ansible/latest/reference_appendices/release_and_maintenance.html#release-status</a>). This means we need to support the separate roles until 2.9 is the oldest maintained release.</p>



<p>We decided to use the ansible-os-hardening git repository for our new collection because it has the most stars. We didn‚Äôt want to lose our precious internet points!
We created a separate branch and worked on this one until the migration to the main branch was ready.
All the roles that lived in separate repositories should move to the <code>roles</code>-directory. It was important for us to keep the history of all roles. Fortunately we weren‚Äôt the first ones who wanted to migrate one repository with its history to another. So with the help of StackOverflow, migrating them wasn‚Äôt too hard.</p>

<p>The roles were tested with the help of test-kitchen (I wrote about it <a href="https://www.zufallsheld.de/2016/01/05/testing-ansible-roles/">here</a>) and our trusted <a href="https://dev-sec.io/baselines/">Inspec Baselines</a>. We kept the baselines but replaced test-kitchen with molecule, the de-facto standard for testing Ansible content. This made it possible to test our collection in the same way locally as done in CI. Speaking of CI: We replaced travis (good riddance - Travis <a href="https://blog.travis-ci.com/2020-11-02-travis-ci-new-billing">changed</a> their pricing model) with <a href="https://github.com/features/actions">Github Actions</a>.
Now every role inside the collection has its own pipeline that only runs when files from the role change. We still test our roles on a plethora of operating systems and the most important ones (CentOS and Ubuntu in its various versions) are all supported with all roles.</p>

<p>One problem with the new releases existed: since we wanted to re-use the ansible-os-hardening repository for the collection, we could not start from version 1.0.0 for the collection since the tag already existed. So to no break the old role we decided to continue the version from the role in the collection. This is why we started with version 7 in the collection.</p>

<p>Releasing new versions with a changelog was something we already <a href="https://github.com/dev-sec/ansible-os-hardening/issues/269">automated</a> some time ago. We wanted to keep the nicely formatted changelogs and automatic releases and modifying the existing Github Actions was no problem.</p>

<p>Our plan how to actually migrate the roles into the collection looked like this: Start building the collection and use the roles as submodules inside the monorepo. This way we can continue to support the separate roles and the roles inside the collection cannot diverge from the legacy roles.</p>

<p>When everything was migrated, we planned to archive the old roles and link to the collection.</p>



<p>There were some problems along the way but nothing we couldn‚Äôt fix.</p>

<p>Along the creation of the collection we needed to update our inspec-baselines as they needed more features to support all our operating systems.
That means we now support newer versions of MySQL and MariaDB (<a href="https://github.com/dev-sec/mysql-baseline/pull/59">https://github.com/dev-sec/mysql-baseline/pull/59</a>, <a href="https://github.com/dev-sec/mysql-baseline/pull/57">https://github.com/dev-sec/mysql-baseline/pull/57</a>) and we support Arch Linux in the linux-baseline (<a href="https://github.com/dev-sec/linux-baseline/pull/136">https://github.com/dev-sec/linux-baseline/pull/136</a>).</p>

<p>We also wanted to replace Inspec with its free distribution <a href="https://cinc.sh/">cinc-auditor</a>. This was surprisingly easy as the people behind cinc made it very easy to install cinc-auditor and use it as a drop-in replacement for Inspec. See this <a href="https://github.com/dev-sec/ansible-os-hardening/pull/291/commits/e7a47a1d342e1b45ceeeae7a1ff247f58ce3434e">commit</a> for details.</p>

<p>There was an <a href="https://github.com/ansible/ansible/issues/66304">issue</a> in Ansible that we needed to work around. This was done by <a href="https://github.com/schurzi/">@schurzi</a> here: <a href="https://github.com/dev-sec/ansible-os-hardening/pull/291/commits/3f7598b5bae80f96cad3ad068f0d57b3e1e538ed">https://github.com/dev-sec/ansible-os-hardening/pull/291/commits/3f7598b5bae80f96cad3ad068f0d57b3e1e538ed</a></p>

<p>Our mysql-hardening-role relies on a existing installation of MySQL or MariaDB. For this we used geerlingguys mysql-role because it supports many operating systems. However the role has some issues and unmerged pull requests that prevented us to use geerlingguys role as is. We had to <a href="https://github.com/dev-sec/ansible-role-mysql/">fork</a> the role and incorporate some PRs and fixes. We hope we don‚Äôt have to continuously support the fork though.</p>

<p>The hardest bug we encountered was a problem with AppArmor and MySQL on recent Ubuntu distributions. Here‚Äôs the bug: <a href="https://bugs.launchpad.net/ubuntu/+source/mysql-5.7/+bug/1610765">https://bugs.launchpad.net/ubuntu/+source/mysql-5.7/+bug/1610765</a>.
A faulty AppArmor profile prevents MySQL from starting because AppArmor blocks access to MySQL‚Äôs configuration files.
And Github Actions run on a Ubuntu 18.04 virtual machine with AppArmor enabled. So I wondered why the role does work when running molecule locally (btw: I use Arch) but not in the CI-pipeline.
It took some days to figure this one out. However once I found out the reason for this, the solution was found much faster. <a href="https://robertdebock.nl/">Robert de Bock</a> also had this problem and fixed it <a href="https://github.com/robertdebock/ansible-role-mysql/commit/7562e99099b06282391ab7ed102b393a0406d212">here</a></p>

<p>We also dropped support for some operating systems:</p>

<ul>
<li>CentOS 6 because support ends in November 2020</li>
<li>Oracle-Linux because supporting it is really cumbersome and we don‚Äôt know anyone that uses our roles on Oracle</li>
</ul>



<p>It‚Äôs here:</p>

<ul>
<li><a href="https://galaxy.ansible.com/devsec/hardening">Galaxy</a></li>
<li><a href="https://github.com/dev-sec/ansible-os-hardening/">Repository on Github</a></li>
</ul>

<p>Please share your feedback with us, ask questions on the mailing list, open issues and pull requests on our repo!</p>



<p>We plan to archive the repositories of the roles incorporated in the collection and redirect everyone to the collection. The open issues and pull requests will be moved or closed.
This way, no code gets lost and (almost) no links will be broken.</p>

<p>Of course we want to continue working on the collection and support more operating systems and more software! If you want to help, reach out!</p>



<p>I want to thank the devsec team, especially <a href="https://github.com/micheelengronne">@micheelengronne</a>, <a href="https://github.com/schurzi/">@schurzi</a> and <a href="https://github.com/chris-rock">@chris-rock</a> for their work and support in creating the collection and this awesome opensource community!</p>

    </article>
  </div>
</section></div>]]>
            </description>
            <link>https://dev-sec.io/blog/2020-10-11-ansible-collection/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067897</guid>
            <pubDate>Thu, 12 Nov 2020 09:02:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Acing your technical interview ‚Äì a hiring manager‚Äôs guide]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067800">thread link</a>) | @ochronus
<br/>
November 12, 2020 | https://ochronus.online/acing-the-tech-interview/ | <a href="https://web.archive.org/web/*/https://ochronus.online/acing-the-tech-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section><p>Even though interviewing for a software engineering job can be intimidating and frustrating (with whiteboard exercises, remote coding challenges, and even full days of onsite interviews), it‚Äôs a lot easier when you know what to expect and are well-prepared.</p><p>I‚Äôve interviewed a few hundred software engineering candidates in the past 10+ years and designed hiring processes. My experience is limited to startups and mid-sized companies, so take everything you read here with that in mind. My advice may not get you into Facebook or Google but will definitely increase your chances at mid-sized companies with a good culture!</p><p>In the first part of this article, I‚Äôll give some context, then give you an actionable list to improve your experience and chances in your next interview</p><p>If you‚Äôre only interested in the actionable list, feel free to skip ahead to it.</p><hr><h2 id="what-you-think-about-the-technical-interview-might-be-incomplete">What you think about the technical interview might be incomplete <a href="#what-you-think-about-the-technical-interview-might-be-incomplete"></a></h2><p>First and foremost, a technical interview is almost never only technical. Up to a certain (and honestly, very useful!) level growing as a ‚Äòcoder‚Äô is not that complicated. Many candidates perform pretty well if we purely look at their coding skills.</p><p>The thing is, you‚Äôll rarely work alone in isolation on your own codebase. You‚Äôll have teammates, you‚Äôll need to agree on things with them, you‚Äôll build on others‚Äô code and others will build on your code. You‚Äôll need to build solutions with a certain level of quality, in a future-proof way, for extensibility, and with performance in mind. Depending on your role and level, you‚Äôll need to architect systems. You‚Äôll need to mentor other engineers. You‚Äôll need to onboard new team members. You‚Äôll need to proactively reach out to other teams in the company and understand their points of view and problems. You‚Äôll talk to product managers, UX researchers, designers, even customers sometimes. You‚Äôll need to manage projects, make tradeoffs and decisions, and align other engineers with that.</p><p>Read my article on <a href="https://ochronus.online/technical-interview-myths/">the most common 11 technical interview myths</a></p><hr><h2 id="types-and-stages-of-technical-interviews">Types and stages of technical interviews <a href="#types-and-stages-of-technical-interviews"></a></h2><p>Most companies use a combination of these steps:</p><ul><li>Screening call with a recruiter ‚Äì We‚Äôre interested in your basic motivations, we‚Äôd like to have a gut feeling about what you‚Äôre looking for and do some sanity check here. You might get asked about your salary requirements, support you need for visa or relocation, and timelines (when could you start, etc.). Some recruiters will also ask you whether you have applied elsewhere so they know how urgent this is for them and you.</li><li>Screening call with the hiring manager ‚Äì Expect some deeper dive into your experience on multiple fronts ‚Äì tech and ‚Äòsoft skills‚Äô alike. As a hiring manager, I‚Äôll prepare by checking out your CV for talking points, maybe even your LinkedIn profile, and definitely GitHub. I‚Äôm not trying to judge you, I‚Äôm just looking for points of connection. I‚Äôll answer any questions you have about the role, the company, the culture, potential teams you‚Äôd be joining, etc. etc. My ultimate goal with this is twofold: would we be a good match for your (and vice versa) and whether I think you‚Äôd be successful in the role.</li><li>Remote technical screening ‚Äì An alternative, or at some places precursor to the online coding exercise. This is with a human on the other end of the line ‚Äì solving tech problems together, usually, you walk them through your solution.</li><li>Online coding exercises (LeetCode, HackerRank, etc.) ‚Äì I know you all hate this. We need such a step to filter out people who can‚Äôt even code at all early on. You‚Äôd be surprised about the number of such applicants. I avoid algorithm/data structure exercises here and try to come up with somewhat interesting ones. Some companies use a much heavier set of exercises and base their judgment of your technical skills solely on this. While I don‚Äôt agree with that strategy, you need to get prepared for this, too.</li><li>Take-home assignment ‚Äì this is one of the most polarizing interview steps for engineers. Some hate it, claiming it‚Äôs just free labor for the companies and it takes too much time, others love it because they feel they have the freedom of giving it much time, really showing off their skills in their own comfortable environment. Whichever camp you‚Äôre in, you can expect some companies requiring this. You usually get a somewhat specified problem to solve and you‚Äôre given different levels of freedom on how to solve it ‚Äì some companies don‚Äôt mind you choosing whichever stack you like, others will even specify the framework.</li><li>Onsite workshop / remote workshop ‚Äì I think this is the most interesting of all steps (well, for me at least). It‚Äôs about solving problems together with people from the company in a simulated environment. You‚Äôll need to show your communication, decision-making, and even prioritization skills here. Sure, people will look at the quality of your code, too, but ‚Äòsoft skills‚Äô are just as important here. We‚Äôll get strong signals about how it would be having you on the team.</li></ul><hr><h2 id="cracking-the-technical-interview">Cracking the technical interview <a href="#cracking-the-technical-interview"></a></h2><h3 id="ask-the-recruiter-or-the-hiring-manager-before-the-interview">Ask the recruiter or the hiring manager before the interview <a href="#ask-the-recruiter-or-the-hiring-manager-before-the-interview"></a></h3><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-1920w.webp 1920w, https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-1280w.webp 1280w, https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-640w.webp 640w, https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-1920w.jpg 1920w, https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-1280w.jpg 1280w, https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-640w.jpg 640w, https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-320w.jpg 320w" type="image/jpeg"><img height="300" src="https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager.jpg" width="300" alt="Ask the recruiter or the hiring manager before the interview" decoding="async" loading="lazy"></picture>Take the guesswork out of the equation. If you feel you don‚Äôt have enough information to prepare, just ask for more! We‚Äôre here to help you succeed. I really mean it. Sometimes we aren‚Äôt doing a great job with sharing enough information proactively about the interview steps but that‚Äôs not intentional! I‚Äôm always happy to help you prepare better ‚Äì ask about anything, please. You‚Äôre doing both of us a favor with that. Ask during the previous interview step or just drop me an email at any time.</p><h3 id="show-up-on-time">Show up on time <a href="#show-up-on-time"></a></h3><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-1920w.webp 1920w, https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-1280w.webp 1280w, https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-640w.webp 640w, https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-1920w.jpg 1920w, https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-1280w.jpg 1280w, https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-640w.jpg 640w, https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-320w.jpg 320w" type="image/jpeg"><img height="300" src="https://ochronus.online/img/acing-the-technical-interview/arrive-on-time.jpg" width="300" alt="Show up on time" decoding="async" loading="lazy"></picture>Make sure you‚Äôre there on time. If you can‚Äôt, for some reason, please let us know, we‚Äôll happily organize for another time, no hard feelings. Showing up on time isn‚Äôt only about respecting each other‚Äôs schedule ‚Äì interview time slots are usually 100% utilized and by arriving 10 minutes late you‚Äôre reducing your own chance to be successful. You‚Äôre also making it more stressful for yourself than necessary. If you need time for commute or for your Zoom/Google Meet setup, think ahead and give yourself a buffer before the start.</p><h3 id="don't-jump-right-into-solution-mode---read%2C-distill%2C-paraphrase">Don't jump right into solution mode - read, distill, paraphrase <a href="#don't-jump-right-into-solution-mode---read%2C-distill%2C-paraphrase"></a></h3><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-1920w.webp 1920w, https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-1280w.webp 1280w, https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-640w.webp 640w, https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-1920w.jpg 1920w, https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-1280w.jpg 1280w, https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-640w.jpg 640w, https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-320w.jpg 320w" type="image/jpeg"><img height="300" src="https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase.jpg" width="300" alt="Don't jump right into solution mode - read, distill, paraphrase" decoding="async" loading="lazy"></picture>The biggest mistake you can do is thinking you understand the problem or what‚Äôs asked of you and jumping right into coding. Take your time, carefully read the problem statement, distill it, don‚Äôt think of solutions just yet. When you feel you understand what‚Äôs asked of you or when you thought about clarifying questions to ask, communicate. Paraphrase what you understood from the problem statement so you can verify it with your interviewers. Only when you‚Äôre on the same page can you shift into solution mode. Even if you come up with the best solution ultimately if you skip this step I‚Äôll remember and have doubts about how it‚Äôd be to work with you. Thinking aloud is really useful here - it will help you and help me too to understand what's on your mind.</p><h3 id="be-articulate-and-communicate-clearly">Be articulate and communicate clearly <a href="#be-articulate-and-communicate-clearly"></a></h3><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-1920w.webp 1920w, https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-1280w.webp 1280w, https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-640w.webp 640w, https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-1920w.jpg 1920w, https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-1280w.jpg 1280w, https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-640w.jpg 640w, https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-320w.jpg 320w" type="image/jpeg"><img height="300" src="https://ochronus.online/img/acing-the-technical-interview/communicate-clearly.jpg" width="300" alt="Be articulate and communicate clearly" decoding="async" loading="lazy"></picture>Even if you know your trade, if you fail to communicate clearly during your interview we‚Äôll have no way of knowing. This takes practice for most people, so take your time and prepare! Use standard terms that other engineers can relate to, avoid passive voice, and be able to articulate what‚Äôs going on in your mind while you‚Äôre thinking. If you need some time to think quietly, say so, don‚Äôt just fall silent suddenly. We‚Äôre trying our best to communicate our expectations around this but it might be a bit late when you‚Äôre in the interview. Trust me on this one, practice here goes a long way.</p><h3 id="ask-clarifying-questions">Ask clarifying questions <a href="#ask-clarifying-questions"></a></h3><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-1920w.webp 1920w, https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-1280w.webp 1280w, https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-640w.webp 640w, https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-1920w.jpg 1920w, https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-1280w.jpg 1280w, https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-640w.jpg 640w, https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-320w.jpg 320w" type="image/jpeg"><img height="300" src="https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions.png" width="300" alt="Ask clarifying questions" decoding="async" loading="lazy"></picture>While you‚Äôd think the interview is about you answering questions, expect that you will need to ask a lot of questions! When you are in the interview and something is not clear don‚Äôt default to thinking ‚ÄúOh god, I should know this, I should understand‚Äù ‚Äì sometimes we are interested in how you behave in such situations, and sometimes we‚Äôre just simply not good enough in giving enough context. If you‚Äôre stuck, a good technique is to ask for clarification! It‚Äôs also 100% OK to say things like ‚ÄúI didn‚Äôt quite get that. Could you rephrase please?‚Äù or ‚ÄúI‚Äôm not sure I understand what you‚Äôre asking‚Äù. These are good signals! I expect my team members to behave like this. These are not signals of you failing. I know it feels like that, but trust me, it‚Äôs just your brain playing tricks on you. I highlight this during the interview several times, to make sure the candidate feels safe asking such questions. Another technique I wholeheartedly welcome is paraphrasing ‚Äì e.g. ‚ÄúWhat I understood from what you said is that I should implement this using co-monads‚Äù (said nobody ever).</p><h3 id="demonstrate-your-tech-skills-the-right-way">Demonstrate your tech skills the right way <a href="#demonstrate-your-tech-skills-the-right-way"></a></h3><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-1920w.webp 1920w, https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-1280w.webp 1280w, https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-640w.webp 640w, https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-1920w.jpg 1920w, https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-1280w.jpg 1280w, https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-640w.jpg 640w, https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-320w.jpg 320w" type="image/jpeg"><img height="300" src="https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer.jpg" width="300" alt="T-shaped engineer" decoding="async" loading="lazy"></picture>Make us see that you‚Äôre deeply proficient in at least one technology. This can be a programming language, for example. Also, demonstrate that you know the adjacent technologies ‚Äì most companies are looking for so-called T-shape engineers. This means that mentioning other aspects of the problem and the solution goes a long way. For example, if you‚Äôre asked to implement a service in NodeJS, mention how you‚Äôd deploy, monitor, and scale it, even if that‚Äôs not explicitly asked. No need to go into too many details (unless people ask you). If you‚Äôre only focused on a single piece of the puzzle I‚Äôll have a hard time seeing how you‚Äôd perform well in a changing environment (where you‚Äôll need to make connections and work on multiple zoom levels and be ready). This is a very generic statement and might not be true in the case of highly specialized roles, of course. On the other hand, if you say your primary language is Python yet you can‚Äôt seem to show even a basic understanding of it, that‚Äôs a no-no. Work on the stem of that T, too. Hopefully, you‚Äôve clarified what you‚Äôd be doing on the interview upfront (see advice #1) so you can think about adjacent technologies in advance.</p><h3 id="don%E2%80%99t-get-too-focused-or-stuck-on-a-solution">Don‚Äôt get too focused or stuck on a solution <a href="#don%E2%80%99t-get-too-focused-or-stuck-on-a-solution"></a></h3><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/you-have-options-1920w.webp 1920w, https://ochronus.online/img/acing-the-technical-interview/you-have-options-1280w.webp 1280w, https://ochronus.online/img/acing-the-technical-interview/you-have-options-640w.webp 640w, https://ochronus.online/img/acing-the-technical-interview/you-have-options-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/you-have-options-1920w.jpg 1920w, https://ochronus.online/img/acing-the-technical-interview/you-have-options-1280w.jpg 1280w, https://ochronus.online/img/acing-the-technical-interview/you-have-options-640w.jpg 640w, https://ochronus.online/img/acing-the-technical-interview/you-have-options-320w.jpg 320w" type="image/jpeg"><img height="300" src="https://ochronus.online/img/acing-the-technical-interview/you-have-options.jpg" width="300" alt="Don‚Äôt get too focused or stuck on a solution" decoding="async" loading="lazy"></picture>Sometimes a solution you came up with ‚Ä¶</p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ochronus.online/acing-the-tech-interview/">https://ochronus.online/acing-the-tech-interview/</a></em></p>]]>
            </description>
            <link>https://ochronus.online/acing-the-tech-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067800</guid>
            <pubDate>Thu, 12 Nov 2020 08:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You don't need a blockchain solution for your next project]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25067702">thread link</a>) | @shrmv
<br/>
November 12, 2020 | https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project | <a href="https://web.archive.org/web/*/https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>Blockchain is one of the hottest technology fields of the last decade, together with machine learning and big data. According to the <a rel="nofollow" href="https://www2.deloitte.com/content/dam/insights/us/articles/6608_2020-global-blockchain-survey/DI_CIR%202020%20global%20blockchain%20survey.pdf">Deloitte 2020 Global Blockchain Survey</a>, businesses worldwide find blockchain an integral part of organizational innovation. </p>
<p>Properly implemented, a blockchain solution can make parts of your business transparent or enable different actors to cooperate quickly and trustlessly. </p>
<p>But today, we won√¢‚Ç¨‚Ñ¢t examine blockchain√¢‚Ç¨‚Ñ¢s strengths. Instead, we will look at why it√¢‚Ç¨‚Ñ¢s not the perfect choice for all your software projects.  </p>
<h2>Blockchain is more expensive</h2>
<p>From our experience, infrastructure and maintenance costs for a blockchain solution are typically 10-15 times higher compared to an ordinary server with a database running on AWS or a custom AWS/GCP/Azure solution.</p>
<p>Even when using economically efficient Azure solutions, it can cost up to ten times more when compared to a centralized DB with similar functionality running on AWS.</p>
<p>Therefore, it√¢‚Ç¨‚Ñ¢s necessary to seriously weigh the costs of running your solution vs. the need for transparency and distribution that blockchain offers. </p>
<h2>Blockchain scales worse</h2>
<p>Performance and scalability are the two major bottlenecks for any blockchain project. </p>
<p>From our experience working for large enterprise companies such as Bayer AG, Delta, PwC, and others, blockchain solutions that work fine for hundreds and thousands of users degrade in performance quite quickly when they need to serve more than ten thousand users.</p>
<p>Scaling blockchain, on the other hand, usually requires a complete rework of the core. Sometimes, there might even be no viable solution. So, despite some ambitious claims by blockchain companies, scaling is still an immature topic in the blockchain world.</p>
<h2>Blockchain is about transparency, not privacy</h2>
<p>Privacy is an issue. It is challenging to maintain privacy on the blockchain. In contrast to regular solutions, existing blockchain solutions are often all about transparency rather than privacy.</p>
<p>Solutions that provide the required level of privacy typically have to compromise on performance through zero-knowledge proofs or other kinds of encryption, which is costly.</p>
<p>Another problem with privacy is that most of the time, blockchain is permissionless or has very primitive permissions levels. Therefore, solutions for permissions are built on top of it as an additional middle layer, which, of course, adds performance overhead, degrades scalability, adds implementation and execution costs, etc.
Conclusion</p>
<p>There are three significant challenges that blockchain projects face: performance, scalability, and privacy. While there are multiple benefits for using blockchain, such as transparency and the ability to operate trustlessly, they need to be weighed against the downsides. </p>
<p>We want to share our knowledge with you about potential problems not to talk you away from blockchain, but to make sure the choice is clear and the right one for your project. If you still aren√¢‚Ç¨‚Ñ¢t sure and would like to have a 30-minute consultation with an expert in the field, you√¢‚Ç¨‚Ñ¢re welcome to <a href="https://exyte.com/contacts">contact us</a>. </p>
                </div></div>]]>
            </description>
            <link>https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067702</guid>
            <pubDate>Thu, 12 Nov 2020 08:25:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WSL explained ‚Äì crucial Q&A to get to know near-native Linux experience]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067677">thread link</a>) | @Pabloemm
<br/>
November 12, 2020 | https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html | <a href="https://web.archive.org/web/*/https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><a href="https://solidstudio.io/index.html">Solidstudio</a>
                    &gt;&gt;
                    <a href="https://solidstudio.io/blog/blog.html">Blog</a>
                    &gt;&gt;
                    &gt;Windows Subsystem for Linux (WSL) explained ‚Äì Q&amp;A
                </p>
                <p>No matter if you program in <a href="https://solidstudio.io/technologies/java.html">Java</a> or <a href="https://solidstudio.io/technologies/kotlin.html">Kotlin</a> or with other technologies, operating on Linux has a number of advantages. One of them is access to Linux Bash with its useful commands.</p>
                <p>However, some developers have to or prefer working on Windows. As stackoverflow.com 2020 <a href="https://insights.stackoverflow.com/survey/2020#development-environments-and-tools" rel="nofollow">survey</a> showed, almost half of developers (45,8%) work in the Windows environment. There are tools that bring them closer to the Linux world like <a href="https://www.cygwin.com/" ref="nofollow">Cygwin</a>.</p>
                
                <h2>The WSL provides a near-native Linux experience</h2>
                <p>Some time ago Microsoft introduced WSL, a new tool that brings Windows users even closer to the Linux experience. Here you can find gathered some frequently asked questions and our expert‚Äôs experience to help you get a better understanding of the WSL.</p>
                
                <h3>What is WSL?</h3>
                <p>WSL or Windows Subsystem for Linux is a part of the Windows operating system that allows running native Linux binaries. A number of distributions exist that can be installed and used. </p>
                
                <h3>How can I install WSL?</h3>
                <p>First thing to do before installing any Linux distribution is to install the WSL itself.</p>
                <p>Go to <i>Control Panel</i> ‚Üí <i>Programs</i> ‚Üí <i>Programs and Features</i> ‚Üí <i>Turn Windows features on and off</i>.</p>
                <p>Select <i>Windows Subsystem for Windows</i>, confirm, and restart the system.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/wsl-install.png" alt="Turn Windows features on and off dialog with Windows Subsystem for Linux selected"></p><p>Now you are ready to select and install a Linux distribution of your choice.</p>
                                
                <h3>What Linux distributions are available on WSL?</h3>
                <p>To find a list of available distributions open Windows Store and search for "Linux".<br>
                The most popular are:
                </p><ul>
                <li>Ubuntu 18.04 and 20.04</li>
                <li>SUSE Linux Enterprise Server</li>
                <li>Debian</li>
                <li>Fedora Remix for WSL</li>
                <li>Kali Linux</li>
                </ul>                
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/windows-store-search.png" alt="Windows Store search result for term Linux"></p><h3>Is it possible to run graphical Linux applications from WSL?</h3>
                <p>Yes, it is possible. You need to install an X Window System server application on your Windows, for example <a href="https://sourceforge.net/projects/xming/" rel="nofollow">Xming X Server for Windows</a>.</p>
                <p>Then check if your WSL system has a <span>DISPLAY</span> environment variable set up. If not set it to <span>:0</span>.</p>
                <pre>export DISPLAY=:0</pre>
                <p>After this configuration you are free to run native Linux applications with user interface.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/xclock.png" alt="WSL running xclock via Xming"></p><h3>Where is wsl.conf located?</h3>
                <p>Each WSL instance can be further configured by creating and editing a config file <span>/etc/wsl.conf</span>.</p>
                
                <h3>How to access Windows files from WSL?</h3>
                <p>All fixed drives with the NTFS or ReFS file system are automatically mounted in <span>/mnt</span> directory. For example a C: drive can be accessed in <span>/mnt/c/</span>. The directory where drives are mounted can be specified in <span>/etc/wsl.conf</span> as follows:</p>
                <pre>[automount]
root=/</pre>
                <p>This setting will cause drives to be mounted under the root folder, so the C: drive would be accessible through <span>/c</span> folder.</p>

                <h3>How to access pendrive from WSL?</h3>
                <p>Unlike fixed drives, removable drives are not mounted automatically. To access files stored on a USB stick you need to mount it yourself. For this purpose, use these commands (assume the drive letter in Windows is F):</p>
                <pre>sudo mkdir /mnt/f
sudo mount -t drvfs H: /mnt/f</pre>

                <h3>How to connect to a DVD drive from WSL?</h3>
                <p>Optical drives are not as popular nowadays as they used to be. Nonetheless, they can be accessed the same way as pendrives (assume G is the drive letter):</p>
                <pre>sudo mkdir /mnt/g
sudo mount -t drvfs G: /mnt/g</pre>

                <h3>Where are WSL files stored?</h3>
                <p>WSL files are exposed through a network share <span>\\wsl$\[distro name]</span>, for example my home directory is at <span "="">\\wsl$\Ubuntu-20.04\home\pawelb</span>.</p>
                <p>Physically the WSL files are located at <span>%USERPROFILE%\AppData\Local\Packages\[distro name]</span>. My home folder is at this rather long path <span>C:\Users\pawelb\AppData\Local\Packages\CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgsc\LocalState\rootfs\home\pawelb</span>.</p>
                <p>However, it is worth noting that manipulating WSL files from within Windows should be avoided as it can destroy Linux-specific file metadata. If you need to manipulate files on both WSL and Windows, store them on a Windows drive and access them from within WSL via <span>/mnt</span>.</p>
                
                <h3>Is it possible to run Windows programs from within WSL?</h3>
                <p>Yes, the WSL was built with interoperability in mind. It can run native Windows programs. However, if this feature is not needed, the user can disable it by adding <span>enabled=false</span> into <span>[interop]</span> section in <span>wsl.conf</span>.</p>
                <pre>[interop]
enabled=false</pre>

                
                <h3>What terminal application to use?</h3>
                <p>Any terminal can do the job, even the good old <span>cmd.exe</span>. Just run the WSL command in. There is however one great application that makes running the WSL console easier. It‚Äôs <a href="https://docs.microsoft.com/en-us/windows/terminal/get-started" rel="nofollow">Windows Terminal</a> and it can be installed from Windows Store. It automatically detects any WSL distributions installed and adds an option to run its console. It also supports regular Windows Command Line, PowerShell, and Azure console out of the box. Also, it supports tabs and split view inside a tab.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/windows-terminal.png" alt="Windows Terminal application"></p><h3>Caveats of interoperability with Windows</h3>
                <p>By default, WSL can run Windows binaries and also appends its <span>%PATH%</span> variable into the <span>$PATH</span> variable of Linux running under WSL. In most cases, this is useful or at least does no harm. However, sometimes unexpected behavior occurs.</p>
                <p>This happened when I tried to run <span>npm</span>.</p>
                <pre>$ npm -v
module.js:471
    throw err;
    ^

Error: Cannot find module '\\wsl$\Ubuntu-20.04\c\Programs\nvm\v6.10.2\node_modules\npm\bin\npm-cli.js'
    at Function.Module._resolveFilename (module.js:469:15)
    at Function.Module._load (module.js:417:25)
    at Module.runMain (module.js:604:10)
    at run (bootstrap_node.js:393:7)
    at startup (bootstrap_node.js:150:9)
    at bootstrap_node.js:508:3</pre>
                
                <p>This error message is not helpful at all. What happened?</p>
                <p>After some investigation, I found out that I had also installed npm on Windows and WSL was using this executable to run. This unfortunately failed under WSL environment.</p>
                <p>A fix was rather simple. I disabled appending Windows <span>%PATH%</span> to WSL <span>$PATH</span>.</p>
                <p>This can be done in two ways.</p>
                <p>The first is to use the Registry Editor (regedit) to add a DWORD <span>AppendNtPath</span> with value <span>0</span> under <span>HKEY_CURRENT_USER\SOFTWARE\Microsoft\Windows\CurrentVersion\Lxss</span>. This affects all WSL distributions.</p>
                <p>The second way is to set a property in <span>/etc/wsl.conf</span>. This affects only a single distribution.</p>
                <pre>[interop]
appendWindowsPath=false</pre>

                <h2>The WSL is a great subsystem for Windows </h2>
                <p>With the introduction of Windows 10, a lot has changed. It seems that the system and its features are more and more thought-out and intuitive. A programmer needs a proper working environment. With WSL, Windows is keeping up with developments in this area, and looks like it is a step in the right direction. It‚Äôs worth having an eye on the development of this solution, hoping that in the future the developers will have a variety of systems that can really compete with each other. Looking for a good and stable, seamless tool, it is worth trying with the WSL.</p>
                
                
                
            </div></div>]]>
            </description>
            <link>https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067677</guid>
            <pubDate>Thu, 12 Nov 2020 08:21:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deno is the same as Node.js, but different]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067625">thread link</a>) | @velmu
<br/>
November 12, 2020 | https://developers.ibexa.co/blog/deno-is-the-same-as-node.js-but-different | <a href="https://web.archive.org/web/*/https://developers.ibexa.co/blog/deno-is-the-same-as-node.js-but-different">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>JavaScript has been on a roll for more than a decade now. What started as a language used for sprinkling some interactivity to static HTML has grown to be arguably the world's most widespread general purpose programming language. The hegemony of JavaScript is also evident on the server side, with Node.js being a staple of job ads for many years. Recently there's been some buzz around a similar technology:&nbsp;<a href="https://deno.land/" title="">Deno</a></p><div><p>Let's find out what Deno is and how it compares with <a href="https://nodejs.org/" title="">Node.js</a>. First things first: The name Deno is an <a href="https://www.arrak.fi/en/ag" title="">anagram</a> of Node, and they are two&nbsp;different open source software projects.&nbsp;Deno&nbsp;sounds like a cheap knock-off of the more established Node.js, given the two technologies' problem domain and overall similarity. But once you learn both were originally kicked off by the same person, <a href="https://en.wikipedia.org/wiki/Ryan_Dahl" title="">Ryan Dahl</a>,&nbsp;it changes the perception.</p><p>Dahl released the first version of Node.js in May 2009. In January 2012 he stepped aside from the project to focus on other things. To the surprise of many he announced Deno in 2018 at a conference talk titled&nbsp;<a href="https://www.youtube.com/watch?v=M3BM9TB-8yA" title="">10 Things I Regret About Node.js</a>. in his talk, the primus motor of Node.js outlines some of the things he'd do differently today.&nbsp;That is what Deno is: An alternative&nbsp;take on a server-side JavaScript runtime.</p><p>Since the unveiling of&nbsp;Deno a developer community has grown&nbsp;around it. To many outside of the dev realm their efforts culminated in the <a href="https://deno.land/posts/v1" title="">launch of&nbsp;1.0</a> in May 2020.</p><h3>What do Node.js and Deno have in common?</h3><p>Both Deno and Node run on the same technology platform: The <a href="https://en.wikipedia.org/wiki/V8_(JavaScript_engine)" title="">V8 JavaScript engine</a>. This is a widespread JavaScript runtime that is largely developed by Google for their <a href="https://en.wikipedia.org/wiki/Google_Chrome" title="">Chrome</a> web browser, but is also present in&nbsp;<a href="https://www.chromium.org/" title="">Chromium</a> variants like <a href="https://opera.com/" title="">Opera</a> and <a href="https://www.microsoft.com/en-us/edge" title="">Microsoft Edge</a>. The&nbsp;<a href="https://v8.dev/" title="">V8 project</a> has&nbsp;received huge investments in time and resources from volunteers and companies. In short,&nbsp;V8 is a killer: It's blazing fast and gets new language features from&nbsp;<a href="https://www.ecma-international.org/publications/standards/Ecma-262.htm" title="">ECMAScript-262</a> (the standard that defines <a href="https://en.wikipedia.org/wiki/JavaScript" title="">JavaScript</a>).</p><p>Node and Deno both do more or less the same thing: They run JavaScript code on a server (yes, there is always a server, even if you're <a href="https://en.wikipedia.org/wiki/Serverless_computing" title="">serverless</a>). The range of apps that can be&nbsp;built&nbsp;is wide; a&nbsp;data pump proxying streams of data from one location and format to another is a common use case, as are API backends for <a href="https://en.wikipedia.org/wiki/Single-page_application" title="">SPAs</a>,&nbsp;but you can also write complex full-stack backend apps like the <a href="https://ghost.org/" title="">Ghost blogging platform</a> or custom apps with <a href="https://developers.ibexa.co/content-root/blog/getting-started-with-next.js-and-ez-platform">a framework like Next.js</a>&nbsp;that runs&nbsp;<a href="https://en.wikipedia.org/wiki/Isomorphic_JavaScript" title="">on the server and the client</a>.</p><p>The shared architecture of JavaScript/V8 means both share similar performance characteristics. There can be some differences, where one is better than the other - but as a baseline both are performant enough for most uses and can be scaled horizontally. If you're looking for the absolute best throughput you should probably <a href="https://www.ageofascent.com/2019/02/04/asp-net-core-saturating-10gbe-at-7-million-requests-per-second/" title="">look at something like .NET Core</a> or something very&nbsp;low level. There are areas where V8 performance won't cut it, but if you're in those fields then you probably know it.</p><p>The JavaScript ecosystem is massive. The core skills you need to work with either Node or Deno are very similar. The syntax is identical, even though Deno actually enforces the use of <a href="https://www.typescriptlang.org/" title="">TypeScript</a>&nbsp;in the <a href="https://en.wikipedia.org/wiki/User_space" title="">userland</a>. TypeScript is a superset of JavaScript, adding optional typing and other features that can be useful in development phase. It's also worth noting that you can also develop Node.js apps in TypeScript, and ultimately the V8 engine executes loosely JavaScript that is compiled from the TypeScript source.</p><h3>How is Deno different from Node.js?</h3><p>Unlike with Node, the use of TypeScript is a requirement with Deno. Some parts of Deno itself are written in TypeScript, but <a href="https://startfunction.com/deno-will-stop-using-typescript/" title="">the team is looking to change that</a> as it is not well suited for that purpose. TS is <a href="https://basarat.gitbook.io/typescript/type-system" title="">not strictly typed</a> and does not offer a bullet proof runtime enforcing 100% <a href="https://en.wikipedia.org/wiki/Type_safety" title="">type safety</a>, but relies quite a bit&nbsp;on <a href="https://en.wikipedia.org/wiki/Type_inference" title="">type inference</a>&nbsp;to <a href="https://symfony.fi/entry/a-practical-introduction-to-typescript-for-php-developers#make-javascript-great-again" title="">enable type checking and associated development time tooling in&nbsp;IDEs for JavaScript</a>.</p><p>Another significant difference is the security model. Node.js never had a universal security model baked in. This means that it easy to write code that will do a lot of harm in the wrong hands,&nbsp;maliciously&nbsp;or accidentally. The approach in Deno is different,&nbsp;in line with browsers and the <a href="https://developers.ibexa.co/content-root/blog/secure-by-default-why-the-role-based-permission-model-offers-powerful-security" title="">Ibexa DXP permissions&nbsp;model</a>:</p><blockquote><p>Deno is secure by default. Therefore, unless you specifically enable it, a deno module has no file, network, or environment access for example. Access to security-sensitive areas or functions requires the use of permissions to be granted to a deno process on the command line.<br>- <a href="https://deno.land/manual/getting_started/permissions" title="">Deno Manual: Permissions</a></p></blockquote><p>The <a href="https://en.wikipedia.org/wiki/Standard_library" title="">standard library</a> is another area where Deno is different from Node.js. Node has a fairly small standard library, which has lead into a large number of&nbsp;external packages for (what some think) should be offered by default in the distribution. For Deno this is again different, as they offer a more comprehensive standard library inspired by&nbsp;<a href="https://golang.org/" title="">Go</a>:</p><blockquote><p>deno_std is a loose port of&nbsp;<a href="https://golang.org/pkg/">Go's standard library</a>. When in doubt, simply port Go's source code, documentation, and tests. There are many times when the nature of JavaScript, TypeScript, or Deno itself justifies diverging from Go, but if possible we want to leverage the energy that went into building Go. We generally welcome direct ports of Go's code.<br>- <a href="https://deno.land/std" title="">Deno Standard Library</a></p></blockquote><p>Related to external packages, this is another big difference between the two. Node.js relies on a central repository, <a href="https://www.npmjs.com/" title="">NPM</a>, for storing and delivering libraries and other code. This ecosystem is a huge benefit for developers as it reduces&nbsp;<a href="https://en.wikipedia.org/wiki/Duplicate_code" title="">duplication</a>. With <a href="https://snyk.io/blog/npm-passes-the-1-millionth-package-milestone-what-can-we-learn/" title="">over a million packages on NPM</a>,&nbsp;it's a common phrase to say <em>there's an NPM package for that</em>&nbsp;in the developer circles. And often this is true, and the benefits are obvious.</p><p>Shared code is good code, and Deno does not intend to implement everything in the <em>stdlib</em>. What is fundamentally different is the distribution model. Instead of a central repository, <a href="https://deno.land/manual/linking_to_external_code" title="">any URL can contain a package</a>. The project hosts a set of packages over at&nbsp;<a href="https://deno.land/x">deno.land/x</a>, but it is not enforced anywhere. This means there is no central owner like with&nbsp;<a href="https://en.wikipedia.org/wiki/Npm_(software)" title="">NPM</a> (now <a href="https://github.blog/2020-03-16-npm-is-joining-github/" title="">owned by GitHub</a> <a href="https://news.microsoft.com/announcement/microsoft-acquires-github/" title="">owned by Microsoft</a>). This approach means you can host a <a href="https://en.wikipedia.org/wiki/Web_server" title="">HTTP server</a> (public or private) and reference libraries directly from there.</p><p>Another area related to extensions is the simplification of code packaging. When Node.js came around, there was no standard <a href="https://en.wikipedia.org/wiki/Modular_programming" title="">module format</a> in the ECMAScript spec. This is why Node.js rolled&nbsp;its&nbsp;own module format, known as&nbsp;<a href="https://en.wikipedia.org/wiki/CommonJS" title="">CommonJS</a>. Because of the popularity of Node.js, CommonJS became the <a href="https://en.wikipedia.org/wiki/De_facto_standard" title="">de facto standard</a>&nbsp;for modules in the JavaScript ecosystem. Since that time the ECMAScript has received regular updates and now includes a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules" title="">standard JavaScript Modules</a>&nbsp;that also <a href="https://jakearchibald.com/2017/es-modules-in-browsers/" title="">work in browsers</a>.</p><p>Nowadays <a href="https://nodejs.medium.com/announcing-core-node-js-support-for-ecmascript-modules-c5d6dc29b663" title="">Node.js also&nbsp;supports JavaScript&nbsp;modules</a>, but much of the ecosystem continues to use CommonJS. Both formats do more or less the same thing, but with a different syntax. This can make it confusing to work with Node since you can use two different ways for a core functionality.&nbsp;<a href="https://deno.land/manual/examples/import_export" title="">Deno standardizes on ECMAScript modules</a>.</p>        
<div>
    
    
    <figure><img src="https://developers.ibexa.co/var/site/storage/images/_aliases/medium/0/0/3/2/112300-1-eng-GB/deno-mascot.png" alt="" height="188" width="200"></figure>

</div>
<p>Finally there's the mascot, Deno. Just take a look at the <a href="https://deno.land/artwork" title="">artwork from the collection</a> (blog post main image courtesy of&nbsp;<a href="https://www.dimitrijagal.com/" title="">Dimitrij Agal</a>).&nbsp;Who could say no to the lil' one?</p><h3>Conclusion</h3><p>As we've learnt there are a number of similarities between Deno and Node.js, but also some key differences in philosophy and implementation. Perhaps the <a href="https://github.com/denoland/deno/issues/47" title="">most controversial difference</a> is the novel take on dependency management in Deno. Resolving a complex set of dependencies could be more challenging (and potentially more unreliable)&nbsp;in this fully distributed model. It's worth noting that you can use packages from the&nbsp;NPM catalogue with <a href="https://jspm.org/" title="">jspm&nbsp;that hosts NPM packages as ES modules</a>.</p><p>Node.js has massive clout on the market, it is a hot technology and developers are sought after by both startups and enterprises. The vibrant ecosystem&nbsp;proves that there is nothing fundamentally wrong with Node.js and it&nbsp;is a big part of the JavaScript success story of the last decade. Node.js is not going anywhere, but&nbsp;Deno could carve out&nbsp;a niche for itself. One thing&nbsp;that comes to mind is&nbsp;FaaS (<a href="https://en.wikipedia.org/wiki/Function_as_a_service" title="">Function as a Service</a>), whose development could be simpler&nbsp;with Deno's more&nbsp;extensive&nbsp;standard library.</p><p>But wait a minute... This is the <a href="https://www.ibexa.co/" title="">Ibexa</a> blog. What's Deno got to do with you? Well, nothing as of now. We're using plenty of JavaScript, for example,&nbsp;<a href="https://www.reactjs.org/" title="">React.js components</a> for the administration user interface, and our asset build pipeline is Node.js based, courtesy of <a href="https://symfony.com/doc/current/frontend/encore/installation.html" title="">Symfony Encore</a>. But as of now the&nbsp;<a href="https://developers.ibexa.co/content-root/products" title="">Ibexa DXP line of products</a> aren't utilizing any active JavaScript server <a href="https://en.wikipedia.org/wiki/Daemon_(computing)" title="">daemons</a> in Node.js, Deno or <a href="https://cs.nyu.edu/~yap/html/tutorial/getstart.htm" title="">Netscape Livewire</a>.</p><p>Implementations where Ibexa DXP is deployed are a different case. Our technology is often a piece of a puzzle involving many technology components, from&nbsp;<a href="https://en.wikipedia.org/wiki/A/B_testing" title="">A/B testing</a> services to&nbsp;<a href="https://developers.ibexa.co/content-root/resources/ebooks/e-commerce-integration-with-erp-and-other-business-systems-pim-and-crm">integrations to enterprise backend systems like ERPs</a>. This is where server side JavaScript is widely used, most commonly as <a href="https://developers.ibexa.co/content-root/blog/running-a-node.js-application-on-ibexa-cloud">Node.js apps&nbsp;that also run on Ibexa Cloud</a>, but increasingly as cloud functions like <a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-overview" title="">Azure Functions</a> or <a href="https://aws.amazon.com/lambda/" title="">AWS Lambda</a>.</p><p>As a melting pot of data and services a Digital Experience Platform needs to be able to interface with everything. This is why it is good for <a href="https://developers.ibexa.co/content-root/success-stories">our clients</a>, <a href="https://developers.ibexa.co/content-root/partners">partners</a> and us to be aware of&nbsp;emerging technologies. Integrations are key for <a href="https://developers.ibexa.co/content-root/blog/the-mid-enterprise-market-guide-to-digital-experience-platforms">DXPs</a>&nbsp;and Deno could be a contender in that space in the near future. And even if it is not, you always learn by&nbsp;studying&nbsp;alternative solutions to problems. Even the ones you choose not to go for.</p>
</div></div>]]>
            </description>
            <link>https://developers.ibexa.co/blog/deno-is-the-same-as-node.js-but-different</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067625</guid>
            <pubDate>Thu, 12 Nov 2020 08:11:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Native Is the Future of Mobile at Shopify]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067617">thread link</a>) | @hijklmno
<br/>
November 12, 2020 | https://shopify.engineering/react-native-future-mobile-shopify | <a href="https://web.archive.org/web/*/https://shopify.engineering/react-native-future-mobile-shopify">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>After years of native mobile development, we‚Äôve decided to go full steam ahead building all of our new mobile apps using React Native. As I‚Äôll explain, that decision doesn‚Äôt come lightly.</p>
<p>Each quarter, the majority of buyers purchase on mobile (with 71% of our buyers purchasing on mobile in Q3 of last year). Black Friday and Cyber Monday (together, BFCM) are the busiest time of year for our merchants, and buying activity during those days is a bellwether. During this year‚Äôs BFCM, Shopify merchants saw another 3% increase in purchases on <a href="https://news.shopify.com/shopify-merchants-break-records-with-29-billion-in-worldwide-sales-over-black-fridaycyber-monday-weekend" target="_blank" title="Shopify merchants break records with $2.9+ billion in worldwide sales over Black Friday/Cyber Monday weekend" rel="noopener noreferrer">mobile, an average of 69% of sales</a>.</p>
<p>So why the switch to React Native? And why now? How does this fit in with our native mobile development? It‚Äôs a complicated answer that‚Äôs best served with a little background.</p>

<p>We have an engineering culture at Shopify of making specific early technology bets that help us move fast.</p>
<p>On the whole, we prefer to have few technologies as a foundation for engineering. This provides us multiple points of leverage:</p>
<ul>
<li>we build <em>extremely</em> specific expertise in a small set of deep technologies (we often become core contributors)</li>
<li>every technology choice has quirks, but we learn them intimately</li>
<li>those outside of the initial team contribute, transfer and maintain code written by others</li>
<li>new people are onboarded more quickly.</li>
</ul>
<p>At the same time, there are always new technologies emerging that provide us with an opportunity for a step change in productivity or capability. We experiment a lot for the opportunity to unlock improvements that are an order of magnitude improvement‚Äîbut ultimately, we adopt few of these for our core engineering.</p>
<p>When we do adopt these early languages or frameworks, we make a calculated bet. And instead of shying away from the risk, we meticulously research, explore and evaluate such risks based on our unique set of conditions. As is often within risky areas, the unexplored opportunities are hidden. We instead think about how we can mitigate that risk:</p>
<ul>
<li>what if a technology stops being supported by the core team?</li>
<li>what if we run into a bug we can‚Äôt fix?</li>
<li>what if the product goes in a direction against our interests?</li>
</ul>
<p>Ruby on Rails was a nascent and obscure framework when Tobi (our CEO) first got involved as a <a href="https://github.com/tobi" target="_blank" title="Tobi on GitHub" rel="nofollow noopener noreferrer">core contributor</a> in 2004. For years, Ruby on Rails has been seen as a non-serious, <a href="https://m.signalvnoise.com/ruby-has-been-fast-enough-for-13-years/" target="_blank" title="Ruby has been fast enough for 13 years - Signal vs. Noise" rel="nofollow noopener noreferrer">non-performant</a> language choice. But that early bet gave Shopify the momentum to outperform the competition even though it was not a popular technology choice. By using Ruby on Rails, the team was able to build faster and attract a different set of talent by using something more modern and with a higher level of abstraction than traditional programming languages and frameworks. <a href="http://www.paulgraham.com/avg.html" target="_blank" title="Beating the Averages - PaulGraham.com" rel="nofollow noopener noreferrer">Paul Graham talks about his decision to use Lisp in building Viaweb to similar effect</a>&nbsp;and <a href="https://twitter.com/mhartl/status/1179561691857616896" target="_blank" title="Michael Hartl on Twitter" rel="nofollow noopener noreferrer">6 of the 10 most valuable Y Combinator companies today all use Ruby on Rails (even though again, it still remains largely unpopular)</a>. As a contrast, none of the Top 10 most valuable Y Combinator companies use Java; largely considered the battle tested enterprise language.</p>
<p>Similarly two years ago, Shopify decided to make the jump to <a href="https://engineering.shopify.com/blogs/engineering/shopify-infrastructure-collaboration-with-google" target="_blank" title="Shopify‚Äôs Infrastructure Collaboration with Google" rel="noopener noreferrer">Google Cloud</a>.&nbsp;<span>Again, a scary proposition for the 3rd largest US Retail eCommerce site in 2019‚Äîto do a cloud migration away from our own data centers, but to also pick an early cloud contender.&nbsp;</span>We saw the technology arc of value creation moving us to focusing on what we‚Äôre good at‚Äîenabling entrepreneurship and letting others (in this case Google Cloud) focus on the undifferentiated heavy lifting of maintaining physical hardware, power, security, the operating system updates, etc.</p>
<h2>What is React Native?</h2>
<p>In 2015, <a href="https://www.youtube.com/watch?v=KVZ-P-ZI6W4" target="_blank" title="React.js Conf 2015 Keynote - Introducing React Native" rel="nofollow noopener noreferrer">Facebook announced</a> and open sourced <a href="https://facebook.github.io/react-native/" target="_blank" title="React Native" rel="nofollow noopener noreferrer">React Native</a>; it was already being used internally for their mobile engineering. React Native is a framework for building native mobile apps using <a href="https://reactjs.org/" target="_blank" title="ReactJS" rel="nofollow noopener noreferrer">React</a>. This means you can use a best-in-class JavaScript library (React) to build your native mobile user interfaces.</p>
<p>At Shopify, the idea had its skeptics at the time (and still does), but many saw its promise. At the company‚Äôs next <a href="https://twitter.com/ShannonKarleen/status/1204881060213002240?s=20" target="_blank" title="Shannon Gallagher on Twitter" rel="nofollow noopener noreferrer">Hackdays</a>&nbsp;the entire company spent time on React Native. While the early team saw many benefits, they decided that we couldn‚Äôt ship an app we‚Äôd be proud of using React Native in 2015. For the most part, this had to do with performance and the absence of first-class Android support. What we did learn was that we liked the <a href="https://en.wikipedia.org/wiki/Reactive_programming" target="_blank" title="Reactive Programming - Wikipedia" rel="nofollow noopener noreferrer">Reactive programming</a> model and <a href="https://help.shopify.com/en/api/getting-started/shopify-and-graphql/graphql-benefits" title="GraphQL Benefits" target="_blank" rel="noopener noreferrer">GraphQL</a>. Also, we built and open-sourced a&nbsp;<a href="https://github.com/Shopify/FunctionalTableData" target="_blank" title="FunctionalTableData on GitHub" rel="nofollow noopener noreferrer">functional rendere</a>r for iOS after working with React Native. We adopted these technologies in 2015 for our native mobile stack, but not React Native for mobile development en masse. <a href="https://www.theglobeandmail.com/report-on-business/how-shopify-finally-got-smart-about-mobile/article33184093/" target="_blank" title="Shopify Grows Up" rel="nofollow noopener noreferrer">The Globe and Mail documented our aspirations</a> in a comprehensive story about the first version of our mobile apps.</p>
<p>Until now, the standard for all mobile development at Shopify was native mobile development. We built <a href="https://engineering.shopify.com/blogs/engineering/tagged/mobile-tooling" target="_blank" title="Mobile Tooling on Shopify Engineering" rel="noopener noreferrer">mobile tooling and foundations</a> teams focused on iOS and Android helping accelerate our development efforts. While these teams and the resulting applications were all successful, there was a suspicion that we could be more effective as a team if we could:</p>
<ul>
<li>bring the power of JavaScript and the web to mobile</li>
<li>adopt a reactive programming model across all client-side applications</li>
<li>consolidate our iOS and Android development onto a single stack.</li>
</ul>
<h3>How React Native Works</h3>
<p>React Native provides a way to build native cross platform mobile apps using JavaScript. React Native is similar to React in that it allows developers to create declarative user interfaces in JavaScript, for which it internally creates a hierarchy tree of UI elements or in React terminology a virtual DOM. Whereas the output of ReactJS targets a browser, React Native translates the virtual DOM into mobile native views using platform native bindings that interface with application logic in JavaScript. For our purposes, the target platforms are Android and iOS, but community driven effort have brought React Native to other platforms such as Windows, macOS and Apple tvOS.</p>
<p><img alt="ReactJS targets a browser, whereas React Native can can target mobile APIs." data-src="//cdn.shopify.com/s/files/1/0779/4361/files/React_Native_Blog_Post_2.jpg?v=1580316281" src="https://cdn.shopify.com/s/files/1/0779/4361/files/React_Native_Blog_Post_2.jpg?v=1580316281"></p>

<p><em>ReactJS targets a browser, whereas React Native can target mobile APIs.</em></p>
<h3>When Will We Not Default to Using React Native?</h3>
<p>There are situations where React Native would not be the default option for building a mobile app at Shopify. For example, if we have a requirement of:</p>
<ul>
<li>deploying on older hardware (CPU &lt;1.5GHz)</li>
<li>extensive processing</li>
<li>ultra-high performance</li>
<li>many background threads.</li>
</ul>
<p>Reminder: Low-level libraries including many open sourced SDKs will remain purely native. And we can always create our own native modules when we need to be close to the metal.</p>
<h3>Why Move to React Native Now?</h3>
<p>There were 3 main reasons now is a great time to take this stance:</p>
<ol>
<li>we learned from our acquisition of Tictail (a mobile first company that focused 100% on React Native) in 2018 how far React Native has come and made 3 deep product investments in 2019</li>
<li>Shopify uses React extensively on the web and that know-how is now transferable to mobile</li>
<li>we see the performance curve bending upwards (think what‚Äôs now possible in Google Docs vs. desktop Microsoft Office) and we can long-term invest in React Native like we do in Ruby, Rails, Kubernetes and Rich Media.</li>
</ol>

<p>We have many mobile surfaces at Shopify for buyers and merchants to interact, both over the web and with our mobile apps. We spent time over the last year experimenting with React Native with three separate teams over three apps: Arrive, Point of Sale, and Compass.</p>
<p>From our experiments we learned that:</p>
<ul>
<li>in rewriting the Arrive app in React Native, the team felt that they were twice as productive than using native development‚Äîeven just on one mobile platform</li>
<li>testing our Point of Sale app on low-power configurations of Android hardware let us set a lower CPU threshold than previously imagined (1.5GHz vs. 2GHz)</li>
<li>we estimated ~80% code sharing between iOS and Android, and were surprised by the extremely high-levels in practice‚Äî95% (Arrive) and 99% (Compass)</li>
</ul>
<p>As an aside, even though we‚Äôre making the decision to build all new apps using React Native, that doesn‚Äôt mean we‚Äôll automatically start rewriting our old apps in React Native.</p>
<h2>Arrive</h2>
<p>At the end of 2018, we decided to rewrite one of our most popular consumer apps, <a href="https://tryarrive.com/" target="_blank" title="Arrive by Shopify" rel="nofollow noopener noreferrer">Arrive</a> in React Native. Arrive is no slouch, it‚Äôs a highly rated, high performing app that has millions of downloads on iOS. It was a good candidate because we didn‚Äôt have an Android version. Our efforts would help us reach all of the Android users who were clamoring for Arrive. It‚Äôs now React Native on both iOS and Android and shares 95% of the same code. We‚Äôll do a deep dive into Arrive in a future blog post.</p>
<p>So far this rewrite resulted in:</p>
<ul>
<li>less crashes on iOS than our native iOS app</li>
<li>an Android version launched</li>
<li>team composed of mobile + non-mobile developers.</li>
</ul>
<p>The team also came up with this cool way to instantly test work-in-progress pull requests. You simply scan a QR code from an automated GitHub comment on your phone and the JavaScript bundle is updated in your app and you‚Äôre now running the latest code from that pull request. JML, <a href="https://twitter.com/jmwind/status/1185268708383645698?s=20" target="_blank" title="JML on Twitter" rel="nofollow noopener noreferrer">our CTO, shared the process on Twitter recently</a>.</p>
<h2>Point of Sale</h2>
<p>At the beginning of 2019, we did a 6-week experiment on our flagship <a href="https://www.shopify.ca/pos" target="_blank" title="Shopify POS" rel="noopener noreferrer">Point of Sale (POS) app</a> to see if it would be a good candidate for a rewrite in React Native. We learned a lot, including that our retail merchants expect almost 2x the responsiveness in our POS due to the muscle memory of using our app while also talking to customers.</p>
<p>In order to best serve our retail merchants and learn about React Native in a physical retail setting, we decided to build out the new POS natively for iOS and use React Native for Android.</p>
<p>We went ahead with 2 teams for the following reasons:</p>
<ol>
<li>we already had a team ramped up with iOS expertise, including many of the folks that built the original POS apps</li>
<li>we wanted to be able to benchmark our React Native engineering velocity as well as app performance against the gold standard which is native iOS</li>
<li>to meet the high performance requirements of our merchants, we felt that we‚Äôd need all of the <a href="https://github.com/react-native-community/discussions-and-proposals/issues/4" target="_blank" title="React Native Fabric (UI-Layer Re-architecture) on GitHub" rel="nofollow noopener noreferrer">Facebook ‚Ä¶</a></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/react-native-future-mobile-shopify">https://shopify.engineering/react-native-future-mobile-shopify</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/react-native-future-mobile-shopify</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067617</guid>
            <pubDate>Thu, 12 Nov 2020 08:09:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Release Notes for Regolith 1.5]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067509">thread link</a>) | @pedrokost
<br/>
November 11, 2020 | https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/ | <a href="https://web.archive.org/web/*/https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	<p>Release notes for Regolith 1.5.</p>
	<p>Regolith R1.5 is a feature release which includes several improvements and optimizations.  To summarize, Regolith 1.5 ships simpler workspace management, a Rofi-based Look switcher, and numerous internal optimizations and cleanup.  Read below for more details.</p>
<h2 id="known-issues">Known Issues</h2>
<p>Issues and fixes are being tracked in <a href="https://github.com/orgs/regolith-linux/projects/13">this project</a>.</p>
<h2 id="features">Features</h2>
<table>
    <tbody>
        <tr>
            <td>Next Free Workspace</td>
            <td colspan="2">A typical part of managing workspaces in an i3-based desktop is moving to unused workspaces and then loading some applications. Before this feature, a user has to determine which unused workspace they prefer.  This is done by scanning the list of existing used workspaces to determine an unused one. Now, the system can do this automatically.  The <span><span>super</span> <span>`</span></span> keybinding will move to the next free workspace.  <span><span>super</span> <span>alt</span> <span>`</span></span> will move the focused window into the next free workspace.</td>
        </tr>
        <tr>
            <td>View and Change Looks via Rofi</td>
            <td><a href="https://regolith-linux.org/docs/reference/releases/regolith-select-look.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-select-look.png"></a></td>
            <td>Looks can be changed now via a Rofi dialog rather than having to configure the Xresource override via the command-line.  To do this, use keybinding `<super>-<alt>l` and then select from the dialog to load a Look.</alt></super></td>
        </tr>
        <tr>
            <td>GSettings Overrides</td>            
            <td colspan="2">Regolith now uses [gsettings overrides](https://help.gnome.org/admin/system-admin-guide/stable/overrides.html.en) to configure various GNOME settings for use with Regolith.  In previous versions of Regolith, settings were written globally to the user session from within the Regolith startup code.  This could cause issues if the user works in multiple desktop environments.  Now, Regolith GNOME settings are defined in an override file that is only in effect while using a Regolith session.  This allows switching between desktop environments without settings from Regolith impacting other environments.</td>
        </tr>
        <tr>
            <td>New Looks</td>
            <td>
              <a href="https://regolith-linux.org/docs/reference/releases/regolith-dracula.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-dracula.png">
              </a><a href="https://regolith-linux.org/docs/reference/releases/regolith-gruvbox.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-gruvbox.png">
              </a><a href="https://regolith-linux.org/docs/reference/releases/regolith-pop-os.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-pop-os.png">
            </a></td>
            <td>Users have contributed some new Looks to Regolith: dracula, gruvbox, and pop-os.  Each of these looks presents a distinctive color palate, typeface, and GTK theme.</td>
        </tr>
        <tr>
            <td>i3-gaps upgraded to 4.18.2</td>
            <td colspan="2">See i3-gaps <a href="https://github.com/Airblader/i3/blob/a4a1a44275ea402b25d2d1365e1163e496024358/RELEASE-NOTES-4.18.2">release notes here</a>.</td>
        </tr>
        <tr>
            <td>More Refined Customizations</td>
            <td colspan="2">Numerous small changes allow more granular system customization, such as specifying the temperature unit, custom Compositor settings, and a more comprehensive way of changing i3 keybindings without having to copy the entire config file.</td>
        </tr>
        <tr>
            <td>More Desktop Environment Packages</td>
            <td colspan="2">The following packages can be installed in place of <code>regolith-desktop</code> for specific sets of packages based on user needs: <code>regolith-desktop-minimal</code>, <code>regolith-desktop-standard</code>, <code>regolith-desktop-mobile</code>, and <code>regolith-desktop-complete</code></td>
        </tr>
        <tr>
            <td>New default compositor: Picom version 8</td>
            <td colspan="2">See Picom's <a href="https://github.com/yshui/picom/releases">releaes notes here</a>.</td>
        </tr>
        <tr>
            <td>Remontoire upgraded to version 1.4</td>
            <td colspan="2">Includes better multi-monitor support and other bug fixes and enhancements.</td>
        </tr>
        <tr>
            <td>Optional integration with <b>td-cli</b></td>
            <td><a href="https://regolith-linux.org/docs/reference/releases/regolith-td.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-td.png"></a></td>
            <td>Access a simple todo app via Rofi.</td>
        </tr>
        <tr>
            <td>Documentation of development process.</td>
            <td colspan="2">The <a href="https://regolith-linux.org/docs/policy-and-process/development/">Regolith development process</a> is now better documented to enable greater transparency and inclusion.</td>
            <td></td>
        </tr>
      
    </tbody>
</table>
<h2 id="fixes">Fixes</h2>
<p>Have a look at the R1.5 project page for a <a href="https://github.com/orgs/regolith-linux/projects/12">list of bug fixes</a>.</p>
<h2 id="changelog-delta-from-regolith-141-to-regolith-15">Changelog Delta from Regolith 1.4.1 to Regolith 1.5</h2>
<pre><code>########################################
# Release Notes for dracula-gtk
########################################
dracula-gtk (1.0.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Remove unnecessary files


dracula-gtk (1.0-1) bionic; urgency=medium

  * [ Ken Gilmer ]
  * Packaging version add4f8c 

########################################
# Release Notes for fonts-materialdesignicons-webfont
########################################
fonts-materialdesignicons-webfont (1.6.50-3regolith3) bionic; urgency=medium

  * Backporting to bionic for Regolith. 


########################################
# Release Notes for gruvbox-gtk
########################################
gruvbox-gtk (1.0.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Rename root directory of theme to Gruvbox for consistency w/ other GTK themes.
  * Add gbp config for package management.


gruvbox-gtk (1.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * New upstream version 1.0


gruvbox-gtk (1.0-1) bionic; urgency=medium

  [ eximus ]
  * Initial commit
  * gruvbox theme


########################################
# Release Notes for i3-gaps-wm
########################################
i3-gaps-wm (4.18.2-1~regolith2) bionic; urgency=medium

  * Package source from upstream https://github.com/Airblader/i3/releases/tag/4.18.2


########################################
# Release Notes for i3ipc-python
########################################
i3ipc-python (2.1.1-1ubuntu1~ppa6) bionic; urgency=medium

  * Update build dependencies hoping to resolve packaing problems. 



########################################
# Release Notes for i3xrocks
########################################
i3xrocks (1.3.4-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Version bump to match changelog.  Cleanup.


i3xrocks (1.3.3-1) bionic; urgency=medium

  [ Will Winder ]
  * Add optional default resource value.
  * Minor cleanup.
  * Free resource allocated by xcb_xrm_resource_get_string
  * Fix possible truncated resource value.

  [ Ken Gilmer ]
  * Add gbp config file


########################################
# Release Notes for picom
########################################
picom (8-1~1.gbp353272ubuntu1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Remove github files from debian branch.


picom (8-1~1.gbp353272) bionic; urgency=medium

  [ Ken Gilmer ]
  * New upstream version 8


########################################
# Release Notes for plano-theme
########################################
plano-theme (3.36-1-1regolith1) bionic; urgency=medium

  [ Ken Gilmer ]
  * New upstream version 3.36-1


########################################
# Release Notes for plymouth-theme-regolith
########################################
plymouth-theme-regolith (1.0.3-1) focal; urgency=medium

  * Tweaks to config files. 


plymouth-theme-regolith (1.0.2-1) focal; urgency=medium

  * Ship grub file. 


plymouth-theme-regolith (1.0.1-1) focal; urgency=medium

  * Add package hooks. 



########################################
# Release Notes for pop-fonts
########################################
pop-fonts (1.0.3~1555617065~18.04~a86eb73) bionic; urgency=medium

  * Auto Build

########################################
# Release Notes for python3-i3ipc
########################################
python3-i3ipc (2.1.1-1ubuntu1~ppa7) bionic; urgency=medium

  * Changes to python version.


i3ipc-python (2.1.1-1ubuntu1~ppa6) bionic; urgency=medium

  * Update build dependencies hoping to resolve packaing problems. 


i3ipc-python (2.1.1-1ubuntu1~ppa4) eoan; urgency=medium

  * Add python-xlib dependency. 


i3ipc-python (2.1.1-1ubuntu1~ppa2) eoan; urgency=medium

  * Initial release from https://github.com/altdesktop/i3ipc-python/archive/v2.1.1.tar.gz.


########################################
# Release Notes for regolith-compositor-compton-glx
########################################
regolith-compositor-compton-glx (1.1.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Init script will kill pre-existing app instance before starting new. Part of fix for https://github.com/regolith-linux/regolith-desktop/issues/475.


regolith-compositor-compton-glx (1.0.10-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Fix typo in compton config file, found by @gservat.


regolith-compositor-compton-glx (1.0.9-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add xrender-sync-fence to handle issue https://github.com/regolith-linux/regolith-desktop/issues/116.


regolith-compositor-compton-glx (1.0.8-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Ship config file.


regolith-compositor-compton-glx (1.0.7-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add gbp conf file, cleanup.



########################################
# Release Notes for regolith-compositor-none
########################################
regolith-compositor-none (1.0.3-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add gbp conf file, cleanup.



########################################
# Release Notes for regolith-compositor-picom-glx
########################################
regolith-compositor-picom-glx (1.1.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Fix typo found in https://github.com/regolith-linux/regolith-compositor-picom-glx/issues/1.
  * Init script will kill pre-existing app instance before starting new. Part of fix for https://github.com/regolith-linux/regolith-desktop/issues/475.


regolith-compositor-picom-glx (1.0.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Fix typo found in 
  https://github.com/regolith-linux/regolith-compositor-picom-glx/issues/1.


regolith-compositor-picom-glx (1.0.0-1) bionic; urgency=medium

  * Initial release


########################################
# Release Notes for regolith-compositor-xcompmgr
########################################
regolith-compositor-xcompmgr (1.2.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Init script will kill pre-existing app instance before starting new. Part of fix for https://github.com/regolith-linux/regolith-desktop/issues/475.


regolith-compositor-xcompmgr (1.1.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add ability to override xcompmgr defaults. Fixes https://github.com/regolith-linux/regolith-desktop/issues/382.


regolith-compositor-xcompmgr (1.0.3-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add gbp conf file, cleanup.



########################################
# Release Notes for regolith-default-settings
########################################
regolith-default-settings (1.0-1bionic1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add bionic specific gsettings overrides.


regolith-default-settings (1.0-1) focal; urgency=medium

  * Initial release, files moved from package regolith-gnome-flashback.


########################################
# Release Notes for regolith-desktop
########################################
regolith-desktop (2.78-1bionic) bionic; urgency=medium

  [ Ken Gilmer ]
  * Move from compton to picom as default compositor.

</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/">https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/</a></em></p>]]>
            </description>
            <link>https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067509</guid>
            <pubDate>Thu, 12 Nov 2020 07:51:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Become a Shopify Developer ‚Äì Resources to Become a Shopify Dev]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067407">thread link</a>) | @iliashad
<br/>
November 11, 2020 | https://iliashaddad.com/blog/how-to-become-shopify-developer | <a href="https://web.archive.org/web/*/https://iliashaddad.com/blog/how-to-become-shopify-developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><div><article><div><p><span>
      <a href="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/af240/how-to-become-shopify-developer-0.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="how to become shopify developer 0" title="how to become shopify developer 0" src="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/0a251/how-to-become-shopify-developer-0.jpg" srcset="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/bce2d/how-to-become-shopify-developer-0.jpg 250w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/953fe/how-to-become-shopify-developer-0.jpg 500w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/0a251/how-to-become-shopify-developer-0.jpg 1000w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/e3932/how-to-become-shopify-developer-0.jpg 1500w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/451a4/how-to-become-shopify-developer-0.jpg 2000w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/af240/how-to-become-shopify-developer-0.jpg 2600w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
  </a>
    </span></p><p>Shopify has been growing so fast in the last couple of years. ‚ÄúWe made history in 2018: no other SaaS company has crossed the $1 billion-dollar revenue mark at a faster growth rate than Shopify has,‚Äù said <a href="https://investors.shopify.com/Investor-News-Details/2019/Shopify-Announces-Fourth-Quarter-and-Full-Year-2018-Financial-Results/default.aspx">Tobi L√ºtke</a></p><p>I‚Äôm a self-taught developer who worked as a freelancer and indie maker in 2019 and I learned Shopify app and theme development and I want to share with you resources that help me to become a Shopify developer</p><h3><strong>Prerequisite to learn Shopify Theme Development&nbsp;:</strong></h3><p>Shopify theme is like WordPress themes but Shopify use their markup language (Liquid ) instead of PHP</p><p>You need to</p><ul><li>have basic knowledge with HTML5, CSS3, and JavaScript</li><li>have basic knowledge with jQuey (Many Shopify libraries use jQuery )‚Ää‚Äî‚ÄäOptional</li><li>have basic knowledge with Command Line</li><li>Create a <a href="https://accounts.shopify.com/signup">Shopify Partner account</a> to upload and test your Shopify theme (Free with unlimited Shopify store for development)</li></ul><h3>Prerequisite to learn Shopify App Development&nbsp;:</h3><p>Shopify app is a web app and you can use any programming language like Ruby, Python, PHP or Node JS to build one and in this guide, I‚Äôll focus on Node JS in this guide</p><p>You need to&nbsp;:</p><ul><li>have basic knowledge with HTML5, CSS3</li><li>a good understanding of JavaScript and React (Shopify Polaris built With React but you can use any framework or just vanilla JS)</li><li>good understanding of how to build a full-stack web application (Authentication, consume external API, Send Requests from the front end and deal with it in the back end )</li><li>have basic knowledge with GraphQL (Shopify API built with GraphQL)</li><li>Create a <a href="https://accounts.shopify.com/signup">Shopify Partner account</a> to create, test and publish your Shopify app (Free)</li></ul><h3>Ressources to learn Shopify Theme Development</h3><ul><li><a href="https://www.shopify.com/partners/blog/">Shopify Partner Blog</a>: Articles and guides about design inspiration, Shopify development tips</li><li><a href="https://www.shopify.com/partners/academy">Shopify Partner Academy</a>: Free courses from Shopify team to learn how to work with Shopify tools</li><li><a href="https://www.skillshare.com/classes/Shopify-Essentials-for-Web-Developers-From-Store-Setup-to-Custom-Themes/1070001866/projects">Shopify for web dev</a>elopers: (Free course) Set up your first Shopify store and create your first custom Shopify theme by a Shopify Expert</li><li><a href="https://www.skillshare.com/classes/Advanced-Shopify-Theme-Development/708093439?utm_campaign=video-embed-708093439&amp;utm_source=Video&amp;utm_medium=video-embed">Advanced Shopify</a> Theme: (Free course) Create advanced Shopify theme (Make Shopify theme a single web app using AJAX ) by a Shopify expert</li><li><a href="https://www.shopify.co.uk/partners/shopify-cheat-sheet">Liquid Cheatsheet</a>: Cheatsheet to get all Shopify liquid variables, filters, and helpers</li><li><a href="https://shopify.github.io/liquid-code-examples/">Liquid Code Examples:</a> Collection of code snippets to speed up your development process and understand how to write liquid code</li><li><a href="https://www.youtube.com/playlist?list=PLXQCP3o-w1Pvras8iuflJKO3tfkBT8c0c">Shopify YB Playlist:</a> Youtube course to learn Shopify theme development</li><li><a href="https://shopify.github.io/themekit/">Shopify Theme Kit</a>: a command-line tool to upload your Shopify theme to a Shopify store automatically when changes are made locally</li><li><a href="https://help.shopify.com/en/themes/development">Shopify Theme Docs</a>: Shopify docs to create your Shopify theme</li></ul><h3>Ressources to learn Shopify App Development</h3><ul><li><a href="https://www.shopify.com/partners/blog/">Shopify Partner Blog</a>: Articles and guides about design inspiration, Shopify development tips</li><li><a href="https://www.shopify.com/partners/academy">Shopify Partner Academy</a>: Free courses from Shopify team to learn how to work with Shopify tools</li><li><a href="https://developers.shopify.com/tutorials/build-a-shopify-app-with-node-and-react/set-up-your-app">Shopify React Node App</a>: Tutorial by Shopify team to create your first React and Node JS Shopify app using Polaris (Shopify React design system) and KOA Js to handle server-side rendering</li><li><a href="https://github.com/Shopify/shopify-app-cli">Shopify App CLI:</a> Create your Shopify app like (Create React App), serve your shopify app in Ngrok server (Free) and update your Ngrok server link automatically in your Shopify App dashboard</li></ul><h3>Conclusion</h3><p>Thanks for reading, I wish you the best on your new journey.</p></div></article></div></main></div></div>]]>
            </description>
            <link>https://iliashaddad.com/blog/how-to-become-shopify-developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067407</guid>
            <pubDate>Thu, 12 Nov 2020 07:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I learned Django so well ‚Äì Blog post]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067291">thread link</a>) | @codewithstein
<br/>
November 11, 2020 | https://codewithstein.com/how-i-learned-django-so-well/ | <a href="https://web.archive.org/web/*/https://codewithstein.com/how-i-learned-django-so-well/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			    	
<div>
    <article itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting">
	

        

        <p>
            <time datetime="20-11-11">Code With Stein / Nov 11, 20 / 0 comments</time>

            /

            
                <a href="https://codewithstein.com/misc/">#Misc</a>
            
        </p>

        <hr>

        <p itemprop="description">
            People of ask me here on YouTube and by e-mail how I have learned Django so well. I thought I could create a video where I explain it to all of you at once.... and here it is.
        </p>

         

        <div itemprop="articleBody">
            <p>I was introduced to Django when it was released back in around 2005/2006. I watched a video conference called Snakes and Rubies where they talked about Django and Ruby on Rails. I was really impressed with the talk about Django. Adrian made a great talk about the framework.</p>

<p>After the video, I played around with both of the frameworks, but Django quickly became my favorite. I already knew basic Python, so I understood much of the Django code.</p>

<p>I learned the basics and built a couple of small projects. After a few years, I built the biggest project I had done so far. This was a website called "finn en frilanser" which is Norwegian for "find a freelancer". So it was basically a Norwegian version of elance, guru and similar. I learned a lot during this process and it was a really cool project to build.</p>

<p>A few years after this, I built a new really big project using Django. This was a project called "FinnFido". This is kind of an amber alert web application for lost and found pets. I also built an API for the same application which I used for an iPhone and Android app.</p>

<p>So, most of why knowledge has comes from building different projects. Each time I start something new, I try to think of new features I can implement so I can learn even more. For the API I built, I had to learn a lot about JSON and security.</p>

<p>What I think has made me learn most of the Django I know, is actually making videos about the subject. Because when I make videos, I need to explain many different things in my own words. This make it stick better in my head. </p>

<p>When I go through someone elses tutorials, I like to play around with code. I use different variable names and values, change the function names etc. Doing this makes it easier to understand why things are done the way they are.</p>

<p>People learn differently, and the best way for me to learn is "learn by doing" and making it stick better by explaining things in my own words. So this sums up what I have done to learn Django. </p>

<p>This also applies to everything else I know. I learn by doing and becomes even better when I try to teach other about it.</p>

<p>And that's it.</p>

<h2>Video</h2>

<p><iframe width="100%" height="400" src="https://www.youtube.com/embed/PA1AC1vDOfk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
        </div>

        <hr>

        <h3>Comments</h3>

        
            <p>No comments yet...</p>
        

        <h3>Add comment</h3>

        

        
    </article>
</div>

			    </div></div>]]>
            </description>
            <link>https://codewithstein.com/how-i-learned-django-so-well/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067291</guid>
            <pubDate>Thu, 12 Nov 2020 07:12:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abu Dhabi launches applied research centre (Middle East AI News)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066909">thread link</a>) | @asiaainews
<br/>
November 11, 2020 | https://www.getrevue.co/profile/middleeastainews/issues/abu-dhabi-launches-applied-research-centre-160m-ai-traffic-systems-centre-in-dubai-291113 | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/middleeastainews/issues/abu-dhabi-launches-applied-research-centre-160m-ai-traffic-systems-centre-in-dubai-291113">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.getrevue.co/profile/middleeastainews/issues/abu-dhabi-launches-applied-research-centre-160m-ai-traffic-systems-centre-in-dubai-291113</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066909</guid>
            <pubDate>Thu, 12 Nov 2020 05:54:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Decentralized Internet Pt 1: Blockchain Domains]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25066874">thread link</a>) | @guttertec
<br/>
November 11, 2020 | https://www.axelquack.capital/blockchain-domains/ | <a href="https://web.archive.org/web/*/https://www.axelquack.capital/blockchain-domains/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<div id="post-content">
					<!--kg-card-begin: markdown--><p>It is a common misunderstanding to exclusively associate blockchain technology with cryptocurrencies like Bitcoin. The technology itself offers already a wide range of services like decentralized messaging services, marketplaces and ‚Äì importantly ‚Äì decentralized domain names, which cannot be censored or taken down completely. Imagine payments could be universally shared and owners have full control over their domain asset.</p>
<p>You might ask yourself "What is so special about this?" A simple answer is:  <strong>the internet of today is broken.</strong> We can use the internet, but we do not own anything we do. Here are a few reason why:</p>
<ol>
<li><a href="https://en.wikipedia.org/wiki/Domain_name_registrar">Registrars</a> are mandatory custodians of centralized domains like .com or .net.</li>
<li><a href="https://en.wikipedia.org/wiki/Domain_name_registry">Registries</a> can revoke domains or be taken down</li>
<li>Hosting services can take content offline entirely, not just off their service platform</li>
</ol>
<p>For the first time in history with the creation of blockchain networks like <a href="https://coinmarketcap.com/currencies/ethereum/">Ethereum</a>, <a href="https://filecoin.io/">Filecoin</a> and others there are new possibilities in regards of ownership and control. On the contrary, blockchain domains are not only decentralized but also secured using cryptographic encryption. They represent a new class of assets that truly belong to the owner, and not to a third party or central authority.</p>
<p>This has several advantages, both for the asset owners and their users ‚Äì these include:</p>
<ul>
<li><strong>(Real) Ownership:</strong> The owner has a private key to their domain, so the domain will be entirely under their control. Current solutions are not governed by and do not require approval from e.g. <a href="https://www.icann.org/">ICANN</a>.</li>
<li><strong>Censorship-resistant:</strong> A blockchain domain also makes a website censorship-resistant for the owner, as private keys should be stored in a (ideally non-custodial) wallet to which only the owner has the keys. No third-party can interfere with or disable the site without the private keys.</li>
<li><strong>Replace cryptocurrency addresses with human-readable names:</strong> A blockchain domain replaces the need for copying and pasting rather cryptic wallet addresses and at the same time simplifies sending and receiving payments dramatically. The domains become <strong>payment gateways</strong> by attaching a cryptocurrency wallet address to a domain name; giving users the chance to send or pay money.</li>
<li><strong>Transfer speed:</strong> Blockchain domains do not require an escrow agent to securely exchange the domain or funds. This transfer can happen in less than 1 minute, from or to anywhere in the world.</li>
</ul>
<!--kg-card-end: markdown--><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/pLDDbCZXvTE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><!--kg-card-begin: markdown--><h2 id="ethereumnameservices">Ethereum Name Services</h2>
<p><a href="https://en.wikipedia.org/wiki/Nick_Johnson_(software_engineer)">Nick Johnson</a> and <a href="https://medium.com/@avsa">Alex Van de Sande</a> of the Ethereum Foundation initially conceptualized the <a href="https://ens.domains/">ENS</a> (Ethereum Name Service).</p>
<p>It offers a names system on Blockchain that integrates with the traditional DNS, unlike some of its competitors, <a href="https://ens.domains/">ENS</a> does not want to replace DNS. Additionally the system provides a secure and decentralized way to address different resources using human-readable names. Instead of sending someones ETH to <em>0xa4edd4f3b6a3f15ecce4b73fd9a196cffc7d28ad</em>, a user can simply send to axelquack.eth.<br>
Lastly, another excellent property that <a href="https://ens.domains/">ENS</a> possesses is its interoperability with the rest of the Ethereum ecosystem. <a href="https://ens.domains/">ENS</a> can interact with all Ethereum-based smart contracts. One contract records all the domains and subdomains, as well the owner's details and the link to the Resolver, which is another smart contract that handles the translations from names to addresses or other types of resources and vice-versa.</p>
<p>It should be noted that <a href="https://ens.domains/">ENS</a> has an annual fee for an .eth domain. This fee is about 5 EUR/year for available domains of "normal length", payable in corresponding ETH value. Even though this might not sound expensive, but one should not forget that the provider can change the fee at any time. Since the user cannot simply move the domain to another provider, this is already a point that might be a disadvantage.</p>
<p>If you are using a browser like Brave or even Chrome, the <a href="https://metamask.io/">MetaMask</a> browser extension will give you support. For example, if you are using Chrome with MetaMask, enter "<a href="http://almonit.eth/">http://almonit.eth</a>" into the URL bar and a website search engine will be loaded.</p>
<!--kg-card-end: markdown--><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/g45ofhOyACg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><!--kg-card-begin: markdown--><h2 id="unstoppabledomainscryptozil">Unstoppable Domains (.crypto/.zil)</h2>
<p><a href="https://unstoppabledomains.com/r/2df713a3dc584f7">Unstoppable Domains</a> was born in 2018 of <a href="https://www.linkedin.com/in/bradley-kam-444aa228/">Brad Kam's</a> desire to "build something at the intersection of tech and policy". Kam studied politics before he met co-founder <a href="https://www.linkedin.com/in/matthew-gould-7877361/">Matthew Gould</a> while working at his first startup, <a href="https://www.talkable.com/">Talkable</a>, a SaaS marketing platform. The startup is backed by <a href="https://draper.vc/">Draper Associates</a> &amp; <a href="https://www.boost.vc/">Boost VC</a> and also received grants from the Ethereum Foundation and the Zilliqa Foundation.</p>
<p>Users can connect with crypto domains such as .zil (live on the <a href="https://www.zilliqa.com/">Zilliqa</a> blockchain) or .crypto (live on Ethereum), to get paid as an example. All someone needs to know is their blockchain domain.<br>
The difference is that .zil domains are stored on and process transactions through the <a href="https://www.zilliqa.com/">Zilliqa</a> blockchain which has low fees. In contrast, .crypto domains are stored on and process transactions through the Ethereum blockchain. Both are capable of pointing to multiple cryptocurrency wallet addresses (for <a href="https://community.unstoppabledomains.com/t/what-cryptocurrencies-are-currently-supported/246">payments</a>) and censorship-resistant website content.</p>
<p>The exciting thing about Unstoppable Domains: A user really buys the domain. Once the domain has been paid for and ended up in a wallet (there is for instance a simple way to store your domains within Coinbase Wallet, Atomic Wallet and so on ‚Äì&nbsp;but also the possibility to store in hardware wallets), nobody can take it away from the owner. Furthermore, <strong>there are no further costs</strong>. That puts the somewhat higher initial costs into perspective quickly. 40 USD are payable for a .crypto domain, 20 USD are payable for .zil domains. Another option is payment by PayPal or Credit Card.</p>
<p>There are multiple ways to access .crypto domains browsers with native support for decentralized websites include Brave (desktop version), Opera (mobile), Status (mobile), MetaMask Mobile (mobile), and Unstoppable Browser (desktop). Besides that it is always possible to install an official Chrome or Mozilla <a href="https://unstoppabledomains.com/extension">extension</a> to access websites built on p2p networks like <a href="https://ipfs.io/">IPFS</a>. The company itself offers a template marketplace and upload functionalities which are interconnected with <a href="https://pinata.cloud/">Pinata</a>.</p>
<p>In May 2020 Unstoppable Domains mentioned they have 200K+ domains registered, 4K+ IPFS websites launched, 12K+ unique Ethereum addresses that own domains just to share some of their key facts. Possible future functionalities mentioned  were support of Decentralized Databases like <a href="https://orbitdb.org/">OrbitDB</a> or <a href="https://gun.eco/">GUN</a> alongside paid hosting.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="finalthoughts">Final thoughts</h2>
<p>Decentralized systems, which do not require a central mediator to function, were already around at the time the Web was invented. Most notably, the Internet was increasingly gaining traction as a large-scale decentralized network. The rise of Blockchain Domains enables not only censorship-resistance, or a shift towards self-ownership, but also simplifies payments with crypto that could drive further adoption of digital assets.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><hr>
<p><i>Website and the information contained herein is not intended to be a source of advice or credit analysis with respect to the material presented, and the information and/or documents contained in this website do not constitute investment advice.</i></p><!--kg-card-end: html-->
				</div><!-- .post-content -->
				<!-- .post-footer -->
			</div><!-- .inner -->
		</article></div>]]>
            </description>
            <link>https://www.axelquack.capital/blockchain-domains/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066874</guid>
            <pubDate>Thu, 12 Nov 2020 05:48:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Key to Consistency]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066783">thread link</a>) | @lassmaglio
<br/>
November 11, 2020 | https://www.sandromaglione.com/2020/11/10/key-to-consistency/ | <a href="https://web.archive.org/web/*/https://www.sandromaglione.com/2020/11/10/key-to-consistency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Doing things is not easy. The simple act of starting some task can become daunting at times. It is often true that the hardest step is starting the work. Everything else from there will most of the time just flow smoothly.</p><p>We can summarize the secret of getting things done in one rule: <strong>how to make sure I will be able to start</strong>.</p><p>There could be many reasons that stop you from starting something. Some reasons more valid than others.</p><p>Generally, though, the main source of resistance is the mind. People conjure intricated excuses for why they should not do something. One of the most frequent is the maxim: ‚ÄúI do not have time right now, maybe later‚Äù.</p><p>We also know that, in order to achieve a goal, oftentimes consistency is more important than intensity.</p><p>It could be learning a new language, exercising, eating healthy. Consistency means doing a little bit of work every day to ensure success in the long run.</p><p>There are mainly three problems with this model:</p><ol><li>Consistency means starting a task every day</li><li>The results of your work may not be visible for a relatively long period of time</li><li>Doing something every day means forgoing some other activities to find the time to work consistently</li></ol><h3>The solution is simple</h3><p>The key to solving the riddle is called <strong>scheduling</strong>.</p><p>Scheduling means assigning a specific date and time to a task. It is as simple as opening an app (or using pen and paper) and picking a time frame in which you commit to doing the work.</p><p>Scheduling solves all the three problems we identified:</p><ol><li>When you schedule a task, you assign it a time slot every day. You won‚Äôt need to think about it anymore. The trigger will be the clock: when the time comes, you know what to do. There could be no reasonable excuses.</li><li>Scheduling allows you to look into the future and plan how long the whole process will take. Every day you show up will be another success. You will visually see yourself getting closer to the day in which all your discipline will bear its fruits.</li><li>Scheduling is not limited to a single task. You can easily schedule all your day to make sure you will be able to complete all the activities that you want. This process is liberating. It frees you from the burden of thinking what and when to do something in any given moment.</li></ol><h3>How to schedule</h3><p>There is no specific secret about scheduling. It is all about observing your day, from when you wake up to when you go to bed, and writing down what you will do in this time window.</p><p>It will take you 5 to 10 minutes to organize your activities and assign to each of them a start and finish time. Then you can simply stop bothering and go about your day.</p><p>Basically it all comes down to:</p><ol><li>List all the activities you need to perform, with an estimate of how long each activity will take to be completed</li><li>Sort your activities by priority</li><li>Choose when you are going to wake up and go to sleep</li><li>Build your day like a puzzle, assigning a time frame to each activity in order of priority</li></ol><p>These four steps are the basic blueprint. Many strategies and tricks exist to improve the efficiency and effectiveness of your scheduling.</p><p>Nonetheless, the core of the process is all about <strong>prioritizing and executing</strong>.</p><h3>Some secrets to help</h3><p>Some guidelines exist to help you with scheduling. Simple rules you can follow to increase even more you productivity.</p><h5><strong>Reduce context switching</strong></h5><p>Context switching is the time that it takes to switch from one activity to another. This time may vary based on the specific activity you perform.</p><p>For example, switching from studying to working out takes time: you need to reorder your books, prepare your clothes, go to the gym, etc.</p><p>In order to increase productivity, you should try to group similar task together, one after the other. This will help to reduce idle time and completing more tasks during the day (or maybe completing them faster and having more leisure time).</p><h5><strong>Schedule in the evening or in the morning</strong></h5><p>The process of scheduling may not be exciting at times. Scheduling must become a habit during your day. It is important to pick a moment during the day devoted to your scheduling plan. The same time every day.</p><p>Generally, first thing in the morning or last thing in the evening is ideal. That is because you will always have time in these moments of the day (by simply waking up a little earlier or going to bed a little later).</p><p>Furthermore, scheduling in the evening or morning allows you to take a look at your day before starting it, so you will know exactly what you are going to achieve for the day.</p><h5><strong>Never schedule on task after the other with no time in between</strong></h5><p>This rule refers back to the problem of context switching. No task can usually be started with no idle time from the previous one. And it shouldn‚Äôt be.</p><p>We need to give some time to our mind to reload. Therefore, always consider some time in between each task to relax.</p><h5><strong>Review the results at the end of the day</strong></h5><p>No matter if you write your schedule in the morning or evening, reviewing your results is paramount to your success. Take some time in the evening to look at your activities during the day.</p><p>This process will help you to estimate better your times and also have a critical look at what you do during your day.</p><h5><strong>Learn to estimate the time it takes for each activity</strong></h5><p>Scheduling is an estimation. We cannot know how much time each activity will actually take. Nonetheless, we assign it a time frame, from start to finish.</p><p>With time, our ability to estimate the amount of time to assign to each task will improve. Eventually, you should be able to schedule your day with a high degree of accuracy.</p><h5><strong>Schedule leisure time</strong></h5><p>Scheduling does not mean 24 hours of work. Scheduling is all about avoiding procrastination and improving efficiency. If you schedule your day properly, you will accomplish more in less time.</p><p>And guess what? All the time you gain in your day can be used to getting more things done or just chill and relax. <strong>You can literally increase your free time</strong>. All it takes is a little bit of planning and a little bit of consistency.</p><hr><h3>What are you waiting for?</h3><p>Scheduling is really a superpower. You will start seeing results in no time. You will feel less stressed during your day. You won‚Äôt need to think about what do to next. This habit will also give more meaning to your time. I cannot recommend it enough. Just try it and see how it goes.</p></div></div></div>]]>
            </description>
            <link>https://www.sandromaglione.com/2020/11/10/key-to-consistency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066783</guid>
            <pubDate>Thu, 12 Nov 2020 05:30:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Member (Open Source, P2P, Decentralized Twitter Clone) Releases Windows App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066663">thread link</a>) | @FreeTrade
<br/>
November 11, 2020 | https://member.cash/p/0cd5f21a46 | <a href="https://web.archive.org/web/*/https://member.cash/p/0cd5f21a46">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="previewcontent">
        <p>Member Desktop (Ember) is Twitter meets Bittorrent.

magnet:?xt=urn:btih:E1E4C04EFEA99A16A992FEF7F8E8F3C5964E865E

It runs on Windows with a single click. Includes pre-synced Bitcoin node, server, db, client. <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/t/member">member</a></p><p><a href="https://member.cash/p/a058ec8564">Interesting.

Is it a bundled Virtual Machine?</a> <a href="https://member.cash/m/shadowofharbringer">@shadowofharbringer</a></p><p><a href="https://member.cash/p/c813d814a2">It is not a virtual machine - it requires Windows to run. Might look at Linux/Macos releases in the future. </a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/p/3e4fe5c003">&gt;  it requires Windows to run

Well, that's unfortunate but I am no longer interested. I will wait for Linux release.</a> <a href="https://member.cash/m/shadowofharbringer">@shadowofharbringer</a></p><p><a href="https://member.cash/p/dc3a9e51f3">Whens the mobile app coming? ;) </a> <a href="https://member.cash/m/%F0%9D%90%85%F0%9D%90%84%F0%9D%90%84%F0%9D%90%8B%F0%9D%90%92">@ùêÖùêÑùêÑùêãùêí</a></p><p><a href="https://member.cash/p/89d6d52caf">I'm not sure. Seems like a lot of work just to get banned doesn't it ? ;) PWA FTW</a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/p/f3bedd316a">Just in case you missed this on Reddit - here's how to run on Linux. (member.cash uses ubuntu)

Yes, I just updated the repo with the latest 5.0.7 release - here it is - https://github</a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/p/e961c4ab94">|.com/memberapp/server

Let me know if you have any problems.
</a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><img src="https://member.cash/img/profilepics/19RyV6XQEww5td2LPWDpK8o5V8at7Vpwgv.640x640.jpg">
    </p></div></div>]]>
            </description>
            <link>https://member.cash/p/0cd5f21a46</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066663</guid>
            <pubDate>Thu, 12 Nov 2020 05:07:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Music-Related Copyright Claims and Twitch]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066598">thread link</a>) | @captn3m0
<br/>
November 11, 2020 | https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/ | <a href="https://web.archive.org/web/*/https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-i18n="ba2fc6a46b864e1cc0b2afadb1eff0cf-content">
    <p>Creators, we hear you. Your frustration and confusion with recent music-related copyright issues is completely justified. Things can‚Äìand should‚Äìbe better for creators than they have been recently, and this post outlines our next steps to get there. Moving forward, we‚Äôll be more transparent with what‚Äôs happening and what tools and resources we‚Äôre building to help.</p>

<p>Copyright law and the DMCA are not small or simple topics, so this won‚Äôt be a brief post. We‚Äôll do our best to keep the legalese to a minimum, though there‚Äôs bound to be technical terms here and there.&nbsp;</p>

<h4 id="dmca-and-twitch"><strong>DMCA and Twitch</strong></h4>

<p>First off, a quick review of what DMCA actually is. The Digital Millennium Copyright Act (‚ÄúDMCA‚Äù) is a set of US laws that allows you to create and share content on digital service providers like Twitch. We comply with the DMCA and similar laws worldwide. Part of complying means that when a copyright holder thinks a streamer has used their content without permission, we have a process in place for them to be able to request the content be taken down.</p>

<p>When we receive a DMCA notification, we process the notification in accordance with our <a href="https://www.twitch.tv/p/legal/dmca-guidelines/">DMCA Guidelines</a>. This includes removing the content, sharing the details with the channel owner, and tracking the allegation.&nbsp;</p>

<p>DMCA takedown notifications can affect your ability to stream because we, as part of our efforts to comply with the DMCA and similar global laws, issue and track copyright strikes and ban the accounts of those who repeatedly infringe the copyrights of others.&nbsp;</p>

<p>This policy is important because we respect the rights of all creators, including those who create or record music, as well as the rights of those who own and control copyrights. As a company that is built around a community of people who create content, we take allegations of copyright infringement seriously.&nbsp;</p>

<h4 id="recent-dmca-notifications"><strong>Recent DMCA notifications</strong></h4>

<p>How did we get to this moment? Until May of this year, streamers received <strong>fewer than 50 music-related DMCA notifications each year</strong> on Twitch. Beginning in May, however, representatives for the major record labels started sending <strong>thousands of DMCA notifications each week</strong> that targeted creators‚Äô archives, mostly for snippets of tracks in years-old Clips. We continue to receive large batches of notifications, and we don‚Äôt expect that to slow down.&nbsp;</p>

<p>This means two things: 1) if you play recorded music on your stream, you need to stop doing that and 2) if you haven‚Äôt already, you should review your historical VODs and Clips that may have music in them and delete any archives that might.&nbsp;</p>

<p>We were as surprised by this sudden avalanche of notifications as many of you were. We also realized that we needed to provide streamers with more educational programs and content management tools to help you deal with this unprecedented number of notifications coming in all at once. So, while we continued to remove content targeted by these notifications as required by the DMCA, we understood VODs and Clips from years ago may not necessarily reflect your current approach to music. Therefore, we also paused the processing of strikes associated with these batched notifications in order to give you the tools, information, and time that you would need to deal with them.</p>

<p>We have analyzed the notifications we received during that period from the end of May through the middle of October. What we found is that more than 99% of the notifications were for tracks that streamers were playing in the background of their stream.&nbsp;</p>

<p>The point of the DMCA is to strike a balance between the interests of rights holders (the major record labels in this case) and creators. Because of this, we were compelled to delete the VODs and Clips that were identified in the notifications. This showed our commitment to upholding our obligations under the DMCA, while affording us the opportunity to sort out the best way to handle issuing strikes in these circumstances. Under these extraordinary circumstances, we recognized creators should have a reasonable chance to understand that content created in the past was being targeted as allegedly infringing and be given an opportunity to change their approach to music use before they got hit with strikes.</p>

<p>This led to the current situation, which is understandably frustrating and worrying for many of you. Given the circumstances, the warning email many of you received didn‚Äôt include all the information that you‚Äôd typically get in a DMCA notification (normally, when we receive a DMCA notification against your channel, we send you an email that includes information about the allegedly infringed work, who the claimant is, how the claimant can be contacted, and possible penalties under our repeat infringer policy, so that you can make an informed decision about whether to submit a counter notification or seek a retraction). We hear your feedback about how frustratingly little information we provided, and we should have made that warning email a lot more informative and helpful.</p>

<p>Over the last several months, we have done our best to manage this situation on behalf of both rights holders and creators. One of the mistakes we made was not building adequate tools to allow creators to manage their own VOD and Clip libraries. You‚Äôre rightly upset that the only option we provided was a mass deletion tool for Clips, and that we only gave you three-days notice to use this tool. We could have developed more sophisticated, user-friendly tools awhile ago. That we didn‚Äôt is on us. And we could have provided creators with a longer time period to address their VOD and Clip libraries ‚Äì that was a miss as well. We‚Äôre truly sorry for these mistakes, and we‚Äôll do better.</p>

<h4 id="how-to-avoid-dmca-notifications"><strong>How to avoid DMCA notifications&nbsp;</strong></h4>

<p>One important question we‚Äôve heard from you is: how can I stream safely and confidently on Twitch without having to worry about getting DMCA notifications from music use?</p>

<p>Most importantly, <strong>don‚Äôt play recorded music in your stream</strong> unless you own all rights in the music, or you have the permission of the necessary rights holder(s). Doing this is the best protection for your streams going forward. If you‚Äôre unsure whether you own all the rights, it‚Äôs pretty likely you don‚Äôt. If you want to include recorded music in your stream, use a fully licensed alternative like Soundtrack by Twitch, or other rights cleared music libraries such as Soundstripe, Monstercat Gold, Chillhop, Epidemic Sound, and NCS.</p>

<p>While we haven‚Äôt received more than a handful of DMCA notifications targeting in-game music, if you‚Äôre playing games with recorded music in them, we recommend you review their End User License Agreements (that wall of text at the beginning of a game) to see how the terms cover streaming with that music. One way to do this is to search for a game‚Äôs official EULA online and then do a ctrl+f (Command+f on Mac) search for words like ‚Äústream,‚Äù ‚Äúlicensed,‚Äù and ‚Äúmusic‚Äù to point you toward the correct sections. If you‚Äôre unsure about the rights, some games allow you to turn off music when streaming, or you can mute the game audio yourself. If neither of those apply, consider turning off VODs and Clips.&nbsp;</p>

<p>For your stream archives (VODs and Clips), right now your only options, if you think they contain unauthorized music, is to either go through them one by one, or, for Clips, use the ‚Äúdelete all‚Äù tool we‚Äôve provided. We understand both of these options have downsides, and we‚Äôre working to provide you more and better options as soon as possible. These things will take time to get right, and new challenges may appear in the future. Regardless, we‚Äôre committing here and now to investing in building better tools and keeping you posted on our progress.</p>

<h4 id="new-products-and-tools"><strong>New products and tools</strong></h4>

<p>Ever since the influx of DMCA notifications began, we have been working on building new (and improving existing) tools to help creators (such as the Clips mass deletion tool). This work is still happening. Many of these changes won‚Äôt be visible to the community, but we‚Äôre focused on three areas where we heard you need more support from us:</p>

<p>First, you don‚Äôt have enough control over the recorded content on your channel. We have made improvements to enable you to mass delete Clips, but in addition, we will (1) expand the use of technology to detect copyrighted audio, and (2) give you more granular ways to manage your archive instead of just a ‚Äúdelete all‚Äù option.</p>

<p>Second, we‚Äôll make it easier for you to control what audio from your live streams will show up in your recorded content. Soundtrack by Twitch has some of this technology built into it, and we‚Äôll work to make it available for everyone regardless of whether you want to use Soundtrack, for which we‚Äôve cleared all necessary rights, or music from others that provide rights-cleared music.</p>

<p>Third, we need to give you the ability to actually review your allegedly infringing content when you receive a DMCA notification, in addition to the details already provided in our takedown notifications - that is, information about what copyrighted work was allegedly infringed, who the claimant is, and how the claimant can be contacted. We also need to help you more easily file counter notifications if you believe you have the rights to use the content‚Äìfor example, because you‚Äôve secured a license, believe the use is a fair use,&nbsp; the claimant does not control the rights, or believe you have the right to use the music without permission.</p>

<p>Some of you have asked why we don‚Äôt have a license covering any and all uses of recorded music. We are actively speaking with the major record labels about potential approaches to additional licenses that would be appropriate for the Twitch service. That said, the current constructs for licenses that the record labels have with other services (which typically take a cut of revenue from creators for payment to record labels) make less sense for Twitch. The vast majority of our creators don‚Äôt have recorded music as a part of their streams, and the revenue implications to creators of ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</a></em></p>]]>
            </description>
            <link>https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066598</guid>
            <pubDate>Thu, 12 Nov 2020 04:57:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Data Viz Is About the Small Things]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066475">thread link</a>) | @tagawa
<br/>
November 11, 2020 | https://hamiltonulmer.com/notes/data-viz-small-things/ | <a href="https://web.archive.org/web/*/https://hamiltonulmer.com/notes/data-viz-small-things/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
<main>
<article>
    <header>
      
        <p>data visualization</p>
        
      
    
      <p>It's all too common to fixate on the choice of data visualization method at the expense of the just-as-important small choices ‚Äì labels, annotations, animation, and other bits you can add to tell the story better. That‚Äôs really where good data viz shines.</p>
    
    <dl>

      <dt>published</dt>
      <dd>Nov 11, 2020</dd>

      

      
        <dt>topics</dt>
        <dd>
          
            <a href="https://hamiltonulmer.com/topics/dataviz">dataviz</a>
          
            <a href="https://hamiltonulmer.com/topics/communication">communication</a>
          
            <a href="https://hamiltonulmer.com/topics/data%20science">data science</a>
          
        </dd>
      
    </dl>
    </header>
    <p>I recently consulted on an internal data visualization project at work, where someone asked this question: <em>‚ÄúWhat's type of data graphic best shows this particular insight?‚Äù</em> I've been asked variations of this a lot over the years, and thought it might be better to just write an answer for posterity's sake.</p>
<p>In my experience, picking a data visualization method to convey some kind of insight is really the start of your journey, not the end. This is not to say that the choice isn‚Äôt important. There‚Äôs plenty of reading material on the internet that addresses the tradeoffs between, say, <a href="https://towardsdatascience.com/not-a-funnel-use-sankey-to-represent-your-sales-process-9621b6578c42">a funnel chart and a Sankey diagram</a>. It's just that fixating on the graphic type focuses the solution on a specific output, not a desired outcome. You have to go so much further.</p>

<p>To that end, I try to get others to reframe the question to this: <em>‚Äúhow can this data visualization enable the reader to effortlessly see the story I see?‚Äù</em>. This question can change your tactics in profound ways. After all, getting someone to understand your viz requires you to practice basic reader empathy. Your readers don't always have the time, the context, nor the skills to uncover insights from the data on their own. Your job is to make it easy ‚Äì hell, I'd say <em>trivial</em> ‚Äì for them to reach that "aha!" moment, where their thinking changes and the possibilities open up.</p>

<p>When you shift your focus to <em>telling the story well</em>, you'll begin to understand why your work doesn't stop at picking a visualization method or graphic type, and what to do next. It's the <em>small things</em> that really make the story stick ‚Äì labels, annotations, design choices, animations, mouse interactions, tooltips, data sources, documentation, and other extraneous details not always covered in your favorite data viz book.</p>
<p>The small things make the reader's journey possible. They're the contextual pieces needed to see the story clearly. They're the details that delight them into trusting your expertise; that one annotation that guides their attention; that helpful tooltip that explains a complicated metric; all the pre-empted answers to their immediate questions. Sometimes, they even make room for the reader to explore on their own.</p>
<p>Your graphic choice may point the reader in the right direction. It may even get them part-way there. But the road that leads them to that "aha!" moment is almost always paved with small things.</p>
<figure>
<p><a href="https://hamiltonulmer.com/img/road-dataviz.jpg">
<img src="https://hamiltonulmer.com/img/road-dataviz.jpg">
</a>
</p>
<figcaption>
  Ridge hiking near Muir Beach, San Francisco in the distance. 

</figcaption></figure>
<p>"Small" may not be the right word ‚Äì not all of these things are visually small ‚Äì but I think it works in this context. Juxtaposed with the "big" choice of graphic type, these other parts are seen as smaller and more numerous. This is probably why they're considered afterthoughts, if they're even considered at all. But without them, readers are liable to:</p>
<ul>
<li><strong>get lost</strong> ‚Äì misinterpreting the visualization can push them to form the wrong conclusion or make the wrong decision.</li>
<li><strong>get stuck in the mud</strong> ‚Äì they might fixate on a meaningless part of the visualization, assuming there is something important that isn't really there, without arriving at the core insight.</li>
<li><strong>give up and head elsewhere</strong> ‚Äì if your data visualization is hard to understand, they may just give up, making a decision without any data.</li>
</ul>
<p>Building intuition about what small things to add is a byproduct of hands-on experience and relentless reader empathy. It requires putting a data visualization in front of someone and seeing them struggle to understand, and having the drive to understand and address their confusion and frustration. The more you do it, the easier it gets to anticipate the ways you can make your visual story clearer.</p>

<p>When a reader does truly understand the story, it's a rewarding experience. The insights will often lead to deeper, more interesting questions and explorations (I sometimes call this the <em>data viz happy path</em>). Isn't this the whole point of telling visual stories with data ‚Äì helping others reach a new understanding?</p>
<p>It's not controversial to say that this idea ‚Äì small details transforming a work from "meh" to "good" ‚Äì is true in just about every communication medium. Small things reduce the cognitive load and make the medium itself disappear, leaving only the story. A great screenplay, an enthralling book, a song that grooves so well it can either fade into the setting or command your attention. "Good" work is not contructed by accident yet feels natural. And so it is with good data visualization. When it's really good, the graphic choices disappear, and the insights remain.</p>
<h3 id="an-example"><a href="#an-example">¬∂</a> An Example</h3>
<p>Let's see the difference between these two framings ‚Äì <em>picking a graphic</em> vs. <em>telling the story well</em> ‚Äì  through a practical example. Say you are fixated on ‚Äúwhich graphic?‚Äù and pick a Sankey chart as a way of expressing some sort of user acquisition funnel for your company's newly-launched product, Sprockets Desktop. The software package you're using can easily express a series of state transitions as a static Sankey diagram, and you're surprised by how easy it is to get something together. You share the chart below with the product manager, who has never seen the acquisition funnel numbers before: <em>"Here's the acquisition funnel we talked about. Any thoughts?"</em></p>

<figure>

<figcaption>
  Stopping at "what graphic to use?"

</figcaption></figure>
<p>The response you get back from the very busy product manager is, well, terse:</p>

<blockquote>
<p><em>Looks good, thanks.<p>
‚Äì the PM</p></em></p>
</blockquote>
<p>You've reached a crucial moment. The product manager may never give you feedback on what's wrong, especially if they are not particularly data-savvy or don't have the time. But you can tell they're underwhelmed.</p>
<p>And this is where people sometimes screw it up. They assume it's because the visualization method isn't right. Before you change directions, let's say you prod this product manager for some real feedback. This encourages them to unleash a longer critique:</p>

<blockquote>
<p><em>What period of time is this chart for? These labels look like columns in a SQL resultset and I don't understand all of them. This Sankey chart gives me a good sense of the overall funnel dynamics but it's missing the numbers. Are these user states big or small in practice? I'd like to just SEE the numbers on the thing directly ‚Äì there‚Äôs so much room available. This is for Sprockets Desktop, right? Why isn‚Äôt the title more descriptive? How do you define these different states? Can I get the raw data somehow? It's neat to see this funnel, but I'm struggling to understand it. Sorry, just being honest!<p>
‚Äì the PM</p></em></p>
</blockquote>
<p>Changing what type of graphic you use won't answer these questions. The reader didn't even criticize the choice of Sankey chart.</p>
<p>Now, let's say you shift your thinking from  <em>picking a graphic</em> to <em>telling the story well</em>, and add the small things they complained about:</p>
<figure>
  <div>
    <a href="https://hamiltonulmer.com/img/sankey-annotation.svg"><!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<svg width="100%" viewBox="350 100 1020 475" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;">
    <use xlink:href="#_Image1" x="366" y="308.577" width="237.942px" height="187.8px" transform="matrix(0.999756,0,0,0.998939,0,0)"></use>
    <use xlink:href="#_Image2" x="613.709" y="309.25" width="237.894px" height="127.972px" transform="matrix(0.999553,0,0,0.999779,0,0)"></use>
    <use xlink:href="#_Image3" x="861.72" y="293.8" width="237.796px" height="75.992px" transform="matrix(0.999145,0,0,0.9999,0,0)"></use>
    <use xlink:href="#_Image4" x="862.125" y="371.316" width="237.698px" height="30.788px" transform="matrix(0.998733,0,0,0.993152,0,0)"></use>
    <use xlink:href="#_Image5" x="1108.53" y="294.43" width="237.971px" height="61.826px" transform="matrix(0.999877,0,0,0.997191,0,0)"></use>
    <use xlink:href="#_Image6" x="1109.85" y="356.285" width="238.618px" height="29.857px" transform="matrix(0.998401,0,0,0.995235,0,0)"></use>
    <use xlink:href="#_Image7" x="1109.85" y="387.947" width="238.618px" height="40.569px" transform="matrix(0.998401,0,0,0.989495,0,0)"></use>
    <use xlink:href="#_Image8" x="1110.55" y="330.721" width="239.382px" height="79.74px" transform="matrix(0.997426,0,0,0.996748,0,0)"></use>
    <use xlink:href="#_Image9" x="366.112" y="184" width="980.45px" height="125.94px" transform="matrix(0.999439,0,0,0.999521,0,0)"></use>
    <use xlink:href="#_Image10" x="862.37" y="400.37" width="485.236px" height="71.658px" transform="matrix(0.998428,0,0,0.995255,0,0)"></use>
    <use xlink:href="#_Image11" x="613.795" y="436.307" width="732.691px" height="109.832px" transform="matrix(0.999578,0,0,0.998473,0,0)"></use>
    <rect x="356.132" y="190.476" width="10" height="296"></rect>
    <text x="372.132px" y="204.676px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">W<tspan x="385.093px 392.879px " y="204.676px 204.676px ">eb</tspan> Sessions</text>
    <text x="372.132px" y="220.676px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">100% (163,500)</text>
    <rect x="603.632" y="317.825" width="10" height="177.6"></rect>
    <text x="619.632px" y="332.025px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Signups</text>
    <text x="619.632px" y="348.025px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">60% (98,100)</text>
    <rect x="851.132" y="310.11" width="10" height="118.4"></rect>
    <text x="867.132px" y="324.31px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">New Installs</text>
    <text x="867.132px" y="340.31px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">40% (65,400)</text>
    <rect x="1098.63" y="294.224" width="10" height="59.2"></rect>
    <text x="973.604px" y="308.424px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Complete ProÔ¨Åles</text>
    <text x="1012.58px" y="324.424px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">20% (32,700)</text>
    <rect x="1098.63" y="369.424" width="10" height="29.6"></rect>
    <text x="982.935px" y="383.624px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Skipped ProÔ¨Åles</text>
    <text x="1014.58px" y="399.624px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">10% (16,350)</text>
    <rect x="1346.13" y="319.288" width="10" height="50.32"></rect>
    <text x="1264.67px" y="333.488px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Activations</text>
    <text x="1265.08px" y="349.488px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">17% (27,795)</text>
    <rect x="1346.13" y="385.608" width="10" height="38.48" style="fill:rgb(177,177,177);"></rect>
    <text x="1242.2px" y="399.808px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Didn't Activate</text>
    <text x="1267.08px" y="415.808px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">13% (21,255)</text>
    <rect x="1346.13" y="184.888" width="10" height="118.4" style="fill:rgb(177,177,177);"></rect>
    <text x="1244.27px" y="199.088px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Didn't Sign Up</text>
    <text x="1256.08px" y="215.088px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">40% (65,400)</text>
    <rect x="1346.13" y="440.088" width="10" height="29.6" style="fill:rgb(177,177,177);"></rect>
    <text x="1178.73px" y="454.288px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Never Launched the App</text>
    <text x="1263.08px" y="470.288px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">10% (16,350)</text>
    <rect x="1346.13" y="485.688" width="10" height="59.2" style="fill:rgb(177,177,177);"></rect>
    <text x="1250.69px" y="499.888px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Didn't Install</text>
    <text x="1260.08px" y="515.888px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">20% (32,700)</text>
    <circle cx="362" cy="525px" r="2" fill="gray"></circle>
    <line x1="362" x2="450" y1="525px" stroke-dasharray="4,1" y2="525px" fill="gray" opacity=".5" stroke="gray" marker-end="url(#arrow)"></line>
    <text x="460px" y="524px" dy=".35em" font-size="12" font-style="italic" fill="gray" text-anchor="start">funnel direction</text>
    <g transform="matrix(1,0,0,1,278.507,75.402)">
        <text x="81.948px" y="47.486px" style="font-family: var(--font--comment), 'Arial', sans-serif;font-size:16px; fill: var(--color--comment)">SPROCKETS DESKTOP</text>
        <text x="81.948px" y="72.271px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:24px; fill:var(--color--text);">User Acquisition Journey</text>
        <text x="81.948px" y="93.729px" style="font-family: var(--font--comment), 'Arial', sans-serif; font-size:14px; fill:var(--color--comment)"><tspan style="font-style: italic">% of Web Sessions</tspan>, October 25th - October 31st, 2020</text>
            <text x="1075" y="50" text-anchor="end" font-size="12" style="font-family: var(--font--comment); fill: var(--color--link);">query</text>
            <text x="1075" y="75" text-anchor="end" font-size="12" style="font-family: var(--font--comment); fill: var(--color--link);">dataset</text>
    </g>
    <defs>
        <marker id="arrow" viewBox="0 0 10 10" refX="5" refY="5" markerWidth="5" markerHeight="5" orient="auto-start-reverse">
            <path d="M 0 0 L 10 5 L 0 10 z"></path>
        </marker>
        <image id="_Image1" width="238px" height="188px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAAC8CAYAAAB/qJLeAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAELklEQVR4nO3aTXLaWBiG0Y8fx7E7M6Y9yVZ6LZqxHs3YTW8lU8262k78Qw8sEgzGAUwDr31O1S2jaw8urnpAutKgabuvVXVVVfN+PC69PurxbDqZF/Bb46r6q6r+PPVCqqqatqt6HvVy2Pcr427LuV3n76rqfjadPPzPbxf2Nj71Al4w6Meqy2Muov8QWQ36R1V9r6rb/ufyeGnu57wPAg7pHMM9J+M60P+oabuHej3y1bnbqvq3qm76cetSggXhHs+oqq77sZem7RYR39TzqDcez6aT729bNudIuFmu+rG1pu0e63nQW0U/m07uDrdsDk2479+wqv7ox9b6U/udvt3r6Rv+/mArZyPhssmoqr70Y2sr1/K7XNM/m5tNJ48HeRfvlHA5tDdfy1dVNW13X+tB/6jD3fZbzD8kbvoJl3O12NHf6RR/H/1ZwqbQH+rEDya9cPyPcOHpLGFUR35W4A2+DU+9AmB3woVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAw/n8cXDqRQC7GQ4Gw/mpFwHsxqkyBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBpX1d9V9aWeIh4sjVMeD6tq1K9vdVz0v4MPa3DqBeyjabtBrYd9UZtD32b+oqo+VdXlyrg40tuCbX2LDPeYmrYb1nrMn/eYc5bAoQj3WJq2G9dTyNdVdbU0Xju+LsGzTrjnrmm7i3o97E2/s/H4fgn3vWra7lNtH/ni9ecK3ff4YITLL/2m32WtR7567f7adf346Av/eITLYTVtN6r9N/MW4S/v9LNOuJy3/oNgm1t8u9wO/N3fbnq+4FwIF3bR3x489YNKN/8BaBQxe31z5s0AAAAASUVORK5CYII="></image>
        <image id="_Image2" width="238px" height="128px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAACACAYAAAAMEFUIAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAC8UlEQVR4nO3YPW5aQQCF0YuD4yitm6wg+8he6FgPnZvsLg1tFPwDaXDkWGDg2QZf+xxpBBq9J81DfGKYUYA3ZTKbj5KMkpytXx+P1eh0y4PDTGbzsyTjJJ/Wrw/fPzU35PpNwTwc26J67j37+DXe80I4yGQ2P09ysWF82TL/cJxnc2Cs+TD4Z71F+5zdYe0z7OZekXDfgXVwLxHbxbHXzjDCPaH1f7Z9Ytq1vTw/9to5LeEOMJnNx3mZXzefP4O8my/OZDYfeoL4eG7bocrDcXakx4KNxpPZ/HuSr3nZI+1Dj8u3XXvI8T18GOMkP5J8O/VCgP3Z8kEh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UKZ1WopXGgzGp0JFxoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwqNT70AOIHbJHePXjfN3SVZJlkdMA69fsh9v4XLW7BM8ifJYsu4TnKT3aHtnLuaXt4d66Fek3B5jttsj+1+PBXkIsnivcR0TML9mK6zO7id42p6uTz6ykki3Db7RrXpV+56PX99Nb1cHX3lvCjhvr5VBmwfN4wbwXFPuP9bZfOhxm2Gxba4ml7eHPcR+AgODXfokfeQI/L7e5LDju+fc+LoPxsVxkl+rt9vjcgWDd6Wvyp5ER6r/UC5AAAAAElFTkSuQmCC"></image>
        <image id="_Image3" width="238px" height="76px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAABMCAYAAABqOovHAAAACXBIWXMAAA7EAAAOxAGVKw4bAAADGElEQVR4nO3cX26iUBiH4R/WsXXi/Om4g9nObIM71sMde5qVMGrbpGpHmQtxShFUVDh88D4JQU/a5Nj0zSkHrScAlflhfCdpkDvyY3V9zdJr4DUCjfPD2JN0L+khdy57nB0b6Xg8rrv5M3Q8AeBAupqdiuvU2KfGJ94gwkVj/DAeSfqSOSa55/uxkas5WkG4uJofxvcqDjH/vNOrYJMIF6XS68SJpO/pURYlQTaMcHvOD+PP2kX5mDvvjzt3s0MZwu249M/YfYRFcXI9aRDhGueH8VCHYWYfj93NDnUh3Jbzw3gg6asOV8v9eeJudnCFcB3LbAAVrZaP2kXr+oY/WoZwa+aH8ViH9yq/iQ0gXIFwL5Tuxp66dzkRUaIGhJuRXk8+qPwNBBMRJFqgM+Gmu6uXvKc1O9aZnwe67aa/qOmKdeojSlU+2lQlvsEtXwvQZkM/jH9pt1lSNbaiMQANGEr6KemH64kAOB+rJGAQ4QIGES5gEOECBhEuYBDhAgYRLmAQ4QIGES5gEOECBhEuYBDhAgYRLmBMkmwJF7DG8waEC1hEuIBBhAsYRLiAQYQLGES4gEGECxhEuIBBhAsYRLiAQYQLGES4gEGECxg0SJKt6zkAqGjgeSy6gDVUCxhEuIBBhAsYRLiAQYQLGES4gEGECxhEuIBBhAsYRLiAQYQLGES4gEFD1xMAemYraZOes0d+7NjXLAgXfbOVtJS0ypxXJWMrvcdyTmxHA4yCaXKrF0G4sORN5wVXOhYF07/NT/v2CBeubSS9SHrOHEXPl1Ew5b8+pAgXddmoPML/z6Ng+upshoYRLi6xkTSXNEvPC+XCJMh6ES6KJNrFmI1zf55LernlRguqI9z+etZ7iPk4n7iebDfC7a5XFa+WM0mLruyu9hXh2rVW8Wo5kzSPguna4dxQM8Jtr/wG0Ic42fzpN8J1400fb5Fkb5OwAYSTCPe21jrv3iV/xuIqhHuefZDH3tlDkGhMH8Jd64L3tGbHomC6aX7aQLm2hJvo+CctLo1vxXUiumgo6beksa7/jOBF38eNfqC6f8+VOQrUh4p7AAAAAElFTkSuQmCC"></image>
        <image id="_Image4" width="238px" height="31px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAAAfCAYAAADgIPGeAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAyUlEQVR4nO3asQ3CUBBEwQVBRjH0QCu0RB1URkYGkkmIQYDF90oziaM7X/LkxKvj6bJPss1vpvL5Jdwwen4JN7TPz7nn1Y77JskhyW6GFwH/cV2PvgD4nHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHCh0DrJavQRwGd8caHPJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwotElyfj6/9eufV6Pnl3DD6Pkl3NA+P+eedztuD61fFUrO8zSAAAAAAElFTkSuQmCC"></image>
        <image id="_Image5" width="238px" height="62px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAAA+CAYAAAAs0CcNAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAEj0lEQVR4nO3dXW7bRhQF4EOZVuwodmJTrpMGRYsCbVEURVF0A13MvHE986ZldEcBmqTyJKjt2q1/xD7w0uafZEoiORzyfMAFacqW5sEHHJEzQ09p8y2AfQALAJFs8/urXlv2e7ezMLgDEdXOB/A7gK+aeHOlTQTgVupmg22yfw3gCsD1LAxum2grkUv8ht/fAzCWmtTxhkqbO0iIZfvk/iwM/qvjs4m6oungNsEHcChVidJmAeACwPmKupyFwaL21hI1wMXgbmIE4KXUMpHS5hLlof4M4IxnbuqKoQS3Cg/AgdTbsl+QYJ8BmMv2DHGgz9tqJBHA4K7rhdQ36YNKmxukgpyqT7MwuG+5jTQADG49xgC+lEqLlDafkA3zHOx205YY3GZ5AAKpH9IvpLrd6a73fBYGF203ktzD4NqzrNv9D4A/0zULg8vWW0edxuB2zwTAd1IAAKXNBYphvrLTPOoCBtcNB4i72g/dbaXN3yiG+V87zaO2MbjuSu5L/5gcUNp8RjbM73kRrJ8Y3H45kvopOaC0MciG+cMsDG7sNI/qwuD2X3JV++fkgNJmjmyYP3LyhlsY3GE6kfpFfo6UNn+hGGYOHukoBpeA+H7zqdSvcmyhtPmIbJjnDHM3MLi0zAjAG6nf5Ni90uYDgPfIhpmzqlrmLxb33mi0Y7sd5IYdxBMw0pMw7uQ7c35YJ8dpN8gfjXYi240gp/l4PDOnRXJ7qmycNu83b4ldZWqKB+BY6vv0CzKsMz9O+wzA+SwMeCKpgMElGyZSX+eO38p953zX27DbncXgUpfsAngtlbFidZKHGlK4GVxyRTKbKj/n+YHS5grFQF+hZCFB16+EM7jUJ8+lCmfsPFm1pMoqoaVLB9v+Ls7g0lAlywa/2uSPZZngddYJr/qAgSoPI7hmcIk240vtW/jsdyMLH0pEW2JwiRzE4BI5iMElchCDS+QgBpfIQQwukYMYXCIHMbhEDvIB/AFgD3GIPdmOKvy86rVdqXGFLUdvEa3Js90ApY2H5aHel0oGj5ftP2u/1URWvbMe3G0pbUYoD/QE8aM7DlM1sdRMojq5H9x1KG12UAxzvg6sNZCommEFtwoJ9zHiBcOnudq12DSiBINblXwXP0QxzCdgF5zaxeDWQWmzh/JAH6EDFwCpdxjcJqW63ekwJ1veBqONRNGCwbVBroRPES98ltRrxE8KIHoKg9sVcnY+QTbMp+DoNipicLtMwnyKbJi/AL83Dx2D6xqljY+4W50O8xQM85AwuH2gtBmjGObAaqOoSQxuXyltnqEY5mOrjaK6MLhDIveb3yAb5o0WBCerGNyhU9o8RzHMh1YbRU9hcKlIafMC2TC/BYd1dgmDS9UobQ5QnHhxgvgJetQuBpe2IxfB8mGeIr4Qxv+vZjC41AwZPHKEbJiTGltsWh8wuNS+Jd3uKbiIQVUMLnVHqtv9CstXJ+H/LINLLpFZVROUh/olHsPd94kZDC71j5y5n1odNL/v0vxoBpcIAJQ2u3gM8h6yywRXWR+8bNtUvhhcoqbITK4kwOs+VGDVa9f/A97Fr1H4MhUiAAAAAElFTkSuQmCC"></image>
        <image id="_Image6" width="239px" height="30px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO8AAAAeCAYAAADEvkkFAAAACXBIWXMAAA7EAAAOxAGVKw4bAAACcElEQVR4nO3bXW7aQBiF4dfglBIgqeSldBHdiO9Yj+/YUTfQ2y7AUhIIBRJMLzxuB2wr/JnxxOeRPuEYKfmU5GQmM+MAEfknTtIeMDDVB3oX1jU+R1X9DJv6JojcSpykAfCF/6GzrwdH3Lff8yUTv3xpVD65OEn7wMjU2NQ9H4etuO4chVcaY0bEIox2KMcV94aO2vSWwisni5P0nvoQ2vdGrnrsAoVX9pjp6wPwaOqbdV2Ufm9aQD+EjomTdEg5jHZIx+66k1MovJ+I2eaYUD1aFtXJxZ3PZpdtA4XXI3GSDqgeLYuaAIGzBuVmgl5/p/C2hFmZnVA/nX0k3xYRATRtbpyZytqrs4crs0VgH8hPzogcReE9gxklh2i7RBzqfHjjJA2pPzZXd8BghP63FMe8DK+Zih5zTvWY+5qqipfCOEnvgK808+TDNZ6yuKMcOC//6IhcUwh8B364bkTEsTdgDWzM69rc2wLZjeqUr7XWCCY+y4AV+4E7rLr37Pub2TTKbt38pRReaYMMeAUW1mtRS/KAloI4m0ZbJ922hMIrTToMYt3Hf2bTaOeqSV8pvHKqDHgBnoG5qcNQLoClAtkshVcOrciDeVhP5nWhULaDwtstO/KRsghiqWbTaO2uPTlFuMu2QdDru+5DrmNDeaR8sa7nPq6qSrUw6PU1BfLHnPrp7PNsGq0c9iY3pmlze7xTP519Ih81O701IvsU3mbtyPcpP9wumU2jpasmxU8K73mWVG+PlA4YaGVWmtLl8B5zbG5NHkg7lK9a9JE28C2875x/ftWuN42I4ruQfAXzN5c/5dDUkxRbPD48LtKUv+t6N2dNwxFeAAAAAElFTkSuQmCC"></image>
        <image id="_Image7" width="239px" height="41px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO8AAAApCAYAAADdwX4QAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAC2klEQVR4nO2d227bMAxAaTtthw3YHxfgN++pyMXbg6mGURTPTnyR5XMAIopjNEaRE9G6MJWqfojID+n4K1debT8MVfXnAsATHCx+LvmmqipyK3Qr/cK3qeBLAPbMYcX3rixERJpn/oB9CSTFTsRFVduXrhggI9aUdypqi/9isl9ctPFzVb3McpUAE1OCvGNppKend4J7sc8h6L0hF/Yo7xCC4G/xCybvOQ56bFga5B1PLSLvFt/Y4FlK6vPiVwi7oPr8/PzVNM3vtS+kcO6klk5sRsvhaQ5N89RAL4wjTMndYKm2F/qkqqeFrw02CmnzuoR7649wwKXfRxE5SSc0qTfcgbz5UUk3UPY9WGZCn3wgNCDvNqgkGiSzUe9YaEa8dwTybpdaunTbp9yx0EfmpcsFecsiJfRF7ntohC4A5C2fMCgWdo4hdCFUqtpIJ3Hlj0/QDhsPatdOBeTBWe6FZh46Y1aXR1VTQtdRu47adXQc5sELfRQWlmTF5j/4Jn+f4I17ZEXK65yiQOiV2Ly8Y7HbBC9z6jmMI14pxg6sBdidvENQ1VquSxoP0gmdXOIIvbADa0aQdwSWonuRffC/HE5yB5Z01U5IwQfCB24i3Kh9HIOqfMA3pOADQd6ZSaTgPhWHcVDCyIG8K2Ep+EGumxBuNiPA08RihwKEd1VIt56iI29GREK/2yODZPORKiscH0uVIc6i/jjyZo4JHffOCJ0PvT8wIFfZ/flx+9HrfeeckXeDuPvo0Du/CffQe+MP8haCCR330AhdLshbMia0753fhKmrUkDevWHz0XEPjdDbA3lBRFVTU1Z8NvIGeSENQmcP8sJwVNVPVbFSbF2QF17DLSxJBcxE27bIC/NhqTc7sOYBeWF52IE1CcgL+WDz0mEqK9xPU8IoDfLCdqCE0Q3IC2Xheu9UpdFUbBXkhX0TVR9NlRXuC3/O0iAvwBQ8qD/+6AcGpmh//QPYWllTHlRvWgAAAABJRU5ErkJggg=="></image>
        <image id="_Image8" width="240px" height="80px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPAAAABQCAYAAAAnSfh8AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAFhElEQVR4nO2dS27jOhBFr/x3nGkDvRztKtNampfzgJ52J7ZsS2/AYqwociwn+pCsewBCdiB02DFPSlX8JBORDMAvOKpaa75vfq3L/SWAUkRKEEJ6Z6HX+ZDfREQA4AIntL+WbV8Tkar9XyGENFncv6U35tqWX92k0bpN9AuAs4icB+4nIdEwpsBdmWlr7ZtG6HOzUWxikRAFvkcGF8U/RPIbYp9E5DJ6DwkZiRgFvkUXsU8AChE5jd89QvonJYFvURd7C7xLXdTaicUzEiMWBG4jA7DWBgCVRuUCwBEUmkRCpvPAv6fuSIDUI3RBoUmIWI3AXVhpAwBohD4CODCHJqFAgbvj8+hnrWwf4GQupu0WsUz28vKSbbdbPkJ/nxJXmY9Td4bYgjlwv5TQx2wAR+bNZGj4CN0vM7ipqi1cZdvLfKDMZAgo8HBkADbaKhF5A/DGnJn0CQUehwzAE4AnXbP9Ciczt1mSHzHP8zwD8Dx1Rwwxg1tA8pzn+TLP82q/33O9NvkWjMDTsgGw0UjsozJ3VZHOsAodHgWczCx8kbswAoeHXwFWisg/AK/MlcktmAOHi99wscvzfJ7n+Xm/3zMikw9Q4PDx2yF3WvQqWfQiHgocFwsAT3mer7V6zYKXcXwOfIH7TQ+9Zu23k0BYAVjppoq/cNVrPl4b5KaoWp3299Sl7vp+Djfn6a+zr74f+RF+GuofC162GFUoEfEi16VuE302Zr8SogLwBicyH68NEGRE1Ojvj5ZtNsrdjSOAv1x7nTZBCvwVIjLHZ6mXiPD/MhInuIj8NnVHSP8kM+hbxP50xKxxLgD8whAWvBIhGYHb0EfxVa0xUrs82Re8OJ8cOaYGswq9xEepTf0MGviCFw/pixTLgxcAICJLuCWLloUu4ApePNMrMiwO1i9Rof1JGtY2e5zh8mQuDIkECvwFIrLAVWZLBbES14IXF4YEDAXuiFa5vcyrO7enAheGBA4F/ga6oqwus4Wf4wFOZC4MCQgLA29QtLK9gTu0zkJkLuBEPkzdEUKBe0Vz5i2czKkv+eROqACgwAMhIhs4mTdT92VguBNqQijwwGi+/AQnc8rTUhVcnvzKPHk8KPCIiMgKTuYN0v7Zn+Gq15yGGpiUB1GwaFTewUaufIDLk1n0GgAKPCFawd7CnUk2n7g7Q8PD6weAAgeCFr12sDMV5f/YGyvYP4ACB4bmyTukX70GXOGrwPVPsDJffhAKHCg6p7yDe8S28jnVZeZe5Q5YGRjRUpuG2iH9gledE64yM2e+AQWOhFrBa4e055PbOOMqMw8fqEGBI0RE1nCVawsFryY+by4AHK0LTYEjRg8f8HmyVepCFwBOlirbFDgBdK+yXxhi/TOt4PLnd6lTFtr6h50Umif7glfqC0Me4QSXR/vrOZUqNwVOFBHxBS9LRwE9QoWG1IhQbAqcOLow5Bnu5E1yH/8Ifm60MsRHcQpsBKMLQ/qmrLVL4/r+eswVZfwgjWFsJ9RUVPgsum9V7Z6q6/tb0Z8CG8XYTqhUaMr9hwITazuhUuI/CkzeMbYTKgUoMPkMC17RQIHJbQzvhIoFCkzuY/Dw+ligwOQxjB1eHzoUmHwf3dboj8kl40OByc/RXNlHZWuHDUwJBSb9olNRW7CCPQYUmAxDrfC1gdtIwbHWPxSYDI/KvMZVZha/+oECk/HR4pePzpT5+1BgMi2aM3uZuaniMSgwCQc9pM9HZ54kch8KTMJE8+ZVo5GPUGASByr0Ek7ktb62Pn4pMImThtC+WRvPFJikg+bQKzixF9pSHuMUmKSNHnq/wEepUxGbAhOb6K6qthaTExSYkDo1sefaZtrqr0OBAhPyCFo8a0rdJvoYi1IoMCFDodssfctqDT29//M/oU4NlA/K/ZQAAAAASUVORK5CYII="></image>
        <image id="_Image9" width="981px" height="126px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA9UAAAB+CAYAAAAqeTKvAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAD9ElEQVR4nO3czWrbQBhA0Ukxhfap9cR9gEJpV4FSnDTc6GdGnLOTxtY32uki7JcBAAAAvGvbtpdn55+eBACAMzx5SP3f8Vvn3ju/yvoMezh6j2fsrzqzjc6aZc7xfj6u3gEAwNFCuB19fJcZewYxwJJENQDsYKe3bbMfrzoDAA4jqgEWMuHbtrOC6Or7Em0AwFOiGib21p8h/OWu63cIwSNmAAAwmce2bd/GGF/Cd/2Qf51ZZ8/cY87sf7JxxjoAADC5xxjj+xjj69UbAQAAgNWUN9QAAADAENUAAACQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgOhx9QYAAIBP+z35+lkzjvjujHOumHnmva10T79ENQDAGv59+Pvs8RHXvGKPb527zfq2bVeEGvBBohoAeLVCtB1xzen2KKIA1iGqATjb1cGzQrQdPkO0AcA+RDVwR8sFzg7HU15TuAEAdzdTVK/0Y/TZZt3tnqb+XdMO15h9f2esv/cZ0QYAwDIeY4wfrwceTgEAAODj/gCkWqOVAS8SegAAAABJRU5ErkJggg=="></image>
        <image id="_Image10" width="486px" height="72px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeYAAABICAYAAAAj8lblAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAE5klEQVR4nO3dbW/aSBSA0UtId6XV/uj531vi/YCdjidjg8EYv5wjWQ44raKq4ckdGHJKKf0bEaf4o4m+5s5rUz53yt+T324iIlJK5XUA2IXPiPgnIs7v/kKmSClFXCOdH7X77rl213U/DACwhM93fwFPOEV/0n+pgR8G8qh/jZx796WUvpb6ugHYli2H+R1m+WEgi/xYzEfPJniAfRLm9znFE08htHH/MY2350t2rTsuYg6wfsK8bR/tcZc2zL1YRyXgcZ3ILbcDvIEwH0s3pd+c1IuJfDDg3WEaB5iHMDOmm8hv/j9pJ+xLdvRup5QuL/w6AXZDmJlLF/FftYvtBD4Y7rjG2/I5cHjCzJJGl9Hb5fBb8bZkDuyaMLMmp7j+nxz8f1ksmf/Oz5bLgT0QZrZmcMk8m7h/l2fRBrZCmNmTwYm7fY77R7DDEjmwMsLMkXTR/ru80E7UtUn796JfIXB4wgxX1RemZZN2d/wXf57TNmUDs/tsmiZOp8V+FwRs0dDyeB7s70OwgWd8ijI8bCjY3XJ4PmELNnAXS9kwv25ZvPdcdhHsfML2xirAN2GG5QwF+yvqE7ZgwwEJM7zfR0T81R7fimDnE7Y92bBjwgzrNRTsJorpOgQbdkOYYXtOcX3ns967n2XBLidse7FhQ4QZ9mMs2JcoJuywFxtWSZhh/8beqtRebFgZYYZjG9uLXU7Ygg0LEGagZugtSu3FhhcTZmCKW3uxy1eKCzZMJMzAHOzFhpkIM/BK9mLDRMIMvMOtrV35c9mXuG7tsh+bQzillLo4l79m6jTw8ZRrr/h7TwNHeQ3Yny7YP85eMc5e7DZgKaWxaN+K+tTru/13hA3JJ+3eWbTZEkGZSUrpI67/nveca/cBr9O9CO1SO4SbNRHmlWgn/Clxr52Bx3y1RzXcEfEl3izFg/lOZGE/x5+pvHa7O4BpxsJ9sWebuQjzAWURvxXw7j7gtiZ+xvsr+tP4l4BzizBzU/v8eS3g5+ywnA7368U6KgHvDkvox+OBlNm0AT8PHN01YJpub/dgvLv7RHwfhJnFFM+DD4Xb0jk8rltOf+gs7OsgzKxKG++hqfszhBtebUrQe/d5/nwewsymtOH+jH6s89vAezUjx6zX9zrhCzO7UUzbZbC9Lzzs09Sol3+29vG7PjciohFmDiOl1AW6dva9AKzBxYMRRC/a5eE5bWBJwgxj2i1gv0KwgWUIMzyiDXZtwvYCNOAZwgxzEmzgScIMS8i2edUOgI4wwzsJNlAQZlijbE92Ldi+b2G/hBm2JqU0NGH7fobtE2bYi8pe7G6bl+9z2A5hhr3z5imwKcIMR1XZ2tVN2IIN7yPMQJ+92PBWwgzcp7K1q5uwBRvmI8zAc+zFhvk0TSPMwGtU9mLnvwwEqBNmYHnZXuza78aGIxNmYD2yKbsWbJM2RyDMwHZke7JrZ49n7IEwA/vQRrsW7HPYm812CDOwf8USeRfqc3F4PGQNhBkg4vuNVcbC7YVpLEGYAe6VLZcPxduSOc8SZoC5tEvmH9lxLm6X90NJmAHepV0+H4p4edvj9TEIM8AWZC9gG5q+T8XZRL5NwgywV23Ma8Eu7xs7syxhBmBYu9x+b8jzmJ8qB7cJMwDLyab4oXA/en3o2tYIMwD71f4gENGP9NDHU28/em3sc5v/AUtziAX6Vf5OAAAAAElFTkSuQmCC"></image>
        <image id="_Image11" width="733px" height="110px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAt0AAABuCAYAAAD79q8AAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAG7UlEQVR4nO3dzW6jSBSA0Ys709Js5pl58MSehaG7XC4wYDB/50hRwMEtz2Kcj9J1parr+t+IqOLuFs/yx+a6ZtLz6rouXQMAAJv1FRH/RcRl7RcyVF3XXT969+bglnzPj/t+Nvk5biAAAM7ha+0XMKPqxfnmJDcQHwv9iLim1wt/AIDlHSm696yKlW4SmvB/CPEoxHnHY0/X1HV9/eh/AADADohuImYcL2oiPo/1QcHe9ZjVeABg70Q3S5h15b4Q8tfke378dC7aAYC1iW72Ig35X2OemIzQDIr0+LvCblQGAJiF6OYsLjFyjCabdx8V7VbXAYCU6IZ+baiPXV3vG39pv37i7wiMVXUAODDRDcuo4h7qg2I9i/SHIM+PraIDwP6IbtiGwZGeBXpXnAt0ANgQ0Q37kwb6P30XDgz0n7DLCwAsSnTDsU0J9J/ke/p1rev6Z9FXCwAHJbqB1ssRl2ZHlz8RHsIcAAYR3cBYQ8O8GOVxnzUX5gCciugGltA70iLMATgb0Q2s5Z0w/4mIbx/+BGAvRDewZa/CPA3y78jCXJQDsBWiG9izS/PVFeUPK+PxGOTGVwD4GNENHFnnhz6bVfC+KL9+6kUCcHyiGzirKu7vgcX3wSbK0xDPo9zoCgCDiW6AsiruYyt98+T5HPl3GF0BoEB0A0xziYjfpR8kO690RbnRFYCTEd0AyxgyT94V5UZXAA5GdAN83qt58nYrxKdtEEOUA+yS6AbYHlshAhyM6AbYH1shAuyM6AY4lqGjK7ZCBPgg0Q1wLmNGV2yFCDAT0Q1Aqm90JcJWiACTfN1ut6iqau3XAcA+2AoRYIIvwQ3ATKZuhfhtdAU4OuMlAHxK5zx5MrrSFeVGV4BdE90AbEU7uvI7/4GtEIG9E90A7MHUrRCvIcqBDRDdABzBq60Q05XyPNCFObA40Q3AGfSulEc8hHke5cIceJvoBoC7Nsw7CXNgKtENAMMJc2AS0Q0A8xoS5hH3AG/DvHQs0OFARDcArKP98OfQQH8K8vxYoMN2iW4A2L420Ht1BHox1gU6fJboBoBjGRPoXavnt+zxW9xD/bbIK4YTEN0AcF7tXwEdpInuzijvOhfrILoBgOGqGBHpreyDo4Oj3QgMRyK6AYBPGDT2kkpivS/S09X3W35ulZ2tEN0AwJa1oT56hT3iT7iXwnzoY0/XCHmmEN0AwNFNGovpkq3Ajwr20mPGaM5BdAMAjDdqVKZPshrffu87nvu6p+dYyV+G6AYAWF+VfV9NcxMQ8V7Adz0/VYr7pa6Z/G/NdRMiugEAKKliAzcBa0tuQlJjw/8qugEAYJz8ZuTVzUk12zwSAABQJroBAGBhohsAABYmugEAYGGiGwAAFia6AQBgYaIbAAAW9hURP/G4eXdpn8GxexECAACNWeO5rushcT7lmiWfl/7Z1b7jodd1vQ4AAM7pKg4XktyATI32OZ7vJgAAYH2i+yyam4BLPAZ56bEh16RBDwBAP9HNNE3ED4nzMVEPAHBEopvtyEK+K9YvheP0HABga0Q3x1LX9aso7zoHAFiK6IaIh5n3sdHu/yEA4BXRDe9IRmIu0R3pv7JjAOBcRDd8WjICUwry/BgA2D/RDVuWBHpXnAt0ANg+0Q1H0QR6V5DnxwDA54huOKMs0H9lX+1j3h8AYB6iGyjrCfP03HsIALwmuoHphDkADCK6gWVlHwYV5gCckegG1lcI8694DnQA2CvRDWxf80eI0hDPo9x7GQBbJrqB/WtWyvMQT88BYE2iGzi+uq5Lq+PtudEVAJYmuoFza0ZX+qLc+yQAb7ndbqIboE+yLWIe5e1jAPCK6AZ4RzO60vUBT/PkAESIboDlJKMrtkIEODfRDbCWZHTFVogAxya6AbbKVogAhyG6AfbKVogAuyG6AY7IVogAmyK6Ac6oZyvE9hyA+YhuAJ4lWyGWotzoCsA4ohuAcWyFCDCa6AZgXrZCBHgiugH4rOyveJaiHOBoRDcA29GMrvTtT250Bdgj0Q3AfvRshdgGuZVyYItENwDHkoyv5LPl6TnAJ4luAM6nCfM8yoU5sBTRDQAlwhyYkegGgKk6wvySHftdC4huAFhSsiNLG+H5cXru9zIck+gGgK1IdmcpBXl+7Hc47IfoBoA9KgR6X6z7fQ/rEt0AcHR1XacxXgr0NsxFOixDdAMAj5pV9DzC+yI9PQeeiW4AYD7JqvrYaIcjE90AwPqSXV6GRHq6Et8ew5aJbgBg/7KRmCr7yh8bco1GYk6iGwCgpBmVGRLnQ0Of8xLdAACfkKzGl2I8XV0fczz2OtYhugEAzqIJ/4jx0T7lOel5FI67Hhtyzd6IbgAA9ie5gUhNCfihkf/Ov337H1kwi7nMGoJdAAAAAElFTkSuQmCC"></image>
    </defs>
</svg>
</a>
  </div>
  <figcaption>
    Focusing on "how do I get the reader to see the story I see?"
  
</figcaption></figure>
<p>The product manager's response is effusive:</p>

<blockquote>
<p><em>This is fascinating. One in three signups never install? Wow ‚Äì what a big opportunity. And this is for the last week, so it could be a result of changes we made a couple weeks ago but never tracked. I am going to share these numbers in our next strategy meeting and see if anyone else has ideas. I think we've been fixated on converting web sessions to signups, but we haven't been considering all the other weak points. Nice that there's a link to the data source. I'm going to pair this with data from our external data vendor. I have so many follow-up questions about where we can go from here!<p>
‚Äì the PM</p></em></p>
</blockquote>
<p>Your updated chart got the reader to an "aha!" moment quickly, answered all of their immediate contextual questions, and put them on the path to asking the next set of deeper product questions. All of these were achieved by focusing on the small things that made the data visualization more immediately interpretable.</p>
<p>This is obviously a contrived example. The data visualization does have to be relevant to the audience. In our example, it'd be a problem if the product manager didn't care about the user journey of the product they're working on. If your data visualization isn't showing something meaningful to the reader, it probably won't get them to care. This said, it's not always so straightforward to get someone to understand that a new insight <em>is</em> relevant, especially if the visual story you're telling is novel to them in some way. But then again, that's why we've reframed the challenge to <em>telling the story well</em>, isn't it?</p>
<h3 id="the-two-constraints"><a href="#the-two-constraints">¬∂</a> The Two Constraints</h3>
<p>The reality is, even if you have the desire to take your data visualization further, there are two things that are likely to get in your way: <strong>limitations with your tools</strong>, and <strong>diminishing returns</strong>.</p>
<h4 id="limitations-with-your-tools"><a href="#limitations-with-your-tools">¬∂</a> limitations with your tools</h4>
<p>If you‚Äôve used a visualization library before, you‚Äôve probably discovered that there are always limits to what you can do. The lower level you go, the more work it is to get annotations and animations to do what you want.</p>
<p>This said, most libraries support all the basic small things in some way. I'm hesitant to suggest what things to add to your charts, since building intuition around effective visual storytelling is more important than having a checklist. This said, there are some common easy-to-implement small things that always immediately improve the readability and interpretation of your graphic:</p>
<ul>
<li><strong>human-readable labels</strong> ‚Äì labels are always the easiest thing to add, and often the most impactful. Make sure they're expressed in clear, simple language. Don't ‚Ä¶</li></ul></article></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hamiltonulmer.com/notes/data-viz-small-things/">https://hamiltonulmer.com/notes/data-viz-small-things/</a></em></p>]]>
            </description>
            <link>https://hamiltonulmer.com/notes/data-viz-small-things/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066475</guid>
            <pubDate>Thu, 12 Nov 2020 04:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Occult History Behind NASA‚Äôs Jet Propulsion Laboratory]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066293">thread link</a>) | @jtmarino
<br/>
November 11, 2020 | https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/ | <a href="https://web.archive.org/web/*/https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>Jack Parsons was one of the most influential figures in the history of the American space program. He was also a Marxist, stood accused of espionage, and held a deep fascination with the occult. His interest in the supernatural went far beyond vaudeville magicians and astrology. By 1939, Parsons and his wife Helen Parsons-Smith had fully embraced the teachings of the Ordo Templis Orientis, a central hub for Aleister Crowley‚Äôs spiritual and religious philosophy ‚Äî Thelema.</span></p></div><div><p><span>Aleister Crowley taught that a Thelemite‚Äôs central ambition was to achieve a higher state of existence by embracing one‚Äôs ‚ÄúTrue Will,‚Äù or one‚Äôs ultimate purpose beyond selfishness or ego. In pursuit of that goal, many aspects of Parsons‚Äôs life blurred the boundaries between science and mysticism. As a Thelemite, he performed ritual magic, including banishing impure elements with pentagrams, invocating the power of the ‚ÄúHoly Guardian Angel,‚Äù and offering daily adorations to the sun. </span></p></div><div><p><span>All while pushing the limits in the nascent field of rocket science.</span></p></div><div><p><span>Jack Parsons was born Marvel Whiteside Parsons on October 2nd, 1914, to Ruth Virginia Whiteside and Marvel H. Parsons in Los Angeles, California. For the first two years of their marriage, the Parsons were swept into a dark whirlwind romance in the heart of the City of Angels. By the 1900s Los Angeles had become </span><a href="https://www.nytimes.com/2005/03/06/books/chapters/strange-angel.html" rel="noopener noreferrer" target="_blank">a hotbed of new-age spiritualism and occult fascination</a><span>, in which the Parsons were active participants. It was turn-of-the-century America‚Äôs Williamsburg, perfect for the upper-middle-class pseudo-bohemian who wanted a crystal ball that matched their silverware set.</span></p></div><div><p><span>Jack‚Äôs father was perhaps too taken by the city‚Äôs attractive social loosening. He made his rapid exodus from California after Ruth exposed him as an adulterer, who had frequented a local prostitute in the months leading up to and following their son‚Äôs birth. After the newlyweds' bitter split, Ruth excised the elder Parsons from their son‚Äôs life both physically and legally, insisting her son be referred to as ‚ÄúJohn Whiteside Parsons‚Äù on all legal documents. The rechristened Parsons was brought up by his mother and his maternal grandparents. Using their </span><a href="https://www.nytimes.com/2005/03/06/books/chapters/strange-angel.html" rel="noopener noreferrer" target="_blank">wealth from the manufacturing industry</a><span>, the Whitesides moved Ruth and John, or ‚ÄúJack‚Äù, to Orange Grove Avenue, Pasadena‚Äôs ‚ÄúMillionaire‚Äôs Mile.‚Äù </span></p></div><div><p><span>Spending a majority of his childhood in solitude, Parsons soon found a personal hideaway in science fiction. Enraptured by Jules Verne and the pulp magazine </span><em>Amazing Stories</em><span>, Parsons developed an interest in rocketry at a young age.</span></p></div><div><p><span>By age 12, the future father of modern rocketry was </span><a href="http://www.spacesafetymagazine.com/aerospace-engineering/rocketry/jack-parsons-occult-roots-jpl/" rel="noopener noreferrer" target="_blank">conducting backyard experiments</a><span> with his classmate Edward Forman. The two boys designed gunpowder-based rockets with aluminum foil, cherry bomb fireworks, and glue. Around the same time, Parsons was performing bedtime incantations to invoke the Devil - another practice he‚Äôd learned from reading </span><em>Amazing </em><span>comics. In an effort to ‚Äústraighten out‚Äù her wayward son, who was so distracted that he started flunking out of grade school, Parsons‚Äôs mother sent him to the Brown Military Academy for Boys in San Diego‚Äîa sprawling, 100-acre private boys‚Äô school known as ‚ÄúThe West Point of the West.‚Äù</span></p></div><div><p><span>It didn‚Äôt work. Parsons was expelled for blowing up the toilets.</span></p></div><div><p><span>With a renewed confidence that only vandalizing private property can give, Parsons resumed his rocket engineering experiments at home. After a brief stint back in school and a year at Stanford University, Parsons was forced to take up working weekends, holidays, and eventually full-time employment at the Hercules Powder Company after his family experienced financial losses during the Great Depression. He was no older than 19. Directly dealing with chemicals and munitions, Parsons not only learned more about the properties of gunpowder and its potential as a rocket propellant, but he also occasionally stole materials from work for his and Forman‚Äôs experiments. Parsons and Forman continued these after-hour experiments well into their mid-to-late 20s.</span></p></div><div><p><span>By 1933, Parsons had constructed his first solid-fuel rocket engine. He was only 29 years old. His boyhood interest in magic and the supernatural only grew stronger as he delved further into rocket science. That same year, Parsons turned his Orange Avenue estate into a bohemian haven, renting rooms out to artists, occultists, and dropouts galore. In 1934, Jack Parsons and Edward Forman met PhD candidate Frank Malina at a public CalTech lecture. The trio soon managed to impress Malina‚Äôs supervising professor Dr. Theodore van K√°rm√°n enough that he allowed the young engineers to conduct experiments at the university‚Äôs Guggenheim Aeronautical Laboratory‚ÄîGALCIT. </span></p></div><div><p><span>With access to CalTech‚Äôs resources and equipment, the trio formed the GALCIT Rocket Research Group. Thus, the blueprint for NASA‚Äôs Jet Propulsion Lab was born. What resulted was a bachelor pad for rocket pioneers.</span></p></div><div><p><span>Between rocket experiments, the trio would wax poetic about their shared socialist values, smoke marijuana, and drink to excess. Parsons and Malina even wrote a sci-fi screenplay and pitched it around to several Hollywood production companies. Making it big on the silver screen was starting to seem like a more viable option than rocket engineering for the GALCIT Group. Most of their experiments increasingly ended in violent explosions, that terrified neighboring CalTech academics so much the three researchers were </span><a href="https://www.kcet.org/shows/blue-sky-metropolis/the-bad-boys-of-space-exploration-and-the-origins-of-the-jet-propulsion" rel="noopener noreferrer" target="_blank">nicknamed the ‚ÄúSuicide Squad.‚Äù</a><span> </span></p></div><div><p><span>Parsons came to a crossroads during his later years with GALCIT. On the one hand, he integrated himself into the academic fold. While working with GALCIT by day, Parsons studied chemistry at USC by night. On the other hand, the wild rocket scientist was falling further into his obsession with Thelema. By 1939 he was enraptured with Aleister Crowley‚Äôs revival of what began as a sixteenth-century philosophy. Thelema was by this time a sprawling esoteric movement, incorporating ancient Egyptian deities, sex rituals, and a range of Eastern and Western mysticism. Eventually, Parsons was forced to choose between his new religious craze or pursuing his degree at USC. Ultimately, Parsons dropped out of school and chose to dedicate himself to Thelema, becoming a member of the local California chapter: the Ordo Templis Orientis. </span></p></div><div><p><span>Parsons‚Äô own religious and scientific pursuits have proven screen worthy. His life has recently been adapted in the CBS All Access series, </span><em>Strange Angel</em><span>, based on the biography </span><em>Strange Angel: The Otherworldly Life of Rocket Scientist John Whiteside Parsons </em><span>by George Pendle. Supercluster sat down with Pendle and show creator, producer, and writer Mark Heyman for exclusive interviews about the life of this rocket-scientist-genius-occultist-playboy.</span></p></div><div><p><span>‚ÄúI first came across a mention of him in reading that book </span><em>Going Clear</em><span>, which you know is about L. Ron Hubbard and Scientology. It was a fascinating moment in that book, and I sort of just filed it away,‚Äù says Heyman. The occult is no real shock to one of the minds behind Academy Award-nominated </span><em>Black Swan</em><span>. ‚ÄúI grew up in Santa Fe, New Mexico, and my parents were involved in a sort of new-age religion that some people would call a cult. I always felt like it was more cult-ish, but it wasn‚Äôt like a full-blown cult. So I‚Äôd always been interested in those sorts of organizations and groups, which is why I was reading ‚ÄúGoing Clear‚Äù in the first place. A year or two after that, I was sent the book for </span><em>Strange Angel</em><span> by a producer. It was my first real deep dive into who Jack Parsons was and my first introduction to him, and it blew my mind on multiple levels.‚Äù</span></p></div><div><p><span>‚ÄúWe tend to think of the 30s and 40s as a more buttoned-down time, a more conservative time, but they were as wild and crazy as anything that happened in the 60s and 70s. And then, there was this sort of intersection of that with the sciences, and the birth of this new fangled science‚Äîrocket science. Which, back then, was not taken seriously at all and was considered just as fringe and out there as some of [Parsons‚Äô] religious preferences.‚Äù</span></p></div><div><p><span>Pendle had this to say about the era, ‚ÄúBecause [Jack‚Äôs] personal life and personal interests were so at odds to the time he lived in, his scientific work‚Äîwhich was so groundbreaking‚Äîwas kind of swept under the carpet‚Ä¶ A lot of people who are very interesting are forgotten by history because they don‚Äôt fit into the pigeon holes we view history through. I often think you can get a better view of history from the edges rather than from the middle.‚Äù</span></p></div><div><p><span>Parsons without a doubt existed on the fringes. When the GALCIT Group first formed, aerospace engineering hadn‚Äôt even been invented yet. The first definition of the phrase would crop up in 1958, more than 20 years after GALCIT Group‚Äôs experiments started, and 6 years after Parsons‚Äô death.</span></p></div><div><p><span>‚ÄúNow, rocket science is sort of synonymous with the most esoteric of sciences. We have that expression, ‚ÄòIt‚Äôs not rocket science.‚Äô It‚Äôs implied that it‚Äôs meant to be the stuff of really, really educated experts,‚Äù says Heyman, ‚ÄúWhereas, back then, it was almost the opposite where it was the stuff of science fiction. It existed in popular culture, but in the way that dragons and time travel existed. It was actually the stuff of entertainment. So, it wasn‚Äôt taken seriously not because it was too complicated or too difficult. It wasn‚Äôt taken seriously because it was seen as imaginary.‚Äù</span></p></div><div><p><span>A figure like Parsons might seem to presage later eccentric innovators like Elon Musk or Steve Jobs. For Pendle, the parallel isn‚Äôt totally accurate. ‚ÄúImagine like a Musk without a fortune, without people backing him, basically plucking spare parts from the garbage to build his electric cars. That‚Äôs the kind of thing you‚Äôd be looking at if you wanted to make them equal."</span></p></div><div><p><span>The scientific community took notice of Jack‚Äôs rag-tag methods in 1938 when his group successfully tested a static motor rocket that could run for over a minute. With funding from the federal government (and at the request of their CalTech peers), the Group relocated to ‚Ä¶</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/">https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/</a></em></p>]]>
            </description>
            <link>https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066293</guid>
            <pubDate>Thu, 12 Nov 2020 04:01:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speed reading with command-line utilty shirah-reader]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066170">thread link</a>) | @ThorBhai
<br/>
November 11, 2020 | https://diode.zone/videos/watch/0065aec7-de6c-48a4-b075-fb6d8a9096c8 | <a href="https://web.archive.org/web/*/https://diode.zone/videos/watch/0065aec7-de6c-48a4-b075-fb6d8a9096c8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://diode.zone/videos/watch/0065aec7-de6c-48a4-b075-fb6d8a9096c8</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066170</guid>
            <pubDate>Thu, 12 Nov 2020 03:42:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Custom GitHub Actions with Docker]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066079">thread link</a>) | @sethetter
<br/>
November 11, 2020 | https://sethetter.com/posts/github-actions-with-docker/ | <a href="https://web.archive.org/web/*/https://sethetter.com/posts/github-actions-with-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <section>
        <p>I finally decided to dip my toes into GitHub actions recently, for a relatively simple task: build and deploy my personal site. The site is built with <a href="https://getzola.org/">zola</a> and deployed to <a href="https://netlify.com/">netlify</a>.</p>
<p>My needs are pretty straightforward.</p>
<ul>
<li>The zola binary</li>
<li>Node, and <a href="https://www.npmjs.com/package/netlify-cli">netlify-cli</a> installed</li>
<li>Secure way to provide netlify config</li>
</ul>
<p>Then I simply make sure my site source is checked out and run the <code>build</code> and <code>deploy</code> commands.</p>
<h2 id="some-terminology">Some terminology</h2>
<p>An <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/about-actions"><strong>action</strong></a> is a single step that may be performed in a larger <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/workflow-syntax-for-github-actions"><strong>workflow</strong></a>, which strings together multiple actions and is kicked off in response to various events (like a <code>git push</code>, or a PR). You can have a workflow that calls a single action, but an action can't be used without being called in a workflow.</p>
<h2 id="first-impression-with-actions">First impression with Actions</h2>
<p>I noticed the marketplace approach first of all, and the emphasis on actions that did one small thing which you compose together. This can definitely be a nice approach to things, but my preferred way of working on CI tasks like this is to have access to a Docker container where I have a bit more control of my environment, and can codify it into a familiar Dockerfile.</p>
<p>My thinking is, if I can get this sort of approach to work, I'll have less required domain knowledge of GitHub actions, and can instead just lean on my Docker knowledge to set up whatever operations I may need.</p>
<p>Needless to say, I simply sidestepped the marketplace and found the <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/creating-a-docker-container-action">documentation for utilizing Docker</a>, which thankfully is a valid option! üéâ</p>
<h2 id="my-setup">My setup</h2>
<p>I stumbled through this quite a bit, but ultimately am happy with the approach. I'm able to have a <code>Dockerfile</code> and custom <a href="https://docs.docker.com/engine/reference/builder/#entrypoint"><code>entrypoint.sh</code></a> file that can receive inputs via env vars from the action configuration. I'm also able to pipe secrets, stored in my GitHub repo, into the action from the workflow file.</p>
<h3 id="the-action-file"><a href="https://github.com/sethetter/sethetter.com/blob/1e916825348e2ee2f401b5204811c18e394432e3/.github/actions/build-and-deploy/action.yml">The action file</a></h3>
<pre><code><span># .github/actions/build-and-deploy/action.yml
</span><span>name</span><span>: </span><span>'</span><span>Build and deploy</span><span>'
</span><span>description</span><span>: </span><span>'</span><span>Build site with Zola and deploy to Netlify</span><span>'
</span><span>inputs</span><span>:
  </span><span>auth_token</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Netlify auth token</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>site_id</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Netlify site ID to deploy to</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>deploy_dir</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Directory to deploy to netlify</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>zola_version</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Version of zola to pull</span><span>'
    </span><span>required</span><span>: </span><span>true
    </span><span>default</span><span>: </span><span>'</span><span>0.12.2</span><span>'
</span><span>runs</span><span>:
  </span><span>using</span><span>: </span><span>'</span><span>docker</span><span>'
  </span><span>image</span><span>: </span><span>'</span><span>Dockerfile</span><span>'
  </span><span>env</span><span>:
    </span><span>ZOLA_VERSION</span><span>: </span><span>${{ inputs.zola_version }}
    NETLIFY_AUTH_TOKEN</span><span>: </span><span>${{ inputs.auth_token }}
    NETLIFY_SITE_ID</span><span>: </span><span>${{ inputs.site_id }}
    NETLIFY_DEPLOY_DIR</span><span>: </span><span>${{ inputs.deploy_dir }}
</span></code></pre>
<p>This file defines our action, which will be called from a workflow which we will configure later. The main thing to notice here is how we are accepting inputs, and passing those on to our Docker container through environment variables.</p>
<p><strong>This was one of the things I stumbled over</strong>. Currently there is no support for passing <a href="https://docs.docker.com/engine/reference/commandline/build/#set-build-time-variables---build-arg">build args</a> to our Dockerfile, and the environment variables we provide are not available during the build stage, only once the <a href="https://docs.docker.com/engine/reference/builder/#entrypoint"><code>ENTRYPOINT</code></a> is called.</p>
<p>I was stuck on this for a decent chunk of time before realizing that <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/metadata-syntax-for-github-actions#runsargs"><code>runs.args</code> with <code>docker</code> are <em>not</em> build args</a>, they are arguments sent to the <code>entrypoint</code>. Don't make the same mistakes I did!</p>
<p>The implication here is that any steps in your action that require one of these inputs must happen in the <code>ENTRYPOINT</code> provided via <code>env</code>. I'll mention this again shortly.</p>
<h3 id="docker-setup">Docker setup</h3>
<p>The <a href="https://github.com/sethetter/sethetter.com/blob/4fdf1675084628f6ddd3aaa31aaa05a1a118b1d6/.github/actions/build-and-deploy/Dockerfile">Dockerfile</a> is pretty minimal, simply setting up the base environment I want, which is <code>node:lts</code> in this case, and then copy in my custom <code>[entrypoint.sh](http://entrypoint.sh)</code> script.</p>
<pre><code><span># .github/actions/build-and-deploy/Dockerfile
</span><span>FROM node:lts
COPY entrypoint.sh /entrypoint.sh
ENTRYPOINT ["/entrypoint.sh"]
</span></code></pre>
<p><strong>Tip!</strong> <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/dockerfile-support-for-github-actions#workdir">Don't set a <code>WORKDIR</code></a>. The action sets the workdir to the <code>$GITHUB_WORKSPACE</code> variable which is where your project source will be located.</p>
<p>All the action happens in the <a href="https://github.com/sethetter/sethetter.com/blob/1e916825348e2ee2f401b5204811c18e394432e3/.github/actions/build-and-deploy/entrypoint.sh"><code>entrypoint.sh</code></a> file.</p>
<pre><code><span># .github/actions/build-and-deploy/entrypoint.sh

#!/usr/bin/env bash
</span><span>ZOLA_URL=https://github.com/getzola/zola/releases/download/v${ZOLA_VERSION}/zola-v${ZOLA_VERSION}-x86_64-unknown-linux-gnu.tar.gz
curl -L $ZOLA_URL | tar xz -C /usr/local/bin

</span><span># Install netlify
</span><span>npm i -g netlify-cli

</span><span># Kick off build and deploy
</span><span>zola build
netlify deploy \
  --prod \
  --dir=$NETLIFY_DEPLOY_DIR \
 --auth=$NETLIFY_AUTH_TOKEN \
 --site=$NETLIFY_SITE_ID
</span></code></pre>
<p>You can see here we're referencing the <code>env</code> vars we defined in our action file. Originally I had the zola and netlify install steps happening in the <code>Dockerfile</code>, but due to the inability to pass build args to the image, I wasn't able to get the <code>$ZOLA_VERSION</code> passed in. Once I had that realization, it seemed just as viable to put everything in <code>entrypoint.sh</code>.</p>
<h3 id="the-workflow-file"><a href="https://github.com/sethetter/sethetter.com/blob/4fdf1675084628f6ddd3aaa31aaa05a1a118b1d6/.github/workflows/build-and-deploy.yml">The workflow file</a></h3>
<pre><code><span># .github/workflows/build-and-deploy.yml
</span><span>name</span><span>: </span><span>build-and-deploy
</span><span>on</span><span>:
  </span><span>push</span><span>:
    </span><span>branches</span><span>: [</span><span>master</span><span>]
</span><span>jobs</span><span>:
  </span><span>build-and-deploy</span><span>:
    </span><span>runs-on</span><span>: </span><span>ubuntu-latest
    steps</span><span>:
      - </span><span>uses</span><span>: </span><span>actions/checkout@v2
      </span><span>- </span><span>uses</span><span>: </span><span>./.github/actions/build-and-deploy
        with</span><span>:
          </span><span>zola_version</span><span>: </span><span>'</span><span>0.12.2</span><span>'
          </span><span>auth_token</span><span>: </span><span>${{ secrets.NETLIFY_AUTH_TOKEN }}
          site_id</span><span>: </span><span>${{ secrets.NETLIFY_SITE_ID }}
          deploy_dir</span><span>: </span><span>'</span><span>public</span><span>'
</span></code></pre>
<p>This is our final configuration file, turning our new custom action into a workflow. We start by setting our workflow triggers in the <code>on</code> block. In this case we just want to run this workflow on pushes to <code>master</code>.</p>
<p>Next is our <code>jobs</code> block. We can define multiple jobs which would all run in parallel. If we need anything serial, it should happen within a single job. In our case, we have just one job with two actions.</p>
<p>The job itself starts with the checkout action, which handles checking out the repo's source into the job workspace, then we call our custom action by providing a path to the action folder.</p>
<p>In our <code>with</code> block we provide values for the inputs we defined on our action. You'll notice that two of the values are provided via <code>secrets</code>, which is a <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/encrypted-secrets">feature of GitHub</a> I wasn't aware of before this. It's very easy to work with!</p>
<h2 id="room-for-improvement">Room for improvement</h2>
<p>I think the main drawback here is potentially slow job run times, since we're installing our dependencies each time. Depending on what's actually slow, there are a number of ways it could be addressed.</p>
<p>In general, finding a base Docker image that has as much of what you need as possible (without too much bloat) is going to help. Maintaining your own images in a registry somewhere comes with it's own overhead, but that's also an option.</p>
<p>I'm sure using the marketplace approach could also be a way to address the performance issues, assuming you find actions that have your dependencies installed and configured appropriately, but the goal of this post was to explore a minimal action configuration while leveraging the power of Docker üòÑ.</p>
<p><strong>That's it!</strong> üëã</p>

    </section>
</article></div>]]>
            </description>
            <link>https://sethetter.com/posts/github-actions-with-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066079</guid>
            <pubDate>Thu, 12 Nov 2020 03:28:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pyxell ‚Äì a programming language that combines Python's elegance with C++'s speed]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25066058">thread link</a>) | @masijo
<br/>
November 11, 2020 | https://www.pyxell.org/docs/manual.html | <a href="https://web.archive.org/web/*/https://www.pyxell.org/docs/manual.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>Pyxell [<em>pixel</em>] is a multi-paradigm, statically typed programming language, compiled to machine code via C++.</p> <p>This manual should let you quickly learn all the details to start programming in Pyxell.
It is assumed that you already know some programming language (preferably Python), since basic programming concepts are not explained here.</p> <p>You are encouraged to run the code snippets and experiment with them for yourself.
To run Pyxell code, go to the <a href="https://www.pyxell.org/docs/playground.html">Playground</a>,
clone the repository and follow the instructions on <a href="https://github.com/adamsol/Pyxell#requirements" target="_blank" rel="noopener noreferrer">Github<span> <span>(opens new window)</span></span></a>,
or download Windows binaries from the <a href="https://github.com/adamsol/Pyxell/releases" target="_blank" rel="noopener noreferrer">Releases<span> <span>(opens new window)</span></span></a>.</p> <h2 id="hello-world"><a href="#hello-world">#</a> Hello, world!</h2> <p>If you can run the following code and see the message on the screen, you are ready to start.</p> <h2 id="variables-and-types"><a href="#variables-and-types">#</a> Variables and types</h2> <h3 id="variable-declaration"><a href="#variable-declaration">#</a> Variable declaration</h3> <p>Pyxell is statically typed. Variables have types assigned during compilation.
In most cases, type of an expression is automatically inferred and the value can be directly assigned to a variable.</p> <p>In other cases, when the type cannot be inferred or you want to declare a variable without initializing it, you can set the type explicitly.
When not directly initialized, variable is automatically initialized with the default value for a given type.
You can find the list of all available types and their default values in the <a href="https://www.pyxell.org/docs/specification.html#types">Specification</a>.</p> <p>Variable name must start with a letter, but may also contain digits, underscores, and apostrophes.
Once a variable has been created, its type cannot be changed.</p> <h3 id="type-coercion"><a href="#type-coercion">#</a> Type coercion</h3> <p>Values of some types can be automatically converted to more general types: <code>Int -&gt; Rat -&gt; Float</code> or <code>Char -&gt; String</code>.</p> <p>The coercion doesn't work in the other direction.</p> <h2 id="arithmetic-and-logic"><a href="#arithmetic-and-logic">#</a> Arithmetic and logic</h2> <h3 id="numbers"><a href="#numbers">#</a> Numbers</h3> <p>Standard integers in Pyxell have 64 bits of precision and range from <code>-2^63</code> to <code>2^63-1</code>.
Binary, octal, and hexadecimal literals are supported.</p> <p>Rational numbers have unlimited precision.
They can be written either as integers with <code>r</code> suffix, or non-integers in decimal form.
They are also created as the result of division or exponentiation
(to obtain an integer from a division or exponentiation, use lossy <code>//</code> and <code>^^</code> operators).</p> <p>You can retrieve the numerator and denominator from a rational number.</p> <p>Floating-point numbers have 64 bits of precision and follow the IEEE 754 standard.
They can be written with <code>f</code> suffix or in scientific notation.</p> <p>Underscores can be additionally used in all numeric literals, to enhance readability of long numbers.</p> <h3 id="boolean-values"><a href="#boolean-values">#</a> Boolean values</h3> <p>There are two boolean values: <code>true</code> and <code>false</code>.
Logical negation and short-circuiting conjunction and disjunction operators are available.</p> <p>Boolean values are most often obtained in the result of comparisons.
When comparison operators are chained, they behave as if connected with <code>and</code> operator.</p> <h2 id="characters-and-strings"><a href="#characters-and-strings">#</a> Characters and strings</h2> <h3 id="characters"><a href="#characters">#</a> Characters</h3> <p>Characters are written in single quotes.</p> <p>You can get character's ASCII code, as well as obtain character corresponding to a given integer.</p> <p>You can also perform some arithmetic operations on characters.</p> <h3 id="strings"><a href="#strings">#</a> Strings</h3> <p>Strings are immutable sequences of characters. They are written in double quotes.</p> <p>You can access string's length, as well as its individual characters. Negative indexing and slicing is also supported, like in Python.</p> <p>Strings can be concatenated with <code>+</code> operator and repeated with <code>*</code> operator.</p> <p>You can construct formatted strings using interpolation syntax.</p> <h2 id="control-flow"><a href="#control-flow">#</a> Control flow</h2> <p>Pyxell uses indentation-based syntax, similar to Python's. Only spaces are allowed (tab character will cause a syntax error).
Rather than <code>:</code> character, Pyxell uses <code>do</code> keyword for indicating beginning of a block, and <code>def</code> keyword for function and class definitions.
The scope of a variable declared in a block is limited to that block.</p> <h3 id="if-statement"><a href="#if-statement">#</a> <code>if</code> statement</h3> <p>The first branch whose condition evaluates to <code>true</code> is executed.</p> <h3 id="while-loop"><a href="#while-loop">#</a> <code>while</code> loop</h3> <p>The loop runs while the condition is satisfied.</p> <h3 id="until-loop"><a href="#until-loop">#</a> <code>until</code> loop</h3> <p>This loop is similar to <code>while</code> loop, but it is always executed at least once and runs until the condition is satisfied.</p> <h3 id="for-loop"><a href="#for-loop">#</a> <code>for</code> loop</h3> <p>It can be used to loop over ranges (of numbers or characters) and other iterables.
Range can be inclusive (<code>a..b</code>), exclusive (<code>a...b</code>), or infinite (<code>a...</code>).</p> <p>You can optionally provide a step value, which can be either positive or negative (it is 1 by default).</p> <p>It is possible to loop over multiple iterables at once and provide custom step values to any of them.</p> <h3 id="continue-and-break"><a href="#continue-and-break">#</a> <code>continue</code> and <code>break</code></h3> <p>Inside loops you can use statements to exit the current iteration or the whole loop.</p> <h2 id="containers"><a href="#containers">#</a> Containers</h2> <h3 id="arrays"><a href="#arrays">#</a> Arrays</h3> <p>Arrays are similar to strings, but they are mutable and can have elements of any type.</p> <p>Containers have reference semantics, so they are not implicitly copied when variables are passed.
Mutation of one instance is reflected in all other instances of the same container.</p> <p>When an empty array is used, its type must be explicitly given.</p> <p>Arrays can be concatenated, repeated, and compared using standard operators.</p> <p>You can use array comprehension, as well as range literals and spread operator with optional step.</p> <p>For type safety, containers in Pyxell are invariant, which means they cannot be implicitly converted to another type,
even if types of the elements match (see <a href="https://stackoverflow.com/q/2745265" target="_blank" rel="noopener noreferrer">here<span> <span>(opens new window)</span></span></a> for a broader explanation).
However, container literals can be automatically converted.</p> <h3 id="sets"><a href="#sets">#</a> Sets</h3> <p>Sets contain no duplicates and do not preserve order of elements.</p> <p>Empty set can be created like an empty array.</p> <p>To check if an element is in the set, use <code>in</code> operator.</p> <p>There exist operators for set union, difference, and intersection.</p> <p>Like with arrays, you can use comprehensions, ranges, and spread syntax to create sets.</p> <p>Containers are not hashable, so they cannot be stored in sets.</p> <h3 id="dictionaries"><a href="#dictionaries">#</a> Dictionaries</h3> <p>Dictionaries are hash maps. Like sets, they do not preserve order of elements.
They work similarly to <code>defaultdict</code> in Python: if a key is not present, the default value for a given type is automatically created in the dictionary.</p> <p>Empty dictionary literal has an additional colon.</p> <p>Use <code>in</code> operator for checking if the dictionary contains a given key.</p> <p>Dictionaries can be merged with <code>+</code> operator. In the case of repeated keys, the second value wins.</p> <p>Dictionary comprehension works similarly to array and set comprehension.</p> <p>When iterated over, dictionaries produce pairs of key and value.</p> <p>Spread operator for dictionaries consists of an extra colon.</p> <h2 id="nullable-types"><a href="#nullable-types">#</a> Nullable types</h2> <p>To accept <code>null</code> value, variable's type must be explicitly marked as nullable.</p> <p>You can either directly check if a value is <code>null</code>, or use special coalescing and conditional operators.</p> <p>There is also an operator to directly retrieve the value, for cases when you are sure it is not null.</p> <h2 id="tuples"><a href="#tuples">#</a> Tuples</h2> <p>Two or more values separated with a comma (outside of a container, function call, and print statement) form a tuple.</p> <p>Values can be retrieved using alphabetical properties or tuple destructuring (unneeded part can be discarded with an underscore).</p> <p>Tuples are mutable, but they have value semantics, so they are hashable and can be passed around as if they were immutable.</p> <h2 id="functions"><a href="#functions">#</a> Functions</h2> <h3 id="function-definition-and-call"><a href="#function-definition-and-call">#</a> Function definition and call</h3> <p>Basic definition of a function consists of its name, list of arguments, return type, and body.</p> <p>When a function does not return anything, the return type may be written as <code>Void</code> or may be omitted completely.</p> <p>You can provide default values for optional arguments.
The expressions will be evaluated every time the function is called (if they are needed), so mutable container literals can be safely used.</p> <p>Arguments can be also passed in any order using their names.</p> <p>Variadic functions are supported too. This is just a syntactic sugar for passing an array.
Ranges and spread syntax can be used when such a function is called.</p> <p>Functions can be stored in variables, passed to other functions as arguments, etc.
However, when a function is converted to a variable, all information about its arguments except for their types is lost.</p> <h3 id="generic-functions"><a href="#generic-functions">#</a> Generic functions</h3> <p>Generic functions are standard functions with additional type variables, which can be used just like normal types.
They are compiled independently for each combination of types they are called with.</p> <p>Function declaration may contain default values for generic arguments, and the body may contain any code dependent on the real types.
Errors will be reported when the function cannot be compiled with given types.</p> <p>When a type name is used more than once, the compiler will try to unify types of the arguments, following the coercion rules.</p> <h3 id="lambda-functions"><a href="#lambda-functions">#</a> Lambda functions</h3> <p>Lambda is a simpler version of generic function, where all arguments, as well as the return type, are generic.</p> <p>You can use placeholder syntax to write even more concise functions. Each underscore corresponds to one argument.</p> <p>Placeholder resolving doesn't run through function calls by default (placeholders inside a function call form their own functions for corresponding arguments).
To create a partial function, add <code>@</code> character.</p> <p>Lambdas can also be multi-line, so that you can define normal functions without any type annotations.</p> <p>Note that lambda functions currently work only with arguments of known types.
You cannot pass a lambda function to another lambda function.
In the case of functional arguments, it's better to use the full generic definition instead.</p> <h3 id="generators"><a href="#generators">#</a> Generators</h3> <p>Generator is a function producing a sequence of values that can be iterated over without storing it in memory.
To create a generator, add an asterisk symbol to the function definition.</p> <p>Lambdas can be generators as well.</p> <p>Note that generators are currently supported only with Clang.</p> <h2 id="classes"><a href="#classes">#</a> Classes</h2> <h3 id="class-definition-and-object-construction"><a href="#class-definition-and-object-construction">#</a> Class definition and object construction</h3> <p>Definition of a class consists of its name and list of fields.
Each field may have an explicit default value; if not provided, it will be the default value for a given type.</p> <p>Every class has a default constructor function that accepts field values in the order of definition, or as named arguments.
Fields not directly initialized will receive their default values.</p> <p>Remember that class objects must always be explicitly constructed before use (they have no valid default ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pyxell.org/docs/manual.html">https://www.pyxell.org/docs/manual.html</a></em></p>]]>
            </description>
            <link>https://www.pyxell.org/docs/manual.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066058</guid>
            <pubDate>Thu, 12 Nov 2020 03:25:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complete Guide to PyTorch for Data Scientists]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065771">thread link</a>) | @shirappu
<br/>
November 11, 2020 | https://mlwhiz.com/blog/2020/09/09/pytorch_guide/ | <a href="https://web.archive.org/web/*/https://mlwhiz.com/blog/2020/09/09/pytorch_guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>PyTorch</strong></em> has sort of became one of the de facto standards for creating Neural Networks now, and I love its interface. Yet, it is somehow a little difficult for beginners to get a hold of.</p><p>I remember picking PyTorch up only after some extensive experimentation a couple of years back. To tell you the truth, it took me a lot of time to pick it up but am I glad that I moved from
<a href="https://towardsdatascience.com/moving-from-keras-to-pytorch-f0d4fff4ce79" target="_blank" rel="nofollow noopener">Keras to PyTorch</a>
. With its high customizability and pythonic syntax,PyTorch is just a joy to work with, and I would recommend it to anyone who wants to do some heavy lifting with Deep Learning.</p><p>So, in this PyTorch guide, <em><strong>I will try to ease some of the pain with PyTorch for starters</strong></em> and go through some of the most important classes and modules that you will require while creating any Neural Network with Pytorch.</p><p>But, that is not to say that this is aimed at beginners only as <em><strong>I will also talk about the</strong></em> <em><strong>high customizability PyTorch provides and will talk about custom Layers, Datasets, Dataloaders, and Loss functions</strong></em>.</p><p>So let‚Äôs get some coffee ‚òï Ô∏èand start it up.</p><hr><h2 id="tensors">Tensors</h2><p>Tensors are the basic building blocks in PyTorch and put very simply, they are NumPy arrays but on GPU. In this part, I will list down some of the most used operations we can use while working with Tensors. This is by no means an exhaustive list of operations you can do with Tensors, but it is helpful to understand what tensors are before going towards the more exciting parts.</p><h3 id="1-create-a-tensor">1. Create a Tensor</h3><p>We can create a PyTorch tensor in multiple ways. This includes converting to tensor from a NumPy array. Below is just a small gist with some examples to start with, but you can do a whole lot of
<a href="https://pytorch.org/docs/stable/tensors.html" target="_blank" rel="nofollow noopener">more things</a>
with tensors just like you can do with NumPy arrays.</p><div><pre><code data-lang="py"><span># Using torch.Tensor</span>
t <span>=</span> torch<span>.</span>Tensor([[<span>1</span>,<span>2</span>,<span>3</span>],[<span>3</span>,<span>4</span>,<span>5</span>]])
<span>print</span>(f<span>"Created Tensor Using torch.Tensor:</span><span>\n</span><span>{t}"</span>)

<span># Using torch.randn</span>
t <span>=</span> torch<span>.</span>randn(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.randn:</span><span>\n</span><span>{t}"</span>)

<span># using torch.[ones|zeros](*size)</span>
t <span>=</span> torch<span>.</span>ones(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.ones:</span><span>\n</span><span>{t}"</span>)
t <span>=</span> torch<span>.</span>zeros(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.zeros:</span><span>\n</span><span>{t}"</span>)

<span># using torch.randint - a tensor of size 4,5 with entries between 0 and 10(excluded)</span>
t <span>=</span> torch<span>.</span>randint(low <span>=</span> <span>0</span>,high <span>=</span> <span>10</span>,size <span>=</span> (<span>4</span>,<span>5</span>))
<span>print</span>(f<span>"Created Tensor Using torch.randint:</span><span>\n</span><span>{t}"</span>)

<span># Using from_numpy to convert from Numpy Array to Tensor</span>
a <span>=</span> np<span>.</span>array([[<span>1</span>,<span>2</span>,<span>3</span>],[<span>3</span>,<span>4</span>,<span>5</span>]])
t <span>=</span> torch<span>.</span>from_numpy(a)
<span>print</span>(f<span>"Convert to Tensor From Numpy Array:</span><span>\n</span><span>{t}"</span>)

<span># Using .numpy() to convert from Tensor to Numpy array</span>
t <span>=</span> t<span>.</span>numpy()
<span>print</span>(f<span>"Convert to Numpy Array From Tensor:</span><span>\n</span><span>{t}"</span>)
</code></pre></div><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/0.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><h3 id="2-tensor-operations">2. Tensor Operations</h3><p>Again, there are a lot of operations you can do on these tensors. The full list of functions can be found
<a href="https://pytorch.org/docs/stable/torch.html?highlight=mm#math-operations" target="_blank" rel="nofollow noopener">here</a>
.</p><div><pre><code data-lang="py">A <span>=</span> torch<span>.</span>randn(<span>3</span>,<span>4</span>)
W <span>=</span> torch<span>.</span>randn(<span>4</span>,<span>2</span>)
<span># Multiply Matrix A and W</span>
t <span>=</span> A<span>.</span>mm(W)
<span>print</span>(f<span>"Created Tensor t by Multiplying A and W:</span><span>\n</span><span>{t}"</span>)
<span># Transpose Tensor t</span>
t <span>=</span> t<span>.</span>t()
<span>print</span>(f<span>"Transpose of Tensor t:</span><span>\n</span><span>{t}"</span>)
<span># Square each element of t</span>
t <span>=</span> t<span>**</span><span>2</span>
<span>print</span>(f<span>"Square each element of Tensor t:</span><span>\n</span><span>{t}"</span>)
<span># return the size of a tensor</span>
<span>print</span>(f<span>"Size of Tensor t using .size():</span><span>\n</span><span>{t.size()}"</span>)
</code></pre></div><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/1.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p><strong>Note:</strong> What are PyTorch Variables? In the previous versions of Pytorch, Tensor and Variables used to be different and provided different functionality, but now the Variable API is
<a href="https://pytorch.org/docs/stable/autograd.html#variable-deprecated" target="_blank" rel="nofollow noopener">deprecated</a>
, and all methods for variables work with Tensors. So, if you don‚Äôt know about them, it‚Äôs fine as they re not needed, and if you know them, you can forget about them.</p><hr><h2 id="the-nnmodule">The nn.Module</h2><p>Photo by
<a href="https://unsplash.com/@fernanddecanne?utm_source=medium&amp;utm_medium=referral" target="_blank" rel="nofollow noopener">Fernand De Canne</a>
on
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_1200x0_resize_box_2.png 1200w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_1500x0_resize_box_2.png 1500w" src="https://mlwhiz.com/images/pytorch_guide/2.png" alt="<a href=&quot;https://unsplash.com?utm_source=medium&amp;amp;utm_medium=referral&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;>Unsplash</a>"></p><p>Here comes the fun part as we are now going to talk about some of the most used constructs in Pytorch while creating deep learning projects. nn.Module lets you create your Deep Learning models as a class. You can inherit from nn.Moduleto define any model as a class. Every model class necessarily contains an<code> __init__</code> procedure block and a block for the <code>forward</code> pass.</p><ul><li><p>In the <code>__init__</code> part, the user can define all the layers the network is going to have but doesn‚Äôt yet define how those layers would be connected to each other.</p></li><li><p>In the <code>forward</code> pass block, the user defines how data flows from one layer to another inside the network.</p></li></ul><p>So, put simply, any network we define will look like:</p><div><pre><code data-lang="py"><span>class</span> <span>myNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> nn<span>.</span>Linear(<span>784</span>, <span>30</span>)
        self<span>.</span>lin2 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>10</span>)
    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x <span>=</span> self<span>.</span>lin1(x)
        x <span>=</span> self<span>.</span>lin2(x)
        <span>return</span> x
</code></pre></div><p>Here we have defined a very simple Network that takes an input of size 784 and passes it through two linear layers in a sequential manner. But the thing to note is that we can define any sort of calculation while defining the forward pass, and that makes PyTorch highly customizable for research purposes. For example, in our crazy experimentation mode, we might have used the below network where we arbitrarily attach our layers. Here we send back the output from the second linear layer back again to the first one after adding the input to it(skip connection) back again(I honestly don‚Äôt know what that will do).</p><div><pre><code data-lang="py"><span>class</span> <span>myCrazyNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> nn<span>.</span>Linear(<span>784</span>, <span>30</span>)
        self<span>.</span>lin2 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>784</span>)
        self<span>.</span>lin3 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>10</span>)

    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x_lin1 <span>=</span> self<span>.</span>lin1(x)
        x_lin2 <span>=</span> x <span>+</span> self<span>.</span>lin2(x_lin1)
        x_lin2 <span>=</span> self<span>.</span>lin1(x_lin2)
        x <span>=</span> self<span>.</span>lin3(x_lin2)
        <span>return</span> x
</code></pre></div><p>We can also check if the neural network forward pass works. I usually do that by first creating some random input and just passing that through the network I have created.</p><div><pre><code data-lang="py">x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>784</span>))
model <span>=</span> myCrazyNeuralNet()
model(x)<span>.</span>size()
<span>--------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>10</span>])
</code></pre></div><hr><h2 id="a-word-about-layers">A word about Layers</h2><p>Pytorch is pretty powerful, and you can actually create any new experimental layer by yourself using <code>nn.Module</code>. For example, rather than using the predefined Linear Layer <code>nn.Linear</code> from Pytorch above, we could have created our <strong>custom linear layer</strong>.</p><div><pre><code data-lang="py"><span>class</span> <span>myCustomLinearLayer</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self,in_size,out_size):
        super()<span>.</span>__init__()
        self<span>.</span>weights <span>=</span> nn<span>.</span>Parameter(torch<span>.</span>randn(in_size, out_size))
        self<span>.</span>bias <span>=</span> nn<span>.</span>Parameter(torch<span>.</span>zeros(out_size))
    <span>def</span> <span>forward</span>(self, x):
        <span>return</span> x<span>.</span>mm(self<span>.</span>weights) <span>+</span> self<span>.</span>bias
</code></pre></div><p>You can see how we wrap our weights tensor in nn.Parameter. This is done to make the tensor to be considered as a model parameter. From PyTorch
<a href="https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter" target="_blank" rel="nofollow noopener">docs</a>
:</p><blockquote><p>Parameters are
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="nofollow noopener">&lt;code&gt;*Tensor*&lt;/code&gt;</a>
subclasses, that have a very special property when used with <em>Module</em> - when they‚Äôre assigned as Module attributes they are automatically added to the list of its parameters, and will appear in <em><code>parameters()</code></em> iterator</p></blockquote><p>As you will later see, the <code>model.parameters()</code> iterator will be an input to the optimizer. But more on that later.</p><p>Right now, we can now use this custom layer in any PyTorch network, just like any other layer.</p><div><pre><code data-lang="py"><span>class</span> <span>myCustomNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> myCustomLinearLayer(<span>784</span>,<span>10</span>)

    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x <span>=</span> self<span>.</span>lin1(x)
        <span>return</span> x
x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>784</span>))
model <span>=</span> myCustomNeuralNet()
model(x)<span>.</span>size()
<span>------------------------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>10</span>])
</code></pre></div><p>But then again, Pytorch would not be so widely used if it didn‚Äôt provide a lot of ready to made layers used very frequently in wide varieties of Neural Network architectures. Some examples are:
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" target="_blank" rel="nofollow noopener">nn.Linear</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" target="_blank" rel="nofollow noopener">nn.Conv2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" target="_blank" rel="nofollow noopener">nn.MaxPool2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" target="_blank" rel="nofollow noopener">nn.ReLU</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d" target="_blank" rel="nofollow noopener">nn.BatchNorm2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" target="_blank" rel="nofollow noopener">nn.Dropout</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" target="_blank" rel="nofollow noopener">nn.Embedding</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU" target="_blank" rel="nofollow noopener">nn.GRU</a>
/
<a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM" target="_blank" rel="nofollow noopener">nn.LSTM</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax" target="_blank" rel="nofollow noopener">nn.Softmax</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax" target="_blank" rel="nofollow noopener">nn.LogSoftmax</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention" target="_blank" rel="nofollow noopener">nn.MultiheadAttention</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html#torch.nn.TransformerEncoder" target="_blank" rel="nofollow noopener">nn.TransformerEncoder</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html#torch.nn.TransformerDecoder" target="_blank" rel="nofollow noopener">nn.TransformerDecoder</a></p><p>I have linked all the layers to their source where you could read all about them, but to show how I usually try to understand a layer and read the docs, I would try to look at a very simple convolutional layer here.</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/3.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p>So, a Conv2d Layer needs as input an Image of height H and width W, with <code>Cin</code> channels. Now, for the first layer in a convnet, the number of <code>in_channels</code> would be 3(RGB), and the number of <code>out_channels</code> can be defined by the user. The <code>kernel_size</code> mostly used is 3x3, and the <code>stride</code> normally used is 1.</p><p>To check a new layer which I don‚Äôt know much about, I usually try to see the input as well as output for the layer like below where I would first initialize the layer:</p><div><pre><code data-lang="py">conv_layer <span>=</span> nn<span>.</span>Conv2d(in_channels <span>=</span> <span>3</span>, out_channels <span>=</span> <span>64</span>, kernel_size <span>=</span> (<span>3</span>,<span>3</span>), stride <span>=</span> <span>1</span>, padding<span>=</span><span>1</span>)
</code></pre></div><p>And then pass some random input through it. Here 100 is the batch size.</p><div><pre><code data-lang="py">x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>3</span>,<span>24</span>,<span>24</span>))
conv_layer(x)<span>.</span>size()
<span>--------------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>64</span>, <span>24</span>, <span>24</span>])
</code></pre></div><p>So, we get the output from the convolution operation as required, and I have sufficient information on how to use this layer in any Neural Network I design.</p><hr><h2 id="datasets-and-dataloaders">Datasets and DataLoaders</h2><p>How would we pass data to our Neural nets while training or while testing? We can definitely pass tensors as we have done above, but Pytorch also provides us with pre-built Datasets to make it easier for us to pass data to our neural nets. You can check out the complete list of datasets provided at
<a href="https://pytorch.org/docs/stable/torchvision/datasets.html" target="_blank" rel="nofollow noopener">torchvision.datasets</a>
and
<a href="https://pytorch.org/text/datasets.html" target="_blank" rel="nofollow noopener">torchtext.datasets</a>
. But, to give a concrete example for datasets, let‚Äôs say we had to pass images to an Image Neural net using a folder which has images in this structure:</p><pre><code>data
    train
        sailboat
        kayak
        .
        .
</code></pre><p>We can use torchvision.datasets.ImageFolder dataset to get an example image like below:</p><div><pre><code data-lang="py"><span>from</span> torchvision <span>import</span> transforms
<span>from</span> torchvision.datasets <span>import</span> ImageFolder
traindir <span>=</span> <span>"data/train/"</span>
t <span>=</span> transforms<span>.</span>Compose([
        transforms<span>.</span>Resize(size<span>=</span><span>256</span>),
    transforms<span>.</span>CenterCrop(size<span>=</span><span>224</span>),
        transforms<span>.</span>ToTensor()])
train_dataset <span>=</span> ImageFolder(root<span>=</span>traindir,transform<span>=</span>t)
<span>print</span>(‚Ä¶</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mlwhiz.com/blog/2020/09/09/pytorch_guide/">https://mlwhiz.com/blog/2020/09/09/pytorch_guide/</a></em></p>]]>
            </description>
            <link>https://mlwhiz.com/blog/2020/09/09/pytorch_guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065771</guid>
            <pubDate>Thu, 12 Nov 2020 02:30:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fastest Way of Computing All Universes (2012) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065400">thread link</a>) | @optimalsolver
<br/>
November 11, 2020 | http://people.idsia.ch/~juergen/fastestuniverse.pdf | <a href="https://web.archive.org/web/*/http://people.idsia.ch/~juergen/fastestuniverse.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>√§√àh√ìY2_√ä¬≤√©[le√≥≈í‚Äö√∑*L√äx√§√±√é√£√â√á√É‚Ç¨√éd≈Ω√≠√¢¬¢S√º
√ß√Æl'8√∫}GV¬≥¬±¬Øz‚Ç¨‚Äû{@≈°√ÉRX√îB√ä‚Ç¨3¬¥¬£\ÀÜ√å≈ΩÔøΩe3∆í9‚Ñ¢√∫P%‚Äò'¬ªO]D?Al√à√ø‚Äô¬πf¬ßÀÜÀÜY=¬≥{‚Äô√ÇJ√òEy‚Ä†√≥6√ã√Ω`√Ø
lh&lt;√üt{√†T_¬±√£E‚Äò¬¶¬∞
¬¥"‚Ç¨∆í‚Äû‚Ä∫√ö?√ö√Ç¬™z‚Äû√¨√ÜFe√àÔøΩ√®U#¬Æ#qR¬¢√∫LG√ú√πa¬æ√ò)
√ò‚Ä∞F√¶√å\$√Ñn√ø¬©√ÆE¬¥≈°√∏√∑√£¬£‚Ä∞+4√è‚Ä°√ê¬¨¬≥¬∂A¬®-√±√à¬π√´j√†]ÔøΩ√ë¬¶a!√Ø√∂√π√Å√èi8Q	0)ÔøΩ√©eFx¬∫‚Äû¬º√¨]‚Äò√åI+√¥√ò'_√î)‚Ä†√é!√π√ß"r‚Äô√†√ê√Ñ0√∞0L√®√ù√ò¬ºy√†#RZbV√Ω~&amp;6√êA7√ç√§h6¬±√Ü		¬§√Å.¬Ω√û√äÀÜR√è)¬∫¬•√û≈ΩT¬∂√îN`=DÔøΩ4C¬ßEY¬™1¬ª¬π2¬°CM√∞ÔøΩ¬§b√ú√Å√Å√Æ85¬°b√¨√ÖDl6e‚Äòj√¨¬º√ë¬º8¬º√®LB≈í7√°~LÀú¬≤‚Äì¬ø√ä√ù‚Ä∞D√©	K%‚Ä†¬∑&gt;¬∏KÔøΩ √∫
√≤≈†(D√àkX√â√≥√É3‚Äû{‚Ä¶‚Ñ¢≈ΩJ‚Ä¢√ù¬≤!m√¥Sb4¬∑!√ÜÀú¬¥F‚Äò√®ÀÜ√ó(|ÀÜ"√ã‚Ñ¢N¬∞&nbsp;√ºq68≈°√ö√µ‚Ä¶√•mÔøΩ,√Øy@
¬∞‚Äî√ç
{‚Ä∞ByG8√ë'√∑2√±v¬º7√ï¬®¬¥√é¬∂*ÔøΩ}√é∆í√¶¬°√π√™Y^aE0√ô5i¬∞;$√áD√±	x¬º4√ßÀÜtC√á=√ê0√ü¬≠‚Ä∫Q√è2√ä≈°!~f¬£]√∞√ù]Àú8√´('&gt;=Àú√ü¬™`√ª≈í*√®[]‚Äì&amp;vW√°‚Äû√†]P,K√®w√§√ô¬º‚Ä∞44_√à¬π
&lt;¬¢W¬º_√ï√•√è√â√û9¬°√∞ESI=gF‚Äò7√µ]√ï¬ªj¬°on√º√ö√¨¬¥/~≈æ√ì&gt;√â√©¬π¬¶YqB/P2¬ß√Ω0‚Ñ¢√ë¬∂5et¬≠‚Äπ¬¶*y‚Äò√µq√ã¬Æ$√üp~√í‚Äù√É¬¢&gt;¬∫@√ãP¬º‚Ñ¢v√õÔøΩ$P&amp;YcW√£B√ô‚Ä∞≈æs¬ß√∫√ú¬Æ√©¬´‚ÄìRY¬π√∫A√ù√Å√µ%√π√•√¨‚Ä°‚Äì√µ√¥@3¬≠√ô≈°√õ1oD√è√¨6 E√µ¬£‚Ä¶¬≥
"‚Äòa√õ‚Äìbn√ñ√ñ√™≈æ¬∫H√ô‚ÄöGqwnrm?u√≥¬ÆjÔøΩ¬∏.B√é‚Äòh.Z≈æj√å√∂¬æJ Àú√úN^√äx√ç¬§e√Ö√´Fj]%√™√∂‚Äùx,√ì&amp;~√ù‚Ä¢√∞¬¢n‚Äô≈†‚ÄπD√ç√Ñ≈ís√°√æ¬™P√¶|
ÔøΩ;ÔøΩ√æ_
X;YJ{p√©Z¬∫i¬≥;7¬Ø¬Ω¬•√∫¬±≈°‚Ä¶S√é√æE√øf‚Ä°¬§M
√ö¬µ‚ÄötGt‚Ä†¬¥Cj√µ¬´¬º√ût‚Ñ¢k√ï¬≠√Ö¬®≈ì¬Æ¬º√éTj}≈ì√™√û{q6g√ºJw¬±√∞√Ç9√¢"¬Ø√ë¬º‚Äûc√æ√ç√∑¬æ‚Äì\D√≥√ú√öK√Å√ª‚Ä∞√¶¬ª6H√ø√ïqcokC{‚Ä¢_[R‚ÄìÔøΩ¬ª¬§¬∏ ‚Äû¬´B7E¬∞≈Ω¬™√π^√≠√æ¬°OdÔøΩ≈∏¬π4√Æo\SÔøΩ√®¬™√≠*√∫√â‚Ñ¢√∂≈†√Ö+ &amp;√¶X(√£¬¢&amp;WF¬ø¬¶√ätCU√Ñ‚Äö,‚Ä¢4‚Äò}'√ï8√∂√é]√•¬∫G√Å√ü√õW
‚Äô¬∑√ï0¬¢Zx)3‚Äπp¬£‚Äú2t√è√∫¬¨‚Ç¨√ï,√Å√∂‚Äú√∂≈†Z:)i√∏√ç‚Äùo‚Äìh¬§√•≈í√ßÀú√Æ;¬≠‚Äö|√á√üYxXk√àÀÜ√ê√¥U√ü√àGo‚Ä∫‚Ç¨√§ÔøΩ¬™√∑h√π√ç¬¢:√õ¬™¬´8‚Ñ¢T‚Ä¢,√çefR)‚Ä¶r√§‚Äû¬¢‚ÄùxI1E√óÀú‚Äπ‚Äîx8ÔøΩVDF¬∫¬™F√≤≈°o√ó:√´}√ät6≈†√Æ%√≥e¬Ø‚Ä†√µ√£v‚Ä∞√êU,Y¬¶0ÔøΩÔøΩ√Çh¬∑≈∏√±√ø√ú√£c≈Ωpx-√¨¬∂√®√ß%‚Äú√±¬Æ√π√ú¬≠√Ü√©√à0O√Ñ√¥D¬Ω8√¶m¬°√ûNÀúP√ÇXHB≈Ω√ò‚Äú¬´√ö‚Ä∞a.√ª9fÀÜÔøΩ¬≠‚ÄöN!!U:¬ª7√•‚Äò-p‚Ä†¬∏√æ=√ë√ß&gt;¬¢r0J≈†¬∑√å‚Äô	2¬≥!√éA√É‚Äö√∫S@√ë@‚Ç¨¬™∆í√∫¬Ωm&amp;f7/≈†E‚Äì`b7&lt;¬≤√ª	]√¥13	u‚Ä∞E‚Ñ¢√ñ√∞9/≈°√ã0√¥*7√§¬´a¬•^√á8D√Ü√¨√ñ
√©√Üp√∞)≈í¬•√Ü√ç√æ@
√¢√Ωee¬≠n√ª√∑√©"‚Ä∫¬±≈ì√Øn√∂v√ß}ÔøΩ
√Ñp¬Ø¬¶ÔøΩ¬µb√òa√Æ¬¥K1i√≠%r√Ω√µ√¢¬ø3ds√ë$?¬°&nbsp;x√Øx≈ì√ºXne~√õ¬æ√•ÔøΩ¬•V√¥√å
I√äy‚Ä∞√íj√¥i'=√®‚Äö√õ≈°ÔøΩ√ò‚Äπ‚Ç¨a¬æZ ro√à√±¬©√†j√±√î√èM‚Ç¨√¥18c√ã√æ¬∏√Ü√ê√±M√£√ïgÔøΩ‚Äî!Àúq¬µ√∞.√ä¬Ω¬¶H√é√Å
ÔøΩ√Ö√°J≈Ω'√¥=¬π i√õ√™√î√´0pÔøΩ+%‚Ä¶‚Äì7‚Äìw¬≠√£¬•p¬®w¬∑¬º¬¢ÔøΩ√•≈Ω‚ÄùCSKt√´¬¢-Rcy√¢n"¬™¬∑H√µ0/√ï)√Å7√Üv√ôJUIzÀúlY√ß≈í	hz√ô√®p&nbsp;^ÔøΩ&gt;¬©√ä‚Äπ!7√ô√ï¬•√©‚Äû√Æ≈∏q‚Ä†3ÔøΩ
$QK≈Ω4/√¥&nbsp;LAÔøΩ√≠s&gt;¬´[√†K√µz‚Ä¢√ú¬ª√´.√ë√°c√èf√ú√åT-¬°¬Ø¬£¬™}R!ÔøΩ√≠^¬≥¬™√ö√§√Æ√∞¬≤]Z√†-
≈íT√ØR√±q√∏≈æ@eZ√èy¬±"‚Äπi¬¶¬§‚Ñ¢M¬™¬¨¬™0¬Øj‚Äú‚Äπ
3≈ì*√≤‚Äì4√á√åÀúVy¬Ωp‚Äî¬æ√Ü√ú‚Äö√ï√≤gY|bÀÜ¬Æ‚Äú&gt;¬∞i√â[-√á#√°√áR-"B√ô2¬°^¬®≈∏‚Ä¢≈†ÔøΩ\√Üj4√Ée√¨&amp;s1√±)eS&lt;+‚Äπ‚Äô3$n¬°√∂w1Rw}^¬§x√ê¬∂&nbsp;≈ì4ÔøΩ}√á=WÔøΩs¬®‚Ä∫9ÀÜ√ßj¬≠√ô√è"√π≈Ωs¬•l√Ñ:√º√∏‚Ä†1√µld=√Ñ[ÔøΩ¬∫ÀúÔøΩ√íbg¬•¬∂√ßL¬´√â√ò√ì√ë?Q√®¬°√¶√ñ¬™9√ñg≈∏G√í¬§√ÖÀú√≥√ß√ß‚Ç¨√ê¬°ÔøΩ¬°3¬©OSc√èB√ûTT}≈†√á8!√å¬Ø,NW#PÔøΩC√é¬π√∫¬Æ/√ñ‚Ç¨,(=√¨6j√∏r√çw√∫√¥√ÑÔøΩ|e√û¬¨h¬∞d^)‚Ä∫YY
¬¥‚Äì^¬ø√à=	j‚Ñ¢√±√°b
¬Æ√ô-ÔøΩy√ßyu(ÔøΩ¬®¬¨r;¬©√™e¬∑√ãj,√ÜJ3¬¥√∏√öd√ö√∑ÔøΩ¬≤≈í¬•G≈ím¬´¬™√Ω5‚Ä°q¬πd¬µ9¬©-¬¶√ç¬πkÔøΩ‚Ä¢¬∂¬ß√±‚Äû≈æ+√≤‚Äìl6√Ω&lt;9MPw√±R√∂¬¢y√Ü√ãT√∂p
K‚Äπ[ukb≈†¬∂ÔøΩ√™*4?Yq√ø$¬¢¬´‚Äô¬±1&gt;w"√ö‚Ä°S√ù√É¬±_np#√´¬Ω2√Æ‚Ä∫"√ï¬Æ√¶jÔøΩ≈æ¬Ω≈Ωd¬∂‚ÄùS¬∂¬™¬∏ow!ÔøΩ√™OPrR√ê√ë$√¢√ç√∑√ñ<l}k&r>√πÔøΩd√ë24√Ø√é√•‚Äô+√ç;X-≈†¬•x‚Äî√úÔøΩ√±¬•j√ì¬ø√Æ√è≈æ‚ÄùuC8)√ñxÔøΩ&nbsp;¬∫‚Ä¢m3¬æÔøΩW√âsRM8‚Ä¶√ª‚Ä∞T‚Äπ2d¬º¬¢¬§√†z‚Äπ‚Äπ√∫¬¢√öq√Ü(g&nbsp;√Æ‚ÄúÔøΩ√∫V√ã`¬•√â‚Äô ¬ª6¬Ø!=¬µ7√í*‚Äû¬§w"~¬π‚Äû‚Äôe‚Ä∫8ybJ‚Äö*6¬≠√∑ ¬Ω‚Ä°¬π√πi‚Äú∆í√º≈ì¬π√¢LK√Ç‚Äú]√¶‚ÄôE√Ö¬¨√Ä&nbsp;¬Æ([√ê√Ø√≤√∂√àz_T‚Ñ¢u¬¨ÔøΩ¬£2√∏√∑¬Ω√æ|√ë$√ü‚Äπ¬ø_~\√æ¬∑√û‚Äô[
endstream
endobj
4 0 obj
   3245
endobj
2 0 obj
&lt;&lt;
   /ExtGState &lt;&lt;
      /a0 &lt;&lt; /CA 1 /ca 1 &gt;&gt;
   &gt;&gt;
   /Font &lt;&lt;
      /f-0-0 5 0 R
      /f-1-0 6 0 R
      /f-2-0 7 0 R
      /f-3-0 8 0 R
      /f-4-0 9 0 R
      /f-5-0 10 0 R
      /f-6-0 11 0 R
      /f-7-0 12 0 R
      /f-8-0 13 0 R
   &gt;&gt;
&gt;&gt;
endobj
14 0 obj
&lt;&lt; /Type /Page
   /Parent 1 0 R
   /MediaBox [ 0 0 611.999983 791.999983 ]
   /Contents 3 0 R
   /Group &lt;&lt;
      /Type /Group
      /S /Transparency
      /CS /DeviceRGB
   &gt;&gt;
   /Resources 2 0 R
&gt;&gt;
endobj
16 0 obj
&lt;&lt; /Length 17 0 R
   /Filter /FlateDecode
&gt;&gt;
stream
x≈ì‚Ä¢Z√â≈†4√á¬æ√óS√¥L+√∑‚Ä†&gt;‚ÄûA√†∆í√¨~|√®¬Æ≈æ√ã √π√†√ów|¬±df√çt[2B√≥WeeFF√Ü√≤√Ö‚Äô√Ω√´√¶N¬µ‚Ä°S√±√æ√¥R¬ª?√Ω√∂~√∫√ª√©_4≈†√ø~√ª√©√¥√ù√ïÔøΩ~√∫√∑√∂¬ß¬∑¬≠≈ì{ÔøΩÔøΩ√á√µ¬±¬ªs-¬Ω√∑z*C¬•¬∑xz√ªe√ª√Æ√£√Ö¬Ω¬∏‚Äú?¬Ω}l√ü^ÔøΩw√°√∫¬´‚Äπ‚Äî‚ÄîÀú√ì¬´K‚Äî√ø√™√≤‚Ä¶√ær‚Ä¢√±√ù‚Ä¢‚Ç¨¬∑1¬±o√Æ√äo√ó√ã?√û~√ò|?¬∑√ñ#¬±√≤v√á¬∑Kh¬Øn¬øD√∑√™√Æ√Æ√ù}]√Ø¬º√á*ÀÜ‚Ä†ÔøΩ&gt;√π&lt;_?zÔøΩY7√∫≈Ω√≠√©#√Ü#;&gt;√¶We√Ç;3√∞√Æo~√∑z√ó√ü}√∞I≈∏u√≥√†6¬ø¬°≈∏k,√ô√∏
	`C¬®√∫ÔøΩC$√í√ô‚Ä¶ÔøΩh‚Äú‚Äû√ï4Yb√Æ"3q√á√¥¬¢≈íb∆í√Ø√üTe√Ω√≥√âÔøΩC√Ø¬ß√ø√ê√Ä√¥√ø√è√õ¬∑√êÔøΩ;√ù7√ØN9√ΩJz√ÅD√º%‚Ä¶≈∏IP√õ√æ√ã√ñ√Ç¬π¬ß~z√±¬æ≈ìc√ç¬ß_N6√í√É9√∑√ø&lt;√Ω√≠√¥√£√∂≈ì@g√ß√±{#5≈∏{XF~‚Äî)6I√§√è√©√ø¬£A√ú¬∂¬∂≈æc√Ω√Å∆í√ò¬π‚Ä∫s√ßT√£"‚Ä∞J‚Ä†≈æK√∏√É¬¢ ≈∏8‚Ä°¬∏≈†√ÇF√æ√∞1&amp;c√®s?√±ae√¢¬¨!~√¶c√∏;9z%WvBR}√å√ßÀú[√Ø‚Ä¶‚Ç¨¬¢≈æc¬Ωe√µ√¥f≈æ√é≈ΩNN√æ√∂3‚Ä†¬ª
√ì√º∆í¬£¬£‚Ä∫¬≥^b#¬∑ÔøΩ√§√∏√ôW]¬£;97√Ä√†F&gt;‚Ä∫√Æ√ß^x‚Ñ¢;√©√£√ÇGn√≠√ú‚Ä∫√´¬≠(aA≈ì‚Ä∫#<sw√Ø. ¬°‚Äô¬∑√ÄubÀÜ¬Ø√Ñvxsp√Øp∆í√®√ç√ùh6¬π¬¢¬º√ü7≈°≈°√ún~"6ÔøΩÔøΩ√ä;w√É‚Ä¢√à√ë√∑¬ª&¬ºr√∑%t¬•√ç√û√´‚Äô‚Äö≈ì¬∫¬¨√õ7√óvx="">‚Äòa√ò√Ä≈†√¢√û‚Ä∞√ù√ö‚Äòa)√¶√∞l‚Ñ¢√ßF¬¥4n¬¥y√º¬¥G&nbsp;√≥¬¶√§/z@¬∑‚Ä°N,A≈°≈Ω√Ä@‚Äö=‚Ç¨YBDZC√ÄG¬∏√ÜgyaZ√æ5&amp;‚Ä¶%√∫	¬Ø‚Ä∞M¬≤K√ùmc¬π√†5‚Äúhy=√≠√°¬ªJÔøΩ9√û]W√±`6t√¨√¥ÔøΩ‚Ä¢2≈Ω√†√ù¬¶√´√â v√ñX√¶√¥S√ê(¬´bd‚Ñ¢√Æ5≈°P√ê(√ÇnC√ó¬π≈∏h-M√ÅD√ß≈ì‚Ä†‚ÄùI√üI≈°b√ä√û,‚ÄπfBuEM¬π√π√õ√•¬•8√µ‚Ä°ÔøΩkX¬æ√í+ÔøΩ8/Àú)6√Ü&nbsp;
¬§√£√∞‚Äò≈íÔøΩ
√°√ö‚Ä∞m√ö¬∏&gt;√ñ‚Äö√â√ï√Ä‚Ñ¢ÔøΩ√®K.I5√πÔøΩ√ß√™ √ö‚ÄπBV‚Äû[up‚ÄûahO'¬§s√à√†s√®&nbsp;L¬π¬∞m√ë√õ√©Xz√•X)√´%jN:W√µ‚Ä¶4f√ü¬ß&amp;yF≈∏&amp;J4%¬§y√ô√ã√±'0^√îX√ó∆í√´¬∫√à√â&lt;√ãP¬Ω_¬£(;¬ß¬¢o¬§X≈∏√ü≈∏√ò;‚Ä∞√¥√òÔøΩ√â√ñ‚Ñ¢"‚Ä†Àúj‚Ä¶‚Ä∞VF√û0"x¬°√è"√öB¬¢ÔøΩN√ç&lt;√∫
≈Ω√ó*}*‚ÄîY XSL‚Ä¢¬∂eaOO√Ö1|\m?√ï√ÜG!&amp;
¬±Z√û√û√ò¬∏N#+&amp;√¢!√º9	G≈°d√Ö¬°∆íp}$0.0√µ¬Ø	≈æ√è√±L√ûR√ú¬°√®‚Ä∫z√´≈†¬∑e√¢~¬¢C√ê√∫x]
√Ö√ö.√ì√∫t¬Æ¬µ√è√µ¬º≈æ√ê‚Ä∫jb¬®∆íP√®¬ø‚Ä∫≈íÔøΩ);&lt;{+‚Äùl‚Äô√Ö√ß¬≥√£√ìn"¬∑4TÀúa√∫√û'5√Ä7L√±jw&nbsp;a¬¢√éF¬≠ÀÜ$I√ä
k¬¨√•√í^c‚Ç¨f√Ü`3¬≤≈†¬§¬™√òp=¬øC√¥/$K:~?√Ç√ç7s√é√®√≠√ú√ª#ci√É¬£≈°√¥√åK6v¬ºKa7‚Ä∞~√¶√ë!√Ö‚Ä†¬Ø√à&lt;‚Ä∞√ÇD'√Å√Ö'‚Äù≈æ≈æ‚Ä¶T¬≤3$≈°)√Æ2]O√ÄÀú√°6√Ö≈í+√û√≥√¢+¬¢B√π√™¬•√ô%√∏√™√ç¬¢Z√Ø≈íÀÜW≈Ω√à‚Ä¶(86Z√≤¬°¬¢√à√•√µ√•¬™R¬¢√ß√ê)√£e√∂¬ª¬∞√íqX√±P‚Äò#¬ΩI¬§√â&gt;4V/G√êi7¬≤√º.ÀÜ)√≤√û¬¨√≤√ØMAQva&nbsp;8¬µG√Å√¶‚Ä∫Z¬∂ ¬±‚Äî¬∞¬•√ß¬π≈æ@√ø)√π∆í]¬æ+x.√©√ÖK√¢√Ä¬∫¬±¬µ#√∫x√ë3¬®‚Äú¬≤≈°;¬¢&nbsp;Àú;√áC√ë√è√Ö√ª
√≠¬¨C'√∫¬™√ôJ¬¥√óUMI¬´√†7&amp;√ì#ÔøΩJ√ú√≥≈Ω√Å!√±√∂%B≈Ω‚Äû"√•¬Ω
&gt;√¥	∆í¬æÔøΩ√ø√¨√Ç≈í6¬∏√Çj√£√ßKN¬≤T¬¢¬´~N¬∏√ç	≈í¬¢¬∑Y&nbsp;.√ä¬§p‚Ä∫*‚Äò	t√ûm√ù4¬π√ù√πo√†¬ø2R≈∏¬§¬π√ëQ√ö¬®¬≤√∂t√¢)√¥¬®√â√æ¬∞K~
√´√±x
!O¬π‚Äπ¬ß√≥√àÔøΩ‚ÄùÔøΩ-√≤√ïM≈í√ä¬®ÀÜeGo¬©¬≤RxO9√πj¬º≈íWd{‚Ä°√§+:√ø√òRDj√™dÔøΩ‚Äò{U(fc,≈†√º¬¢+√´L+≈†,?B¬£‚Äù√Ω%√ã≈∏a√Ék‚Äö√ö<k‚Äúi√ê"{¬¨‚Ç¨¬π√âf¬∫‚Ä¶√â‚Ä°√à5√≤ pb‚Ç¨mf√´b√òn≈†√±r√á¬º="" √Æ≈Ω√Ñ¬£p¬¥q¬≤√ö‚Ä¢)2¬£√∏@b¬£‚Ä¢‚Äö√ß√™6ÔøΩ¬§√å@¬°i<ÔøΩ√ß"√ªqz%√ô="">√å4√´(z9√ÉFs√ì√å√ñ()u∆íÀú√≤¬ø‚Ä†ÀúgYFF!√Ç‚Ä∫&gt;√â3√à√ÖC‚Ä†‚Äπ√á^√è5&amp;√ò√æ‚Äî&lt;√£¬™~√£≈∏dT‚Äî‚Äô‚ÄòmP¬¶r√∂‚Äù¬∑*¬´√üH%¬£`o¬∂¬±X¬™lo√¥M√•*2U=r~y√£√±‚Ä°\√ójCÀú√£
‚Äú√≥H%Ef√ß√µ√¨N√°\√ï√µ¬≥7/-¬§¬®√•√°U√öc√†E#¬¶¬º‚Ä∞Aq√π‚Äû√ó+¬≤√ç√¢x√Ñ]7¬´o√Ñ√∏√ùÀÜ√ë¬º@√é√èOX‚Ä†√ß√∞:‚Ñ¢¬¶√≥))¬´XZ√¶~
√ªi√∏aK√∫r√±ZÔøΩ,F¬∂√õ≈ìp	‚Äπe√ª¬™xs√é$√ø√Ö√Å$√óJMK8tx;b√è¬±2$√™¬µu‚Ä¢¬≠¬¨√ù,ÔøΩ√Ä@√•‚Ä¢√µX¬£√âcQ√ëUd¬ªm¬æ¬π¬´%
√ª0√∏√êx√´$
ZN√ª3√àY≈†D\√°≈Ω#cy‚Äô;ÔøΩ@√ï√∑¬§√Ö;?g√ì≈°W¬≠J2√ÑOT¬æÔøΩ!‚Äö√≥y‚Ä†√±d√Ä`¬¥√æ¬™‚Äù√¨√ó√Ü√®Y‚Äò√Ω¬¢}≈†¬©√£¬ªn¬≠¬¢cSjME‚Ñ¢7~√úQa√üw√ô√äz*b√°A¬∫+¬±¬≤¬•√®¬¨√ê√á√£
¬®√Ü√û√õ√ÜWnH√∞ :¬ª√¶√â√úHpÔøΩqX2C	√®≈í¬¨ÔøΩ√ô‚Ä¶¬≤ÔøΩ‚Ä∞¬´9√Ωj&amp;¬∑‚Äò¬Æ!w¬∂E√õ√Æ¬∫¬™&nbsp;¬µ≈ìG\√ô‚ÄπMÔøΩ√æQ.ÔøΩ¬Ø√û√∫1C√ü√Ü‚Äπ√Å‚Äî‚Ñ¢‚Äπ≈í¬®*Àú¬æ?1≈°$√â¬∏@6√É√†!¬∫√ú√ú√ÄB‚Ä∞l√™2√Ø√Äke#ÔøΩ√¢7¬•,-√≥¬°*ixX¬≥√¨ÔøΩ√ì√õ¬§‚Ä∞:7&gt;(=V}D‚Ä†√•√ë3u√ìÔøΩ¬•((%8√ß‚Ç¨√±)√ów√•n6@√ü√å
√ügK√®¬Æ≈íI¬æ¬©ÔøΩ‚Ä¢√ß
‚Äö
m√∞‚Äû√Ä‚Äî
D.√Ñ¬©‚Ä¢ÔøΩÔøΩ|¬µ‚ÄöJu√Äs¬§√ìg2d√£ ‚Ä∞√®√á√Ü√ÇÔøΩ¬æ√≥√ÆCVV E≈íFÀú¬©√ë√πt√ï¬∑√†∆í‚Äù!ÔøΩ≈í√É√ö¬ø[¬Ø≈í√Ç¬æ¬ø≈Ω(√±¬©
√á√ü√¢√ö¬æB√Ül√∏ÔøΩÀú¬∑}≈†‚Ñ¢√ú¬¨[¬Ωzi√û√çZ√î√ú
¬≠O3o¬ÆadIg‚Ä°ec‚Äì¬Æ_√ä[?2√¶t‚Ä∞D¬æY√øJ√ö‚Äùj‚Äö‚Äô¬ÆsSXKBe√™E[≈†√è¬≤‚Äîo√Ç√°.¬≠√ö‚Äù‚Ä∫5xr√ø‚Äô‚Äù∆í2√Æ√ã‚Äö¬™√ÜfÀú√ò¬≠D21pX√¢‚Ñ¢≈í≈æw[u&amp;‚Äî.√â‚Ä∞‚Ç¨√ú
"√∫√ò√¶.\√í√°√âÔøΩ√ñ√∑√íY√â√ç√†ilb&nbsp;;r¬¢√∑8¬ªUF‚Ä¢
√ñ√ã‚Äö~YÔøΩp"‚Äú‚Äûk√ó¬™√ßN;√ô¬§-#‚Ñ¢%‚Äú√†"≈Ω N&lt;|X√ëC2&nbsp;‚Äù~@8‚Ä°√Ö¬®;/¬π√É≈†z√±√Üi‚Ä¶√Ñ√ß√Üh√û‚Äö√ûM¬æ"∆í2z√´‚Äò#¬±ew√ú‚Ä∞√©`=&nbsp;√î√∑9√ß√ò√ô≈í3Q¬™√è√º√¨¬∞√≥@Z≈Ω√Ç√Ärv)$¬ΩL¬ΩK√ò√ª≈∏¬π√π√±√ç¬™
M√íT<h[√ûg*√†-√ú√ë9√íyq3√î?n2¬Æ&≈æÔøΩm≈†¬Æ¬∏‚Ä°93√ó√ë¬´√åvvu#;.¬∏∆í≈†√êj‚Ä¶:√∫!‚Ä∞b¬π&ÔøΩy√õ\√áj¬∑ÔøΩ√ò√è¬∏j√ü¬≤‚Äù√É3y‚Äìw-‚Ä°‚Äû√£¬π√Äfg¬π√ô¬•qb√´√£>√£¬¨d√í¬±M‚Ä∫√É√≤YQ¬Ø&nbsp;√µ√å√ï√≤√Ä/'+√Ör√∫Jl√≤`P¬∫¬≠M√∂V√¶#q√Ü7R‚Ä∞9¬ºk√ó9¬¶√§5√ë‚ÄùGA√≠z√≥¬≥¬•¬©√á¬≠z~√ª¬Ω|≈í2√Æ‚ÄòI)√û¬¨√ó[MR‚Äî≈†√£√ÑÔøΩ$≈æ[_.J√ô√ç6"√öa‚Ä∫√πh=¬§,Y≈°^√Å≈íh¬•¬æ√î√π√íM√àVÔøΩUX@¬£¬™∆í√ΩS√¥RC√ú¬æ%r(√¨n√≥lk‚Ä∞V5√ç√ç?h$¬≥¬∑‚Ä∞‚Ä¢√∏‚Äò}[¬¶L¬ºh√æÀÜ√π¬∑%v!(√§¬º√§¬∂:d¬≤‚ÄôD2¬¥c‚Äù=(√á√ªZ¬æ√á√è%&nbsp;I√•√ï√¢√Å√£'!_¬™√∑√∞√¨‚Äì‚Ç¨&lt;√≥√ú_-√∏VHry¬Æ_o	√û√µ^ÔøΩ√ºY!√ò√≠@‚Äî7¬´$¬§√†Ng≈∏B√´√©KP¬ªy+{wDo√ºÔøΩ√ÉU√Æ
}√ó*HK9¬´√§√≥¬µs¬≠¬¶9√º√±‚Äú‚ÄöS(√ôB,.ÔøΩÔøΩE√£b}√Éu√ì√≠√ì¬ÆLaI√µÔøΩm+‚Äò‚Ñ¢¬ß√û√≤¬¶‚Äî [3√∞M¬Ω√ß\~¬¥√®‚Ä°~N'√±)‚Äì√ó√∞√Åi?8
√∏k¬≠√ÖJR/f√úV¬∞.*&gt;√è√ëo‚Äô√•K√¥U√Ø¬∏H√´z‚Ä°√ü‚Äöc√µ≈í√ê√º1√ì√ê&amp;√¶¬ÆS¬µÔøΩ‚Ä†√§OÔøΩÔøΩ%√ëe‚Ä∫9√´‚Ä¢&nbsp;7,√Ñ‚Äπ¬π√ÇÀÜN‚Äô√öK√¶&amp;≈ìAjÔøΩcHEM√¨fG‚Ä¶ÔøΩP√¢¬∂√ø√ßI√ë--√ø√ß√ù‚Ä¢‚Ç¨≈∏√ç√ãc√≠]√≥¬©√πwO#‚Ä∫≈†‚ÄôT√ª√õ8¬µ\¬ªp√ö√§¬∫'M√çl‚Äô;√à2¬µ√ï8¬¢¬Ωx√´%¬Æ√ó/√Ü]PÀÜg&gt;¬∫√Ö*E¬¶a¬•‚Ä†√à]ÔøΩ-r\¬Ω√É‚Äò‚Äî≈∏¬¨k\√É√ù√Ö`√§.√ó√ô√µ¬ª√ú-o√∫√É≈†xH@@¬ªÔøΩ√å‚Ä°¬Ω√õ√•X‚Äπuy)L¬¢√ù¬∞√èÔøΩ‚Äπ¬º#uÔøΩ√ª8y√º√§‚Äû(2¬¢b√µ‚Äô‚Ä∞c√ê~\¬∞S&lt;√•√ª¬°}¬≤‚Ä°√≤¬µO‚Ä∫‚Ä°,√≠≈æ‚Äô3√åq√´√Å¬ß{‚Äô√ü√áEb√©∆í√ë¬•¬£¬¨e¬Ø&nbsp;‚Äò%‚Äî√ìG√æ√≤ÔøΩ√∞U‚Ä¢_√ô‚Ä∞D¬©w√∂Y4√Ω‚Äôf√ô√õ7√±k√á¬≠gIR√á,&nbsp;*~7:‚Ä°≈ì√ú¬ª≈°√Æ√ß√ä√àu≈í¬©√±&amp;≈í=√´√à/≈í¬ß¬±z)√Ö¬´¬∑√≠Hs≈æ¬Ø¬πvWd8√¢fY"¬º#‚Äπ√≥‚Ä°¬Æ¬´auF¬±‚Ñ¢√´√±
√º√≥Àú&amp;kÀÜ‚Äù¬≥¬Ω7√Ω_√†¬´$¬Ø+e¬¶¬±√®NN(√®EÔøΩ&gt;e¬æk√≤≈° ÔøΩY‚Äù‚Ä†T√≤YB[¬µ¬≥√ßFr¬ß√≤ÔøΩ.&lt;√êpt¬™a√æY‚Äûi‚ÄîG√≠:UqW-√≥‚Äî%K¬©&amp;¬øV5√¢√ßÔøΩ_√ªP√ê√ª√≠cQ√Æ~≈°√ù'¬´√üp√∫=√ê&amp;ÔøΩBP¬π7√Çi¬∂rO8‚Äù3u+t¬¥xq√≥&gt;F{√Ö√Ω√ó√ã√™√Ø√ü¬∂¬∑√ø√ñ¬±8≈ì
endstream
endobj
17 0 obj
   3732
endobj
15 0 obj
&lt;&lt;
   /ExtGState &lt;&lt;
      /a0 &lt;&lt; /CA 1 /ca 1 &gt;&gt;
   &gt;&gt;
   /Font &lt;&lt;
      /f-0-0 5 0 R
      /f-8-0 13 0 R
      /f-9-0 18 0 R
      /f-2-0 7 0 R
      /f-1-0 6 0 R
      /f-6-0 11 0 R
      /f-10-0 19 0 R
      /f-7-0 12 0 R
   &gt;&gt;
&gt;&gt;
endobj
20 0 obj
&lt;&lt; /Type /Page
   /Parent 1 0 R
   /MediaBox [ 0 0 611.999983 791.999983 ]
   /Contents 16 0 R
   /Group &lt;&lt;
      /Type /Group
      /S /Transparency
      /CS /DeviceRGB
   &gt;&gt;
   /Resources 15 0 R
&gt;&gt;
endobj
22 0 obj
&lt;&lt; /Length 23 0 R
   /Filter /FlateDecode
&gt;&gt;
stream
x≈ì‚Ä¢Z√â¬Æ+√á
√ù√∑W√®√î¬Æy-d√°√§Y^H-√â‚Ç¨¬∞¬≥√à√Ø‚Ä°‚Ä°d
¬≠√°√π‚Ä†√ØkU√ó√Äb‚Äò‚Ä°‚Ä°¬¨√æ}1‚Ä°\√ù!Y{8√¶j√ú√ø&lt;√º‚Ä∫Z√±√ü¬ø¬æ¬ªÀú√É/√øY¬æ√ø¬≤¬§¬µf_¬∏]¬´Ys¬™¬µ√¶C√ähJ¬µ√∏√É‚Äî√ü‚Äì√ØGs4{√∏√≤X~:k√ú√ô√ï‚Äú√±√ß¬£ÔøΩ√°d√Ç√πhO&amp;≈æ√©OjM&amp;scA#√û‚Ä∫√§√∞¬´w¬¨‚Äπ¬π√∞¬Ø√ã√π√ß/?,¬∂¬Æ¬•TO¬¢|¬πa‚Ä∞√´√ô‚Ä¢‚Äú√ô√é√û≈ì√å√ç√ú√çC√¶¬µ√ÜZ≈í¬≤≈Ω√¶¬∞√û√á√è√ÑÔøΩV{√¶‚Ä¶√ûcyz‚Ä∞vÔøΩ√á≈†‚Äî√±d/&lt;√±√Ü√ú√≠√ïnV√∑bo√∫√Ø√ù:√¥Ywf√°F√à√´√™≈°}≈†M^g¬°1dV¬ª√ë¬£√≥4u4√éZ√Ñ;5‚ÄòX:√èB√ú√ê=¬©&nbsp;X√†/_√¥√à√æ√æ√ó∆íY]¬≠‚Ä°√øR√É√¥√ø¬Ø√ãO?S‚Äú9√úk;√ºN√ß‚Äö≈Ω√∏K¬æ√í√π√°√ò¬∂√ü‚Äì√¢√ñ√™√°hmZ}≈Ω‚Ä°√ü¬≠¬•¬∫5ÔøΩ√¥√ø:√º√£√∞√£√≤y‚Äö√®VcM√†√º√™k¬°	r\¬´‚Ä∫Z√æt:√ò¬∏≈∏"¬ø‚Ä†√øo‚Äô¬∂‚Äùy¬Ω√©7√í√∂]≈íYC√∂‚Äú&amp;2zL√Æ‚Ä∫UA&gt;¬±:?¬´¬¢¬µ|√≥6‚Ä†¬Ω√©‚Ä∫¬•‚Ç¨≈∏X7‚Äπuf√ß≈∏√•√®√æN≈Ω≈æ√â‚Ä¢ÔøΩL¬©ÔøΩ√éD≈°√á√ñ(√≤√™ÔøΩ¬´%¬™¬ß√ó√â√ìo&amp;‚Äô+}!‚Äî¬æ≈∏¬π√∞.ÀÜ6¬´√é√®‚Äπ'{‚Ä†∆í≈†1√≥oF√∏&amp;F‚ÄôcZm2i¬±‚Ñ¢√ù_√º√òd[√ò)1√®rv√©di√™√®√π_√àS7[¬®√ì√ç\√çfÔøΩ¬πZ√É√ûAb‚Äì!√¶√πXJ0‚ÄöK7√®R√ó≈°√®x¬∞i}¬¥&gt;¬Æ&gt;‚ÄìZ√ì!‚Äì¬≤√ñbjI¬∫i7m√∫B¬ª√∑$y‚Ç¨h¬§√ö¬¨ ≈°¬´g√∂nj¬¨'√ïC2y8~4@√™√ÜoRV"√Ø‚Äì√Æ7√öD0√º√ä‚Ä¶K@V_$t√¨&amp;(√Ω¬•y	ÔøΩ√∞&amp;b√´√ãx¬¥√≥√¨‚ÄòV√ä√¥¬∞√æf¬£g‚Ç¨1fÀú0¬´‚Ç¨v1√©√ú&amp;J‚Ç¨&gt;ÀúqF‚Ä¢√ê{3w‚Ä†T‚Ç¨√ù√ê{(√ïÔøΩ≈íH≈∏|¬¥√ù@gr‚Äû¬æ≈í¬Ω`‚Ä†√†√©√∏/u√ë_V¬±&gt;¬±≈°w
;‚Äû√Öx√ö¬¢mLRix√ôp√π$√ö√Ñp≈°/a:&amp;‚Ä∞Iq√®X¬Ω√∂LX¬∞√û‚Ä∞%√ã√â√â$ÔøΩ√É‚Äò√§9ÔøΩ~¬Ω√à]√™√¥‚Äú¬∏i√Å√≥&amp;≈æ‚Äîs‚Äî¬°)R¬æi≈°√¢¬£d√πo√íq‚ÄùL6¬πJ√ü≈°Y√ß√ô¬¨¬π√ìF√ñ≈∏√âlR√´√¢^¬ª√Ä6∆í‚ÄúM¬°‚Ä¶|
f#v¬º√©;+≈°‚Äû¬πrRCL‚Ñ¢√Ü¬≠¬∞Àú
O‚Äöc‚Äú-‚Ä∫√©aXi√Æ¬æ¬æ√Å`s√õ%√¨√Æ¬Ω√µm:Ax√ï≈ì¬∫√•√£u≈í7¬§XU√å‚Äπ√ù‚Äò√¢≈°9¬ª√µUE√Ö7√µ¬¢¬£√è√¥√´:√î√†s√ß ?m√ª‚Äîw¬±1¬º√åJ¬¥√ö√Å√Ä≈ìy√Ü¬≠√ª}4√¨¬´Y&lt;≈Ω1√¢¬æ2+√Ø√äJo+¬≤	¬∞∆í¬≠%+√∂¬§v≈æ@¬∞√ã√π√ã¬Øo¬∞√ã"&amp;
ÀÜ√ë¬¨√ñ¬•1|2√ì=V√ÜJ
¬º01i√≥‚Ñ¢}√Ö¬≥V¬´@‚Ä∫	√û0√ãic¬≤Z√Ø√ë≈†G6¬æ¬∏{√ÄA√ºIfMCRhÔøΩ≈æ√¶U√Å¬®*qzUÔøΩ√≥ÀÜ√°¬¥5O¬±≈íh5oUs%e√ó√∑√äq!S√§√ã&lt;∆í√è¬´√ç√±¬≠v`√∏l]$,l¬ª	√Æ√Ø,YXCp√Ñ√ØG"WÔøΩ√¥
6}¬¢&nbsp;B¬´≈°√É¬Æ√µ'√òCU√åÀú¬´Y‚Ä¶c≈∏a¬¶k‚Ñ¢√ÖRT¬™M¬∫¬∏g

√ú5‚Äπ‚Äö\¬¢.√Ø¬µD≈†'¬™*¬±‚Ä¶¬Øi)
√≠¬¶√ê¬¥o5EÀÜ¬µ√ö√™y‚Äì¬Øi¬™√í≈Ω√®√åx√ç"h≈†S	/√Ä¬∂√Å√îhÔøΩ9%≈í)trz`)ds√Å√†√°k≈í√à¬∞&amp;√≠
)ZÔøΩyhV'√ó‚Äì√ä√†s‚Ñ¢f√¶v≈Ω¬∫
.Uu√™[&lt;√à'6√ä]8‚ÄúQ√ó≈Ω¬¥≈∏¬™‚Äú2yÔøΩ
√®√ûW[d∆í¬ªÔøΩ√∂≈∏√ö¬©72
‚ÄìADq]√êK√£¬Æ√∑ÔøΩÔøΩ¬£¬ºe √£q
Z√≤√ñR!√≠ja√ö≈Ω¬£$¬∂¬µC√∑;[√ó√∞|√àV¬≤≈æ‚Äöa√ñP‚Ä¢}a¬ø√â¬¥5‚Ä∞√ç√∞q¬∫D√îÔøΩ2‚ÄîwÔøΩ√ä[,d√ØB2DJ¬≤D√±‚Äö‚Ä°√Ñ‚Äì¬∑Q√ë√™√∂‚Ç¨¬≤‚Äì¬¥0x¬∞‚Äô"‚ÄûIÔøΩ¬µÔøΩ‚Ñ¢√∑h¬∞√ö4‚Ä∞‚Äô|‚Äò¬ª;√â√â-√§¬∞q√àl√π√Å√ì≈ΩlX¬£+√ôg$Y¬¶√î√ÇrQ√¶√ø! ¬∞)g	√£-I(¬∑¬¥¬¥x‚Ä¢%√ìI#4?;≈†
¬¶√à^H-√º√Ç1.√¥‚Äù]ÀÜ√∂G√ú√üuÔøΩ6Gd‚Äö√∂√¢√∂6√Ö5^¬´≈†u)¬µd√Ø¬§}√∏√§¬≤√ç/ÀÜ=‚Ä¢S_≈Ω√Ä@%¬´‚Ç¨‚Ä¶‚Äò0Lb∆íl¬∂¬¢¬±√é1Z&lt; ¬¶≈Ω&nbsp;√º√åH√Ånz√ï‚Ä∞‚ÄìÀú√§zV≈†L√≥√≥)&gt;R&amp;D¬¶‚Ä†√∏Àú‚Ä∫√í√ïWxs¬§¬Ω√∑√±‚Äò%‚Äö2≈æh~¬™c√º¬§Z√∑‚Ç¨D√´√â√∫√Ö√µ≈æ≈í?√é√©c¬ß√íÔøΩ‚Äû√±?√°‚Äö¬∞'RÀÜU4√ß}‚Ä°≈Ω@4$¬∂pj√ã≈íg√≥‚Äî√ê√àY+¬Æ≈æ‚Äö√≠hi¬°P
√ê‚Äò=*√µ‚Äûd¬æ+√ë≈∏¬§‚Äö,¬¢i¬´t+J≈°@B~ÀÜ¬æ‚ÄùS8¬Ø√ï%¬°√Ü√ª≈†√ø@L\%√ã¬≥E√ÜS ¬∑√π¬≠√¢‚Ä∫jPÀÜ¬•√õ√è‚Äù
a‚ÄîÔøΩ¬≤`√á.¬§kQ√è√Å √ñf[√å¬∑
~E√ª‚Äù¬©√áÀúrxAi√Ö√•]¬≤5	¬•n≈°/+√≠3√¶6√ä¬£x:;√ç~0√ô‚Ä∞‚Ä°∆íif√£¬Ω√û¬∞¬∫√ú¬≠n1√ö¬°√á
¬©ÔøΩd√©)√ìH$w¬ø¬≥√¶√¢ÔøΩ‚Äù√Ö&lt;(k¬ß9√°Y-w√¢‚ÄòvÔøΩd‚Äì√∂=C¬Ø\&gt;sed√Öq√â√†√ö5 ¬¶√Ø5√åzÔøΩn√®|√ì√à√ñ%‚Äú7d≈ìd¬¥[W+
¬ª√âÀÜ¬æ‚Äπ‚ÄìJ*¬∑√¨9√ß‚Ä¢‚Äö."√©√ô]√π√Çd√•√î]ÀÜ√ß¬°√≥C1I¬¨D√û‚Ñ¢h¬®√èU¬§BK¬∫¬´√¶5t¬∑√≥√≠*√®√©9√Å¬≠-√Å√ù√¶L√¨¬π$P√î¬®-‚Äì¬±r
Q√îj√∑tÔøΩy#C√â≈°√ü√ç
B√çx√Ç√´2√•‚Ä¶h]√µb√ÇÀú¬±¬ø¬ºKdm√í\¬∫√äZ√ª√à	)∆í {¬∂9A‚Äì√≠√æ)_¬∫67√í&nbsp;NB¬£‚Ä†z¬∂:k‚Äú¬±√ê√µ≈°ÔøΩm‚Ç¨C√≥;¬¢¬´√éT
√òÔøΩ)!¬¨r¬©≈†¬±√ëC√∫√≥&nbsp;ÀÜ≈æ‚Ä∫√™‚Ä¢#p≈∏√òk√áFT√Ø√î√Ö‚Äπ‚Äì-ÀÜ√≥ OB%:‚Ä∞
LdrN¬™√Ø√ñY√§9√¢¬≥¬∞√û¬•H6√Ñ√í√∫‚Äô_T&nbsp;8¬ß¬§√ë
yu
¬ªup&nbsp;s+ÔøΩ¬§ÔøΩ¬≥tX¬≠Y√¨XF¬±‚Äúr√Ø√ï¬¶‚Ç¨¬ª≈ì√ì%√ëi√≠945‚Äù¬ª1‚ÄôUfkJ√Ω;E√®√ì¬µ√†≈†√≤Pj‚Ä∞√≠lG≈ìe√â√Ñ√™√Ω√ígiu(¬•≈°¬Ø%'¬≤@√é7:‚Ä†xOXq√©√å‚Ä¶√çM(t√ô√≥_8¬¢7ÔøΩ√≤¬¢¬∫‚Ä∫≈Ω!.D√øo3√ãÀÜ-_√Ø¬¶Q‚Äî_¬≥R√åF'¬¶,¬∫6z¬§^g)√çD1¬ª‚Ä∫√¥S√∏[)ÔøΩcs¬®h)&lt;\√úo.2√≠√ãq?[¬º¬ªqI,¬≤v;√¢w¬≠.4√äe≈ì.ÔøΩ=y&nbsp;√ÖÀÜ√®√≠√Ω√Ä&nbsp;¬æPo√ÇY‚Äú¬∑ÔøΩXLpÔøΩ&lt;‚ÄûÔøΩ,√™√•√õ8g√ã¬Ø√ó@[^¬¨P\{x√Ç√ê¬©¬∑√å√ßx√âbH
Kh√ØUD¬Ω√å@¬¥√ãf/√Äd√°^√çx"&amp;¬¥√Ñ‚Äìv‚Ä¶√ü√ç≈í√ûy√†√í:Ij√á√Ä≈í!(√éV≈ΩÔøΩ√Ö¬¶[W√ò‚Äô+^¬∏√∫‚Ä∫√®`n‚Äπ√îÔøΩ&amp;√∏√ßi':‚Äúw9¬¶L&lt;¬∂[Qu‚Ñ¢W√†3‚Ä∞√ª  ;√¨(√ø√ô√∞√ò√¨n\√©¬±jN√∑s‚ÄúN√ã√ç√ñÔøΩ2√•≈†\q√µ¬¶L¬•¬º)≈∏‚Ä¢4√É√§)≈í√∞¬Ø‚Ä†~4≈ΩrR?ÔøΩw√ç}f √ô‚Ä¶≈†√Ö}√å&gt;¬±YK9√•!u
√Ñ kxW≈ì√ªPU¬°√åkMDÔøΩ1&lt;¬Æ‚Ä¶¬¢N&gt;√ß‚ÄìS"S√∂F√â
√µ√ârdÔøΩ¬º/T√õ‚Äôh√ès√±√æ√Ç√Æ-5¬∑[(√ö¬æ√ñd8OF¬≠¬©¬•f^√≤‚Ä†√õ√ªB3√™w‚Ä¶z}(2√£¬µÀÜ√å√á¬≥¬´√ªq√ç√ô0√≤]8√î‚Ä¢¬ßrÔøΩo√à¬∫√∂l≈†	¬§¬´=]‚Ñ¢~T≈Ω√ΩIXM√™√πjHm¬æ[:DTn8√ú%‚Äö√ñ√≠'ri√•/√¨&gt;s‚Äû√´≈ì‚Äò)H√¶‚Äö√û√ÅMÔøΩS9‚Äî√ú		¬Ø‚ÄπT`{M√å¬ª0Àú√≤≈æ√â√Å%¬ªÀú(¬ø¬µ√±^Ab√ë5&amp;√∂7_‚Ä∫≈í[‚Äû)∆í√≤√üu-‚Ñ¢p:ÔøΩ¬π‚Äì¬ø√¥√öu√ßR(¬≠√õ≈í¬¶gd‚Ä¢√∞√πKi-ÔøΩ√ïz4‚Äò≈æ√ªsP√Ü√≠(√ß‚ÄùO‚Ä¶√ño‚Äò≈Ω√æ√§√î√Ñ‚Äπf2≈æb`Q√µ√æ¬©¬§√ü√î¬µ√ßuq√éy√©√ØOAw√∑{¬±L√ë‚Ä¢mN√§√¥√∏)‚Ä¶</h[√æg*√†-√º√±9√≤yq3√¥?n2¬Æ&≈æÔøΩm≈°¬Æ¬∏‚Ä°93√ó√±¬´√¨vvu#;.¬∏∆í≈°√∞j‚Ä¶:√∫!‚Ä∞b¬π&ÔøΩy√ª\√ßj¬∑ÔøΩ√∏√Ø¬∏j√ü¬≤‚Äù√£3y‚Äìw-‚Ä°‚Äû√£¬π√†fg¬π√π¬•qb√´√£></k‚Äúi√∞"{¬¨‚Ç¨¬π√©f¬∫‚Ä¶√©‚Ä°√®5√≤></sw√Ø.></l}k&r></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://people.idsia.ch/~juergen/fastestuniverse.pdf">http://people.idsia.ch/~juergen/fastestuniverse.pdf</a></em></p>]]>
            </description>
            <link>http://people.idsia.ch/~juergen/fastestuniverse.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065400</guid>
            <pubDate>Thu, 12 Nov 2020 01:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Kernel Bug Fixing Mentorship]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065177">thread link</a>) | @simonpure
<br/>
November 11, 2020 | https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship | <a href="https://web.archive.org/web/*/https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="634481719919165440">
                    
                        
                            <h3><a href="https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">Linux Kernel Bug Fixing Mentorship</a></h3>
                        <p>I recently finished a three months long <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2F&amp;t=NmU4Y2E5MmVjZDhjNzkzMjAwMDI3NGZkNTU4NzMxMjU1NWZhM2M3MCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605342140" target="_blank">CommunityBridge(now knows as LFX)</a> mentorship with <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.linuxfoundation.org%2F&amp;t=YWJhMGVmZDczM2I4YzdiYjFhZTk5MWJjNTE1YzcwOWY2ZGZmNmJjOCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605342140" target="_blank">The Linux Foundation</a>. I worked as a <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2Fproject%2Ff06db0d5-537e-4e0f-8ca4-0a471f95a04d&amp;t=NmIwODMxMzFhNGFlZjRhOTkyYTU3ZWFhZDE3ZWQyOTg2NzdiM2YyNCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605342140" target="_blank">Linux kernel bug fixing</a> mentee under <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwww.kroah.com%2Flog%2Fabout.html&amp;t=MWQ2ZDAwODBkNjhmNzk3NGIwYTU1MjkzYjhlZDBjYjM0NDIzNzJjZCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605342140" target="_blank">Greg Kroah-Hartman</a>. This post is about my experience and work during the mentorship program.</p><p>In
the first week of the mentorship program, I learned about debugging
techniques for the Linux kernel, how to use decode_stacktrace.sh, and
what is CONFIG_KASAN. These were all unfamiliar concepts for me, and
I found the mentors‚Äô learning resources very useful. My first task
was to write summaries of my understanding of these concepts. I found
these summaries quite helpful while fixing real bugs in the kernel
later in the mentorship.</p><p>I
was also unfamiliar with syzkaller and syzbot before becoming part of
the mentorship. So after completing the summary tasks, I spent the
next few days getting familiar with these tools. The syzbot dashboard
has hundreds of reported bugs, and I found it a little challenging to
decide which one I should pick first.</p><p>In
the meantime, my mentor, Greg KH, redirected me towards an ongoing
discussion regarding a bug produced due to a short read in
usb_control_msg() call. There existed a few ways to fix it, and after
discussing them with the mentor, I proposed a fix. The patch
generated a fair amount of discussion, and I also received comments
that the proposed fix wasn‚Äôt the right way to handle the bug. The
discussion also concluded that many other usages of
usb_control_msg(), which don‚Äôt have proper error checks, are also
prone to similar bugs. I fixed the bug by adding an adequate error
check to prevent short reads in the caller, and Greg KH wrote new
wrapper functions for usb_control_msg() to be used in such scenarios
to avoid similar bugs.</p><p>Apart
from this bug, I also explored two other bugs. I found them
fascinating because inspite of being listed on the dashboard, their
reproducers weren‚Äôt triggering any issues. I learned that a commit
had fixed one of these bugs, and it was yet to be applied to all
kernel trees. But the other bug didn‚Äôt have any reported fix, yet the
reproducer wasn‚Äôt triggering the issue. I discussed this with the
mentor and learned that the syzbot dashboard isn‚Äôt quite dynamic. So
we decided to mark the bug as ‚Äúinvalid.‚Äù On a later
discussion with other community members I learned that it was not a
good idea, and I‚Äôve ended up marking a potentially valid bug as
‚Äúinvalid‚Äù!</p><p>As
a follow-up work on the first usb_control_msg() bug, I submitted a
cleanup patch series for some of the drivers/net/usb files. One of
those patches ignored the GFP_NOIO flag used in the original code and
replaced it with the GFP_KERNEL flag used in the new wrapper API
functions. It was a blunder that resulted in a discussion to add a
new argument for memory allocation flags in the wrapper functions.
Now the wrapper functions take memory flags as arguments preventing
mentees like me from repeating such blunders.</p><p>I
continued the follow-up work by investigating drivers/usb/serial/
files. I noticed that many usages of usb_control_msg() rely on its
return value of the number of bytes read/wrote. And the new wrapper
functions don‚Äôt retain that information. So I had a discussion with
the mentor about if that information was really necessary. We
concluded that it is almost always unnecessary, and having an error
code returned is a better way.</p><p>I
ended up submitting 19 patches as part of the mentorship program. The
first one is a fix for the usb_control_msg() short read bug. The next
three are cleanup patches for usb_control_msg() wrapper functions for
drivers/net/usb files, which were rejected because of the memory flag
blunder. And the remaining 15 are usb_control_msg() cleanup patches
for drivers/usb/serial/ files. Greg KH has reviewed them, but they
are not yet merged in the mainline.</p><p>Apart
from the bug fixing, I also learned few other interesting things
about the Linux kernel and its developer community, like how we test
various changes in the kernel and why we strictly use plain text
emails. I also attended talks at the Linux Plumber‚Äôs Conference and
the Open Source Summit Europe during the mentorship, which helped me
catch up with what is happening in the kernel world, learn new
things, and make new connections.</p><p>
My
mentorship program experience has been fantastic, and I recommend it
to everyone interested in pursuing Linux kernel development and
looking for mentoring. I am heartily thankful to my mentor Greg KH,
Shuah Khan, and The Linux Foundation, for providing me with this
opportunity and a great learning experience. 
</p><p>Patches can be found on&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flore.kernel.org%2Flkml%2F%3Fq%3Dhimadrispandya&amp;t=NmUzNDlmNjlkMDFhZDBkOTdhMzQ3ZDg0ZTE1NWQ4NTMzYTE3ZWMyOSxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605342140" target="_blank"> https://lore.kernel.org/lkml/?q=himadrispandya.<br></a></p>
                    </article></div>]]>
            </description>
            <link>https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065177</guid>
            <pubDate>Thu, 12 Nov 2020 01:13:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Illustrated Children's Guide to Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065144">thread link</a>) | @tomasreimers
<br/>
November 11, 2020 | https://www.cncf.io/phippy/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/phippy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article>
		
<div><figure><img loading="lazy" width="472" height="487" src="https://www.cncf.io/wp-content/uploads/2020/07/phippy-01-1.svg" alt=""></figure><p><strong>Phippy</strong>&nbsp;is a simple PHP app, trying to find a home in a cloud native world.</p></div>







<div><div>




<h2>Introducing Phippy and friends</h2>












</div></div>







<div>
<div>
<figure><img loading="lazy" width="849" height="651" src="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg 849w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-300x230.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-768x589.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-261x200.jpg 261w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-700x537.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-222x170.jpg 222w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-352x270.jpg 352w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-443x340.jpg 443w" sizes="(max-width: 849px) 100vw, 849px"></figure>




</div>



<div>
<h3>The Illustrated Children‚Äôs Guide to Kubernetes</h3>



<p><em>The Illustrated Children‚Äôs Guide to Kubernetes</em> is a simple, gentle answer a father gave his daughter when she inquisitively asked about Kubernetes. It‚Äôs dedicated to all the parents who try to explain software engineering to their children.</p>



<p>The star of <em>The Illustrated Children‚Äôs Guide to Kubernetes</em>, Phippy and her friends explain the core concepts of Kubernetes in simple terms.</p>




</div>
</div>







<div>
<div>
<h3>Phippy Goes to the Zoo</h3>



<p>Follow the tale of Phippy and her niece Zee as they take an educational trip to the Kubernetes Zoo.</p>








</div>



<div>
<figure><img loading="lazy" width="851" height="655" src="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg 851w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-300x231.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-768x591.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-260x200.jpg 260w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-700x539.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-221x170.jpg 221w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-351x270.jpg 351w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-442x340.jpg 442w" sizes="(max-width: 851px) 100vw, 851px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy and Zee go to the Mountains</h3>



<p>Another work featuring Phippy and friends: Join Phippy and Zee on a 4-dimensional hike!</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="768" src="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-300x225.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-768x576.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-267x200.jpg 267w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-700x525.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-227x170.jpg 227w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-360x270.jpg 360w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-453x340.jpg 453w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8.jpg 1367w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy In Space: Adventures in Cloud-Native Recovery</h3>



<p>In the not-so-distant future, space outposts (cloud-native infrastructure) are the next frontier for settlement and Captain Kube is in charge of the cutting-edge Mars outpost. As the outpost has grown in size and complexity, Captain Kube needs to find solutions for many of the settlement‚Äôs growing pains. He has recruited Phippy to work with him on the outpost‚Äôs Day 2 challenges.</p>



<p>Join them on their adventure, as they journey to Mars and brainstorm solutions.</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="792" src="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-300x232.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-768x594.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1536x1187.jpg 1536w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-259x200.jpg 259w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-700x541.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-220x170.jpg 220w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-349x270.jpg 349w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-440x340.jpg 440w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space.jpg 1568w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>















<p>The characters Phippy, Captain Kube, Goldie, and Zee and the two books are owned by The Linux Foundation, on behalf of the Cloud Native Computing Foundation, and licensed under the Creative Commons Attribution License (<a href="https://creativecommons.org/licenses/by/4.0/">CC-BY</a>), which means that you can remix, transform, and build upon the material for any purpose, even commercially. If you use the characters, please include the text ‚Äú<a href="https://phippy.io/">phippy.io</a>‚Äù to provide attribution (and online, please include a link to&nbsp;<a href="https://phippy.io/">https://phippy.io</a>).</p>



<p>The characters and the two books were created by&nbsp;<a href="https://twitter.com/technosophos">Matt Butcher</a>,&nbsp;<a href="https://twitter.com/karenhchu">Karen Chu</a>, and&nbsp;<a href="https://www.baileyjeanstudio.com/">Bailey Beougher</a>&nbsp;and donated by Microsoft to CNCF. Goldie is based on the Go Gopher, created by&nbsp;<a href="https://blog.golang.org/gopher">Renee French</a>, which is also licensed under&nbsp;<a href="https://creativecommons.org/licenses/by/3.0/" target="_blank" rel="noreferrer noopener">CC-BY</a>.</p>



<p>Images of Phippy, Captain Kube, Goldie, and Zee are available in the CNCF&nbsp;<a href="https://github.com/cncf/artwork/blob/master/examples/other.md#phippy--friends-group-logos">artwork</a>&nbsp;repo in svg and png formats and in color, black, and white.</p>
	</article>
</div></div>]]>
            </description>
            <link>https://www.cncf.io/phippy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065144</guid>
            <pubDate>Thu, 12 Nov 2020 01:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Version 11 of Angular Now Available]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25065091">thread link</a>) | @mgechev
<br/>
November 11, 2020 | https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7 | <a href="https://web.archive.org/web/*/https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@markathompson?source=post_page-----74721b7952f7--------------------------------" rel="noopener"><img alt="Mark Techson" src="https://miro.medium.com/fit/c/96/96/1*2hqK0rVXWghtk_RLFx33oA.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Photo of a Torch Ginger by Jules Kremer" src="https://miro.medium.com/max/2368/0*55kr1t601sp22pkE" width="1184" height="1091" srcset="https://miro.medium.com/max/552/0*55kr1t601sp22pkE 276w, https://miro.medium.com/max/1104/0*55kr1t601sp22pkE 552w, https://miro.medium.com/max/1280/0*55kr1t601sp22pkE 640w, https://miro.medium.com/max/1400/0*55kr1t601sp22pkE 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*55kr1t601sp22pkE?q=20"></p></div></div></div><figcaption>Photo of a Torch Ginger by Jules Kremer</figcaption></figure><p id="1feb"><strong>Welcome to the Angular version 11 release.</strong></p><p id="1877">Version 11.0.0 is here and we‚Äôve got some great updates for Angular developers everywhere. This release has updates across the platform including the framework, the CLI and components. Let‚Äôs dive in!</p><h2 id="1182">Updates on Operation Byelog</h2><p id="593b">When we shared <a href="https://angular.io/guide/roadmap" rel="noopener">Angular‚Äôs Roadmap</a>, one of the items was Operation Byelog where we committed to putting a significant engineering effort towards triaging issues and PRs until we have a clear understanding of the broader community needs. We can now report that the original goal is complete! We‚Äôve triaged all the issues in all three of the monorepos and will continue this as an ongoing effort as new issues get reported.</p><p id="bc06">This is our commitment: Going forward all new issues reported will be triaged within 2 weeks.</p><p id="2104">In the process, we resolved a few <a href="https://github.com/angular/angular/issues/12842" rel="noopener">popular</a> <a href="https://github.com/angular/angular/issues/18469" rel="noopener">issues</a> in the <a href="https://github.com/angular/angular/issues/13011" rel="noopener">router</a> and <a href="https://github.com/angular/angular/issues/14542" rel="noopener">forms</a>.</p><p id="a1cd">Also, we‚Äôve closed the <a href="https://github.com/angular/angular/issues/11405" rel="noopener"><em>third most popular issue</em></a><em>!</em></p><p id="5773">Now, we‚Äôre planning the next steps to support the Angular community. We‚Äôll continue triaging and fixing issues, and work towards improving our processes for accepting community contributions.</p><h2 id="4683">Automatic Inlining of Fonts</h2><p id="6a67">To make your apps even faster by speeding up their <a href="https://web.dev/first-contentful-paint/" rel="noopener">first contentful paint</a>, we‚Äôre introducing automatic font inlining. During compile time Angular CLI will download and inline fonts that are being used and linked in the application. We enable this by default in apps built with version 11. All you need to do to take advantage of this optimization is update your app!</p><h2 id="124e">Component Test Harnesses</h2><p id="78d2">In Angular v9 we introduced Component Test Harnesses. They provide a robust and legible API surface to help with testing Angular Material components. It gives developers a way to interact with Angular Material components using the supported API during testing.</p><p id="2932">Releasing with version 11, we have harnesses for all of the components! Now developers can create more robust test suites.</p><p id="3e07">We‚Äôve also included performance improvements and new APIs. The <em>parallel</em> function makes working with asynchronous actions in your tests easier by allowing developers to run multiple asynchronous interactions with components in parallel. The <em>manualChangeDetection</em> function gives developers access to finer grained control of change detection by disabling automatic change detection in unit tests.</p><p id="752c">For more details and examples of these APIs and other new features, be sure to check out the <a href="http://material.angular.io/cdk/test-harnesses/overview" rel="noopener">documentation for Angular Material</a> Test Harnesses!</p><h2 id="173a">Improved Reporting and Logging</h2><p id="968c">We‚Äôve made changes to the builder phase reporting to make it even more helpful during development. We are bringing in new CLI output updates to make logs and reports easier to read.</p><figure><div><div><p><img alt="Screenshot of angular CLI output nicely formatted into columns." src="https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX" width="607" height="355" srcset="https://miro.medium.com/max/552/0*-dCa80651cnfbjpX 276w, https://miro.medium.com/max/1104/0*-dCa80651cnfbjpX 552w, https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX 607w" sizes="607px" data-old-src="https://miro.medium.com/max/60/0*-dCa80651cnfbjpX?q=20"></p></div></div><figcaption>Improved CLI output formatting</figcaption></figure><h2 id="970e">Updated Language Service Preview</h2><p id="650a">The Angular Language Service provides helpful tools to make development with Angular productive and fun. The current version of the language service is based on View Engine and today we‚Äôre giving a sneak peek of the Ivy-based language service. The updated language service provides a more powerful and accurate experience for developers.</p><p id="15e6">Now, the language service will be able to correctly infer generic types in templates the same way the TypeScript compiler does. For example, in the screenshot below we‚Äôre able to infer that the iterable is of type string.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Screenshot of intellisense style insights in Angular templates." src="https://miro.medium.com/max/3000/0*L1Tg13gdu3PCqUNN" width="1500" height="902" srcset="https://miro.medium.com/max/552/0*L1Tg13gdu3PCqUNN 276w, https://miro.medium.com/max/1104/0*L1Tg13gdu3PCqUNN 552w, https://miro.medium.com/max/1280/0*L1Tg13gdu3PCqUNN 640w, https://miro.medium.com/max/1400/0*L1Tg13gdu3PCqUNN 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*L1Tg13gdu3PCqUNN?q=20"></p></div></div></div><figcaption>Angular Language Service inferring iterable types in templates</figcaption></figure><p id="e67f">This powerful new update is still in development but we wanted to share an update as we keep preparing it for a full release in an upcoming version.</p><h2 id="48a5">Updated Hot Module Replacement (HMR) Support</h2><p id="303f">Angular has offered support for HMR but enabling it required configuration and code changes making it less than ideal to quickly include in Angular projects. In version 11 we‚Äôve updated the CLI to allow enabling HMR when starting an application with ng serve. To get started, run the following command:</p><pre><span id="3ac4">ng serve --hmr</span></pre><p id="f3bc">After the local server starts the console will display a message confirming that HMR is active:</p><p id="f521">NOTICE: Hot Module Replacement (HMR) is enabled for the dev server.</p><p id="5155">See <a href="https://webpack.js.org/guides/hot-module-replacement" rel="noopener">https://webpack.js.org/guides/hot-module-replacement</a> for information on working with HMR for webpack.</p><p id="3796">Now during development the latest changes to components, templates and styles will be instantly updated into the running application. All without requiring a full page refresh. Data typed into forms are preserved as well as scroll position providing a boost to developer productivity.</p><h2 id="6de3">Faster Builds</h2><p id="630c">We‚Äôre bringing a faster development and build cycle by making updates to some key areas.</p><ul><li id="4336">When installing dependencies, the ngcc update process is now 2‚Äì4x faster.</li><li id="b30d">Faster compilation with TypeScript v4.0.</li></ul><p id="ed18">Now, teams can opt-in to webpack v5. Currently, you could experiment with <a href="https://webpack.js.org/concepts/module-federation/" rel="noopener">module federation</a>. In the future, webpack v5 will clear the path for:</p><ul><li id="db89">Faster builds with persistent disk caching</li><li id="7ab4">Smaller bundles thanks to <a href="https://webpack.js.org/guides/tree-shaking/" rel="noopener">cjs tree-shaking</a></li></ul><p id="dae8">Support is experimental and under development so we don‚Äôt recommend opting in for production uses.</p><p id="4ca8">Want to try out webpack 5? To enable it in your project, add the following section to your package.json file:</p><pre><span id="386c">"resolutions": {<br>     "webpack": "5.4.0"<br>}</span></pre><p id="65a0">Currently, you‚Äôll need to use <strong>yarn</strong> to test this as npm does not yet support the resolutions property.</p><h2 id="d0a9">Linting</h2><p id="e4b2">In previous versions of Angular, we‚Äôve shipped a default implementation for linting (TSLint). Now, TSLint is deprecated by the project creators who recommend migration to ESLint. <a href="https://twitter.com/mrjameshenry" rel="noopener">James Henry</a> together with other folks from the open-source community developed a third-party solution and migration path via <a href="https://github.com/typescript-eslint/typescript-eslint" rel="noopener">typescript-eslint</a>, <a href="https://github.com/angular-eslint/angular-eslint" rel="noopener">angular-eslint</a> and <a href="https://github.com/typescript-eslint/tslint-to-eslint-config" rel="noopener">tslint-to-eslint-config</a>! We‚Äôve been collaborating closely to ensure a smooth transition of Angular developers to the supported linting stack.</p><p id="6071">We‚Äôre deprecating the use of TSLint and Codelyzer in version 11. This means that in future versions the default implementation for linting Angular projects will not be available.</p><p id="806d">Head over to the <a href="https://github.com/angular-eslint/angular-eslint#migrating-from-codelyzer-and-tslint" rel="noopener">official project page</a> for a guide to incorporate angular-eslint in a project and migrate from TSLint.</p><h2 id="98a6">Housekeeping</h2><p id="0727">In this update we‚Äôre removing support for IE9/IE10 and IE mobile. IE11 is the only version of IE <a href="https://angular.io/guide/browser-support" rel="noopener">still supported</a> by Angular. We‚Äôve also <a href="https://angular.io/guide/deprecations" rel="noopener">removed deprecated APIs</a> and added a few to the deprecation list. Be sure to check this out to make sure you are using the latest APIs and following our recommended best practices.</p><h2 id="a3c7">Roadmap</h2><p id="9aad">We‚Äôve also updated the <a href="https://angular.io/guide/roadmap" rel="noopener">roadmap</a> to keep you posted on our current priorities. Some of the announcements in this post are updates on in-progress projects from the roadmap. This reflects our approach to incrementally rollout larger efforts and allows developers to provide early feedback that we can incorporate it into the final release.</p><p id="8c07">We collaborated with <a href="https://twitter.com/simpulton" rel="noopener">Lukas Ruebbelke</a> from the Angular community on updating the content of some of the projects to better reflect the value they provide to developers.</p><h2 id="6939">How to update to get version 11</h2><p id="0170">When you are ready to go run this command to update Angular and CLI:</p><pre><span id="5983">ng update @angular/cli @angular/core</span></pre><p id="ac5f">Head over to <a href="https://update.angular.io/" rel="noopener">update.angular.io</a> to find detailed information and guidance on updating. We always recommend upgrading one major release at a time to have the best update experience.</p><p id="732f">We hope you enjoy this feature update and be sure to let us know what you think here or on <a href="https://twitter.com/angular" rel="noopener">Twitter</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065091</guid>
            <pubDate>Thu, 12 Nov 2020 01:06:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ransomware Prohibition]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065057">thread link</a>) | @SCHiM
<br/>
November 11, 2020 | https://gru.gq/2020/10/18/ransomware-prohibition/ | <a href="https://web.archive.org/web/*/https://gru.gq/2020/10/18/ransomware-prohibition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><main><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><h2>Theres nothing that can‚Äôt be made worse</h2>
<p><a href="https://home.treasury.gov/policy-issues/financial-sanctions/recent-actions/20201001">The Treasury has moved to prohibit payment of ransomware ransoms</a>. They‚Äôve said there will be some exceptions, and it is obvious that this won‚Äôt be an effective complete global ban on payment. The result, a partial ban on payment, is the worst possible ransomware environment for victims. The impact of different legal regimes governing ransom payments are well documented and understood, <a href="https://rusi.org/publication/occasional-papers/closing-gap-assessing-responses-terrorist-related-kidnap-ransom">see RUSI here</a>.</p>
<p>Banning ransomware payments seems like a means of removing the financial reward for the gangs. It makes intuitive sense that if the victims cannot pay, then the gangs will stop using ransomware. Unfortunately the counterintuitive truth is that an incomplete, ineffective, partial ban will actually make objectively ransomware worse for everyone.</p>
<p>If there is a complete universal global ban, then ransomware ceases to be a source of money and the ransomware gangs stop. Or at least migrate to something else that makes money. We know this scenario is not going to happen.</p>
<h3>What‚Äôs the worst that can happen?</h3>
<p>A partial ban creates significant unintended consequences. Firstly, the ransomware gangs still make money from ransomware, so they do <strong>not</strong> cease operations. Then, to encourage payment they become more drastic and extreme in their actions. They have to make a stronger incentive to encourage people who are dissuaded by the ban, but might pay if given sufficient ‚Äúencouragement‚Äù. Then, because the prohibition on payment drives it underground ‚Äì with all the limited transparency and brutal mechanisms for enforcing compliance ‚Äî the ransom prices rise. This environment: higher prices, more aggressive ransomware gangs, fewer reputable companies negotiating and handling the ransom payments (and thereby managing the gangs); it is the worst possible situation for everyone.</p>
<h3>How to control attacker behaviour</h3>
<p>The only entity with power to control the behaviour of ransomware gangs is the one providing their protection. The gangs need a place to operate and somewhere to convert their crypto currency into hard currency. They are cashing out hundreds of thousands of dollars in crypto, and there is no way that isn‚Äôt raising ‚Äúknow your customer‚Äù alerts for money laundering.</p>
<p>The only controlling entity is the one that allows the gangs to operate. The gangs are completely at the mercy of whichever entity provides protection (yes, it‚Äôs Russia). This is the rule everywhere that kidnapping gangs operate, and ransomware gangs share this trait with kidnap&amp;ransom (K&amp;R) gangs with regards to their operational requirements.</p>
<h3>Private governance. Better than nothing? Hmm</h3>
<p>The current situation, where there is no criminalisation of payment has created a market place where a number of companies working with insurers are handling the vast majority of ransomware incidents. There are crisis responders who help the companies recover, who arrange a minimal payment, and who get paid by the insurers. This is market governance and it keeps the prices down because there is a sort of gentlemen‚Äôs agreement between the gangs and the payment companies. Also, the lack of prohibition means these companies operate in the open and they can share information about pricing etc internally and with each other. (Transparency)</p>
<p>The status quo is not the ideal world, but it is far better than the nightmare of ineffective partial prohibition.</p>
<div><p>Liked it? Take a second to support grugq on Patreon!</p><p><a rel="nofollow" target="_blank" href="https://www.patreon.com/oauth2/become-patron?response_type=code&amp;min_cents=100&amp;client_id=XPz53m5BPTmu-cnihK1RXoEaRoNywCco8VIPCNbwnAexV5YWdi_YG5Asup2LeG9p&amp;scope=identity%20identity[email]&amp;redirect_uri=https://gru.gq/patreon-authorization/&amp;state=eyJmaW5hbF9yZWRpcmVjdF91cmkiOiJodHRwczpcL1wvZ3J1LmdxXC8yMDIwXC8xMFwvMThcL3JhbnNvbXdhcmUtcHJvaGliaXRpb25cLyJ9&amp;utm_source=https%3A%2F%2Fgru.gq%2F2020%2F10%2F18%2Fransomware-prohibition%2F&amp;utm_medium=patreon_wordpress_plugin&amp;utm_campaign=457796&amp;utm_term=&amp;utm_content=post_unlock_button"><img src="https://i2.wp.com/gru.gq/wp-content/plugins/patron-button-and-widgets-by-codebard/images/become_a_patron_button.png?ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/gru.gq/wp-content/plugins/patron-button-and-widgets-by-codebard/images/become_a_patron_button.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p></div>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://gru.gq/2020/10/18/ransomware-prohibition/"
    dc:identifier="https://gru.gq/2020/10/18/ransomware-prohibition/"
    dc:title="Ransomware Prohibition"
    trackback:ping="https://gru.gq/2020/10/18/ransomware-prohibition/trackback/" />
</rdf:RDF>-->
</div></article>
		

		
		

		</main></div></div></div></div>]]>
            </description>
            <link>https://gru.gq/2020/10/18/ransomware-prohibition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065057</guid>
            <pubDate>Thu, 12 Nov 2020 01:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MacBook Air in Pure CSS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064721">thread link</a>) | @ent101
<br/>
November 11, 2020 | https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/e47219f7aa-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>7</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login?ref=https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064721</guid>
            <pubDate>Thu, 12 Nov 2020 00:24:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting a macOS Apple Silicon Kernel in QEMU]]>
            </title>
            <description>
<![CDATA[
Score 201 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25064593">thread link</a>) | @empyrical
<br/>
November 11, 2020 | https://worthdoingbadly.com/xnuqemu3/ | <a href="https://web.archive.org/web/*/https://worthdoingbadly.com/xnuqemu3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I booted the arm64e kernel of macOS 11.0.1 beta 1 kernel in QEMU up to launchd. It‚Äôs completely useless, but may be interesting if you‚Äôre wondering how an Apple Silicon Mac will boot.</p>

<h2 id="howto">Howto</h2>

<p>This is similar to my previous guide on running <a href="https://worthdoingbadly.com/xnuqemu2/">iOS kernel in QEMU</a>:</p>

<ul>
  <li>install macOS 11.0.1 beta 1 (20B5012D)</li>
  <li>run <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh"><code>build_arm64e_kcache.sh</code></a> to create an Apple Silicon Boot Kext Collection</li>
  <li>build the modified QEMU:
    <div><div><pre><code>git clone https://github.com/zhuowei/qemu
cd qemu
git checkout a12z-macos
mkdir build
cd build
../configure --target-list=aarch64-softmmu
make
</code></pre></div>    </div>
  </li>
  <li>create a modified device tree by running <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">DTRewriter</a> on <a href="https://updates.cdn-apple.com/2020SummerSeed/fullrestores/001-30235/6D8C0CA3-5952-4FD8-AEB3-4B4CADB626BC/iPad8,11,iPad8,12_14.0_18A5332f_Restore.ipsw">iPad Pro firmware</a>:
    <div><div><pre><code>python3 extractfilefromim4p.py Firmware/all_flash/DeviceTree.j421ap.im4p DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree
java DTRewriter DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb
</code></pre></div>    </div>
  </li>
  <li>run QEMU:
    <div><div><pre><code>./aarch64-softmmu/qemu-system-aarch64 -M virt -cpu max \
  -kernel /path/to/bootcache-arm64e \
  -dtb /path/to/DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb  \
  -monitor stdio -m 6G -s -S -d unimp,mmu \
  -serial file:/dev/stdout -serial file:/dev/stdout -serial file:/dev/stdout \
  -append "-noprogress cs_enforcement_disable=1 amfi_get_out_of_my_way=1 nvram-log=1 debug=0x8 kextlog=0xffff io=0xfff serial=0x7 cpus=1 rd=md0 apcie=0xffffffff" \
  -initrd /path/to/ios14.0b3/ramdisk.dmg $@
</code></pre></div>    </div>
  </li>
  <li>run gdb with <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/bootit.gdbscript">this script</a>:
    <div><div><pre><code>~/Library/Android/sdk/ndk/21.0.6113669/prebuilt/darwin-x86_64/bin/gdb \
-D /any/emptydir \
-x bootit.gdbscript
</code></pre></div>    </div>
    
  </li>
</ul>

<p>And the macOS kernel will <a href="https://gist.github.com/zhuowei/5aa668e76f387374cd56848313aa2197">boot into launchd</a>.</p>

<h2 id="is-this-useful">Is this useful?</h2>

<p><img src="https://worthdoingbadly.com/assets/blog/xnuqemu3/wwdc2018_no.jpg" alt="&quot;No.&quot; - Craig Federighi, WWDC 2018"></p>

<p>No:</p>

<ul>
  <li>Absolutely nothing is supported: literally only the kernel and the serial port works, not even the userspace since there‚Äôs no disk driver</li>
  <li>Userspace is instead borrowed from iOS 14 b3</li>
  <li>This will never boot anything close to graphical macOS UI</li>
  <li>Most importantly, even if I ever managed to fully boot the macOS kernel, emulating macOS is useless anyways.</li>
</ul>

<p>There are only three reasons I can think of for emulating macOS: security research, software development without a real Apple Silicon machine, and Hackintoshing. This approach will help with none of these:</p>

<ul>
  <li>Emulating iOS is useful for security research when jailbreak is not available. Apple Silicon Macs already support kernel debugging.</li>
  <li>Not useful for software dev: QEMU‚Äôs CPU emulation doesn‚Äôt support Apple Silicon-specific features, such as Rosetta‚Äôs memory ordering or the APRR JIT.</li>
  <li>as for Hackintosh: macOS uses CPU instructions that aren‚Äôt available yet on non-Apple ARM CPUs, so you can‚Äôt have hardware accelerated virtualization, only very slow emulation. Besides, Hackintoshes are often built when Apple‚Äôs own hardware isn‚Äôt fast enough; in this case, Apple‚Äôs ARM processors are already some of the fastest in the industry.</li>
</ul>

<p>I researched this this not because it‚Äôll be practical, but only to understand how an Apple Silicon Mac works. This will never be a <a href="https://www.youtube.com/watch?v=1AtE54HpXBM">Time Train</a>: only a <a href="https://youtu.be/UswpJh6Zvd8?t=119">science experiment</a>.</p>

<h2 id="what-i-did">What I did</h2>

<h2 id="create-kext-collection">Create kext collection</h2>

<p>On iOS, the kernel and its Kexts are packed together into a bootable file called the <strong>Kernel Cache</strong>.</p>

<p>macOS 11 uses an evolved version of this format, called the <strong>Boot Kext Collection</strong>.</p>

<p>Like the iOS kernelcache, it contains all Kexts required for booting, so the bootloader only needs to load it into memory and jump into it.</p>

<p>To create a boot kext collection, macOS 11 introduces the <a href="https://developer.apple.com/documentation/kernel/installing_a_custom_kernel_extension?language=objc"><code>kmutil</code></a> tool.</p>

<p>Here‚Äôs <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh">my script</a> to get <code>kmutil</code> to generate an arm64e kext collection.</p>

<p>It manually excludes some kexts because they cause kmutil to error out. Most are because they depend on ACPI, which is not available on Apple Silicon. I made a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/printexcludekexts.sh">script</a> to detect them.</p>

<p>Debugging <code>kmutil</code> failures on macOS 11 beta 3 was easy because it dumped out the entire NSError message. However, on macOS 11.0.1 beta, Apple decided to hide the full error message and only print an error code. I had to disable SIP and put a breakpoint on <code>swift_errorRetain</code> to get at the underlying error.</p>

<p>Once the <code>build_arm64e_kcache.sh</code> runs, a Boot Kext Collection is created at <code>~/kcache_out/bootcache-arm64e</code>, which can be booted in QEMU.</p>

<h2 id="disassembling-the-boot-kext-collection">Disassembling the boot kext collection</h2>

<p>For debugging, I also had to disassemble the newly created Boot Kext Collection in Ghidra.</p>

<p>Unfortunately, Ghidra isn‚Äôt updated for macOS 11 and will refuse to load the file, first giving an error about XML DOCTYPE, then - once that‚Äôs worked around - an <a href="https://github.com/NationalSecurityAgency/ghidra/issues/2192">IOException</a> from the invalid <code>ntools</code> value in the <code>LC_BUILD_VERSION</code> load command.</p>

<p>I created a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/patch_boot_kext_collection_for_ghidra.py">script</a> to fix up the kext collection so that Ghidra can load it.</p>

<p>Note that this is still not perfect - Ghidra still doesn‚Äôt fixup pointers or read symbols.</p>

<p>To get method names, I also disassembled the raw kernel file (<code>/System/Library/Kernels/kernel.release.t8020</code>) for cross reference. Note that the raw kernel is based at a different address - you can either rebase it in Ghidra, or just be careful to convert addresses.</p>

<h2 id="disable-pac">Disable PAC</h2>

<p>I already had a <a href="https://worthdoingbadly.com/xnuqemu2/">modified QEMU to boot an iOS kernel</a> (which has inspired others, such as <a href="https://alephsecurity.com/">Aleph Security</a>, to build much better open-source iOS emulation platforms)</p>

<p>In early 2019 I updated my modified QEMU to work with PAC for the iPhone Xs/Xr.</p>

<p>QEMU by that time already supported PAC instructions; however, Apple <a href="https://googleprojectzero.blogspot.com/2019/02/examining-pointer-authentication-on.html">modified</a> the crypto algorithm when implementing PAC, so the kernel fails to boot.</p>

<p>I decided to instead <a href="https://github.com/zhuowei/qemu/commit/16613b67ad15a902791109077ebfb1091f1873aa">turn PAC instructions</a> into no-ops, since I don‚Äôt know how Apple‚Äôs algorithm worked. This also makes it easier to debug the kernel.</p>

<p>Since the macOS DTK used an A12z processor, the modified QEMU just worked.</p>

<h2 id="device-tree">Device tree</h2>

<p>Like iOS, macOS on Apple Silicon uses a <strong>device tree</strong> to describe hardware to the kernel, and to pass boot arguments.</p>

<p>macOS 11.0.1 beta‚Äôs installer doesn‚Äôt contain a device tree for the DTK: I suspect it would be in the .ipsw files, which are not publically available. Instead, I borrowed the iPad Pro‚Äôs device tree from iOS 14 beta 3.</p>

<p>Like the <a href="https://worthdoingbadly.com/xnuqemu2/">iOS in QEMU experiments</a>, I first disabled every piece of hardware in the device tree except the serial port.</p>

<p>Unlike iOS, macOS expects some more information in the device tree:</p>
<ul>
  <li>ram size (since Macs have upgradeable RAM)</li>
  <li>nvram, otherwise panics with a null pointer while reading nonce-seed. (I copied nvram from <a href="https://gist.github.com/bazad/1faef1a6fe396b820a43170b43e38be1">bazad‚Äôs dump of an iPhone device tree</a>.)</li>
  <li>AMCC (KTRR) register positions</li>
  <li>System Integrity Protection status</li>
</ul>

<p>I rewrote my <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">device tree editor</a> to allow populating these extra params.</p>

<h2 id="up-to-launchd">Up to launchd</h2>

<p>I can‚Äôt actually boot a macOS root filesystem as I don‚Äôt have an emulated hard disk.</p>

<p>I don‚Äôt have a recovery ramdisk either: that would likely only be included in the DTK IPSW, which is not public.</p>

<p>Instead, I decided to boot with an iOS ramdisk to test the kernel, and disable signature checking using a GDB breakpoint.</p>

<p>I also couldn‚Äôt get the trustcache (list of executables trusted by the kernel) to load. I tried following <a href="https://alephsecurity.com/2019/06/25/xnu-qemu-arm64-2/">Aleph Security‚Äôs guide</a>, but macOS 11 is more strict than iOS 12 and needs it below the kernel; I couldn‚Äôt figure out the correct memory address.</p>

<h2 id="why-it-took-so-long">Why it took so long</h2>

<p>I actually had this blog post ready since <a href="https://gist.github.com/zhuowei/27816d39f234468cf2956479c0dea7ad">August 9th</a>, but I spent an extra 3 months trying to fix issues, since I really wanted to at least get to a shell!</p>

<p>Unfortunately:</p>
<ul>
  <li>debugging why drivers wasn‚Äôt loading was hard</li>
  <li>I couldn‚Äôt disable signature checking properly</li>
  <li>I wanted to wait until Apple released an A14 kernel instead of the DTK‚Äôs A12, so that we can look at how virtualization works, but they never did</li>
</ul>

<p>It‚Äôs now November 9th and Apple‚Äôs holding their press conference tomorrow: so it‚Äôs <a href="https://www.youtube.com/watch?v=9tAbhrDUrqM">now or never</a>.</p>

<h2 id="whats-left">What‚Äôs left</h2>

<p>I‚Äôm probably not going to be working further on this, but here‚Äôs what one can do to make this an actual useful research platform:</p>

<ul>
  <li>Figure out why half the drivers aren‚Äôt loading at all</li>
  <li>Write basic drivers/emulations:
    <ul>
      <li>probably emulate AIC in QEMU (based on Project Sandcastle‚Äôs Linux driver) since a custom interrupt controller Kext would be hard to write</li>
      <li>port Apple‚Äôs old <a href="https://opensource.apple.com/source/AppleMacRiscPCI/AppleMacRiscPCI-3.4/AppleMacRiscPCI.cpp.auto.html">PowerPC PCIE</a> drivers, since it‚Äôs too hard to emulate the Apple Silicon PCIE controller. This will allow us to connect a virtual hard drive.</li>
    </ul>
  </li>
  <li>Switch to the A14 kernel when Apple releases Apple Silicon Macs, so we can test virtualization</li>
</ul>

<h2 id="what-i-learned">What I learned</h2>

<ul>
  <li>How to modify QEMU to disable PAC</li>
  <li>How iBoot on Apple Silicon passes boot options in the device tree</li>
  <li>How to generate an Apple Silicon kernel cache without an Apple Silicon Mac</li>
  <li>How to fight <code>kmutil</code> for the real error message</li>
  <li>Never procrastinate on a blog post for three months</li>
</ul>

  </div>
</article>

      </div>
      
    </div></div>]]>
            </description>
            <link>https://worthdoingbadly.com/xnuqemu3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064593</guid>
            <pubDate>Thu, 12 Nov 2020 00:09:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overlooked source of Apple M1 performance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064570">thread link</a>) | @kwiromeo
<br/>
November 11, 2020 | https://kwiromeo.com/explaining-apple-m1-products-performance/ | <a href="https://web.archive.org/web/*/https://kwiromeo.com/explaining-apple-m1-products-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>When watching <a href="https://youtu.be/5AwdkGKmZ0I">Apple's Arm laptops</a> event, I couldn't help but wonder: where is all that performance coming from? During the event, there were two key points (that are not obvious, IMHO), that further explain where they are getting all that extra performance from.</p><p>But first, let's mention the obvious stuff, that plenty of analysts will anchor on, and that are valid:</p><ul><li><strong>More transistors is better</strong>: 5nm process allows more transistors in a chip. More transistors = more instructions processed = faster performance</li><li><strong>Small means low power consumption:</strong> 5nm process allows for lower power consumption. This is because, at that size, the transistor can operate between 0.7V - 1.2V per transistor[<a href="https://www.anandtech.com/show/15219/early-tsmc-5nm-test-chip-yields-80-hvm-coming-in-h1-2020">1</a>] (instead of 1V - 1.35V)[<a href="https://www.anandtech.com/show/16107/what-products-use-intel-10nm-superfin-demystified">2</a>]. At the numbers of billions of transistors, a small voltage difference means a lot for battery consumption.</li><li><strong>Specialized hardware gives an edge</strong>: Accelerators (like the neural engine) allow the Mac to offload specific tasks to another core, which leaves the main processor, M1 to do the work that is less specific (like compiling your code from XCode üòâ )</li></ul><h2 id="unified-memory-architecture-or-making-friends-with-physics-">Unified Memory Architecture (or Making Friends with Physics)</h2><p>When I was transitions careers to become a software developer, I came across this post about latency numbers of common computer components ( a link at <a href="http://norvig.com/21-days.html#answers">Peter Norvig post about it</a>), it occurred to me that all these numbers were proportional to the distance between the CPU and the location of the data. The further the electrons need to travel, the more time they will take. This is a massive oversimplification but illustrates the point well. There are other details to take into account as well. &nbsp;The one that comes to mind is that having the electrical signal only traveling though the SoC instead of the printed circuit board, avoid a lot of signal conditioning that would need to happen to keep signal integrity. Apple brought all their chips closer, which reduced the amount of travel time for every critical signal, as well as reduced the number of medium transitions (from an integrated circuit to a printed circuit board, back to an integrated circuit) as shown in the figure below. This results in higher data access speed by the CPU and the GPU, which translates to a faster experience for the end-user.</p><figure><img src="https://kwiromeo.com/content/images/2020/11/apple_m1_soc_vs_logic_board.jpg" alt="sketch of a logic board with separate chips compared to an apple M1 SoC"><figcaption>Showing the reduced distance of signal traveling for a logic board vs. a SoC :-)&nbsp;</figcaption></figure><h2 id="avoid-unnecessary-copies-or-the-gospel-by-a-c-performance-engineer-">Avoid Unnecessary Copies (or the gospel by a C++ performance engineer)</h2><p>In my year of learning and using C++, I've learned that (unnecessary) copies are bad, and Craig Federighi also knows this. During the presentation, he says</p><blockquote>"We built macOS on Apple Silicon to use the same data formats for things like video decode, GPU and display, so there's no need for expensive copying or translation"</blockquote><p>Why are copies they bad? This has to do with what happens when an object is copied. Here's a simple way to look at the process. Whenever a program issues a copy command, then the CPU needs to:</p><ul><li>read the memory location of the data,</li><li>then reserve memory where the data will be copied</li><li>then copy the data</li><li>then decide what to do with the original data</li></ul><p>When the source of the data copied remains, then the CPU is done. However, when the source data needs to be deleted, then there's the additional step of de-allocating memory space so that other instructions can use it. This problem is sometimes caught by the compiler, whenever possible, and performs an optimization called <a href="https://en.wikipedia.org/wiki/Copy_elision">copy elision</a> whenever it is obvious that a copy is unnecessary. However, while <a href="https://youtu.be/bSkpMdDe4g4">compilers are awesome</a>, they can't undo a programmer's lack of optimization knowledge. One solution that the C++ community found useful, is that we can help the compiler by specifying when copies are not needed. Since C++ 14, programmers can also tell the compilers that we don't need to go through a deep copy, instead, use a command <code>std::move</code>, which does the magic of not destroying and recreate the same thing. This saves CPU cycles, and improves performance.</p><p>From the Apple M1 MacBook presentation, Apple makes the above behavior default: <strong>instead of having the programmer choose between copying or reusing data, reuse of the data is the default</strong>. This makes the efficient behavior to be the default, and save programs from being slowed down by unnecessary copies</p><h2 id="things-i-may-have-missed-and-things-i-don-t-know-about-">Things I May Have Missed (and Things I Don't Know About)</h2><p>The above is a simplified view of the programming model of Apple's new M1 chip. By not having programmed for one, the above is my best guess at how the items noted in the keynote mentions would translate in hardware and software. It's possible that Apple simplified the programming paradigm of CPU vs GPU programming by obfuscating calls to GPU instructions in the macOS APIs. If all the hardware is one the same chip, the programmer doesn't need to know what sub-chip (CPU, GPU, Neural Engine, etc...) is doing the job, but just that the chip (M1) is doing it. From there, the job is for compiler optimization to take over, and make the best decision as to which sub-chip needs to process the instruction.</p><p>‚Äî</p><p>PS: if someone who knows the nitty gritty details of this, hit me up <a href="https://twitter.com/kwiromeo">@kwiromeo</a> on twitter. I would love to learn more about this.</p><hr><p>[1] AnandTech - <a href="https://www.anandtech.com/show/15219/early-tsmc-5nm-test-chip-yields-80-hvm-coming-in-h1-2020">Early TSMC 5nm Test Chip Yields 80%, HVM Coming in H1 2020</a></p><p>[2] AnandTech - <a href="https://www.anandtech.com/show/16107/what-products-use-intel-10nm-superfin-demystified">What Products Use Intel 10nm? SuperFin and 10++ Demystified</a></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://kwiromeo.com/explaining-apple-m1-products-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064570</guid>
            <pubDate>Thu, 12 Nov 2020 00:06:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Government Mandated Backdoors ‚Äì Security Explained]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064542">thread link</a>) | @sec-explained
<br/>
November 11, 2020 | http://securityexplained.fm/1245467/6099736-government-mandated-backdoors | <a href="https://web.archive.org/web/*/http://securityexplained.fm/1245467/6099736-government-mandated-backdoors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <p>Security Explained</p>
      <p>Government Mandated Backdoors</p>
      <p><span>Nov 11, 2020</span>
        <span>Season 1</span>
        <span>Episode 6</span>
      </p>
      <p>Chris Grayson, Drew Porter, Logan Lamb</p>
      <div>
        <div><p>The Department of Justice has recently released a new memo entitled "International Statement: End-To-End Encryption and Public Safety," and while it says a lot about helping trafficked kids and combating other crime, the memo outlines proposals that will do nothing of the sort. In this episode we discuss the content of this memo and the eerily similar-sounding EARN IT act, pick apart which parts of both are valid and which aren't, and talk about the real motivations behind these documents. We cover the current processes for gaining lawful access to data and how these new proposals don't amount to any true improvement upon existing capabilities.</p><p>As has been the standard theme for the past two decades, American privacy is under attack. These new positions reflect a stark step in the wrong direction if you care to preserve human privacy.</p></div>
      </div>
    </div>
  </div></div>]]>
            </description>
            <link>http://securityexplained.fm/1245467/6099736-government-mandated-backdoors</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064542</guid>
            <pubDate>Thu, 12 Nov 2020 00:00:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Python on .NET 5]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064143">thread link</a>) | @eatox
<br/>
November 11, 2020 | https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html | <a href="https://web.archive.org/web/*/https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <p><em>This post is an update on the Pyjion project to plug the .NET 5 CLR JIT compiler into Python 3.9.</em></p>
<p>.NET 5 was released on November 10, 2020. It is the cross-platform and open-source replacement of the <a href="https://github.com/dotnet/core"><strong>.NET Core</strong></a> project and the <strong>.NET</strong> project that ran exclusively on Windows since the late 90‚Äôs.</p>
<p>.NET is formed of many components:</p>
<ul>
<li>3 builtin languages, C#, F# and VB.NET, each with its own compiler</li>
<li>A standard library</li>
<li>A common intermediate language to abstract the high level languages from the core runtime. This is a standard known as <a href="https://github.com/tonybaloney/ecma-335/tree/master/docs">ECMA 335 CIL</a>.</li>
<li>A common language runtime (CLR) that compiles CIL into native machine code so that it can be executed and packages executables into .exe formats.</li>
</ul>
<p><img alt=".NET architecture" src="https://tonybaloney.github.io/img/posts/Common_Language_Infrastructure.png"></p>
<p>.NET 5 CLR comes bundled with a performant JIT compiler (codenamed RyuJIT) that will compile .NETs CIL into native machine instructions on Intel x86, x86-64, and ARM CPU architectures.</p>
<p>You can write code in a number of languages, like C++, C#, F# and compile those into CIL and then into native machine code (as a binary executable) on macOS, Linux, and Windows. Pretty neat.</p>
<p>But this is a blog about Python. So what does this have to do with Python?</p>
<p>Pyjion is a project to replace the core execution loop of CPython by transpiling CPython bytecode to ECMA CIL and then using the .NET 5 CLR to compile that into machine code. It then executes the machine-code compiled JIT frames at runtime instead of using the native execution loop of CPython.</p>
<h2>Very-quick overview of Python‚Äôs compiler</h2>
<p>When CPython compiles Python code, it compiles it into an intermediate format, similar to .NET, called Python bytecode. This bytecode is cached on disk so that when you import a module that hasn‚Äôt changed, it doesn‚Äôt compile it every time. You can see the bytecode by disassembling any Python function:</p>
<pre><code>&gt;&gt;&gt; import dis
&gt;&gt;&gt; def half(x):
...    return x/2
... 
&gt;&gt;&gt; dis.dis(half)
  2           0 LOAD_FAST                0 (x)
              2 LOAD_CONST               1 (2)
              4 BINARY_TRUE_DIVIDE
              6 RETURN_VALUE
</code></pre>

<p>To execute anything on a CPU, you have to provide the OS with machine-code instructions. This can be accomplished by compiling them up-front using a compiled like the C or C++ compilers. They compile code into executable formats as either shared libraries or standalone executables. <a href="https://tonybaloney.github.io/posts/extending-python-with-assembly.html"><em>See my post on Python/assembly for a bit more info on this topic</em></a>.</p>
<p>CPython converts the bytecode into machine code instructions like looping over them in a precompiled function, called the evaluation loop. This is essentially a big for loop with a switch statement. The compiled version of CPython that you‚Äôre running already has the instructions required. This is why CPython‚Äôs evaluation loop is an ‚ÄúAOT‚Äù, or ‚ÄúAhead of Time‚Äù compiled library:</p>
<p><img alt="diagram 1" src="https://tonybaloney.github.io/img/posts/Slide1.png"></p>
<p><strong>Note: There is a lot more to CPython‚Äôs compiler. I‚Äôve written a <a href="https://realpython.com/products/cpython-internals-book/">whole book on the CPython compiler and the internals of CPython</a> if you want to learn more.</strong></p>
<p>There are a few issues with this approach. The biggest is speed. A series of inline machine-code instructions is very performant. CPython has to make judgements at runtime for which code branch to follow every time your function is run. This leads to CPython being 100x slower in ‚Äútight-loop‚Äù problems where its executing the same thing again and again. The machine-code is compiled ahead of time and it has to loop around to get to the right instructions. Checkout my PyCon talk for a more in-depth explanation:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/I4nkgJdVZFA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>The most common way around this performance barrier is to compile Python extensions from C. This produces a custom binary with inline machine-code instructions for the task at hand. This is how most machine-learning and data science libraries like numpy, pandas, SKL are put together. This approach is still AOT compiling the code. It also requires a lot of knowledge of C. This approach has worked really well for the data science community, where algorithms can be performant and leverage low-level platforms <a href="https://numba.pydata.org/numba-doc/latest/cuda/index.html">like GPUs or specialised AI chipsets</a>.</p>
<p>There are a few issues with the AOT extension module approach. One is that it still uses the evaluation loop. C extension modules are a set of functions. Once you call the C-compiled function, its in the performant code, but your Python code that‚Äôs calling it still lives inside Python‚Äôs loop. If you want to leverage a compiled library and your Python code is doing some heavy number crunching, you end up having to use an API of functions, like numpy, instead of a more fluent Python API:</p>
<pre><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; a = np.ones([9, 5, 7, 4])
&gt;&gt;&gt; c = np.ones([9, 5, 4, 3])
&gt;&gt;&gt; np.dot(a, c).shape
(9, 5, 7, 9, 5, 3)
&gt;&gt;&gt; np.matmul(a, c).shape
(9, 5, 7, 3)
</code></pre>

<h2>What Pyjion does to solve this issue</h2>
<p>A few releases of Python ago (CPython specifically, the most commonly used version of Python) in 3.7 a new API was added to be able to swap out ‚Äúframe execution‚Äù with a replacement implementation. This is otherwise known as <a href="https://www.python.org/dev/peps/pep-0523/">PEP 523</a>. PEP 523 also added the capability to store additional attributes in <em>code objects</em> (compiled Python code.</p>
<p>Pyjion does not compile Python code. It compiles Python frames (code objects, like blocks, functions, methods, classes) into machine-code at runtime using a performant JIT:</p>
<p><img alt="diagram 2" src="https://tonybaloney.github.io/img/posts/Slide2.png"></p>
<p>CPython compiles the Python code, so whatever language features and behaviours there are in CPython 3.9, like the walrus operator, <a href="https://www.python.org/dev/peps/pep-0584">the dictionary union operator</a>, will all work exactly the same with this extension enabled. This also means that this extension uses the same standard library as Python 3.9.</p>
<p>Pyjion is a ‚Äúpip installable‚Äù package for standard CPython that JIT compiles all Python code at runtime using the .NET 5 JIT compiler. You can use off-the-shelf CPython 3.9 on macOS, Linux or Windows. After installing this package you just import the module and enable the JIT.</p>
<p>Once a frame has been compiled, the binary code is cached in memory and reused every time the function is called:</p>
<p><img alt="diagram 3" src="https://tonybaloney.github.io/img/posts/Slide3.png"></p>
<h2>Using Pyjion</h2>
<p>To get started, you need to have .NET 5 installed, with Python 3.9 and the Pyjion package (I also recommend using a virtual environment).</p>
<p>After importing pyjion, enable it by calling <code>pyjion.enable()</code> which sets a compilation threshold to 0 (the code only needs to be run once to be compiled by the JIT):</p>
<pre><code>&gt;&gt;&gt; import pyjion
&gt;&gt;&gt; pyjion.enable()
</code></pre>

<p>Any Python code you define or import after enabling pyjion will be JIT compiled. You don‚Äôt need to execute functions in any special API, its completely transparent:</p>
<pre><code>&gt;&gt;&gt; def half(x):
...    return x/2
&gt;&gt;&gt; half(2)
1.0
</code></pre>

<p>Pyjion will have compiled the <code>half</code> function into machine code on-the-fly and stored a cached version of that compiled function inside the function object.
You can see some basic stats by running <code>pyjion.info(f)</code>, where <code>f</code> is the function object:</p>
<pre><code>&gt;&gt;&gt; pyjion.info(half)
{'failed': False, 'compiled': True, 'run_count': 1}
</code></pre>

<p>You can see the machine code for the compiled function by disassembling it in the Python REPL.
Pyjion has essentially compiled your small Python function into a small, standalone application.
Install <code>distorm3</code> first to disassemble x86-64 assembly and run <code>pyjion.dis.dis_native(f)</code>:</p>
<pre><code>&gt;&gt;&gt; import pyjion.dis
&gt;&gt;&gt; pyjion.dis.dis_native(half)
00000000: PUSH RBP
00000001: MOV RBP, RSP
00000004: PUSH R14
00000006: PUSH RBX
00000007: MOV RBX, RSI
0000000a: MOV R14, [RDI+0x40]
0000000e: CALL 0x1b34
00000013: CMP DWORD [RAX+0x30], 0x0
00000017: JZ 0x31
00000019: CMP QWORD [RAX+0x40], 0x0
0000001e: JZ 0x31
00000020: MOV RDI, RAX
00000023: MOV RSI, RBX
00000026: XOR EDX, EDX
00000028: POP RBX
00000029: POP R14
...
</code></pre>

<p>The complex logic of converting a portable instruction set into low-level machine instructions is done by .NET‚Äôs CLR JIT compiler.</p>
<p>All Python code executed after the JIT is enabled will be compiled into native machine code at runtime and cached on disk. For example, to enable the JIT on a simple <code>app.py</code> for a Flask web app:</p>
<pre><code>import pyjion
pyjion.enable()

from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello_world():
    return 'Hello, World!'

app.run()
</code></pre>

<p>That‚Äôs it.</p>
<h2>Will this be compatible with my existing Python code? What about C Extensions?</h2>
<p>The short answer is- if your existing Python code runs on CPython 3.9 ‚Äì <strong>yes</strong> it will be compatible. To make sure, Pyjion has been tested against the full CPython ‚Äútest suite‚Äù on all platforms. In fact, it was the first JIT ever to pass the test suite.</p>
<p>Thats because this isn‚Äôt a Python runtime, it uses the existing Python compiler to compile your code into Python bytecode (low level instructions).</p>
<p>Pyjion uses the same dynamic module loader as CPython, so if you import a Python extension from your virtual environment, it will work just the same in Pyjion.</p>
<h2>Project History</h2>
<p>Pyjion isn‚Äôt new. Brett Cannon and Dino Viehland started the Pyjion project 4 years ago. This was the first JIT to pass the full CPython test suite.
There were some limitations to the original proof-of-concept:</p>
<ul>
<li>Written against an old version of .NET Core</li>
<li>Required custom patches of .NET and compiling from source</li>
<li>Required custom patches of CPython and compiling from source</li>
<li>Only worked on Windows</li>
<li>It was written for Python 3.6 before PEP 523 was agreed and merged</li>
</ul>
<p>Has much changed since Python 3.6? To the average user, not really. But under the hood, the implementation of a few things has completely changed:</p>
<ul>
<li>Function calls</li>
<li>Iterators</li>
<li>Exception Handling</li>
<li>Dictionary, list and set comprehensions</li>
<li>Generators and coroutines</li>
</ul>
<p>Actually, a <strong>lot</strong> has changed in the last few releases of CPython. The <a href="https://github.com/microsoft/Pyjion/pull/237">patch that I‚Äôm talking about</a> to get Pyjion working with the latest version of everything was a big undertaking‚Ä¶</p>
<p><img alt="not-much-has-changed" src="https://tonybaloney.github.io/img/posts-original/not-much-has-changed.png"></p>
<p>The goal with the latest patch was to get the project up to the condition of:</p>
<ul>
<li>Using the release binaries of .NET 5 and CPython 3.9</li>
<li>Making it work across all platforms</li>
<li>Implement the PEP523 interface</li>
<li>Implement all the new features of Python 3.9</li>
<li>Making the package ‚Äúpip installable‚Äù from PyPi</li>
<li>Improving the test coverage</li>
<li>Adding a disassembler (both machine-code and CIL) to aid development</li>
</ul>
<h2>Is this faster?</h2>
<p>The short answer a little, but not by much (yet).</p>
<p>JIT ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html">https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html</a></em></p>]]>
            </description>
            <link>https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064143</guid>
            <pubDate>Wed, 11 Nov 2020 23:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All known, public ACME servers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25063759">thread link</a>) | @riffic
<br/>
November 11, 2020 | https://docs.https.dev/list-of-acme-servers | <a href="https://web.archive.org/web/*/https://docs.https.dev/list-of-acme-servers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><p><span>All known, public ACME servers</span></p></div></div></div></div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="3b72c1eb76324fcea60749a49d24393c" autocorrect="on" spellcheck="true" data-gramm="false"><p data-key="a7423c5bafea4eb385c7e07d0826ea40"><span><span data-key="2d2fcbc1b03349468d8ed1673c1750e0"><span data-offset-key="2d2fcbc1b03349468d8ed1673c1750e0:0">All endpoints on this list are compliant with RFC 8555.</span></span></span></p><p data-key="43f617bd0df447d6b37ca47b12b0a2b7"><span><span data-key="48583dcada4646548bc5caa4bbdd9b9b"><span data-offset-key="48583dcada4646548bc5caa4bbdd9b9b:0">Please note that different CAs have varying legal terms, pricing, and some difference in their ACME issuance policies. Consult each CA's documentation for more information.</span></span></span></p><ul data-key="7ae709311946447e951eaf568ddef55a"><li></li><li></li><li></li><li></li><li></li></ul></div></div></div></div></div></div>]]>
            </description>
            <link>https://docs.https.dev/list-of-acme-servers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063759</guid>
            <pubDate>Wed, 11 Nov 2020 22:27:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deploy professionally built algo-traders in 5 mins with 0 code]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25063678">thread link</a>) | @tjs8rj
<br/>
November 11, 2020 | https://areyouinterested.co/site/quantbase/ | <a href="https://web.archive.org/web/*/https://areyouinterested.co/site/quantbase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="hero-1"><p id="subheading">Deploy algorithms from top hedge funds,<br> rank and use 100s of users‚Äô algorithms,<br> or create new algo-traders effortlessly</p>

              <div id="interested">
                <h3>Are you interested?</h3>
                <div id="buttons">
                  <p><a href="https://areyouinterested.co/site/quantbase/yes" id="yes">Yes</a>
                  <a href="https://areyouinterested.co/site/quantbase/no" id="no">No</a>
                </p></div>
              </div>

            </div></div>]]>
            </description>
            <link>https://areyouinterested.co/site/quantbase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063678</guid>
            <pubDate>Wed, 11 Nov 2020 22:18:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case for Make: The New Old Build Tool]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25063540">thread link</a>) | @chill1
<br/>
November 11, 2020 | https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool.html | <a href="https://web.archive.org/web/*/https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>If you've never had to migrate a project from one build system to another, I envy you. How sweet it is to have not experienced the psychological torture that is unwinding years of hacks and work-arounds layered on-top of one another during a legacy project's lifetime. But nothing lasts forever. You too will know this feeling eventually. Or maybe not. Let's talk about how you can avoid this fate by using a new (very old) build system called <a href="https://www.gnu.org/software/make/">Make</a>.</p>
<h2 id="the-case-against-modern-build-systems">The Case Against Modern Build Systems</h2>
<p>Modern build systems use an insane number of dependencies:</p>
<ul>
<li><a href="https://npm.anvaka.com/#/view/2d/gulp">gulp</a> - 296 nodes, 513 links</li>
<li><a href="https://npm.anvaka.com/#/view/2d/grunt">grunt</a> - 170 nodes, 277 links</li>
<li><a href="https://npm.anvaka.com/#/view/2d/webpack">webpack</a> - 82 nodes, 119 links</li>
</ul>
<div>
  <div>
    <p><img width="1920" height="1080" src="https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool/images/dep-tree-gulp.jpg" alt="" title="gulp's dependency graph">
      <img width="1920" height="1080" src="https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool/images/dep-tree-grunt.jpg" alt="" title="grunt's dependency graph">
      <img width="1920" height="1080" src="https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool/images/dep-tree-webpack.jpg" alt="" title="webpack's dependency graph">
    </p>
    <p><b>gulp</b> (left), <b>grunt</b> (center), <b>webpack</b> (right)</p>
  </div>
</div>

<p>Of the build systems mentioned above, only one is still under active development. That one is <a href="https://webpack.js.org/">webpack</a>, which is used by the popular web framework <a href="https://reactjs.org/">React</a>. If you are unfamiliar with webpack, good for you. It is a gigantic piece of software that does too many things. From my experience, webpack can be nice to bootstrap a simple proof-of-concept project, but eventually you will hit a wall where you need to do some extremely hacky work-arounds to do something that it doesn't easily support.</p>
<p>Why am I talking about dependencies? Well...</p>
<blockquote>
<p>Earlier this week, many npm users suffered a disruption when a package that many projects depend on ‚Äî directly or indirectly ‚Äî was unpublished by its author, as part of a dispute over a package name. The event generated a lot of attention and raised many concerns, because of the scale of disruption, the circumstances that led to this dispute, and the actions npm, Inc. took in response.</p>
</blockquote>
<p>This was the <a href="https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm">"leftpad incident"</a> as it has become to be known.</p>
<p>The package author mentioned in the above quote unpublished more than 250 packages from the npm registry in a very short time. This broke thousands of projects and caused a lot of headaches for maintainers and developers throughout the ecosystem.</p>
<p>This alone should be a strong reason to try to limit your project's exposure to huge dependency graphs.</p>
<p>But in case you are not yet convinced, here are a few more reasons:</p>
<ul>
<li>Less time wasted fixing the build process after upgrading dependencies.</li>
<li>Reduce the attack surface that could allow malicious/rogue dependencies to:<ul>
<li><a href="https://www.veracode.com/blog/research/abusing-npm-libraries-data-exfiltration">Exfiltrate sensitive data</a> such as keys or secrets via the file system or environment variables.</li>
<li>Utilize (abuse) system resources to mine cryptocurrencies.</li>
<li>Use system's network capacity to spam, run proxy servers, or DOS attack other services.</li>
</ul>
</li>
</ul>
<h2 id="the-case-for-make">The Case For Make</h2>
<p>Make. Is. Everywhere. You very likely already have it installed on your system. Or if not, it will be available to install via your system's package repository.</p>
<p>Make is ideal for running builds or as a general purpose task runner. It allows you to easily incorporate bash commands and tools that already exist on your system. All of these tools have been around forever, are well tested, and they are stable.</p>
<h3 id="make-in-practice">Make In Practice</h3>
<p>Here is an example Makefile that includes comments that explain each section:</p>
<pre><code>







BUILD<span>=</span>build
ALL_CSS<span>=</span><span>$</span><span>(</span>BUILD<span>)</span>/css/all.css
SRC<span>=</span>src















<span>.PHONY</span><span>:</span> build\
clean\
fonts\
images

<span>build</span><span>:</span> fonts images <span>$</span><span>(</span>ALL_CSS<span>)</span>

<span>clean</span><span>:</span>
  
  rm -rf <span>$</span><span>(</span>BUILD<span>)</span>/*


CSS_FILES<span>=</span><span>$</span><span>(</span>SRC<span>)</span>/css/fonts.css\
<span>$</span><span>(</span>SRC<span>)</span>/css/reset.css\
<span>$</span><span>(</span>SRC<span>)</span>/css/styles.css\
<span>$</span><span>(</span>SRC<span>)</span>/css/responsive.css

<span><span>$</span>(ALL_CSS)</span><span>:</span> <span>$</span><span>(</span>SRC<span>)</span>/css/
  mkdir -p <span>$$</span><span>(</span>dirname <span>$@</span><span>)</span>
  rm -f <span>$</span><span>(</span>ALL_CSS<span>)</span>
  for file in <span>$</span><span>(</span>CSS_FILES<span>)</span><span>;</span> do \
    echo <span>"/* $$file */"</span> &gt;&gt; <span>$</span><span>(</span>ALL_CSS<span>)</span><span>;</span> \
    cat <span>$$file</span> &gt;&gt; <span>$</span><span>(</span>ALL_CSS<span>)</span><span>;</span> \
    echo <span>""</span> &gt;&gt; <span>$</span><span>(</span>ALL_CSS<span>)</span><span>;</span> \
  done

<span>fonts</span><span>:</span>
  
  mkdir -p <span>$</span><span>(</span>BUILD<span>)</span>/fonts/OpenSans
  cp -r node_modules/open-sans-fontface/fonts/**/* <span>$</span><span>(</span>BUILD<span>)</span>/fonts/OpenSans/

<span>images</span><span>:</span>
  
  mkdir -p <span>$</span><span>(</span>BUILD<span>)</span>/images/
  cp -r <span>$</span><span>(</span>SRC<span>)</span>/* <span>$</span><span>(</span>BUILD<span>)</span>/images/</code></pre>
<p>It is basically bash with the added syntax for build targets. Make will only build files whose inputs have been modified. So in this example, if you change one of your CSS source files then the all.css build file will be recompiled.</p>
<p>The example above is quite simple. It only includes copying and concatenating files. You can add dependencies as you need them to perform minification of JavaScript files, syntax highlighting, templating, and more.</p>
<p>For more advanced build processes, it's a good idea to execute bash (or node.js) scripts from within the Makefile. This gives you the structure and functionality of Make with the flexibility of whichever scripting language you prefer.</p>
<p>During the last few years, I've migrated several projects to Make and it has turned out to be a great move for the long-term maintainability of those projects. You can have a look at some of these projects for more complex, real-world examples using Make:</p>
<ul>
<li><a href="https://github.com/samotari/pay-no-way">PayNoWay</a> - Bitcoin double-spending app for Android</li>
<li><a href="https://github.com/samotari/bleskomat">Bleskomat</a> - Lightning Network ATM hardware + software project</li>
</ul>
<p>Choose Make as your next project's build system. Your future self will thank you!</p>

		</div></div>]]>
            </description>
            <link>https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063540</guid>
            <pubDate>Wed, 11 Nov 2020 22:01:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reviving Yo: How to Patch an APK]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25063163">thread link</a>) | @wesleyac
<br/>
November 11, 2020 | https://blog.wesleyac.com/posts/patching-apks | <a href="https://web.archive.org/web/*/https://blog.wesleyac.com/posts/patching-apks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>I got talking to a friend the other day about <a href="https://en.wikipedia.org/wiki/Yo_(app)">Yo</a>, the app where you can send your friends the word "Yo." It's nominally still around, run off donations, but the SSL certificate for the API server has been expired for a little while, so the app doesn't work anymore. Not to worry, though, that's something we can fix by patching the APK pretty quickly.</p>

<p>First, <a href="https://play.google.com/store/apps/details?id=com.justyo">download Yo on the Play Store</a>. Then, download <a href="https://play.google.com/store/apps/details?id=com.ext.ui">APK Extractor</a>, and use it to download the APK off your phone (you'll need to get it onto your computer somehow, I emailed it to myself). You should have a file called <code>Yo_base.apk</code>.</p>

<p>Next, install <a href="https://ibotpeaches.github.io/Apktool/"><code>apktool</code></a>, and use it to decompile the APK:</p>
<div><pre><code data-lang="">apktool if Yo_base.apk
apktool d Yo_base.apk
</code></pre></div>
<p>This should make a directory called <code>Yo_base</code>, which you can edit however you want. I changed <code>https://newapi.justyo.co</code> to <code>http://newapi.justyo.co</code> in <code>res/values/strings.xml</code>, but you could also make other changes as well. Once you've done that, recompile the APK like so:</p>

<p>Now there should be a <code>Yo_base/dist/Yo_base.apk</code> file, but it's not signed, so we can't use it. Signing it isn't too tricky though. Using the <code>keytool</code> and <code>jarsigner</code> tools that come with the JDK:</p>
<div><pre><code data-lang="">keytool -genkey -v -keystore my-release-key.keystore -alias alias_name -keyalg RSA -keysize 2048 -validity 10000
jarsigner -verbose -sigalg SHA1withRSA -digestalg SHA1 -keystore my-release-key.keystore Yo_base/dist/Yo_base.apk alias_name
</code></pre></div>
<p>It'll ask you to make a password and enter your name and things, I don't think it really matters what you choose. Once you've done all that, you can move the <code>Yo_base/dist/Yo_base.apk</code> file to your phone, click through all the fuss that Android makes about running a unsigned APK, and start Yoing away! This also works for other apps just as well :)</p>

          </div></div>]]>
            </description>
            <link>https://blog.wesleyac.com/posts/patching-apks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063163</guid>
            <pubDate>Wed, 11 Nov 2020 21:24:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to master being high on ownership-a guide for Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062859">thread link</a>) | @justanotherpm
<br/>
November 11, 2020 | https://blog.justanotherpm.com/how-to-master-being-high-on-ownership/ | <a href="https://web.archive.org/web/*/https://blog.justanotherpm.com/how-to-master-being-high-on-ownership/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
            <p>This post is a follow up to the last one: <a href="https://blog.justanotherpm.com/why-is-ownership-such-an-important-quality-for-great-product-managers-5-reasons/">Why is Ownership Important for Product Managers</a>.</p><p>Today, we talk about different ways to build high ownership as a product manager, especially a new product manager.</p><ol><li><strong>Be the most knowledgable person on the team.</strong> Its easier said than done. That is why you should make learning a priority when you join a new team or organization. Learn about your product, business, customers and industry. Read internal and external documents, get access to the relevant data / dashboards, and talk to those who have the most information. Every time I join a new team, I regularly meet with senior leaders from different teams to get as much knowledge as possible.</li><li><strong>Understand your team's and the company's goals</strong>. The direct manager and other PMs on the team are usually the best people to share the most relevant context. Talking to the engineers will &nbsp;always bring a different perspective. In these discussions, your main aim should be to uncover "what" is the goal and "why" is it the focus at that time.</li><li><strong>Strong relationships with stakeholders.</strong> If you've been reading my posts, you know that I mention <em>building relationships</em> in almost all my guides. And that is because building relationships is truly one of the most important things to do. I always actively work on building relationships from day one. It helps me gain more knowledge, influence the same stakeholders (if and when required), and to remove blockers in critical situations. Basically, these relations make execution seamless.</li><li><strong>Visibility, transparency, openness.</strong> Create processes that encourage transparency and openness to share feedback. Create visibility for others in your progress. It is a signal of strength. It conveys a simple yet powerful message: "you are doing your best. Despite that, things will go wrong. And when that happens, you are open to feedback and to learn from others' experience"</li><li><strong>Execution. Get shit done.</strong> There is nothing that speaks louder of a PM's ownership than her ability to <em>ship</em> products. Executing projects and tasks is the most tangible signal that non-technical stakeholders use to assess you. Exceptions do exist.</li></ol><p>High ownership is sometimes confused with owning a large set of projects or an extended portfolio of products. But high ownership is more about identifying and working only on critical projects, and <strong>always delivering</strong> on them.</p><hr><p>Get bite-sized summaries of the best product management content in your WhatsApp inbox: <a href="http://bit.ly/wajapm">http://bit.ly/wajapm</a></p>
    </div>
        
</article>                            </main>
</div>
        </div></div>]]>
            </description>
            <link>https://blog.justanotherpm.com/how-to-master-being-high-on-ownership/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062859</guid>
            <pubDate>Wed, 11 Nov 2020 20:54:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Owning Your Own Business]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062764">thread link</a>) | @rossdavidh
<br/>
November 11, 2020 | https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/ | <a href="https://web.archive.org/web/*/https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p>So, you want to strike out on your own, and start your own business?  Great!  Here are a few things you might want to know about that.  They are based on my own experience as an independent contractor (computer programmer), what I've seen being married to an owner (with a partner) of a small retail shop, and what I've seen and heard talking to multiple small business owners of various kinds in the last twenty years.  Some of them are successful, some of them were not, and some were successful but didn't like it, and stopped.  The recurring thing I've seen (and my own lived experience) is that owning and running your own business is not what most people think it is like, so perhaps this will be useful to you as you set out on a different path.</p>



<h2>Lesson 1: You Still Have A Boss</h2>
<p>The most important thing to know, is that being a business owner is NOT like being an employee, except without the boss.  This is, I think, the number one misconception that most people have.  In fact, not only do you still have a boss, but your boss:</p>
<ul>
<li>gives you no paid vacation</li>
<li>gives you no paid sick leave</li>
<li>docks your pay if you break the rules</li>
<li>...but doesn't tell you what those rules are</li>
<li>doesn't (generally) pay overtime if you work long hours or on weekends</li>
<li>does (usually) dock your pay if you take off early</li>
<li>may occasionally pay bonuses, but won't tell you ahead of time what you have to do to get them</li>
</ul>

<p>Your boss is, of course, the market.  New small business owners (and even old ones, sometimes) think they get to decide when they will work, and therefore that customers will show up when they want them to.  But in practice, customers show up when THEY want to, and you need to be ready for them.  If you are not, generally speaking, they will go elsewhere or just forego spending entirely.  The same logic applies to all of the rest of the items in the list above.  The market does all of this, and it is up to you to figure it out, because it won't tell you ahead of time.</p>

<p>Which means really, you have to figure out the rules, and impose them on yourself.  So, when owning your own business, it is not as if you no longer have a boss who makes you do stuff you don't want to do.  It's more like, you also have to be that boss, forcing yourself to do things you don't feel like doing, because there isn't anyone else there to tell you to do it.  That's what "being your own boss" really means; it's not the same as not having a boss.  If you aren't able to make yourself do things when they need doing, even though you don't feel like it right then, then being your own boss may not be for you.</p>

<h2>Lesson 2: The Loop</h2>
<p>There is a process, which you need to know about and think about, as you run a small business.  It is a loop, which can be divided into four parts:</p>
<ol>
<li>Try something (typically involves spending $$ and/or time)</li>
<li>Get results (typically involves receiving $$ or saving time)</li>
<li>Observe that result (notice what just happened)</li>
<li>Plan your next thing to try</li>
</ol>

<img src="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/loop.png">

<p>It may seem so simple and straightforward, that there's no point in stating it.  But, most business failures can be traced ultimately to one of the following breaks in the loop:</p>
<ul>
<li>Not keeping enough data about what happened (failure in the "observe" step, above)</li>
<li>Not taking time to plan what to do (failure in the "plan" step)</li>
<li>Not actually doing what was planned (failure in the "try" step)</li>
</ul>

<p>Let's look at each of these failures in more detail.</p>
<h3>Failure to Observe</h3>

<img src="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/loop_without_observe.png">

<p>Part of this, is the common conception that keeping a lot of data about what happened is a drag, and only corporate losers do that sort of thing and starting your own business is all about getting away from that.  Part of it is a failure to understand (per Lesson 1: You Still Have A Boss) that having your own business doesn't mean you get to do whatever you want.  One example I've often seen, is in the decision of what hours a day, and what days of the week, to be open.</p>

<p>Now, it is certainly true that you have the right to close your store whenever you want to.  Perhaps you don't want to be open on Sundays, because your religious beliefs prohibit it.  It's your life.  More typically, though, people just sort of don't want to be open on Sundays, but don't want to pay any penalty for this.  Therefore, they convince themselves that nobody shops on Sundays anyway.  This is, essentially, trying to get out of working on Sundays, without letting your boss see you doing it and docking your pay.  This is employee-type thinking.  Once you are a business owner, not an employee, this way of thinking makes no sense anymore.  If you want to know the cost of not being open on Sundays, you need to collect some data.  For example, you can keep your store open 7 days a week at the beginning, and keep track of how much your sales are each day.  If you do, you will probably find that, just as you want to do a good bit of your shopping on Sunday, so do your (potential) customers.  Sunday is not quite as busy as Saturday, but probably it is more busy than, say, Monday or Tuesday.</p>

<p>But, the lesson is NOT that you should be open on Sundays.  The lesson is that you should not take my word for it, or your own intuition; you should keep track of exactly what happens when you do stay open on Sundays, and look at the cold, hard, unfeeling, pitiless numbers in a spreadsheet before you decide that it's not worth staying open on Sunday.  Of course, if it's a religious thing, or you just don't care about making money, or for whatever other reason you decide to close on Sundays anyway, that is entirely up to you.  But DON'T fail to collect the data.  Don't make decisions based only on your intuition, because when you do that it's the equivalent of the boss asking his employees, "I dunno, should we be open on Sundays?".  What they tell him is based on what they want, not what's good for the business.  You are the boss, and your intuition is like the employees here.  Your intuition will tell you what it wants to be true.  Keep track, numerically, in a spreadsheet, of what happened.  That's what tells you what really is true.</p>

<p>The same logic applies to having a 25% off sale, having a special event at your business, selling a new product, and so forth.  It's your decision, but fortify yourself against wishful thinking by keeping careful, numerical, track of what happened.  You should have, in a spreadsheet, a record of what happened at this time last week, last month, last year.  If sales are slow, is this because they always are slow this time of year?  Or this day of the week?  Or is there something new going on, that you need to look into?  If you spent money to get a new kind of merchandise in your store, how much did you pay for it, and how much did it sell for?  How much do you spend on things, and how much of that goes to waste?  You should know, and you should not rely on your memory or your intuitive hunch.  Put it in a spreadsheet, and look at it.  When it comes time to pay the bills, the bank's computer will take a cold, hard, pitiless look at how much money is in your bank account.  Therefore, you need to be taking a cold, hard, pitiless look at what is working, and what isn't, so that you will be able to pay those bills.</p>

<h3>Failure to Plan</h3>

<img src="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/loop_without_plan.png">

<p>Let's assume, for the moment, that you have a decent work ethic.  You're willing to hustle to get things done.  This is mostly a good thing, but there is one case where it can get you into trouble, and that's when you're not willing to pause, and plan, because there's so much work to do and you want to get started.  Many times, there are more things that need doing, than there is time to get it all done.  It may seem like this means you need to hustle more.  In fact, it means you need to stop hustling, at least for a little while, and think carefully about what needs to be done first.</p>

<p>Once again,this may mean you end up acting a little like those boring loser corporations that you were wanting to get away from when you decided to start your own business.  Planning, to some people, is boring and seems pointless because nothing gets actually accomplished.  But you don't have enough time, energy, and money to do everything you can think of that needs doing.  When you have your own business, you NEVER run out of things that need doing.  This means you need to carefully plan, and prioritize, so that what you actually do is what is most likely to help.  Just because you are working hard, doesn't mean you are doing what is most important right then.  Make a list of all the things that need doing, put them in an order from highest priority to lowest, and start from the top.  Don't work on the first thing you happen to see that needs doing.  Work on the thing at the top of the list of priorities, and leave some time in your schedule for making sure that list is right.  Is the thing at the top more important than what is below it?  If you cannot get everything done, is the stuff at the top of your list what you would choose to do?  Or will you discover that you have been sprinting nonstop for weeks and much of what you did turned out to be pointless, because (for example) you spent a lot of time painting the great looking sign for your bakery's special Easter sidewalk sale, but never got the permit from the city to have a sidewalk sale so you cannot do that, and the time spent on painting that sign is wasted.  Work on the most necessary things first, and realize that not everything you can think of, will get done.  Even though stopping to plan takes away some of your (already insufficient) time, it also helps increase the odds that you are spending your time wisely, and not wasting it.</p>

<p>All of the above discussion about prioritizing your time, also applies to prioritizing your money.  You will run out of money, if you spend it on anything that seems like a good idea.  There are absolutely more sensible-sounding, good ideas to spend your money on, than you have money.  So prioritize.  You cannot run your business, if you don't pay rent.  You cannot ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/">https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/</a></em></p>]]>
            </description>
            <link>https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062764</guid>
            <pubDate>Wed, 11 Nov 2020 20:45:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software engineering photonics and color science]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062325">thread link</a>) | @pete314
<br/>
November 11, 2020 | https://www.softcolorsoftware.com/resources/software-engineering-photonics-and-color-science/ | <a href="https://web.archive.org/web/*/https://www.softcolorsoftware.com/resources/software-engineering-photonics-and-color-science/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<hr><h2>Software engineering photonics and color science</h2>

<p>

<img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science.png">

</p>
<p>Hi everybody, I am Petri Piirainen, a co-founder and chief technology officer of SoftColor company. Welcome to this video lecture about SoftColor's fifteen-year software engineering photonics and color science story. </p>

<p>This lecture is part of the University of Eastern Finland's photonics applications course and lecture series. </p>

<p>Since 2005 we have made photo editing automation software. Our photonics journey is slightly different from traditional optics-focused companies, which you have met during this lecture series. </p>

<p>During this lecture, I will tell you what we have learned about developing and selling photonics applications. </p>

<hr><h2>My history with photonics and software engineering </h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_2.png"></p><p>I have an MSc degree in computer science (from the University of Eastern Finland). I studied computer science in a digital signal processing program, and then I had mandatory applied mathematics and physics as minor studies. With physics studies, there was a lot of photonics and color science courses. </p>

<p>I started by software business and engineering career during high school in the 90s.  In 2005 we founded SoftColor Oy, and since that, we have developed faster, easier, and better photo editing automation software.</p>


<hr><h2>Photonics applications: What have we learned?</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_3.png"></p><p>First, I would like to talk a little bit about photonics applications, the beauty and the beast of engineering photonics applications. We have learned that developing useful photonics applications is very hard and requires a lot of engineering and math knowledge. It is challenging because photonics applications (software or hardware) usually have to quickly process tons of data and calculations. </p>

<hr><h2>Technical elements of useful photonics application</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_4.png"></p><p>My favorite thing with photonics is that all photonics applications contain four types of engineering. </p>
<ul>
<li>Physics</li>
<li>Mathematics</li>
<li>Electrical engineering</li>
<li>Computer science </li>

</ul>

<p>But there is also one thing, which is fascinating.  All photonics applications require a lot of arts too.</p>

<ul>
<li>Image quality</li>
<li>Industrial design</li>
<li>User experience</li>
<li>User interaction</li>
<li>User interfaces</li>

</ul>

<p>This mixture of arts and engineering is my main topic for you today.</p>

<hr><h2>Topics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_5.png"></p><p>My topics today are:</p>

<ul>
<li>A short history and introduction to our company</li>
<li>What we do and how products work</li>
<li>How have we mixed photonics with software engineering</li>
<li>What we learned about to make useful photonics applications</li>
<li>And there will be a bonus "homework" for  you</li>

</ul>


<hr><h2>Story of SoftColor Oy</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_6.png"></p><p>Let's have a quick look at our products and technology. </p>

<hr><h2>What we do</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_7.png"></p><p>We make faster, easier, and better photo edition automation software. Our software runs on Windows PCs and servers.</p>

<hr><h2>SoftColor Oy</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_8.png"></p><p>We founded SoftColor in 2005, so our company is now a teenager. </p>

<p>We have three products: Automata Server, Automata Pro, and PhotoEQ.</p>

<p>We are located in Joensuu, Finland. </p>

<hr><h2>Our business</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_9.png"></p><p>We sell our software on the internet. And all our products are free to try before buying.  Our customers are:</p>

<ul>
<li>Printing industry</li>
<li>Photographers</li>
<li>360 photography</li>
<li>Newspapers</li>
<li>Ad agencies</li>
<li>Repro</li>
<li>Real estate</li>
<li>Car retail</li>
<li>Photo editors</li>
<li>Office workers</li>
<li>Developers</li>

</ul>

<p>Our customers are from the English speaking world. But we have a lof customers from Germany and Spain too.</p>

<hr><h2>Our research and development</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_10.png"></p><p>Our research and development work is to make our photo editing automation software faster, more comfortable, and better to use.</p>

<hr><h2>SoftColor engine </h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_11.png"></p><p>Our applications use the SoftColor engine. It is the brains and heart of our software. </p>

<p>SoftColor engine does all photo editing automation tasks, color correction, image editing, and color management. </p>

<p>To get this automation working. We have combined computer vision, color science, computer graphics, digital signal processing, and machine learning techniques into one packet. </p>

<p>This combination of different engineering tools has made our photo editing automation to work very well.</p>

<hr><h2>How does our color and tone correction work?</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_12.png"></p><p>Let's check how our photo enhancement automation works, with good or bad photos. </p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_13.png"></p><p>We can fix white balance, exposure, and contrast problems automatically. Results are very natural and good looking.</p>

<p>Our correction works with challenging photos too.</p>

<p>Our white balance correction will you very natural results.</p>

<p>It works with all kinds of photos and cameras.</p>

<p>You will never lose any shots. We can fix them.</p>

<hr><h2>SoftColor and photonics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_14.png"></p><p>Let's talk a little bit about photonics. </p>

<hr><h2>We are processing colors, not pixels.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_15.png"></p><p>To get photo editing automation working better. We have learned computers to process colors, not pixels. </p>

<hr><h2>A good photo is a combination of art and science.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_16.png"></p><p>The most challenging part of photo editing automation is to get results that make our customers happy. The problem is that the excellent photo is a combination of art and science. There is eighty percent of art in the superb picture and only twenty percent of engineering.  </p>

<p>For this problem, we managed to create an excellent solution.</p>

<hr><h2>Traditional image editing and photonics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_17.png"></p><p>There is photonics behind every camera, display, and photo-editing algorithms. </p>

<hr><h2>SoftColor engine and photonics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_18.png"></p><p>We have changed to traditional photo editing. We built our engine to take colors first.  This solution has helped us to make better photo enhancement automation.</p>

<hr><h2>We have made a color correction automation that has tools for science and art.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_19.png"></p><p>Our applications offer tools to our customers to combine art and science with photo editing automation. </p>

<p>Science part:</p>

<ul>
<li>Layer based processing</li>
<li>Statistical analysis </li>
<li>Metadata analysis</li>
<li>Machine vision</li>
<li>Machine learning</li>

</ul>

<p>and the arts:</p>

<ul>
<li>Color grading for mass photo processing</li>
<li>Selective color adjustments </li>
<li>No workflow limitations</li>

</ul>

<hr><h2>SoftColor engine benefits</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_20.png"></p><p>We are processing the colors, not pixels. This approach gives three significant benefits:</p>

<ul>
<li>More accurate automatic correction</li>
<li>Batch color grading for photos</li>
<li>Easier and accurate customization</li>

</ul>


<hr><h2>SoftColor engine technical details</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_21.png"></p><p>Let's take a look inside our engine.</p>

<hr><h2>Layer based processing</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_22.png"></p><p>We use layers based processing, which means that all correction and image processing tools are separate layers. </p>

<p>You will full control of how each step works. For automatic color and tone correction, we have six layers. </p>

<ul>
<li>Rich dynamics enhancer</li>
<li>Luminosity enhancer</li>
<li>White balance </li>
<li>Natural color temperature</li>
<li>Exposure and contrast</li>
<li>Color grading</li>

</ul>


<hr><h2>Spectral illumination estimation technology for better color correction</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_23.png"></p><p>To get better automatic results for all kinds of photos. We have developed spectral illumination estimation technology. </p>

<hr><h2>Same parameters for human and computer</h2>
<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_24.png"></p><p>We use spectral illumination detection to create the same parameters for the user and the computer. </p>

<p>We calculate these parameters from the original image by using:</p>

<ul>
<li>Spectral  illumination estimation from RGB image</li>
<li>Metadata analysis EXIF &amp; camera data</li>
<li>Machine learning for estimated data</li>

</ul>

<p>From this data, we generate parameters for automatic correction.</p>

<p>When users change parameters, they will alter the same settings as our automatic correction uses.</p>

<p>The solution is possible by mixing spectral illumination data with computer graphics techniques.</p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_25.png"></p><hr><h2>What we have learned about photonics applications during the last fifteen years</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_26.png"></p><p>There six things which we have learned. Which are the requirements for good photonics software or hardware applications.</p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_27.png"></p><ol>
<li>Software is the glue for photonics applications</li>
<li>Optical engineering</li>
<li>Software engineering</li>
<li>Electrical engineering</li>
<li>User experience engineering</li>

</ol>

<p>These are things and skills which are required. But there is always one challenge, battery, and CPU limitations.  It is the reason why we all need to tune our algorithms, software, and hardware better every day.</p>

<hr><h2>Bonus "homework." Useful resources for your entrepreneur career</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_28.png"></p><p>There has been a lot of questions about how to get started with the photonics business.  Here are two great resources to read or watch.</p>


<hr><h2>To watch "Halt and Catch Fire" tv-series.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_29.png"></p><p>Halt and Catch Fire is an excellent and very realistic business world tv-series.  The tv-series follows some players in the 80s technological revolution that lead to an information society. It is quite an unknown series, but now it is available in streaming services. </p>



<p>You will learn a lot about the hardware and software business. </p>

<p>The tv-series covers the following useful topics:</p>

<ul>
<li>Venture capital</li>
<li>Bootstrapping</li>
<li>Human resources</li>
<li>Risk management </li>
<li>Work/life balance</li>
<li>Legal stuff (due diligence, intellectual property rights, revenge engineering process) </li>
<li>Fortune 500 vs. startup life </li>

</ul>

<p>And there is a lot of 80s and 90s retro computing and nostalgia too.</p>

<p>
<a href="https://en.wikipedia.org/wiki/Halt_and_Catch_Fire_(TV_series)" target="_blank">Halt and Catch Fire in Wikipedia</a>
</p>


<hr><h2>To read "Masters of Doom" book.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_30.png"></p><p>Masters of Doom book tells the story of ID software. The makers of Wolf3D, Doom, and Quake games. </p>

<p>There are fascinating stories about how small teams can change the world. For the photonics industry, there is interesting how ID software took the latest research topics from computer graphics and science. And how they utilized them to make their games better.</p>

<p>This book is also available as an audiobook.</p>

<p>
<a href="https://en.wikipedia.org/wiki/Masters_of_Doom" target="_blank">Masters of Doom book in Wikipedia</a>
</p>


<hr><h2>Summary </h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_31.png"></p><p>That was our 15 years story with software engineering, photonics, and color science. I hope that you have learned something new for photonics career or business.</p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_32.png"></p><p>Here is a summary of the main topics:</p>

<ul>
<li>A good photo is a combination of art and science</li>

</ul>

<ul>
<li>Software is the glue for photonics applications.</li>

</ul>

<ul>
<li>Photonics is a mixture of science, engineering, and arts.</li>

</ul>

<hr><h2>Feedback and comments</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_33.png"></p><p>
It would be great to hear your feedback about this lecture! <a href="https://www.softcolorsoftware.com/contact/">
</a></p><a href="https://www.softcolorsoftware.com/contact/">
</a><center><a href="https://www.softcolorsoftware.com/contact/">
Just drop us a message.</a>
</center>


</div></div>]]>
            </description>
            <link>https://www.softcolorsoftware.com/resources/software-engineering-photonics-and-color-science/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062325</guid>
            <pubDate>Wed, 11 Nov 2020 20:02:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[.new TLD Shortcuts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062243">thread link</a>) | @twapi
<br/>
November 11, 2020 | https://whats.new/shortcuts/ | <a href="https://web.archive.org/web/*/https://whats.new/shortcuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://whats.new/shortcuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062243</guid>
            <pubDate>Wed, 11 Nov 2020 19:56:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust as a productive high-level language]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062055">thread link</a>) | @praveenperera
<br/>
November 11, 2020 | https://omarabid.com/rust-high-level-language | <a href="https://web.archive.org/web/*/https://omarabid.com/rust-high-level-language">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="container">
  <article id="wBiL7EUi4Kw16ahNjk6hmU">
	<time datetime="2020-11-10">November 10, 2020</time>
  
	<p>Rust is often critiqued as a <a href="https://news.ycombinator.com/item?id=24536645">not a very productive</a> programming language. It is true that there is a bit of a learning curve to be able to program in Rust; but beyond that, I think it pays off in productivity; and massively I must say.</p>

<p>I haven‚Äôt been using Rust for production much; maybe a bit more than a year. The static type checks means I‚Äôm getting much less bugs in my code, and spend considerably less time in debugging. I can safely say that, for me, Rust is more productive than JavaScript, PHP or Python and the margin keeps getting larger as I get more acquainted with the ecosystem.</p>

<hr>

<p>To entice your interest, here is a situation that I handled lately: I have a program that writes logs to <a href="https://en.wikipedia.org/wiki/Syslog">syslog</a> and the terminal. The program compiles and functions correctly on my development machine. However, it returned an error when I deployed it to an <a href="https://alpinelinux.org/">Alpine</a> Docker container. Turns out, Alpine doesn‚Äôt have a running syslog service by default.</p>

<p>Now that‚Äôs fine, the program functioned correctly. But I don‚Äôt care much for syslog on deployment since the program is running inside a container. One solution is to remove the syslog <a href="https://en.wikipedia.org/wiki/Sink_(computing)">drain</a> but I need that for development. I can use <a href="https://doc.rust-lang.org/reference/conditional-compilation.html">conditional compilation</a>; but there is a better option: If syslog fails, for whatever reason, just ignore that and move on.</p>

<p>So let‚Äôs take a look at the old code. </p>

<pre><code>    let syslog_drain = syslog_drain()?;
    let term_drain = term_drain()?;
</code></pre>

<p>This code creates two logging drains: one for syslog and one for the terminal. It uses the <a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html">? operator</a> to evaluate the result. If the function returns an error, execution will stop and the error bubbles back to the top of the program.</p>

<p>I have no idea how the syslog or any particular drain fails. And honestly, I don‚Äôt want to get into these details. What I want is to check if there is a failure; and if so ignore that particular drain. Or return a <a href="https://docs.rs/slog/2.5.2/slog/struct.Discard.html">Discard drain</a>.</p>

<p>The <a href="https://doc.rust-lang.org/std/result/">Result</a> type and <code>? operator</code> make this particularly easy. So here is the code that does that.</p>

<pre><code>    let syslog_drain = syslog_drain().unwrap_or(discard_drain()?);
    let term_drain = term_drain().unwrap_or(discard_drain()?);
</code></pre>

<p>And that‚Äôs it. This code now compiles and runs correctly. If syslog is running, it‚Äôll write logs to syslog and the terminal. Otherwise, it‚Äôll write logs to the terminal and syslog is skipped. There are no conditions, no complicated checks and it‚Äôs perfectly readable.</p>

<hr>

<p>There is more to Rust productivity than that. Macros, Iterators, Advanced Traits and Types, the new Async system. Once you are comfortable with all of these, you are now able to be productive, safe and fast.</p>

  <figure id="kudo_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>133</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>133</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]>
            </description>
            <link>https://omarabid.com/rust-high-level-language</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062055</guid>
            <pubDate>Wed, 11 Nov 2020 19:40:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the fractal nature of effort estimates]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061983">thread link</a>) | @adamkl
<br/>
November 11, 2020 | https://realfiction.net/2016/02/28/on-the-fractal-nature-of-effort-estimates | <a href="https://web.archive.org/web/*/https://realfiction.net/2016/02/28/on-the-fractal-nature-of-effort-estimates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p><span>February 28, 2016</span> in<span><a href="https://realfiction.net/tags/software-development">software-development</a></span></p></div><p>We still live in a world where people want to play the game of estimates. Indeed, in some industries this may (kind of) work (Yes, this is the 30th automobile we are designing, and the requirements may be more or less the same (not really) than for the 1st automobile we designed). Alas, in software development we are still regularly in trouble if we try to estimate what it will cost us to finalize some software project.</p><p><a href="https://www.quora.com/Why-are-software-development-task-estimations-regularly-off-by-a-factor-of-2-3">I am not the first one</a> to compare the creation of software to a hike following some coast-line. Let's play along, though. Our project needs us to walk around the Lake Constance. First, we have a broad overview of what software we want to build. We look at the lake at the 50km scale of Google Maps:</p><p><img src="https://realfiction.net/assets/LakeConstance-50kmScale.png"></p><p>192 km, nice. We start adding more detail, i.e. we look closer to the aim of walking around the lake...</p><p><img src="https://realfiction.net/assets/LakeConstance-20kmScale.png"></p><p>205 km, still on track.</p><p><img src="https://realfiction.net/assets/LakeConstance-5kmScale.png"></p><p>231 km. Only 20% more expensive than the original estimate, looks like we are gaining confidence. We do see that we may be taking some shortcuts for which we could account with some risk percentages.</p><p>We decide to start the project...</p><p><img src="https://realfiction.net/assets/LakeConstanceProject-Leg1.png"></p><p>We have burned through almost a quarter of the original budget. <strong>50%</strong> more than what we wanted to burn up to now. We also had to make up some additional rules with regard to rivers and the like (we go to the next bridge and cross there).</p><p>The next leg then became a total disaster...</p><p><img src="https://realfiction.net/assets/LakeConstanceProject-Leg2.png"></p><p>57 km...compare this to the estimate on the 20km scale:</p><p><img src="https://realfiction.net/assets/LakeConstance-20kmScaleFromNear.png"></p><p>15 km...<strong>it took almost 4 times the estimate to cover the desired distance!</strong> What happened?!</p><p><img src="https://realfiction.net/assets/LakeConstance-Unforeseen1.png"></p><p>We didn't find a damn bridge!</p><p><img src="https://realfiction.net/assets/LakeConstance-Unforeseen2.png"></p><p>A place where our efforts were about to explode. We took a shortcut!</p><p>And so on, and so on. The scope of the project didn't change, but the expenses are exploding!</p><p>Do I see affirmative nods by fellow software developers?</p><p>If this metaphor works so well, the question is: <strong>Why</strong> does it work so well?</p><p>It may have to do with the nature of fractals. One of the main characteristics of fractals is that they are self-similar. Zoom into a structure, and you will find additional structures, very similar to the ones you already saw from <em>"higher up"</em>. We find self-similarities in large projects, too. On a large scale, we may draw up necessary activities to get from one place to the other. The activities are inter-dependent. We identify problems for which we provide slack. <strong>This happens again and again while we zoom into activities</strong>. Some time into the process we will arrive at the point where we don't see additional value in planning - we will start walking. Whatever detail we put into the planning (Check our 3rd plan of the lake circumference, it looks pretty exact!), it doesn't protect us from additional activities, inter-dependencies and problems that we did not foresee.</p><p><img src="https://realfiction.net/assets/zoominto.jpg"></p><p>Other things that we haven't even gotten into, but will probably greatly affect our estimating efforts:</p><ul><li>The effort involved in monitoring the activities (as witnessed by measuring out the distance) grows exponentially.</li><li>In an actual software project, the expected results of the project will inevitably change - In our metaphor this amounts to either a changing coast line, or, when facing the sheer amount of effort required to trace a particular part of the line, to the statement <em>"we will do this later"</em>.</li></ul><p>Does all of this information help us in any way? I am not sure. However, especially in the case of tracing coastlines, mathematics has a concept that encapsulates the increase in effort with increasing detail: The <a href="http://fractalfoundation.org/OFC/OFC-10-4.html">fractal dimension</a>. Hence, if there is more to tracing coastlines than being a metaphor to developing software, there may be a chance that the mathematics of fractals can help us in understanding better the capabilities and, more importantly, the inadequacies of estimating efforts in a large software project.</p><h2>Previous &amp; Next</h2><h2>Comments</h2></article></div></div>]]>
            </description>
            <link>https://realfiction.net/2016/02/28/on-the-fractal-nature-of-effort-estimates</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061983</guid>
            <pubDate>Wed, 11 Nov 2020 19:33:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most misunderstood billion dollar industry in the world?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25061784">thread link</a>) | @mattob
<br/>
November 11, 2020 | https://www.fourpm.co/p/cannabis-is-the-most-misunderstood | <a href="https://web.archive.org/web/*/https://www.fourpm.co/p/cannabis-is-the-most-misunderstood">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>Every morning I write an email discussing the business and the people behind cannabis. If you would like to receive it directly in your inbox, subscribe now.</strong></em></p><p>Friends, </p><p>I woke up on Wednesday, June 21st <em>ready</em>.&nbsp;   </p><p>It was my final day of high school, and I was preparing to take an economics exam later that day. It was also same day that I was preparing to move half-ways across the world from a small town in rural Ireland to Toronto, Canada. </p><p>About 4 hours later after the completion of my economics exam, I found myself on the way to the airport (some 5 hours away to Dublin) to catch a flight to Toronto at 2.AM the next morning - all of this courtesy of reading a brilliant book called Narconomics.</p><p>Within this book, I found one of the most logical arguments that I had ever heard, an argument that we as a society should effectively embrace legalizing all drugs. This was not a moral argument, instead it was a highly convincing argument based on economic theory and practical use cases from around the world, and I wanted to learn more. </p><p>After many months of diligent planning, I arrived in Toronto, slightly jet lagged after more than 15 hours of travel. With less than $500 CAD in my bank account I had a modest first few months upon my arrival in Canada, however, shortly afterwards I found myself working as a budtender at a cannabis retail store in Vancouver, B.C. </p><p>Starting off at this ground level provided me with the best foundation that I could have asked for as an entry point into the cannabis industry, and it was from here that I worked tirelessly over the next two years to gain all of the insights that I craved into everything that encompassed the cannabis industry to learn exactly how it operated.</p><p>As I fast approach the three year anniversary for my joining the cannabis industry. Here are the five biggest things I‚Äôve learned over the last three years.</p><h4><strong>1.</strong> Assume everything you currently know about cannabis is wrong</h4><p>When I first started working in the cannabis industry, I had little to no understanding of cannabis. </p><p>Although in the beginning this seemed to serve as a significant disadvantage, with all of my initial interactions with customers being very uninformed, within four weeks of working as a budtender my understanding of cannabis had already surpassed everyone I was directly working with by virtue of assuming that I knew nothing to begin with.</p><p>My own approach was to spend every moment on days off, or wasn‚Äôt serving a customer in store to read as much of the research that has been done on cannabis to date, of which their was surprisingly a lot more than what I had expected there to be.     </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F52e41090-cae2-4424-8754-d5b591f7362a_3872x2581.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F52e41090-cae2-4424-8754-d5b591f7362a_3872x2581.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/52e41090-cae2-4424-8754-d5b591f7362a_3872x2581.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:539504,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><h4><strong>2.</strong> Get very comfortable with constant change</h4><p>One of the most important lessons I have learned from working within the cannabis industry is to get very comfortable with the idea of <em><strong>constant change</strong></em>. </p><p>In the three years that I have worked within the cannabis industry I have seen the industry transition out of the black market into a fully federally legal framework -  with cannabis stocks being traded on some of the most prestigious stock exchanges in the world, and with this we have seen cannabis companies valuations experience meteoric rises and with this meteoric declines shortly afterwards. </p><p>Although all of these changes may seem significant, I suspect that many of these changes will seem minor in comparison to some of the changes I see on the horizon for the cannabis industry in the coming years. </p><h4><strong>3.</strong> <a href="https://www.youtube.com/watch?v=jtRFd1N43y4">The best is yet to come</a></h4><p>When I joined the cannabis industry three years ago working in the store below, what captivated me the most was not where the industry was at this point, what captivated me was where I thought the industry would be 20 years from now.</p><p>Here in Canada it‚Äôs estimated that 15% of Canadians over the age of 15 have consumed cannabis within the past 12 months, while this number is 78.5% for those who have consumed alcohol.</p><p>As someone who no longer consumes alcohol in favor of consuming cannabis derived products, I am perhaps blinded by my own basis here, however, the approach that I took to make this determination was simply by reading research. </p><p>Truthfully, when presented with the known evidence, going <a href="https://myhighly.com/cannabis-101/the-rise-of-cali-sober">Cali Sober</a> was the easiest decision I have every made.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faab6ddb0-7d5b-42c9-9310-3a4472738a2b_1328x747.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faab6ddb0-7d5b-42c9-9310-3a4472738a2b_1328x747.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/aab6ddb0-7d5b-42c9-9310-3a4472738a2b_1328x747.png&quot;,&quot;height&quot;:747,&quot;width&quot;:1328,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1461029,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><h4><strong>4.</strong> We stand on the shoulders of giants</h4><p>Sometimes we have to look to the the past to understand the future. </p><p>To understand the future of the cannabis industry I personally think it‚Äôs essential to understand the path that has brought us to where we are today. </p><p>This path has been paved by activists who‚Äôs endless passion for this amazing plant has ensured that the draconian policies our politicians have sought to implement don‚Äôt prevail, and that those who need access to cannabis will be provided that access. </p><p>Their is also a long list of researchers to thank for providing the cannabis industry with the evidence that it needed to fights its case in court to prove that cannabis is not the cause of many modern problems, rather the solution. </p><h4><strong>5.</strong> An enormous regulatory burden </h4><p>Regulations, regulations, regulations. </p><p>As someone who operates a cannabis business, operating in the industry is by no means an easy challenge as it requires a level of attention to detail that adds on significant costs to cannabis companies who choose to operate in the legal market.</p><p>In the long run I personally think it‚Äôs inevitable that the legal industry will overtake the existing legacy markets that exist around the world today through cheer innovations, of which their is no shortage on the horizon.</p><p>In the meantime all cannabis operators will have to operate within a high fragmented regulatory environment that will make it harder to expand into new markets at the rate which perhaps many would would like to, however, many are already paving the way. </p><h4><strong>A final word.</strong></h4><p>In an industry whereby the only constant is change, it‚Äôs abundantly clear that the cannabis industry will undergo many additional changes in the coming years.</p><p>Courtesy of being a member of this community, my aim is to provide you with the most up to date information to allow you to understand all of the complexity that is the cannabis industry.</p><p>If learning about this billion industry is something of interest to you then sign up now so you don‚Äôt miss the first issue which will be published Saturday the 17th of October 2020. Did I mention that it‚Äôs free for the first 1,000 members? </p><p>- Matthew O‚ÄôBrien</p><p>üëâ&nbsp;If you enjoyed reading this post, feel free to share it with friends!  </p><p data-attrs="{&quot;url&quot;:&quot;https://fourpm.substack.com/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share 4 PM&quot;,&quot;class&quot;:null}"><a href="https://fourpm.substack.com/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share"><span>Share 4 PM</span></a></p><p>‚Ä¶ For more like this, make sure to sign up here:  </p></div></div>]]>
            </description>
            <link>https://www.fourpm.co/p/cannabis-is-the-most-misunderstood</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061784</guid>
            <pubDate>Wed, 11 Nov 2020 19:16:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notion Timeline View]]>
            </title>
            <description>
<![CDATA[
Score 287 | Comments 147 (<a href="https://news.ycombinator.com/item?id=25061781">thread link</a>) | @AlphaWeaver
<br/>
November 11, 2020 | https://www.notion.so/guides/timeline-view-unlocks-high-output-planning-for-your-team | <a href="https://web.archive.org/web/*/https://www.notion.so/guides/timeline-view-unlocks-high-output-planning-for-your-team">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/guides/timeline-view-unlocks-high-output-planning-for-your-team</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061781</guid>
            <pubDate>Wed, 11 Nov 2020 19:15:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On solving your own tiny annoyances]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061753">thread link</a>) | @rjyoungling
<br/>
November 11, 2020 | https://www.younglingfeynman.com/essays/airbnb2 | <a href="https://web.archive.org/web/*/https://www.younglingfeynman.com/essays/airbnb2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-8f03ceb2cec309b9bc66"><div><p><em>EDIT: I‚Äôm gonna open this essay up with the caveat that there‚Äôs a lot of non-Airbnb stuff in here. That‚Äôs because I wanted to draw parallels between Airbnb and other startups. I‚Äôm less interested in lazily inspiring you with examples like most sites do, and more in what you should take away to increase your probability of success.</em></p><p><em>I‚Äôve also decided to split the original essay up into 4 parts (shipping 1 part each day). It was almost half an hour long and I feel like that just would‚Äôve been too cumbersome to consume.</em></p><p><em>Hope you enjoy.</em></p><p><em>RJ</em></p><p><em>Links to the rest of the good stuff:</em></p><p><a href="https://www.younglingfeynman.com/essays/airbnb"><em>The Dumbest Startup That Ever Worked‚Ää ‚Äî What You Can Learn From Airbnb‚Ää ‚Äî PART 1</em></a></p><p><a href="https://www.younglingfeynman.com/essays/airbnb2"><em>The Dumbest Startup That Ever Worked‚Ää ‚Äî What You Can Learn From Airbnb‚Ää ‚Äî PART 2</em></a></p><p><a href="https://www.younglingfeynman.com/essays/airbnb3" target="_blank"><em>The Dumbest Startup That Ever Worked‚Ää ‚Äî What You Can Learn From Airbnb‚Ää ‚Äî PART 3</em></a></p><p><a href="https://www.younglingfeynman.com/essays/airbnb4" target="_blank"><em>The Dumbest Startup That Ever Worked‚Ää ‚Äî What You Can Learn From Airbnb‚Ää ‚Äî PART 4</em></a></p><p><em>TLDR: Lesson 1: It‚Äôs possible for you to make things better. Lesson 2: Solve your own tiny problem. Lesson 3: Validate quickly and double down when it works. Lesson 4: It‚Äôs easy to connect the dots ex-post-facto. Lesson 5: Finding product/market fit from day one is fiction.</em></p><p><em>We‚Äôll cover lessons 2 and 3 today. Let‚Äôs get this show on the road, yes?</em></p><p>When Brian moved to SF and decided to live with Joe to figure out what their billion-dollar startup was gonna be, he quickly learned that in order to make rent in SF, you have to sell a kidney. Probably both if you‚Äôre one of those fancy, pampered types that enjoys the finer things in life such as, you know, nutrition.</p><p>He didn‚Äôt have his part of the rent though ($1150).</p><p>But that weekend, there just so happened to be <a href="https://www.sxsw.com/news/2016/sxsw-eco-award-winners-and-conference-highlights/" target="_blank">an international design conference at SXSW</a>, and they noticed that all the hotels on the website were listed fully booked.</p><p>They figured: well, designers are gonna have to stay somewhere, we don‚Äôt have the money to make rent, so what if we made a makeshift Bed and Breakfast?</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_29128"><div><p>But Brian and Joe didn‚Äôt have any beds. However, Joe had some airbeds leftover from camping so they changed their idea to an Airbed and Breakfast (Airbnb).</p><p>They ended up hosting a 35yr old woman from Boston, a 45yr old father of 5 from Utah, and a <a href="https://nextshark.com/meet-man-became-airbnbs-first-guest/" target="_blank">30yr old man from India</a>. Oh‚Ä¶ and they made rent.</p><p><em>If you just want to read about Airbnb, skip the following section and pick back up at: BUILD SOMETHING SMALL THAT YOU WANT AND THINK IS DOPE.</em></p><p><strong>Notice that they weren‚Äôt trying to build a unicorn</strong>. They just needed to make rent and it seemed like a cool, fun thing to try.</p><p>This is a surprisingly common theme in startups. Travis made a similar remark about the origins of Uber:&nbsp;</p><blockquote><p>‚Äò‚ÄôWhen we first started it wasn‚Äôt about taking over the world. It wasn‚Äôt about taking on corruption in every city around the world. It was actually just about being baller in San Francisco.‚Äô‚Äô</p></blockquote><p><em>Because literally every POS article on Business Insider type websites doesn‚Äôt have the accurate quote and more annoyingly can‚Äôt be bothered with a source either, here it is:</em></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_32526"><div><p><em>Travis Kalanick at Startup School 2012 (2 years after founding Uber).</em></p><p>Back when computers were expensive, Woz built his own because he wanted one for himself. That was the origin of Woz, Jobs, and for 12 days Wayne‚Äôs, Apple.</p><blockquote><p>‚Äò‚ÄôI had no idea that I was taking exactly the right steps up this nice smooth ladder that leads up to the Apple II.‚Äô‚Äô</p></blockquote><p>Notice the nice smooth ladder he‚Äôs talking about. You start small and incrementally work your way up. You don‚Äôt start with the vision of the trillion-dollar Apple we have today.</p><blockquote><p>‚Äò‚ÄôI told my father: ‚ÄòSomeday, I‚Äôm gonna own a 4K Nova Computer, so I can write programs.‚Äô And he said: ‚ÄòThat‚Äôll cost as much as a house.‚Äô And I said: ‚ÄòI‚Äôll live in an appartment.‚Äô I would rather have a computer in my life than a house.‚Äô‚Äô&nbsp;</p></blockquote></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_36039"><div><blockquote><p>‚Äò‚ÄôI was giving away the schematics, passing them out. No copyright notices, no nothing. Passing out the listings of the code I wrote to other people in my club [<a href="https://en.wikipedia.org/wiki/Homebrew_Computer_Club" target="_blank">The Homebrew Computer Club</a>]. I was saying: ‚ÄòHere, you can build your own.‚Äô And nobody really had the time to build it. And, so Steve Jobs came by and said: ‚ÄòWhy don‚Äôt we make a PC board to save them the time to build it.‚Äô</p></blockquote></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_38102"><div><p>There‚Äôs this idea that in order to change the world you have to start with the vision to cure cancer or build a quantum computer or something.</p><p>I don‚Äôt really like that approach. Maaaybe it‚Äôs useful for a second-time founder but for a first-time founder, I think it‚Äôs way too overwhelming.</p><p>When you‚Äôre ambitions are so grandiose, it‚Äôll scare you into inaction.</p><p>We know from BJ Fogg‚Äôs work (2009) on behavior science that if ability is low (something is extremely hard to do), then even with high levels of motivation, behavior won‚Äôt occur. And reminders (called prompts) will just make you frustrated.&nbsp;</p><p>But there‚Äôs another problem too. Namely, there are just so many examples of solutions to tiny irritations that escalate into big companies.</p><p>There are a few reasons for that but one of them is that it brings clarity, simplicity, and focus. My favorite example of this is The Point vs. Groupon. [4]</p><p>So be open to solving small problems in your life. Yesterday I saw Mikael Cho, founder of Unsplash talk about this on Twitter. It‚Äôs a good reminder that small stuff really can become big.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_48211"><div><p>And if after that you‚Äôre still inspired to tackle the hard and obvious problems, you‚Äôll be in a much more favorable position. [5]</p><p>They went from idea to execution fast. There was no complex infrastructure. No complicated back-end designed to handle the influx of millions of people. No, it was all very ghetto. We need to pay the rent, so can we get 3 people to <a href="https://nextshark.com/meet-man-became-airbnbs-first-guest/" target="_blank">pay us $80</a> to stay with us and sleep on our Airbeds during the conference?</p><p>Most of the time when founders do that stuff, it‚Äôs just another way to hide.</p><p>One of the best models we have today is the <a href="https://okdork.com/resources/validate-business/" target="_blank">Kagan Validation Model</a>: Get 3 paying customers in 48 hours without spending any money. (Sumo Group founder and early Facebook/Mint employee <a href="https://www.youtube.com/c/OkDork" target="_blank">Noah Kagan</a>.)</p><p>Sure, that might eliminate ideas that would‚Äôve worked had you spend more resources (false negatives). But it also prevents you from spending months or even years on ideas that are never gonna work (false positives).&nbsp;</p><p>Since the latter is a far more common problem, it‚Äôs more important to prevent that from happening.</p><p>By making the system overly sensitive, you‚Äôll prevent wasting resources on ideas that‚Äôll never work and the stuff that does make it through your filter is much more likely to succeed.</p><p>Think about it. If you can presell something based on a phone call then that leaves all the tools in your toolbox available to grow it. Whereas if you launch with the perfect product and marketing after years of refining it behind closed doors, then where exactly are you gonna take it from there? What‚Äôs left to optimize?</p><p>This does beg the question: ‚Äò‚ÄòWhy make the system overly sensitive in the first place? Why not adjust it so it‚Äôs perfect?‚Äô‚Äô Because that‚Äôs not possible. There‚Äôs no way to create a system that will sort good ideas from bad ideas perfectly. So you‚Äôll always have to be biased toward identifying good ideas and throwing away good ones that seemed bad (false negative) or identifying bad ideas and continuing to work on bad ideas that seem good (false positives).</p><p><em>This essay </em><a href="https://www.younglingfeynman.com/essays/paradigm" target="_blank"><em>Paradigm Shift: Drastically Increase The Odds of Success</em></a><em> goes into depth on how to think about false positives and negatives.</em></p><p><em>[4] From </em><a href="https://www.younglingfeynman.com/essays/startstartup" target="_blank"><em>The Right Way To Start A Startup</em></a><em>:</em></p><blockquote><p>Andrew at the NY Tech Meetup in 2008:</p><p>‚Äò‚ÄôThe biggest mistake we made with The Point was being encumbered by this vision of what I wanted it to be. And taking 10 months to build the product and making all these assumptions of what people would want, that we then spend the next 10 months backtracking on. Instead of focussing on the one little piece of the product that people actually liked. </p><p>So, uhm, If there‚Äôs any advice that I have it‚Äôs you‚Äôre way too dumb to figure out if your idea is any good. It‚Äôs up to the masses. So build that very small thing and get it out there and keep on trying different things and eventually you‚Äôll get it right.‚Äô‚Äô</p></blockquote><p><em>[5] Elon Musk is a role model for many founders nowadays but what he‚Äôs doing now is much less accessible than what Jack Dorsey, Drew Houston, or Mark Zuckerberg have done. In fact, it was so inaccessible that he couldn‚Äôt raise enough from investors. Which is why half a billion dollars in loans from the government was required. As for the hundreds of millions to kickstart Tesla and SpaceX? His own money. Which he made from‚Ä¶ yup‚Ä¶ internet startups. His first project was a small video game called Blastar. After that, he created Zip2 (Internet version of the yellow pages telephone directory with maps included.), then PayPal.</em></p><p><em>Also, SpaceX grew in ambition. Originally </em><a href="https://en.wikipedia.org/wiki/History_of_SpaceX#cite_note-1"><em>the idea</em></a><em> was just to use 100 of the 180 million dollar payout of the PayPal acquisition to eBay, to get people excited about space again. He wanted to land a miniature experimental greenhouse containing seeds with dehydrated gel on Mars to grow plants on Martian soil, ‚Äúso this would be the furthest that life‚Äôs ever traveled‚Äù in an attempt to regain public interest in space exploration and increase the budget of NASA.</em></p><p><em>As for Tesla, that wasn‚Äôt even founded by Elon. Which most founders know but gen. pop. or the up and coming founder might not. The </em><a href="https://www.wired.com/2009/06/tesla-founder/" target="_blank"><em>original idea</em></a><em> came from AC Propulsion where Tom Gage and Alan Cocconi had built </em><a href="http://www.discoverychannel.co.uk/video/future-cars-t-zero/" target="_blank"><em>the t zero</em></a><em>.</em></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_53941"><div><p><em>Point is, he didn‚Äôt start with his current vision and you shouldn‚Äôt either.</em></p><p>Berkeley Haas. (2008). <em>Steve Wozniak on the Early Days of Apple [Video]. </em>Retrieved 20 October 2020, from https://youtu.be/5WBX6SACViI.</p><p>Dang, L., &amp; General, R. (2016).&nbsp;<em>Meet the Man Who Became Airbnb's Very First Guest</em>. NextShark. Retrieved 20 October 2020, from https://nextshark.com/meet-man-became-airbnbs-first-guest/.</p><p>Fogg, BJ. (2009).<em> </em>A behavior model for persuasive design. <em>Persuasive ‚Äô09: Proceedings Of The 4Th International Conference On Persuasive Technology</em>, <em>40</em>, 1‚Äì7. <a href="https://d1wqtxts1xzle7.cloudfront.net/36817028/Behavior-Model-for-Persuasive-Design.pdf?1425238284=&amp;response-content-disposition=inline%3B+filename%3DBehavior_Model_for_Persuasive_Design.pdf&amp;Expires=1602589095&amp;Signature=KPddqP810HPTN~SZLDPWhUoEbIIz7rKXZmSs6MVnhCNnTISRH6k60ORCxlQfh8WphZtdJtu85lxVfbuneBEPDVfDlWS7tD8UNBn3Y5YpqvS5TjiQ3c0h9gcHWG00op6Fl5wmABWosDACoudSqS-9p471kocL7es~kQLdvan5FLVH7boNVWk7rS9QOBNU67k95h7Xl1xg1YasOC43BbLs4qeVzNeuZ-mOR7i32gtScEOWvu97ODs48SYSFSmdpXUFaap~Nln2ICvLEsCYdRbs3RN1toGCRHAsuwl1MBUKq8aZxMEKPBn3YCadIiBfwzWGaWuGKCj1ya1cIdrZVhXUSg__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA" target="_blank"><em>https://doi.org/10.1145/1541948.1541999</em></a></p><p>FORA.tv. (2014).<em> Steve Wozniak Remembers Building the First Apple Computer. </em>Retrieved 20 October 2020, from ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.younglingfeynman.com/essays/airbnb2">https://www.younglingfeynman.com/essays/airbnb2</a></em></p>]]>
            </description>
            <link>https://www.younglingfeynman.com/essays/airbnb2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061753</guid>
            <pubDate>Wed, 11 Nov 2020 19:12:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Source Code Is Not the Whole Story: Understanding Software Through APIs]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061745">thread link</a>) | @jeanyang
<br/>
November 11, 2020 | https://www.akitasoftware.com/blog/2020/11/10/kbgnmpu9bdi6qsgkkxo1amqptellna | <a href="https://web.archive.org/web/*/https://www.akitasoftware.com/blog/2020/11/10/kbgnmpu9bdi6qsgkkxo1amqptellna">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-0b8680fe602586cc73eb"><div><p>üëã hunters!</p><p>After putting out an early iteration a few months ago, we‚Äôre excited to officially launch our private beta‚Äîand to make our docs public for the first time!</p><p>And we'd like to give a big thank-you to all the users and friends of Akita who got us here. üòä<br></p><h2><strong>üöó How we got here</strong></h2><p>In 2018, I was a <a href="http://jeanyang.com/">CS professor at Carnegie Mellon University</a>. When Cambridge Analytica hit, I started asking friends in industry how they knew what data their apps were sending around. It turned out that there was no good solution for understanding interactions across APIs‚Äînot just for privacy and security but also for reliability and diagnostics. When I realized that this was the exact problem I‚Äôd been teeing up to solve, I took leave from my job, sold my furniture, and drove across the country to start Akita.</p><p>There is now a small team of us working on Akita, coming from places like Twilio and Amazon. Our team‚Äôs experience building in service-oriented environments made everyone especially excited to build a product that would help developers move faster together.</p><h2><strong>üîé Source code isn‚Äôt the whole story.</strong></h2><p>At Akita, we believe the way to understand your software is through your APIs. Our solution builds dynamic models of API behavior to automatically:</p><p>‚úÖCatch breaking changes on every pull request<br>‚úÖGenerate specs for any API<br>‚úÖUpdate API specs on every pull request<br>‚úÖDiscover and document endpoints</p><h2>üèó <strong>How we built it</strong></h2><p>From the beginning of Akita, I knew where I wanted us to go: automatically map out the graph of API interactions. This would be key to improving reliability, diagnostics, and security in modern web apps.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1605055841399_25008"><div><p>What we didn‚Äôt know was exactly how we would get there. Should we integrate with a tracing library? Should we build a proxy?</p><p>After <a href="https://blog.sigplan.org/2020/10/27/whats-the-role-of-developer-experience-in-programming-languages-research/">talking with dozens of developers and engineering leaders</a>, we came up with three main requirements. First, whatever we built needed to work with any tech stack. Second, people needed to be able to integrate our solution in minutes. Finally, we wanted something that could run in production without adding overhead or exposing sensitive data. These were not easy requirements to balance!</p><p>After over a year of building, we‚Äôre super excited to launch a solution that requires no code changes, no proxies, works with any language, and integrates in just minutes. Akita works by watching API traffic, analyzing, and sanitizing the traffic locally to share only metadata back to our cloud. This means you can Akita deploy Akita anywhere: your laptop, CI/CD, or production‚Äîwithout having to worry about us seeing your data. We are really proud of our approach and believe it is the future of cloud observability.</p><p>And for those who are curious, our tech stack is Go, typed Python, and React. üòä</p><h2><strong>üíñ Let‚Äôs make software development better</strong></h2><p>We believe that Akita can help anybody with a web app who wants to move quickly without losing customers. We understand that we have a long way to go to achieve the vision‚Äîand that the only way to get there is by getting feedback early and often from people like you.</p><p>We‚Äôd love to have you <a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_private_launch&amp;utm_medium=blog&amp;utm_source=2020_11_11_producthunt">try out the private beta</a>! We‚Äôll also be checking the comments on <a href="https://www.producthunt.com/posts/akita-private-beta">ProductHunt</a> for feedback and questions. We look forward to hearing from you.</p><p>Onward ‚ö°Ô∏è,<br>Jean Yang (<a href="https://www.linkedin.com/in/jean-yang-96575030/">LinkedIn</a>; <a href="https://twitter.com/jeanqasaur">Twitter</a>)<br>Founder and CEO, Akita Software</p><p>P.S. Thank you to the veterans out there!<br>P.P.S. Follow our updates and tell us what you think on Twitter <a href="https://twitter.com/AkitaSoftware">@AkitaSoftware</a>!</p></div></div></div>]]>
            </description>
            <link>https://www.akitasoftware.com/blog/2020/11/10/kbgnmpu9bdi6qsgkkxo1amqptellna</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061745</guid>
            <pubDate>Wed, 11 Nov 2020 19:12:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cotter ‚Äì Restrict Login to ‚ÄúAllowed‚Äù Emails Only, No Code]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25061724">thread link</a>) | @mmarcelline
<br/>
November 11, 2020 | https://blog.cotter.app/how-to-restrict-your-webflow-website-to-allowed-emails-only/ | <a href="https://web.archive.org/web/*/https://blog.cotter.app/how-to-restrict-your-webflow-website-to-allowed-emails-only/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<div>
<figure><iframe width="480" height="270" src="https://www.youtube.com/embed/w9kJyBDcm9w?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><h3 id="prerequisites">Prerequisites</h3><p>Before we begin, make sure you have done the following:</p><ul><li><strong>Follow Cotter's Basic Webflow Tutorial</strong>: <a href="https://blog.cotter.app/integrate-cotter-magic-link-to-webflow-in-less-than-15-minutes/">How to Integrate Cotter's Magic Link to Your Webflow Site in Less Than 7 minutes</a></li></ul><h3 id="how-it-works">How it works</h3><p>We'll have 3 pages in this tutorial: <strong>A Waitlist Page (/waitlist), a Login Page (/), and a Protected Page (/protected)</strong>. </p><p>Users can sign up to the waitlist by entering their email on the Waitlist Page. You can manage people on the waitlist in your Google Sheets. Only people who are marked as <code>Allowed: TRUE</code> on the waitlist can login to your website using the Login Page and access the Protected Page.</p><p>In this tutorial,<strong> we'll make the Waitlist Page, </strong>and then<strong> update the Login and Protected Page </strong>that you have made in the prerequisite tutorial<strong>.</strong></p><h2 id="make-a-waitlist-page">Make a Waitlist Page</h2><h3 id="step-1-set-up-google-sheets">Step 1: Set up Google Sheets</h3><p>Go to <a href="https://cotteremaillist.herokuapp.com/">https://cotteremaillist.herokuapp.com</a> to connect your Google Sheets that contains a list of emails and follow the instructions there. See an <a href="https://docs.google.com/spreadsheets/d/1EYaErpQUCOhfXgCb0vhObEwDMFBqi_-gmRJ8C7DcOAA/edit?usp=sharing">example Google Sheet here.</a> (You can make this sheet private - you just need to connect your Google Account in the website above).</p><h3 id="step-2-make-elements-to-show-the-waitlist-email-form-and-a-success-message">Step 2: Make elements to show the waitlist email form and a success message</h3><ul><li>Include a section element to load Cotter's login form. <strong>We need to set that section id "cotter-form-container"</strong>.<strong> </strong>Make the section <strong>width </strong>and<strong> height </strong>to<strong> <code>300px</code> </strong>for best results.</li><li>Include a text element with <strong>id "waitlist-message"</strong>. We will show if the email is successfully added to the waitlist here.</li></ul><h3 id="step-3-add-cotter-js-sdk">Step 3: Add Cotter JS SDK</h3><p>After finishing the page setup we can start with adding custom code to the Waitlist Page. Copy paste the code below to the custom code tab on the Waitlist Page settings.</p><figure><img src="https://blog.cotter.app/content/images/2020/11/image-4.png"><figcaption>Waitlist Page Settings</figcaption></figure><figure><img src="https://blog.cotter.app/content/images/2020/11/image-5.png"><figcaption>Scroll Down to "Custom Code" section</figcaption></figure><p>Add the code below to the <strong>head</strong> of Waitlist page:</p><pre><code>&lt;!--Get Cotter JS SDK--&gt;
&lt;script
  src="https://unpkg.com/<a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="aecdc1dadacbdcee9e809d809c9d">[email&nbsp;protected]</a>/dist/cotter.min.js"
  type="text/javascript"
&gt;&lt;/script&gt;</code></pre><h3 id="step-4-add-a-function-to-insert-email-to-your-google-sheets">Step 4: Add a function to insert email to your Google Sheets</h3><p>Make sure you have already done Step 1 by going to <a href="https://cotteremaillist.herokuapp.com/">https://cotteremaillist.herokuapp.com</a> and connecting your Google Sheets that contains the waitlist (this can be empty, but make sure you follow the format specified).</p><p>Add the code below to the <strong>body</strong> of Waitlist page:</p><pre><code>&lt;script&gt;
  const insertEmail = async (payload) =&gt; {
    try {
      const body = {
        spreadsheetId: "&lt;YOUR SPREADSHEET ID&gt;", //üëà Add your Spreadsheet ID
        apiKeyID: "&lt;YOUR API KEY ID&gt;", //üëà Add your API KEY ID
        email: payload.email,
        allowed: false // By default, new emails are not allowed to login
      };
      let resp = await fetch(
        "https://cotteremaillist.herokuapp.com/api/insertemail",
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json"
          },
          body: JSON.stringify(body)
        }
      );
      let respBody = await resp.json();
      if (respBody.success) {
        document.getElementById("waitlist-message").innerHTML =
          "Added to waitlist";
      } else {
        document.getElementById("waitlist-message").innerHTML =
          "Something went wrong";
      }
    } catch (e) {
      document.getElementById("waitlist-message").innerHTML =
        "Something went wrong";
    }
  };
&lt;/script&gt;</code></pre><p>Make sure that you have pasted your<strong> <u>Spreadsheet ID</u> </strong>and your<strong> <u>API Key ID</u> </strong>on the code block above.</p><p>You can grab a Cotter API Key ID by visiting <a href="https://dev.cotter.app/">https://dev.cotter.app</a> and creating an account. Once you have created an account, make sure to create a new project and grab the API Key ID.</p><h3 id="step-5-add-the-code-below-to-show-the-email-form-join-waitlist-form-">Step 5: Add the code below to show the email form ("Join Waitlist" form)</h3><p>Below the code on step 4, add this code:</p><pre><code>&lt;script&gt;
    var cotter = new Cotter({
      ApiKeyID: "&lt;YOUR_API_KEY_ID&gt;",  // üëà Specify your API KEY ID here
      ButtonText: "Join Waitlist",
    });
    cotter
      .signInWithLink() // Verify email with Magic Link
      .showEmailForm() // Send Magic Link via email
      .then((payload) =&gt; {
        insertEmail(payload);
      })
      .catch((err) =&gt; {
      // handle error
      });
&lt;/script&gt;</code></pre><p>Make sure that you have pasted your<strong> <u>API Key ID</u> </strong>on the code block above.</p><h2 id="login-page-setup-where-the-login-form-will-show-up-">Login Page Setup (where the login form will show up)</h2><p>You should already have a Login Page after following the prerequisite tutorial above. Only users who are allowed in your Google Sheets can login. We are going to modify and add some of the necessary code.</p><h3 id="step-1-add-the-code-below-to-the-body-of-the-login-page">Step 1. Add the code below to the body of the Login Page</h3><p>Add this code before you Initialize Cotter</p><pre><code>&lt;script&gt;
  const checkEmail = async (payload) =&gt; {
    try {
      const body = {
        spreadsheetId: "&lt;YOUR SPREADSHEET ID&gt;", //üëà Add your Spreadsheet ID
        apiKeyID: "&lt;YOUR API KEY ID&gt;",  // üëà Specify your API KEY ID here
        email: payload.identifier
      };
      let resp = await fetch(
        "https://cotteremaillist.herokuapp.com/api/checkemail",
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json"
          },
          body: JSON.stringify(body)
        }
      );
      let respBody = await resp.json();
      if (!respBody.allowed) {
        return "You are not allowed to log in";
      } else {
        return null;
      }
    } catch (e) {
      console.log(e);
      return "You are not allowed to log in";
    }
  };
&lt;/script&gt;</code></pre><p><strong>Make sure that you have pasted your <u>Spreadsheet ID</u> and your <u>API Key ID</u> on the code block above.</strong></p><h3 id="step-2-change-the-code-in-the-body-of-the-login-page-to-the-code-below">Step 2. Change the code in the body of the Login Page to the code below</h3><pre><code>&lt;script&gt;
  var cotter = new Cotter("&lt;YOUR_API_KEY_ID&gt;"); // üëà Specify your API KEY ID
  cotter
    // Choose what method of login do you want
    // Sign In with Magic Link
-   .signInWithLink()
+   .signInWithLink(checkEmail)
    // Send Magic Link via email
    .showEmailForm()
    
    .then(payload =&gt; {
      // redirect to the protected page
      window.location.href = "/protected";
    })
    .catch(err =&gt; {
      // handle error
    });
 &lt;/script&gt;</code></pre><p>Make sure you deleted the line ".signInWithLink()" and added the line ".signInWithLink(checkEmail)".</p><p>Also, make sure that you have pasted your <u>API Key ID</u> on the code block above.</p><h2 id="protected-page-setup-and-any-other-page-you-want-to-protect-">Protected Page Setup (and any other page you want to protect)</h2><p>You should already have a Protected Page after following the prerequisite tutorial above. We are going to modify and add some of the necessary code.</p><pre><code>&lt;script
  src="https://unpkg.com/<a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="3a59554e4e5f487a0a1409140809">[email&nbsp;protected]</a>/dist/cotter.min.js"
  type="text/javascript"
&gt;&lt;/script&gt;

&lt;script&gt;
  async function checkLoggedIn() {
    //Initialize Cotter
    var cotter = new Cotter("&lt;YOUR_API_KEY_ID&gt;"); // üëà Specify your API KEY ID
    
    // 1. We check if a user has already logged in
    const accessTokenObject = await cotter.tokenHandler.getAccessToken();
    const accessToken = accessTokenObject ? accessTokenObject.token : null;

    // 2. If user is not logged in then we redirect to the login page
    if (!accessToken) window.location.href = "/";

    // 3. Construct the body for access token verification
    let body = {
      oauth_token: {
        access_token: accessToken
-     } 
+     },
+     spreadsheetId: "&lt;YOUR SPREADSHEET ID&gt;",  //üëà Add your Spreadsheet ID
+     apiKeyID: "&lt;YOUR API KEY ID&gt;" // üëà Specify your API KEY ID here
    };

    // 4. If user is logged in then we fetch the user data
+   //    and check if the email is allowed based on our Google sheets
-   let url = "https://worker.cotter.app/verify";
+   let url = "https://cotteremaillist.herokuapp.com/api/login"
    fetch(url, {
      method: "POST",
      cache: "no-cache",
      headers: {
        "Content-Type": "application/json",
-        API_KEY_ID: "&lt;YOUR_API_KEY_ID&gt;"   // üëà Specify your API KEY ID here
      },
-     mode: "cors",
      body: JSON.stringify(body)
    })
      .then((resp) =&gt; resp.json())
      .then((data) =&gt; {
        if (!data.success) { window.location.href = "/" }
      });
  }
  
  //Call the CheckLoggedIn function
  checkLoggedIn();
  
&lt;/script&gt;</code></pre><p><strong>Make sure you delete all lines with the "-" symbol and added all lines with the "+" symbol.</strong> (Do not include the <code>+</code> sign itself).</p><p>Also, make sure that you have pasted your <u>Spreadsheet ID</u> and your <u>API Key ID</u> on the code block above.</p><hr><h3 id="questions-feedback">Questions &amp; Feedback</h3><p>Come and talk to the founders of Cotter and other developers who are using Cotter on <a href="https://join.slack.com/t/askcotter/shared_invite/zt-dxzf311g-5Mp3~odZNB2DwYaxIJ1dJA">Cotter's Slack Channel</a>.</p><h3 id="ready-to-use-cotter">Ready to use Cotter?</h3><p>If you enjoyed this tutorial and want to integrate Cotter into your website or app, you can <a href="https://dev.cotter.app/">create a free account</a> and <a href="https://docs.cotter.app/">check out our documentation</a>.</p><p>If you need help, ping us on our <a href="https://join.slack.com/t/askcotter/shared_invite/zt-dxzf311g-5Mp3~odZNB2DwYaxIJ1dJA">Slack channel</a> or email us at <a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="fa8e9f9b97ba99958e8e9f88d49b8a8ad4">[email&nbsp;protected]</a></p>
</div>
</section></div>]]>
            </description>
            <link>https://blog.cotter.app/how-to-restrict-your-webflow-website-to-allowed-emails-only/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061724</guid>
            <pubDate>Wed, 11 Nov 2020 19:11:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gantt Charts Arrive in Notion]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25061649">thread link</a>) | @saviorand
<br/>
November 11, 2020 | https://optemization.com/timeline-view-notion | <a href="https://web.archive.org/web/*/https://optemization.com/timeline-view-notion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-timeline-view-notion"><blockquote id="block-659ced01cffc486ca3fa1b6e01fb482d"><span><span>It's about time: gantt charts, page customization and more arrive to Notion ‚Äî
here's our breakdown.</span></span></blockquote><div id="block-9ce0f17fa5904c5ba88176d78f03d8ff"><div id="block-f4c2486805a1467cb60c4a5aa1db40e5"><p><span><span>Hello there! Welcome to </span><span><em>Digital Opsessions</em></span><span> issue #0003</span></span></p></div></div><div id="block-e49dbd8e89f34444b7a9118c475aa629"><div id="block-2c66366dc9994fae8d874f1f30735471"><p><span><span>Today, marvelous talents at Notion decided to make it a bright Wednesday for us and share three major updates in the app! As part of the Notion Ambassadors group, we were fortunate enough to beta test these features and help spread the announcement news. </span></span></p><p><span><span>Here's what's up </span></span></p></div></div><div id="block-d85f6c16c65a4a098d6794d204a0267b"><div id="block-67d522c072b8469b8543221c3b19634a"><p><span><span>It has been a loooong dark 469 days since this Tweet has swept the world of project management. Frankly, it feels like the gap between season seven and season eight of the Game of Thrones. Only this time, you're going to be very happy. </span></span></p><p><span><span>Now that I think about it: Pfizer's vaccine announcement to COVID-19 is like Arya to the Night King (if you know what I mean ‚Äî </span><span><span><span>no spoilers</span></span></span><span>). </span></span></p></div></div><h2 id="block-8854e6d47bc8427ba082691fcd7e95e6"><span id="8854e6d47bc8427ba082691fcd7e95e6"></span><span><span>How to Timeline View</span></span></h2><p><span><span>Starting today, you will see the timeline view option show up in all your databases and linked database views. This is how it looks like:</span></span></p><div id="block-cb36fbb3f3d742e59a7052a3434dc403"><picture><source srcset="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>Here are some main configuration options to be aware of.</span></span></p><h3 id="block-3a98d91ea0c7408b9d38b302d0a9cf96"><span id="3a98d91ea0c7408b9d38b302d0a9cf96"></span><span><span>Timeline by</span></span></h3><p><span><span>Just like with board and calendar views, you can choose what dates the Timeline view indexes by. </span></span></p><div id="block-056fc67a35f34ed38fe2deff5ea12a8b"><picture><source srcset="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>In our case, we're arranging our content calendar by two date properties. To do that, toggle the </span><span><code>use separate start and end dates</code></span><span> option. We also like to enter both start and end dates in one property, but needed filtered visibility in the view. 
So we added a two simple formula properties:</span></span></p><ol><li id="block-f89f02f1bac2425789e0f9ecddeee9f4"><span><span>Start date: </span><span><code>start(prop("Promotion Dates"))</code></span></span></li><li id="block-7861a869b8284263831a9a9b58104177"><span><span>End date </span><span><code>end(prop("Promotion Dates"))</code></span></span></li></ol><div id="block-afad72a4ccbe4f1580bd7a0f1f142601"><p><span><span>Note that the "timeline by" setting will </span><span><strong>not</strong></span><span> sort your records chronologically by default. You need to enable this option if you need it.</span></span></p></div><h3 id="block-afa3f89aff864e099417bc191809b611"><span id="afa3f89aff864e099417bc191809b611"></span><span><span>Show table </span></span></h3><p><span><span>For the first time in Notion databases-and-views history you can fully hide the table! That comes in handy with timeline view ‚Äî if you just want to see that beautiful timeline. 
You'll also notice that you can limit the amount of records that show up without filtering, but more on that below</span></span></p><div id="block-2f1dc0d7047146d095c018880c646883"><picture><source srcset="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=1500" alt="image" loading="lazy"></picture></div><h2 id="block-2f419ddfbd474c8e9744b4b41831f8f7"><span id="2f419ddfbd474c8e9744b4b41831f8f7"></span><span><span>The Good / The Bad</span></span></h2><div id="block-98a043c9f3d54cbfaf16507beddb2f56"><picture><source srcset="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=1500" alt="image" loading="lazy"></picture></div><h3 id="block-3595a6e3558e48f9815ea8277e41a6dd"><span id="3595a6e3558e48f9815ea8277e41a6dd"></span><span><span>Things we love</span></span></h3><p><span><span><strong>Moving multiple date-specific records is seamless</strong></span><span>. Now, if you need to adjust a project timeline that has multiple pieces to it, whether its tasks, milestones, or events, you can just select them all, drag and all the dates will adjust accordingly. We use this, for example, to adjust whole complex project schedules to start from a given date ‚Äî very handy!</span></span></p><div id="block-633f34747c1f45bb9bcd4b392939fe48"><picture><source srcset="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>Hiding the property table is possible! </strong></span><span>If you'd like to see the timeline view in its full glory you can now toggle the table on and off. In the other Notion views, you cannot hide the main "Name" / ID property. </span></span></p><div id="block-50d1fed52f7c4101beb7d215660af070"><picture><source srcset="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>You can timeline by separate properties. </strong></span><span>The default Notion date property does not allow filtering or sorting by the date range. It uses the start date. That can be tricky and annoying when you want to filter your timeline view. Luckily, you have the option to timeline by separate fields!</span></span></p><div id="block-e347aea8615f4fb68f3dd07579d1d4af"><picture><source srcset="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=1500" alt="image" loading="lazy"></picture></div><h3 id="block-b01c6b44c6eb42b8a0e4d062c85b586f"><span id="b01c6b44c6eb42b8a0e4d062c85b586f"></span><span><span>Things we hate</span></span></h3><p><span><span><strong>Data overflow: </strong></span><span>Items look bad when you show more than one property in the timeline, or when an event takes place on a single day (then item is just a small white dot, and text overflows). When more than a few properties toggled on the timeline, the UI of each becomes visible cluttered. For both the table and timeline, a "wrap cells" options would be great.</span></span></p><div id="block-b126bbb5b6e546db81fe1c95982de683"><picture><source srcset="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>Only full width. C</strong></span><span>urrently timelines with a table toggles "on", do not adjust to standard width.That's annoying because for some it might be useful to see the table and timeline on the standard width.</span></span></p><div id="block-9c638003ac144730b036479a2d56bf6c"><picture><source srcset="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>Paid plans limits</strong></span></span></p><div id="block-4058fc818edf482ab647cb0d6a4790ba"><div id="block-6c4afe4fb0934ecba8c9d341c6e955e9"><div id="block-6fc04eb8d9bf427c81b524a58a270ae5"><picture><source srcset="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434" alt="image" loading="lazy"></picture></div></div><div id="block-ad57120d749247d08823002a95441e09"><p><span><span>With the introduction of Timelines, Notion team added a new pricing tweak ‚Äî a limit on the number of Timelines you can use. You can only add 3 timelines on a Personal plan and up to 5 on Team plan. For unlimited timelines you have to buy Enterprise</span></span></p></div></div><p><span><span>We managed to lay our hands on the Timeline view before the release, and had the chance to prepare this proposal template with a Gantt chart included!</span></span></p><p><span><span>It's easy to try ‚Äî just duplicate it into your workspace and drag all milestones, meetings, deliverables and billing activities to your project's start date. Voila! You now have a complete, detailed project schedule aligned with your preferred dates.</span></span></p><p><span><span>You can change any part of this template ‚Äî remove or add new records, change default structure, introduce new types of project activities, such as legal (marking the date when the contract is signed), holidays, events.</span></span></p><p><span><span>We use this template ourselves to spin up new client proposals ‚Äî it saves tons of time on routine editing and allows us to focus on things that are essential, like pain points we help clients address, or our unique approach. </span></span></p><p><span><span>Making these kinds of documents in Notion is enjoyable ‚Äî you can templatize pretty much any common structure. If the lack of Gantt Charts is something that was stopping you from going all-in on Notion, now is the time. </span></span></p><h2 id="block-3c4bd798e6b34e7abd3977fbe0825efb"><span id="3c4bd798e6b34e7abd3977fbe0825efb"></span><span><span>Get the template!</span></span></h2><h3 id="block-f851a8c9110c4392a445c1f5aa42fd57"><span id="f851a8c9110c4392a445c1f5aa42fd57"></span><span><span>Properties</span></span></h3><p><span><span>Power users know that complex. data-heavy workflows in Notion were tough to work with so far. When making structures that's more sophisticated than a simple "Basic CRM" workflow, properties tend to pile up ‚Äî at some point, when opening a page, you don't see its content on the first screen, just properties.</span></span></p><p><span><span>Not anymore! Now you can hide properties you don't use and get straight to that page content every time you open a page. </span></span></p><div id="block-1fd0baefcc3d4939af7c1f0dcf418a19"><picture><source srcset="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406" alt="image" loading="lazy"></picture></div><p><span><span>The best part is that you can set up advanced rules on when to show or hide specific properties ‚Äî for example, you can show a property only when it's not empty for the current page, or always hide a specific property on a page (you can always open it up manually).</span></span></p><div id="block-6b34b9caaab340d9a69316d845cee4cb"><picture><source srcset="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350" alt="image" loading="lazy"></picture></div><h3 id="block-e0e751d263f64ecc9596b3e091381dd9"><span id="e0e751d263f64ecc9596b3e091381dd9"></span><span><span>Comments, Backlinks</span></span></h3><p><span><span>It's simple with comments ‚Äî you can just hide them for a page. Same with backlinks, but you can also select "Show in a popover". That option will display a small "X backlinks" button indicating how many backlinks a page has. Then you can press that button and view the backlinks.</span></span></p><div id="block-3e1f67ea498d4fa0ad79e33295222f8e"><picture><source srcset="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320" alt="image" loading="lazy"></picture></div><p><span><span>This functionality allows to keep any workspace clean, and the main use case is for large organizations managing tons of data. </span></span></p><p><span><span>Previously, when you shared access to a page with someone, they would automatically get access to all the subpages in it. Now when you open up a subpage you can see exactly what page it inherits permissions form ‚Äî and then change permissions for this specific subpage.</span></span></p><div id="block-87a9344e6a4a4313aaa9430e7ef34cdc"><picture><source srcset="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620" alt="image" loading="lazy"></picture></div><p><span><span>This is useful when you have private pages that live inside a larger page ‚Äî and you want to share the parent one without sharing these specific private pages. Think company's internal wiki with a subpage that contains sensitive data. </span></span></p><p><span><span>You can also add group permissions ‚Äî Notion team mentions the use case of giving Engineering team access to most of the workspace except a couple read-only pages.</span></span></p><p><span><span>Notion will now show you a "Show X records" option when working with database settings ‚Äî and will clip all the records above the number selected. Previously, if you had a huge database, it will display all the records in an infinite scroll as you move down the page ‚Äî this might have been okay for small databases, but quickly got hard to manage with additional information load.</span></span></p><p><span><span>Timeline view, page customization, advanced permissions and row number limits ‚Äî all of this seems to be targeting enterprise users, who need more control over large setups, Notion team is obviously hitting the nerve with big teams here. </span></span></p><p><span><span>Some features will also be handy for small teams and individual makers ‚Äî authors can use the timeline view to manage their content editorial, freelancers can use it to control their work load. Advanced customization is valuable for anyone who keeps data in Notion.</span></span></p><div id="block-35eebc7612e34ff79f23e056bf85977e"><div id="block-ca65c34a263e4c7881ef4767fca59df4"><p><span><span>The </span><span><em>Digital Opsessions</em></span><span> newsletter helps you figure out how to use digital productivity systems, tools and habits to free up time, energy and focus </span><span><span>for more important or fun </span></span><span>things in life.</span></span></p><p><span><span><strong>Subscribe + share</strong></span><span> </span><span><span><span>(if you haven't already)</span></span></span><span> üëâ</span></span></p></div></div></article></div></div></div>]]>
            </description>
            <link>https://optemization.com/timeline-view-notion</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061649</guid>
            <pubDate>Wed, 11 Nov 2020 19:05:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mathematicians Estimate Ethereum 2.0 Launch Date]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061381">thread link</a>) | @npguy
<br/>
November 11, 2020 | https://doublespend.io/2020/10/28/breakthrough-mathematicians-estimate-ethereum-2-0-launch-date/ | <a href="https://web.archive.org/web/*/https://doublespend.io/2020/10/28/breakthrough-mathematicians-estimate-ethereum-2-0-launch-date/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
<article id="post-445">
	
				<p><a href="https://doublespend.io/wp-content/uploads/2020/10/eth2.jpg"><img width="800" height="445" src="https://doublespend.io/wp-content/uploads/2020/10/eth2-800x445.jpg" alt="" loading="lazy" srcset="https://doublespend.io/wp-content/uploads/2020/10/eth2.jpg 800w, https://doublespend.io/wp-content/uploads/2020/10/eth2-300x167.jpg 300w, https://doublespend.io/wp-content/uploads/2020/10/eth2-768x427.jpg 768w" sizes="(max-width: 800px) 100vw, 800px"></a>
								</p>
			
	<div>

		
		

		
		<div>
			
<p>A group of elite mathematicians have finally solved a problem that has puzzled millions of crypto folks for about two decades now. ‚ÄúIt took us about four years to get here, but man does it feel good‚Äù John Calculus, the lead mathematician, told DoubleSpend. </p>



<p>‚ÄúI was working on the P versus NP problem for about 10 years before moving onto solving two problems in parallel: discovering the largest prime number, and estimating the launch date of Ethereum 2.0. But when&nbsp;<a href="http://www.sciencedaily.com/releases/2013/02/130213225424.htm">Curtis Cooper beat me</a>&nbsp;to discovering the largest known prime number, I started focusing on the Ethereum 2.0 problem one hundred percent‚Äù a visibly excited John Calculus told our reporter.</p>
		</div>

	</div>

	</article>

		</div></div>]]>
            </description>
            <link>https://doublespend.io/2020/10/28/breakthrough-mathematicians-estimate-ethereum-2-0-launch-date/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061381</guid>
            <pubDate>Wed, 11 Nov 2020 18:41:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AndroWish ‚Äì run desktop Tcl/Tk programs almost unaltered on the Android Platform]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25061292">thread link</a>) | @jakobdabo
<br/>
November 11, 2020 | https://www.androwish.org/index.html/home | <a href="https://web.archive.org/web/*/https://www.androwish.org/index.html/home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tbody><tr><td>
<p>Tcl (Tool Command Language) is a very powerful but easy to learn dynamic programming language, suitable for a very wide range of uses, including web and desktop applications, networking, administration, testing and many more. Open source and business-friendly, Tcl is a mature yet evolving language that is truly cross platform, easily deployed and highly extensible.

</p><p>Tk is a graphical user interface toolkit that takes developing desktop applications to a higher level than conventional approaches. Tk is the standard GUI not only for Tcl, but for many other dynamic languages, and can produce rich, native applications that run unchanged across Windows, Mac OS X, Linux and more. 

</p><p>AndroWish allows to run desktop Tcl and Tk programs almost unaltered on the Android Platform while it opens the door to script a rich feature set of a mobile platform. Its sibling <a href="https://www.androwish.org/index.html/wiki?name=undroidwish">undroidwish</a> uses the same code base and  offers a similar feature set on various desktop and embedded platforms.

</p></td><td>
<img width="160px" height="160px" src="data:image/png;base64,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">
</td></tr>
</tbody></div><p>The current AndroWish-debug.apk can be downloaded <a href="https://www.androwish.org/download/AndroWish-c48f047f5b-debug.apk">here</a> (about 36 MByte, requires "install from unknown sources" in Android settings). Prehistoric versions are <a href="http://www.ch-werner.de/sdltk/AndroWish">still available here</a>.


</p></div>]]>
            </description>
            <link>https://www.androwish.org/index.html/home</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061292</guid>
            <pubDate>Wed, 11 Nov 2020 18:36:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Music-Related Copyright Claims and Twitch]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25061259">thread link</a>) | @haunter
<br/>
November 11, 2020 | https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/ | <a href="https://web.archive.org/web/*/https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-i18n="ba2fc6a46b864e1cc0b2afadb1eff0cf-content">
    <p>Creators, we hear you. Your frustration and confusion with recent music-related copyright issues is completely justified. Things can‚Äìand should‚Äìbe better for creators than they have been recently, and this post outlines our next steps to get there. Moving forward, we‚Äôll be more transparent with what‚Äôs happening and what tools and resources we‚Äôre building to help.</p>

<p>Copyright law and the DMCA are not small or simple topics, so this won‚Äôt be a brief post. We‚Äôll do our best to keep the legalese to a minimum, though there‚Äôs bound to be technical terms here and there.&nbsp;</p>

<h4 id="dmca-and-twitch"><strong>DMCA and Twitch</strong></h4>

<p>First off, a quick review of what DMCA actually is. The Digital Millennium Copyright Act (‚ÄúDMCA‚Äù) is a set of US laws that allows you to create and share content on digital service providers like Twitch. We comply with the DMCA and similar laws worldwide. Part of complying means that when a copyright holder thinks a streamer has used their content without permission, we have a process in place for them to be able to request the content be taken down.</p>

<p>When we receive a DMCA notification, we process the notification in accordance with our <a href="https://www.twitch.tv/p/legal/dmca-guidelines/">DMCA Guidelines</a>. This includes removing the content, sharing the details with the channel owner, and tracking the allegation.&nbsp;</p>

<p>DMCA takedown notifications can affect your ability to stream because we, as part of our efforts to comply with the DMCA and similar global laws, issue and track copyright strikes and ban the accounts of those who repeatedly infringe the copyrights of others.&nbsp;</p>

<p>This policy is important because we respect the rights of all creators, including those who create or record music, as well as the rights of those who own and control copyrights. As a company that is built around a community of people who create content, we take allegations of copyright infringement seriously.&nbsp;</p>

<h4 id="recent-dmca-notifications"><strong>Recent DMCA notifications</strong></h4>

<p>How did we get to this moment? Until May of this year, streamers received <strong>fewer than 50 music-related DMCA notifications each year</strong> on Twitch. Beginning in May, however, representatives for the major record labels started sending <strong>thousands of DMCA notifications each week</strong> that targeted creators‚Äô archives, mostly for snippets of tracks in years-old Clips. We continue to receive large batches of notifications, and we don‚Äôt expect that to slow down.&nbsp;</p>

<p>This means two things: 1) if you play recorded music on your stream, you need to stop doing that and 2) if you haven‚Äôt already, you should review your historical VODs and Clips that may have music in them and delete any archives that might.&nbsp;</p>

<p>We were as surprised by this sudden avalanche of notifications as many of you were. We also realized that we needed to provide streamers with more educational programs and content management tools to help you deal with this unprecedented number of notifications coming in all at once. So, while we continued to remove content targeted by these notifications as required by the DMCA, we understood VODs and Clips from years ago may not necessarily reflect your current approach to music. Therefore, we also paused the processing of strikes associated with these batched notifications in order to give you the tools, information, and time that you would need to deal with them.</p>

<p>We have analyzed the notifications we received during that period from the end of May through the middle of October. What we found is that more than 99% of the notifications were for tracks that streamers were playing in the background of their stream.&nbsp;</p>

<p>The point of the DMCA is to strike a balance between the interests of rights holders (the major record labels in this case) and creators. Because of this, we were compelled to delete the VODs and Clips that were identified in the notifications. This showed our commitment to upholding our obligations under the DMCA, while affording us the opportunity to sort out the best way to handle issuing strikes in these circumstances. Under these extraordinary circumstances, we recognized creators should have a reasonable chance to understand that content created in the past was being targeted as allegedly infringing and be given an opportunity to change their approach to music use before they got hit with strikes.</p>

<p>This led to the current situation, which is understandably frustrating and worrying for many of you. Given the circumstances, the warning email many of you received didn‚Äôt include all the information that you‚Äôd typically get in a DMCA notification (normally, when we receive a DMCA notification against your channel, we send you an email that includes information about the allegedly infringed work, who the claimant is, how the claimant can be contacted, and possible penalties under our repeat infringer policy, so that you can make an informed decision about whether to submit a counter notification or seek a retraction). We hear your feedback about how frustratingly little information we provided, and we should have made that warning email a lot more informative and helpful.</p>

<p>Over the last several months, we have done our best to manage this situation on behalf of both rights holders and creators. One of the mistakes we made was not building adequate tools to allow creators to manage their own VOD and Clip libraries. You‚Äôre rightly upset that the only option we provided was a mass deletion tool for Clips, and that we only gave you three-days notice to use this tool. We could have developed more sophisticated, user-friendly tools awhile ago. That we didn‚Äôt is on us. And we could have provided creators with a longer time period to address their VOD and Clip libraries ‚Äì that was a miss as well. We‚Äôre truly sorry for these mistakes, and we‚Äôll do better.</p>

<h4 id="how-to-avoid-dmca-notifications"><strong>How to avoid DMCA notifications&nbsp;</strong></h4>

<p>One important question we‚Äôve heard from you is: how can I stream safely and confidently on Twitch without having to worry about getting DMCA notifications from music use?</p>

<p>Most importantly, <strong>don‚Äôt play recorded music in your stream</strong> unless you own all rights in the music, or you have the permission of the necessary rights holder(s). Doing this is the best protection for your streams going forward. If you‚Äôre unsure whether you own all the rights, it‚Äôs pretty likely you don‚Äôt. If you want to include recorded music in your stream, use a fully licensed alternative like Soundtrack by Twitch, or other rights cleared music libraries such as Soundstripe, Monstercat Gold, Chillhop, Epidemic Sound, and NCS.</p>

<p>While we haven‚Äôt received more than a handful of DMCA notifications targeting in-game music, if you‚Äôre playing games with recorded music in them, we recommend you review their End User License Agreements (that wall of text at the beginning of a game) to see how the terms cover streaming with that music. One way to do this is to search for a game‚Äôs official EULA online and then do a ctrl+f (Command+f on Mac) search for words like ‚Äústream,‚Äù ‚Äúlicensed,‚Äù and ‚Äúmusic‚Äù to point you toward the correct sections. If you‚Äôre unsure about the rights, some games allow you to turn off music when streaming, or you can mute the game audio yourself. If neither of those apply, consider turning off VODs and Clips.&nbsp;</p>

<p>For your stream archives (VODs and Clips), right now your only options, if you think they contain unauthorized music, is to either go through them one by one, or, for Clips, use the ‚Äúdelete all‚Äù tool we‚Äôve provided. We understand both of these options have downsides, and we‚Äôre working to provide you more and better options as soon as possible. These things will take time to get right, and new challenges may appear in the future. Regardless, we‚Äôre committing here and now to investing in building better tools and keeping you posted on our progress.</p>

<h4 id="new-products-and-tools"><strong>New products and tools</strong></h4>

<p>Ever since the influx of DMCA notifications began, we have been working on building new (and improving existing) tools to help creators (such as the Clips mass deletion tool). This work is still happening. Many of these changes won‚Äôt be visible to the community, but we‚Äôre focused on three areas where we heard you need more support from us:</p>

<p>First, you don‚Äôt have enough control over the recorded content on your channel. We have made improvements to enable you to mass delete Clips, but in addition, we will (1) expand the use of technology to detect copyrighted audio, and (2) give you more granular ways to manage your archive instead of just a ‚Äúdelete all‚Äù option.</p>

<p>Second, we‚Äôll make it easier for you to control what audio from your live streams will show up in your recorded content. Soundtrack by Twitch has some of this technology built into it, and we‚Äôll work to make it available for everyone regardless of whether you want to use Soundtrack, for which we‚Äôve cleared all necessary rights, or music from others that provide rights-cleared music.</p>

<p>Third, we need to give you the ability to actually review your allegedly infringing content when you receive a DMCA notification, in addition to the details already provided in our takedown notifications - that is, information about what copyrighted work was allegedly infringed, who the claimant is, and how the claimant can be contacted. We also need to help you more easily file counter notifications if you believe you have the rights to use the content‚Äìfor example, because you‚Äôve secured a license, believe the use is a fair use,&nbsp; the claimant does not control the rights, or believe you have the right to use the music without permission.</p>

<p>Some of you have asked why we don‚Äôt have a license covering any and all uses of recorded music. We are actively speaking with the major record labels about potential approaches to additional licenses that would be appropriate for the Twitch service. That said, the current constructs for licenses that the record labels have with other services (which typically take a cut of revenue from creators for payment to record labels) make less sense for Twitch. The vast majority of our creators don‚Äôt have recorded music as a part of their streams, and the revenue implications to creators of ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</a></em></p>]]>
            </description>
            <link>https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061259</guid>
            <pubDate>Wed, 11 Nov 2020 18:33:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nyxt Release 2 Pre-release 4]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061101">thread link</a>) | @jmercouris
<br/>
November 11, 2020 | https://nyxt.atlas.engineer/article/release-2-pre-release-4.org | <a href="https://web.archive.org/web/*/https://nyxt.atlas.engineer/article/release-2-pre-release-4.org">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Nyxt 2 Pre-release 4</title>
  
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->


<header>

</header>
<p>We are happy to announce the fourth pre-release of Nyxt version 2.0.0. If you missed the previous pre-release announcement, see <a href="https://nyxt.atlas.engineer/article/release-2-pre-release-3.org">here</a>.</p>
<p>Nyxt 2 is a massive overhaul of the Nyxt 1 series. A lot of effort has been geared towards improving the code quality under the hood which should reflect on the overall user experience with better performance, increased stability and better accessibility.</p>
<p>This is a test release for everyone to try out before the final release. It contains experimental features and some parts are still unfinished. Please feel free to share your feedback on our <a href="https://github.com/atlas-engineer/nyxt/issues">GitHub issue tracker</a>!</p>
<p>Notable highlights:</p>
<ul>
<li><p>Overhauled status area view to resemble powerline.</p>
<ul>
<li>Hold <code>shift</code> to scroll the tabs horizontally.</li>
</ul></li>
<li><p>New <code>dark-mode</code> (experimental).</p></li>
<li><p>New universal package manager interface.</p>
<p>Install, uninstall, describe packages, list their files, change generations, etc. See the various <code>*-package-*</code> and <code>*-generation-*</code> commands.</p>
<ul>
<li><p>Currently only interfaces the Guix package manager.</p></li>
<li><p>Help to implement additional backends is welcome!</p></li>
</ul></li>
<li><p>New <code>nowebgl-mode</code>.</p></li>
<li><p>New <code>nyxt-init-file</code> helper to derive a file name relative to the Nyxt configuration folder.</p></li>
<li><p>No longer ask to restore session when there is none.</p></li>
</ul>
<p>For the complete change list, please consult the <a href="https://github.com/atlas-engineer/nyxt/blob/2-pre-release-4/documents/CHANGELOG.org#2-pre-release-4">CHANGELOG.org</a> file.</p>
<p>We hope you enjoy these new features, and that they help make you more productive. Thanks for reading :-)</p>

<h2 id="nyxt-powerline">Nyxt Powerline</h2>
<p><img src="https://nyxt.atlas.engineer/static/image/article/status-area.png"></p>
<h2 id="package-manager">Package Manager</h2>
<p><img src="https://nyxt.atlas.engineer/static/image/article/describe-os-package.png"></p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/git-package.png"></p>
<h2 id="dark-mode">Dark Mode</h2>
<p><img src="https://nyxt.atlas.engineer/static/image/article/wiki-normal.png"></p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/wiki-dark.png"></p>


</div></div>]]>
            </description>
            <link>https://nyxt.atlas.engineer/article/release-2-pre-release-4.org</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061101</guid>
            <pubDate>Wed, 11 Nov 2020 18:21:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi Homelab with Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25061097">thread link</a>) | @amitpm
<br/>
November 11, 2020 | https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/ | <a href="https://web.archive.org/web/*/https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>I‚Äôve been running <a href="https://pi-hole.net/">Pi-Hole</a> on a Raspberry Pi 3b wired into my wifi router for most of last year and its been great. So when the new Raspberry Pi 4 came out, I picked one up. It sits on my desk, mostly for easy access to its USB ports, which allows me to hook it up to some of my esp32 devkits and push micropython code onto them. The pi4 has been a great general purpose development environment.</p><p>Recently, I‚Äôve been wanting to write some trivial web endpoints for ‚Äúinternal‚Äù dashboards and such for the house. Plus, its a great excuse to learn Golang. In this day and age, clearly a dockerized golang dev environment is the way to go. Have I truly built something, if my dev environment isn‚Äôt dockerized?</p><p>So we‚Äôre agreed that dockerizing my dev environment is the way to go. Surely if my dev environment is dockerized, how much more should my app deployments use containers? Nothing less will do. But now I need a way to deploy and orchestrate said containers? I know! I should run a kubernetes cluster across my two Pi‚Äôs! Might as well run the Pi-hole on it as well, how hard can it be?</p><p>So that is what I spent the better part of last week figuring out.</p><figure><img src="https://imgs.xkcd.com/comics/automation.png" alt="Mandatory xkcd"><figcaption><center>Mandatory xkcd</center></figcaption></figure><p>This blog post walks through what I did, and how I did it, It‚Äôs purpose is two-fold -</p><ol><li>It is a map to allow me to retrace my steps if I need to</li><li>Perhaps it may prove of (dubious) use to you.</li></ol><p>So, both my Pi‚Äôs run Ubuntu server. I decided I should start from scratch, and flashed the latest ubuntu server image onto the SD cards for both Pi‚Äôs. Being a very optimistic person by nature, I expected to have Pi-hole back up and running on this new Kubernetes cluster within a day, and a day of unfiltered ads was a small price to pay for the experience. Alas, it was close to a week before I had Pi-Hole working on my network again, but yay! you get to learn from my experience!</p><p>I didn‚Äôt have much of an understanding of Kubernetes components going into this project - but hey, that‚Äôs what these projects are meant to give you, and boy, did it. So fret not if you don‚Äôt understand some of these terms, the kubernetes documentation pages are great!</p><p>None of this work is original. I cobbled together guides and walkthroughts from various sources to get to this frankenstein‚Äôs monster of a post that you see here. You can find links to the sources I used at the end of this page.</p><p>The first step to this journey involves making sure you have the required packages on all your machines. In my case, this was two machines - the Pi4 (called Terminus) and the Pi3b (called Trantor). You need <code>docker</code>, <code>kubelet</code>, <code>kubeadm</code> and <code>kubectl</code>. You want this installed on all your nodes. Terminus will be my master node, Trantor will be my worker. Asimov fans may protest that the Second Foundation was on Trantor after all, but let‚Äôs go with this for now. Setting static IPs on the master and workers on your cluster also helps, but I won‚Äôt cover that here.</p><p>Update apt repos and packages.</p><div><pre><code data-lang="bash">sudo apt-get update
sudo apt-get upgrade
</code></pre></div><p>Install Docker using the Convenience script. Yes, shame on you for blindly running a script you downloaded from the internet.</p><div><pre><code data-lang="bash">curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
</code></pre></div><p>Let‚Äôs make sure our non-root user can use Docker.</p><div><pre><code data-lang="bash">sudo usermod -aG docker $USER
</code></pre></div><p>Now there‚Äôs some additional setup that needs to be done in order to get Kubernetes to work on the Raspberry Pi - specifically enabling <code>cgroups</code>. You can do this by editing the file <code>/boot/firmware/cmdline.txt</code> and adding the following options at the end.</p><pre><code>cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1 swapaccount=1
</code></pre><p>You‚Äôll need to reboot the Pi after this.</p><p>Add the K8s apt repo.</p><div><pre><code data-lang="bash">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

cat <span>&lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
</span><span>deb https://apt.kubernetes.io/ kubernetes-xenial main
</span><span>EOF</span>
</code></pre></div><p>You‚Äôll notice we‚Äôre using <code>kubernetes-xenial</code> which was the latest release at the time of writing this. Update this to the latest release available if you need to.</p><p>Let‚Äôs install our main K8s helpers. We‚Äôll also make sure they‚Äôre excluded freom any system upgrades. As the kubernetes <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">documentation</a> says, ‚Äú<code>kubeadm</code> and <code>kubectl</code> require special attention to upgrade.‚Äù</p><div><pre><code data-lang="bash">sudo apt update <span>&amp;&amp;</span> sudo apt install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
</code></pre></div><figure><img src="https://raw.githubusercontent.com/kubernetes/kubernetes/master/logo/logo.png" width="200" height="200"></figure><p>Create the cluster by running the following commands on the master node only. Pay special attention to the <code>--pod-network-cidr</code> parameter. You‚Äôll need this CIDR range later on when setting up Flannel.</p><div><pre><code data-lang="bash"><span># Create the bootstrap token</span>
TOKEN<span>=</span><span>$(</span>sudo kubeadm token generate<span>)</span>
sudo kubeadm init --token<span>=</span><span>${</span>TOKEN<span>}</span> --pod-network-cidr<span>=</span>10.10.0.0/16
</code></pre></div><p>Congratulations. You are now the proud owner of a bare-metal kubernetes cluster (with one node). Admire the output, and consider running the commands they ask you to. For example, you‚Äôll need a config file in <code>$HOME/.kube/config</code> if you want <code>kubectl</code> to work without too much hassle. Also make special note of the <code>kubeadm join</code> command as well, you‚Äôll need to run that on your worker nodes.</p><p>These are the commands that the output from the previous step suggest you to run. Run this on the master node, in case that isn‚Äôt clear.</p><div><pre><code data-lang="bash">mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown <span>$(</span>id -u<span>)</span>:<span>$(</span>id -g<span>)</span> $HOME/.kube/config
</code></pre></div><p>Go run the <code>kubeadm join</code> commands on all the worker nodes you‚Äôd like to dedicate to this cluster. I‚Äôll wait.</p><p>Going through this guide, you‚Äôll quickly become familiar with the command <code>kubectl apply</code>. This command ‚Äúapplies a configuration to a resource‚Äù in kubernetes parlance and is typically provided a YAML ‚Äúmanifest‚Äù file as parameter.</p><p>So now we have a cluster, but technically Kubernetes doesn‚Äôt know how to handle networking between any pods that are scheduled on this cluster - atleast, that‚Äôs what I‚Äôve understood. This is why you need an addon like Flannel to handle this for you. You can find a full list of Networking and Network Policy Addons <a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/">here</a>. But in case it isn‚Äôt clear yet, we‚Äôll use Flannel.</p><figure><img src="https://raw.githubusercontent.com/coreos/flannel/master/logos/flannel-horizontal-color.png"></figure><p>If you‚Äôve specified a <code>pod-network-cidr</code> parameter when creating your cluster, you‚Äôll need to edit the Flannel manifest with this CIDR before you apply it to the cluster.</p><p>Let‚Äôs download the default flannel manifest</p><div><pre><code data-lang="bash">curl https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml --output kube-flannel-updated.yml
</code></pre></div><p>Open it the file up in your favourite editor, and find the key <code>net-conf.json</code>. Update the CIDR given there with the right CIDR for your cluster. Once done, apply the manifest like so.</p><div><pre><code data-lang="bash">kubectl apply -f ./kube-flannel-updated.yml
</code></pre></div><p>To check if this worked, run the following command to get all pods running on your cluster.</p><p>You should see <code>core-dns</code> and <code>kube-flannel</code> pods running like so. I have two pods for each because I have two nodes in my cluster.</p><div><pre><code data-lang="bash">NAMESPACE              NAME                                          READY   STATUS    RESTARTS   AGE
kube-system            coredns-f9fd979d6-h9m47                       1/1     Running   <span>1</span>          3d2h
kube-system            coredns-f9fd979d6-m5jrd                       1/1     Running   <span>1</span>          3d2h
kube-system            kube-flannel-ds-2ngxd                         1/1     Running   <span>1</span>          3d2h
kube-system            kube-flannel-ds-kqflv                         1/1     Running   <span>1</span>          3d2h
</code></pre></div><p>Namespaces are used to isolate pods and services running on the same cluster. My data engineer brain thinks of the cluster as a database and namespaces as schemas, but I could be mistaken and maybe should be thinking of the cluster as a single database install, and the namespaces as individual databases. Or maybe, this is entirely the wrong abstraction to bring in. Scratch all of this, let‚Äôs move on.</p><p>We now have a cluster, that knows how to handle pod networking. Let‚Äôs run something on it! How about the <a href="https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/">Kubernetes dashboard</a>, so that you have something pretty to show your non-technically inclined significant other as the output of your hard work?</p><figure><img src="https://raw.githubusercontent.com/kubernetes/dashboard/master/docs/images/dashboard-ui.png" alt="Behold! The fruits of your labour!"><figcaption><center>Behold! The fruits of your labour!</center></figcaption></figure><p>We‚Äôll create a namespace to hold everything related to the Kubernetes Dashboard. I‚Äôm calling the namespace - <code>kubernetes-dashboard</code>. Very imaginative, no?</p><div><pre><code data-lang="bash">kubectl create namespace kubernetes-dashboard
</code></pre></div><p>We‚Äôll now download the manifest file for Kubernetes dashboard, because we need to make some changes.</p><div><pre><code data-lang="bash">curl https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.4/aio/deploy/recommended.yaml --output kubernetes-dashboard.yaml
</code></pre></div><p>I spent a few days trying to figure out why the manifest did not work out of the box, it kept failing when trying to pull the docker image. I worked around this by doing two things -</p><ol><li>Ran <code>docker pull kubernetesui/dashboard:v2.0.0</code> to cache a local copy of the docker image.</li><li>Commented out the <code>imagePullPolicy: Always</code> in the manifest file under the <code>kubernetes-dashboard</code> deployment block.</li></ol><p>For the more K8s experienced among you, you may be wondering why I did not try using the Helm chart - I did. Kubernetes-dashboard needs to run two services - <code>dashboard-metrics-scraper</code> and <code>kubernetes-dashboard</code>. The Helm chart only seemed to bring up <code>kubernetes-dashboard</code>. I‚Äôm sure I must be doing something wrong, but at this point my patience was wearing thin and I just wanted to get on with it.</p><p>Ok, so now we have an edited manifest, let‚Äôs apply it.</p><div><pre><code data-lang="bash">kubectl apply -f kubernetes-dashboard.yaml
</code></pre></div><p>It takes a little bit of time for the dashboard to come up. You can amuse yourself by looking at the pods as they spin up as follows -</p><div><pre><code data-lang="bash">watch kubectl get pods -n kubernetes-dashboard
</code></pre></div><p>You can get details on a specific pod by running -</p><div><pre><code data-lang="bash">kubectl describe pod &lt;pod_name&gt; -n kubernetes-dashboard
</code></pre></div><p>You can also tail logs on a specific pod by running -</p><div><pre><code data-lang="bash">kubectl -n kubernetes-dashboard logs &lt;pod_name&gt; -f
</code></pre></div><p>Once you see the dashbaord services up and running, let‚Äôs figure out how we actually get access to the dashboard UI.</p><p>We‚Äôll assume that you haven‚Äôt configured kubectl on your local machine and are instead, running all these commands from your (headless) raspberry pi.</p><p>Run <code>kubectl proxy</code> first. This exposes the cluster API server over HTTP to the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/">https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/</a></em></p>]]>
            </description>
            <link>https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061097</guid>
            <pubDate>Wed, 11 Nov 2020 18:21:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ultimate Guide to All in One CRM Solutions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061084">thread link</a>) | @pstephenson5
<br/>
November 11, 2020 | https://1crm.com/ultimate-guide-all-in-one-crm-solutions/ | <a href="https://web.archive.org/web/*/https://1crm.com/ultimate-guide-all-in-one-crm-solutions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">

<div>
<div>
<div id="content" role="main">
<article id="post-43451">
<div><div><div><div><div>
<div>
<p><span>You‚Äôre in the right place If you‚Äôre looking to learn more about all in one CRM solutions. Please use the links below to read the full articles and discover more. We‚Äôll be adding more articles over the coming weeks so be sure to bookmark this valuable resource!</span></p>
</div>
<div id="ultimate-heading-30025faf4f8e00149" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-30025faf4f8e00149 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>What is an All In One CRM?</h2></p></div>
<div>
<p><span>Learn which customer relationship management software is defined as an all in one CRM and what makes this different from other CRMs.</span></p>
</div>
<div id="ultimate-heading-59195faf4f8e007d6" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-59195faf4f8e007d6 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>Who Needs an All In One CRM and Why?</h2></p></div>
<div>
<p><span>Now you know what an all in one CRM is, learn more about the size and type of organizations that can benefit. Use our simple decision flowchart to work out if an all in one CRM is right for you.</span></p>
</div>
</div></div></div></div><div><div><div><div><div id="ultimate-heading-52985faf4f8e02894" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-52985faf4f8e02894 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>The Best All In One CRM Solutions in 2021</h2></p></div>
<div>
<p><span>We‚Äôve shortlisted 11 of the best all in one CRM solutions in the market today. Each review covers the product, its pricing, and pros and cons. We‚Äôve even added some recommendations based on some typical buying criteria organizations like yours use.</span></p>
</div>
<div id="ultimate-heading-16995faf4f8e0db15" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-16995faf4f8e0db15 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>All in One CRMs and E-Commerce</h2></p></div>
<div>
<p><span>Understand the benefits of integrating an all in one CRM with your e-commerce store to make your operations seamless and efficient.</span></p>
</div>
<div id="ultimate-heading-47855faf4f8e0dd09" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-47855faf4f8e0dd09 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>All in One CRM with Order Management</h2></p></div>
<div>
<p><span>Implementing an all in one CRM that includes order management offers you extensive business management benefits in the areas of Customer Service, Project Management, plus extended capabilities in your customer portal.</span></p>
</div>
<div id="ultimate-heading-21475faf4f8e0dea0" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-21475faf4f8e0dea0 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>All in One CRM with a Customer Portal</h2></p></div>
<div>
<p><span>A self-service customer portal is a key part of any CRM implementation. And when you implement an all in one CRM your portal gets turbo-charged with an extensive set of additional capabilities!</span></p>
</div>
<div id="ultimate-heading-17415faf4f8e0e07f" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-17415faf4f8e0e07f h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>All in One CRM and Integrations</h2></p></div>
<div>
<p><span> Making sure that all of your business systems play well together is really important, but can potentially be so complex that it is a major distraction. One approach to minimizing the effort required on this front is the adoption of an All in One CRM. </span></p>
</div>
</div></div></div></div><div><div><div><div><div id="ultimate-heading-89435faf4f8e19932" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-89435faf4f8e19932 h4" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:30px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h4>Get Your 1CRM 30-Day Free Trial</h4></p></div>
<div>
<div>
<p><span>Want to test drive 1CRM 8.6? Try it out for 30 days ‚Äì on us! </span></p>
<p><span>With no credit card required, you can sign up and be online within minutes!</span></p>
</div>
</div>
</div></div></div><div><div><div><div><div><p><img src="https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-500x289.png" data-src="https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-500x289.png" data-srcset="https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-500x289.png 500w, https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-1000x578.png 1000w" width="500" height="289" data-dt-location="https://1crm.com/whats-new-8-5/1crm-8-5-laptop/" alt="1CRM-laptop" srcset="https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-500x289.png 500w, https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-1000x578.png 1000w"></p></div></div></div></div></div></div>
</div> <div>
<p><img src="https://1crm.com/wp-content/uploads/2018/04/suzanne-pic--150x150.jpg" width="80" height="80" alt="Suzanne Louis" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2080%2080'%3E%3C/svg%3E" data-lazy-src="https://1crm.com/wp-content/uploads/2018/04/suzanne-pic--150x150.jpg"></p> <div>
<h4><span>Author:</span>&nbsp;Suzanne Louis</h4>
<p>Suzanne is an independent marketing consultant, in charge of product marketing at 1CRM Corp. Her responsibilities include web design and content, videos, social media, analytics, public relations, advertising, and the 1CRM Blog.</p>
</div>
</div>

</article>

</div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://1crm.com/ultimate-guide-all-in-one-crm-solutions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061084</guid>
            <pubDate>Wed, 11 Nov 2020 18:20:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lyft, Netflix, Expedia, Slack, and Segment: Comparing DIY Cloud Cost Tools]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25061054">thread link</a>) | @CloudZero
<br/>
November 11, 2020 | https://www.cloudzero.com/blog/cloud-cost-management-tools | <a href="https://web.archive.org/web/*/https://www.cloudzero.com/blog/cloud-cost-management-tools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        
        
        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Breakthroughs in engineering best practices often stem from a handful of top tech companies. &nbsp;</p>
<!--more-->
<p>Many of them share their behind-the-scenes stories at <a href="https://www.youtube.com/watch?v=ChupgIbZr5Q">conferences</a>, in <a href="https://blog.twitter.com/engineering/en_us/a/2013/observability-at-twitter.html">blogs</a>, and <a href="https://www.slideshare.net/reed2001/culture-1798664">slide decks</a> ‚Äî or <a href="https://netflix.github.io/chaosmonkey/">open source</a> code.</p>
<p>These companies invest millions of dollars and dedicated headcount in optimizing everything from uptime to engineering velocity ‚Äî so why wouldn‚Äôt you look to them for inspiration?</p>
<p>CloudZero is a company that enables engineering to build more profitable applications, so we thought it would be interesting to investigate and share how these top companies think about cloud cost ‚Äî and what kinds of cloud cost management tools they use and build. Luckily for us, a lot of them have blogged and spoken about it.</p>
<p>By the way, if you want to achieve results like these companies, without pulling your best engineers off your roadmap to build a homegrown system, <a href="https://www.cloudzero.com/platform">check CloudZero out</a>.</p>

<h2>Part 1: The Common Threads</h2>
<p>Before we dive in to the specifics, here are a few of the patterns that emerged across each DIY cloud cost management tool:</p>
<h3>They‚Äôve built cultures of cost-conscious engineering.</h3>
<ul>
<li>Top companies <a href="https://www.cloudzero.com/engineering-teams">decentralize cost management</a> to engineering teams. All of them have reported that when engineers have visibility into their spending, they make better decisions.</li>
<li>These companies know it‚Äôs all about balance between cost and velocity. An engineer shouldn‚Äôt spend hours on something to save five dollars. Cost visibility is all about making better decisions and tradeoffs ‚Äî not saving money at all costs.</li>
<li>They want <a href="https://www.cloudzero.com/engineering-teams">engineering teams to have autonomy and move quickly</a> ‚Äî and understand that‚Äôs a key pillar to move quickly. At the same time, many of them have built guardrails to control cost while they.</li>
</ul>
<h3>They view cost in context of business.</h3>
<ul>
<li>Their disruptive business models have been enabled by strong command of cost and unit economics. The reason why they have revolutionized their respective categories is that they deliver innovative solutions to customers in cost effective ways. To do this, they understand their <a href="https://www.cloudzero.com/blog/cloud-unit-economics">cloud unit economics</a>, like cost per ride or stream, and discuss cost in the context of their business.</li>
<li>They have built custom ways to make the data <a href="https://www.cloudzero.com/solutions/cost-per-customer">speak to the different stakeholders</a>, including leadership and individual dev teams.</li>
<li>They‚Äôve had to figure out ways to automate or supplement their tagging in order to be able to report on cost. They‚Äôve also allocated container spend in custom ways.</li>
</ul>
<h3>They are complex and customized, but all achieving similar outcomes.</h3>
<ul>
<li>Existing offerings weren‚Äôt enough. Cloud cost management tools ‚Äî at least the players you might see listed in the Gartner Magic Quadrant or Forrester Wave ‚Äî weren‚Äôt doing the trick. Their engineering teams have all adopted next generation practices and services ‚Äî and they needed a cost solution that could keep up.</li>
<li>These systems are an enormous amount of work and custom engineering. They have entire teams of full-time employees building these homegrown systems.</li>
</ul>


<h2>Part 2: The Homegrown Cloud Cost Management Tools</h2>

<p><img src="https://lh5.googleusercontent.com/kAplBll6TH9hj9tdoBc-wiySRwJX0oieyx1wGPTgf_vsiO3wDdCzPlrBh5n_X0WxucHwIf2WW2mXEfghckjD5GHYeK5oIA8EclrwCGN79VuoMLdau7wdA_FwQ7rkM9NmJLOu3XAB" width="139" height="69" alt="Lyft Logo"></p>
<p><strong><span>How We Know</span></strong></p>
<p>The Lyft team spoke at re:Invent in 2019 in a session called ‚ÄúManaging Your Cloud Financials as you Scale on AWS.‚Äù</p>
<p>You can watch it <a href="https://www.youtube.com/watch?v=ChupgIbZr5Q">here</a>. Lyft starts talking at around the 35 minute mark.</p>
<p><strong><span>How They Do It</span></strong></p>
<ul>
<li>Lyft has built a system of customized dashboards for all of their stakeholders, including leadership, engineering, and capacity planning.</li>
<li>Each engineering team lead has their own dashboard where they can drill in and investigate spend.</li>
<li>They measure cost per ride to track unit cost.</li>
<li>They have processing that sits on top of tags to be able to attribute spend to teams and projects.</li>
<li>They had to build a way to allocate container costs ‚Äî a project which was much more challenging than expected.</li>
</ul>
<p><strong><span>Cost Culture</span></strong></p>
<p>Lyft has said that once their engineers had visibility into what they were spending, they started to make better decisions around cost. Teams are now shown how much they spend compared to other teams, which has led to some good-spirited competition to reduce costs.</p>
<p><img src="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=800&amp;name=cloud-cost-management-tools-01.png" width="800" alt="Lyft's Cloud Cost Management Best Practices" srcset="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=400&amp;name=cloud-cost-management-tools-01.png 400w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=800&amp;name=cloud-cost-management-tools-01.png 800w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=1200&amp;name=cloud-cost-management-tools-01.png 1200w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=1600&amp;name=cloud-cost-management-tools-01.png 1600w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=2000&amp;name=cloud-cost-management-tools-01.png 2000w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=2400&amp;name=cloud-cost-management-tools-01.png 2400w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p><em>A slide from the re:Invent presentation detailing Lyft‚Äôs custom cost management solution.</em></p>

<p><img src="https://lh3.googleusercontent.com/BKAFIAGWqHo0wrdlf__Sr-1RyiQqs8lN5VkU833O-Q7IDPwnSTspC7yATG5hZ-8lmDuHGPceHjIr3Ujx_nvy3zP5BfYWebmNxsIGr0wXEGH7Rtl5X19_A6rI0QsmFJCViIowisWm" width="175" height="117" alt="Netflix Logo"></p>
<p><span><strong>How We Know</strong></span></p>
<p>Netflix wrote a very detailed blog about their home grown efficiency and cost management system.</p>
<p>You can read it <a href="https://netflixtechblog.com/byte-down-making-netflixs-data-infrastructure-cost-effective-fee7b3235032">here</a>.</p>
<p><span><strong>How They Do It</strong></span></p>
<ul>
<li>Netflix has a ‚Äúa custom dashboard that serves as a feedback loop to data producers and consumers ‚Äî it is the single holistic source of truth for cost and usage trends for Netflix‚Äôs data users.‚Äù</li>
<li>They break down cost into ‚Äúmeaningful resource unit (table, index, column family, job, etc).‚Äù</li>
<li>They categorize AWS billing data by service, such as Amazon EC2 and Amazon S3. However, they have built custom ways to get further granularity into each.</li>
<li>They found AWS billing data was not granular enough for them, so they have built custom methods to align cost to the business metrics they care about like teams and products.</li>
<li>They provide optimization for some scenarios, such as storage.</li>
<li>They deliver cost alerts directly to their engineers.</li>
</ul>
<p><span><strong>Cost Culture</strong></span></p>
<p>Netflix sums up their approach as: ‚ÄúAt many other organizations, an effective way to manage data infrastructure costs is to set budgets and other heavy guardrails to limit spending. However, due to the highly distributed nature of our data infrastructure and our emphasis on freedom and responsibility, those processes are counter-cultural and ineffective.</p>
<p>Our efficiency approach, therefore, is to provide cost transparency and place the efficiency context as close to the decision-makers as possible.‚Äù</p>
<p><img src="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=800&amp;name=cloud-cost-management-tools-02.png" width="800" alt="Netflix's Cloud Cost Management Best Practices" srcset="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=400&amp;name=cloud-cost-management-tools-02.png 400w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=800&amp;name=cloud-cost-management-tools-02.png 800w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=1200&amp;name=cloud-cost-management-tools-02.png 1200w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=1600&amp;name=cloud-cost-management-tools-02.png 1600w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=2000&amp;name=cloud-cost-management-tools-02.png 2000w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=2400&amp;name=cloud-cost-management-tools-02.png 2400w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p><em>A picture of Netflix‚Äôs dashboard that shows cost by organizational hierarchy. This kind of reporting helps give every team ownership of their cost.</em></p>


<p><strong><img src="https://lh4.googleusercontent.com/NFqGI195_7US8FTRoEbUYloGvtOaXxwOrIYgGBOPT--iAe5Et9VAI2mOJMW8_s_YI9M_eWkVEzkU_FAQTUF37FX5VmymWHs-3I5FhOGnLe8qlSdQ1BxRDZl2M_yaZAHnoyty_l3J" width="247" height="98" alt="Expedia Logo"></strong></p>
<p><strong><span>How We Know</span></strong></p>
<p>Expedia spoke at re:Invent in 2017. This is a few years old at this point, but Expedia was quite sophisticated, even back then. You can watch it <a href="https://www.youtube.com/watch?v=iOWNZqG0RN4&amp;feature=emb_logo">here</a>.</p>
<p><strong><span>How They Do It</span></strong></p>
<p>At the time of this presentation, they were just embarking on building their own custom tool to get the metrics they needed, so this is a bit light on the details of what they eventually built.</p>
<p>However, they did share that their cost optimization practices are:</p>
<ul>
<li>Automation to tag all resources</li>
<li>Visualization and monitoring tools</li>
<li>Measure, measure, measure</li>
<li>Leveraged RI pricing</li>
<li>Decentralized forecasting and planning process</li>
<li>Encouraged teams to share optimization best practices</li>
</ul>
<p><strong><span>Cost Culture</span></strong></p>
<p>In 2017, Expedia wasn‚Äôt just focusing on cost optimization. They were building ‚Äúcost transparency‚Äù for their engineering teams and decentralizing responsibility for cost management. One of the major changes they made was involving engineering teams in the forecasting and budgeting.</p>
<p><img src="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=800&amp;name=cloud-cost-management-tools-03.png" alt="Expedia's Cloud Cost Management Best Practices" width="800" srcset="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=400&amp;name=cloud-cost-management-tools-03.png 400w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=800&amp;name=cloud-cost-management-tools-03.png 800w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=1200&amp;name=cloud-cost-management-tools-03.png 1200w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=1600&amp;name=cloud-cost-management-tools-03.png 1600w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=2000&amp;name=cloud-cost-management-tools-03.png 2000w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=2400&amp;name=cloud-cost-management-tools-03.png 2400w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p><em>A slide from Expedia's Re:Invent talk in 2017.&nbsp;</em></p>


<p><img src="https://lh5.googleusercontent.com/NI7jOF1kxFDxmn_q3P-_70Gw251xlwBtnJXXk6YOtEOFy1-qkpIOX9pRCJN_tE_vdT7N1JQMS6S57rEi33S_KdoDSYmJgKrgFajCmTIdD3hLzAIr6C99i-S9YfyOWy8N7Yf905ue" width="228" height="58" alt="Slack Logo"></p>
<p><strong><span>How We Know</span></strong></p>
<p>Slack published a <a href="https://angel.co/company/slack/jobs/1025669-software-engineer-cloud-economics">job posting</a> for a cloud economics engineer. While it is not quite as extensive as the blogs and re:Invent talks, it still gives us a glimpse into what Slack does for cost management. We suspect this posting won‚Äôt last forever, so we pasted it into a document <a href="https://docs.google.com/document/d/1ZC9e3dhGrAcKXdQR5wTz8Dpg9ZGc-1-PimGsn-K-FZY/edit?usp=sharing">here</a>.</p>
<p><strong><span>How They Do It</span></strong></p>
<ul>
<li>Slack has a cloud economics engineering team composed of cloud engineers, financial analysts, and AWS subject matter experts working to make Slack more performant, available, and cost-efficient each day.</li>
<li>They are developing a new platform to provide engineering teams visibility into their cloud spend and efficiency.</li>
<li>They are building a home-grown chargeback system to ensure the correct service owners know the cost they place onto other systems.</li>
</ul>
<p>They monitor cloud spend, track and alert on changes over time.</p>
<p><strong><span>Cost Culture</span></strong></p>
<p>This about sums it up: ‚ÄúWe advise teams within Slack on how to maximize their value from the cloud and ultimately aim to build a culture where all our engineers are cost-conscious and building a business scalable for the long term. We get excited about making Slack cost-efficient whilst ensuring we use the right technology stack.‚Äù</p>


<p><strong><img src="https://lh5.googleusercontent.com/k2T9Lahj1hs0np6zRfTBUhtTEKY1HNxItg6ItI5O0wxAWg0RrlDD5p68IiYsTFf7opSlcgwo7_9JxF2AE2uJDpNHCzUxwcrxaHJxEXmpG5kbq7olC4zeMWNxHzHfCy2sLHgDZNHV" width="257" height="52" alt="Segment Logo"></strong></p>
<p><span><strong>How We Know</strong></span></p>
<p>Segment has written two blogs about how they do cost management.</p>
<p>You can check them out here:</p>
<ul>
<li><a href="https://segment.com/blog/the-million-dollar-eng-problem/">The Million Dollar Engineering Problem </a> (2017)</li>
<li><a href="https://segment.com/blog/the-10m-engineering-problem/">The Ten Million Dollar Engineering Problem </a> (2019)</li>
</ul>
<p>Both blogs focus on how they cut down existing costs to improve margins (which we‚Äôre guessing helped that really, really big <a href="https://techcrunch.com/2020/10/12/twilios-3-2b-segment-acquisition-about-helping-developers-build-data-fueled-apps/">acquisition number</a>). We‚Äôre going to focus more on how they do ongoing monitoring and proactively reduce spend, which is covered in the 2019 blog.</p>
<p><span><strong>How They Do It</strong></span></p>
<ul>
<li>Today, they monitor their spend on an ongoing basis, so they won‚Äôt have to worry about their margins creeping up on them anymore.</li>
<li>To get the ongoing visibility they need, Segment built a set of repeatable pricing drivers, calculated daily. The entire cost pipeline feeds into their Redshift instance, and they get daily monitoring on their ‚Äúcost drivers‚Äù, visualized in Tableau. They have now built custom alerting to detect spikes and send teams an email.</li>
</ul>
<p><span><strong>Cost Culture</strong></span></p>
<p>Segment lists 36 people who are part of their ‚Äúgross margin team.‚Äù It‚Äôs clear they‚Äôve helped their engineering team understand the value of building cost-effective products.</p>

<h2>Part 3: Intelligence vs. Management</h2>
<p>Each company uses slightly different terminology. Expedia and Netflix both say they‚Äôve built ‚Äúcost transparency,‚Äù for example. But what is more striking ‚Äî are the similarities.</p>
<p>Each team has built essentially the same solution to transform cloud cost from centralized and reactive to autonomous and proactive ‚Äî while integrating cost as a key metric in their development process. They have also found metrics that align to their business, so everyone from their CEO down to an individual engineer can make better decisions based on cost.</p>
<p>At CloudZero, we call this <a href="https://www.cloudzero.com/cloud-cost-intelligence">cloud cost intelligence</a>.</p>
<p>Cloud cost management is about reporting retroactively on how much you have spent. Cloud cost intelligence is about leveraging cost data to outperform your competition ‚Äî or know exactly what levers you can pull when times get tough.</p>
<p>These companies have wielded this power to their advantage to generate resilient growth ‚Äî and you can too.</p>

<h2>Add Cloud Cost Intelligence the Easy Way</h2>
<p>Here‚Äôs the ‚Ä¶</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cloudzero.com/blog/cloud-cost-management-tools">https://www.cloudzero.com/blog/cloud-cost-management-tools</a></em></p>]]>
            </description>
            <link>https://www.cloudzero.com/blog/cloud-cost-management-tools</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061054</guid>
            <pubDate>Wed, 11 Nov 2020 18:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking Structured Interviewing: Hiring for Jobs You Don't Understand]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061052">thread link</a>) | @nickpresta
<br/>
November 11, 2020 | https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/ | <a href="https://web.archive.org/web/*/https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Have you ever hired for a job you didn‚Äôt understand? It‚Äôs scary. If you don‚Äôt know how to do the job yourself, how can you assess what a strong candidate looks like?</p>

<p>In this post, we‚Äôll see how to modify a well-researched interview methodology to quickly build a process  that helps you hire for the unknown in 4 steps. And, in the spirit of incrementalism, you‚Äôll have something useful after each step.</p>

<!--more-->

<p>(This post was also published as a series of articles on LinkedIn. See part <a href="https://www.linkedin.com/pulse/hacking-structured-interviewing-hiring-jobs-you-dont-part-dibernardo/">one.</a>)</p>

<h2 id="different-people-same-problem">Different People, Same Problem</h2>

<p>A couple of weeks ago, I spoke to two very different people who had the same problem. The first was a senior engineering leader at a ~300 person company who needed to hire a data analytics lead, a role that was very unfamiliar to them. The second was a founder who was hiring their first software engineer.</p>

<p>They were pretty stressed about it. Perhaps you can relate.</p>

<p>In my experience, people tend to approach this problem in one of two ways:</p>
<ol>
  <li>‚ÄúWe don‚Äôt know how to hire for this position, and we could spend a lot of time creating an interview process that doesn‚Äôt even work. We should hire based on ‚Äòculture fit‚Äô, which we can figure out by getting to know them. Sometimes we have to take risks.‚Äù</li>
  <li>‚ÄúWe don‚Äôt know how to hire for this position, It would be very expensive to hire the wrong person. We should create an exhaustive interview that assesses everything needed in this role, since this is a foundational hire. We don‚Äôt want to take too many risks.‚Äù</li>
</ol>

<p>These are both natural reactions. Both have clear downsides, and my experience is that both can easily lead to bad hiring decisions. So, perhaps the lesson is that if these are your only options, it‚Äôs probably better to take the former!</p>

<p>However, I think we can do better.</p>

<p>With a few hours of work, we can build a process that:</p>
<ul>
  <li>Reduces hiring risk</li>
  <li>Reduces bias and unfairness</li>
  <li>Creates a good experience for both candidate and the interviewers</li>
</ul>

<p>Furthermore, you can have something <em>usable</em>‚Äînot great, but usable‚Äîin under an hour.</p>

<p>How will we do this?</p>

<p>Starting from scratch would take too long. Luckily, there‚Äôs a lot of research-based practice that we can hack to make a good first hire without prohibitive effort.</p>

<p>In this article, we‚Äôll look to and oldie-but-goodie as a guide.</p>

<h2 id="hacking-structured-interviewing">Hacking Structured Interviewing</h2>

<p>Structured interviewing is a hiring methodology that has been heavily researched and practices for decades. Google has summarized the research and their own experiences with it on <a href="https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/steps/introduction/">re:work</a>, which is a super useful resource that I‚Äôve often referred to.</p>

<p>In their introduction to the topic, the writers state:</p>

<blockquote>
  <p>Structured interviewing simply means using the same interviewing methods to
assess candidates applying for the same job. Research shows that structured
interviews can be predictive of candidate performance, even for jobs that are
themselves unstructured.</p>
</blockquote>

<p>Sounds great! If we‚Äôre hiring this role for the first time, the job is likely to be pretty unstructured.</p>

<p>However, in the very next paragraph, we read:</p>

<blockquote>
  <p>So why don‚Äôt more organizations use structured interview questions? Well,
they are hard to develop. You have to write them, test them, and make sure
interviewers stick to them.</p>
</blockquote>

<p>Oof. And here I am assuring you this won‚Äôt take long. Maybe it‚Äôll just be easier to go with what you were originally planning. After all, how hard can it be?</p>

<p>Well:</p>

<blockquote>
  <p>Research has also shown that structured interviews aren‚Äôt more frequently used because, in general, interviewers everywhere think they‚Äôre good at interviewing and don‚Äôt need the help. Surely many of us like to think we‚Äôre excellent judges of character.</p>
</blockquote>

<blockquote>
  <p>But when it comes to hiring, don‚Äôt trust your gut. Research shows that during first encounters we make snap, unconscious judgments heavily influenced by our existing unconscious biases and beliefs. For example, in an interview context, without realizing it, we shift from assessing the complexities of a candidate‚Äôs competencies to hunting for evidence that confirms our initial impression. Psychologists call this <em>confirmation bias</em>.</p>
</blockquote>

<p>This cautionary clause helps us define our design problem.</p>

<p>We want to <em>quickly</em> create a hiring process that reduces our confirmation bias, because that will lead to better decisions.</p>

<p>The resources in re:work help with the confirmation bias part, but they don‚Äôt show us how to do it quickly. Let‚Äôs see how we can hack what they‚Äôve shown us to get some speed out of it.</p>

<h2 id="the-raw-materials">The Raw Materials</h2>

<p>There are a handful of <a href="https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/steps/know-the-components/">key elements</a> to a structured interview:</p>

<ol>
  <li>A small set of <strong>competencies</strong> that we‚Äôre looking for from candidates.</li>
  <li>Standard <strong>questions</strong> that test those competencies.</li>
  <li>Comprehensive <strong>feedback</strong> gathered by interviewers asking the questions.</li>
  <li>A <strong>rubric</strong> that helps interviewers consistently deliver their feedback.</li>
</ol>

<p>That seems like a lot to consider. However, this short list helps focus our hacking on techniques that are known to work.</p>

<p>We‚Äôre going to transform this list into a 4-step recipe for your own structured interview process. In the spirit of incrementalism, you‚Äôll have something useful after each step.</p>

<p>If you follow the whole thing, it should take about 3-4 hours.</p>

<h2 id="step-1-define-competencies">Step 1: Define Competencies</h2>

<p>Take 15-30 mins. and come up with a list of 3-5 <em>competencies</em> that are important in this role.</p>

<p>It can be tempting to pick more than that, but please start small. If Google can reduce their hiring criteria to <a href="https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/steps/define-hiring-attributes/">4 competencies</a>, I think we can get there too.</p>

<p>Each one should have a short 1-3 word ‚Äúslug‚Äù that captures its spirit, and a sentence or two to describe what it means in more detail.</p>

<p>If you‚Äôre not sure how to start, you can hack this boring-but-effective list:</p>

<ol>
  <li><strong>Technically Skilled.</strong> Has the hard skills and knowledge required to do the job well.</li>
  <li><strong>Effective Communicator.</strong> Talks about their work in a way that we understand and trust.</li>
  <li><strong>Has Soft Skills We Value.</strong> There are certain strengths or skills that each company uniquely values, so articulate this here.</li>
</ol>

<p>Each of these higher-level competencies can be broken down into more specific ones, but remember to keep the total to 5 or fewer.</p>

<p>To help with the hacking, let‚Äôs explore each of these suggested competencies a bit further.</p>

<h3 id="technical-skills">Technical Skills</h3>

<p>‚ÄúWait,‚Äù you may be thinking. ‚ÄúThe whole reason I‚Äôm reading this article is because I don‚Äôt know how to do this person‚Äôs job. Now you‚Äôre telling me to figure out how to assess their technical ability? What gives?!‚Äù</p>

<p>I know. It sucks. This will likely be the hardest competency for you to define. If you are hiring for a role that is the first of its kind in your company, you may not be able to describe it any more precisely than I already have, and that‚Äôs OK. We‚Äôll talk about some ways to manage this in the next step.</p>

<p>Most people in this position will get help from a teammate or other connection who knows the technicals of the job. This is especially true if you‚Äôre hiring a new leader to level-up a more junior team that is already doing the work.</p>

<p>Your role is to keep their ideas <em>focused</em>. This is important, because subject-matter experts can have a hard time keeping this list under control. I‚Äôve seen people struggle to pick fewer than 10 separate technical competencies that are important in their jobs.</p>

<p>You can help by finding ways to:</p>

<ul>
  <li>Coalesce competencies into larger areas of concern, and</li>
  <li>Eliminate things.</li>
</ul>

<p>If this is nerve-wracking, remember that time is always a constraint. More things on the list means longer interviews, and longer interviews mean less time for other important work. We‚Äôre not trying to cover every single thing that is important to the job; we‚Äôre trying to assess the most critical things with the time that we have.</p>

<h3 id="effective-communicator">Effective Communicator</h3>

<p>You may be unsurprised to find this in the list, but I want to highlight why I think this is especially important for a pioneering role.</p>

<p>If you‚Äôre creating a new kind of job in your team‚Äîeven if it already exists somewhere else at your company‚Äî it‚Äôs really important that you can trust this person to furnish you with information in a way that helps you make effective decisions.</p>

<p>When we‚Äôre hiring for something new, we can get so focused on the person‚Äôs ability to do the job that we lose sight of how important it is for everyone to meaningfully understand <em>how the work is going</em>. This is especially important if this person is responsible for building an entirely new competency within the company, because it‚Äôs hard for new things to build momentum without understanding and trust.</p>

<p>To summarize: It‚Äôs important that this person can do the job. It‚Äôs also super important that they can explain it to you and others in a way that‚Äôs easy to understand. This understanding creates trust, and trust fuels meaningful results.</p>

<h3 id="has-soft-skills-we-value">Has Soft Skills We Value</h3>

<p>I once spoke to a founder who was looking for people who were ‚Äúnaturally inquisitive.‚Äù That sounded off to me, because it requires more than testing for curiosity; it requires us to determine whether that curiosity is <em>intrinsic</em>.</p>

<p>I asked for a concrete example of what ‚Äúnatural inquisitiveness‚Äù looked like. They said: ‚ÄúWell, at the lunch table, we‚Äôll often have big debates about political or social issues. These are really fun, because people won‚Äôt just state their thoughts: They‚Äôll try to find the logical arguments or fallacies behind the different positions. It‚Äôs not just an emotional conversation. We‚Äôre always looking to verify the underlying principles.‚Äù</p>

<p>From this starting point, we were eventually able to articulate the ‚Äúsoft skill‚Äù that they were looking for: A good candidate would <em>effectively apply the scientific method to everyday problems</em>.</p>

<p>This re-framing improves on the original in several ways:</p>

<ul>
  <li>It‚Äôs easier to assess than ‚Äúnaturally inquisitive‚Äù.</li>
  <li>It has less to do with <em>identity</em> and more to do with <em>ability</em>.</li>
  <li>It connects to a unique part of the company‚Äôs history, which was founded by scientists out of a university research project.</li>
</ul>

<p>Because first-time hires tend to be fraught with risk, I find that interviewers naturally want to latch onto something that helps ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/">https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/</a></em></p>]]>
            </description>
            <link>https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061052</guid>
            <pubDate>Wed, 11 Nov 2020 18:18:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overview of 3D meshing methods using open source tools]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25060942">thread link</a>) | @alibabaSX
<br/>
November 11, 2020 | https://www.sesamx.io/blog/3d_mesh_with_free_tools/ | <a href="https://web.archive.org/web/*/https://www.sesamx.io/blog/3d_mesh_with_free_tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        

<p>The Internet is full of beautiful 3D mesh examples, but it is difficult to get clues
about how they were constructed. In fact, <strong>creating a good 3D mesh can be very
painful without the right tools or training</strong>. Furthermore, most of commercial
pre-processing software have been improving and propose powerful 3D meshing algorithm,
capable of building hybrid or full hexahedron mesh. <strong>The aim of
this article is to give an overview of the constraints involved when building
a 3D mesh for structural finite element, as well as exposing various meshing
methods relying on free and open source tools</strong>.</p>

<h2 id="introduction">Introduction</h2>

<p>Before we start, let‚Äôs give some background information about 3D mesh
construction. Usually a 3D mesh can be composed of 4 types of elements:</p>

<ul>
<li><p>tetrahedron (4 corners),</p></li>

<li><p>wedge (6 corners),</p></li>

<li><p>hexahedron (8 corners),</p></li>

<li><p>and rarely pyramids (5 corners).</p></li>
</ul>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/3d_mesh_element_types.png" alt="3D mesh element types"></p>

<p><strong>The goal is to get a mesh with the lowest number of
degrees of freedom (‚Äúdofs‚Äù), while maintaining a good representative capability</strong>.
We may be
tempted to race for tetrahedrons, which have only 4 nodes (for a linear
element). But reality is more involved: <strong>certain types of elements behave better
than others</strong>. Without entering to much into the details, we can provide some hints
about this:</p>

<ul>
<li><p><strong>4-node tetrahedron (linear element) must be avoided as mush as possible</strong>. It
behaves poorly and a lot of them are needed to get meaningful results. If you
have no other choice, try to convert them to 10-node tetrahedron which is much
better.</p></li>

<li><p>if you want to stay with linear elements, <strong>you must aim towards hexahedron</strong>. Most
finite element software (you can guess that SesamX is part of them) propose an
improved version of the hexahedron element. That makes it a better choice than
the other elements.</p></li>

<li><p><strong>6-node wedge (linear element)</strong> is better than 4-node tetrahedron but worse than
8-node hexahedron. <strong>It is ok to use them, but go for hexahedron wherever possible</strong>.</p></li>

<li><p>I have not tested the pyramid enough to give relevant advice. Nevertheless,
from the fact that this element is seldom used in 3D mesh, this article will not
shed light on it.</p></li>
</ul>

<p>It is easy to build a full tetrahedron mesh using an automatic mesher
(and it is widespread among various software). On the contrary, <strong>full hexahedron or
hybrid automatic meshers are more involved and harder to find</strong> (you can find them
among commercial solutions but almost not among free ones).</p>

<p><strong>However, using only free and open source tools, we are still able to build
quality 3D meshes</strong>.</p>

<p>The remaining of <strong>this article exhibits 4 methods to build 3D meshes using Salome or
Gmsh</strong>. The goal is not to enter into every detail about the options used, but to
give an overview of how 3D meshes can be built. Whatever the tool we use, changing
the element order is usually a trivial task (either linear or quadratic).
Therefore I will not detail it here. Instead, <strong>I will focus on controlling the
element shapes while meshing</strong>.</p>

<p>For each method, I provide a step by step guide with illustrative screenshots. And, when
appropriate, I also provide the final result file that you can edit and modify
on your own.</p>

<h2 id="geometry-used">Geometry used</h2>

<p>I will use the following con rod to showcase how to build each mesh.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/con_rod_geometry.PNG" alt="Con rod geometry"></p>

<p>One important feature to mention here, is that <strong>this con rod geometry is made of
a compound of 3 solids</strong> (this reason will make sense when talking about the hybrid
mesh generation method) corresponding to each color on the image above.</p>

<p>You can find the corresponding step file
<a href="https://www.sesamx.io/blog/files/008_3d_mesh_with_free_tools/con_rod_to_mesh.step">here</a>.</p>

<h2 id="full-tetrahedron-automatic-meshing-method">Full tetrahedron automatic meshing method</h2>

<p>As mentioned before, <strong>it is pretty straightforward to get a full tetrahedron<br>
mesh</strong>. To build this mesh, we use <strong>Salome</strong>.</p>

<p>First, we go to the geometry module and import the step file. The Salome tree
should look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_import_tree.PNG" alt="Salome import tree"></p>

<p>Then we have to explode the compound geometry into its 3 sub-solids and create a
partition from these solids. <strong>This step is necessary to ensure that Salome will merge
coincident nodes from each solid faces</strong>. The result tree is then:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_partition_tree.PNG" alt="Salome partition"></p>

<p>Next we go to the mesh module, and create a new mesh on the partition. Under
algorithm we can select ‚ÄúNETGEN 1D-2D-3D‚Äù and under hypothesis ‚ÄúNETGEN 3D
Simple Parameters‚Äù. Finally we have to input the edge size that our elements should
have.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/tetrahedron_mesh_parameters.png" alt="Salome tetrahedron mesh parameters"></p>

<p>Eventually we have to right click on the mesh and hit ‚ÄúCompute‚Äù. The mesh should
look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/tetrahedron_mesh.PNG" alt="Salome tetrahedron mesh"></p>

<p>As you can see, the mesh is made of tetrahedron but also triangles and edges
elements. To get rid of the 2D and 1D elements, the first step is to
click on the mesh and select ‚ÄúCreate Group‚Äù. A panel appear and we can create one
group containing all the 2D elements (as shown on the picture below) and
similarly for the 1D elements.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_create_group.png" alt="Salome create group"></p>

<p>Next to delete these elements, we have to right
click on each group and select ‚ÄúDelete Group with Content‚Äù. <strong>And we get
the following full tetrahedron mesh</strong>.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/final_tetrahedron_mesh.PNG" alt="Salome final tetrahedron mesh"></p>

<p>Finally, <strong>to check that the mesh does not contain any duplicated nodes</strong> we have to
select the mesh and use ‚ÄúControls / Node Controls / Double Nodes‚Äù.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/full_tet_double_nodes.PNG" alt="Tetrahedron duplicated nodes check"></p>

<p>If you want to manipulate this mesh, you can find the corresponding Salome database
<a href="https://www.sesamx.io/blog/files/008_3d_mesh_with_free_tools/full_tet_con_rod.hdf">here</a>.</p>

<h2 id="full-hexahedron-automatic-meshing-method">Full hexahedron automatic meshing method</h2>

<p>Next come the full hexahedron mesh. To build this mesh, we use <strong>Gmsh</strong>.</p>

<p>First, <strong>it is necessary to create a volume physical group containing the 3
solids of the model. It ensure afterwards that the mesh export will, in fact,
export only the 3D elements.</strong></p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/gmsh_volume_physical_group.PNG" alt="Gmsh volume physical group"></p>

<p>Next we go to ‚ÄúTools / Options‚Äù then ‚ÄúMesh / General‚Äù to select the meshing
parameters. We can
choose whatever makes it for the 2D algorithm, 3D algorithm and 2D recombination
algorithm. These parameters influence how the mesh is built, feel free to change
them to notice the difference in the mesh. As a first guess, we can
stay with ‚ÄúDelaunay‚Äù and ‚ÄúBlossom‚Äù. However, <strong>make sure to select ‚ÄúAll Hexas‚Äù as the
‚ÄúSubdivision algorithm‚Äù so that the volumes will be filled with hexahedron only.</strong></p>

<p>Finally under ‚ÄúMin/Max element size‚Äù we can fix the element size.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/gmsh_meshing_parameters.PNG" alt="Gmsh meshing parameters"></p>

<p>Eventually, we have to go back to the Gmsh tree and click ‚Äú3D‚Äù under ‚ÄúMesh‚Äù to
build the mesh.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/gmsh_mesh_creation.png" alt="Gmsh mesh creation"></p>

<p>We can check the mesh content under ‚ÄúTools / Statistics‚Äù. As you can see, the mesh
is made of 1D, 2D and 3D-hexahedron elements. <strong>Because we have created a physical
group for the 3 volumes, only the 3D mesh will be exported.</strong></p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/final_hexaedron_mesh.PNG" alt="Gmsh mesh creation"></p>

<p>If you have troubles visualizing the 3D elements, you can adjust the visibility
parameters in the ‚ÄúMesh‚Äù options window under the ‚ÄúVisibility‚Äù tab.</p>

<p>Unfortunately, there is a trap here. <strong>The mesh obtained has duplicated nodes</strong>
at the interfaces between the 3 solids. To visualize them, we can export the mesh
as a .med file, import it in Salome, and use the ‚Äúdouble nodes‚Äù tool mentioned
previously.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/full_hexahedron_duplicated_nodes.PNG" alt="Hexahedron duplicated nodes"></p>

<p>Finally, to solve this issue, we have to use the ‚ÄúMerge Nodes‚Äù tool under
‚ÄúModification / Transformation‚Äù.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/full_hexahedron_remove_duplicated.PNG" alt="Hexahedron remove duplicated nodes"></p>

<h2 id="hybrid-meshing-method">Hybrid meshing method</h2>

<p>Next <strong>I am showcasing how to build an efficient hybrid mesh with Salome.</strong> This
method is my favorite because <strong>it leads to a well structured mesh, which can
capture more efficiently the details of the geometry</strong> (if you have a close look
to the automatic tetrahedron and hexadreon meshes, you can see that the fillet
is not always ‚Äúwell captured‚Äù for instance). The drawback of this method is that it does not
lead to a full hexahedron mesh but an hybrid mesh made with a majority of
hexahedrons, and a minority of wedges used to fill gaps.</p>

<p><strong>The 3D mesh will be built first by meshing 2D surfaces and then by extruding
them.</strong> To make this process workable, the geometry has been split into 3 solids
beforehand. Each of these solids can then be meshed as an extrusion of the surface
meshes.</p>

<table>
<thead>
<tr>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybride_mesh_solid_1.PNG" alt="Solid 1"></th>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybride_mesh_solid_2.PNG" alt="Solid 2"></th>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybride_mesh_solid_3.PNG" alt="Solid 3"></th>
</tr>
</thead>

<tbody>
<tr>
<td><center><em>Solid 1</em></center></td>
<td><center><em>Solid 2</em></center></td>
<td><center><em>Solid 3</em></center></td>
</tr>
</tbody>
</table>

<p>As explained for the full-tetrahedron mesh, <strong>we first need to explode the
compound geometry and build a partition.</strong></p>

<p>Then, in order to build the 2D meshes on the surfaces and the 3D extrusion meshes,
we need to extract (using explode) the relevant geometries from this partition:</p>

<ul>
<li>the 3 solids geometries,</li>
<li>the top face of solid 1 (red face on solid 1 image), that will drive the
3D mesh on solid 1,</li>
<li>the ‚Äúfillet face‚Äù of solid 2 and 3 (red face on solid 3 image) that will drive
the 3D mesh on solid 2 and solid 3.</li>
</ul>

<p>The Salome tree should look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_partition_tree_hybrid.PNG" alt="Salome tree for hybrid mesh"></p>

<p>Next, we go to the mesh module. The meshing process is the following:</p>

<ul>
<li><p>Create a mesh object and assign default 3D mesh parameters to the whole
partition,</p></li>

<li><p>Create 2 sub-meshes for the 2 surfaces to mesh,</p></li>

<li><p>Create 3 sub-meshes for the 3 solids to mesh.</p></li>
</ul>

<p><strong>The default 3D meshing parameters will not be used while computing the mesh,
because the sub-meshes definition will cover the whole partition.</strong> Nevertheless, Salome
still requires these default parameters.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/tetrahedron_mesh_parameters.png" alt="Salome import tree"></p>

<p>To create the faces sub-meshes, we have to right click on the mesh and
select ‚ÄúCreate Sub-mesh‚Äù. We then need to select one of the faces and choose the
‚ÄúNETGEN 1D-2D‚Äù
algorithm with ‚ÄúNETGEN 2D Simple Parameters‚Äù. Then we can input the element size
and <strong>make sure to check ‚ÄúQuad-dominated‚Äù (to avoid at most triangles)</strong>.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/face_submesh_parameters.png" alt="Salome face submesh parameters"></p>

<p>To compute the sub-mesh, we have to right click on it and select ‚ÄúCompute
Sub-mesh‚Äù. And we repeat these operations for the second face.</p>

<p><strong>Creating the 3D sub-meshes is similar.</strong> Once we have selected the solid to mesh,
we choose ‚ÄúExtrusion 3D‚Äù as the meshing algorithm and no hypothesis needs to be associated.
However, we have to provide the 1D algorithm and hypothesis to define
how the mesh extrusion should behave.</p>

<p>We select ‚ÄúWire Discretisation‚Äù as the 1D algorithm, and the previous local length
used for the 2D sub-meshes as the hypothesis.</p>

<table>
<thead>
<tr>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_3d_submesh_parameters.png" alt="Hybrid 3D submesh parameters"></th>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_1d_submesh_parameters.png" alt="Hybrid 1D submesh parameters"></th>
</tr>
</thead>

<tbody>
<tr>
<td><center><em>3D submesh parameters</em></center></td>
<td><center><em>1D submesh parameters</em></center></td>
</tr>
</tbody>
</table>

<p>We repeat this for the 2 other solids. The mesh tree should look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_mesh_tree.PNG" alt="Salome hybrid mesh tree"></p>

<p><strong>Before computing the mesh, we need to tell Salome in which order the sub-meshes
should be computed.</strong> To avoid meshing conflict while extruding, it is best in
our case, to fully mesh solid 1 before meshing the driving surface of solid 2
and solid 3. We have to right click on the mesh and select ‚ÄúChange sub-mesh Priority‚Äù.
The meshing order should be the following:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_mesh_order.PNG" alt="Salome hybrid mesh tree"></p>

<p>After ‚Ä¶</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sesamx.io/blog/3d_mesh_with_free_tools/">https://www.sesamx.io/blog/3d_mesh_with_free_tools/</a></em></p>]]>
            </description>
            <link>https://www.sesamx.io/blog/3d_mesh_with_free_tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060942</guid>
            <pubDate>Wed, 11 Nov 2020 18:07:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote Work: 5 Tips for Finding the Best Remote Jobs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060843">thread link</a>) | @martin_crd
<br/>
November 11, 2020 | https://remoteworkers.net/blog/5-tips-for-finding-best-remote-jobs | <a href="https://web.archive.org/web/*/https://remoteworkers.net/blog/5-tips-for-finding-best-remote-jobs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The pandemic has caused an enormous shift in the way the world works. Companies had to adapt, and we see that <strong>remote working</strong> has become a reality for many employees. Many people are now considering if this transition could be a more permanent work situation after the Covid crisis is over and asking: What if I could work remotely forever?</p><p>If you are thinking about taking the plunge, here are the best tips for you to find the best <strong>remote jobs</strong>:</p><h2>1) Is this the Right kind of Job for You?</h2><p><strong>Remote work</strong> is not for everybody, some people thrive in an office environment, and others easily succeed in working remotely. Be honest and ask yourself which one are you. Only you can define if it is a fit for your work and lifestyle.</p><h2>2) Get to know the remote work community</h2><p>Most job sites don‚Äôt have a very good ‚Äúremote work‚Äù filter, but that has changed in the past couple of years with more platforms out there advertising exclusively for remote jobs.</p><p>Once you start your search it‚Äôs important to understand the differences between fully and partially distributed companies. A fully distributed company is one in which everyone in the company works remotely. Partially distributed companies are any companies with one or more remote workers, also known as ‚Äúremote-friendly‚Äù or ‚Äúremote-flexible‚Äù.&nbsp;</p><p>But why does that matter?</p><p>Most fully distributed companies have solid onboarding systems and ongoing training programs, so you‚Äôll be set up for success. There are also many partially distributed companies that have successfully integrated a remote workforce. Keep that in mind while searching for a position and ask about it in the interview process.</p><h2>3) Know What Remote Employers Are Looking For</h2><p>Trustworthy people that truly love their work are, by far, the most important traits that employers are looking for in a candidate for a remote job position.</p><p>It seems pretty obvious if you consider that they need to trust that each team member will do their job, as well as create high-quality work, all outside an office environment. If you‚Äôre not motivated to work, you likely won‚Äôt succeed if no one is looking over your shoulder. Show your remote interviewer how much you care about your work;&nbsp; it will definitely resonate with them.</p><h2>4) Tailor your resume for remote job applications.</h2><p>To land an interview, your resume needs to be tailored to remote companies. Consider including the following points to stand out to remote employers:</p><p><strong>List all important tools:</strong> software tools that you are familiar with using are great to mention. Remote companies are very dependent on these tools to assure that the work and communication flows. Some examples: Slack, Google Hangouts, Trello,&nbsp; Zoom, etc.</p><p><strong>Communication:</strong> Remote companies fail because of bad communication, consequently they look to hire amazing communicators. Your resume should talk about your communication skills, and your email communication with hiring managers and recruiters should be impeccable.</p><p><strong>Autonomy:</strong> Any time you worked with low or no supervision is valuable and will be well noticed on your resume.</p><h2>5) Take Timezone and Location into consideration</h2><p>Looking to start <strong>working remotely</strong> for a company that has its team spread around the globe sounds exciting, but pay attention to the working hours and what your working schedule would look like. Some companies offer total flexibility and you only have to consider their time zone in case of a virtual team meeting from time to time.</p><p>This might be very different for other companies, in which your "online presence" will be expected according to the time zone of where the company has its headquarters. It's easy if you live in Portugal, applying for a remote position in a french company.&nbsp; Figuring out a good time for a meeting from Lisbon while the rest of your team is based in Tokyo might be a much more complicated task. Pay attention to these details while searching for the perfect remote job for you.</p><p>The <strong>remote job</strong> application is not harder but indeed a bit different from other traditional office jobs. To stand out from other candidates, it‚Äôs imperative that you immerse yourself in the remote community and show passion for your work.</p><h2>Are you ready?</h2><p>Start now looking for your dream remote job at a remote-friendly company looking to hire the best talent, join <a href="https://remoteworkers.net/signup">Remote Workers</a> today!</p></div></div>]]>
            </description>
            <link>https://remoteworkers.net/blog/5-tips-for-finding-best-remote-jobs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060843</guid>
            <pubDate>Wed, 11 Nov 2020 17:58:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Datasaur (YC W20) CEO Ivan on how to build/label NLP data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060816">thread link</a>) | @cl42
<br/>
November 11, 2020 | https://phaseai.com/resources/datasaur-label-build-nlp-datasets | <a href="https://web.archive.org/web/*/https://phaseai.com/resources/datasaur-label-build-nlp-datasets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <div>
     <div>

     <p>&nbsp;

<iframe src="https://player.vimeo.com/video/477875501?title=0&amp;byline=0&amp;portrait=0" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>

     </p><h3>Best Practices for NLP Data Collection and Design</h3>
     <p><i>Ivan Lee on November 10, 2020</i>

     </p><p>You can't build NLP-powered products and services without robust, detailed data sets. Unfortunately, building such data sets can be time consuming and expensive; a poorly designed data set will also prevent your models from actually helping users. Ivan Lee is the CEO and founder of <a href="https://datasaur.ai/" target="_blank">Datasaur</a>, which provides an end-to-end solution for labeling data and using it to build and train NLP-powered models and products. He will discuss best practices for data set design and labelling.
     
     </p><p>Datasaur recently raised <a href="https://techcrunch.com/2020/09/29/datasaur-snags-3-9m-investment-to-build-intelligent-machine-learning-labeling-platform/" target="_blank">$3.9M to build their NLP data platform</a>, and the company is part of Y Combinator's Winter 2020 batch.

     </p></div>
   </div>
</div></div>]]>
            </description>
            <link>https://phaseai.com/resources/datasaur-label-build-nlp-datasets</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060816</guid>
            <pubDate>Wed, 11 Nov 2020 17:56:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing leaky logs: how to find a bug and ensure it never returns]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060456">thread link</a>) | @pabloest
<br/>
November 11, 2020 | https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><blockquote>
<p><strong>TL;DR</strong> I lay out a case for moving security enforcement into the hands
of developers. I show how I and another developer at r2c successfully identified data
leakage in our logs, fixed the issue, and prevented it from happening in the
future. We did this <em>in a matter of hours, without assistance from our AppSec team</em>.</p>
</blockquote>
<h2>Introduction</h2>
<p>As a developer and engineering manager, I‚Äôve become obsessed with finding ways
to rapidly solve security issues across the engineering organization without ever
needing to fully involve our security team.</p>
<p>Why is this important? I see multiple benefits:</p>
<ul>
<li>Fixing security issues is <em>fast</em>. So fast, in fact, that we can solve them in
minutes after identifying them, without security issues languishing for days
or weeks. In previous roles, I've seen internally known security issues lie
open with only obscurity protecting my organization from fallout.</li>
<li>When developers can solve security issues easily themselves, it frees the
security team to focus on ‚Äúbig picture‚Äù security. I want security engineers
to be thinking how to choose frameworks, set up tools, help with secure
architecture, and build defense-in-depth‚Äînot finding my last XSS mistake.</li>
</ul>
<p>I call this concept ‚Äúself-service DevSec‚Äù.</p>
<p>In the rest of this blog post, I'll walk through a security bug we encountered
during the day-to-day course of regular development work. I'll discuss how we
discovered the issue, and how, within just a few hours, fixed the security
issue, and used Semgrep to prevent the bug from reoccurring.</p>
<p>Here's the story:</p>
<h2>Story</h2>
<p>Last month, I was debugging a Flask web-app authentication workflow with
Clara McCreery, another engineer at r2c. Like many engineers faced with
a confusing debugging problem, one of our first steps was to throw the web-app
into debug logging.</p>
<p>Specifically, we wanted to know what was going on with our database operations,
so we set our ORM (in this case, we use SQLAlchemy) into INFO-level logging with:</p>
<div data-language="py"><pre><code>logging<span>.</span>getLogger<span>(</span><span>"sqlalchemy.engine.base.Engine"</span><span>)</span><span>.</span>setLevel<span>(</span>logging<span>.</span>INFO<span>)</span></code></pre></div>
<p>This configures SQLAlchemy to log all SQL statements, together with passed
parameters. Let's look at some of the output we saw:</p>
<div data-language="shell-session"><pre><code><span>INFO:werkzeug:127.0.0.1 - - [25/Sep/2020 11:50:01] "POST /api/auth/authenticate HTTP/1.1" 200 -
INFO:sqlalchemy.engine.base.Engine:BEGIN (implicit)
INFO:sqlalchemy.engine.base.Engine:SELECT token.id AS token_id, token.token AS token_token, token.name AS token_name
FROM token
WHERE token.token = %(token_1)s
 LIMIT %(param_1)s
</span><span>INFO<span>:</span><span>sqlalchemy.engine.base.Engine:{'token_1': </span></span><span><span>$</span><span>2a<span>$10</span><span>$KVsyW1jjKn</span>.pvkVi3w9Rn.1mwnZFd7F2SFveGDG8flIhbe.MoJH4G, <span>'param_1'</span><span>:</span> <span>1</span><span>}</span></span></span></code></pre></div>
<p>...Uh-oh.</p>
<p>We definitely shouldn‚Äôt be logging tokens (even if they're securely hashed).
(In this example the actual token value has been changed to protect
the innocent.)</p>
<h2>Let‚Äôs make a plan</h2>
<p>At this point we‚Äôve identified a security issue, and we want to stomp it out
while preserving our ability to inspect logs. Our plan:</p>
<ol>
<li>Mitigate the immediate security issue.</li>
<li>Find a permanent solution to the problem that‚Äôs future proof. A permanent
solution means a baked-in change to our systems. Ideally this solution is
automated and seamless across our entire organization.</li>
<li>Add a mechanism to enforce our solution‚Äôs use organization-wide.</li>
</ol>
<p>In the rest of this post, I‚Äôll walk you through how we addressed each step.
Notably, we were able to accomplish this entire flow in a couple hours, without
engaging the security team at all.</p>
<h3>1. Mitigation</h3>
<p>Mitigation here was fairly straightforward, as we already knew the root cause
of our problem. We can quickly revert our logging change. Then we can do
a quick audit of our logs to ensure that only development test tokens were
leaked.</p>
<h3>2. The permanent solution</h3>
<p>How do we prevent SQLAlchemy from logging sensitive data?</p>
<p><em>A valiant attempt</em></p>
<p>Step 1 was to read the docs. A quick web search of ‚Äúsqlalchemy hide parameters
in engine logging‚Äù linked us to the SQLAlchemy <a href="https://docs.sqlalchemy.org/en/13/core/engines.html" target="_blank" rel="noopener">Engine
documentation</a>. A detailed
read later, we found the <code>hide_parameters</code> flag, which prevents the logging
framework from emitting <em>any</em> parameters in logs or exceptions.</p>
<p>While this certainly would prevent our security issue, it was too blunt of a hammer
for us: we wanted to know (for example) database IDs, and the like, for debugging.</p>
<p><em>The real solution</em></p>
<p>We then inspected the relevant SQLAlchemy <a href="https://github.com/sqlalchemy/sqlalchemy/tree/master/lib/sqlalchemy" target="_blank" rel="noopener">source
code</a>. The
relevant code is in <code>sqlalchemy/engine/base.py</code>:</p>
<div data-language="py"><pre><code>    <span>if</span> self<span>.</span>_echo<span>:</span>
        self<span>.</span>engine<span>.</span>logger<span>.</span>info<span>(</span>statement<span>)</span>
        <span>if</span> <span>not</span> self<span>.</span>engine<span>.</span>hide_parameters<span>:</span>
            self<span>.</span>engine<span>.</span>logger<span>.</span>info<span>(</span>
                <span>"%r"</span><span>,</span>
                sql_util<span>.</span>_repr_params<span>(</span>
                    parameters<span>,</span> batches<span>=</span><span>10</span><span>,</span> ismulti<span>=</span>context<span>.</span>executemany
                <span>)</span><span>,</span>
            <span>)</span></code></pre></div>
<p><code>sql_util._repr_params</code>, in turn, runs:</p>
<div data-language="py"><pre><code><span>def</span> <span>_repr_params</span><span>(</span>self<span>,</span> params<span>,</span> typ<span>)</span><span>:</span>
    trunc <span>=</span> self<span>.</span>trunc
    <span>if</span> typ <span>is</span> self<span>.</span>_DICT<span>:</span>
        <span>return</span> <span>"{%s}"</span> <span>%</span> <span>(</span>
            <span>", "</span><span>.</span>join<span>(</span>
                <span>"%r: %s"</span> <span>%</span> <span>(</span>key<span>,</span> trunc<span>(</span>value<span>)</span><span>)</span>
                <span>for</span> key<span>,</span> value <span>in</span> params<span>.</span>items<span>(</span><span>)</span>
            <span>)</span>
        <span>)</span>
    <span>.</span><span>.</span><span>.</span></code></pre></div>
<p>Investigating <code>trunc</code>, we found that it converts the parameter value by
truncating the parameter‚Äôs <code>repr</code> to a maximum number of characters.</p>
<p>This meant that we should override the <code>repr</code> method of the parameter object to
prevent sensitive logging.</p>
<p>At this point, like good engineers, we took the lazy route: stand on your
peers‚Äô shoulders. I found <a href="https://github.com/sqlalchemy/sqlalchemy/issues/4806" target="_blank" rel="noopener">this GitHub
issue</a>, where <a href="https://techspot.zzzeek.org/" target="_blank" rel="noopener">Mike
Bayer</a> had already posted a nice solution.</p>
<p>Some shameless copying later (and adding some types to make <code>mypy</code> happy), we
had <a href="https://gist.github.com/nbrahms/2fee940f4d87f09ffc3823be5a334cf3" target="_blank" rel="noopener">this
Gist</a>. The
key code is:</p>
<div data-language="py"><pre><code><span>class</span> <span>ObfuscatedString</span><span>(</span>types<span>.</span>TypeDecorator<span>)</span><span>:</span>
    <span>"""
    String column type for use with SQLAlchemy models whose
    content should not appear in logs or exceptions
    """</span>

    impl <span>=</span> types<span>.</span>String

    <span>class</span> <span>Repr</span><span>(</span><span>str</span><span>)</span><span>:</span>
        <span>def</span> <span>__repr__</span><span>(</span>self<span>)</span> <span>-</span><span>&gt;</span> <span>str</span><span>:</span>
            <span>return</span> <span>"********"</span>

    <span>def</span> <span>process_bind_param</span><span>(</span>self<span>,</span> value<span>:</span> Optional<span>[</span><span>str</span><span>]</span><span>,</span> dialect<span>:</span> Any<span>)</span> <span>-</span><span>&gt;</span> Optional<span>[</span>Repr<span>]</span><span>:</span>
        <span>return</span> self<span>.</span>Repr<span>(</span>value<span>)</span> <span>if</span> value <span>else</span> <span>None</span>

    <span>def</span> <span>process_result_value</span><span>(</span>
        self<span>,</span> value<span>:</span> Optional<span>[</span>Repr<span>]</span><span>,</span> dialect<span>:</span> Any
    <span>)</span> <span>-</span><span>&gt;</span> Optional<span>[</span><span>str</span><span>]</span><span>:</span>
        <span>return</span> <span>str</span><span>(</span>value<span>)</span> <span>if</span> value <span>else</span> <span>None</span>


<span>setattr</span><span>(</span>db<span>,</span> <span>"ObfuscatedString"</span><span>,</span> ObfuscatedString<span>)</span></code></pre></div>
<p>What does this code accomplish? It replaces our original <code>str</code> parameters
with a new <code>ObfuscatedString.Repr</code> parameter. When logged (or when emitted
into an exception message), the string is replaced by our <code>********</code>
obfuscation sentinel. Since the parameter is still bound as a raw string (via
<code>impl = types.String</code>), the correct value is still inserted and selected from
the database.</p>
<p>To use this new column type, we set our <code>token</code>‚Äôs column type:</p>
<div data-language="py"><pre><code><span>class</span> <span>Token</span><span>(</span>db<span>.</span>Model<span>)</span><span>:</span>
    <span>.</span><span>.</span><span>.</span>
    token <span>=</span> db<span>.</span>Column<span>(</span>db<span>.</span>ObfuscatedString<span>,</span> <span>.</span><span>.</span><span>.</span><span>)</span>
    <span>.</span><span>.</span><span>.</span></code></pre></div>
<p>We then re-enabled INFO logging, and checked that we were properly obfuscating
text:</p>
<div data-language="shell-session"><pre><code><span>INFO:werkzeug:127.0.0.1 - - [25/Sep/2020 13:48:55] "GET /api/agent/deployments/1/policies HTTP/1.1" 200 -
INFO:sqlalchemy.engine.base.Engine:BEGIN (implicit)
INFO:sqlalchemy.engine.base.Engine:SELECT token.id AS token_id, token.token AS token_token, token.name AS token_name
FROM token
WHERE token.token = %(token_1)s
 LIMIT %(param_1)s
INFO:sqlalchemy.engine.base.Engine:{'token_1': ********, 'param_1': 1}</span></code></pre></div>
<p>For completeness, we also validated in our development database console that the
correct values were stored and retrieved.</p>
<p>Great success! üö¢ Ship it.</p>
<h3>3. Enforcement</h3>
<p>It was tempting to rest on our laurels here. We had solved our security issue for
the time being, and we could get back to debugging our original auth issue.</p>
<p>But we wanted to guarantee that <em>we would never see this issue again</em>. How would we do
this?</p>
<p>Here are some ideas that I‚Äôm sure we‚Äôve all encountered before:</p>
<ol>
<li>Block all commits to SQLAlchemy models on security review!</li>
<li>Host a yearly security training for all devs, including the pitfalls of
logging sensitive data!</li>
<li>Audit logs weekly!</li>
<li>File an issue with your SAST provider, demanding they add checks to catch
sensitively logged data!</li>
</ol>
<p>If there is a central take-away from this blog post, it is this: these are not
ideal solutions:</p>
<ol>
<li>Blocking commits introduces needless friction into the development
process, slows development velocity, and needlessly distracts the security
team.</li>
<li>Security trainings are an important component to a security program, and
necessary to keep developers aware of evolving security threats, but humans
have fallible memory, and we can forget things we've heard months or even
days in the past.</li>
<li>Regular audits, like blocking commits, introduce a heavy workload on an
almost certainly overloaded security team.</li>
<li>Your SAST provider will certainly welcome your suggestion, but you will be
beholden to their software release cycle, and may not see checks be
available for months; furthermore, if your issue is domain-specific, it may
not even make sense for a check to be implemented within a generalist product.</li>
</ol>
<p>Fortunately, Semgrep gave us a simple solution here: Define an
<em>invariant</em> in your code, and <em>enforce</em> it using a Semgrep scan on every CI
run.</p>
<p>At r2c, we use GitHub Actions to run Semgrep on every merge request. We define
what checks Semgrep should run using <em>a managed policy</em>, a list of rules and
notification settings managed by <a href="https://semgrep.dev/" target="_blank" rel="noopener">semgrep.dev</a>.</p>
<p>To guarantee our code against future issues, I went to
<a href="https://semgrep.dev/editor" target="_blank" rel="noopener">semgrep.dev/editor</a> and wrote <a href="https://semgrep.dev/s/nbrahms:obfuscate-sensitive-string-columns-2" target="_blank" rel="noopener">a quick rule</a>
to detect potential insecurely logged SQLAlchemy columns.</p>
<p>Here's the rule definition in Semgrep's YAML definition language:</p>
<div data-language="yaml"><pre><code><span>rules</span><span>:</span>
<span>-</span> <span>id</span><span>:</span> obfuscate<span>-</span>sensitive<span>-</span>string<span>-</span>columns
  <span>patterns</span><span>:</span>
    <span>-</span> <span>pattern</span><span>:</span> <span>|</span><span>
        $COLUMN = db.Column(db.String, ...)</span>
    <span>-</span> <span>metavariable-regex</span><span>:</span>
        <span>metavariable</span><span>:</span> $COLUMN
        <span>regex</span><span>:</span> <span>'.*(?&lt;![A-Za-z])(token|key|email|secret)(?![A-RT-Za-rt-z]).*'</span>
  <span>message</span><span>:</span> <span>|</span><span>
    '$COLUMN' may expose sensitive information in logs and exceptions. Use
    'db.ObfuscatedString' instead of 'db.String'.</span>
  <span>severity</span><span>:</span> WARNING</code></pre></div>
<p>What does this rule do? Let‚Äôs break it down:</p>
<ul>
<li><code>id</code>: We give our rule a concise descriptive ID for easy reference by any developer who
sees it pop up in their editor or CI output.</li>
<li>
<p><code>patterns</code>: This is composed of two parts:</p>
<ul>
<li><code>pattern</code>: This expression tells Semgrep to ‚Ä¶</li></ul></li></ul></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/">https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/</a></em></p>]]>
            </description>
            <link>https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060456</guid>
            <pubDate>Wed, 11 Nov 2020 17:29:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doomsday prepping ‚Äì Disaster planning for less crazy folk (2016)]]>
            </title>
            <description>
<![CDATA[
Score 168 | Comments 111 (<a href="https://news.ycombinator.com/item?id=25060418">thread link</a>) | @VBprogrammer
<br/>
November 11, 2020 | https://lcamtuf.coredump.cx/prep/ | <a href="https://web.archive.org/web/*/https://lcamtuf.coredump.cx/prep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

 

<a name="1"></a>
<h2>1. Introduction <span>[<a href="#1">link</a>]</span></h2>

<p>
The prepper culture begs to be taken with a grain of salt. In a sense, it has
all the makings of a doomsday cult: a tribe of unkempt misfits who hoard gold
bullion, study herbalism, and preach about the imminent collapse of our society.
</p>

<p>
Today, we see such worries as absurd. It's not that life-altering disasters are
rare: every year, we hear about millions of people displaced by wildfires, earthquakes,
hurricanes, or floods. Heck, not a decade goes by without at least one first-class
democracy lapsing into armed conflict or fiscal disarray. But having grown up in a period
of unprecedented prosperity and calm, we take our way of life for granted - and find
it difficult to believe that an episode of bad weather or a currency crisis could
upend our lives for good.
</p>

<p>
I suspect that we dismiss such hazards not only because they seem surreal, but also because
worrying about them makes us feel helpless and lost. What's more, we follow the same instincts
to tune out far more pedestrian and avoidable risks; for example, 
most of us don't plan ahead for losing a job, for dealing with a week-long water outage, or
for surviving the night if our home goes up in smoke.
</p>

<p>
For many, the singular strategy for dealing with such dangers is to pray for the
government to bail us out. But no matter if our elected officials prefer to school us with
passages from
<a href="https://smile.amazon.com/dp/0156334607">Milton
Friedman</a> or from
<a href="https://smile.amazon.com/dp/0486477487" title="I'm sorry... I'm really sorry!">Thomas
Piketty</a>, the hard truth is that no state can provide a robust safety net for all
of life's likely contingencies; in most places, government-run social programs are severely deficient in funding, in
efficiency, and in scope. Large-scale disasters pit us against even worse odds; from New Orleans in 2005 to
Fukushima in 2011, there are countless stories of people left behind due to political dysfunction, poorly
allocated resources, or lost paperwork.
</p>

<p>
And so, the purpose of this guide is to combat the mindset of learned helplessness by
promoting simple, level-headed, personal preparedness techniques that are easy to
implement, don't cost much, and will probably help you cope with whatever life throws your way.
</p>

<p>
Oh, one thing: in contrast to most other docs of its kind, this page an
unadulterated labor of love; there are no affiliate links, paid product placements, or ads anywhere in the guide.
</p>

<a name="2"></a>
<h2>2. Mapping out the unknown <span>[<a href="#2">link</a>]</span></h2>

<p>
Effective preparedness can be simple, but it has to be rooted in an honest and
systematic review of the risks you are likely to face. Plenty of excited newcomers begin
by shopping for ballistic vests and night vision goggles; they would be better
served by grabbing a fire extinguisher, some bottled water, and then putting the rest of
their money in a rainy-day fund.
</p>

<p>
To maintain sanity while trying to enumerate risks, I found that it's best to focus on
broad outcomes instead of trying to track down every single way for things to go south.
Say, it should not matter if you are laid off because of a downsizing, because
your new boss hates you, or because they finally catch you stealing paperclips. The
outcome is the same: you are out of a job and urgently need a way to pay your bills.
</p>

<p>
Another insidious distraction is the desire to immediately figure out how to respond to all the scenarios
we end up dreaming of. Let's save that for later; by prematurely focusing on the second half of the
problem, we may end up glossing over some of the less tractable scenarios - or make
haphazard assumptions that will cloud our judgment in other ways.
</p>

<p>
I also found that to come up with a rational threat model, we need to think of "risk" as a product of
both the probability and the consequences of a given event. By that metric, stubbed toes
and zombie outbreaks are equally uninteresting; one of them has nearly zero significance,
the other, nearly zero odds.
</p>

<p>
What else? Ah, right: the final piece of advice I have is to keep things uncomplicated. There are
popular doomsday predictions that deal with cutting-edge particle physics, god-like computer
hackers, vast government conspiracies, or extraterrestrial messages hidden in pop songs. I suppose
we can't <i>really</i> rule that stuff out, but historical data suggests that there's a lot more
merit in worrying about falling off a ladder or getting hit by a car.
</p>

<p>
All right! With these caveats in mind, let's go over some canonical scenarios that are worth thinking about.
</p>

<a name="2.1"></a>
<h3>2.1. Problem space #1: Small-scale events <span>[<a href="#2.1">link</a>]</span></h3>

<p>
It's always fun to speculate about solar flares and supervolcanoes; it's far more mind-numbing to
seriously evaluate the consequences of backed up sewage or burst water mains. But in reality,
such unglamorous, small-scale incidents are far more likely to disrupt and reshape our
lives.
</p>

<p>
Broadly speaking, disastrous outcomes of such humdrum contingencies can be divided into
several groups:
</p>

<ul>

<li>
<p>
<b>Insolvency.</b>
  If a person over the age of 40 tells you that they have never lost a job, they are
  pretty lucky (or lying). Yet, the risk is seldom taken seriously; many middle-class,
  single-income families would be in deep trouble if it ever took them more than 2-3 months
  to find a new, equally well-paying gig.
</p>

</li><li>
<p>
<b>Disrupted access to water, food, energy, or transportation.</b>
  Substantial and prolonged outages happen everywhere; many of us will experience
  at least one at some point in our lives. A week without electricity may be just
  inconvenient and scary, especially in a high-rise or
  in a seedy neighborhood; but even a single hot day without potable water is really
  bad news.
</p>

</li><li>
<p>
<b>Loss of shelter.</b>
  Every year, there are over 350,000 house fires in the United States. Such accidents
  usually aren't deadly - but if you are unlucky, they can leave you stranded in the middle
  of the night in your PJs, with no documents or credit cards in hand.
</p>

</li><li>
<p>
<b>Unintentional injury.</b>
  Largely preventable and predictable incidents - such as falls, vehicle collisions, and poisonings -
  account for some 40 million ER visits annually. And lest you say people are simply too
  quick to rush to the hospital, said incidents also result in about 100,000 US
  deaths every year.
</p>

</li><li>
<p>
<b>Intentionally inflicted harm.</b>
  Violent crime is essentially <i>normal</i> almost everywhere in the world.
  In the US in the 90s, your lifetime likelihood of victimization was
  estimated to be around 80%; the odds of suffering criminal injury hovered at 40%. More recent
  research is hard to come by - but rest assured, life-threatening encounters remain a very real risk.
</p>

</li><li>
<p>
<b>Debilitating illness or death.</b>
  It's going to get you; maybe next week, maybe in 50 years. We can't really predict the day,
  but we can understand and meaningfully manage the impact it will have on those who depend on us -
  say, our stay-at-home partners or young kids.
</p>

</li></ul>

<p>
All in all, the risks discussed in this section have three defining characteristics: they are relatively
likely to happen; are strikingly easy to mitigate (we'll get into that soon); and tend to be so
unglamorous that they seldom make the cut in any "serious" guide to emergency preparedness.
</p>

<a name="2.2"></a>
<h3>2.2. Problem space #2: Mass calamities <span>[<a href="#2.2">link</a>]</span></h3>

<p>
If an errant backhoe took out the utilities for your block, you would probably head to the
grocery store to pick up bottled water (and use their restrooms, too). But if a
once-in-a-century storm damaged major roads and left half the city without running water, your
options wouldn't be as clear-cut.
</p>


<p>
That's why we have to look at larger-scale emergencies through somewhat different lens, taking into
account their likely magnitude, duration, and the nature of the forces at play. Some of the
plausible scenarios to think about include:
</p>

<ul>

<li>
<p>
<b>Natural disasters.</b>
  Common examples include floods, hurricanes, earthquakes, wildfires, and heatwaves. In some
  regions, such events are very rare; in others, they are almost guaranteed every decade or two.
</p>

</li><li>
<p>
<b>Industrial accidents.</b>
  Many people live in the proximity of heavy industries - say, refineries, freight railroads, or power plants.
  Depending on the type of industrial facilities nearby, you may want to evaluate the potential
  consequences of upwind and upstream explosions or chemical spills.
</p>

</li><li>
<p>
<b>Social unrest.</b>
  Riots are a distinct risk in many urban and suburban areas around the world. When angry mobs
  take it to the streets, widespread arson and violent crime are not unheard of, sometimes going
  on for days or weeks.
</p>

</li><li>
<p>
<b>Economic crises.</b>
  All highly developed countries go through cyclic recessions and periods of high unemployment;
  the US had about ten big ones in the past 100 years alone. Sometimes, such events
  are accompanied by bank runs and collapses of financial institutions; other times,
  they involve hyperinflation, product rationing, and currency controls.
</p>

</li><li>
<p>
<b>Pandemic.</b>
  It's been a while since the highly developed world experienced a devastating outbreak, but it
  may be premature to flat out dismiss the risk. In 1918, an unusual strain of flu managed to kill 75
  million people. Few years later, a mysterious sleeping sickness - probably also of viral origin -
  swept the globe, crippling millions, some for life. We aren't necessarily better prepared
  for similar events today.
</p>

</li><li>
<p>
<b>Terrorism or conventional war.</b>
  We think we would see it coming - but history shows that such events tend to catch nations
  off guard. These phenomena are noteworthy not only because of their immediate death toll,
  which can be relatively low - but because of the far-reaching and long-term socioeconomic
  disruption they can cause.
</p>

</li></ul>

<p>
Most of us will probably not get tangled up in a large-scale disaster of any sort, but it
is only wise to hedge your bets. There are countless examples to demonstrate that such events
happen often and can strike close to home - say:
</p>

<ul>

<li>
<p>
The EU debt crisis, from 2009 onward. A series of events that led to staggering unemployment rates
in Greece, deposit confiscations in Cyprus, and uncertain prospects for the entire
eurozone.
</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lcamtuf.coredump.cx/prep/">https://lcamtuf.coredump.cx/prep/</a></em></p>]]>
            </description>
            <link>https://lcamtuf.coredump.cx/prep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060418</guid>
            <pubDate>Wed, 11 Nov 2020 17:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Event Sourcing and CQRS with Incident ‚Äì Part 1]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25060270">thread link</a>) | @pedroassumpcao
<br/>
November 11, 2020 | https://pedroassumpcao.ghost.io/event-sourcing-and-cqrs-using-incident-part-1/ | <a href="https://web.archive.org/web/*/https://pedroassumpcao.ghost.io/event-sourcing-and-cqrs-using-incident-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
        <main id="main">
            <div>

                

                
<section>

    <header>
        <span>November 2, 2020</span>
        
            <p>Event Sourcing and CQRS are design patterns that are great for some domains. The Incident library will help implement them without compromising other parts of your application.</p>
    </header>

    <p><img src="https://pedroassumpcao.ghost.io/content/images/2020/11/e227890b80a0c1ca5436721579babc8b.jpg" alt="Using Event Sourcing and CQRS with Incident -  Part 1"></p>

    <div>
        <p>This is the first of a series of posts that I will present on how your application can use <strong>Event Sourcing</strong> and <strong>CQRS</strong> for specific domains with an open-source library that I am developing called <strong><a href="https://github.com/pedroassumpcao/incident">Incident</a></strong>.</p><hr><p>My first contact with Event Sourcing was back in 2016 when I was working for Raise Marketplace and I led a project that the goal was to solve an accounting burden regarding seller payments. As a marketplace, in a nutshell, a buyer pays for something, the company gets a commission and the seller receives the remaining funds. Track the money flow, depending on the options the marketplace offers, can become complex. In that specific case, sellers could opt for combining funds to be paid daily, via different methods such as check, PayPal, ACH, and so on, or decide to request funds one by one. Around all of that, there was a fraud detection process, transfer limits, a different category of sellers, and so on.</p><p>Before Event Sourcing, there was a lack of a cohesive way to track the steps of each fund, from buyer to seller, and all possible scenarios. And when that comes to accounting people, it becomes a nightmare.</p><p>With well-defined commands, events, and logic associated with them, it became more clear the information the Accounting department needed at the time.</p><p>Later on, I had the opportunity to work on other personal projects using Event Sourcing so I decided to build something to help me moving forward, and from that learning came <a href="https://github.com/pedroassumpcao/incident">Incident</a>.</p><h2 id="what-is-event-sourcing">What is Event Sourcing?</h2><p><strong>Event Sourcing</strong> is a design pattern that defines that the state changes of an entity are stored as a sequence of events. Events are the source of truth and immutable, and the current state of any entity is playing all events of the entity in the order they happened.</p><p>If you are new to <strong>Event Sourcing</strong> and <strong>CQRS</strong> I highly recommend watch <a href="https://www.youtube.com/watch?v=JHGkaShoyNs" rel="nofollow">Greg Young's presentation at Code on the Beach 2014</a> before moving forward as my intention with this blog post series is not to present Event Sourcing principles per se and the details but how those principles were used in the implementation.</p><h2 id="what-event-sourcing-is-not">What Event Sourcing is not?</h2><p>One of the misconceptions that I often see is that if you decide to use Event Sourcing you should apply it to your entire system, to all your domains. This is &nbsp;wrong in my opinion, an anti-pattern and you should avoid at all costs as unlikely all your domains will suit.</p><p>Another fact, Event Sourcing is not new, many industries using "Event Sourcing" concepts even not naming the same way. Accounting keeps track of all account operations, your medical record is about your health history, contracts don't change, they have addendums, and so on.</p><h2 id="incident-main-goals">Incident Main Goals</h2><p>When I decided to implement a new library, based on my learning through other projects, I had some goals in mind that I'd like to achieve:</p><ul><li>incentivize the usage of Event Sourcing and CQRS as a great choice for domains that can leverage the main benefits of this design pattern;</li><li>offer the essential building blocks for using Event Sourcing in your system with proper contracts, but allowing specific needs to leverage what Elixir already brings to the table, for example, concurrency;</li><li>leverage functions and reducers for executing commands and applying events in the aggregate logic, facilitating stateless tests;</li><li>be extensible without compromising the main principles;</li></ul><h2 id="events-vs-projections">Events vs Projections</h2><p>Events are the <strong>source of truth</strong> in any Event Sourcing domain, they are immutable and they are used to calculate the current state of any aggregate (or entity) at any time. All the events of any type, for any aggregate type, are stored in the Event Store in a single table.</p><p>The projections are the <strong>representation of the current state</strong> of an aggregate and they are very similar to what any system that does not use Event Sourcing has. The domain will have as many projection tables as you need but usually, you will have one table for each entity type. All projection tables are stored in the Projection Store.</p><p>The following diagram helps understand the separation between the command model from the query model, and their responsibilities as well.</p><ol><li>UI/API issues a <strong>Command</strong> to attempt to change the state;</li><li><strong>Aggregate</strong> logic that lives in the <strong>Command Model</strong> is used (including past events) and if everything is fine, a new <strong>Event</strong> will be persisted in the <strong>Event Store</strong>;</li><li>The <strong>Event Handler</strong> will receive the new event and project the new aggregate state into the <strong>Projection Store</strong>;</li><li>UI/API will query the <strong>Aggregate Current State</strong> from the <strong>Query Model</strong>;</li></ol><figure><img src="https://pedroassumpcao.ghost.io/content/images/2020/10/Event-Sourcing.png" alt="Event Sourcing - Command and Query Model" srcset="https://pedroassumpcao.ghost.io/content/images/size/w600/2020/10/Event-Sourcing.png 600w, https://pedroassumpcao.ghost.io/content/images/2020/10/Event-Sourcing.png 710w"></figure><h2 id="aggregate-vs-aggregate-state">Aggregate vs Aggregate State</h2><p>One of the things that I see when implementing Event Sourcing that makes it harder is to try to manage aggregate logic, aggregate state data structure, and aggregate state logic in the same place. Incident does a little differently.</p><p>The <strong>Aggregate</strong> will define how a specific entity (<em>Bank Account</em>, for example) will execute each of its allowed commands and apply each of its allowed events. The aggregate itself only defines the logic but not the current state calculation.</p><p>The <strong>Aggregate State</strong> defines the initial state of an Aggregate and it is able to calculate the current state by replaying all the events through the aggregate logic.</p><p>Back in 2013, Greg Young tweeted the following:</p><!--kg-card-begin: html--><blockquote><div lang="en" dir="ltr"><p>want to learn event sourcing? </p><p>f(state, event) =&gt; state</p></div>‚Äî Greg Young (@gregyoung) <a href="https://twitter.com/gregyoung/status/313358540821647360?ref_src=twsrc%5Etfw">March 17, 2013</a></blockquote> <!--kg-card-end: html--><p>Incident follows that principle with the <strong>Aggregate</strong> logic in a nutshell being:</p><ul><li>Command &gt; Function &gt; Event;</li><li>Event and State &gt; Function &gt; New State;</li></ul><p>And part of the <strong>Aggregate State</strong> logic is similar to:</p><!--kg-card-begin: markdown--><pre><code>Enum.reduce(events, state, fn event, state -&gt;
  aggregate.apply(event, state)
end)
</code></pre>
<!--kg-card-end: markdown--><hr><h2 id="let-s-get-started">Let's Get Started</h2><p>In this series we will be using Incident to implement the <strong>Account</strong> domain of a <strong>Bank</strong> system for these main reasons:</p><ul><li>it is a domain that benefits from the Event Sourcing principles;</li><li>it contains simple scenarios such as <strong>opening an account</strong>, <strong>depositing funds</strong>;</li><li>it contains complex scenarios such as <strong>transferring funds</strong> from one account to another;</li></ul><p>Other common domains of a typical Bank system, for example, Client Profile, Authentication/Authorization won't be the focus of the Incident implementation as they are not a good fit, at least not in our case. This is to emphasize the fact that you don't need to have Event Sourcing in your entire system.</p><h3 id="application-and-incident-setup">Application and Incident Setup</h3><p>Let's create a new application for our Bank, including the supervision tree. As a side note, I am using <strong>Elixir 1.11</strong> in this series so some of the Elixir configuration details might vary depending on the version you are using.</p><!--kg-card-begin: markdown--><pre><code>~&gt; mix new bank --sup
</code></pre>
<!--kg-card-end: markdown--><p>Add <strong>Incident</strong> in <code>mix.exs</code>, fetch and compile the dependencies:</p><!--kg-card-begin: markdown--><pre><code>defmodule Bank.MixProject do
  use Mix.Project

  # hidden code
  
  def deps do
    [
      {:incident, "~&gt; 0.5.1"}
    ]
  end
end
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code>~&gt; mix do deps.get, deps.compile
</code></pre>
<!--kg-card-end: markdown--><p>Generate Ecto Repos for the <strong>Event Store</strong> and <strong>Projection Store</strong>, this will create the repo modules:</p><!--kg-card-begin: markdown--><pre><code>~&gt; mix ecto.gen.repo -r Bank.EventStoreRepo
...
~&gt; mix ecto.gen.repo -r Bank.ProjectionStoreRepo
...
</code></pre>
<!--kg-card-end: markdown--><p>In your application <code>config/config.exs</code> specify the Ecto repos and configure Incident:</p><!--kg-card-begin: markdown--><pre><code># hidden code

config :bank, ecto_repos: [Bank.EventStoreRepo, Bank.ProjectionStoreRepo]

config :incident, :event_store,
  adapter: Incident.EventStore.PostgresAdapter,
  options: [
    repo: Bank.EventStoreRepo
  ]

config :incident, :projection_store,
  adapter: Incident.ProjectionStore.PostgresAdapter,
  options: [
    repo: Bank.ProjectionStoreRepo
  ]

import_config "#{config_env()}.exs"
</code></pre>
<!--kg-card-end: markdown--><p>In your application <code>config/dev|test|prod.exs</code> (the example below defines two separated databases but it could be the same one), set up the database access for Ecto for each environment:</p><!--kg-card-begin: markdown--><pre><code># config/dev.exs

# hidden code

config :bank, Bank.EventStoreRepo,
  username: "postgres",
  password: "postgres",
  hostname: "localhost",
  database: "bank_event_store_dev"

config :bank, Bank.ProjectionStoreRepo,
  username: "postgres",
  password: "postgres",
  hostname: "localhost",
  database: "bank_projection_store_dev"
</code></pre>
<!--kg-card-end: markdown--><p>Add the Ecto repo modules to the supervision tree in your <code>lib/bank/application.ex</code>:</p><!--kg-card-begin: markdown--><pre><code>defmodule Bank.Application do
  @moduledoc false

  use Application

  @impl true
  def start(_type, _args) do
    children = [
      Bank.EventStoreRepo,
      Bank.ProjectionStoreRepo
    ]

    opts = [strategy: :one_for_one, name: Bank.Supervisor]
    Supervisor.start_link(children, opts)
  end
end
</code></pre>
<!--kg-card-end: markdown--><p>Create the database(s), generate the Incident <strong>events table</strong> migration, and run the migrations:</p><!--kg-card-begin: markdown--><pre><code>~&gt; mix ecto.create
...
~&gt; mix incident.postgres.init -r Bank.EventStoreRepo
...
~&gt; mix ecto.migrate
...
</code></pre>
<!--kg-card-end: markdown--><p>The setup is done, it seems a lot but most of it is a common setup needed for any application using Ecto.</p><h2 id="the-bank-account">The Bank Account</h2><p>As we will keep track of bank accounts, we will define some initial components that are defined only once, and then later evolve the aggregate with the logic that will be based on the operations we want the aggregate to respond to.</p><h3 id="projection">Projection</h3><p>We will need to present to the user some bank account information. So we will define one projection that will contain the current state of the bank accounts. Generate an Ecto migration as below, please notice the <code>-r</code> flag that specifies which repo the migration will be:</p><!--kg-card-begin: markdown--><pre><code>~&gt; mix ecto.gen.migration CreateBankAccountsTable -r Bank.ProjectionStoreRepo
</code></pre>
<!--kg-card-end: markdown--><p>Populate the migration with the following fields. Besides the desired fields related to bank account data, every projection should also contain <code>version</code>, <code>event_id</code>, and <code>event_date</code> fields. They inform the last event that updated the projection and how many events were applied to it:</p><!--kg-card-begin: markdown--><pre><code>defmodule Bank.ProjectionStoreRepo.Migrations.CreateBankAccountsTable do
  use Ecto.Migration

  def change do
    create table(:bank_accounts) do
      add(:aggregate_id, :string, null: false)
      ‚Ä¶</code></pre></div></section></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pedroassumpcao.ghost.io/event-sourcing-and-cqrs-using-incident-part-1/">https://pedroassumpcao.ghost.io/event-sourcing-and-cqrs-using-incident-part-1/</a></em></p>]]>
            </description>
            <link>https://pedroassumpcao.ghost.io/event-sourcing-and-cqrs-using-incident-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060270</guid>
            <pubDate>Wed, 11 Nov 2020 17:13:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advance Electromagnetism Notes (Site)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060248">thread link</a>) | @E-Reverance
<br/>
November 11, 2020 | https://andrealommen.github.io/PHY309/lectures | <a href="https://web.archive.org/web/*/https://andrealommen.github.io/PHY309/lectures">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article>

  

  <div>
    <h3 id="for-reference">For reference</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/derivatives">All the Fundamental Theorems Together</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/maxwell">Maxwell‚Äôs Equations</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/minus_signs">Minus Signs</a><br></p>
<h3 id="chapter-1-vector-analysis">Chapter 1: Vector Analysis</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/grad">Gradients Theorem</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/div">Divergence Theorem</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/curl">Stokes‚Äô Theorem (Curl)</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/dirac">Dirac Delta Function</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/potentials">Potentials and Boundary Conditions</a><br></p>
<h3 id="chapter-2-electrostatics">Chapter 2: Electrostatics</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt2">Andrea‚Äôs Crash Course in Chapter 2</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/electric">Electric Field</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/divcurlE">Divergence and Curl of Electric Field, Gauss‚Äôs Law</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/PotentialWorkEnergy">Potential, Work, Energy</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/conductors">Boundary Conditions and Conductors</a><br></p>
<h3 id="chapter-3-potentials">Chapter 3: Potentials</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt3">Andrea‚Äôs Crash Course in Chapter 3</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/laplace">Laplace‚Äôs Equation and the Method of Images</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/separation">Separation of Variables</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/multipole">Multipole Expansion </a><br></p>
<h3 id="chapter-4-electric-fields-in-matter">Chapter 4: Electric Fields in Matter</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt4">Andrea‚Äôs Crash Course in Chapter 4</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/polarization">Polarization</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/debrief">Debrief HW3</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/displacement">Displacement</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/boundaryD">Boundary Values in the Presence of a Dielectric</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/SolutionToInClassDielectricCylinderProblem.pdf">Full solution to the Dielectric Cylinder Problem</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/final_words_displacement">Final Words (Rant?) on Displacement</a><br></p>
<h3 id="one-third-of-the-way-through-the-course-we-reflect">One-third of the way through the course, we reflect‚Ä¶</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/CumulativeSummary1">Summary of Course so Far</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/Survey.html">Survey Results</a><br></p>
<h3 id="first-exam">First Exam</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/firstexamformat">What will be the format of the 1st exam?</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/practice_problems_1st">Practice Problems for 1st exam</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/firstexam">First Exam</a><br></p>
<h3 id="chapter-5-magnetostatics">Chapter 5: Magnetostatics</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt5">Andrea‚Äôs Crash Course in Chapter 5</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/lorentz">Lorentz and Biot-Savart</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/ampere">Ampere‚Äôs Law and the Vector Potential</a><br></p>
<h3 id="chapter-6-magnetic-fields-in-matter">Chapter 6: Magnetic Fields in Matter</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt6">Andrea‚Äôs Crash Course in Chapter 6</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/magnetized_matter">Magnetization and the Field of a Magnetized Object</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/auxiliary">The Auxiliary Field</a><br></p>
<h3 id="chapter-7-electrodynamics">Chapter 7: Electrodynamics</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/allChapt7">Andrea‚Äôs Crash Course in Chapter 7</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/induction">Electromotive Force and Induction</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/maxwellChapt7">Maxwell‚Äôs Equations</a><br></p>
<h3 id="chapter-8-griffiths-calls-it-conservation-laws-at-this-point-we-only-picked-up-the-continuity-equation-and-saved-the-rest-for-after-chapter-9">Chapter 8: Griffiths calls it Conservation laws, at this point we only picked up the Continuity Equation and saved the rest for after Chapter 9</h3>
<p>(We‚Äôre kind of picking up Chapter 8 along the way‚Ä¶)<br>
<a href="https://andrealommen.github.io/PHY309/lectures/allChapt8">Andrea‚Äôs Crash Course in Chapter 8</a><br></p>
<h3 id="chapter-9-electromagnetic-waves">Chapter 9: Electromagnetic Waves</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/allChapt9">Andrea‚Äôs Crash Course in Chapter 9</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/light">Light!!!!!</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/polarization">Polarization of Waves in Linear and Conducting Media</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/reflection">Boundary Conditions, Reflection and Transmission</a><br></p>
<h3 id="second-exam">Second Exam</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/secondexamreview">Review for the second exam</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/secondexamformat">What will be the format of the 2nd exam?</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/practice_problems_2nd">Practice Problems for 2nd exam</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/secondexam">Second Exam</a><br></p>
<h3 id="poynting-vector-energy-transmission-coefficient-parts-of-chapters-8-and-9">Poynting Vector, Energy, Transmission coefficient (parts of chapters 8 and 9)</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/quarterwaveplate">In a quarter wave plate, can we really assume the transmission coefficients are the same?</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/poynting">Poynting Theorem, Poynting Vector, Energy, Momentum</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/transmission">Poynting Theorem in EM Waves, Transmission and Reflection Coefficients</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/plasma">Waves in a Tenuous Plasma, Dispersion</a> <br></p>
<h3 id="chapter-10-potentials-and-fields">Chapter 10: Potentials and Fields</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/Chapt10ReviewPlusTensors">Andrea‚Äôs Crash Course in Chapter 10</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/potentialformulation">The Potential Formulation</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/deferred">The Deferred Potential</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/leinard">Leinard-Wiechert Potential</a> <br></p>
<h3 id="chapter-11-radiation">Chapter 11: Radiation</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/allChapt11">Andrea‚Äôs Crash Course in Chapter 11</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/radiation">Radiation</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/dipole">Dipole Radiation</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/point">Radiation from a Point Charge</a> <br></p>
<h3 id="the-final-week-looking-backwards-and-forwards">The Final Week: Looking backwards and forwards</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/Chapt10ReviewPlusTensors">Chapter 10 Review (emphasis Gauge and Deferred) Plus Relativity, Chapt 12</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/Chapt10ReviewPt2">Chapter 10 Review cont‚Äôd including Deferred Potential</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/allChapt11">Pancake breakfast party, and Review Chapter 11.  We‚Äôll do a questionnaire here to get your thoughts about the class</a></p>
<h3 id="the-final-exam">The Final Exam</h3>
<p>You may look at the following whenever you want.  It explains the format of the exam and what kind of problems
to expect.
<a href="https://andrealommen.github.io/PHY309/lectures/finalexamformat">Format of the Final Exam</a><br></p>

<p>When you‚Äôre ready to take the exam please click <a href="https://andrealommen.github.io/PHY309/lectures/finalexam">here.</a></p>

  </div>


</article>


      </div>
    </div></div>]]>
            </description>
            <link>https://andrealommen.github.io/PHY309/lectures</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060248</guid>
            <pubDate>Wed, 11 Nov 2020 17:11:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will Futhark Work on Apple Silicon?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060172">thread link</a>) | @Athas
<br/>
November 11, 2020 | https://futhark-lang.org/blog/2020-11-11-will-futhark-work-on-apple-silicon.html | <a href="https://web.archive.org/web/*/https://futhark-lang.org/blog/2020-11-11-will-futhark-work-on-apple-silicon.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      

<p>
    Posted on November 11, 2020
    
        by Troels Henriksen
    
</p>

<p>Apple is coming out with computers that are basically ARM64, <a href="https://en.wikipedia.org/wiki/Think_different">but with a different ABI than existing ARM64 for some reason</a>. They call the architecture <a href="https://en.wikipedia.org/wiki/Mac_transition_to_Apple_Silicon">Apple Silicon</a>, which is a wonderful term that will undoubtedly never become dated or insufficiently precise.</p>
<p>Anyway, you see various posts such <a href="https://developer.r-project.org/Blog/public/2020/11/02/will-r-work-on-apple-silicon/">Will R Work on Apple Silicon?</a> where language developers answer whether their language will work on these new machines. Since these machines will support transparent emulation of x86, the simple answer is <em>yes</em>. Apple‚Äôs emulation was quite good during the PPC-to-x86 transition, so this is trustworthy. Of course, emulation is never going to be as fast as native compilation. For R, the problem is that they depend on some Fortran code, and there is <a href="https://developer.apple.com/forums/thread/651476">not yet a Fortran compiler available for Apple Silicon</a>.</p>
<p>Well, I can confirm that Futhark depends on absolutely no Fortran. Futhark compiles to C (or Python), and does not care about the specific target architecture. Therefore, Futhark programs should run fine on Apple Silicon. The bigger problem is that <a href="https://www.extremetech.com/computing/270902-apple-defends-killing-opengl-opencl-as-developers-threaten-revolt">Apple has deprecated OpenCL</a>, and <a href="https://www.provideocoalition.com/officially-official-nvidia-drops-cuda-support-for-macos/">does not support CUDA at all</a> due to being grumpy with NVIDIA, so there may eventually be no way to run Futhark <em>on a GPU</em> on macOS. It is unlikely that we will find the time to add a backend for Apple‚Äôs <a href="https://developer.apple.com/metal/">proprietary Metal API</a> that is supported <em>absolutely nowhere else</em>, but it‚Äôs possible that we‚Äôll finish Futhark‚Äôs embryonic Vulkan backend. While macOS does not come bundled with Vulkan, <a href="https://github.com/KhronosGroup/MoltenVK">even Apple probably cannot hold back this eruption</a>.</p>
<p>And of course, the Futhark multi-core backend should run well on any Unix-like system.</p>


    </div></div>]]>
            </description>
            <link>https://futhark-lang.org/blog/2020-11-11-will-futhark-work-on-apple-silicon.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060172</guid>
            <pubDate>Wed, 11 Nov 2020 17:04:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Minimal 3D creative coding tool ‚Äì control 8√ó8√ó8 dots with JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25060146">thread link</a>) | @doersino
<br/>
November 11, 2020 | https://doersino.github.io/tixyz/ | <a href="https://web.archive.org/web/*/https://doersino.github.io/tixyz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://doersino.github.io/tixyz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060146</guid>
            <pubDate>Wed, 11 Nov 2020 17:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at how LinkedIn exfiltrates extension data from their users (2020)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060089">thread link</a>) | @coreyprophitt
<br/>
November 11, 2020 | https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users | <a href="https://web.archive.org/web/*/https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div>
          <p><img src="https://prophitt.me/assets/images/posts/linkedins-gambit.svg" width="300" height="300"></p><div>
            
            <p><time datetime="2020/11/05T00:00:00Z">Published on November 5th, 2020</time>
          </p></div>
        </div>

        <p><span>√Ç¬∑</span><span>√Ç¬∑</span><span>√Ç¬∑</span></p>

        <h2>What did I find?</h2>
        <p>
          LinkedIn is actively spraying their users' browser with web requests and dom queries in an attempt to determine
          if certain browser extensions are installed. The data is then exfiltrated back to LinkedIn.
        </p>
        <p>
          It is not clear what the data is used for or how it is used by LinkedIn. However, it is clear LinkedIn is
          targeting certain sales and recruiting tools. It is also common knowledge in the sales and recruiting
          communities that LinkedIn restricts or outright bans accounts based on the use of unapproved tools.
        </p>
        <p>
          LinkedIn is within their right to detect malicious user behavior and take action. However, the means they are
          employing are problematic for a number of reasons:
          </p><ol>
            <li>
              LinkedIn doesn't verify you are actually using the extension, they only check if the extension is currently
              installed and/or enabled.
            </li>
            <li>
              A number of the tools LinkedIn does not allow have legitimate uses and can be used on public web pages.
            </li>
            <li>
              The exfiltrated data could be further used for nefarious things such as browser finger printing.
            </li>
          </ol>
        

        <p>
          Furthermore, the methods employed by LinkedIn to detect extensions take advantage of developer oversights and
          browser extension limitations. This comes across as shady to me.
        </p>

        <h2>Unraveling the Mystery</h2>
        <p>
          I was initially turned on to LinkedIn's data exfiltration when I noticed a large number of failed web requests while visiting
          a LinkedIn profile. Initially, I thought my adblocker was blocking network requests. However, upon a closer look I noticed the
          web requests were not being sent across the web. They were actually being sent locally, to the browser itself. This can be
          seen clearly when viewing the network request's path. The paths were all being made using Chrome's own extension protocol. All
          requests began with <strong>chrome-extension://</strong>.
        </p>
        <p>
          For the uninitiated, the Chrome extension protocol is used to make web requests directly to an installed browser extension.
          Typically, this is used by the extension itself to retrieve resources or assets. However, any resources listed in an extension's
          manifest under the <strong>"web_accessible_resources"</strong> key are available to all web page contexts. Ironically, this
          section of the manifest was designed to minimize browser fingerprinting and protect the privacy of the extension user. Here's
          an excerpt directly from <a target="_blank" rel="noopener noreferrer" href="https://developer.chrome.com/extensions/manifest/web_accessible_resources">
          Google's own documentation</a> regarding the web accessible resources:
        </p>

        <blockquote>
         Prior to manifest version 2 all resources within an extension could be accessed from any page on the web. This allowed a malicious website to fingerprint the extensions that a user has installed or exploit vulnerabilities (for example XSS bugs) within installed extensions. Limiting availability to only resources which are explicitly intended to be web accessible serves to both minimize the available attack surface and protect the privacy of users.
        </blockquote>

        <p>
         Unfortunately, Google's changes only minimized the attack surface and did not prevent browser fingerprinting or privacy violations.
         It is this very issue that is leveraged by LinkedIn to identify installed extensions.
        </p>

        <p>
          My curiosity got the best of me and I set out to learn more about how LinkedIn was performing the scan and what they were doing
          with the data.
        </p>

        <h2>Eeny, Meeny, Miny, Moe</h2>
        <p>
          The sheer number of Chrome extension web requests performed by LinkedIn were staggering. I began to wonder how they were storing
          all of the extension information in order to make those web requests. The hunt began.
        </p>
        <p>
          Initially, I jotted down a few of the unique extension ids in hopes of finding references to them. I looked for any reference
          to the ids within LinkedIn's web responses but I had no luck. I looked within LinkedIn's web resources and code, but again I had no
          luck. Another idea crossed my mind; <i>Maybe they were hiding the extension information in their cookies or local storage?</i>
        </p>
        <p>
          My hunch led me to LinkedIn's local storage and a curious key, <strong>C_C_M</strong>. The value for the key was a large,
          seemingly random set of characters seen below:
        </p><pre><code>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‚Ä¶</code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users">https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users</a></em></p>]]>
            </description>
            <link>https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060089</guid>
            <pubDate>Wed, 11 Nov 2020 16:58:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Xilinx-Samsung SmartSSD Computational Storage Drive Launched]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25059946">thread link</a>) | @blopeur
<br/>
November 11, 2020 | https://www.servethehome.com/xilinx-samsung-smartssd-computational-storage-drive-launched/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/xilinx-samsung-smartssd-computational-storage-drive-launched/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1.jpg" data-caption="Smartssd Pr 1120x560"><img width="696" height="461" src="https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-696x461.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-696x461.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-400x265.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-634x420.jpg 634w, https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="Smartssd Pr 1120x560" title="Smartssd Pr 1120x560"></a><figcaption>Smartssd Pr 1120x560</figcaption></figure></div>
            <!-- content --><p>Computational storage is a small but growing segment of the market. To address this, the Samsung SmartSSD is being launched with a Xilinx Kintex FPGA inside to bring computational storage capabilities in a standard form factor. In this article, we are going to discuss how Xilinx and Samsung are delivering a computational storage platform.<span id="more-48283"></span></p>
<h2>Xilinx-Samsung SmartSSD Background</h2>
<p>First, why computational storage. One of the big drivers is that moving data, at high speeds, across systems can use a lot of power and consumes bandwidth. With computational storage, data can be processed without bringing it back to the main CPU.</p>
<figure id="attachment_48289" aria-describedby="caption-attachment-48289"><a href="https://www.servethehome.com/?attachment_id=48289" rel="attachment wp-att-48289"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand.png" alt="Xilinx SmartSSD Computational Storage Demand" width="1511" height="825" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand.png 1511w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-400x218.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-800x437.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-696x380.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-1068x583.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-769x420.png 769w" sizes="(max-width: 1511px) 100vw, 1511px"></a><figcaption id="caption-attachment-48289">Xilinx SmartSSD Computational Storage Demand</figcaption></figure>
<p>Part of the other driver here is that Xilinx sees computational storage as becoming mainstream, projected to be 5% of the market in only a few years. For its part, Xilinx is covering a number of different types of accelerators aside form the Samsung SmartSSD including those from Pliops, ScaleFlux, and BittWare.</p>
<figure id="attachment_48288" aria-describedby="caption-attachment-48288"><a href="https://www.servethehome.com/?attachment_id=48288" rel="attachment wp-att-48288"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream.png" alt="Xilinx SmartSSD Computational Storage Becoming Mainstream" width="1481" height="781" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream.png 1481w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-400x211.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-800x422.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-696x367.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-1068x563.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-796x420.png 796w" sizes="(max-width: 1481px) 100vw, 1481px"></a><figcaption id="caption-attachment-48288">Xilinx SmartSSD Computational Storage Becoming Mainstream</figcaption></figure>
<p>The basic Samsung SmartSSD has two main sets of components. One is basically a 4TB Samsung V-NAND SSD. This includes a NAND controller, and we are told DRAM for the controller to use as well. The second part of the solution is a Xilinx Kintex FPGA with its own 4GB of memory.</p>
<figure id="attachment_48285" aria-describedby="caption-attachment-48285"><a href="https://www.servethehome.com/?attachment_id=48285" rel="attachment wp-att-48285"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components.png" alt="Samsung Xilinx SmartSSD Internal Components" width="1263" height="783" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components.png 1263w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-400x248.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-800x496.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-696x431.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-1068x662.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-677x420.png 677w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-356x220.png 356w" sizes="(max-width: 1263px) 100vw, 1263px"></a><figcaption id="caption-attachment-48285">Samsung Xilinx SmartSSD Internal Components</figcaption></figure>
<p>The basic flow is that commands can be issued to either the SSD or the FPGA portion of the drive and processing can occur at the FPGA instead of going back to the host system.</p>
<figure id="attachment_48286" aria-describedby="caption-attachment-48286"><a href="https://www.servethehome.com/?attachment_id=48286" rel="attachment wp-att-48286"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation.png" alt="Samsung Xilinx SmartSSD Internal Operation" width="1456" height="836" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation.png 1456w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-400x230.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-800x459.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-696x400.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-1068x613.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-731x420.png 731w" sizes="(max-width: 1456px) 100vw, 1456px"></a><figcaption id="caption-attachment-48286">Samsung Xilinx SmartSSD Internal Operation</figcaption></figure>
<p>We are going to show an example later but a common question will be how are these programmed. One can use a standard storage stack or the OpenCL stack for computational storage aspects.</p>
<figure id="attachment_48291" aria-describedby="caption-attachment-48291"><a href="https://www.servethehome.com/?attachment_id=48291" rel="attachment wp-att-48291"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack.png" alt="Xilinx SmartSSD IP Runtime Stack" width="1470" height="723" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack.png 1470w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-400x197.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-800x393.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-696x342.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-1068x525.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-854x420.png 854w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-324x160.png 324w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-533x261.png 533w" sizes="(max-width: 1470px) 100vw, 1470px"></a><figcaption id="caption-attachment-48291">Xilinx SmartSSD IP Runtime Stack</figcaption></figure>
<p>As one would expect with a FPGA, there is a tie in with partner IP solutions as well as those that Xilinx and Samsung will have.</p>
<figure id="attachment_48290" aria-describedby="caption-attachment-48290"><a href="https://www.servethehome.com/?attachment_id=48290" rel="attachment wp-att-48290"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development.png" alt="Xilinx SmartSSD IP Development" width="1487" height="727" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development.png 1487w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-400x196.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-800x391.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-696x340.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-1068x522.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-859x420.png 859w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-533x261.png 533w" sizes="(max-width: 1487px) 100vw, 1487px"></a><figcaption id="caption-attachment-48290">Xilinx SmartSSD IP Development</figcaption></figure>
<p>The Xilinx Storage Services (XSS) are offloads available for the platform. These include compression and crypto offloads.</p>
<figure id="attachment_48292" aria-describedby="caption-attachment-48292"><a href="https://www.servethehome.com/?attachment_id=48292" rel="attachment wp-att-48292"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services.png" alt="Xilinx SmartSSD IP Xilinx Storage Services" width="1531" height="786" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services.png 1531w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-400x205.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-800x411.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-696x357.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-1068x548.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-818x420.png 818w" sizes="(max-width: 1531px) 100vw, 1531px"></a><figcaption id="caption-attachment-48292">Xilinx SmartSSD IP Xilinx Storage Services</figcaption></figure>
<p>Taking the compression in VDO as an example, the following slides have the basic flow:</p>
<figure id="attachment_48294" aria-describedby="caption-attachment-48294"><a href="https://www.servethehome.com/?attachment_id=48294" rel="attachment wp-att-48294"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1.png" alt="Xilinx SmartSSD VDO 1" width="1379" height="780" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1.png 1379w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-400x226.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-800x453.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-696x394.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-1068x604.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-743x420.png 743w" sizes="(max-width: 1379px) 100vw, 1379px"></a><figcaption id="caption-attachment-48294">Xilinx SmartSSD VDO 1</figcaption></figure>
<p>For reads, the FPGA is used to decompress data at the SmartSSD. By putting the compression on the SSD, Xilinx says it can get better compression ratios.</p>
<figure id="attachment_48295" aria-describedby="caption-attachment-48295"><a href="https://www.servethehome.com/?attachment_id=48295" rel="attachment wp-att-48295"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2.png" alt="Xilinx SmartSSD VDO 2" width="1447" height="784" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2.png 1447w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-400x217.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-800x433.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-696x377.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-1068x580.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-775x420.png 775w" sizes="(max-width: 1447px) 100vw, 1447px"></a><figcaption id="caption-attachment-48295">Xilinx SmartSSD VDO 2</figcaption></figure>
<p>In terms of examples, we wanted to highlight one from Lewis Rhodes Labs where they are doing NPUSearch using computational storage. Effectively here the SmartSSDs are being used to scale out the number of accelerators with the number of SSDs. An application can send requests to the storage, data can be evaluated at the drives, and only results passed back to the main system.</p>
<figure id="attachment_48293" aria-describedby="caption-attachment-48293"><a href="https://www.servethehome.com/?attachment_id=48293" rel="attachment wp-att-48293"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search.png" alt="Xilinx SmartSSD Lewis Rhodes Labs Search" width="1538" height="837" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search.png 1538w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-400x218.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-800x435.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-1536x836.png 1536w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-696x379.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-1068x580.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-772x420.png 772w" sizes="(max-width: 1538px) 100vw, 1538px"></a><figcaption id="caption-attachment-48293">Xilinx SmartSSD Lewis Rhodes Labs Search</figcaption></figure>
<p>Since many of our readers will have noticed this, we asked about the PCIe Gen3 and we were told that there is a roadmap to the future.</p>
<h2>Final Words</h2>
<p>For STH readers, an immediate question is going to be why computational storage? Part of this model is that accelerators are tied to storage. For accelerator companies, this is great. Many of our readers though are going to ask about why not use DPUs instead. If you missed it&nbsp;<a href="https://www.servethehome.com/what-is-a-dpu-a-data-processing-unit-quick-primer/">What is a DPU A Data Processing Unit Quick Primer</a> is a good resource there. We asked since if the only goal is offload, and the SmartSSD is in many ways two devices that are co-packaged, then it could make sense to offload to a bigger chip. We were told that it is less expensive to use a smaller accelerator on each drive than to scale to a larger accelerator. This is one area that we know there is a lot of momentum behind each model in the data center. It will be interesting to see which ultimately wins.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/xilinx-samsung-smartssd-computational-storage-drive-launched/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059946</guid>
            <pubDate>Wed, 11 Nov 2020 16:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Miniselect: Practical and Generic Selection Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059942">thread link</a>) | @cristaloleg
<br/>
November 11, 2020 | https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/ | <a href="https://web.archive.org/web/*/https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-555">

	

	
	<div>
		
<p>Today I present a big effort from my side to publish <a href="https://github.com/danlark1/miniselect">miniselect</a> ‚Äî generic C++ library to support multiple selection and partial sorting algorithms. It is already <a href="https://github.com/ClickHouse/ClickHouse/pull/16825">used</a> in <a href="https://clickhouse.tech/">ClickHouse</a> with huge performance benefits. Exact benchmarks and results will be later in this post and now let‚Äôs tell some stories about how it all arose. I publish this library under Boost License and any contributions are highly welcome.</p>



<h2>It all started with sorting</h2>



<p>While reading lots of articles, papers, and posts from Hacker News, I found it pretty funny each several months new ‚Äúshiny‚Äù, ‚Äúfastest‚Äù, ‚Äúgeneric‚Äù sorting algorithms to come or remembered from old papers such as the recent paper on <a href="https://blog.acolyer.org/2020/10/19/the-case-for-a-learned-sorting-algorithm/">learned sorting</a>, <a href="https://sortingsearching.com/2020/06/06/kirkpatrick-reisch.html">Kirkpatrick-Reisch</a> sort or <a href="https://news.ycombinator.com/item?id=14661659">pdqsort</a>. It is that we are essentially 65+ years into writing sorting algorithms, and we still find improvements. Shouldn‚Äôt sorting items be a ‚Äúsolved‚Äù problem by now? Unfortunately, not. New hardware features come, we find that sorting numbers can be actually done faster than best comparison <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log n)" title="O(n \log n)"> time complexity and we still find improvements in sorting algorithms like avoiding <a href="https://www.researchgate.net/publication/301614727_BlockQuicksort_How_Branch_Mispredictions_don't_affect_Quicksort">branches in partitions</a> and trying to find good pivots as pdqsort does. Also, there are many open questions in that area as ‚Äúwhat is the minimum number of comparisons needed?‚Äù.</p>



<p>Huge competition is still going on in sorting algorithms and I believe we are not near the optimal sorting and learned sorting looks like the next step. But it uses the fundamental fact that no one expects sorting to be completed in a couple of passes and we can understand something about data during first array passes. We will understand why it matters later.</p>



<p>My favorite general sorting is <a href="https://github.com/orlp/pdqsort">pdqsort</a>, it proves to be currently the best general sorting algorithm and it shows a significant boost over all standard sorts that are provided in C++. It is also <a href="https://docs.rs/pdqsort/1.0.3/pdqsort/">used</a> in Rust.</p>



<h2>Selection and Partial Sorting</h2>



<p>Nearly a couple of months ago I started thinking about a slightly different approach when it comes to sorting ‚Äî partial sorting algorithms. It means that you don‚Äôt need to sort all <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> elements but only find <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> smallest and sort them. For example, it is widely used in SQL queries when you do <code>ORDER BY LIMIT N</code> and <code>N</code> is often small, from 1-10 to ideally couple of thousands, bigger values still happen but rare. And, oh god, how little engineering and theoretical research has been done there compared to full sorting algorithms. In fact, the question of specifically finding <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th order statistics when <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> is small is open and no good solution is presented. Also, partial sorting is quite easy to obtain after that, you need to sort the first <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> elements by some sorting algorithm to get optimal <img src="https://s0.wp.com/latex.php?latex=O%28n+%2B+k+%5Clog+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n + k \log k)" title="O(n + k \log k)"> comparisons and we will look at only one example when it is not the case. Yes, there are a bunch of median algorithms that can be generalized to find the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th smallest element. So, what are they? Yeah, you may know some of them but let‚Äôs revise, it is useful to know your enemies.</p>



<h3>QuickSelect</h3>



<p>This is almost the very first algorithm for finding the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th smallest element, just do like <a href="https://en.wikipedia.org/wiki/Quicksort">QuickSort</a> but don‚Äôt go recursively in two directions, that‚Äôs it. Pick middle or even random element and partition by this element, see in which of two parts <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> is located, update the one of the borders, voila, after maximum of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> partitions you will find <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th smallest element. Good news that on average it takes <img src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n)" title="O(n)"> comparisons if we pick random pivot. That is because if we define <img src="https://s0.wp.com/latex.php?latex=C%28n%2C+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n, k)" title="C(n, k)"> is the expected number of comparisons for finding <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th element in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> elements and <img src="https://s0.wp.com/latex.php?latex=C%28n%29+%3D+%5Cmax_%7B1%7D%5E%7Bn%7D+C%28n%2C+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) = \max_{1}^{n} C(n, k)" title="C(n) = \max_{1}^{n} C(n, k)">, then during one stage we do <img src="https://s0.wp.com/latex.php?latex=n+-+1&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n - 1" title="n - 1"> comparisons and uniformly pick any pivot, then even if we pick the biggest part on each step</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+C%28n%29+%5Cleq+n+-+1+%2B+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bn%2F2%7D%5E%7Bn+-+1%7D+C%28i%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="\displaystyle C(n) \leq n - 1 + \frac{1}{n}\sum_{n/2}^{n - 1} C(i)" title="\displaystyle C(n) \leq n - 1 + \frac{1}{n}\sum_{n/2}^{n - 1} C(i)"></p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+C%28n%29+%5Cleq+%28n+-+1%29+%2B+%5Cmathrm%7Bavg%7D%28C%28n%2F2%29%2C+%5Cldots%2C+C%28n%29%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="\displaystyle C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n))" title="\displaystyle C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n))"></p>



<p>If assuming by induction that <img src="https://s0.wp.com/latex.php?latex=C%28i%29+%5Cleq+4i&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(i) \leq 4i" title="C(i) \leq 4i"> with an obvious induction base, we get</p>



<p><img src="https://s0.wp.com/latex.php?latex=C%28n%29+%5Cleq+%28n+-+1%29+%2B+%5Cmathrm%7Bavg%7D%28C%28n%2F2%29%2C+%5Cldots%2C+C%28n%29%29+%5Cleq+n+-+1+%2B+4%283n%2F4%29+%3C+4n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n)) \leq n - 1 + 4(3n/4) < 4n" title="C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n)) \leq n - 1 + 4(3n/4) < 4n"> </p>



<p>Bad news is that the worst case will still be <img src="https://s0.wp.com/latex.php?latex=O%28n%5E2%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n^2)" title="O(n^2)"> if we are unfortunate and always pick the biggest element as a pivot, thus partitioning .</p>



<p>In that sense that algorithm provides lots of pivot ‚Äústrategies‚Äù that are used nowadays, for example, picking pivot as a <img src="https://s0.wp.com/latex.php?latex=n%2F2&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n/2" title="n/2"> element of the array or picking pivot from 3 random elements . Or do like <code>std::nth_element</code> from libcxx ‚Äî choose the middle out out of <img src="https://s0.wp.com/latex.php?latex=A%5B0%5D%2C+A%5Bn%2F2%5D%2C+A%5Bn+-+1%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="A[0], A[n/2], A[n - 1]" title="A[0], A[n/2], A[n - 1]">.</p>



<p>I decided to visualize all algorithms I am going to talk about today, so quickselect with a median of 3 strategy on random input looks something like this:</p>



<figure><img data-attachment-id="579" data-permalink="https://danlark.org/nth-element-clang-2020-11-09_11-18-38/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nth-element-clang-2020-11-09_11.18.38" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif?w=1024" alt=""><figcaption>nth_element in libcxx, median of 3 strategies</figcaption></figure>



<p>And random pivot out of 3 elements works similar</p>



<figure><img data-attachment-id="581" data-permalink="https://danlark.org/median-of-3-random-2020-11-09_11-06-02/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="median-of-3-random-2020-11-09_11.06.02" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif?w=1024" alt=""><figcaption>Finding median in median of 3 random algorithm</figcaption></figure>



<p>For a strategy like <a href="https://github.com/llvm/llvm-project/blob/3ed89b51da38f081fedb57727076262abb81d149/libcxx/include/algorithm#L5159">libcxx</a> (C++ llvm standard library) does, there are quadratic counterexamples that are pretty easy to detect, such patterns also appear in real data. The counterexample looks like that:</p>



<figure><div>
<div id="gist106376435">
    <div>
      <div>
        

      </div>
      
    </div>
</div>

</div></figure>



<figure><img data-attachment-id="584" data-permalink="https://danlark.org/nth_element_clang_median_3_killer-2020-11-10_22-55-30/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nth_element_clang_median_3_killer-2020-11-10_22.55.30" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif?w=1024" alt=""><figcaption>std::nth_element in libcxx for Medianof3Killer</figcaption></figure>



<p>This is definitely quadratic. By the way, this is perfectly ok with the C++ standard wording as it says:</p>



<figure><img data-attachment-id="587" data-permalink="https://danlark.org/2020-11-10-230126_795x63_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png" data-orig-size="795,63" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-11-10-230126_795x63_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=795" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png 795w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=768 768w" sizes="(max-width: 795px) 100vw, 795px"><figcaption><a href="https://eel.is/c++draft/alg.nth.element#5">https://eel.is/c++draft/alg.nth.element#5</a></figcaption></figure>



<h2>Median of Medians</h2>



<p>For a long time, computer scientists thought that it is impossible to find medians in worst-case linear time, however, Blum, Floyd, Pratt, Rivest, Tarjan came up with BFPRT algorithm or like sometimes it is called, median of medians algorithm.</p>



<p>Median of medians algorithm: Given array <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="A" title="A"> of size <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> and integer <img src="https://s0.wp.com/latex.php?latex=k+%5Cleq+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k \leq n" title="k \leq n">,</p>



<ol><li>Group the array into <img src="https://s0.wp.com/latex.php?latex=n%2F5&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n/5" title="n/5"> groups of size 5 and find the median of each group. (For simplicity, we will ignore integrality issues.)</li><li>Recursively, find the true median of the medians. Call this <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p">.</li><li>Use <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p"> as a pivot to partition the array.</li><li>Recurse on the appropriate piece.</li></ol>



<p>When we find the median <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p"> of <img src="https://s0.wp.com/latex.php?latex=g+%3D+n%2F5&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="g = n/5" title="g = n/5"> groups, at least <img src="https://s0.wp.com/latex.php?latex=g%2F2&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="g/2" title="g/2"> of them have at least 3 out of 5 elements that are smaller or equal than <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p">, that said the biggest out of 2 partitioned chunks have size <img src="https://s0.wp.com/latex.php?latex=7n%2F10&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="7n/10" title="7n/10"> and we have the reccurence</p>



<p><img src="https://s0.wp.com/latex.php?latex=C%28n%29+%5Cleq+cn+%2B+C%28n%2F5%29+%2B+C%287n%2F10%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) \leq cn + C(n/5) + C(7n/10)" title="C(n) \leq cn + C(n/5) + C(7n/10)"></p>



<p>If we appropriately build the recurse tree we will see that</p>



<figure><img data-attachment-id="589" data-permalink="https://danlark.org/2020-11-10-232345_1330x458_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png" data-orig-size="1330,458" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-11-10-232345_1330x458_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=1024" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=768 768w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png 1330w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>This is the geometric series with <img src="https://s0.wp.com/latex.php?latex=cn%281+%2B+9%2F10+%2B+%289%2F10%29%5E2+%2B+%289%2F10%29%5E3+%2B+%5Cldots+...%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="cn(1 + 9/10 + (9/10)^2 + (9/10)^3 + \ldots ...)" title="cn(1 + 9/10 + (9/10)^2 + (9/10)^3 + \ldots ...)"> which gives us the result <img src="https://s0.wp.com/latex.php?latex=C%28n%29+%5Cleq+10+c+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) \leq 10 c n" title="C(n) \leq 10 c n">.</p>



<p>Actually, this constant 10 is really big. For example, if we look a bit closer, <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="c" title="c"> is at least 1 because we need to partition the array, then finding median out of 5 elements cannot be done in less than 6 comparisons (can be proven by only brute-forcing) and in 6 comparisons it can be done in the following way</p>



<ol><li>Use three comparisons and shuffle around the numbers so that <img src="https://s0.wp.com/latex.php?latex=a%5B1%5D+%3C+a%5B2%5D%2C+a%5B4%5D+%3C+a%5B5%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[1] < a[2], a[4] < a[5]" title="a[1] < a[2], a[4] < a[5]">, and <img src="https://s0.wp.com/latex.php?latex=a%5B1%5D+%3C+a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[1] < a[4]" title="a[1] < a[4]">.</li><li>If <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D+%3E+a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3] > a[2]" title="a[3] > a[2]">, then the problem is fairly easy. If <img src="https://s0.wp.com/latex.php?latex=a%5B2%5D+%3C+a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[2] < a[4]" title="a[2] < a[4]">, the median value is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3]" title="a[3]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[4]" title="a[4]">. If not, the median value is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[2]" title="a[2]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B5%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[5]" title="a[5]">.</li><li>So <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D+%3C+a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3] < a[2]" title="a[3] < a[2]">. If <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D+%3E+a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3] > a[4]" title="a[3] > a[4]">, then the solution is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3]" title="a[3]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B5%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[5]" title="a[5]">. Otherwise, the solution is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[2]" title="a[2]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[4]" title="a[4]">.</li></ol>



<p>So that maximum <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="c" title="c"> can be <img src="https://s0.wp.com/latex.php?latex=11%2F5&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="11/5" title="11/5"> and it gives us the upper bound <img src="https://s0.wp.com/latex.php?latex=22n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="22n" title="22n"> comparisons which looks like it can be achieved. Some other tricks can be done in place to achieve a bit lower constants like <img src="https://s0.wp.com/latex.php?latex=18n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="18n" title="18n"> (for example, sorting arrays of 5 and comparing less afterwards). In practice, the constant is really big and you can see it from the following demonstration which was even fastened because it took quite a few seconds:</p>



<figure><img data-attachment-id="593" data-permalink="https://danlark.org/median-of-medians-2020-11-09_11-04-33/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="median-of-medians-2020-11-09_11.04.33" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif?w=1024" alt=""><figcaption>Median of medians for random input</figcaption></figure>



<h2>HeapSelect</h2>



<p>Another approach to finding <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th element is to create a <a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">heap</a> on an array of size <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> and push other <img src="https://s0.wp.com/latex.php?latex=n+-+k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n - k" title="n - k"> elements into this heap. C++ <code>std::partial_sort</code> works that way (with additional heap sorting of the first heap). It shows good results for very small <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> and random/ascending arrays, however starts to significantly degrade with growing <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> and becomes impractical. Best case <img src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n)" title="O(n)">, worst <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log k)" title="O(n \log k)">, average <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log k)" title="O(n \log k)">.</p>



<figure><img data-attachment-id="596" data-permalink="https://danlark.org/partial_sort-2020-11-09_12-28-40/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="partial_sort-2020-11-09_12.28.40" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif?w=1024" alt=""><figcaption>std::partial_sort, two stages, first HeapSelect then heap sort of the first half, accelerated for speed</figcaption></figure>



<h2>IntroSelect</h2>



<p>As the previous algorithm is not very much practical and QuickSelect is really good on average, in 1997 <a href="http://www.cs.rpi.edu/~musser/gp/introsort.ps">‚ÄúIntrospective Sorting and Selection Algorithms‚Äù</a>  from David Musser came out with a sorting algorithm called ‚ÄúIntroSelect‚Äù. </p>



<p>IntroSelect works by optimistically starting out with QuickSelect and only switching to MedianOfMedians if it recurses too many times without making sufficient progress. Simply limiting the recursion to constant depth is not good enough, since this would make the algorithm switch on all sufficiently large arrays. Musser discusses a couple of simple approaches:</p>







<p>This algorithm came into <a href="https://github.com/gcc-mirror/gcc/blob/e0af865ab9d9d5b6b3ac7fdde26cf9bbf635b6b4/libstdc%2B%2B-v3/include/bits/stl_algo.h#L4748">libstdcxx</a> and guess which strategy was chosen? Correct, none of them. Instead, they try <img src="https://s0.wp.com/latex.php?latex=2%5Clog+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="2\log n" title="2\log n"> QuickSelect steps and if not successful, fallback to HeapSelect algorithm. So, worst case <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log n)" title="O(n \log n)">, average <img src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n)" title="O(n)"></p>



<figure><img data-attachment-id="598" data-permalink="https://danlark.org/nth-element-gcc-2020-11-09_11-06-37/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nth-element-gcc-2020-11-09_11.06.37" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif?w=1024" alt=""><figcaption>std::nth_element in libstdcxx, ‚ÄúIntroSelect‚Äù</figcaption></figure>



<h2>PDQSelect</h2>



<p>Now that most of the known algorithms come to an end üòà, we can start looking into something special and extraordinary. And the first one to look at is pdqselect which comes pretty straightforward from <a href="https://github.com/orlp/pdqsort">pdqsort</a>, the algorithm is basically QuickSelect but with some interesting ideas on how to choose an appropriate pivot:</p>



<ol><li>If there are <img src="https://s0.wp.com/latex.php?latex=n+%3C+24&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n < 24" title="n < 24"> elements, use <a href="https://en.wikipedia.org/wiki/Insertion_sort">insertion sort</a> to partition or even sort them. As insertion sort is really fast for a small amount of elements, it is reasonable</li><li>If it is more, choose <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p"> ‚Äî pivot:<ol><li>If there are less or equal than 128 elements, choose pseudomedian (or ‚Äúninther‚Äù, or median of medians which are all them same) of the following 3 groups:<ol><li>begin, mid, end</li><li>begin + 1, mid ‚Äì 1, end ‚Äì 1</li><li>begin + 2, mid + 1, end ‚Äì 2</li></ol></li><li>If there are more than 128 elements, choose median of 3 from begin, mid, end</li></ol></li><li>Partition the array by the chosen pivot with avoiding <a href="https://www.researchgate.net/publication/301614727_BlockQuicksort_How_Branch_Mispredictions_don't_affect_Quicksort">branches</a>:<ol><li>The partition is called bad if it splits less than <img src="https://s0.wp.com/latex.php?latex=1%2F8n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="1/8n" title="1/8n"> elements</li><li>If the total number of bad partitions exceeds <img src="https://s0.wp.com/latex.php?latex=%5Clog+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="\log n" title="\log n">, use <code>std::nth_element</code> or any other fallback algorithm and return</li><li>Otherwise, try to defeat some patterns in the partition by (sizes are l_size and r_size respectively):<ol><li>Swapping begin, begin + l_size / 4</li><li>Swapping p ‚Äì 1 and p ‚Äì l_size / 4</li><li>And if the number of elements is more than 128<ol><li>begin + 1, begin + l_size / 4 + 1</li><li>begin + 2, begin + l_size / 4 + 2</li><li>p ‚Äì 2, p ‚Äì l_size / 4 + 1</li><li>p ‚Äì 3, p ‚Äì l_size / 4 + 2</li></ol></li><li>Do the same with the right partition</li></ol></li></ol></li><li>Choose the right partition part and repeat like in QuickSelect</li></ol>



<figure><img data-attachment-id="605" data-permalink="https://danlark.org/pdqselect-2020-11-09_11-03-23/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pdqselect-2020-11-09_11.03.23" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif?w=1024" alt=""><figcaption>pdqselect on random input</figcaption></figure>



<h2>Media‚Ä¶</h2></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/">https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/</a></em></p>]]>
            </description>
            <link>https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059942</guid>
            <pubDate>Wed, 11 Nov 2020 16:46:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is It Time to Modernize the PostgreSQL Core Team?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059852">thread link</a>) | @ahachete
<br/>
November 11, 2020 | https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/ | <a href="https://web.archive.org/web/*/https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <div>
                
                <div>
                    
<p>The PostgreSQL Community is large, diverse and global. There are users, enthusiasts, developers, contributors, advocates and commercial entities from around the world. All of them working in a loosely collaborative fashion to grow and make PostgreSQL succeed.</p>
<p>The Postgres Core Team is considered to be the steering committee for the Community. The definition of the group responsibilities can be <a href="https://www.postgresql.org/developer/core/">found here</a>. The core team members are listed on the <a href="https://www.postgresql.org/community/contributors/">Contributor Profiles</a> page.</p>
<p>On September 30th EnterpriseDB acquired 2ndQuadrant. At the time of the acquisition there were five members in Core; two of them were EnterpriseDB employees and another one a 2ndQuadrant employee. This meant that 60% of the Core members would be employed by EnterpriseDB. On October 20th, in an effort to diffuse concerns about a single commercial entity having majority control, the <a href="https://www.postgresql.org/about/news/statement-from-the-postgresql-core-team-on-the-edb-acquisition-of-2ndquadrant-2094/">Core Team announced</a> that this is an issue that they would be addressing:</p>
<p>‚Äú<em>There has long been an unwritten rule that there should be no more than 50% of the membership of the Core Team working for the same company</em>‚Äù</p>
<p>This rule was enacted back in the days of the <a href="https://www.postgresql.org/message-id/39181CCD.99531ADA@greatbridge.com">Great Bridge</a>. Core addressed the unwritten rule by appointing on November 2nd <a href="https://www.postgresql.org/about/news/new-postgresql-core-team-members-2103/">two new members: Andres Freund and Jonathan Katz</a>. This change in Core reduced the proportion of EnterpriseDB members to three out of seven. <strong>Fundaci√≥n PostgreSQL</strong> would like to extend a very warm welcome to Andres and Jonathan. They are both well known and long time community contributors.</p>
<p>The addition of the new members allowed Core to be compliant with the 50% rule. However: was this organizational change the best choice? Was it the only change that could have been implemented? Could we have looked at the culture of our global community and used this opportunity to strengthen our ties?</p>
<p>Here are some facts about Core‚Äôs structure and membership:</p>
<ul>
<li><strong>Company influence</strong>:
<ul>
<li>Core has switched from having 40% of its members from a single company to now having 43% from a single company and 71% from two companies.</li>
<li>100% of the members are from only 4 companies.</li>
</ul>
</li>
<li><strong>Diversity</strong>:
<ul>
<li>100% of the current Core team members are white men.</li>
<li>All of the Core members are either US or European. No other region is represented.</li>
<li>All but one Core member work for US companies.</li>
</ul>
</li>
<li><strong>Democracy:</strong>
<ul>
<li>Core members are only appointed by existing Core members. In contrast, the ‚Äú<a href="https://www.postgresql.org/community/recognition/#npos">Recognised Postgres Nonprofit Organisations</a>‚Äù (created and enforced by Core) has as a requirement that the ‚Äú<em>board of directors MUST be elected by the membership</em>‚Äù. These rules were, in turn, created by Core itself.</li>
<li>Core members serve for an <em>unlimited</em> term. In contrast, the same Community recognition rules above also require that ‚Äú<em>Lifetime directorships MUST NOT be allowed</em>‚Äù. Four of the current Core members <a href="https://web.archive.org/web/20051023004218/http://www.postgresql.org/developer/bios">have been serving in the Core team for more than 15 years</a>.</li>
</ul>
</li>
<li><strong>Transparency</strong>:
<ul>
<li>The election process, candidate selection, selection criteria, etc are all secret.</li>
<li>Core Team meeting minutes are secret.</li>
<li>Core team policies are enacted by declaration, without involvement of the global community.</li>
</ul>
</li>
</ul>
<p>Facts aside, there are some organizational concerns that may require some further analysis.</p>
<p>In the PostgreSQL distributed community, the <a href="https://www.postgresql.org/developer/core/">Core Team</a> acts as the <em>de facto</em> ‚Äúcentral authority‚Äù for the project. The <a href="https://www.postgres.ca/">Postgres Association of Canada</a> (‚ÄúCA‚Äù, in short), acts as its legal arm, holding assets (including intellectual property, like domain names and trademarks).</p>
<p>However, this presents an interesting dichotomy: Core makes decisions, but if these require a legal entity to be executed, they are executed by CA. Which has its own board of directors, that needs to approve them. What if they don‚Äôt? What if they don‚Äôt follow Core? Similarly, how is Core accountable, if it is not backed directly by a legal entity? Because of this, are there any potential liabilities faced directly by their members, as individuals? And what happens if CA‚Äôs Board goes haywire?</p>
<p>Other mature and successful open source projects, while distributed as Postgres and built from the contributions of people and organizations all around the world, are nowadays backed by clear and strong legal and organizational structure. Take for example the <a href="https://www.apache.org/foundation/">Apache Foundation</a>, or the <a href="https://www.fsf.org/working-together/fiscal-sponsorship">Free Software Foundation</a>. Or the <a href="https://www.cncf.io/">Cloud Native Computing Foundation (CNCF)</a>, which is a Charter of the Linux Foundation. Its structure <a href="https://www.cncf.io/blog/2019/12/06/cncf-toc-governance-structure-elections-2020/">has three main bodies</a>:</p>
<p>‚Äú<em>A <strong>Governing Board (GB)</strong> that is responsible for marketing, budget and other business oversight decisions for the CNCF, a <strong>Technical Oversight Committee (TOC)</strong> that is responsible for defining and maintaining the technical vision, and an <strong>End User Community (EUC)</strong> that is responsible for providing feedback from companies and startups to help improve the overall experience for the cloud native ecosystem</em>‚Äù</p>
<p>The <a href="https://www.cncf.io/people/governing-board/">Governing Board has currently 24 members</a>, and their <a href="https://www.cncf.io/about/governing-board-meeting-minutes/">meeting minutes are public</a> (they are not alone: MariaDB Foundation <a href="https://mariadb.org/bodminutes/2020-10-21/">is now publishing their board meetings too</a>); the <a href="https://www.cncf.io/people/technical-oversight-committee/">Technical Committee consists of 11 members and 77 contributors</a>; the <a href="https://docs.google.com/presentation/d/194SyKdHL7ws_DBOdbrXdowEJi54kIzDdDK_h-6Ag0uo/edit#slide=id.g9ffb40d42b_0_161">End User Community has more than 150 companies</a>; furthermore, there are dozens of <a href="https://www.cncf.io/people/ambassadors/">ambassadors</a>; and also dozens of <a href="https://www.cncf.io/people/staff/">staff</a> members. While possibly operating at a different scale than PostgreSQL, they all contribute, in different manners, to the steering, development and vision of the CNCF.</p>
<p>What do you think? <strong>Is PostgreSQL Core today what the PostgreSQL Community needs, or is it time to modernize its processes, structure and governance?</strong> If you think it is the latter, please leave your comments below. I hope this post serves as the starting point for a broader and constructive discussion that can serve as feedback to Core. Let‚Äôs ensure the best future for our beloved open source database!</p>

                </div>
                
                    
                
            </div>
        </div>
    </div>
</section></div>]]>
            </description>
            <link>https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059852</guid>
            <pubDate>Wed, 11 Nov 2020 16:39:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I Wish I Knew About Incident Management]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059769">thread link</a>) | @ronaknnathani
<br/>
November 11, 2020 | https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/ | <a href="https://web.archive.org/web/*/https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I gave this talk last year at LinkedIn‚Äôs internal SRE conference, thought I‚Äôd share it here as well.</p><hr><h2 id="why-i-am-writing-this-post">Why I am writing this post</h2><p>Like every Software Engineer / SRE, I‚Äôve had my share of troubleshooting software. However, I had never been oncall before I joined Linkedin and the impact of a system outage that affects thousands of engineers made the first week of oncall pretty overwhelming.</p><p><img src="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/then-with-caption.gif" alt="first week of me handling production issues"></p><p>But things got better overtime.</p><p>In this post, I would like to share the incident management practices I have picked up over the years as an SRE at Linkedin that help me keep calm under pressure and effectively drive incidents to resolution.</p><p><img src="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/now-with-caption.gif" alt="present me handling production issues"></p><h2 id="what-this-post-is-not-about">What this post is not about</h2><p>In this post, I am not going to talk about how to debug linux or distributed systems or the various debugging tools. (For stories from the frontlines,
<a href="https://ronaknathani.com/#subscribe">stay tuned for a podcast coming soon</a>!)</p><h2 id="first-oncall-week">First oncall week</h2><p>My first few weeks at Linkedin - they were great! I was meeting smart engineers and learning new things. It wasn‚Äôt until my first oncall rotation that I started thinking <em>what if there‚Äôs an outage and I need to fix it?</em></p><p><img src="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/anxious.gif" alt="anxiety before first week of oncall"></p><p>Now, don‚Äôt get me wrong. LinkedIn has really good systems in place for monitoring/alerting, triaging issues and a very well defined process for incident response. Those are absolutely critical. And to prepare, I had shadowed our oncall the week prior and even had an experienced team member shadow me to guide and help me out, but still, I was anxious.</p><p>Here‚Äôs what I wish I had known.</p><ul><li><a href="#before-oncall-starts">Before oncall starts</a><ul><li><a href="#oncall-handoff">Oncall handoff</a></li><li><a href="#organizing-slack-during-an-oncall-week">Organizing Slack during an oncall week</a></li></ul></li><li><a href="#signal-vs-noise">Signal vs Noise</a><ul><li><a href="#trust-but-verify---not-all-alerts-are-created-equal">Trust, but verify - not all alerts are created equal</a></li><li><a href="#declaring-an-incident">Declaring an incident</a></li></ul></li><li><a href="#communication-during-an-incident">Communication during an incident</a><ul><li><a href="#the-incident-title-and-scoping-the-impact">The incident title and scoping the impact</a></li><li><a href="#establish-communication-channels-and-an-incident-lead">Establish communication channels and an incident lead</a></li><li><a href="#communicate-changes-to-the-system">Communicate changes to the system</a></li><li><a href="#provide-regular-updates">Provide regular updates</a></li></ul></li><li><a href="#incident-response-is-a-collaborative-process">Incident response is a collaborative process</a><ul><li><a href="#get-help-early">Get help early</a></li><li><a href="#working-with-others">Working with others</a></li><li><a href="#video-conferencing-is-your-friend">Video conferencing is your friend</a></li></ul></li><li><a href="#towards-a-resolution">Towards a resolution</a><ul><li><a href="#looking-at-changes">Looking at changes</a></li><li><a href="#keep-calm-and-carry-on---one-step-at-a-time">Keep calm and carry on - one step at a time</a></li></ul></li><li><a href="#learning-from-the-incident">Learning from the incident</a></li></ul><h2 id="before-oncall-starts">Before Oncall Starts</h2><h3 id="oncall-handoff">Oncall handoff</h3><p>Before an oncall week starts, I talk to the person who is currently oncall to get context on any incidents that happened during the week or any weird bugs that were discovered in our stack. It gives me perspectives on issues that could be getting carried over from the previous week and any critical changes I should be aware of.
Although you can‚Äôt plan for all that happens during an oncall week, a proper handoff helps you prepare for it.</p><h3 id="organizing-slack-during-an-oncall-week">Organizing Slack during an oncall week</h3><p>As an SRE on LinkedIn‚Äôs container scheduler and deployment infrastructure team, our users are engineers at LinkedIn. We use Slack for internal communication and we have certain channels where users share issues they are experiencing with the tooling or to get our oncall‚Äôs attention. During an oncall week, I star these channels and organize my sidebar so that I can easily notice messages from our users and distinguish them from the other messages I receive. As an optional tip - I also like to mute/leave channels that I am not actively participating in to reduce clutter.</p><p>As compared to a normal week, I spend more time on Slack when I am oncall - responding to people, answering support requests, helping users with tooling. These Slack notifications can create a little bit of distraction, however, considering all our users are internal, a rise in messages on our channels can also indicate that something might be wrong with our system and our alerting hasn‚Äôt caught it yet.</p><p><img src="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/slack-pings.gif" alt="slack pings during oncall"></p><h2 id="signal-vs-noise">Signal vs Noise</h2><h3 id="trust-but-verify---not-all-alerts-are-created-equal">Trust, but verify - not all alerts are created equal</h3><p><img src="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/trust-but-verify-you-must.jpg" alt="trust-but-verify-you-must"></p><p><i>This is something I learned during my interview at LinkedIn and it has been very applicable in my experience since.</i></p><p>In early days of oncall and incident management, it is very common to feel as if things are on fire when any alert gets triggered. Over time, I have realized that gaining context and verifying that the alert is actually indicating an issue helps with the right next steps. It is important to distinguish signal from noise because:</p><ul><li>An alert could be non-actionable as it was recently configured with a threshold that‚Äôs making it too noisy</li><li>The monitoring stack is down and the alert is being triggered because the configuration treats a lack of data points as an issue</li><li>Your service is operating perfectly fine, however, the traffic tier routing requests to your service had an issue</li><li>Timer on a deliberately silenced alert expired and the alert started triggering</li></ul><p>I have experienced all of the above at some point in time. Now when I either receive an alert or a user reports an issue, I check our services (metrics, logs, reproduce the reported problem etc.) to verify that the issue is real.</p><h3 id="declaring-an-incident">Declaring an incident</h3><p>Not all actionable alerts result in an incident. To be effective at identifying the ones that do, it is extremely crucial to think about the bigger picture of mitigating the issue than be overwhelmed by the technical task of resolving the alert.</p><p>Some of the qualitative measures that help make this differentiation is to consider whether an issue requires coordinating the fix with other teams or whether the issue is impacting customers or violating an SLO. If any of the conditions are true, declare an incident. It is always better to declare an incident early in the process than waiting too long.</p><p>At LinkedIn, we have defined guidelines for all teams about what warrants an incident along with different levels of severity. This takes guesswork out of the picture, and provides a shared understanding to every team member.</p><h2 id="communication-during-an-incident">Communication during an incident</h2><h3 id="the-incident-title-and-scoping-the-impact">The incident title and scoping the impact</h3><p>Every incident gets a title. I didn‚Äôt realize it initially, but giving an incident a title forces one to define the problem and communicate it to the stakeholders very succinctly. When communicating to stakeholders, <strong>scoping the incident is very important</strong>. What I mean by scoping is identifying how big the impact is - which environment is impacted, is the impact limited to a region or is it global, how many customers are impacted, etc. For instance, ‚Äúthe login feature on the site is not working‚Äù vs ‚Äúthe login feature on the site is not working for traffic originating from Asia Pacific‚Äù say two very different things.</p><h3 id="establish-communication-channels-and-an-incident-lead">Establish communication channels and an incident lead</h3><p>We heavily rely on Slack to communicate during an incident. A dedicated slack channel helps focus all the energy and inputs from everyone in one place. It helps the incident lead collect data about symptoms that the users are experiencing and also captures a log of considered/discarded hypotheses and any changes made to the system. Once the Slack channel is created, establish an incident lead and let everyone know who is driving the incident forward.</p><p>Eslablishing explicit comms channels for reporting and identifying issues and establishing an incident lead reduce the delay in action and disambiguate any confusion.</p><h3 id="communicate-changes-to-the-system">Communicate changes to the system</h3><p>If there‚Äôs a fix you‚Äôd like to try out, let others know who are and encourage everyone to do the same. This ensures that the potential fix doesn‚Äôt make an already bad situation worse and helps catch any blind spots early. If you do end up making a change to the system after getting consensus, let others know and follow up on its effects.</p><h3 id="provide-regular-updates">Provide regular updates</h3><p>While working towards a resolution for the incident, it is very easy to get overwhelmed by the technical details and miss to communicate an update. This leads to angry leadership and annoyed customers who have no insight into what‚Äôs happening.</p><p>An update provides visibility to the customers that the issue is being worked upon and lets the leadership identify if they can help out with anything. Depending on the severity of the incident, an update every 15-30 mins serves pretty well. The update doesn‚Äôt have to be extremely detailed, rather a brief summary describing the current state and immediate next steps is sufficient. An example update:</p><blockquote><p><strong>[UPDATE]</strong> Our hypothesis about the memory leak checks out and we have validated the fix in the staging environment. We have pushed out the change and as soon as it goes through the CI pipeline, we‚Äôll canary the new release, monitor metrics and promote the change after verifying the fix.</p></blockquote><h2 id="incident-response-is-a-collaborative-process">Incident response is a collaborative process</h2><h3 id="get-help-early">Get help early</h3><p>In my earlier days, I used to think that it was solely my responsibility to mitigate the issue, find the root cause, and roll out the fix. If I couldn‚Äôt do it, it wouldn‚Äôt reflect well on me. In reality, incident management, like much of software development, is a very collaborative process.</p><p>One of the big differences in how I approach it now is I focus on actively pulling in other engineers who could help with debugging or resolving the issue early in the process. This change in perspective has relieved me of a lot of unnecessary stress and also made me more effective at resolving incidents.</p><p>When requesting help, be specific about the task as well as the urgency. It helps others calibrate their response and manage things they might have at hand.</p><h3 id="working-with-others">Working with others</h3><p>One of the most important things while handling incidents is working with others. Considering the multi-faceted nature of an SRE role, it‚Äôs one of the most important while underrated skills.</p><p>With multiple people involved, various possibilities get shared and one of the responsibilities of the incident lead is to guide these discussions in a productive direction while filtering out the noise. One should be cautious about going down any rabbit holes and focus on stopping the bleeding first. If there‚Äôs a probable cause, share it early - it helps rule out possibilities. And it‚Äôs okay to ask questions that seem obvious, but specific questions are more helpful.</p><p>Being fearlessly curious, and keeping an open mind enables one to consider possibilities that could be overseen otherwise. Remember, you are working together as a team on sharing and ruling out hypotheses to solve a challenging problem.</p><h3 id="video-conferencing-is-your-friend">Video Conferencing is your friend</h3><p>We work ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/">https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/</a></em></p>]]>
            </description>
            <link>https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059769</guid>
            <pubDate>Wed, 11 Nov 2020 16:33:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are Package Registries Holding Open-Source Hostage?]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 67 (<a href="https://news.ycombinator.com/item?id=25059755">thread link</a>) | @aviaviavi
<br/>
November 11, 2020 | https://about.scarf.sh/post/package-registries-and-open-source | <a href="https://web.archive.org/web/*/https://about.scarf.sh/post/package-registries-and-open-source">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>A few days ago, I received an email from Docker about a change I already knew was coming:<em>‚Äç</em></p><blockquote><em>Docker will begin enforcing rate limits on container pulls for Anonymous and Free users.</em><br></blockquote><p>To many, this came as no surprise. For years, <a href="http://hub.docker.com/">Docker Hub</a> has offered free hosting of container images, which typically range in size from a few megabytes to many gigabytes. Docker workflows as a result use a <em>lot</em> of bandwidth, and that bandwidth costs money.<br></p><p>Should we OSS (open-source software)&nbsp;developers have to think about the business and financial models of the platforms we host our software on? In a perfect world, we wouldn't have to‚Äîbut in the real world we very much do. The incentives between OSS maintainers and the registries they use are often misaligned.&nbsp;<br></p><p>Docker Hub, <a href="http://npmjs.com/">npm</a>, and other comparable registries are incentivized to create lock-in, even if it makes the product experience worse for their users and customers. This is especially true of the for-profit companies behind the registries, but we see similar issues from many of the not-for-profit registries. </p><p>Maintainers, on the other hand, are incentivized to choose the best product for their needs at the lowest cost, which depends on being able to switch providers when a better service comes on the market.&nbsp;<br></p><p>This situation is fundamentally at odds with the today's package management ecosystem, where immutability is paramount in order to achieve stability. We avoid breaking things at all costs, on principle, since OSS packages are the nuts and bolts of the software ecosystem, the internet, and thus society itself.<br></p><h6><strong>Mechanics of registry lock-in</strong><br></h6><p>The registry where you host your packages and containers might be free today, but if that changes later, as is the case now with Docker, you and your users might be stuck paying whatever price the vendor chooses to set. Your users might even agree to access your package without the rate limit, but<strong> </strong><em>you</em> will not be seeing any of that revenue. Access to your open-source software was effectively just sold for a profit, and you, the author of that software, were cut out of the transaction.<br></p><p>While you could in theory just host your software somewhere else, can you really do that without breaking things for your current users? If you maintain and distribute a popular Docker image, switching the package registry is likely difficult.<br></p><p>Currently, any image on Docker Hub is installable as:<br></p><div><pre><code>$ docker run org-name/image-name</code></pre></div><p><em>‚Äç</em>If you decide later you actually want to move your container hosting somewhere else - let's say <a href="https://cloud.google.com/container-registry" target="_blank">Google Container Registry</a> for this example - the Docker client is reasonable and lets you pull down images by their URL:<br></p><div><pre><code>$ docker run gcr.io/org-name/image-name</code></pre></div><p><em>‚Äç</em>The problem here is that once you've changed the URL to your images, all of your existing users will stop getting updates! Even worse, this can break builds or pipelines for your users whenever they hit the new rate limits, which are not under your control. </p><p>At the point where your container has a sizable user-base all going through one of the existing container registries, your lock-in is substantial. Moving platforms will be painful. The crux of the problem here is that <em>you</em> don't own the distribution channel. The registry is the&nbsp; first place the web traffic goes, and everything that happens after that is at <em>the registry vendor‚Äôs</em><strong> </strong>discretion and to their advantage, not yours.<br></p><h6><strong>Effects of registry lock-in</strong><br></h6><p>Some might respond: <em>"This still seems like more of a theoretical problem than a practical one."</em><br></p><p>There are several practical downstream effects of the misaligned incentive structures to open-source package hosting. One major effect of registry lock-in is that maintainers cannot access their usage data. The data that registries naturally collect from package downloads can be quite useful to maintainers in a myriad of ways, yet registries typically don't share anything beyond a download count. </p><p>Registries know where the downloads are coming from, the devices, the package versions, which other packages are installed alongside, and a whole lot more. Little to none that information is shared with maintainers. Thus, maintainers are effectively locked out from observing the usage traffic.&nbsp;<br></p><p>Why is this the case? It's not because developers don't ask for it (<a href="https://github.com/npm/npm/issues/279">https://github.com/npm/npm/issues/279</a>). It's because the registries have no incentive to do so. It would cost the registries money to build and maintain the features to provide this data. Some registries even claim that exposing this data publicly would incentivize maintainers to game the system. Meanwhile, the extreme levels of inertia in software distribution keep maintainers locked in. </p><p>The registries' demonstrated distrust of maintainers seems counterproductive in a space where there's opportunity to work together cooperatively. If registry incentives were aligned accordingly, a registry like npm, for instance, would be in a great position to empower maintainers to leverage their own distribution data to deliver the best software possible.<br></p><p>What makes npm‚Äôs particular scenario even worse is that they've made it so difficult to use a registry that is<em> not</em> npm. There's no way to pull a single package from an alternate registry without switching to that registry. Which makes it quite impossible to actually publish a widely used JavaScript package without putting it on npm.&nbsp;<br></p><p>Contrast this scenario to Docker: Docker Hub creates different tradeoffs that both help and harm OSS maintainers. They've loosened their grip on OSS maintainers by making it user-friendly to pull containers down from alternative registries besides Docker Hub. However, even if you switch away from Docker Hub, you're still jumping from one company to another. This is because, at the end of the day, the registries‚Äînot the maintainers‚Äîown the distribution URL. The power imbalance continues.<br></p><p>My argument is not intended to dismiss the efforts of the registries as a whole. Package registries serve an essential role in software distribution, and have collectively serviced billions upon billions of package downloads. They‚Äôve made it easy for anyone in the world to interact with open-source, and as a result have helped push open-source forward. Astonishingly, they have, for most part, remained free to use! But as software continues to eat the world and the distribution of that software becomes more important, conflicting interests in this space become increasingly problematic.<br></p><h6><strong>Looking forward</strong><br></h6><p>How do we solve this? Ultimately, package registries need to align their incentives with those of maintainers. Registries should build products maintainers <em>want</em> to use rather than products they <em>have</em> to use.&nbsp;The entire OSS&nbsp;community can benefit. <br></p><p>Part of this means registries must be more intentional about giving maintainers back control over the distribution of their own software, even when it means the maintainers could take their packages elsewhere. As a community, we should be empowering maintainers to do their best work rather than constraining them to work within a specific&nbsp; platform or framework.&nbsp;<br></p><p>For the health of the open source ecosystem, it's critical to ensure that maintainers are not locked out from accessing the data about their own software distribution. Maintainers must be able to make data-informed decisions and treat distribution data as something that rightfully belongs to them, instead of just the registry providers.<br></p><p>Unfortunately, the current software distribution model works to cut maintainers out, making all downstream actions more difficult and strictly less informed. When we as a community decide to better align ourselves with open-source maintainers and build platforms to empower them, the result will be better software for the entire ecosystem.</p><p>Scarf is working on new tooling to address these problems, so stay tuned! Follow <a href="https://twitter.com/scarf_oss" target="_blank">@scarf_oss</a> on Twitter or subscribe below for periodic updates.<br></p></div></div></div></div>]]>
            </description>
            <link>https://about.scarf.sh/post/package-registries-and-open-source</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059755</guid>
            <pubDate>Wed, 11 Nov 2020 16:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to the Scrypt Hash]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059496">thread link</a>) | @lanecwagner
<br/>
November 11, 2020 | https://qvault.io/2020/07/25/very-basic-intro-to-the-scrypt-hash/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/07/25/very-basic-intro-to-the-scrypt-hash/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Scrypt is a slow-by-design <a href="https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/">hash function</a> or more accurately, a <a href="https://qvault.io/2019/12/30/very-basic-intro-to-key-derivation-functions-argon2-scrypt-etc/">KDF</a> function. Simply put, the purpose of the Scrypt hash is to take some input data, and create a fingerprint of that data, but to do it very slowly. A common use-case is to take a password and create an n-bit private key, which is much longer and more secure. Here at <a href="https://app.qvault.io/">Qvault,</a> we use a similar KDF for securing user passwords.</p>



<p>For example, let‚Äôs pretend your password is <code>password1234</code>. By using Scrypt, we can extend that deterministically into a 256-bit key:</p>



<pre><code>password1234 -&gt; 
AwEEDA4HCwQFAA8DAwwHDQwPDwUOBwoOCQACAgUJBQ0JAAYNBAMCDQ4JCQgLDwcGDQMDDgMKAQsNBAkLAwsACA==</code></pre>



<p>That long 256-bit key can now be used as a private key to encrypt and decrypt data. For example, it could be the key in an <a href="https://qvault.io/2020/01/02/very-basic-intro-to-aes-256-cipher/">AES-256</a> cipher.</p>



<h2>Why Not Encrypt With The Password Directly?</h2>



<p>Most encryption algorithms, including AES-256, require that a key of sufficient length is used. By hashing the password, we can derive a longer, more secure, fixed-size key.</p>



<p>Furthermore, using a KDF like Scrypt provides additional benefits over a traditional hash function like <a href="https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">SHA-2</a>:</p>



<ul><li>Computationally expensive and slow</li><li>Memory intensive (potentially several gigabytes of RAM is used to execute the hash)</li></ul>



<p>Often times <a href="https://qvault.io/2020/02/11/how-do-brute-force-attackers-know-they-found-the-key/">brute-force attackers</a> will try to break encryption by guessing passwords over and over until they get it right. AES-256 and SHA-2 are fast, so an attacker would be able to guess many passwords per second. By using a slow hashing function like Scrypt to derive a key, we can force the attacker to waste more resources trying to break in.</p>



<h2>Scrypt Step-by-Step</h2>



<p>Scrypt can be visualized by some psuedo-code:</p>



<pre><code lang="go">func Scrypt(
	passphrase, // string of characters to be hashed
	salt,  // random salt
	costFactor, // CPU/Memory cost, must be power of 2
	blockSizeFactor,
	parallelizationFactor, // (1..232-1 * hLen/MFlen)
	desiredKeyLen // Desired key length in bytes
) derivedKey {
	// we'll get to this
}</code></pre>



<p>Let‚Äôs go through the steps of converting those inputs into the desired <code>derivedKey</code></p>



<h3>1 ‚Äì Define Blocksize</h3>



<pre><code lang="go">const blockSize = 128 * blockSizeFactor</code></pre>



<h3>2 ‚Äì Generate Initial Salt</h3>



<p>Scrypt uses <a aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/PBKDF2" target="_blank" rel="noreferrer noopener nofollow">PBKDF2</a> as a child key-derivation function. We use it to generate an initial salt. <code>PBKDF2</code> has the following signature:</p>



<pre><code lang="go">func PBKDF2(
	prf,
	password,
	salt,
	numIterations,
	desiredKeyLen
) derivedKey {}</code></pre>



<p>We use it as follows:</p>



<pre><code lang="go">const initialSalt = PBKDF2(HMAC-SHA256, passphrase, salt, 1, blockSize * parallelizationFactor)</code></pre>



<h3>3 ‚Äì Mix Salt</h3>



<p>Next, we mix the salt. We split <code>initialSalt</code> into <code>splitSalt</code>, which is a 2D array of bytes. Each sub-array contains 1024 bytes</p>



<pre><code lang="go">splitSalt := [][1024]byte(initialSalt)
for i, block := range splitSalt {
	newBlock := roMix(block, costFactor)
	splitSalt[i] = newBlock
}</code></pre>



<p>Where <code>roMix</code> is the following function:</p>



<pre><code lang="go">func roMix(block, iterations){
	v := []
	x := block
	for i := 0; i &lt; iterations; i++ {
		v[i] = x
		x = blockMix(x)
	}
	for i := 0; i &lt; iterations; i++ {
		j := integerify(x) % iterations
		x = blockMix(x ^ v[j])
	}
	return x
}</code></pre>



<p><code>integerify</code> is defined by <a aria-label=" (opens in a new tab)" href="https://tools.ietf.org/html/rfc7914" target="_blank" rel="noreferrer noopener nofollow">RFC-7914</a> and <code>blockMix</code> is:</p>



<pre><code lang="go">func blockMix(block){
	r := len(block) / 128
	// split block into an array of 2r 64-byte chunks
	chunks := get2r64ByteChunks()

	x := chunks[len(chunks)-1]
	y := []
	for i := 0; i &lt; len(chunks); i++{
		x = salsa20-8(x ^ chunks[i])
		y[i] = x
	}
	return [y[0], y[2], ...y[2r-2], y[1], y[3], ...y[2r-1]]
}</code></pre>



<p><code>salsa20-8</code> is the 8-round version of the algorithm defined <a href="https://en.wikipedia.org/wiki/Salsa20" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener nofollow">here</a>.</p>



<h3>4 ‚Äì Finalize Salt</h3>



<p>Now <code>splitSalt</code> has been mixed in such a computationally exhausting way that we will call it an <code>expensiveSalt</code>. Expensive salt will be a single array of bytes, so we need to concatenate all the subarrays in <code>splitSalt</code>.</p>



<pre><code lang="go">expensiveSalt := append([], splitSalt...)</code></pre>



<h3>5 ‚Äì Return Final KDF</h3>



<pre><code lang="go">return PBKDF2(HMAC-SHA256, passphrase, expensiveSalt, 1, desiredKeyLen)</code></pre>



<p>The final pseudocode for our top level function is as follows:</p>



<pre><code lang="go">func Scrypt(
	passphrase, // string of characters to be hashed
	salt,  // random salt
	costFactor, // CPU/Memory cost, must be power of 2
	blockSizeFactor,
	parallelizationFactor, // (1..232-1 * hLen/MFlen)
	desiredKeyLen // Desired key length in bytes
) derivedKey {
	const blockSize = 128 * blockSizeFactor

	const initialSalt = PBKDF2(HMAC-SHA256, passphrase, salt, 1, blockSize * parallelizationFactor)

	splitSalt := [][1024]byte(initialSalt)
	for i, block := range splitSalt {
		newBlock := roMix(block, costFactor)
		splitSalt[i] = newBlock
	}

	expensiveSalt := append([], splitSalt...)

	return PBKDF2(HMAC-SHA256, passphrase, expensiveSalt, 1, desiredKeyLen)
}</code></pre>



<p>Or, if you prefer, the pseudocode as defined by <a href="https://en.wikipedia.org/wiki/Scrypt" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener nofollow">Wikipedia</a>:</p>



<pre><code lang="">Function scrypt
   Inputs:
      Passphrase:                Bytes    string of characters to be hashed
      Salt:                      Bytes    random salt
      CostFactor (N):            Integer  CPU/memory cost parameter - Must be a power of 2 (e.g. 1024)
      BlockSizeFactor (r):       Integer  blocksize parameter (8 is commonly used)
      ParallelizationFactor (p): Integer  Parallelization parameter. (1..232-1 * hLen/MFlen)
      DesiredKeyLen:             Integer  Desired key length in bytes
   Output:
      DerivedKey:                Bytes    array of bytes, DesiredKeyLen long

   Step 1. Generate expensive salt
   blockSize ‚Üê 128*BlockSizeFactor  //Length (in bytes) of the SMix mixing function output (e.g. 128*8 = 1024 bytes)

   Use PBKDF2 to generate initial 128*BlockSizeFactor*p bytes of data (e.g. 128*8*3 = 3072 bytes)
   Treat the result as an array of p elements, each entry being blocksize bytes (e.g. 3 elements, each 1024 bytes)
   [B0...Bp‚àí1] ‚Üê PBKDF2HMAC-SHA256(Passphrase, Salt, 1, blockSize*ParallelizationFactor)

   Mix each block in B Costfactor times using ROMix function (each block can be mixed in parallel)
   for i ‚Üê 0 to p-1 do
      Bi ‚Üê ROMix(Bi, CostFactor)

   All the elements of B is our new "expensive" salt
   expensiveSalt ‚Üê B0‚à•B1‚à•B2‚à• ... ‚à•Bp-1  //where ‚à• is concatenation
 
   Step 2. Use PBKDF2 to generate the desired number of bytes, but using the expensive salt we just generated
   return PBKDF2HMAC-SHA256(Passphrase, expensiveSalt, 1, DesiredKeyLen);</code></pre>




		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/07/25/very-basic-intro-to-the-scrypt-hash/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059496</guid>
            <pubDate>Wed, 11 Nov 2020 16:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mental Models for Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059450">thread link</a>) | @laybak
<br/>
November 11, 2020 | https://informedpm.com/posts/mental-models | <a href="https://web.archive.org/web/*/https://informedpm.com/posts/mental-models">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>It is trendy to talk about mental models these days, especially in the tech industry. But really, it's just a fancy way of saying "useful ways of thinking".</span></p> <p><span>In this post, I present a collection of mental models that are most relevant to the work of product managers. Some of these are borrowed from other disciplines. And they can be valuable additions to your toolbox for dealing with complexity.</span></p> <p><span>I intend for these to be jumping-off points for further thinking and learning. And not an exhaustive list. For a general introduction to mental models, here is a </span> <a href="https://fs.blog/mental-models/" target="_blank"><span>useful article by Farnam Street</span></a> <span>.</span></p> <p><span>Let's get started.</span></p>  <p><h2><span>Part 1: Learning </span></h2></p> <p><h3><span>Ensemble of Models</span></h3></p> <p><span>All models are wrong because they simplify. They omit details. For this reason, we should not rely on any single model. Instead, a many-model approach allows you to explain more and avoid blindspots. This works because the wrongness in each model tends to cancel out.</span></p> <p><span>Charlie Munger, an investor who popularized mental models, advocates combining them in a "latticework of models". And in machine learning, </span> <a href="https://en.wikipedia.org/wiki/Ensemble_learning" target="_blank"><span>ensemble methods</span></a> <span> can be an effective approach. </span></p> <p><span>This is useful when considering the diverse perspectives and opinions of your stakeholders.</span></p>  <p><h3><span>Learning by Doing</span></h3></p> <p><span>Which mental models matter in which circumstances? Knowing that is the hard part. </span></p> <p><span>A lot of skills and knowledge are implicit. They are hard to codify, or even articulate. You won't find them in neatly packaged books or elegant theories. </span></p> <p><span>But you can hone your judgment by maintaining contact with reality. You can put in iterations, and let your learning compound over time.</span></p>  <p><h3><span>Bayesian Updating</span></h3></p> <p><span>We get new information all the time. Feedback from a customer, changes in the industry, unforeseen challenges etc.</span></p> <p><span>Bayes' theorem provides a mathematical approach to weigh the old hypothesis (the "prior", initial belief) and new evidence. Bayesian inference is widely applicable in many areas, including AI and machine learning. Fun fact, it is also effective for </span> <a href="https://en.wikipedia.org/wiki/Bayesian_search_theory" target="_blank"><span>finding missing aircrafts</span></a> <span>.</span></p> <p><span>Here is an engaging introductory video on the topic.</span></p> <div><p><iframe src="https://www.youtube.com/embed/HZGCoVF3YvM?title=0&amp;byline=0&amp;portrait=0" frameborder="0"></iframe></p></div>  <p><h3><span>Process vs Outcome</span></h3></p> <p><span>It is tempting to judge our decisions by the outcome. But good decisions can lead to bad outcomes. And vice versa.</span></p> <p><span>Having a good process with a good outcome is ideal. Whereas a bad process with a good outcome is just gambling with blind luck.</span></p> <p><span>One way to calibrate your decisions over time is to document your decisions in a </span> <a href="https://fs.blog/2014/02/decision-journal/" target="_blank"><span>decision journal</span></a> <span>. Good things to write down include the context for the decision, alternatives and the range of outcomes, what you expect to happen, and how you feel mentally and physically.</span></p>  <p><h3><span>Dumb Idea Paradox</span></h3></p> <p><span>Many of the big success stories sounded stupid. Red Bull is an expensive drink that tastes disgusting. Snapchat is an app for sending disappearing photos. </span></p> <p><span>In the book </span> <a href="https://www.amazon.com/Loonshots-Nurture-Diseases-Transform-Industries-ebook/dp/B07D2BKVQR" target="_blank"><span>Loonshots</span></a> <span>, Safe Bahcall gave examples of brilliant ideas that had to survive "the Three Deaths" before finally succeeding. He wrote, "In the real world, ideas are ridiculed, experiments fail, budgets are cut, and good people are fired for stupid reasons." Andrew Chen also wrote about this in </span> <a href="https://andrewchen.co/dumb-idea-paradox/" target="_blank"><span>Dumb Idea Paradox</span></a> <span>.</span></p>  <p><h3><span>Satisficing</span></h3></p> <p><span>We make decisions in a world of uncertainty, with incomplete and imperfect information. Certainty is an illusion. It is better to be vaguely right than precisely wrong. </span></p> <p><span>Ôªø</span> <a href="https://en.wikipedia.org/wiki/Satisficing" target="_blank"><span>Satisficing</span></a> <span> (satisfy + suffice), introduced by&nbsp;</span> <a href="https://en.wikipedia.org/wiki/Herbert_A._Simon" target="_blank"><span>Herbert A. Simon</span></a> <span>, is about making decisions that are not perfect, but good enough. You can satisfice either by finding optimal solutions for a simplified world, or satisfactory solutions for a realistic one.</span></p>  <p><h2><span>Part 2: Collaboration &amp; Execution</span></h2></p> <p><h3><span>Maker's Schedule. Manager's Schedule</span></h3></p> <p><span>Context switching is costly, especially for creative work. In </span> <a href="http://www.paulgraham.com/makersschedule.html" target="_blank"><span>Paul Graham's popular essay</span></a> <span>, he discussed the cost of meetings and interruptions:</span></p> <p><em>"When you're operating on the maker's schedule, meetings are a disaster. A single meeting can blow a whole afternoon, by breaking it into two pieces each too small to do anything hard in."</em></p> <p><span>It is important to recognize the nature of different types of work. This way we can get more focused time for deep work, for ourselves and for our team.</span></p>  <p><h3><span>Working Memory and Cognitive Load</span></h3></p> <p><span>Ôªø</span> <a href="https://en.wikipedia.org/wiki/Working_memory" target="_blank"><span>Working memory</span></a> <span> is basically </span> <em>"how much stuff you can think about at the same time"</em> <span>. Each of us has a limited capacity. The "</span> <a href="https://en.wikipedia.org/wiki/The_Magical_Number_Seven%2C_Plus_or_Minus_Two" target="_blank"><span>magic number</span></a> <span>" of objects an average human can hold in short-term memory is 7, plus or minus 2.</span></p> <p><span>In the workplace, there is a lot of information to process. And the sheer load can quickly overwhelm our working memory.</span></p> <p><span>This calls for building a system to work around this. It could mean regular follow-ups, reminders, repetition, and good note-taking and documentation.</span></p>  <p><h3><span>Circle of Competence</span></h3></p> <p><span>Ôªø</span> <a href="https://en.wikipedia.org/wiki/Circle_of_competence" target="_blank"><span>Circle of competence</span></a> <span> is a mental model developed by Warren Buffett and Charlie Munger. Here's how Buffett summarized it:</span></p> <p><em>"Know your circle of competence, and stick within it. The size of that circle is not very important; knowing its boundaries, however, is vital."</em></p> <p><span>Being clear about what you know and what you think you know can keep your hubris in check. It can also help you identify blind spots and areas of improvement. </span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/circle-of-competence.png"></p>  <p><h3><span>Batch Processing</span></h3></p> <p><span>Instead of completing tasks in the order that they come, you can often save time by grouping similar tasks together. It reduces costly context switching and interrupts by consolidating repetitive tasks that are not time-sensitive.</span></p> <p><span>This approach can be helpful in answering emails, reading news articles, processing customer feedback etc. As an added benefit, once you batch the tasks, they also tend to be easier to delegate or automate.</span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/batch-processing.png"></p>  <p><h3><span>Incentives</span></h3></p> <p><span>All living creatures respond to incentives. That is, the proverbial carrot and stick. Behaviours that are rewarded are reinforced.</span></p> <p><span>Knowing this helps us understand the true motivation of our partners, stakeholders, and even customers. This allows us to influence without direct power.</span></p>  <p><h3><span>Goodhart's Law</span></h3></p> <p><span>It is important to consider incentives when deciding measurements of success and metrics to focus on. </span></p> <p><span>Goodhart's Law was named after the economist Charles Goodhart. The general version, phrased by anthropologist Marilyn Strathern, states that "</span> <em>When a measure becomes a target, it ceases to be a good measure</em> <span>."
to be a good measure." </span></p> <p><span>It is possible that some stakeholders can "game the system" and artificially inflate metrics in ways that don't reflect customer value.</span></p> <p><span>We need to be careful about what to measure and consider the incentives of the individual stakeholders. </span></p>  <p><h3><span>Persuasion</span></h3></p> <p><span>To make change happen, persuasion is essential. I have compiled the models, principles, and tactics on this topic in a </span> <a href="https://informedpm.com/posts/persuasion-product-manager" target="_blank"><span>separate post</span></a> <span>. </span></p>  <p><h2><span>Part 3: Systems Thinking</span></h2></p> <p><span>Product managers routinely deal with complex systems. A product is a system of features, stakeholders, processes, customers, other players in the market, changing industry and economic trends etc.</span></p> <p><span>A system is more than the sum of its parts. Systems thinking allows us to better understand the interconnections of the different parts.</span></p>  <p><h3><span>Feedback Loops</span></h3></p> <p><span>A feedback loop is a closed chain of causal connections formed by routing an output of a system back as an input. </span></p> <p><span>Different feedback structures can produce drastically different behaviours. Balancing feedback loops lead to stability or an equilibrium. Whereas reinforcing feedback loops lead to exponential growth or collapses. </span></p> <p><span>Understanding the structure of the system helps us understand its behaviours.</span></p> <p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/General_Feedback_Loop.svg/330px-General_Feedback_Loop.svg.png"></p>  <p><h3><span>Flywheel</span></h3></p> <p><span>The "</span> <a href="https://www.jimcollins.com/article_topics/articles/the-flywheel-effect.html" target="_blank"><span>flywheel effect</span></a> <span>" is a concept developed by researcher Jim Collins. It is a special kind of feedback loop (positive/reinforcing). Push the flywheel. Accelerate momentum. Then repeat.</span></p> <p><span>It is said that Bezos considered Amazon's application of the flywheel concept to be its "secret sauce". </span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/Amazon%20flywheel.png"></p>  <p><h3><span>Non-Linearity</span></h3></p> <p><span>A linear relationship between two variables can be drawn on a chart with a straight line. In a non-linear relationship, the cause does not produce a proportional effect.     </span></p> <p><span>In a linear system, twice the push can produce twice the response. But in a nonlinear system, twice the push can produce the response squared, a sixth, or no response at all.</span></p> <p><span>For example, doubling the team headcount may yield 1.2X the output. Tripling the price may yield 10X the revenue. </span></p> <p><span>Many relationships in systems are non-linear. This is often a source of surprise. Beware of the trap of assuming (though more intuitive) linear relationships. </span></p>  <p><h3><span>Leverage Points </span></h3></p> <p><span>To get more of a desired outcome, we may have to change the structure of a system. There are leverage points in all systems, where the efforts you apply can yield disproportionate results. For instance, identifying and resolving a bottleneck in a process can be a force multiplier for your efforts.</span></p> <p><span>But as systems scientist </span> <a href="https://en.wikipedia.org/wiki/Donella_Meadows" target="_blank"><span>Donella Meadows</span></a> <span> pointed out, leverage points are often counter-intuitive. And there is no cheap way to mastering the art of identifying leverage points. Though in her book </span> <a href="https://www.amazon.com/Thinking-Systems-Primer-Donella-Meadows/dp/1603580557" target="_blank"><span>Thinking in Systems</span></a> <span>, she proposed a ranked list of leverage point candidates based on her experience. </span></p>  <p><h3><span>Second and Higher Order Effects</span></h3></p> <p><span>First-order effects are the direct consequences of an action. They tend to be immediate. They tend to be obvious. They tend to be static. Thinking in first-order effects often a dangerous over-simplification.</span></p> <p><span>In real life, each agent in the system can respond to changes. Second (and higher) order effects include the effects of subsequent actions. </span></p> <p><span>An example of first-order thinking would be to assume that introducing a new feature will lead to more users coming. Higher-order effects would include increasing technical complexity internally, cluttering and degrading the overall UX, competitors responding by copying the feature or launching a new product etc.</span></p>  <p><h2><span>Part 4: Strategy &amp; Planning</span></h2></p> <p><h3><span>Inversion</span></h3></p> <p><span>Inversion as a thinking tool turns the problem upside down. </span></p> <p><span>Instead of always starting at the beginning, sometimes it is beneficial to start at the end. This thinking can be useful in planning, where we start with the end goal and work backward. For instance, at Amazon, there is a practice of writing a ‚Ä¶</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://informedpm.com/posts/mental-models">https://informedpm.com/posts/mental-models</a></em></p>]]>
            </description>
            <link>https://informedpm.com/posts/mental-models</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059450</guid>
            <pubDate>Wed, 11 Nov 2020 16:04:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why an IDE?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059374">thread link</a>) | @matklad
<br/>
November 11, 2020 | https://matklad.github.io/2020/11/11/yde.html | <a href="https://web.archive.org/web/*/https://matklad.github.io/2020/11/11/yde.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Nov 11, 2020</p>
  <p>Some time ago I wrote a reddit comment explaining the benefits of IDEs.
Folks refer to it from time to time, so I decided to edit it into an article form.
Enjoy!</p>
<p>I think I have a rather balanced perspective on IDEs.
I used to be a heavy Emacs user (<a href="https://github.com/matklad/.emacs.d/tree/475de5db99f8729c57fed7e6fde4cd06f5ccb62f">old config</a>, <a href="https://github.com/matklad/config/blob/d555642a5a9e4e8b0ca0c77f188ffd976f06327c/home/.emacs.d/init.el">current config</a>).
I worked at JetBrains on <a href="https://github.com/intellij-rust/intellij-rust">IntelliJ Rust</a> for several years.
I used evil mode and vim for a bit, and tried tmux and kakoune.
Nowadays, I primarily use VS Code to develop <a href="https://github.com/rust-analyzer/rust-analyzer/">rust-analyzer</a>: LSP-based editor-independent IDE backend for Rust.</p>
<p>I will be focusing on IntelliJ family of IDEs, as I believe these are the most advanced IDEs today.</p>
<p>The main distinguishing feature of IntelliJ is semantic understanding of code.
The core of IntelliJ is a compiler which parses, type checks and otherwise understands your code.
<a href="https://martinfowler.com/bliki/PostIntelliJ.html">PostIntelliJ</a> is the canonical post about this.
That article also refutes the claim that ‚ÄúSmalltalk IDE is the best we‚Äôve ever had‚Äù.</p>
<p>Note that ‚Äúsemantic understanding‚Äù is mostly unrelated to the traditional interpretation of ‚ÄúIDE‚Äù as <em>Integrated</em> Development Environment.
I personally don‚Äôt feel that the ‚ÄúIntegrated‚Äù bit is all that important.
I commit&amp;push from the command line using Julia scripts, rebase in magit, and do code reviews in a browser.
If anything, there‚Äôs an ample room for improvement for the integration bits.
For me, <strong>I</strong> in ‚Äú<strong>I</strong>DE‚Äù stands for ‚Äúintelligent‚Äù, smart.</p>
<p>Keep in mind this terminology difference.
I feel it is a common source of misunderstanding.
‚ÄúUnix and command line can do anything an IDE can do‚Äù is correct about integrated bits, but is wrong about semantical bits.</p>
<p>Traditional editors like Vim or Emacs understand programming languages very approximately, mostly via regular expressions.
For me, this feels very wrong.
It‚Äôs <a href="https://stackoverflow.com/a/1732454">common knowledge</a> that HTML shall not be parsed with regex.
Yet this is exactly what happens every time one does <code>vim index.html</code> with syntax highlighting on.
I sincerely think that almost every syntax highlighter out there is wrong and we, as an industry, should do better.
I also understand that this is a tall order, but I do my best to change the status quo here :-)</p>
<p>These are mostly theoretical concerns though.
The question is, does semantic understanding help in practice?
I am pretty sure that it is non-essential, especially for smaller code bases.
My <a href="https://github.com/matklad/rustraytracer">first non-trivial Rust program</a> was written in Emacs, and it was fine.
Most of rust-analyzer was written using pretty spartan IDE support.
There are a lot of insanely-productive folks who are like ‚Äúsometimes I type vim, sometimes I type vi, they are sufficiently similar‚Äù.
Regex-based syntax highlighting and regex based fuzzy symbol search (<a href="https://github.com/universal-ctags/ctags">ctags</a>) get you a really long way.</p>
<p>However, I do believe that features unlocked by deep understanding of the language help.
The funniest example here is extend/shrink selection.
This features allows you to extend current selection to the next encompassing syntactic construct.
It‚Äôs the simplest feature a PostIntelliJ IDE can have, it only needs the parser.
But it is sooo helpful when writing code, it just completely blows vim‚Äôs text objects out of the water, especially when combined with multiple cursors.
In a sense, this is structural editing which works for text.</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98809232-80e3db00-241d-11eb-883a-5aece9a1dbfc.gif" alt="98809232 80e3db00 241d 11eb 883a 5aece9a1dbfc">
</p>
</div>
<p>If you add further knowledge of the language into a mix, you‚Äôll get the ‚Äúassists‚Äù system: micro-refactoring which available in a particular context.
For example, is the cursor is on a comma in a list of function arguments, you can <span><kbd>alt</kbd>+<kbd>enter</kbd></span> &gt; ‚Äúswap arguments‚Äù, and the order of arguments will be changed in the declaration and on various call-sites as well.
(See <a href="https://rust-analyzer.github.io/blog/2020/09/28/how-to-make-a-light-bulb.html">this post</a> to learn how assists are implemented).</p>
<p>These small dwim things add up to a really nice editing experience, where you mostly express the intention, and the IDE deals with boring syntactical aspects of code editing:</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98812121-37e25580-2422-11eb-8541-2c5a32926845.gif" alt="98812121 37e25580 2422 11eb 8541 2c5a32926845">
</p>
</div>
<p>For larger projects, complex refactors are a huge time-saver.
Doing project-wide renames and signature changes automatically and without thinking reduces the cost of keeping the code clean.</p>
<p>Another transformative experience is navigation.
In IntelliJ, you generally don‚Äôt ‚Äúopen a file‚Äù.
Instead you think directly in terms of functions, types and modules, and navigate to those using file structure, goto symbol, to do definition/implementation/type, etc:</p>

<p>When I used Emacs, I really admired its buffer management facilities, because they made opening a file I want a breeze.
When I later switched to IntelliJ, I stopped thinking in terms of a set of opened files altogether.
I disabled editor tabs and started using editor splits less often‚Äâ‚Äî‚Äâyou don‚Äôt need bookmarks if you can just find things.</p>
<p>For me, there‚Äôs one aspect of traditional editors which is typically not matched in IDEs out of the box‚Äâ‚Äî‚Äâbasic cursor motion.
Using arrow keys for that is slow and flow-breaking, because one needs to move the hand from the home row.
Even Emacs' horrific <kbd>C-p</kbd>, <kbd>C-n</kbd> are a big improvement, and vim‚Äôs <kbd>hjkl</kbd> go even further.
One fix here is to configure each tool to use your favorite shortcuts, but this is a whack-a-mole game.
What I do is remapping <kbd>CapsLock</kbd> to act as an extra modifier, such that <kbd>ijkl</kbd> <strong>are</strong> arrow keys.
(There are also keyboards with <a href="https://ultimatehackingkeyboard.com/">hardware</a> <a href="https://ergodox-ez.com/">support</a> for this).
This works in all applications the same way.
Easy motion / ace jump functionality for jumping to any visible character is also handy, and usually is available <a href="https://plugins.jetbrains.com/plugin/9803-acejump-lite">via</a> <a href="https://marketplace.visualstudio.com/items?itemName=lucax88x.codeacejumper">a plugin</a>.</p>
<p>Recent advancements with LSP protocol promise to give one the best of both worlds, where semantic-aware backend and light-weight editor frontend are different processes, which can be mixed and matched.
This is nice in theory, but not as nice in practice as IntelliJ yet, mostly because IntelliJ is way more polished.</p>
<p>To give a simple example, in IntelliJ for ‚Äúgo to symbol by fuzzy name‚Äù functionality, I can filter the search scope by:</p>
<div>
<ul>
<li>
<p>is this my code/code from a dependency?</p>
</li>
<li>
<p>is this test/production code?</p>
</li>
<li>
<p>is a symbol a type-like thing, or a method-like thing?</p>
</li>
<li>
<p>path to the module where the symbol is defined.</p>
</li>
</ul>
</div>
<p>VS Code and LSP simply do not have capabilities for such filters yet, they have to be bolted on using hacks.
Support for LSP in other editors is even more hit-and-miss.</p>
<p>LSP did achieve a significant breakthrough‚Äâ‚Äî‚Äâit made people care about implementing IDE backends.
Experience shows that re-engineering an existing compiler to power an IDE is often impossible, or isomorphic to a rewrite.
How a compiler talks to an editor is the smaller problem.
The hard one is building a compiler that can do IDE stuff in the first place.
Check out <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">this post</a> for some of the technical details.
Starting with this use-case in mind saves a lot of effort down the road.</p>
<p>This I think is a big deal.
I hypothesize that the reason why IDEs do not completely dominate tooling landscape is the lack of good IDE backends.</p>
<p>If we look at the set of languages fairly popular recently, a significant fraction of them is dynamically typed: PHP, JavaScript, Python, Ruby.
The helpfulness of an IDE for dynamically typed languages is severely limited: while approximations and heuristics can get you a long way, you still need humans in the loop to verify IDE‚Äôs guesses.</p>
<p>There‚Äôs C++, but its templates are effectively dynamically typed, with exactly the same issues (and a very complex base language to boot).
Curiously, C looks like a language for which implementing a near-perfect IDE is pretty feasible.
I don‚Äôt know why it didn‚Äôt happen before CLion.</p>
<p>This leaves C# and Java.
Indeed, these languages are dominated by IDEs.
There‚Äôs a saying that you can‚Äôt write Java without an IDE.
I think it gets the causation direction backwards: Java is one of the few languages for which it is possible to implement a great IDE without great pain.
Supporting evidence here is Go.
According to <a href="https://blog.golang.org/survey2019-results#TOC_5.">survey results</a>, text editors are stably declining in popularity in favor of IDEs.</p>
<p>I think this is because Go actually has good IDEs.
This is possible because the language is sufficiently statically typed for an IDE to be a marked improvement.
Additionally, the language is very simple, so the amount of work you need to put in to make a decent IDE is much lower than for other languages.
If you have something like JavaScript‚Ä¶‚Äã
Well, you first need to build n alternative language for which you can actually implement and an IDE (<a href="https://www.typescriptlang.org/">TypeScript</a>) and only then you can build the IDE itself (<a href="https://github.com/microsoft/vscode">VS Code</a>).</p>
</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io/2020/11/11/yde.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059374</guid>
            <pubDate>Wed, 11 Nov 2020 15:56:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TypeScript splits the atom A first look at TS 4.1's new template literal types]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059336">thread link</a>) | @danvk
<br/>
November 11, 2020 | https://effectivetypescript.com/2020/11/05/template-literal-types/ | <a href="https://web.archive.org/web/*/https://effectivetypescript.com/2020/11/05/template-literal-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><img src="https://effectivetypescript.com/images/split-atom.png" width="324" height="298" alt="Splitting a string type"></p><p>TypeScript's type system has grown steadily more powerful over the past five years, allowing you to precisely type more and more patterns in JavaScript. The upcoming <a href="https://github.com/microsoft/TypeScript/issues/40124" target="_blank" rel="noopener" onclick="return trackOutboundLink('', 'https://github.com/microsoft/TypeScript/issues/40124', event);">TypeScript 4.1 release</a> includes a particularly exciting new <a href="https://github.com/microsoft/TypeScript/pull/40336" target="_blank" rel="noopener" onclick="return trackOutboundLink('', 'https://github.com/microsoft/TypeScript/pull/40336', event);">addition</a> to the type system: <em>template literal types</em>.</p>
<p>Template literal types solve a <a href="https://github.com/microsoft/TypeScript/issues/12754" target="_blank" rel="noopener" onclick="return trackOutboundLink('', 'https://github.com/microsoft/TypeScript/issues/12754', event);">long-standing gap</a> in TypeScript's type system and, as I'll argue at the end of the post, they solve it in a particularly <em>TypeScripty</em> way.</p>
<p>To understand template literal types, let's start with a seemingly simple question: what can't you type?</p>
<h2 id="The-limits-of-type-safety-in-TypeScript"><a href="#The-limits-of-type-safety-in-TypeScript" title="The limits of type safety in TypeScript"></a>The limits of type safety in TypeScript</h2><p>My standard example of a pattern you <em>couldn't</em> type has always been the <code>camelCase</code> function, which maps something like <code>"foo_bar"</code> ‚Üí <code>"fooBar"</code>. It's easy to implement in JavaScript using a regular expression:</p>
<figure><div><pre><code><span><span>function</span> <span>camelCase</span>(<span>term</span>) </span>{<br>  <span>return</span> term.replace(<span>/_([a-z])/g</span>, <span><span>m</span> =&gt;</span> m[<span>1</span>].toUpperCase());<br>}<br></code></pre></div></figure>

<p>This function is trivial to <em>simply</em> type:</p>
<figure><div><pre><code><span>declare</span> <span><span>function</span> <span>camelCase</span>(<span>term: <span>string</span></span>): <span>string</span></span>;<br></code></pre></div></figure>

<p>So that's not quite what I'm getting at. Ideally you'd like to be able to use this to convert objects with <code>snake_cased</code> properties (like you'd get from a database) into one with <code>camelCased</code> properties (like you typically use in JS/TS). In other words, what should the return type of this function be to make the following code type check (or not) as you'd expect?</p>
<figure><div><pre><code><span><span>function</span> <span>objectToCamel</span>&lt;<span>T</span> <span>extends</span> <span>object</span>&gt;(<span>obj: T</span>) </span>{<br>  <span>const</span> out: <span>any</span> = {};<br>  <span>for</span> (<span>const</span> [k, v] of <span>Object</span>.entries(obj)) {<br>    out[camelCase(k)] = v;<br>  }<br>  <span>return</span> out;<br>}<p><span>const</span> snake = {foo_bar: <span>12</span>}; <br><span>const</span> camel = objectToCamel(snake);<br><br><span>const</span> val = camel.fooBar;  <br><span>const</span> val2 = camel.foo_bar;  </p></code></pre></div></figure>

<p>Prior to TypeScript 4.1 (now a release candidate) this just wasn't possible. The reason was that string literal types like <code>"foo_bar"</code> were "atomic" in the sense that you couldn't observe any structure inside of them. They were indivisible. But clearly there <em>is</em> structure in strings. Just look at <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String#Instance_methods" target="_blank" rel="noopener" onclick="return trackOutboundLink('the limits of type safety in typescript', 'https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String#Instance_methods', event);">all the methods</a> on <code>String.prototype</code>.</p>
<p>Enter: TypeScript 4.1!</p>
<h2 id="TypeScript-splits-the-atom"><a href="#TypeScript-splits-the-atom" title="TypeScript splits the atom"></a>TypeScript splits the atom</h2><p>TypeScript 4.1 introduce a few features that make it possible to precisely type the <code>objectToCamel</code> function:</p>
<ol>
<li><em>Template literal types</em> This is the key advance. Template literal types allow you to find structure inside string literal types and create infinite, strict subsets of <code>string</code> (think "strings starting with <code>on</code>").</li>
<li><em>Key Remapping in Mapped Types</em> While it was possible to change the keys in an object before using tricks like <a href="https://effectivetypescript.com/2020/05/12/unionize-objectify/">Unionize and Objectify</a>, this new feature makes it much more straightforward.</li>
</ol>
<p>Let's use these two features to implement <code>objectToCamel</code>.</p>
<p>First, let's look at template literal types. They look like ES template literals:</p>
<figure><div><pre><code><span>type</span> OnString = <span>`on<span>${<span>string</span>}</span>`</span>;<br><span>const</span> onClick: OnString = <span>'onClick'</span>;<br><span>const</span> handleClick: OnString = <span>'handleClick'</span>;<br>   <br></code></pre></div></figure>

<p>This lets you create a type for "strings starting with <code>on</code>." Before TypeScript 4.1, you either had <code>string</code> or an enumerated union of string literal types (<code>"a" | "b" | "c"</code>). Now you can define structured subsets of <code>string</code>.</p>
<p>Here are a few other patterns:</p>
<figure><div><pre><code><span>type</span> IdNum = <span>`id<span>${<span>number</span>}</span>`</span>;<br><span>const</span> id1: IdNum = <span>'id123'</span>;  <br><span>const</span> id2: IdNum = <span>'idABC'</span>;   <p><span>type</span> Digit = <span>'0'</span> | <span>'1'</span> | <span>'2'</span> | <span>'3'</span> | <span>'4'</span> |<br>             <span>'5'</span> | <span>'6'</span> | <span>'7'</span> | <span>'8'</span> | <span>'9'</span>;<br><span>type</span> ThreeDigitNum = <span>`<span>${Digit}</span><span>${Digit}</span><span>${Digit}</span>`</span>;</p></code></pre></div></figure>

<p>What makes this really powerful is that you can use the <a href="https://artsy.github.io/blog/2018/11/21/conditional-types-in-typescript/" target="_blank" rel="noopener" onclick="return trackOutboundLink('typescript splits the atom', 'https://artsy.github.io/blog/2018/11/21/conditional-types-in-typescript/', event);"><code>infer</code> keyword</a> in a template literal type to do pattern matching:</p>
<figure><div><pre><code><span>type</span> ToCamel1&lt;S <span>extends</span> <span>string</span>&gt; =<br>    S <span>extends</span> <span>`<span>${infer Head}</span>_<span>${infer Tail}</span>`</span><br>    ? <span>`<span>${Head}</span><span>${Capitalize&lt;Tail&gt;}</span>`</span><br>    : S;<p><span>type</span> T = ToCamel1&lt;<span>'foo_bar'</span>&gt;;  </p></code></pre></div></figure>

<p>The conditional matches string literal types of the form <code>"head_tail"</code>. The "<code>_</code>" acts as a delimiter to split the string. Because <a href="https://mariusschulz.com/blog/conditional-types-in-typescript#distributive-conditional-types" target="_blank" rel="noopener" onclick="return trackOutboundLink('typescript splits the atom', 'https://mariusschulz.com/blog/conditional-types-in-typescript#distributive-conditional-types', event);">conditional types distribute over unions</a>, this also works for union types:</p>
<figure><div><pre><code><span>type</span> TU = ToCamel1&lt;<span>'first_name'</span> | <span>'last_name'</span>&gt;;<br><br></code></pre></div></figure>

<p>There's a big issue, though. What if there's two <code>_</code>s in the string literal type?</p>
<figure><div><pre><code><span>type</span> T2 = ToCamel1&lt;<span>'foo_bar_baz'</span>&gt;;  <br></code></pre></div></figure>

<p>We can't stop after the first "<code>_</code>", we need to keep going. We can do this by making the type recursive:</p>
<figure><div><pre><code><span>type</span> ToCamel&lt;S <span>extends</span> <span>string</span>&gt; =<br>    S <span>extends</span> <span>`<span>${infer Head}</span>_<span>${infer Tail}</span>`</span><br>    ? <span>`<span>${Head}</span><span>${Capitalize&lt;ToCamel&lt;Tail&gt;&gt;}</span>`</span><br>    : S;<br><span>type</span> T0 = ToCamel&lt;<span>'foo'</span>&gt;;  <br><span>type</span> T1 = ToCamel&lt;<span>'foo_bar'</span>&gt;;  <br><span>type</span> T2 = ToCamel&lt;<span>'foo_bar_baz'</span>&gt;;  <br></code></pre></div></figure>

<p>The recursive bit is where we call <code>ToCamel&lt;Tail&gt;</code>.</p>
<p>Pretty neat! Now let's put it all together.</p>
<h2 id="A-typed-objectToCamel"><a href="#A-typed-objectToCamel" title="A typed objectToCamel"></a>A typed objectToCamel</h2><p>Recall that a <a href="https://medium.com/@danvdk/a-typed-pluck-exploring-typescript-2-1s-mapped-types-c15f72bf4ca8" target="_blank" rel="noopener" onclick="return trackOutboundLink('a typed objecttocamel', 'https://medium.com/@danvdk/a-typed-pluck-exploring-typescript-2-1s-mapped-types-c15f72bf4ca8', event);">mapped type</a> in TypeScript looks and works something like this:</p>
<figure><div><pre><code><span>interface</span> Vector {<br>  x: <span>number</span>;<br>  y: <span>number</span>;<br>}<br><span>type</span> Promisify&lt;T <span>extends</span> object&gt; = {<br>  [K <span>in</span> keyof T]: <span>Promise</span>&lt;T[K]&gt;  <br>};<br><span>type</span> VectorPromise = Promisify&lt;Vector&gt;;<br><br></code></pre></div></figure>

<p>The <code>keyof T</code> here produces a union of string literal types (<code>"x" | "y"</code>) and the mapped type produces an object type from this given a way to produce the values (the <code>Promise&lt;T[K]&gt;</code>). But the keys are set by the union. You can't change them.</p>
<p>With Key Remapping, you can add an <code>as</code> clause to the key in a mapped type to change things around. This works particularly well with template literal types:</p>
<figure><div><pre><code><span>interface</span> Student {<br>  name: <span>string</span>;<br>  age: <span>number</span>;<br>}<br><span>type</span> Evented&lt;T <span>extends</span> object&gt; = {<br>  [K <span>in</span> keyof T <span>as</span> <span>`<span>${K &amp; <span>string</span>}</span>Changed`</span>]: <span>(<span>val: T[K]</span>) =&gt;</span> <span>void</span>;<br>}<br><span>type</span> StudentEvents = Evented&lt;Student&gt;;<br><br><br><br><br></code></pre></div></figure>

<p>(The <code>&amp; string</code> is there for technical reasons that I don't want to get into.)</p>
<p>Using this, we can plug in our <code>ToCamel</code> generic to put it all together:</p>
<figure><div><pre><code><span>type</span> ObjectToCamel&lt;T <span>extends</span> object&gt; = {<br>  [K <span>in</span> keyof T <span>as</span> ToCamel&lt;K&gt;]: T[K]<br>};<p><span><span>function</span> <span>objectToCamel</span>&lt;<span>T</span> <span>extends</span> <span>object</span>&gt;(<span>obj: T</span>): <span>ObjectToCamel</span>&lt;<span>T</span>&gt; </span>{<br>  <br>}</p><p><span>const</span> snake = {foo_bar: <span>12</span>}; <br><span>const</span> camel = objectToCamel(snake);<br><br><span>const</span> val = camel.fooBar;  <br><span>const</span> val2 = camel.foo_bar;<br>                <br>                </p></code></pre></div></figure>

<p>Here's a <a href="https://www.typescriptlang.org/play?ts=4.2.0-dev.20201109#code/C4TwDgpgBAKg9gYQIYFsIBsA8BlKEAewEAdgCYDOU5wATgJbEDmAfFALwBQU3UuBRZSgAMAJAG8GAMwg0oACQhJSAXwD64qTNhI66ZUK48A-FFFiFS5eORg6wJOjoAvCJnjI0WGDvTNm+w24ALl4Abg5QSFgABnZYRFQMTABySTg4ZOZQ7gB6HKhI6DpKACI0uBKI8GgYAEY490SsVPTVACMkGkzsqDyC6qhiqDL0gCFOysLYACYGhM8U8vbO5adu3PypoZG4cZpxp0qOSQBXYgBjYDo4YihzpuRyVxg8QhIKKloGFgAKIhoUCEYABKIHzJIwVhiQw0CDAE40W7-FAAOlhYHQSHOEB+OVUPwA2kgALROAC6wJyjAANFAUOxWCgCbUySjgHAAKpgSA0R444HAqBISiNBaQ8LKDhVKIAeTaACsIJdRRDXgIPnAFUrgKw2FBodwCQBpQa3ADWEBAcEksCFIvBWBNADJPvQmMwyUDjWSOMpwsczpdrrdNYrlQ63Gr3pRQ9rmD9Q0DQVA5WHgCqvFDDOcbtQoHATsAQkhiCA4mI-YY0rIfjniHmCWbaQA3Mn5m2p7UokhfCDkBMKgX6wL5wsE+6ePk-M3Att65vhbiS7iw+GI0fACVSut5sDC+7octLDo0EK1aZ+3qbAZDMTHzohYgnFBtGSSnfAO5NOKx8MeDA-Hu5AHsC4R9FslBiFA5R7I+z6vrI765p+zYOHEE4YCiMGdD04E3pQT4vjIHAflAqHoLMeoYegWGtCei48IxTE8H0AB+7EcaxUAAAo0HAPKgFALRwMsXRQKQcB9lAxBwJ+BDFJ+Nz9JAI7McxfRqUJUHYae0nwTI2TKMkKJQAAInQpBQFaJx0ootzCXsyRGBwQA" target="_blank" rel="noopener" onclick="return trackOutboundLink('a typed objecttocamel', 'https://www.typescriptlang.org/play?ts=4.2.0-dev.20201109#code/C4TwDgpgBAKg9gYQIYFsIBsA8BlKEAewEAdgCYDOU5wATgJbEDmAfFALwBQU3UuBRZSgAMAJAG8GAMwg0oACQhJSAXwD64qTNhI66ZUK48A-FFFiFS5eORg6wJOjoAvCJnjI0WGDvTNm+w24ALl4Abg5QSFgABnZYRFQMTABySTg4ZOZQ7gB6HKhI6DpKACI0uBKI8GgYAEY490SsVPTVACMkGkzsqDyC6qhiqDL0gCFOysLYACYGhM8U8vbO5adu3PypoZG4cZpxp0qOSQBXYgBjYDo4YihzpuRyVxg8QhIKKloGFgAKIhoUCEYABKIHzJIwVhiQw0CDAE40W7-FAAOlhYHQSHOEB+OVUPwA2kgALROAC6wJyjAANFAUOxWCgCbUySjgHAAKpgSA0R444HAqBISiNBaQ8LKDhVKIAeTaACsIJdRRDXgIPnAFUrgKw2FBodwCQBpQa3ADWEBAcEksCFIvBWBNADJPvQmMwyUDjWSOMpwsczpdrrdNYrlQ63Gr3pRQ9rmD9Q0DQVA5WHgCqvFDDOcbtQoHATsAQkhiCA4mI-YY0rIfjniHmCWbaQA3Mn5m2p7UokhfCDkBMKgX6wL5wsE+6ePk-M3Att65vhbiS7iw+GI0fACVSut5sDC+7octLDo0EK1aZ+3qbAZDMTHzohYgnFBtGSSnfAO5NOKx8MeDA-Hu5AHsC4R9FslBiFA5R7I+z6vrI765p+zYOHEE4YCiMGdD04E3pQT4vjIHAflAqHoLMeoYegWGtCei48IxTE8H0AB+7EcaxUAAAo0HAPKgFALRwMsXRQKQcB9lAxBwJ+BDFJ+Nz9JAI7McxfRqUJUHYae0nwTI2TKMkKJQAAInQpBQFaJx0ootzCXsyRGBwQA', event);">complete playground</a>.</p>
<h2 id="What-can-should-you-do-with-template-literal-types"><a href="#What-can-should-you-do-with-template-literal-types" title="What can should you do with template literal types?"></a>What <del>can</del> should you do with template literal types?</h2><p>After template literal types landed, the TypeScript Twittersphere went crazy. I shared a use case around <a href="https://expressjs.com/en/guide/routing.html" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://expressjs.com/en/guide/routing.html', event);">express</a>, which quickly became the most popular tweet I've ever posted:</p>
<blockquote><p lang="en" dir="ltr">Another use of <a href="https://twitter.com/typescript?ref_src=twsrc%5Etfw" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://twitter.com/typescript?ref_src=twsrc%5Etfw', event);">@TypeScript</a> 4.1's template literal types: extracting the URL parameters from an express route. Pretty amazing you can do this in the type system! <a href="https://t.co/gfZQy70whg" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://t.co/gfZQy70whg', event);">https://t.co/gfZQy70whg</a> <a href="https://t.co/aEyfMwjjqX" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://t.co/aEyfMwjjqX', event);">pic.twitter.com/aEyfMwjjqX</a></p>‚Äî Dan Vanderkam (@danvdk) <a href="https://twitter.com/danvdk/status/1301707026507198464?ref_src=twsrc%5Etfw" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://twitter.com/danvdk/status/1301707026507198464?ref_src=twsrc%5Etfw', event);">September 4, 2020</a></blockquote> 

<p>A <a href="https://twitter.com/buildsghost/status/1301976526603206657" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://twitter.com/buildsghost/status/1301976526603206657', event);">JSON parser</a> made the rounds and then someone <a href="https://github.com/codemix/ts-sql" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/codemix/ts-sql', event);">implemented a full SQL engine</a> in the type system. Hacker news <a href="https://news.ycombinator.com/item?id=24615185" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://news.ycombinator.com/item?id=24615185', event);">was impressed</a>.</p>
<p>As with any new tool, it will take some time for the community to figure out the best ways to use it. Here are a few ideas. We'll see how they pan out!</p>
<ul>
<li><p>Dotted access: <strong>easy win</strong></p>
<p>Lodash allows you to write <a href="https://stackoverflow.com/a/43395675/388951" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://stackoverflow.com/a/43395675/388951', event);">"iteratee" expressions</a> like <code>xs.map('a.b.c')</code>, which is roughly the same as <code>xs.map(x =&gt; x.a.b.c)</code>. Template literal types will make it possible for this sort of API to be typed.</p>
<p>I've never been a big fan of this style. I'd prefer to write <code>x =&gt; x.a.b.c</code>. But perhaps some of this is just bias from not being able to type these properly in the past. Using string literals for enums, for example, is frowned upon in Java as unsafe, <a href="https://cocoacasts.com/the-danger-of-string-literals-and-stringly-typed-code" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://cocoacasts.com/the-danger-of-string-literals-and-stringly-typed-code', event);">stringly typed</a>, code. But it turns out to be fine in TypeScript because the type system is rich enough to capture it. So we'll see!</p>
</li>
<li><p>Parsing routes: <strong>huge win!</strong></p>
<p>See my tweet above. Parsing <code>{userId: string}</code> out of <code>/users/:userId</code> will be a big win for express users.</p>
<p>Going the other direction is also compelling. In a server I use at work, we issue API calls via something like <code>get('/users/:userId', {userId: 'id'})</code>. We have types defined for the parameters for each route. But now we can just let TypeScript infer them to ensure that nothing will ever get out of sync.</p>
<p>Similar considerations apply to routes with <a href="https://reactrouter.com/web/example/url-params" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://reactrouter.com/web/example/url-params', event);">react-router</a>.</p>
</li>
<li><p>Better types for <code>querySelector</code> / <code>querySelectorAll</code>: <strong>nice win</strong></p>
<p>The <a href="https://github.com/microsoft/TypeScript/blob/b5b0437a86661c8d7bc76c5860c07305df17899c/lib/lib.dom.d.ts#L11341-L11349" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/microsoft/TypeScript/blob/b5b0437a86661c8d7bc76c5860c07305df17899c/lib/lib.dom.d.ts#L11341-L11349', event);">DOM typings</a> are clever enough to infer a subtype of <code>Element</code> here:</p>
<figure><div><pre><code><span>const</span> input = <span>document</span>.queryQuerySelector(<span>'input'</span>);<br><br></code></pre></div></figure>

<p>But once you add anything more complex to the selector, you lose this:</p>
<figure><div><pre><code><span>const</span> input = <span>document</span>.queryQuerySelector(<span>'input.my-class'</span>);<br><br></code></pre></div></figure>

<p>With template literal types, it will be possible to fix this. I wouldn't be surprised if it becomes common practice to replace calls to <code>getElementById</code> with equivalent calls to <code>querySelector</code>:</p>
<figure><div><pre><code><span>const</span> el1 = <span>document</span>.getElementById(<span>'foo'</span>);<br><br><span>const</span> div = <span>document</span>.querySelector(<span>'div#foo'</span>);<br><br></code></pre></div></figure>

<p>This will no doubt require me to rewrite Item 55 of <a href="https://amzn.to/38s1oCK" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://amzn.to/38s1oCK', event);"><em>Effective TypeScript</em></a> ("Understand the DOM hierarchy"). Oh well!</p>
</li>
<li><p>Parsing options in <a href="https://www.npmjs.com/package/commander" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://www.npmjs.com/package/commander', event);">Commander</a> or <a href="https://github.com/docopt/docopt.coffee" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/docopt/docopt.coffee', event);">docopt</a>: <strong>a small win</strong></p>
<p>With <a href="https://www.npmjs.com/package/commander" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://www.npmjs.com/package/commander', event);">Commander</a>, you define your command line tool's arguments using something like this:</p>
<figure><div><pre><code>program<br>  .option(<span>'-d, --debug'</span>, <span>'output extra debugging'</span>)<br>  .option(<span>'-s, --small'</span>, <span>'small pizza size'</span>)<br>program.parse(process.argv);<br><span>console</span>.log(program.debug, program.small);<br></code></pre></div></figure>

<p>Setting aside the mutation style, which is hard to model in TypeScript, template literal types should make it possible to extract the parameter names from the calls to <code>.option</code>.</p>
</li>
<li><p>Parsing SQL or GraphQL: <strong>I could go either way!</strong></p>
<p>The <a href="https://github.com/codemix/ts-sql" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/codemix/ts-sql', event);">ts-sql</a> demo <a href="https://news.ycombinator.com/item?id=24615185" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://news.ycombinator.com/item?id=24615185', event);">raised some eyebrows</a>, but it also made a real point about the power of template literal types. Given a TypeScript version of your database schema (which can be generated using <a href="https://github.com/PSYT/schemats" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/PSYT/schemats', event);">schemats</a> or <a href="https://github.com/danvk/schemats" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/danvk/schemats', event);">pg-to-ts</a>), it should be possible to infer result types for a SQL query:</p>
<figure><div><pre><code><span>import</span> {Schema} <span>from</span> <span>'./dbschema'</span>;<p><span>async</span> <span><span>function</span> <span>getStudentsByAge</span>(<span>db: Pool, age: <span>number</span></span>) </span>{<br>  <span>const</span> result = <span>await</span> db.query&lt;Schema&gt;(<span>`</span><br><span>  SELECT first_name, last_name FROM students</span><br><span>  WHERE age = $1;</span><br><span>  `</span>, [age]);  <br>  <span>return</span> result.rows;<br>  <br>}</p></code></pre></div></figure>

<p>This seems potentially amazing, but also perhaps brittle. You'd have to work in the subset of SQL that your types understood: presumably you wouldn't want to implement all of <a href="https://en.wikipedia.org/wiki/PL/pgSQL" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://en.wikipedia.org/wiki/PL/pgSQL', event);">PL/pgSQL</a> in the type system. But I could imagine getting a large class of queries, including joins, to work.</p>
<p>So I'm on the fence on this one! Similar considerations apply to GraphQL queries, which would be a bit easier to join with a schema in the type system than raw SQL.</p>
</li>
</ul>
<p>Template literal types open up many new doors for TypeScript library authors and should improve the overall experience of using TypeScript for everyone by capturing more JavaScript patterns in the type system.</p>
<p>I'd like to conclude by pointing out that this is a very <em>TypeScripty</em> solution to this problem. ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://effectivetypescript.com/2020/11/05/template-literal-types/">https://effectivetypescript.com/2020/11/05/template-literal-types/</a></em></p>]]>
            </description>
            <link>https://effectivetypescript.com/2020/11/05/template-literal-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059336</guid>
            <pubDate>Wed, 11 Nov 2020 15:52:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ZX Spectrum 8-Bit Chiptune Music Collection: AY-3-8910, Beeper, Digital]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059328">thread link</a>) | @elvis70
<br/>
November 11, 2020 | https://zxart.ee/eng/music/ | <a href="https://web.archive.org/web/*/https://zxart.ee/eng/music/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://zxart.ee/eng/music/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059328</guid>
            <pubDate>Wed, 11 Nov 2020 15:51:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using the Webmention.io API]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059318">thread link</a>) | @todsacerdoti
<br/>
November 11, 2020 | https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/ | <a href="https://web.archive.org/web/*/https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article>
    <header>
      <p>Fetching my IndieWeb mentions with HTTPie and Requests</p><section>
      <p><time datetime="2020-11-10T00:00:00+00:00">
            <a href="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/">
              Tuesday, 10 November, 2020
            </a>
          </time>‚Äî by
          <br>
        <a href="https://randomgeekery.org/post">Post</a>
        ‚Äî <a href="https://randomgeekery.org/categories/tools/">Tools</a>
      
      
      
        ‚Äî
        
          <a href="https://randomgeekery.org/tags/python">Python</a>
        
          <a href="https://randomgeekery.org/tags/indieweb">IndieWeb</a>
        
          <a href="https://randomgeekery.org/tags/fixing-my-site">fixing my site</a>
        
          <a href="https://randomgeekery.org/tags/site">Site</a>
        
      <br>
        Around 1,300 words, or 6 minutes of reading</p><section><p>Part 1 of 1 in the
              <a href="https://randomgeekery.org/series/fixing-my-webmentions">fixing my webmentions</a> series.</p>
          <dl></dl></section>
        

        
        
<nav>
  <section>
    <header>
      
      Previous Post
    </header>
    
      <p>
        <a href="https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/">Tangling code from Hugo content with Raku</a>
      </p>
      
    
  </section>
  <section>
    <header>
      Next Post
      
    </header>
    
      <p><em>You are reading the newest post</em></p>
    
  </section>
</nav>

      </section>
  
  
  
    
  

  <figure>
    <a href="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/cover.jpg">
      <img src="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/cover.jpg" alt="A spiderweb! For Webmention! Get it? Okay, yeah. Sorry.">
    </a><figcaption>A spiderweb! For Webmention! Get it? Okay, yeah. Sorry.</figcaption></figure>


    </header>
    <section>

      <p>So I hosed a local copy of my mentions feed the other month.
What‚Äôs my ‚Äúmentions feed,‚Äù I hear you wondering?</p>
<p>Whenever somebody shares a reaction to something here ‚Äî like, reshare, reply, mention ‚Äî that reaction gets sent to <a href="https://webmention.io/">Webmention.io</a>.
There are more moving parts than that, of course.
<a href="https://brid.gy/">Bridgy</a> aggregates reactions to my announcement toots and tweets and sends those to Webmention.
It shows in my mentions feed as a reaction to site content when someone reacts to a relevant tweet.</p>
<p><em>Sometimes</em> folks even post mentions, replies, and reactions directly to the Webmention endpoint.
Mostly it‚Äôs just social media reactions, though.</p>
<p>The <a href="https://github.com/aaronpk/webmention.io#api">Webmention.io API</a> lets me gather all of these reactions.</p>
<p>Let‚Äôs acquaint ourselves with the important parts of this API.
You‚Äôll need your API token, which can be found in the Webmention <a href="https://webmention.io/settings">Settings</a> once you sign up.</p>
<h2 id="reading-the-feed-with-httpie">Reading the feed with HTTPie</h2>
<p>I‚Äôll use <a href="https://httpie.io/">HTTPie</a> for my little exploration.
I like the way it works.</p>
<h3 id="getting-recent-reactions">Getting recent reactions</h3>
<p>We mainly care about the mentions endpoint.
Hand it your domain and API token, and it will send you the 20 most recent responses for your site.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span>
</code></pre></div><p>HTTPie‚Äôs double-equals <code>==</code> syntax means ‚Äúmake a query string,‚Äù so I end up with something like this:</p>
<div><pre><code data-lang="text">https://webmention.io/api/mentions.jf2?domain=randomgeekery.org&amp;token=xxxxx
</code></pre></div><p>When <code>http</code> fetches that URL, I get back a <a href="https://www.w3.org/TR/jf2/">JF2</a> feed that looks something like this.</p>
<div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>"Jumpei KAWAMI"</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>"https://webmention.io/avatar/‚Ä¶"</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>"https://twitter.com/junkw"</span>
            <span>},</span>
            <span>"content"</span><span>:</span> <span>{</span>
                <span>"text"</span><span>:</span> <span>"I wrote a note:\n\nI added this note from org mode‚Ä¶"</span>
            <span>},</span>
            <span>"published"</span><span>:</span> <span>"2020-10-25T23:32:25+00:00"</span><span>,</span>
            <span>"repost-of"</span><span>:</span> <span>"https://randomgeekery.org/note/2020/10/i-added-this-note-from-org-mode/"</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://twitter.com/junkw/status/1320508544601509889"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>887739</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"repost-of"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-10-26T04:07:20Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://brid-gy.appspot.com/repost/twitter/brianwisti/‚Ä¶"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org/note/2020/10/i-added-this-note-from-org-mode/"</span>
        <span>},</span>
        <span>‚ãÆ</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>What‚Äôs JF2?
It‚Äôs obviously JSON.
Maybe something to do with <a href="https://jsonfeed.org/">JSON Feed</a>?
Similar, but no.
JF2 is a JSON format for IndieWeb‚Äôs <a href="http://microformats.org/wiki/microformats2">microformats2</a>.
The mnemonic I‚Äôve been trying to drill into my head is ‚ÄúJSON (micro)Formats 2.‚Äù</p>
<p>It‚Äôs not a very good mnemonic.</p>
<p>Each entry summarizes the reaction, including which of my posts they were reacting to.
That‚Äôs kind of important.
Most recently, Twitter user <a href="https://twitter.com/junkw">junkw</a> retweeted my announcement about <a href="https://randomgeekery.org/note/2020/10/i-added-this-note-from-org-mode/">adding a note from Org mode</a>.</p>
<div>
  <p>Note</p><p>

  There‚Äôs also a <code>.json</code> endpoint for every feed that presents a different structure for mentions.
I prefer it, because it contains fewer <code>wm-*</code> fields.
But the documentation uses JF2, so that‚Äôs what I‚Äôll do.</p></div>

<h3 id="checking-for-new-reactions">Checking for new reactions</h3>
<p>Maybe I‚Äôm checking again later and only want to see the <em>new</em> reactions.
I request mentions received since the value of the <code>wm-received</code> field in the last entry I have.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>\
</span><span></span>  <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>\
</span><span></span>  <span>since</span><span>==</span><span>"2020-10-26T04:07:20Z"</span>
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>Well, yeah.
That makes sense.
I don‚Äôt get the kind of traffic where you‚Äôd expect fresh reactions every time you check.</p>
<h3 id="fetching-the-oldest-reactions-first">Fetching the oldest reactions first</h3>
<p>As I mentioned at the start, my site is a little broken.
I need to rebuild the full list of reactions so my <a href="https://randomgeekery.org/tags/hugo">Hugo</a> site can work with a complete record.
To do that, I should probably start from the oldest mentions and work my way forward.</p>
<p>Rather than the default <code>sort-dir</code> of <code>down</code>, I specify <code>up</code>.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>\
</span><span></span>  <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>\
</span><span></span>  sort-dir<span>==</span>up
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>"Steve Scaffidi"</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>"https://webmention.io/avatar/‚Ä¶"</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>"https://twitter.com/hercynium"</span>
            <span>},</span>
            <span>"content"</span><span>:</span> <span>{</span>
                <span>"html"</span><span>:</span> <span>"This is where I wish Perl5 had something like Python's AST class hierarchy‚Ä¶"</span><span>,</span>
                <span>"text"</span><span>:</span> <span>"This is where I wish Perl5 had something like Python's AST class hierarchy‚Ä¶"</span>
            <span>},</span>
            <span>"in-reply-to"</span><span>:</span> <span>"https://randomgeekery.org/2020/02/17/python-invoke/"</span><span>,</span>
            <span>"published"</span><span>:</span> <span>"2020-02-18T03:11:58+00:00"</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://twitter.com/hercynium/status/1229604443651526656"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>757935</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"in-reply-to"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-02-18T22:32:20Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://brid-gy.appspot.com/comment/twitter/brianwisti/‚Ä¶"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org/2020/02/17/python-invoke/"</span>
        <span>}</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>Aww, my first site reply.
From <a href="https://twitter.com/hercynium">hercynium</a>.</p>
<p>I only get 20 results by default, though.
Here.
Let‚Äôs make <a href="https://stedolan.github.io/jq/">jq</a> show us.
Here‚Äôs a default page.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> sort-dir<span>==</span>up <span>\
</span><span></span>  <span>|</span> jq <span>'.children | length'</span>
</code></pre></div><pre><code>20
</code></pre><h3 id="handling-result-pagination">Handling result pagination</h3>
<p>I can specify how many responses I want in each response with the <code>per-page</code> parameter.
With <code>per-page</code> set to 100, I get a hundred entries.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> per-page<span>==</span><span>100</span> <span>\
</span><span></span>  <span>|</span> jq <span>'.children | length'</span>
</code></pre></div><pre><code>100
</code></pre><p>Of course, if there aren‚Äôt a hundred entries to fill the page, I only get what‚Äôs available.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>since</span><span>==</span><span>"2020-10-26T04:07:20Z"</span> per-page<span>=</span><span>100</span> <span>\
</span><span></span>  <span>|</span> jq <span>'.children | length'</span>
</code></pre></div><pre><code>0
</code></pre><p>The <code>page</code> parameter ‚Äî which starts at zero ‚Äî lets me step through the feed in batches.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>\
</span><span></span>  <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>\
</span><span></span>  sort-dir<span>==</span>up <span>\
</span><span></span>  <span>page</span><span>==</span><span>1</span>
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>"brian wisti"</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>"https://webmention.io/avatar/‚Ä¶"</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>"https://twitter.com/brianwisti"</span>
            <span>},</span>
            <span>"content"</span><span>:</span> <span>{</span>
                <span>"html"</span><span>:</span> <span>"‚Ä¶"</span><span>,</span>
                <span>"text"</span><span>:</span> <span>"‚Ä¶"</span><span>,</span>
            <span>},</span>
            <span>"in-reply-to"</span><span>:</span> <span>"https://randomgeekery.org/2020/01/19/restructuredtext-basics-for-blogging/"</span><span>,</span>
            <span>"published"</span><span>:</span> <span>"2020-03-10T06:24:45+00:00"</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://twitter.com/brianwisti/status/1237263101482823681"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>766993</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"in-reply-to"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-03-10T06:38:55Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://brid-gy.appspot.com/comment/twitter/brianwisti/‚Ä¶"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org/2020/01/19/restructuredtext-basics-for-blogging/"</span>
        <span>},</span>
        <span>‚ãÆ</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>Right.
That‚Äôs Bridgy catching a Twitter thread.
At least I can see the full conversation from my site.
Or I wil once I‚Äôm done fixing everything.</p>
<h3 id="bonus-checking-for-reactions-to-a-specific-post">Bonus: checking for reactions to a specific post</h3>
<p>I could get a JF2 feed for specific URLs on my site if I was so inclined.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>target</span><span>==</span>https://randomgeekery.org
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>""</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>""</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>""</span>
            <span>},</span>
            <span>"mention-of"</span><span>:</span> <span>"https://randomgeekery.org"</span><span>,</span>
            <span>"published"</span><span>:</span> <span>null</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://kevq.uk/blogroll/"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>796241</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"mention-of"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-05-14T11:25:47Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://kevq.uk/blogroll/"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org"</span>
        <span>}</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>I deal with my site reactions in bulk so they can be incorporated in the Hugo build.
This could be handy for JavaScript-driven update on reactions since the site was last built and pushed, though.</p>
<h2 id="rebuilding-the-local-mentions-file">Rebuilding the local mentions file</h2>
<p>Now I want to take what I learned about the API to build a local copy of my site‚Äôs mention history.
Let‚Äôs step away from HTTPie and the command line before I try something dangerous.</p>
<p>The <a href="https://requests.readthedocs.io/en/master/">requests</a> library for <a href="https://randomgeekery.org/tags/python">Python</a> can help me build one list of Webmentions.</p>
<div><pre><code data-lang="python"><span>import</span> <span>json</span>
<span>import</span> <span>os</span>
<span>import</span> <span>time</span>

<span>import</span> <span>requests</span>

<span>def</span> <span>rebuild_full_feed</span><span>(</span><span>domain</span><span>:</span> <span>str</span><span>,</span> <span>token</span><span>:</span> <span>str</span><span>,</span> <span>target_file</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
    <span>endpoint</span> <span>=</span> <span>"https://webmention.io/api/mentions.jf2"</span>
    <span>page_size</span> <span>=</span> <span>100</span>
    <span>all_entries</span> <span>=</span> <span>[]</span>
    <span>page_index</span> ‚Ä¶</code></pre></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/">https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/</a></em></p>]]>
            </description>
            <link>https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059318</guid>
            <pubDate>Wed, 11 Nov 2020 15:49:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Instacart Web Performance Audit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059265">thread link</a>) | @toddgardner
<br/>
November 11, 2020 | https://requestmetrics.com/web-performance/performance-profiling-instacart | <a href="https://web.archive.org/web/*/https://requestmetrics.com/web-performance/performance-profiling-instacart">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Grocery shopping is tedious and time consuming.  In search of a more streamlined experience, I decided to try Instacart.  Unfortunately, using their site is <em>also</em> tedious and time consuming.</p>

<!--more-->

<h2 id="common-actions-take-too-long">Common Actions Take Too Long</h2>
<p>In the video you‚Äôll see I attempt to visit the landing page of my local grocery store and, after that loads, do a search for <em>yogurt</em>.</p>

<figure>
    <video controls="" muted="" preload="metadata">
        <source src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-load-and-search.mp4" type="video/mp4">
    </video>
    <figcaption>Visiting a grocery store homepage and searching for items.</figcaption>
</figure>

<p>Over <strong>25</strong> seconds to perform a single load and search.  Just loading the Cub Foods ‚Äústorefront‚Äù page took <strong>14</strong> seconds and <strong>154</strong> requests.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-total-stats.png" alt="Loading a single storefront">
    <figcaption>Network stats for loading a single storefront in Instacart.</figcaption>
</figure>

<p>On the plus side there were some very nice placeholder graphics that set the mood while I waited.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-placeholder.png" alt="Placeholder graphics for days">
</figure>

<h3 id="when-its-not-javascripts-fault">When it‚Äôs not JavaScript‚Äôs Fault</h3>
<p>Usually when I look at ‚Äúmodern‚Äù websites the main performance culprit is JavaScript.  Too many scripts doing too much rendering.  While Instacart <em>does</em> have too much JavaScript, they have a bigger problem: <strong>the server</strong>.</p>

<h4 id="the-initial-page-load-is-slow">The Initial Page Load is Slow</h4>
<p>Instacart uses some combination of server and client rendering.  On the one hand, it‚Äôs great that they don‚Äôt just load a blank page with a big spinner in the middle and wait for 20MB of JavaScript to load.</p>
<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-page.png" alt="3 seconds to load the basic page skeleton">
</figure>
<p>On the other hand it took <strong>3</strong> seconds to get the single page layout skeleton back.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-skeleton.png" alt="Just a basic SPA template">
    <figcaption>Three seconds for some placeholder template HTML is a bit long.</figcaption>
</figure>

<p>The images to populate the placeholder template took another few seconds:</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-image.png" alt="4 seconds for a background image">
</figure>

<p>If you notice the first segment of the URL after the Cloudfront domain is <code>/156x/</code>. These endpoints will return custom sized images and that first segment is the requested dimensions.  You can change that segment to <code>/300x/</code>, for example, and you‚Äôll get a bigger image that maintains aspect ratio (it will be 300px wide by whatever the height should be to keep the ratio).  You can also specify a height if you want a different effect:</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-custom-image-size.png" alt="Custom images sizes are great, but costly for performance">
</figure>

<p>Cool, but this is almost certainly part of the reason loading uncached images is so slow. The origin behind Cloudfront is doing a lot of work to make a custom image and send it over the wire on-demand.</p>

<p>In all fairness, these images have the proper cache response headers, so subsequent page loads will have the images served from the browser memory cache.  But that first hit is very slow.</p>

<h4 id="the-api-is-slow-too">The API is Slow Too</h4>
<p>It isn‚Äôt just the page load and images that are slow.  The servers responding to API requests are taking their time as well.  Some of the calls to populate data on the page took over <strong>5</strong> seconds!</p>
<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-api.png" alt="Several API calls took over 5 seconds">
</figure>

<p>One of the endpoints shown here fetches coupon information.  In the initial loading video you can see the coupon section is particularly slow to render.  Even though there is content loaded below the fold, the user has no idea since the placeholders are still shown for the coupon section until that call returns.</p>

<h4 id="placeholders-are-nice-but-faster-endpoints-are-better">Placeholders are Nice But Faster Endpoints are Better</h4>

<p>This is where the hybrid rendering model falls apart a bit.  There is a lot of dynamic content being rendered post page load.  And since the API is slow the user is getting even more placeholders.</p>

<p>As the user scrolls down the page there are on-demand API calls made to show products from each grocery department.  These calls can take upwards of 2 seconds each.  And there‚Äôs a lot of them.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-department.png" alt="On-demand API calls to load additional products are slow.">
</figure>

<p>For each one we get more placeholder graphics until the server returns its response:</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-more-placeholders.png" alt="Placeholders are cool, but speed would be better.">
</figure>

<p>Placeholders do a nice job of minimizing jank or <a href="https://requestmetrics.com/web-performance/cumulative-layout-shift">cumulative layout shift</a> but they are a poor substitute for the actual content.  Paradoxically I find they can also make a site feel slower since the UI is changing out from under the user so frequently.</p>

<h3 id="maybe-instacart-doesnt-think-it-has-a-performance-problem">Maybe Instacart Doesn‚Äôt Think It Has a Performance Problem?</h3>
<p>There‚Äôs a <a href="https://tech.instacart.com/building-instacarts-view-model-api-part-1-why-view-model-4362f64ffd2a">few articles</a> on <a href="https://tech.instacart.com/scaling-at-instacart-distributing-data-across-multiple-postgres-databases-with-rails-13b1e4eba202">the Instacart engineering blog</a> discussing the back-end technical implementation of the site.  In both the linked articles they discuss ‚Äúimproved performance‚Äù and the existing ‚Äúhealthy performance‚Äù of the site.  Perhaps the main problem is they don‚Äôt think there‚Äôs a performance issue to fix?</p>

<p>Most modern technical stacks are capable of serving pages and API calls in sub-second time if that‚Äôs the company‚Äôs goal.  I suspect in this case they have limited resources and other priorities.  Maybe things are better in the phone app, but I think I‚Äôll stick with going to the grocery store for now, it‚Äôs faster.</p>

</div></div>]]>
            </description>
            <link>https://requestmetrics.com/web-performance/performance-profiling-instacart</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059265</guid>
            <pubDate>Wed, 11 Nov 2020 15:44:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Productivity vs. Privacy]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25059205">thread link</a>) | @jessems
<br/>
November 11, 2020 | https://jessems.com/productivity-vs-privacy | <a href="https://web.archive.org/web/*/https://jessems.com/productivity-vs-privacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>In recent years there's been a steady growth in privacy focused companies. Some examples that have reached large-scale adoption are <a href="https://protonmail.com/">ProtonMail</a>, <a href="https://signal.com/">Signal</a>, and <a href="https://duckduckgo.com/">DuckDuckGo</a>. These are companies that have put privacy front and center to their value proposition and can be considered <em>privacy-preserving products</em>. I've come to beleive a goal of preserving user privacy is often inherently in tension with the goal of advancing user productivity.</p><p>What these services have in common is that they promise their users a higher degree of privacy relative to their competitors. Instead of the usual encryption in transit (protection from eavesdroppers) and encryption at rest (protection against unauthorized users), services like Signal and ProtonMail enable their users to hide data from anyone except the intended recipient, which ‚Äî crucially ‚Äî includes the service providers themselves.</p><p>This category of encryption is known as end-to-end encryption (e2e) and has found adopters in anyone from principled libertarians to journalists and human rights activitists whose lives may depend on their conversations remaining unwiretapped.</p><h2>Early privacy-preserving software was too difficult to use</h2><p>The canonical implementation of e2e for email is known as Pretty Good Privacy (PGP) and its reference implementation is GPG. GPG never reached mass adoption and there seems to be a myriad of reasons for that. The most salient reason, however, seems to be that to this day, it continues to be difficult to use. As the founder of Signal, Moxie Marlinspike <a href="https://moxie.org/2015/02/24/gpg-and-me.html">explains</a>, the spirit behind GPG was the following:</p><blockquote><p>Instead of developing opinionated software with a simple interface, GPG was written to be as powerful and flexible as possible.</p></blockquote><p>Powerful, flexible software written by nerds, unfortunately also tends to be prohibitively complex for normal users. Combined with the fact that <a href="https://signal.org/blog/the-ecosystem-is-moving/">decentralized technology seems unable to quickly adapt to change</a>, the result has been a clunky solution that has, quite frankly, stayed clunky. With no feasible privacy-preserving alternative <!-- -->[1]<!-- -->, non-privacy preserving email providers became the norm.</p><h2>Surveillance capitalist companies will not encrypt your data, because they rely on being able to read it</h2><p>One such email provider, Gmail by Google, gained millions of users by offering a free plan. Their initial monetization strategy was scanning your emails and serving you personalized ads. Although they've stopped personalizing the ads, they're still scanning your email's contents to serve you a better experience across their services. Similarly, Facebook tracks what you do to shape your experience and keep you glued (they would say 'engaged') to their platform.</p><p>What unites platforms like Google and Facebook, is described by Professor Shoshana Zuboff as ‚Äú<a href="https://en.wikipedia.org/wiki/Surveillance_capitalism">surveillance capitalism</a>‚Äù. The business model of surveillance capitalist companies is to harvest personal data about you to build a model that predicts your behavior. These prediction models are packaged and sold as advertisement opportunities to companies eager to buy your attention. You might be the user, but you're not the customer ‚Äî the advertisers are.</p><p>It should come as no surprise then, that none of these platforms has shipped with end-to-end encryption by default. Doing so would go against the incentives that undergird their very business model. Their ability to predict your behavior, and sell ads based on those predictions, hinges on their ability to harvest your data.</p><h2>Data is also collected to improve the service</h2><p>A company like Google has other business models of course. Google Workspace, aimed at businesses, is a collection of collaboration and productivity tools. This ranges from Google Docs, to chat, to video conferencing, and more. By offering this as a paid service, Google exposes itself to a different incentive, one where the customer and the user are now one and the same.</p><p>Even if you're both the user and the customer, your data is still being harvested. This data might not feed into personalized ads (because that‚Äôs no longer the primary business model) but rather into improving your experience. But as a business user, when does your experience improve? And as a service provider, how do you know what improves the experience?</p><h2>Improvements are productivity gains</h2><p>There's an inclination to think of improvements as things that help you do the thing you want to do quicker, better and/or with less frustration. We can go one step further and borrow some of the thinking used in economics and treat productivity simply as the ratio between outputs (salaries and corporate profits) and inputs (hours worked). Productivity increases if inputs can be decreased (for equal outputs) or outputs can be increased (for equal inputs). What's more, we would expect this quantity to improve along with advances in technology.</p><p>How does technology lead to increases in productivity? One obvious way is by making us more efficient. If some new technology saves us time doing a certain task (decreased input), all other things being equal, we‚Äôll end up seeing those gains reflected in our outputs.</p><h2>Productivity gains are discovered, not planned</h2><p>What exactly are the things that increase efficiency? Here's where it gets tricky. In the realm of knowledge work, we don't always know where the gains will come from ‚Äî that is, before they are made. We are still discovering new ways in which we can be more productive and especially so in the domain of collaborative productivity. An illustrative example of how productivity gains are discovered comes from Kevin A. Kwok's description of Figma's road to success.</p><p>In "Why Figma Wins", <a href="https://kwokchain.com/2020/06/19/why-figma-wins/">Kwok details</a> how the product team discovered a way to enable more efficient collaboration in the design process. That this potential existed wasn't at all  obvious to even those within the scene. While Sketch had broken new ground with their vector based design tool geared towards product designers, Figma took it to another level by taking many of the same (dare I say revolutionary) UX patterns and offering them in a web-native, multiplayer web application.</p><blockquote><p>The core insight of Figma is that design is larger than just designers. Design is all of the conversations between designers and PMs about what to build. It is the mocks and prototypes and the feedback on them. It is the handoff of specs and assets to engineers and how easy it is for them to implement them.</p></blockquote><p>As Kevin explains, Figma brought together the disparate disciplines that are involved in a design process into a synced browser window for everybody. This helped democratize design and remove a lot of friction that had existed before.</p><p>Not only did Figma push the frontier of productivity into new territory, it wasn‚Äôt obvious beforehand what that territory would look like. The lesson is that productivity improvements are won through a process of <em>discovery</em>. Kevin explains:</p><blockquote><p>As disciplines evolve, they figure out the social norms needed to operate better, build tools that can be shared across the industry, and invent abstractions that allow offloading more and more of the workload. They learn how to collaborate better, not just with each other but with all the other functions as well.</p></blockquote><p>Although there's some inherent uncertainty about what the productivity gains will look like (and where to look for them), there's no uncertainty about whether they will be made at all. If one thing can be counted on, it's the tech industry's relentless march towards higher productivity. The big tech platforms know this and don't shy away from investing heavily in innovation (discovery) in that direction.</p><h2>Productivity gains are unlocked by harvesting data</h2><p>Although there is some inherent tension between preserving privacy vs. allowing for a multiplayer mode like Figma, we can find even stronger tensions when it comes to harvesting data in favor of productivity gains.</p><p>A search feature relies on indexing your data. A recommendation feature relies on mining your browsing history. An autocomplete feature relies on what you (or other users) typed before.</p><p>All these potential features which are made possible through harvesting your user data are not available to privacy-preserving products. The user data isn't readable to them ‚Äî and that's the whole point.</p><p>This creates a trade-off from the user's perspective. Whatever your particular motivation might be, as soon as you opt for a privacy-preserving service you're opting for a service that is not able to read your data, and by extension, not able to harvest it. Because the harvesting of data is what is driving many of the improvements in productivity, in choosing to preserve user privacy, these services are forgoing their ability to provide additional gains in productivity.</p><p>Historically, as we saw with the origins of GPG, there has always been additional friction involved in replicating a workflow in a privacy-preserving manner. Although using e2e services such as Signal and ProtonMail has become nearly frictionless, they lack many features their non-privacy preserving counterparts offer.</p><h2>The productivity gap between privacy-preserving and non-preserving services</h2><p>If you compare the productivity gains between privacy-preserving and non-preserving products from the perspective of the user, it's hard not to arrive at the conclusion that there‚Äôs a gap between the two ‚Äî and it appears to be growing.</p><p>There is perhaps no better example of a feature which hinges on the ability to read user data than search. Although ProtonMail is reminiscent of Gmail in many ways, one area where it falls short is the absence of any ability to  search the contents of your emails. Search only works if the provider of such functionality can scan and index your content. It works even better if the provider is able to harvest search queries and use those to build predictive models (e.g. autocomplete and smart suggestions). These are features which make Gmail users more productive but aren't available to ProtonMail users <!-- -->[3]<!-- -->.</p><p>The absence of search might not be a dealbreaker for a ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jessems.com/productivity-vs-privacy">https://jessems.com/productivity-vs-privacy</a></em></p>]]>
            </description>
            <link>https://jessems.com/productivity-vs-privacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059205</guid>
            <pubDate>Wed, 11 Nov 2020 15:37:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Public Safety Announcement: The 2020 Election Is Not Over]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25059009">thread link</a>) | @lettergram
<br/>
November 11, 2020 | https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3754">

<div>
<p>I have been listening to my friends and family and am concerned that many are not aware of the election process. Having the presidential election flip from Democrat to Republican at this point can cause massive rioting, violence, etc.</p>
<p>We should all be aware of the current situation and the news outlets do not appear to be informing people.</p>
<blockquote><p><strong>Disclaimer</strong>: I‚Äôm am not pro-democrat or pro-republican. Personally, I believe neither party is fit to run the country.</p></blockquote>
<p>I wanted to share what appears to be the Republican strategy and why it‚Äôs possible (though still unlikely) Trump could win.</p>
<p>At time of writing Trump the betting markets have <a href="https://electionbettingodds.com/4hr.html" target="_blank" rel="noopener noreferrer">13% odds of winning the election</a> (odds calculated average from <a href="https://www.betfair.com/exchange/plus/politics">Betfair</a> and <a href="https://www.predictit.org/promo/electionbetting">PredictIt</a>).</p>
<p><a href="https://www.predictit.org/markets/detail/3698/Who-will-win-the-2020-US-presidential-election" target="_blank" rel="noopener noreferrer">PredictIt</a> currently has 16% odds of Trump winning:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" alt="" width="500" height="344" srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w" sizes="(max-width: 500px) 100vw, 500px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w"></a></p>
<h3>Biden is not Officially the President-Elect</h3>
<p>The president elect is determined by the electoral college or the General Services Administration (aka Trump conceding). That did not occur.</p>
<p>This is not uncommon, from <a href="https://en.wikipedia.org/wiki/President-elect_of_the_United_States" target="_blank" rel="noopener noreferrer">wikipedia</a>:</p>
<blockquote><p>The closest instance of there being no qualified person to take the presidential oath of office on Inauguration Day happened in 1877 when the disputed election between Rutherford B. Hayes and Samuel J. Tilden was decided and certified in Hayes‚Äô favor just three days before the inauguration (then March 4).</p></blockquote>
<h3>Evidence, Pending Review</h3>
<p>It takes time to build evidence. Last night on <a href="https://www.youtube.com/watch?v=7WzYTSwt18k" target="_blank" rel="noopener noreferrer">Fox News (Hannity, 11/10/2020)</a> the Republicans discussed some of the election (video may be removed, not on Fox News website).</p>
<p>The Republicans claim 11,000+ incident reports of vote manipulation, currently being vetted by attorneys. 250+ affidavits already signed, many have corroborating physical evidence, photos or additional witnesses (unclear how much). In a section below, some specific claims are covered.</p>
<h3>The Voting Recount Process</h3>
<ol>
<li>Affidavit is necessary to challenge some ballots</li>
<li>After canvassing, Republicans can request a recount</li>
<li>A judges in each county can review evidence (aka affidavits, photos, etc)</li>
<li>The judge can remove ballots (at random) based on evidence</li>
<li>Judgements can be challenged to a higher court</li>
<li>Recount occurs after ballots removed</li>
<li>IF it‚Äôs so wide spread or there‚Äôs a major error. The house or senate decide (or special elections), it depends on the State.</li>
<li>Electors vote on to December 14 and delivered December 23rd [<a href="https://crsreports.congress.gov/product/pdf/IF/IF11641">1</a>]</li>
</ol>
<h4>State Government Affiliation(s)</h4>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Pennsylvania_General_Assembly" target="_blank" rel="noopener noreferrer">PA</a>, <a href="https://en.wikipedia.org/wiki/Michigan_Legislature" target="_blank" rel="noopener noreferrer">MI</a>, <a href="https://en.wikipedia.org/wiki/Wisconsin_Legislature" target="_blank" rel="noopener noreferrer">WI</a> and <a href="https://en.wikipedia.org/wiki/Georgia_General_Assembly" target="_blank" rel="noopener noreferrer">GA</a> have a fairly large republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Arizona_State_Legislature" target="_blank" rel="noopener noreferrer">AZ</a> has a slight republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Nevada_Legislature" target="_blank" rel="noopener noreferrer">NV</a> has a large Democrat majority in both houses</li>
</ul>
<p>It‚Äôs also still possible the United States Supreme Court could still toss hundreds of thousands of ballots out of PA (Biden‚Äôs up by 40k)[<a href="https://www.washingtonexaminer.com/news/republican-state-attorneys-general-ask-supreme-court-to-take-up-pennsylvania-late-mail-in-ballot-case" target="_blank" rel="noopener noreferrer">2</a>].</p>
<h3>Affidavit Claims</h3>
<p>Selected claims on Fox / Hannity (on 11/10/2020):</p>
<p>1. There was a ‚Äúsoftware bug‚Äù in one jurisdiction, the exact same software was used in half of Michigan and multiple states. Only the one county noted the fix. They want to re-evaluate and manually recount in said counties. Code reviews requested.</p>
<p>2. Pennsylvania USPS (more than one) said the postal service was backdating ballots AND collecting ballots after the date (prior to back dating, i.e. they knew)</p>
<p>3. Michigan had a lot of dead people vote &gt;50 for one county, thus far that they‚Äôve found.</p>
<p>4. All the states have laws enabling the voting process to be accessible to the public, due to COVID-19 they limited public observers, particularly from independents. Legal challenges can occur, as that is against many states laws.</p>
<p>5. Democrat poll watchers were handing out pamphlets on ‚Äúhow to distract GOP poll watchers‚Äù</p>
<p>6. Poll watchers claim to have seen ballots with the same or no signatures be counted in Michigan</p>
<h3>Personal Opinion</h3>
<p>Personally, I believe this is the correct course of action. I‚Äôm not sure I believe all the claims.</p>
<p>However, I think it‚Äôs very important we challenge the votes, see where it falls and improve the Republic. Even if we do it after the election, it‚Äôs important we identify fraud and / or improve the process so this doesn‚Äôt happen again.</p>
<p>Unfortunately, the news media is not presenting this very well. I am concerned this will lead to a civil war. The Democratic party knows they are not officially the president elect, yet hold press conferences, that look like this‚Ä¶</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" alt="" width="792" height="530" srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w" sizes="(max-width: 792px) 100vw, 792px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w"></a>I‚Äôm not convinced this wont lead to violence. I‚Äôm concerned because it looks like <em>if the Democrats lose the election.</em> There will be a rival government setup. Several <a href="https://www.cnn.com/2020/11/07/americas/biden-global-reaction-election-intl/index.html" target="_blank" rel="noopener noreferrer">foreign powers have already acknowledged Biden as the victor</a>, for instance.</p>
<p>Personally, I just want a safe environment for my friends and family. I think most of us do.</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059009</guid>
            <pubDate>Wed, 11 Nov 2020 15:14:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to setup EKS on AWS with Terraform]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058923">thread link</a>) | @shuron
<br/>
November 11, 2020 | http://alexander.holbreich.org/eks-on-aws-with-terraform/ | <a href="https://web.archive.org/web/*/http://alexander.holbreich.org/eks-on-aws-with-terraform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <p>After setup of several kubernetes clusters i would like to share how we do it. I hope this helps people to get start with <a href="http://alexander.holbreich.org/tag/k8n/">kubernetes</a>. But also im keen to read your feedback and improvement proposals.</p>

<h3 id="whyterraform">Why Terraform</h3>

<p>From time to to time i do explore <a href="http://alexander.holbreich.org/tag/terrafrom/">terraform</a>, in log term since it appearence (See my exploration on <a href="http://alexander.holbreich.org/aws-automation/">AWS automation</a>). Basically i think this tool (as many other from Hashicorp) just had right idea to the right time. Let me explain: The nature of the IT infrastructure is more or less static. No surprize, that declarative approach is very situative here. And here terraform creators seem to have clear vision on this when they evolve terraform language design and elaborated tooling around it. Terraformes has become favorit tool for cloud resources provisioning in many teams.</p>

<p>Meanwhile the concept of "state" finally evolved and found place in new hashicorp <em>terraform cloud</em> (with free tier for small or mid-size projects). It's very convinient and impoves teamworking. Btw. i'm not affilatet with Hashicorp.</p>

<h2 id="bootstraping">Bootstraping</h2>

<p>Ok, how do i start with it. Well I usually start with AWS Sub Account for the project. It makes sence anyway especially if there is no connection to other projects or parts of your systems. See <a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_introduction.html">AWS Organization</a>. New Organization has at least one user whith enough rights. However for terraform i do addtional user 'terraform user' that has sufficient rights to create my enviroments. Basically i give him <code>AdministratorAccess</code></p>

<p>From this point on we can bootstrap terraform.  </p>

<h3 id="terrafomconfig">Terrafom config</h3>

<pre><code># See docu https://learn.hashicorp.com/tutorials/terraform/cloud-workspace-configure
provider "aws" {  
  region = "us-west-1" 
}

#https://www.terraform.io/docs/backends/types/remote.html
terraform {  
  backend "remote" {
    hostname = "app.terraform.io"
    organization = "YourOrga"

    workspaces {
      name = "your-aws-infa-workspace"
    }
  }
}
</code></pre>

<p>This is basically everything for bootstraping. </p>

<p>This setup assumes you have <code>aws-cli</code> installed and configured<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> on your development Maschine, meaning  your local terraform executions are able to conntect to AWS API. <br>
Secondly it assumes that terraform state will be hostet and terrafor cloud: <code>backend "remote"</code> </p>

<p>Provided configuration changes your local terrafom workspace to be the remote one.  </p>

<p>To be more specific. The terraform cloud can be operated in two ways:</p>

<ol>
<li>Hosting only your terrafrom state</li>
<li>Hosting state but also be single point of the change and the hostory of that change (full remote operations)</li>
</ol>

<p>Here i'm talking about the second scenario, where <code>terraform apply</code> is only possibly from the cloud UI only. Please also keep in mind that, when using terraform cloud, the <code>terraform plan</code> and other commands will use variable values from the associated Terraform Cloud workspace. So it's TF-Cloud where you should configure access to you AWS account with the secret key of your terraform IAM user or role. </p>

<p>To summ this up: You need an account at: <strong><a href="https://app.terraform.io/">https://app.terraform.io</a></strong> <br>
And you're can enable team-members not only participate in commiting terraform code, but also for provisioning the infrastruture, without sharing and maintaning admin credentials to the AWS cloud.</p>

<p>Last step is to setup a Workspace and connect your git repository with it. Now you can provision the Infrastructure. <br>
At the end your terraform rund of <code>terraform plan</code> and <code>terraform apply</code> will look something like this: <br>
<img src="http://alexander.holbreich.org/content/images/2020/09/terraform_cloud.png" alt="">
and <br>
<img src="http://alexander.holbreich.org/content/images/2020/09/terraform_cloud2.png" alt=""></p>

<h3 id="provisioningnetwork">Provisioning Network</h3>

<pre><code># VPC for kubernetes and all other cluster related resources

resource "aws_vpc" "main" {  
  cidr_block           = "10.100.0.0/16"
  enable_dns_support   = true
  enable_dns_hostnames = true

  tags = {
    Name      = "main"
    managedby = "terraform"
  }
}
</code></pre>

<p>The subnets. The number of your Subnets should correspond to the number of AZ in the Region.</p>

<pre><code>## ==== Kubernetes subnets =====

#us-west-2a
resource "aws_subnet" "eks_a" {  
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.100.1.0/24"
  availability_zone = "us-west-2a"
  map_public_ip_on_launch = true

  tags = {
    managedby                                          = "terraform"
    Name                                               = "EKS, AZ a"
    "kubernetes.io/cluster/${local.cluster_name}"      = "shared"
    "kubernetes.io/role/elb"                           = "1"
    "kubernetes.io/role/internal-elb"                  = "1"
  }
}

#us-west-2b
resource "aws_subnet" "eks_b" {  
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.100.2.0/24"
  availability_zone = "us-west-2b"
  map_public_ip_on_launch = true

  tags = {
    managedby                                          = "terraform"
    Name                                               = "EKS, AZ b"
    "kubernetes.io/cluster/${local.cluster_name}" = "shared"
    "kubernetes.io/role/elb"                           = "1"
    "kubernetes.io/role/internal-elb"                  = "1"
  }
}

#us-west-2c
resource "aws_subnet" "eks_c" {  
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.100.3.0/24"
  availability_zone = "us-west-2c"
  map_public_ip_on_launch = true

  tags = {
    managedby                                          = "terraform"
    Name                                               = "EKS, AZ c"
    "kubernetes.io/cluster/${local.cluster_name}" = "shared"
    "kubernetes.io/role/elb"                           = "1"
    "kubernetes.io/role/internal-elb"                  = "1"
  }

}
</code></pre>

<p>This is pretty forward, for details consult Terraform Docu on <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/subnet">Resource: aws_subnet</a>, for the kubernetes cluster the provided tags are of interest. <br>
The tags are used by AWS EKS to understand where to put <a href="https://docs.aws.amazon.com/eks/latest/userguide/load-balancing.html">automatically requested LoadBalancers</a>. <br>
ESK requires <a href="https://docs.aws.amazon.com/eks/latest/userguide/network_reqs.html#vpc-subnet-tagging">special subnet tagging</a> <br>
<code>kubernetes.io/role/elb</code> with cluster name. The rest of it is up to you and not much pitfalls here except: <code>map_public_ip_on_launch = true</code>. This is needed because in this scenario i use <em>public sub-nets</em>. EKS Master nodes are managed by AWS and are deployed outside of my VPC while workers inside my VPC need to accessed their masters. So they need to have public IP addresses. The Fine grane access to the worker nodes is defined by Security Groups later. If it not suitable for you there is more defensive option to use private Workers with <em>private sub-nets</em> (not covered here).</p>

<p>Well and while we establihing the communication with Public Addresses, in the AWS universum we need the <em>Internet Gateway</em>.  </p>

<pre><code>resource "aws_internet_gateway" "igw1" {  
  vpc_id = aws_vpc.main.id

  tags = {
    Name = "main-igw1"
    managedby         = "terraform"
  }
}

resource "aws_route" "route_to_igw1" {  
  route_table_id            = "rtb-someId" #haven't found better way than hardcoding so far.
  destination_cidr_block    = "0.0.0.0/0"
  gateway_id                =  aws_internet_gateway.igw1.id

}
</code></pre>

<p><br>
With that basic networking is in place and it's time for kubernetes.</p>

<h2 id="theekscluster">The EKS Cluster</h2>

<p>We have good experinces with the <a href="https://registry.terraform.io/modules/terraform-aws-modules/eks/aws/">official Terraform EKS module</a>. <br>
Later versions of it utilize special <em>terraform kubernetes provider</em> for the provisioning of cluster Users and roles. So my examples show it. </p>

<pre><code>## 1 Cluster Module starts here.

module "eks_cluster" {  
  source                 = "terraform-aws-modules/eks/aws"
  version                = "12.2.0"
  cluster_name           = "${local.cluster_name}"
  cluster_version        = "1.17"
  subnets                = ["${aws_subnet.eks_a.id}", "${aws_subnet.eks_b.id}", "${aws_subnet.eks_c.id}"]
  vpc_id                 = "${aws_vpc.main.id}"
  cluster_create_timeout = "30m" # need to increase module defaults
  write_kubeconfig       = false # Disabled permanent writing of config files
  providers = {
    # Reference to kuberntes provider, see below
    kubernetes = kubernetes.eks_cluster
  }

  manage_aws_auth = true //TODO enable it https://github.com/terraform-aws-modules/terraform-aws-eks/issues/699

  node_groups_defaults = {
    ami_type  = "AL2_x86_64" #alternative is e.g. AL2_x86_64_GPU
    disk_size = 50
  }


  node_groups = {
    # EKS managed Nodes group with name prefix "ram"
    ram = {
      desired_capacity = 3
      max_capacity     = 10
      min_capacity     = 1

      public_ip = true

      instance_type = "r5.large"
      #Labels for nodes and tags
      k8s_labels = {
        node_type = "default"
      }
      # Resource tags are not labels
      additional_tags = {
        managedby   = "terraform"
      }
    }
  }

  #Users
  # Can be checked with: kubectl describe configmap -n kube-system aws-auth
  map_users = [
    {
      userarn  = "${aws_iam_user.my_addtionaluser.arn}"
      username = "${aws_iam_user.my_addtionaluser.name}"
      groups   = ["system:masters"]
    }
  ]

  tags = {
    managedby   = "terraform"
  }
}

## Configuration of kubernetes provides starts here
data "aws_eks_cluster" "eks-cluster" {  
  name = module.eks_cluster.cluster_id
}

data "aws_eks_cluster_auth" "eks-cluster" {  
  name = module.eks_cluster.cluster_id
}

provider "kubernetes" {  
  host                   = data.aws_eks_cluster.eks-cluster.endpoint
  cluster_ca_certificate = base64decode(data.aws_eks_cluster.eks-cluster.certificate_authority.0.data)
  token                  = data.aws_eks_cluster_auth.eks-cluster.token
  load_config_file       = false
  alias   = "eks_cluster"
  version = "~&gt; 1.10"
}
</code></pre>

<p>I think this the configuration is more or less self-explanatory. <br>
It starts with EKS module, that takes a list of agruments like version, list of users and List of node groups with Details to machines inside of such group. <br>
Also reference to kubernetes provider is present. <br>
The configuration is the kubernetes provider has to be placed here but is basically reference to the cluster. See EKS Modul documentation for Details.</p>

<h2 id="alternatives">Alternatives</h2>

<p>Of course there are alternatives and you can exchange any of the tools here. Meanwile the EKS has evolved (and got a bit simlier) and also terraform *nativ" Resource <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/eks_cluster">eks_cluster</a> hase evolved. I'm interested in your experienced with it... ‚Ä¶</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://alexander.holbreich.org/eks-on-aws-with-terraform/">http://alexander.holbreich.org/eks-on-aws-with-terraform/</a></em></p>]]>
            </description>
            <link>http://alexander.holbreich.org/eks-on-aws-with-terraform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058923</guid>
            <pubDate>Wed, 11 Nov 2020 15:03:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You may not need Redis with Elixir]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058805">thread link</a>) | @wojtekmach
<br/>
November 11, 2020 | https://dashbit.co/blog/you-may-not-need-redis-with-elixir | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/you-may-not-need-redis-with-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> Jos√© Valim
  </li>
  <li>
    <i></i> November 11th, 2020
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/redis">redis</a>, <a href="https://dashbit.co/blog/tags/phoenix">phoenix</a>, <a href="https://dashbit.co/blog/tags/pubsub">pubsub</a>, <a href="https://dashbit.co/blog/tags/processes">processes</a>
  </li>
</ul>
<p>
If you have participated in a discussion about Elixir, you may have heard ‚Äúyou may not need Redis with Elixir‚Äù. Given that Redis has many use cases, this sentence may confuse developers as they try to match Elixir‚Äôs different features against Redis‚Äô capabilities. This article aims to explore different scenarios where the above is true, when they are not, and which trade-offs you may want to consider. We will discuss four cases:</p>
<ol>
  <li>
<a href="#post-pubsub">Distributed PubSub</a>  </li>
  <li>
<a href="#post-presence">Presence</a>  </li>
  <li>
<a href="#post-caching">Caching</a>  </li>
  <li>
<a href="#post-async">Asynchronous processing</a>  </li>
</ol>
<p>
Before we start, I want to emphasize we find Redis a fantastic piece of technology. This is not a critique of Redis but rather a discussion of the different options Elixir developers may have available.</p>
<h2 id="post-pubsub">
  Case #1: Distributed PubSub</h2>
<p>
The first scenario where you may not need Redis with Elixir is Distributed <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">PubSub</a>. Throughout this section, we will consider PubSub systems to provide <strong>at-most-once delivery</strong>: they broadcast events to the currently available subscribers. If a subscriber is not around, they won‚Äôt receive the message later.</p>
<p>
For this reason, PubSub systems are often paired with databases to offer persistence. For example, every time someone sends a message in a chat application, the system can save the contents to the database and then broadcast it to all users. This means everyone connected at a given moment sees the update immediately, but disconnected users can catch up later.</p>
<p>
Imagine that you have multiple nodes, and you want to exchange messages between said nodes. In Elixir, thanks to the Erlang VM, which ships with distribution support, this can be as simple as:</p>
<pre><code><span>for</span><span> </span><span>node</span><span> </span><span>&lt;-</span><span> </span><span>Node</span><span>.</span><span>list</span><span data-group-id="8737372369-1">(</span><span data-group-id="8737372369-1">)</span><span> </span><span data-group-id="8737372369-2">do</span><span>
  </span><span>send</span><span data-group-id="8737372369-3">(</span><span data-group-id="8737372369-4">{</span><span>:known_name</span><span>,</span><span> </span><span>node</span><span data-group-id="8737372369-4">}</span><span>,</span><span> </span><span>:hello_world</span><span data-group-id="8737372369-3">)</span><span>
</span><span data-group-id="8737372369-2">end</span></code></pre>
<p>
In <a href="https://github.com/phoenixframework/phoenix_pubsub/blob/master/lib/phoenix/pubsub.ex">200LOC or less</a>, you can implement a PubSub system that broadcasts to all subscribers within the same node or anywhere else in a cluster, without bringing any third-party tools. At best, you will need <a href="https://github.com/bitwalker/libcluster">libcluster</a> - an Elixir library - to establish the connection between the nodes based on some strategy (K8s, AWS, DNS, etc.).</p>
<p>
In other words, PubSub pretty much ships out of the box with Elixir. Technologies without distribution would need to rely on Redis PubSub, PostgreSQL Notifications, or similar to achieve the same.</p>
<p>
Of course, the above assumes your infrastructure allows you to directly establish connections between nodes, which may not be possible in some PaaS, such as Heroku. In those cases, you can use any of the technologies above (Phoenix <a href="https://dashbit.co/blog/github.com/phoenixframework/phoenix_pubsub_redis/">has a Redis adapter</a> for its PubSub), or alternatively use platforms, such as <a href="https://www.gigalixir.com/">Gigalixir</a>, that make it trivial to setup a cluster.</p>
<h2 id="post-presence">
  Case #2: Presence</h2>
<p>
Presence is the ability to track who is connected in a cluster right now ‚Äî the ‚Äúwho‚Äù may be users, phones, IoT devices, etc. For example, if Alice is connected to node A, she wants to see that Bob is also available, even if he has joined node B.</p>
<p>
Presence is one of the problems that are more complicated to implement than it sounds. For example, let‚Äôs consider implementing Presence by storing the connected entities in a database. However, what happens if a node crashes or leaves the cluster? Because the node crashed, all the users connected to it must be removed, but the node itself cannot do so. Therefore the other nodes need to detect those failure scenarios and act accordingly. But observing failures in a distributed system is also complicated: how do you differentiate between a temporarily unresponsive node from one that permanently failed?</p>
<p>
Another common approach to solve this problem is to frequently write to a database while users are connected. If you have seen no writes within a timeframe, you consider those users to be disconnected. However, such solutions have to choose between being write-intensive or inaccurate. For instance, let‚Äôs say that users become disconnected after 1 minute. This means that you need to write to the database every 1 minute for every user. If you have 10k users, that‚Äôs 167 writes per second, only to track that the users are connected. Meanwhile, the gap between a user leaving and having their status reflected in the UI is, in the worst-case scenario, also 1 minute. Any attempt at reducing the number of writes implies an increased gap.</p>
<p>
Given Elixir‚Äôs clustering support, we can once more implement <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Presence</a> without a need for third-party dependencies! We use a PubSub system to implement Presence, as we need to notify as users join and leave. Instead of relying on centralized storage, the nodes directly communicate and exchange information about who is around. This removes the need for frequent writes. When a user leaves, this is also reflected immediately.</p>
<p>
So while you can use Redis or another storage to provide Presence, Elixir can deliver a solution that is efficient and doesn‚Äôt require third-party tools.</p>
<h2 id="post-caching">
  Case #3: Caching</h2>
<p>
The solutions to previous cases were built on top of Erlang‚Äôs unique distribution capabilities. In the following sections, the distinguishing factor between needing Redis or not will be <strong>multi-core concurrency</strong>, so this discussion is more generally applicable. Therefore, when we say Elixir in this section, it will also apply to JVM, Go, and other environments. They will contrast to Ruby, Python, and Node.js, in which their primary runtimes do not provide adequate multi-core concurrency within a single Operating System process.</p>
<p>
Let‚Äôs start with the non-concurrent scenario. Consider you are building a web application in Ruby, Python, etc. To deploy it, you get two eight-core machines. In languages that do not provide satisfactory multi-core concurrency, a common option for deployment is to start 8 instances of your web application, one per core, on each node. Overall, you will have CxN instances, where C is the number of cores, and N is the number of nodes.</p>
<p>
Now consider a particular operation in this application that is expensive, and you want to cache its results. The easiest solution, regardless of your programming environment, is to cache it in memory. However, given we have 16 instances of this application, caching it in memory is suboptimal: we will have to perform this expensive operation at least 16 times, one for each instance. For this reason, it is widespread to use Redis, Memcached, or similar for caching in environments like Ruby, Python, etc. With Redis, you would cache it only once, and it will be shared across all instances. The trade-off is that we are replacing memory access by a network round-trip, and the latter is orders of magnitude more expensive.</p>
<p>
Now let‚Äôs consider environments with multi-core concurrency. In languages like Elixir, you start one instance per node, regardless of the number of cores, since the runtime will share memory and efficiently spread the work across all cores. When it comes to caching, keeping the cache in-memory is a much more affordable scenario, as you will only have to compute once per node. Therefore, you have the <em>option</em> to skip Redis or Memcached altogether and avoid network round-trip.</p>
<p>
Of course, this depends on how many nodes you are effectively running in production. Luckily, many companies report being able to <a href="https://dev.to/erlangsolutions/why-elixir-is-the-programming-language-you-should-learn-in-2020-5g00">run Elixir with an order of magnitude less nodes</a> than technologies they have migrated from.</p>
<p>
You can also choose a mixed approach and store the cache both in-memory and in Redis. First, you look up in memory and, if missing, you fallback to Redis. If unavailable in both, then you execute the operation and cache it in each. The critical part to highlight here is that multi-core environments give you more flexibility to tackle these problems while reducing resource utilization. In Elixir/Erlang, you can also keep the cache in memory and use PubSub to distribute it across nodes. You can see this last approach in action <a href="https://github.com/tompave/fun_with_flags">in the excellent FunWithFlags library</a>.</p>
<p>
Another trade-off to consider is that all in-memory cache will be gone once you deploy new nodes. Therefore, if you need data to persist across deployments, you will want to use Redis as a cache layer, as detailed above, or dump the cache in a storage, such as database, S3, or Redis, before each deployment.</p>
<h2 id="post-async">
  Case #4: Asynchronous processing</h2>
<p>
Another scenario you may not need Redis in Elixir is to perform asynchronous processing. Let‚Äôs continue the discussion from the previous case.</p>
<p>
In environments without or with limited multi-core concurrency, given each instance is assigned to one core, they are limited in their ability to handle requests concurrently. This has led to a common saying that ‚Äúyou should avoid blocking the main thread‚Äù. For example, imagine that your application has to deliver emails on sign up or generate some computationally expensive reports. While one of your 16 web instances is doing this, it cannot handle other incoming requests efficiently. For this reason, a common choice here is to move the work elsewhere, typically a background-job processing queue. First, you store the work to be done on Redis or similar. Then one of the 16 web instances (or more commonly a completely different set of workers) grabs it from the queue.</p>
<p>
In multi-core concurrent environments, requests can be handled concurrently regardless if they are doing CPU or IO work. Sending the email from the request itself won‚Äôt block other requests. Generating the report is not a problem, as requests can be served by other CPUs. These platforms typically get assigned as many requests as they can handle and they distribute the work over the machine resources. Even if you prefer to deliver emails outside of the request, in order to send an earlier response to users, you can spawn an asynchronous worker without a need to move the delivery to an external queue or to another machine. Once again, concurrency gives us a more straightforward option to tackle these scenarios.</p>
<p>
Note the Erlang VM takes care of multiplexing CPU and IO work without a need for developers to tag functions as async or similar. Workers in Erlang/Elixir are ‚Ä¶</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/you-may-not-need-redis-with-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058805</guid>
            <pubDate>Wed, 11 Nov 2020 14:48:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Systematically removing code]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 44 (<a href="https://news.ycombinator.com/item?id=25058632">thread link</a>) | @jerodsanto
<br/>
November 11, 2020 | https://thepugautomatic.com/2020/11/systematically-removing-code/ | <a href="https://web.archive.org/web/*/https://thepugautomatic.com/2020/11/systematically-removing-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><hgroup><p><span>Written November 8, 2020. <span>Tagged <a href="https://thepugautomatic.com/tag/methodology">Methodology</a>.</span></span></p></hgroup><div><p>It's easy to miss things when removing code, leaving behind unused methods, templates, CSS classes or translation keys. (Especially in a dynamic language like Ruby, without a compiler to help you spot dead code.)</p><p>I avoid this by removing code systematically, line by line, depth-first.</p><p>This is one of those things that seems obvious when you do it, but in my experience, many people do it haphazardly.</p><p>Say we wanted to remove the "item box" from this page:</p><p>page.html.erb</p><pre><code><span><span><span>&lt;</span>p</span><span>&gt;</span></span>Welcome to my page!<span><span><span>&lt;/</span>p</span><span>&gt;</span></span><p><span><span>&lt;%=</span> render<span>(</span><span>"item_box"</span><span>,</span> item<span>:</span> item<span>)</span> <span>%&gt;</span></span></p></code></pre><p>_item_box.html.erb</p><pre><code><span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>box box--fancy<span>"</span></span><span>&gt;</span></span><br>  <span><span><span>&lt;</span>h2</span><span>&gt;</span></span><span><span>&lt;%=</span> item<span>.</span>title <span>%&gt;</span></span><span><span><span>&lt;/</span>h2</span><span>&gt;</span></span><br>  <span><span>&lt;%=</span> format_description<span>(</span>item<span>.</span>description<span>)</span> <span>%&gt;</span></span><br>  <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span><span>&lt;%=</span> <span>I18n</span><span>.</span>translate<span>(</span><span>"my.translation.key"</span><span>)</span> <span>%&gt;</span></span><br><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre><p>So our end goal is to remove the <code>&lt;%= render("item_box", item: item) %&gt;</code> line.</p><p>First, we search the project to check that <code>_item_box.html.erb</code> isn't used somewhere else, or referenced in docs that we'll need to update. It isn't, so we're OK to remove it ‚Äì but before we do that, we must go through it line by line.</p><p>The first line is <code>&lt;div class="box box--fancy"&gt;</code>. So we search the project for these two CSS classes, checking if they're in use somewhere else. If not, we remove them from the CSS files.</p><p>We go deeper if required ‚Äì perhaps the CSS for <code>.box--fancy</code> uses a CSS variable. Then we check if that variable is in use elsewhere. <a href="https://thepugautomatic.com/2014/03/stacked-vim-searches-down-cold/">Stacked searches in Vim</a> are helpful here.</p><p>Once we've checked a line in the file, we delete that line. This helps us keep track of what we've already checked.</p><p>So after we've checked and removed that line, we're left with</p><p>_item_box.html.erb</p><pre><code>  <span><span><span>&lt;</span>h2</span><span>&gt;</span></span><span><span>&lt;%=</span> item<span>.</span>title <span>%&gt;</span></span><span><span><span>&lt;/</span>h2</span><span>&gt;</span></span><br>  <span><span>&lt;%=</span> format_description<span>(</span>item<span>.</span>description<span>)</span> <span>%&gt;</span></span><br>  <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span><span>&lt;%=</span> <span>I18n</span><span>.</span>translate<span>(</span><span>"my.translation.key"</span><span>)</span> <span>%&gt;</span></span><br><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre><p>And we continue this way, line by line. Is the <code>item.title</code> used elsewhere? If not, we should probably remove it, too. What about <code>format_description</code>, <code>item.description</code>, the <code>my.translation.key</code> translation key?</p><p>Again, we go deeper if required, not removing the <code>format_description</code> method until we've gone through <em>it</em> line by line.</p><p>When we've looked at every line in <code>_item_box.html.erb</code> and deleted them as we went, the file will be empty, and we can start popping the stack.</p><p>We remove the empty <code>_item_box.html.erb</code> file.</p><p>And we can finally remove the <code>&lt;%= render("item_box", item: item) %&gt;</code> line, fairly confident that we didn't leave dead code behind.</p><p>This probably sounds more tedious than it is. It tends to be quick work, and you can take shortcuts ‚Äì removing a swathe of lines that don't reference anything else, or that only call methods that you know are used elsewhere.</p></div></section></div><div><p>Content and design ¬© <a href="https://henrik.nyh.se/">Henrik Nyh</a> (<a href="https://twitter.com/henrik">@henrik</a>). Code is under a <a href="http://en.wikipedia.org/wiki/MIT_License">MIT License</a> unless otherwise stated.</p><p>Pug art by <a href="https://johannaost.com/">Johanna √ñst</a>; other graphics are under a <a href="http://creativecommons.org/licenses/by/3.0/">CC BY License</a>.</p><p>Powered by <a href="https://11ty.dev/">Eleventy</a>.</p></div></div>]]>
            </description>
            <link>https://thepugautomatic.com/2020/11/systematically-removing-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058632</guid>
            <pubDate>Wed, 11 Nov 2020 14:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Linear Algebra for Applied Machine Learning with Python]]>
            </title>
            <description>
<![CDATA[
Score 380 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25058619">thread link</a>) | @Anon84
<br/>
November 11, 2020 | https://pabloinsente.github.io/intro-linear-algebra | <a href="https://web.archive.org/web/*/https://pabloinsente.github.io/intro-linear-algebra">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        
<!-- https://docs.mathjax.org/en/latest/configuration.html#local-config-files -->




<article>
  <h2>Introduction to Linear Algebra for Applied Machine Learning with Python</h2>
  <time datetime="2020-05-26T00:00:00+00:00">26 May 2020</time>
  

  

<p>Linear algebra is to machine learning as flour to bakery: <strong>every machine learning model is based in linear algebra, as every cake is based in flour</strong>. It is not the only ingredient, of course. Machine learning models need vector calculus, probability, and optimization, as cakes need sugar, eggs, and butter. Applied machine learning, like bakery, is essentially about combining these mathematical ingredients in clever ways to create useful (tasty?) models.</p>

<p>This document contains <strong>introductory level linear algebra notes for applied machine learning</strong>. It is meant as a reference rather than a comprehensive review. If you ever get confused by matrix multiplication, don‚Äôt remember what was the $L_2$ norm, or the conditions for linear independence, this can serve as a quick reference. It also a good introduction for people that don‚Äôt need a deep understanding of linear algebra, but still want to learn about the fundamentals to read about machine learning or to use pre-packaged machine learning solutions. Further, it is a good source for people that learned linear algebra a while ago and need a refresher.</p>

<p>These notes are based in a series of (mostly) freely available textbooks, video lectures, and classes I‚Äôve read, watched and taken in the past. If you want to obtain a deeper understanding or to find exercises for each topic, you may want to consult those sources directly.</p>

<p><strong>Free resources</strong>:</p>

<ul>
  <li><strong>Mathematics for Machine Learning</strong> by Deisenroth, Faisal, and Ong. 1st Ed. <a href="https://mml-book.github.io/">Book link</a>.</li>
  <li><strong>Introduction to Applied Linear Algebra</strong> by Boyd and Vandenberghe. 1sr Ed. <a href="http://vmls-book.stanford.edu/">Book link</a></li>
  <li><strong>Linear Algebra Ch. in Deep Learning</strong> by Goodfellow, Bengio, and Courville. 1st Ed. <a href="https://www.deeplearningbook.org/contents/linear_algebra.html">Chapter link</a>.</li>
  <li><strong>Linear Algebra Ch. in Dive into Deep Learning</strong> by Zhang, Lipton, Li, And Smola. <a href="https://d2l.ai/chapter_preliminaries/linear-algebra.html">Chapter link</a>.</li>
  <li><strong>Prof. Pavel Grinfeld‚Äôs Linear Algebra Lectures</strong> at Lemma. <a href="https://www.lem.ma/books/AIApowDnjlDDQrp-uOZVow/landing">Videos link</a>.</li>
  <li><strong>Prof. Gilbert Strang‚Äôs Linear Algebra Lectures</strong> at MIT. <a href="https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/">Videos link</a>.</li>
  <li><strong>Salman Khan‚Äôs Linear Algebra Lectures</strong> at Khan Academy. <a href="https://www.khanacademy.org/math/linear-algebra">Videos link</a>.</li>
  <li><strong>3blue1brown‚Äôs Linear Algebra Series</strong> at YouTube. <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Videos link</a>.</li>
</ul>

<p><strong>Not-free resources</strong>:</p>

<ul>
  <li><strong>Introduction to Linear Algebra</strong> by Gilbert Strang. 5th Ed. <a href="https://www.amazon.com/Introduction-Linear-Algebra-Gilbert-Strang/dp/0980232775">Book link</a>.</li>
  <li><strong>No Bullshit Guide to Linear Algebra</strong> by Ivan Savov. 2nd Ed. <a href="https://www.amazon.com/No-bullshit-guide-linear-algebra/dp/0992001021">Book Link</a>.</li>
</ul>

<p>I‚Äôve consulted all these resources at one point or another. Pavel Grinfeld‚Äôs lectures are my absolute favorites. Salman Khan‚Äôs lectures are really good for absolute beginners (they are long though). The famous 3blue1brown series in linear algebra is delightful to watch and to get a solid high-level view of linear algebra.</p>

<p>If you have to pic one book, I‚Äôd pic <strong>Boyd‚Äôs and Vandenberghe‚Äôs Intro to applied linear algebra</strong>, as it is the most beginner friendly book on linear algebra I‚Äôve encounter. Every aspect of the notation is clearly explained and pretty much all the key content for applied machine learning is covered. The Linear Algebra Chapter in Goodfellow et al is a nice and concise introduction, but it may require some previous exposure to linear algebra concepts. Deisenroth et all book is probably the best and most comprehensive source for linear algebra for machine learning I‚Äôve found, although it assumes that you are good at reading math (and at math more generally). Savov‚Äôs book it‚Äôs also great for beginners but requires time to digest. Professor Strang lectures are great too but I won‚Äôt recommend it for absolute beginners.</p>

<p>I‚Äôll do my best to keep notation consistent. Nevertheless, learning to adjust to changing or inconsistent notation is a useful skill, since most authors will use their own preferred notation, and everyone seems to think that its/his/her own notation is better.</p>

<p>To make everything more dynamic and practical, I‚Äôll introduce bits of Python code to exemplify each mathematical operation (when possible) with <code>NumPy</code>, which is the facto standard package for scientific computing in Python.</p>

<p>Finally, keep in mind this is created by a non-mathematician for (mostly) non-mathematicians. I wrote this as if I were talking to myself or a dear friend, which explains why my writing is sometimes conversational and informal.</p>

<p>If you find any mistake in notes feel free to reach me out at pcaceres@wisc.edu and to https://pablocaceres.org/ so I can correct the issue.</p>



<p><strong>Note:</strong> <em>underlined sections</em> are the newest sections and/or corrected ones.</p>

<p><strong><a href="#preliminary-concepts">Preliminary concepts</a></strong>:</p>
<ul>
  <li><a href="#sets">Sets</a></li>
  <li><a href="#belonging-and-inclusion">Belonging and inclusion</a></li>
  <li><a href="#set-specification">Set specification</a></li>
  <li><a href="#ordered-pairs">Ordered pairs</a></li>
  <li><a href="#relations">Relations</a></li>
  <li><a href="#functions">Functions</a></li>
</ul>

<p><strong><a href="#vectors">Vectors</a></strong>:</p>
<ul>
  <li><a href="#types-of-vectors">Types of vectors</a>
    <ul>
      <li><a href="#geometric-vectors">Geometric vectors</a></li>
      <li><a href="#polynomials">Polynomials</a></li>
      <li><a href="#elements-of-r">Elements of R</a></li>
    </ul>
  </li>
  <li><a href="#zero-vector-unit-vector-and-sparse-vector">Zero vector, unit vector, and sparse vector</a></li>
  <li><a href="#vector-dimensions-and-coordinate-system">Vector dimensions and coordinate system</a></li>
  <li><a href="#basic-vector-operations">Basic vector operations</a>
    <ul>
      <li><a href="#vector-vector-addition">Vector-vector addition</a></li>
      <li><a href="#vector-scalar-multiplication">Vector-scalar multiplication</a></li>
      <li><a href="#linear-combinations-of-vectors">Linear combinations of vectors</a></li>
      <li><a href="#vector-vector-multiplication-dot-product">Vector-vector multiplication: dot product</a></li>
    </ul>
  </li>
  <li><a href="#vector-space-span-and-subspace">Vector space, span, and subspace</a>
    <ul>
      <li><a href="#vector-space">Vector space</a></li>
      <li><a href="#vector-span">Vector span</a></li>
      <li><a href="#vector-subspaces">Vector subspaces</a></li>
    </ul>
  </li>
  <li><a href="#linear-dependence-and-independence">Linear dependence and independence</a></li>
  <li><a href="#vector-null-space">Vector null space</a></li>
  <li><a href="#vector-norms">Vector norms</a>
    <ul>
      <li><a href="#euclidean-norm">Euclidean norm: $L_2$</a></li>
      <li><a href="#manhattan-norm">Manhattan norm: $L_1$</a></li>
      <li><a href="#max-norm">Max norm: $L_\infty$</a></li>
    </ul>
  </li>
  <li><a href="#vector-inner-product-length-and-distance">Vector inner product, length, and distance</a></li>
  <li><a href="#vector-angles-and-orthogonality">Vector angles and orthogonality</a></li>
  <li><a href="#systems-of-linear-equations">Systems of linear equations</a></li>
</ul>

<p><strong><a href="#matrices">Matrices</a></strong>:</p>

<ul>
  <li><a href="#basic-matrix-operations">Basic matrix operations</a>
    <ul>
      <li><a href="#matrix-matrix-addition">Matrix-matrix addition</a></li>
      <li><a href="#matrix-scalar-multiplication">Matrix-scalar multiplication</a></li>
      <li><a href="#matrix-vector-multiplication-dot-product">Matrix-vector multiplication: dot product</a></li>
      <li><a href="#matrix-matrix-multiplication">Matrix-matrix multiplication</a></li>
      <li><a href="#matrix-identity">Matrix identity</a></li>
      <li><a href="#matrix-inverse">Matrix inverse</a></li>
      <li><a href="#matrix-transpose">Matrix transpose</a></li>
      <li><a href="#hadamard-product">Hadamard product</a></li>
    </ul>
  </li>
  <li><a href="#special-matrices">Special matrices</a>
    <ul>
      <li><a href="#rectangular-matrix">Rectangular matrix</a></li>
      <li><a href="#square-matrix">Square matrix</a></li>
      <li><a href="#diagonal-matrix">Diagonal matrix</a></li>
      <li><a href="#upper-triangular-matrix">Upper triangular matrix</a></li>
      <li><a href="#lower-triangular-matrix">Lower triangular matrix</a></li>
      <li><a href="#symmetric-matrix">Symmetric matrix</a></li>
      <li><a href="#identity-matrix">Identity matrix</a></li>
      <li><a href="#scalar-matrix">Scalar matrix</a></li>
      <li><a href="#null-or-zero-matrix">Null or zero matrix</a></li>
      <li><a href="#echelon-matrix">Echelon matrix</a></li>
      <li><a href="#antidiagonal-matrix">Antidiagonal matrix</a></li>
      <li><a href="#design-matrix">Design matrix</a></li>
    </ul>
  </li>
  <li><a href="#matrices-as-systems-of-linear-equations">Matrices as systems of linear equations</a></li>
  <li><a href="#the-four-fundamental-matrix-subsapces">The four fundamental matrix subsapces</a>
    <ul>
      <li><a href="#the-column-space">The column space</a></li>
      <li><a href="#the-row-space">The row space</a></li>
      <li><a href="#the-null-space">The null space</a></li>
      <li><a href="#the-null-space-of-the-transpose">The null space of the transpose</a></li>
    </ul>
  </li>
  <li><a href="#solving-systems-of-linear-equations-with-matrices">Solving systems of linear equations with matrices</a>
    <ul>
      <li><a href="#gaussian-elimination">Gaussian Elimination</a></li>
      <li><a href="#gauss-jordan-elimination">Gauss-Jordan Elimination</a></li>
    </ul>
  </li>
  <li><a href="#matrix-basis-and-rank">Matrix basis and rank</a></li>
  <li><a href="#matrix-norm">Matrix norm</a></li>
</ul>

<p><strong><a href="#linear-and-affine-mappings">Linear and affine mappings</a></strong>:</p>

<ul>
  <li><a href="#linear-mappings">Linear mappings</a></li>
  <li><a href="#examples-of-linear-mappings">Examples of linear mappings</a>
    <ul>
      <li><a href="#negation-matrix">Negation matrix</a></li>
      <li><a href="#reversal-matrix">Reversal matrix</a></li>
    </ul>
  </li>
  <li><a href="#examples-of-nonlinear-mappings">Examples of nonlinear mappings</a>
    <ul>
      <li><a href="#norms">Norms</a></li>
      <li><a href="#translation">Translation</a></li>
    </ul>
  </li>
  <li><a href="#affine-mappings">Affine mappings</a>
    <ul>
      <li><a href="#affine-combination-of-vectors">Affine combination of vectors</a></li>
      <li><a href="#affine-span">Affine span</a></li>
      <li><a href="#affine-space-and-subspace">Affine space and subspace</a></li>
      <li><a href="#affine-mappings-using-the-augmented-matrix">Affine mappings using the augmented matrix</a></li>
    </ul>
  </li>
  <li><a href="#special-linear-mappings">Special linear mappings</a>
    <ul>
      <li><a href="#scaling">Scaling</a></li>
      <li><a href="#reflection">Reflection</a></li>
      <li><a href="#shear">Shear</a></li>
      <li><a href="#rotation">Rotation</a></li>
    </ul>
  </li>
  <li><a href="#projections">Projections</a>
    <ul>
      <li><a href="#projections-onto-lines">Projections onto lines</a></li>
      <li><a href="#projections-onto-general-subspaces">Projections onto general subspaces</a></li>
      <li><a href="#projections-as-approximate-solutions-to-systems-of-linear-equations">Projections as approximate solutions to systems of linear equations</a></li>
    </ul>
  </li>
</ul>

<p><strong><a href="#matrix-decompositions">Matrix decompositions</a></strong>:</p>
<ul>
  <li><a href="#lu-decomposition">LU decomposition</a>
    <ul>
      <li><a href="#elementary-matrices">Elementary matrices</a></li>
      <li><a href="#the-inverse-of-elementary-matrices">The inverse of elementary matrices</a></li>
      <li><a href="#lu-decomposition-as-gaussian-elimination">LU decomposition as Gaussian Elimination</a></li>
      <li><a href="#lu-decomposition-with-pivoting">LU decomposition with pivoting</a></li>
    </ul>
  </li>
  <li><a href="#qr-decomposition">QR decomposition</a>
    <ul>
      <li><a href="#orthonormal-basis">Orthonormal basis</a></li>
      <li><a href="#orthonormal-basis-transpose">Orthonormal basis transpose</a></li>
      <li><a href="#gram-schmidt-orthogonalization">Gram-Schmidt Orthogonalization </a></li>
      <li><a href="#qr-decomposition-as-gram-schmidt-orthogonalization">QR decomposition as Gram-Schmidt Orthogonalization</a></li>
    </ul>
  </li>
  <li><a href="#determinant">Determinant</a>
    <ul>
      <li><a href="#determinant-as-measures-of-volume">Determinant as measures of volume</a></li>
      <li><a href="#the-2-x-2-determinant">The 2X2 determinant</a></li>
      <li><a href="#the-n-x-n-determinant">The NXN determinant</a></li>
      <li><a href="#determinants-as-scaling-factors">Determinants as scaling factors</a></li>
      <li><a href="#the-importance-of-determinants">The importance of determinants</a></li>
    </ul>
  </li>
  <li><a href="#eigenthings">Eigenthings</a>
    <ul>
      <li><a href="#change-of-basis">Change of basis</a></li>
      <li><a href="#eigenvectors-eigenvalues-and-eigenspaces">Eigenvectors, Eigenvalues, and Eigenspaces</a></li>
      <li><a href="#trace-and-determinant-with-eigenvalues">Trace and determinant with eigenvalues</a></li>
      <li><a href="#eigendecomposition">Eigendecomposition</a></li>
      <li><a href="#eigenbasis-are-a-good-basis">Eigenbasis are a good basis</a></li>
      <li><a href="#geometric-interpretation-of-eigendecomposition">Geometric interpretation of Eigendecomposition</a></li>
      <li><a href="#the-problem-with-eigendecomposition">The problem with Eigendecomposition</a></li>
    </ul>
  </li>
  <li><a href="#singular-value-decomposition">Singular Value Decomposition</a>:
    <ul>
      <li><a href="#singular-value-decomposition-theorem">Singular Value Decomposition Theorem</a></li>
      <li><a href="#singular-value-decomposition-computation">Singular Value Decomposition computation</a></li>
      <li><a href="#geometric-interpretation-of-the-singular-value-decomposition">Geometric interpretation of the Singular Value Decomposition</a></li>
      <li><a href="#singular-value-decomposition-vs-eigendecomposition">Singular Value Decomposition vs Eigendecomposition</a></li>
    </ul>
  </li>
  <li><a href="#matrix-approximation">Matrix Approximation</a>:
    <ul>
      <li><a href="#best-rank-k-approximation-with-svd">Best rank-k approximation with SVD</a></li>
      <li><a href="#best-low-rank-approximation-as-a-minimization-problem">Best low-rank approximation as a minimization problem</a></li>
    </ul>
  </li>
</ul>

<p><strong><a href="#epilogue">Epilogue</a></strong></p>



<p>While writing about linear mappings, I realized the importance of having a basic understanding of a few concepts before approaching the study of linear algebra. If you are like me, you may not have formal mathematical training beyond high school. If so, I encourage you to read this section and spent some time wrapping your head around these concepts before going over the linear algebra content (otherwise, you might prefer to skip this part). I believe that reviewing these concepts is of great help to understand the <em>notation</em>, which in my experience is one of the main barriers to understand mathematics for nonmathematicians: we are <em>non</em>native speakers, so we are continuously building up our vocabulary. I‚Äôll keep this section very short, as is not the focus of this mini-course.</p>

<p>For this section, my notes are based on readings of:</p>

<ul>
  <li><strong>Geometric transformations (Vol. 1)</strong> (1966) by Modenov &amp; Parkhomenko</li>
  <li><strong>Naive Set Theory</strong> (1960) by P.R. Halmos</li>
  <li><strong>Abstract Algebra: Theory and Applications</strong> (2016) by Judson &amp; Beeer. <a href="http://abstract.pugetsound.edu/download/aata-20160809.pdf">Book link</a></li>
</ul>

<h2 id="sets">Sets</h2>

<p>Sets are one of the most fundamental concepts in mathematics. They are so fundamental that they are not defined in terms of anything else. On the contrary, other branches of mathematics are defined in terms of sets, including linear algebra. Put simply, <strong>sets are well-defined collections of objects</strong>. Such objects are called <strong>elements or members</strong> of the set. The crew of a ship, a caravan of camels, and the LA Lakers roster, are all examples of sets. The captain of the ship, the first camel in the caravan, and LeBron James are all examples of ‚Äúmembers‚Äù or ‚Äúelements‚Äù of their corresponding sets. We denote a set with an upper case italic letter as $\textit{A}$. In the context of linear algebra, we say that a line is a set of points, and the set of all lines in the plane is a set of sets. Similarly, we can say that <em>vectors</em> are sets of points, and <em>matrices</em> sets of vectors.</p>

<h2 id="belonging-and-inclusion">Belonging and inclusion</h2>

<p>We build sets using the notion of <strong>belonging</strong>. We denote that $a$ <em>belongs</em> (or is an <em>element</em> or <em>member</em> of) to $\textit{A}$ with the Greek letter epsilon as:</p>



<p>Another important idea is <strong>inclusion</strong>, which allow us to build <em>subsets</em>. Consider sets $\textit{A}$ and $\textit{B}$. When every element of $\textit{A}$ is an element of $\textit{B}$, we say that $\textit{A}$ is a <em>subset</em> of $\textit{B}$, or that $\textit{B}$ <em>includes</em> $\textit{A}$. The notation is:</p>



<p>or</p>



<p>Belonging and inclusion are derived from <strong>axion of extension</strong>: <em>two sets are equal if and only if they have the same elements</em>. This axiom may sound trivially obvious but is necessary to make belonging and ‚Ä¶</p></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pabloinsente.github.io/intro-linear-algebra">https://pabloinsente.github.io/intro-linear-algebra</a></em></p>]]>
            </description>
            <link>https://pabloinsente.github.io/intro-linear-algebra</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058619</guid>
            <pubDate>Wed, 11 Nov 2020 14:24:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Retention Revenue Is Important in SaaS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058588">thread link</a>) | @randrews543
<br/>
November 11, 2020 | https://talkinsaasy.com/blog/why-retention-revenue-is-important-in-saas | <a href="https://web.archive.org/web/*/https://talkinsaasy.com/blog/why-retention-revenue-is-important-in-saas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5fab3ba5a829a03e790cfc93"><div><div><div data-block-type="2" id="block-83f2beced4fc56fd9669"><div><p>Retention Revenue is the measure of how much revenue is left over after a startup has retained their customer month-to-month. It‚Äôs an important metric for subscription startups to calculate in order to understand their true CAC payback and profitability, so how do we get there?</p><p>First you take topline revenue, or the total amount of all of the subscriptions paid to you in that month. First you will want to calculate your gross revenue which is your total revenue minus your CORS (cost of revenue sold) which is typically hosting costs for software/tech companies, for services or physical goos this is more complicated, but the formula for Gross Revenue is below:</p><ul data-rte-list="default"><li><p><strong>Gross Revenue = Revenue - Cost of Goods Sold</strong></p></li></ul><p>After finding Gross Revenue we can now calculate our Retention Revenue. To get retention revenue you need to find your cost of servicing, marketing and success for your existing customer each month. Similar to how you calculate CAC by adding up sales and marketing costs.</p><p>You will wan to add up the cost of your customer success, customer service teams and customer marketing expenses to get your ‚Äúretention expense‚Äù which is the cost that you had to incur to keep your customers (and their revenue). The formula to then calculate retention revenue is as follows:</p><ul data-rte-list="default"><li><p><strong>Retention Revenue = Gross Revenue - Customer Service Costs- Customer Success Costs - Customer Marketing Costs</strong></p></li></ul><p>Retention Revenue is the take how revenue at the end of the month after you have kept your customers. Using retention revenue is a more accurate way to understand the profitability. While there are other operating expenses that fall outside of the above retention expenses, on a per customer basis that is the best way for a startup, particularly one with recurring revenue, to understand your unit economics.</p><p>Think about a startup with a $2,500 CAC and a customer with a MRR of $300, that is a CAC Payback period of 8.3 months which is pretty good. But if we calculate their retention revenue that same customer only generates $180 in take home revenue at the end of the month making that CAC payback closer to 14 months. Now that might seem like a negative, but what this reveals us is an opportunity. We now have multiple levers to pull to drive towards profitability and sustainable growth. Maybe you do an analysis and realize you could automate the most common customer service requests and drive down your retention costs. Maybe you highlight your idea customer and tailor marketing messaging to drive down CAC. You can always upsell/add new features to increase your average monthly revenue as well.</p><p>A lot of early-stage SaaS companies avoid digging this deep for fear of the initial negative picture it paints. But the reporting economics off of top-line revenue actually can hurt growth long term and limits your visibility into growth levers and operational efficiency. Take the time to drill down to retention level metrics and you uncover a path to growth and sustainability for your startup.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://talkinsaasy.com/blog/why-retention-revenue-is-important-in-saas</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058588</guid>
            <pubDate>Wed, 11 Nov 2020 14:21:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Off-BRAND ‚Äì A high-fashion brand, a local ice cream shop and IP]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058570">thread link</a>) | @VegetableArmy
<br/>
November 11, 2020 | https://www.legallyinsightful.com/2020/11/off-brand-how-high-fashion-brand-and.html | <a href="https://web.archive.org/web/*/https://www.legallyinsightful.com/2020/11/off-brand-how-high-fashion-brand-and.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h3>
OFF-BRAND - How a high-fashion brand and a local ice cream shop have come to blows over intellectual property
</h3>
</div><div>
<div id="post-body-4397561652220542783">
<h2><span>How a high-fashion brand and an ice cream shop have come to blows over intellectual property</span></h2><div><p><a href="https://1.bp.blogspot.com/-M9DU9zcfGEM/X6vx7TBn83I/AAAAAAAA5Uc/FcCL5fs2b-wqCxNbl6Evh7ZG5F0TgOaTACLcBGAsYHQ/s1920/ice%2Bcream.jpg"><img data-original-height="1281" data-original-width="1920" height="291" src="https://1.bp.blogspot.com/-M9DU9zcfGEM/X6vx7TBn83I/AAAAAAAA5Uc/FcCL5fs2b-wqCxNbl6Evh7ZG5F0TgOaTACLcBGAsYHQ/w435-h291/ice%2Bcream.jpg" width="435"></a></p></div><p><span data-preserver-spaces="true">In the various industries that are out there, not too many are as different as fashion and ice cream. One is involved in providing happiness, comfort and everything nice in this world and that other provides a sharp reminder that maybe that extra scoop of ice cream was too much. But suffice to say, a rift between the two industries is not something that you would expect to find.&nbsp;</span></p><p><span data-preserver-spaces="true">But as hype culture and the obsessive fandom on the internet have grown, the industries have been growing closer and closer together. But sadly, not in the way you think, we are still a few years off wearable ice cream. Instead, there is now a good chance that your local ice creamery sells merchandise. Less impressive, for sure. But this has become a staple for restaurants with even just a modicum of goodwill attached to their name and why not? If customers are willing to pay an extra $50 so that people will mistake them as an 'off the clock' employee, then go for it. However, it is always important to keep in mind that merely the fact that a store does not typically deal in goods from a particular industry, this does not exempt that store from the standard business conventions of that industry.&nbsp;</span></p><p><span data-preserver-spaces="true">This lesson was learnt recently by Afters Ice Cream, which after launching a line of merchandise was reportedly</span><span data-preserver-spaces="true">&nbsp;sued by the high-fashion brand, Off-White.&nbsp;</span></p><p><span data-preserver-spaces="true">Afters Ice Cream advertised a number of different types of clothing that featured the phrase 'Off-Diet' and using images similar to very notable Off-White works. Off-White claims that the merchandise is 'confusingly similar' to Off-White's graphics and registered trademarks. It also stated that "retail fixtures, signage, [and] interior d√©cor" is intended to "confuse consumers into believing that [its] products are Off-White products and/or that [it or its] business is affiliated with Off-White."&nbsp;</span></p><p><span data-preserver-spaces="true">While it is ironic that the Off-White, a company which has been at the other end of numerous copyright infringement claims, even to the extent of a case being called&nbsp;</span><em>OffWhite Co v Off-White</em><span data-preserver-spaces="true">&nbsp;</span><em>LLC</em><span data-preserver-spaces="true">, was so quick to launch their own proceeding, however, the law is pretty straightforward concerning unlicensed reproduction of copyrighted works.&nbsp;</span></p><p><span data-preserver-spaces="true">But it is not all doom and gloom, and there is hope for the plucky ice cream store yet as due to use of humour in the respective shirts, a reproduction of copyrighted works could be okay if it is for the purposes of parody or satire.&nbsp;&nbsp;</span></p><p><span data-preserver-spaces="true">This concept was demonstrated in a recent case in the Ninth Circuit, where the makers of a dog toy that resembled a bottle of Jack Daniels Whiskey were found not to be infringing copyright as the dog toy was found to be humourous and expressive and not a sign of your dog falling off the wagon.&nbsp;</span></p><p><span data-preserver-spaces="true">As for the Off-White matter, we will have to wait and see if this matter progresses to court or if cooler heads prevail and the case is dropped.&nbsp;</span></p>
</div>

</div></div>]]>
            </description>
            <link>https://www.legallyinsightful.com/2020/11/off-brand-how-high-fashion-brand-and.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058570</guid>
            <pubDate>Wed, 11 Nov 2020 14:18:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Online conversation is the attention system of society ‚Äì and it's broken]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25058548">thread link</a>) | @etherio
<br/>
November 11, 2020 | http://norse.horse/articles/attention-system-of-society.html | <a href="https://web.archive.org/web/*/http://norse.horse/articles/attention-system-of-society.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>
Humans are hypersocial animals; as soon as we invent something new, from signal fires to electricity,  we use it to communicate. Users of the very first computers would leave notes on the system for friends to read; today, Internet users spend on average over two hours per day using social media. As a cognitive scientist, I√¢‚Ç¨‚Ñ¢m interested in how we use online tools to communicate, adjust our views, and make decisions; and I√¢‚Ç¨‚Ñ¢m concerned about the effects of for-profit social media on conversation and debate. My generation is the last to have grown up writing letters - handwritten, meaningful messages from friends - and for-profit social media is psychologically very different.
</p><p>
In October 2017 three academics, concerned about Whatsapp√¢‚Ç¨‚Ñ¢s influence on the Brazilian election, called for the Facebook-owned company to make it harder to share messages. Instant sharing means that an individual can reach many more people and that events, rumours and viewpoints can go viral in a few hours, sweeping across a country as a wave of copies is made. Importantly, the reader has no sense that the sender has taken the time to craft a communication; sharing is not an act of expression. Oversharing also swamps readers with the cognitive demand of reading hundreds of low-effort posts per day. Luckily for big social media, there is a solution at hand: the algorithm.
</p><p>
Facebook, Snapchat and Twitter originally showed new posts in chronological order. Today, they use news-feed algorithms to select the posts you see. The details of how these algorithms work and what they prioritise are murky, but two things are certain: they collect huge amounts of data on our behaviour, and they aim to maximise the time we spend logged in - not to give us the most interesting or meaningful material. If we argue with someone over an offensive post, the algorithm may counterproductively show us more posts like it. If you turn Facebook√¢‚Ç¨‚Ñ¢s algorithm off, it swiftly switches itself back on.
</p><p>
The tools we use to communicate online play a huge role in our lives: they help us choose our friends, fix our political and moral beliefs, and construct our personalities. I study attention, the set of brain processes which decide what details of the outside world are important. When you notice a bright light, screen out a distracting noise, or select the most trustworthy panellist in a debate, your attention system is at work. In the modern world, online communication tools enable and support social trends; they host flurries of political discourse during elections; and they allow the viral spread of ideas, from memes to movements. They are the attention system of society.
</p><p>
Before sharing and before the news-feed algorithm, individual people played a huge role in society√¢‚Ç¨‚Ñ¢s online attention system. Millions of small decisions by individuals combined to select the topics that would dominate the headlines. But we have given up the job. With our news feeds curated by algorithms, we no longer decide what to read. We can still choose which groups to subscribe to or which friends to follow, but we have completely abnegated the most basic and central decision - what messages are put in front of our eyes.
</p><p>
So, using social media is a very different experience from reading or writing a letter. There is no natural end to the experience; there is little incentive to put time and care into writing a message; and there is no control over what you read. For-profit social media, being free, is not a product. Neither is it a a service; it does not give us the options we need to control it. Social media is an experience designed to attract and retain us - so that we can provide the attention which earns Facebook √Ç¬£20 per year per user in advertising revenue, and the behaviour data which is its most valuable asset.
</p><p>
The consequences of our society√¢‚Ç¨‚Ñ¢s new attention system are extremely serious. Before the 2016 referendum on EU membership, over √Ç¬£2.7m was spent on often-misleading Facebook adverts by an unregulated consortium of lobbying organisations which conspired to break the Electoral Commission√¢‚Ç¨‚Ñ¢s rules on data sharing. Shortly before the last US election, $70 million per month was spent on social media advertising by the Trump campaign, using voter data stolen through a Facebook loophole to predict personalities and target political ads. 
</p><p>
I believe that the best way to highlight the harmful effects of oversharing and news-feed algorithms is to build a platform that supports conversation, discussion, and independent thought rather than prioritising sharing and screen time. A communication tool should not be an experience; it should be a true service, one which puts readers√¢‚Ç¨‚Ñ¢ and writers√¢‚Ç¨‚Ñ¢ needs first by giving them the tools to control what they read and who reads their conversations.
</p><p>
We all have a right to freedom of speech - but we don't automatically have the right to broadcast. We need to think carefully about public groups - spaces which can go viral and take on a life of their own. A closed group can√¢‚Ç¨‚Ñ¢t go viral or expand into a huge community. Public groups can connect you with like-minded people and show you interesting material, but when people disagree on topics close to their heart - human rights, economic policy - public groups descend into chaos or censorship. Their owners or controllers may be unclear; they must use moderators, whose rules are often unfair; and by suppressing conflicting opinions they encourage the development of filter bubbles. What we read online should be selected by individuals√¢‚Ç¨‚Ñ¢ decisions, not by the moderators of anonymous groups or by algorithms trained for profit.
</p><p>
It is certainly easier to immerse yourself in the experience of for-profit social media. But I believe that conversation and debate should be more than a passive experience: they require effort, engagement and attention. Every day, we spend hours reading and conversing online. Just as we are careful with what we eat and drink, we should be careful with what we read, what we allow to influence us, and to whom we delegate the responsibility of choosing what is put in front of our eyes. The days of letter-writing may have passed, but the experience of reading a message carefully written for you, conveyed to you by a system whose only purpose is to support communication, should live on.
</p>





</div></div>]]>
            </description>
            <link>http://norse.horse/articles/attention-system-of-society.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058548</guid>
            <pubDate>Wed, 11 Nov 2020 14:15:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What mother never told you about VM service (1983) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058543">thread link</a>) | @fanf2
<br/>
November 11, 2020 | http://www.leeandmelindavarian.com/Melinda/tutorial.pdf | <a href="https://web.archive.org/web/*/http://www.leeandmelindavarian.com/Melinda/tutorial.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.leeandmelindavarian.com/Melinda/tutorial.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058543</guid>
            <pubDate>Wed, 11 Nov 2020 14:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 Beta]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058503">thread link</a>) | @simonpure
<br/>
November 11, 2020 | https://reasonabledeviations.com/2020/11/09/covid-beta/ | <a href="https://web.archive.org/web/*/https://reasonabledeviations.com/2020/11/09/covid-beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  
  
  
  <p>In this short post, we compute and visualise ‚ÄúCOVID-19 betas‚Äù for stocks in the S&amp;P500 index, to quantitatively and visually understand which companies were most affected (positively and negatively) by COVID-19.</p>

<!--more-->
<p>For those of you who just want to see the (interactive!) result, here it is. Click on any sector to zoom in on its constituents:</p>





<p>If you would like to generate this plot for yourself, perhaps using a different basket of stocks, the Jupyter notebook is <a href="https://github.com/robertmartin8/RandomWalks/blob/master/COvidBeta/CovidBeta.ipynb">here</a>.</p>

<p><em>Note: most of this post was written before November 9th 2020, the day on which Pfizer announced incredibly encouraging results regarding their vaccine.</em></p>

<h2 id="motivation">Motivation</h2>

<p>Let‚Äôs go back in time to the start of 2020. Despite aggressive trade rhetoric, 2019 has been a great year for markets, with the S&amp;P500 up about 30%. Thanks to low rates (and the Fed‚Äôs commitment to loose monetary policy), the ‚Äúblip‚Äù of 2018Q4 is nothing more than a distant bad dream. Big tech is killing it; multiples are expanding; volatility is at a comfortable low.</p>

<p>On January 4th, the World Health Organisation (WHO) <a href="https://twitter.com/WHO/status/1213523866703814656?s=20">tweets</a> that there is a cluster of pneumonia cases in Wuhan, China. As far as the West is concerned, this is a non-event, happening way ‚Äúover there‚Äù in the East. On January 13th, a case is recorded in Thailand. What follows is two months of health officials gathering and mulling over the evidence (on January 23rd an independent committee reports that there is insufficient evidence to make a decision), while the rest of the world continues on blissfully unaware of the worsening situation. The markets continue their steady rise, largely unperturbed.</p>

<p>In February, the situation becomes hard to ignore; by February 13th, COVID-19 is present in 25 countries, with more than 60,000 cases (<a href="https://www.thinkglobalhealth.org/article/updated-timeline-coronavirus">source</a>). On the 14th of February, market participants suddenly seem to appreciate the gravity of the situation; in one short month, the S&amp;P500 loses 1/3 of its value. People who have been diligently following the prevailing personal finance advice and investing their money in the stock markets are suddenly faced with an unprecedentedly rapid loss of net worth. Speculators, who have been riding the rally with leverage, are caught with their trousers down.</p>

<p>By March, there is full-on panic as the worldwide number of cases hits 100,000 and nations start to impose heavy travel restrictions.  What had started as whispers of a viral cough ‚Äúfar away in the East‚Äù has now blown up into the terrifying spectre of an omnipresent contagion ‚Äì $R_0$ numbers suggest that before long, the majority of the world population will be infected by a virus whose severity is still unknown. Readers of mainstream news could be forgiven for thinking that it is the end of the world as we know it.</p>

<p>Cut to 18th August ‚Äì 6 months later. The S&amp;P500 has just posted a new all-time high, having appreciated about 50% from the low of March 20th.</p>

<center>
<img src="https://reasonabledeviations.com/assets/images/covid_beta/spy_covid.png">
</center>

<p>I have written this dramatised account largely as a note-to-self. With the rose-tinted spectacles of hindsight, it is now clear that the widespread and indiscriminate risk-off in March created a fantastic opportunity for level-headed investors to pick up high-quality companies, well suited to a social-distanced society, at steep discounts. Many of us are now kicking ourselves for not having bought more, but we must remember that in the moment, the future was murky indeed.</p>

<p>All this said, things certainly aren‚Äôt back to where they were. Only a handful of companies (mostly big tech) have been responsible for the majority of the market‚Äôs rebound. Whether you are optimistic or pessimistic about how the pandemic plays out from here, as long as you think COVID-19 is a key driver for stock markets it is important to know how different sectors or companies are affected by the virus. Optimists might be keen to identify which stocks have been hardest hit, to play the rebound, while those who think that the situation will stay unresolved for longer than consensus expects may want to remain overweight the companies that thrive in a pandemic environment.</p>

<p>The goal of this investigation, therefore, is to develop a highly intuitive tool to allow the viewer to understand, at a glance, which companies respond <em>well</em> and <em>badly</em> to COVID-19 news.</p>

<h2 id="methodology">Methodology</h2>

<p>The standard approach is ‚Äúarmchair reasoning‚Äù: sitting down and logically thinking through what the impacts of COVID-19 have been / will be.
On April 2nd 2020, I made this brainstorming mindmap to reason about some of the second-order implications of the pandemic. Several of the companies I mentioned, which may seem obvious in hindsight, have done very well:</p>

<center>
<img src="https://reasonabledeviations.com/assets/images/covid_beta/covid_brainstorming.png">
</center>

<p>Alternatively, we might adopt the ‚Äúdata-driven‚Äù approach: let market performance tell you which stocks benefitted most and least from COVID-19. Naively, we could simply look at which stocks/sectors have performed best/worst this year. This is a reasonable starting point but contains a lot of noise because stocks move up and down for all sorts of reasons.</p>

<p>A better methodology for understanding how some factor (in our case, COVID-19) affects stock prices is is to compute the <strong>beta</strong> of the asset returns to the factor. Concretely, we examine the correlation between the daily change in stock prices and the daily increases in COVID-19 cases: if a stock tends to have negative returns whenever COVID cases rise, we may believe that there is some association between COVID and the stock. The nice thing about this approach is that we can remove the effects of as many other variables as we want by introducing them as additional regression variables.</p>

<p>In this post, we will regress stock returns against both COVID-19 cases and the overall S&amp;P500 index (the latter being what people typically call <em>the</em> beta, though it is really just <em>a</em> beta). This serves to identify the effect of COVID-19 on the stock <em>in excess</em> of the overall market effects, which should give a more accurate picture of how COVID-19 is affecting a stock.</p>

<p>I pulled COVID data from the New York Times‚Äô <a href="https://github.com/nytimes/covid-19-data">GitHub repo</a>, and as usual, I used Yahoo Finance (via the <code>yfinance</code> python library) for stock/index pricing data. The ‚Äúheavy lifting‚Äù ‚Äì regressing stock returns against SPY returns and the change in daily cases ‚Äì was done by the linear regression class within <code>scikit-learn</code>.</p>

<h2 id="analysis-and-visualisation">Analysis and Visualisation</h2>

<p>A higher COVID beta means that a stock‚Äôs returns were <em>positively</em> correlated with the change in COVID cases, i.e. more COVID cases helped the stock. Perhaps unsurprisingly, among the stocks with the highest COVID betas were Netflix, Walmart, Hasbro, Intel, and Citrix (enterprise technology). Conversely, the stocks with the most negative COVID betas include hard-hit companies in the energy and consumer discretionary sectors. This is encouraging, as our methodology passes the basic sanity check. Tech companies like Netflix were clear winners from national lockdowns, while energy companies faced a massive demand shock as people no longer drove to work or travelled overseas.</p>

<p>To summarise the betas in one clear diagram, I drew inspiration from the Bloomberg terminal heatmap, which gives an instant ‚Äúpulse‚Äù of the market with respect to one key variable (with the size of a rectangle representing market caps):</p>

<center>
<img src="https://reasonabledeviations.com/assets/images/covid_beta/CovidBeta.png">
</center>

<p>(Note: we don‚Äôt see a large blue rectangle corresponding to Zoom because Zoom isn‚Äôt yet in the S&amp;P500 index)</p>

<p>At a first glance, this graphic seems to accurately describe much of our intuition regarding what COVID has benefitted/harmed. Tech is largely blue (benefitting), as are healthcare and consumer staples. Energy has been particularly hard hit, with financials having a tough time also. But the effect of COVID on other sectors may not be as obvious, and it is here where the visualisation becomes especially helpful.</p>

<p><em>Note regarding the Pfizer news of November 9th 2020</em></p>

<p>On 9 November, while I was halfway through writing this post, Pfizer announced very promising results from their vaccine. I found the heatmap to be a very useful reference ‚Äì the red companies/sectors posted stunning returns, while many of the blue companies (e.g big tech) had a lacklustre day ‚Äì and actually ended up using the heatmap to help identify some stocks to trade. Based on my qualitative judgment post-hoc, the betas on the heatmap do seem to properly reflect the economic link between COVID-19 and the companies.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In this post, we have constructed a ‚Äúquick and dirty‚Äù method of understanding and visualising the effects of COVID-19 on different companies. There are several important caveats which should be considered before you use the heatmap for anything important.</p>

<p>Firstly, betas are essentially correlations, so we must be careful about using them to retroactively create narratives to explain <em>why</em> certain stocks did well/badly with respect to COVID-19. One must exercise judgment in determining which betas represent broad economic impacts due to COVID-19, rather than idiosyncratic company effects. For example, I noticed that within the financials sector, Goldman Sachs stood out as having a positive COVID beta ‚Äì I reasoned that this was <em>because</em> GS doesn‚Äôt have significant commercial banking exposure, instead being focused on trading (which benefits from volatility) and investment banking. However, this narrative is somewhat contradicted by the fact that Morgan Stanley also lacks commercial banking exposure, yet had a negative COVID beta anyway.</p>

<p>Secondly, this analysis treats beta as if it is a static parameter. In reality, to compute beta (or any other time-series property), one must decide on a rolling window for the calculation. In this post, we used all year-to-date stock price data, but the plot below shows how the 2-month rolling beta for the 10 highest/lowest beta stocks (averaged) varied over time.</p>

<center>
<img src="https://reasonabledeviations.com/assets/images/covid_beta/rolling_beta.png">
</center>

<p>Lastly, we have all likely heard the many complaints about the market diverging from reality, along with the standard response that ‚Äúmarkets are forward-looking‚Äù. Our methodology is not at all forward-looking, as it is simply ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reasonabledeviations.com/2020/11/09/covid-beta/">https://reasonabledeviations.com/2020/11/09/covid-beta/</a></em></p>]]>
            </description>
            <link>https://reasonabledeviations.com/2020/11/09/covid-beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058503</guid>
            <pubDate>Wed, 11 Nov 2020 14:09:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why an IDE?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058502">thread link</a>) | @todsacerdoti
<br/>
November 11, 2020 | https://matklad.github.io//2020/11/11/yde.html | <a href="https://web.archive.org/web/*/https://matklad.github.io//2020/11/11/yde.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Nov 11, 2020</p>
  <p>Some time ago I wrote a reddit comment explaining the benefits of IDEs.
Folks refer to it from time to time, so I decided to edit it into an article form.
Enjoy!</p>
<p>I think I have a rather balanced perspective on IDEs.
I used to be a heavy Emacs user (<a href="https://github.com/matklad/.emacs.d/tree/475de5db99f8729c57fed7e6fde4cd06f5ccb62f">old config</a>, <a href="https://github.com/matklad/config/blob/d555642a5a9e4e8b0ca0c77f188ffd976f06327c/home/.emacs.d/init.el">current config</a>).
I worked at JetBrains on <a href="https://github.com/intellij-rust/intellij-rust">IntelliJ Rust</a> for several years.
I used evil mode and vim for a bit, and tried tmux and kakoune.
Nowadays, I primarily use VS Code to develop <a href="https://github.com/rust-analyzer/rust-analyzer/">rust-analyzer</a>: LSP-based editor-independent IDE backend for Rust.</p>
<p>I will be focusing on IntelliJ family of IDEs, as I believe these are the most advanced IDEs today.</p>
<p>The main distinguishing feature of IntelliJ is semantic understanding of code.
The core of IntelliJ is a compiler which parses, type checks and otherwise understands your code.
<a href="https://martinfowler.com/bliki/PostIntelliJ.html">PostIntelliJ</a> is the canonical post about this.
That article also refutes the claim that ‚ÄúSmalltalk IDE is the best we‚Äôve ever had‚Äù.</p>
<p>Note that ‚Äúsemantic understanding‚Äù is mostly unrelated to the traditional interpretation of ‚ÄúIDE‚Äù as <em>Integrated</em> Development Environment.
I personally don‚Äôt feel that the ‚ÄúIntegrated‚Äù bit is all that important.
I commit&amp;push from the command line using Julia scripts, rebase in magit, and do code reviews in a browser.
If anything, there‚Äôs an ample room for improvement for the integration bits.
For me, <strong>I</strong> in ‚Äú<strong>I</strong>DE‚Äù stands for ‚Äúintelligent‚Äù, smart.</p>
<p>Keep in mind this terminology difference.
I feel it is a common source of misunderstanding.
‚ÄúUnix and command line can do anything an IDE can do‚Äù is correct about integrated bits, but is wrong about semantical bits.</p>
<p>Traditional editors like Vim or Emacs understand programming languages very approximately, mostly via regular expressions.
For me, this feels very wrong.
It‚Äôs <a href="https://stackoverflow.com/a/1732454">common knowledge</a> that HTML shall not be parsed with regex.
Yet this is exactly what happens every time one does <code>vim index.html</code> with syntax highlighting on.
I sincerely think that almost every syntax highlighter out there is wrong and we, as an industry, should do better.
I also understand that this is a tall order, but I do my best to change the status quo here :-)</p>
<p>These are mostly theoretical concerns though.
The question is, does semantic understanding help in practice?
I am pretty sure that it is non-essential, especially for smaller code bases.
My <a href="https://github.com/matklad/rustraytracer">first non-trivial Rust program</a> was written in Emacs, and it was fine.
Most of rust-analyzer was written using pretty spartan IDE support.
There are a lot of insanely-productive folks who are like ‚Äúsometimes I type vim, sometimes I type vi, they are sufficiently similar‚Äù.
Regex-based syntax highlighting and regex based fuzzy symbol search (<a href="https://github.com/universal-ctags/ctags">ctags</a>) get you a really long way.</p>
<p>However, I do believe that features unlocked by deep understanding of the language help.
The funniest example here is extend/shrink selection.
This features allows you to extend current selection to the next encompassing syntactic construct.
It‚Äôs the simplest feature a PostIntelliJ IDE can have, it only needs the parser.
But it is sooo helpful when writing code, it just completely blows vim‚Äôs text objects out of the water, especially when combined with multiple cursors.
In a sense, this is structural editing which works for text.</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98809232-80e3db00-241d-11eb-883a-5aece9a1dbfc.gif" alt="98809232 80e3db00 241d 11eb 883a 5aece9a1dbfc">
</p>
</div>
<p>If you add further knowledge of the language into a mix, you‚Äôll get the ‚Äúassists‚Äù system: micro-refactoring which available in a particular context.
For example, is the cursor is on a comma in a list of function arguments, you can <span><kbd>alt</kbd>+<kbd>enter</kbd></span> &gt; ‚Äúswap arguments‚Äù, and the order of arguments will be changed in the declaration and on various call-sites as well.
(See <a href="https://rust-analyzer.github.io/blog/2020/09/28/how-to-make-a-light-bulb.html">this post</a> to learn how assists are implemented).</p>
<p>These small dwim things add up to a really nice editing experience, where you mostly express the intention, and the IDE deals with boring syntactical aspects of code editing:</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98812121-37e25580-2422-11eb-8541-2c5a32926845.gif" alt="98812121 37e25580 2422 11eb 8541 2c5a32926845">
</p>
</div>
<p>For larger projects, complex refactors are a huge time-saver.
Doing project-wide renames and signature changes automatically and without thinking reduces the cost of keeping the code clean.</p>
<p>Another transformative experience is navigation.
In IntelliJ, you generally don‚Äôt ‚Äúopen a file‚Äù.
Instead you think directly in terms of functions, types and modules, and navigate to those using file structure, goto symbol, to do definition/implementation/type, etc:</p>

<p>When I used Emacs, I really admired its buffer management facilities, because they made opening a file I want a breeze.
When I later switched to IntelliJ, I stopped thinking in terms of a set of opened files altogether.
I disabled editor tabs and started using editor splits less often‚Äâ‚Äî‚Äâyou don‚Äôt need bookmarks if you can just find things.</p>
<p>For me, there‚Äôs one aspect of traditional editors which is typically not matched in IDEs out of the box‚Äâ‚Äî‚Äâbasic cursor motion.
Using arrow keys for that is slow and flow-breaking, because one needs to move the hand from the home row.
Even Emacs' horrific <kbd>C-p</kbd>, <kbd>C-n</kbd> are a big improvement, and vim‚Äôs <kbd>hjkl</kbd> go even further.
One fix here is to configure each tool to use your favorite shortcuts, but this is a whack-a-mole game.
What I do is remapping <kbd>CapsLock</kbd> to act as an extra modifier, such that <kbd>ijkl</kbd> <strong>are</strong> arrow keys.
(There are also keyboards with <a href="https://ultimatehackingkeyboard.com/">hardware</a> <a href="https://ergodox-ez.com/">support</a> for this).
This works in all applications the same way.
Easy motion / ace jump functionality for jumping to any visible character is also handy, and usually is available <a href="https://plugins.jetbrains.com/plugin/9803-acejump-lite">via</a> <a href="https://marketplace.visualstudio.com/items?itemName=lucax88x.codeacejumper">a plugin</a>.</p>
<p>Recent advancements with LSP protocol promise to give one the best of both worlds, where semantic-aware backend and light-weight editor frontend are different processes, which can be mixed and matched.
This is nice in theory, but not as nice in practice as IntelliJ yet, mostly because IntelliJ is way more polished.</p>
<p>To give a simple example, in IntelliJ for ‚Äúgo to symbol by fuzzy name‚Äù functionality, I can filter the search scope by:</p>
<div>
<ul>
<li>
<p>is this my code/code from a dependency?</p>
</li>
<li>
<p>is this test/production code?</p>
</li>
<li>
<p>is a symbol a type-like thing, or a method-like thing?</p>
</li>
<li>
<p>path to the module where the symbol is defined.</p>
</li>
</ul>
</div>
<p>VS Code and LSP simply do not have capabilities for such filters yet, they have to be bolted on using hacks.
Support for LSP in other editors is even more hit-and-miss.</p>
<p>LSP did achieve a significant breakthrough‚Äâ‚Äî‚Äâit made people care about implementing IDE backends.
Experience shows that re-engineering an existing compiler to power an IDE is often impossible, or isomorphic to a rewrite.
How a compiler talks to an editor is the smaller problem.
The hard one is building a compiler that can do IDE stuff in the first place.
Check out <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">this post</a> for some of the technical details.
Starting with this use-case in mind saves a lot of effort down the road.</p>
<p>This I think is a big deal.
I hypothesize that the reason why IDEs do not completely dominate tooling landscape is the lack of good IDE backends.</p>
<p>If we look at the set of languages fairly popular recently, a significant fraction of them is dynamically typed: PHP, JavaScript, Python, Ruby.
The helpfulness of an IDE for dynamically typed languages is severely limited: while approximations and heuristics can get you a long way, you still need humans in the loop to verify IDE‚Äôs guesses.</p>
<p>There‚Äôs C++, but its templates are effectively dynamically typed, with exactly the same issues (and a very complex base language to boot).
Curiously, C looks like a language for which implementing a near-perfect IDE is pretty feasible.
I don‚Äôt know why it didn‚Äôt happen before CLion.</p>
<p>This leaves C# and Java.
Indeed, these languages are dominated by IDEs.
There‚Äôs a saying that you can‚Äôt write Java without an IDE.
I think it gets the causation direction backwards: Java is one of the few languages for which it is possible to implement a great IDE without great pain.
Supporting evidence here is Go.
According to <a href="https://blog.golang.org/survey2019-results#TOC_5.">survey results</a>, text editors are stably declining in popularity in favor of IDEs.</p>
<p>I think this is because Go actually has good IDEs.
This is possible because the language is sufficiently statically typed for an IDE to be a marked improvement.
Additionally, the language is very simple, so the amount of work you need to put in to make a decent IDE is much lower than for other languages.
If you have something like JavaScript‚Ä¶‚Äã
Well, you first need to build n alternative language for which you can actually implement and an IDE (<a href="https://www.typescriptlang.org/">TypeScript</a>) and only then you can build the IDE itself (<a href="https://github.com/microsoft/vscode">VS Code</a>).</p>
</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io//2020/11/11/yde.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058502</guid>
            <pubDate>Wed, 11 Nov 2020 14:09:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$200k in sales from a $6k advertisement]]>
            </title>
            <description>
<![CDATA[
Score 371 | Comments 102 (<a href="https://news.ycombinator.com/item?id=25058363">thread link</a>) | @mildlyclassic
<br/>
November 11, 2020 | https://www.wifidabba.com/blog/200000-dollars-in-sales-from-one-daringfireball-ad | <a href="https://web.archive.org/web/*/https://www.wifidabba.com/blog/200000-dollars-in-sales-from-one-daringfireball-ad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <div>
        <div>
          <div>


          
            <table>
                <thead>
                  <tr>
                    <th>
                      Metric
                    </th>
                    <th>
                      Count
                    </th>
                  </tr>
                </thead>
                <tbody>
                <tr data-href="#!">
                    <td>
                      Time period
                    </td>
                    <td>
                      Aug 17,2020 - Aug 24,2020
                    </td>
                  </tr>
                  <tr data-href="#!">
                    <td>
                      Visitors
                    </td>
                    <td>
                      7,200
                    </td>
                  </tr>
                  <tr data-href="#!">
                    <td>
                      Emails
                    </td>
                    <td>
                      45
                    </td>
                    
                  </tr>
                  <tr data-href="#!">
                    <td>
                      Video calls
                    </td>
                    <td>
                      30
                    </td>
                    
                  </tr>
                  <tr data-href="#!">
                    <td>
                      <strong>Units sold</strong>
                    </td>
                    <td>
                      <b>10</b>
                    </td>
                  </tr>   
                  <tr data-href="#!">
                    <td>
                      <strong>Unit price</strong>
                    </td>
                    <td>
                      <b>$20,000</b>
                    </td>
                  </tr>
                  <tr data-href="#!">
                    <td>
                      <strong>Total revenue from DF</strong>
                    </td>
                    <td>
                      <b>$200,000</b>
                    </td>
                  </tr>
                  
                </tbody>
              </table>
              
              
          <ul>
              <li>
                Build cheap broadband distribution technology.
              </li>
              <li>
                Prove the tech works by connecting 1M people in one city.
              </li>
              <li>
                Deploy across 1,000 cities in India
              </li>
            </ul>

            

            <p>
                Our goal at <a href="https://www.wifidabba.com/">Wifi Dabba</a> is to lower the cost of broadband access in India. We use lasers instead of underground fiber as our core network and commodity components to dramatically lower the cost of deploying a broadband network.
            
                We've been running a beta network in Bengaluru, India for the last 9 months serving thousands of live customers. We're now ready to deploy a city wide network and provide cheap internet access to a million people.
            </p>

            <iframe width="100%" height="450" src="https://www.youtube.com/embed/LwVWJXBNQg8?autoplay=1" srcdoc="<style>*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}</style><a href=https://www.youtube.com/embed/LwVWJXBNQg8?autoplay=1><img width='100%' style='min-height:250px;' src='https://img.youtube.com/vi/LwVWJXBNQg8/hqdefault.jpg' alt='Wifi Dabba overview'><span>‚ñ∂</span></a>" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" title="Wifi Dabba overview"></iframe>

            
            <p>
              A core tenet of the Wifi Dabba network is distributed ownership. We believe that ownership of the internet should be in the hands of as many people as possible. If the cost of broadband tech drops, then more people can help pay for the cost of the network.
              And if you're one of the people paying for the distribution, we believe you should get revenue in return.
            </p>

            <p>
              We've divided the city of Bengaluru into 100 regions called PoPs. Anyone can buy a region and get a share in the revenue from those subscribers. 
            </p>

            <p>
              The Wifi Dabba franchise model:
            </p>

            <ul>
              <li>
                <strong>$20,000</strong> to purchase a 4sqkm. PoP.
              </li>
              <li>
                <strong>Minimum guaranteed revenue</strong> Paid quarterly with a 6 year rev share agreement.
              </li>
              <li>
                <strong>Fully managed service</strong> Be an absentee landlord
              </li>
            </ul>

            

            <p>
              <span>We've sold 40 as of the time of writing this.</span>
              <br>
              
              Wifi Dabba is insanely lucky for the amount of public support we have as a company. We regularly get phone calls, emails and even people dropping by our office just to tell us they like our service. Over the last 3 years we've received dozens of emails from people requesting franchises or other types of partnerships.
              We're incredibly humbled and thankful for this support on a daily basis.
            </p>

            
            <p>
              We believe there is a large group of people that care about the future of the internet and would be willing to put their money where their mouths are. As long as the price and the level of risk involved is reasonable.
              Our gut told us that this group would most likely be people that have seen success in the technology business as engineers, operators and entreprenuers.
            </p>

            
            <p>
              We've had our heads down over the last three years building and testing our network stack. Publicity or notariety has never been high on our list. 
              We've begun ramping up our social media efforts but it was clear that to kickstart our outreach, we had to do a little bit of advertising.
            </p>

            
            
              <p><img src="https://www.wifidabba.com/images/df-venn.png" height="300" width="330" alt="...">
                <br>
              </p>
            <p>
              <a href="https://www.daringfireball.net/">Daringfireball.net</a> is a great blog authored by <a href="https://en.wikipedia.org/wiki/John_Gruber">John Gruber</a> who is also the creator of <a href="https://daringfireball.net/projects/markdown/">Markdown</a>.
              DF was a natural choice for us as we've been readers of the blog for a long while and we knew from experience that DF readers would fit our target market rather well. Given the high quality of John's writing and insights into the industry, we felt that there would be a large pool of senior tech veterans that would be interested in Wifi Dabba among DF's audience.
            </p>

            <p>
                The sponsorship cost us $6,500 and ran for the week starting Aug 17, 2020 and we got:
                </p><ul>
                <li>
                  A display ad in the sidebar on every page of the site, all week long.
                </li>
                <li>
                  A post from the sponsor in the RSS feed at the start of the week. Us, the sponsor, got to address Daring Fireball‚Äôs most dedicated readers directly.
                </li>
                <li>
                  At the end of the week, John also posts an item thanking and linking to the feed sponsor.
                </li>
              </ul>
            

            <p>
                Stats about DF readership
                </p><ul>
                <li>
                Typical weekday web page views: 80,000‚Äì100,000.
                </li>
                <li>
                Estimated monthly web page views: 2.5 million.
                </li>
                <li>
                Estimated Daring Fireball RSS feed subscribers: Over 200,000.
                </li>
                <li>
                Twitter followers on the @daringfireball  account: Over 92,000.
                </li>
              </ul>
            
            

            
            <p>
                We created two variants of our message. Designed in bold colours to stand out against DF's dark theme. These creatives rotated randomly.
                We decided to focus on the technology because of the nature of the audience and hoped that the website did a good job of explaining the product.  
                </p><p><img src="https://www.wifidabba.com/images/df-ads.png" width="100%" alt="Buy internet POP">
                </p>
            

            
            <div>
                <p><strong>Click Ad -&gt; Browse site -&gt; Setup a call</strong></p><p>

                We expected visitors to click on the ad in DF and land on our homepage. Once on our site, we hoped that visitors would check out our videos as well as browse through a few pages.
                If they liked what they saw, we had a prominent buy button on the front page which led to a page to setup a video call.
            </p></div>

            <p>
                It's worth noting here that we knew going in that a large percentage of DF's audience would be using Ad-blockers. Nothing wrong with that, we use ad-blockers ourselves.
            </p>

            <p>
              Furthermore, we made a deliberate choice to add a high friction call to action and contact process. In order to purchase a PoP, a visitor would be directed to a calendar managed by calendly that would help them setup a call with someone from our team at a convenient time.
            </p>
            <p><a href="https://wifidabba.com/buy">
              <img width="100%" src="https://www.wifidabba.com/images/df-buy.png" alt="Setup Call">
            </a></p><p>
              The reason for this is that we knew DF would deliver a few hundred visitors a day to our site. We're a small team and our core focus is deploying the network, not necessarily sales and our goal is to sell the PoPs to people that are really excited a lot about our idea and show a high level of interest.
              The $20,000 price point of our product + the high friction of the contact process + users that are OK with ads = A high signal to noise ratio from DF visitors. 
              We'd love to hear any feedback on what you think about this.
            </p>

            
              

              <p>
                Our thesis turned out to be pretty spot on. Senior engineers from Google, Apple and a host of other technology companies purchased the PoPs.
                The actual sales process turned out to be fairly quick and straight forward. Most of the people that purchased the PoPs did so within a period of 48 hours of having the call.
              </p>

              



          </div>
        </div>
    </div>
    </section></div>]]>
            </description>
            <link>https://www.wifidabba.com/blog/200000-dollars-in-sales-from-one-daringfireball-ad</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058363</guid>
            <pubDate>Wed, 11 Nov 2020 13:51:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Executing GraphQL Queries]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058361">thread link</a>) | @chmaynard
<br/>
November 11, 2020 | https://jemma.dev/blog/executing-graphql-queries | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/executing-graphql-queries">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><a href="https://graphql.org/">GraphQL</a> is surging in popularity as a preferred choice for APIs over REST APIs. One of the reasons many companies cite for converting their APIs from REST to GraphQL is its ease of use. If you know JSON, GraphQL is incredibly intuitive. And there are helpful tools like <a href="https://github.com/graphql/graphiql">GraphiQL</a>, an in browser GraphQL IDE.</p>

<p>Even with its usability, there are still a few pointers which are helpful to learning GraphQL. GitHub implemented their <a href="https://developer.github.com/v4/">API v4</a> using GraphQL. Let‚Äôs work through an example using <a href="https://developer.github.com/v4/explorer/">GitHub‚Äôs GraphiQL explorer</a> to hit the GitHub API as a way to learn some basic GraphQL:</p>

<h3 id="graphiql-keyboard-shortcuts">GraphiQL Keyboard Shortcuts</h3>

<p>Before we start, take a look at these keyboard shortcuts I frequently use when working in the GraphiQL IDE:</p>

<ul>
  <li>Auto Complete: Ctrl-Space (or Option-Space)</li>
  <li>Run query: Ctrl-Enter</li>
  <li>Format query: Ctrl-Shift-P</li>
</ul>

<h3 id="githubs-graphiql-explorer">GitHub‚Äôs GraphiQL Explorer</h3>

<p>When you open up <a href="https://developer.github.com/v4/explorer/">GitHub‚Äôs GraphiQL explorer</a>, you‚Äôll see three panes. The top left is a query editor for our GraphQL query to GitHub‚Äôs API; bottom left is for query variables; and the right side will display query results when we hit the API.</p>

<p>After signing in with your GitHub account details, Hit play (Ctrl-Enter) on the query which GitHub autofills! You‚Äôll see your login displayed on the right side of the screen. The first item to note here is that the result mirrors the syntax and format of the query. This is a big part of what makes GraphQL so intuitive! The API responses mirror the API requests.</p>

<h3 id="reading-the-docs">Reading the Docs</h3>

<p>Towards the right of the GraphiQL explorer, there‚Äôs a <code>&lt; Docs</code> button. Toggle it! (This is not to be confused with the topbar menu <code>Docs</code> dropdown.) The <code>&lt; Docs</code> will toggle a little interface which tells us what to expect in our queries, and helps us when we use incorrect syntax. It will let us search by type.</p>

<p>Your first question, though, might be, how will we know the type of our data? In GraphQL, we can use <code>__typename</code> on any data to get its type. For instance, we can edit the query we just wrote:</p>

<div><div><pre><code>query <span>{</span>
  viewer <span>{</span>
    __typename
  <span>}</span>
<span>}</span>
</code></pre></div></div>
<p>and we‚Äôll see that <code>viewer</code> has the type <code>"User"</code>. If we now search the docs for <code>"User"</code>, we‚Äôll see there are many <code>"Fields"</code> on user which we can explore. Try adding a few fields to your initial query.</p>

<h3 id="user">User</h3>

<p>Well, there must also be other <code>"User"</code>s we can access instead of just ourselves. Let‚Äôs try it! Replace <code>viewer</code> in the query from above with <code>user</code>. When we run this snippet, we‚Äôll see an error:</p>

<div><div><pre><code>query <span>{</span>
  user <span>{</span>
    name
    login
    createdAt
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The error will appear on our right pane. The error message tells us our problem, <code>"Field 'user' is missing required arguments: login"</code> Ah! We haven‚Äôt told GraphQL <em>which</em> user we‚Äôre interested in. As it suggests, let‚Äôs pass in a user‚Äôs login. <a href="https://github.com/torvalds">Linus Torvalds</a> created git, so he seems like an appropriate user to play with. His login is <code>torvalds</code>:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Neat. On the right side of your screen you should see that he‚Äôs had a GitHub account since 2011.</p>

<h3 id="connections">Connections</h3>

<p>When looking at the <code>User</code> docs, you might have noticed a type suffixed with <code>"Connection"</code>, for instance, <code>followers</code> has type <code>"FollowerConnection"</code>.</p>

<p>In GraphQL, <code>User</code> is a <code>Node</code>. Nodes have edges, and lists of these edges are called <code>Connections</code>. A <code>Connection</code> is a way to see all nodes that are connected to a certain node in a specific way. In our case, we‚Äôre looking for all <code>followers</code> nodes which are connected to Linus Torvalds. (See <a href="https://www.apollographql.com/blog/explaining-graphql-connections-c48b7c3d6976/">this Apollo blog post</a> for further reading about connections.)</p>

<p>If we try typing <code>followers</code> in the query, GraphiQL will give us an indication of an error. Hovering, we can read the error message, saying that <code>followers</code> must have a selection of subfields. This is where GraphiQL is incredibly helpful. Hit run (Ctrl-enter) after typing <code>followers</code>, and GraphiQL will autocomplete what its asking for:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers <span>{</span>
      edges <span>{</span>
        node <span>{</span>
          <span>id</span>
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>GraphiQL has auto-filled in the <code>edges</code>, <code>node</code> and <code>id</code> field on <code>followers</code> as defaults to give us some data about Linus‚Äô followers. This makes sense given what we know about edges and nodes: followers has <code>edges</code> and each of these is a <code>node</code>.</p>

<p>But, if we look to the right side of our screen, we‚Äôll see we have an error instead of results. The type <code>"MISSING_PAGINATION_BOUNDARIES"</code> and message <code>"You must provide a 'first' or 'last' value to properly paginate the 'followers' connection."</code> are both helpful here.</p>

<p>One of GraphQL‚Äôs real features is that it never returns more data than you ask it for. That said, we must tell it exactly how much data we want, by using (as prompted), the <code>first</code> or <code>last</code> field to limit the number of followers we‚Äôre asking for. Let‚Äôs look at Linus‚Äô last 5 followers:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
      edges <span>{</span>
        node <span>{</span>
          <span>id</span>
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This worked! But the <code>id</code>s aren‚Äôt particularly informative. We can see the type of <code>followers</code> by again using <code>__typename</code>. Or, we can use Ctrl-space to autoprompt some fields we might be interested in. Instead of the <code>id</code> field on a <code>node</code>, let‚Äôs look at <code>name</code>:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
      edges <span>{</span>
        node <span>{</span>
          name
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Aha, we can see the name of a few of Linus‚Äô followers. But, exactly how popular is he? For that, we can use the <code>totalCount</code> field under <code>followers</code>:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
      totalCount
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>As of the writing of this post, he has 124,812 followers. Notably, <code>totalCount</code> was <em>not</em> limited by our pagination. This is because it is only returning a single value, not a series of values.</p>

<h3 id="query-variables">Query Variables</h3>

<p>Reading this, you might have been curious how many followers a different user has. For that, we could replace <code>"torvalds"</code> with a different user‚Äôs login. Or, we could learn about Query Variables!</p>

<p>This is the last remaining pane (on the bottom left) which we haven‚Äôt touched yet.</p>

<p>We first need to declare the argument within our query. GraphQL requires a type here. We‚Äôll need to declare it in two places. The first is passing it into the query itself. The syntax is <code>query ($variable_name:type!) { ...</code> In our case, we want to pass a <code>login</code> of type <code>String</code>, so <code>query ($login:String!) {...</code>. Secondly, we want this to be our user‚Äôs login. So we can replace <code>torvalds</code> with <code>$login</code> as follows:</p>

<div><div><pre><code>query <span>(</span><span>$login</span>:String!<span>)</span> <span>{</span>
  user<span>(</span>login: <span>$login</span><span>)</span> <span>{</span>
    name
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
     totalCount
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>If we run this, our error message tells us that <code>"Variable $login of type String! was provided invalid value"</code>! Ah! We still didn‚Äôt use our bottom left ‚ÄúQuery Variables‚Äù pane. Let‚Äôs fill it in. Again, we can use the Ctrl-space to help us out: <code>{"login": "jemmaissroff"}</code>. If we now hit run, we‚Äôll see (among other things) that I have <em>significantly</em> fewer followers than Linus Torvalds.</p>

<h3 id="tldr">TL;DR</h3>

<p>For those short on time or attention:</p>

<ul>
  <li>GraphQL query results mirror JSON, making them easy to parse, write and reason about</li>
  <li><a href="https://github.com/graphql/graphiql">GraphiQL</a> is a helpful GraphQL IDE</li>
  <li><code>__typename</code> gives the type of an item, helpful for reading the docs</li>
  <li>Some queries have required arguments to limit the scope of a search, like <code>login</code> for user</li>
  <li>Pagination is a feature of GraphQL, requiring us to limit our queries, sometimes using <code>first</code> or <code>last</code></li>
  <li>Query variables must have a type and be named in the query declaration</li>
  <li>Query variables then can be used throughout the query itself by referencing the name in the declaration</li>
</ul>

<p>For an example of a queries which uses a few additional features of GraphQL, check out the queries I wrote <a href="https://github.com/jemmaissroff/find_github_email/blob/main/lib/find_github_email/queries.rb">here</a> for a Ruby gem to <a href="https://github.com/jemmaissroff/find_github_email">find GitHub users‚Äô emails</a>.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/executing-graphql-queries</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058361</guid>
            <pubDate>Wed, 11 Nov 2020 13:50:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NodeJVM]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058252">thread link</a>) | @mooreds
<br/>
November 11, 2020 | https://mikehearn.github.io/nodejvm/ | <a href="https://web.archive.org/web/*/https://mikehearn.github.io/nodejvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        
      
      
      <main role="main">
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/mikehearn/nodejvm/edit/master/docs/index.md" title="Edit this page">Óèâ</a>
                
                
                
<p>This repository demonstrates how to use NodeJS/npm modules directly from Java and Kotlin. Why is it useful:</p>
<ul>
<li>Gain access to unique JavaScript modules, like the Dat peer to peer file sharing framework shown in the samples.</li>
<li>Combine your existing NodeJS and Java servers together, eliminating the overheads of REST, serialisation, two separate
  virtual machines. Simplify your microservices architecture into being a polyglot architecture instead.</li>
<li>Use it to start porting NodeJS apps to the JVM world and languages, incrementally, one chunk at a time, whilst always
  having a runnable app. Or do the reverse.</li>
</ul>
<h2 id="how-does-it-work">How does it work?<a href="#how-does-it-work" title="Permanent link">¬∂</a></h2>
<p><a href="https://www.graalvm.org/">GraalVM</a> is a modified version of OpenJDK that includes the cutting edge Graal and Truffle compiler infrastructure.
It provides an advanced JavaScript engine that has competitive performance with V8, and also a modified version of
NodeJS 10 that swaps out V8 for this enhanced JVM. In this way you can fuse together NodeJS and the JVM, allowing apps
to smoothly access both worlds simultaneously with full JIT compilation.</p>
<h2 id="known-limitations">Known limitations<a href="#known-limitations" title="Permanent link">¬∂</a></h2>
<p>NodeJS really wants to load module files from the filesystem and nowhere else, so your Java app will need a <code>node_modules</code>
directory from where it's started. There are tricks to work around this and allow bundling of JS into JAR files as
libraries, but nothing done at the moment.</p>
<p>GraalVM uses NodeJS 10, not the latest versions.</p>
<p>You change <code>java</code> on the command line to <code>nodejvm</code> and that's all it needs, but many tools and IDEs expect the java
launcher to always be called <code>java</code>.  </p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

      
    </div></div>]]>
            </description>
            <link>https://mikehearn.github.io/nodejvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058252</guid>
            <pubDate>Wed, 11 Nov 2020 13:36:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Headless E-Commerce and Jamstack]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058125">thread link</a>) | @rcymerys
<br/>
November 11, 2020 | https://upsidelab.io/blog/e-commerce-headless-jamstack/ | <a href="https://web.archive.org/web/*/https://upsidelab.io/blog/e-commerce-headless-jamstack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The Web has gone a tremendously long way since it's conception in 1989. It has progressed to the point where it‚Äôs so omnipresent and the user base is so vast that it‚Äôs becoming harder and harder to scale and expand existing services to satisfy the ever growing demand. &nbsp;The <em>traditional </em>architecture is starting to show its limitations and suddenly it‚Äôs becoming clear that what was considered <strong>the way</strong> to develop web applications is not going to cut it under the current circumstances.</p><p><strong>Monolithic architecture</strong></p><p>Also known as the <em>traditional </em>architecture, is what powers the vast majority of what the Web has to offer. It‚Äôs the all-in-one bundle of web applications - the backend is tightly coupled with the frontend and the whole app is just one big ecosystem.</p><figure><img src="https://publish.upsidelab.io/blog/content/images/2020/09/final4.png" alt=""><figcaption>The monolithic architecture</figcaption></figure><p>For a big chunk of time this approach was the undisputed king of web development. And while it‚Äôs without a doubt still reigning and growing steadily, the consumer trends evolve in a direction that makes many service providers reconsider the usage of this kind of tools, namely WordPress.</p><p>Back in the day running a website was enough to ensure that you target the majority of Internet dwellers. Nowadays, thanks to some monumental advancements in technology, the users have many more ways to go online - phones, smartwatches, voice assistants, AR glasses etc.</p><figure><img src="https://publish.upsidelab.io/blog/content/images/2020/09/monolith_fail2.png" alt=""><figcaption>A monolith's problems with multi-channelled user base</figcaption></figure><p>This makes one of the problems very clear - because of how tightly coupled the presentational layer is with the backend logic it‚Äôs a major hassle (or downright impossible) to expand the application so it can support more channels than it was originally designed to do.</p><p>For example, one could imagine that it would be solvable by running multiple instances of the application, each designed to handle a specific medium. Apart from the obvious development overhead this would generate, managing multiple systems simultaneously would be a major headache - e.g. in e-commerce websites product discounts would have to be entered and synchronized separately for each running instance.</p><p>This is especially true for businesses that are heavily reliant on how accessible their web services are, most notably e-commerce websites. Expansion beyond the web is often the key to new market penetration and is often what distinguishes ‚Äújust‚Äù successful ventures from market leaders.</p><p>Another thing that caused the shift away from monolithic architecture is the fact that the server would render pages visited by users with each request. This greatly impacts the user experience and makes the website feel less ‚Äúsnappy‚Äù.</p><p>While this is but a drop in the sea of shortcomings, it‚Äôs what widely believed to be the turning point and reason why alternative solutions are gaining traction exponentially.</p><p><strong>Headless architecture</strong></p><p>Despite its <em>buzzwordy</em> status nowadays, the concept of <em>headless </em>software is dead simple and has been around for ages. ‚ÄúHead‚Äù in this context means ‚Äúgraphical interface‚Äù - you can probably see where this is going. The <em>headless </em>approach completely removes the presentational layer, leaving just the backend logic that can be exposed through a universally accessible API layer.</p><figure><img src="https://publish.upsidelab.io/blog/content/images/2020/09/headless2.png" alt=""><figcaption>The headless architecture</figcaption></figure><p>Instead of a singular, tightly coupled with the logic and heavily specialized frontend, its focused on providing applications with the raw content/services it offers. One of such apps can be responsible for consuming the data and presenting it to the end user.</p><p>That‚Äôs precisely what‚Äôs needed when it comes to building multi-channel applications. Since the presentational layer is completely interchangeable and the core API is universally accessible, there could be multiple entry points interacting with the app, each designed to support a different medium.</p><figure><img src="https://publish.upsidelab.io/blog/content/images/2020/09/headless2-1-.png" alt="" srcset="https://publish.upsidelab.io/blog/content/images/size/w600/2020/09/headless2-1-.png 600w, https://publish.upsidelab.io/blog/content/images/size/w715/2020/09/headless2-1-.png 715w"><figcaption>Headless handling multi-channeled user base</figcaption></figure><p><strong>External integrations</strong></p><p>Nowadays, a big portion of an application‚Äôs features can be extracted to third-party SaaS platforms. Not only does this reduce a product‚Äôs time-to-market but, since they usually cover some highly technical features, can also improve the systems overall security. Some of them could be payment gateways, delivery services, ERP systems etc.</p><p>The most common monolithic choice on the Web is WordPress - a staple among traditional Content Management Systems. It offers a user-friendly interface for managing content and basic customizability through various plugins. There are extensions providing integrations with the most <em>common</em> of services which could prove sufficient for some very generic applications.</p><p>The word ‚Äúcommon‚Äù was emphasised for a reason though. If the chosen platform doesn‚Äôt offer a specific plugin that is required by the project‚Äôs requirements, there is no other way but to either write it from scratch (often in some obscure technology) or change the platform. Keep in mind that even the largest of traditional CMSs doesn‚Äôt support a portion of the third-party platforms, so you can expect to run into situations where a part of your project‚Äôs scope gets blocked by an unexisting plugin.</p><p>On the other hand, headless architecture ties in very nicely with external services and applications. As emphasised before, headless benefits greatly by dividing its functionalities between multiple components. To draw comparison with the aforementioned WordPress, we can consider what‚Äôs called a <em>headless CMS</em>, such as GraphCMS or Contentful. It provides the same functionality, that is content storage and a user friendly administration panel, without coupling it with any presentational layer and crippling it‚Äôs extendability in the process.</p><p><strong>Scalability</strong></p><p>At first glance scaling monolithic applications seems trivial - multiple instances of it can be hidden behind a load balancer to scale horizontally. However, as the application grows in size, scaling becomes increasingly difficult and inefficient.</p><p>For example, it‚Äôs impossible to scale one single part of the application independently. In cases when there are few different bottlenecks scaling the entire system is very cost inefficient.</p><p>Moreover, for stateful applications, you have to take user sessions into account and incorporate mechanisms like <em>sticky sessions </em>to ensure that users with existing sessions are routed to the same physical machine each time.</p><p>On the other hand, it‚Äôs easy to imagine how headless can improve scalability - the application can be divided into autonomous services and scaled independently.</p><p><strong>Workflow differences</strong></p><p>Apart from the obvious structural differences, both approaches differ heavily when it comes to implementation, maintenance and development workflow in general.</p><p>Developer teams working on large monolithic applications have to constantly be aware of all the systems components and it‚Äôs impossible to work on a single part independently.</p><p>Moreover, continuous deployment is, to put it lightly, problematic when working on monolithic apps. With each new release the entire application has to be redeployed. This forces teams working on different parts of the system, e.g. the UI and the business logic, to coordinate their deployments.</p><p>On the other hand the compartmentalised nature of headless architecture makes it an ideal choice for teams consisting of multiple developers. Each part of the application can be independently managed, tested and deployed without interfering with the rest of the system.</p><p><strong>Enter Jamstack</strong></p><p>Jamstack is one of the hottest trends in web development right now. It‚Äôs focused on certain assumptions and best practices rather than on certain technologies. The performance and security improvements it brings to the table make it very popular among modern website developers and service providers.</p><p>At its core is the premise that the frontend doesn‚Äôt depend on a web server. All dynamic data is requested and handled by <strong>J</strong>avascript, delivered through <strong>A</strong>PI‚Äôs and all the <strong>M</strong>arkup is pre-generated during build time. The entire application is then distributed through a Content Delivery Network which greatly increases the websites responsiveness and improves overall user experience.</p><figure><img src="https://publish.upsidelab.io/blog/content/images/2020/09/headless1-1.png" alt="" srcset="https://publish.upsidelab.io/blog/content/images/size/w600/2020/09/headless1-1.png 600w, https://publish.upsidelab.io/blog/content/images/size/w714/2020/09/headless1-1.png 714w"><figcaption>The Jamstack</figcaption></figure><p>Jamstack stands in complete opposition to traditional, monolithic applications. It shifts the focus from an omniscient, one-man-army backend to lean and powerful frontend. Extracting all logic to external API‚Äôs improves the sites overall security by reducing the number of potential attack vectors.</p><p>As it happens, Jamstack works hand in glove with headless applications.</p><p><strong>Headless + Jamstack in practice</strong></p><p>Building Jamstack websites has become very easy since the conception of tools such as Nuxt or Gatsby. They are based on tools very familiar to developers, Vue and React respectively, so they are right there in the comfort-zone.</p><p>Such frameworks intelligently build HTML files from templates filled with pre-fetched data so they can be served through CDNs as static assets. This, as one might expect, is a huge boost to the site‚Äôs performance, making navigation almost instantaneous. CDN service providers also make it easy to force the use of SSL on your sites (sometimes it‚Äôs as simple as flipping a switch), which can otherwise be problematic since, by design, there is no underlying server.</p><p>Serving static assets is not that useful if there is no way of populating the site with easily modifiable content. That‚Äôs where the aforementioned headless CMS‚Äôs come into play. They offer exactly the same content modeling functionality as traditional solutions, such as WordPress, and expose it through a blazing fast API. The chosen Jamstack framework will pre-fetch all the data it needs during the page generation phase and build static HTML files according to the templates that were defined. That‚Äôs an ideal setup for websites like blogs or product catalogs, where user interaction is scarce and content serving speed is the main bottleneck.</p><p>There is one caveat though - since the pages are pre-generated, they won‚Äôt automatically display new content that was created. A good majority of SaaS‚Äôs offer a well-known mechanism to automatically trigger rebuilds when a change in content is ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://upsidelab.io/blog/e-commerce-headless-jamstack/">https://upsidelab.io/blog/e-commerce-headless-jamstack/</a></em></p>]]>
            </description>
            <link>https://upsidelab.io/blog/e-commerce-headless-jamstack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058125</guid>
            <pubDate>Wed, 11 Nov 2020 13:22:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Defense of GnuPG]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058064">thread link</a>) | @m3rcury
<br/>
November 11, 2020 | https://www.oyd.org.tr/en/articles/defense-of-gpg/ | <a href="https://web.archive.org/web/*/https://www.oyd.org.tr/en/articles/defense-of-gpg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
  <article>
    
     
      
    <p>For several years, there has been an uprasing against GPG. Every now and then someone writes up a blog post and condemn OpenPGP and it‚Äôs implementations for being too hard to use or too easy to mess up. The GPG side is mostly silent. So, this article is in defence of GPG.</p>
<p>Main points made against GPG can be listed like this:</p>
<ol start="0">
<li>GPG is too complicated for ‚Äúnormal‚Äù users</li>
<li>Because GPG is too complicated, it‚Äôs userbase is minuscule</li>
<li>Email is inherently impossible to secure so don‚Äôt even bother encrypting it. Just abandon GPG</li>
<li>Nobody bothers to read emails of ‚Äúnormal‚Äù people so don‚Äôt encrypt</li>
<li>TLS has done much more for email security than GPG</li>
<li>GPG is error prone and security wise it is dangerous for people to use it when actual security is needed</li>
<li>For various reasons, only cryptonerds use it and take pride on GPG so it is lame</li>
<li>GPG‚Äôs trust model (web of trust) is broken and only cryptonerds are keeping it alive</li>
<li>GPG is old</li>
<li>There are better [insert anything involving app like crypto tool] why bother with GPG</li>
<li>GPG crypto has [Insert any long term RSA based cryptography‚Äôs short comings and trust problems] why not use modern crypto</li>
</ol>
<p>During these discussion, these point are mostly assumed to be true;</p>
<ol start="0">
<li>People are stupid and lazy so are the users of encryption tools</li>
<li>Since users are stupid and lazy tools should be designed keeping that in mind</li>
<li>Designing for stupid and lazy requires stripping people from anything than needed(i.e freedom)</li>
<li>If security is not absolute it is worthless</li>
<li>If privacy is not absolute, anonymity is worthless</li>
<li>If your adversary cannot compromise  of your security then there is no need for GPG even for privacy</li>
</ol>
<h2 id="whats-the-problem">What‚Äôs The Problem</h2>
<p>We name periods of human history by their defining property. That property is mainly what drives human society and culture at that current age. The iron age was shaped by the superiority of iron as a material for weapons and agricultural tools. Today‚Äôs digitally shaped age is called <a href="https://www.schneier.com/essays/archives/2012/11/when_it_comes_to_sec.html">digital feudalism</a> and it governs our lives. Just like regular feudalism the resources of society is controlled by few, generated by many and the feudal lords of ours claim their right to their thrones through their infrastructure.</p>
<p>We as users are fueling the rise of the digital technologies but handful of companies are controlling and profiting from it. Just like peasants of the middle ages, you are seen as basic people who cannot understand the complex life that only a few selected elites can. It is what you are asusmed to be: simple people who wants simple things, like ‚Äúapps‚Äù that will give you what you assumed to need and nothing more. It is the same old condescending view of serfs, now given to you by companies, ignorant and arrogant developers and overall by capitalism.</p>
<p>Today saying ‚Äúwhat do I understand about computers‚Äù is equivalent to saying ‚ÄúI don‚Äôt know how to light a fire‚Äù in stone age! Just because someone might be feeding you back in those days did not mean that you could survive on your own. The same applies to current digital age. Just because someone is doing <strong>stuff</strong> for you does not ensure your digital survival. There was no easy way to light a fire back then and there will be no ‚Äúpress this button‚Äù easy way to take back the power in the digital age. Whoever claims people <strong>want</strong> or <strong>need</strong> only simple stupid apps and whoever denies the fact that we are living in digital feudalism are building a dystopian future where few elite unprecedentedly controls the future. Self determination is never given by anyone but can only be taken by everyone!</p>
<p>This ideology that ‚Äúpeople are stupid‚Äù and ‚Äúpeople want easy(read:stupid)‚Äù things dominates today‚Äôs end user software development. Good UX does not equal to simple. The real meaning in these expressions is: ‚Äúyou are too stupid to take responsibility for your self and to understand what‚Äôs going on, so we as technological elites will take care of you‚Äù. This is what‚Äôs the base of almost all GPG related criticism. GPG is too hard for people!</p>
<p>PGP, the preceder of GPG, was conceived in 1991 and this era was shaped by hackers. Not the hackers that main stream media shows in black hoods and authorities around the world paint as people with no moral boundaries. Hackers are the people who playfully expanded what is available to what is possible. This attitude brought general public; personal computers, GNU/Linux operating system that are now powering almost every backbone in the world, 3D printers etc. PGP was shaped by the empowerment of that era, not the ‚Äúthere is an app for that‚Äù era of today which is shaped by multi-billion dollar cooperation built upon the cultural and technological accumulation of hackers.</p>
<p>That brings us to the point: GPG is hard for people, but so were the general purpose computers around 20 years ago. Everything requires individual dedication and determination to learn and maintain. What happened with computers is that some people capitalised on the opportunity, poured money into devices and after hundreds of hours long R&amp;D those computers became ‚Äúeasy‚Äù. The outcome of that process was loss of the right to fix, more enclosed and restricted user environments and computers that works against us! So those who invested in computers can profit from their investment.</p>
<p>The same problem also exists for encryption. There was no real incentive for capitalists to invest in publicly accessible encryption. Solid encryption would make reaching data possible only for the user who owns it and this would be counter intuitive to the interest of capitalism. But today there is an incentive: people are afraid of what our digital world has become. They are afraid of their <a href="https://en.wikipedia.org/wiki/Global_surveillance_disclosures_(2013%E2%80%93present)">government‚Äôs abuse of power</a>, they are afraid of <a href="https://www.theguardian.com/technology/2017/sep/26/tinder-personal-data-dating-app-messages-hacked-sold">companies taking advantage of their lives</a>, they are afraid that their <a href="https://en.wikipedia.org/wiki/Facebook%E2%80%93Cambridge_Analytica_data_scandal">involment in democracy will be lost</a>. People are afraid and there is no better time to sell something. That‚Äôs why Apple is now selling <a href="https://en.wikipedia.org/wiki/FBI%E2%80%93Apple_encryption_dispute">privacy as a product</a> and that is why every communication service regardless their privacy invasive tendencies are <a href="https://faq.whatsapp.com/en/android/28030015/">promoting encryption</a>. What is missing is that people are still an object in this case. Whoever holds the key holds the future and there is no alternative to GPG that gives the user the best self determination!</p>
<p>So, how is GPG doing while the craze to own next killer encryption app continiue? <a href="https://en.wikipedia.org/wiki/Werner_Koch"><strong>Werner Koch</strong></a>, is the single person maintaining GPG. He was almost about to give up on GPG for <a href="https://www.propublica.org/article/the-worlds-email-encryption-software-relies-on-one-guy-who-is-going-broke">economic reasons</a> when the <a href="https://en.wikipedia.org/wiki/Edward_Snowden">Snowden incident</a> has chanced his decision. The world‚Äôs whole server infrastructure security and personal freedom rests on his shoulder and he had to ask for help. It is a huge difference in investment/impact ratio when compared to every other encryption tool. GPG exist by determination and not through capital pressure.</p>
<p>In every ‚ÄúGPG is dead‚Äù cry almost always includes some <strong>killer</strong> new technology that makes more <strong>sense</strong> than GPG. Let‚Äôs talk about them for a while.</p>
<h2 id="signal">Signal</h2>
<p>A big hit in secure instant messaging. Signal is build upon proprietary software Textsecure and RedPhone that had been once developed by <a href="https://en.wikipedia.org/wiki/Moxie_Marlinspike">Moxie Merlinspike</a> and his co-founder Stuart Anderson. Signal Protocol utilizing <a href="https://en.wikipedia.org/wiki/Double_Ratchet_Algorithm">double ratchet</a> encryption is a game changer for modern connectivity and implemented in [several applications[(https://signal.org/blog/whatsapp-complete/). Signal applications and server code is free software but <a href="https://oyd.org.tr/en/articles/stop-saying-freedom-is-a-private-matter/">their developers and business model is not</a>. It is <a href="#https://matrix.org/blog/2020/01/02/on-privacy-versus-freedom/">yet another walled garden with no federation</a> and <a href="https://moxie.org/blog/gpg-and-me/">claiming GPG is dead</a>.</p>
<h2 id="matrix-protocol">Matrix Protocol</h2>
<p><a href="https://en.wikipedia.org/wiki/Matrix_(protocol)">Matrix protocol</a> is an open standard for general communication needs. Like <a href="https://en.wikipedia.org/wiki/Xmpp">XMPP -Extensible Messaging and Presence Protocol-</a> it is designed to be implemented widely and serve various modern needs of communication. End-to-end encryption is falling behind and there are still implementation problems but if everything goes well Matrix Protocol could be a modern free future for communication. The only problem is that Matrix Protocol is still an instant communication system and the cryptography behind it is specialized only for that purpose.</p>
<h2 id="insert-any-app-or-protocol">[Insert Any App or Protocol]</h2>
<p>Almost all have some of these short comings:</p>
<ul>
<li>Walled Gardens with no federation</li>
<li>Non-free dependencies</li>
<li>Single purpose</li>
<li>Symmetrical communication while e-mail being asymmetrical</li>
<li>Opaque key generation and management</li>
</ul>
<p>Modern messaging softwares do have merits that are desirable such as <a href="https://en.wikipedia.org/wiki/Forward_secrecy">forward secrecy</a>, <a href="https://en.wikipedia.org/wiki/Elliptic_curve_cryptography">recent algorithms with shorter keys</a>(read: not necessarily more secure) and more frictionless key management(which heavily depends on central key servers and personal data). All these merits are, to some degree, desireable for GPG too but those tool‚Äôs have different design requirements than GPG. GPG can and will become better at most points. When the case is single person against a multi-billion dollar industry, this should not count as a fair trial.</p>
<p>What GPG is offering in exchange is <strong>freedom</strong>, not just another ‚Äúapp‚Äù that walls it‚Äôs users in and here is why:</p>
<h2 id="gpg-giving-you-the-total-control-of-your-key-and-identity">GPG giving you the TOTAL control of your key and identity</h2>
<p>This primary point is so important, the rest seems moot. GPG is the most liberating piece of software EVER. What GPG is capable of and how it is implemented almost always secondary to the fact that <strong>you</strong> as the user in need of cryptography <strong>control</strong> the key. You can export it, expand it, change it, renew it, <a href="https://github.com/intra2net/paperbackup">print it on paper</a>, revoke it. The fact that you own and control your key actually makes it possible for you to build your identity around that key. This is almost like being your own certificate authority and issuing your certificates as you please.</p>
<p>This comes with the trust problem of cryptopgraphy. If anyone can generate a key with any metadata, then who is deciding on a particular key belong to an individual. The answer is <strong>no one</strong> and <strong>everyone</strong>. <a href="https://en.wikipedia.org/wiki/Web_of_trust">Web of trust</a> is an answer to this question for most part. You basically sign keys of people who you know and the people who trust you, trusts your friends.</p>
<p>This implementation is <a href="https://web.archive.org/web/20131009142806/https://www.rubygems-openpgp-ca.org/blog/theres-trust-and-then-theres-trust-and-then-theres-trust.html">considered broken</a> by a lot of people and there is a natural down side of making your social network public. That being said building trust ‚Ä¶</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.oyd.org.tr/en/articles/defense-of-gpg/">https://www.oyd.org.tr/en/articles/defense-of-gpg/</a></em></p>]]>
            </description>
            <link>https://www.oyd.org.tr/en/articles/defense-of-gpg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058064</guid>
            <pubDate>Wed, 11 Nov 2020 13:14:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Graphical Output from Our Custom RISC-V Operating System in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058039">thread link</a>) | @pavehawk2007
<br/>
November 11, 2020 | https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>An operating system is used to make our job easier when using graphics. In our instance, in addition to everything else. In this post, we will be writing a GPU (graphics processing unit) driver using the VirtIO specification. In here, we will allow user applications to have a portion of the screen as RAM‚Äìwith what is commonly known as a <em>framebuffer</em>.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#pixels">Pixels and Resolution</a></li><li><a href="#virtio">The GPU VirtIO Device</a></li><li><a href="#init">Initialization</a></li><li><a href="#invalid">Invalidation and Transfer</a></li><li><a href="#response">Device Responses</a></li><li><a href="#user">User Space</a></li><li><a href="#api">Simple Graphics API</a></li><li><a href="#conclusion">Conclusions and Further Reading</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We command the virtual GPU (virtio-gpu) by sending certain commands to the host (the device). The guest (the OS driver) has an allocation of RAM that becomes the framebuffer. The driver then tells the device, ‚Äúhey, here‚Äôs the RAM that we‚Äôre going to use to store pixel information.‚Äù</p>



<p>The RAM is contiguous in our OS, but according to the specification, this isn‚Äôt strictly required. We will give the driver a rectangle. Everything that falls within that rectangle will be copied to the host. We don‚Äôt want to keep copying the entire buffer over and over again.</p>



<p>We will be using the virtio protocol that we used for the block driver here, so I won‚Äôt rehash the general virtio protocol. However, the device-specific structures are a bit different, so we‚Äôll cover that part more in depth.</p>



<hr>



<h2 id="pixels">Pixels and Resolution</h2>



<p>A framebuffer must be large enough to store \(\text{width}\times\text{height}\times\text{pixel size}\) number of bytes. There are \(\text{width}\times\text{height}\) number of pixels. Each pixel has a 1-byte red, green, blue, and alpha channels. So, each pixel is exactly 4 bytes with the configuration we‚Äôre going to specify.</p>



<p>The framebuffer for our junior GPU driver is going to support a fixed resolution of \(640\times 480\). If you‚Äôre a child of the 90s, you saw this resolution a lot. In fact, my first computer, a Laser Pal 386, had a 16-color monitor with a resolution of 640 pixels wide with 480 pixels tall.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png" alt="" width="458" height="281" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png 611w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13-300x184.png 300w" sizes="(max-width: 458px) 100vw, 458px"></a></figure></div>



<p>There are red, green, and blue pixels so close together that by varying the intensity of these three channels, we can change the color. The closer we get to our monitors, the easier a pixel is to see.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png" alt="" width="285" height="288" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png 380w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14-297x300.png 297w" sizes="(max-width: 285px) 100vw, 285px"></a><figcaption>Pixels on a Viewsonic VX2770SMH-LED monitor.</figcaption></figure></div>



<p>You can see these little squares. If you squint enough, you can see that they aren‚Äôt pure white. Instead, you can see bits of red, blue, and green. That‚Äôs because each one of these little squares is subdivided into three colors: yep, red, green, and blue! To make white, these pixels are turned up to 11 (get the joke?). To make black, we turn off all three channels of that pixel.</p>



<p>The resolution refers to how many of these squares are on our monitor. This is a 1920√ó1080 monitor. That means that there are 1920 of these squares going left to right, and there are 1080 of these squares from top to bottom. All in all, we have \(1920\times 1080=2,073,600\) number of pixels. Each one of these pixels is expressed using 4 bytes in the framebuffer, meaning we need \(2,073,600\times 4=8,294,400\) bytes in RAM to store the pixel information.</p>



<p>You can see why I limited our resolution to 640√ó480, which only requires \(640\times 480\times 4=1,228,800\) bytes‚Äìa bit over a megabyte.</p>



<hr>



<h2 id="virtio">The GPU VirtIO Device</h2>



<p>The GPU device requires us to read a more up-to-date VirtIO specification. I‚Äôll be reading from version 1.1, which you can get a copy here: <a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html">https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html</a>. Specifically, chapter 5.7 ‚ÄúGPU Device‚Äù. This is an <em>unaccelerated</em> 2D device, meaning that we must use the CPU to actually form the framebuffer, then we transfer our CPU formulated memory location to the host GPU, which is then responsible for drawing it to the screen.</p>



<p>The device uses a request/response system, where we the driver make a command to request something from the host (the GPU).  We add a bit of extra memory into our request so that the host can formulate its response. When the GPU interrupts us, we can take a look at this response memory location to see what the GPU told us. This is much like the <em>status</em> field on the block driver, where the block device tells us the status of our last request.</p>



<p>Each request starts with a <em>Command Header</em>, which in Rust looks as follows:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
struct CtrlHeader {
	ctrl_type: CtrlType,
	flags: u32,
	fence_id: u64,
	ctx_id: u32,
	padding: u32
}</pre>



<p>The header is common for all requests and all responses. We can differentiate by the CtrlType enumeration, which is:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum CtrlType {
	/* 2d commands */
	CmdGetDisplayInfo = 0x0100,
	CmdResourceCreate2d,
	CmdResourceUref,
	CmdSetScanout,
	CmdResourceFlush,
	CmdTransferToHost2d,
	CmdResourceAttachBacking,
	CmdResourceDetachBacking,
	CmdGetCapsetInfo,
	CmdGetCapset,
	CmdGetEdid,
	/* cursor commands */
	CmdUpdateCursor = 0x0300,
	CmdMoveCursor,
	/* success responses */
	RespOkNoData = 0x1100,
	RespOkDisplayInfo,
	RespOkCapsetInfo,
	RespOkCapset,
	RespOkEdid,
	/* error responses */
	RespErrUnspec = 0x1200,
	RespErrOutOfMemory,
	RespErrInvalidScanoutId,
	RespErrInvalidResourceId,
	RespErrInvalidContextId,
	RespErrInvalidParameter,
}</pre>



<p>I took this directly from the specification, but Rust-ified the names to avoid getting yelled at by the linter.</p>



<h3>Pixel Formats</h3>



<p>Recall that the framebuffer is just a bunch of bytes in memory. We need to put a structure behind the framebuffer so the host (the GPU) knows how to interpret your sequence of bytes. There are several formats, but all-in-all, they just re-arrange the red, green, blue, and alpha channels. All are exactly 4 bytes, which makes the <em>stride</em> the same. The stride is the spacing from one pixel to another‚Äì4 bytes.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum Formats {
	B8G8R8A8Unorm = 1,
	B8G8R8X8Unorm = 2,
	A8R8G8B8Unorm = 3,
	X8R8G8B8Unorm = 4,
	R8G8B8A8Unorm = 67,
	X8B8G8R8Unorm = 68,
	A8B8G8R8Unorm = 121,
	R8G8B8X8Unorm = 134,
}</pre>



<p>The type, <em>unorm</em>, is an 8-bit (1-byte) unsigned value from 0 through 255, where 0 represents no intensity and 255 represents full intensity, and a number in between is a linear-interpolation between no and full intensity. Since there are three color (and one alpha), that gives us \(256\times 256\times 256=16,776,216\) different colors or levels of colors.</p>



<p>For this tutorial, I selected <code>R8G8B8A8Unorm = 67</code>, which has red first, green second, blue third, and alpha fourth. This is a common ordering, so I‚Äôll select it to make it easy to follow along.</p>



<p>Our selected format makes the pixel structure look as follows:</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png" alt="" width="512" height="307" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-300x180.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-768x461.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1536x921.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-2048x1228.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></a></figure></div>



<p>Recall that each individual component R, G, B, and A are each one byte a piece, so each Pixel referred to by (x, y) is 4 bytes. This is why our memory pointer is a Pixel structure instead of a byte.</p>



<hr>



<h2 id="init">Initialization</h2>



<p>Just like all other virtio devices, we set up the virtqueues first and then we work on device-specific initialization. In my code, I just directly copied-and-pasted from the block driver into the gpu driver. The only thing I added to the Device structure was the framebuffer and dimensions of the framebuffer.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">pub struct Device {
	queue:        *mut Queue,
	dev:          *mut u32,
	idx:          u16,
	ack_used_idx: u16,
	framebuffer:  *mut Pixel,
	width:        u32,
	height:       u32,
}</pre>



<p>The specification tells us to do the following in order to initialize the device and get things ready to draw. I Rust-ified some of the content to match our enumerations.</p>



<h4>Create a framebuffer and configure scanout</h4>



<ol><li>Create a host resource using <code>CmdResourceCreate2d</code>.</li><li>Allocate a framebuffer from guest ram, and attach it as backing storage to the resource just created, using <code>CmdResourceAttachBacking</code>.</li><li>Use <code>CmdSetScanout</code> to link the framebuffer to a display scanout.</li></ol>



<h3>A Request Structure</h3>



<p>Recall that our request and response come packaged together. We will put them in separate descriptors, but whenever we get a response back from the device, it is going to be easier if we free just once to free both the request and response. So, in Rust, I created the Request structure to support doing this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">struct Request&lt;RqT, RpT&gt; {
	request: RqT,
	response: RpT,
}
impl&lt;RqT, RpT&gt; Request&lt;RqT, RpT&gt; {
	pub fn new(request: RqT) -&gt; *mut Self {
		let sz = size_of::&lt;RqT&gt;() + size_of::&lt;RpT&gt;();
		let ptr = kmalloc(sz) as *mut Self;
		unsafe {
			(*ptr).request = request;
		}
		ptr
	}
}</pre>



<h4>Step 1: Create host resource</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request::new(ResourceCreate2d {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceCreate2d,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	format: Formats::R8G8B8A8Unorm,
	width: dev.width,
	height: dev.height,
});
let desc_c2d = Descriptor {
	addr: unsafe { &amp;(*rq).request as *const ResourceCreate2d as u64 },
	len: size_of::&lt;ResourceCreate2d&gt;() as u32,
	flags: VIRTIO_DESC_F_NEXT,
	next: (dev.idx + 1) % VIRTIO_RING_SIZE as u16,
};
let desc_c2d_resp = Descriptor {
	addr: unsafe { &amp;(*rq).response as *const CtrlHeader as u64 },
	len: size_of::&lt;CtrlHeader&gt;() as u32,
	flags: VIRTIO_DESC_F_WRITE,
	next: 0,
};
unsafe {
	let head = dev.idx;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d_resp;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).avail.ring[(*dev.queue).avail.idx as usize % VIRTIO_RING_SIZE] = head;
	(*dev.queue).avail.idx = (*dev.queue).avail.idx.wrapping_add(1);
}</pre>



<p>All we‚Äôre really telling the GPU here is our resolution and the format of the framebuffer. When we create this, the host gets to configure itself, such as allocating an identical buffer to make transfers from our OS.</p>



<h4>Step 2: Attach framebuffer backing.</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request3::new(AttachBacking {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceAttachBacking,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	nr_entries: 1,
},
MemEntry {
	addr: dev.framebuffer as u64,
	length: dev.width * dev.height * size_of::&lt;Pixel&gt;() as u32,
	‚Ä¶</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058039</guid>
            <pubDate>Wed, 11 Nov 2020 13:11:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualization of connections between politicians and orgs awarded gov contracts]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25057931">thread link</a>) | @roxanneonhacker
<br/>
November 11, 2020 | https://sophieehill.shinyapps.io/my-little-crony/ | <a href="https://web.archive.org/web/*/https://sophieehill.shinyapps.io/my-little-crony/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
          A visualization of the connections between
          <strong>Tory politicians</strong>
          and
          <strong>companies being awarded government contracts during the pandemic,</strong>
          based on reporting by
          <a href="https://www.opendemocracy.net/en/dark-money-investigations/">openDemocracy,</a>
          <a href="https://bylinetimes.com/">Byline Times,</a>
          and more.
        </p>
    </div></div>]]>
            </description>
            <link>https://sophieehill.shinyapps.io/my-little-crony/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057931</guid>
            <pubDate>Wed, 11 Nov 2020 12:57:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced System-on-Chip Design Lecture Notes]]>
            </title>
            <description>
<![CDATA[
Score 204 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25057889">thread link</a>) | @allending
<br/>
November 11, 2020 | https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/ | <a href="https://web.archive.org/web/*/https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057889</guid>
            <pubDate>Wed, 11 Nov 2020 12:51:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[92% efficacy of Sputnik V Covid-19 vaccine]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057881">thread link</a>) | @pama
<br/>
November 11, 2020 | https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/ | <a href="https://web.archive.org/web/*/https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<ul>
<li><i>The Sputnik V vaccine efficacy amounted to 92% (calculation based on the 20 confirmed COVID-19 cases split between vaccinated individuals and those who received the placebo). Currently 40,000 volunteers are taking part in double-blind, randomized, placebo-controlled Phase III of Sputnik V clinical trials, out of which over 20,000 have been vaccinated with the first dose of the vaccine and more than 16,000 with both the first and second doses of the vaccine. </i></li>
<li><i>Efficacy was demonstrated on the basis of a first interim analysis obtained 21 days after the first injection. </i></li>
<li><i>There were no unexpected adverse events during the trials. Monitoring of the participants is ongoing. </i></li>
<li><i>The world‚Äôs first registration of COVID-19 vaccine, done in Russia on the 11th of August under the emergency use authorization mechanism, enables the Russian Federation to administer the vaccine outside of the clinical trials to volunteers such as medics and other high-risk groups. Trials conducted under the civil use of the vaccine in Russia (not being a part of clinical trials) based on the monitoring of additional 10,000 vaccinated confirmed vaccine efficacy at a rate of over 90%. </i></li>
<li><i>The interim research data will be published by the Gamaleya Center team in one of the leading international peer-reviewed medical journals. Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report. </i></li>
<li><i>Currently Sputnik V Phase III clinical trials are approved and are undergoing in Belarus, UAE, Venezuela and other countries, as well as Phase II-III ‚Äì in India. </i></li>
<li><i>The Sputnik V vaccine is based on a well-studied human adenoviral vector platform that had proven safe and effective with no long-term side effects in more than 250 clinical trials globally conducted during the past two decades (while the history of use of human adenoviruses in vaccine development started in 1953). More than 100,000 people have received approved and registered drugs based on the human adenoviral vectors. </i></li>
<li><i>The uniqueness of the Russian vaccine is in using two different human adenoviral vectors that enable to provide strong and long-term immune response after the second injection.</i> </li>
</ul>
<p>
<b>Moscow, 11.11.2020</b> ‚Äì The National Research Center for Epidemiology and Microbiology named after N.F. Gamaleya of the Ministry of Health of the Russian Federation (Gamaleya Center) and the Russian Direct Investment Fund (RDIF, Russia‚Äôs sovereign wealth fund), announce that the Sputnik V vaccine, the world's first registered vaccine against coronavirus (registered on the 11th of August under the emergency use authorization mechanism) created on the well-studied platform of human adenoviral vectors, demonstrated high efficacy. The confirmation is based on the first interim data from the largest double-blind, randomized, placebo-controlled Phase III clinical trials in Russia involving 40,000 volunteers.
</p>
<p>
The trials evaluated efficacy among over 16,000 volunteers who received the vaccine or placebo 21 days after the first injection. As a result of a statistical analysis of 20 confirmed cases of coronavirus, the case split between vaccinated individuals and those who received the placebo indicates that the Sputnik V vaccine had an efficacy rate of 92% after the second dose.
</p>
<p>
Separately, in September the vaccine was first administered to a group of volunteers from the ‚Äúred zones‚Äù of Russian hospitals. The observation of additional 10,000 vaccinated volunteers representing medics and other high-risk groups under the civil use of the vaccine out of clinical trials also confirmed the vaccine‚Äôs efficacy rate of over 90 percent.
</p>
<p>
The data received will be published by Gamaleya&nbsp;Center researchers in one of the world‚Äôs leading peer-reviewed medical academic journals following an independent valuation of the data by leading epidemiology experts. Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report.
</p>
<p>
As of November 11, as part of the clinical trials in Russia‚Äôs 29 medical centers, more than 20,000 volunteers were vaccinated with first dose and over 16,000 volunteers with the first and the second dose of the vaccine.
</p>
<p>
In addition, as of November 11, no unexpected adverse events were identified as part of the research. Some of those vaccinated had short-term minor adverse events such as pain at the injection site, flu-like syndrome including fever, weakness, fatigue, and headache.
</p>
<p>
During the clinical trials, the safety of the vaccine is constantly being monitored; information is analysed by the Independent Monitoring Committee comprising of leading Russian scientists. Collection, quality control and data processing is conducted in line with ICH GCP standards and involving active participation of Moscow‚Äôs Health Department and Crocus Medical, the contract research organization (CRO).
</p>
<p>
Observation of study participants will continue for six months after which the final report will be presented. Currently Sputnik V Phase III clinical trials are approved and are undergoing in Belarus, the UAE, Venezuela and other countries, as well as Phase II-III in India. A separate detailed study of the vaccine‚Äôs safety and immunogenicity for elderly people is being conducted.
</p>
<p>
The research data will be provided by RDIF to the national regulators of countries interested in purchasing the Russian vaccine in order to streamline the registration process.
</p>
<p>
<b>Mikhail Murashko, Minister of Health of the Russian Federation: </b><br>
‚ÄúThe use of the vaccine and the results of clinical trials demonstrate that it is an efficient solution to stop the spread of coronavirus infection, –∞ preventive healthcare tool, and this is the most successful path to defeat the pandemic.‚Äù
</p>
<p>
<b>Alexander Gintsburg, Gamaleya Center Director: </b><br>
‚ÄúThe publication of the interim results of the post-registration clinical trials that convincingly demonstrate Sputnik V vaccine‚Äôs efficacy gives way to mass vaccination in Russia against COVID-19 in the coming weeks. Thanks to the production scale up at new manufacturing sites, Sputnik V vaccine will soon be available for a wider population. This will break the current trend and lead to an eventual decrease in COVID-19 infection rates, first in Russia, then globally.‚Äù
</p>
<p>
<b>Denis Logunov, Gamaleya Center Deputy Director: </b><br>
‚ÄúPositive interim results of Phase III give reasons to expect a successful outcome of Sputnik V clinical trials. We will continue to process and analyse all the data and look to the future with optimism, expecting that results of our work will help end the pandemic sooner.‚Äù
</p>
<p>
<b>Kirill Dmitriev, CEO, Russian Direct Investment Fund: </b><br>
‚ÄúSputnik V is the first registered vaccine against COVID-19 in the world, the vaccine is based on safe and effective platform of human adenoviral vectors. More and more countries are recognizing the human adenoviral vector platform and plan to include these vaccines, as the most studied and known, in their respective national vaccine portfolio. I would also like to stress the importance of international cooperation and close partnership among vaccine-developing states. Vaccines should be above politics. The world needs a diversified portfolio of high-quality vaccines with Sputnik V, based on the well-tested human adenoviral vector platform, being an important element of it.‚Äù
</p>
<p>
The safety of vaccines based on human adenoviruses was confirmed in more than 75 international publications and more than 250 clinical trials conducted during the past two decades (while the history of use of human adenoviruses in vaccine development started in 1953). Adenovirus vectors are genetically modified viruses of the regular flu that cannot reproduce in a human body. When Sputnik V vaccine is used, the coronavirus itself does not enter the body as the vaccine only contains genetic information about part of its outer protein coat, the so called "spikes" forming its crown. This completely eliminates the possibility of getting infected as a result of vaccination while also causing the body's stable immune response.
</p>
<p>
On September 4, The Lancet, one of world‚Äôs leading medical journals, published a research paper on the results of Phase I and Phase II clinical trials of the vaccine that showed no serious adverse events and an effective immune response of those vaccinated.
</p>
<p>
Requests for more than 1.2 billion doses of Sputnik V vaccine came from over 50 countries. The vaccine supplies for the global market will be produced by RDIF‚Äôs international partners in India, Brazil, China, South Korea and other countries. The existing RDIF contracts with international partners enable the production of 500 million doses of the Sputnik V vaccine outside Russia annually. RDIF is now considering additional requests from a number of countries and companies to further increase its foreign production capacities.
</p>
<p>
On August 11, the Sputnik V vaccine developed by the Gamaleya Center was registered by Russia‚Äôs Health Ministry and became the world‚Äôs first registered vaccine against COVID-19. Detailed information on the Sputnik V vaccine, its human adenoviral vectors technological platform, and other details are available at&nbsp;<a href="http://" target="_blank">sputnikvaccine.com</a><a target="_blank" href="http://"></a>
</p>
<p>
<b>Be the first to learn about Sputnik V on social networks:</b>
</p>
<p>
<a href="https://twitter.com/sputnikvaccine" target="_blank">Twitter</a>
</p>
<p>
<a href="https://www.facebook.com/sputnikvaccine" target="_blank">Facebook</a>
</p>
<p>
<a href="https://www.instagram.com/sputnik_vaccine/" target="_blank">Instagram</a>
</p>
<p>
<a href="https://www.youtube.com/channel/UCLvQuKL3Nn7NnT9Jyi_dlgQ" target="_blank">Youtube</a>
</p>
<p>
***
</p>
<p>
<b>Russian Direct Investment Fund (RDIF) </b>is Russia's sovereign wealth fund established in 2011 to make equity co-investments, primarily in Russia, alongside reputable international financial and strategic investors. RDIF acts as a catalyst for direct investment in the Russian economy. RDIF‚Äôs management company is based in Moscow. Currently, RDIF has experience of the successful joint implementation of more than 80 projects with foreign partners totaling more than RUB1.9 trillion and covering 95% of the regions of the Russian Federation. RDIF portfolio companies employ more than 800,000 people and generate revenues which ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/">https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/</a></em></p>]]>
            </description>
            <link>https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057881</guid>
            <pubDate>Wed, 11 Nov 2020 12:51:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Richard Feynman and How to Learn Anything Well]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057821">thread link</a>) | @stanrivers
<br/>
November 11, 2020 | https://www.butwhatfor.com/feynman-technique/ | <a href="https://web.archive.org/web/*/https://www.butwhatfor.com/feynman-technique/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Disclosure: Links to Amazon are generally affiliated links. As an Amazon Associate, we earn from qualifying purchases, meaning a commission may be generated on purchased items.</p><div>
<div>
<div>
<div>
<p><strong><a href="https://www.butwhatfor.com/richard-feynman/">Richard P. Feynman </a></strong> (1918 ‚Äì 1988) was an American theoretical physicist often referred to as ‚ÄúThe Great Explainer‚Äù due to his ability to make complex topics understandable. While he won the Nobel Price in Physics in 1965 for his work developing quantum electrodynamics, today he is also famous for his forays into bongo drum playing, Tuvan throat singing, and safe cracking.</p>
<div>
<figure>
<p><a href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa27b9e93-62e5-4bb9-9632-c333e7503580_600x315.jpeg" target="_blank" rel="noopener noreferrer"><br>
<img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa27b9e93-62e5-4bb9-9632-c333e7503580_600x315.jpeg" alt="" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a27b9e93-62e5-4bb9-9632-c333e7503580_600x315.jpeg&quot;,&quot;height&quot;:315,&quot;width&quot;:600,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:53211,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}"><br>
</a></p>
</figure>
</div>
<p data-pm-context="[]">It is 1941 and you have a problem. While you haven‚Äôt yet gotten around to defining quantum electrodynamics or even started your work helping design the atomic bomb, you are nearing the end of your second year of graduate school. This means you have an exam soon.</p>
<p>That‚Äôs OK though. You know what to do. After all, you have made it this far already. You just do what you always do ‚Äì you pull out a notebook. And not just any notebook, but one especially well-prepared for the task at hand. Namely, a blank one.</p>
<p>A fitting title is needed for the first page. You think for a moment, smiling to yourself as you creatively run through all the options you could pick. But, alas, none of them seem right. You opt for the tried-and-true but never worn out choice. You write it down.</p>
<p>You are Richard P. Feynman, arguably the brightest young physics mind in the United States at the time, and you have just written ‚ÄúNotebook Of Things I Don‚Äôt Know About‚Äù on the title page.</p>
<p><em>Note: For more on Richard Feynman, check out <a href="https://amzn.to/36pgDxt">Genius: The Life and Science of Richard Feynman, </a>the definitive biography by James Gleick, or Feynman‚Äôs autobiographical writings in<a href="https://amzn.to/35krIk7"> ‚ÄúSurely You‚Äôre Joking, Mr. Feynman!‚Äù</a></em></p>
<h4>The Feynman Learning Technique</h4>
<p>Feynman realized early on that people can trick themselves into believing they understand something more deeply than they truly do. This self-delusion often comes from an earnest effort focused on learning the wrong thing ‚Äì learning the name of something as opposed to that which it truly is.</p>
<blockquote><p>The next Monday we were playing in a field, and a kid said to me, ‚ÄúWhat‚Äôs that bird? Do you know the name of that bird?‚Äù I said, ‚ÄúI haven‚Äôt the slightest idea.‚Äù He said, ‚ÄúWell, it is a brown‚Äëthroated thrush.‚Äù He said, ‚ÄúYour father doesn‚Äôt teach you anything.‚Äù</p>

<p>But my father had already taught me about the names of birds. Once we walked, and he said, ‚ÄúThat is a brown-throated thrush. In German it is called the Pfleegel fl√ºgel. In Chinese it is called Keewontong. In Japanese a Towhatowharra‚Äù, and so on.</p>

<p>And when you know all the names of that bird in every language, you know nothing, know absolutely nothing, about the bird‚Ä¶ So I had learned already that names don‚Äôt constitute knowledge‚Ä¶</p>

<p>We have to learn that these are the kinds of disciplines in the field of science that you have to learn ‚Äì to know when you know, and when you don‚Äôt know, and what it is you know, and what it is you don‚Äôt know.</p>

<p>You‚Äôve got to be very careful not to confuse yourself.</p></blockquote>
<p>Understanding this, Feynman was very careful to not delude himself into a superficial understanding of important topics. He developed a more holistic, multidisciplinary approach to learning that served him well throughout his career. While never specifically stated by Feynman as a set technique with steps, Feynman loved sharing with others enough that we can piece together his teachings, along with stories of his life, to better understand how he naturally approached learning anything new.</p>
<p>The combination of ideas, which many different authors outline slightly differently but are holistically the same, is known as <em>The Feynman Learning Technique</em>.</p>
<p>So how does this technique actually work?</p>
<h4>Step 1: Whatever you are trying to learn, take a stab at learning it</h4>
<p>The way that Feynman learned and internalized new ideas was to first attack them head on the old fashioned way ‚Äì by reading and thinking through them. The key emphasis in that sentence is on the word <em>thinking</em>. Famously, Feynman would read the abstract of a scientific paper, and before reading any further, attempt to solve the stated problem. Only then would he read through the rest of the paper. He was focused on mentally wrestling with an idea as opposed to letting someone else walk him to the final answer.</p>
<p>So the first step in the process is to pick something that you need (or better yet, desire) to learn and spend time with the new idea until you have internalized it to the best of your ability.</p>
<p>Now, you might aptly question, ‚ÄúWhat is this <em>hogwash</em>? Step 1 of this supposed wonderfully useful learning technique is to learn something? I‚Äôm out.‚Äù</p>
<p>Stop your <em>swining</em> and don‚Äôt worry ‚Äì there is more to it than that. Which brings us to the second step.</p>
<h4>Step 2: Write everything down, in as simple a way as possible, as if you were preparing a lecture for an inquisitive child</h4>
<p>This is where the notebook comes in. Open it. Close everything else.</p>
<p>From memory, write down everything you can about what you are trying to learn as if you were preparing to teach it to someone else. Preferably, pretend you are planning to teach the topic to a child ‚Äì the more you can simplify your language and the ideas, the more likely you are to find areas where you are hiding behind the name of something as opposed to true understanding.</p>
<blockquote><p>Test it this way: You say, ‚ÄúWithout using the new word which you have just learned, try to rephrase what you have just learned in your own language. Without using the word ‚Äòenergy,‚Äô tell me what you know now about the dog‚Äôs motion.‚Äù You cannot. So you learned nothing about science. That may be all right. You may not want to learn something about science right away.</p>

<p>You have to learn definitions. But for the very first lesson, is that not possibly destructive?</p></blockquote>
<p>At this point, you will probably notice that there are things that you are missing or don‚Äôt remember as well as you thought you did. Write those items down ‚Äì make a list of all the things you don‚Äôt know.</p>
<p>Now open everything back up and search out the answers to those items. Get to a point where you feel like you have conveyed what is required for your theoretical student to deeply understand the topic.</p>

<h4>Step 3: Ask questions as if you were a child to identify gaps in your understanding</h4>
<p data-pm-context="[]">Now you need to channel your inner child. Feynman‚Äôs neverending child-like curiosity is often viewed as the core, natural foundation that differentiated Feynman from other equally intelligent individuals. As children are wont to do, <a href="https://www.butwhatfor.com/invert-always-invert-avoid-failure-to-succeed/">start questioning every line you have written down</a>.</p>
<p>If we take a concept ‚Äì for example, the calculation of <a href="https://www.investopedia.com/terms/n/npv.asp">net present value</a>. Why do we discount cash received in the future? How do you choose a discount rate? Can the rate change between people? Should it change over time? Can you use a different discount rate in different periods? How many years of cash do you think about? How do you determine what those cash numbers will be in the future? What happens if cash is negative in the future? And so on.</p>
<p>If you are seeking Feynman-level understanding, it is not enough to merely know the math formula as that is akin to just knowing the name of something. You need to understand the information qualitatively and quantitatively supporting the formula ‚Äì only then should you feel confident in your understanding.</p>
<p>As you write out these new questions, you‚Äôll find you can answer some of these. Maybe even most of these. However, at some point, you will run out of answers for the incessant child ‚Äì write all these things down as items you ‚Äúdon‚Äôt know about.‚Äù Then go find the answers to these new topics.</p>
<p>By doing this, you are strengthening the foundation upon which your primary new learnings are ingrained in your head.</p>
<blockquote><p>But the problem, you see, when you ask&nbsp;<em>why</em>&nbsp;something happens, how does a person answer why something happens? For example, Aunt Minnie is in the hospital. <em>Why?</em> Because she went out, slipped on the ice, and broke her hip. That satisfies people. It satisfies, but it wouldn‚Äôt satisfy someone who came from another planet and who knew nothing about why when you break your hip do you go to the hospital‚Ä¶</p>

<p>And you begin to get a very interesting understanding of the world and all its complications. If you try to follow anything up, you go deeper and deeper in various directions. For example, if you go, ‚Äú<em>Why did she slip on the ice?‚Äù</em> Well, ice is slippery. Everybody knows that, no problem. But you ask&nbsp;<em>why is ice slippery?</em>&nbsp;That‚Äôs kinda curious. Ice is extremely slippery. It‚Äôs very interesting. <em>You say, how does it work?</em> You could either say, ‚ÄúI‚Äôm satisfied that you‚Äôve answered me. Ice is slippery; that explains it,‚Äù or you could go on and say, ‚Äú<em>Why is ice slippery?‚Äù</em> and then you‚Äôre involved with something, because there aren‚Äôt many things as slippery as ice‚Ä¶</p>

<p><em>A solid that‚Äôs so slippery?</em> Because it is, in the case of ice, when you stand on it (they say) momentarily the pressure melts the ice a little bit so you get a sort of instantaneous water surface on which you‚Äôre slipping. W<em>hy on ice and not on other things?</em> Because water expands when it freezes, so the pressure tries to undo the expansion and melts it. It‚Äôs capable of melting, but other substances get cracked when they‚Äôre freezing, and when you push them they‚Äôre satisfied to be solid.</p>

<p><em>Why does water expand when it freezes and other substances don‚Äôt?</em> I‚Äôm not answering your question, but I‚Äôm telling you how difficult the&nbsp;<em>why&nbsp;</em>question is. You have to know what it is that you‚Äôre permitted to understand and allow to be understood and known, and what it is you‚Äôre not. You‚Äôll notice, in this example, that the more I ask why, the deeper a thing is, the more interesting it gets. We could even go further and say, ‚Äú<em>Why did she fall down when she slipped?‚Äù</em> It has to do with gravity, involves all the planets and everything else. Nevermind! It goes on and on.</p></blockquote>

<h4>Step 4: Repeat step 3 until the questioning adds no incremental value</h4>
<p data-pm-context="[]">Now you iterate with yourself. After you have written down the ‚Ä¶</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.butwhatfor.com/feynman-technique/">https://www.butwhatfor.com/feynman-technique/</a></em></p>]]>
            </description>
            <link>https://www.butwhatfor.com/feynman-technique/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057821</guid>
            <pubDate>Wed, 11 Nov 2020 12:39:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with PromQL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057754">thread link</a>) | @thechiefio
<br/>
November 11, 2020 | https://thechief.io/c/metricfire/getting-started-promql/ | <a href="https://web.archive.org/web/*/https://thechief.io/c/metricfire/getting-started-promql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thechief.io/c/metricfire/getting-started-promql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057754</guid>
            <pubDate>Wed, 11 Nov 2020 12:25:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unix ASCII Games]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057750">thread link</a>) | @elvis70
<br/>
November 11, 2020 | https://ligurio.github.io/awesome-ttygames/ | <a href="https://web.archive.org/web/*/https://ligurio.github.io/awesome-ttygames/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

      

<p><a href="https://travis-ci.org/ligurio/awesome-ttygames"><img src="https://travis-ci.org/ligurio/awesome-ttygames.svg?branch=master" alt="Build Status"></a></p>

<p>See additional resources about games in console:</p>
<ul>
  <li>https://inconsolation.wordpress.com/tag/game/</li>
  <li>https://ttygames.wordpress.com/</li>
  <li>https://theouterlinux.gitlab.io/RecommendedSoftware/Linux/Games/RecommendedSoftware_Linux_Games.html</li>
</ul>

<p>Feel free to submit pull requests to add new games and improve information about
those already in the database.</p>

<h2 id="how-to-contribute">How to contribute</h2>

<p>Check <code>games.yaml</code> out. All information is inside, and you should more or less
understand what‚Äôs going on by reading it. Sorting is alphabetical.</p>

<p>Simplest way to contribute: edit <a href="https://ligurio.github.io/awesome-ttygames/games.yaml">games.yaml</a>, and then
your changes will be submitted as a pull request.</p>

<p>Use this template:</p>

<div><div><pre><code>- name: hangman
  url: http://www.openbsd.org/cgi-bin/man.cgi/OpenBSD-current/man6/hangman.6?query=hangman&amp;sec=6&amp;arch=i386
  info: computer version of the game hangman
  screencast:
  play:
</code></pre></div></div>

<ul>
  <li><code>name</code>: Name of the game</li>
  <li><code>url</code>: URL of main page</li>
  <li><code>info</code>: free text with game description</li>
  <li><code>screencast</code>: link to screencast (for example on asciinema)</li>
  <li><code>play</code>: server hostname where game is available via telnet or ssh</li>
</ul>

<h2 id="license">License</h2>

<p><a href="http://creativecommons.org/publicdomain/zero/1.0/"><img src="http://i.creativecommons.org/p/zero/1.0/88x31.png" alt="CC0 Public Domain"></a></p>

<p>To the extent possible under law, <a href="https://bronevichok.ru/">Sergey Bronnikov</a> has
waived all copyright and related or neighboring rights to this work.</p>

<h3 id="0verkill">0verkill</h3>

<p>0verkill is bloody 2D action deathmatch-like game in ASCII-ART.</p>

<h3 id="2048"><a href="https://github.com/mevdschee/2048.c">2048</a></h3>

<p>This is an ncurses version of the game ‚Äò2048‚Äô.</p>

<h3 id="2048-cli"><a href="https://github.com/Tiehuis/2048-cli">2048-cli</a></h3>

<p><a href="https://asciinema.org/a/34067"><img src="https://asciinema.org/a/34067.svg" alt="asciicast"></a></p>

<p>A cli version of the game 2048 for your Linux terminal.</p>

<h3 id="n2048"><a href="http://freshmeat.sourceforge.net/projects/n2048">n2048</a></h3>

<p><a href="https://asciinema.org/a/35973"><img src="https://asciinema.org/a/35973.svg" alt="asciicast"></a></p>

<p>n2048 is a console-based game based on the highly addictive sliding puzzle 2048. Slide the tiles together to combine them, until you reach the highest one.</p>

<h3 id="ascii-patrol"><a href="http://ascii-patrol.com/">ascii patrol</a></h3>

<p>None</p>

<p><strong>Play</strong>: <code>http://ascii-patrol.com/area51/ascii-patrol-html5.html</code></p>

<h3 id="abura-tan"><a href="http://aburatan.sourceforge.net/">abura tan</a></h3>

<p>A roguelike game of Cowboy Knights and Lurking Horror.</p>

<h3 id="ad-astra"><a href="https://code.google.com/archive/p/ad-astra-game/">ad astra</a></h3>

<p>Ad Astra is a turn-based space strategy game written in Python that uses curses for its display.</p>

<h3 id="adom-ancient-domains-of-mystery"><a href="https://www.adom.de/">ADOM (Ancient Domains of Mystery)</a></h3>

<p>ADOM is a roguelike game.</p>

<h3 id="adventure"><a href="https://man.openbsd.org/OpenBSD-current/man6/adventure.6">adventure</a></h3>

<p>An exploration game. It‚Äôs a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Colossal_Cave_Adventure">Wikipedia</a>.</p>

<p><strong>Play</strong>: <code>https://grack.com/demos/adventure/</code></p>

<h3 id="alienrl"><a href="https://alien.chaosforge.org/">alienrl</a></h3>

<p>AliensRL is a tactical roguelike game, inspired by the ‚ÄúAliens‚Äù movie.</p>

<h3 id="alienwave"><a href="https://www.alessandropira.org/alienwave/aw.html">alienwave</a></h3>

<p>another good variant of the space invaders game.</p>

<h3 id="angband"><a href="https://rephial.org/">angband</a></h3>

<p>Angband is a free, single-player dungeon exploration game.</p>

<h3 id="anonymine"><a href="https://oskog97.com/projects/anonymine/">Anonymine</a></h3>

<p><a href="https://asciinema.org/a/82455"><img src="https://asciinema.org/a/82455.svg" alt="asciicast"></a></p>

<p>A curses mode minesweeper solvable without guessing, and the only with von Neumann neighbourhoods.</p>

<p><strong>Play</strong>: <code>ssh play@anonymine-demo.oskog97.com -p 2222; Password is "play"</code></p>

<h3 id="aop"><a href="https://raffi.at/view/code/aop">aop</a></h3>

<p><a href="https://asciinema.org/a/34678"><img src="https://asciinema.org/a/34678.svg" alt="asciicast"></a></p>

<p>Ambassador of Pain (aop). A very nice and challenging arcade game.</p>

<h3 id="apple-trek"><a href="http://peyre.x10.mx/GWBASIC/index.htm#AppleTrek">Apple Trek</a></h3>

<p>See also <a href="https://en.wikipedia.org/wiki/Apple_Trek">Wikipedia</a>.</p>

<h3 id="arkanoid-bash"><a href="https://github.com/bolknote/shellgames/blob/master/arcanoid.sh">arkanoid-bash</a></h3>

<p><a href="https://asciinema.org/a/36415"><img src="https://asciinema.org/a/36415.svg" alt="asciicast"></a></p>

<p>Arkanoid is an arcade game developed by Taito in 1986. Written in Bash.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Arkanoid">Wikipedia</a>.</p>

<h3 id="arkanoidpy"><a href="https://blog.yjl.im/2015/12/arkanoid-example-from-pygamii-ascii.html">arkanoid.py</a></h3>

<p>Arkanoid is an arcade game developed by Taito in 1986. Written in Python.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Arkanoid">Wikipedia</a>.</p>

<h3 id="arkanoid-sed"><a href="http://sed.sourceforge.net/local/games/arkanoid.sed.html">arkanoid-sed</a></h3>

<p>Arkanoid is an arcade game developed by Taito in 1986. Written in Sed.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Arkanoid">Wikipedia</a>.</p>

<h3 id="arithmetic"><a href="https://man.openbsd.org/arithmetic.6">arithmetic</a></h3>

<p>quiz on simple arithmetic</p>

<h3 id="asciijump"><a href="http://freshmeat.sourceforge.net/projects/asciijump">asciijump</a></h3>

<p><a href="https://asciinema.org/a/31340"><img src="https://asciinema.org/a/31340.svg" alt="asciicast"></a></p>

<p>asciijump is an ASCII art game about ski jumping.</p>

<h3 id="ascii-portal"><a href="https://github.com/cymonsgames/ASCIIpOrtal">ascii portal</a></h3>

<p>ASCIIpOrtal is a text based puzzle game inspired by the popular video game.</p>

<h3 id="asciisector"><a href="http://www.asciisector.net/">asciisector</a></h3>

<p>asciisector is a free space combat/exploration/trading game.</p>

<h3 id="astwar"><a href="https://savannah.nongnu.org/projects/astwar">astwar</a></h3>

<p>Astwar is a ncurses based game that features two little ships on each side of the screen shooting each other.</p>

<h3 id="atc"><a href="https://man.openbsd.org/OpenBSD-current/man6/atc.6">atc</a></h3>

<p>air traffic controller game. It‚Äôs a BSD game.</p>

<h3 id="avanor"><a href="http://avanor.sourceforge.net/">avanor</a></h3>

<p>Rogue-like game with easy ADOM-like user interface.</p>

<h3 id="awkaster"><a href="https://github.com/TheMozg/awk-raycaster">awkaster</a></h3>

<p>Pseudo-3D shooter written completely in gawk using raycasting technique</p>

<h3 id="backgammon"><a href="https://man.openbsd.org/OpenBSD-current/man6/backgammon.6">backgammon</a></h3>

<p>A backgammon game; you can play against the computer. It‚Äôs a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Backgammon">Wikipedia</a>.</p>

<h3 id="bastet"><a href="http://fph.altervista.org/prog/bastet.html">bastet</a></h3>

<p>Bastet (short for Bastard Tetris).</p>

<h3 id="battleships"><a href="http://www.catb.org/~esr/bs/">battleships</a></h3>

<p>Uses character-cell graphics with a visual point-and-shoot interface.</p>

<h3 id="battlestar"><a href="https://man.openbsd.org/OpenBSD-current/man6/battlestar.6">battlestar</a></h3>

<p>A tropical adventure game. It‚Äôs a BSD game.</p>

<h3 id="bcd"><a href="https://man.openbsd.org/bcd.6">bcd</a></h3>

<p>punched card</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Punched_card">Wikipedia</a>.</p>

<h3 id="beasts"><a href="https://peteg.org/beasts/beasts.html">beasts</a></h3>

<p>The game Beasts is a Linux version of the old DOS game called Beast.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Beast_(video_game)">Wikipedia</a>.</p>

<h3 id="beyond-the-tesseract"><a href="https://www.wurb.com/if.php/game/211">beyond the tesseract</a></h3>

<p>A highly conceptual game in which you interact with abstract concepts and mathematical entities as if they were tangible.</p>

<p><strong>Play</strong>: <code>telnet or ssh on sdf.org</code></p>

<h3 id="blocks">blocks</h3>

<p>A block-based puzzle game.</p>

<h3 id="bluemoon"><a href="http://www.catb.org/~esr/bluemoon/">bluemoon</a></h3>

<p>The Blue Moon card solitaire.</p>

<h3 id="bj">bj</h3>

<p>a black-jack card game.</p>

<p><strong>Play</strong>: <code>telnet or ssh on sdf.org</code></p>

<h3 id="boggle"><a href="https://man.openbsd.org/OpenBSD-current/man6/boggle.6">boggle</a></h3>

<p>Word search game. It‚Äôs a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Boggle">Wikipedia</a>.</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="bombardier"><a href="https://packages.debian.org/en/sid/i386/games/bombardier">bombardier</a></h3>

<p>This game is the same as the old Blitz16 game on Commodore 16/Plus 4, written by Simon Taylor.</p>

<h3 id="boulder-dash">boulder dash</h3>

<p>A Boulder Dash game clone for your favorite terminal. You are trapped in the CAVEZ of PHEAR, your mission is to escape through all the caves and make it out alive. To escape through a cave you will have to find all the diamonds located in it. Once you‚Äôve found all the diamonds, their powers combined will help you get to the next cave, one step closer to freedom.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Boulder_Dash">Wikipedia</a>.</p>

<h3 id="bowling"><a href="https://github.com/haliphax/pybowl">bowling</a></h3>

<p><a href="https://asciinema.org/a/41475"><img src="https://asciinema.org/a/41475.svg" alt="asciicast"></a></p>

<p>Python bowling game using the Blessed terminal library.</p>

<h3 id="braincurses"><a href="https://sourceforge.net/projects/braincurses/">braincurses</a></h3>

<p>A nice version of the mastermind game.</p>

<h3 id="brogue"><a href="https://sites.google.com/site/broguegame/">brogue</a></h3>

<p>Brogue is a Roguelike game.</p>

<h3 id="bs"><a href="https://man.openbsd.org/OpenBSD-current/man6/bs.6">bs</a></h3>

<p>Battleships game. It‚Äôs a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Battleship_%28game%29">Wikipedia</a>.</p>

<h3 id="caesar"><a href="https://man.openbsd.org/caesar.6">caesar</a></h3>

<p>decrypt caesar cyphers</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Caesar_cipher">Wikipedia</a>.</p>

<h3 id="canfield"><a href="https://man.openbsd.org/OpenBSD-current/man6/canfield.6">canfield</a></h3>

<p>The solitaire card game canfield. It‚Äôs a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Canfield_%28solitaire%29">Wikipedia</a>.</p>

<h3 id="caribbean-stud">Caribbean Stud</h3>

<p>a multi-player card game, written by Hero</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="cataclysm-dark-days-ahead"><a href="https://web.archive.org/web/20190209031801/http://en.cataclysmdda.com/">cataclysm: dark days ahead</a></h3>

<p>Cataclysm: Dark Days Ahead is a roguelike set in a post-apocalyptic world. Surviving is difficult: you have been thrown, ill-equipped, into a landscape now riddled with monstrosities of which flesh eating zombies are neither the strangest nor the deadliest.</p>

<h3 id="cavez-of-phear">cavez of phear</h3>

<p>cavez of phear is a boulder dash / digger like game for console using ncurses.</p>

<h3 id="cbattleship"><a href="https://github.com/gnomengineer/cBattleship">cbattleship</a></h3>

<p>A implementation of the classic Battleship game in C++. Includes a server program, and multiple different client programs. The server program wait‚Äôs until two client program connected to start a game. The server dictates the rules of the game.</p>

<h3 id="cblocks"><a href="https://www.muppetlabs.com/~breadbox/software/cgames.html">cblocks</a></h3>

<p>a set of sliding-block puzzles.</p>

<h3 id="checkers">Checkers</h3>

<p>a two-player board game, written by Alexi</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="chess"><a href="https://github.com/bolknote/SedChess">chess</a></h3>

<p>Chess implemented in sed utility.</p>

<h3 id="gnuchess"><a href="https://www.gnu.org/software/chess/">gnuchess</a></h3>

<p>GNU Chess is a chess-playing program.</p>

<p><strong>Play</strong>: <code>telnet freechess.org 5000 (login guest)</code></p>

<h3 id="chimaera"><a href="https://www.mipmip.org/C_games/">chimaera</a></h3>

<p>A highly unusual ‚Äúinfinite‚Äù adventure game written by Chris Newall.</p>

<h3 id="chroma"><a href="http://www.level7.org.uk/chroma/">chroma</a></h3>

<p>A challenging puzzle game.</p>

<h3 id="ckhet"><a href="https://mbays.freeshell.org/ckhet/">ckhet</a></h3>

<p>Curses implementation of the laser board game Khet.</p>

<p><strong>Play</strong>: <code>ssh ckhet@sshgames.thegonz.net; password: ckhet</code></p>

<h3 id="clines"><a href="http://manticore.2y.net/prj/clines-a.html">clines</a></h3>

<p>Clines is a standard ‚ÄúLines‚Äù game, implemented as a curses application.</p>

<h3 id="clines-1"><a href="https://github.com/veselov/clines">clines</a></h3>

<p>Color Lines clone in console.</p>

<h3 id="cmines"><a href="https://www.muppetlabs.com/~breadbox/software/cgames.html">cmines</a></h3>

<p>minesweeper.</p>

<h3 id="cnibbles"><a href="http://cnibbles.sourceforge.net/">cnibbles</a></h3>

<p>Another Nibbles game with good and smooth animations.</p>

<h3 id="open-adventure"><a href="https://gitlab.com/esr/open-adventure">Open Adventure</a></h3>

<p>Colossal Cave Adventure (also known as ADVENT, Colossal Cave, or Adventure) is one of the earliest computer adventure games and a precursor form of role playing video game. The original version was designed by Will Crowther, a programmer and caving enthusiast who based the layout on part of the Mammoth Cave system in Kentucky.</p>

<h3 id="connect-four">Connect Four</h3>

<p>a two-player slot game, written by Sarac</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="connect4"><a href="https://github.com/badescunicu/connect4">connect4</a></h3>

<p>The Connect4 game using ncurses C library.</p>

<h3 id="conquest"><a href="https://github.com/beejjorgensen/conquest">Conquest</a></h3>

<p>Port of the old Amiga Conquest text-based game</p>

<h3 id="conquest-1"><a href="https://github.com/jtrulson/conquest/">conquest</a></h3>

<p>a real-time, multi-player space warfare game.</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="gnu-conquest"><a href="https://sourceforge.net/projects/gnu-conquest/">gnu-conquest</a></h3>

<p>A multiplayer galactic game.</p>

<h3 id="corewar"><a href="http://www.corewar.info/">corewar</a></h3>

<p>Core War is a programming game created by D. G. Jones and A. K. Dewdney in which two or more battle programs (called ‚Äúwarriors‚Äù) compete for control of a virtual computer.</p>

<h3 id="cpat"><a href="http://cpat.sourceforge.net/">cpat</a></h3>

<p>CPat is probably the best card game for the Linux console; it is a collection of many solitaire/patience games from the most famous to less known games.</p>

<h3 id="crawl"><a href="https://crawl.develz.org/wordpress/">crawl</a></h3>

<p><a href="https://asciinema.org/a/524"><img src="https://asciinema.org/a/524.svg" alt="asciicast"></a></p>

<p>One of the best games for the Linux console.</p>

<h3 id="cribbage"><a href="https://man.openbsd.org/OpenBSD-current/man6/cribbage.6">cribbage</a></h3>

<p>The card game cribbage. It‚Äôs a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Cribbage">Wikipedia</a>.</p>

<h3 id="cryptrover"><a href="https://code.google.com/archive/p/cryptrover/">cryptrover</a></h3>

<p>Escape From The Crypt.</p>

<h3 id="ctris"><a href="https://github.com/dominikhackl/ctris">ctris</a></h3>

<p>Another version of the tetris game.</p>

<h3 id="cursedmate"><a href="https://web.archive.org/web/20130804035452/http://www.uberwall.org/~dash/">cursedmate</a></h3>

<p>A game with a hacking atmosphere.</p>

<h3 id="curse-of-war"><a href="https://a-nikolaev.github.io/curseofwar/">curse-of-war</a></h3>

<p>Curse of War is a fast-paced action strategy game for Linux originally implemented using ncurses user interface.</p>

<h3 id="dab"><a href="https://netbsd.gw.com/cgi-bin/man-cgi?dab+6+NetBSD-6.0">dab</a></h3>

<p>Dots and Boxes game.</p>

<h3 id="diablorl"><a href="https://diablo.chaosforge.org/">diablorl</a></h3>

<p>DiabloRL is a roguelike ‚Äúunmake‚Äù of the popular Blizzard game Diablo.</p>

<h3 id="doomrl"><a href="https://drl.chaosforge.org/">doomrl</a></h3>

<p>DoomRL (Doom, the Roguelike) is a fast and furious coffee-break Roguelike game, that is heavily inspired by the popular FPS game Doom by ID Software.</p>

<h3 id="dopewars"><a href="https://dopewars.sourceforge.io/">dopewars</a></h3>

<p>A funny game about trading drugs. Dopewars is a free rewrite of a game originally based on Drug Wars by John E. Dell.</p>

<p><strong>Play</strong>: <code>telnet or ssh on sdf.org</code></p>

<h3 id="dsol"><a href="https://feld.me/pub/vga_cardgames-1.3.1.tgz">dsol</a></h3>

<p>dSol is a command line solitaire card game.</p>

<h3 id="duel-commander"><a href="https://sourceforge.net/projects/duelcommander/">duel commander</a></h3>

<p>Duel Commander is a turn based command line fighting game for Windows and Unix-like systems.</p>

<h3 id="dungeon-crawl"><a href="http://www.dungeoncrawl.org/">dungeon crawl</a></h3>

<p>Dungeon Crawl, a text-based roguelike game.</p>

<h3 id="dwarf-fortress"><a href="https://www.bay12games.com/dwarves/">dwarf fortress</a></h3>

<p>Dwarf Fortress is a single-player fantasy game.</p>

<h3 id="emacs"><a href="https://www.emacswiki.org/emacs/CategoryGames">emacs</a></h3>

<p>Actually it is not a game, but text editor. It includes a bunch of text games like chess, sokoban, pong etc.</p>

<h3 id="encircled"><a href="http://www.roguebasin.com/index.php?title=Encircled">encircled</a></h3>

<p>Encircled is a roguelike game.</p>

<h3 id="enigma"><a href="https://www.chiark.greenend.org.uk/~sgtatham/enigma/">enigma</a></h3>

<p>A puzzle game where items have to be collected in the right order.</p>

<h3 id="eyangband"><a href="http://eyangband.sourceforge.net/">eyangband</a></h3>

<p>Another variant of Angband.</p>

<h3 id="factor"><a href="https://man.openbsd.org/factor.6">factor</a></h3>

<p>factor a number, generate primes</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Factorization">Wikipedia</a>.</p>

<h3 id="fbird-screencast"><a href="https://github.com/nanochess/fbird">fbird</a> <a href="https://www.youtube.com/watch?v=p31XFFAeze4">Screencast</a></h3>

<p>F-Bird, a text bootsector game</p>

<h3 id="fish"><a href="https://man.openbsd.org/OpenBSD-current/man6/fish.6">fish</a></h3>

<p>Play ``Go Fish‚Äô‚Äô. It‚Äôs a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Go_Fish">Wikipedia</a>.</p>

<h3 id="fortune"><a href="https://man.openbsd.org/fortune.6">fortune</a></h3>

<p>print a random, hopefully interesting, adage</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Fortune_%28Unix%29">Wikipedia</a>.</p>

<h3 id="freecell"><a href="https://www.linusakesson.net/software/freecell.php">freecell</a></h3>

<p>This is a console (ncurses) version of the popular and addictive solitaire game.</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="freesweep"><a href="https://code.google.com/archive/p/freesweep/">freesweep</a></h3>

<p>minesweeper game using curses.</p>

<h3 id="freesweep-1"><a href="https://github.com/rwestlund/freesweep">freesweep</a></h3>

<p>Freesweep is a console minesweeper-style game written in C for Unix-like systems.</p>

<h3 id="fkmines"><a href="https://sourceforge.net/projects/fkmines/">fkmines</a></h3>

<p>Another minesweeper-style game.</p>

<h3 id="frozen-depths"><a href="https://frozendepths.net/">frozen depths</a></h3>

<p>A very nice roguelike game with an entertaining atmosphere.</p>

<h3 id="frotz"><a href="https://davidgriffith.gitlab.io/frotz/">frotz</a></h3>

<p>Frotz is an interpreter for Infocom games and other Z-machine games.</p>

<h3 id="galaxis"><a href="http://www.catb.org/esr/galaxis/">galaxis</a></h3>

<p>Find the lost lifeboats from an interstellar liner.</p>

<h3 id="gameroom">gameroom</h3>

<p>11 arcade games</p>

<p><strong>Play</strong>: <code>ssh gameroom@bitreich.org</code></p>

<h3 id="gearhead"><a href="http://www.gearheadrpg.com/">gearhead</a></h3>

<p>GearHead is the first roguelike to explore the world of ‚Äúmechas‚Äù (giant robots).</p>

<h3 id="gnake">gnake</h3>

<p>Another variant of the snake game with a smooth movement.</p>

<h3 id="gnugo"><a href="https://www.gnu.org/software/gnugo/">gnugo</a></h3>

<p>GNU Go is a free ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ligurio.github.io/awesome-ttygames/">https://ligurio.github.io/awesome-ttygames/</a></em></p>]]>
            </description>
            <link>https://ligurio.github.io/awesome-ttygames/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057750</guid>
            <pubDate>Wed, 11 Nov 2020 12:24:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hardly Working with Cloudflare Workers]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25057709">thread link</a>) | @malthejorgensen
<br/>
November 11, 2020 | https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers | <a href="https://web.archive.org/web/*/https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <!-- Possible titles:
Cloudflare workers are hard to work with
Working with Cloudflare Workers
Hardly working with Cloudflare Workers
-->

<p><em>Note: The team behind Notifly also runs <a href="https://www.eduflow.com/">Eduflow</a> and <a href="https://www.peergrade.io/">Peergrade</a>.</em></p>

<h2 id="introduction">Introduction</h2>

<p>This is the story of me trying to replace a simple NGINX reverse proxy (plus some basic redirects) with a Cloudflare Worker.</p>

<p>Our old landing page is a Wordpress blog hosted on WPEngine. Historically, this has always been set up behind an NGINX reverse proxy serving at <a href="http://peergrade.io/">peergrade.io</a> and <a href="http://www.peergrade.io/">www.peergrade.io</a>. The reverse proxy was needed for doing various redirects outside of Wordpress and doing some cookie trickery to redirect to <a href="http://app.peergrade.io/">app.peergrade.io</a> if the session cookie for the app was present.</p>

<p>The reverse proxy is hosted on DigitalOcean and is the only thing we have hosted there, so I wanted to get rid of it. We already use Cloudflare and so I thought ‚Äúthis would be a good test to try out Cloudflare Workers‚Äù. And less infrastructure is better, right?</p>

<h2 id="the-good-parts">The good parts</h2>

<p>Getting set up with <code>wrangler</code> ‚Äì the CLI for Cloudflare Workers ‚Äì was a breeze. It gives you a webpack setup out of the box which allowed me to install NPM packages and use them without any extra work on my part. I eventually downgraded to a setup without webpack (called ‚Äújavascript‚Äù in <code>wrangler</code>) ‚Äì since I ended up not needing any packages.</p>

<p>The vanilla Javascript setup allows you to ‚Äúlive edit‚Äù the worker at <code>https://dash.cloudflare.com/&lt;account-id&gt;/workers/edit/&lt;worker-slug&gt;</code></p>

<p>Here you can edit and run the updated script without saving and deploying the worker, allowing for a very fast and easy ‚Äúedit-compile-run‚Äù loop.</p>

<p>Another cool thing is that you can change the URL in the small ‚Äúbrowser‚Äù on the page to your liking ‚Äì this is very useful for testing out proxies and other things that depend on the domain name or precise URL being sent to the worker. The debugger part of the UI is also incredibly useful but does have a tendency to disconnect from time to time.</p>

<h2 id="page-rules-vs-workers">Page Rules vs. Workers</h2>

<p>In a classic setup you‚Äôll usually have a couple of redirects alongside your reverse proxy ‚Äì and so do we. We use <a href="http://www.peergrade.io/">www.peergrade.io</a> as our canonical domain so we redirect peergrade.io to www.peergrade.io and we redirect http:// to https://.</p>

<p>This can be set up easily in Cloudflare by adding a couple of redirects in your Page Rules.</p>

<p>However, redirects from page rules are applied after any worker on the same URL. Since my worker‚Äôs default action is to reverse proxy, the redirect page rule will never be hit.</p>

<p>Annoyingly, this isn‚Äôt clearly described in the docs and you‚Äôll have to find <a href="https://community.cloudflare.com/t/cf-workers-and-rate-limiting-firewall-rules-bot-management/132164/3">this forum post</a> from the official Cloudflare forum to know that.
The post notes that ‚Äú<em>security-related ones will run before [workers]</em>‚Äù ‚Äì but which ones are those? (All respect to Kenton Varda who wrote the post and is the main architect behind Cloudflare Workers. Cloudflare Workers <em>are</em> very very cool, but they are also a bit more quirky than I‚Äôd like at the moment)</p>

<p>In order to preserve these redirects, I‚Äôll have to manually write them in the worker code (or relay the URLs that need to redirect to Cloudflare itself ‚Äì which is basically the same amount of code).</p>

<!-- 
- An aside:

    Apparently *Always Use HTTPS* is such a "security-related" page rule, even though it's basically an http:// to https:// redirect. Cloudflare even admits to that [in the docs](https://support.cloudflare.com/hc/en-us/articles/204144518-SSL-FAQ#h_a61bfdef-08dd-40f8-8888-7edd8e40d156). 

    Cloudflare Page Rules allows you to set up multiple rules for a single URL-pattern, but then only allows you to use that pattern once. However, *Always Use HTTPS* is special and doesn't allow any other rules once it's used on a URL-pattern. This means if you want *Automatic HTTPS Rewrites* on top of *Always Use HTTPS* you have to specify 2 rules:

    1. www.peergrade.io ‚Äì *Always Use HTTPS*
    2. [https://www.peergrade.io](https://www.peergrade.io) ‚Äì *Automatic HTTPS Rewrites*
-->

<p>The same thing goes for cache rules. I had previously been using a page rule to aggressively cache static assets and user-uploaded content served from Wordpress. That now has to be written inside the worker as well.</p>

<p>Page rules have an internal ordering that you can set. Rules that match the given URL are executed in order ‚Äì so that if two redirect rules match the URL, the first one in the ordering will be used. It would be <em>really nice</em> if workers could be added to the same list ‚Äì that would mean I could put the redirects and cache rules before my worker and much more easily handle this scenario. <em>In principle</em> this would be easy if all the built-in page rules were reimplemented as workers, but there‚Äôs probably legacy behaviors and tie-ins to the rest of the stack that makes that impossible or at least non-trivial. (Still hoping for a future update on this ü§ûüèª)</p>

<h2 id="the-reverse-proxy">The reverse proxy</h2>

<p>Back to the main task at hand ‚Äì we‚Äôre implementing a simple reverse proxy and that happens to be <a href="https://developers.cloudflare.com/workers/examples/bulk-origin-proxy">one of the examples</a> in the Cloudflare Worker docs. However, getting it set up myself I quickly ran into issues with redirect loops and cases where my origin would redirect for seemingly no reason. To be fair, proxying can be tricky to get right since it‚Äôs hard to test properly before rollout, and on top of that you have DNS propagation and caching, which means there might be timing issues. But even with that, it seemed extra tricky with Cloudflare Workers.</p>

<p>On closer inspection, the example from the Cloudflare docs seems to defy reasoning. The incoming request in the example must have the header <code>Host: google.yourdomain.com</code> in order for it to match the Google entry in <code>ORIGINS</code>. I was able to confirm as much by inspecting the incoming request in the Cloudflare worker debugger. That incoming request is then relayed directly to <code>www.google.com</code>. Let‚Äôs try that ourselves:</p>

<div><div><pre><code>curl -H 'Host: google.yourdomain.com' https://www.google.com
</code></pre></div></div>

<p>The response we get is a 404 page (which makes sense since the host doesn‚Äôt match). However, the Cloudflare worker doesn‚Äôt get a 404 ‚Äì it renders the familiar Google search frontpage. Something must be happening behind the scenes. That something is what I call ‚ÄúThe Web Platform‚Äù part of Cloudflare Workers.</p>

<h2 id="the-web-platform">The Web Platform</h2>

<p>Cloudflare Workers uses Chrome‚Äôs V8 as its execution engine and this also sets the context in which your script is run.</p>

<p>The available API is a very small subset of <a href="https://platform.html5.org/">The Web Platform</a> (the Javascript API available in modern browsers) ‚Äì specifically Ecmascript/Javascript itself, plus <code>Fetch</code>, <code>URL</code>, and <code>Blob</code>. I believe Cloudflare chose this API because it melds well with V8, but also because web devs will be familiar with those APIs. But how familiar are you <em>really</em> with <code>fetch</code>, <code>Request</code>, and <code>Response</code>? (all part of the <code>Fetch</code>-spec)<br>
I don‚Äôt think I actually knew the <code>Request</code> and <code>Response</code>-objects in any detail before using Cloudflare Workers ‚Äì having gotten along just fine with variations of</p>

<div><div><pre><code>fetch('http://example.org', { options }).then((r) =&gt; r.json())
</code></pre></div></div>

<p>plus some error handling on top for many years.</p>

<p>When working with Workers what you‚Äôll mostly be doing is to manipulate the incoming <code>Request</code>-object  and pass it on to <code>fetch</code>, or manipulate the outgoing <code>Response</code>-object and passing that on to Cloudflare‚Äôs handler. Have you ever manually created a <code>Request</code>-object in the browser? I haven‚Äôt. The reason this gets complicated is the fact that the spec for <code>fetch</code> itself is very ‚Äúloose‚Äù. For example, <code>fetch</code> can take either a <code>Request</code>-object or a simple Javascript object that just looks a lot like a <code>Request</code>-object as its argument ‚Äì and it not really clear what differences between the two are.
<code>fetch</code> also allows passing a <code>Request</code>-objects as both its first and second argument <code>fetch(Request(...), Request(...))</code> ‚Äì good luck trying to figure out what that does!</p>

<p>If we go back to the example from the Cloudflare docs ‚Äì what‚Äôs going on ‚Äúbehind the scenes‚Äù in our proxy example from earlier is that you can‚Äôt change the <code>Host</code>-header when doing a <code>fetch</code>. This makes a lot of security sense in the browser where <code>fetch</code> normally lives, but it‚Äôs quite normal behavior for a reverse proxy and actually something I was doing in my NGINX setup in order to have WPEngine respond with the right content. It‚Äôs not a behavior you‚Äôve ever needed or thought about when using <code>fetch</code> in the browser.
The server is just a very different environment than the browser. The browser Javascript API is not built with server functionality in mind, and it ends up being a hamstring when working with Cloudflare Workers.</p>

<h2 id="maybe-maybe-maybe">Maybe, maybe, maybe‚Ä¶?</h2>

<p>A bunch of forum posts on community.cloudflare.com talk about this issue</p>

<ul>
  <li><strong>Only available on the Enterprise plan?</strong> <a href="https://community.cloudflare.com/t/override-host-header-using-workers/73434/2">This forum post</a> describes that setting the <code>Host</code> -header in workers is not possible. Followed up with <a href="https://community.cloudflare.com/t/override-host-header-using-workers/73434/5">a later answer</a> that it‚Äôs possible but only for Enterprise accounts.
 <a href="https://community.cloudflare.com/t/reverse-proxy-using-page-rules/47836/16">This other post</a> says the same.</li>
  <li><strong>Kenton Varda to the rescue</strong> In response to <a href="https://community.cloudflare.com/t/not-possible-to-override-the-host-header-on-workers-requests/13077/7">this post</a> Kenton Varda actually extends Cloudflare Workers with the <code>cf.resolveOverride</code>-flag on the <code>Request</code>-object,
which should allow at least part of the reverse proxy setup to work.
Unfortunately, to explain the new feature the post just links to the top-level URL of the documentation for Cloudflare Workers ‚Äì which currently doesn‚Äôt
describe how  <code>cf.resolveOverride</code> works and how to use it.</li>
  <li><strong>The missing documentation</strong> <a href="https://community.cloudflare.com/t/different-hostname-with-same-origin-in-workers/16662/12">This older post</a> seemingly cites documentation that no longer exists! :(<br>
 I have been unable to find any meaningful documentation of <code>cf.resolveOverride</code> outside of the community forum, and I was unable to have it allow me to switch the <code>Host</code>-header.</li>
</ul>

<h2 id="the-final-nail-in-the-coffin">The final nail in the coffin</h2>

<p>For a brief moment I actually thought my setup was working, but it only ‚Äúlooked‚Äù like it was working due to the following sequence of events:</p>

<ul>
  <li>A request for <code>www.peergrade.io</code> would hit the worker</li>
  <li>The worker would then do a request to <code>peergrade.wpengine.com</code></li>
  <li>Wordpress/WPEngine would then respond with a redirect to <code>www.peergrade.io</code> since the <code>Host</code>-header is incorrect</li>
  <li>Cloudflare by default then follows that redirect and makes a new request to <code>www.peergrade.io</code>.
Since Cloudflare is the host of <code>www.peergrade.io</code> you‚Äôd think we‚Äôd hit infinite recursion here.
But magically, it doesn‚Äôt just enter the worker script again ‚Äì it knows (somehow) it has to go further down the Cloudflare stack.
Since the DNS A-record in Cloudflare still had the IP of the DigitalOcean instance, that final fetch would simply fetch the page from the old proxy server which worked as it always had ü§¶üèª</li>
</ul>

<!--
Another example of this "familiar but unfamiliar" API is when I was trying to inspect the session cookie: I had to do a base64 decode into a `Uint8Array` (in order to do a zlib decompression). The function available for decoding base64 is `atob` which you may know from the browser.

However, in order to get the actual binary data you'll have to do this Javascript incantation:

```jsx
const weirdstr = atob(cookiestr);
const bytearray = new Uint8Array(new ArrayBuffer(weirdstr.length));

for (let i = 0; i < weirdstr.length; i++) {
  bytearray[i] = weirdstr.charCodeAt(i);
}
```

Again, this isn't Cloudflare's fault per se, but they're inheriting a bad choice from The Web Platform where they could have done something else. That bad choice becomes accentuated by the fact that most workers need to implement something that is basically backend or proxy server behavior, which by now you can see The Web Platform really isn't set up for. 

Similarly, you'll inherit this weird quirk directly from the browser Javascript engine:

```jsx
console.log(btoa('Ê±âÂ≠ó'))
// The above raises a DOMException in your Cloudflare Worker with the
// following message:
// "btoa() can only operate on characters in the Latin1 (ISO/IEC 8859-1) range."
```

Yes yes, there's some sense to this ‚Äì Javascript strings are UTF-16 and that's why this example doesn't work. But take a look at Node.js where `btoa` and `atob` are not available ‚Äì Node.js has a much better answer to many of these problems.

Lastly, since many things are iterables or DOM-objects, you won't get anything useful out of console logging `request.headers`, `request.headers.keys()`, `request.headers.values()`, `request.headers.entries()`. This wouldn't be a problem if the `request`-object was fully inspectable in the debugger but nothing shows up when you open up `request.headers`.
The solution to this is just `console.log([...request.headers])`.
-->

<h2 id="conclusion">Conclusion</h2>

<p>Overall, Cloudflare Workers are really cool and the tooling around them is pretty great. But I do feel like it was an unfortunate choice to adopt The Web Platform
instead of using parts of the Node standard library or a different, more server-oriented API. Lastly, while the documentation feels fairly complete and fleshed out ‚Äì the fact
that the answers on the forum tell 2-3 different stories about whether it‚Äôs possible to change the <code>Host</code>-header means that it‚Äôs something that is ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers">https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers</a></em></p>]]>
            </description>
            <link>https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057709</guid>
            <pubDate>Wed, 11 Nov 2020 12:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Ruby on Rails Patterns and Anti-Patterns]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057531">thread link</a>) | @nikolalsvk
<br/>
November 11, 2020 | https://pragmaticpineapple.com/introduction-to-ruby-on-rails-patterns-and-anti-patterns/ | <a href="https://web.archive.org/web/*/https://pragmaticpineapple.com/introduction-to-ruby-on-rails-patterns-and-anti-patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><span>
      <span></span>
  <img alt="Rails Patterns" title="Rails Patterns" src="https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/1c72d/cover.jpg" srcset="https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/a80bd/cover.jpg 148w,
https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/1c91a/cover.jpg 295w,
https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/1c72d/cover.jpg 590w,
https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/a8a14/cover.jpg 885w,
https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/fbd2c/cover.jpg 1180w,
https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/e5166/cover.jpg 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>

<p>Welcome to the first post in our series about Ruby on Rails Patterns and Anti-patterns. In each of the posts, we‚Äôll take a deep dive into all sorts of patterns you might come across while working with Rails apps.</p>
<p>Today, we‚Äôll show what a (design) pattern is and then try to explain what an anti-pattern is as well. To better illustrate explanations, we will use the Ruby on Rails framework that has been around for quite some time. If Rails isn‚Äôt your cup of tea for some reason, hang on, the ideas (or patterns) described here might resonate with whatever technology you wind up using.</p>
<p>But before we jump into explaining what patterns and anti-patterns are, how did we get to the point where we need them? Why do we need to have all these things for our software? Why do we need to <strong>design</strong> our solution?</p>
<h2 id="yes-you-are-a-designer"><a href="#yes-you-are-a-designer" aria-label="yes you are a designer permalink"></a>Yes, You Are a Designer</h2>
<p>Even from early computer programming days, people had to deal with the design of the programs they were writing. To write a program (or software) is to design a solution for a problem. When you write software, you are a designer‚Äîfeel free to append that to your job title. Designing good solutions is important because the software we write will be read and/or edited by others. Also, the solutions we come up with will be built on by others in the future.</p>
<p>Having all this in mind, generations of engineers started seeing similar designs in code and architecture throughout their careers. Folks started extracting and documenting standard solutions to problems. Some would say it‚Äôs a natural way of how we as humans function. We like to <a href="https://en.wikipedia.org/wiki/Principles_of_grouping">categorize</a> and <a href="https://en.wikipedia.org/wiki/Gestalt_psychology#Pr%C3%A4gnanz">find patterns</a> in everything, and software is no exception to that.</p>
<p>Being human, as we are, patterns started emerging more and more as software engineering got more complex. Software design patterns began to develop and cement themselves with engineers around the world. Books, essays, and talks were given, further spreading ideas of well thought out and battle-tested solutions. Those solutions saved a lot of people time and money, so let‚Äôs go over the term design pattern, and see what it truly is.</p>
<h2 id="what-is-a-design-pattern"><a href="#what-is-a-design-pattern" aria-label="what is a design pattern permalink"></a>What Is a Design Pattern?</h2>
<p>In software engineering, a pattern is described as a solution that can be reused to solve a common problem. The pattern is something that is considered a good practice among software engineers. Since software engineers set them, they can quickly go from patterns to their opposite‚Äîanti-patterns‚Äîbut we‚Äôll get to that later.</p>
<p>A design pattern will show you the way to the solution but it won‚Äôt give you a piece of code ready to be plugged into the rest of your software. Think of a pattern as a guide for writing well-designed code, but you have to come up with the implementation. Using patterns in day-to-day coding emerged in the late ‚Äò80s, where Kent Beck and Ward Cunningham came up with an idea of using a <a href="http://c2.com/doc/oopsla87.html">‚Äòpattern language‚Äô</a>.</p>
<p>The idea of pattern languages came in the late ‚Äô70s by Christopher Alexander in his book <a href="https://www.goodreads.com/book/show/79766.A_Pattern_Language">A Pattern Language</a>. You might be surprised, but the book is not about software engineering but the architecture of buildings. The pattern language is an organized and coherent set of patterns, each of which describes a problem and the core of a solution that can be used in many ways. Sounds familiar? (Hint: frameworks, another hint: Rails)</p>
<p>Later on, design patterns in software engineering became famous with large audiences after the legendary book <a href="https://www.goodreads.com/book/show/85009.Design_Patterns">Design Patterns</a> by the <a href="http://wiki.c2.com/?GangOfFour">Gang Of Four</a> published in 1994. In the book, there are explanations and definitions of patterns that are used nowadays ‚Äî Factory, Singleton, Decorator, just to name a few.</p>
<p>Great, now that we got acquainted or refreshed our knowledge on design and patterns, let‚Äôs find out what anti-patterns are.</p>
<h2 id="what-is-a-design-anti-pattern"><a href="#what-is-a-design-anti-pattern" aria-label="what is a design anti pattern permalink"></a>What Is a Design Anti-Pattern?</h2>
<p>If you think of patterns as the good guys, the anti-patterns are the bad ones. To be more precise, a software anti-pattern is a pattern that may be commonly used but is considered ineffective or counterproductive. Typical examples of anti-patterns are God objects that contain many functions and dependencies, which could be extracted and separated into different objects.</p>
<p>Common causes of anti-patterns in code are many. For example, a good one is when the good guy (pattern) becomes the bad guy (an anti-pattern). Let‚Äôs say you got used to using a particular technology at your previous company, and you gained a high level of competence in it. For the sake of the example, let‚Äôs use Docker. You know how to efficiently pack applications into Docker containers, orchestrate them in the cloud, and pull their logs down from the cloud. Suddenly, you get a new job where you need to ship front end applications. Since you know a lot about Docker and how to ship apps with it, your first decision is to package everything up and deploy it to the cloud.</p>
<p>But, little did you know, the front end apps are not that complex at your current job, and putting them into containers might not be the most effective solution. It first sounds like a good idea, but later down the road, it proves as counterproductive. This anti-pattern is called <a href="https://en.wikipedia.org/wiki/Law_of_the_instrument">‚ÄúGolden Hammer‚Äù</a>.</p>
<p>It can be summed up with the saying, ‚ÄúIf you have a hammer, everything looks like a nail‚Äù. If you are really good with Docker and orchestration of services, everything is a Docker service made to be orchestrated in the cloud.</p>
<p>These things happen and will happen. Good guys turn to bad buys, and vice-versa. But where do Ruby and Rails fit into this picture?</p>
<h2 id="ruby-first-then-rails"><a href="#ruby-first-then-rails" aria-label="ruby first then rails permalink"></a>Ruby First, Then Rails</h2>
<p>Most folks were introduced to Ruby by using Ruby on Rails, a popular framework for building websites quickly. I got acquainted with Ruby in the same way, nothing wrong with that. Rails is based on this well-established software pattern called Model-View-Controller, or MVC for short. But before we dive into details of the MVC pattern in Rails, one big fallacy that often happens is using Rails without learning Ruby properly.</p>
<p>The Rails framework was one of the go-to frameworks when you had an idea and wanted to build it fast. Nowadays, it‚Äôs a whole different story, Rails is still used, but not to the extent it was in its prime. Being so easy to use and run, a lot of beginners set out to build their web apps using rails new command. What happened then, along the road, problems started occurring. As a beginner, you are lured by the speed and simplicity of development with Rails, and everything works so magically and smoothly at first. Then you see you‚Äôve taken a lot of ‚Äòmagic‚Äô for granted, and you don‚Äôt understand what is going on behind the curtain.</p>
<p>I had this problem, and I‚Äôm sure many beginners and advanced beginners are suffering from it. You start with a framework in hand, you build on it, and when you try to add something highly custom, you can‚Äôt, because you‚Äôve used up all the magic points from that framework. At that point, you have to go back to the beginning and learn the basics. Going back is no biggie, happens to the best of us. But the problem grows more significant if you move on without learning the essential things, like in Ruby. One good book that can help you in this regard is <a href="https://www.goodreads.com/book/show/3892688-the-well-grounded-rubyist">The Well-Grounded Rubyist</a>.</p>
<p>As a beginner, you don‚Äôt have to read it from start to end. But keep it by your side so you can consult it quickly. I am not saying that you should suddenly stop whatever you were doing and read the whole book, but stop from time to time and refresh your knowledge of the Ruby basics, it might open some new horizons for you.</p>
<h2 id="mvc-rails-bread--butter"><a href="#mvc-rails-bread--butter" aria-label="mvc rails bread  butter permalink"></a>MVC: Rails‚Äô Bread &amp; Butter</h2>
<p>OK, but what about MVC? The Model-View-Controller pattern has been around for ages. It‚Äôs been adopted by many frameworks across a plethora of languages like Ruby (Rails), Python (Django), Java (Play, Spring MVC). The idea is to have separate components that each do their job:</p>
<ul>
<li>The Model handles data and business logic.</li>
<li>The View is for the presentation of the data and the user interface.</li>
<li>The Controller ties the two together by getting data from the Model and showing the View to the user.</li>
</ul>
<p>Sounds great in theory, and it‚Äôs excellent when the logic is minimal and your website doesn‚Äôt hold complex logic. That is where things get tricky, but we‚Äôll get to that in a second.</p>
<p>MVC spread out like wildfire throughout the web development community. Even libraries like React, which is insanely popular these days is explained as the view layer of your web app. No other pattern has been popularized so much that it cannot be shaken off. Rails added the <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">Publish-Subscribe</a> with ActionCable, where the concept of <a href="https://guides.rubyonrails.org/action_cable_overview.html#terminology">channels is described as the controller</a> of the MVC pattern.</p>
<p>But what are the anti-patterns there, in the so widely used pattern? Let‚Äôs go over some of the most common anti-patterns for each part of the MVC pattern.</p>
<h3 id="model-problems"><a href="#model-problems" aria-label="model problems permalink"></a>Model Problems</h3>
<p>As an application grows and business logic gets expanded, folks tend to overcrowd their models. Constant growth can lead to an anti-pattern called the Fat Model.</p>
<p>The famous ‚ÄòFat Model, Skinny Controller‚Äô pattern identifies as a bad guy, some as the good guy. We will say that having any of the fat is an anti-pattern. To better understand it, let‚Äôs get into an example. Imagine we have a streaming service like Spotify or Deezer. Inside it, we have a model for songs like this:</p>
<div data-language="rb"><pre><code><span>class</span> <span>Song</span> <span>&lt;</span> <span>ApplicationRecord</span>
  belongs_to <span>:album</span>
  belongs_to <span>:artist</span>
  belongs_to <span>:publisher</span>

  has_one <span>:text</span>
  has_many <span>:downloads</span>

  validates <span>:artist_id</span><span>,</span> presence<span>:</span> <span>true</span>
  validates <span>:publisher_id</span><span>,</span> presence<span>:</span> <span>true</span>

  after_update <span>:alert_artist_followers</span>
  after_update <span>:alert_publisher</span>

  <span>def</span> <span><span>alert_artist_followers</span></span>
    <span>return</span> <span>if</span> unreleased<span>?</span>

    artist<span>.</span>followers<span>.</span><span>each</span> <span>{</span> <span>|</span>follower<span>|</span> follower<span>.</span>notify<span>(</span><span>self</span><span>)</span> <span>}</span>
  <span>end</span>

  <span>def</span> <span><span>alert_publisher</span></span>
    <span>PublisherMailer</span><span>.</span>song_email<span>(</span>publisher<span>,</span> <span>self</span><span>)</span><span>.</span>deliver_now
  <span>end</span>

  <span>def</span> <span><span>includes_profanities</span></span><span>?</span>
    text<span>.</span>scan_for_profanities<span>.</span>any<span>?</span>
  <span>end</span>

  <span>def</span> <span><span>user_downloaded</span></span><span>?</span><span>(</span>user<span>)</span>
    user<span>.</span>library<span>.</span>has_song<span>?</span><span>(</span><span>self</span><span>)</span>
  <span>end</span>

  <span>def</span> <span><span>find_published_from_artist_with_albums</span></span>
    <span>.</span><span>.</span><span>.</span>
  <span>end</span>

  <span>def</span> <span><span>find_published_with_albums</span></span>
    <span>.</span><span>.</span><span>.</span>
  <span>end</span>

  <span>def</span> <span><span>to_wav</span></span>
    <span>.</span><span>.</span><span>.</span>
  <span>end</span>

  <span>def</span> <span><span>to_mp3</span></span>
    <span>.</span><span>.</span><span>.</span>
  <span>end</span>

  <span>def</span>‚Ä¶</code></pre></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pragmaticpineapple.com/introduction-to-ruby-on-rails-patterns-and-anti-patterns/">https://pragmaticpineapple.com/introduction-to-ruby-on-rails-patterns-and-anti-patterns/</a></em></p>]]>
            </description>
            <link>https://pragmaticpineapple.com/introduction-to-ruby-on-rails-patterns-and-anti-patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057531</guid>
            <pubDate>Wed, 11 Nov 2020 11:42:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rise of the bystander as a complicit historical actor]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057512">thread link</a>) | @rbanffy
<br/>
November 11, 2020 | https://psyche.co/ideas/the-bystanders-rise-as-a-morally-complicit-actor-in-history | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/the-bystanders-rise-as-a-morally-complicit-actor-in-history">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>At about 3 o√¢‚Ç¨‚Ñ¢clock</strong> one morning in the early spring of 1964, Kitty Genovese, 28, arrived home from the bar in New York City where she worked, as she did morning after morning. While she walked in darkness from the lot where she√¢‚Ç¨‚Ñ¢d parked her car, an assailant attacked her, drove away and then returned to assault her some more. Genovese repeatedly screamed for help. Several neighbours reported hearing her but, as the <a href="https://aeon.co/essays/why-don-t-people-come-to-the-rescue-of-victims-of-crime" rel="noopener">story</a> goes, no one answered her calls. The assailant left her eventually to die.</p>
<p><em>The New York Times</em> gave the incident routine coverage: Genovese was one more victim of brutal assault on the streets of the city. But a couple of weeks later, the story made front-page news. There were no new facts or startling discoveries; what was new was the reframing of the story: where were the neighbours? How could they so heartlessly ignore the victim√¢‚Ç¨‚Ñ¢s cries for help? What was just another violent crime turned into a sensational murder case. Genovese became a household name associated with what grew into a controversial story about bystanders and their complicit silence. The residents of the Mowbray, an apartment complex in Queens across the street from the crime scene, were in the unenviable position of having to defend themselves from international criticism. They asserted that it was, after all, three in the morning and they were asleep √¢‚Ç¨‚Äú moreover, with windows shut tight against the outside cold. Some claimed that, even if they√¢‚Ç¨‚Ñ¢d called the police, they wouldn√¢‚Ç¨‚Ñ¢t have responded to yet another street crime.</p>
<p>Bystander incrimination has taken root. Over time, bystanders were called out for summary condemnation. The activist Abbie Hoffman remarked: √¢‚Ç¨ÀúAnd so you ask, √¢‚Ç¨≈ìWhat about innocent bystanders?√¢‚Ç¨ÔøΩ But we are in a time of revolution. If you are a bystander, you are not innocent.√¢‚Ç¨‚Ñ¢ The political philosopher Hannah Arendt, also writing in the 1960s, made the point by referring to the requirements of civil conduct: our √¢‚Ç¨Àúvicarious responsibility for things we have not done, this taking upon ourselves the consequences for things we are entirely innocent of, is the price we pay for the fact that we live our lives not by ourselves but among our fellow [citizens].√¢‚Ç¨‚Ñ¢</p>
<p>The alleged responsibilities of bystanders acquired such moral force that critics have pushed back. Victoria Barnett, author of <em>Bystanders: Conscience and Complicity During the Holocaust</em> (1999), asked: √¢‚Ç¨ÀúWhat lies beneath the surface [of silence]?√¢‚Ç¨‚Ñ¢ suggesting that fear or perpetrator allegiance explains the reticence of onlookers. Henrik Edgren, another scholar who has written about bystanders, posits assertions that are similarly exculpatory, explaining that bystanders are often coerced from interfering in harmful acts. Offering canonic justification for bystander inertia, the evidence-based theory of the bystander effect proposed in 1968 by the social psychologists John Darley and Bibb Latan√É¬© <a href="https://psycnet.apa.org/record/1968-08862-001" rel="nofollow noreferrer noopener">argued</a> that onlookers fail to intervene when they believe that others will.</p>
<p>The presumption of bystanders√¢‚Ç¨‚Ñ¢ responsibility has, however, crystallised into the predominant opinion. Good Samaritan laws ratify intervention and protect √¢‚Ç¨Àúupstanders√¢‚Ç¨‚Ñ¢ from liability. Bystander intervention is now axiomatic, a paragon of civic behaviour. Consider, by contrast, an image from the Tulsa race massacre of 1921 in Oklahoma: men and women blithely go about their business while the city within view burns. Images of lynchings are also revealing: onlookers, hardly indifferent, are downright jubilant. Nazi authorities made a point of including onlookers in their documentation of persecution. Edgren is no doubt right about the risks of intervention, but it is just as likely that German onlookers felt lucky to be on the right side of history or were even impressed with the clarity that the Nazis achieved about who belonged to the new Germany and who didn√¢‚Ç¨‚Ñ¢t. Other images from the Nazi period confirm that looking on was acceptable behaviour, if not a joyful experience, often serving to bind observers into a community of privileged insiders. Images of <em>Kristallnacht</em>, for example, show spectators gazing inertly at a burning synagogue and urban passers-by oblivious to the effects of racially inspired vandalism.</p>
<p>Jews remonstrated as strongly against the indifference of onlookers as they did against their assailants</p>
<p><strong>Paradoxically, the Nazi</strong> period was pivotal in turning public opinion against bystanders. Victims were making themselves heard. In 1935, Joachim Prinz, a leader of the German Jewish community, wrote an early and classic statement of bystander incrimination when racism was again on the rise after a two-year lull in state-inspired antisemitism. The notorious Nuremberg Laws, which emerged later that year, would codify national apartheid. Jews, wrote Prinz, were dangerously vulnerable, but just as ominous, he asserted, was the silence of his compatriots: √¢‚Ç¨ÀúThe Jews of small towns, who live at the market square without neighbours, whose children go to school without neighbouring children, feel the isolation √¢‚Ç¨¬¶√¢‚Ç¨‚Ñ¢ It √¢‚Ç¨Àúmight be the hardest lot anyone can befall√¢‚Ç¨‚Ñ¢ √¢‚Ç¨‚Äú as hard as persecution itself.</p>
<p>Jews, whose demise accelerated during the Second World War, remonstrated as strongly against the indifference of onlookers as they did against their assailants. Writing in 1944 from his hiding place in Warsaw, Tadeusz Obr√Ñ‚Ñ¢ski reviled the Polish government-in-exile:</p>
<blockquote>Why √¢‚Ç¨¬¶ didn√¢‚Ç¨‚Ñ¢t it order the Poles, back in 1939, to help Jews hide from the German murderers? Why did they keep silent? Why did they let, and why are they still letting, us be destroyed, here on the Aryan side? √¢‚Ç¨¬¶ The Polish people betrayed three and a half million Jews. This is a fact which will be discussed in [future] history.</blockquote>
<p>Obr√Ñ‚Ñ¢ski made sure that, in losing hope for survival, he would save his final, bitter words for feckless officials and ordinary citizens alike.</p>
<p>It√¢‚Ç¨‚Ñ¢s unlikely that the turn from bystander innocence to bystander incrimination started during the Nazi period. We need more research on the history of bystander construction to clarify its emergence as consensus opinion. Did Black people in the United States, for example, implore white neighbours for protection against the systems of slavery and Jim Crow? We find little evidence for this until the mobilisation of the civil rights movement in the 1950s and √¢‚Ç¨‚Ñ¢60s, and Black people did so then in good part because the Holocaust and its legacy exposed bystanders√¢‚Ç¨‚Ñ¢ complicity. Writing in 1963, Martin Luther King, Jr commented that, though it was √¢‚Ç¨Àú√¢‚Ç¨≈ìillegal√¢‚Ç¨ÔøΩ to aid and comfort a Jew in Hitler√¢‚Ç¨‚Ñ¢s Germany √¢‚Ç¨¬¶ had I lived in Germany at the time I would have aided and comforted my Jewish brothers.√¢‚Ç¨‚Ñ¢ At the time, the Black militant magazine <em>The Liberator</em> frequently referred to the consequences of passivity during the Holocaust era, as it saw it, to inspire action as well, turning its attention to Black people themselves.</p>
<p>Historically, European Jews could hardly imagine that their neighbours wouldn√¢‚Ç¨‚Ñ¢t provide protection whenever they were collectively threatened. Obr√Ñ‚Ñ¢ski√¢‚Ç¨‚Ñ¢s reference to betrayal is significant. For Jews, the system had been favourable. Their statutory emancipation from medieval ghettos, spanning the late-18th to late-19th centuries, promised their recognition as citizens, which entitled them to equal protections secured by the rule of law. It was not unreasonable for Jews to expect protection, if not from the state then from other Germans. As Prinz wrote: √¢‚Ç¨ÀúWe would not find it all [isolation] so painful if we did not have the feeling that we once did have neighbours.√¢‚Ç¨‚Ñ¢</p>
<p>Black Americans, by contrast had no choice but to rely on other Black Americans. Some even argue, and argue persuasively, that it√¢‚Ç¨‚Ñ¢s more prudent this way because relying on others for help would put Black people at the mercy of their capricious neighbours, a policy that ultimately proved fatal for Jews. In retrospect, Jews rued their naivety. They suffered from the unanticipated abandonment of their compatriots. Abandonment, <a href="https://www.jstor.org/stable/1344023?seq=1" rel="nofollow noreferrer noopener">wrote</a> the Holocaust survivor Vladimir Jank√É¬©l√É¬©vitch, was √¢‚Ç¨Àúone of the most frightful aspects of their ordeal√¢‚Ç¨‚Ñ¢. Simon Wiesenthal, another survivor, elaborated: √¢‚Ç¨ÀúOur fathers had crept out of the confines of the [premodern] ghetto into the open world. They had worked hard and done all they could to be recognised by their fellow creatures. But it was all in vain.√¢‚Ç¨‚Ñ¢ Like Prinz, Wiesenthal felt the sting of abject betrayal.</p>
<p>Informed by the memory of the Holocaust, onlookers metamorphosed into accessories to crime</p>
<p><strong>The discourse of bystander</strong> incrimination grew stronger in the 1960s. Bystanders were roundly condemned for their indifference. While onlookers and others offered exculpatory reasons for inaction, victims were unwavering: bystanders were unconditionally complicit. King, writing from a Birmingham jail, observed: √¢‚Ç¨ÀúWe will have to repent in this generation not merely for the hateful words and the actions of the bad people but for the appalling silence of the good people.√¢‚Ç¨‚Ñ¢ Jewish survivors were also vocal. At the signature Great March on Washington the same year, Prinz, now a German expatriate and American citizen, echoed what he wrote three decades before:</p>
<blockquote>When I was a rabbi of the Jewish community in Berlin under the Hitler regime √¢‚Ç¨¬¶ the most important thing that I learned √¢‚Ç¨¬¶ is that bigotry and hatred are not the most urgent problem. The most urgent, the most disgraceful, the most shameful and the most tragic problem is silence. A great people which had created a great civilisation had become a nation of onlookers √¢‚Ç¨¬¶ America must not become a nation of onlookers. America must not remain silent.</blockquote>
<p>The 1960s was the decade when Holocaust survivors started to publish their accounts for a largely unsympathetic audience: Jank√É¬©l√É¬©vitch in 1967, Wiesenthal in 1969 and, among the most reflective memoirists, Jean Am√É¬©ry in 1966. Later, Am√É¬©ry wrote with bitter irony that: √¢‚Ç¨ÀúThe expectation of help, the certainty ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/the-bystanders-rise-as-a-morally-complicit-actor-in-history">https://psyche.co/ideas/the-bystanders-rise-as-a-morally-complicit-actor-in-history</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/the-bystanders-rise-as-a-morally-complicit-actor-in-history</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057512</guid>
            <pubDate>Wed, 11 Nov 2020 11:37:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Connect your on-premises databases to Kubernetes in the cloud]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057481">thread link</a>) | @alexellisuk
<br/>
November 11, 2020 | https://inlets.dev/blog/2020/11/06/hybrid-cloud-with-inlets.html | <a href="https://web.archive.org/web/*/https://inlets.dev/blog/2020/11/06/hybrid-cloud-with-inlets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Learn how to connect private on-premises services to the public cloud with inlets</p>

<h2 id="what-is-hybrid-cloud-anyway">What is ‚Äúhybrid cloud‚Äù anyway?</h2>

<p>Before we get started, let‚Äôs have a clear idea what ‚Äúhybrid cloud‚Äù is all about.</p>

<blockquote>
  <p>‚Äú<strong>Hybrid Cloud</strong> is a composition of a public cloud and a private environment, such as a private cloud or on-premises resources, offering the benefits of multiple deployment models. ‚Ä¶ For example, an organization may store sensitive client data in house on a private cloud application, but interconnect that application to services provided on a public cloud as a software service.‚Äù ‚Äì <a href="https://en.wikipedia.org/wiki/Cloud_computing#Hybrid_cloud">Wikipedia</a></p>
</blockquote>

<p>A hybrid cloud strategy can give a huge benefit for your business by moving workloads to a public cloud, leveraging the flexibility and robustness of managed services, while keeping sensitive data on a private cloud or local data center.</p>

<p>In this post, we‚Äôll demonstrate how you can bring your on-premises services or databases into a Kubernetes cluster running on a public cloud.</p>

<p>This model applies for different use-cases:</p>
<ul>
  <li>perhaps you are in the middle of a digital transformation where some parts of the architecture is deployed on a public cloud, but they still need to integrate with some legacy services</li>
  <li>you have some sensitive data to be kept in a private data center due to data residency regulation</li>
</ul>

<h2 id="tutorial">Tutorial</h2>

<p>You‚Äôll need:</p>
<ul>
  <li>A Kubernetes cluster running on a public cloud (e.g. GKE, AKS, EKS, DOKS, ‚Ä¶)</li>
  <li><code>kubectl</code>, configured to connect to the cluster</li>
  <li>A domain and access to your DNS admin panel to create a sub-domain</li>
  <li>A service, like a database, running locally</li>
  <li>An inlets PRO license, start <a href="https://docs.google.com/forms/d/e/1FAIpQLScfNQr1o_Ctu_6vbMoTJ0xwZKZ3Hszu9C-8GJGWw1Fnebzz-g/viewform?usp=sf_link">a 14-day free trial</a>.</li>
</ul>

<p>As an example, we will connect a WordPress instance running in the cloud with a MySQL server running locally. Still, this solution is perfectly applicable to other databases or services like e.g. an Oracle database, a MinIO cluster or a RabbitMQ service.</p>

<p><img src="https://inlets.dev/images/2020-11-06-hybrid-cloud-with-inlets/mysql-wordpress.png" alt="hybrid-mysql-wordpress"></p>

<blockquote>
  <p>Picture above: our target architecture, a WordPress in the cloud connecting to a MySQL on-prem via inlets PRO</p>
</blockquote>

<h3 id="create-the-inlets-pro-exit-server">Create the inlets PRO exit server</h3>

<p>Before we start an inlets-pro exit service, create a Kubernetes secret with a token:</p>

<div><div><pre><code>kubectl create secret generic inlets-token <span>--from-literal</span><span>=</span><span>token</span><span>=</span>&lt;a random token&gt;
</code></pre></div></div>

<p>First, start an inlets-pro exit server pod and make it public with a LoadBalancer service:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>apps/v1</span>
<span>kind</span><span>:</span> <span>Deployment</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>inlets-pro-server</span>
<span>spec</span><span>:</span>
  <span>replicas</span><span>:</span> <span>1</span>
  <span>selector</span><span>:</span>
    <span>matchLabels</span><span>:</span>
      <span>app</span><span>:</span> <span>inlets-pro-server</span>
  <span>template</span><span>:</span>
    <span>metadata</span><span>:</span>
      <span>labels</span><span>:</span>
        <span>app</span><span>:</span> <span>inlets-pro-server</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>inlets-pro</span>
          <span>image</span><span>:</span> <span>inlets/inlets-pro:0.7.2</span>
          <span>imagePullPolicy</span><span>:</span> <span>IfNotPresent</span>
          <span>command</span><span>:</span> <span>[</span> <span>"</span><span>inlets-pro"</span> <span>]</span>
          <span>args</span><span>:</span>
            <span>-</span> <span>"</span><span>server"</span>
            <span>-</span> <span>"</span><span>--auto-tls"</span>
            <span>-</span> <span>"</span><span>--common-name=inlets.example.com"</span>
            <span>-</span> <span>"</span><span>--token-from=/etc/inlets/token"</span>
          <span>volumeMounts</span><span>:</span>
            <span>-</span> <span>name</span><span>:</span> <span>temp-volume</span>
              <span>mountPath</span><span>:</span> <span>/tmp</span>
            <span>-</span> <span>name</span><span>:</span> <span>inlets-token</span>
              <span>mountPath</span><span>:</span> <span>/etc/inlets</span>
              <span>readOnly</span><span>:</span> <span>true</span>   
      <span>volumes</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>temp-volume</span>
          <span>emptyDir</span><span>:</span> <span>{}</span>        
        <span>-</span> <span>name</span><span>:</span> <span>inlets-token</span>
          <span>secret</span><span>:</span>
            <span>secretName</span><span>:</span> <span>inlets-token</span>
</code></pre></div></div>

<p>After applying this on the cluster, a exit server pod is available with:</p>

<ul>
  <li><code>auto-tls</code> enabled, meaning a TLS certificate for the <code>common-name</code> is automatically generated</li>
  <li>the default control port 8123</li>
  <li>the token available in the previously created secret</li>
</ul>

<p>Now expose the exit server with a LoadBalancer service:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>v1</span>
<span>kind</span><span>:</span> <span>Service</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>inlets-pro-server</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>inlets-pro-server</span>
<span>spec</span><span>:</span>
  <span>type</span><span>:</span> <span>LoadBalancer</span>
  <span>ports</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> <span>control</span>
      <span>port</span><span>:</span> <span>8123</span>
      <span>targetPort</span><span>:</span> <span>8123</span>
  <span>selector</span><span>:</span>
    <span>app</span><span>:</span> <span>inlets-pro-server</span>
</code></pre></div></div>

<blockquote>
  <p>Instead of using a LoadBalancer service, a Kubernetes Ingress can also be used here, especially when bringing multiple services into your cluster.</p>
</blockquote>

<p>As you can see, we‚Äôll only expose the control port 8123 to the outside world.
This is actually a good thing, as our database will only reachable from within our Kubernetes cluster, making it more secure.</p>

<p>Wait a little bit until the load balancer is created, grab it‚Äôs public IP address and point your domain (remember the common-name) to it.</p>

<div><div><pre><code><span>$ </span>kubectl get service inlets-pro-server
NAME                TYPE           CLUSTER-IP       EXTERNAL-IP       PORT<span>(</span>S<span>)</span>          AGE
inlets-pro-server   LoadBalancer   192.168.197.17   185.136.232.105   8123:31981/TCP   8m11s
</code></pre></div></div>

<blockquote>
  <p>TIP: Some cloud providers honor the <code>loadBalancerSourceRanges</code> field in the Service spec, which allows you to provide a list of IP CIDR blocks allowed to connect to the load balancer. By creating firewall rules, only connections coming from your on-prem data center are allowed.</p>
</blockquote>

<h3 id="start-the-inlets-pro-client">Start the inlets-pro client</h3>

<p>Now that the server part of the tunnel is running, it is time to start the client in our private data center.
Let‚Äôs say we have a MySQL instance available with an internal IP address <code>10.1.0.50</code>, start the inlets-pro client:</p>

<div><div><pre><code><span>$ </span>inlets-pro client <span>--license-file</span> ~/inlets-license <span>--port</span> 3306 <span>--url</span> wss://inlets.example.com:8123/connect <span>--upstream</span> 10.1.0.50 <span>--token</span> &lt;your token&gt; 
2020/11/05 13:23:21 Welcome to inlets-pro! Client version 0.7.2
2020/11/05 13:23:21 Licensed to: Johan Siebens &lt;xxxx@gmail.com&gt;, expires: xxx day<span>(</span>s<span>)</span>
2020/11/05 13:23:21 Upstream server: 10.1.0.50, <span>for </span>ports: 3306
inlets-pro client. Copyright Alex Ellis, OpenFaaS Ltd 2020
INFO[2020/11/05 13:23:21] Connecting to proxy                           <span>url</span><span>=</span><span>"wss://inlets.example.com:8123/connect"</span>
</code></pre></div></div>

<p>Perfect! Now the client made the connection, port 3306 of the server pod in our public cloud is accepting connection and will tunnel traffic to the MySQL instance.</p>

<h3 id="create-a-mysql-service">Create a MySQL service</h3>

<p>When we deploy WordPress, we could configure it to connect directly to the inlets-pro server pod, but it is better to create Kubernetes Service:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>v1</span>
<span>kind</span><span>:</span> <span>Service</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>mysql</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>mysql</span>
<span>spec</span><span>:</span>
  <span>ports</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> <span>mysql</span>
      <span>port</span><span>:</span> <span>3306</span>
      <span>targetPort</span><span>:</span> <span>3306</span>
  <span>selector</span><span>:</span>
    <span>app</span><span>:</span> <span>inlets-pro-server</span>
</code></pre></div></div>

<p>The set of Pods targeted by this Service is determined by the same selector as the previous service, but this time it is a service of type ClusterIP, making it only accessible from inside the cluster.</p>

<h3 id="deploy-wordpress">Deploy WordPress</h3>

<p>The only thing left for our example is deploying a WordPress instance, connecting to the MySQL database via the inlets-pro tunnel:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>apps/v1</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>wordpress</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>wordpress</span>
<span>spec</span><span>:</span>
  <span>selector</span><span>:</span>
    <span>matchLabels</span><span>:</span>
      <span>app</span><span>:</span> <span>wordpress</span>
  <span>template</span><span>:</span>
    <span>metadata</span><span>:</span>
      <span>labels</span><span>:</span>
        <span>app</span><span>:</span> <span>wordpress</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span>-</span> <span>image</span><span>:</span> <span>wordpress</span>
        <span>name</span><span>:</span> <span>wordpress</span>
        <span>env</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>WORDPRESS_DB_HOST</span>
          <span>value</span><span>:</span> <span>mysql</span>
        <span>ports</span><span>:</span>
        <span>-</span> <span>containerPort</span><span>:</span> <span>80</span>
          <span>name</span><span>:</span> <span>wordpress</span>
</code></pre></div></div>

<blockquote>
  <p>note: this WordPress is not production-ready as it is missing the required volumes for the content</p>
</blockquote>

<p>Mission accomplished! Our WordPress application, running in a public cloud environments is using the MySQL server located in the private data center.</p>

<h2 id="wrapping-up">Wrapping up</h2>

<p>This tutorial gives us a short introduction on how inlets PRO can help us to build a hybrid cloud between existing servers and public cloud.
As a cheaper, easier alternative to a data-center uplink or managed product like AWS Direct Connect or Azure Express Route it is a very lightweight, but powerful, tool to bring your on-prem services to a cloud workload.</p>

<p>For the example we chose WordPress, but the same technique can be applied to any other applications that use TCP traffic.</p>

<ul>
  <li>Resource heavy ETL processes on the cloud, combining multiple data sources like private legacy databases and event streams in the public cloud.</li>
  <li>Data migrations from and to on-prem databases</li>
  <li>Connect your new application to legacy service during a digital transformation</li>
  <li>Keep your LDAP side on-premises in Active Directory and connect to a SaaS IDP product like Auth0. That way anyone can log into a website using their corporate identity without having to migrate Active Directory to the cloud.</li>
</ul>

<p>Further resources:</p>

<ul>
  <li><a href="https://docs.inlets.dev/">Read tutorials and documentation for inlets PRO and OSS</a></li>
  <li><a href="https://inlets.dev/">Kick the tires with free 14-day trial of inlets PRO</a></li>
  <li><a href="https://twitter.com/inletsdev/">Follow @inletsdev on Twitter</a></li>
</ul>

        </div></div>]]>
            </description>
            <link>https://inlets.dev/blog/2020/11/06/hybrid-cloud-with-inlets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057481</guid>
            <pubDate>Wed, 11 Nov 2020 11:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EmacsConf ‚Äì 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057456">thread link</a>) | @ProfDreamer
<br/>
November 11, 2020 | https://emacsconf.org/2020/ | <a href="https://web.archive.org/web/*/https://emacsconf.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">



<div id="pagebody">







<div id="content" role="main">
<p>EmacsConf 2020 | Online Conference | <strong>November 28 and 29, 2020</strong><br>
<a href="https://emacsconf.org/i/emacsconf-logo1-256.png"><img src="https://emacsconf.org/i/emacsconf-logo1-256.png" width="256" height="256" alt="EmacsConf logo"></a><br>
<a href="https://emacsconf.org/2020/schedule/"><strong>Schedule</strong></a> | <a href="https://emacsconf.org/2020/poster/"><strong>Poster</strong></a> | <a href="https://emacsconf.org/2020/planning/">Planning</a> |
<a href="https://emacsconf.org/conduct/">Code of Conduct</a></p>

<p>EmacsConf is the conference about the joy of Emacs, Emacs Lisp, and
memorizing key sequences.</p>

<p>We are holding EmacsConf 2020 as a virtual (online) conference again
this year, especially now, given the current state of the world with
the ongoing global pandemic. We remain fully committed to freedom, and
we will continue using our infrastructure and streaming setup
consisting entirely of <a href="https://www.gnu.org/philosophy/free-sw.html">free software</a>, much like the last
EmacsConf. Check out the <a href="https://emacsconf.org/2020/schedule/"><strong>Schedule</strong></a> and
<a href="https://emacsconf.org/2020/poster/"><strong>Poster</strong></a> for more details.</p>

<h2>Watching</h2>

<p>On November 28 and 29 you will be able to watch the livestreams via
<a href="https://live.emacsconf.org/">https://live.emacsconf.org</a>, which also has details on how to watch the
streams using media players that support streaming (like mpv and VLC).</p>

<p>We'll record the conference and post the videos and links on the
individual talk pages. In the meantime, please enjoy
<a href="https://emacsconf.org/2019/talks/">last year's talks</a>.</p>

<h2>Participating</h2>

<p>For audience questions specifically, we will be experimenting with
using a collaboratively-editable Etherpad as the primary means of
collecting audience questions. We will be posting a link to the pad
closer to the event. If, however, you are unable to access the pad to
add your question(s), we will still try to take questions from our
questions-specific IRC channel (<code>#emacsconf-questions</code> on
<code>chat.freenode.net</code>), and ask one or two volunteers to kindly add
questions from that channel to the pad on behalf of folks who are not
able to or prefer not to use the web-based questions pad.</p>

<p>Come hang out with us in <code>#emacsconf</code> on <code>chat.freenode.net</code>.  You can
join the chat using <a href="ircs://chat.freenode.net:6697/emacsconf">your favourite IRC client</a>, or by visiting
<a href="https://chat.emacsconf.org/">chat.emacsconf.org</a> in your web browser, a self-hosted instance
of <a href="https://thelounge.chat/">The Lounge</a> free software web IRC client for EmacsConf.</p>

<h2>Updates</h2>

<p>Be sure to subscribe to our mailing list
<a href="https://lists.gnu.org/mailman/listinfo/emacsconf-discuss">emacsconf-discuss</a> for discussion and
announcements about the conference.</p>

</div>







</div>



</div></div>]]>
            </description>
            <link>https://emacsconf.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057456</guid>
            <pubDate>Wed, 11 Nov 2020 11:26:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[hystreet.com]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057455">thread link</a>) | @weinzierl
<br/>
November 11, 2020 | https://hystreet.com/en/methodology | <a href="https://web.archive.org/web/*/https://hystreet.com/en/methodology">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><section><div><div><div><h2>Technical principles</h2><p>hystreet.com measures the number of people crossing an imaginary line on a shopping street 24 hours a day, 365 days a year. The laser scanners attached to the facades of houses generate a fourfold light curtain for reliable pedestrian frequency counting. This enables the counter not only to distinguish between different zones, but also to determine the walking directions of pedestrians. Pedestrians who cross an imaginary line several times within a measuring interval are counted anew.</p><p>Furthermore, with this technique, it is possible to distinguish between children and adults, as body size is also a measurable feature. On our website you will find only the pedestrian frequencies of pedestrians over a size of 80 cm.</p></div></div></div></section><section><div><div><div><h2>Live Data</h2><p>Be in the picture at any time and anywhere about the passersby frequency - with the mobile version of hystreet.com you also have the opportunity to conveniently access and analyze all data on the go. All important features and settings are available in the mobile version as well as the ability to save data.</p></div></div></div></section><section><div><div><h2>Hourly retrieval</h2><p>The pedestrian frequency is available for every hour of the year. Thus all daily maximum values are recognizable.</p></div></div></section><section><div><div><h2>Weather data for all metering points</h2><p>We show additional weather data for each measured value of our locations, to provide more context for each measurement. <a href="https://darksky.net/poweredby/">Powered by Dark Sky</a>.</p><ul><li><span>Clear sky, after sunrise</span></li><li><span>Clear sky, after sunset</span></li><li><span>Partly cloudy, after sunrise</span></li><li><span>Partly cloudy, after sunset</span></li><li><span>Mostly cloudy</span></li><li><span>Rainy</span></li><li><span>Windy</span></li><li><svg viewBox="0 0 512 512" width="32"><path fill="currentColor" d="M416 128c-.6 0-1.1.2-1.6.2 1.1-5.2 1.6-10.6 1.6-16.2 0-44.2-35.8-80-80-80-24.6 0-46.3 11.3-61 28.8C256.4 24.8 219.3 0 176 0 114.2 0 64 50.1 64 112c0 7.3.8 14.3 2.1 21.2C27.8 145.8 0 181.5 0 224c0 53 43 96 96 96h320c53 0 96-43 96-96s-43-96-96-96zm57.5 239.5h-435c-8.8 0-16 7.2-16 16v16c0 8.8 7.2 16 16 16h435c8.8 0 16-7.2 16-16v-16c0-8.8-7.2-16-16-16zm0 96h-435c-8.8 0-16 7.2-16 16v16c0 8.8 7.2 16 16 16h435c8.8 0 16-7.2 16-16v-16c0-8.8-7.2-16-16-16z"></path></svg><span>Fog</span></li><li><span>Snowfall</span></li><li><svg id="cloud-sleet_svg__Layer_1" x="0" y="0" viewBox="0 0 512 512" xml:space="preserve" width="32"><g fill="currentColor"><path d="M144.7 395.5c15.4 0 27.8 12.5 27.8 27.8 0 15.4-12.5 27.8-27.8 27.8-15.4 0-27.8-12.5-27.8-27.8-.1-15.4 12.4-27.8 27.8-27.8zM256 451.1c15.4 0 27.8 12.5 27.8 27.8 0 15.4-12.5 27.8-27.8 27.8-15.4 0-27.8-12.5-27.8-27.8s12.4-27.8 27.8-27.8zM367.3 395.5c15.4 0 27.8 12.5 27.8 27.8 0 15.4-12.5 27.8-27.8 27.8-15.4 0-27.8-12.5-27.8-27.8 0-15.4 12.5-27.8 27.8-27.8z"></path><path d="M416 128c-.6 0-1.1.2-1.6.2 1.1-5.2 1.6-10.6 1.6-16.2 0-44.2-35.8-80-80-80-24.6 0-46.3 11.3-61 28.8C256.4 24.8 219.3 0 176 0 114.2 0 64 50.1 64 112c0 7.3.8 14.3 2.1 21.2C27.8 145.8 0 181.5 0 224c0 53 43 96 96 96h32.7l.1 35.5c0 8.9 7.2 16 16.1 15.9 2.9 0 5.6-.8 7.9-2.1 4.8-2.7 8-7.9 8-13.9l-.1-35.4H240l.2 84.4c0 8.9 7.2 16 16.1 15.9 2.9 0 5.6-.8 7.9-2.1 4.8-2.7 8-7.9 8-13.9L272 320h79.4l.1 35.5c0 8.9 7.2 16 16.1 15.9 2.9 0 5.6-.8 7.9-2.1 4.8-2.7 8-7.9 8-13.9l-.1-35.4H416c53 0 96-43 96-96s-43-96-96-96z"></path></g></svg><span>Sleet</span></li></ul></div></div></section><section><div><div><h2>Eye-safe and safe under data protection law</h2><p>The technique we use is eye-safe and invisible.
Personal data is not collected with this technology. Thus
we work with a 100% GDPR compliant solution.</p><h2>99% counting accuracy</h2><p>According to the manufacturer, a counting accuracy of 99% can be achieved with the technology used up to a flow rate of approx. 500 persons per minute.</p><h2>Precise positioning of the laser scanners</h2><p>Laser scanners (type PeCo LC) are permanently installed on the facades at all metering points. The devices are installed at a height between 4 and 20 metres. The device can thus optimally measure a road width of up to 32 metres.</p><p>For street widths over 32 metres, it is possible to measure from two opposite sides. The published data is always the pedestrian frequency of the entire street width (unless otherwise specified).</p><h2>Verification of data</h2><p>The laser must have a clear view in its measuring lines. If these once blocked by external circumstances (e.g. scaffolding, cranes, superstructures or treetops), temporary measurement inaccuracies may occur as a result. Even in case of power failures it is not possible to measure the frequencies. The measured data are therefore randomly checked and corrected if necessary.</p></div></div></section><section><div><div><p><span>Peco LC</span></p><div><h2>Technical data PeCo LC</h2><ul><li>Laser class 1</li><li>Weight: 3,4kg</li><li>Dimension: 247x121x109 (hxdxw)</li><li>Minimum installation height 4m, Maximum height: 20 m</li><li>Power consumption: 0.047 kW/h, electricity costs: ca. 45‚Ç¨/year</li></ul></div></div></div><p><img src="https://hystreet.com/packs/media/sections/assets/lase-logo-713d4738753630d32ce040de8be25fc4.png"></p></section><section><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" preserveAspectRatio="none" style="bottom:100%"><polygon points="0,100 100,100 0,0"></polygon></svg></section></div></div></div>]]>
            </description>
            <link>https://hystreet.com/en/methodology</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057455</guid>
            <pubDate>Wed, 11 Nov 2020 11:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fork Awesome: a fork of the iconic font and CSS toolkit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057452">thread link</a>) | @edward
<br/>
November 11, 2020 | https://forkaweso.me/Fork-Awesome/ | <a href="https://web.archive.org/web/*/https://forkaweso.me/Fork-Awesome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrap"> <!-- necessary for sticky footer. wrap all content except footer -->
    


    




<div>
  <section id="why">
  <div>
    <div>
      <h4> One Font, 744 Icons</h4><p>
      In a single collection, Fork Awesome is a pictographic language of web-related actions.
    </p></div>
    <div>
      <h4> No JavaScript Required</h4><p>
      Fewer compatibility concerns because Fork Awesome doesn't require JavaScript.
    </p></div>
    <div>
      <h4> Infinite Scalability</h4><p>
      Scalable vector graphics means every icon looks awesome at any size.
    </p></div>
    <div>
      <h4> Free, as in Speech</h4><p>
      Fork Awesome is completely free for commercial use. Check out the <a href="https://forkaweso.me/Fork-Awesome/license/">license</a>.
    </p></div>
    <div>
      <h4> CSS Control</h4><p>
      Easily style icon color, size, shadow, and anything that's possible with CSS.
    </p></div>
    <div>
      <h4> Perfect on Retina Displays</h4><p>
      Fork Awesome icons are vectors, which mean they're gorgeous on high-resolution displays.
    </p></div>
    <div>
      <h4> Plays Well with Others</h4><p>
      Originally designed for <a href="http://getbootstrap.com/">Bootstrap</a>, Fork Awesome works great with all frameworks.
    </p></div>
    <div>
      <h4> Desktop Friendly</h4><p>
      To use on the desktop or for a complete set of vectors,
      check out the <a href="https://forkaweso.me/Fork-Awesome/cheatsheet/">cheatsheet</a>.
    </p></div>
    
  </div>
</section>

  <section id="thanks-to">
  
  <div>
    <p>
        Thanks to <a href="https://twitter.com/davegandy">@davegandy</a> for his
        original work on Font Awesome and to
        <a href="https://twitter.com/gtagliala">@gtagliala</a> for managing pull
        requests and issues on the Font Awesome Github repo.
      </p>
    <p>
        Thanks to the still growing community of <a href="https://github.com/ForkAwesome/Fork-Awesome/blob/master/CONTRIBUTORS.md">115 contributors</a> who've carried this project from the early days of Font Awesome and who have joined this project since the fork.
        If you feel your contribution has not been recognized. Please file an issue, we'll happily add you to the list.
      </p>
  </div>
</section>

</div>




  </div></div>]]>
            </description>
            <link>https://forkaweso.me/Fork-Awesome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057452</guid>
            <pubDate>Wed, 11 Nov 2020 11:25:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Write Unit Tests for Logging]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25057372">thread link</a>) | @JanVanRyswyck
<br/>
November 11, 2020 | https://principal-it.eu/2020/11/unit-tests-for-logging/ | <a href="https://web.archive.org/web/*/https://principal-it.eu/2020/11/unit-tests-for-logging/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>
					<h2>
						How To Write Unit Tests For Logging
					</h2>
					<p><span>
						November 11, 2020
					</span>
				</p></div>

				
<p>Once in a while I get asked the question whether one should write <a href="https://principal-it.eu/2019/10/taxonomy-of-tests/">solitary tests</a> for 
logging functionality. My answer to this question is the typical consultant answer: ‚ÄúIt depends‚Äù. In essence, logging 
is an infrastructure concern. The end result is log data that is being written to a resource which is external to 
an application. Usually the generated data ends up in a file, a database or it might even end up in a cloud service.</p>

<p>Because logging crosses the process boundary of an application, it is more useful to write 
<a href="https://principal-it.eu/2019/10/taxonomy-of-tests/">sociable tests</a> to verify this particular functionality. It doesn‚Äôt make sense to 
use solitary tests in this particular case.</p>

<p>That being said, there are situations where business requirements explicitly state that logging should be a part of the 
interface of an application. In this situation, the intent of logging should be expressed explicitly by the code which 
in turn should also be exercised by solitary tests. The excellent book 
<a href="https://bit.ly/tdd-goos2" target="blank" rel="noopener noreferrer nofollow">Growing Object Oriented Software 
Guided By Tests</a>, written by Steve Freeman and Nat Pryce, mentions that there are generally two separate types of 
logging:</p>

<ul>
  <li>Support logging</li>
  <li>Diagnostic logging</li>
</ul>

<p>A support log contains messages that are intended for those that perform operational activities. These messages are used 
to determine whether the system behaves correctly or not. The log level for these messages is usually of type <em>error</em> 
or <em>info</em>.</p>

<p>A diagnostic log on the other hand holds messages that are targeted towards software developers. These messages provide 
valuable insights into the details of a running system. The log level for these messages is usually of type <em>debug</em> or 
<em>trace</em>.</p>

<p>Given these two types of logging, the basic idea is that code which expresses the intent of support logging should be 
exercised by solitary tests. Code statements that initiate diagnostic logging are usually not covered by tests.</p>

<p>Let‚Äôs have a look at an example that demonstrates both support and diagnostic logging in action.</p>

<pre><code>public class ExpenseSheetController : Controller
{
    private readonly ICommandHandler&lt;CreateExpenseSheet&gt; _commandHandler;
    private readonly ISupportNotifier _supportNotifier;

    public ExpenseSheetController(ICommandHandler&lt;CreateExpenseSheet&gt; commandHandler,
                                  ISupportNotifier supportNotifier)
    {
        _commandHandler = commandHandler;
        _supportNotifier = supportNotifier;
    }
    
    [HttpPost]
    [ServiceFilter(typeof(PerformanceTracing))]
    public IActionResult Create(CreateExpenseSheetFormModel formModel)
    {
        try
        {
            var command = new CreateExpenseSheet(Guid.NewGuid(), formModel.EmployeeId);
            _commandHandler.Handle(command);
        }
        catch(Exception ex)
        {
            _supportNotifier.ErrorDuringExpenseSheetCreation(ex, formModel.EmployeeId);
            return BadRequest();
        }
        
        _supportNotifier.ExpenseSheetCreated(formModel.EmployeeId);
        return Ok();
    }
}
</code></pre>

<p>Here we have the implementation of a controller that can receive a request for creating a new expense sheet. Notice that 
the constructor of this controller class expects an instance of the <em>ISupportNotifier</em> interface. This dependency is 
being used by the implementation of the <em>Create</em> method for logging an error when an exception occurs. It is also used 
for logging when an expense sheet has been successfully created.</p>

<p>This is how the implementation of the <em>SupportNotifier</em> looks like.</p>

<pre><code>public class SupportNotifier : ISupportNotifier
{
    private readonly ILogger&lt;SupportNotifier&gt; _logger;

    public SupportNotifier(ILogger&lt;SupportNotifier&gt; logger)
    {
        _logger = logger;
    }
    
    public void ExpenseSheetCreated(Guid employeeId)
    {
        _logger.LogInformation("Expense sheet created for employee with ID '{employeeId}'.");
    }

    public void ErrorDuringExpenseSheetCreation(Exception ex, Guid employeeId)
    {
        _logger.LogError(ex, $"Unable to create a new expense sheet for employee with ID '{employeeId}'");
    }
}
</code></pre>

<p>This code demonstrates that support logging uses log levels <em>error</em> or <em>info</em> depending on the context. Verifying the
code of the <em>SupportNotifier</em> class itself can be done by using sociable tests. It‚Äôs not a good idea to write
solitary tests for the <em>SupportNotifier</em> class. This would imply that a test double should be used as an instance of 
<em>ILogger</em>. As we already touched on in a <a href="https://principal-it.eu/2020/05/test-double-heuristics/">previous blog post</a>, it‚Äôs much better to 
avoid using test doubles for types that you don‚Äôt own. In this particular case it would even be quite hard to do as 
the <em>Logxx</em> methods of <em>ILogger</em> are actually extension methods and not regular methods.</p>

<p>Let‚Äôs have a look at the tests for the <em>ExpenseSheetController</em>.</p>

<pre><code>[Specification]
public class When_handling_a_request_for_creating_a_new_expense_sheet
{
    [Establish]
    public void Context()
    {
        var commandHandler = Substitute.For&lt;ICommandHandler&lt;CreateExpenseSheet&gt;&gt;();
        _supportNotifier = Substitute.For&lt;ISupportNotifier&gt;();

        _sut = new ExpenseSheetController(commandHandler, _supportNotifier);
    }

    [Because]
    public void Of()
    {
        var formModel = new CreateExpenseSheetFormModel 
        { 
            EmployeeId = new Guid("94EDE8F3-9675-4DD7-A18F-E37B1F323699") 
        };

        _sut.Create(formModel);
    }
    
    [Observation]
    public void Then_it_should_notify_support()
    {
        _supportNotifier.Received()
            .ExpenseSheetCreated(new Guid("94EDE8F3-9675-4DD7-A18F-E37B1F323699"));
    }

    private ExpenseSheetController _sut;
    private ISupportNotifier _supportNotifier;
}

[Specification]
public class When_an_error_occurs_while_handling_a_request_for_creating_a_new_expense_sheet
{
    [Establish]
    public void Context()
    {
        _supportNotifier = Substitute.For&lt;ISupportNotifier&gt;();
        _exception = new InvalidOperationException("Meltdown");
        
        var commandHandler = Substitute.For&lt;ICommandHandler&lt;CreateExpenseSheet&gt;&gt;();
        commandHandler.WhenForAnyArgs(ch =&gt; ch.Handle(null))
            .Throw(_exception);
        
        _sut = new ExpenseSheetController(commandHandler, _supportNotifier);
    }
    
    [Because]
    public void Of()
    {
        var formModel = new CreateExpenseSheetFormModel 
        { 
            EmployeeId = new Guid("D1067157-5C73-4140-9D29-0FE5C1C4C2FB") 
        };

        _sut.Create(formModel);
    }
    
    [Observation]
    public void Then_it_should_notify_support_that_a_new_expense_sheet_has_been_created()
    {
        _supportNotifier.Received()
            .ErrorDuringExpenseSheetCreation(_exception, 
                new Guid("D1067157-5C73-4140-9D29-0FE5C1C4C2FB"));
    }
    
    private ExpenseSheetController _sut;
    private ISupportNotifier _supportNotifier;
    private Exception _exception;
}
</code></pre>

<p>These tests verify whether support logging occurs when an expense sheet has been created or when an exception gets 
raised. This way we express the intent of the operational requirements.</p>

<p>Notice that controller method has been decorated with a <em>ServiceFilter</em> attribute.</p>

<pre><code>[HttpPost]
[ServiceFilter(typeof(PerformanceTracing))]
public IActionResult Create(CreateExpenseSheetFormModel formModel)
{
    ...
}
</code></pre>

<p>By applying this attribute, the <em>PerformanceTracing</em> action filter is being registered to surround the execution of the 
controller method. Let‚Äôs have a look at the implementation of this action filter.</p>

<pre><code>public class PerformanceTracing : ActionFilterAttribute
{
    private readonly ILogger&lt;PerformanceTracing&gt; _logger;
    private readonly Stopwatch _stopWatch;

    public PerformanceTracing(ILogger&lt;PerformanceTracing&gt; logger)
    {
        _logger = logger;
        _stopWatch = new Stopwatch();
    }

    public override void OnActionExecuting(ActionExecutingContext context)
    {
        _stopWatch.Start();
    }

    public override void OnActionExecuted(ActionExecutedContext context)
    {
        _stopWatch.Stop();

        var controllerName = context.Controller.GetType().Name;
        var controllerActionName = context.ActionDescriptor.DisplayName;
        
        _logger.LogTrace($"Action '{controllerActionName}' of controller {controllerName} executed in " + 
            $"{_stopWatch.ElapsedMilliseconds} ms.");
    }
}
</code></pre>

<p>This implementation is a nice example of diagnostic logging. The action filter measures the execution time of a 
controller method and logs the result. Notice that we‚Äôre injecting the <em>ILogger</em> interface directly into the constructor.
By registering the <em>PerformanceTracing</em> action filter using the <em>ServiceFilter</em> attribute, we ensure that an instance 
of <em>ILogger</em> gets resolved and properly injected. We didn‚Äôt provide any tests for this implementation.</p>

<p>I think it‚Äôs useful to consider support logging and diagnostic logging as two separate concepts, even though they quite 
often use the same mechanisms under the hood.</p>


				<p>
						<em>
							If you and your team want to learn more about how to <u>write maintainable unit tests</u>
							and <u>get the most out of TDD practices</u>, make sure to have look at our
							<a href="https://principal-it.eu/training.html">trainings and workshops</a> or checkout
							the <a href="https://principal-it.eu/books.html">books section</a>. Feel free to reach
							out at <span>info@principal-it.be</span>.
						</em>
					</p>

				

				

				
			</div></div>]]>
            </description>
            <link>https://principal-it.eu/2020/11/unit-tests-for-logging/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057372</guid>
            <pubDate>Wed, 11 Nov 2020 11:06:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revolutionize your support with Chat Bot]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057330">thread link</a>) | @eugen_2pay
<br/>
November 11, 2020 | https://tap2pay.me/revolutionize-support-chat-bot/ | <a href="https://web.archive.org/web/*/https://tap2pay.me/revolutionize-support-chat-bot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p>Robots are taking over our daily routine in every aspect of our life: from paying bank bills to cleaning the house. It does not mean that within a year you will be leaving in a Matrix, but modern robots will for sure simplify your life in many ways.</p>

<p>Automation is everything. Chat support on smartphone saves our time and energy for more important things.</p>

<p>According to a survey, <strong>over 80% of customer problems will be solved with the help of chatbots.</strong></p>

<p>What kind of customers can really use the help of live support?</p>

<h4>Here are the Top 5 Business Areas that benefit from ChatBot support:</h4>

<p><strong>Banks</strong></p>
<p>‚Ä¢ prompting nearest branch locations, self-service terminals<br>
‚Ä¢ sending information about available credit programs and its terms<br>
‚Ä¢ helping to choose the necessary type of deposit<br>
‚Ä¢ accepting the request for required documents</p>

<p><strong>Events selling agencies</strong></p>
<p>‚Ä¢ registering of new clients<br>
‚Ä¢ answering basic queries about cost, time, and location<br>
‚Ä¢ performing support functions<br>
‚Ä¢ booking tickets online</p>

<p><strong>Online Stores</strong></p>
<p>‚Ä¢ registering new customers<br>
‚Ä¢ processing order placements<br>
‚Ä¢ processing payments for products<br>
‚Ä¢ conducting marketing surveys</p>

<p><strong>Mobile operators</strong></p>
<p>‚Ä¢ onboarding of new users<br>
‚Ä¢ processing payments<br>
‚Ä¢ answering basic queries about cost, time, and location</p>

<p><iframe width="1140" height="641" src="https://www.youtube.com/embed/yCcQpyYSvks?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<p><strong>Providers of Education services</strong></p>
<p>‚Ä¢ processing payments<br>
‚Ä¢ helping to choose an educational program<br>
‚Ä¢ accepting requests for required programs</p>

<p><img src="https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture.jpg" alt="" width="700" height="393" srcset="https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture.jpg 700w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-300x168.jpg 300w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-71x40.jpg 71w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-255x143.jpg 255w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-142x80.jpg 142w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-360x202.jpg 360w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-500x281.jpg 500w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-600x337.jpg 600w" sizes="(max-width: 700px) 100vw, 700px"></p>

<p><a href="https://secure.tap2pay.me/users/signup">Tap2Pay</a> strives for excellence in every aspect of creating smooth and friendly chat support on smartphones.</p>
<p>We have developed stunning software for effortless payment processing via the most well-known social media messengers Facebook, Instagram, Telegram, WhatsApp with built-in chatbot client support.</p>

<p><iframe width="1140" height="641" src="https://www.youtube.com/embed/jJxIfNR99Do?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<p>If you need any assistance with updating your payment processing method with built-in chat support, please <a href="https://tap2pay.me/contacts/">connect with our Customer Support Team.</a></p>
	
                </div></div>]]>
            </description>
            <link>https://tap2pay.me/revolutionize-support-chat-bot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057330</guid>
            <pubDate>Wed, 11 Nov 2020 10:58:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Telegram Bot with Azure Functions and Node.js]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057328">thread link</a>) | @qpbp_user
<br/>
November 11, 2020 | http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/ | <a href="https://web.archive.org/web/*/http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><ul><li><a href="#introduction">Introduction</a></li><li><a href="#flow-review">Flow Review</a></li><li><a href="#prerequisites">Prerequisites</a></li><li><a href="#create-an-azure-function-in-visual-studio-code">Create an Azure function in Visual Studio Code</a></li><li><a href="#folder-structure">Folder structure</a></li><li><a href="#run-function-locally">Run function locally</a></li><li><a href="#implement-the-bot">Implement the bot</a></li><li><a href="#running-bot-locally">Running bot locally</a></li><li><a href="#deploy-azure-function-to-the-portal">Deploy Azure Function to the portal</a></li><li><a href="#conclusion">Conclusion</a></li></ul><h2 id="introduction">Introduction</h2><p>In this tutorial, we will create an Azure Function with a simple Telegram Bot (Echo Bot). We will test it locally and then deploy it to Azure Portal. It means our bot will work only at the moment when someone is using it. So the function will be triggered only when someone is sending a message to a bot.</p><h2 id="flow-review">Flow Review</h2><ol><li>The user sends any message to Telegram Bot</li><li>Telegram sends requests via Webhook to our Azure Function</li><li>Azure Function replies to Webhook with a copied message</li></ol><h2 id="prerequisites">Prerequisites</h2><ul><li>node.js - v10.16.2</li><li>npm - v6.14.5</li><li>telegraf - v3.38.0</li><li>ngrok - v2.3.35</li><li>Azure subscribtion</li><li>you need to install <a href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azurefunctions">Azure Functions extension</a> to Visual Studio Code</li></ul><h2 id="create-an-azure-function-in-visual-studio-code">Create an Azure function in Visual Studio Code</h2><ol><li><p>click on Azure Icon in Visual Studio Code</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.48.39-1024x885.png" alt="Azure Icon in VSC"></p></li><li><p>login under your Azure subscription</p></li><li><p>click on ‚ÄúCreate Function Icon‚Äù</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.51.16.png" alt="Create Function Icon"></p></li><li><p>you will be asked to use an existing project or create a new. Let‚Äôs create a new:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.54.40-1024x281.png" alt="Create a new project"></p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.55.13-1024x589.png" alt="Create new project folder"></p></li><li><p>select the function template. We will use <strong>HTTP trigger</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.55.36-1024x607.png" alt="Choose a Function Template"></p></li><li><p>provide a function name and select Enter:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.16-1024x213.png" alt="Enter the name of the function"></p></li><li><p>please provide a <strong>Function</strong> key for a <strong>Function authorization</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.27-1024x280.png" alt="Function Authorization level"></p></li><li><p>penultimate step. Select how you would like to open a project. We will use the current window:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.39-1024x291.png" alt="How to open a function project in Visual Studio Code"></p></li><li><p>you will be redirected to the <strong>default HTTP trigger function with Javascript code</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.57.02-1024x618.png" alt="The default function Code"></p></li><li><p>now this function will appear in Azure Functions section:</p></li></ol><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-11.23.30-1024x340.png" alt="Newly created function"></p><h2 id="folder-structure">Folder structure</h2><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-11.29.34-300x256.png" alt="Function Folder Structure"></p><ul><li><strong>package.json</strong> - metadata relevant to the Node.js project</li><li><strong>proxies.json</strong> - you can modify requests and responses from function</li><li><strong>host.json</strong> - metadata file relevant to the Azure project. It‚Äôs a global configuration for all functions in an application</li><li><strong>azure-bot-cloud-function</strong> - it‚Äôs our function folder. Each function has a separate folder with code file (.js in our case) and function.json. Function.json it‚Äôs a <a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-expressions-patterns">binding configuration file</a>.</li></ul><h2 id="run-function-locally">Run function locally</h2><ol><li><p>Select Run -&gt; Start Debugging in Visual Studio Code menu</p></li><li><p>If you have no Azure Functions Core Tools locally, you need to install them on this step. The instruction can be found in <a href="https://github.com/Azure/azure-functions-core-tools#installing">Azure repo:</a></p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-20.48.48-1024x127.png" alt="Install Azure Function Core Tools"></p></li><li><p>You should see how the NPM tasks will executing and finally get a link to the working function:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-21.08.28-1024x601.png" alt="Link to the local Azure function"></p></li><li><p>Let‚Äôs open our function in the browser:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-21.20.46-1024x274.png" alt="Azure Function is working locally"></p><p>As you see, the function responds to us with the behavior by default. Also, you can simply run the function using the <strong>func start</strong> command.</p></li></ol><h2 id="implement-the-bot">Implement the bot</h2><p>For work with Telegram API, we will use the most popular library for Node.js - <a href="https://github.com/telegraf/telegraf">Telegraf.js</a>. We need to install it in the project folder:</p><div><pre><code data-lang="bash">npm install telegraf --save
</code></pre></div><p>Please make sure the <code>package.json</code> has Telegraf after the running previous command.</p><p>Because Telegram will send webhook requests to our bot, we need to make an external HTTPS URL. For this purpose we can use <a href="https://ngrok.com/">ngrok library</a>:</p><p>If all is good, we can go to <code>function-folder&gt;/index.js</code> and create a simple Echo-bot:</p><div><pre><code data-lang="javascript"><span>const</span> <span>Telegraf</span> <span>=</span> <span>require</span>(<span>'telegraf'</span>)
<span>const</span> { <span>TELEGRAM_BOT_TOKEN</span>, <span>WEBHOOK_ADDRESS</span> } <span>=</span> <span>process</span>.<span>env</span>

<span>const</span> <span>bot</span> <span>=</span> <span>new</span> <span>Telegraf</span>(<span>TELEGRAM_BOT_TOKEN</span>, {<span>telegram</span><span>:</span> { <span>webhookReply</span><span>:</span> <span>true</span> }})

<span>bot</span>.<span>telegram</span>.<span>setWebhook</span>(<span>WEBHOOK_ADDRESS</span>)
<span>bot</span>.<span>on</span>(<span>'message'</span>, (<span>ctx</span>) =&gt; <span>ctx</span>.<span>telegram</span>.<span>sendCopy</span>(<span>ctx</span>.<span>chat</span>.<span>id</span>, <span>ctx</span>.<span>message</span>))

<span>module</span>.<span>exports</span> <span>=</span> <span>async</span> <span>function</span> (<span>context</span>, <span>req</span>) {
	<span>return</span> <span>bot</span>.<span>handleUpdate</span>(<span>req</span>.<span>body</span>, <span>context</span>.<span>res</span>)
}
</code></pre></div><p>You can take <code>TELEGRAM_BOT_TOKEN</code> value from <a href="https://telegram.me/BotFather">BotFather bot</a>. The <code>WEBHOOK_ADDRESS</code> will contain a link to the Azure Function. We will talk about this variable later. Our bot will work in Webhook mode - it‚Äôs a more preferable way to run Telegram bot. The Telegram will automatically inform our bot about all updates. In the polling mechanism, our bot needs to frequently ask Telegram about updates, so it requires non-stop work for our bot (most cases).</p><h2 id="running-bot-locally">Running bot locally</h2><p>To run this bot locally we need to create a public address using ngrok. By default, the local Azure function is running on port <code>7071</code>. We can use the following combination in the terminal to create a public URL:</p><p>In the terminal you will get your HTTPS link for testing Webhook:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.29.42-1024x400.png" alt="HTTPS public URL using ngrok"></p><p>Copy the ngrok-created link and add the route to the function. Something similar to this:</p><div><pre><code data-lang="javascript"><span>bot</span>.<span>telegram</span>.<span>setWebhook</span>(<span>'https://&lt;random-value&gt;.ngrok.io/api/azure-bot-cloud-function'</span>)
</code></pre></div><p>Also, don‚Äôt forget to pass a real Telegram token to the Telegraf constructor:</p><div><pre><code data-lang="javascript"><span>const</span> <span>bot</span> <span>=</span> <span>new</span> <span>Telegraf</span>(<span>'some-token-value'</span>, {
	<span>telegram</span><span>:</span> { <span>webhookReply</span><span>:</span> <span>true</span> },
})
</code></pre></div><p>It‚Äôs very dirty, but for a quick test it‚Äôs OK, so please remember to remove all real keys from the code.</p><p>Then you can run a function just using the simple command:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.49.14-1024x709.png" alt="Azure Functions is running locally"></p><p>Good job! Now open your bot in Telegram and send any message. Our bot should copy it and resend to you:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.41.16.png" alt="Echo-Bot example"></p><h2 id="deploy-azure-function-to-the-portal">Deploy Azure Function to the portal</h2><p>To deploy Azure Function we just need to click on this button:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.52.40-1024x730.png" alt="Deploy Azure Function"></p><p>Then choose your resource and press ‚ÄúDeploy‚Äù. The process will be started:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.53.55-1024x406.png" alt="The process of deploying Azure Function"></p><p>After successful deployment, we need to go to Azure Portal and update <strong>WEBHOOK_ADDRESS</strong> and <strong>TELEGRAM_BOT_TOKEN</strong> variables with real values.</p><p>To get a real function URL, go to ‚ÄúFunctions‚Äù, then choose your Azure Function and press ‚ÄúGet Function Url‚Äù button:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.05.24-1024x275.png" alt="How to get Azure Function URL"></p><p>We need to copy this value and paste to Application Settings along with Telegram Token:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.59.12-1024x343.png" alt="Application Settings in Azure"></p><p>After adding our secret keys, press ‚ÄúSave‚Äù and restart our application:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.09.41-1024x424.png" alt="Restart Azure application"></p><p>That‚Äôs all. Our bot should work in the cloud and you can track all function executions in real-time:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.13.07-1024x325.png" alt="Azure Dashboard"></p><p>Each function execution means that our bot handled 1 single message.</p><h2 id="conclusion">Conclusion</h2><p>In this tutorial, we have created an Azure Function with a simple Echo-Bot for Telegram. Azure Functions its a cool way to host your bots. You will be chargeable by the simple formula - (Memory size)X(Execution time in ms)X(Executions per month) and also remember that the first 400,000 GB/s of execution and 1,000,000 executions are free. If you need to estimate your pricing costs you can use <a href="https://azure.microsoft.com/en-us/pricing/calculator/">this pricing calculator</a>.</p><p>P.s. don‚Äôt forget to delete/clean/stop all resources.</p><p><a href="https://disqus.com/">comments powered by </a></p></div></div></section></div>]]>
            </description>
            <link>http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057328</guid>
            <pubDate>Wed, 11 Nov 2020 10:57:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging the Kernel with QEMU]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057309">thread link</a>) | @__rompy
<br/>
November 11, 2020 | https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html | <a href="https://web.archive.org/web/*/https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4480419177723293408">
<p>Hi folks, in this post I'm going to walk through how to setup the linux kernel for debugging. I will also demonstrate that the setup works by setting a break-point to a test driver I wrote myself. All the code will be available from my gitlab, all the links to my gitlab will be re-posted at the end.&nbsp;</p><p>The setup I describe here re-uses some parts of the syzkaller setup, and for good reason later on in the post series I will break into a tutorial for the syzkaller tool as well. So lets get on with it.</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-u2vPJD5mvfQ/X6v9Jig2QOI/AAAAAAAAQFA/AeLKhrX1BXM8HY7pN694qJFyvWDilFojACLcBGAsYHQ/s1109/Screenshot%2Bfrom%2B2020-11-11%2B17-00-44.png" imageanchor="1"><img data-original-height="625" data-original-width="1109" height="360" src="https://1.bp.blogspot.com/-u2vPJD5mvfQ/X6v9Jig2QOI/AAAAAAAAQFA/AeLKhrX1BXM8HY7pN694qJFyvWDilFojACLcBGAsYHQ/w640-h360/Screenshot%2Bfrom%2B2020-11-11%2B17-00-44.png" width="640"></a></td></tr><tr><td>Screenshot of a successful debug session with full debug symbols for the kernel! We can even see the call to start_kernel and a frame before that as well!<br></td></tr></tbody></table><br>&nbsp;<h2>The Process</h2><p>Okay so we want to study kernel exploitation but given that the kernel isn't something totally accessible in userspace, its not as convenient to debug as userpace stuff, we need a bit of a run up before we can actually poke and prod the kernel to figure out how to write our exploits. So there's a number of important steps to how we get this done, here's what we're going to do:</p><ol><li>Build a kernel</li><li>Build an image</li><li>Launch the virtual machine&nbsp;</li><li>Attach and setup the debugger</li><li>Building, loading and debugging a test module <br></li></ol><p>We also need to be able to build our kernel because there may be build options that are important to configure in order to control exploit protection or include modules and functionality to the kernel when needed. <br></p><h2>Building a Kernel</h2><p>Okay so before we get going with launching our Qemu instances and debugging modules we need an environment. For convenience sake I'm working off of a fresh Ubuntu 18.04.5 LTS machine. I'll document the processes from fresh install to first successful kernel build.</p><p>To start we need to make sure we have everything we need to build a kernel:</p><p><span>$<b>sudo apt-get update</b></span></p><p><span>$<b>sudo apt-get upgrade </b><br></span></p><p><span>$<b>sudo apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison qemu-system-x86</b></span></p><p>Next we obviously need a kernel so lets download a brand new kernel:</p><p><span>$<b>wget https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.9.7.tar.xz</b><br>--2020-11-10 23:00:26--&nbsp; https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.9.7.tar.xz<br>Resolving cdn.kernel.org (cdn.kernel.org)... 151.101.225.176, 2a04:4e42:35::432<br>Connecting to cdn.kernel.org (cdn.kernel.org)|151.101.225.176|:443... connected.<br>HTTP request sent, awaiting response... 200 OK<br>Length: 115538096 (110M) [application/x-xz]<br>Saving to: ‚Äòlinux-5.9.7.tar.xz‚Äô<p>linux-5.9.7.tar.xz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 42%[=============&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]&nbsp; 46.79M&nbsp; 3.08MB/s&nbsp;&nbsp;&nbsp; eta 23s&nbsp;&nbsp; &nbsp;</p></span></p><p><span>... <br></span></p><p><span>$<b>tar -xf linux-5.9.7.tar.xz</b></span></p><p>We're just a couple steps from sending the final build commands, before we get to that lets make sure the kernel config is ready to rock. Because we're working on a Linux host we can simply swipe the .config for the virtual machine's Ubuntu kernel like so:</p><p><span>$<b>cp /boot/config-5.4.0-52-generic .config</b></span></p><p>We then need to select some options that make debugging and exploit dev a little easier. First thing we need is to merge some options for making the kernel easier to run in a virtual machine:</p><p><span>$<b>make kvmconfig</b></span></p><p><span>Using .config as base<br>Merging ./kernel/configs/kvm_guest.config<br>#<br># merged configuration written to .config (needs make)<br>#</span></p><p><span>...</span></p><p>Great, now we need to enable some options for debug symbols, kaslr and other awesome things. So open the <span>.config</span> somewhere in a text editor and make sure you either add or modify the file so these options are set:</p><p><span>CONFIG_KCOV=y<br>CONFIG_DEBUG_INFO=y<br>CONFIG_KASAN=y<br>CONFIG_KASAN_INLINE=y<br>CONFIG_CONFIGFS_FS=y<br>CONFIG_SECURITYFS=y </span><br><span><span># CONFIG_RANDOMIZE_BASE is not set<br></span></span></p><p>Cool now we need to make sure the config is ready to go for a build:</p><p><span>$<b>make savedefconfig</b></span></p><p><span>$<b>make -j4</b></span></p><p><span>&nbsp;...</span></p><p>Now you should grab some coffee, play a startcraft2 game because this may take a while. Okay so if your build worked you should have an object file in the following location:</p><p><span>[kernel_dir]/arch/x86_64/boot/bzImage</span>&nbsp;</p><h2>Build an image</h2><p>We're going to build an image for this kernel so we might as well plop a "image" directory in this folder:</p><p><span>$<b>mkdir [kernel_dir]/image/</b></span></p><p>Once you're kernel is build we need to start thinking about how to build a file system for this. Here I'm going to cheat and steal some tips from the syzkaller folks. We need to first download syzkaller, as follows:</p><p><span>$<b>git clone https://github.com/google/syzkaller.git</b></span></p><p><span>Cloning into 'syzkaller'...<br>remote: Enumerating objects: 1, done.<br>remote: Counting objects: 100% (1/1), done.<br>...<br></span></p><p>Move back to the kernel build and setup an image:</p><p><span>$<b>cd [kernel_dir]/image/</b></span></p><p><span>$<b>cp [syzkaller_dir]/tools/create_image.sh .</b></span></p><p>Okay so we can now create an image, all we need to do is simply invoke create_image.sh:</p><p><span>$<b>./create_image.sh&nbsp;</b></span></p><p><span>+ DIR=chroot<br>+ PREINSTALL_PKGS=openssh-server,curl,tar,gcc,libc6-dev,time,strace,sudo,less,psmisc,selinux-utils,policycoreutils,checkpolicy,selinux-policy-default,firmware-atheros,python,xrdp,g++,make,libtool,autoconf,nasm<br>+ '[' -z ']'<br>+ ADD_PACKAGE=make,sysbench,git,vim,tmux,usbutils,tcpdump</span></p><p><span>...</span><br></p><p>If that worked you should have the following in your folder:</p><p><span>$<b>ls</b>&nbsp;</span></p><p><span>chroot/</span></p><p><span>create-image.sh</span></p><p><span>stretch.id_rsa</span></p><p><span>stretch.id_rsa.pub</span></p><p><span>stretch.img</span><br></p><h2>Launch the virtual machine <br></h2><p>Now we can launch qemu with all the goodies in place:</p><p><span>qemu-system-x86_64 \<br>&nbsp; -kernel <b>../arch/boot/x86_64/bzImage</b> \<br>&nbsp; -append "console=ttyS0 root=/dev/sda earlyprintk=serial nokaslr"\<br>&nbsp; -hda <b>./stretch.img</b> \<br>&nbsp; -net user,hostfwd=tcp::10021-:22 -net nic \<br>&nbsp; -enable-kvm \<br>&nbsp; -nographic \<br>&nbsp; -m 2G \<br>&nbsp; -s \<br>&nbsp; -S \<br>&nbsp; -smp 2 \<br>&nbsp; -pidfile vm.pid \<br>&nbsp; 2&gt;&amp;1 | tee vm.log</span></p><p><span>...</span></p><p><br>The <span>-s</span> is a shorthand for <span>-gdb tcp::1234</span>, which means the gdbserver will be hosted at port 1234. -S tells qemu not to start the cpu automatically, this gives us a chance to set a breakpoint before the kernel starts executing. </p><p>So that's the image running smoothly, lets setup our debugging environment.</p><h2>Attach and setup the debugger<br></h2><p>We can then attach a gdb debugger to the qemu instance as follows. On another terminal, separate from the one running your qemu instance, start up gdb and issue the following commands:</p><p><span>$<b>cd [kernel_dir]/image/ </b><br></span></p><p><span>$<b>gdb ../vmlinux<br></b></span></p><p><span>Reading symbols from ../vmlinux...</span></p><p><span>(gdb)<b> target remote :1234<br></b></span></p><p><span>Remote debugging using :1234<br>0x000000000000fff0 in exception_stacks ()<br></span></p><p><span>(gdb) <b>c</b></span></p><p>We give the "c" command to continue execution. We can now set some of our own breakpoints. As part of the tutorial I've included a custom IOCTL driver and app code (code that invokes the ioctl from userspace), i thought this would be nifty since it shows full ability to develope and debug a driver, something crucial to hunting down modern bugs and exploit development. Anyway lets code and build our own module.</p><h2>Building, Loading and debugging a test module<br></h2><p>Okay so we need to make a test ioctl driver, so lets head over the to kernel source directory and make a new folder in the /driver/ subfolder:</p><p><span>$</span><b><span>cd&nbsp; [kernel_dir]/drivers/</span></b></p><p><span>$</span><b><span>mkdir debug_driver/</span></b></p><p><span>$</span><b><span>cd debug_driver/ <br></span></b></p><p><span>$</span><b><span>touch debug_driver.c</span></b></p><p><span>$</span><b><span>touch debug_driver_app.c</span></b></p><p><span>$</span><b><span>touch Makefile</span></b></p><p>The code for <span>debug_driver.c</span> and <span>debug_driver_app.c </span>as we well as the <span>Makefile</span> are available at this repo <a href="https://gitlab.com/k3170makan/linux-kernel-exploit-development">https://gitlab.com/k3170makan/linux-kernel-exploit-development</a>. All you need to do is download the repo and stick this in its own folder under <span>[kernel_dir]/drivers/</span>. To build the module the we need to set the "M" variable in the kernel make script:</p><p><span>$<b>cd [kernel_dir]; make -C . M=drivers/debug_driver/</b></span></p><p><span>make: Entering directory '/home/kh3m/Research/Kernel/debug_image/linux-5.5.3'<br>&nbsp; AR&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; drivers/debug_driver//built-in.a<br>&nbsp; CC [M]&nbsp; drivers/debug_driver//debug_driver.o</span></p><p><span>...</span></p><p>Now we need to get this module on our qemu host somehow, I do this the hard way, I'm sure there's all sorts of nifty ways to scp files onto the qemu host but I actually just re-create the image after copying the drivers to a folder to be baked into the start up filesystem. First we need to edit create-image.sh so it includes everything in a folder we specify, that way we can just dump stuff in the folder and run create-image.sh whenever we want those files on a live instance.</p><p>So before create-image.sh builds the disk image on line 129, stick this in there:</p><p>++ <span>sudo cp -r ./add/* $DIR/home/.</span><br></p><p>now we make a "add" folder and stick the kernel module and app code in there:</p><p><span>$<b> cd [kernel_dir]/image/</b></span></p><p><span>$ <b>mkdir add/</b></span></p><p><span>$ <b>cd add/</b></span></p><p><span>$ <b>cp ../../drivers/debug_driver/debug_driver.ko .</b><br></span></p><p><span>$ <b>cp ../../drivers/debug_driver/debug_driver_app.c .</b></span></p><p><span>$ <b>./create-image.sh</b> </span></p><p>Okay so we have a module, we have a symbol file debug_driver.ko, with stuff we need to set breakpoints. Lets load the module into the kernel, then check where it gets loaded before we actually set the breakpoint:</p><p><span>root@syzkaller:$ <b>cd /home/</b></span></p><p><span>root@syzkaller:$ insmod debug_driver.ko</span></p><p><span> [&nbsp;&nbsp; 32.792570] audit: type=1400 audit(1605058227.605:7): avc:&nbsp; denied&nbsp; { module_load } for&nbsp; pid=249 comm="insmod" path="/home/debug_driver.ko" dev="sda" ino=21253 scontext=system_u:system_r:kernel_t:s0 1<br>[&nbsp;&nbsp; 32.793766] debug_driver: loading out-of-tree module taints kernel.<br>[&nbsp;&nbsp; 32.800394] [debug_driver] loaded! <br>[&nbsp;&nbsp; 32.800826] [debug_driver] device registered successfully<br>[&nbsp;&nbsp; 32.802298] [debug_driver] device has been successfully created <b><br></b></span></p><p>Before we can debug it properly we need to know where it is loaded in kernel memory:</p><p><span>root@syzkaller:/home# <b>cat /proc/modules</b> <br>debug_driver 16384 0 - Live <b>0xffffffffa0000000</b> (O)</span></p><p>Okay lets now set our breakpoint and load the symbol file using the base address of the module:</p><div><p><span>&nbsp;(gdb) <b>add-symbol-file ../drivers/debug_driver/debug_driver.ko&nbsp; 0xffffffffa0000000</b><br>add symbol table from file "../drivers/debug_driver/debug_driver.ko" at<br>&nbsp;&nbsp; &nbsp;.text_addr = 0xffffffffa0000000<br>(y or n) <b>y</b><br>Reading symbols from ../drivers/debug_driver/debug_driver.ko...<br>(gdb) <b>break dev_read</b><br>Breakpoint 1 at <b>0xffffffffa0000010: file drivers/debug_driver//debug_driver.c</b>, line 81.<br>(gdb) c</span></p></div><p>Cool lets execute the driver program so we can trigger the code we want:</p><p><span>root@syzkaller:$ <b>gcc -o debug_driver_app.elf debug_driver_app.c<br></b></span></p><p><span><span>root@syzkaller:/home# <b>./debug_driver_app.elf </b><br>Usage: ./debug_driver_app.elf [message to write] [read length] <br></span></span></p><p><span><span>root@syzkaller:</span>$ <b>./debug_driver_app.elf "hello" 10</b></span></p><p><span>[&nbsp; 160.083320] [debug_driver] message successfully copied message =&gt; [hello]<br>[&nbsp; 160.083326] [debug_driver] buffer copied to message holder<br>[debug_driv‚Ä¶</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html">https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html</a></em></p>]]>
            </description>
            <link>https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057309</guid>
            <pubDate>Wed, 11 Nov 2020 10:53:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why electronic voting is dangerous]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057302">thread link</a>) | @ian_starts
<br/>
November 11, 2020 | https://blog.iankok.com/risk-electronic-voting | <a href="https://web.archive.org/web/*/https://blog.iankok.com/risk-electronic-voting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>With the 2020 US elections having mail in ballots,
I found myself wondering if a digital solution would be safer, more reliable and easier. As usual the answer isn't straightforward. </p>
<p>In this post I'll talk you through some possible solutions and their potential downsides.</p>
<p>I will mostly focus on Dutch elections, seeing as I can provide the best insights, and most arguments are easily
transferable to other nations.</p>
<h2>Requirements</h2>
<p>If we would develop a voting system from scratch it would need to have some features that protect our rights and make
sure the elected ruler is the one the people really wanted (questionable if that's the case with current electoral systems, but that's for another time).</p>
<ol>
<li><strong>Accuracy</strong> - are all the votes counted, do they represent the will o' the people?</li>
<li><strong>Anonymity</strong> - very difficult this one. We don't want the votes to be signed, that would leave opportunities for
coercion and intimidation. However, we do need to verify that the voter is eligible to vote (or a real person at all for that matter).</li>
<li><strong>Verifiability</strong> - we need to be able to verify if the process went correctly.</li>
<li><strong>Speed</strong> - it would be useful if votes would be counted quicker. </li>
</ol>
<p>A big problem with anonymity and verifiability is that making votes anonymous makes them difficult to verify.</p>
<p>If we had a database with all the people who voted, and their cast vote, verifiability would be tackled. However, it wouldn't be anonymous.</p>
<h2>e-voting vs i-voting</h2>
<p>When discussing electronic voting there are essentially two things at play. </p>
<ol>
<li><strong>e-voting</strong> - voting on a machine on location. Like 35 municipalities did in the Netherlands between roughly 1970 and 2007.</li>
<li><strong>i-voting</strong> - voting online using a device connected to the internet.</li>
</ol>
<p>e-voting is usually seen as the easier one. You can tackle anonymity by submitting anonymous votes, and verify it
manually with a passport check before entering the voting booth.</p>
<p>i-voting is much more difficult, because you can't have the manual check.</p>
<h2>We can protect our back accounts, so how hard can protecting votes be, right?</h2>
<p>Well, unless you're part of a secret society with unlimited wealth, chances are your bank account is not a very interesting target.</p>
<p>The scale of an election is massive. The decision made there has so much influence,
that it's an incredibly high value target.</p>
<blockquote>
<p>Most hackers aren't hardcore geeks typing away on their kali linux distro. It's usually a game of
influencing people, leaked data or a weak password. This can be summarised as the <em>human error</em>.</p>
</blockquote>
<p>It's much more likely hackers will pour resources into hacking an election than a bank account.</p>
<h2>e-voting</h2>
<p>e-voting seems like a pretty good idea. it's pretty straight forward on an abstract level: keep everything the same, only make the counting digital.</p>
<p>Too bad it's an oversimplification. It's impossible for most voters to check how the system works internally.
Even if the voters were all programmers, the source code doesn't have to be open-source. There's no rule against making the source code private. </p>
<p>So basically, it's a black box which we have to trust with one of the most important things in a democracy, and impossible for any voter to check the process.</p>
<p>This fear is backed by a <a href="https://www.bundesverfassungsgericht.de/SharedDocs/Pressemitteilungen/EN/2009/bvg09-019.html">2009 decision</a> by the Federal Constitutional Court of Germany:</p>
<blockquote>
<p>The use of voting machines which electronically record the voters‚Äô votes and electronically ascertain the election
result only meets the constitutional requirements if the essential steps of the voting and of the ascertainment of the
result can be examined reliably and without any specialist knowledge of the subject.  </p>
</blockquote>
<p>Beside these 'lack of control' fears, a lot of systems have failed miserably over the years.</p>
<p>The lack of pen-testing (inviting good-guy hackers to attack your system and check for vulnerabilities) makes it very hard to pinpoint exact failures, but here's a curated list of found problems in the US:</p>
<ul>
<li>2003 ‚Äì In Fairfax, new voting machines either didn‚Äôt work, or would lose the voter‚Äôs choice after a few moments.</li>
<li>2003 ‚Äì The State of Maryland found that the Diebold Election Systems, Inc. (now rebranded as Premier Election Solutions) AccuVote-TS system ‚Äúas implemented in policy, procedure, and technology, is at high risk of compromise.‚Äù</li>
<li>2002-2006 ‚Äì During this period, Election Systems and Software, the US‚Äôs leading voting machine manufacture was shipping some of its systems with remote access software, making them vulnerable to hacking.  </li>
<li>2006 ‚Äì Researchers from the Voting Systems Technology Assessment Advisory Board (VSTAAB) and the University of California corroborated previous research that found various Diebold voting machines can have the votes on their memory cards tampered with in a way that cannot be detected. They found a number of other security vulnerabilities as well.</li>
<li>2006 ‚Äì Princeton researchers studied the Diebold AccuVote-TS and found that it was vulnerable to a range of serious attacks. These included the possibility of malware installation which could be used to alter the vote.</li>
<li>2015 ‚Äì The Virginia Information Technologies Agency assessed the WinVote machine, which is manufactured by Advanced Voting Solutions. The agency recommended discontinuing the use of these machines after they found a range of serious flaws such as weak passwords, outdated security protocols, and insufficient system hardening.</li>
<li>2018 ‚Äì At DEFCON, J. Alex Halderman showed that Diebold AccuVote TSX voting machines could be manipulated remotely in a mock election. The same vulnerable machines were being used in 18 different states. After the event, a 50 page report was released, detailing vulnerabilities in Election Systems &amp; Software‚Äôs M650 machine and the Diebold AccuVote TSX. Together, these machines are used in as many as 23 states.</li>
<li>2018 ‚Äì Some voters in Texas allege that the Hart InterCivic‚Äôs eSlate machine was switching their vote to another candidate in the state‚Äôs election for senator.</li>
</ul>
<p>And of course a Dutch problem:</p>
<ul>
<li>2007 - It was possible to read and analyse the Electromagnetic radiation of voting machines from dozens of meters away. This caused the anonymity to be completely compromised.</li>
</ul>
<p>Side-note; this was known before an election took place. Still, parts of the election were held with the voting machines,
causing the Dutch government to be sued, losing, and going back to paper ballots.</p>
<p>So yeah, e-voting; not perfect.</p>
<h2>Hopes for e-voting</h2>
<p>More recently there has been talk of re-instating e-voting with some big adaptations. </p>
<p>The new version would basically be a computer with a printer. You can cast your vote in a voting booth with no
connectivity to the web. The voting machine would print your vote on a piece of paper, which you can then check for errors and deposit in the voting box.
These printed votes are easily read by a central computer, making counting them a lot easier and quicker.</p>
<p>Though this seems like an interesting concept, it's also doesn't have a lot of benefits over paper ballots. As the software axiom goes "keep it simple, stupid",
this doesn't really comply.</p>
<h2>i-voting</h2>
<p>I-voting, also known as remote e-voting, is casting your vote from the comfort of your own couch.
The only country which implemented such a system is Estonia. With tech giants migrating more of your life to the internet,
it seems that it's only logical to move to i-voting. Let's take a look at Estonia. How their system works,
what the vulnerabilities are, and whether we should follow suit.</p>
<h3>How it works</h3>
<p>Estonia's i-voting system builds on their ID card. This ID card is also a smart card and allows owners to digitally
sign documents and facilitates secure authentication. This already laid infrastructure makes it possible to tackle one of our demands; <strong>verifiability</strong>.</p>
<p>The i-voting system is available in an early voting period (sixth day to fourth day prior to Election Day). You can
change your vote an unlimited amount of times in that timeframe. You can also overwrite your vote by going to a
polling station, invalidating your i-vote.</p>
<p>When this new voting method was first introduced, the president Arnold R√º√ºtel challenged i-voting, claiming breach of the principle of equality of voting.
The president brought a petition against the e-voting provisions to Estonian Supreme Court but lost. R√º√ºtel was mostly
popular amongst the still Russian speaking elderly minority. About 1.9% voted online in the
<a href="https://archive.is/20120713045721/http://news.com.com/Estonia+pulls+off+nationwide+Net+voting/2100-1028_3-5898115.html">2005 election</a>.
This has increased over the years to <a href="https://rk2019.valimised.ee/en/voting-result/voting-result-main.html">43.8% in 2019</a>.</p>
<p>Estonia also open-sourced much of their source code to make the system as transparent as possible. They haven't
released everything (annoying some critics). Most notably, all the client side code is missing (more in that later).</p>
<p>One of the biggest things going for i-voting is potentially increasing voter turnout, however that
claim has been <a href="https://core.ac.uk/download/pdf/95665595.pdf">mostly invalidated.</a></p>
<h3>Vulnerabilities</h3>
<p>One peer <a href="https://estoniaevoting.org/findings/paper/">reviewed research paper</a> claims the researchers could be able to
breach the system, change votes and vote totals, and erase any evidence of their actions if they could install
malware on the election servers. Now of course, it's basically impossible to breach the security of election servers.
However, circling back to human error; what if someone is bribed, careless, or just malicious? The stakes are immense,
and these edge cases can not be ignored.</p>
<p>Another gaping security hole is the personal device of the voter. This may be the weakest link in the chain.
The system is quite robust after the ballot has been cast. However, sending that ballot is not trivial. </p>
<p>It's easy to write a fake web client (hence the hidden source code. That would make it too easy),
tricking people into thinking they've already voted. Or a piece of malware, sending a different vote than you typed.</p>
<p>The Estonian National Electoral parried these criticisms, <a href="http://vvk.ee/valimiste-korraldamine/vvk-uudised/vabariigi-valimiskomisjoni-vastulause-the-guardianis-ilmunud-artiklile">claiming</a>
they "give us no reason to suspend online balloting". The purported vulnerabilities were said to be either not feasible in reality or already accounted for in the design of the e-voting system.</p>
<p>The Estonian Information System Authority also responded. Claiming the criticisms as a political, rather ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.iankok.com/risk-electronic-voting">https://blog.iankok.com/risk-electronic-voting</a></em></p>]]>
            </description>
            <link>https://blog.iankok.com/risk-electronic-voting</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057302</guid>
            <pubDate>Wed, 11 Nov 2020 10:52:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Kernel Bug Fixing Mentorship]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057256">thread link</a>) | @janvdberg
<br/>
November 11, 2020 | https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship | <a href="https://web.archive.org/web/*/https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="634481719919165440">
                    
                        
                            <h3><a href="https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">Linux Kernel Bug Fixing Mentorship</a></h3>
                        <p>I recently finished a three months long <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2F&amp;t=NmU4Y2E5MmVjZDhjNzkzMjAwMDI3NGZkNTU4NzMxMjU1NWZhM2M3MCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605342140" target="_blank">CommunityBridge(now knows as LFX)</a> mentorship with <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.linuxfoundation.org%2F&amp;t=YWJhMGVmZDczM2I4YzdiYjFhZTk5MWJjNTE1YzcwOWY2ZGZmNmJjOCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605342140" target="_blank">The Linux Foundation</a>. I worked as a <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2Fproject%2Ff06db0d5-537e-4e0f-8ca4-0a471f95a04d&amp;t=NmIwODMxMzFhNGFlZjRhOTkyYTU3ZWFhZDE3ZWQyOTg2NzdiM2YyNCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605342140" target="_blank">Linux kernel bug fixing</a> mentee under <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwww.kroah.com%2Flog%2Fabout.html&amp;t=MWQ2ZDAwODBkNjhmNzk3NGIwYTU1MjkzYjhlZDBjYjM0NDIzNzJjZCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605342140" target="_blank">Greg Kroah-Hartman</a>. This post is about my experience and work during the mentorship program.</p><p>In
the first week of the mentorship program, I learned about debugging
techniques for the Linux kernel, how to use decode_stacktrace.sh, and
what is CONFIG_KASAN. These were all unfamiliar concepts for me, and
I found the mentors‚Äô learning resources very useful. My first task
was to write summaries of my understanding of these concepts. I found
these summaries quite helpful while fixing real bugs in the kernel
later in the mentorship.</p><p>I
was also unfamiliar with syzkaller and syzbot before becoming part of
the mentorship. So after completing the summary tasks, I spent the
next few days getting familiar with these tools. The syzbot dashboard
has hundreds of reported bugs, and I found it a little challenging to
decide which one I should pick first.</p><p>In
the meantime, my mentor, Greg KH, redirected me towards an ongoing
discussion regarding a bug produced due to a short read in
usb_control_msg() call. There existed a few ways to fix it, and after
discussing them with the mentor, I proposed a fix. The patch
generated a fair amount of discussion, and I also received comments
that the proposed fix wasn‚Äôt the right way to handle the bug. The
discussion also concluded that many other usages of
usb_control_msg(), which don‚Äôt have proper error checks, are also
prone to similar bugs. I fixed the bug by adding an adequate error
check to prevent short reads in the caller, and Greg KH wrote new
wrapper functions for usb_control_msg() to be used in such scenarios
to avoid similar bugs.</p><p>Apart
from this bug, I also explored two other bugs. I found them
fascinating because inspite of being listed on the dashboard, their
reproducers weren‚Äôt triggering any issues. I learned that a commit
had fixed one of these bugs, and it was yet to be applied to all
kernel trees. But the other bug didn‚Äôt have any reported fix, yet the
reproducer wasn‚Äôt triggering the issue. I discussed this with the
mentor and learned that the syzbot dashboard isn‚Äôt quite dynamic. So
we decided to mark the bug as ‚Äúinvalid.‚Äù On a later
discussion with other community members I learned that it was not a
good idea, and I‚Äôve ended up marking a potentially valid bug as
‚Äúinvalid‚Äù!</p><p>As
a follow-up work on the first usb_control_msg() bug, I submitted a
cleanup patch series for some of the drivers/net/usb files. One of
those patches ignored the GFP_NOIO flag used in the original code and
replaced it with the GFP_KERNEL flag used in the new wrapper API
functions. It was a blunder that resulted in a discussion to add a
new argument for memory allocation flags in the wrapper functions.
Now the wrapper functions take memory flags as arguments preventing
mentees like me from repeating such blunders.</p><p>I
continued the follow-up work by investigating drivers/usb/serial/
files. I noticed that many usages of usb_control_msg() rely on its
return value of the number of bytes read/wrote. And the new wrapper
functions don‚Äôt retain that information. So I had a discussion with
the mentor about if that information was really necessary. We
concluded that it is almost always unnecessary, and having an error
code returned is a better way.</p><p>I
ended up submitting 19 patches as part of the mentorship program. The
first one is a fix for the usb_control_msg() short read bug. The next
three are cleanup patches for usb_control_msg() wrapper functions for
drivers/net/usb files, which were rejected because of the memory flag
blunder. And the remaining 15 are usb_control_msg() cleanup patches
for drivers/usb/serial/ files. Greg KH has reviewed them, but they
are not yet merged in the mainline.</p><p>Apart
from the bug fixing, I also learned few other interesting things
about the Linux kernel and its developer community, like how we test
various changes in the kernel and why we strictly use plain text
emails. I also attended talks at the Linux Plumber‚Äôs Conference and
the Open Source Summit Europe during the mentorship, which helped me
catch up with what is happening in the kernel world, learn new
things, and make new connections.</p><p>
My
mentorship program experience has been fantastic, and I recommend it
to everyone interested in pursuing Linux kernel development and
looking for mentoring. I am heartily thankful to my mentor Greg KH,
Shuah Khan, and The Linux Foundation, for providing me with this
opportunity and a great learning experience. 
</p><p>Patches can be found on&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flore.kernel.org%2Flkml%2F%3Fq%3Dhimadrispandya&amp;t=NmUzNDlmNjlkMDFhZDBkOTdhMzQ3ZDg0ZTE1NWQ4NTMzYTE3ZWMyOSxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605342140" target="_blank"> https://lore.kernel.org/lkml/?q=himadrispandya.<br></a></p>
                    </article></div>]]>
            </description>
            <link>https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057256</guid>
            <pubDate>Wed, 11 Nov 2020 10:41:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Choosing Boring Tech]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057240">thread link</a>) | @amzans
<br/>
November 11, 2020 | https://panelbear.com/blog/boring-tech/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/boring-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Over the years I have observed that many engineers tend to attribute much of the success or failure of a company to the technical choices made. I know I‚Äôm often guilty of this too. And while it is often justified, I would argue that for the vast majority of startups out there, the choice of programming language, framework, or even database doesn‚Äôt matter that much. This seems especially true during the early stages.</p><h2>Through the engineering lens</h2><p>This perception is understandable, we as engineers tend to look at the world from a specific lens, and are often biased by what we know best. Our daily activities may include things such as debugging CI pipelines, implementing new features, pairing with colleagues, or migrating the always present legacy codebase. The environment that surrounds us makes it easy to believe that it all boils down to those things that we see and understand. It‚Äôs an illusion that makes us feel like we‚Äôre fully in control of what makes or breaks the product.</p><p>Don‚Äôt get me wrong, it can be a huge advantage for many companies to make their product 3x more efficient than competitors, or to have elegant, composable code. But you might be focusing on the wrong problems if nobody cares about the product you‚Äôre actually building, and sooner or later your business will hit this wall.</p><p>I‚Äôm not saying that software doesn‚Äôt matter. A solid foundation for your startup goes a long way. If investing in this allows you to build better features faster than your competitors, more power to you. But finding the right balance is highly dependent on what you‚Äôre trying to solve and the resources you have at hand. There‚Äôs no right or wrong way to do it, and as usual, it mainly comes down to tradeoffs.</p><p><img src="https://panelbear.com/static/img/blog/lenses.png" alt="Different lenses"></p><h2>Boring makes me happy</h2><p>I believe aiming for a healthy balance of risk vs reward when it comes to your technical choices is something to strive for. In particular, if it decreases the chances you get stuck on the wrong problems down the road.</p><p>This is why I have come to appreciate ideas such as <a href="https://mcfunley.com/choose-boring-technology">Choose Boring Technology</a>. This is often interpreted as ‚Äúpicking old technologies over newer ones‚Äù, but it doesn‚Äôt necessarily mean that. For me, this comes down to using proven technologies in which the ways it can fail are mostly known, but occasionally experimenting with different, possibly newer tools that might suit me better.</p><p>Maybe you want to gain more experience by using the latest framework or programming language, or you just want to have some fun. You do what makes you happy. But if you‚Äôre trying to make a decision to increase the odds that your product or business will succeed, it‚Äôs worth stepping back and considering your options.</p><p>For me, mainly choosing software that has been around for longer is not about it being boring or older, it‚Äôs about the fact that the ways in which it fails are better known. There are fewer unknowns for you to deal with and this maximizes your chances of actually shipping the project.</p><p>For example the other day I had an issue with my Django app, and a quick search led me to tens of answers to this problem in various forums and websites. It took me at most 10 minutes to get back on track and that was the end of this issue.</p><p>I experienced the exact opposite a few years ago with a popular, but not so battle-tested Scala library my team had been using for a while. We were probably among the first to encounter the issues we were facing, and it seemed nobody had walked down this path before. Maybe it sounds like a fun challenge or a great chance to contribute back to OSS (which I‚Äôm happy to), but once you solve it, do your customers really care about it? How many days, weeks, or even months are you willing to invest in such issues? In my case, I‚Äôd rather use that time to ship new features or improve the existing ones.</p><h2>Proven tech vs new tools</h2><p>I try to follow an 80/20 distribution when it comes to my choice of tools. This means my stack consists of about 80% software I already know well, but I do allow myself 20% of the stack to explore tech I have less experience with. The exact ratio is not what‚Äôs important here, it‚Äôs more the fact that you should lean towards using proven technologies.</p><p>This also resonates with how <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed bandits</a> work. You try to maximize your expected gain by taking advantage of what worked well in the past, while sometimes exploring new things to avoid missing out on a possible goldmine.</p><p><img src="https://panelbear.com/static/img/blog/bandits.png" alt="Balance new vs proven"></p><p>A more recent example of mine is <a href="https://panelbear.com/">Panelbear</a>, it started as an embarrassingly simple Django app with no charts, all metrics were rendered on a plain HTML table, and all data was stored on a SQLite database. Took literally a weekend to get it up and running including manually deploying to a $5/mo VM. Low risk and high reward for my needs at the time.</p><p>Fast forward and as I added more features and began handling more page views for various websites, I started to notice that the codebase could use some refactoring. It also became increasingly repetitive to do things like deploying to new instances, issuing SSL certs, and keeping the DNS records up to date in case the IP address of my instances changed.</p><p>As a second iteration, I upgraded to a docker-compose setup plus lots of glue code. But soon enough I found myself reinventing what other tools already do well. There are multiple ways to solve each of these pain points, but in my case, it came down to using a tool I am very familiar with from my full-time job: Kubernetes.</p><p>Yes, I am well aware Kubernetes is an absolute overkill for a lot of projects out there, and I could have gotten away with a more traditional solution. But it allowed me to simplify the operational aspects tremendously, and I feel comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. That‚Äôs why I wouldn‚Äôt bindly recommend it to everyone. Do what you know best.
As an added benefit, it also made it trivial when I migrated from DigitalOcean to Linode, and most recently to AWS (each migration took mostly an evening of changing my Terraform files and deploying them - I‚Äôm being serious). But that‚Äôs for another post.</p><p>Another case in which it paid off once again, was when I wanted to experiment with using Clickhouse for data ingestion and the aggregation queries. It took me less than 10 minutes to write a basic deployment manifest and have it up and running. This included automated SSL certs, in-cluster service discovery, and unified logging/monitoring out of the box. It was a huge win since it allowed me to try things out faster than before.</p><p>Even better, I can deploy any container and operate it the exact same way as I deploy anything else on my cluster. Need more volume storage with zero downtime? It‚Äôs a simple manifest change, commit and deploy. Same thing when I needed Redis for caching, I was up and running in minutes, without increasing my costs or adding operational complexity.</p><h2>Focus on shipping</h2><p>My point is, I moved into these technologies as the pain with the previous solution was higher than dealing with the new tech. But more importantly, it helped me ship features even faster to my customers while reducing the operational overhead for me.</p><p>If I had started with the more advanced setup from day one, I might have lost all motivation before I would have had the first version of Panelbear. The key is to solve the problems that are getting between you and your goals, not potential issues you believe one day will be yours.</p><p>Hope you enjoyed this blog post. I plan on writing more about Panelbear‚Äôs tech stack, and lessons learned along the way. So stay tuned!</p></div></div></div>]]>
            </description>
            <link>https://panelbear.com/blog/boring-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057240</guid>
            <pubDate>Wed, 11 Nov 2020 10:37:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Option Hacking the Tektronix TDS 420A]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25057162">thread link</a>) | @segfaultbuserr
<br/>
November 11, 2020 | https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html | <a href="https://web.archive.org/web/*/https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Previous installments in this series: <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html">In the Lab - Tektronix TDS 420A Oscilloscope</a>, 
 <a href="https://tomverbeure.github.io/2020/06/27/Tektronix-TDS420A-Remote-Control-over-GPIB.html">Tektronix TDS 420A Remote Control over GPIB</a>, 
 <a href="https://tomverbeure.github.io/2020/07/02/Extracting-the-Tektronix-TDS420A-Firmware.html">Extracting the Tektronix TDS 420A Firmware</a>, 
 <a href="https://tomverbeure.github.io/2020/07/03/TDS420A-Serial-Debug-Console-Symbol-Table-Ghidra.html">A Tektronix TDS 420A, a Serial Debug Console, a Symbol Table, and Ghidra</a></em></p>

<ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#how-a-tds400-oscilloscope-manages-hardware-features" id="markdown-toc-how-a-tds400-oscilloscope-manages-hardware-features">How a TDS400 Oscilloscope Manages Hardware Features</a></li>
  <li><a href="#the-key-to-enabling-option-05---video-triggering" id="markdown-toc-the-key-to-enabling-option-05---video-triggering">The Key to Enabling Option 05 - Video Triggering</a></li>
  <li><a href="#the-key-to-enabling-option-2f---advanced-dsp-math" id="markdown-toc-the-key-to-enabling-option-2f---advanced-dsp-math">The Key to Enabling Option 2F - Advanced DSP Math</a></li>
  <li><a href="#options-05-and-2f-enabled" id="markdown-toc-options-05-and-2f-enabled">Options 05 and 2F Enabled!</a></li>
  <li><a href="#option-1m---120k-sample-points---a-different-story" id="markdown-toc-option-1m---120k-sample-points---a-different-story">Option 1M - 120K Sample Points - A Different Story</a></li>
  <li><a href="#in-search-of-the-missing-memory" id="markdown-toc-in-search-of-the-missing-memory">In Search of the Missing Memory</a></li>
  <li><a href="#success-at-last" id="markdown-toc-success-at-last">Success at Last!</a></li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>



<p>I wrote <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html#the-tektronix-tds-420a-in-brief">earlier</a>
about the optional features of TDS 400 series of oscilloscopes:</p>

<ul>
  <li>Option 05: Video Trigger</li>
  <li>Option 13: RS-232/Centronics Hardcopy Interface</li>
  <li>Option 1F: File System/Floppy</li>
  <li>Option 2F: Advanced DSP Math</li>
  <li>Option 1M: 120k waveform sample points</li>
</ul>

<p>Most scopes, including mine, come with options 13 and 1F, but the remaining ones are less common.</p>

<p>The video triggering and advanced DSP math options are pure firmware functions, but even 
the 120k sample points option seemed like something that could be enabled with a software hack, since
the signal acquisition board has the 512KB of RAM available to store the data.</p>

<p>Here, I‚Äôll describe how the TDS 400 series manages option enablement, and
how you can hack the scope into getting them to work.</p>



<p>Using Ghidra and the debug console, I figured out how the scope manages hardware
features: it has a function called <code>hwAccountantQuery</code> that has a single
parameter which I‚Äôll call the ‚Äòfeature ID‚Äô.</p>

<p><code>hwAccountantQuery</code> will return an integer value for that feature ID. These values
can be boolean in nature (‚ÄúIs a certain feature present or not‚Äù) or can be the
amount of DSP memory etc.</p>

<p>Here‚Äôs a very non-exhaustive list of codes that I‚Äôve been able to identify:</p>

<div><div><pre><code>0x20d: number of scope channels
0x20f: size of acquisition RAM
0x216: ProbeD2MemSize
0x248: CPU clock period
0x255: InstrumentNameStringPtr
0x271: hwProbeSpecialDiagModeActive
0x2a0: hwProbeSpecialDiagLoopCount
0x2a1: hwProbeSpecialDaigSeqId
0x2b8: 30000 points -&gt; value when 1M option is not possible
0x2bf: TDS420A
0x2d2: RS232 Debug uart present
0x317: MathPak      -&gt; this is the advanced DSP math function
0x461: Floppy drive present
0x537: flashRomDateStringPtr
0x54c: TDS410A
0x560: TDS430A
0x700: hwProbeTvTrigPresent
</code></pre></div></div>

<p><code>hwAccountantQuery</code> calls <code>hwAccountantGetValue</code>. The first part of that function looks liks this:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwAccountantGetValue.png" alt="hwAccountantGetValue"></p>

<p>It‚Äôs a large <code>if-then-else</code> or <code>case</code> statement that calls a dedicated function for a particular
feature ID.</p>



<p>Did you see <code>_hwProbeTvTrigPresent()</code>? That‚Äôs the function that checks
if the video triggering feature should be enabled:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTvTrigPresent.png" alt="hwProbeTvTrigPresent"></p>

<p>And there we have it! To enable ‚ÄúOption 05 - Video Triggering‚Äù, all you need to do
is store a non-zero value in non-volatile RAM location 7!</p>

<p><em>This is not a shocking new discovery: plenty of online sources already mentioned this,
but it‚Äôs great to confirm it from first principles, by going to the source.</em></p>



<p>Internally, the Advanced Math DSP is called ‚ÄúMathPak‚Äù. Just like for video triggering, 
the <code>hwAccountGetValue</code> function issues a call to <code>hwProbeMathPakPresent()</code>:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeMathPakPresent.png" alt="hwProbeMathPakPresent"></p>

<p>Option 2F simply relies on a non-zero value in NVRAM location 9!</p>



<p>It‚Äôs now just a matter of issuing the following 2 commands on the debug console:</p>

<div><div><pre><code>libManagerWordAtPut 0x50007, 1
libManagerWordAtPut 0x50009, 1
</code></pre></div></div>

<p>My scope booted up with this image:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/options_05_and_2f_enabled.jpg" alt="Options 05 and 2F enabled"></p>

<p>Success! I‚Äôm now the proud owner of a scope that supports an entirely obsolete video triggering
mode, and a FFT math option!</p>

<p>Video Triggering Menu:
<img src="https://tomverbeure.github.io/assets/tds420a/video_triggering_features.jpg" alt="Video triggering features"></p>

<p>Live FFT of a 1kHz square wave:
<img src="https://tomverbeure.github.io/assets/tds420a/fft.jpg" alt="FFT"></p>



<p>Unfortunately, the <code>case</code> statement is only a small part of the <code>hwAccountGetValue</code> function: most
feature checking functions are performed by looping through an array of structs that
have the feature ID and a function pointer to the checking function. It‚Äôs a bit harder to figure 
out in Ghidra, but we already know that the function names to enable options start with <code>hwProbe</code>.</p>

<p>With Ghidra, we can filter on this, and that gives the <code>hwProbe1MOption</code> and the 
<code>hwProbe1MPresent</code> functions.</p>

<p><code>hwProbe1MPresent</code> looks very familiar:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MPresent.png" alt="hwProbe1MPresent"></p>

<p>Just like for the 05 and 2F options, we need to set a specific byte in the
NVRAM:</p>

<div><div><pre><code>libManagerWordAtPut 0x50006, 1
</code></pre></div></div>

<p><code>hwProbe1MOption</code> is a different story:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MOption.png" alt="hwProbe1MOption"></p>

<p>When you run <code>hwProbe1MOption</code> on the command line, the function returns a 0.</p>

<p>Feature IDs 0x216 and 0x20f are also part of the array of structs. They call the functions
<code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> respectively.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTable.png" alt="hwProbe table"></p>

<p><code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> both run a test to check the amount of RAM that 
is populated on the board.</p>

<p>When you run these query commands on the debug console, you get:</p>

<div><div><pre><code>hwAccountantQuery(0x216)    
262143
hwAccountantQuery(0x20f)    
131071
</code></pre></div></div>

<p>It‚Äôs now clear why option 1M doesn‚Äôt get enabled after changing the NVRAM value: 
feature ID 0x20f is fine (131071/0x1ffff is larger than 0x1fffe), but feature ID 0x216 is not 
(262143/0x3ffff is smaller than 0xffffe).</p>

<p>Whatever it is used for, the amount of ‚ÄúD2‚Äù memory in the scope is too small.</p>



<p>This finally gave me the crucial hint to start looking at other PCBs inside the scope and
try to find if there‚Äôs a place with empty footprints for RAM chips.</p>

<p>I call this the DSP PCB. Luckily, it‚Äôs a board that‚Äôs easy to remove from the chassis, without 
fragile flex cables or connectors.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_pcb.jpg" alt="DSP PCB"></p>

<p>Look at those 6 beautiful, unused footprints!</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/ram_footprints_closeup.jpg" alt="RAM footprints closeup"></p>

<p>The RAM chips are M5M51008 with a 100ns speed rating, made by Mitsubishi LSI.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_datasheet.jpg" alt="Memory Datasheet"></p>

<p>Surprisingly, Digikey still carries these parts: they‚Äôre now made by Rochester
Electronics, and only available in 70ns or 55ns version, but faster is better,
so that shouldn‚Äôt be a problem.</p>

<p>They‚Äôre cheap too at just $2.56 a piece.</p>

<p>The only issue is a minimum order quantity of 100 parts. $256 for a feature
on a 25 years old $190 oscilloscope is a bit too much! Luckily, the parts
are available at various Chinese chip brokers: I was able to buy them at 
<a href="https://utsource.net/">UTSource</a> for just $1.81 a piece. Even when buying 10 
of them (for redundancy), shipping was the biggest part of the cost:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_order.png" alt="Memory Order"></p>

<p><em>Once ordered, UTSource let me know that these parts were refurbished‚Ä¶</em></p>

<p>A few days later, the parts arrived at my front door, ready to be populated
on the DSP board:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_board_before_surgery.jpg" alt="DSP Board Before Surgery"></p>

<p>Note how I did not disconnect the battery that‚Äôs wired to the board: it‚Äôs used to
permanently provide power to those 4 RAMs chips on the left that are encased into 
some transparant polymer gu. Removing the battery will result in lost calibration
data (or so they say.)</p>

<p>I used a regular soldering iron instead of a hot air gun to attach the 6 RAMs:
there was enough solder on the pads and I‚Äôm most comfortable doing it that way.
Afterwards I Ohm‚Äôed out most of the pins, and I‚Äôm glad I did because
there were some open connections.</p>

<p>The end result isn‚Äôt perfect, but it‚Äôs good enough:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/rams_populated.jpg" alt="RAMs Populated"></p>



<p>With the RAM populated, it‚Äôs time to power on the scope and check the result
of the enhancement surgery!</p>

<p>The scope bootup screen looks good:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/option_1m_enabled.jpg" alt="Option 1M enabled"></p>

<p>And this formerly grayed out 12000 points menu option is now available:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/120k_points.jpg" alt="120K Points"></p>

<p>Victory at Last!</p>



<p>The TDS 420A is an old oscilloscope, and even with those 3 new options enabled, it‚Äôs
far inferior to my Siglent 2304X or even my HP 54825A (Windows 95!) loaner.</p>

<p>120K sample points is obviously better than 30K, but it still pales in comparison
to the 140M sample points of the Siglent.</p>

<p>So what then was the point of this whole exercise?</p>

<p>I got a close up view of oscilloscope internals, I learned Ghidra from scratch and
applied it on a real, non-trival project, I added RAM to a 25 year old oscilloscope 
and it worked, I spent tons of late night hours decoding firmware, and 
I had an unreasonable amount of fun doing so.</p>

<p>I even started to appreciate the Tektronix user interface a little bit!</p>

<p>It was time well spent.</p>

<p>For now, the scope will remain on my bench while I start adding Tektronix support 
in glscopeclient. That was the whole point of acquiring the scope to being with!</p>

<p>And if it turns out that it‚Äôs really too limited for my use, I can always
sell it back on eBay, this time with 3 additional features enabled.</p>



<ul>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/hacking-my-tds460a-to-have-options-1m2f/">Hacking my TDS460A to have options 1M/2F?</a></p>
  </li>
  <li>
    <p><a href="https://forum.tek.com/viewtopic.php?t=140268">TDS420 Options Possible?</a></p>
  </li>
  <li>
    <p><a href="http://videohifi17.rssing.com/chan-62314146/all_p49.html">Upgrade Tektronix: FFT analyzer</a></p>

    <p>Story about upgrading the CPU board from 8MB to 16MB on a TDS420 (not the 420A?) and then FFT in the
  NVRAM.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=iJt2O5zaLRE">Enabling FFT option in Tektronix TDS 540A oscilloscope</a></p>

    <p>Not very useful for 420A owners: enables FFT by copying NVRAM EEPROM.</p>
  </li>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/tds420-with-lost-options/msg2032465/?PHPSESSID=021nnvu02ca549sh5le7s9r8i5#msg2032465">TDS420 with lost options</a></p>

    <p>Specific comment about how to enable options on the 420A over GPIB. I wasn‚Äôt able to get this to 
  work for some reason.</p>
  </li>
  <li>
    <p><a href="http://www.ko4bb.com/getsimple/index.php?id=enable-tds754d-options">Enable TDS754D Options using GPIB</a></p>

    <p>Another one about using GPIB.</p>
  </li>
</ul>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057162</guid>
            <pubDate>Wed, 11 Nov 2020 10:22:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Tracking]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057142">thread link</a>) | @hanspagel
<br/>
November 11, 2020 | https://blog.ueber.io/post/time-tracking/ | <a href="https://web.archive.org/web/*/https://blog.ueber.io/post/time-tracking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Our whole company is based on time tracking. While we can understand the love-hate relationship many people have with it, you shouldn‚Äôt overlook the benefits. Let‚Äôs go through a few things we learned about time tracking and how we make it less scary.</p>
<h2 id="the-benefits-of-tracking-time">The benefits of tracking time</h2>
<p>First of all, we think that time is the most precious thing we all have, so that‚Äôs what we sell. Clients trustfully hire us to work with them for a certain amount of days, giving the best we can during that time. We promise to focus entirely on our client‚Äôs projects and do the thing we can do best.</p>
<p>That also means no one is paying more hours than we work, and no one is paying fewer hours than we did. If we‚Äôre pretty fast together, that‚Äôs a win for both of us. If you‚Äôre adding more and more requirements to the feature, you‚Äôll get more, also pay more in the end, and it‚Äôs also a win for both sides. That‚Äôs the fairest it can get.</p>
<p>That makes writing offers and invoices easier, too. Why should we waste time negotiating a price with you? It‚Äôs not what we are good at, and it‚Äôs nothing anybody benefits from. <a href="https://blog.ueber.io/post/fixed-budgets">Our offers have a recommended amount of days we need to work together to help you the best.</a> Our invoices are a monthly sum of tracked hours, roughly the amount in our offers. Or it‚Äôs less if we didn‚Äôt work as much as we expected, or more if there was more to do a particular month.</p>
<p>Also, that‚Äôs fully transparent for everyone. We can warn our clients upfront if we‚Äôre going to need more time and leave the decision to them.</p>
<p>Most of our invoices only include the sum of hours and a list of things achieved in that time. If someone asks, we also attach a detailed time tracking report. From our experience, clients who ask for that level of transparency have trust issues anyway, and we can‚Äôt build up trust from that alone, so there‚Äôs probably some more serious issues behind that question.</p>
<p>Most people here work from their home office, and so a lot happens without everyone knowing it, but the sum of tracked hours per project gives a good glimpse over what happens in the company. Note that there is a big assumption in it, which probably doesn‚Äôt work for every team. We assume if people spend time on a project, they move it forward. If we want to move a project forward quicker, it‚Äôs often enough <a href="https://blog.ueber.io/post/the-schedule">to schedule more time of one or two project members for those projects for the upcoming months</a>.</p>
<h2 id="without-tracking-time">Without tracking time</h2>
<p>Sure, it‚Äôs great not having to press a button before and after work. But, that can be very dangerous in many regards, especially for creative work.</p>
<p>I don‚Äôt know about you, but we forget about time when we‚Äôre in a flow state and deeply concentrated. There is no chance I could tell you if I was working one or four hours on a problem at the end of a day, or I could know if I was working 50 or 100 hours on a specific project at the end of the month.</p>
<p>Though, I like to look up how much I worked over the week on a Friday evening. A lot of hours can be a sign of a lot of uninterrupted work, which‚Äôs a good thing.</p>
<p>We even feel it protects us from doing more or less than we get paid. Both could be bad for a calm working environment, where you don‚Äôt want to do extra hours (stress!) and don‚Äôt want to slack around too much in between projects (procrastination leads to stress).</p>
<h2 id="how-we-do-it">How we do it</h2>
<p><a href="https://blog.ueber.io/post/tools">We use Toggl Track for a few years now</a>, but you can use whatever you like. It‚Äôs a service that everyone in the team has access to, has a big start/stop button, and a description field. That‚Äôs it.</p>
<p>By the way, some tools offer automatic time tracking, which checks what app you‚Äôre running for how long. If you struggle to build the habit of tracking the time, that‚Äôs probably a better start.</p>
<p>When you‚Äôre ready to work on a project, start by clicking the start button. When you‚Äôre finished, hit stop. There is no need to stop the tracking if you‚Äôre away from the keyboard for a few minutes. Only pause the timer if you‚Äôre about to take your lunch break, any other kind of long pause, or to switch to a different project (which we try to avoid).</p>
<p>For most projects, it‚Äôs enough to attach the entry to that project and roughly describe in few words what you‚Äôre doing, for example, ‚ÄúDesigning wireframes‚Äù. There is no need to get too specific here and mention single tasks or anything like that.</p>
<h2 id="what-were-tracking">What we‚Äôre tracking</h2>
<p>Our whole billing bases on time tracking, so it‚Äôs essential to track clients‚Äô work, including everything you need to advance the project. For example, when you‚Äôre designing, developing, thinking, doing research, or experiments.</p>
<p>Besides that, we also expect people to track internal projects (I‚Äôm tracking time on ‚ÄúBlog‚Äù right now), and we have a lot of them. For example, our website, <a href="https://blog.ueber.io/post/list-of-side-projects">all of our self-initiated projects</a>, a sustainability project, social engagement projects, and many more.</p>
<p><a href="https://blog.ueber.io/post/keep-learning">Every team member needs time to learn</a>, so we schedule days to do just that. We ask people to track that too. Learning doesn‚Äôt produce a tangible outcome, so the tracked time can be a great indicator if there was enough time to learn over the year.</p>
<h2 id="dont-track-that">Don‚Äôt track that</h2>
<p>We don‚Äôt track other things, like socializing, watching a video between tasks, or other smaller breaks. We all need those, especially while doing creative work.</p>
<p>Also, we don‚Äôt expect anyone to get to the amount of time in their contract. There are probably many people sitting eight hours a day in front of their screen, but no one works eight hours straight‚Äîno need to get to that sum of hours for your working day.</p>
<h2 id="common-pitfalls">Common pitfalls</h2>
<p>We don‚Äôt want to sound too optimistic here. Yes, it can be unpleasant to press the start/stop before doing the actual work. All our projects are scheduled based on days, so people only have to press start and stop a few times in an ideal week. From our experience adding descriptions can feel tedious, too. For example, as I‚Äôve already said, ‚Äúdeveloping the backend‚Äù is eloquent enough in most cases.</p>
<p>If you expect to track your whole day, that‚Äôs going to be disappointing, too. We don‚Äôt get tired to repeat it:</p>
<p>No one works eight hours straight. A day with four to six hours of tracked time has probably been a great day with plenty of uninterrupted work. We consider that a huge success already. There is no need to get to eight hours per day (or whatever your contract says).</p>
<p>Oh, and yes, we don‚Äôt confuse the tracked time with ‚Äúperformance‚Äù or take it as a metric of success for a single team member or us as a company. Tracking more time doesn‚Äôt make you or us more productive per se. We try to keep it fair for everyone. For you, for the whole team, and our clients, that‚Äôs all.</p>
<h2 id="your-experience">Your experience</h2>
<p>What‚Äôs your experience with time tracking? Is there anything that annoys you? Do you have an idea of how it can get more comfortable? <a href="https://twitter.com/hanspagel/status/1326468288201826305" target="_blank" rel="nofollow noopener noreferrer">Share it with us on Twitter!</a></p>
</section></div>]]>
            </description>
            <link>https://blog.ueber.io/post/time-tracking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057142</guid>
            <pubDate>Wed, 11 Nov 2020 10:18:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four Steps to Take After Your Unsuccessful Job Interview]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057115">thread link</a>) | @eisabai
<br/>
November 11, 2020 | https://code.likeagirl.io/four-steps-to-take-after-your-unsuccessful-job-interview-d4e5df344b1a?source=your_stories_page------------------------------------- | <a href="https://web.archive.org/web/*/https://code.likeagirl.io/four-steps-to-take-after-your-unsuccessful-job-interview-d4e5df344b1a?source=your_stories_page-------------------------------------">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="1182">What to do when you‚Äôve failed a job interview</h2><div><div><div><div><a href="https://medium.com/@eisabai?source=post_page-----d4e5df344b1a--------------------------------" rel="noopener"><div><p><img alt="Isabel Nyo" src="https://miro.medium.com/fit/c/96/96/1*BGXgVWhH-nqrX6VruxEvmA.jpeg" width="48" height="48"></p></div></a></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/12032/0*TadXdhbziKwvqTAg" width="6016" height="4016" srcset="https://miro.medium.com/max/552/0*TadXdhbziKwvqTAg 276w, https://miro.medium.com/max/1104/0*TadXdhbziKwvqTAg 552w, https://miro.medium.com/max/1280/0*TadXdhbziKwvqTAg 640w, https://miro.medium.com/max/1400/0*TadXdhbziKwvqTAg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*TadXdhbziKwvqTAg?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@benwhitephotography?utm_source=medium&amp;utm_medium=referral" rel="noopener">Ben White</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><blockquote><p id="b5c7">Dear {Name},</p><p id="03fa">We are sorry to inform you that the decision has been made not to progress with your application for the {role}. I‚Äôm sorry it isn‚Äôt better news.</p><p id="b9b8">Signed,<br>Recruiter/Hiring Manager</p></blockquote><p id="7790">We have all seen this kind of messages. Unfortunately though, it doesn‚Äôt get easier no matter how many times you have seen it.</p><p id="8f61">As someone who has been on the other side of the table many times as an interviewer and have had a good track record when it comes to nailing interviews as an interviewee, I still can‚Äôt completely escaped from such rejection messages.</p><p id="98d6">In this article, I‚Äôd like to share with you four steps that you can take to still walk away as a winner even after being rejected at an interview.</p></div></div></section><section><div><div><h2 id="f612">1. Obtain as much feedback as possible</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/10368/0*l_fDsPC7ZWbZo-RG" width="5184" height="3456" srcset="https://miro.medium.com/max/552/0*l_fDsPC7ZWbZo-RG 276w, https://miro.medium.com/max/1104/0*l_fDsPC7ZWbZo-RG 552w, https://miro.medium.com/max/1280/0*l_fDsPC7ZWbZo-RG 640w, https://miro.medium.com/max/1400/0*l_fDsPC7ZWbZo-RG 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*l_fDsPC7ZWbZo-RG?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@nshuman1291?utm_source=medium&amp;utm_medium=referral" rel="noopener">Nathaniel Shuman</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="3d09">If you don‚Äôt hear from the company a few days or week after your interview or if you receive a generic rejection email, it‚Äôs on you to try and obtain as much feedback as possible. Be polite and professional and tell them that this will help you understand what you had done well and what you could do to improve next time. As long as you were honest in your ask, most companies will get back to you with some form of feedback. You will be using this feedback to adjust your game plan and strategy as needed, which is part of step 3.</p><p id="8408">What you should avoid doing though is to argue or counter their feedback. The decision is already made. Don‚Äôt waste your time. However, in rare occasions, if incorrect assumption was made regarding your take home exercise, or live presentation interview, you can provide more information to address the feedback. But do not expect to be considered for the role again ‚Äî in other words, do not keep your hopes up.</p></div></div></section><section><div><div><h2 id="48f7">2. Give yourself time to digest and process your emotion</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/9216/0*yV4AO854GZ9Pm1u9" width="4608" height="3456" srcset="https://miro.medium.com/max/552/0*yV4AO854GZ9Pm1u9 276w, https://miro.medium.com/max/1104/0*yV4AO854GZ9Pm1u9 552w, https://miro.medium.com/max/1280/0*yV4AO854GZ9Pm1u9 640w, https://miro.medium.com/max/1400/0*yV4AO854GZ9Pm1u9 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*yV4AO854GZ9Pm1u9?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@blitzer?utm_source=medium&amp;utm_medium=referral" rel="noopener">Niklas Rh√∂se</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="925f">Being rejected and being unsuccessful at an interview is disappointing. There is no other way to put it. Even if you have got another offer from a different company or a different role, you would still want to get an offer for all the roles that you applied for. That‚Äôs human nature.</p><p id="b688">It‚Äôs completely ok to feel disappointed, upset, angry, defeated, or any other negative emotion for a while. Take the time to process your emotion. Personally for me, I go through a cycle of disappointment, sadness, anger, and then finally, acceptance. It usually takes me two hours, but every person is different, so it might just be 20 minutes for you, or 20 hours for another person. The key here is to allow yourself to feel that negative emotion instead of trying to push it aside. Once you‚Äôve felt all the emotions, you will find that you‚Äôre ready to move on and think clearly again.</p><p id="baf9">Maybe the interviewer made an error in judgement, maybe you said something that were taken on the face value, maybe your interview performance was not good enough, maybe there are more suitable candidates, it doesn‚Äôt matter what the reason is. What matter is for you to be able to move on without getting paralysed by what could have been.</p></div></div></section><section><div><div><h2 id="955e">3. Adjust your game plan and strategy if needed</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/12000/0*AvjW-1p4Xhn6LC15" width="6000" height="4000" srcset="https://miro.medium.com/max/552/0*AvjW-1p4Xhn6LC15 276w, https://miro.medium.com/max/1104/0*AvjW-1p4Xhn6LC15 552w, https://miro.medium.com/max/1280/0*AvjW-1p4Xhn6LC15 640w, https://miro.medium.com/max/1400/0*AvjW-1p4Xhn6LC15 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*AvjW-1p4Xhn6LC15?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@felix_mittermeier?utm_source=medium&amp;utm_medium=referral" rel="noopener">Felix Mittermeier</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="06dc">Based on the feedback that you receive, you can do one of three things. First, you may want to change how you present yourself and how you communicate your skills to be more aligned with what interviewers are looking for. Second, you may decide to gain additional knowledge and skills in the areas that were identified as gaps. Third, you may accept that you are not going to change your tactics but apply for different roles that are more aligned with your skills and experiences.</p><p id="fed4">To give you my personal example, one of the feedback that I receive from those who do not know me or have worked with me in the industry is that I do not have a leadership presence. The perception comes from the fact that technology is a male-dominated industry and people are used to seeing assertive leaders who value hierarchy and command and control. To add to the fact that I am female, petite and soft-spoken, it‚Äôs hard for some to accept that I am an effective leader. While it‚Äôs sad to see gender and leader stereotypes in the 21st century, I have come to accept the fact. I am not willing to put on an act during an interview and display the masculine attributes commonly associated with effective leadership, such as assertiveness and competition, just to get the job.</p><p id="0ad5">This doesn‚Äôt mean I do not apply for leadership roles nor get leadership positions. I just have to understand myself well and know how to present myself in the best possible light without losing my integrity. And if I am unsuccessful because it was still not good enough in the interviewer‚Äôs opinion, then so be it.</p></div></div></section><section><div><div><h2 id="ed95">4. Remember the golden rule</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7744/0*bzx94k8FR8OiGrQr" width="3872" height="2592" srcset="https://miro.medium.com/max/552/0*bzx94k8FR8OiGrQr 276w, https://miro.medium.com/max/1104/0*bzx94k8FR8OiGrQr 552w, https://miro.medium.com/max/1280/0*bzx94k8FR8OiGrQr 640w, https://miro.medium.com/max/1400/0*bzx94k8FR8OiGrQr 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*bzx94k8FR8OiGrQr?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@quentinreyphoto?utm_source=medium&amp;utm_medium=referral" rel="noopener">Quentin Rey</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="f2ae">What‚Äôs the golden rule, I hear you ask. Dalai Lama once said, ‚ÄúRemember that sometimes not getting what you want is a wonderful stroke of luck.‚Äù Whether the reason for rejection was because you didn‚Äôt yet have the technical skills required for the role, personal traits that were deemed necessary by the interviewers and/or company, or purely a misjudgement from the interviewer‚Äôs part (yes, interviewers are humans too and they may make wrong decision), know that your worth is not tied to the performance of an interview.</p><p id="ecf7">I truly believe that everything in this world happens for you, not to you. Every time after I was rejected for a role, I got a better offer from another company. So my advice for you is to spend your time and energy on becoming a better person every day instead of dwelling on the rejection, and trust that a superior offer is just around the corner.</p></div></div></section><section><div><div><h2 id="a25c">Take the next step forward</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/10368/0*QY53jEzOGv_1Qgl5" width="5184" height="3888" srcset="https://miro.medium.com/max/552/0*QY53jEzOGv_1Qgl5 276w, https://miro.medium.com/max/1104/0*QY53jEzOGv_1Qgl5 552w, https://miro.medium.com/max/1280/0*QY53jEzOGv_1Qgl5 640w, https://miro.medium.com/max/1400/0*QY53jEzOGv_1Qgl5 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*QY53jEzOGv_1Qgl5?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@brett_jordan?utm_source=medium&amp;utm_medium=referral" rel="noopener">Brett Jordan</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="e65d">So what you were rejected for a role. Your life isn‚Äôt over, your career isn‚Äôt over. It‚Äôs ok. The important thing is for you to pick yourself up again and take the next step forward. You win some, you lose some, but those who are the ultimate winners are those who have the courage to keep going until they get what they deserve, in this case, a role that is aligned with what you‚Äôre looking for and a company and colleagues who will appreciate you for what you bring to the table.</p><p id="c752">Good luck!</p></div></div></section></div></div>]]>
            </description>
            <link>https://code.likeagirl.io/four-steps-to-take-after-your-unsuccessful-job-interview-d4e5df344b1a?source=your_stories_page-------------------------------------</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057115</guid>
            <pubDate>Wed, 11 Nov 2020 10:12:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forming Professional Dev Team Habits]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057078">thread link</a>) | @morchen
<br/>
November 11, 2020 | https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/ | <a href="https://web.archive.org/web/*/https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-v-f94c7cca=""> <!----> <div data-v-0cf44990="" data-v-f94c7cca=""><div><p>How does your workplace cultivate an environment of team development? How do you make sure your engineers have time for creative ideas and professional development, all the while meeting sprints, deadlines and deliverables? While branded photogenic team building activities are common in many tech companies ‚Äî especially with rapidly growing teams, this strategy fails to help grow together as professionals and misses the aim in the long run.</p>
<p>For long, I‚Äôve been toying with such questions, asking myself ‚Äî how can companies keep ‚Äúthe fun bits‚Äù, but also cultivate purpose and a culture of self and team professional development. In this post you‚Äôll find the pilot we‚Äôre launching at Swimm: the main goals of such a pilot and why we believe in it, as well as the execution strategy. We will follow-up and share our experiences in future posts.</p>
<h3><strong>The Why: Delivering Code Excellence</strong></h3>
<p><strong>Professionalism</strong>. First, we want to create a culture where all of our team members learn new things, on an ongoing basis. To become professionals, we need to keep learning all the time. To stay happy and challenged at work we need access to resources, and need our managers to invest in our development.</p>
<p><strong>Innovation</strong>. Second, reviewing together new topics and brainstorming on how they can be integrated into our products will provide new ideas and make us constantly rethink our current approaches.</p>
<p>While thinking about a way to achieve these goals, I was looking for best practice, study cases and models that worked well or gloriously failed in other places in the tech industry. Specifically, I was inspired by <a href="https://medium.com/@Idan.Bassuk/a-proven-methodology-for-becoming-an-a-i-expert-32d43887cb1e">this post</a> by Idan Bassuk from <strong>Aidoc</strong>. I contacted Idan and he was very kind to answer all my questions. I learned that they‚Äôve been continuing their ‚ÄúDeep Snips‚Äù (where one of their team members learns a subject and presents it to the team) for the past 3 years, and that he still believes this method helps achieve its goals. I learned from their experience that many of their talks resulted in actual impact to their products. This gave me confidence that this method can indeed have a meaningful impact, and I was now more eager than before to put this to the test.</p>
<h3><strong>The How: Swimminars X 2 Weeks</strong></h3>
<p><strong>Swimminars.</strong> Every other week, one of our engineers will get to learn something new that they wish to dive deeper into and learn. It can be about anything at all, as long as it‚Äôs technological, and can be applied to our product(s), even if not in the foreseeable future. Then, the engineer will give a lecture, sharing their research and new knowledge with the team. After every session, we will also publish a blog post, summarising the lecture for our community or new hires to use if they wish.</p>
<p><strong>Technicalities</strong>. We plan to divide the session into two parts ‚Äî the first will be technical, an in-depth overview of the relevant subject (will be covered on our blog posts). The second part will include holding internal discussions on the possible utilisation, adoption and impacts of the topic on our product(s). Are we already relying on some of this knowledge? Can it help us tackle a current or future issue? Perhaps we need to consider implementing it now?</p>
<p>During the two weeks of the engineer‚Äôs turn, (s)he gets as much time as needed to learn the subject and prepare the lecture. This will be prioritised over other tasks, and we assume it will take between one and two days. This is a huge commitment ‚Äî with all the tasks that we have as a startup, every day is precious. Still, we decided that the impact we are hoping for is so valuable that it‚Äôs worth the price, and that we are willing to make the experiment.</p>
<h3><strong>Piloting: Managing Expectations</strong></h3>
<p><strong>Risks</strong>. Yet, as always, it‚Äôs easier said than done. Indeed this can go wrong in different ways ‚Äî time management vs efficiency, getting to a high level of interesting presentations and useful technological insight, or getting every one‚Äôs voice heard on the team in a manner that compliments them. It‚Äôs a learning on the go activity. So we‚Äôre up for a team challenge.</p>
<p><strong>Upsides</strong>. For the duration of our team pilot, every other week, the entire dev team will get to learn something new while taking turns deepening knowledge, improving writing and presentation skills and becoming experts within the team on their Swimminar topics. This team exercise will provide each engineer individually and the team as whole, positive experiences of success. We hope.</p>
<p>I will be the first to give a Swimminar ‚Äî specifically, on <strong>git internals</strong>. How it goes from there, only time will tell. We promise to report back on how this experiment is working for us. Stay tuned.</p>
<p><em>Swimm is a tool helping engineers contribute to any codebase faster and better with automatically generated hints and codebase insight.</em></p>
<p><em>Omer Rosenbaum, Swimm‚Äôs Chief Technology Officer. Cyber training expert and Founder of Checkpoint Security Academy. Author of <a href="https://data.cyber.org.il/networks/networks.pdf">Computer Networks (in Hebrew)</a>. Visit My <a href="https://www.youtube.com/watch?v=79jlgESHzKQ&amp;list=PL9lx0DXCC4BMS7dB7vsrKI5wzFyVIk2Kg">YouTube Channel</a>.</em></p>
</div></div> </section></div>]]>
            </description>
            <link>https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057078</guid>
            <pubDate>Wed, 11 Nov 2020 10:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bdshemu: Bitdefender shellcode emulator]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25057062">thread link</a>) | @mdontu
<br/>
November 11, 2020 | https://hvmi.github.io/blog/2020/11/11/bdshemu.html | <a href="https://web.archive.org/web/*/https://hvmi.github.io/blog/2020/11/11/bdshemu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="introduction">Introduction</h2>

<p>Detecting exploits is one of the major strengths of Hypervisor Memory Introspection (HVMI). The ability to monitor guest physical memory pages against different kinds of accesses, such as write or execute, allows HVMI to impose restrictions on critical memory regions: for example, stack or heap pages can be marked as being non-executable at the EPT level, so when an exploit manages to gain arbitrary code execution, the introspection logic would step in and block the execution of the shellcode.</p>

<p>In theory, intercepting execution attempts from memory regions such as the stack or the heap should be enough to prevent most of the exploits. Real life is often more complicated, and there are many cases where legit software uses techniques that may resemble on attack - Just In Time compilation (JIT) in browsers is one good example. In addition, an attacker may store its payload in other memory regions, outside the stack or the heap, so a method of discerning good code from bad code is useful.</p>

<p>We will talk in this blog post about the Bitdefender Shellcode Emulator, or <a href="https://github.com/bitdefender/bddisasm">bdshemu</a> for short. bdshemu is a library capable of emulating basic x86  instructions (in all modes - 16, 32 and 64 bit), while observing shellcode-like behavior. Legitimate code, such as JIT code, will look different compared to a traditional shellcode, so this is what bdshemu is trying to determine: whether the emulated code behaves like a shellcode or not.</p>

<h2 id="bdshemu-overview">bdshemu Overview</h2>

<p>bdshemu is a library written in C, and is part of the bddisasm project (and of course, it makes use of bddisasm for instruction decoding). The bdshemu library is built to emulate x86 code only, so it has no support for API calls. In fact, the emulation environment is highly restricted and stripped down, and there are only two memory regions available:</p>

<ul>
  <li>The page(s) containing the emulated code;</li>
  <li>The stack;</li>
</ul>

<p>Both of these memory regions are virtualized, meaning that they are in fact copies of the actual memory being emulated, so modifications made to them don‚Äôt affect the actual system state. Any access made by the emulated code outside of these two areas (which we will call the shellcode and the stack, respectively) will trigger immediate emulation termination. For example, an API call will automatically cause a branch outside the shellcode region, thus terminating emulation. However, in bdshemu, all we care about is instruction-level behavior of the code, which is enough to tell us whether the code is malicious or not.</p>

<p>While bdshemu provides the main infrastructure for detecting shellcodes inside a guest operating-system, it is worth noting that this is not the only way HVMI determines that execution of a certain page is malicious - two other important indicators are used:</p>

<ul>
  <li>The executed page is located on the stack - this is common with stack-based vulnerabilities;</li>
  <li>The stack is pivoted - when a page is first executed and the <code>RSP</code> register points outside the normal stack allocated for the thread;</li>
</ul>

<p>These two indicators are enough on their own to trigger an exploit detection. If these are not triggered, bdshemu is used to take a good look at the executed code, and decide if it should be blocked or not.</p>

<h2 id="bdshemu-architecture">bdshemu Architecture</h2>

<p>bdshemu is created as a standalone C library, and it only depends on bddisasm. Working with bdshemu is fairly simple, as just like bddisasm, it is a single-API library:</p>
<div><div><pre><code><span>SHEMU_STATUS</span>
<span>ShemuEmulate</span><span>(</span>
    <span>SHEMU_CONTEXT</span> <span>*</span><span>Context</span>
    <span>);</span>
</code></pre></div></div>

<p>The emulator expects a single <code>SHEMU_CONTEXT</code> argument, containing all the needed information in order to emulate the suspicious code. This context is split in two sections - input parameters and output parameters. The input parameters must be supplied by the caller, and they contain information such as the code to be emulated, or initial register values. The output parameters contain information such as what shellcode indicators bdshemu detected. All these fields are well documented in the source-code.</p>

<p>Initially, the context is filled in with the following main information (please note that emulation outcome may change depending on the value of the provided registers and stack):</p>

<ul>
  <li>Input registers, such as segments, general purpose registers, MMX and SSE registers; they can be left 0, if they are not known, or if they are irrelevant;</li>
  <li>Input code, which is the actual code to be emulated;</li>
  <li>Input stack, which can contain actual stack contents, or can be left 0;</li>
  <li>Environment info, such as mode (32 or 64 bit), or ring (0, 1, 2 or 3);</li>
  <li>Control parameters, such as minimum stack-string length, minimum NOP sled length or the maximum number of instructions that should be emulated;</li>
</ul>

<p>The main output parameter is the <code>Flags</code> field, which contains a list of shellcode indicators detected during the emulation. Generally, a non-zero value of this field strongly suggests that the emulate code is, in fact, a shellcode.</p>

<p>bdshemu is built as a plain, quick and simple x86 instruction emulator: since it only works with the shellcode itself and a small virtual stack, it doesn‚Äôt have to emulate any architectural specifics - interrupts or exceptions, descriptor tables, page-tables, etc. In addition, since we only deal with the shellcode and stack memory, bdshemu does not do memory access checks, since it doesn‚Äôt even allow accesses to other addresses. The only state apart from the registers that can be accessed is the shellcode itself and the stack, and both are copies of the actual memory contents - the system state is never modified during the emulation, only the provided <code>SHEMU_CONTEXT</code> is. This makes bdshemu extremely fast, simple, and lets us focus on its main purpose: detecting shellcodes.</p>

<p>As far as instruction support goes, bdshemu supports all the basic x86 instructions, such as branches, arithmetic, logic, shift, bit manipulation, multiplication/divison, stack access and data transfer instructions. In addition, it also has support for other instructions, such as some basic MMX or AVX instructions - <code>PUNPCKLBW</code> or <code>VPBROADCAST</code> are two good examples.</p>

<h2 id="bdshemu-detection-techniques">bdshemu Detection Techniques</h2>

<p>In order to determine whether an emulated piece of code behaves like a shellcode, there are several indicators bdshemu uses.</p>

<h3 id="nop-sled">NOP Sled</h3>

<p>This is the classic presentation of shellcodes; since the exact entry point of the shellcode when gaining code execution may be unknown, attackers usually prepend a long sequence of <code>NOP</code> instructions, encoding <code>0x90</code>. The parameters for the NOP-sled length can be controlled when calling the emulator, via the <code>NopThreshold</code> context field. The default value is <code>SHEMU_DEFAULT_NOP_THRESHOLD</code>, which is <code>75</code>, meaning that minimum 75% of all the emulated instruction must be <code>NOP</code>.</p>

<h3 id="rip-load">RIP Load</h3>

<p>Shellcodes are designed to work correctly no matter what address they‚Äôre loaded at. This means that the shellcode has to determine, dynamically, during runtime, the address it was loaded at, so absolute addressing can be replaced with some form of relative addressing. This is typically achieved by retrieving the value of the instruction pointer using well-known techniques:</p>

<ul>
  <li><code>CALL $+5/POP ebp</code> - executing these two instructions will result in the value of the instruction pointer being stored in the <code>ebp</code> register; data can then be accessed inside the shellcode using offsets relative to the <code>ebp</code> value;</li>
  <li><code>FNOP/FNSTENV [esp-0xc]/POP edi</code> - the first instruction is any FPU instruction (not necessarily <code>FNOP</code>), and the second instruction, <code>FNSTENV</code> saves the FPU environment on the stack; the third instruction will retrieve the <code>FPU Instruction Pointer</code> from <code>esp-0xc</code>, which is part of the FPU environment, and contains the address of the last FPU executed - in our case, <code>FNOP</code>; from there on, addressing relative to the <code>edi</code> can be used to access shellcode data;</li>
</ul>

<p>Internally, bdshemu keeps track of all the instances of the instruction pointer being saved on the stack. Later loading that instruction pointer from the stack in any way will result in triggering this detection. Due to the way bdshemu keeps track of the saved instruction pointers, it doesn‚Äôt matter when, where or how the shellcode attempts to load the RIP in a register and use it, bdshemu will always trigger a detection.</p>

<p>In 64 bit, RIP-relative addressing can be used directly, since the instruction encoding allows it. However, surprisingly, a large number of shellcodes still use a classic method of retrieving the instruction pointer (generally the <code>CALL/POP</code> technique), which is somehow weird, but it probably indicated that 32 bit shellcodes were ported to 64 bit with minimal modifications.</p>

<h3 id="write-self">Write Self</h3>

<p>Most often, shellcodes come in encoded or encrypted forms, in order to avoid certain bad characters (for example, <code>0x00</code> in a shellcode that should resemble a string may break the exploit) or to avoid detection by security technologies (for example, AV scanners). This means that during runtime, the shellcode must decode itself (usually in-place), by modifying its own contents, and then executing the plain-text code. Typical methods of decoding involve <code>XOR</code> or <code>ADD</code> based decryption algorithms.</p>

<p>Certainly, bdshemu follows this kind of behavior, and keeps track internally of each modified byte inside the shellcode. Whenever the suspected shellcode writes any portion of itself, and then it executes it, the self-write detection will be triggered.</p>

<h3 id="tib-access">TIB Access</h3>

<p>Once a shellcode has gained code execution, it needs to locate several functions inside various modules, in order to carry its actual payload (for example, downloading a file, or creating a process). On Windows, the most common way of doing this is by parsing the user-mode loader structures, in order to locate the addresses where the required modules were loaded, and then locate the needed functions inside these modules. The sequence of structures the shellcode will access is:</p>

<ol>
  <li>The Thread Environment Block (<code>TEB</code>), which is located at <code>fs:[0]</code> (32 bit thread) or <code>gs:[0]</code> (64 bit thread);</li>
  <li>The Process Environment Block (<code>PEB</code>), which is located at <code>TEB+0x30</code> (32 bit) or <code>TEB+0x60</code> (64 bit)</li></ol></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hvmi.github.io/blog/2020/11/11/bdshemu.html">https://hvmi.github.io/blog/2020/11/11/bdshemu.html</a></em></p>]]>
            </description>
            <link>https://hvmi.github.io/blog/2020/11/11/bdshemu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057062</guid>
            <pubDate>Wed, 11 Nov 2020 10:01:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Test your event-driven architecture with Microcks and AsyncAPI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057022">thread link</a>) | @derberg
<br/>
November 11, 2020 | https://www.asyncapi.com/blog/microcks-asyncapi-part1 | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/microcks-asyncapi-part1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/microcks-1.0.0-loves-asyncapi.webp" alt="Post cover image"><p>August 11th 2020 was the official announcement of <a href="https://microcks.io/blog/microcks-1.0.0-release/">Microcks 1.0.0</a> release and our first Microcks General Availability (GA) version to fully manage event-driven API through the support of <a href="https://www.asyncapi.com/">AsyncAPI</a> specification. <strong>This first post explains why we decided to start this project and provides more insights.</strong></p><p>For those who don't know <a href="https://microcks.io/">Microcks</a> yet: it is the ultimate Open source Kubernetes Native tool for Mocking and Testing all your APIs. With Microcks, you can turn your API contract, collection or SOAP UI projects into live mocks in a few seconds. For further information, please read <a href="https://microcks.io/blog/why-microcks/">"Why Microcks ?"</a>.</p><p>We are following the <a href="https://www.asyncapi.com/">AsyncAPI</a> specification initiative since day one and I clearly remember how the <a href="https://blog.hitchhq.com/introducing-the-asyncapi-specification-7feb57b460ae">first announcement back in 2017</a> resonated within our team ! We shared the same principles: Open source and community driven... and last but not least, 100% aligned with our vision that open specifications standards like <a href="https://www.openapis.org/">OpenAPI</a> is the ultimate way to move forward and perpetuate our mantra: unlock developers potential in an unpredictable and strongly innovative environment!</p><p>Since then, we have been in touch with our mutual communities and strategic users to see if we all embrace the idea of adding AsyncAPI testing and mocking support within Microcks.
Microcks community was very enthusiastic by the idea and problem this integration can solve. We have helped some users on their AsyncAPI use cases to grab valuable feedback on how to manage Microcks event-driven API integration. We learned a lot from different vertical industries, including tricky IoT &amp; Edge computing or fintech implementations.</p><p>Our communities clearly validate that it makes sense to have the same tool managing all their API whatever the type, open contract definition or design tool used. This is why, today Microcks supports open standards for contract definitions and mainstream open collaborative tools:</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/microcks-supported-standards.webp" alt="microcks-supported-standards"></p><p>It took us a year to make, which explains why Microcks 1.0.0 release is already GA and the first tool on <a href="https://www.asyncapi.com/docs/tooling/#mocking">this topic</a><undefined> <span role="img" aria-label="winking face">üòâ</span> </undefined></p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/asyncapi-tool-tweet.webp" alt="asyncapi-tool-tweet"></p><p>This is a major step forward as we are convinced that the transition to cloud-native applications will strongly embrace event-based and reactive architecture. Thus the need to speed-up and govern event-based API like any other services mocking using Microcks will be crucial and a key success factor for any modern and agile software developments.</p><p>Microcks 1.0.0 provides a solid platform for simulating event-based API using message broker technologies like <a href="https://kafka.apache.org/">Apache Kafka</a> even before the publishing component has been developed. And once developed, it is then capable to validate that all the publisher sent events will be compliant with the defined specification, automatically from a CI/CD pipeline.</p><p>To demonstrate our commitment/vision and to <a href="https://www.asyncapi.com/blog/status-update-37-20/#proposal-for-more-formal-examples">improve AsyncAPI specifications</a> on our favorite topic: testing &amp; mocking, we have launched an upstream feature request in order to provide a formal type for message examples.</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/call-to-action.webp" alt="call-to-action"></p><p>Please have a look at <a href="https://github.com/asyncapi/asyncapi/issues/329">this proposal #329</a> and share your opinion. At the moment, it is a part of <a href="https://github.com/asyncapi/asyncapi/milestone/17">AsyncAPI 2.1 milestone</a>.</p><p> <strong> In the next article, we will focus on Microcks + AsyncAPI use cases. Stay tuned.</strong></p><blockquote><p>And if you can't wait for text explanataions, do not hesitate having a look at the <a href="https://www.youtube.com/watch?v=pmRA4M-TWuE">AsyncAPI SIG Meeting #34 recording</a><undefined> for full illustrations of the capabilities. <span role="img" aria-label="winking face">üòâ</span></undefined></p></blockquote></article></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/microcks-asyncapi-part1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057022</guid>
            <pubDate>Wed, 11 Nov 2020 09:53:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keyboardio Atreus: Yeah or Meh?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056988">thread link</a>) | @liveweird
<br/>
November 11, 2020 | https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5faba45f5480d10039a1a829">
	

	<section>
		<p>I've bought another mechanical keyboard (technically - I've backed <a href="https://www.kickstarter.com/projects/keyboardio/atreus">the Kickstarter campaign</a>). Feel free to call me an addict - I don't mind. It's my 4th and all three that I already have work well until now, so I have no valid reason to complain about them. Why waste money then (as they were not cheap - we're talking about an expenditure of 130+ USD per keyboard)?</p><p>The truth is, I use more than one computer (on a daily basis). Desktop PC powered by Windows 10, my private development machine (macOS), and the one provided by the company I currently cooperate with (Ubuntu 20). That means constant switching between very different keyboards and layouts. MacBook Pro's keyboard is pure rubbish (even the refined scissor 2020 model), Lenovo Thinkpad's one is a bit better but still very far from typing experience achievable only for mechanical keyboards, my desktop keyboard is fine but freakin' huge.</p><p>That's why I've decided that what I really need is a reliable mechanical keyboard <strong>I could carry with me easily</strong> and plug anywhere I want.</p><p>Sounds easy, but there are objective obstacles. Mechanical keyboards are generally large and heavy. Both Das Keyboards I own are 100% out of the question here. I have an 88 WASD keyboard as well, but even w/o a numerical keypad, it's too big to carry in the backpack.</p><p>Atreus to the rescue.</p><p>The brand "Atreus" is not new. If you're into mechanical keyboards, you've probably heard about <a href="https://atreus.technomancy.us/">Classic Atreus</a> - as it's available since 2014. The concept was very simple - to create a mechanical keyboard that is fully optimized for natural palms position, so you have all the keys within reach w/o making any move. That also means minimizing the number of keycaps by doing some crazy optimizations (more about that later).</p><p>The keyboard I've ordered is a product of cooperation of <strong>Atreus</strong> and <strong>Keyboardio</strong> - a refreshed, minimalistic version of Classic Atreus with few slight improvements aimed to make it even more compact and apply the lessons from previous models (e.g., adjust the keys in the very center area). You can read more about it (incl. specs and design decisions) <a href="https://shop.keyboard.io/products/keyboardio-atreus">here</a>.</p><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/11/atreus_top.jpg" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/11/atreus_top.jpg 600w, https://no-kill-switch.ghost.io/content/images/2020/11/atreus_top.jpg 900w" sizes="(min-width: 720px) 720px"></figure><p>I've ordered a blank model (no symbols on the top of keycaps) with <strong>Kailh BOX White switches</strong> and the dedicated case. It's the first model with Kailh switches I've ever tried. The white ones are clicky and have very early tactile feedback. I'm not going to delay that message - the switches turned out to be <u>AWESOME</u>. The typing experience is extremely satisfying (IMHO better than Cherry MX Clear or Gamma Zulu ones). It does require some (reasonable) force, but in exchange, you get the subliminal certainty (the one that doesn't involve conscious thinking) of whether you pressed the button effectively (once) or not.</p><p>OK, good switches are important, but what about the layout? If you've used previous models of Atreus before, you won't be surprised - the changes are subtle but not revolutionary. If you had no prior experience with Atreus, it may be a real shocker.</p><p>First of all, the keyboard has only <strong>44 keycaps</strong> (yay). The space bar is of the size of any other keycap. There are three modes - black, blue, and red (officially named: default, fun, and upper). Default is ... well, default. Fun is active when you <u>hold</u> the 'Fun' button (3rd from the left in the bottom row of the right part of the keyboard) and upper is <u>switched on</u> by (pressing, you don't need to hold them) <strong>Fun</strong> &amp; <strong>Esc</strong> combo.</p><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/11/atreus.png" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/11/atreus.png 600w, https://no-kill-switch.ghost.io/content/images/2020/11/atreus.png 680w"></figure><p>Some "standard" keys are entirely missing (e.g., <strong>Caps Lock</strong>), some have very un-intuitive positions (<strong>Escape</strong>, <strong>Tab</strong>, <strong>Backspace</strong>). You can read about the layout on the official page (linked above), so I'm not going to describe all the nuances - I'd like to focus on the impressions instead: how does it work? Is it easy to get used to? Convenient? How does it work for typical development keystrokes/routines?</p><p>It ... depends.</p><p>It didn't take me much time to get used to typing texts (articles, blog posts, e-mails) - the layout is a bit skewed, but still: it's QWERTY. The most mistakes I was making were in the 3rd row (<strong>'b'</strong>, <strong>'c'</strong> and <strong>'m'</strong>). However, getting accustomed to control/function keys is an entirely different kind of story:</p><ul><li><strong>Backspace</strong>/<strong>Space</strong> tandem is very different to what you know but once you try it, it gets very intuitive</li><li><strong>Ctrl</strong> and <strong>Alt</strong> are well within reach, but they force you to change your mechanical habits - that will take time</li><li><strong>Tab</strong>'s positioning is the most surprising - it's probably the least reachable keycap on the board</li><li>Having <strong>Delete</strong> in the red (upper) mode means that you're pretty much restricted to using <strong>Backspace</strong></li><li>All kinds of parenthesis (in the blue mode) require memorization from scratch</li><li>TBH I don't use red mode at all - it's just too much of a hassle (that means no <strong>PageUp</strong>, <strong>PageDown</strong>, <strong>F1 </strong>... <strong>F12 </strong>keys - but TBH I've used them very rarely anyway)</li></ul><hr><p><em>A side-note: I don't use Vim, I've also recently gave up on Spacemacs. Last months for codecrafting I've used mainly SublimeText + TabNine (80%) and Visual Studio Code (20%).</em></p><p>After two weeks of using Atreus, it feels like I'm still <u>terribly slow</u> - quite fluent, can manage without a cheatsheet, but still - just painfully slooow. The new automations (you don't need to think about) are not (yet) there, and the old ones got rusty already (when I try to use Das Keyboard occasionally). Ahh, yeah - I've mentioned the printed cheat sheet - it comes in the box with the keyboard, it's laminated, and it's a hell of help - especially in the first few days. A decent idea - kudos for that.</p><p>To be honest, I think that those few weeks are still too little to make a proper judgment, so let's consider it an early review and revisit in few months time.</p><p>IMHO, Atreus delivers what it promises. </p><p>It's compact and lightweight indeed. The quality (of manufacturing) is flawless - sharp, raw, minimalistic, yet beautiful.</p><p>Overall, it's my 2nd favorite of all mech keyboards I've ever used (runner up only to the <a href="https://www.wasdkeyboards.com/wasd-v3-88-key-iso-custom-mechanical-keyboard.html">Cherry MX Clear 88-key WASD</a>), and that says a lot. Yes, this position has been earned mainly by the outstanding switches and the unquestionable mobility, but it's not that I classify the layout as a con. It does require time to adjust your habits, but it's hard to name even a single, irrevocably bad design decision (in terms of positioning or spacing) - with <strong>Tab</strong> positioning being the most controversial one.</p><p>Btw. if you don't like any particular key position, there's a dedicated piece of software (Chrysalis: <a href="https://github.com/keyboardio/Chrysalis">https://github.com/keyboardio/Chrysalis</a>) you can use to conveniently remap it (in the end: I didn't remap any single key).</p><p>It should be stated very clearly - IMHO, this keyboard is <strong><u>much better suited for typists</u></strong> than e.g., developers (or gamers), but even for a typist, it will take several weeks to get used to it and regain a proper pace of typing. What does it mean 'proper pace'? Is it possible to get as effective as with a standard IBM Model M layout?</p><p>Opinions vary.</p><p>Personally, I don't think so, but please keep in mind that this is not a 105-cap but 44-cap keyboard - some efficiency is intended to be sacrificed for the compactness. Consider carefully the scenarios you'd like to use it for, before, not after buying.</p>
	</section>

	
</article></div>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056988</guid>
            <pubDate>Wed, 11 Nov 2020 09:45:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmark a Decentralized Search System on 79 Past Releases]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056863">thread link</a>) | @pepperwool
<br/>
November 11, 2020 | https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/ | <a href="https://web.archive.org/web/*/https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://get.jina.ai/" target="_blank" rel="noopener">Jina</a> is designed as a decentralized system from day one. Components are modularized as microservices, which we call <a href="https://github.com/jina-ai/jina/tree/master/docs/chapters/101#peas" target="_blank" rel="noopener">Pea/Pod</a> in Jina idioms. The data passing is done via <a href="https://zeromq.org/" target="_blank" rel="noopener">ZeroMQ</a> and <a href="https://grpc.io/" target="_blank" rel="noopener">gRPC</a>. Comparing to the traditional deep learning frameworks that follow a monolith architecture, latency and overhead are something the community and we care about a lot.<a id="more"></a></p><p>From the first release <code>v0.1</code> in May 2020 to <code>0.7.7</code> today, we have released 79 versions, including 2800+ new commits with 35K lines changes from 50+ contributors. How is the indexing and querying speed now comparing to May? Most importantly, how can we even benchmark fairly over different releases?</p><video width="90%" controls="" muted="" loop="" poster="https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/2fba5081.png"><br><source src="https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/index-speed.mp4" type="video/mp4"><br>Your browser does not support the HTML5 video tag. :(<br></video><p>This post will explain our containerized benchmark environment and highlight those changes made in the last few months that significantly improve/degrade the performance.</p><div><p><strong>Jina</strong> is an easier way for enterprises and developers to build cross- &amp; multi-modal neural search systems on the cloud. You can use Jina to bootstrap a text/image/video/audio search system in minutes. Give it a try:</p><p><a href="https://get.jina.ai/" target="_blank" rel="noopener"><img src="https://img.shields.io/github/stars/jina-ai/jina?label=Star%20Jina%20on%20Github&amp;style=for-the-badge&amp;logo=github&amp;color=3aa373" alt="GitHub Repo stars"></a></p></div><h4><span id="table-of-content">Table of Content</span></h4><ul><li><a href="#containerized-benchmark">Containerized Benchmark</a><ul><li><a href="#benchmark-task">Benchmark Task</a></li><li><a href="#reproducible-experiment-via-containerization">Reproducible Experiment via Containerization</a></li></ul></li><li><a href="#quick-analysis-on-the-speed">Quick Analysis on the Speed</a><ul><li><a href="#index-speed">Index Speed</a></li><li><a href="#query-speed">Query Speed</a></li></ul></li><li><a href="#summary">Summary</a></li></ul><h2><span id="containerized-benchmark">Containerized Benchmark</span></h2><h4><span id="benchmark-task">Benchmark Task</span></h4><p>If you are a Jina user, then you must know <code>jina hello-world</code>: an one-liner that showcases the entire index and query workflows on Fashion-MNIST dataset. It indexes 60,000 images via an index flow. The vectorized data is stored into multiple shards. It then randomly samples test set as queries, ask Jina to retrieve relevant results. Below is Jina√¢‚Ç¨‚Ñ¢s retrievals, where the left-most column is query image.</p><p><img src="https://hanxiao.io/2020/10/28/Mindspore-powered-Neural-Search-in-Jina/hello-world.gif"></p><p>This one-liner demo has been shipped in every Jina releases since <code>v0.1</code>, with a consistent high-level task across versions regardless the changes of the low-level API. This is perfect for serving as our benchmark task. The code snippet below shows the sketch of the benchmark function:</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br></pre></td><td><pre><span><span><span>def</span> <span>benchmark</span><span>()</span>:</span></span><br><span>    <span>try</span>:</span><br><span>        <span>from</span> jina <span>import</span> __version__</span><br><span>        <span>from</span> jina.flow <span>import</span> Flow</span><br><span></span><br><span>        </span><br><span></span><br><span>        </span><br><span>        f = Flow.load_config(resource_filename(<span>'jina'</span>, <span>'/'</span>.join((<span>'resources'</span>, <span>'helloworld.flow.index.yml'</span>))))</span><br><span>        st = time.perf_counter()</span><br><span>        <span>with</span> f:</span><br><span>            f.index(input_numpy(load_mnist(<span>'original/index'</span>)), batch_size=<span>1024</span>)</span><br><span>        index_time = time.perf_counter() - st</span><br><span></span><br><span>        </span><br><span>        f = Flow.load_config(resource_filename(<span>'jina'</span>, <span>'/'</span>.join((<span>'resources'</span>, <span>'helloworld.flow.query.yml'</span>))))</span><br><span>        st = time.perf_counter()</span><br><span>        <span>with</span> f:</span><br><span>            f.search(input_numpy(load_mnist(<span>'original/query'</span>), size=query_size), batch_size=<span>1024</span>, top_k=<span>50</span>)</span><br><span>        query_time = time.perf_counter() - st</span><br><span></span><br><span>    <span>except</span> Exception:</span><br><span>        </span><br><span>        </span><br><span>        </span><br><span>    <span>return</span> {</span><br><span>        <span>'version'</span>: __version__,</span><br><span>        <span>'index_time'</span>: index_time,</span><br><span>        <span>'query_time'</span>: query_time,</span><br><span>        <span>'index_qps'</span>: index_size / index_time,</span><br><span>        <span>'query_qps'</span>: query_size / query_time,</span><br><span>    }</span><br></pre></td></tr></tbody></table></figure><p>Although Jina today provides many handy interfaces such as <code>Flow.index_ndarray()</code> and <code>TimeContext</code>, allowing you to write the same code more concisely; they are not necessarily available in the early versions. To maximize the compatibility, I use a very <strong>primitive style</strong> of Jina programming. I even put <code>from jina import ...</code> inside the try-except block, in case we don√¢‚Ç¨‚Ñ¢t have those interfaces (or in a different module structure) in the early version. Readers should not take it as the best practice.</p><h4><span id="reproducible-experiment-via-containerization">Reproducible Experiment via Containerization</span></h4><p>So we want to run <code>benchmark()</code> by looping over all releases. Of course no one want to <code>pip</code> install one by one and mess up the local environment. We want to conduct each experiment in a clean and immutable environment, and make sure the whole set is reproducible.</p><p>I use the Docker image tagged with <code>jinaai/jina:x.y.z</code> published on every patch release. It is a self-contained image based on <code>python:3.7.6-slim</code> with all dependencies installed. My benchmark function (<code>app.py</code>) has to be running inside these containers to get an accurate result. Here is how the <code>Dockerfile</code> of a benchmark container looks like:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></pre></td><td><pre><span><span>ARG</span> JINA_VER</span><br><span></span><br><span><span>FROM</span> jinaai/jina:$JINA_VER</span><br><span></span><br><span><span>WORKDIR</span><span> workspace/</span></span><br><span></span><br><span><span>ADD</span><span> app.py ./  </span></span><br><span></span><br><span><span>ENTRYPOINT</span><span> [<span>"python"</span>, <span>"app.py"</span>]  </span></span><br></pre></td></tr></tbody></table></figure><p>Note, <code>ARG</code> is put in front of <code>FROM</code> to make version number as a parameter, so that one can choose a specific version for benchmarking. I then wrap <code>docker build</code> and <code>docker run</code> with a simple Bash script, which lists all releases and loops over them:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></pre></td><td><pre><span>JINA_VERS=$(git ls-remote --tags https://github.com/jina-ai/jina.git <span>"refs/tags/v*^{}"</span> | cut -d<span>'/'</span> -f3 | cut -d<span>'^'</span> -f1 | cut -d<span>'v'</span> -f2 | sort -Vr)</span><br><span></span><br><span><span>for</span> VER <span>in</span> <span>$JINA_VERS</span></span><br><span><span>do</span></span><br><span>  docker build --build-arg JINA_VER=<span>$VER</span> . -t latency-tracking</span><br><span>  docker run -v $(<span>pwd</span>)/output:/workspace/output -v $(<span>pwd</span>)/original:/workspace/original latency-tracking</span><br><span><span>done</span></span><br></pre></td></tr></tbody></table></figure><p>The figure below illustrates this procedure, where the results are aggregated to <code>benchmark.json</code>:</p><p><img src="https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/container-env.png"></p><p>The source code behind the benchmark environment <a href="https://github.com/jina-ai/latency-tracking" target="_blank" rel="noopener">can be found here</a>.</p><h2><span id="quick-analysis-on-the-speed">Quick Analysis on the Speed</span></h2><p>I run the benchmark on a 6-Core i7 machine with 32GB memory, with parallelization and sharding set to 4. In the end, the earliest version I can benchmark is <code>v0.0.8</code>. That was on Apr. 23, 2020, one week before first release.</p><h4><span id="index-speed">Index Speed</span></h4><p><img src="https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/51c3bf2e.png"></p><ul><li>The index speed has increased from 2000 docs/s to around 4000 docs/s over last few months.</li><li>The <code>hello-world</code> indexing time for 60,000 docs is reduced from 32 seconds at <code>0.0.8</code> to 14 seconds at <code>0.7.7</code>.</li><li>Besides continuous refactoring, the major improvements come from:<ul><li>Introducing <code>zmqstream</code> &amp; async IO around <code>0.3</code></li><li><a href="https://hanxiao.io/2020/08/28/What-s-New-in-Jina-v0-5/#hello-world-after-refactoring">Unifying <code>Document</code> structure and <code>Chunk</code> structure into one representation around <code>0.5</code></a></li><li>Removing <code>gzip</code> compression on <code>Document</code> and <a href="https://hanxiao.io/2020/09/21/Numpy-Tricks-and-A-Strong-Baseline-for-Vector-Index/#removing-gzip-compression">using <code>memmap</code> for <code>KVIndexer</code> &amp; <code>NumpyIndexer</code> around <code>0.6</code></a></li><li>Optimizing ZeroMQ binary protocol and <a href="https://github.com/jina-ai/jina/pull/1210" target="_blank" rel="noopener">introducing LazyRequest around 0.7</a></li></ul></li></ul><h4><span id="query-speed">Query Speed</span></h4><p><img src="https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/d3c56f81.png"></p><ul><li>The query speed has increased from 20 docs/s to around 70 docs/s over last few months.</li><li>The major improvement around <code>0.4</code> is due to unifying <code>Document</code> structure and <code>Chunk</code> structure.</li><li>The major setback around <code>0.6</code> is due to the use of <code>memmap</code> for <code>KVIndexer</code> &amp; <code>NumpyIndexer</code>. The search shifts away from <strong>in-memory search</strong> to <strong>on-disk search</strong>.</li><li>The slowly degraded query speed from <code>0.4</code> to <code>0.7</code> could be due to the refactoring on <code>Executor</code> and <code>Driver</code>, from then we have made <code>Executor</code> Protobuf-agnostic and algorithm-focus. Moreover, we have decoupled many huge all-in-one <code>Driver</code> into small pieces and then use them in a chain-style. <a href="https://hanxiao.io/2020/08/28/What-s-New-in-Jina-v0-5/#new-query-language-driver"><code>QueryLangDriver</code> introduced in <code>0.5</code> is a good example</a>. Though this effort is a sensible design decision and clarifies code structures, it may add extra dispatch overheads.</li><li>Need to keep an eye on the query speed in the future releases. More comprehensive analysis on the overhead is required. Avoid unnecessary work at the query time.</li></ul><h2><span id="summary">Summary</span></h2><p>Like traveling with a time machine, it is fun to look back on what we had back in May. Interestingly, the architecture and high-level user experience are consistent enough to benchmark all history versions. Four things made this benchmark possible:</p><ul><li>The <code>hello-world</code> demo defines a high-level task that is fixed across all releases.</li><li>Along with PyPI package on each release, we publish a Docker images with dependencies included, providing an immutable √¢‚Ç¨≈ìplayback√¢‚Ç¨ÔøΩ environment.</li><li><a href="https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/" title="Jina's multi-abstraction-layer design">Jina's multi-abstraction-layer design</a> separates its high-level API from the intermediate and low-level API, allowing search developers to be agnostic on the lower-level changes.</li><li>Last but not least, <strong>high code quality</strong> and robust DevOps &amp; CICD infra from day one.</li></ul><p>If you√¢‚Ç¨‚Ñ¢d like to share some experiences and thoughts on latency issues, welcome to join <a href="https://hanxiao.io/2020/08/06/Engineering-All-Hands-in-Public/" title="our monthly Engineering All Hands via Zoom or Youtube live stream">our monthly Engineering All Hands via Zoom or Youtube live stream</a>. If you like Jina and want to join us as a full-time AI / Backend / Frontend developer, please submit your CV to <a href="https://career.jina.ai/" target="_blank" rel="noopener">our job portal</a>. Let√¢‚Ç¨‚Ñ¢s build the next neural search ecosystem together!</p></div></div>]]>
            </description>
            <link>https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056863</guid>
            <pubDate>Wed, 11 Nov 2020 09:23:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A curious case of stacks and queues]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25056603">thread link</a>) | @oecumena
<br/>
November 11, 2020 | http://www.cofault.com/2020/11/a-curious-case-of-stacks-and-queues.html | <a href="https://web.archive.org/web/*/http://www.cofault.com/2020/11/a-curious-case-of-stacks-and-queues.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When studying computing science we all learn how to convert an expression in the "normal" ("<a href="https://en.wikipedia.org/wiki/Infix_notation">infix</a>", "algebraic") notation to "<a href="https://en.wikipedia.org/wiki/Reverse_Polish_notation">reverse Polish</a>" notation. For example, an expression "<code>a*b + c*d</code>" is converted to "<code>a b * c d * +</code>". An expression in reverse Polish notation can be seen as a program for <a href="https://en.wikipedia.org/wiki/Pushdown_automaton">a stack automaton</a>:

</p><div><pre><code>PUSH A
PUSH B
MUL
PUSH C
PUSH D
MUL
ADD</code></pre></div>

<p>Where <code>PUSH</code> pushes its argument on the top of the (implicit) stack, while <code>ADD</code> and <code>MUL</code> pop 2 top elements from the stack, perform the respective operation and push the result back. 
</p><p>For reasons that will be clearer anon, let's re-write this program as
</p><div><pre><code>Container c;
c.put(A);
c.put(B);
c.put(c.get() * c.get())
c.put(C);
c.put(D);
c.put(c.get() * c.get())
c.put(c.get() + c.get())</code></pre></div>

<p>Where <code>Container</code> is the type of stacks, <code>c.put()</code> pushes the element on the top of the stack and <code>c.get()</code> pops and returns the top of the stack. <a href="https://en.wikipedia.org/wiki/LIFO">LIFO</a> discipline of stacks is so widely used (implemented natively on all modern processors, built in programming languages in the form of call-stack) that one never ask whether a different method of evaluating expressions is possible.
</p><p>Here is a problem: find a way to translate infix notation to a program for a queue automaton, that is, in a program like the one above, but where <code>Container</code> is the type of <a href="https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)">FIFO</a> <a href="https://en.wikipedia.org/wiki/Queue_(abstract_data_type)">queues</a> with <code>c.put()</code> enqueuing an element at the rear of the queue and <code>c.get()</code> dequeuing at the front. This problem was <a href="https://www.cs.utexas.edu/users/EWD/ewd08xx/EWD887.PDF">reportedly</a> solved by <a href="https://en.wikipedia.org/wiki/Jan_L._A._van_de_Snepscheut">Jan L.A. van de Snepscheut</a> sometime during spring 1984.

</p><p>While you are thinking about it, consider the following tree-traversal code (in some abstract imaginary language):
</p><div><pre><code>walk(Treenode root) {
        Container todo;
        todo.put(root);
        while (!todo.is_empty()) {
                next = todo.get();
                visit(next);
                for (child in next.children) {
                        todo.put(child);
                }
        }
}</code></pre></div>
<p>Where <code>node.children</code> is the list of node children suitable for iteration by <code>for</code> loop.
</p><p>Convince yourself that if <code>Container</code> is the type of stacks, tree-walk is depth-first. And if <code>Container</code> is the type of queues, tree-walk is breadth-first. Then, convince yourself that a depth-first walk of the parse tree of an infix expression produces the expression in Polish notation (unreversed) and its breadth-first walk produces the expression in "queue notation" (that is, the desired program for a queue automaton). Isn't it marvelous that traversing a parse tree with a stack container gives you the program for stack-based execution and traversing the same tree with a queue container gives you the program for queue-based execution?
</p><p>I feel that there is something deep behind this. <a href="https://en.wikipedia.org/wiki/Alexander_Stepanov">A. Stepanov</a> had an intuition (which cost him <a href="http://www.stlport.org/resources/StepanovUSA.html">dearly</a>) that <em>algorithms are defined on algebraic structures</em>. Elegant interconnection between queues and stacks on one hand and tree-walks and automaton programs on the other, tells us that the correspondence between algorithms and structures goes in both directions.

</p></div></div>]]>
            </description>
            <link>http://www.cofault.com/2020/11/a-curious-case-of-stacks-and-queues.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056603</guid>
            <pubDate>Wed, 11 Nov 2020 08:36:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Container Queries are coming to Chromium]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056551">thread link</a>) | @LorenzA
<br/>
November 11, 2020 | https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com | <a href="https://web.archive.org/web/*/https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div id="primary">
<main id="main">
<article id="post-25159">

<div>
<p><img loading="lazy" src="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png" alt="" width="2024" height="880" srcset="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png 2024w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-560x243.png 560w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1120x487.png 1120w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-768x334.png 768w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1536x668.png 1536w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1568x682.png 1568w" sizes="(max-width: 2024px) 100vw, 2024px" data-old-src="https://www.bram.us/wordpress/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png" data-srcset="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png 2024w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-560x243.png 560w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1120x487.png 1120w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-768x334.png 768w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1536x668.png 1536w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1568x682.png 1568w"></p>
<p>Just <a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/u1AKdrXhPGI/m/wrJb-unhAgAJ">announced</a> on the Chromium mailing list is an <a href="https://www.chromium.org/blink/launching-features">‚ÄúIntent to Prototype‚Äù</a> Container Queries, which is quite exciting news üéâ</p>
<details>
<summary>ü§î Container Queries?</summary>
<p>Container Queries allow authors to style elements according to the size of a container. This is similar to a @media query, except that it evaluates against a container instead of the viewport.</p>
</details>
<p>The experimental implementation will follow <a href="https://gist.github.com/mirisuzanne/748169312f110d6246e092945673b16e">Miriam Suzanne‚Äôs proposal</a>, which looks like this:</p>
<pre><code>main,
aside {
  contain: size; /* (1) Create an implicit "container root" or "containment context" */
}

.media-object {
  display: grid;
  gap: 1em;
}

@container (max-width: 45em) { /* (2) When the nearest `contain: size` ancestor has a max-width of 45em ‚Ä¶ */
  .media-object { /* ‚Ä¶ apply these rules onto .media-object */
    grid-template: 'img content' auto / auto 1fr;
  }
}</code></pre>
<p>Using <code>contain: size</code> <em>(1)</em> will create an implicit ‚Äúcontainer root‚Äù or ‚Äúcontainment context‚Äù on that element. Elements contained inside it can then have container queries applied onto them, by use of a new at-rule <code>@container (<em>&lt;container-media-query&gt;</em>)</code> <em>(2)</em>. The target selector and CSS rules to apply in that case are nested within the <code>@container</code> at-rule, just like we already do with other at-rules.</p>
<p>In the example above extra rules will be applied to <code>.media-object</code> whenever its nearest ancestor with size containment set ‚Äî such as <code>&lt;main&gt;</code> or <code>&lt;aside&gt;</code> ‚Äî has a <code>max-width</code> of <code>45em</code>.</p>
<p>~</p>
<p>A <a href="https://github.com/dbaron/container-queries-implementability#proposal">previous version of this proposal by L. David Baron</a> required a context selector to be set, but that has been dropped here. The <code>@container</code> rule from Miriam‚Äôs version will work in any containment context <em>(read: the nearest parent element that has <code>contain: size</code> set)</em>. The syntax might still change, but that‚Äôs irrelevant to the prototype which is to be implemented:</p>
<blockquote><p>This is not at all finalized, but the underlying problems we need to solve in Blink are (mostly) the same regardless of how the feature is accessed, so we‚Äôll for now use this proposal as the temporary syntax.</p></blockquote>
<p>~</p>
<p><a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/u1AKdrXhPGI/m/wrJb-unhAgAJ">Intent to Prototype: Container Queries ‚Üí</a><br><a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1145970">Chrome Tracking Bug ‚Üí</a></p>
<div>
<p><b>Did this help you out? Like what you see?<br>Thank me with a coffee.</b></p><p>I don't do this for profit but a small one-time donation would always put a smile on my face. Thanks!</p>
<p><a href="https://www.paypal.me/bramus/3EUR">‚òïÔ∏è Buy me a Coffee <em>(‚Ç¨3)</em></a></p>
</div>
</div>

<div>

<p>
Bramus is a Freelance Web Developer from Belgium. From the moment he discovered view-source at the age of 14 <em>(way back in 1997)</em>, he fell in love with the web and has been tinkering with it ever since <i><a href="https://www.bram.us/about">(more ‚Ä¶)</a></i> <a href="https://www.bram.us/author/bramus/" rel="author">
View more posts </a>
</p>
</div>
</article>
<nav role="navigation" aria-label="Posts">
<h2>Post navigation</h2>

</nav>

</main>
</div>
</div></div>]]>
            </description>
            <link>https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056551</guid>
            <pubDate>Wed, 11 Nov 2020 08:28:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being a minority in fancy coding land: a Windows user]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25056380">thread link</a>) | @flo_hu
<br/>
November 10, 2020 | https://blog.esciencecenter.nl/being-a-minority-in-fancy-coding-land-a-windows-user-d853d80a6ef9 | <a href="https://web.archive.org/web/*/https://blog.esciencecenter.nl/being-a-minority-in-fancy-coding-land-a-windows-user-d853d80a6ef9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="8c04">How I slowly went from my imposter-syndrome hiding to accepting what I am. A Windows user, at least most of the time. (Don‚Äôt worry, this is NOT one of those Linux vs. Windows posts!)</h2><div><div><div><div><a href="https://medium.com/@f.huber?source=post_page-----d853d80a6ef9--------------------------------" rel="noopener"><div><p><img alt="Florian Huber" src="https://miro.medium.com/fit/c/96/96/1*sv95w_DZibIhPBTosB6R2w.jpeg" width="48" height="48"></p></div></a></div></div></div></div><p id="c959">I work at the <a href="http://esciencecenter.nl/" rel="noopener">Netherlands eScience Center</a>, a wonderful organization with very nice colleagues. Hopefully nice enough to stay my colleagues after the following confession: I am a Windows user.</p><p id="a268">What‚Äôs so special about this? Most people use Windows, right? <br>Well, not in my small <em>coding bubble</em>. <br>In the world I work in (use all your clich√© imagination on nerds, hackers, computer scientists ‚Ä¶ but then remove those pictures of people wearing sun glasses indoors and desks full of pizza and caffeine-rich soft-drinks) coding from a Windows environment is often considered something between a no-go and a handicap. Breathing quickly, my fingers start to tremble as I write this, risking my career as a data scientist and machine learning practitioner. Or isn‚Äôt it all that bad?</p></div></div><div><div><h2 id="738b">How did I end up using Windows?</h2><p id="64d2"><em>(I see your shaking heads‚Ä¶ why the hell did he end up there?)</em><br>Let‚Äôs just say I have grown into it. All the way from <a href="https://en.wikipedia.org/wiki/MS-DOS" rel="noopener">MS DOS</a> through many painfully bad Windows versions and then I got so used to it that <strong>my skills to deal with it always felt better than my skills in handling the alternatives</strong>.</p><p id="4c26">In addition, I am not a software developer or computer scientist by training. For a long time I was a physicist, a scientist, an academic. And in the scientific fields where I was working, using Windows was ‚Äî believe it or not ‚Äîthe norm.</p><p id="061d">Sure, I had already installed VirtualBox on my computer to run Ubuntu. I had even done some stuff with Ubuntu, including training some machine learning models (for implementations for which the packages didn‚Äôt support Windows‚Ä¶). I knew the 10 most common shell commands and everything else I would simply look up when needed. No wonder working with Linux still feels like writing a long letter with my left hand (I am right handed): I am terribly slow and in the end it looks horrible.</p><h2 id="4cbb">But ‚Ä¶ why?</h2><p id="fb46">Ah, I see. That all sounds like lame excuses to you.<br>Well, it is not that I didn‚Äôt see all those golden merits of using Linux over Windows. Of course that‚Äôs the better system for many tasks, say setting up a server or handling access rights. And yes, it is much less wasteful in using hardware resources, it is considered less vulnerable, ‚Ä¶ and so on ‚Ä¶ , plus it is freely available without commercial interests. Still, I never wanted to pay the price of not having access to some of the high-end software that you would get on mac-OS or Windows (such as some MS office stuff or Adobe products). By the way: I am not trying to convince anybody that Windows is the best option. I am already happy if we can agree that it is<strong> <em>an</em></strong> option.</p><p id="5163">Time for another uncomfortable revelation: sometimes, being lazy simply pays off. For instance if you need to sort out a huge pile of stuff with some emotional value to you. Just put it in a box and hide it, take it out 10 years later and easily decide to dump nearly all of it. That‚Äôs a bit what I did with Linux. I survived with minimal use of VirtualBx and alike. Until recently, <em>finally!</em>, Linux became part of Windows. And that works pretty well for me. <a href="https://www.howtogeek.com/249966/how-to-install-and-use-the-linux-bash-shell-on-windows-10/" rel="noopener">See how simple it now is to run Linux from Windows 10.</a> And enjoy how easily you now can have the best of both worlds (not for nothing are more and more people arguing <a href="https://towardsdatascience.com/dual-boot-is-dead-windows-and-linux-are-now-one-27555902a128" rel="noopener">that the good old ‚Äúdual boot‚Äù is dead</a> for exactly this reason).</p></div></div><div><div><p id="617d">Enough all-united-hippie-talk. Let me share a few impressions of the actual life of an aspiring data scientist/research software engineer that happens to use Windows:</p><h2 id="5753">Starting a new job.</h2><p id="d098">I did a lot of programming as a researcher, but clearly I had never learned the proper software development basics such as testing, versioning etc. (in many academic fields those terms are often still unheard of!). No wonder I suffered a lot from imposter syndrome in the very beginning.</p><blockquote><p id="63c1"><em>I hope they won‚Äôt find out I can‚Äôt write proper code!</em></p></blockquote><p id="1c35">Naturally, that means that you might not immediately ask your colleagues for help, because that would reveal your amateur level, right?<br>But even worse, imagining you ask that colleague about how to get that Python package working and it turns out you are using Windows?</p><blockquote><p id="3038">Can you help me setting up that environment? ‚Ä¶ By the way ‚Ä¶ I use Windows for that.</p></blockquote><p id="9df6">The looks you get are suggesting that you have just asked how to import a 5GB .csv file into your Excel table (<em>*you don‚Äôt*</em>). So little surprise I did spend a fair amount of time in Forum-Land during my first months‚Ä¶</p><h2 id="e8ad">Being that Windows user in the room</h2><p id="0abd">You sit in that hands-on workshop on some fancy programming techniques, and the instructors asks:</p><blockquote><p id="6f37">Is there anybody using Windows? (chuckles)</p></blockquote><p id="a471">Or, actually worse, nobody asks. Of course the instructions are only given for Linux and mac-OS. Well, at least I can hide my Windows handicap for a little longer then‚Ä¶ but <strong>NO</strong>!, when the instructor walks around to inspect the progress of the participants she/he will of course shout out:</p><blockquote><p id="ec64">Wow ‚Ä¶ you are really using Windows for that!?</p></blockquote><p id="0f4b">Great. Now officially being tagged as <strong>the Windows user</strong> in the room. Better keep quiet and not ask any silly questions then‚Ä¶</p><h2 id="d5b7">Get used to rolled eyes ‚Äîthen secretly roll your eyes, too.</h2><p id="2553">As I grew more confident of what I was doing, the imposter syndrome started to disappear. It still occasionally comes back to say hello (for instance if people speak shell over coffee), but that‚Äôs OK.</p><p id="9f7e">In the end it‚Äôs luckily the results that matters most. I learned that you can write as good or bad code on Windows as on Linux. You can build great software on Windows that is then used by Linux people, and the other way around. Sure, for some things you better go the Linux way. But it turns out that in my projects this is less than 1% of my working time, which makes it OK to be a bit clumsy using it. And secretly (<em>don‚Äôt point at them, that‚Äôs mean!</em>), I can also enjoy those moments when another colloquium presentation doesn‚Äôt run properly because Ubuntu did not work well with the projector, or the microphone, or both.</p><h2 id="7d78">Do better than pointing at each other</h2><p id="7527">Windows is more convenient for running some very common software (e.g. MS office), Linux is more stable‚Ä¶ so go some cliches. But instead of fighting about what‚Äôs better (or hiding what feels inferior) it makes more sense to me to accept what‚Äôs there and simply go along with it. If somebody lives in a very geeky bubble it works fine to safely assume everyone runs their code on a certain operating systems and knows the in and outs of object oriented programming and containerization. But many of the more exciting projects involve people outside this bubble: researchers, users, future contributors, students. And they might as well ‚Äî lo and behold ‚Äî be using Windows (and by the way: containers are still primarily <strong>big steel boxes</strong> to most people).</p><p id="2b2a">So, even though in some IT-bubbles it can occasionally feel as if we are talking about a small unfortunate minority ‚Ä¶ in reality that‚Äôs really not true. Check out <a href="https://www.freecodecamp.org/news/stack-overflow-developer-survey-2020-programming-language-framework-salary-data/" rel="noopener">the 2020 Stack Overflow Developer Survey</a> to see that <strong>most developers actually use Windows</strong>.</p><h2 id="a2c4">What can you do to get more Windows users to adopt your package?</h2><p id="1114">Think of Windows what you want. I don‚Äôt work for Microsoft, and honestly, I don‚Äôt really care. But I assume that many coders out there working on great new software, methods, tools, tutorials, etc. actually want that people become happy users (paid by eternal gratitude). And that is a good enough reason to think about those Windows users as well.</p><ul><li id="10e8">Consider setting up your next continuous integration for your software package, so that it runs on all systems and will be used by more people.<br>For instance with <a href="https://docs.github.com/en/free-pro-team@latest/actions/guides/about-continuous-integration" rel="noopener">continuous integration using GitHub</a> actions it can be as simple as adding a <code>‚Äòwindows-latest‚Äô</code> to your matrix:<br><code>os: [‚Äòubuntu-latest‚Äô, ‚Äòmacos-latest‚Äô, ‚Äòwindows-latest‚Äô]<br></code>(small warning: adding different operating systems to such a continuous integration workflow is comparably easy, the later debugging sometimes is not. One option can be to work with <a href="https://developer.microsoft.com/en-us/windows/downloads/virtual-machines/" rel="noopener">Windows virtual machine</a>).</li><li id="906a">What about providing installation instructions for Windows users as well? Or did you just write a new tutorial? Great! But will it work for your fellow Windows users? You would be surprised how many packages and tutorials come with instructions that clearly won‚Äôt work for a Windows user. <br>Don‚Äôt know how to do that? No Problem! Just ask a Windows user to help you. Believe me, they will be very glad to assist.</li></ul><h2 id="3a14">Final symmetry</h2><p id="9879">Most of my arguments will hold when we just swap the named OS. So, obviously if you are (like me) primarily a Windows user: Think of all those Linux and mac-OS people out there. Either way, it will require learning a bit about the differences. But it will help to avoid a lot of frustration on all ends due to failing notebooks or hard to install packages.</p><h2 id="e34f">Get in touch</h2><p id="38ab">If you have comments or questions please get in touch! You can also find me on twitter: <a href="https://twitter.com/me_datapoint" rel="noopener"><strong>me_datapoint</strong></a></p></div></div></div>]]>
            </description>
            <link>https://blog.esciencecenter.nl/being-a-minority-in-fancy-coding-land-a-windows-user-d853d80a6ef9</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056380</guid>
            <pubDate>Wed, 11 Nov 2020 07:56:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Back to C# basics: Difference between ‚Äú=‚Äù and ‚Äú{ get; } =‚Äù for properties]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056344">thread link</a>) | @cincura_net
<br/>
November 10, 2020 | https://www.tabsoverspaces.com/id/233844 | <a href="https://web.archive.org/web/*/https://www.tabsoverspaces.com/id/233844">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<h3>Back to C# basics: Difference between "=&gt;" and "{ get; } =" for properties <a href="https://www.tabsoverspaces.com/id/233844" rel="bookmark nofollow" title="Permalink"><span aria-label="Permalink"></span></a></h3>
	<p>
	<span aria-label="Published"></span> 11 Nov 2020
	<span></span>
	<span aria-label="Time to read"></span> 1 mins
	<span></span>
	<span aria-label="Tags"></span> .NET
</p>
<p>I recently realized, the difference between <code>=&gt;</code> and <code>{ get; } =</code> for properties might not be as known as everybody thinks, based on code I saw multiple times.</p>
<!-- excerpt --> 
<p>Here‚Äôs an example code.</p>
<pre><code>public class C
{
	public Foo A { get; } = new Foo();
	public Foo B =&gt; new Foo();
}
</code></pre>
<p>Is it the same or is it not? The answer is, it‚Äôs not the same. The <code>A</code> property is property with <em>getter</em> only (aka read only or immutable property). When <code>C</code> instance is created a new instance of <code>Foo</code> is assigned to the property and will be returned from now on. The <code>B</code> property defines also only <em>getter</em>, but this time the <em>getter</em> contains the <code>new Foo();</code> as it‚Äôs body, aka returning new instance of <code>Foo</code> every time you access <code>B</code>.</p>
<p>Putting it into barebone C#, it would look like this.</p>
<pre><code>public class C
{
	readonly Foo _a = new Foo();
	
	public Foo A
	{
		get { return _a; }
	}

	public Foo B
	{
		get { return new Foo(); }
	}
}
</code></pre>
<p>Makes sense?</p>

</article><article>
	<p>
		<a href="https://www.tabsoverspaces.com/about"><img src="https://www.tabsoverspaces.com/assets/bio_image.png" alt="Profile Picture"></a>
		Ji≈ô√≠ ƒåinƒçura is an independent developer focusing on data and business layers, language constructs, parallelism and databases. Specifically Entity Framework, asynchronous and parallel programming, cloud and Azure. He's Microsoft Most Valuable Professional and you can read his articles, guides, tips and tricks at www.tabsoverspaces.com.
	</p>
</article></div>]]>
            </description>
            <link>https://www.tabsoverspaces.com/id/233844</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056344</guid>
            <pubDate>Wed, 11 Nov 2020 07:47:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cell Signaling Technologies ‚Äì Detailed 3D model of human cells]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25055908">thread link</a>) | @ozten
<br/>
November 10, 2020 | http://www.digizyme.com/cst_landscapes.html | <a href="https://web.archive.org/web/*/http://www.digizyme.com/cst_landscapes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="u6389-bw">
     <div id="u6389"><!-- column -->
      <div id="u6389_align_to_page">
       <!-- m_editable region-id="editable-static-tag-U6264-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p><span id="u6264">Cell Signaling Technologies</span></p>
       <!-- /m_editable -->
       <!-- m_editable region-id="editable-static-tag-U6399-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p>Molecular Landscapes</p>
       <!-- /m_editable -->
       
       
       
      </div>
     </div>
    </div></div>]]>
            </description>
            <link>http://www.digizyme.com/cst_landscapes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055908</guid>
            <pubDate>Wed, 11 Nov 2020 06:02:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dive into BPF: a list of reading material]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055866">thread link</a>) | @moks
<br/>
November 10, 2020 | https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/ | <a href="https://web.archive.org/web/*/https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<ul id="markdown-toc">
  <li><a href="#what-is-bpf" id="markdown-toc-what-is-bpf">What is BPF?</a></li>
  <li><a href="#dive-into-the-bytecode" id="markdown-toc-dive-into-the-bytecode">Dive into the bytecode</a></li>
  <li><a href="#resources" id="markdown-toc-resources">Resources</a>    <ul>
      <li><a href="#generic-presentations" id="markdown-toc-generic-presentations">Generic presentations</a>        <ul>
          <li><a href="#about-bpf" id="markdown-toc-about-bpf">About BPF</a></li>
          <li><a href="#about-xdp" id="markdown-toc-about-xdp">About XDP</a></li>
          <li><a href="#about-other-components-related-or-based-on-ebpf" id="markdown-toc-about-other-components-related-or-based-on-ebpf">About other components related or based on eBPF</a></li>
        </ul>
      </li>
      <li><a href="#documentation" id="markdown-toc-documentation">Documentation</a>        <ul>
          <li><a href="#about-bpf-1" id="markdown-toc-about-bpf-1">About BPF</a></li>
          <li><a href="#about-tc" id="markdown-toc-about-tc">About tc</a></li>
          <li><a href="#about-xdp-1" id="markdown-toc-about-xdp-1">About XDP</a></li>
          <li><a href="#about-flow-dissectors" id="markdown-toc-about-flow-dissectors">About flow dissectors</a></li>
          <li><a href="#about-p4-and-bpf" id="markdown-toc-about-p4-and-bpf">About P4 and BPF</a></li>
        </ul>
      </li>
      <li><a href="#tutorials" id="markdown-toc-tutorials">Tutorials</a></li>
      <li><a href="#examples" id="markdown-toc-examples">Examples</a>        <ul>
          <li><a href="#from-the-kernel" id="markdown-toc-from-the-kernel">From the kernel</a></li>
          <li><a href="#from-package-iproute2" id="markdown-toc-from-package-iproute2">From package iproute2</a></li>
          <li><a href="#from-bcc-set-of-tools" id="markdown-toc-from-bcc-set-of-tools">From bcc set of tools</a></li>
          <li><a href="#other-examples" id="markdown-toc-other-examples">Other examples</a></li>
          <li><a href="#manual-pages" id="markdown-toc-manual-pages">Manual pages</a></li>
        </ul>
      </li>
      <li><a href="#the-code" id="markdown-toc-the-code">The code</a>        <ul>
          <li><a href="#bpf-code-in-the-kernel" id="markdown-toc-bpf-code-in-the-kernel">BPF code in the kernel</a></li>
          <li><a href="#xdp-hooks-code" id="markdown-toc-xdp-hooks-code">XDP hooks code</a></li>
          <li><a href="#bpf-logic-in-bcc" id="markdown-toc-bpf-logic-in-bcc">BPF logic in bcc</a></li>
          <li><a href="#code-to-manage-bpf-with-tc" id="markdown-toc-code-to-manage-bpf-with-tc">Code to manage BPF with tc</a></li>
          <li><a href="#bpf-utilities" id="markdown-toc-bpf-utilities">BPF utilities</a></li>
          <li><a href="#other-interesting-chunks" id="markdown-toc-other-interesting-chunks">Other interesting chunks</a></li>
          <li><a href="#llvm-backend" id="markdown-toc-llvm-backend">LLVM backend</a></li>
          <li><a href="#running-in-userspace" id="markdown-toc-running-in-userspace">Running in userspace</a></li>
          <li><a href="#commit-logs" id="markdown-toc-commit-logs">Commit logs</a></li>
        </ul>
      </li>
      <li><a href="#troubleshooting" id="markdown-toc-troubleshooting">Troubleshooting</a>        <ul>
          <li><a href="#errors-at-compilation-time" id="markdown-toc-errors-at-compilation-time">Errors at compilation time</a></li>
          <li><a href="#errors-at-load-and-run-time" id="markdown-toc-errors-at-load-and-run-time">Errors at load and run time</a></li>
        </ul>
      </li>
      <li><a href="#and-still-more" id="markdown-toc-and-still-more">And still more!</a></li>
    </ul>
  </li>
</ul>

<p><em>~ <a href="https://github.com/qmonnet/whirl-offload/commits/gh-pages/_posts/2016-09-01-dive-into-bpf.md">Updated</a> 2019-01-10 ~</em></p>



<p>BPF, as in <strong>B</strong>erkeley <strong>P</strong>acket <strong>F</strong>ilter, was initially conceived in 1992
so as to provide a way to filter packets and to avoid useless packet copies
from kernel to userspace. It initially consisted in a simple bytecode that is
injected from userspace into the kernel, where it is checked by a verifier‚Äîto
prevent kernel crashes or security issues‚Äîand attached to a socket, then run on
each received packet. It was ported to Linux a couple of years later, and used
for a small number of applications (tcpdump for example). The simplicity of the
language as well as the existence of an in-kernel Just-In-Time (JIT) compiling
machine for BPF were factors for the excellent performances of this tool.</p>

<p>Then in 2013, Alexei Starovoitov completely reshaped it, started to add new
functionalities and to improve the performances of BPF. This new version is
designated as eBPF (for ‚Äúextended BPF‚Äù), while the former becomes cBPF
(‚Äúclassic‚Äù BPF). New features such as maps and tail calls appeared. The JIT
machines were rewritten. The new language is even closer to native machine
language than cBPF was. And also, new attach points in the kernel have been
created.</p>

<p>Thanks to those new hooks, eBPF programs can be designed for a variety of use
cases, that divide into two fields of applications. One of them is the domain
of kernel tracing and event monitoring. BPF programs can be attached to kprobes
and they compare with other tracing methods, with many advantages (and
sometimes some drawbacks).</p>

<p>The other application domain remains network programming. In addition to socket
filter, eBPF programs can be attached to tc (Linux traffic control tool)
ingress or egress interfaces and perform a variety of packet processing tasks,
in an efficient way. This opens new perspectives in the domain.</p>

<p>And eBPF performances are further leveraged through the technologies developed
for the IO Visor project: new hooks have also been added for XDP (‚ÄúeXpress Data
Path‚Äù), a new fast path recently added to the kernel. XDP works in conjunction
with the Linux stack, and relies on BPF to perform very fast packet processing.</p>

<p>Even some projects such as P4, Open vSwitch,
<a href="http://openvswitch.org/pipermail/ovs-dev/2014-October/047421.html">consider</a>
or started to approach BPF. Some others, such as CETH, Cilium, are entirely
based on it. BPF is buzzing, so we can expect a lot of tools and projects to
orbit around it soon‚Ä¶</p>



<p>As for me: some of my work (including for
<a href="https://qmonnet.github.io/whirl-offload/2016/07/15/beba-research-project/">BEBA</a>)
is closely related to eBPF, and several future articles on this site will focus
on this topic. Logically, I wanted to somehow introduce BPF on this blog before
going down to the details‚ÄîI mean, a real introduction, more developed on BPF
functionalities that the brief abstract provided in first section: What are BPF
maps? Tail calls? What do the internals look like? And so on. But there are a
lot of presentations on this topic available on the web already, and I do not
wish to create ‚Äúyet another BPF introduction‚Äù that would come as a duplicate of
existing documents.</p>

<p>So instead, here is what we will do. After all, I spent some time reading and
learning about BPF, and while doing so, I gathered a fair amount of material
about BPF: introductions, documentation, but also tutorials or examples. There
is a lot to read, but in order to read it, one has to <em>find</em> it first.
Therefore, as an attempt to help people who wish to learn and use BPF, the
present article introduces a list of resources. These are various kinds of
readings, that hopefully will help you dive into the mechanics of this kernel
bytecode.</p>



<figure>
  <img src="https://qmonnet.github.io/whirl-offload/img/icons/pic.svg">
</figure>

<h2 id="generic-presentations">Generic presentations</h2>

<p>The documents linked below provide a generic overview of BPF, or of some
closely related topics. If you are very new to BPF, you can try picking a
couple of presentation among the first ones and reading the ones you like most.
If you know eBPF already, you probably want to target specific topics instead,
lower down in the list.</p>

<h3 id="about-bpf">About BPF</h3>

<p>Generic presentations about eBPF:</p>

<ul>
  <li>
    <p><a href="https://blogs.igalia.com/dpino/2019/01/07/introduction-to-xdp-and-ebpf/"><em>A brief introduction to XDP and eBPF</em></a>
(Diego Pino Garc√≠a, January 2019): <br>
An excellent and accessible introduction providing context, history, and
details about the functioning of eBPF.</p>
  </li>
  <li>
    <p><a href="https://www.redhat.com/en/blog/introduction-ebpf-red-hat-enterprise-linux-7"><em>Introduction to eBPF in Red Hat Enterprise Linux 7</em></a>
(Stanislav Kozina, January 2019): <br>
Focusing on the eBPF features arriving in Red Hat.</p>
  </li>
  <li>
    <p><a href="http://fulvio.frisso.net/files/18HPSR%20-%20eBPF.pdf"><em>Toward Flexible and Efficient In-Kernel Network Function Chaining with IO Visor</em></a>
(Fulvio Risso, HPSR 2018, Bucharest, June 2018): <br>
A generic introduction to BPF, XDP, IO Visor, bcc and other components.</p>
  </li>
  <li>
    <p><a href="https://lwn.net/Articles/740157/"><em>A thorough introduction to eBPF</em></a>
(Matt Flemming, on LWN.net, December 2017): <br>
A well-written and accessible introduction providing an overview of eBPF
subsystem components.</p>
  </li>
  <li>
    <p><a href="http://schd.ws/hosted_files/ossna2017/da/BPFandXDP.pdf"><em>Making the Kernel‚Äôs Networking Data Path Programmable with BPF and XDP</em></a>
(Daniel Borkmann, OSSNA17, Los Angeles, September 2017):<br>
One of the best set of slides available to understand quickly all the basics about eBPF and XDP (mostly for network processing).</p>
  </li>
  <li>
    <p><a href="https://speakerdeck.com/tuxology/the-bsd-packet-filter">The BSD Packet Filter</a>
(Suchakra Sharma, June 2017): <br>
A very nice introduction, mostly about the tracing aspects.</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/brendangregg/bpf-tracing-and-more"><em>BPF: tracing and more</em></a>
(Brendan Gregg, January 2017):<br>
Mostly about the tracing use cases.</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/brendangregg/linux-bpf-superpowers"><em>Linux BPF Superpowers</em></a>
(Brendan Gregg, March 2016):<br>
With a first part on the use of <strong>flame graphs</strong>.</p>
  </li>
  <li>
    <p><a href="https://www.socallinuxexpo.org/sites/default/files/presentations/Room%20211%20-%20IOVisor%20-%20SCaLE%2014x.pdf"><em>IO Visor</em></a>
(Brenden Blanco, SCaLE 14x, January 2016):<br>
Also introduces <strong>IO Visor project</strong>.</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/ebpf_on_the_mainframe_lcon_2015.pdf"><em>eBPF on the Mainframe</em></a>
(Michael Holzheu, LinuxCon, Dublin, October 2015)</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/tracing-linux-ezannoni-linuxcon-ja-2015_0.pdf"><em>New (and Exciting!) Developments in Linux Tracing</em></a>
(Elena Zannoni, LinuxCon, Japan, 2015)</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/bpf_collabsummit_2015feb20.pdf"><em>BPF ‚Äî in-kernel virtual machine</em></a>
(Alexei Starovoitov, February 2015):<br>
Presentation by the author of eBPF.</p>
  </li>
  <li>
    <p><a href="https://lwn.net/Articles/603983/"><em>Extending extended BPF</em></a>
(Jonathan Corbet, July 2014)</p>
  </li>
</ul>

<p><strong>BPF internals</strong>:</p>

<ul>
  <li>Daniel Borkmann has been doing an amazing work to present <strong>the internals</strong> of eBPF, in particular about <strong>its use with tc</strong>, through several talks and papers.
    <ul>
      <li><a href="http://netdevconf.org/1.2/session.html?daniel-borkmann"><em>Advanced programmability and recent updates with tc‚Äôs cls_bpf</em></a>
(netdev 1.2, Tokyo, October 2016):<br>
Daniel provides details on eBPF, its use for tunneling and encapsulation,
direct packet access, and other features.</li>
      <li><a href="http://netdevconf.org/1.2/slides/oct5/07_tcws_daniel_borkmann_2016_tcws.pdf"><em>cls_bpf/eBPF updates since netdev 1.1</em></a>
(netdev 1.2, Tokyo, October 2016, part of
<a href="http://netdevconf.org/1.2/session.html?jamal-tc-workshop">this tc workshop</a>)</li>
      <li><a href="http://www.netdevconf.org/1.1/proceedings/slides/borkmann-tc-classifier-cls-bpf.pdf"><em>On getting tc classifier fully programmable with cls_bpf</em></a>
(netdev 1.1, Sevilla, February 2016):<br>
After introducing eBPF, this presentation provides insights on many
internal BPF mechanisms (map management, tail calls, verifier). A
must-read! For the most ambitious,
<a href="http://www.netdevconf.org/1.1/proceedings/papers/On-getting-tc-classifier-fully-programmable-with-cls-bpf.pdf">the full paper is available here</a>.</li>
      <li><a href="https://archive.fosdem.org/2016/schedule/event/ebpf/attachments/slides/1159/export/events/attachments/ebpf/slides/1159/ebpf.pdf"><em>Linux tc and eBPF</em></a>
(fosdem16, Brussels, Belgium, January 2016)</li>
      <li><a href="https://fosdem.org/2017/schedule/event/ebpf_xdp/"><em>eBPF and XDP walkthrough and recent updates</em></a>
(fosdem17, Brussels, Belgium, February 2017)</li>
    </ul>

    <p>These presentations are probably one of the best sources of documentation to
understand the design and implementation of internal mechanisms of eBPF.</p>
  </li>
</ul>

<p>The <a href="https://www.iovisor.org/resources/blog"><strong>IO Visor blog</strong></a> has some
interesting technical articles about BPF. Some of them contain a bit of
marketing talks.</p>

<p>As of early 2019, there are more and more presentations being done around
multiple aspects of BPF. One nice example is
<a href="http://vger.kernel.org/lpc-bpf.html">the BPF track</a> that was held in parallel
to the Linux Plumbers Conference in late 2018 (and should be held again on
coming years), where lots of topics related to eBPF development or use cases
were presented.</p>

<p><strong>Kernel tracing</strong>: summing up all existing methods, including BPF:</p>

<ul>
  <li>
    <p><a href="http://www.slideshare.net/vh21/meet-cutebetweenebpfandtracing"><em>Meet-cute between eBPF and Kerne Tracing</em></a>
(Viller Hsiao, July 2016):<br>
Kprobes, uprobes, ftrace</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/vh21/linux-kernel-tracing"><em>Linux Kernel Tracing</em></a>
(Viller Hsiao, July 2016):<br>
Systemtap, Kernelshark, trace-cmd, LTTng, perf-tool, ftrace, hist-trigger,
perf, function tracer, tracepoint, kprobe/uprobe‚Ä¶</p>
  </li>
</ul>

<p>Regarding <strong>event tracing and monitoring</strong>, Brendan Gregg uses eBPF a lot and
does an excellent job at documenting some of his use cases. If you are in
kernel tracing, you should see his blog articles related to eBPF or to flame
graphs. Most of it are accessible
<a href="http://www.brendangregg.com/blog/2016-03-05/linux-bpf-superpowers.html">from this article</a>
or by browsing his blog.</p>

<p>Introducing BPF, but also presenting <strong>generic concepts of Linux networking</strong>:</p>

<ul>
  <li>
    <p><a href="http://www.slideshare.net/ThomasGraf5/linux-networking-explained"><em>Linux Networking Explained</em></a>
(Thomas Graf, LinuxCon, Toronto, August 2016)</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/ThomasGraf5/linuxcon-2015-linux-kernel-networking-walkthrough"><em>Kernel Networking Walkthrough</em></a>
(Thomas Graf, LinuxCon, Seattle, August 2015)</p>
  </li>
</ul>

<p><strong>Hardware offload</strong>:</p>

<ul>
  <li>eBPF with tc or XDP supports hardware offload, starting with Linux kernel
version 4.9 and introduced by Netronome. Here is a presentation about this
feature:<br>
<a href="http://netdevconf.org/1.2/session.html?jakub-kicinski">eBPF/XDP hardware offload to SmartNICs</a>
(Jakub Kicinski and Nic Viljoen, netdev 1.2, Tokyo, October 2016)</li>
  <li>An updated version was presented on year later:<br>
<a href="https://www.netdevconf.org/2.2/session.html?viljoen-xdpoffload-talk">Comprehensive XDP offload‚ÄîHandling the edge cases</a>
(Jakub Kicinski and Nic Viljoen, netdev 2.2, Seoul, November 2017)</li>
  <li>I presented a shorter but updated version at FOSDEM 2018:<br>
<a href="https://fosdem.org/2018/schedule/event/xdp/">The Challenges of XDP Hardware Offload</a>
(Quentin Monnet, FOSDEM‚Äô18, Brussels, February 2018)</li>
</ul>

<p>About <strong>cBPF</strong>:</p>

<ul>
  <li>
    <p><a href="http://www.tcpdump.org/papers/bpf-usenix93.pdf"><em>The BSD Packet Filter: A New Architecture for User-level Packet Capture</em></a>
(Steven McCanne and Van Jacobson, 1992):<br>
The original paper about (classic) BPF.</p>
  </li>
  <li>
    <p><a href="http://www.gsp.com/cgi-bin/man.cgi?topic=bpf">The FreeBSD manual page about BPF</a>
is a useful resource to understand cBPF programs.</p>
  </li>
  <li>
    <p>Daniel Borkmann realized at least two presentations on cBPF,
<a href="http://borkmann.ch/talks/2013_devconf.pdf">one in 2013 on mmap, BPF and Netsniff-NG</a>, and
<a href="http://borkmann.ch/talks/2014_devconf.pdf">a very complete one in 2014 on tc and cls_bpf</a>.</p>
  </li>
  <li>
    <p>On Cloudflare‚Äôs blog, Marek Majkowski presented his
<a href="https://blog.cloudflare.com/introducing-the-bpf-tools/">use of BPF bytecode with the <code>xt_bpf</code> module for <strong>iptables</strong></a>.
It is worth mentioning that eBPF is also supported by this module, starting
with Linux kernel 4.10 (I do not know of ‚Ä¶</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/">https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/</a></em></p>]]>
            </description>
            <link>https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055866</guid>
            <pubDate>Wed, 11 Nov 2020 05:51:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personal epistemology, free speech, and tech companies]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25055742">thread link</a>) | @jseliger
<br/>
November 10, 2020 | https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies | <a href="https://web.archive.org/web/*/https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
						<p>The NYT describes ‚Äú<a href="https://www.nytimes.com/2020/10/13/magazine/free-speech.html">The Problem of Free Speech in an Age of Disinformation</a>, and in response Hacker News commenter <a href="https://news.ycombinator.com/item?id=24813749">throwaway13337</a> says, in part, ‚ÄúIt‚Äôs not unchecked free speech. Instead, it‚Äôs unchecked curation by media and social media companies with the goal of engagement.‚Äù There‚Äôs some truth to the idea that social media companies have evolved to seek engagement, rather than truth, but I think the social media companies are reflecting a deeper human tendency. I wrote back to throwaway13337: ‚ÄúTry teaching non-elite undergrads, and particularly assignments that require some sense of epistemology, and you‚Äôll discover that the vast majority of people have pretty poor personal epistemic hygiene‚Äîit‚Äôs not much required in most people, most of the time, in most jobs.‚Äù</p>
<p>From what I can tell, we evolved to form tribes, not to be ‚Äúright:‚Äù Jonathan‚Äôs Haidt‚Äôs <a href="https://jakeseliger.com/2012/03/25/jonathan-haidts-the-righteous-mind-and-what-were-really-arguing-about/"><em>The Righteous Mind: Why Good People Are Divided by Politics and Religion</em></a> deals with this topic well and at length, and I‚Äôve not seen any substantial rebuttals of it. We don‚Äôt naturally take to tracking the question, ‚ÄúHow do I know what I know?‚Äù Instead, we naturally seem to want to find ‚Äúfacts‚Äù or ideas that support our preexisting views. In the HN comment thread, someone asked for specific examples of poor undergrad epistemic hygiene, and while I‚Äôd prefer not to get super specific for reasons of privacy, I‚Äôve had many conversations that take the following form: ‚ÄúHow do you know article x is accurate?‚Äù ‚ÄúGoogle told me.‚Äù ‚ÄúHow does Google work?‚Äù ‚ÄúI don‚Äôt know.‚Äù ‚ÄúWhat does it take to make a claim on the Internet.‚Äù ‚ÄúUm. A phone, I guess?‚Äù A lot of people‚Äîmaybe most‚Äîwill uncritically take as fact whatever happens to be served up by Google (it‚Äôs always Google and never Duck Duck Go or Bing), and most undergrads whose work I‚Äôve read will, again uncritically, accept clickbait sites and similar as accurate. Part of the reason for this reasoning is that undergrads‚Äôs lives are minimally affected by being wrong or incomplete about some claim done in a short assignment that‚Äôs being imposed by some annoying professor toff standing between them and their degree.</p>
<p>The gap between elite information discourse and everyday information discourse, even among college students, who may be more sophisticated than their peer equivalents, is vast‚Äîso vast that I don‚Äôt think most journalists (who mostly talk to other journalists and to experts) and to other people who work with information, data, and ideas really truly understand it. We‚Äôre all living in bubbles. I don‚Äôt think I did, either, before I saw the epistemic hygiene most undergrads practice, or don‚Äôt practice. This is not a ‚Äúkids these days‚Äù rant, either: many of them have never really been taught to ask themselves, ‚ÄúHow do I know what I know?‚Äù Many have never really learned anything about the scientific method. It‚Äôs not happening much in most non-elite schools, so where are they going to get epistemic hygiene from?</p>
<p>The United States alone has 320 million people in it. Table DP02 in the Census at data.census.gov estimates that 20.3% of the population age 25 and older has a college bachelor‚Äôs degree, and 12.8% have a graduate or professional degree. Before someone objects, let me admit that a college degree is far from a perfect proxy for epistemic hygiene or general knowledge, and some high school dropouts perform much better at cognition, meta cognition, statistical reasoning, and so forth, than do some people with graduate degrees. With that said, though, a college degree is probably a decent approximation for baseline abstract reasoning skills and epistemic hygiene.</p>
<p>Almost anyone who wants a megaphone in the form of one of the many social media platforms available now has one. The number of people motivated by questions like ‚ÄúWhat is really true, and how do I discern what is really true? How do I enable myself to get countervailing data and information into my view, or worldview, or worldviews?‚Äù is not zero, again obviously, but it‚Äôs not a huge part of the population. And many very ‚Äúsmart‚Äù people in an IQ sense use their intelligence to build better rationalizations, rather than to seek truth (and I may be among the rationalizers: I‚Äôm not trying to exclude myself from that category).</p>
<p>Until relatively recently, almost everyone with a media megaphone had some kind of training or interest in epistemology, even they didn‚Äôt call it ‚Äúepistemology.‚Äù Editors would ask, ‚ÄúHow do you know that?‚Äù or ‚ÄúWho told you that?‚Äù or that sort of thing. Professors have systems that are supposed to encourage greater-than-average epistemic hygiene (again: these systems were not and are not perfect, and nothing I have written so far implies that they were or are).</p>
<p>Most people don‚Äôt care about the question, ‚ÄúHow do you know what you know?‚Äù and they‚Äôll be fairly surprised if it‚Äôs asked, implicitly or explicitly. Some people are intrigued by it but most aren‚Äôt, and view questions about sources and knowledge to be a hindrance. This is less likely to be true of people who aspire to be researchers or work in other knowledge-related professions, but that describes only a small percentage of undergraduates, particularly at non-elite schools. And the ‚Äúelite schools‚Äù thing drives a lot of the media discourse around education. One of the things I like about Professor X‚Äôs book <a href="https://jakeseliger.com/2011/06/10/summary-judgement-in-the-basement-of-the-ivory-tower-confessions-of-an-accidental-academic-professor-x/"><em>In the Basement of the Ivory Tower</em></a> is how it functions as a corrective to that discourse.</p>
<p>For most people, floating a factually incorrect conspiracy theory online isn‚Äôt going to negatively affect their lives. If someone is a nurse and gives a patient a wrong medication or incorrect medication, that person is not going to be a nurse for long. If the nurse states or repeats a factually incorrect political or social idea online, particularly but not exclusively under a pseudonym, that nurse‚Äôs life likely won‚Äôt be affected. There‚Äôs no truth feedback loop. The same is true for someone working in, say, construction, or engineering, or many other fields. The person is free to state things that are factually incorrect, or incomplete, or misleading, and doing so isn‚Äôt going to have many negative consequences. Maybe it will have some positive consequences: one way to show that you‚Äôre really on team x is to state or repeat falsehoods that show you‚Äôre on team x, rather than on team ‚ÄúWhat is really true?‚Äù</p>
<p>I don‚Äôt want to get into daily political discourse, since that tends to raise defenses and elicit anger, but the last eight months have demonstrated many people‚Äôs problems with epistemology, and in a way that can have immediate, negative personal consequences‚Äîbut not for everyone.</p>
<p><a href="https://www.pewresearch.org/fact-tank/2019/09/26/who-doesnt-read-books-in-america/">Pew Research data indicate that a quarter of US adults didn‚Äôt read a book in 2018</a>; this is consistent with <a href="https://www.newyorker.com/magazine/2007/12/24/twilight-of-the-books">other data</a> indicating that about half of US adults read zero or one books per year. Again, yes, there are surely many individuals who read other materials and have excellent epistemic hygiene, but this is a reasonable mass proxy, given the demands that reading makes on us.</p>
<p>Many people driving the (relatively) elite discourse don‚Äôt realize how many people are not only not like them, but wildly not like them, along numerous metrics. It may also be that <a href="http://www.arnoldkling.com/blog/gossip-at-scale/">we don‚Äôt know how to deal with gossip at scale</a>. Interpersonal gossip is all about personal stories, while many problems at scale are best understood through data‚Äîbut the number of people deeply interested in data and data‚Äôs veracity is small. And elite discourse has some of its own possible epistemic falsehoods, or at least uncertainties, embedded within it: some of the populist rhetoric against elites is rooted in truth.</p>
<p>We are all caught in our bubble, and the universe of people is almost unimaginably larger than the number of people in our bubble. If you got this far, you‚Äôre probably in a nerd bubble: usually, anything involving the word ‚Äúepistemology‚Äù sends people to sleep or, alternately, scurrying for something like ‚ÄúYou won‚Äôt believe what this celebrity wore/said/did‚Äù instead. Almost no one wants to consider epistemology; to do so as a hobby is rare. One person‚Äôs disinformation is another person‚Äôs teambuilding. If you think the preceding sentence is in favor of disinformation, by the way, it‚Äôs not.</p>
					</div><!-- .entry-content -->
	</div></div>]]>
            </description>
            <link>https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055742</guid>
            <pubDate>Wed, 11 Nov 2020 05:28:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Foundation for securing communications plane of CPS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055601">thread link</a>) | @takko_the_boss
<br/>
November 10, 2020 | https://mikecurnow.com/csis_introduction/ | <a href="https://web.archive.org/web/*/https://mikecurnow.com/csis_introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mikecurnow.com/csis_introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055601</guid>
            <pubDate>Wed, 11 Nov 2020 04:53:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Business ideas (from my first million podcast)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055308">thread link</a>) | @micropoet
<br/>
November 10, 2020 | https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553 | <a href="https://web.archive.org/web/*/https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055308</guid>
            <pubDate>Wed, 11 Nov 2020 03:46:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning a New Language While Browsing the Web]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25055257">thread link</a>) | @rahulchowdhury
<br/>
November 10, 2020 | https://hulry.com/toucan-learn-language/ | <a href="https://web.archive.org/web/*/https://hulry.com/toucan-learn-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
<p>Around 2015, I picked up a hobby of learning a new language ‚Äî Spanish.</p>



<p>However, after a few months of dedicated learning time, I couldn‚Äôt get myself to stick to the hobby.</p>



<p>I had other things to work on, and learning a language was not my priority.</p>



<p>But things have changed now.</p>



<p>In this post, I‚Äôll talk about how I‚Äôm learning a bit of Spanish every single day using a new language learning tool called <a href="https://jointoucan.com/" target="_blank" rel="noreferrer noopener">Toucan</a>.</p>



<p>Let‚Äôs get started with:</p>



<h2>My experience with various language-learning apps</h2>



<p>I started my Spanish learning journey with the most popular language-learning app ‚Äî <a href="https://www.duolingo.com/" target="_blank" rel="noreferrer noopener nofollow">Duolingo</a>.</p>



<p>While it was fun initially, I soon found myself missing practice days.</p>



<p>As time passed by, the gap widened. And soon enough, I stopped my Spanish sessions.</p>



<p>In the last few years, I‚Äôve tried to rekindle the Spanish spark in me and continue learning with Duolingo. Still, I never succeeded in sticking to the classes.</p>



<p>Then came <a href="https://www.babbel.com/" target="_blank" rel="noreferrer noopener nofollow">Babbel</a>.</p>



<p>While I must say that Babbel has a better course in terms of learning proper grammar and dialects, it had the same problem as Duolingo:</p>



<p>It was hard for me to dedicate time from my schedule for learning sessions.</p>



<p>My only motivation for learning Spanish was to expand my skill set.</p>



<p>Since I‚Äôm not moving to a Spanish speaking country anytime soon, I didn‚Äôt feel the need to prioritise this hobby.</p>



<p>But then:</p>



<p>A few months ago, I spotted a new <a href="https://chrome.google.com/webstore/detail/toucan/lokjgaehpcnlmkebpmjiofccpklbmoci" target="_blank" rel="noreferrer noopener nofollow">Chrome extension called Toucan</a>. Around the same time, a similar extension launched called <a href="https://www.usefluent.co/" target="_blank" rel="noreferrer noopener">Fluent</a>.</p>



<p>The key selling point of these new extensions was to learn a new language while browsing the web.</p>



<p>You don‚Äôt need to dedicate time for picking up a new language. Club the learning sessions, along with activities we do every day ‚Äî browsing the web and reading articles online.</p>



<p>After a quick test ride, here‚Äôs:</p>



<h2>Why I find language learning extensions interesting</h2>



<p>The first and most immense value ‚Äî habit bundling.</p>



<p>I had previously talked about how I <a href="https://hulry.com/building-podcasts-habit/" target="_blank" rel="noreferrer noopener">clubbed my habit</a> of making tea every morning with listening to podcasts.</p>



<p>I saw a similar opportunity with these browser extensions.</p>



<p>The biggest hurdle for me in learning Spanish was making time for classes.</p>



<p>Now:</p>



<p>I don‚Äôt need to dedicate time out of my daily routine to learn a new language.</p>



<p>I browse and read lots of articles online. With Toucan or Fluent, I can learn and practice Spanish every time I read stuff online.</p>



<p>Here‚Äôs:</p>



<h2>How Toucan and Fluent work</h2>



<p>Install Toucan or Fluent, and browse the web as you‚Äôd typically do.</p>



<p>These extensions will translate and highlight some words from the page content into the language you‚Äôve chosen.</p>



<p>Hovering over the highlighted word will bring up a popup card like this:</p>



<div><figure><img data-attachment-id="943" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-demo/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=1646%2C742&amp;ssl=1" data-orig-size="1646,742" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-demo" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=300%2C135&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=1024%2C462&amp;ssl=1" loading="lazy" width="1024" height="462" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1" alt="Toucan translating and showing up a word on Instapaper." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=300%2C135&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=768%2C346&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1536%2C692&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1200%2C541&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?w=1646&amp;ssl=1 1646w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=300%2C135&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=768%2C346&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1536%2C692&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1200%2C541&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?w=1646&amp;ssl=1 1646w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan translating and showing up a word on Instapaper.</figcaption></figure></div>



<p>Pretty neat. Right?</p>



<p>Apart from the convenience, another thing I like is that the translations are beautifully blended into the content.</p>



<p>For example, from the above screenshot, you can see Toucan seamlessly translated and blended the English word ‚Äúevent‚Äù into its Spanish counterpart ‚Äî evento.</p>



<p>While reading an article, I can see a mixture of English and the language I want to learn.</p>



<p>To know more about the translated word, I can hover on it and Toucan will show me the word in English, with its definition.</p>



<p>I‚Äôve tried both Toucan and Fluent on multiple websites, and they seem to blend in translations flawlessly with the page‚Äôs design.</p>



<p>Here‚Äôs an article on Forbes with Toucan translations:</p>



<div><figure><img data-attachment-id="947" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-forbes/" data-orig-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=1474%2C814&amp;ssl=1" data-orig-size="1474,814" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-forbes" data-image-description="" data-medium-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=300%2C166&amp;ssl=1" data-large-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=1024%2C565&amp;ssl=1" loading="lazy" width="1024" height="565" src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1" alt="Toucan translating words from an article on Forbes." srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=300%2C166&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=768%2C424&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1200%2C663&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?w=1474&amp;ssl=1 1474w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=300%2C166&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=768%2C424&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1200%2C663&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?w=1474&amp;ssl=1 1474w" data-lazy-src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan translating words from an article on Forbes.</figcaption></figure></div>



<p>Now:</p>



<p>Fluent, however, has a more targeted highlighting than Toucan. </p>



<p>If you‚Äôre using Fluent, it‚Äôll highlight words with different colour based on gender.</p>



<div><figure><img data-attachment-id="983" data-permalink="https://hulry.com/toucan-learn-language/fluent-colour-highlights/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=1596%2C508&amp;ssl=1" data-orig-size="1596,508" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fluent-colour-highlights" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=300%2C95&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=1024%2C326&amp;ssl=1" loading="lazy" width="1024" height="326" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1" alt="Fluent highlighting words with a different colour." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=768%2C244&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1200%2C382&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?w=1596&amp;ssl=1 1596w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=768%2C244&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1200%2C382&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?w=1596&amp;ssl=1 1596w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Fluent highlighting words with a different colour.</figcaption></figure></div>



<p>In the paragraph shown above, Fluent highlighted the word ‚Äúderrame‚Äù with a yellow tint (because it‚Äôs masculine), and ‚Äúincluso‚Äù with a neutral grey-ish colour (because it‚Äôs gender-neutral).</p>



<p>That said, here are:</p>



<h2>Some features in Toucan that caught my attention</h2>



<p>Trying out both extensions, I chose to stick with Toucan, mainly due to a couple of subtle features.</p>



<p>The first being:</p>



<h3>Word definitions</h3>



<p>Toucan shows up the definition of a translated word on the hovercard that shows up.</p>



<div><figure><img data-attachment-id="952" data-permalink="https://hulry.com/toucan-learn-language/toucan-word-definition/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=1524%2C632&amp;ssl=1" data-orig-size="1524,632" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-word-definition" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=300%2C124&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=1024%2C425&amp;ssl=1" loading="lazy" width="1024" height="425" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1" alt="Toucan showing a word's definition." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1200%2C498&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?w=1524&amp;ssl=1 1524w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1200%2C498&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?w=1524&amp;ssl=1 1524w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan showing a word‚Äôs definition.</figcaption></figure></div>



<p>As a non-native English speaker, this feature is helpful to me. </p>



<p>If I don‚Äôt know the meaning of the translated word, I can read the definition on the card.</p>



<p>There‚Äôs one caveat though:</p>



<p>Right now, not all words show up a definition. However, the number of words without a description is low.</p>



<p>Also, the team at Toucan promised they are continuously working on adding more words and definitions to the tool.</p>



<p>Therefore, this caveat should no longer exist pretty soon.</p>



<p>Another feature I found helpful is:</p>



<h3>The ability to mark a word as learnt</h3>



<p>The Toucan hovercard has a little checkmark which lets me mark a word as learnt, like this:</p>



<div><figure><img data-attachment-id="958" data-permalink="https://hulry.com/toucan-learn-language/touch-mark-word-done/" data-orig-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=840%2C526&amp;ssl=1" data-orig-size="840,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="touch-mark-word-done" data-image-description="" data-medium-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=300%2C188&amp;ssl=1" data-large-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=840%2C526&amp;ssl=1" loading="lazy" width="840" height="526" src="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?resize=840%2C526&amp;ssl=1" alt="Marking a word as known in Toucan." data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Marking a word as known in Toucan.</figcaption></figure></div>



<p>What this does is it prevents the word from getting translated in future articles or content.</p>



<p>Since I had taken a couple of Spanish lessons in the past, I marked a handful of words as ‚ÄúI know this‚Äù and Toucan will leave those words in the source language ‚Äî English, for me.</p>



<p>Also:</p>



<p>The Toucan team is working on some recommendation magic for this feature.</p>



<p>For example:</p>



<p>Marking the word ‚Äúcoffee‚Äù as learnt will set Toucan to translate tricky words like ‚Äúhot coffee‚Äù or ‚Äúnice coffee‚Äù in your future reads.</p>



<p>This is how I‚Äôll be able to calibrate Toucan to show up more complicated words as I progress in my Spanish learning journey. </p>



<p>Now:</p>



<p>Everyone learns at a different pace.</p>



<p>To make it easy to progress comfortably, Toucan allows me to:</p>



<h3>Select language packs for translation</h3>



<p>Instead of being bombarded with a giant index of Spanish words, Toucan allows me to <a href="https://jointoucan.com/dashboard" target="_blank" rel="noreferrer noopener nofollow">select language packs</a> on the dashboard:</p>



<div><figure><img data-attachment-id="962" data-permalink="https://hulry.com/toucan-learn-language/toucan-language-packs/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=1860%2C1182&amp;ssl=1" data-orig-size="1860,1182" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-language-packs" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=300%2C191&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=1024%2C651&amp;ssl=1" loading="lazy" width="1024" height="651" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1" alt="Selecting language packs in Toucan." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=300%2C191&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=768%2C488&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1536%2C976&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1200%2C763&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?w=1860&amp;ssl=1 1860w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=300%2C191&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=768%2C488&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1536%2C976&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1200%2C763&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?w=1860&amp;ssl=1 1860w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Selecting language packs in Toucan.</figcaption></figure></div>



<p>Each language pack has a set of words that Toucan will search for in an article or web page content and translate.</p>



<p>For example, choosing the language pack ‚ÄúGet Around the City‚Äù will set Toucan to translate the following English words in the collection to their Spanish counterparts:</p>



<div><figure><img data-attachment-id="964" data-permalink="https://hulry.com/toucan-learn-language/toucan-get-around-city-pack/" data-orig-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=1420%2C834&amp;ssl=1" data-orig-size="1420,834" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-get-around-city-pack" data-image-description="" data-medium-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=1024%2C601&amp;ssl=1" loading="lazy" width="1024" height="601" src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1" alt="Toucan's &quot;Get Around the City&quot; language pack." srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=300%2C176&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=768%2C451&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1200%2C705&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?w=1420&amp;ssl=1 1420w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=300%2C176&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=768%2C451&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1200%2C705&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?w=1420&amp;ssl=1 1420w" data-lazy-src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan‚Äôs ‚ÄúGet Around the City‚Äù language pack.</figcaption></figure></div>



<p>This feature is beneficial for beginners because we can choose a handful of language packs and start learning.</p>



<p>Once we have mastered the words in the selected packs, we can remove them from our list and move on to more advanced packs.</p>



<p>So, overall, Toucan seems to be a useful tool for learning a language.</p>



<p>But, here‚Äôs a burning question:</p>



<h2>Can language extensions be a distraction?</h2>



<p>It depends on the translation density set for the extension.</p>



<p>For example, in Toucan, we can control the number of translations on a page with the following setting:</p>



<div><figure><img data-attachment-id="967" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-frequency/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=1600%2C1158&amp;ssl=1" data-orig-size="1600,1158" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-frequency" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=300%2C217&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=1024%2C741&amp;ssl=1" loading="lazy" width="1024" height="741" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1" alt="Choosing a translation density in Toucan." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=300%2C217&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=768%2C556&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1536%2C1112&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1200%2C869&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=300%2C217&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=768%2C556&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1536%2C1112&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1200%2C869&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Choosing a translation density in Toucan.</figcaption></figure></div>



<p>Choosing ‚ÄúMany‚Äù will set Toucan to replace and highlight a substantial number of words on the page with their translated counterparts.</p>



<p>I tried this setting for some time, and I found it somewhat distracting because there were a ton of words highlighted in the page fighting for my attention.</p>



<p>To take it easy and progress gradually, I started with the setting ‚ÄúLess‚Äù.</p>



<p>With ‚ÄúLess‚Äù, I get around 5‚Äì7 words translated in an article of 4‚Äì5 min read time.</p>



<p>Also:</p>



<p>With ‚ÄúLess‚Äù translations are distributed evenly in the article. Thus, the highlights don‚Äôt steal my attention from the content.</p>



<p>I can naturally spot a highlight as I read through the content, and hover on the translated word for the meaning.</p>



<p>Here‚Äôs what I recommend:</p>



<p>Start with ‚ÄúLess‚Äù ‚Üí As you become comfortable with the translations ‚Üí Move to ‚ÄúMore‚Äù.</p>



<p>With a gradual transition, it‚Äôll be easier to stick to this extension and interpret it as a tool instead of a distraction.</p>



<p>Similar to Toucan, Fluent also shows up an option to choose how many words you‚Äôd like to see translated:</p>



<div><figure><img data-attachment-id="992" data-permalink="https://hulry.com/toucan-learn-language/fluent-set-word-density/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=1584%2C662&amp;ssl=1" data-orig-size="1584,662" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fluent-set-word-density" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=300%2C125&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=1024%2C428&amp;ssl=1" loading="lazy" width="1024" height="428" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1" alt="Setting a translation density on Fluent." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=300%2C125&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=768%2C321&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1536%2C642&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1200%2C502&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?w=1584&amp;ssl=1 1584w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=300%2C125&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=768%2C321&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1536%2C642&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1200%2C502&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?w=1584&amp;ssl=1 1584w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Setting a translation density on Fluent.</figcaption></figure></div>



<p>Establishing the fact that these extensions are a tool rather than a distraction, here‚Äôs another critical question:</p>



<h2>Are there any privacy concerns?</h2>



<p>Privacy is a significant factor in an extension like this since we‚Äôre giving the extension full access to whatever we browse.</p>



<p>Both <a href="https://jointoucan.com/privacy" target="_blank" rel="noreferrer noopener nofollow">Toucan</a> and <a href="https://www.usefluent.co/privacy" target="_blank" rel="noreferrer noopener nofollow">Fluent</a> have addressed this concern with a friendly privacy policy.</p>



<p>Here‚Äôs a gist:</p>



<ul><li>They don‚Äôt sell user data for ads.</li><li>The extensions don‚Äôt store any browsing history.</li><li>They only store the translated words in a browsing session to keep track of your learning progress.</li></ul>



<p>But:</p>



<p>With a free product, there will always be privacy concerns, no matter how clean it‚Äôs privacy policy might be. The business needs to make money.</p>



<p>Here‚Äôs how Toucan generates revenue right now:</p>



<ul><li><strong>Premium memberships.</strong> Toucan offers a premium membership which unlocks a couple of advanced learning packs.</li><li><strong>Own a word.</strong> With Toucan, you can <a href="https://jointoucan.com/own-the-word/claim" target="_blank" rel="noreferrer noopener nofollow">own a word</a> for <strong>$0.99/week</strong>. This means that if I own the word ‚Äúproductivity‚Äù, then every time someone hovers over the translated word for ‚Äúproductivity‚Äù, they‚Äôll see my name and website at the bottom of the card. Consider it a form of advertisement without the use of your browsing history.</li></ul>



<p>That said:</p>



<p>I would still recommend you turn off Toucan on sensitive websites like your email inbox, banking sites, etc.</p>



<p>Here‚Äôs how you can do it:</p>



<div><figure><img data-attachment-id="975" data-permalink="https://hulry.com/toucan-learn-language/turn-off-toucan/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=840%2C526&amp;ssl=1" data-orig-size="840,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="turn-off-toucan" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=300%2C188&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=840%2C526&amp;ssl=1" loading="lazy" width="840" height="526" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?resize=840%2C526&amp;ssl=1" alt="Turning off Toucan translations on a specific website." data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Turning off Toucan translations on a specific website.</figcaption></figure></div>



<p>Once Toucan is turned off for a particular website, the extension will never read any data from any page of the website.</p>



<p>Here are some of the websites where I have disabled Toucan:</p>



<ul><li>HEY email</li><li>Dropbox</li><li>Gmail</li><li>Banking websites I use</li><li>WordPress</li><li>Notion</li></ul>



<p>It‚Äôs always wise to fine-tune privacy settings so that we don‚Äôt leak any of our data to a company who might use it to their advantage.</p>



<p>Now that we talked about Toucan‚Äôs premium subscription, let‚Äôs see:</p>



<h2>Whether premium is worth the money</h2>



<p>Right now, the only selling point of ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hulry.com/toucan-learn-language/">https://hulry.com/toucan-learn-language/</a></em></p>]]>
            </description>
            <link>https://hulry.com/toucan-learn-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055257</guid>
            <pubDate>Wed, 11 Nov 2020 03:39:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Value for People]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055070">thread link</a>) | @mooreds
<br/>
November 10, 2020 | https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><em>This is a guest post from Minh Pham. Enjoy.</em></p>



<p>Dear new developer,</p>



<p>I want to start off by saying Congrats and Good job. If you‚Äôre reading this, it‚Äôs likely you know how to code ‚Äì and even if you‚Äôre still working on getting that first job, that means you have one of the most desirable skill sets in the world today. I congratulate you because getting here took work. You weren‚Äôt born with this knowledge, and even if you felt like it came naturally, it was still a journey of discovery, learning, and practice that got you where you are today.</p>



<p>As you look towards your first job ‚Äì I want to offer you a single piece of advice that may act as your career‚Äôs guiding north star:</p>



<p><strong>Create Value for People.</strong></p>



<p>When you have the power to create anything, you begin to realize the importance isn‚Äôt on the code you‚Äôre writing but rather why you‚Äôre writing it in the first place. What value are you creating through your skill? This is why companies hire people like yourself. They are seeking out individuals who can ultimately deliver value to their customers, particularly through software. As you mature, you will realize that much of engineering has little to do with how fancy your solution is, and instead has everything to do with what problem it solves for the user. Once you accept this, you‚Äôll begin to see that discussions of tech choice and code structure rarely matters outside the context of what business value it represents.</p>



<p>This is where your focus should stay.</p>



<p>Obsessions with patterns and algorithms don‚Äôt serve anyone‚Äôs mission by themselves. Ignore the constant pressure to assert yourself through syntactic cleverness and obscure trivia. These things don‚Äôt matter. These things don‚Äôt drive value for anyone. No matter how many ‚Äúexperienced‚Äù engineers tell you these are important, I promise you no company hires people simply for them to recite principles and algorithms.</p>



<p>While coding might be your latest skill set, it is by no means an engineer‚Äôs only skillset. Remember that at the end of the day, it doesn‚Äôt matter if your code is ugly, fancy, verbose or concise ‚Äì the value you create matters. Strive to be an excellent communicator, a quality teammate, and an outstanding human. These attributes will guide your engineering efforts to ensure you bring value.</p>



<p>No matter where your career goes, if you focus on creating value for people, opportunities will never be in short supply. Desire for specific skills may rise and fall, but people will always look to those who can create value.</p>



<p>With that, I wish you the best of luck and may our journeys cross again,</p>



<p>Minh Pham</p>



<p><em><a href="https://www.linkedin.com/in/miniseagoat/">Minh Pham</a> believes you should lead how you want to be led. This has been the guiding principle of his career since he started. As an Engineer, he always wished he had someone who would guide him ‚Äì telling him what‚Äôs important, what he has to work on, and what he should ignore. Having gone through all that and then some, Minh now looks to be the positive influence he wishes he had.</em></p>



<p><em>As a manager, Minh‚Äôs greatest passion was teaching people the skills to create and drive the careers they want to have. Now as a career coach, he works to show people they have the power to build the life they want.</em></p>



<p><em>Minh believes anyone can do it ‚Äì and he promises it doesn‚Äôt involve linked lists or graph traversals.</em></p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-11-09T09:27:00-07:00">November 9, 2020</time><time datetime="2020-10-23T21:27:22-06:00">October 23, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055070</guid>
            <pubDate>Wed, 11 Nov 2020 03:00:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facial-Recognition Software for Bears]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25054992">thread link</a>) | @sandworm101
<br/>
November 10, 2020 | https://www.cbc.ca/news/canada/british-columbia/grizzly-bear-facial-recognition-software-1.5797525 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/british-columbia/grizzly-bear-facial-recognition-software-1.5797525">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Facial recognition technology previously used on humans has huge implications for managing bear-human interactions, says UVic ecologist who has developed software to identify grizzly bears.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5797547.1605049994!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/bearid.JPG"></p></div><figcaption>BearID is grizzly bear facial recognition software developed 'from the ground up' with algorithms used to identify humans and primates. <!-- --> <!-- -->(Melanie Clapham)</figcaption></figure><p><span><p>Melanie Clapham has spent the last three years snapping images of grizzly bears at Knight Inlet, on the B.C. coast, using small camera traps housed in metal and strapped securely to the forest branches.</p>  <p>Three years and thousands of images later, the behavioural ecologist and postdoctoral student at the University of Victoria <a href="https://onlinelibrary.wiley.com/doi/10.1002/ece3.6840" target="_blank">has partnered with</a> two software developers living in Silicon Valley&nbsp;and a grizzly research centre in Alaska&nbsp;to develop facial recognition technology used to identify the bears.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/bearid-2.jpg 300w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/bearid-2.jpg 460w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/bearid-2.jpg 620w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/bearid-2.jpg 780w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/bearid-2.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/bearid-2.jpg"></p></div><figcaption>Melanie Clapham sets up a camera trap to capture images of grizzly bears for the BearID project.<!-- --> <!-- -->(Moira Le Patourel)</figcaption></figure></span></p>  <p>"They don't have distinctive markings on their bodies," said Clapham, whose&nbsp;interest in this technology stemmed from the need to "identify and recognize individual bears over time" as part of her behavioural research over the last 11 years.&nbsp;</p>  <p>Now, she says, the <a href="http://bearresearch.org/" target="_blank">open-source Bear ID software</a> can be used and adapted by anyone&nbsp;and could have huge implications for understanding the animals' behaviour and mitigating bear-human encounters.&nbsp;</p>  <h2>Technology based on human facial recognition</h2>  <p>Ed Miller and his partner Mary Nyugen are the software developers from California who connected with Clapham in an online forum for conservation technology in late 2017.&nbsp;</p>  <p>The pair were looking for photos of bears "for fun" as a way to learn more about recognition software, and so they connected with Clapham to offer their expertise in adapting artificial intelligence.</p>    <p>"The technology we're using is based on the same software [used] to recognize humans," said Miller, who added that human identification is far easier, as there are literally millions of images the software can learn from.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/bearid-3.JPG 300w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/bearid-3.JPG 460w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/bearid-3.JPG 620w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/bearid-3.JPG 780w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/bearid-3.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/bearid-3.JPG"></p></div><figcaption>Grizzly bears can be difficult to track, as many do not have distinctive markings on their bodies. <!-- --> <!-- -->(Melanie Clapham)</figcaption></figure></span></p>  <p>"We need (lots of) images of individual animals to tell the system which bear is which," said Clapham, who explained "deep learning" as the process where the software trains itself to recognize certain bears more accurately the more pictures it has.&nbsp;</p>    <p>This is especially important, given that a bear's appearance can change dramatically throughout the year as its fur moults and its weight fluctuates.&nbsp;</p>  <p>Claphams says BearID currently has an 84 per cent accuracy rate.</p>  <h2>Many practical applications</h2>  <p>Clapham said she hopes the technology will be adapted by municipalities, governments, non-profits ‚Äî as many groups as possible ‚Äî as it will allow people to understand animal behaviour, like how they move&nbsp;in and out of densely populated areas. It could also help researchers understand the movements of endangered species.</p>  <p>It can track bears as they move "in a similar way that a human is tracked through airports," she explained. From there, authorities could make better-informed land management and conservation decisions.&nbsp;</p>  <p>It could also help mitigate conflict encounters between bears and humans. </p>  <p>"If you have a bear digging through garbage cans, and you set cameras up ‚Ä¶ is this just one bear or is this five different bears coming into the area?" Clapham said.</p>  <p>Dallas Smith, president of the Nanwakolas Council, a group of five First Nations from Vancouver Island and the B.C. Coast&nbsp;formed to make land management decisions, said he's very excited for First Nations to use BearID, after connecting with Clapham.</p>  <p>"The grizzly bear is an icon in our cultural heritage. It's always been important to work in harmony with them," he explained. "It's really helping us gain a foothold in taking over the management of grizzly bear interactions in our territories."</p>  <p>He said the "collective territory" is working to gather more images for the system.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/british-columbia/grizzly-bear-facial-recognition-software-1.5797525</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054992</guid>
            <pubDate>Wed, 11 Nov 2020 02:44:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Series of blog posts about technology migrations]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054689">thread link</a>) | @poros
<br/>
November 10, 2020 | http://poros.github.io/technology-migrations-series/ | <a href="https://web.archive.org/web/*/http://poros.github.io/technology-migrations-series/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div> <nav> <ul> <li> <a href="http://poros.github.io/">Home</a> </li> <li> <a href="http://poros.github.io/pseudoblog">PseudoBlog</a> </li> <li> <a href="http://poros.github.io/projects">Projects</a> </li> <li> <a href="http://poros.github.io/works">Works</a> </li> <li> <a href="http://poros.github.io/about">About</a> </li> </ul> </nav>  <p><span> <time datetime="18-10-2020">Sunday. October 18, 2020</time> </span></p><div> <p><a href="http://poros.github.io/tags/#technology-migrations-series">technology-migrations-series</a> <a href="http://poros.github.io/tags/#tech-lead">tech-lead</a> </p></div>  <p><strong>Migrations are a messy business.</strong> They always run far behind schedule, and it is actually quite rare for them to end at all. They are hard to justify in terms of return on investment. They have a bad reputation among both users and management. They are emotionally draining. Yet they are the way things move forward, technologically speaking at least.</p> <p>Having been working for my entire career (so far) on internal teams focused on infrastructure or platforms, I end up thinking about migrations a lot. I have built my own little taxonomy of technology migrations, I have come up with my personal recipe to pull them off, and I have initiated engineers in the craft of running them. And those are the topics and the intent of this series of blog posts.</p> <p>The first post goes over the taxonomy of migrations and how to approach them based on the category they belong to. But you can start from the second one if you are only interested in how to run the most common type. In case you have read the entire thing already or you don‚Äôt have time for long reads, you can find a summary checklist to follow during your migration in the very last post.</p> <ol> <li><a href="http://poros.github.io/taxonomy-of-migrations/">A taxonomy of migrations</a></li> <li><a href="http://poros.github.io/mum-preparations/">Migrations under monopoly: Preparations</a></li> <li><a href="http://poros.github.io/mum-alpha/">Migrations under monopoly: Alpha</a></li> <li><a href="http://poros.github.io/mum-beta/">Migrations under monopoly: Beta</a></li> <li><a href="http://poros.github.io/mum-automation/">Migrations under monopoly: Automation</a></li> <li><a href="http://poros.github.io/mum-nudges/">Migrations under monopoly: Nudges</a></li> <li><a href="http://poros.github.io/mum-the-fat-tail/">Migrations under monopoly: The fat tail</a></li> <li><a href="http://poros.github.io/mum-deprecation/">Migrations under monopoly: Deprecation</a></li> <li><a href="http://poros.github.io/migration-checklist/">The migration checklist</a></li> </ol> <div> <a href="http://poros.github.io/taxonomy-of-migrations/"> <img src="http://poros.github.io/assets/images/next_arrow.png" alt="Next"> <b><figcaption>Next</figcaption></b> <figcaption>A taxonomy of migrations</figcaption> </a> </div> <div> <h4>Related Posts</h4> <ul> <li> <a href="http://poros.github.io/migration-checklist/">The migration checklist </a> </li> <li> <a href="http://poros.github.io/mum-deprecation/">Migrations under monopoly: Deprecation </a> </li> <li> <a href="http://poros.github.io/mum-the-fat-tail/">Migrations under monopoly: The fat tail </a> </li> <li> <a href="http://poros.github.io/mum-nudges/">Migrations under monopoly: Nudges </a> </li> <li> <a href="http://poros.github.io/mum-automation/">Migrations under monopoly: Automation </a> </li> </ul> </div> <section> <p><img src="http://poros.github.io/assets/images/profile.jpg" alt="Antonio Uccio Verardi"> </p> <div> <h4>Antonio Uccio Verardi</h4> <p>from <a href="http://www.yelp.com/" target="_blank">yelp</a> import engineering_manager</p>  </div> </section> <section>    <a href="http://disqus.com/">comments powered by <span>Disqus</span></a> </section>  </div> </div></div>]]>
            </description>
            <link>http://poros.github.io/technology-migrations-series/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054689</guid>
            <pubDate>Wed, 11 Nov 2020 01:49:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Great Code Reviews‚ÄìThe Superpower Your Team Needs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054556">thread link</a>) | @saranshk
<br/>
November 10, 2020 | https://shopify.engineering/great-code-reviews | <a href="https://web.archive.org/web/*/https://shopify.engineering/great-code-reviews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>There is a general consensus that code reviews are an important aspect of highly effective teams. <a href="https://sail.cs.queensu.ca/Downloads/EMSE_AnEmpiricalStudyOfTheImpactOfModernCodeReviewPracticesOnSoftwareQuality.pdf" target="_blank" title="An Empirical Study of the Impact of Modern Code Review Practices on Software Quality" rel="nofollow noopener noreferrer">This research paper</a> is one of many exploring this subject. Most organizations undergo code reviews of some form.</p>
<p>However, it‚Äôs all too common to see code reviews that barely scratch the surface, or that offer feedback that is unclear or hard to act upon. This robs the team the opportunity to speed up learning, share knowledge and context, and raise the quality bar on the resulting code.</p>
<p>At Shopify, we want to move fast while building for the long term. In our experience, having strong code review practices has a huge impact on the growth of our engineers and in the quality of the products we build.</p>

<p>Imagine you join a new team and you‚Äôre given a coding task to work on. Since you‚Äôre new on the team, you really want to show what you‚Äôre made of. You want to perform. So, this is what you do:</p>
<ol>
<li>You work frantically on your task for 3 weeks.</li>
<li>You submit a Pull Request for review with about 1000 new lines of code</li>
<li>You get a couple comments about code style and a question that shows the person has no clue what this work is about.</li>
<li>You get approval from both reviewers after fixing the code style and answering the question.</li>
<li>You merge your branch into master, eyes closed, shoulders tense, grinding your teeth. After a few minutes, CI completes. Master is not broken. Yet.</li>
<li>You live in fear for 6 months, not knowing when and how your code will break.</li>
</ol>
<p>You may have lived through some of the situations above, and hopefully you‚Äôve seen some of the red flags in that process.</p>
<p>Let‚Äôs talk about how we can make it much better.</p>

<p>At Shopify, we value the speed of shipping, learning, and building for the long term. These values - which sometimes conflict - lead us to experiment with many techniques and team dynamics. In this article, I have distilled a series of very practical techniques we use at Shopify to ship valuable code that can stand the test of time.</p>
<p>A Note about terminology: We refer to Pull Requests (PR) as one unit of work that's put forth for review before merging into the base branch. Github and Bitbucket users will be familiar with this term.</p>
<h2>1. Keep Your Pull Requests Small</h2>
<p>As simple as this sounds, this is easily the most impactful technique you can follow to level up your code review workflow. There are 2 fundamental reasons why this works:</p>
<ul>
<li>It‚Äôs mentally easier to <strong>start and complete a review</strong> for a small piece. Larger PRs will naturally make reviewers delay and procrastinate examining the work, and they are more likely to be interrupted mid-review.</li>
<li>As a reviewer, it‚Äôs exponentially <strong>harder to dive deep</strong> if the PR is long. The more code there is to examine, the bigger the mental map we need to build to understand the whole piece.</li>
</ul>
<p>Breaking up your work in smaller chunks increases your chances of getting faster and deeper reviews.</p>
<p>Now, it‚Äôs impossible to set one universal standard that applies to all programming languages and all types of work. Internally, for our data engineering work, the guideline is around 200-300 lines of code affected. If we go above this threshold, we almost always break up the work into smaller blocks.</p>
<p>Of course, we need to be careful about breaking up PRs into chunks that are <strong>too small</strong>, since this means reviewers may need to inspect several PRs to understand the overall picture.</p>
<h2>2. Use Draft PRs</h2>
<p>Have you heard the metaphor of building a car vs. drawing a car? It goes something like this:</p>
<ol>
<li>You‚Äôre asked to build a car.</li>
<li>You go away for 6 months and build a beautiful Porsche.</li>
<li>When you show it to your users, they ask about space for their 5 children and the surf boards.</li>
</ol>
<p>Clearly, the problem here is that the goal is poorly defined and the team jumped directly into the solution before gathering enough feedback.If after step 1 we created a drawing of the car and showed it to our users, they would have asked the same questions and we would have discovered their expectations and saved ourselves 6 months of work. Software is no different‚Äîwe can make the same mistake and work for a long time on a feature or module that isn't what our users need.</p>
<p>At Shopify, it‚Äôs common practice to use <strong>Work In Progress (WIP) PRs</strong> to elicit early feedback whose goal is validating direction (choice of algorithm, design, API, etc). Early changes mean less wasted effort on details, polish, documentation, etc.</p>
<p>As an author, this means you need to be open to changing the direction of your work. At Shopify, we try to embrace the principle of <a href="https://engineering.shopify.com/blogs/engineering/scaling-mobile-development-by-treating-apps-as-services" target="_blank" title="Scaling Mobile Development by Treating Apps as Services - Shopify Engineering" rel="noopener noreferrer"><strong>strong opinions, loosely held</strong></a>. We want people to make decisions confidently, but also be open to learning new and better alternatives, given sufficient evidence. In practice, we use Github‚Äôs <strong>Draft PRs</strong>‚Äîthey clearly signal the work is still in flow and Github prevents you from merging a Draft PR. Other tools may have similar functionality, but at the very least you can create normal PRs with a clear <strong>WIP</strong> label to indicate the work is early stage. This will help your reviewers focus on offering the right type of feedback.</p>
<h2>3. One PR Per Concern</h2>
<p>In addition to line count, another dimension to consider is how many <em>concerns</em> your unit of work is trying to address. A concern may be a feature, a bugfix, a dependency upgrade, an API change, etc. Are you introducing a new feature while refactoring at the same time? Fixing two bugs in one shot? Introducing a library upgrade and a new service?</p>
<p>Breaking down PRs into individual concerns has the following effects:</p>
<ul>
<li>
<strong>More independent review units</strong> and therefore <strong>better review quality</strong>
</li>
<li>
<strong>Fewer affected people</strong>, therefore less domains of expertise to gather</li>
<li>
<strong>Atomicity of rollbacks,</strong>&nbsp;the ability of rolling back a small commit or PR. This is valuable because if something goes wrong, it will be easier to identify where errors were introduced and what to roll back.</li>
<li>
<strong>Separating easy stuff from hard stuff</strong>. Imagine a new feature that requires refactoring a frequently used API. You change the API, update a dozen call-sites, and then implement your feature. 80% of your changes are obvious and skimmable with no functional changes, while 20% are new code that needs careful attention to test coverage, intended behaviour, error handling, etc. and will likely go through multiple revisions. With each revision, the reviewer will need to skim through <em>all</em> of the changes to find the relevant bits. By splitting this in two PRs, it becomes easy to quickly land the majority of the work and to optimize the review effort applied to the harder work.</li>
</ul>
<p>If you end up with a PR that includes more than one concern, you can break it down into individual chunks. Doing so will accelerate the iteration cycle on each individual review, giving a faster review overall. Often part of the work can land quickly, avoiding code rot and merge conflicts.</p>
<p><img alt="Breaking down PRs into individual concerns" data-src="//cdn.shopify.com/s/files/1/0779/4361/files/Code_Reviews_at_Shopify_-_blog_article.jpg?v=1581342642" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Code_Reviews_at_Shopify_-_blog_article.jpg?v=1581342642"></p>
<meta charset="utf-8">
<p><em>Breaking down PRs into individual concerns</em></p>
<p>In the example above, we‚Äôve taken a PR that covered three different concerns and broke it up. You can see how each reviewer has strictly less context to go over. Best of all, as soon as <em>any</em> of the reviews is complete, the author can begin addressing feedback while continuing to wait for the rest of the work. In the most extreme cases, instead of completing a first draft, waiting several days (and shifting focus), and then eventually returning to address feedback, the author can work almost continuously on their family of PRs as they receive the different reviews asynchronously.</p>
<h2>4. Focus on the Code, Not the Person</h2>
<p>Focus on the code, not the person practice refers to communication styles and relationships between people. Fundamentally, it‚Äôs about trying to focus on making the product better, and avoiding the author perceiving a review as personal criticism.</p>
<p>Here are some tips you can follow:</p>
<ul>
<li>As a reviewer, think, ‚ÄúThis is <strong>our</strong> code, how can we improve on it?‚Äù</li>
<li>Offer positive remarks! If you see something done well, comment on it. This reinforces good work and helps the author balance suggestions for improvement.</li>
<li>As an author, assume best intention, and don‚Äôt take comments personally.</li>
</ul>
<p>Below are a few examples of not-so-great review comments, and a suggestion on how we can reword to emphasize the tips above.</p>
<table>
<tbody>
<tr>
<td>

<strong>Less of These</strong>
</td>
<td><strong>&nbsp;More of These</strong></td>
</tr>
<tr>
<td>

Move this to Markdown</td>
<td>

How about moving this documentation into our Markdown README file? That way we can more easily share with other users.<strong></strong>
</td>
</tr>
<tr>
<td>

Read the Google Python style guidelines</td>
<td>

We should avoid single-character variables. How about board_size or size instead?</td>
</tr>
<tr>
<td>

This feels too slow. Make it faster. Lightning fast.</td>
<td>&nbsp;This algorithm is very easy to read but I‚Äôm concerned about performance. Let‚Äôs test this with a large dataset to gauge its efficiency.</td>
</tr>
<tr>
<td>

Bool or int?</td>
<td>

Why did you choose a list of bool values instead of integers?</td>
</tr>
</tbody>
</table>
<p><br>Ultimately, a code review is a learning and teaching opportunity and should be celebrated as such.</p>
<h2>5. Pick the Right People to Review</h2>
<p>It‚Äôs often challenging to decide who should review your work. Here are some questions can use as guidance:</p>
<ul>
<li>Who has context on the feature or component you‚Äôre building?</li>
<li>Who has strong skills in the language, framework, or tool you‚Äôre using?</li>
<li>Who has strong opinions on the subject?</li>
<li>Who cares about the result of what you‚Äôre doing?</li>
<li>Who should learn this stuff? Or if you‚Äôre a junior reviewing someone more senior, use this as an opportunity to ask questions and learn. Ask all the silly questions, a strong team will find the time to share knowledge.</li>
</ul>
<p>Whatever rules your team might have, remember that it is your responsibility as an author to seek and receive a high-quality code review from a person or people with the right context.</p>
<h2>6. Give Your Reviewers a Map</h2>
<p>Last but definitely not least, the description on your PR is crucial. Depending on who you picked for review, different people will have different context. The onus is on the author to help reviewers by providing key information or links to more context so they can produce meaningful feedback.</p>
<p>Some questions you can include in <a href="https://help.github.com/en/github/building-a-strong-community/creating-a-pull-request-template-for-your-repository" target="_blank" title="Creating a pull request template for your repository - GitHub" rel="nofollow noopener noreferrer">your PR templates</a>:</p>
<ul>
<li>Why is this PR necessary?</li>
<li>Who benefits from this?</li>
<li>What could go wrong?</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/great-code-reviews">https://shopify.engineering/great-code-reviews</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/great-code-reviews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054556</guid>
            <pubDate>Wed, 11 Nov 2020 01:31:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Helped me be more Productive as a Software Developer]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25054231">thread link</a>) | @strikingloo
<br/>
November 10, 2020 | https://www.datastuff.tech/programming/productivity-software-developer-student/ | <a href="https://web.archive.org/web/*/https://www.datastuff.tech/programming/productivity-software-developer-student/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-884" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@strikingloo">
<meta name="twitter:title" content="How I Stay Productive as a Software Developer">
<meta name="twitter:description" content="Imagine getting more stuff done, more effectively, in less time.">
<meta name="twitter:image" content="https://cdn.pixabay.com/photo/2020/11/04/19/22/windmill-5713337_1280.jpg">
<p>Imagine getting more stuff done, more effectively, in less time. That is how I will define productivity for the rest of this piece.</p>
<p>I‚Äôve been reading a lot of productivity articles, tips, tricks and Twitter threads. In a way, doing so is the worst kind of procrastination, entropy for entropy‚Äôs sake. But every once in a while you‚Äôll glean some gold nugget among the rubble, and it will all be worth it.</p>
<p>This is my attempt at recollecting what nuggets I found. On each section I will:</p>
<ul><li>Cite sources I found interesting or relevant.</li><li>Mention whether the methods have worked for me and what exact impact they‚Äôve had.</li></ul>
<p>I will add a big caveat though: I think every person‚Äôs optimal productivity engine should be different. Thus, all of this advice should be taken, tested, and left to rot if it doesn‚Äôt work for you. And that pretty much applies to all other posts of this kind, in any blog ever, in my opinion.</p>
<p>Without further ado, here are the things I‚Äôve seen actually work to make me get more stuff done, or stay less stressed.</p>
<h2>Reduce cognitive load</h2>
<p>Cognitive load is a beautiful term. It roughly means ‚ÄúHow full is your mind‚Äôs RAM?‚Äù. </p>
<p>Whenever you‚Äôre thinking of the next 5 things you have to do, your groceries list, and whether you left the stove on, you‚Äôre carrying cognitive load.</p>
<p>It should be evident, but cognitive load stresses you out. Reducing it can help you better focus on your task.</p>
<p>Here‚Äôs what has worked for me on this account:</p>
<ul><li>Keep a clean room, office and desk<sup><a href="#fn1">1</a></sup>. You shouldn‚Äôt have trouble finding anything you use often, and the things you use the most often should be very easy to reach. This also applies to your filesystem, bookmarks system, etc. If you know you‚Äôll want to check a certain link again in the future, bookmark it under an intuitive path. Don‚Äôt find yourself looking for it through your twitter feed.</li><li>If something‚Äôs on your mind and it‚Äôs not useful to keep thinking of it, <strong>write it down and forget it</strong>. You can look it up later. </li></ul>
<p>Take this article, for instance: instead of pestering myself thinking ‚ÄòYou have to write that article!‚Äô I just added an item on my Trello backlog that said ‚Äòarticle on productivity‚Äô and forgot about it until I had free time again and checked.</p>
<p>My own setup for task tracking is a combination of Trello for daily/weekly tasks and a Google sheet for long term stuff -like a deferred backlog- but really, every person has their own perfect combination of tools and processes. Find your own. </p>
<p>I know many people who prefer physical post-its, or a board. I‚Äôd rather get the portability of a browser app and the tracking for future reference. This is especially good if you also practice journaling, because then it‚Äôs just ‚ÄúWhat did I do today? Oh ok I‚Äôll check today‚Äôs cards‚Äù. Still, your mileage will vary, so try many things and see what works best for you.</p>
<h2>Keep productive habits</h2>
<blockquote><p>‚Ä¶Watch your actions, they become your habits; watch your habits, they become your character; watch your character, it becomes your destiny.‚Äù</p><cite><em>‚Äï&nbsp;</em><strong>Lao Tzu</strong></cite></blockquote>
<p>Some people recommend this book called ‚ÄúAtomic Habits‚Äù. I won‚Äôt lie, I haven‚Äôt read it. But I read a good summary on reddit and agree with most of it, thought I was already kind of doing most of what it talks about.</p>
<p>The gist of it is: don‚Äôt try to build productivity on its own, build systems that incentivize you to be productive.</p>
<p>Some people use pomodoros, others prefer to put on noise-blocking headphones; I personally prefer to hide my cell phone until I have got enough stuff done. </p>
<p>My technique for this is simple: every month, (or use whatever time frame works for you), I decide which routines I will keep.</p>
<p>Right now for instance, my routines are:</p>
<ul><li>Exercise 4 times a week.</li><li>Do everything I have to for work and school, obviously.</li><li>Journal every night</li><li>2 hours of Japanese study every day</li></ul>
<p>The painful side of having a very clear set of goals and habits is: you‚Äôre extremely accountable to them. Is the day ending and you haven‚Äôt done your daily study session? You better get down to it right now. </p>
<p>In my case, my own conscience is a harsh enough mistress, but if you are not that hard on yourself when your to-do lists have uncrossed items, you may want to try something like </p>
<ul><li>Asking your SO to make passive aggressive remarks to you if you don‚Äôt finish your tasks.</li><li>Reward yourself with something sweet.</li><li>Going full monk-mode and forfeiting cell phone time until everything is done.</li></ul>
<p>Now for the flip side: you‚Äôre accountable for your tasks, yes, but you also set them. So whenever you define what your habits will be, don‚Äôt overestimate yourself. It‚Äôs better to have realistic, achievable goals that fall a bit short of your <em>maximum effort</em>, than it is to overstep, burn out or just not build the habits because you can‚Äôt keep up with them. </p>
<p>Did you underestimate your time management skills and now you‚Äôre doing everything you planned for <em>and</em> then get a lot of free time anyway? Cool! You get to feel productive <em>and</em> have free time. </p>
<p>You definitely don‚Äôt want to optimize for minimum free time. It sounds obvious, but I‚Äôve caught myself and others doing this without realizing it.</p>
<p>The devil doesn‚Äôt always make work with idle hands.</p>
<p>Another thing about incentives: this ties to the ‚Äúunclutter‚Äù rule I mentioned earlier, but do try to turn everything around you into a big <strong>habit-keeping engine</strong>. </p>
<p>For instance, if your goal is to read a book every week, have your book on sight and within arm‚Äôs reach at all times. Carry it on your suitcase/backpack, take it out instead of your cell phone when you want to procrastinate, etc. </p>
<p>You‚Äôll be surprised by how much stuff you get done when <strong>everything around you is making you do it</strong>.</p>
<p>For a small guide on creating habits that I found interesting (though maybe more complicated than necessary) see <a href="https://www.lesswrong.com/posts/vE7Z2JTDo5BHsCp4T/instrumental-rationality-4-2-creating-habits">creating habits</a>.</p>
<h2>Don‚Äôt use your head for things a PC was made for</h2>
<p>Really though, remember what I said about cognitive load? Defining daily goals is not cool if you end up spending 5 minutes every hour thinking ‚Äúok what comes next? I already crossed my Chinese practice and my Economics lecture, what was the next item?‚Äù. </p>
<p>You want whatever system you build to be maintainable in the long run, so you should make it as easy to consult as possible, and not depend on a very fallible piece of architecture (your head).</p>
<p>So keep everything written down, on a nice .txt file, a Google doc, a sheet, etc. Use whatever you like, but not your head. Really it‚Äôs that simple, and it works. </p>
<p>(Aside: I am not going into detail into different tools or task tracking systems because honestly? There are like 20 different articles on this topic posted on HackerNews every week, and they‚Äôre all the same).</p>
<h2>Effective Note Taking</h2>
<p>This is all I have to say about note taking.</p>
<p>I am not a very note taking inclined person. I started this particular habit this year, and even though it <em>feels</em> productive, I don‚Äôt feel like I can quite say it has actually made me perform better yet.</p>
<p>So my first tip on this will be: <strong>don‚Äôt take notes if you don‚Äôt think it will be worth it</strong>. Some people retain information better when they take notes, I am not one of those people but if you are, then that piece of advice doesn‚Äôt apply to you. Remember when I said systems needed to be custom?</p>
<p>I also say this because I see there‚Äôs this trend in the internet of ‚Äúwrite everything down, take all the notes!‚Äù and I think we‚Äôre tending towards an excessive ‚Äúpro-notes-taking‚Äù bias, which may be unwarranted.</p>
<p>Secondly: if you are not writing everything down, how do you decide what should be kept? Well, I‚Äôm open to better ideas, but in my case I optimize for (estimated) <strong>future searchability</strong>: is what I just read, heard or watched something I am <strong>likely to think of in the future</strong>? And maybe I will want to recall it exactly and won‚Äôt be able to? Well then, into the notes it goes.</p>
<p>Note that it doesn‚Äôt need to be a relevant piece of information per se. I take notes about interesting history facts, anime trivia and weird Japanese words, not because they‚Äôll come up in my final exams (fingers crossed) or, gods forbid, my job. I keep those quotes and facts around because they may come up in conversation.</p>
<p>Generally though, I think the category that makes the best notes is ‚Äúthings that I am likely to forget and look up again in the future, but I don‚Äôt care to learn by heart right now‚Äù. </p>
<p>This includes things like very specific facts about a domain, convoluted bash commands that you put into a script to not have to remember again (but want to persist somewhere else in case you want them on a different pc), or syntax details in a programming language.</p>
<p>I will be reading an article and think ‚Äúoh, $FRIEND_X surely would find this very funny‚Äù and just write it down. And then I may send it to them through IM, but let‚Äôs be honest I could forget‚Ä¶ until I reread my notes in the future.</p>
<p>Oh, the topic of rereading notes. This one is a tricky bit I haven‚Äôt mastered yet, and I am also open to suggestions in this area. Personally, I only reread notes on technical topics whenever they come up and I want to refresh my memory, and any other topic if I am thinking of it.</p>
<p>I know some people like to go through all of their notes every X time and they say it improves their creativity and gets the writing juices flowing. I am not super concerned about my creativity or writing right now (in case my one year posting-gap didn‚Äôt make that clear), but I will definitely experiment with that in the future (and write about it if I get any relevant results).</p>
<p>Lastly, I‚Äôve recently been using a <strong>personal wiki</strong> for some of my notes (only the polished, public-facing ones), and it‚Äôs really cool, but it just reinforces point one: I feel like part of why I use a personal wiki is just that it feels nice, and I haven‚Äôt yet seen a lot of improvement over a simple Evernote or Google Docs. Maybe it‚Äôs a matter of scale and the effects won‚Äôt be apparent until a few years in? We will see.</p>
<h2>Anki and SRS for studying and productivity.</h2>
<blockquote><p><strong>Anki makes memory a choice</strong>, rather than a haphazard event, to be left to chance.</p><cite>Michal ‚Ä¶</cite></blockquote></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.datastuff.tech/programming/productivity-software-developer-student/">https://www.datastuff.tech/programming/productivity-software-developer-student/</a></em></p>]]>
            </description>
            <link>https://www.datastuff.tech/programming/productivity-software-developer-student/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054231</guid>
            <pubDate>Wed, 11 Nov 2020 00:47:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PilferShush Jammer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054222">thread link</a>) | @karlzt
<br/>
November 10, 2020 | https://www.cityfreqs.com.au/pilfer.php | <a href="https://web.archive.org/web/*/https://www.cityfreqs.com.au/pilfer.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
            Basic information about how the SDKs code function. They start with a call to the Android/Java API that deals with audio recording and playback. From there with a buffer array full of some audio data, it can then be sent to a native code library that is also installed as part of the SDK. These libraries handle the more CPU intensive work such as sifting through the data using various common methods (Goertzel et al) to find audio signals of interest. 
            </p><p>
            This first section shows some of the Android/Java function calls and parameters used.
            </p><p>
							<strong>alphonso</strong>
              <br>
              ALPHONSO_VERSION = "2.0.46";
              </p><pre>    private static final int RECORDER_AUDIO_BYTES_PER_SEC = 16000;
    private static final int RECORDER_AUDIO_ENCODING = 2;
    private static final int RECORDER_BIG_BUFFER_MULTIPLIER = 16;
    private static final int RECORDER_CHANNELS = 16;
    private static final int RECORDER_SAMPLERATE_44100 = 44100;
    private static final int RECORDER_SAMPLERATE_8000 = 8000;
    private static final int RECORDER_SMALL_BUFFER_MULTIPLIER = 4;
    public static final byte ACR_SHIFT_186 = (byte) 0;
    public static final byte ACR_SHIFT_93 = (byte) 1;
    public static final int ACR_SPLIT = 2;</pre>

              <p><strong>bitsound</strong>
              <br>
              VERSION_NAME = "v4.2.2"
              </p><pre>    public void a(int i) {
      try {
        this.d = new AudioRecord(6, this.b, 16, 2, i);
        if (this.d.getState() == 1) {
          try {
            this.d.startRecording();
            if (this.d.getRecordingState() != 3) {
              b.c(a, "Audio recording startDetection fail");
              this.d.release();
              this.e = false;
              return;
            }
            a(this.d);
            this.e = true;
            return;</pre>
            
              <p><strong>cifrasoft</strong>
              <br>
              VERSION_NAME = "1.0.3"
              </p><pre>    public static final int AUDIO_BUFFER_SIZE_MULTIPLIER = 4;
    public static final int AUDIO_THREAD_STOP_TIMEOUT = 3000;
    public static final int MAX_EMPTY_AUDIO_BUFFER_SEQUENTIAL_READS = 10;
    this.SAMPLE_RATE = 44100;</pre>
    
              <pre>    private int readAudioData(int currentPcmOffset, byte[] pcm) {
      AudioRecordService.handler.sendEmptyMessageDelayed(1, 3000);
      int result = this.mAudioRecord.read(pcm, currentPcmOffset * 2, this.bufferLength * 2);
      AudioRecordService.handler.removeMessages(1);
      return result;
    }</pre>

              <p><strong>copsonic</strong>
              <br>
              CORE_VERSION = "SonicAuth_CORE_v1.2.2.1";
              </p><pre>    "signalType": "ULTRASONIC_TONES",
    "content" : {
        "frequencies" : [ [18000, 20000, "TwoTones"] ]

    "signalType": "ZADOFF_CHU",
    "content": {
      "config": {
        "samplingFreq": 44100,
        "minFreq": 18000,
        "maxFreq": 19850,
        "filterRolloff": 0.5,
        "totalSignalTime": 0.3,
        "nMsgSymbols": 2,
        "filterSpan": 8
      },
      "set": {
        "centralFreq": 18925,
        "nElemSamples": 36,
        "nSymbolElems": 181</pre>

              <p><strong>dv (dov-e)</strong>
              <br>
              VERSION_NAME = "1.1.7"
              </p><pre>    private void recorderWork() {
      if (this.recordingActive) {
        int bytesReadNumber = this.myRecorder.read(this.myBuffer, 0, this.myBuffer.length);
        if (this.recordingActive) {
          DVSDK.getInstance().DVCRxAudioSamplesProcessEvent(this.myBuffer, 0, bytesReadNumber / 2);
        }
      }
    }</pre>
    
              <p><strong>fanpictor</strong>
              <br>
              VERSION_NAME = "3.2.3"
              </p><pre>    enum FNPFrequencyBand {
      Default,
      Low,
      High
    }
              </pre>

              <p><strong>fidzup</strong></p><pre>    a. this.frequency = paramBasicAudioAnalyzerConfig.frequency;   // 19000.0f
    b. this.samplingFrequency = paramBasicAudioAnalyzerConfig.samplingRate;    // 44100.0f
    c. this.windowSize = paramBasicAudioAnalyzerConfig.windowSize;   // 0x200 (512)
    d. /* pulseDuration = 69.66f */
    e. this.pulseWidth = Math.round(paramBasicAudioAnalyzerConfig.pulseDuration * (this.samplingFrequency / 1000.0F));
    f. this.pulseRatio = paramBasicAudioAnalyzerConfig.pulseRatio;   // 32.0f
    /* signalSize = 0x20 (32)
    g. this.signalPeriodPulses = paramBasicAudioAnalyzerConfig.signalSize;
    h. this.bitCounts = paramBasicAudioAnalyzerConfig.bitcounts;   // 0xb (11)</pre>         
            <pre>    paramf.a = 19000.0F;            
    paramf.b = 44100.0F;            
    paramf.c = 512;                 
    paramf.d = 69.66F;              
    paramf.e = 0.33333334F;         
    paramf.f = ((int)(paramf.d * 32.0F * 3.2F)); // 7133.184
    paramf.g = 32;                 
    paramf.h = new int[] { 15, 17, 19, 13, 11, 21, 23, 9, 7, 25, 27 };</pre>             

              <p><strong>fluzo</strong>
              <br>
              VERSION = "1.3.001"</p><pre>    this.p = jSONObject.getInt("frame_length_milliseconds");
    this.q = jSONObject.getInt("frame_step_milliseconds");
    this.r = (float) jSONObject.getDouble("preemphasis_coefficient");
    this.s = jSONObject.getInt("num_filters");
    this.t = jSONObject.getInt("num_coefficients");
    this.u = jSONObject.getInt("derivative_window_size");</pre>
    
              <p><strong>instreamatic</strong>
              <br>
              VERSION_NAME = "7.16.0"</p><pre>    private static final int BUFFER_SECONDS = 5;
    private static int DESIRED_SAMPLE_RATE = 16000;</pre>
 
              <p><strong>lisnr</strong>
              <br>
              VERSION_NAME = "5.0.1.1";
              </p><pre>    // LisnrIDTone          
    public long calculateToneDuration() {
        return ((long) (((double) (this.lastIteration + 1)) * 2.72d)) * 1000;
    }
    // LisnrTextTone
    public long calculateToneDuration() {
        return (long) (((this.text.length() * 6) * 40) + 1280);
    }
    // LisnrDataTone
    public long calculateToneDuration() {
        return (long) (((this.data.length * 6) * 40) + 1280);
    }
    AudioRecord audioRecord = new AudioRecord(0, d, 16, 2, 131072);</pre>  

              <pre>    ArrayAudioPlayer.this.audioOutput = new AudioTrack(3, ArrayAudioPlayer.this.samplerate, 4, 2, 16000, 1);
    ArrayAudioPlayer.this.audioOutput.play();
    int written = 0;
    while (!ArrayAudioPlayer.this.threadShouldStop) {
      try {
        if (ArrayAudioPlayer.this.buffer.getBufferLeftToRead() &gt; 0) {
          int size = ArrayAudioPlayer.this.buffer.getBufferLeftToRead();
          written += size;
          ArrayAudioPlayer.this.audioOutput.write(ArrayAudioPlayer.this.buffer.readFromBuffer(size), 0, size);
          } else {
            ArrayAudioPlayer.this.threadShouldStop = true;
          }
        } catch (IOException e) {
          e.printStackTrace();
        }</pre>
        
              <p><strong>moodmedia</strong>
              <br>
              getVersion() = "1.2.1";
              </p><pre>    b = new AudioRecord(5, 44100, 16, 2, Math.max(AudioRecord.getMinBufferSize(44100, 16, 2) * 4, 32768));
    this.b = Type.SONIC;
    this.b = Type.ULTRASONIC;
    if (num.intValue() == 44100 || num.intValue() == 48000)
    this.j.setName("Demodulator");
    this.k.setName("Decoder");
    this.l.setName("HitCounter");
              </pre>
 
              <p><strong>prontoly (sonarax)</strong>
              <br>
              VERSION_NAME = "4.2.0";
             </p><pre>    contentValues.put("time", cVar.a);
    contentValues.put("type", cVar.b.name());
    contentValues.put(NotificationCompat.CATEGORY_EVENT, cVar.c);
    contentValues.put("communication_type", cVar.d);
    contentValues.put("sample_rate", cVar.e);
    contentValues.put("range_mode", cVar.f);
    contentValues.put("data", cVar.g);
    contentValues.put("duration", cVar.h);
    contentValues.put("count", cVar.i);
    contentValues.put("volume", cVar.j);</pre>
    
              <p><strong>realitymine</strong>
              <br>
              getSdkVersion = "5.1.6";
              </p><pre>    this.e = AudioRecord.getMinBufferSize(44100, 16, 2);
    int i = this.e;
    this.d = new byte[i];
    this.c = new AudioRecord(1, 44100, 16, 2, i);</pre>

              <p><strong>redbricklane (zapr)</strong>
              <br>
              SDK_VERSION = "3.3.0";
              </p><pre>    AudioRecord localAudioRecord = new AudioRecord(1, 8000, 16, 2, 122880);
    if (localAudioRecord.getState() == 1) {
      this.logger.write_log("Recorder initialized", "finger_print_manager");
      this.logger.write_log("Recording started", "finger_print_manager");
      localAudioRecord.startRecording();</pre>

              <p><strong>runacr</strong>
              <br>
              release = "1.0.4"
              </p><pre>    int minBufferSize = AudioRecord.getMinBufferSize(11025, 16, 2);
    this.K = new AudioRecord(6, 11025, 16, 2, minBufferSize * 10);</pre>

              <p><strong>shopkick</strong></p><pre>    .field bitDetectThreshold:Ljava/lang/Double;
    .field carrierThreshold:Ljava/lang/Double;
    .field detectThreshold:Ljava/lang/Double;
    .field frFactors:Ljava/lang/String;
    .field gapInSamplesBetweenLowFreqAndCalibration:Ljava/lang/Integer;
    .field maxFracOfAvgForOne:Ljava/lang/Double;
    .field maxIntermediates:Ljava/lang/Integer;
    .field minCarriers:Ljava/lang/Integer;
    .field noiseThreshold:Ljava/lang/Double;
    .field numPrefixBitsRequired:Ljava/lang/Integer;
    .field numSamplesToCalibrateWith:Ljava/lang/Integer;
    .field presenceDetectMinBits:Ljava/lang/Integer;
    .field presenceNarrowBandDetectThreshold:Ljava/lang/Double;
    .field presenceStrengthRatioThreshold:Ljava/lang/Double;
    .field presenceWideBandDetectThreshold:Ljava/lang/Double;
    .field useErrorCorrection:Ljava/lang/Boolean;
    .field wideBandPresenceDetectEnabled:Ljava/lang/Boolean;
    .field highPassFilterType:Ljava/lang/Integer;</pre>
              <pre>    Java_com_shopkick_app_presence_NativePresencePipeline_setDopplerCorrectionEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setHighPassFilterEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setWideBandDetectEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setNumPrefixBitsRequiredParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setPresenceDetectNarrowBandDetectThresholdFCParam
    ‚Ä¶</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cityfreqs.com.au/pilfer.php">https://www.cityfreqs.com.au/pilfer.php</a></em></p>]]>
            </description>
            <link>https://www.cityfreqs.com.au/pilfer.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054222</guid>
            <pubDate>Wed, 11 Nov 2020 00:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eddie's Ink Chip Hack (2002)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054177">thread link</a>) | @userbinator
<br/>
November 10, 2020 | http://www.eddiem.com/photo/CIS/inkchip/chip.html | <a href="https://web.archive.org/web/*/http://www.eddiem.com/photo/CIS/inkchip/chip.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tr>
<td>
<p lang="en-GB"><a href="http://www.eddiem.com/photo/CIS/cis.htm">My CIS page.</a></p></td>
<th>
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/inkchip.JPG" name="Graphic2" width="401" height="400"></p></th>
<td>
<p lang="en-GB"><a href="http://www.eddiem.com/photo/printer/chipreset/resetchip.html">Part
				2 build your own reseter</a></p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><strong>What is a Intellidge ink chip.</strong><span size="5"><br>
</span>Epson fit
				small circuit boards to most of their ink cartridges. These
				record the amount of ink that is estimated to be in the
				cartridge. I read that the official epson line is that it is for
				the customers benefit and not an anti-refill device. Whether you
				believe this or not they are a bloody nuisance to anyone wanting
				to refill the cartridges or use bulk ink. It also stops people
				using old cartridges full of solvent for cleaning the heads.
				Another problem was early printer models didn't check if the
				cartridge had been changed while power was on. This was good if
				you wanted to trick the printer into copying a ‚Äúfull‚Äù
				chip to and empty one, however the reverse was also true and you
				could easily copy and ‚Äúempty‚Äù one into your full
				one.<br>
They are just a small memory device holds 32 bytes of
				data, they do not measure real ink level and nor does the
				printer. The printer reads the chips on startup, estimates
				(sometimes badly) how much ink should have been used and writes
				this back at shutdown. They hold other data as well.<br>
So epson
				go to the trouble of fitting chips to cartridges and building all
				the extra sockets, wiring, electronics and software into the
				printer so you can use the computer to see the predicted level
				and it can stop you printing if it think you've used enough ink.
				High-end Canon's on the other hand make the inks tank clear so
				you can see and have optical sensor to detect emptiness. This
				make a lot more sense ‚Äì unless you are making an
				anti-refill device that is. Canon almost got my business this
				time but nobody I could find has run pigment in them ‚Äì too
				risky.<br>
To get around the chip problems someone usually end up
				producing read-only chip which always read full (for use with
				CIS) and chip reseters for those who want to refill. These are
				not available for 2100p at the time of writing as far as I can
				tell.<br>
Before ordering my 2100p I did my homework and it seemed
				fairly likely a chip reseter would become available at some point
				and read-only chips as well. I was also cocky enough to think I
				could crack it myself and I have. It didn't go quite as expected
				though.<br>
<strong>What do I want to do?</strong><br>
I want the easiest way
				to fool the printer into believing it has full cartridges present
				so I can build my CIS.<br>
<strong>What did I expect?</strong><br>
A logical
				interface for Intellidge is i2c (i squared c) or TWI (two wire
				interface). Then the chip could just be some standard i2c eeprom.
				The Intellidge have too many pads for this but I was hopeful.
				After that would could SPI or microwire ‚Äì again this could
				use off the shelf parts. If the chips were micro-controllers then
				plain asynchronous serial would be my choice.<br>
<strong>I had a
				look.</strong><br>
To do this I use a AVR mega323 micro, I declined
				offers of logic analyzers being a homebrew type of guy. The 323
				has 2K of internal ram which is enough for some minimalist data
				logging. It was about $50AUS in parts ($30US) to make. I wired a
				cartridge to bring the signals out and took a quick look with a
				voltmeter.<br>
<strong>Nothing!</strong><br>
There was nothing there. I
				expected some power but no, the chips are only powered briefly
				when the are accessed. I used leds to get a rough idea what was
				what and hooked up the micro via resistors to give some degree of
				protection to the printer if I screwed up. The code in the micro
				was written is assembler and captured data sent via rs232 to my
				PC where I wrote a delphi program to display and process the
				data.</p></td></tr>
<tr>
<td colspan="3">
</td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><a href="http://www.eddiem.com/photo/CIS/inkchip/traces.html"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/fastendsml.gif" name="Graphic5" width="615" height="213"></a><br>
<a href="http://www.eddiem.com/photo/CIS/inkchip/traces.html">Click
				here for more traces.</a></p>
<p lang="en-GB">This is the sort of thing I got. No
				protocol I ever seen. Obviously synchronous with bi-directional
				data, very short format. I was confused a little by how short it
				was - because I expect much better precision for the ink
				level.<br>
The traces seem to be.<br>
Top ‚Äì some sort of sync
				line, this always goes low before the start of transmission.<br>
Next
				‚Äì power this goes low (off) between chip reads at printer
				startup but stays high during the shutdown ‚Äì when data is
				written to the chip.<br>
Next ‚Äì the clock, data is read of
				the rising edge and changed on the falling.<br>
Bottom ‚Äì
				bi-directional data, the first 4 bits are always from printer to
				the chip, the rest depend on whether it is a read or write. LSB
				first (left).</p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB">Convert to binary and some patterns emerge.<br>
It
				was not real obvious how the chips were addressed or which bits
				encoded ink levels. Some more data when some ink had been used
				made it easier.</p>
<p lang="en-GB">Below is one chip being read at startup, there
				are 7 accesses one for each chip. Only 3 block have data ‚Äì
				the other chips must be hooked to different data lines.</p>
<div lang="en-GB"><p><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/strtbinary.gif" name="Graphic6" width="818" height="45"></p></div></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB">Below is the complete shutdown stream. Again we
				can only see 3 chips from here.</p>
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/endbinary.gif" name="Graphic7" width="297" height="199"><br clear="left">
After
				printing a few bits near the beginning of the bit stream did
				change. It looks to me like the first 3 bits are the chip address
				the next is a write bit then the ink level, I get the feeling
				there aren't many bits used to encode it (later looks like 6).<br>
So
				‚Äì the top one shows 252 bits of data being read out of the
				chip.<br>
The first part of the shutdown shows just the ink level
				being read out, this is to check the same chip is there.<br>
The
				second part is the ink-level and some other stuff (printer serial
				number maybe) being written into the chip. Seeing I didn't use
				any ink the bit-stream is identical to the read except for bit 3
				‚Äì presumably the write bit.</p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><span size="5"><br>
Tuesday
				24 Sept 2002. I fooled the printer.</span></p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/spoofed.gif" name="Graphic8" width="381" height="363"><span size="3">The
				interesting thing about this screen grab is the black cartridge
				is really only two thirds full. I spoofed the printer by pulling
				the serial data line low during the time the ink level bits are
				being clocked out of the ink chip.<br>
This is means 6 bits
				starting at the 5'th bit in the stream.</span></p>
<p lang="en-GB"><span size="3">The first 3 bits appear to be the
				chip address, I guess the next is a read/write select. I used a
				AVR mega323 to detect the start of the serial transmission look
				for the address of chip1+read (black apparently) then pull data
				low for 6 clock edges. </span></p>
<p lang="en-GB"><span size="3">I'm sure I can reset 3 of the chips
				by tapping into chip1 signal. Reseting the rest will mean tapping
				into at least one more. </span></p>
<p lang="en-GB"><span size="3">The current set up is for
				experimentation only ‚Äì it is not ‚Äúthe real thing‚Äù.</span></p>
<p lang="en-GB"><span size="3">Shorting the data to ground may be a
				bit drastic but it is only for a very brief time. I hoped the
				data line would be open collector but this doesn't seem to be the
				case.</span></p></td></tr></div></div>]]>
            </description>
            <link>http://www.eddiem.com/photo/CIS/inkchip/chip.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054177</guid>
            <pubDate>Wed, 11 Nov 2020 00:41:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nadia Eghbal on working (and writing) in public]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053962">thread link</a>) | @jger15
<br/>
November 10, 2020 | https://www.thepullrequest.com/p/nadia-eghbal | <a href="https://web.archive.org/web/*/https://www.thepullrequest.com/p/nadia-eghbal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg&quot;,&quot;height&quot;:1200,&quot;width&quot;:900,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:399616,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>                                                                                              Portrait by <a href="https://www.katiasobolski.com/">Katia Sobolski</a>.</em></p><p><strong>Nadia Eghbal is uniquely positioned to write about open source having spent almost two years in developer relations at the Alexandrian library of open source, GitHub. She then spent two years continuing her quasi-anthropological study of open source at Protocol Labs, and now works in writer relations at Substack (host of this publication). Her new book is <a href="https://www.amazon.com/Working-Public-Making-Maintenance-Software/dp/0578675862/">Working in Public: The Making and Maintenance of Open Source Software</a>, which like her career trajectory, starts in open source software but ends up grappling with larger issues of creators in an unbundled digital economy. </strong><em><strong><a href="https://pullrequest.substack.com/p/the-glory-of-achievement">The Pull Request</a></strong></em><strong><a href="https://pullrequest.substack.com/p/the-glory-of-achievement"> review is here</a>.</strong></p><p><em>AGM: My naive mental model of open-source was this almost communitarian kibbutz model. And yet, the big lesson from your book is that that‚Äôs not really how it works. </em></p><p>NE: Part of the reason why I wrote this book was because I feel like we've had this communitarian kibbutz kind of model, which you've identified, is the prevailing model that people understand in open source and that gets frequently talked about. And I think that narrative has kind of been owned by the likes of [Richard] Stallman or Eric Raymond or anyone who kind of remembers those early days of open source. And that model definitely still exists within the matrix of different community models. The ‚Äòclubs‚Äô are kind of like that, where everyone is rolling up their sleeves and there's lots of different active contributors. And then we also have  the ‚Äòfederations‚Äô that are kinda like the really big open source projects that we're used to thinking about like Linux, but then there‚Äôs the rise of the ‚Äòstadium‚Äô model that is, I think, much newer.</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png&quot;,&quot;height&quot;:408,&quot;width&quot;:934,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:57769,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>The Eghbal model of open-source communities (referenced copiously here), whose contours are readily applicable more broadly.</em></p><p>If you look at what's happened to open source for the past 20 years, at some point demand outpaced supply and the amount of context that anyone can really have around any one open source project‚Äîbecause every developer is relying on like hundreds of different projects‚Äîit's not really possible to become this roll-up-your-sleeves member of every single project. And so, yeah, I think the governance does look really different and it‚Äôs specifically something that I didn't want to bang people over the head about it in the book. But I think a stadium model lends itself a little bit more to that kind authoritarian model and there‚Äôs less the kind of governance issues that we see in like a federation where people are like <em>this is a democracy!</em> and everyone is gonna ask everyone for opinions and stuff even if you might only have one or a few contributors. The contributors [in a stadium] are kind of just making the decisions and I think they should feel comfortable leaning into that. Even though right now I think a lot of them feel uncomfortable doing that because they keep being told that open source is supposed to this super participatory thing.</p><p><em>AGM: And you think that it doesn't necessarily have to be.</em></p><p>NE: I think the tension in one of these stadium models is where you do have a lot of users. And then you have some of these casual contributors who are opening issues, making feature requests or just lost, and you are kind of sorting through all that volume from people that you don't know. In my view, it's kind of like, well, I don't understand why should that person have a say in your project, if they've never looked at it before, and they're just kind of coming in for the first time and you're the core developer of the project. </p><p>There is a set of rhetoric in open source that says every person is a contributor, and anyone who kind of comes in, you should treat them as a contributor and like invest in them and all this stuff, but I don't feel like we would do that for anything else. If you had a hobby meetup kind of group with you and your friends and someone came in once and then was like <em>I think we should runs a group like this</em>, you'd be like: W<em>ho are you?</em> <em>This is this is our thing. </em>I think I want people to feel more comfortable saying that. And there's obvious parallels between that and the Internet at large right now.</p><p><em>AGM: You took the words right out of my mouth. In the book, you‚Äôve got a long riff on the <a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons">tragedy of the commons</a>. Not that I want to turn this interview into a Facebook thing, because having worked there and spent part of my career on it, it's like the last thing I want to talk about‚Ä¶but I do think it's somewhat relevant in that, Twitter or Facebook, is it actually the public forum and a commons? Can Zuck or Jack run it as you suggest? Can they run it like [Guido] van Rossum does Python, as officially-titled Benevolent Dictator For Life? In some sense that‚Äôs actually better? </em></p><p>NE: Yeah. Well, I don't think Facebook is a commons anymore, just by sheer size that we‚Äôre dealing with. One of the things that I'm trying to do in the book is go back through Elinor Ostrom‚Äôs definition of a commons and saying, okay, she makes the argument that we can avoid this tragedy of the commons by having people self govern. But she has very specific rules that she's laid out around what actually qualifies something as a commons, so we can self govern in a healthy way, assuming these conditions hold and a lot of those conditions have to do with having clear membership boundaries and very high context for your interactions with each other. And so if you think just about Facebook being 2.6 billion people or however many people are on Facebook now, it's impossible that literally multiple billions of people all have that kind of context for each other. I think of Facebook as being this substrate that fosters a bunch of smaller communities. You might have Facebook Messenger which resembles more like the group chats or the ‚Äòclub‚Äô-style communities. You might have the ‚Äòstadium‚Äô type situations that are more like one person broadcasting out to a group of people and you might have Facebook groups which could be like either ‚Äòclubs‚Äô or ‚Äòfederations‚Äô depending how big they are. You actually have a permutation of lots of different types of communities that are across the entire platform. But I think having that kind of vocabulary can help us figure out, what does it actually mean to develop governance for any of these platforms? It's the same thing with Twitter also. I don't see a world where we have one policy or a certain set of guidelines. </p><p><em>AGM: That‚Äôs a somewhat shocking statement.</em></p><p>NE: Yeah, it's so it's funny that that‚Äôs controversial. Part of what I was trying to do in the book is saying like, okay, let's not like talk about social media, let's just talk about this other weird thing called open source. And let's look at the dynamics there and how that's evolved for 20 years. Can you depersonalize this a little bit and if you agree with me that these things seem to be happening in open source. And stacking this up against other economic frameworks we've had in the past, like the commons, and it doesn't seem to hold here, then can we take that conclusion and transfer it back over somewhere else‚Ä¶</p><p><em>AGM: Okay, that's the vibe I got from your book that you were trying to actually talk about the rest of it. So it's good to know that I wasn't over-reading into it. </em></p><p>NE: I was trying to be sensible about it. </p><p><em>AGM: Do you think the push on Facebook for content moderation, and Twitter, is a fool's errand? You know how Kevin Roose and Charles Warzel of </em>The Times<em> and that whole whiny mob that's constantly trying to get them to moderate everything. You think that's probably not the way forward?</em></p><p>NE: It seems beyond not just gonna happen, it seems actively wrong to me. It‚Äôs as though we're asking another country to govern the United States or something. I'm trying to look at where do those governance boundaries start and who should be moderating themselves or not, and just the thought that you would have a sort of widespread platform governance on some of these issues just seems, yeah, morally wrong to me.</p><p><em>AGM: Are you a free-speech absolutist, Nadia, that rarest of breeds?</em></p><p>NE: I'm not super public about my politics, but then I don‚Äôt mind poking my head out a little bit around it and publishing the book was kind of part of this for me because, to be totally frank, there are these democratic kind of ideals and these like communist-y ideals that we are holding about both the Internet and open source which are driving me crazy and, I'm trying to point out, you know, that's not always the case. And sometimes it's about one person who was doing a lot of things and we're just like couching it in a group cooperative. Yeah, I don't really know what my politics are, but I definitely err as far to that side as possible, as I think is reasonable. I do think this kind of moderation stuff, no one really has the answer to it. And so I'm not gonna sit here and be like, <em>I know how to fix it!</em> No one knows how to fix Facebook. Or any of these platforms. There's there's some humility that should be in place there, but I know what I stand for and what I'm aiming for.</p><p><em>AGM: I dislike looking always at the extreme example. But you know, Balaji [Srinivasan] had this whole dust-up with Taylor Lorenz and he's constantly getting into fights with these media people. And it's weird because he's often so right in so many ways, and he's good at getting attention. But somehow he hasn't parlayed into a mainstream following. </em></p><p>NE: I do feel like we need to have institutions a little bit in order to reinforce that. Well, I don't know if that's true or not, because people do follow like Elon Musk or Joe Rogan, or whatever. So that does exist. But I feel it would be so nice that if we had a publication that we could be proud of, that people would read outside of tech. There's no legible symbols for someone else to kind of follow. Like it's even weird that the most popular tech figures are not always the most popular figures actually in tech. Like Mark Cuban ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thepullrequest.com/p/nadia-eghbal">https://www.thepullrequest.com/p/nadia-eghbal</a></em></p>]]>
            </description>
            <link>https://www.thepullrequest.com/p/nadia-eghbal</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053962</guid>
            <pubDate>Wed, 11 Nov 2020 00:16:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analyzing Voting Systems]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053892">thread link</a>) | @shihn
<br/>
November 10, 2020 | https://shihn.ca/posts/2020/voting-systems/ | <a href="https://web.archive.org/web/*/https://shihn.ca/posts/2020/voting-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      
<h2>Introduction</h2>
<p>We encounter voting in some form around us all the time. We rate our Uber drivers, they rate us back. We up-vote and down-vote posts and trolls on Reddit. We give stars to movies and restaurants. We vote on who gets kicked out of our favorite reality television show. We vote for Presidents.</p>
<p>All these voting systems seem a bit different from one another, but one thing that's definitely common among them ‚Äî we will find ways to complain about them. The way a voting system is designed can make an <em>election</em> trivial or really complicated in nature. In fact, sometimes, the winner of an election may be determined by the rules of the voting system and not the intent of the voters (electoral college anyone?). In this post I try to explore the core of different voting systems and wonder if there is a perfect voting system.</p>
<p>Here I am going to use the word <em>election</em> to define an event or a goal that requires voting. An election doesn't have to be political in nature.</p>
<p><em>Note and Acknowledgement: This blog post is influenced by the chapter on voting systems in video games in the book Power-Up by Matthew Lane.</em></p>
<h2>Plurality Voting</h2>
<p>This is the simplest form of voting. Most political elections in the United States are done using this form of voting. It's quite simple ‚Äî every voter casts a vote for their favorite candidate. The candidate with the most number of votes wins.</p>
<p>Let's look at an example that we will continue to use in this post. We ask 100 people to vote for their favorite flavor of ice cream. The candidates are <em>Vanilla</em>, <em>Chocolate</em>, and <em>Strawberry</em>. Here's the result:</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>45</td>
</tr>
<tr>
<td>Chocolate</td>
<td>40</td>
</tr>
<tr>
<td>Strawberry</td>
<td>15</td>
</tr>
</tbody>
</table>
<p><strong>Vanilla has won!</strong> Now if you stare at the numbers a bit, you will find some downsides in declaring Vanilla the winner in this election of the flavors.</p>
<p>An obvious one is that more votes were cast for a flavor that is not the winning flavor. You could also argue that no flavor should win because none of them reached a majority.</p>
<p>Here Strawberry is acting as a <strong>spoiler</strong> ‚Äî similar to how third-party candidates in US elections can be considered spoilers. Maybe we should have a <strong><em>run-off election</em></strong> where only Vanilla and Chocolate are considered. Perhaps more people favor Chocolate over Vanilla when Strawberry is out of the picture. (The US state of Georgia has rules akin to this. In the 2020 elections for the senate seats in Georgia, none of the candidates achieved a majority. So run-off elections will be held in January of 2021 with the top two candidates).</p>
<p>The essence of the Plurality voting system is that it does not capture the full spectrum of voters' preferences. If someone voted for Strawberry, it does not tell us how they feel about Vanilla or Chocolate.</p>
<p>This system does not truly determine the <em>'will of the people'</em>, unless.... there are only two candidates. One of the candidates is guaranteed to receive a majority, barring a tie. So if it were truly a <em>two-party system</em> some of the flaws of this system do not matter any more.</p>
<h2>Ranked Choice Voting</h2>
<p>Since the Plurality based system does not capture the full spectrum of the voter's preferences, we should probably ask for more information from the voters. What if we asked the voters to rank all the candidates, rather than cast a ballot for their favorite?</p>
<p>Let's look at the example we've been working with. We asked the 100 people to rank the candidate flavors. Here's the result:</p>
<table>
<thead>
<tr>
<th>1st</th>
<th>2nd</th>
<th>3rd</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>Strawberry</td>
<td>Chocolate</td>
<td>45</td>
</tr>
<tr>
<td>Strawberry</td>
<td>Chocolate</td>
<td>Vanilla</td>
<td>15</td>
</tr>
<tr>
<td>Chocolate</td>
<td>Strawberry</td>
<td>Vanilla</td>
<td>30</td>
</tr>
<tr>
<td>Chocolate</td>
<td>Vanilla</td>
<td>Strawberry</td>
<td>10</td>
</tr>
</tbody>
</table>
<p>All of the 45 people who voted for Vanilla had Strawberry as the second choice. All 15 people who voted for Strawberry, had Chocolate as their second choice. Of the 40 people who voted for Chocolate, 30 preferred Strawberry over Vanilla, and 10 preferred Vanilla. So, which flavor won? There are multiple ways to interpret this data. Let's look at a couple üëá</p>
<h2>Borda Count</h2>
<p>In this system for <code>n</code> candidates, each first-place vote receives <code>n</code> points. Second-place receives <code>n-1</code> points, and so on. The candidate with the most points wins.</p>
<p>Let's compute the points in our example. Vanilla received 45 first places, 10 second places, and 45 third places. So the score for Vanilla is <code>45n + 10(n-1) + 45(n-2)</code>. Here, <code>n</code> is <code>3</code>, giving Vanilla a score of <code>200</code>. Here's the final tally:</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Points</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>200</td>
</tr>
<tr>
<td>Chocolate</td>
<td>195</td>
</tr>
<tr>
<td>Strawberry</td>
<td>205</td>
</tr>
</tbody>
</table>
<p><strong>Strawberry has won!</strong> Strawberry, which had the fewest votes in the Plurality voting system, has the most points in the Borda ranking system. Totally ridiculous, isn't it? Well maybe, but maybe not. Strawberry did receive the fewest third-place votes. And 75% of the people had Strawberry as their second choice.  Perhaps Strawberry does deserve to win!</p>
<h2>Instant Runoff Voting</h2>
<p>Let's take a look at a different model of interpreting the ranked voting data. In an Instant Runoff, the candidate with the fewest first-place votes is eliminated, and its votes are distributed to the second choice. This is then repeated until we have one candidate left standing.</p>
<p>Some consider this model of iterative elimination a bit confusing and thereby not practical. But it's getting wide adoption, including in political elections (San Francisco and Oakland city elections, for example). It is also used to decide the winner of the Best Picture Academy Award.</p>
<p>Let's apply this to our current example.</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>45</td>
</tr>
<tr>
<td>Chocolate</td>
<td>40</td>
</tr>
<tr>
<td>Strawberry (eliminated)</td>
<td>15</td>
</tr>
</tbody>
</table>
<p>Strawberry is eliminated. Since all Strawberry voters preferred Chocolate over Vanilla, Chocolate gets Strawberry's 15 votes. Chocolate now has 55 votes, a majority. <strong>Chocolate has won!</strong></p>
<h2>Quick Recap</h2>
<p>We have discussed three systems so far, and in our example, we have had three different winners for the same election. You may decide subjectively that one of these systems may be better for the use case you have in mind, or you might think as I did at first: <strong>It's all pointless!</strong></p>
<h2>The Impossibility</h2>
<p>There is a concept in decision theory called the <strong><a href="https://en.wikipedia.org/wiki/Independence_of_irrelevant_alternatives">Independence of Irrelevant Alternatives (IIA)</a></strong> which states a voter's preference between two choices <code>x</code> and <code>y</code>, should not depend on any other choices.</p>
<p>This seems like a simple and a good rule to live by and our election systems should live by them as well. Sadly, all the systems we have looked at so far do not abide by this rule.</p>
<p>Let's look at the Plurality system - From the rankings we know that all of Strawberry voters prefer Chocolate over Vanilla. If the choice of Strawberry was not there, Chocolate would have won with 55 votes. But with Strawberry present, Vanilla wins with 45 votes.</p>
<p>For the Borda system, Chocolate is the spoiler. With Chocolate in the picture, Strawberry wins. Without Chocolate, Vanilla wins 55-45.</p>
<p>In the Instant Runoff, Chocolate wins when Vanilla is present but Strawberry wins 60-40 if Vanilla is not.</p>
<h3>Arrow's Impossibility Theorem</h3>
<p>In decision theory, here are some good things to have in an election or any voting system.</p>
<ul>
<li>Independence of Irrelevant Alternatives: which we have discussed and failed to account for so far.</li>
<li>Nondictatorship: Output should not be based on one individual, the wishes of multiple voters should be taken into consideration.</li>
<li>Pareto Efficiency (Unanimity): should have a notion of <a href="https://en.wikipedia.org/wiki/Pareto_efficiency">unanimity</a> ‚Äî If every voter prefers candidate A over candidate B, candidate A should win.</li>
<li>Unrestricted Domain: Voting must account for all individual preferences.</li>
<li>Ordering:  Each individual should be able to order the choices in any way.</li>
</ul>
<p>All good rules, don't you think? Let's create the ultimate voting system! But here comes <a href="https://en.wikipedia.org/wiki/Kenneth_Arrow">Kenneth Arrow</a> to shatter our hopes.</p>
<p><strong><a href="https://en.wikipedia.org/wiki/Arrow's_impossibility_theorem">Arrow's Impossibility Theorem</a> states that in all cases where preferences are ranked, it is impossible to formulate a social ordering without violating one of these rules.</strong></p>
<p>In other words, any democracy that satisfies Unanimity and the Independence of Irrelevant Alternatives, must be a dictatorship! *<em>insert dramatic sound effects</em>*</p>
<p>So yeah, we will always find things to argue about in an election. üòí</p>
<h2>Dodging the Impossibility</h2>
<p>Since every system is flawed, is it the end of this essay? Unfortunately for you, I, like many of you, noticed this one clause in Arrow's impossibility theorem which provides a way for us to escape this gravity well.</p>
<p>The theorem assumes that we are dealing with a ranked choice voting system. Let's just not rank our candidates. üí°</p>
<p>Here I would remind you, that we're trying to look at voting systems in general, not just political elections.</p>
<p>We have implemented non rank based systems in Software numerous times. Think Netflix, Yelp, Reddit, Tinder. The key as you may have guessed is rating, and not ranking (Tinder being a more specific type of rating - approval voting, which I'll discuss later). A voting system based on rating is usually called <strong>Score Voting</strong>.</p>
<h2>Score Voting</h2>
<p>The idea behind score voting is that you give each candidate a score in one or many categories. This score is independent of the score the other candidates receive. Think Diving and Gymnastics in the Olympics. The judges rate each athlete based on form, routine, landings. One with the highest total score wins.</p>
<p>But is this system better? That's subjective but we know it lets us escape the impossibility mathematically, and yet conform to independence, unanimity and nondictatorship rules.</p>
<h2>Approval Voting</h2>
<p>There's a simpler form or Score Voting - Approval Voting. Think of it as a binary version of the score voting. Each person can give a candidate a score of <code>0</code> or <code>1</code>. In other words one can approve or disapprove any number of candidates.</p>
<p>This is similar to how people vote on dating apps like Tinder. They give prospects a score of <code>1</code> by swiping right, and a score of <code>0</code> by swiping left.</p>
<h2>Strategizing the Ranked Vote</h2>
<p>One key advantage for Score Voting and Approval Voting is that it never hurts to vote for your favorite candidate. It may seem obvious and trivial but it's not always satisfied by voting systems. For example, it is common in political elections for people to not vote for the third-party candidate even though the third-party candidate may be the voter's first ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shihn.ca/posts/2020/voting-systems/">https://shihn.ca/posts/2020/voting-systems/</a></em></p>]]>
            </description>
            <link>https://shihn.ca/posts/2020/voting-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053892</guid>
            <pubDate>Wed, 11 Nov 2020 00:09:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Frontload: Simple full-stack data loading for React]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053845">thread link</a>) | @davnicwil
<br/>
November 10, 2020 | https://davnicwil.com/react-frontload/ | <a href="https://web.archive.org/web/*/https://davnicwil.com/react-frontload/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactroot="" data-reactid="1" data-react-checksum="1067123220"><div data-reactid="6"><div data-reactid="7"><p><img src="https://davnicwil.com/image/react-frontload-logo.png" width="100" height="100" data-reactid="8"></p></div><p data-reactid="10"><h2 data-reactid="11">Simple full-stack data loading for React</h2></p><p><a href="https://www.npmjs.com/package/react-frontload" data-reactid="13"><img src="https://img.shields.io/npm/v/react-frontload?style=social&amp;logo=npm" data-reactid="14"></a><a href="https://github.com/davnicwil/react-frontload" data-reactid="15"><img src="https://img.shields.io/github/stars/davnicwil/react-frontload?style=social" data-reactid="16"></a><a href="https://www.npmjs.com/package/react-frontload" data-reactid="17"><img src="https://img.shields.io/npm/dm/react-frontload?style=social" data-reactid="18"></a><a href="https://twitter.com/davnicwil" data-reactid="19"><img src="https://img.shields.io/twitter/url?label=made%20by%20%40davnicwil&amp;style=social&amp;url=https%3A%2F%2Fdavnicwil.com" data-reactid="20"></a></p></div><p data-reactid="21">React Frontload is a library to load and manage data inline in React components that works on both client and server.</p><div data-reactid="22"><ul data-reactid="23"><li data-reactid="24"><span data-reactid="25">Load data with a hook which works on client and server</span></li><li data-reactid="26"><span data-reactid="27">Data is managed in component state - no need for Redux / MobX</span></li><li data-reactid="28"><span data-reactid="29">Written in TypeScript, typing is easy as everything's inline</span></li><li data-reactid="30"><span data-reactid="31">Less than 3.5KB Gzipped, zero dependencies</span></li></ul></div><div data-reactid="32"><div data-reactid="33"><!-- react-text: 34 --><p>v2 has just shipped! </p><!-- /react-text --><p><a href="https://davnicwil.com/react-frontload/v2" data-reactid="35">See here</a></p><!-- react-text: 36 --><p> for the motivation for v2 and comparison with v1</p><!-- /react-text --></div></div><div data-reactid="37"><p>Install</p><p>npm install react-frontload</p></div><div id="problem" data-reactid="53"><h3 data-reactid="54">What problem does this solve?</h3><p><a href="#problem" data-reactid="55">#</a></p></div><p data-reactid="56">React provides no built-in way to do data loading - it's left for you to implement. Doing this is tricky in a React app that uses server side rendering (SSR) because client and server rendering work quite differently: Client render is async so data can be loaded inside components when they render, but server render is completely synchronous - the data must be loaded before render happens.</p><p data-reactid="57">Data loading is, of course, async. The client component-centric data loading pattern is nice, but it's incompatible with synchronous server render. React simply has no mechanism to wait for data to load when components render on SSR. There's a further problem too: React also provides no built-in way to hydrate data loaded during SSR into client state on first render. This is also up to you to implement.</p><p data-reactid="58">So, full stack data loading in React is a tricky problem. A couple of solutions have emerged:</p><ol data-reactid="59"><li data-reactid="60"><p data-reactid="61">Load data at the route level, instead of the component level, then pass data to all components under the route. Works on SSR since the route is known in the request, so data can be loaded before render begins. Can be implemented by piecing together router and state manager libraries.</p></li><li data-reactid="62"><p data-reactid="63">Use a framework that wraps React and abstracts the problem away, perhaps by providing a framework-specific async data loading function for components that works on SSR, and also takes care of hydrating state on the client.</p></li></ol><p data-reactid="64">React Frontload aims to provide a third way - the component-centric data loading pattern available full stack, but without having to buy into a whole framework just to get this feature. It's just a small library that solves this one problem, and can be used in any React stack.</p><p data-reactid="68">Here's an example of loading data into a component with React Frontload</p><p><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span>
    stuff<span>:</span> <span>await</span> api<span>.</span><span>getStuff</span><span>(</span><span>)</span>
  <span>}</span><span>)</span><span>)</span>

  <span>if</span> <span>(</span>frontloadMeta<span>.</span>pending<span>)</span> <span>return</span> <span>&lt;</span>div<span>&gt;</span>loading<span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>if</span> <span>(</span>frontloadMeta<span>.</span>error<span>)</span>   <span>return</span> <span>&lt;</span>div<span>&gt;</span>error<span>&lt;</span><span>/</span>div<span>&gt;</span>

  <span>return</span> <span>&lt;</span>div<span>&gt;</span><span>{</span>data<span>.</span>stuff<span>}</span><span>&lt;</span><span>/</span>div<span>&gt;</span>
<span>}</span>
</p><p data-reactid="70"><!-- react-text: 71 -->Here we have a <!-- /react-text --><span data-reactid="72">Component</span><!-- react-text: 73 --> that needs to load <!-- /react-text --><span data-reactid="74">stuff</span><!-- react-text: 75 --> from an API, with the usual loading state whilst it loads and some sort of error state if loading fails for some reason.<!-- /react-text --></p><p data-reactid="76"><!-- react-text: 77 -->With React Frontload, we do this by passing an async data loading function to the <!-- /react-text --><span data-reactid="78">useFrontload</span><!-- react-text: 79 --> hook. The hook loads the return value of the function into<!-- /react-text --><!-- react-text: 80 --> <!-- /react-text --><span data-reactid="81">data</span><!-- react-text: 82 -->, and gives us<!-- /react-text --><!-- react-text: 83 --> <!-- /react-text --><span data-reactid="84">frontloadMetadata</span><!-- react-text: 85 --> out the box so we can see when it's still <!-- /react-text --><span data-reactid="86">pending</span><!-- react-text: 87 --> or if an <!-- /react-text --><span data-reactid="88">error</span><!-- react-text: 89 --> is thrown when running the function.<!-- /react-text --></p><p data-reactid="90"><!-- react-text: 91 -->That's it - we're done in those few lines of code. That's the power of doing data loading inline in a component. And the best part here is that this just works on the server. If we render<!-- /react-text --><!-- react-text: 92 --> <!-- /react-text --><span data-reactid="93">Component</span><!-- react-text: 94 --> in a route, any route,<!-- /react-text --><!-- react-text: 95 --> <!-- /react-text --><span data-reactid="96">stuff</span><!-- react-text: 97 --> will load.<!-- /react-text --></p><p data-reactid="98"><!-- react-text: 99 -->To emphasise the ease and lack of plumbing involved in making changes, let's have <!-- /react-text --><span data-reactid="100">Component</span><!-- react-text: 101 --> load some more stuff:<!-- /react-text --></p><p><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span>
    stuff<span>:</span> <span>await</span> api<span>.</span><span>getStuff</span><span>(</span><span>)</span><span>,</span>
    moreStuff<span>:</span> <span>await</span> api<span>.</span><span>getMoreStuff</span><span>(</span><span>)</span> 
  <span>}</span><span>)</span><span>)</span>

  <span>if</span> <span>(</span>frontloadMeta<span>.</span>pending<span>)</span> <span>return</span> <span>&lt;</span>div<span>&gt;</span>loading<span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>if</span> <span>(</span>frontloadMeta<span>.</span>error<span>)</span>   <span>return</span> <span>&lt;</span>div<span>&gt;</span>error<span>&lt;</span><span>/</span>div<span>&gt;</span>

  <span>return</span> <span>&lt;</span>div<span>&gt;</span><span>{</span>data<span>.</span>stuff<span>}</span> and <span>{</span>data<span>.</span>moreStuff<span>}</span><span>&lt;</span><span>/</span>div<span>&gt;</span> 
<span>}</span>
</p><p data-reactid="103"><!-- react-text: 104 -->It's literally that simple - just add whatever you need to<!-- /react-text --><!-- react-text: 105 --> <!-- /react-text --><span data-reactid="106">useFrontload</span><!-- react-text: 107 --> and use it. Remember that this is all automatically typed. If the value returned by the<!-- /react-text --><!-- react-text: 108 --> <!-- /react-text --><span data-reactid="109">getMoreStuff</span><!-- react-text: 110 --> api call is a<!-- /react-text --><span data-reactid="111">string</span><!-- react-text: 112 -->,<!-- /react-text --><!-- react-text: 113 --> <!-- /react-text --><span data-reactid="114">data.moreStuff</span><!-- react-text: 115 --> has the string type, and you'll get errors if you try to use it as a number.<!-- /react-text --></p><p data-reactid="116"><!-- react-text: 117 -->You may have noticed that the above code loads data less efficiently than it could. <!-- /react-text --><span data-reactid="118">api.getStuff()</span><!-- react-text: 119 --> and<!-- /react-text --><!-- react-text: 120 --> <!-- /react-text --><span data-reactid="121">api.getMoreStuff()</span><!-- react-text: 122 --> are called in serial, when they could probably be called in parallel. Since it's just Javascript, though, we can change this:<!-- /react-text --></p><p><span>const</span> <span>{</span> data<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>[</span>stuff<span>,</span> moreStuff<span>]</span> <span>=</span> Promise<span>.</span><span>all</span><span>(</span><span>[</span>
    api<span>.</span><span>getStuff</span><span>(</span><span>)</span><span>,</span>
    api<span>.</span><span>getMoreStuff</span><span>(</span><span>)</span>
  <span>]</span><span>)</span>

  <span>return</span> <span>{</span> stuff<span>,</span> moreStuff <span>}</span>
<span>}</span><span>)</span>
</p><p data-reactid="124">In fact as data loaders get more complex, you can use any combination of serial and parallel that you need. It's just Javascript - you have the full power of the language without any abstractions or misdirection on top.</p><p data-reactid="125"><!-- react-text: 126 -->There is one more piece to this - what about updating data? Since React Frontload uses React component state to hold<!-- /react-text --><!-- react-text: 127 --> <!-- /react-text --><span data-reactid="128">data</span><!-- react-text: 129 -->, updating it is just a case of updating that state. React Frontload provides another function, called<!-- /react-text --><!-- react-text: 130 --> <!-- /react-text --><span data-reactid="131">setData</span><!-- react-text: 132 -->, for this:<!-- /react-text --></p><p><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> setData<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span>
    stuff<span>:</span> <span>await</span> api<span>.</span><span>getStuff</span><span>(</span><span>)</span>
  <span>}</span><span>)</span><span>)</span>

  <span>if</span> <span>(</span>frontloadMeta<span>.</span>pending<span>)</span> <span>return</span> <span>&lt;</span>div<span>&gt;</span>loading<span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>if</span> <span>(</span>frontloadMeta<span>.</span>error<span>)</span>   <span>return</span> <span>&lt;</span>div<span>&gt;</span>error<span>&lt;</span><span>/</span>div<span>&gt;</span>

  <span>const</span> <span>updateStuff</span> <span>=</span> <span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>try</span> <span>{</span>
      <span>const</span> updatedStuff <span>=</span> <span>await</span> <span>updateStuff</span><span>(</span><span>'new value'</span><span>)</span> 
      <span>setData</span><span>(</span><span>data</span> <span>=&gt;</span> <span>(</span><span>{</span> <span>...</span>data<span>,</span> stuff<span>:</span> updatedStuff <span>}</span><span>)</span><span>)</span> 
    <span>}</span> <span>catch</span> <span>{</span>
      
    <span>}</span>
  <span>}</span>

  <span>return</span> <span>(</span>
    <span>&lt;</span><span>&gt;</span>
      <span>&lt;</span>div<span>&gt;</span><span>{</span>data<span>.</span>stuff<span>}</span><span>&lt;</span><span>/</span>div<span>&gt;</span>
      <span>&lt;</span>button onClick<span>=</span><span>{</span>updateStuff<span>}</span><span>&gt;</span>update<span>&lt;</span><span>/</span>button<span>&gt;</span>
    <span>&lt;</span><span>&gt;</span>
  <span>)</span>
</p><p data-reactid="134"><!-- react-text: 135 -->Again, this is all just inline in the component with zero plumbing. If you're coming from Redux, you can think of<!-- /react-text --><!-- react-text: 136 --> <!-- /react-text --><span data-reactid="137">setData</span><!-- react-text: 138 --> a little bit like a mini reducer. It takes the existing value of<!-- /react-text --><!-- react-text: 139 --> <!-- /react-text --><span data-reactid="140">data</span><!-- react-text: 141 --> as an argument, and you merge updates into it to return an updated value of<!-- /react-text --><!-- react-text: 142 --> <!-- /react-text --><span data-reactid="143">data</span><!-- react-text: 144 -->.<!-- /react-text --></p><p data-reactid="145">And that's it - full stack data loading and management inline in your React components.</p><p data-reactid="149"><!-- react-text: 150 -->The <!-- /react-text --><span data-reactid="151">useEffect</span><!-- react-text: 152 --> hook seen in the example above is the core of React Frontload - the code you'll actually work with in your components - but there is also a small amount of one-time setup code to write to get it to work.<!-- /react-text --></p><p data-reactid="153"><!-- react-text: 154 -->Essentially this is setting up wrappers around your server render logic, and your React application on both server and client, to make the<!-- /react-text --><span data-reactid="155">useFrontload</span><!-- react-text: 156 --> hook work, and also enable hydration of state loaded on server render to the client.<!-- /react-text --></p><p data-reactid="157">App Provider</p><p data-reactid="158">Wrap your app in the React Frontload provider</p><p><span>import</span> <span>{</span> FrontloadProvider <span>}</span> <span>from</span> <span>'react-frontload'</span>

<span>const</span> <span>App</span> <span>=</span> <span>(</span><span><span>{</span> frontloadState <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span>
  <span>&lt;</span>FrontloadProvider initialState<span>=</span><span>{</span>frontloadState<span>}</span><span>&gt;</span>
    <span>&lt;</span>Content<span>&gt;</span><span>...</span><span>&lt;</span><span>/</span>Content<span>&gt;</span>
  <span>&lt;</span><span>/</span>FrontloadProvider<span>&gt;</span>
<span>)</span>
</p><p data-reactid="160">Server render</p><p data-reactid="161"><!-- react-text: 162 -->On server render, you need to wrap your existing synchronous server render code with<!-- /react-text --><!-- react-text: 163 --> <!-- /react-text --><span data-reactid="164">reactFrontloadServerRender</span><!-- react-text: 165 -->.<!-- /react-text --></p><p data-reactid="166"><!-- react-text: 167 -->You can think of this as the polyfill that allows React Frontload to load data asynchronously on server render. It just uses regular React server rendering under the hood, and its output is exactly the same. Read more about this <!-- /react-text --><a href="#how-it-works" data-reactid="168">here</a><!-- react-text: 169 -->.<!-- /react-text --></p><p><span>import</span> <span>{</span> renderToString <span>}</span> <span>from</span> <span>'react-dom/server'</span>
<span>import</span> <span>{</span> createFrontloadState<span>,</span> frontloadServerRender <span>}</span> <span>from</span> <span>'react-frontload'</span>
<span>import</span> serverApi <span>from</span> <span>'./serverApi'</span>

app<span>.</span><span>get</span><span>(</span><span>'*'</span><span>,</span> <span>async</span> <span>(</span><span>req<span>,</span> res</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>...</span>

  
  
  <span>const</span> frontloadState <span>=</span> createFrontloadState<span>.</span><span>server</span><span>(</span><span>{</span>
    
    
    
    context<span>:</span> <span>{</span> api<span>:</span> serverApi <span>}</span>
  <span>}</span><span>)</span>

  <span>try</span> <span>{</span>
    
    <span>const</span> <span>{</span> rendered<span>,</span> data <span>}</span> <span>=</span> <span>await</span> <span>frontloadServerRender</span><span>(</span><span>{</span>
      frontloadState<span>,</span>
      <span>render</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>renderToString</span><span>(</span><span>&lt;</span>App frontloadState<span>=</span><span>{</span>frontloadState<span>}</span> <span>/</span><span>&gt;</span><span>)</span>
    <span>}</span><span>)</span>

    res<span>.</span><span>send</span><span>(</span><span><span>`</span><span>
      &lt;html&gt;
        ...
        &lt;!-- server rendered markup --&gt;
        </span><span><span>${</span>rendered<span>}</span></span><span>

        &lt;!-- loaded data (to be hydrated on client) --&gt;
        &lt;script&gt;window._frontloadData=</span><span><span>${</span><span>toSanitizedJSON</span><span>(</span>data<span>)</span><span>}</span></span><span>&lt;/script&gt;
        ...
      &lt;/html&gt;
    </span><span>`</span></span><span>)</span>
  <span>}</span> <span>catch</span> <span>(</span>err<span>)</span> <span>{</span>
    
  <span>}</span>
<span>}</span><span>)</span>
</p><p data-reactid="171"><!-- react-text: 172 -->The output of<!-- /react-text --><!-- react-text: 173 --> <!-- /react-text --><span data-reactid="174">reactFrontloadServerRender</span><!-- react-text: 175 --> contains a <!-- /react-text --><span data-reactid="176">rendered</span><!-- react-text: 177 --> string, which is just the server render output to inject into your HTML template as usual.<!-- /react-text --></p><p data-reactid="178"><!-- react-text: 179 -->It also contains a <!-- /react-text --><span data-reactid="180">data</span><!-- react-text: 181 --> object, which you should serialize into your HTML as sanitised JSON.<!-- /react-text --><!-- react-text: 182 --> <!-- /react-text --><span data-reactid="183">data</span><!-- react-text: 184 --> contains all the data loaded for the current view across all components, and the purpose of this is to hydrate this data into React Frontload on the client (using<!-- /react-text --><!-- react-text: 185 --> <!-- /react-text --><span data-reactid="186">initialState</span><!-- react-text: 187 -->) so that it does not have to be reloaded on first render. This pattern is essentially the same as the one you see with other state managers such as Redux.<!-- /react-text --></p><p data-reactid="188">Client render</p><p data-reactid="189">The last remaining step is client integration, which is rather simpler. Just initialise a React Frontload state object on the client using your serialized data from server render, and pass it to the provider.</p><p><span>import</span> clientApi <span>from</span> <span>'./clientApi'</span>

<span>const</span> frontloadState <span>=</span> createFrontloadState<span>.</span><span>client</span><span>(</span><span>{</span>
  
  
  context<span>:</span> <span>{</span> api<span>:</span> clientApi <span>}</span><span>,</span>

  
  serverRenderedData<span>:</span> window<span>.</span>_frontloadData
<span>}</span><span>)</span>
<span>...</span>
ReactDOM<span>.</span><span>render</span><span>(</span><span>&lt;</span>App frontloadState<span>=</span><span>{</span>frontloadState<span>}</span> <span>/</span><span>&gt;</span><span>,</span> <span>...</span><span>)</span>
</p><p data-reactid="194">For most usecases, you don't need to care about this.</p><p data-reactid="195">That said, all abstractions are leaky at some point, and it's always useful to understand how things work under the hood so that when they behave unexpectedly, you can figure out why.</p><p data-reactid="196">The mechanism used to polyfill async on server render is deliberately very simple. As shown in the code above, React Frontload wraps ordinary synchronous server render code with an async function.</p><p data-reactid="197"><!-- react-text: 198 -->It works by running that synchronous function, and collecting the promises encountered on each render of a<!-- /react-text --><!-- react-text: 199 --> <!-- /react-text --><span data-reactid="200">useFrontload</span><!-- react-text: 201 --> hook. After the render, the collected promises are then awaited, which loads the data in those functions the same as it would be on the client. Now, React Frontload runs the server render again - this time injecting the data loaded from the previous run into each component ahead of the render. In this new render round, if no new<!-- /react-text --><!-- react-text: 202 --> <!-- /react-text --><span data-reactid="203">useFrontload</span><!-- react-text: 204 --> hooks are encountered (i.e. if there are no nested components with a<!-- /react-text --><!-- react-text: 205 --> <!-- /react-text --><span data-reactid="206">useFrontload</span><!-- react-text: 207 --> hook), then the output of this render is returned as the final output. If nested<!-- /react-text --><!-- react-text: 208 --> <!-- /react-text --><span data-reactid="209">useFrontload</span><!-- react-text: 210 --> hooks<!-- /react-text --><!-- react-text: 211 --> <!-- /react-text --><span data-reactid="212">are</span><!-- react-text: 213 --> found, the process repeats.<!-- /react-text --></p><ul id="api-useFrontload" data-reactid="225"><li data-reactid="226"><span data-reactid="227">useFrontload</span><a href="#api-useFrontload" data-reactid="228">#</a></li></ul><p data-reactid="229"><span data-reactid="230">useFrontload</span><!-- react-text: 231 --> is the React Frontload hook.<!-- /react-text --></p><p><span>import</span> <span>{</span> useFrontload <span>}</span> <span>from</span> <span>'react-frontload'</span>

<span>useFrontload</span><span>(</span>
  ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davnicwil.com/react-frontload/">https://davnicwil.com/react-frontload/</a></em></p>]]>
            </description>
            <link>https://davnicwil.com/react-frontload/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053845</guid>
            <pubDate>Wed, 11 Nov 2020 00:03:34 GMT</pubDate>
        </item>
    </channel>
</rss>
