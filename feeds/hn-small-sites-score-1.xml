<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 31 Oct 2020 20:16:30 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 31 Oct 2020 20:16:30 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Show HN: Backtest Trading Strategies: A Quantopian Alternative]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24940644">thread link</a>) | @hydershykh
<br/>
October 30, 2020 | https://www.tradytics.com/backtester | <a href="https://web.archive.org/web/*/https://www.tradytics.com/backtester">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <div>
          <p>
            <h4>Trading Strategies Backtester</h4>
            <h5>Backtest your favorite technical analysis based strategies with our backtester.</h5>
          </p>
          
        </div>

        <div>
          

          <div>
            <div>
              <p>
                <h5>Buy Strategy</h5>
              </p>
              <div>
                <div>
                  
                  <div aria-labelledby="dropdownMenuButtonBuy">
                    <p onclick="make_current_ta('RSI')">RSI</p>
                    <p onclick="make_current_ta('CCI')">CCI</p>
                    <p onclick="make_current_ta('MFI')">MFI</p>
                    <p onclick="make_current_ta('MACD')">MACD</p>
                    <p onclick="make_current_ta('ATR')">ATR</p>
                    <p onclick="make_current_ta('ADX')">ADX</p>
                    <p onclick="make_current_ta('STOCHS')">STOCHS</p>
                  </div>
                </div>
                
                
                </div>
              <div>
                <h6>Pre-made</h6>
                <div>
                  <div aria-labelledby="dropdownMenuButtonPremade">
                    <p onclick="make_current_strategy('EMA9 > EMA20')">9EMA &gt; 20EMA</p>
                    <p onclick="make_current_strategy('EMA20 > EMA50')">20EMA &gt; 50EMA</p>
                    <p onclick="make_current_strategy('EMA9 < EMA20')">9EMA &lt; 20EMA</p>
                    <p onclick="make_current_strategy('EMA20 < EMA50')">20EMA &lt; 50EMA</p>
                    <p onclick="make_current_strategy('EMA20 > Price')">20EMA &gt; Price</p>
                    <p onclick="make_current_strategy('EMA50 > Price')">50EMA &gt; Price</p>
                    <p onclick="make_current_strategy('EMA20 < Price')">20EMA &lt; Price</p>
                    <p onclick="make_current_strategy('EMA50 < Price')">50EMA &lt; Price</p>
                    <p onclick="make_current_strategy('obv_slope > 0')">Pos OBV Slope</p>
                    <p onclick="make_current_strategy('obv_slope < 0')">Neg OBV Slope</p>
                    <p onclick="make_current_strategy('VWAP > Price')">VWAP &gt; Price</p>
                    <p onclick="make_current_strategy('VWAP < Price')">VWAP &lt; Price</p>
                    <p onclick="make_current_strategy('SIGNAL > MACD')">Signal &gt; MACD</p>
                    <p onclick="make_current_strategy('SIGNAL < MACD')">Signal &lt; MACD</p>
                    <p onclick="make_current_strategy('hband > Price')">UpperBollinger &gt; Price</p>
                    <p onclick="make_current_strategy('lband < Price')">LowerBollinger &lt; Price</p>
                    <!--<p class="dropdown-item" onclick="make_current_strategy('At Support')">At Support</p>
                    <p class="dropdown-item" onclick="make_current_strategy('At Resistance')">At Resistance</p>-->
                  </div>
                </div>
                </div>
            </div>
          </div>



          <div>
            <div>
              <p>
                <h5>Sell Strategy</h5>
              </p>
              <div>
                <div>
                  
                  <div aria-labelledby="dropdownMenuButtonSell">
                    <p onclick="make_current_ta_sell('RSI')">RSI</p>
                    <p onclick="make_current_ta_sell('CCI')">CCI</p>
                    <p onclick="make_current_ta_sell('MFI')">MFI</p>
                    <p onclick="make_current_ta_sell('MACD')">MACD</p>
                    <p onclick="make_current_ta_sell('ATR')">ATR</p>
                    <p onclick="make_current_ta_sell('ADX')">ADX</p>
                    <p onclick="make_current_ta_sell('STOCHS')">STOCHS</p>
                  </div>
                </div>
                
                
                </div>
              <div>
                <h6>Pre-made</h6>
                <div>
                  <div aria-labelledby="dropdownMenuButtonPremadeSell">
                    <p onclick="make_current_strategy_sell('EMA9 > EMA20')">9EMA &gt; 20EMA</p>
                    <p onclick="make_current_strategy_sell('EMA20 > EMA50')">20EMA &gt; 50EMA</p>
                    <p onclick="make_current_strategy_sell('EMA9 < EMA20')">9EMA &lt; 20EMA</p>
                    <p onclick="make_current_strategy_sell('EMA20 < EMA50')">20EMA &lt; 50EMA</p>
                    <p onclick="make_current_strategy_sell('EMA20 > Price')">20EMA &gt; Price</p>
                    <p onclick="make_current_strategy_sell('EMA50 > Price')">50EMA &gt; Price</p>
                    <p onclick="make_current_strategy_sell('EMA20 < Price')">20EMA &lt; Price</p>
                    <p onclick="make_current_strategy_sell('EMA50 < Price')">50EMA &lt; Price</p>
                    <p onclick="make_current_strategy_sell('obv_slope > 0')">Pos OBV Slope</p>
                    <p onclick="make_current_strategy_sell('obv_slope < 0')">Neg OBV Slope</p>
                    <p onclick="make_current_strategy_sell('VWAP > Price')">VWAP &gt; Price</p>
                    <p onclick="make_current_strategy_sell('VWAP < Price')">VWAP &lt; Price</p>
                    <p onclick="make_current_strategy_sell('SIGNAL > MACD')">Signal &gt; MACD</p>
                    <p onclick="make_current_strategy_sell('SIGNAL < MACD')">Signal &lt; MACD</p>
                    <p onclick="make_current_strategy_sell('hband > Price')">UpperBollinger &gt; Price</p>
                    <p onclick="make_current_strategy_sell('lband < Price')">LowerBollinger &lt; Price</p>
                  </div>
                </div>
                </div>
            </div>
          </div>
          
          
        </div> <!-- row -->


         <!-- row -->

         <!-- row -->

         <!-- row -->

        <div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="activity"></i> Win Rate</h6>
                </p>
                <p>Win rate of this strategy.</p>
                
                
              </div>
            </div>
          </div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="corner-right-down"></i> Biggest Drawdown</h6>
                </p>
                <p>Highest loss incurred in a trade.</p>
                
              </div>
            </div>
          </div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="navigation-2"></i> Biggest Win</h6>
                </p>
                <p>Highest profit gained in a trade.</p>
                
              </div>
            </div>
          </div>
        </div> <!-- row -->


        <div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="arrow-up"></i> Long Only</h6>
                </p>
                <p>Profits and losses from long positions.</p>
                
              </div> 
            </div>
          </div>

          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="arrow-down"></i> Short Only</h6>
                </p>
                <p>Profits and losses from short positions.</p>
                
              </div> 
            </div>
          </div>
        </div> <!-- row -->

        
        

      </div></div>]]>
            </description>
            <link>https://www.tradytics.com/backtester</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940644</guid>
            <pubDate>Fri, 30 Oct 2020 09:48:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Nailing Your First Launch by Adam Wathan]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24940629">thread link</a>) | @reconquestio
<br/>
October 30, 2020 | https://samizdat.dev/notes-on-nailing-your-first-launch-by-adam-wathan/ | <a href="https://web.archive.org/web/*/https://samizdat.dev/notes-on-nailing-your-first-launch-by-adam-wathan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>I’ve just watched the talk «Nailing Your First Launch» (MicroConf Starter 2018) by Adam Wathan and I
took notes that I’d like to share and re-visit them in the future. Some of them are just text from his screens, some thoughts are mine.</p>
<p>But don’t let me steal the video from you by providing a digested summary.
In my humble opinion, the main idea of watching talks or reading something is to change your mind
model of seeing this topic.
Don’t hesitate and start watching the video before proceeding to notes.
The notes are here just to come back from time to time and re-call some especially useful highlights.</p>
<p><a href="https://www.youtube.com/watch?v=ajrDxZRpP9M">https://www.youtube.com/watch?v=ajrDxZRpP9M</a></p>
<hr>

<h3 id="one-time-purchase-products-are-way-easier-to-sell">One-time purchase products are way easier to sell</h3>
<ul>
<li>Harder to convince people that for $9 dollars per month they’d have value.</li>
<li>But it’s a very frequent case when people buy $100 courses and don’t even watch them.</li>
<li>One-time payments are much easier to go away with.</li>
</ul>
<h3 id="they-can-be-done">They can be “done”</h3>
<ul>
<li>You don’t have to maintain them forever.</li>
<li>A course can be finished. A book can be finished.</li>
</ul>
<h3 id="you-can-put-one-together-in-3-months-of-nights-and-weekends">You can put one together in 3 months of nights and weekends</h3>
<ul>
<li>Easier to plan.</li>
</ul>
<h3 id="they-put-money-in-the-bank-fast-then-drop-off-opposite-to-saas">They put money in the bank fast then drop off (opposite to SAAS)</h3>
<ul>
<li>One-time projects do have a more clear cliff of death, but they produce more money than saas during
launch days.</li>
</ul>
<hr>

<h3 id="building-an-audience">Building an audience</h3>
<ul>
<li>
<p>Having a big audience can compensate for almost any mistake made in marketing/sales.</p>
</li>
<li>
<p>Huge audience + bad sales plan produces way more profit than no audience + good sales plan.</p>
</li>
<li>
<p>Produce blog posts, tutorials, podcasts, screencasts, interview people</p>
</li>
<li>
<p>You should be worth following (provide a value for your audience)</p>
</li>
<li>
<p>Help people where they already are (Wes Bos)</p>
</li>
<li>
<p>Specific tactics for tech guys: tweet your hacks (like some tricks with css) that save you time.</p>
</li>
</ul>
<h3 id="picking-the-right-idea">Picking the right idea</h3>
<ul>
<li>Have an idea
<ul>
<li>what are you already putting out there that peoeple seem excited about?</li>
<li>what are you excited about that you think others will get excited about?</li>
<li>what do people think you’re better at than they are?</li>
<li>what have you learned outside your community would benefit from?</li>
<li>what did you have to figure out yourself but was really helpful to learn?</li>
</ul>
</li>
<li>Test it
<ul>
<li>
<p>«First thing to do is to put a landing page and start emailing.»</p>
<p>It’s not a bad way, but it’s not the first thing that you should do.
Especially it doesn’t work if you have no audience. People wouldn’t trust you.</p>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Collect feedback from tweets, have a catalog of them. Can be used later for your landing/sales pages.</p>
</blockquote>
<h3 id="define-the-product">Define the product</h3>
<ul>
<li>Plan small, it will end up bigger than you think anyway
<ul>
<li>Don’t worry about size. A short book is still a book.</li>
<li>3 hours of a video course is plenty.</li>
<li>Actually, not everyone is looking for a full knowledge base on a specific topic and read
500 pages on that. Collection of great ideas (like tweets) on that specific topic works
too.</li>
</ul>
</li>
</ul>
<blockquote>
<p>In general, courses are easier to sell at higher prices because people expect products such as
books to be in a specific cost range, even if they understand that it brings a high value.</p>
</blockquote>
<h3 id="landing-page">Landing page</h3>
<p>The goal is to collect e-mail addresses.</p>
<p>Example of Adam’s landing page can be seen on 19:33 - 22:25</p>
<ul>
<li>Promise something in advance (sign up for free screencasts and a big discount)</li>
<li>You can put your catalog of feedback on your landing page to earn more trust.</li>
</ul>
<h3 id="pre-sell">Pre-sell</h3>
<h4 id="advantages">Advantages</h4>
<ul>
<li>Best form of product validation</li>
<li>You’ll make more money</li>
<li>More motivation to finish</li>
<li>Can buy you the time to focus on the product</li>
</ul>
<h4 id="disadvantages">Disadvantages</h4>
<ul>
<li>Selling multiple tiers is trickier</li>
<li>Can’t easily change scope</li>
<li>Like taking on debt, can be extremely stressful. People paid you 50k$ and you have to return
it as the value in N months. (impostor syndrome?)</li>
</ul>
<h3 id="building-your-email-list">Building Your Email List</h3>
<ul>
<li>Always tell your audience.</li>
</ul>
<blockquote>
<p>Announce the announcement — «about to announce the next big project I’m working on; if you check
it out and are excited about it, I’d love any help spreading the word!»</p>
</blockquote>
<ul>
<li>Share progress. Send an update every week or so.</li>
<li>Repurpose content (Take a chapter from a book, make it a blog post and share it)</li>
</ul>
<h3 id="getting-it-finished">Getting it finished</h3>
<p>A few strategies to finally finish it:</p>
<ul>
<li>Make promises («this week I’m going to deliver a screencast»)</li>
<li>Email on a schedule</li>
<li>Reduce scope. (the project/book gets bigger and bigger, the best way to cross the finish line</li>
</ul>
<h3 id="figuring-pricing">Figuring pricing</h3>
<ul>
<li>It’s hard to sell tiers during pre-sales.</li>
<li>Sell pre-orders with top tier price.</li>
</ul>
<h4 id="single-tier">Single tier</h4>
<ul>
<li>Can be fine if you can charge enough</li>
<li>Often necessary if pre-selling</li>
<li>Nice if you can’t figure out a way to add additional tiers that actually feel valuable</li>
<li>In general, prefer multiple tiers</li>
</ul>
<h4 id="two-tiers">Two tiers</h4>
<ul>
<li>Usually a price anchoring strategy, first tier makes second tier look like better deal</li>
<li>Second tier is usually the “real” product</li>
<li>Prices are often close-ish, maybe 1x and 1.5x</li>
<li>Works well with video courses where easy to cut content for budget version</li>
</ul>
<h4 id="three-tiers">Three tiers:</h4>
<ul>
<li>Great for books if you can come up with the bonus content (videos?)</li>
<li>Makes it easier to evaluate as its own product instead of compring to Amazon book prices</li>
<li>Prices are usually 1x, ~2x, ~5x</li>
<li>This will make you a lot more money from a book than just selling the book on its own</li>
</ul>
<blockquote>
<p><strong>Adam’s case</strong></p>
<ul>
<li>First tier: The Bare Essentials, $39
<ul>
<li>The 158-page book in pdf format</li>
<li>Comprehensive set of exercises</li>
</ul>
</li>
<li>Second tier: The Premium Training Package, $79
<ul>
<li>Over 4 hours of screencasts, covering all of the book examples</li>
<li>Three additional advanced tutorials</li>
</ul>
<ul>
<li>all from first tier</li>
</ul>
</li>
<li>Third tier: The complete Reference Package, $179
<ul>
<li>The source code of Nitpick CI, a production Laravel application that makes heavy
use of collection pipelines</li>
</ul>
<ul>
<li>all from second tier</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="launch-discounts">Launch discounts</h3>
<ul>
<li>Discount it by enough to be appealing, at least 30%</li>
<li>Use stepped discounts; lower discount on cheaper tiers and better discount on higher tiers</li>
<li>Reverse engineer non-discounted price from your planned discounted price, it’ll help you charge more</li>
</ul>
<h3 id="nailing-the-launch">Nailing the launch</h3>
<ul>
<li>
<p>Build the sales page 39:13</p>
<ul>
<li>Still include an email sign up that sends preview content for new traffic (sign up to get
four free preview lessons)</li>
<li>Testimonials and social proof are important; use feedback from preview content to start</li>
<li>Sort tiers from highest price to lower price, use visuals to communicate value of higher
tiers (ui/ux hacks, make more important text bold, more physical things on a picture)</li>
</ul>
</li>
<li>
<p>Announce the launch details</p>
<ul>
<li>Include all package and pricing details</li>
<li>Complete TOC or content list</li>
<li>Final free content preview if possible</li>
</ul>
</li>
<li>
<p>Launch it</p>
<ul>
<li>Easiest part. Send an email — “xxx is now available!”, include discount</li>
<li>Launch on tuesday, no evidence, but it seems at least as good as any other day for Adam</li>
<li>Morning EST works well too</li>
</ul>
</li>
<li>
<p>Leverage early feedback</p>
<ul>
<li>Collect and catalog feedback after the launch.</li>
<li>Send new reviews to other people who hasn’t bought the course/book yet. Send them preview
of another chapter.</li>
</ul>
</li>
<li>
<p>Closing the launch</p>
<ul>
<li>Close the discount. Announce closing it. (“Hey, this is the last week of the launch”)</li>
<li>But don’t specify a closing date in advance</li>
</ul>
</li>
</ul>
<hr>
<h3 id="links">Links</h3>
<ul>
<li><a href="https://gist.github.com/adamwathan/30dc4230ac575cfa3425b39ca11ea859">Gist with useful links by Adam</a></li>
<li><a href="https://twitter.com/adamwathan">Twitter: @adamwathan</a></li>
<li><a href="https://adamwathan.me/">Blog: adamwathan.me</a></li>
<li><a href="https://www.youtube.com/watch?v=ajrDxZRpP9M">Talk on youtube</a></li>
</ul>
</article>

        </div></div>]]>
            </description>
            <link>https://samizdat.dev/notes-on-nailing-your-first-launch-by-adam-wathan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940629</guid>
            <pubDate>Fri, 30 Oct 2020 09:46:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kafka nightmare replication issues on FreeBSD (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24940623">thread link</a>) | @letientai299
<br/>
October 30, 2020 | https://stacksoft.io/blog/kafka-troubles/ | <a href="https://web.archive.org/web/*/https://stacksoft.io/blog/kafka-troubles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <div>
        <div>
		  

<p>I recently created a tool for a client to export some data from a Kafka topic and after waiting about 10 minutes for it to export, the program returned a rather bizarre error:</p>

<pre><code>kafka: error while consuming telemetry/0: kafka server: Message contents does not match its CRC.

</code></pre>

<p>Intuition gave me a bad feeling about that error, but I was not prepared for what was going to come next. I decide to look up the error quickly and the error indicated that the CRC calculated by the consumer was not matching the message header. Huh, what was going on here?</p>

<p>Before I dive into this article, it’s helpful to learn a little bit about the software that was being run when we started running into this problem. We had 3 VMs on an Azure cluster that were running FreeBSD. The producers were using <a href="https://github.com/Shopify/sarama">https://github.com/Shopify/sarama</a> and the consumers were using <a href="https://github.com/bsm/sarama-cluster">https://github.com/bsm/sarama-cluster</a></p>

<p>What’s also interesting is, no matter how many machines we might have had in the cluster (if they were all FreeBSD), we most likely would have experienced failure across the board. This wasn’t really great since the entire point of replicating the cluster across N machines was to prevent complete system failure. In this case, it really wouldn’t have helped us. A tear falls down my cheek for failed distributed programming promises.</p>

<table>
<thead>
<tr>
<th>Software</th>
<th>Version</th>
</tr>
</thead>

<tbody>
<tr>
<td>FreeBSD</td>
<td>11.0-RELEASE-p8</td>
</tr>

<tr>
<td>ZFS</td>
<td>-</td>
</tr>

<tr>
<td>Kafka</td>
<td>0.10.2</td>
</tr>

<tr>
<td>Zookeeper</td>
<td>3.4.10</td>
</tr>

<tr>
<td>OpenJDK</td>
<td>1.8.0_121-b13</td>
</tr>

<tr>
<td>Sarama</td>
<td>5e8fd95863bd4a894fcd29225547d56967f189ad</td>
</tr>

<tr>
<td>Sarama-cluster</td>
<td>d98592677c0aa08d8aafb882d344fb461682b722</td>
</tr>
</tbody>
</table>

<p>A little bit after my export tool ran, I got a ping on Slack that one of the services that uses this Kafka topic was no longer working. I check the logs of that service, and sure enough, the same error:</p>

<pre><code>kafka: error while consuming topic/0: kafka server: Message contents does not match its CRC.

</code></pre>

<p>Because this was a live running service, my first thought was to use the power of Kafka to shift the offset by 1 for this particular consumer so we can skip this corrupt message and get everything running again quickly.</p>

<p><code>kafka-consumer-groups.sh</code> is a command line tool that let’s you do exactly this, except it doesn’t work on <code>kafka-0.10.2</code>. That was a little bit of a surprise to me, I assumed one of the coolest things about Kafka is that you can pick an offset to consume from. The libraries we were using also had no way to manually select an offset to start from.</p>

<p>Okay, crap, so I need to upgrade Kafka to shift the offsets. This is a good opportunity to get on <code>1.0.0</code> anyway and perhaps restarting the services will actually fix the problem. I update my Ansible scripts for <code>kafka 1.0.1</code> and start reading the upgrade guide for a live running environment: <a href="https://kafka.apache.org/documentation/#upgrade">https://kafka.apache.org/documentation/#upgrade</a>.</p>

<p>Great, we’re on <code>1.0.1</code>, but the problem still exists. I have the ability to move the offet over, so I shift the offset by 1.</p>

<pre><code>./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group "api-consumer-group" --topic "telemetry:0" --reset-offsets --shift-by 1 --execute
</code></pre>

<p>I restart the service and the error comes up again. Darn. So it’s not only one message that is corrupt, it’s a range, that’s not great. I decided to commit to this strategy because this service needed to be up and running for a live demo in the coming week.</p>

<p>So instead, my idea was to shift the offset by a larger number until I find a number that actually works. Once I find a number that works, I can do a manual binary search to find the exact offset where the corruption started and shift it by 1.</p>

<p>After doing a manual binary search, I have found that the corrupted records are between <code>23769420-23772231</code> inclusive and corrupted, so good messages begin at <code>23772232</code> so 2811 corrupted messages. I run <code>./kafka-consumer-groups.sh</code> again, but this time I specify the exact offset to start from instead of using <code>shift-by</code></p>

<p>I restart the service again, and it works! Great, let’s hope this monkey patch works until the live demo. Nope, the next day, the same message appears again.</p>

<p>At this point, I’ve had my fair share of complicated problems, and I have a deep gut instinct that it’s most likely not the code we’ve written because the problem started to appear on multiple other topics in the cluster and the problem was produced by multiple independent services.</p>

<p>Of course, the book Pragmatic Programmer still pops up in my head:</p>

<p><em>“select” Isn’t Broken</em>:</p>

<blockquote>
<p>It is rare to find a bug in the OS or the compiler, or even a third-party product or library. The bug is most likely in the application.</p>
</blockquote>

<p>So I focus on starting from the application and then working outwards, I upgrade our libraries used in our code. I upgrade Sarama to <code>1.6.0</code> and I upgrade <code>sarama-cluster</code> to <code>master</code>. I run our deployment scripts and everything is running again.</p>

<p>I do the ridiculous offset binary-search trick again to shift everything and sure enough the issue comes up again with our Kafka libraries upgraded to the latest version. I decide to look at the logs of the broker themslelves and this is what I see;</p>

<pre><code>[2018-03-17 20:11:58,551] ERROR [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error for partition telemetry-0 to broker 3:org.apache.kafka.common.errors.CorruptRecordException: This message has failed its CRC checksum, exceeds the valid size, or is otherwise corrupt. (kafka.server.ReplicaFetcherThread)
[2018-03-17 20:11:58,747] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition topic-2 to broker 2:org.apache.kafka.common.errors.CorruptRecordException: This message has failed its CRC checksum, exceeds the valid size, or is otherwise corrupt. (kafka.server.ReplicaFetcherThread)
</code></pre>

<p>Looking at that error message, it appears that the replica thread inside of Kafka is running into exactly the same problem as our consumers. Uh oh, at this point I know it’s definitely not our application code, so much for that Pragmatic Programmer tip, gut instinct all the way!</p>

<p>There is a Kafka tool to let’s you see deeper into the health of your cluster <code>./kafka-topics.sh --zookeeper localhost:2181 --describe</code>. Here’s the output:</p>

<pre><code>Topic:telemetry PartitionCount:6 ReplicationFactor:3 Configs:
 Topic: telemetry Partition: 0 Leader: 2 Replicas: 2,1,3 Isr: 2
 Topic: telemetry Partition: 1 Leader: 3 Replicas: 3,2,1 Isr: 3
 Topic: telemetry Partition: 2 Leader: 1 Replicas: 1,3,2 Isr: 1
 Topic: telemetry Partition: 3 Leader: 2 Replicas: 2,3,1 Isr: 2
 Topic: telemetry Partition: 4 Leader: 3 Replicas: 3,1,2 Isr: 3
 Topic: telemetry Partition: 5 Leader: 1 Replicas: 1,2,3 Isr: 1
</code></pre>

<p>If you look at the <code>Isr</code> column, it stands for <code>In-Sync</code> replica. It appears that this cluster is not healthy because only the leader broker is in sync while all the other brokers cannot replicate that partition. Our goal here is to get that <code>Isr</code> column back to <code>1,2,3</code>.</p>

<p>So at this point, here are the options:</p>

<ul>
<li>- Hardware failure, such as disk failure, or network connectivity issues.</li>
<li>- The cluster is misbehaving because of resource allocation issues, perhaps it’s going OOM, or we’re out disk space.</li>
<li>- A bug with the Kafka version we were using</li>
<li>- An OpenJDK bug</li>
</ul>

<p>I decide to quickly look into our various servers to see if this is a resource allocation issue that is causing Kafka to misbehave. This was a red herring, one of the servers that was responsible for pushing to this topic actually filled its root partition and for a second I thought that might have been the issue, but that issue was fixed and the issue still remained.</p>

<p>The actual Kafka instances seemed to be fine, they were nowhere near capacity in terms of disk space, and the chances of having hardware failure across 3 machines was unlikely.</p>

<p>it gets a little confusing on what could be wrong and I start to realize that this is becoming a difficult problem and we have to get this live system working. I can’t just adjust things at random and hope that the problem is fixed. It’s time to dig deeper, it’s time to look at what Kafka is actually writing to disk.</p>

<h3 id="digging-deeper">Digging deeper</h3>

<p>Kafka writes the messages it receives into a log folder. The log folder contains a folder for each topic and partition combo. This is how it might look for this particular topic we’re having issues with:</p>

<pre><code>.
|-- telemetry-0
|   |-- 00000000000000000000.index
|   |-- 00000000000000000000.log
|   |-- 00000000000000000000.timeindex
|   |-- 00000000000003859610.index
|   |-- 00000000000003859610.log
|   |-- 00000000000003859610.snapshot
|   |-- 00000000000003859610.timeindex
|   |-- 00000000000008551431.index
|   |-- 00000000000008551431.log
|   |-- 00000000000008551431.snapshot
|   |-- 00000000000008551431.timeindex
|   |-- 00000000000012458429.snapshot
|   `-- leader-epoch-checkpoint
|-- telemetry-1
|   |-- 00000000000000000000.index
|   |-- 00000000000000000000.log
|   |-- 00000000000000000000.timeindex
|   |-- 00000000000003854233.index
|   |-- 00000000000003854233.log
|   |-- 00000000000003854233.timeindex
|   |-- 00000000000008541867.index
|   |-- 00000000000008541867.log
|   |-- 00000000000008541867.timeindex
|   `-- leader-epoch-checkpoint
|-- telemetry-2
|   |-- 00000000000000000000.index
|   |-- 00000000000000000000.log
|   |-- 00000000000000000000.timeindex
|   |-- 00000000000003850719.index
|   |-- 00000000000003850719.log
|   |-- 00000000000003850719.timeindex
|   |-- 00000000000008543680.index
|   |-- 00000000000008543680.log
|   |-- 00000000000008543680.timeindex
|   `-- leader-epoch-checkpoint

</code></pre>

<p>The <code>.log</code> file is where the messages we push to Kafka are stored. We’re going to attempt to extract the offset that is corrupt to see what exactly is corrupt about it. If you’re curious on learning about the internals of Kafka, check out this article, it was a lot simpler than I thought: <a href="https://thehoard.blog/how-kafkas-storage-internals-work-3a29b02e026">https://thehoard.blog/how-kafkas-storage-internals-work-3a29b02e026</a></p>

<p>Kafka provides a tool, <code>kafka.tools.DumpLogSegments</code> that lets you dive into these log files and grab more details about individual records that are in the file. Hilariously enough, when I ran this tool, it bails right when it hits a corrupt message.</p>

<pre><code>Exc…</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stacksoft.io/blog/kafka-troubles/">https://stacksoft.io/blog/kafka-troubles/</a></em></p>]]>
            </description>
            <link>https://stacksoft.io/blog/kafka-troubles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940623</guid>
            <pubDate>Fri, 30 Oct 2020 09:45:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Good Parts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24940075">thread link</a>) | @_query
<br/>
October 30, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There’s been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it’s ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That’s how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It’s really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it’s highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it’s finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there’s now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it’s finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940075</guid>
            <pubDate>Fri, 30 Oct 2020 08:02:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Higher Kinded Types in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939974">thread link</a>) | @lukastyrychtr
<br/>
October 30, 2020 | https://sobolevn.me/2020/10/higher-kinded-types-in-python | <a href="https://web.archive.org/web/*/https://sobolevn.me/2020/10/higher-kinded-types-in-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p><img src="https://dev-to-uploads.s3.amazonaws.com/i/73uvh47fvxfveqpz2xgi.png" alt="Cover image"></p>

<p><code>dry-python/returns@0.15</code> is <a href="https://github.com/dry-python/returns/releases/tag/0.15.0">released</a>! And it means that now anyone can use our Higher Kinded Types emulation in their projects.</p>

<p>In this post I will explain:</p>
<ul>
  <li>What Higher Kinded Types (HKTs) are and why they are useful</li>
  <li>How they are implemented and what limitations there are</li>
  <li>How can you use them in your own projects</li>
</ul>

<p>Without further ado, let’s talk about typing!</p>


      <h2 id="simple-types">
        
        <a href="#simple-types">Simple types</a>
        
      </h2>

<p>Typing is layered. Like a good cake. There are at least three layers that we are going to cover.</p>

<p>Simple (or flat) typing, like <code>x: int = 1</code>. This allows us to express simple types and their transformations. Like <code>int -&gt; str</code>:</p>

<div><div><pre><code><span>def</span> <span>stringify</span><span>(</span><span>arg</span><span>:</span> <span>int</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>return</span> <span>str</span><span>(</span><span>arg</span><span>)</span>
</code></pre></div></div>

<p>A lot of languages like <code>go</code> and <code>php</code> do not go beyond this line. And they still work pretty well! These types are also sometimes called <code>*</code>-kinded. It can be understood as “a place for just a single type argument”.</p>


    
      <h2 id="generic">
        
        <a href="#generic">Generic</a>
        
      </h2>

<p>Generic level is required to express “nested” types. For example, you have a list of integers. In Python we annotate it as <code>List[int]</code> or <a href="https://www.python.org/dev/peps/pep-0585/"><code>list[int]</code></a> in Python <code>3.9</code>. This allows us to have types with other types as arguments. <code>List</code> can receive <code>int</code> or <code>str</code> or even another <code>List</code> as the type argument. This way we can nest type and types start to have their own structure.</p>

<p>Generics are much more interesting than simple types. And they can have multiple type arguments:</p>
<ul>
  <li>List has one: for values, so it has a kind of <code>* -&gt; *</code>. It can be understood as a type transformation <code>List -&gt; T = List[T]</code></li>
  <li>Dict has two: for keys and values, so it has a kind of <code>* -&gt; * -&gt; *</code>. It can be understood as a type transformation <code>Dict -&gt; K -&gt; V = Dict[K, V]</code></li>
  <li>And so on!</li>
</ul>

<p>This would be very helpful for us in the future, I promise.</p>

<p>We can also write transformations for generic types:</p>

<div><div><pre><code><span>def</span> <span>stringify_list_items</span><span>(</span><span>arg</span><span>:</span> <span>List</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>List</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>[</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>]</span>
</code></pre></div></div>

<p>But, that is where things begin to be quite complicated.</p>

<p>How can this function work with other iterables like <code>set</code>, <code>frozenset</code>, <code>tuple</code>?
We can express this in Python as easy as:</p>

<div><div><pre><code><span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>):</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>But the typing part would be quite challenging. Let’s try several things.</p>


    
      <h3 id="common-interface">
        
        <a href="#common-interface">Common interface</a>
        
      </h3>

<p>The first obvious thing to try is <code>Iterable</code> protocol. It is builtin into Python and does what we need.</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Iterable</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>Iterable</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>Iterable</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>Let’s try it out:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>]))</span>
<span># Revealed type is 'typing.Iterable[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>}))</span>
<span>#  Revealed type is 'typing.Iterable[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>((</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>)))</span>
<span>#  Revealed type is 'typing.Iterable[builtins.str]'
</span></code></pre></div></div>

<p>You can see that a part of our typing information is lost. We pass <code>List</code> or <code>Set</code> or <code>Tuple</code> and always get the <code>Iterable</code> back.</p>

<p>Sometimes - this is ok. But, in some cases, this is not enough. Let’s try some other technique!</p>


    
      <h3 id="methods">
        
        <a href="#methods">Methods</a>
        
      </h3>

<p>One can say: we are all using Object-Oriented Programming! Why cannot we just create a new method for each type we need? And specify the exact return type there!</p>

<p>Well, it is a possible solution. But, there are some reasonable problems:</p>

<ul>
  <li>You cannot add methods to existing types and extend them with this approach. Only create new ones, probably via subtyping, and add new methods there. In our example you would have to create your own versions of <code>List</code>, <code>Set</code>, and <code>Tuple</code>. Which is not desirable in most situations</li>
  <li>It really starts to be messy if you have a lot of methods to add. A type with more than <code>X</code> (choose the number yourself) methods starts to be really complex to read, understand, and use. Instead, using separate functions is much easier, because we don’t have to put everything into a single namespace</li>
</ul>

<p>Let’s try something else.</p>


    
      <h3 id="overloads">
        
        <a href="#overloads">overloads</a>
        
      </h3>

<p>Another solution that might solve our problem is using the <code>@overload</code> decorator with proper types for each required case.</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>List</span><span>,</span> <span>Set</span><span>,</span> <span>overload</span>

<span>@</span><span>overload</span>
<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>List</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>List</span><span>[</span><span>str</span><span>]:</span>
    <span>...</span>

<span>@</span><span>overload</span>
<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>Set</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>Set</span><span>[</span><span>str</span><span>]:</span>
    <span>...</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>):</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>Let’s test it:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>]))</span>
<span># Revealed type is 'builtins.list[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>}))</span>
<span># Revealed type is 'builtins.set[builtins.str]'
</span></code></pre></div></div>

<p>Awesome! Looks like we’ve achieved our goal, haven’t we? But, there’s a new problem. We have to manually list all possible cases in a function’s signature. This works for cases when all possible arguments and outcomes are known in advance. But, not in this case. In Python <code>Iterable</code> is a protocol. We can use this function with any type with <code>__iter__</code> method defined: with both builtin and custom types. So, the number of possible arguments and outcomes is endless.</p>

<p>To illusrate the problem, let’s see what happens for <code>Tuple</code> which is not listed in the function’s overloads:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>((</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>)))</span>
<span># error: No overload variant of "stringify_iterable_items" matches argument type "Tuple[int, int, int]"
</span></code></pre></div></div>

<p>We, in <code>dry-python</code> <a href="https://github.com/dry-python/returns/blob/0.14.0/returns/_generated/converters/flatten.pyi">used this technique</a> with <code>@overload</code> decorator for our previous versions. This allowed us to write correct definitions of functions working with generic types. But, they were limited to the pre-defined set of our own types. And we wanted to allow our users to create their custom types based on our interfaces. With the full existing code reuse.</p>


    
      <h2 id="higher-kinded-types">
        
        <a href="#higher-kinded-types">Higher Kinded Types</a>
        
      </h2>

<p>That’s where the idea of Higher Kinded Types becomes useful. We need HKTs when we want to change the inner structure of generics with full type information preserving and openness to the extension. In theory, you can write something like:</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Iterable</span>

<span>T</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'T'</span><span>,</span> <span>bound</span><span>=</span><span>Iterable</span><span>)</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>T</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>T</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>And this would solve our problem! What happens here is that we abstract away the <code>Iterable</code> type itself. And then ask <code>mypy</code> to figure this out for us.</p>

<p>This way we can potentially have <code>stringify_iterable_items</code> working for any <code>Iterable</code> type, but with the exact same type returned back without any information lost. And it would work for all types.</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>]))</span>
<span># Revealed type is 'builtins.list[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>}))</span>
<span># Revealed type is 'builtins.set[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>(</span><span>MyCustomIterable</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)))</span>
<span># Revealed type is 'my_module.MyCustomIterable[builtins.str]'
</span></code></pre></div></div>

<p>Unfortunately, <a href="https://github.com/python/typing/issues/548">it is not supported</a> at the moment.</p>


    
      <h3 id="emulation">
        
        <a href="#emulation">Emulation</a>
        
      </h3>

<p>Turns out we are not alone in this situation. There are multiple languages where Higher Kinded Types are not natively supported yet. But, they can be emulated:</p>

<ul>
  <li><a href="https://github.com/gcanti/fp-ts/blob/master/docs/guides/HKT.md">TypeScript</a></li>
  <li><a href="https://bow-swift.io/docs/fp-concepts/higher-kinded-types/">Swift</a></li>
  <li><a href="https://arrow-kt.io/docs/0.10/patterns/glossary/#higher-kinds">Kotlin</a></li>
</ul>

<p>And now with <a href="https://returns.readthedocs.io/en/latest/pages/hkt.html">Python</a> too!</p>

<p>There’s also <a href="https://www.cl.cam.ac.uk/~jdy22/papers/lightweight-higher-kinded-polymorphism.pdf">an original whitepaper</a> for ones who are interested.</p>

<p>The core idea of HKT emulation is that we can write types the other way around: not like <code>T[int]</code>, but rather like <code>Kind[T, int]</code> (which is absolutely the same thing).</p>

<p>This way we can transform the inner structure of generics, but maintain the simple context without reinventing <code>TypeVar</code> with type arguments. And our function’s type signature will look like: <code>Kind[T, int] -&gt; Kind[T, str]</code>.</p>

<p>Let’s see the implementation.</p>


    
      <h2 id="implementation">
        
        <a href="#implementation">Implementation</a>
        
      </h2>

<p><strong>TLDR</strong>: here’s <a href="https://gist.github.com/sobolevn/7f8ffd885aec70e55dd47928a1fb3e61">the final working code</a> with all the logic, all the hacks, and everything. In this article, we going to write and explain it step by step.</p>

<p>We would need a better example to test our implementation. Let’s build two types: a <code>Box</code> and a <code>Bag</code>. <code>Box</code> is defined by its size, while a <code>Bag</code> is an item of fashion: it has a brand name and a model name (I have a wife, I know this stuff!).</p>

<div><div><pre><code><span>from</span> <span>dataclasses</span> <span>import</span> <span>dataclass</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Callable</span><span>,</span> <span>Generic</span><span>,</span> <span>TypeVar</span>

<span>_ValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_ValueType'</span><span>)</span>
<span>_NewValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_NewValueType'</span><span>)</span>

<span>@</span><span>dataclass</span>
<span>class</span> <span>Box</span><span>(</span><span>Generic</span><span>[</span><span>_ValueType</span><span>]):</span>
    <span>value</span><span>:</span> <span>_ValueType</span>
    <span>length</span><span>:</span> <span>int</span>
    <span>width</span><span>:</span> <span>int</span>
    <span>height</span><span>:</span> <span>int</span>

<span>@</span><span>dataclass</span>
<span>class</span> <span>Bag</span><span>(</span><span>Generic</span><span>[</span><span>_ValueType</span><span>]):</span>
    <span>value</span><span>:</span> <span>_ValueType</span>
    <span>brand</span><span>:</span> <span>str</span>
    <span>model</span><span>:</span> <span>str</span>
</code></pre></div></div>

<p>And we can create <code>Box</code>es and <code>Bag</code>s of different types, because we can put different things inside them:</p>

<div><div><pre><code><span>box</span> <span>=</span> <span>Box</span><span>(</span><span>value</span><span>=</span><span>10</span><span>,</span> <span>length</span><span>=</span><span>1</span><span>,</span> <span>width</span><span>=</span><span>2</span><span>,</span> <span>height</span><span>=</span><span>3</span><span>)</span>  <span># Box[int]
</span><span>bag</span> <span>=</span> <span>Bag</span><span>(</span><span>value</span><span>=</span><span>5</span><span>,</span> <span>brand</span><span>=</span><span>'Fancy'</span><span>,</span> <span>model</span><span>=</span><span>'Baggy'</span><span>)</span>  <span># Bag[int]
</span></code></pre></div></div>

<p>Now, we need a function with a type transformation. Let’s say we want to apply a function to the value inside boxes and bags. Let’s use fake <code>BoxOrBag</code> type for now to illustrate our intent:</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Callable</span>

<span>_NewValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_NewValueType'</span><span>)</span>

<span>def</span> <span>apply_function</span><span>(</span>
    <span>instance</span><span>:</span> <span>BoxOrBag</span><span>[</span><span>_ValueType</span><span>],</span>  <span># fake type for now
</span>    <span>callback</span><span>:</span> <span>Callable</span><span>[[</span><span>_ValueType</span><span>],</span> <span>_NewValueType</span><span>],</span>
<span>)</span> <span>-&gt;</span> <span>BoxOrBag</span><span>[</span><span>_NewValueType</span><span>]:</span>  <span># fake type for now
</span>    <span>...</span>
</code></pre></div></div>

<p>It is going to work like so:</p>

<div><div><pre><code><span>assert</span> <span>apply_function</span><span>(</span><span>box</span><span>,</span> <span>str</span><span>)</span> <span>==</span> <span>Box</span><span>(</span><span>value</span><span>=</span><span>'10'</span><span>,</span> <span>length</span><span>=</span><span>1</span><span>,</span> <span>width</span><span>=</span><span>2</span><span>,</span> <span>height</span><span>=</span><span>3</span><span>)</span>
<span>assert</span> <span>apply_function</span><span>(</span><span>bag</span><span>,</span> <span>bool</span><span>)</span> <span>==</span> <span>Bag</span><span>(</span><span>value</span><span>=</span><span>True</span><span>,</span> <span>brand</span><span>=</span><span>'Fancy'</span><span>,</span> <span>model</span><span>=</span><span>'Baggy'</span><span>)</span>
</code></pre></div></div>

<p>We only need to change current fake <code>BoxOrBag</code> type to a real HKT. We would need to define a new <code>Kind</code> type to make the emulation:</p>

<div><div><pre><code><span>_InstanceType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_InstanceType'</span><span>,</span> <span>covariant</span><span>=</span><span>True</span><span>)</span>
<span>_FirstTypeArgType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_FirstTypeArgType'</span><span>,</span> <span>covariant</span><span>=</span><span>True</span><span>)</span>

<span>class</span> <span>Kind</span><span>(</span><span>Generic</span><span>[</span><span>_InstanceType</span><span>,</span> <span>_FirstTypeArgType</span><span>]):</span>
    <span>"""Used for HKT emulation."""</span>
</code></pre></div></div>

<p>One pro-tip about <code>Kind</code>: it won’t not exist during runtime. Only during type-checking.</p>

<p>Now, let’s change <code>apply_function</code> to use <code>Kind</code>:</p>

<div><div><pre><code><span>_InstanceKind</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_InstanceKind'</span><span>)</span>

<span>def</span> <span>apply_function</span><span>(</span>
    <span>instance</span><span>:</span> <span>Kind</span><span>[</span><span>_InstanceKind</span><span>,</span> <span>_ValueType</span><span>],</span>
    <span>callback</span><span>:</span> <span>Callable</span>…</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sobolevn.me/2020/10/higher-kinded-types-in-python">https://sobolevn.me/2020/10/higher-kinded-types-in-python</a></em></p>]]>
            </description>
            <link>https://sobolevn.me/2020/10/higher-kinded-types-in-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939974</guid>
            <pubDate>Fri, 30 Oct 2020 07:40:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2 People, No VC Money, $700k+ ARR in Less Than 3 Years]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939911">thread link</a>) | @yosid
<br/>
October 30, 2020 | https://provesrc.com/blog/celebrating-3-years/ | <a href="https://web.archive.org/web/*/https://provesrc.com/blog/celebrating-3-years/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p><strong>TLDR:</strong> Stories and takeaways from growing ProveSource from 0 to $700k ARR as a 2-person team in less than 3 years and with no funding.</p>
<p><img loading="lazy" src="https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover.png" alt="3 year story provesource" width="1920" height="1080" srcset="https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover.png 1920w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-300x169.png 300w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-1024x576.png 1024w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-768x432.png 768w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-1536x864.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<h2><strong>Our false start</strong></h2>
<p>We started the company in June 2015 with no real idea.</p>
<p>Most people we know fail to ever get started because they’re looking for the perfect idea.</p>
<p>As the founder of Instagram famously said:</p>
<p>“It’s about going through false starts. The best companies in the world have all had predecessors. YouTube was a dating site. You always have to evolve into something else.”</p>
<p>We brainstormed for several days and because both myself and Natan (my co-founder) are very good with mobile app development (iOS &amp; Android) we decided to build a personalization platform for mobile apps and sell it to enterprises.</p>
<p>Around 2.5 years later, having invested almost $100k out of our own pockets, having done hundreds of calls and demos with huge enterprises and dozens of Proof of Concepts, we decided it’s time to move on…</p>
<p>It felt awful – like you’re killing something you love, but it had to be done.</p>
<p>That was our “false start”. But more on that another time.</p>
<p><strong>🧠 Lesson learned:</strong></p>
<p>The sooner you kill an idea that is getting no traction, even if it’s super hard because it’s your baby, the less painful it is. The more time and resources you devote, the harder it becomes to pull out in case things don’t work out.</p>
<h2><strong>Starting over – The lean way</strong></h2>
<p>In January 2018 we decided to start working on a new SaaS product.</p>
<p>The idea was to “steal” the social proof hack that Booking.com was using (e.g. 5 people booked this hotel, etc.) and create a platform from it – a social proof marketing platform.</p>
<p>This time, because we were running on fumes, both in terms of cash and motivation, we decided to validate the idea first.</p>
<p>We had a single purpose in mind – getting 100 leads interested in our product.</p>
<p>We created a landing page that showcased our new idea as a real product, including pricing, a signup button, and all – a social proof marketing platform for mobile apps.</p>
<p><img loading="lazy" src="https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps.png" alt="" width="1920" height="1080" srcset="https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps.png 1920w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-300x169.png 300w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-1024x576.png 1024w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-768x432.png 768w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-1536x864.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<p>The fastest way to get targeted traffic to your website is to use Google Ads targeting the brand names of the biggest players in your niche.</p>
<p>So we did that.</p>
<p>We also posted the landing page anywhere we could think of: Reddit, ProductHunt, BetaList, social media, wherever…</p>
<p>About one month and – $300 later, we had around 200 leads that wanted to try out ProveSource.</p>
<p>We were finally making progress!</p>
<p>We figured that even if only 1% of them converted, we would already have 2 paying customers.</p>
<p><strong>🧠 Lesson learned:</strong></p>
<p>You can easily get traction without having a product.</p>
<p>Just buy a domain, build a landing page, and go validate your business idea.</p>
<p>We usually create landing pages to validate products using plain HTML and Airtable, to send the leads we collect from the forms. No fancy designs, no expensive CRM.</p>
<h2><strong>Making our first dollar $</strong></h2>
<p>Next goal – how do we make a dollar?</p>
<p>That is, unlike our previous product which made practically $0 in 2.5 years.</p>
<p>We created a rule that whenever we launch a new product, all our efforts will be towards making our first dollar, so we can have real-life validation.</p>
<p>So we have 200 people interested in ProveSource.</p>
<p>Now we needed to give them a product and get them to pay.</p>
<p>We built the leanest MVP possible:</p>
<ul>
<li>A product just for website owners (mobile was too small of a niche).</li>
<li>You could only show how many page visitors you had on your website.</li>
<li>The whole UI and UX should be super simple. No menus and extra buttons, don’t give users a reason to abandon your product.</li>
</ul>
<p>Did you forget your password and need to reset it? Sorry, no can do.</p>
<p>Did we accidentally change your password when you logged in? Oops, we’re on it.</p>
<p>What are onboarding and email automation? Dunno, don’t care.</p>
<p>April 2018 – we are approached by a Facebook Group admin that is interested in promoting our product to his group as a “lifetime deal” (LTD).</p>
<p>This means selling a lifetime subscription to your product for a one-off payment ranging from $39-$99.</p>
<p>We’ve never heard of this before so we thought long and hard about the consequences of selling a lifetime deal and how it would position the product and our company…</p>
<p>We decided to go with the deal and ran it with the group for 1 week.</p>
<p>We generated over $7k revenue, got tons of feedback, ideas for product improvements, tons of bugs were discovered in the process, which taught us the value of having live chat support.</p>
<p><strong>🧠 Lesson learned:</strong></p>
<p>In hindsight, there were no real consequences, only advantages to running a lifetime deal.</p>
<p>Sure, you have a few dozens of customers that are not paying you on a recurring basis – but they help a lot in the beginning when you need the cash and the validation.</p>
<p>Once we were done with the LTD we started pushing the product in all marketing channels and to our 200 user waiting list. None of them converted by the way.</p>
<p>A couple of days later we got our first monthly subscription customer ($19/month).</p>
<p>It was an amazing moment, validating that you indeed have a real business opportunity in your hands.</p>
<h2><strong>Our “wow moment”</strong></h2>
<p>During the next months, we focused on spreading the word, squashing bugs, and doing tons of support for our existing customers.</p>
<p>How did we decide what to build next?</p>
<ul>
<li>We learned to ask questions about our product’s value. Why do people buy our product? Is it because they want to increase conversions? How do we help them achieve that?</li>
<li>We brainstormed about what it means to be a social proof platform.</li>
<li>We heard our customers’ feedback</li>
<li>We learned from competitors; but not too much. We found that those who only copy will always lag behind.</li>
</ul>
<p>This whole process has to be accompanied by analytics and metrics.</p>
<p>You don’t have to measure each and every step or A/B test you do, though.</p>
<p>We don’t really do it, to this day.</p>
<p>A lot of product leaders talk about the “wow effect” or “wow moment” – if you want to retain users, make them say “wow”.</p>
<p>For Facebook, for example, their “wow moment” is logging into their platform and seeing familiar faces. That’s why they make sure that during sign up, you connect with as many people you know on Facebook as possible.</p>
<p>In our case, we focused on improving our user onboarding.</p>
<p>Since the product requires users to install a javascript snippet on their website, we put a big emphasis on making that process as easy as possible.</p>
<p>Our thought was – if users can see a social proof notification on their website, they’ll get to that “wow moment”.</p>
<p>We can see a very close correlation between successful onboarding and someone becoming a paying customer.</p>
<p>The funnel looks like this:</p>
<ul>
<li>8-10% of visitors will signup.</li>
<li>70% of those signups will complete the onboarding.</li>
<li>7-10% of those users who are onboarded will eventually become paying customers.</li>
</ul>
<p><img loading="lazy" src="https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel.png" alt="ProveSource Signups Funnel" width="1920" height="1080" srcset="https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel.png 1920w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-300x169.png 300w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-1024x576.png 1024w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-768x432.png 768w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-1536x864.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<p><strong>🧠 Lesson learned:</strong></p>
<p>Find what your “wow moment” is in your users’ experience, and make sure you get users to experience it as early in the onboarding process as possible. That way you can spend a lot on User Acquisition activities because the users you bring in end up becoming paying customers and sticking with you.</p>
<h2><strong>Our First Growth “Hack”</strong></h2>
<p>After we added some “necessary” features like showing recent sales and polishing the product to have fewer bugs – we wanted to grow bigger, we wanted to scale up, we wanted to get more exposure.</p>
<p>How do you scale a notifications product that is essentially an add-on for websites?</p>
<p>You build integrations for all website builders.</p>
<p>So we worked hard on adding more and more integrations: <a href="https://wordpress.org/plugins/provesource/">WordPress plugin</a>, <a href="https://apps.shopify.com/provesource">Shopify app</a>, Magento plugin, Wix app, <a href="https://zapier.com/apps/provesource/integrations">Zapier</a>, <a href="https://www.bigcommerce.com/apps/provesource-social-proof/">BigCommerce</a>, and more.</p>
<p>All of these marketplaces and app stores proved to be really good traffic sources and traction channels for us, each with its own audience and unique requirements.</p>
<p>Today, around 20% of our customers and revenue comes from Shopify alone.</p>
<h2><strong>Scaling past 2 people</strong></h2>
<p>Being a two-person team that does development, marketing, support, accounting, and more is tough. But it also teaches you a lot, you learn so much about your business, your audience, and your customers.</p>
<p>And that gives you the experience you need on what to look for when hiring someone to take over some of your responsibilities.</p>
<p>In September 2019 we decided it’s time to scale the team.</p>
<p>After all, a great company can’t be just 2 people, right?</p>
<p>Naturally, a software company’s first hire would be a developer.</p>
<p>Bringing Dima to the team, allowed us to build more integrations faster, and scale the company beyond its initial stage.</p>
<p>So we now have tons of integrations, pretty much with any large marketing or website platform out there.</p>
<p>We also scaled and optimized our Google and Facebook ads as much as we could.</p>
<p>We optimized our product onboarding rate, increased prices, added great features, and made it even easier to use the product, by adding tooltips, auto-suggestions, wizards, and more.</p>
<p>We were growing at a steady rate, so what could possibly be bothering us?</p>
<p>Well, we didn’t know how to grow faster, or what to do next.</p>
<p>We came up with a few ideas:</p>
<ul>
<li>Bring a Growth team member to scale our marketing efforts and bring new ideas to the table.</li>
<li>Since our product offering is strong and we couldn’t think about any impactful feature we could develop – we thought about zooming out of our product’s initial market.</li>
<li>Build a new product – we have no investors so we are free to make any decision we want about the company’s direction. Investors often block the founders from doing whatever is best for the company and push for a point where they can exit.</li>
</ul>
<h2><strong>Building a new product</strong></h2>
<p>At this point, we decided to build another product to scale the company further.</p>
<p>We had these questions in mind before picking what to work on:</p>
<ul>
<li>How big is the market, is it potentially bigger than our current product?</li>
<li>Would our existing customers be customers of this new product too?</li>
<li>What do our existing customers need and are willing to pay for?</li>
</ul>
<p>Adding ProveSource to your website is great, but, there is a critical prerequisite to making it work for you and your website: traffic. If your website has no traffic, you won’t be able to generate social proof.</p>
<p>Here’s the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://provesrc.com/blog/celebrating-3-years/">https://provesrc.com/blog/celebrating-3-years/</a></em></p>]]>
            </description>
            <link>https://provesrc.com/blog/celebrating-3-years/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939911</guid>
            <pubDate>Fri, 30 Oct 2020 07:21:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For Complex Applications, Rust Is as Productive as Kotlin]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939875">thread link</a>) | @quyleanh
<br/>
October 30, 2020 | https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="preamble">
<div>
<p>In this article, we will compare one apple (IntelliJ Rust) to one orange (rust-analyzer) to reach general and sweeping conclusions.
Specifically, I want to present a case study supporting the following claim:</p>
<p>For complex applications, Rust is as productive as Kotlin.</p>
<p>For me, this is an unusual claim to argue: I always thought exactly the opposite, but I am not so sure now.
I came to Rust from C++.
I was of the opinion that this is a brilliant low-level language and always felt puzzled at people writing higher-level things in Rust.
Clearly, choosing Rust means taking a productivity hit, and using Kotlin, C# or Go just makes much more sense if you can afford GC.
My <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">list of Rust criticisms</a> starts with this objection.</p>
<p>What moved my position in the other direction was my experience as the lead developer of rust-analyzer and IntelliJ Rust.
Let me introduce the two projects.</p>
<p><a href="https://github.com/intellij-rust/intellij-rust"><strong>IntelliJ Rust</strong></a> is the plugin for IntelliJ Platform, providing Rust support.
In effect, it is a Rust compiler front-end, written in Kotlin and making use of language-support features of the platform.
These features include lossless syntax trees, a parser generator, persistence and indexing infrastructure, among others.
Nonetheless, as programming languages differ lot, the bulk of logic for analyzing Rust is implemented in the plugin itself.
Presentational features like completion list come from the platform, but most of the language semantics is hand-written.
IntelliJ Rust also includes a bit of a Swing GUI.</p>
<p><a href="https://github.com/rust-analyzer/rust-analyzer"><strong>rust-analyzer</strong></a> is an implementation of
<a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a> for Rust.
It is a Rust compiler front-end written from scratch with an eye towards IDE support.
It makes heavy use of <a href="https://github.com/salsa-rs/salsa">salsa</a> library for incremental computations.
Beyond the compiler itself, rust-analyzer includes code for managing long-lived multithreaded process of the language server itself.</p>
<p>The projects are essentially equivalent in scope — rust compiler front-ends suitable for IDEs.
The two biggest differences are:</p>
<div>
<ul>
<li>
<p>IntelliJ Rust is a plugin, so it can re-use code and design patterns of the surrounding platform.</p>
</li>
<li>
<p>rust-analyzer is the second system, so it leverages experience of IntelliJ Rust for a from-scratch design.</p>
</li>
</ul>
</div>
<p>The internal architecture of the two projects also differs a lot.
In terms of <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">Three Architectures</a>, IntelliJ Rust is map-reduce, and rust-analyzer is query-based.</p>
<p>Writing an IDE-ready compiler is a high-level task.
You don’t need to talk to the operating system directly.
There are some fancy data structures and concurrency here and there, but they are also high-level.
It’s not about implementing crazy lock-free schemes, it’s about maintaining application state and sanity in the multithreaded world.
The bulk of the compiler is symbolic manipulation, arguably best suited for lisp.
Picking a VM-based language for such task (for example, OCaml), doesn’t have any intrinsic downsides.</p>
<p>At the same time, the task is pretty complex and unique.
The ratio of “your code” vs “framework code” when implementing features is much higher than in a typical CRUD backend.</p>
<p>Now that the projects are introduced, lets take two roughly equivalent slices of history.</p>

<p>Both are about 2 years old, with 1-1.5 developers working full time and vibrant and thriving community of open-source contributors.
There are 52k lines of Kotlin and 66k lines of Rust.</p>
<p>Both delivered roughly equivalent feature sets at that time.
To be honest, I still don’t really believe this :)
rust-analyzer started from zero, it didn’t have a decade worth of Java classes to bootstrap from, and the productivity drop between Kotlin and Rust is supposed to be huge.
But it’s hard to argue with reality.
Instead, let me try to reflect on my experience building both, and to try to explain Rust’s surprising productivity.</p>
</div>
</div>
<div>
<h2 id="_learning_curve">Learning Curve</h2>
<div>
<p>It’s easy to characterize Kotlin’s learning curve — it is nearly zero.
I’ve started IntelliJ Rust without Kotlin experience and never felt that I need to specifically learn Kotlin.</p>
<p>When I switched to rust-analyzer, I was pretty experienced with Rust.
I would say that one definitely needs to deliberately learn Rust, it’s hard to pick it up on the go.
Ownership and aliasing control are novel concepts (even if you come from C++), and taking holistic approach to learning them pays off.
After the initial learning step the ride is generally smooth.</p>
<p>By the way, this is the perfect place to plug our Rust courses and tailor-made <a href="https://ferrous-systems.com/training/">trainings</a> :-)
The next <a href="https://ferrous-systems.com/training/#package-intro-training">introduction to Rust</a> is happening this December!</p>
</div>
</div>
<div>
<h2 id="_modularity">Modularity</h2>
<div>
<p>This I think is the biggest factor.
Both projects are moderately large in terms of scope as well as in terms of amount of source code.
I believe that the only way to ship big things is to split them in independent-ish chunks and implement the chunks separately.</p>
<p>I also find most of the languages I am familiar with to be pretty horrible with respect to modularity.
More generally, I am amused with FP vs OO debate, as it seems that “why no one does modules right?” is a more salient issue.</p>
<p>Rust is one of the few languages which has first-class concept of libraries.
Rust code is organized on two levels:</p>
<div>
<ul>
<li>
<p>as a tree of inter-dependent modules inside a crate</p>
</li>
<li>
<p>and as a directed acyclic graph of crates</p>
</li>
</ul>
</div>
<p>Cyclic dependencies are allowed between the modules, but not between the crates.
Crates are units of reuse and privacy: only crate’s public API matters, and it is crystal clear what crate’s public API is.
Moreover, crates are anonymous, so you don’t get name conflicts and dependency hell when mixing several versions of the same crate in a single crate graph.</p>
<p>This makes it very easy to make two pieces of code <strong>not</strong> depend on each other (non-dependencies are the essence of modularity): just put them in separate crates.
During code review, only changes to Cargo.tomls need to be monitored carefully.</p>
<p>At the time of comparison, rust-analyzer is split into 23 internal crates, with a handful general-purposed ones released on crates.io.
In contrast, IntelliJ Rust is a single Kotlin module, where everything can depend on everything else.
Although internal organization of IntelliJ Rust is pretty clean, it’s not reflected in the file system layout and build system, and needs constant maintenance.</p>
</div>
</div>
<div>
<h2 id="_build_system">Build System</h2>
<div>
<p>Managing project’s build takes significant amount of times, and has multiplicative effect on everything else.</p>
<p>Rust’s build system, <a href="https://doc.rust-lang.org/cargo/index.html">Cargo</a>, is very good.
It’s not perfect, but it is a breath of fresh air after Java’s <a href="https://gradle.org/">Gradle</a>.</p>
<p>Cargo’s trick is that it doesn’t try to be a general purpose build system.
It can only build Rust projects, and it has rigid expectation about the project structure.
It’s impossible to opt out of the core assumptions.
Configuration is a static non-extensible TOML file.</p>
<p>In contrast, Gradle allows free-form project structure, and is configured via a Turing complete language.
I feel like I’ve spend more time learning Gradle than learning Rust!
Running <code>wc -w</code> gives 182_817 words for Rust book, and 280_506 for Gradle’s user guide.</p>
<p>Additionally, Cargo is just faster than Gradle in most cases.</p>
<p>Of course, the biggest downside is that custom build logic is not expressible in Cargo.
Both projects needs substantial amount of logic beyond mere compilation to deliver the final result to the user.
For rust-analyzer, this is handled by hand-written Rust script, which works perfectly at this scale.</p>
</div>
</div>
<div>
<h2 id="_ecosystem">Ecosystem</h2>
<div>
<p>Language-level support for libraries and top-notch build system/package manager allow for a thriving ecosystem.
rust-analyzer relies on third-party libraries much more than IntelliJ Rust.
Some parts of rust-analyzer are also published to crates.io for other projects to reuse.</p>
<p>Additionally, low-level nature of the Rust programming language often allows for “perfect” library interfaces.
Interfaces which exactly reflect the underlying problem, without imposing intermediate language-level abstractions.</p>
</div>
</div>
<div>
<h2 id="_basic_conveniences">Basic Conveniences</h2>
<div>
<p>I feel that Rust is significantly more productive when it comes to basic language nuts and bolts — structs, enums, functions, etc.
This is not specific to Rust — any ML-family language has them.
However, Rust is the first industrial language which wraps these features in a nice package, not constrained by backwards compatibility.
I want to list specific features which I think allow producing maintainable code faster in Rust</p>
<p><em>Emphasis on data over behavior</em>.
Aka, Rust is not an OOP language.
The core idea of OOP is that of dynamic dispatch — which code is invoked by a function call is decided at runtime (late binding).
This is a powerful pattern which allows for flexible and extensible system.
The problem is, extensibility is costly!
It’s better only to apply it in certain designated areas.
Designing for extensibility by default is not cost effective.
Rust puts static dispatch front and center: it is mostly clear whats going on by just reading the code, as it is independent of runtime types of the objects.</p>
<p>One small syntactic thing I enjoy about Rust is how it puts fields and methods into different blocks syntactically:</p>
<div>
<div>
<pre><code data-lang="rust"><span>struct</span> <span>Person</span> <span>{</span>
  <span>first_name</span><span>:</span> <span>String</span><span>,</span>
  <span>last_name</span><span>:</span> <span>String</span><span>,</span>
<span>}</span>

<span>impl</span> <span>Person</span> <span>{</span>
    <span>fn</span> <span>full_name</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
        <span>...</span>
    <span>}</span>
<span>}</span></code></pre>
</div>
</div>
<p>Being able to see at a glance all the fields makes understanding the code much simpler.
Fields convey much more information than methods.</p>
<p><em>Sum types</em>.
Rust’s humbly named enums are full algebraic data types.
This means that you can express the idea of disjoint union:</p>
<div>
<div>
<pre><code data-lang="rust"><span>enum</span> <span>Either</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span> <span>{</span> <span>A</span><span>(</span><span>A</span><span>),</span> <span>B</span><span>(</span><span>B</span><span>)</span> <span>}</span></code></pre>
</div>
</div>
<p>This is hugely useful in day-to-day programming in the small, and some times during programming in the large as well.
To give one example, one of the core concepts for an IDE are references and definitions.
A definition a like <code>let foo = 92;</code> assigns a name to an entity which can be used down a line.
A reference like <code>foo + 90</code> <em>refers</em> to some definition.
When you ctrl-click on reference, you go to the definition.</p>
<p>Natural way to model that in Kotlin is by adding <code>interface Definition</code> and <code>interface Reference</code>.
The problem is, some things are …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</a></em></p>]]>
            </description>
            <link>https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939875</guid>
            <pubDate>Fri, 30 Oct 2020 07:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cycling through all the streets in central London]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939328">thread link</a>) | @quickthrower2
<br/>
October 29, 2020 | http://davis.vilums.me/all-the-streets/ | <a href="https://web.archive.org/web/*/http://davis.vilums.me/all-the-streets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="themify_builder_content-660" data-postid="660">
    	<!-- module_row -->
	<div data-fullwidthvideo="https://www.youtube.com/watch?v=0nA_H-57i-w">
	    	    <div>
			<div>
	    	    	        <div>
		    <!-- module text -->
<div>
            <p>
    <h3>Cycling through</h3>

<h3>in central London</h3>    </p>
</div>
<!-- /module text -->
	        </div>
	    	</div>
		    </div>
	    <!-- /row_inner -->
	</div>
	<!-- /module_row -->
		<!-- module_row -->
	<div>
	    	    <div data-basecol="2" data-col_tablet="column-full">
			<div>
	    	    	        <div>
		    <!-- module text -->
<div>
            <p>
    <h2>Why?</h2>
<h3>I am a passionate cyclist, and I love the streets of London. Most of my travels are daily 25-minute rides to work. Over time my route became boring. I decided to make it a little bit more interesting by taking the parallel streets on my way there. I bought a map of central London and started to colour in the streets to mark the routes that I have taken. And then I got obsessed with it.</h3>    </p>
</div>
<!-- /module text -->
	        </div>
	    	</div>
		<div>
	    	    	        <div>
		        <!-- module image -->
    <div>
	                <p><img src="http://davis.vilums.me/wp-content/uploads/2019/10/ezgif.com-optimize-6.gif" alt="ezgif.com-optimize (6)" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">            
                        </p>
            <!-- /image-wrap -->
        
        
        </div>
    <!-- /module image -->
	        </div>
	    	</div>
		    </div>
	    <!-- /row_inner -->
	</div>
	<!-- /module_row -->
		<!-- module_row -->
	<div>
	    	    <div>
			<div>
	    	    	        <div>
		    	<div>
	    	    <div data-tablet_dir="rtl" data-mobile_dir="rtl" data-basecol="2" data-col_tablet="column-full" data-col_tablet_landscape="column4-2" data-col_mobile="column-full">
			<div> 
	    	    	        <div>
		        <!-- module image -->
    <div>
	                <p><a href="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674.jpg">
                                           <img src="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674.jpg" alt="Both of the maps that I mainly used" srcset="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674.jpg 4032w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674-300x225.jpg 300w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674-1024x768.jpg 1024w" sizes="(max-width: 4032px) 100vw, 4032px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674.jpg" data-lazy-srcset="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674.jpg 4032w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674-300x225.jpg 300w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674-1024x768.jpg 1024w">                </a>
            
                        </p>
            <!-- /image-wrap -->
        
        
        </div>
    <!-- /module image -->
	        </div>
	    	</div>
		<div> 
	    	    	        <div>
		    <!-- module text -->
<div>
            <div>
    <h2>How did I do it?</h2>
<p>In the beginning, I used the “<a href="https://www.az.co.uk/london-a-z-map-walks.html">London A-Z Map &amp; Walks</a>” map. It covered a significant amount of central London, but it wasn’t enough, and the shape was not regular. So I found the “<a href="https://www.az.co.uk/london-super-scale-a-z-map.html">London Super Scale A-Z Map</a>” that was rectangular and covered a larger area. An essential thing for the map of my choice was that streets are laid out very accurately. Including some irregular times off, overall it took me four years to visit every single road on the map. When I started this hobby, it took me 30 to 40 minutes to do the route. Later it expanded to 2 hours to get to the office when I tried to reach the furthest places on my map. One of the main goals was never to be late for work. From the beginning, I planned to visit not only the main roads but every single accessible mews, yard, park trail, and a path that was possible to go through. I used Endomondo app to have a proper record of my journeys and proof that I have been there. After every trip, I prepared my next route in Google maps where it was easy to adjust streets to the next ones and mark points to revisit if I missed something.</p>    </div>
</div>
<!-- /module text -->
	        </div>
	    	</div>
		    </div>
	</div><!-- /themify_builder_sub_row -->
		<div>
	    	    <div data-tablet_landscape_dir="rtl" data-basecol="2" data-col_tablet="column-full" data-col_tablet_landscape="column4-2">
			<div> 
	    	    	        <div>
		    <!-- module text -->
<div>
            <div>
    <h2>How was it?&nbsp;</h2>
<p>The most satisfying feeling I got when I found a shortcut in some of my trails. It was like finding some portal that links two separated parts on the map. There were some obstacles, like road closures or construction works, that sometimes prevented me from accessing the streets. I marked all of those streets as necessary to visit later when the street was accessible again (like London bridge station surroundings and few streets around Barbican etc.). Occasionally I found my route trough yards and gardens that are not visited by passersby very often. If anyone asked how did I get there, I had to pretend to be lost. I take traffic and rules very seriously, so I always have to be aware of the surroundings in unfamiliar places. If it is not allowed to cycle through the park, I always push my bicycle instead.</p>    </div>
</div>
<!-- /module text -->
    <!-- module image -->
    <div>
	                <p><a href="http://davis.vilums.me/wp-content/uploads/2019/10/a-1.jpg">
                                           <img src="http://davis.vilums.me/wp-content/uploads/2019/10/a-1-470x352.jpg" width="470" alt="Fully coloured &quot;London Super Scale A-Z Map&quot;" srcset="http://davis.vilums.me/wp-content/uploads/2019/10/a-1-470x352.jpg 470w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-300x225.jpg 300w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-1024x768.jpg 1024w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-450x337.jpg 450w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1.jpg 2000w" sizes="(max-width: 470px) 100vw, 470px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="http://davis.vilums.me/wp-content/uploads/2019/10/a-1-470x352.jpg" data-lazy-srcset="http://davis.vilums.me/wp-content/uploads/2019/10/a-1-470x352.jpg 470w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-300x225.jpg 300w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-1024x768.jpg 1024w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-450x337.jpg 450w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1.jpg 2000w">                </a>
            
                        </p>
            <!-- /image-wrap -->
        
        
        </div>
    <!-- /module image -->
	        </div>
	    	</div>
		<div> 
	    	    	        <div>
		        <!-- module image -->
    <div>
	                <p><a href="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430.jpg">
                                           <img src="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430.jpg" alt="" srcset="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430.jpg 2736w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430-225x300.jpg 225w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430-768x1024.jpg 768w" sizes="(max-width: 2736px) 100vw, 2736px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430.jpg" data-lazy-srcset="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430.jpg 2736w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430-225x300.jpg 225w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430-768x1024.jpg 768w">                </a>
            
                        </p>
            <!-- /image-wrap -->
        
        
        </div>
    <!-- /module image -->
	        </div>
	    	</div>
		    </div>
	</div><!-- /themify_builder_sub_row -->
		        </div>
	    	</div>
		    </div>
	    <!-- /row_inner -->
	</div>
	<!-- /module_row -->
		<!-- module_row -->
	
	<!-- /module_row -->
		<!-- module_row -->
	<div>
	    	    <div data-basecol="3" data-col_tablet="column-full" data-col_mobile="column-full">
			
		<div>
	    	    	        <div>
		    <!-- module text -->
<div>
            <div>
    <h2>Wrapping it up all together</h2>
<p>I exported all my tracks from the Endomondo app and put together in a single video. Now we can see how I gradually covered all the visible space on the map, and the result was very pleasing. It resulted in thunderstorm type of effect where each path looks like a lightning flash, that reveals London’s street grid.</p>

<p><a href="http://davis.vilums.me/wp-content/uploads/2019/10/PicturesCompressed.mp4">Longer linear time version</a></p>
    </div>
</div>
<!-- /module text -->
	        </div>
	    	</div>
		
		    </div>
	    <!-- /row_inner -->
	</div>
	<!-- /module_row -->
		<!-- module_row -->
	<div>
	    	    <div data-basecol="3" data-col_tablet="column-full" data-col_mobile="column-full">
			
		<div>
	    	    	        <div>
		    <!-- module text -->
<div>
            <div>
    <h2>Conclusion&nbsp;</h2>
<p>That was an enjoyable waste of time, and I liked every bit of it, planning, executing and then colouring in the streets and paths where my route took place. I found it a great way how to discover new areas in London and familiarise all the boroughs of central London. This journey for me made every corner of central London feel like home.</p>    </div>
</div>
<!-- /module text -->
    <!-- module image -->
    <div>
	                <p><img src="http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1.jpg" alt="IMG_20191027_160926 (1) (1)" srcset="http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1.jpg 1000w, http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1-300x283.jpg 300w" sizes="(max-width: 1000px) 100vw, 1000px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1.jpg" data-lazy-srcset="http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1.jpg 1000w, http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1-300x283.jpg 300w">            
                        </p>
            <!-- /image-wrap -->
        
        
        </div>
    <!-- /module image -->
<!-- module text -->
<div>
            <div>
    <p>cycling@vilums.me&nbsp;</p>
<p><a href="https://www.youtube.com/watch?v=BWpnqRTDIWQ&amp;list=PLd0jT172k7naa8ALKDXwyu6uiNN3Dc8ZN">YouTube</a></p>
<p><a href="https://www.instagram.com/davisvilums/">Instagram</a></p>
<p><a href="http://davis.vilums.me/visas-ielas/">Latviski</a></p>
<p>&nbsp;<a href="https://londonist.com/london/transport/cycle-every-street-central-london">Londonist Article</a></p>
<p><a href="https://www.reci.pe/">Recipe</a></p>
<p><a href="https://www.givingforlatvia.com/">Giving for Latvia</a></p>

<h5>If you like what I’m doing, please, help me get a new bike?</h5>
    </div>
</div>
<!-- /module text -->
	        </div>
	    	</div>
		
		    </div>
	    <!-- /row_inner -->
	</div>
	<!-- /module_row -->
	</div></div>]]>
            </description>
            <link>http://davis.vilums.me/all-the-streets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939328</guid>
            <pubDate>Fri, 30 Oct 2020 05:01:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Object Oriented Done Right]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939258">thread link</a>) | @brendt_gd
<br/>
October 29, 2020 | https://front-line-php.com/object-oriented | <a href="https://web.archive.org/web/*/https://front-line-php.com/object-oriented">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            
<div>
    <p>Alan Kay, the inventor of the term “object-oriented programming”, told a story once during a talk more than 20 years ago. You can build a dog house using only a hammer, nails, planks, and just a little bit of skill. I figure even I would be able to build it given enough time. Once you've built it you've earned the skills and know-how, and could apply it to other projects. Next, you want to build a cathedral, using the same approach with your hammer, nails, and planks. It's a 100 times larger, but you've done this before — right? It'll only take a little longer.</p>

    <p>While the scale went up by a factor of 100, its mass went up by a factor of 1.000.000 and its strength only by 10.000. Inevitably, the building will collapse. Some people plaster over the rubble, make it into a pyramid and say it was the plan all along; but you and I know what really went on.</p>

    <p>Alan used this metaphor to explain a critical problem he saw with “modern OOP” 20 years ago. I think it still holds today: we've taken the solution to a problem — OO code — we've scaled it by a factor of 100, and expected it to work the same way. Today still, we don't think enough about architecture — which is rather crucial if you're building a cathedral — we use the OO solutions we learned without any extra thought. Most of us learned OO in isolation with small examples, and rarely at scale. In most real life projects, you cannot simply apply the patterns you've learned and expect everything to fall into place the same way it did with Animals, Cats, and Dogs.</p>
    <p>This reckless scaling of OO code is what cause many people to voice their disapproval of it in recent years. Personally I believe OOP is as good a tool as any other — functional programming being the modern-day popular contestant — <em>if</em> used correctly.</p>
    <p>My takeaway from Alan's vision is that each object is a little program on its own, with its own internal state. Objects send messages between each other — packages of immutable data — which other objects can interpret and react to. You can't write all code this way, and that's fine — it's fine to not blindly follow these rules.
        Still, I have experienced the positive impact of this mindset first hand. Thinking of objects as little standalone programs, I started writing parts of my code in a different style. I hope that, now that we're going to look at OOP, you'll keep Alan's ideas in mind. Don't blindly apply patterns and principles. Try to look at what you're building as a whole.</p>
    <h2 id="the-pitfall-of-inheritance"><a href="#the-pitfall-of-inheritance">#</a> The pitfall of inheritance</h2>
    <p>I found it difficult to believe at first, but classes and inheritance have nothing to do with OOP the way Alan envisioned it. That doesn't mean they are bad things per se, but it <em>is</em> good to think about their purpose and how we can use, as well as abuse them.
        Alan's vision only described objects — it didn't describe how those objects were created. Classes were added later as a convenient way to manage objects, but they are only an implementation detail, not the core idea of OOP. With classes came inheritance, another a useful tool when used correctly. That hasn't been the case though: the problem Alan tried to address 20 years ago still exists today.</p>
    <p>One of the acclaimed strengths of OOP is that it models our code in ways humans think about the world. In reality though, we rarely think in terms of abstractions and inheritance. Instead of using inheritance in places where it actually makes sense, we've been abusing it as a way to share code, and to configure objects in an obscure way.
        I'm going to show you a great example that illustrates this problem, though I want to say up front that it isn't my own: it's Sandi Metz's, a great teacher on the subject of OOP. Let's take a look.</p>
    <p>There's a children's nursery rhyme called “The House That Jack Built” (it's also a horror movie but that's unrelated).
        It starts like this:</p>
    <pre><code>This is the house that Jack built.</code></pre>
    <p>Every iteration there's a sentence added to it:</p>
    <pre><code>This is the malt that lay in
        the house that Jack built.</code></pre>
    <p>And next:</p>
    <pre><code>This is the rat that ate
        the malt that lay in
        the house that Jack built.</code></pre>
    <p>Get it? This is the final poem:</p>
    <pre><code>This is the horse and the hound and the horn that belonged to
        the farmer sowing his corn that kept
        the rooster that crowed in the morn that woke
        the priest all shaven and shorn that married
        the man all tattered and torn that kissed
        the maiden all forlorn that milked
        the cow with the crumpled horn that tossed
        the dog that worried
        the cat that killed
        the rat that ate
        the malt that lay in
        the house that Jack built.</code></pre>
    <p>Let's code this together, I'll be using PHP. We're going to make a program that you can ask a given iteration, and it will produce the poem up until that point. Let's do it in an OO way. We start by adding all parts into a data array within a class; let's call that class <code><span>PoemGenerator</span></code> — sounds very OO, right? Good.</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    <span>private</span> <span>static</span> <span>array</span> <span>$data</span> = [
        <span>'the horse and the hound and the horn that belonged to'</span>,
        <span>'the farmer sowing his corn that kept'</span>,
        <span>'the rooster that crowed in the morn that woke'</span>,
        <span>'the priest all shaven and shorn that married'</span>,
        <span>'the man all tattered and torn that kissed'</span>,
        <span>'the maiden all forlorn that milked'</span>,
        <span>'the cow with the crumpled horn that tossed'</span>,
        <span>'the dog that worried'</span>,
        <span>'the cat that killed'</span>,
        <span>'the rat that ate'</span>,
        <span>'the malt that lay in'</span>,
        <span>'the house that Jack built'</span>,
    ];
}</code></pre>
    <p>Now let's add two methods <code><span>generate</span></code> and <code><span>phrase</span></code>. <code><span>generate</span></code> will return the end result, and <code><span>phrase</span></code> is an internal function that glues the parts together.</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    

    <span>public</span> <span><span>function</span> <span>generate</span><span>(<span>int</span> $number)</span>: <span>string</span>
    </span>{
        <span>return</span> <span>"This is {$this-&gt;<span>phrase</span>($number)}."</span>;
    }

    <span>protected</span> <span><span>function</span> <span>phrase</span><span>(<span>int</span> $number)</span>: <span>string</span>
    </span>{
        $parts = <span>array_slice</span>(<span>self</span>::<span>$data</span>, -$number, $number);

        <span>return</span> <span>implode</span>(<span>"\n        "</span>, $parts);
    }
}</code></pre>
    <p>It seems like our solution works: we can use <code><span>phrase</span></code> to take x-amount of items from the end of our data array and implode those into one phrase; next we use <code><span>generate</span></code> to wrap the final result with <code>This is</code> and <code>.</code>. By the way, I implode on that spaced delimiter just to format the output a little nicer.</p>
    <pre><code>$generator = <span>new</span> <span>PoemGenerator</span>();

$generator-&gt;<span>generate</span>(<span>4</span>);




</code></pre>
    <p>Exactly what we'd expect the result to be.</p>
    <hr>
    <p>Then comes along… a new feature request. Let's build a <em>random</em> poem generator: it will randomise the order of the phrases. How do we solve this in a clean way without copying and duplicating code? Inheritance to the rescue — right?
        First let's do a little refactor, let's add a protected <code><span>data</span></code> method, so that we have a little more flexibility in what it actually returns:</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    <span>protected</span> <span><span>function</span> <span>phrase</span><span>(<span>int</span> $number)</span>: <span>string</span>
    </span>{
        $parts = <span>array_slice</span>(<span><span>$this</span>-&gt;<span>data</span>()</span>, -$number, $number);

        <span>return</span> <span>implode</span>(<span>"\n        "</span>, $parts);
    }

<span>    <span>protected</span> <span><span>function</span> <span>data</span><span>()</span>: <span>array</span>
    </span>{
        <span>return</span> [
            <span>'the horse and the hound and the horn that belonged to'</span>,
            
            <span>'the house that Jack built'</span>,
        ];
    }</span>}</code></pre>
    <p>Next we build our <code><span>RandomPoemGenerator</span></code>:</p>
    <pre><code><span><span>class</span> <span>RandomPoemGenerator</span> <span>extends</span> <span>PoemGenerator</span>
</span>{
    <span>protected</span> <span><span>function</span> <span>data</span><span>()</span>: <span>array</span>
    </span>{
        $data = <span>parent</span>::<span>data</span>();

        <span>shuffle</span>($data);

        <span>return</span> $data;
    }
}</code></pre>
    <p>How great is inheritance! We only needed to override a small part of our code, and everything works just as expected!</p>
    <pre><code>$generator = <span>new</span> <span>RandomPoemGenerator</span>();

$generator-&gt;<span>generate</span>(<span>4</span>);</code></pre>
    <pre><code>This is the priest all shaven and shorn that married
        the cow with the crumpled horn that tossed
        the man all tattered and torn that kissed
        the rooster that crowed in the morn that woke.</code></pre>
    <p>Awesome!</p>
    <hr>
    <p>Once again… a new feature request: an echo generator: it repeats every line a second time. So you'd get this:</p>
    <pre><code>This is the malt that lay in the malt that lay in
        the house that Jack built the house that Jack built.</code></pre>
    <p>We can solve this; inheritance — right?</p>
    <p>Let's again do a small refactor in <code><span>PoemGenerator</span></code>, just to make sure our code stays clean! Let's extract the array slicing functionality in <code><span>phrase</span></code> to its own method, because that's a better separation of concerns — which we learned is a good thing!</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    

    <span>protected</span> <span><span>function</span> <span>phrase</span><span>(int $number)</span>: <span>string</span>
    </span>{
        $parts = <span><span>$this</span>-&gt;<span>parts</span>($number)</span>;

        <span>return</span> <span>implode</span>(<span>"\n        "</span>, $parts);
    }

<span>    <span>protected</span> <span><span>function</span> <span><span>parts</span></span><span>(int $number)</span>: <span>array</span>
    </span>{
        <span>return</span> <span>array_slice</span>(<span>$this</span>-&gt;<span>data</span>(), -$number, $number);
    }</span>}</code></pre>
    <p>Having refactored this, implementing <code><span>EchoPoemGenerator</span></code> is again very easy:</p>
    <pre><code><span><span>class</span> <span>EchoPoemGenerator</span> <span>extends</span> <span>PoemGenerator</span>
</span>{
    <span>protected</span> <span><span>function</span> <span>parts</span><span>(<span>int</span> $number)</span>: <span>array</span>
    </span>{
        <span>return</span> <span>array_reduce</span>(
            <span>parent</span>::<span>parts</span>($number),
            <span>fn</span> (<span><span>array</span></span> $output, <span>string</span> $line) =&gt; [...$output, <span>"{$line} {$line}"</span>],
            []
        );
    }
}</code></pre>
    <p>Can we take a moment to appreciate the power of inheritance? We've created two different implementations of our original <code><span>PoemGenerator</span></code>, and have <em>only</em> overridden the parts that differ from it in <code><span>RandomPoemGenerator</span></code> and <code><span>EchoPoemGenerator</span></code>. We've even used SOLID principles to ensure that our code is decoupled so that it's easy to override specific parts. This is what great OOP is about — right?</p>
    <hr>
    <p>One more time… another feature request: please make one more implementation, one that combines both the random and echo behaviour: <code><span>RandomEchoPoemGenerator</span></code>.</p>
    <p>Now what? Which class will that one extend?</p>
    <p>If we're extending <code><span>PoemGenerator</span></code>, we'll have to override both our <code><span>data</span></code> and <code><span>parts</span></code> methods, essentially copying code from both <code><span>RandomPoemGenerator</span></code> and <code><span>EchoPoemGenerator</span></code>. That's bad design, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://front-line-php.com/object-oriented">https://front-line-php.com/object-oriented</a></em></p>]]>
            </description>
            <link>https://front-line-php.com/object-oriented</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939258</guid>
            <pubDate>Fri, 30 Oct 2020 04:44:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Flexbox with 30 Code Tidbits]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939224">thread link</a>) | @nilsandrey
<br/>
October 29, 2020 | https://www.samanthaming.com/flexbox30/ | <a href="https://web.archive.org/web/*/https://www.samanthaming.com/flexbox30/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app" data-server-rendered="true"><div><p>
      🔥 NEW Code Tidbit Every Week 🔥
    </p> <header><nav data-v-51356df1=""><div data-v-51356df1=""> <ul data-v-51356df1=""><li data-v-51356df1=""><a href="https://www.samanthaming.com/" name="Go to Home Page - SamanthaMing.com" data-v-51356df1=""><img src="https://www.samanthaming.com/images/samantha-ming-logo.svg" alt="Samantha Ming Logo" data-v-51356df1=""> <span data-v-51356df1="">Samantha Ming</span></a></li> <li data-v-51356df1=""><a href="https://www.samanthaming.com/tidbits/" data-v-51356df1="">
          Tidbits
        </a></li><li data-v-51356df1=""><a href="https://www.samanthaming.com/blog/" data-v-51356df1="">
          Blog
        </a></li><li data-v-51356df1=""><a href="https://www.samanthaming.com/courses/" data-v-51356df1="">
          Courses
        </a></li><li data-v-51356df1=""><a href="https://www.samanthaming.com/contact/" data-v-51356df1="">
          Contact
        </a></li></ul> <div data-v-51356df1=""></div></div></nav> </header>  <main><div><div><div><a href="https://www.samanthaming.com/flexbox30/1-flexbox-intro/"><img src="https://samanthaming.gumlet.io/courses/flexbox30.jpg.gz?format=auto" alt="Flexbox30" data-v-067b84ea=""> <p>
            Start Course
          </p></a></div></div> <div><div><div><div> <p>
      Learn Flexbox with 30 Code Tidbits ✨
      <a href="https://www.samanthaming.com/flexbox30/1-flexbox-intro/">
        Start Course
      </a> </p></div></div></div></div></div> <div><ul><li><a href="https://twitter.com/intent/tweet?text=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8&amp;url=https://www.samanthaming.com/flexbox30/&amp;via=samantha_ming" title="Share this course on Twitter" rel="noopener noreferrer" target="_blank" data-analytics-social="Twitter"> <span>Share to Twitter</span> <span>Twitter</span></a></li><li><a href="https://www.facebook.com/sharer/sharer.php?text=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8&amp;u=https://www.samanthaming.com/flexbox30/" title="Share this course on Facebook" rel="noopener noreferrer" target="_blank" data-analytics-social="Facebook"> <span>Share to Facebook</span> <span>Facebook</span></a></li><li><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.samanthaming.com/flexbox30/&amp;smid=li-share&amp;title=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8" title="Share this course on LinkedIn" rel="noopener noreferrer" target="_blank" data-analytics-social="LinkedIn"> <span>Share to LinkedIn</span> <span>LinkedIn</span></a></li><li><a href="https://reddit.com/submit?url=https://www.samanthaming.com/flexbox30/&amp;smid=re-share&amp;%20%20%20%20%20%20%20%20title=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8" title="Share this course on Reddit" rel="noopener noreferrer" target="_blank" data-analytics-social="Reddit"> <span>Share to Reddit</span> <span>Reddit</span></a></li><li><a href="https://news.ycombinator.com/submitlink?u=https://www.samanthaming.com/flexbox30/" title="Share this course on Hacker News" rel="noopener noreferrer" target="_blank" data-analytics-social="Hacker News"> <span>Share to Hacker News</span> <span>Hacker News</span></a></li><li><a href="mailto:?subject=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8%20|%20SamanthaMing.com&amp;body=Learn%20Flexbox%20with%2030%20code%20tidbits.%20Become%20a%20flexbox%20ninja%20with%20this%20FREE%20course!%0A%0Ahttps://www.samanthaming.com/flexbox30/" title="Share this course on Email" rel="noopener noreferrer" target="_blank" data-analytics-social="Email"> <span>Email</span> <span>Email</span></a></li></ul></div> <section><div><div><h2>
          Flexbox Core Concepts
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/1-flexbox-intro/" aria-label="Read the article for Introduction" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/1-flexbox-intro.jpg.gz?format=auto&amp;width=256" alt="Introduction" data-v-067b84ea=""><span>1</span></p></a> <h3 data-v-605d1001="">
    Introduction
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/2-flex-container-flex-items/" aria-label="Read the article for Flex Container &amp; Flex Items" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/2-flex-container-flex-items.jpg.gz?format=auto&amp;width=256" alt="Flex Container &amp; Flex Items" data-v-067b84ea=""><span>2</span></p></a> <h3 data-v-605d1001="">
    Flex Container &amp; Flex Items
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/3-immediate-child-only/" aria-label="Read the article for Immediate Child Only" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/3-immediate-child-only.jpg.gz?format=auto&amp;width=256" alt="Immediate Child Only" data-v-067b84ea=""><span>3</span></p></a> <h3 data-v-605d1001="">
    Immediate Child Only
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/4-flexbox-axes/" aria-label="Read the article for Flexbox Axes" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/4-flexbox-axes.jpg.gz?format=auto&amp;width=256" alt="Flexbox Axes" data-v-067b84ea=""><span>4</span></p></a> <h3 data-v-605d1001="">
    Flexbox Axes
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/5-flexbox-module/" aria-label="Read the article for Flexbox Module" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/5-flexbox-module.jpg.gz?format=auto&amp;width=256" alt="Flexbox Module" data-v-067b84ea=""><span>5</span></p></a> <h3 data-v-605d1001="">
    Flexbox Module
  </h3></li></ul></div><div><h2>
          Parent Properties
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/6-parent-properties/" aria-label="Read the article for Parent Properties" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/6-parent-properties.jpg.gz?format=auto&amp;width=256" alt="Parent Properties" data-v-067b84ea=""><span>6</span></p></a> <h3 data-v-605d1001="">
    Parent Properties
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/7-display/" aria-label="Read the article for display" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/7-display.jpg.gz?format=auto&amp;width=256" alt="display" data-v-067b84ea=""><span>7</span></p></a> <h3 data-v-605d1001="">
    display
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/8-block-vs-inline/" aria-label="Read the article for block vs inline" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/8-block-vs-inline.jpg.gz?format=auto&amp;width=256" alt="block vs inline" data-v-067b84ea=""><span>8</span></p></a> <h3 data-v-605d1001="">
    block vs inline
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/9-flex-direction/" aria-label="Read the article for flex-direction" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/9-flex-direction.jpg.gz?format=auto&amp;width=256" alt="flex-direction" data-v-067b84ea=""><span>9</span></p></a> <h3 data-v-605d1001="">
    flex-direction
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/10-flex-wrap/" aria-label="Read the article for flex-wrap" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/10-flex-wrap.jpg.gz?format=auto&amp;width=256" alt="flex-wrap" data-v-067b84ea=""><span>10</span></p></a> <h3 data-v-605d1001="">
    flex-wrap
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/11-flex-flow/" aria-label="Read the article for flex-flow" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/11-flex-flow.jpg.gz?format=auto&amp;width=256" alt="flex-flow" data-v-067b84ea=""><span>11</span></p></a> <h3 data-v-605d1001="">
    flex-flow
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/12-justify-content-row/" aria-label="Read the article for justify-content [row]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/12-justify-content-row.jpg.gz?format=auto&amp;width=256" alt="justify-content [row]" data-v-067b84ea=""><span>12</span></p></a> <h3 data-v-605d1001="">
    justify-content [row]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/13-justify-content-column/" aria-label="Read the article for justify-content [column]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/13-justify-content-column.jpg.gz?format=auto&amp;width=256" alt="justify-content [column]" data-v-067b84ea=""><span>13</span></p></a> <h3 data-v-605d1001="">
    justify-content [column]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/14-space-around-vs-space-evenly/" aria-label="Read the article for space-around vs space-evenly" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/14-space-around-vs-space-evenly.jpg.gz?format=auto&amp;width=256" alt="space-around vs space-evenly" data-v-067b84ea=""><span>14</span></p></a> <h3 data-v-605d1001="">
    space-around vs space-evenly
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/15-align-items-row/" aria-label="Read the article for align-items [row]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/15-align-items-row.jpg.gz?format=auto&amp;width=256" alt="align-items [row]" data-v-067b84ea=""><span>15</span></p></a> <h3 data-v-605d1001="">
    align-items [row]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/16-baseline/" aria-label="Read the article for baseline" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/16-baseline.jpg.gz?format=auto&amp;width=256" alt="baseline" data-v-067b84ea=""><span>16</span></p></a> <h3 data-v-605d1001="">
    baseline
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/17-align-items-column/" aria-label="Read the article for align-items [column]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/17-align-items-column.jpg.gz?format=auto&amp;width=256" alt="align-items [column]" data-v-067b84ea=""><span>17</span></p></a> <h3 data-v-605d1001="">
    align-items [column]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/18-align-content/" aria-label="Read the article for align-content" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/18-align-content.jpg.gz?format=auto&amp;width=256" alt="align-content" data-v-067b84ea=""><span>18</span></p></a> <h3 data-v-605d1001="">
    align-content
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/27-flex/" aria-label="Read the article for flex" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/27-flex.jpg.gz?format=auto&amp;width=256" alt="flex" data-v-067b84ea=""><span>27</span></p></a> <h3 data-v-605d1001="">
    flex
  </h3></li></ul></div><div><h2>
          Child Properties
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/19-child-properties/" aria-label="Read the article for Child Properties" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/19-child-properties.jpg.gz?format=auto&amp;width=256" alt="Child Properties" data-v-067b84ea=""><span>19</span></p></a> <h3 data-v-605d1001="">
    Child Properties
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/20-order/" aria-label="Read the article for order" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/20-order.jpg.gz?format=auto&amp;width=256" alt="order" data-v-067b84ea=""><span>20</span></p></a> <h3 data-v-605d1001="">
    order
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/21-flex-grow/" aria-label="Read the article for flex-grow" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/21-flex-grow.jpg.gz?format=auto&amp;width=256" alt="flex-grow" data-v-067b84ea=""><span>21</span></p></a> <h3 data-v-605d1001="">
    flex-grow
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/22-flex-grow-calculation/" aria-label="Read the article for flex-grow calculation" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/22-flex-grow-calculation.jpg.gz?format=auto&amp;width=256" alt="flex-grow calculation" data-v-067b84ea=""><span>22</span></p></a> <h3 data-v-605d1001="">
    flex-grow calculation
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/23-flex-shrink/" aria-label="Read the article for flex-shrink" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/23-flex-shrink.jpg.gz?format=auto&amp;width=256" alt="flex-shrink" data-v-067b84ea=""><span>23</span></p></a> <h3 data-v-605d1001="">
    flex-shrink
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/24-flex-shrink-calculation/" aria-label="Read the article for flex-shrink calculation" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/24-flex-shrink-calculation.jpg.gz?format=auto&amp;width=256" alt="flex-shrink calculation" data-v-067b84ea=""><span>24</span></p></a> <h3 data-v-605d1001="">
    flex-shrink calculation
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/25-flex-basis/" aria-label="Read the article for flex-basis" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/25-flex-basis.jpg.gz?format=auto&amp;width=256" alt="flex-basis" data-v-067b84ea=""><span>25</span></p></a> <h3 data-v-605d1001="">
    flex-basis
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/26-flex-basis-vs-widths/" aria-label="Read the article for flex-basis vs widths" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/26-flex-basis-vs-widths.jpg.gz?format=auto&amp;width=256" alt="flex-basis vs widths" data-v-067b84ea=""><span>26</span></p></a> <h3 data-v-605d1001="">
    flex-basis vs widths
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/28-align-self/" aria-label="Read the article for align-self" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/28-align-self.jpg.gz?format=auto&amp;width=256" alt="align-self" data-v-067b84ea=""><span>28</span></p></a> <h3 data-v-605d1001="">
    align-self
  </h3></li></ul></div><div><h2>
          Summary
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/29-flexbox-properties/" aria-label="Read the article for Flexbox Properties" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/29-flexbox-properties.jpg.gz?format=auto&amp;width=256" alt="Flexbox Properties" data-v-067b84ea=""><span>29</span></p></a> <h3 data-v-605d1001="">
    Flexbox Properties
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/30-flexbox-cheatsheet/" aria-label="Read the article for Flexbox Cheatsheet" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/30-flexbox-cheatsheet.jpg.gz?format=auto&amp;width=256" alt="Flexbox Cheatsheet" data-v-067b84ea=""><span>30</span></p></a> <h3 data-v-605d1001="">
    Flexbox Cheatsheet
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/31-flexbox-with-auto-margins/" aria-label="Read the article for Bonus: Flexbox with Auto Margins" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/31-flexbox-with-auto-margins.jpg.gz?format=auto&amp;width=256" alt="Bonus: Flexbox with Auto Margins" data-v-067b84ea=""><span>31</span></p></a> <h3 data-v-605d1001="">
    Bonus: Flexbox with Auto Margins
  </h3></li></ul></div></div></section> <section><div><hr> <div><h2>
        More Courses
      </h2> <!----> </div></div> <ul><li><a href="https://www.samanthaming.com/codetidbits30/"><div><h3>
          CodeTidbits30
        </h3> <p>
          30 days of the best JS, CSS, HTML tidbits 🎄
        </p></div></a></li><li><a href="https://www.samanthaming.com/basics/"><div><h3>
          Web Basics
        </h3> <p>
          Web Basics Explained with Tidbits 🍎
        </p></div></a></li><li><a href="https://www.samanthaming.com/pictorials/"><div><h3>
          Pictorials
        </h3> <p>
          Step by Step Code Tutorials 👣
        </p></div></a></li></ul></section> <section><div><hr> <div><h2><a href="https://www.samanthaming.com/tidbits/"><span>
      Top Tidbits
    </span> </a></h2> <!----> </div></div> <div><ul> <li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/29-check-if-number-is-positive-or-negative/" aria-label="Read the article for Math.sign: How to Check if Number is Negative or Positive in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/29-check-if-number-is-positive-or-negative.jpg.gz?format=auto" alt="Code snippet on Math.sign: How to Check if Number is Negative or Positive in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        Math.sign: How to Check if Number is Negative or Positive in JavaScript
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/11-setting-default-parameters/" aria-label="Read the article for Setting Default Parameters in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/11-setting-default-parameters.jpg.gz?format=auto" alt="Code snippet on Setting Default Parameters in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        Setting Default Parameters in JavaScript
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/45-pretty-json-output/" aria-label="Read the article for Pretty JSON output" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/45-pretty-json-output.jpg.gz?format=auto" alt="Code snippet on Pretty JSON output" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        Pretty JSON output
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/50-how-to-deep-clone-an-array/" aria-label="Read the article for How to Deep Clone an Array in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/50-how-to-deep-clone-an-array.jpg.gz?format=auto" alt="Code snippet on How to Deep Clone an Array in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        How to Deep Clone an Array in JavaScript
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/89-how-to-check-if-variable-is-array/" aria-label="Read the article for How to check if Variable is an Array in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/89-how-to-check-if-variable-is-array.jpg.gz?format=auto" alt="Code snippet on How to check if Variable is an Array in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        How to check if Variable is an Array in JavaScript
      </h3></p></a></li> <p>
      hi</p></ul></div></section> </main>  </div></div></div>]]>
            </description>
            <link>https://www.samanthaming.com/flexbox30/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939224</guid>
            <pubDate>Fri, 30 Oct 2020 04:39:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research discovers breakthrough with potential to prevent, reverse Alzheimer's]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939160">thread link</a>) | @walterbell
<br/>
October 29, 2020 | https://libin.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers | <a href="https://web.archive.org/web/*/https://libin.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              <div>

                
                                
                                                  <div>
                                                                                        <p><span><span>A research team at the University of Calgary’s <a href="https://cumming.ucalgary.ca/">Cumming School of Medicine</a> (CSM) led by Dr. S.R. Wayne Chen, PhD, has made an exciting breakthrough with the potential to prevent and reverse the effects of Alzheimer’s disease.</span></span></p>

<p><span><span>The team discovered that limiting the open time of a channel called the ryanodine receptor, which acts like a gateway to cells located in the heart and brain, reverses and prevents progression of Alzheimer’s disease in animal models. They also identified a drug that interrupts the disease process.</span></span></p>

<p><span><span>The effect of giving the drug to animal models was remarkable: After one month of treatment, the memory loss and cognitive impairments in these models disappeared. </span></span></p>

<p><span><span>“The significance of identifying a clinically used drug that acts on a defined target to provide anti-Alzheimer’s disease benefits can’t be overstated,” says Chen, a member of the <a href="https://libin.ucalgary.ca/">Libin Cardiovascular Institute</a> and the <a href="https://hbi.ucalgary.ca/">Hotchkiss Brain Institute</a> at the CSM.&nbsp;</span></span><span lang="EN-US"><span><span><span>Dr. Jinjing Yao, PhD, a student of Chen, is the first author of the study.</span></span></span></span></p>

<p><span><span>The results of this groundbreaking study were recently published in the peer-reviewed journal, <a href="https://www.cell.com/cell-reports/fulltext/S2211-1247(20)31158-X"><em>Cell Reports</em></a>.&nbsp;</span></span></p>

<p><span><span>This work is potentially highly impactful as more than half a million Canadians live with Alzheimer’s disease and other dementias, suffering memory loss and other cognitive impairments with a negative impact on quality of life. </span></span></p>

<h3><strong><span><span><span><span>The science behind the findings</span></span></span></span></strong></h3>

<p><span><span>Previous research has shown that the progression of Alzheimer’s disease is driven by a vicious cycle of the protein amyloid β (Aβ) inducing hyperactivity at the neuron level. However, the mechanism behind this wasn’t fully understood nor were there effective treatments to stop the cycle. &nbsp;</span></span></p>

<p><span><span>Chen’s team used a portion of an existing drug used for heart patients, carvedilol, to treat mice models with Alzheimer’s symptoms. After a month of treatment, researchers tested animal models with very promising results. </span></span></p>

<p><span><span>“We treated them for a month and the effect was quite amazing,” says Chen, explaining the drug was successful in reversing major symptoms of Alzheimer’s disease. “We couldn’t tell the drug-treated disease models and the healthy models apart.” </span></span></p>

<p><span><span>Chen, a Clarivate Highly Cited Researcher, is optimistic about the future of this research, noting the next step will be clinical trials in people.</span></span></p>

<p><em><span><span>Wayne Chen is a professor in the Department&nbsp;of Physiology and Pharmacology, Biochemistry and </span></span><span><span>Molecular Biology at the CSM.&nbsp;</span></span></em><span><span><em><span lang="EN-US"><span><span>Led by the&nbsp;</span></span></span></em><a href="http://www.hbi.ucalgary.ca/"><em><span><span><span><span><span>Hotchkiss Brain Institute</span></span></span></span></span></em></a><em><span lang="EN-US"><span><span>,&nbsp;</span></span></span></em><a href="http://www.ucalgary.ca/research/brain-and-mental-health"><em><span><span><span><span><span>Brain and Mental Health</span></span></span></span></span></em></a><em><span lang="EN-US"><span><span>&nbsp;is one of six research strategies guiding the University of Calgary toward its&nbsp;Eyes High&nbsp;goals. The strategy provides a unifying direction for brain and mental health research at the university.</span></span></span></em></span></span></p>



                                                                                                                                                                                                                                      

  
    

    
  <div data-history-node-id="23525" role="article" about="/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers" typeof="schema:Article">
    <div>
      <div>
                          <div>
            <div>
              <div>
                <div>
                                        <picture>
                <!--[if IE 9]><video style="display: none;"><![endif]-->
              <source srcset="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_desktop/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=ByB_f0m8 1x" media="all and (min-width: 992px)" type="image/jpeg">
              <source srcset="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_tablet/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=5tYigcJ8 1x" media="all and (min-width: 768px)" type="image/jpeg">
              <source srcset="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_mobile/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=-CoV0v5E 1x" media="all and (max-width: 767px)" type="image/jpeg">
            <!--[if IE 9]></video><![endif]-->
            <img src="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_desktop/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=ByB_f0m8" alt="Dr. Wayne Chen, PhD" title="Dr. Wayne Chen, PhD" typeof="foaf:Image">

  </picture>

                                    </div>
                                  <p>Dr. Wayne Chen, PhD</p>
                                                  <p>Britton Ledingham for the Libin Cardiovascular Institute</p>
                              </div>
            </div>
          </div>
              </div>
          </div>
  </div>


                                                                                    </div>
                
                
              </div>
              
            </div>

          </div>
        </div></div>]]>
            </description>
            <link>https://libin.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939160</guid>
            <pubDate>Fri, 30 Oct 2020 04:27:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Writing and Coding Workflow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939140">thread link</a>) | @thecedarprince
<br/>
October 29, 2020 | http://jacobzelko.com/workflow/ | <a href="https://web.archive.org/web/*/http://jacobzelko.com/workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><em>My personal workflow for terminal-based coding, writing, research, and more!</em></p>

<p>Hello everyone!
It has been quite sometime since I last posted!
Suffice it to say, I have been immensely busy the past year but I am happy to say I am able to resurrect this blog! <img title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"></p>

<p>I have thoroughly grown into my own workflow for programming, research, and writing.
Today, I am happy to be able to share it with you!</p>

<p>If you prefer to watch a video describing most of this entire process, here is an overview of my workflow from one of my <a href="https://www.twitch.tv/thecedarprince">live streams</a>.
It does not go as in-depth as this document but should serve as a strong complement to this post. <img title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"></p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/2SLZQQfMF8E" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>



<p>I use <a href="https://github.com/alacritty/alacritty">Alacritty</a> as my terminal, <a href="https://www.zsh.org/">zsh</a> and <a href="https://ohmyz.sh/">oh-my-zsh</a> as my shell and plugin manager respectively, <a href="https://github.com/tmux/tmux">tmux</a> as my multiplexer, <a href="https://github.com/Peltoche/lsd">lsd</a> as my list command with fun icons, <a href="https://github.com/belluzj/fantasque-sans">Fantasque Sans Mono</a> as my typeface font, <a href="https://github.com/neovim/neovim">neovim</a> for my editor, <a href="https://github.com/junegunn/fzf">fzf</a> paired with <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> for speedy and interactive file finding, <a href="https://github.com/sharkdp/bat">bat</a> an enhanced <code>cat</code> with a git diff gutter, <a href="https://github.com/jgm/pandoc">pandoc</a> for writing in markdown and LaTeX and outputting the piece to whatever file type I want, <a href="http://jacobzelko.com/setting-up-zotero/">Zotero</a> for managing my collection on scientific literature, <a href="https://github.com/ranger/ranger">ranger</a> as a terminal-based file explorer, and <a href="https://github.com/morhetz/gruvbox-contrib">gruvbox-dark</a> as my general color palette.</p>

<p>Here are gists to the relevant config files I use to modify my interface and user experience:</p>

<ul>
  <li>
<strong>neovim</strong>: <a href="https://gist.github.com/TheCedarPrince/7b9b51af4c146880f17c39407815b594">init.vim</a>
</li>
  <li>
<strong>Alacritty</strong>: <a href="https://gist.github.com/TheCedarPrince/7743091bd8743a7568b718f30bf707c2">.alacritty.yml</a>
</li>
  <li>
<strong>tmux</strong>: <a href="https://gist.github.com/TheCedarPrince/07f6f8f79b1451ec436ff8dee236ccdd">.tmux.conf</a>
</li>
  <li>
<strong>zsh</strong>: <a href="https://gist.github.com/TheCedarPrince/77afe2674803d965a0f5abd108337040">.zshrc</a>
</li>
</ul>

<p>Here is a picture of what that looks like altogether:</p>

<p><img src="http://jacobzelko.com/assets/workflow_layout.png" alt=""></p>

<h2 id="my-workflow-in-action">My Workflow in Action</h2>

<p>The following sections describe in broad strokes my workflow.
I mention some plugins that I use and are provided in my config files.
If you want to learn more about them, I encourage you to read through my config files or search for them.</p>

<h3 id="persistent-working-sessions-via-tmux">Persistent Working Sessions via tmux</h3>

<p><img src="http://jacobzelko.com/assets/tmux_restore.gif" alt=""></p>

<p>Though it is a little hard to see, I closed my terminal completely.
Oh no!
All my paneling and windows have disappeared! 
I’ll have to spend valuable time getting my workflow set back up… Or do I?</p>

<p>tmux can actually remember all these layouts with the plugins, <code>resurrect</code> and <code>continuum</code>. 
This is great for when your computer unexpectedly dies or crashes as everything is backed up at regular intervals you define!
Furthermore, pairing the (neo)vim plugin, <code>obsession</code>, allows tmux to also automatically recover vim layouts and sessions as well.
You will never have to worry about losing your terminal workflow again!</p>

<h3 id="vim-slime-for-rapid-evaluation">Vim-Slime for Rapid Evaluation</h3>

<p><img src="http://jacobzelko.com/assets/vim_slime.gif" alt=""></p>

<p>Here, I target my Julia REPL in a tmux panel and use the <code>vim-slime</code> plugin to send code from my Julia script opened in neovim to the Julia REPL for rapid evaluation. 
This config works for any time you want to target a window.
This also works for code chunks such as functions or loops!</p>

<h3 id="mouse-mode">Mouse Mode</h3>

<p><img src="http://jacobzelko.com/assets/mouse_mode.gif" alt=""></p>

<p>tmux and (neo)vim also support mouse mode and interactivity!
I can quickly jump all over the place with my mouse or easily resize any opened pane.</p>

<h3 id="interactive-file-finding">Interactive File Finding</h3>

<p><img src="http://jacobzelko.com/assets/vim_fzf.gif" alt=""></p>

<p>I integrated the powerful file finding tool, <code>fzf</code>, with <code>ripgrep</code> to quickly find files I am looking to use. 
Then, in my (neo)vim configuration file, I merged these two together into one function that I can easily call while editing files in (neo)vim. 
find files I search for and pandoc to enable citations in pandoc, markdown, or TeX files.</p>

<h3 id="terminal-based-file-explorer">Terminal-Based File Explorer</h3>

<p><img src="http://jacobzelko.com/assets/ranger_mode.gif" alt=""></p>

<p>Furthermore, I also use the great tool, <code>ranger</code>, which allows me to have a terminal based file explorer.
It’s nice as it pops up in its own window and does not actually directly interfere with any of the background files being edited. 
It even has image preview capabilities!</p>

<h3 id="citation-engine--live-preview">Citation Engine &amp; Live Preview</h3>

<p><img src="http://jacobzelko.com/assets/citation_mode.gif" alt=""></p>

<p>As a researcher, this part gets me immensely excited!
While I am writing, I can actively insert citation keys into whatever I am working on via <code>vim-pandoc</code>.
With my config file, you will have to specify where your own .bib file exists.
Furthermore, <code>markdown-preview</code> allows me to preview my markdown in a web browser and <code>vim-latex-live-preview</code> allows me to view my current TeX files in a pdf viewer – works for subfiles too! 
This works for whenever I write TeX files or markdown files which makes writing a breeze!</p>

<p>If any of this section is confusing, I strongly encourage you to read my article on <a href="http://jacobzelko.com/personal-research-management/">Knowledge Management</a>.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I hope you found my workflow and toolchain interesting!
My dream would be for this workflow to serve as inspiration for your own workflow.
Make it your own and all the best!</p>

<p><em>If you spot any errors or have any questions, feel free to <a href="http://jacobzelko.com/contact/">contact me</a> about them!</em></p>

<hr>

        </div></div>]]>
            </description>
            <link>http://jacobzelko.com/workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939140</guid>
            <pubDate>Fri, 30 Oct 2020 04:22:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Every brown take-out bag]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938760">thread link</a>) | @secondbreakfast
<br/>
October 29, 2020 | https://secondbreakfast.co/inside-every-brown-take-out-bag… | <a href="https://web.archive.org/web/*/https://secondbreakfast.co/inside-every-brown-take-out-bag…">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<blockquote>
<p><span>“</span>I wanted Uber Eats because it was raining. But didn’t end up ordering because it was raining.” - Recent text from a friend</p>
</blockquote>
<p>Paying for somebody to deliver burgers and fries usually feels fine. <em>They could decline the gig if the price isn’t fair.</em></p>
<p>But when you’re sitting on a bench across from a mid-forties man <a href="https://secondbreakfast.co/union-square">rubbing his knee and popping Advil</a>, or when a woman is standing outside the door, dripping wet, brown bag in hands, glancing at the gray Scandinavian couch and 65″ Sony on the wall, guilt creeps in.</p>
<p>Maybe Doordash and Instacart aren’t stealing the tips. Maybe they are. I don’t know. But I do know something feels weird about paying somebody to mask up and pluck items off the shelf while I sit on the couch. For only $8!</p>
<p>I’d order more often if I didn’t feel guilty.</p>
<p>But the gig economy is stuck in a prisoner’s dilemma. Doordash can’t raise prices to pay Dashers™ more. If they did, everyone would use Postmates or Uber or Amazon instead.</p>
<p>Game theory means it’s cutthroat prices and cutthroat wages. Game theory means inside every bag of hot food left on the doorstep, there’s a little feeling of shame. <em>They could decline the gig if the price isn’t fair.</em></p>
<p>When price for delivery goes up, people order less often. Same in the other direction. But I wonder if the gig economy prisoner’s dilemma is suppressing overall demand for food and grocery delivery.</p>
<p>If seeing Palm Oil on an ingredients list didn’t make customers think about deforestation and global warming, then more products would have palm oil.</p>
<p>The same goes for delivery and labor practices.</p>
</div></div>]]>
            </description>
            <link>https://secondbreakfast.co/inside-every-brown-take-out-bag…</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938760</guid>
            <pubDate>Fri, 30 Oct 2020 03:14:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SM2 (Chinese) National Secret algorithm is accepted into Linux kernel]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24938686">thread link</a>) | @hyiltiz
<br/>
October 29, 2020 | https://www.codetd.com/en/article/12031985 | <a href="https://web.archive.org/web/*/https://www.codetd.com/en/article/12031985">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
                        <p><span>
                            <a href="https://www.codetd.com/en/cat/17746/1">News</a>
                        </span>
                            <span>2020-10-27 14:44:54</span>
                            <span>views: null</span>
                        </p>

                    </div><div><div> 
  
 <p><span><span>On October 25, a developer posted that the SM2 national secret algorithm was finally accepted by the Linux kernel community. </span><span>The author stated that the SM2 patch has been updated to version v7. This version of the patch was finally accepted by the community. It has been </span></span><a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/log/?qt=author&amp;q=Tianjia+Zhang"><span><span>merged into the 5.10-rc1 of the Linux mainline</span></span></a><span><span> . If nothing </span><a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/log/?qt=author&amp;q=Tianjia+Zhang"><span>else</span></a><span> , it will be officially released in the 5.10 kernel version.</span></span></p> 
 <p><span><span>National Secret is the abbreviation of National Commercial Encryption. The National Encryption Administration Bureau formulates algorithm standards, and it also formulates a large number of product and interface specifications and application scenarios. </span><span>Since 2012, the State Cryptography Administration has successively published SM2/SM3/SM4 and other cryptographic algorithm standards and their application specifications in the form of the "People's Republic of China Password Industry Standards". </span><span>Among them, "SM" stands for "commercial secret", which is a cryptographic technology used for commercial use that does not involve state secrets.</span></span></p> 
 <p><span><span>According to the author, the current Linux kernel has well supported the SM3 and SM4 algorithms, thanks to the widespread use of wireless LAN standards. </span><span>However, the SM2 algorithm and the national secret certificate have not been supported for a long time, and it is impossible to establish full-stack trust and integrity verification in the kernel based on the national secret. Therefore, it has become urgent to support this system in the kernel.</span></span></p> 
 <p><span><span>It took 7 rounds for the kernel community to accept SM2. </span><span>The initial consideration was to migrate from openssl, but the openssl architecture and infrastructure code needed to be ported because of the huge workload. </span><span>After several rounds of discussion and testing, I found that the existing libgcrypt already has a complete elliptic curve basic algorithm, so I tried to implement SM2 in libgcrypt first, and finally the SM2 algorithm was accepted by the community as a sub-algorithm of ECC. </span><span>After that, SM2 was gradually accepted by the kernel community.</span></span></p> 
 <p><span><span>At present, libgcrypt has fully supported the national secret algorithm SM2/3/4, and these implementations will be officially released in the next version 1.9.0. </span><span>At the same time, as a user-mode tool for IMA integrity signatures, ima-evm-utils' support for national secrets has not fallen. </span><span>Click to view </span></span><a href="https://sourceforge.net/p/linux-ima/ima-evm-utils/ci/ceecb28d3b5267c7d32c6e9401923c94f5786cfb/log/?path="><span><span>related submissions</span></span></a><span><span> .</span></span></p> 
 <p><span><span>Finally, the author also summarizes the known issues of SM2:</span></span></p> 
 <ul> 
  <li><span><span>To support national secret certificate verification, SM2 either does not compile, or it must be built-in compilation, and does not support compilation into modules. </span><span>Of course, SM2, as an asymmetric algorithm, only signs a hash or IMA verification based on national secrets, and there is no such limitation.</span></span></li> 
  <li><span><span>The IMA signature tool ima-evm-utils and the national secret algorithm used by the kernel to calculate the SM3 hash of the file do not add Za. This is a little difference from the specification.</span></span></li> 
 </ul> 
 <p><a href="https://linux.cn/article-12751-1.html"><span><span>Reference reading</span></span></a></p> 
</div></div></div>]]>
            </description>
            <link>https://www.codetd.com/en/article/12031985</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938686</guid>
            <pubDate>Fri, 30 Oct 2020 03:01:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Messy, Booming Business of Recycling Cruise Ships]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938508">thread link</a>) | @finphil
<br/>
October 29, 2020 | https://www.bnnbloomberg.ca/the-messy-booming-business-of-recycling-cruise-ships-1.1514614 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/the-messy-booming-business-of-recycling-cruise-ships-1.1514614">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>(Bloomberg) -- Carnival Fantasy was a ship famous for its outlandish dÃ©cor, all-night revelry and its sizeâ€”back when 2,000 was an incredible number of passengers. The â€œFun Shipâ€� vibe it introduced in 1990 came with such whimsical spaces as an Egyptian-themed piano bar, decorated with a fake sarcophagus, and a glitzy glass-topped atrium that was the hub of the social scene.</p><p>Today the Fantasy is attracting a whole different breed of booty-seeker. In July, the 30-year-old ship sailed to the Aegean Sea, wrapping its final voyageÂ&nbsp;in the shipbreaking capital of Aliaga, Turkey.</p><p>Its resting place there isÂ&nbsp;aÂ&nbsp;demolition yard where old cargo ships, tankers, research vesselsâ€”and now cruise ships retired during the Covid-19 pandemicâ€”get torn apart and broken into pieces. In this case, theyâ€™re not being broken in half to  get upgraded and stitched back together. Instead,Â&nbsp;circling the Fantasyâ€™s partially deconstructed innards are buyers from all sorts of industries, looking for rock bottom deals on everything from artwork and kitchenwares to electrical wires and stainless-steel sinks.</p><p>For the cruise company, itâ€™s an opportunity to recoup at least some value from an asset thatâ€™s currently acting as dead weight; while shipsâ€™ values  declineÂ&nbsp;with age, the Fantasy was originally built for about $225 million. And for the recycling companies that buy the vesselÂ&nbsp;for cash and take on the hazardous task of emptying all its valuables, itâ€™s a matter of a months-long salvage resale on steroids.</p><p>Cutting the Losses</p><p>Itâ€™s hard to gauge how exactly much money is made off of cruise ship recycling. Companies donâ€™t immediately disclose the sale prices of the vessels after relinquishing ownership, and the resale value of their most sought-after commodity, scrap steel, fluctuates in each global market on a daily basis.Â&nbsp;</p><p>But the business is booming.</p><p>Next to Carnival Fantasy in Aliaga are two otherÂ&nbsp;Fantasy-class ships built in the late 1990s. And next to them are two former Royal Caribbean vessels (scrapped by Royalâ€™s Spanish partner line Pullmantur Cruceros). The ships all had big fan bases, even as they aged. Fantasy and its sister ships started 2020 full of passengers bent on fun-in-the-sun activities in the Caribbean, Bahamas, and Mexican Riviera.</p><p>The ships would have left the fleet in coming years even in a healthy industry; the pandemic sped up the process, with owners of idled vesselsÂ&nbsp;hemorrhaging cashÂ&nbsp;and looking to cut their losses.</p><p>In its third quarter filing, Carnival Corporation said it planned to sell 18 â€œless efficientâ€� ships in 2020, resulting in a 12% reduction of its nine-brand fleet. â€œThose ships were giving us a bad drain,â€� Carnival CEO Arnold Donald said during a recent webinar with the Society of American Travel Writers.</p><p>Going, Going, Gone</p><p>Without much of a market for second-hand tonnage, the main worth of the ships is the steel that makes up the superstructure.</p><p>If, for instance, Carnival Fantasy has 15,000 tons of steel in its superstructure, the scrap may sell for upwards of $4.7 million based on current global market pricesâ€”though other factors also come into play, such as local prices and demand.</p><p>Along with the risk of these market fluctuations, the buyer also takes on the uncertainty of just how much metal can be salvaged. Pre-1990s ships tend to have more steel in their hulls and underwater plating, but those built in the â€™90s and after can bear lighter and stronger alloys.</p><p>Either way, steel and metal scraps will travel to a smelter to make rebar for construction projects around the world. Steel from some other dismantled ships can find its way to Turkeyâ€™s  large car manufacturing industry, where it might become parts for a Toyota orÂ&nbsp;a Ford.</p><p>Aluminum, copper, and stainless steel are also salvaged and resold, along with other valuable commodities that mostly remain in Turkey. The ripped out teak decks on Fantasy may end up in local shops, restaurants, and homes. Theater scenery and lighting may find its way into show productions. Even the tackiest artwork has some value, and can end up in restaurants throughout the country.</p><p>Buyers come to the yard for everything down to the bolts and nuts. Even if a used toilet sells for a fraction of the shelf price, multiply that amount by a few thousandâ€”given the number of cabins and public spaces on each shipâ€”and it can add up to a substantial sum.</p><p>According to Orbay Simsek, vice president of the Aliaga-based Simsekler Ship Recycling Company, there are even markets for kitchenware, closets, and blankets.Â&nbsp;</p><p>Basically anything and everything that can be sold, sells. Everything must go. Even the sarcophagus.</p><p>Eco-friendly Shipbreaking</p><p>Taking apart ships is a controversial topic, thanks to concerns over both human and environmental risks. Itâ€™s one of the most dangerous jobs in the world, according to Wouter Rozenveld, director of Sea2Cradle (SC2), an expert in green ship recycling who was hired by Carnival to oversee the safe dismantling of its ships. Each Carnival vessel may take up to nine months to break down, he says, and the blowtorch-based work comes with constant fire hazards.</p><p>Those hazards are amplified when the recyclable component pieces, like furniture, cabling, piping, and machinery inside each deck have to be carefully taken apart and separated says Ehud Bar-Lev, who overseesÂ&nbsp;assessment services at maritime specialist Lloydâ€™s Register.</p><p>The extra steps in disassembly also increase potential for hazardous waste spills, containing everything from oily residues to sludge, asbestos, and coolants in fridges.</p><p>To prevent those incidents, the Turkish shipbreaking yard undertakes its work in a concrete holding area that catches debris; in similar facilities throughout India and Bangladesh, the process may happen on the beach. Rather thanÂ&nbsp;letting toxic chemicals spew into the water, the Turkish yard collects the materials, has them cataloged by Sea2Cradle, and then hands them over toÂ&nbsp;the government-runÂ&nbsp;Ship Recycling Association of Turkey for proper disposal.</p><p>Carnival Corporation saw these precautions as a marketingÂ&nbsp;opportunity, making aÂ&nbsp;highly unusual move to publicize its efforts as â€œresponsible recycling.â€� But it was the shipbreaking yard, not Carnival, that saw the biggest windfall as a result:Â&nbsp;never before hasÂ&nbsp;AliagaÂ&nbsp;seen five mega cruise ships in its harbor.</p><p>There may be more coming in the months ahead.</p><p>â€œThe longer the pandemic rages on in the world, the more cruise ships will end up in scrapyards, and my guess is at an increasingly younger age,â€� says ManWo Ng, a maritime management professor at Virginiaâ€™s Old Dominion University. â€œEven if a vaccine becomes available, how many of us will be comfortable jumping right back on cruise ships?â€�</p><p>Â©2020 Bloomberg L.P.</p></div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/the-messy-booming-business-of-recycling-cruise-ships-1.1514614</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938508</guid>
            <pubDate>Fri, 30 Oct 2020 02:28:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Clojure?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938484">thread link</a>) | @simonpure
<br/>
October 29, 2020 | https://jeffchen.dev/posts/Why-Clojure/ | <a href="https://web.archive.org/web/*/https://jeffchen.dev/posts/Why-Clojure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One piece of unattributed wisdom that's stuck with me is "don't take more than one technology bet". At Ladder, our big bet is using <a href="https://clojure.org/" target="_blank" rel="nofollow noopener noreferrer">Clojure</a> for fullstack app development. Ladder's used Clojure since day 1 in 2015, and we wouldn't want it any different! In particular, Clojure's Lisp heritage, focus on pure functions and immutable data structures, unified client-server support, and superior developer experience have helped us write higher quality code faster.</p>
<!-- excerpt -->
<h2>Pure functions and immutability</h2>
<p>One of the challenges with ordinary, imperative programming languages like Javascript or Python is the increasing complexity of state management. As your application grows, it becomes harder and harder to isolate where in the codebase specific changes to your application state occur. This is because with typical application architectures in those languages, any function can perform <a href="https://en.wikipedia.org/wiki/Side_effect_%28computer_science%29" target="_blank" rel="nofollow noopener noreferrer">side effects</a> or modify incoming or global state. On the other hand, Clojure strongly emphasizes working with <a href="https://en.wikipedia.org/wiki/Pure_function" target="_blank" rel="nofollow noopener noreferrer">pure functions</a> (well, if you discount I/O...) and <a href="https://clojure.org/about/state" target="_blank" rel="nofollow noopener noreferrer">immutable data structures</a>. A Clojure programmer must be explicit when defining and modifying mutable state - this helps minimize its usage and makes it easier to reason about.</p>
<p>Immutable data structures and pure functions also lend themselves well to concurrent programming. We rarely find ourselves worrying about locks and shared data in a multi-threaded environment, because our functions are rarely modifying shared state. And when we do, Clojure provides <code>atom</code>, a thread-safe wrapper around ordinary data structures. Behind the scenes, setting an <code>atom</code>'s value calls <code>compare-and-set!</code>. That means no fussing around with locks or mutexes and no worrying about your data changing before you modify it. With this one simple construct, Clojure removes 99% of our concurrency headaches.</p>
<h2>Clojure is a Lisp</h2>
<p>There are probably enough Lisp arguments on the Internet already - I'll defer to <a href="https://clojure.org/about/rationale#_lisp_is_a_good_thing" target="_blank" rel="nofollow noopener noreferrer">Rich Hickey</a> (Clojure's creator) and <a href="http://www.paulgraham.com/avg.html" target="_blank" rel="nofollow noopener noreferrer">Paul Graham</a> instead of adding another rehash. That said, Clojure provides some advantages over other Lisps like Common Lisp and Scheme:</p>
<ul>
<li>CL only includes lists in its core language spec. Clojure introduces vectors, sets, and maps which makes reading and writing code so much less tedious. Of course Scheme has all of these except sets.</li>
<li>Clojure's core data structures are immutable which, as discussed above, makes reasoning about code, especially concurrent code, much easier.</li>
</ul>
<h2>Clojure runs everywhere</h2>
<p>Clojure provides first class support for sharing code between platforms with <a href="https://clojure.org/guides/reader_conditionals" target="_blank" rel="nofollow noopener noreferrer">reader conditionals</a>. Most of our namespaces at Ladder take advantage of this and are shared across our client (Clojurescript) and server (Clojure). In fact, all of our client React code (aside from browser-specific API calls like clipboard, input handlers, etc) supports being run on the JVM. This lets us run what we call "full-stack tests" entirely within a Java process. For example, we can run full user flows like "user can accept a life insurance policy" and assert against both client and server state <strong>in the same test</strong>. The closest analogue without this superpower would be running a Selenium test against a running webserver, which introduces all sorts of potential flakiness. For more on full-stack tests, check out <a href="https://www.youtube.com/watch?v=qijWBPYkRAQ&amp;t=346s" target="_blank" rel="nofollow noopener noreferrer">this talk</a> two of our engineers gave at Clojure West in 2017.</p>
<p>Clojure also provides easy <a href="https://clojure.org/guides/reader_conditionals#_host_interop" target="_blank" rel="nofollow noopener noreferrer">host interop</a> for each supported platform. This lets us leverage the full JVM (and Javascript) ecosystem. For example, we use popular Java libraries like <a href="https://www.eclipse.org/jetty/" target="_blank" rel="nofollow noopener noreferrer">Jetty</a>, <a href="https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients" target="_blank" rel="nofollow noopener noreferrer">kafka-clients</a>, <a href="https://github.com/google/tink" target="_blank" rel="nofollow noopener noreferrer">Tink</a>, and more. On the frontend, we use React, and can easily include other Javascript libraries for analytics, error handling, and session replays.</p>
<h2>Developer experience</h2>
<p>When I’ve worked with Typescript and Python in the past, I was constantly waiting for my development server to reload. Clojure makes updating code on your local server as simple as reloading the updated namespace in your REPL. If you want, you can even <a href="https://github.com/nrepl/nrepl" target="_blank" rel="nofollow noopener noreferrer">update remote, (hopefully) non-production webservers</a>! Being able to evaluate code in a REPL and have your running web server update in less than a second makes exploration and iteration on your actual backend so much faster. Instant feedback makes developers more playful and experimental. Ultimately, it helps them write better code faster.</p>
<p>It’s also super easy to run small chunks of code in the REPL. Ladder, like other Clojure shops, has a convention of documenting namespace usage with a <code>comment</code> block at the bottom. Developers can use the code within to learn the namespace’s API, run commonly used procedures, or test changes to the rest of the namespace - all without leaving their editor!</p>
<h2>Why not Clojure?</h2>
<p>While we're extremely satisfied with our choice of Clojure, we've had our fair share of headaches. First, Clojure processes take a long time to start up - especially as the size of the application grows. Our webserver at Ladder takes a full minute before it can accept web requests. This makes autoscaling in response to load more challenging - some of our load can spike in well under a minute, so we have to be consistently overprovisioned to handle it. Second, Clojure produces pretty big artifacts. This matters less on the backend, where our webserver JAR is over 1.5GB, but hurts us on the frontend. We still have work to do here, but our initial bundle is 7.2MB uncompressed (1.0MB gzipped)! If raw performance or bundle size is your primary concern, you might be better off choosing another language.</p>
<h2>Conclusion</h2>
<p>As a small company, we have more ideas to try than we have bandwidth to implement. Using Clojure has helped our team be more iterative and more productive, so we can ship more experiments and projects than we would otherwise be able to. I feel super lucky that Ladder introduced me to Clojure - and I'm excited to see how Clojure and our use of it continues to evolve!</p>
</div></div>]]>
            </description>
            <link>https://jeffchen.dev/posts/Why-Clojure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938484</guid>
            <pubDate>Fri, 30 Oct 2020 02:23:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Path for Mastering Japanese]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938456">thread link</a>) | @sova
<br/>
October 29, 2020 | https://japanesecomplete.com/path/ | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/path/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">    
    <!-- Hero section -->
    <section id="hero">
      <!-- Navigation -->
      <nav id="tmNav">              
        
      </nav>
      
      <div>
        <div>
            <h2>Mastering Japanese</h2>
            <p>
              Getting to Native-Level Japanese
              <br>A Straightforward <strong>Path to Mastery</strong>

              <br>by <span>Hake Hayashi</span><br>
              <span>27 October 2020</span>
            </p>
        </div>        
      </div>

            
    </section>

    <section id="introduction">
      <div>
        <div>
          <p><img src="https://japanesecomplete.com/img/castle-sunset.jpg" alt="Japanese Castle at Sunset">
          </p>
          <div>
            <div>
                <h2>The Syllabaries</h2>
                <div><p>
                  The Japanese language, called 日本語（にほんご）[knee-hohn-go] is composed of 2 major syllabaries, <strong>Hiragana and Katakana.</strong> Made up of <strong>Consonant-Vowel pairs</strong> [ka, ga, ta, su, mu] as opposed to single letters that can be combined in variety, Hiragana and Katakana are two versions of the same collection, Katakana being used for <strong>foreign loan words</strong> since the reorganization of public education in 1962.</p><p>
                  In addition to Hiragana (the native script) and Katakana (reserved for foreign loan-words post-62), Japan imported symbolic glyphs from mainland Asia and they are referred to as 漢字（かんじ） kanji — letters of the Han Dynasty.
              </p></div>
                <p>
                  You can learn the Hiragana in the inside front cover of our <a href="https://japanesecomplete.com/guide">guide</a> that contains information on essential grammar, sentence structure, sound-effect language, and covers some of the more nuanced aspects of the language in plain English.</p>
                  
            </div>
          </div>
        </div>

        <div>
          <div>
            <h4>Hiragana ひらがな</h4>
            <p>Warm and curvy, the ひらがな [hiragana] are used for native Japanese words and are the primary phonetic syllabary of Japanese.
            </p>
            <p>あ　い　う　え　お</p>
            <p>か　き　く　け　こ</p>
            <p>さ　し　す　せ　そ</p>
            <p>た　ち　つ　て　と</p>
            <p>ま　み　む　め　も</p>
            <p><a href="https://japanesecomplete.com/guide">Full Hiragana Chart in our Guide…</a></p>
          </div>
        
        <div>
          <h4>Katakana カタカナ</h4>
          <p>
            The カタカナ [katakana] are sharp and angular, and while letters to friends have been written entirely in Katakana (and Kanji), <a href="https://upload.wikimedia.org/wikipedia/commons/3/3f/Masabumi_Hosono_titanic_diary.jpg">such as this beautiful letter recovered from the Titanic,</a> since 1962 the カタカナ [katakana] have been reserved for foreign loan-words such as "computer" コンピュータ [konpyuuta] and "glass" ガラス [garasu].  <br>カタカナ [katakana] have a one-to-one correlation with the ひらがな [hiragana] similar to how English has print and cursive.
          </p>
        </div>
        <div>
          <h4>Kanji 漢字（かんじ）</h4>
          <p>
           The 漢字（かんじ） [kanji] were imported lock, stock, and barrel from mainland Asia starting in the 5th century.  Fewer than 4% of them are pictographs, and over 90% of the kanji are "meaning and sound borrowers."  You can read more about the <a href="https://learnjapanesebest.wordpress.com/2019/12/11/the-four-types-of-kanji/">four types of kanji here.</a>
          </p>
        </div>
      </div>
    </div></section> <!--end part1-->

      <section id="part2">
      <div>
        <div>
          <div>
            <div>
                <h2>Practice Listening + Identifying</h2>
                <p>
                  「聞き取れない」（ききとれない）[kiki-torenai] is the Japanese expression for "unable to get a clear ear grab" of a sound or a term when listening.  The audible morphemes of Japanese require plenty of exposure to be able to distinguish them easily, due in part to the clunkiness of the syllabaries, the ひらがな Hiragana and カタカナ Katakana.  
              </p>
              <p>
                Japanese Complete provides a <a href="https://japanesecomplete.com/path/japanesecomplete.com/hiragana">ひらがな Hiragana listening challenge</a> for free to all; our カタカナ Katakana listening challenge is available to <a href="https://japanesecomplete.com/purchase">premium subscribers</a>
              </p>
                <p>
                  The site <a href="https://supernative.tv/">SuperNative.tv</a> has an incredible cornucopia of film and television show clips that one can watch on replay with subtitles and fill-in-the-blank exercises to practice the ability to "ear catch" or "ear grab" the audible morphemes of Japanese.  We highly recommend this resource for new learners to get an "ear grip" of the common Japanese sounds and how they are actually pronounced.  Naturally, real-life speech and the way it is written down may not appear to match up perfectly until one has plenty of exposure.</p>
                  
            </div>
          </div>
          <p><img src="https://japanesecomplete.com/img/sakura-close.jpg" alt="Image">
          </p>
        </div>
    </div></section> <!--end part 2-->

  <section id="part3">
      <div>
        <div>
          <p><img src="https://japanesecomplete.com/img/shinkansen-night.jpg" alt="Image">
          </p>
          <div>
            <div>
                <h2>Grammar: Particles</h2>
                <p>
                  Rather than relying on word sequence, Japanese relies on particles to partner with words in order to indicate the role of the word in the sentence.  Think of particles as dancing partners wearing brightly colored clothing who let you know the current occupation of their partner.  A subject dances with a pink-scarf wearing dancer.  A topic dances with a blue-scarf wearing dancer.  A destination of travel dances with a green-scarf wearing dancer.  When we look at the dancers, we can see clearly who they are dancing with, letting us know what the sentence means.  
              </p>
              <p>Particles are used to explain the <strong>who, what, when, where, and how</strong> of Japanese sentences and they are in <strong>post-fix position</strong>, meaning that they follow the words to which they snap.</p>
              <p>Mastery of particles is essential to having a native-level understanding of Japanese.  In fact, by exploring a frequency dictionary or the <a href="https://pj.ninjal.ac.jp/corpus_center/bccwj/en/">Balanced Corpus of Contemporary Written Japanese,</a> one will find that <em>of the 37 most frequent words, 17 of them are particles (45%).</em></p>
                <p>
                  In Japanese Complete we teach particles using a method devised specifically for Japanese Complete and not available elsewhere: <strong>the bunsetsu jar</strong>.  Every jar (which contains a person, place, or thing) needs a lid (which contains a grammatical particle).</p>
                  
            </div>
          </div>
        </div>
    </div></section> <!--end part3-->

      <section id="part4">
      <div>
        <div>
          <div>
            <div>
                <h2>Kanji: Meanings</h2>
                <p>
                  Japan imported symbolic glyphs from mainland Asia and they are referred to as 漢字（かんじ） kanji — letters of the Han Dynasty and there are <a href="https://learnjapanesebest.wordpress.com/2019/12/11/the-four-types-of-kanji/">four types of kanji</a> where only 4% are simple pictographs and over 90% are "meaning-and-sound borrowers."
              </p>
              <p>In acquiring Japanese, modern learners often rely on methods inspired by <a href="https://smile.amazon.com/Remembering-Kanji-Complete-Japanese-Characters/dp/0824835921?pldnSite=1">Heisig's Remembering the Kanji,</a> a book written by James Heisig after he had arrived in Japan too late to take the introductory course; upon asking his friends what the hardest part of the language was, he was quickly informed that the Kanji are a most formidable adversary.  He took the spare time before the next semester started to try his best to conquer this formidable opponent, and in the process discovered that he could break the kanji down section-by-section, part-by-part, and develop clever mnemonic devices and imaginary scenes to remember their <strong>general meanings</strong> for the long-term.
              </p>
                <p>
                  Heisig only provides clear and concise mnemonics for the first hundred-or-so kanji in his series, which is quite deflating to the beginner, leaving much of the creative and mental work to the learner when they could be absorbing, rather than generating, content.  This is the reason that we have taken it upon ourselves at Japanese Complete to provide detailed mnemonic lessons for the kanji we teach.  You can see the most frequent 777 kanji on our <a href="https://japanesecomplete.com/777">777 kanji list.</a></p>
                
            </div>
          </div>
          <p><img src="https://japanesecomplete.com/img/shrine-green.jpg" alt="Image">
          </p>
        </div>
    </div></section> <!--end part 4-->

  <section id="part5">
      <div>
        <div>
          <p><img src="https://japanesecomplete.com/img/himeji-sky.jpg" alt="Image">
          </p>
          <div>
            <div>
                <h2>Verbs: Meanings, Connotations</h2>
                <p>
                  Every Japanese sentence ends with a verb.  Our classification scheme in Japanese Complete comes from conversations with expert language teachers from University College London and Middlebury College, schools renowned for their East Asian studies and language departments.  While normal textbooks try to wedge Japanese grammar as a round peg into the square-hole shape of English, Japanese Complete strives to simplify the equation as much as possible while retaining all the fidelity and integrity of real Japanese.  Our <a href="https://japanesecomplete.com/reverse-engineer/">Reverse Engineering a Japanese Sentence</a> page details how our classification of verbs and nouns differs from common textbooks, and illustrates how they are more coherent with actual Japanese.
              </p>
              <p>In general, verbs are the missing piece of every Japanese sentence and we must wait until the end of the sentence or phrase to hear or read them.  This is what makes translation and interpretation notoriously difficult, for a translator needing a verb to connect two thoughts, nouns, or ideas, must allow the Japanese speaker to complete the phrase, adding a significant delay to the process, all-the-while needing to be able to perceive the beginning of the next phrase.  The latency effect in translating and interpreting Japanese makes this skill quite coveted in tourism, national and international diplomacy, and any role where interpretation in real-time is a must.
              </p>
                <p>
                By learning a large subset of verbs in their "plain-form" first, and then learning how to transform verbs into their variety of tenses and aspects, one builds a solid foundation for understanding written and oral Japanese.  <strong>It is wise to familiarize oneself with the great variety of tenses, active and passive constructions, and formality levels early on, so that they are not completely foreign when encountered later on in advanced studies.</strong>  In Japanese Complete, we teach politeness levels, active and passive tenses, and the variety of verbs early on so that learners have a solid foundation and are not surprised to find whole new constructions in years 3 or 4, but instead are immediately confronted with the variegated tones of the language and its inflexions.
                </p>
                
            </div>
          </div>
        </div>
    </div></section> <!--end part 5-->

      <section id="part6">
      <div>
        <div>
          <div>
            <div>
                <h2>Kanji: Masking</h2>
                <p>
                  Have you ever written a message using emoji only?  Did you know that emoji is a word imported from Japanese?  
              </p>
              <p>
                Just as there are ways to communicate entirely using emoji, Japanese adopted a way early on of using …</p></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://japanesecomplete.com/path/">https://japanesecomplete.com/path/</a></em></p>]]>
            </description>
            <link>https://japanesecomplete.com/path/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938456</guid>
            <pubDate>Fri, 30 Oct 2020 02:19:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating large scale machine learning pipelines with MinIO and TensorFlow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24938451">thread link</a>) | @jtsymonds
<br/>
October 29, 2020 | https://blog.min.io/hyper-scale-machine-learning-with-minio-and-tensorflow/ | <a href="https://web.archive.org/web/*/https://blog.min.io/hyper-scale-machine-learning-with-minio-and-tensorflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <div><p>We are living in a transformative era defined by information and AI. Massive amounts of data are generated and collected every day to feed these voracious, state-of-the-art, AI/ML algorithms. The more data, the better the outcomes. </p><p>One of the frameworks that has emerged as the lead industry standards is <a href="https://www.tensorflow.org/">Google's TensorFlow</a>. &nbsp;Highly versatile, one can get started quickly and write simple models with their <a href="https://www.tensorflow.org/guide/keras?hl=en">Keras</a> framework. If you seek a more advanced approach TensorFlow also allows you to construct your own machine learning models using low level APIs. No matter what strategy you choose, TensorFlow will make sure that your algorithm gets optimized for whatever infrastructure you select for your algorithms - whether it's <a href="https://en.wikipedia.org/wiki/Central_processing_unit">CPU's</a>, <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit">GPU's</a> or <a href="https://en.wikipedia.org/wiki/Tensor_processing_unit">TPU's</a>.</p></div><p>As datasets become too large to fit into memory or local disk, AI/ML pipelines now have the requirement to load data from an external data source. Take for example the <a href="https://en.wikipedia.org/wiki/ImageNet">ImageNet</a> dataset with its <code>14 Million Images</code> with an estimated storage size of <code>1.31TB</code>. This dataset cannot be fit into memory nor on any machine local storage drive. These challenges are further complicated if your pipelines are running inside a stateless environment such a Kubernetes (which is increasingly the norm). </p><p>The emerging standard for this problem is to employ high performance object storage in the design of your AI/ML pipelines. MinIO is the leader in this space and has published a number of benchmarks that speak to its throughput capabilities. In this post, we will cover how to leverage MinIO for your TensorFlow projects. </p><p><strong>A Four Stage Hyper-Scale Data Pipeline</strong></p><p>To build a hyper-scale pipeline we will have each stage of the pipeline read from MinIO. In this example we are going to build four stages of a machine learning pipeline. This architecture will load the desired data on-demand from MinIO. </p><p>First, we are going to preprocess our dataset and encode it in a format that TensorFlow can quickly digest. This format is the <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord">tf.TFRecord</a>, which is a type of binary encoding for our data. We are taking this step because we do not want to waste time processing the data during the training as we are planning on loading each batch of training directly from MinIO as it's needed. If the data is pre-processed before we feed it into the model training we save a significant amount of time. Ideally, we create pre-processed chunks of data that group a good chunk of records - at least <code>100-200MB</code> in size.</p><p>To speed up the data-loading and training stages we are going to leverage the excellent <a href="https://www.tensorflow.org/api_docs/python/tf/data">tf.data</a> api. This API is designed to efficiently load data during the training/validation of our model. It prepares the next batch of data as the current one is being processed by the model. The advantage of this approach is that it ensures efficient utilization of expensive GPUs or TPUs which cannot sit idle due to slow loading data. MinIO does not encounter this problem - <a href="https://min.io/resources/docs/MinIO-Throughput-Benchmarks-on-NVMe-SSD-32-Node.pdf">it can saturate 100Gbps network with a few NVMe drives</a> or also <a href="https://min.io/resources/docs/MinIO-Throughput-Benchmarks-on-HDD-24-Node.pdf">with Hard Disk Drives</a> ensuring the pipeline is crunching data as fast as the hardware allows.</p><p>During training we want to make sure we store the training checkpoints of our model as well as TensorBoard histograms. The checkpoints are useful in case the training gets interrupted and we want to resume the training or if we get more data and want to keep training our model with the new data and the TensorBoard histograms let us see how the training is going as it happens. TensorFlow supports writing both of these directly to MinIO.</p><p>A quick side note. When the model is complete we will save it to MinIO as well - allowing us to serve it using <a href="https://www.tensorflow.org/tfx/guide/serving">TensorFlow Serving</a> &nbsp;- but that's a post for some other time.</p><figure><img src="https://blog.min.io/content/images/2020/05/Screen-Shot-2020-05-11-at-5.36.46-PM.png"><figcaption>End-to-End Pipeline using MinIO</figcaption></figure><h2 id="building-the-pipeline">Building the Pipeline</h2><p>For our hyper-scale pipeline we are going to use a dataset that can easily fit into your local computer so you can follow along. The <a href="https://ai.stanford.edu/~amaas/data/sentiment/">Large Movie Review Dataset </a>from Stanford is great since it has a large number of samples (25,000 for training and 25,000 for testing) so we are going to build a <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis model</a> that will tell us whether a movie review is <code>positive</code> or <code>negative</code>. Keep in mind that each step can be applied to any larger dataset. The advantage of this dataset is that you can try on your own computer. Let's get started!</p><p>Download the dataset and upload it to MinIO using <a href="https://docs.min.io/docs/minio-client-quickstart-guide.html">MinIO Client</a></p><pre><code>curl -O http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz
mc mb myminio/datasets
mc cp aclImdb_v1.tar.gz myminio/datasets/</code></pre><p>Let's start by declaring some configurations for our pipeline, &nbsp;such as <code>batch size</code>, location of our dataset and a fixed <code>random seed</code> so we can run this pipeline again and again and get the same results.</p><pre><code>random_seed = 44
batch_size = 128
datasets_bucket = 'datasets'
preprocessed_data_folder = 'preprocessed-data'
tf_record_file_size = 500
# Set the random seed
tf.random.set_seed(random_seed)

# How to access MinIO
minio_address = 'localhost:9000'
minio_access_key = 'minioadmin'
minio_secret_key = 'minioadmin'</code></pre><p>We are going to download our dataset from MinIO using <code><a href="https://github.com/minio/minio-py">minio-py</a></code></p><pre><code>minioClient = Minio(minio_address,
                  access_key=minio_access_key,
                  secret_key=minio_secret_key,
                  secure=False)
try:
       minioClient.fget_object(
           datasets_bucket,
           'aclImdb_v1.tar.gz',
           '/tmp/dataset.tar.gz')
except ResponseError as err:
       print(err)</code></pre><p>Now let's uncompress the dataset to a temporary folder (<code>/tmp/dataset</code>) to preprocess our data</p><pre><code>extract_folder = f'/tmp/{datasets_bucket}/'

with tarfile.open("/tmp/dataset.tar.gz", "r:gz") as tar:
    tar.extractall(path=extract_folder)</code></pre><h3 id="pre-processing">Pre-Processing</h3><p>Due to the structure of the dataset we are going to read from four folders, initially <code>test</code> and <code>train</code> which hold <code>25,000</code> examples each, then, in each of those folders we have <code>12,500</code> of each label <code>pos</code> for positive comments and <code>neg</code> for negative comments. From these four folders, we are going to store all samples into two variables, <code>train</code> and <code>test</code>. If we were preprocessing a dataset that couldn't fit in the local machine we could simply load segments of the object, one at a time and process them as well.</p><pre><code>train = []
test = []

dirs_to_read = [
    'aclImdb/train/pos',
    'aclImdb/train/neg',
    'aclImdb/test/pos',
    'aclImdb/test/neg',
]

for dir_name in dirs_to_read:
    parts = dir_name.split("/")
    dataset = parts[1]
    label = parts[2]
    for filename in os.listdir(os.path.join(extract_folder,dir_name)):
        with open(os.path.join(extract_folder,dir_name,filename),'r') as f:
            content = f.read()
            if dataset == "train":
                train.append({
                    "text":content,
                    "label":label
                })
            elif dataset == "test":
                test.append({
                    "text":content,
                    "label":label
                })</code></pre><p>We will then shuffle the dataset so we don't introduce bias into the training by providing 12,500 consecutive positive examples followed by 12,500 consecutive negative examples. Our model would have a hard time generalizing that. By shuffling the data the model will get to see and learn from both positive and negative examples at the same time.</p><pre><code>random.Random(random_seed).shuffle(train)
random.Random(random_seed).shuffle(test)</code></pre><p>Since we are dealing with text we need to turn the text to a vector representation that accurately depicts the meanings of the sentence. If we were dealing with images we would resize the images and turn them into vector representations having each pixel be a value of the resized image. </p><p>For text, however, we have a bigger challenge since a word doesn't really have a numerical representation. This is where <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> are useful. An embedding is a vector representation of some text, in this case we are going to represent the whole review as a single vector of 512 dimensions. Instead of doing the pre-processing of text manually (tokenizing, building vocabulary and training an embeddings layer) we are going to leverage an existing model called <a href="https://arxiv.org/abs/1803.11175">USE (Universal Sentence Encoder)</a> to encode sentences into vectors so we can continue with our example. This is one of the wonders of deep learning, the ability to re-use different models alongside yours. Here we use TensorFlow Hub and we are going to load the latest <code>USE</code> model.</p><pre><code>import tensorflow_hub as hub
embed = hub.load("https://tfhub.dev/google/universal-sentence-encoder-large/5")</code></pre><p>Since it would be too much to create the embeddings of <code>25,000</code> sentences and keep that in memory, we are going to slice our datasets into chunks of <code>500</code>.</p><p>To store our data into a <code>TFRecord</code> we need to encode the features as <code>tf.train.Feature</code>. &nbsp;We are going to store the label of our data as list of <code>tf.int64</code> and our Movie Review as a list of floats since after we encode the sentence using <code>USE</code> we will end-up with a embedding of <code>512</code> dimensions</p><pre><code>def _embedded_sentence_feature(value):
    return tf.train.Feature(float_list=tf.train.FloatList(value=value))
def _label_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))
def encode_label(label):
    if label == "pos":
        return tf.constant([1,0])
    elif label == "neg":
        return tf.constant([0,1])

# This will take the label and the embedded sentence and encode it as a tf.TFRecord
def serialize_example(label, sentence_tensor):
    feature = {
      'sentence': _embedded_sentence_feature(sentence_tensor[0]),
      'label': _label_feature(label),
    }
    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))
    return example_proto
    
def process_examples(records,prefix=""):
    starttime = timeit.default_timer()
    total_training = len(records)
    print(f"Total of {total_training} elements")
    total_batches = math.floor(total_training / tf_record_file_size)
    if total_training % tf_record_file_size != 0:
        total_batches += 1 
    print(f"Total of {total_batches} files of {tf_record_file_size} records")

    counter = 0
 …</code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.min.io/hyper-scale-machine-learning-with-minio-and-tensorflow/">https://blog.min.io/hyper-scale-machine-learning-with-minio-and-tensorflow/</a></em></p>]]>
            </description>
            <link>https://blog.min.io/hyper-scale-machine-learning-with-minio-and-tensorflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938451</guid>
            <pubDate>Fri, 30 Oct 2020 02:18:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predicting the stock market impact of the Presidential election outcome]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938426">thread link</a>) | @greatwave1
<br/>
October 29, 2020 | https://www.quiverquant.com/blog/092420 | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/blog/092420">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="presentation" width="100%"><tbody><tr><td><div id="hs_cos_wrapper_module_16009687456759" data-hs-cos-general-type="widget" data-hs-cos-type="module"><div id="hs_cos_wrapper_module_16009687456759_" data-hs-cos-general-type="widget" data-hs-cos-type="rich_text"><p>The effect of the election on health technology and health services stocks will likely depend not only on who wins the Presidency but also on whether or not Republicans maintain control of the Senate.</p>

<p>If Democrats win both the White House and the Senate (and maintain control of the House) you’ll see revived efforts to pick up the pieces of the Affordable Care Act and continue to transform the U.S. healthcare system. This transformation is likely to come at the expense of private healthcare companies' bottom lines.</p>

<p>On the other hand, Republicans maintaining control of the White House and/or Senate would likely result in a divided government, with no significant legislation on healthcare being passed.</p>

<p><span><strong>Cannabis</strong></span></p>
<p>Not surprisingly, most major cannabis stocks have a very low Trump Beta, meaning they are likely to perform well if Biden is elected.</p>

<p><a href="https://www.quiverquant.com/dashboard/cgc?utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--aeAl_3OrGl0eIcgqVx9ZyT6fLkP5VebAkQXLL8vu_yMXHRAtBKo4rmmQtRkFWTuB6kHhk" rel="noopener" data-hs-link-id="0" target="_blank">Canopy Growth Corp ($CGC)</a> has a Trump Beta of -0.20, <a href="https://www.quiverquant.com/dashboard/gwph?utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--aeAl_3OrGl0eIcgqVx9ZyT6fLkP5VebAkQXLL8vu_yMXHRAtBKo4rmmQtRkFWTuB6kHhk" rel="noopener" data-hs-link-id="0" target="_blank">GW Pharmaceuticals ($GWPH)</a> comes in at -0.29, and <a href="https://www.quiverquant.com/dashboard/cron?utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--aeAl_3OrGl0eIcgqVx9ZyT6fLkP5VebAkQXLL8vu_yMXHRAtBKo4rmmQtRkFWTuB6kHhk" rel="noopener" data-hs-link-id="0" target="_blank">Cronos Group ($CRON)</a> has a Trump Beta of -0.31.</p>

<p>Though Biden took a tough stance on federally controlled substances back in the 1980s and 1990s, he has recently embraced a platform of decriminalizing marijuana. Additionally, running mate Kamala Harris is known as an advocate for legalization. As a junior senator in California, she sponsored the Marijuana Opportunity Reinvestment and Expungement (MORE) Act, which the Democrat-controlled House Judiciary Committee passed last November. The bill hasn’t gotten anywhere yet, but many suppose that a democratic sweep this November could lead to marijuana legalization.</p>

<p>On the other hand, cannabis legislation has not been a priority under Trump, and there is no reason right now to believe that this will change during a second term.</p>

<p><span><strong>Large-cap Tech Companies</strong></span></p>
<p>Companies in the technology services and electronic technology sectors have an average Trump Beta of 0.12 and 0.15, respectively. This is primarily driven by the large-cap tech companies that dominate their industries, with Microsoft, Google, Apple, and Adobe all showing strong positive correlations with a Trump re-election.</p></div></div></td></tr></tbody></div></div>]]>
            </description>
            <link>https://www.quiverquant.com/blog/092420</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938426</guid>
            <pubDate>Fri, 30 Oct 2020 02:14:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advice from AI Experts to Those Starting Out in the Field]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938401">thread link</a>) | @navanchauhan
<br/>
October 29, 2020 | https://blog.re-work.co/ai-experts-advice-for-those-entering-the-field/ | <a href="https://web.archive.org/web/*/https://blog.re-work.co/ai-experts-advice-for-those-entering-the-field/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://blog.re-work.co/content/images/size/w300/2020/10/antenna-cw-cj_nFa14-unsplash.jpg 300w,
                            https://blog.re-work.co/content/images/size/w600/2020/10/antenna-cw-cj_nFa14-unsplash.jpg 600w,
                            https://blog.re-work.co/content/images/size/w1000/2020/10/antenna-cw-cj_nFa14-unsplash.jpg 1000w,
                            https://blog.re-work.co/content/images/size/w2000/2020/10/antenna-cw-cj_nFa14-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.re-work.co/content/images/size/w2000/2020/10/antenna-cw-cj_nFa14-unsplash.jpg" alt="20+ Pieces Of Advice From AI Experts To Those Starting Out In The Field">
</figure>
<section>
<div>
<p>Following on from our previous <a href="https://blog.re-work.co/tag/expert-blogs/">expert-led series</a>, we asked our community of AI experts what advice they would give to both those starting out their careers and those that have a desire to potentially join the field. </p><p>Below we have contributions from those working in both academia and industry settings, all at the forefront of AI development. What pieces of advice would you add?</p><p>TL;DR available in the footer. </p><h3 id="alexia-jolicoeur-martineau-phd-researcher-mila"><a href="https://www.linkedin.com/in/alexiajm/">Alexia Jolicoeur-Martineau</a>, PhD Researcher, MILA</h3><p>Here are some general advices, they are a bit more research oriented, but the perfectionism one applies even to applied positions..</p><ul><li>Don't over <strong>obsess on having everything 100% perfect</strong>. Develop a getting things done attitude. Academic perfectionism is the biggest plague in academia</li><li>Don't expect your research to speak for itself. Promotion (on social media) and dissemination (with blog posts) is important</li></ul><hr><h3 id="jane-wang-senior-research-scientist-deepmind"><a href="https://www.linkedin.com/in/jane-wang-63167017/">Jane Wang</a>, Senior Research Scientist, DeepMind</h3><p><strong>Don't chase after the hottest trends or the biggest splashes</strong>, as these areas will have the most competition and also will likely be superseded quickly anyway. Think about what kinds of problems you're most interested in solving, and what problems are likely to make the most impact if solved. The first involves being aware of what kinds of work you like doing (programming, theorizing, playing with real-world data, etc), and the second involves looking around and being informed about how the rest of the world lives. <strong>It's important we don't silo ourselves off in a bubble in this field</strong>, because this technology is making and will continue to make a huge impact on everyone in the world. Try to figure out what kind of role you want to have in that impact, and how to actively shape that impact to be beneficial for everyone.</p><hr><h3 id="abhishek-gupta-founder-montreal-ai-ethics-institute"><a href="https://www.linkedin.com/in/abhishekguptamcgill/">Abhishek Gupta</a>, Founder, Montreal AI Ethics Institute</h3><p>For those who are just getting started in an AI role, my primary advice would be to take a measured approach in believing AI to be a magic bullet that solves everything. As reality and business constraints emerge, an emerging practitioner will realize the role that simplicity plays in achieving real-world deployments and how taking an engineering and scientific approach to the deployment of the systems is more important than chasing every shiny new technique that they see on the internet. A deep understanding of the societal impacts of their work is also something that they should consider as a part of their work. And finally, thinking about the value of collaborating with domain experts should be something that is front and center for an emerging practitioner. <strong>I have seen far too many new practitioners apply AI skills to projects where there is no domain expertise involved and it inevitably leads to non-meaningful outcomes</strong> that diminish the value of the time and effort that goes into creating a project and can also result in harm for the people who are the subjects of that system.</p><hr><h3 id="andriy-burkov-director-of-data-science-gartner"><a href="https://www.linkedin.com/in/andriyburkov/">Andriy Burkov</a>, Director of Data Science, Gartner</h3><p>1. Learn the foundations. <strong>"Hands-on" alone, without an understanding of the underlying math, will not let you become the best in this profession</strong>. Today, and especially in the next 5-7 years, the tools will become so mature, that only your imagination will count. <strong>In AI, you cannot imagine anything meaningful if you don't know how the machine "thinks."</strong> Take a sculptor, an architect, or a painter. The best of them know everything about the tools and materials they work with. The same is true for AI.2.<strong> Go where the data is</strong>. AI is nothing without data, just as your talents.</p><hr><h3 id="alireza-fathi-senior-research-scientist-google"><a href="https://www.linkedin.com/in/alireza-fathi-04338411/">Alireza Fathi</a>, Senior Research Scientist, Google</h3><p>The two main pieces that I can think of that can result in a successful career in AI are the following: (a) <strong>strong math and coding fundamentals</strong> and (b) being on top of the most recently published papers in the field. I think a strong background in Algebra, probability and statistics, machine learning and at the same time powerful coding skills are critical to the success of an AI scientist in the long term. Sometimes (like now) the field becomes more practical and result oriented where coding is a very necessary skill to be able to implement ideas and run experiments quickly and efficiently.</p><p>But there will always be times when things become more theoretical and fundamental where having a strong math background can make a big difference. <strong>Being on top of AI literature is another very important skill. Unlike most other established fields where one can learn a lot from books, AI is a very new field that is evolving day to day</strong>. Methods that were achieving state of the art performance six months ago will be obsolete now. Thus, being able to quickly read papers, understand them and position them in the large body of previous work is a necessary skill for a successful AI scientist.</p><hr><h3 id="sarah-laszlo-phd-senior-neuroscientist-x-the-moonshot-factory"><a href="https://www.linkedin.com/in/sarah-laszlo-284886114/">Sarah Laszlo</a>, PhD, Senior Neuroscientist, X, The Moonshot Factory</h3><p>1) &nbsp;Don't judge yourself for not knowing something.</p><p><strong>One of my team's principles for working together is that we all agree that "Not knowing something only means not knowing something.</strong>" &nbsp;It doesn't have any other meaning: it doesn't mean you are stupid; it doesn't mean you are not trying hard enough; it doesn't mean you aren't good at your job. &nbsp;It only means that you don't know that particular thing. &nbsp;No one can know everything, and you shouldn't judge yourself because you don't.</p><p>Which brings us to #2:</p><p>2) Don't work with people who judge you for not knowing everything.</p><p>Don't work with people that make you feel like you don't belong, aren't smart enough, can't do this job. To the extent that you get to choose what teams you work on, gravitate to teams where not knowing something is seen as an opportunity to learn something new, rather than a strike against you.</p><p><strong>In my experience, a good sign of a good team is an environment where questions are not only welcome, but encouraged</strong>. When a complicated topic is raised, do people ask questions, or sit silently with a grim look of determined understanding on their face? Is the environment welcoming for questions and curiosity, or do team members seem embarrassed to ask questions? Do team members make an effort to explain complicated topics? &nbsp;Does the team value presentations that everyone in the audience understands? Wherever you can, you should require the teams that you work on to create an inclusive environment where everyone’s curiosity is respected and valued. It is possible to work in the AI field without constantly feeling impostor-syndrome dread; don't accept it as the norm.</p><hr><h3 id="frankie-cancino-senior-ai-scientist-target"><a href="https://www.linkedin.com/in/frankie-cancino/">Frankie Cancino</a>, Senior AI Scientist, Target </h3><p>Landing your first AI role is electrifying. A career in AI comes with many challenges, but it allows for innovation and exciting possibilities. My first piece of advice – <strong>don’t forget the basics and what got you there</strong>. It is easy to jump at the newest tech and methodologies. However, building a solid foundation with skills that can be applied across many domains will help with the additional building blocks. These skills will include writing code, statistics, probability theory, and linear algebra. Which leads into my second bit of advice – <strong>never stop learning</strong>. Continue to put yourself in situations that will require you to learn. </p><p>If you follow the first bit of advice, you will set yourself up for success and give yourself flexibility in implementing solutions. Keep in mind, the mathematical knowledge alone may not be enough. You will likely need to develop some domain expertise in the area you decide to pursue. Other skills such as writing (good) code, scalability, excellent user experience, and learning from past mistakes are important to develop. Since technology continuously evolves, you will have to continuously apply this learning mindset to keep up. Something extra I will leave with – remember your why. As with any job or career, it rarely goes as smooth as you would hope. Personally, I find work in AI fascinating, interesting, and fun. <strong>You may have a different reason for entering the field of AI. Whatever your reason may be, it’s good to remind yourself on occasion</strong>.</p><hr><h3 id="jeff-clune-research-team-leader-openai"><a href="https://www.linkedin.com/in/jeff-clune-56403a26/">Jeff Clune</a>, Research Team Leader, OpenAI</h3><p>When speaking to Jeff earlier this year, I asked him what advice he would give to someone starting a career in AI or Data Science. It was simple (mainly due to the quick-fire question format of our interview), but one that leaves you pondering. "To quote the words of Wayne Gretzky, the greatest of all time, <strong>skate to where the puck is going not where it is now.</strong>" &nbsp;</p><hr><h3 id="anirudh-koul-machine-learning-lead-nasa"><a href="https://www.linkedin.com/in/anirudhkoul/">Anirudh Koul</a>, Machine Learning Lead, NASA &nbsp;</h3><p><strong>Learn by building projects</strong>: Everybody learns differently, but you need excitement, you need the motivation to keep learning day after day - after the glamour of AI buzz words dies out. So what better way to learn than to take something relatable, build it in a few lines of code using high-level APIs. And as you start getting comfortable, then start to look at the inner theory and improve your breadth and depth in knowledge step by step.</p><p><strong>Training is just half the battle: </strong>Questions to ponder over when you build any project:</p><ul><li>What would your complete end to end pipeline look like?</li><li>How would you build a cloud API to serve the web frontend?</li><li>How do you scale from hundreds of images vs millions to billions?</li><li>What would be the cost involved in scaling this up?</li><li>How would you evaluate performance metrics, eg latency, and accuracy for model drift?</li><li>How would you process the new incoming data? When would you retrain the model?</li><li>While scaling up how do you make your network and pipeline efficient? How do you reduce the floating-point computations in your network? How would you reduce the size of the embeddings while still having the same representative power?</li><li>What could be potential sources of bias?</li></ul><p><strong>An experienced AI practitioner asks these questions from the get-go. So building experience in end to end projects teaches you industry-relevant skills early on.</strong></p><hr><h3 id="lofred-madzou-ai-project-lead-world-economic-forum"><a href="https://www.linkedin.com/in/lofred-madzou-5878a875/">Lofred Madzou</a>, AI Project Lead, World Economic Forum </h3><p>Over the past decade, artificial intelligence (AI) has emerged as the software engine that drives the Fourth Industrial Revolution, a …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.re-work.co/ai-experts-advice-for-those-entering-the-field/">https://blog.re-work.co/ai-experts-advice-for-those-entering-the-field/</a></em></p>]]>
            </description>
            <link>https://blog.re-work.co/ai-experts-advice-for-those-entering-the-field/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938401</guid>
            <pubDate>Fri, 30 Oct 2020 02:10:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Audio Visualizations Working with Web Audio API]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24938292">thread link</a>) | @arcatech
<br/>
October 29, 2020 | https://dwayne.xyz/post/audio-visualizations-web-audio-api | <a href="https://web.archive.org/web/*/https://dwayne.xyz/post/audio-visualizations-web-audio-api">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2>Web Audio API</h2>
<p>I’ve been working on getting WebRTC video chat working here on the website for a few weeks now. I finally got to the point where both text, video chat, and screen sharing all work really well, but somewhere in the back of my mind I kept thinking about complaints about “<a href="https://www.psychologytoday.com/us/blog/brain-waves/202007/why-zoom-fatigue-is-real-and-what-you-can-do-about-it">Zoom fatigue</a>” during the pandemic:</p>
<blockquote>
<p>Zoom fatigue, Hall argues now, is real. “Zoom is exhausting and lonely because you have to be so much more attentive and so much more aware of what’s going on than you do on phone calls.” If you haven’t turned off your own camera, you are also watching yourself speak, which can be arousing and disconcerting. The blips, delays and cut off sentences also create confusion. Much more exploration needs to be done, but he says, “maybe this isn’t the solution to our problems that we thought it might have been.” Phone calls, by comparison, are less demanding. “You can be in your own space. You can take a walk, make dinner,” Hall says.</p>
</blockquote>

<p>It’s kind of an interesting thing to have on your mind while spending weeks writing/debugging/testing video chat code.</p>
<p>So I decided to add an audio-only mode. And if I was gonna do that, I had to show something cool in place of the video. So I figured I would try to add audio visualizations when one or both of the users didn’t have video on. Using the relatively recent<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API">Web Audio API</a> seemed like the right way to go.</p>
<p>Here’s what I came up with:</p>
<div><video controls="" muted="" autoplay="" playsinline="" loop=""><source src="https://media.dwayne.xyz/blog/audio-visualization.mp4" type="video/mp4"></video><p>Screen recording of the local audio visualization. I cycle through bar graph in light mode, bar graph in dark mode, sine wave in dark mode, then sine wave in light mode.</p></div>
<h2>Creating and hooking up an AnalyserNode</h2>
<p>To create audio visualizations, the first thing you’ll need is an <code>AnalyserNode</code>, which you can get from the <code>createAnalyser</code> method of a <code>BaseAudioContext</code>. You can get both of these things pretty easily<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> like this:</p>
<pre><span>1</span><span>const</span> audioContext <span>=</span> <span>new</span> <span>window</span>.AudioContext();
<span>2</span><span>const</span> analyser <span>=</span> audioContext.createAnalyser();
</pre><p>Next, create a <code>MediaStreamAudioSourceNode</code> from an existing data stream (I use either the local or remote data streams from either <code>getUserMedia</code> or from the ‘track’ event of <code>RTCPeerConnection</code> respectively) using <code>AudioContext.createMediaStreamSource</code>. Then you can connect that audio source to the analyser object like this:</p>
<pre><span>1</span><span>const</span> audioSource <span>=</span> <span>this</span>.audioContext.createMediaStreamSource(stream);
<span>2</span>audioSource.connect(analyser);
</pre>
<h2>Using requestAnimationFrame</h2>
<p><code>window.requestAnimationFrame</code> is nice. Call it, passing in your drawing function, and then inside that function call <code>requestAnimationFrame</code> again. Get yourself a nice little recursive loop going that’s automatically timed properly by the browser.</p>
<p>In my situation, there will either be 0, 1, or 2 visualizations running, since either side can choose either video chat, audio-only (…except during screen sharing), or just text chat. So I have one loop that draws both. It looks like this:</p>
<pre><span>1</span><span>const</span> drawAudioVisualizations <span>=</span> () =&gt; {
<span>2</span>    audioCancel <span>=</span> <span>window</span>.requestAnimationFrame(drawAudioVisualizations);
<span>3</span>    localAudioVisualization.draw();
<span>4</span>    remoteAudioVisualization.draw();
<span>5</span>};
</pre><p>I created the class for those visualization objects, and they handle whether or not to draw. They each contain the analyser, source, and context objects for their visualization.</p>
<p>Then when I detect that loop doesn’t have to run anymore, I can cancel it using that <code>audioCancel</code> value:</p>
<pre><span>1</span><span>window</span>.cancelAnimationFrame(audioCancel);
<span>2</span>audioCancel <span>=</span> <span>0</span>;
</pre>
<h2>Configuring the Analyser</h2>
<p>Like in the <a href="https://github.com/mdn/voice-change-o-matic/blob/gh-pages/scripts/app.js">example you’ll see a lot</a> if you look at the MDN documentation for this stuff, I provide options for two audio visualizations: frequency bars and a sine wave. Here’s how I configure the analyser for each type:</p>
<pre><span> 1</span><span>switch</span> (<span>this</span>.type) {
<span> 2</span>    <span>case</span> <span>'frequencybars'</span><span>:</span>
<span> 3</span>        <span>this</span>.analyser.minDecibels <span>=</span> <span>-</span><span>90</span>;
<span> 4</span>        <span>this</span>.analyser.maxDecibels <span>=</span> <span>-</span><span>10</span>;
<span> 5</span>        <span>this</span>.analyser.smoothingTimeConstant <span>=</span> <span>0.85</span>;
<span> 6</span>        <span>this</span>.analyser.fftSize <span>=</span> <span>256</span>;
<span> 7</span>        <span>this</span>.bufferLength <span>=</span> <span>this</span>.analyser.frequencyBinCount;
<span> 8</span>        <span>this</span>.dataArray <span>=</span> <span>new</span> Uint8Array(<span>this</span>.bufferLength);
<span> 9</span>        <span>break</span>;
<span>10</span>    <span>default</span><span>:</span>
<span>11</span>        <span>this</span>.analyser.minDecibels <span>=</span> <span>-</span><span>90</span>;
<span>12</span>        <span>this</span>.analyser.maxDecibels <span>=</span> <span>-</span><span>10</span>;
<span>13</span>        <span>this</span>.analyser.smoothingTimeConstant <span>=</span> <span>0.9</span>;
<span>14</span>        <span>this</span>.analyser.fftSize <span>=</span> <span>1024</span>;
<span>15</span>        <span>this</span>.bufferLength <span>=</span> <span>this</span>.analyser.fftSize;
<span>16</span>        <span>this</span>.dataArray <span>=</span> <span>new</span> Uint8Array(<span>this</span>.bufferLength);
<span>17</span>        <span>break</span>;
<span>18</span>}
</pre><div><p>I’ve adjusted these numbers a lot, and I’m gonna keep doing it. A note about <code>fftSize</code> and <code>frequencyBinCount</code>: <code>frequencyBinCount</code> is set right after you set <code>fftSize</code> and it’s usually just half the <code>fftSize</code> value. These values are about the amount of data you want to receive from the main analyser functions I’m about to talk about next. As you can see, they directly control the size of the data array that you’ll use to store the audio data on each draw call.
</p></div>
<h2>Using the Analyser</h2>
<p>On each draw call, depending on the type of visualization, call either <code>getByteFrequencyData</code> or <code>getByteTimeDomainData</code> with the array that was created above, and it’ll be filled with data. Then you run a simple loop over each element and start drawing. Here’s my sine wave code:</p>
<pre><span> 1</span><span>this</span>.analyser.getByteTimeDomainData(<span>this</span>.dataArray);
<span> 2</span><span>this</span>.ctx.lineWidth <span>=</span> <span>2</span>;
<span> 3</span><span>this</span>.ctx.strokeStyle <span>=</span> audioSecondaryStroke;
<span> 4</span>
<span> 5</span><span>this</span>.ctx.beginPath();
<span> 6</span>
<span> 7</span><span>let</span> v, y;
<span> 8</span><span>for</span> (<span>let</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> <span>this</span>.bufferLength; i<span>++</span>) {
<span> 9</span>    v <span>=</span> <span>this</span>.dataArray[i] <span>/</span> <span>128.0</span>;
<span>10</span>    y <span>=</span> v <span>*</span> height <span>/</span> <span>2</span>;
<span>11</span>
<span>12</span>    <span>if</span> (i <span>===</span> <span>0</span>) {
<span>13</span>        <span>this</span>.ctx.moveTo(x, y);
<span>14</span>    } <span>else</span> {
<span>15</span>        <span>this</span>.ctx.lineTo(x, y);
<span>16</span>    }
<span>17</span>
<span>18</span>    x <span>+=</span> width <span>*</span> <span>1.0</span> <span>/</span> <span>this</span>.bufferLength;
<span>19</span>}
<span>20</span>
<span>21</span><span>this</span>.ctx.lineTo(width, height <span>/</span> <span>2</span>);
<span>22</span><span>this</span>.ctx.stroke();
</pre><div><p>The fill and stroke colors are dynamic based on the website color scheme.
</p></div>
<h2>Good ol' Safari</h2>
<p>So I did all of this stuff I just talked about, but for <strong>days</strong> I could <em>not</em> get this to work in Safari. Not because of errors or anything, but because both <code>getByteFrequencyData</code> and <code>getByteTimeDomainData</code> just filled the array with 0s every time. No matter what I did. I was able to get the audio data in Firefox just fine.</p>
<p>So at first, I figured it just didn’t work at all in Safari and I would just have to wait until Apple fixed it. But then I came across <a href="https://mdn.github.io/voice-change-o-matic/">this sample audio project</a> and noticed it worked just fine in Safari.</p>
<div><p>So I studied the code for an hour trying to understand what was different about my code and theirs. I made a lot of changes to my code to make it more like what they were doing. One of the big differences is that they’re connecting the audio source to different audio distortion nodes to actually change the audio. I just want to create a visualization so I wasn’t using any of those objects.
</p></div>
<h3>Audio Distortion Effects</h3>
<p>The <code>BaseAudioContext</code> has a few methods you can use to create audio distortion objects.</p>
<ul>
<li><code>WaveShaperNode</code>: Use <code>BaseAudioContext.createWaveShaper</code> to create a non-linear distortion. You can use a custom function to change the audio data.</li>
<li><code>GainNode</code>: Use <code>BaseAudioContext.createGain</code> to control the overall gain (volume) of the audio.</li>
<li><code>BiquadFilterNode</code>: Use <code>BaseAudioContext.createBiquadFilter</code> to apply some common audio effects.</li>
<li><code>ConvolverNode</code>: Use <code>BaseAudioContext.createConvolver</code> to apply reverb effects to audio.</li>
</ul>
<p>Each one of these objects has a <code>connect</code> function where you pass another context, output, or filter. Each one has a certain number of inputs and outputs. Here’s an example from that sample project of connecting all of them:</p>
<pre><span>1</span>source <span>=</span> audioCtx.createMediaStreamSource(stream);
<span>2</span>source.connect(distortion);
<span>3</span>distortion.connect(biquadFilter);
<span>4</span>biquadFilter.connect(gainNode);
<span>5</span>convolver.connect(gainNode);
<span>6</span>gainNode.connect(analyser);
<span>7</span>analyser.connect(audioCtx.destination);
</pre><p><strong>Note</strong>: Don’t connect to your audio context <code>destination</code> if you’re just trying to create a visualization for a call. The user will hear themselves talking.</p>
<div><p>Anyway, I tried adding these things to my code to see if that would get it working in Safari, but I had no luck.
</p></div>
<h2>Figuring out the Safari issue</h2>
<p>I was starting to get <em>real</em> frustrated trying to figure this out. I was gonna let it go when I thought Safari was just broken (because it usually is), but since I knew it <em>could</em> work in Safari, I couldn’t leave it alone.</p>
<p>Eventually I downloaded the actual HTML and Javascript files from that sample and started removing shit from their code, running it locally and seeing if it worked. Which it did. So now I’m editing my own code, and <em>their code</em>, to get them to be pretty much the same. Which I did. And <strong>still</strong> theirs worked and mine didn’t.</p>
<p>Next I just started desperately logging every single object at different points in my code to figure out what the fuck was going on. Then I noticed something.</p>
<div><p><img src="https://media.dwayne.xyz/blog/audio-context-suspended.png" alt="Dev console showing the output of logging this.audioContext. The state attribute is shown as suspended"></p><p>Output of logging the audio context object.</p></div>
<p>The <code>state</code> is “suspended”? Why? I don’t know. I did the same log in the sample code (that I had downloaded and was running on my machine) and it was “running”.</p>
<p>This is the code that fixes it:</p>
<pre><span>1</span><span>this</span>.audioSource <span>=</span> <span>this</span>.audioContext.createMediaStreamSource(<span>this</span>.stream);
<span>2</span><span>this</span>.audioSource.connect(<span>this</span>.analyser);
<span>3</span><span>this</span>.audioContext.resume(); <span>// Why??????
</span></pre><div><p>Calling <code>resume</code> changes the state and then everything works. To this day I still don’t know why the sample code didn’t need that line.
</p></div>
<h2>Drawing the image and supporting light/dark modes</h2>
<p>Like everything else on my site, all of this must support different color schemes (and screen sizes, and mobile devices). That was surprisingly difficult when trying to draw an SVG on the canvas.</p>
<p>I’m using <a href="https://fontawesome.com/">FontAwesome</a> for all my icons on the site. I wanted to use one of them for these visualizations. The FontAwesome files are all SVGs (which is great), but I didn’t know how to draw the image in different colors in Javascript. The way I decided to do this was to load the SVG file into a Javascript <code>Image</code> object, then draw that onto the canvas each draw call.</p>
<p>That worked, but it only drew it black even after changing the fill and stroke colors. So after some web searching I read about someone deciding to draw out an image on an offscreen canvas, reading all the image data, and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dwayne.xyz/post/audio-visualizations-web-audio-api">https://dwayne.xyz/post/audio-visualizations-web-audio-api</a></em></p>]]>
            </description>
            <link>https://dwayne.xyz/post/audio-visualizations-web-audio-api</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938292</guid>
            <pubDate>Fri, 30 Oct 2020 01:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Collections from API with Gridsome]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938194">thread link</a>) | @phongduong
<br/>
October 29, 2020 | https://phongduong.dev/blog/create-collections-from-api-with-gridsome/ | <a href="https://web.archive.org/web/*/https://phongduong.dev/blog/create-collections-from-api-with-gridsome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Gridsome provides many source plugins that help you create collections from your source. But if you want to create collections from your API or a third-party API, you have to create collections manually. </p>
<p>In <code>gridsome.server.js</code> file, you call <code>loadSource</code> method of <code>api</code> parameter. You pass a callback function which you will fetch the API and create collections from data.</p>
<p>Your callback has an <code>actions</code> parameter, it has <code>addCollection</code> method. You will use this method to create your collections</p>
<pre><code><span>const</span> axios <span>=</span> <span>require</span><span>(</span><span>"axios"</span><span>)</span>

module<span>.</span><span>exports</span> <span>=</span> <span>function</span><span>(</span><span>api</span><span>)</span> <span>{</span>
  api<span>.</span><span>loadSource</span><span>(</span><span>actions</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> <span>{</span> data <span>}</span> <span>=</span> <span>await</span> axios<span>.</span><span>get</span><span>(</span><span>'https://example.com/api/v1/posts'</span><span>)</span>
    <span>const</span> postCollection <span>=</span> actions<span>.</span><span>addCollection</span><span>(</span><span>"Post"</span><span>)</span>
    
    <span>for</span><span>(</span><span>const</span> post <span>of</span> data<span>)</span> <span>{</span>
      postCollection<span>.</span><span>addNode</span><span>(</span><span>{</span>
        id<span>:</span> post<span>.</span><span>id</span><span>,</span>
        title<span>:</span> post<span>.</span><span>title</span>
      <span>}</span><span>)</span>
    <span>}</span>
  <span>}</span>
<span>}</span><span>;</span></code></pre>
<p>After you start the server, it will create <code>Post</code> collection. To get the collection, you call <code>getCollection</code> method with the collection's name</p>
<pre><code>actions<span>.</span><span>getCollection</span><span>(</span><span>"Post"</span><span>)</span></code></pre>
</div></div>]]>
            </description>
            <link>https://phongduong.dev/blog/create-collections-from-api-with-gridsome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938194</guid>
            <pubDate>Fri, 30 Oct 2020 01:32:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantbase – Deploy your own algo trader in 5 minutes with 0 code]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938082">thread link</a>) | @tjs8rj
<br/>
October 29, 2020 | https://areyouinterested.co/site/quantbase/ | <a href="https://web.archive.org/web/*/https://areyouinterested.co/site/quantbase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="hero-1"><p id="subheading">Deploy algorithms from top hedge funds,<br> rank and use 100s of users’ algorithms,<br> or create new algo-traders effortlessly</p>

              <div id="interested">
                <h3>Are you interested?</h3>
                <div id="buttons">
                  <p><a href="https://areyouinterested.co/site/quantbase/yes" id="yes">Yes</a>
                  <a href="https://areyouinterested.co/site/quantbase/no" id="no">No</a>
                </p></div>
              </div>

            </div></div>]]>
            </description>
            <link>https://areyouinterested.co/site/quantbase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938082</guid>
            <pubDate>Fri, 30 Oct 2020 01:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vega-Lite: A Grammar of Interactive Graphics]]>
            </title>
            <description>
<![CDATA[
Score 152 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24937954">thread link</a>) | @tosh
<br/>
October 29, 2020 | https://vega.github.io/vega-lite/ | <a href="https://web.archive.org/web/*/https://vega.github.io/vega-lite/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <section>
    <p>
  <strong>Vega-Lite</strong> is a high-level grammar of interactive graphics. It provides a concise, declarative JSON syntax to create an expressive range of visualizations for data analysis and presentation.
</p>

<p><span>
  <span>
    Vega-Lite specifications describe visualizations as encoding mappings from data to <strong>properties of graphical marks</strong> (e.g., points or bars).
    The Vega-Lite compiler <strong>automatically produces visualization components</strong> including axes, legends, and scales.
    It determines default properties of these components based on a set of <strong>carefully designed rules</strong>.
    This approach allows Vega-Lite specifications to be concise for quick visualization authoring, while giving user control to override defaults and customize various parts of a visualization.
    As we also designed Vega-Lite to support data analysis, Vega-Lite supports both <strong>data transformations</strong> (e.g., aggregation, binning, filtering, sorting) and <strong>visual transformations</strong> (e.g., stacking and faceting).
    Moreover, Vega-Lite specifications can be <strong>composed</strong> into layered and multi-view displays, and made <strong>interactive with selections</strong>.
  </span>
  <span>
  <a href="https://vega.github.io/vega-lite/tutorials/getting_started.html">Get started<br><small>Latest Version: 4.17.0</small></a>
  <a href="https://vega.github.io/editor/#/custom/vega-lite">Try online</a>
  </span>
</span></p>

<p>Compared to <a href="https://vega.github.io/vega">Vega</a>, Vega-Lite provides a more concise and convenient form to author common visualizations. As Vega-Lite can compile its specifications to Vega specifications, users may use Vega-Lite as the <em>primary</em> visualization tool and, if needed, transition to use the lower-level Vega for advanced use cases.</p>

<p>For more information, read our <a href="https://medium.com/@uwdata/de6661c12d58">introduction article to Vega-Lite v2 on Medium</a>, watch our <a href="https://www.youtube.com/watch?v=9uaHRWj04D4">OpenVis Conf talk about the new features in Vega-Lite v2</a>, see the <a href="https://vega.github.io/vega-lite/docs/">documentation</a> and take a look at our <a href="https://vega.github.io/vega-lite/examples/">example gallery</a>. Follow us on <a href="https://twitter.com/vega_vis">Twitter at @vega_vis</a> to stay informed about updates.</p>

<h2 id="example">Example</h2>



<h2 id="additional-links">Additional Links</h2>

<ul>
  <li>Award winning <a href="https://idl.cs.washington.edu/papers/vega-lite">research paper</a> and <a href="https://www.youtube.com/watch?v=9uaHRWj04D4">video of our OpenVis Conf talk</a> on the design of Vega-Lite</li>
  <li>Listen to a Data Stories episode about <a href="http://datastori.es/121-declarative-visualization-with-vega-lite-and-altair-with-dominik-moritz-jacob-vanderplas-kanit-ham-wongsuphasawat/">Declarative Visualization with Vega-Lite and Altair</a>
</li>
  <li>
<a href="http://json-schema.org/">JSON schema</a> specification for <a href="https://github.com/vega/schema">Vega-Lite</a> (<a href="https://vega.github.io/schema/vega-lite/v4.json">latest</a>)</li>
  <li>Ask questions about Vega-Lite on <a href="https://stackoverflow.com/tags/vega-lite">Stack Overflow</a> or <a href="https://bit.ly/join-vega-slack-2020">Slack</a>
</li>
  <li>Fork our <a href="https://bl.ocks.org/domoritz/455e1c7872c4b38a58b90df0c3d7b1b9">Vega-Lite Block</a>, or <a href="https://beta.observablehq.com/@domoritz/vega-lite-demo">Observable Notebook</a>.</li>
</ul>

<h2 id="users">Users</h2>

<p>Vega-Lite is used by thousands of data enthusiasts, developers, journalists, data scientists, teachers, and researchers across many organizations. Here are some of them. Learn about integrations on our <a href="https://vega.github.io/vega-lite/ecosystem.html">ecosystem page</a>.</p>



<h2 id="team">Team</h2>

<p>The development of Vega-Lite is led by the alumni and members of the <a href="https://idl.cs.washington.edu/">University of Washington Interactive Data Lab</a> (UW IDL), including <a href="https://twitter.com/kanitw">Kanit “Ham” Wongsuphasawat</a> (now at Apple), <a href="https://twitter.com/domoritz">Dominik Moritz</a> (now at CMU / Apple), <a href="https://twitter.com/arvindsatya1">Arvind Satyanarayan</a> (now at MIT), and <a href="https://twitter.com/jeffrey_heer">Jeffrey Heer</a> (UW IDL).</p>

<p>Vega-Lite gets significant contributions from its community–in particular <a href="https://willium.com/">Will Strimling</a>, <a href="https://github.com/YuhanLu">Yuhan (Zoe) Lu</a>, <a href="https://github.com/invokesus">Souvik Sen</a>, <a href="https://github.com/chanwutk">Chanwut Kittivorawong</a>, <a href="https://github.com/mattwchun">Matthew Chun</a>, <a href="https://github.com/AkshatSh">Akshat Shrivastava</a>, <a href="https://github.com/Saba9">Saba Noorassa</a>, <a href="https://github.com/sirahd">Sira Horradarn</a>, <a href="https://github.com/donghaoren">Donghao Ren</a>, and <a href="https://github.com/haldenl">Halden Lin</a>. Please see the <a href="https://github.com/vega/vega-lite/graphs/contributors">contributors page</a> for the full list of contributors.</p>

  </section>
</div></div>]]>
            </description>
            <link>https://vega.github.io/vega-lite/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937954</guid>
            <pubDate>Fri, 30 Oct 2020 00:52:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Adding a simple Reddit feed to your Discord with Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937851">thread link</a>) | @DanWritesCode
<br/>
October 29, 2020 | https://danwalker.com/python-discord-reddit-feed/ | <a href="https://web.archive.org/web/*/https://danwalker.com/python-discord-reddit-feed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <main aria-label="Content"> <article itemscope="" itemtype="https://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>I’m a moderator of many Discords, and I run a lot of bots and scripts to help manage and improve communities. It’s pretty common for larger subreddits to have a Discord server these days, and for that reason, today we’re going to be looking at a useful feature for both users and moderators alike: adding a Reddit feed to your Discord server.</p> <h2 id="what-well-be-doing"> <a href="#what-well-be-doing"></a> What we’ll be doing </h2> <p>We’re going to create a separate channel in our Discord server, and receive updates about any new posts within a given subreddit. We’ll be using /r/discordapp for this post. We’ll create a Python script to do the work for us, and this script will need to live somewhere (such as a <a href="https://m.do.co/c/f24e8a65668a">Digital Ocean VPS</a> - click for free credit).</p> <h3 id="create-a-discord-channel-and-webhook"> <a href="#create-a-discord-channel-and-webhook"></a> Create a Discord channel and webhook </h3> <p>For this example, we will first create a new channel called <code>#reddit-feed</code>, with read-only permissions for everyone:</p> <p><img src="https://danwalker.com/python-discord-reddit-feed/discord-new-channel.png" alt="Discord channel creation"></p> <p>Once created, open the settings page for the new channel, and then select the Integrations section from the left menu:</p> <p><img src="https://danwalker.com/python-discord-reddit-feed/webhook-create.png" alt="Discord channel editing"></p> <p>Finally, create a new webhook. You can call it whatever you’d like, I’ll simply name it <code>Reddit Feed</code> for this example. Be sure to save your changes, and voila! We can visit this page any time to copy our webhook URL.</p> <p>Let’s test out our new webhook from the terminal, before we get started with code.</p> <div><div><pre><code>$ export WEBHOOK_URL="https://discord.com/api/webhooks/YOUR_WEBHOOK_HERE"
$ curl -X POST -H "Content-Type: application/json" -d '{"username": "Hello", "content": "World"}' $WEBHOOK_URL
</code></pre></div></div> <p>Success!</p> <p><img src="https://danwalker.com/python-discord-reddit-feed/discord-message.png" alt="Discord message"></p> <h3 id="fetching-posts"> <a href="#fetching-posts"></a> Fetching posts </h3> <p>Now let’s start our actual Python code, we’ll begin by fetching a list of posts from Reddit. Luckily, Reddit makes this quite easy as you can append <code>.json</code> to most URLs to receive a JSON formatted response, for example: <code>https://www.reddit.com/r/discordapp/new/.json</code> which will return the 25 newest posts from /r/discordapp.</p> <p>Let’s fetch it with Python</p> <div><div><pre><code><span>import</span> <span>requests</span>

<span>subreddit</span> <span>=</span> <span>'discordapp'</span>

<span>req</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>f'https://www.reddit.com/r/</span><span>{</span><span>subreddit</span><span>}</span><span>/new/.json'</span><span>,</span> <span>headers</span><span>=</span><span>{</span>
    <span>"Cache-Control"</span><span>:</span> <span>"no-cache"</span><span>,</span>
    <span>"Pragma"</span><span>:</span> <span>"no-cache"</span><span>,</span>
    <span>"User-Agent"</span><span>:</span> <span>"discord-feed-bot"</span><span>})</span>

<span>posts</span> <span>=</span> <span>req</span><span>.</span><span>json</span><span>()[</span><span>'data'</span><span>][</span><span>'children'</span><span>]</span>

<span>for</span> <span>post</span> <span>in</span> <span>posts</span><span>:</span>
    <span>print</span><span>(</span><span>f"Found post: </span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'title'</span><span>]</span><span>}</span><span>"</span><span>)</span>

</code></pre></div></div> <p>First of all we load the <code>requests</code> library for fetching data from Reddit.</p> <p>Next we store the subreddit in a variable, and send a request to Reddit for the JSON of the latest posts. We use some headers here to make sure we avoid cache, and it’s also good practice to set a user-agent that identifies the creator - you could put an invite link to your Discord here, or similar.</p> <p>We then loop through the individual posts, which are stored within the <code>posts &gt; data &gt; children</code> of the returned JSON.</p> <p>Running the above should give an output similar to this:</p> <div><div><pre><code>Found post: Discord logged me out and is now telling me that my email doesn't exist
Found post: any ETA for Wayland support?
Found post: Is there a way to change a discord server's "permanent" invite link?
Found post: Discord's app breaking in an odd way. Send help.

[output truncated]
</code></pre></div></div> <h2 id="only-showing-new-posts"> <a href="#only-showing-new-posts"></a> Only showing new posts </h2> <p>Now, the problem is, every time we run the above script we will grab all the new posts, regardless of whether or not we’ve seen them before. If we run this script as a one-minute cronjob, 25 posts will be repeatedly found each time.</p> <p>There are many ways to deal with this, for example if we know we’ll be running this script every minute, we could check the <code>post['data']['created']</code> timestamp and check whether or not the post was created in the last minute and then display it. This approach may miss posts if our cronjob fails for any reason, or the server running it reboots, so we could use a cache instead to help get round this.</p> <p>By storing a list of post IDs we have already discovered, we can avoid sending duplicate messages, and it doesn’t matter if the script doesn’t run for a short while.</p> <h3 id="caching-locally"> <a href="#caching-locally"></a> Caching locally </h3> <p>We’ll store a list of seen post IDs in a file. Let’s add a block of code at the top to check whether the file exists and load the data if so:</p> <div><div><pre><code><span>import</span> <span>json</span>

<span>try</span><span>:</span>
    <span>with</span> <span>open</span><span>(</span><span>'db.json'</span><span>)</span> <span>as</span> <span>json_file</span><span>:</span>
        <span>db</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>json_file</span><span>)</span>
<span>except</span> <span>FileNotFoundError</span><span>:</span>
    <span>db</span> <span>=</span> <span>[]</span>
</code></pre></div></div> <p>Now we have a <code>db</code> list, which is either a list of post IDs we’ve already seen, or an empty list (because we haven’t seen any before). We’ll add any new IDs to this list later, and save it, with this block at the end of our script:</p> <div><div><pre><code><span>with</span> <span>open</span><span>(</span><span>'db.json'</span><span>,</span> <span>'w'</span><span>)</span> <span>as</span> <span>outfile</span><span>:</span>
    <span>json</span><span>.</span><span>dump</span><span>(</span><span>db</span><span>,</span> <span>outfile</span><span>,</span> <span>indent</span><span>=</span><span>2</span><span>)</span>
</code></pre></div></div> <h3 id="checking-whether-posts-are-unique"> <a href="#checking-whether-posts-are-unique"></a> Checking whether posts are unique </h3> <p>We only need to store a single piece of uniquely identifying information for each post, and for that we can use the <code>name</code> field which will have a format like <code>t3_abcde1</code>. Let’s modify our loop to look like this:</p> <div><div><pre><code><span>for</span> <span>post</span> <span>in</span> <span>posts</span><span>:</span>
    <span>if</span> <span>post</span><span>[</span><span>'data'</span><span>][</span><span>'name'</span><span>]</span> <span>not</span> <span>in</span> <span>db</span><span>:</span>
        <span>print</span><span>(</span><span>f"New post: </span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'title'</span><span>]</span><span>}</span><span>"</span><span>)</span>
        <span>db</span><span>.</span><span>append</span><span>(</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'name'</span><span>])</span>
</code></pre></div></div> <p>We should now have some output that looks like this:</p> <div><div><pre><code>Dans-MacBook-Pro:Desktop dwalker$ python3 test.py 
New post: Mic Distortion In Voice Calls and Mic Test
New post: Did anyone get that survey pop up?
...
[output truncated]
...
New post: Why is my phone number being listed as invalid when I have not used it for anything?
New post: Is there a way to get admin if you lost it?
Dans-MacBook-Pro:Desktop dwalker$ python3 test.py 
Dans-MacBook-Pro:Desktop dwalker$ cat db.json 
[
  "t3_jiqtfg",
  "t3_jiqoqr",
  ...
  [output truncated]
  ...
  "t3_jinmi4",
  "t3_jinbaj"
]Dans-MacBook-Pro:Desktop dwalker$ 
</code></pre></div></div> <p>Notice in the above example, on the second run of the script, no new posts were found, meaning our cache is working as expected.</p> <h3 id="limiting-the-cache-size"> <a href="#limiting-the-cache-size"></a> Limiting the cache size </h3> <p>One thing to note, as it’s good practice to always think about scaling and future growth, is that our cache will grow infinitely with post IDs. In order to fix this, we can limit how much we store in our cache.</p> <p>This is a simple fix, instead of dumping the entire <code>db</code> list to the output file, let’s just add the last 50 elements, by using <code>db[-50:]</code>. We can reference a list element from the end of a list, using negative numbers. By using a colon, we’re telling Python we want that element, and every element until the end of the list.</p> <p>Why 50? Reddit will return 25 new posts, however, if some get deleted then we may display duplicates when older posts re-appear on the <code>/new/.json</code> page, so we’ll store an extra page worth as a buffer.</p> <p>Our new output block looks like:</p> <div><div><pre><code><span>with</span> <span>open</span><span>(</span><span>'db.json'</span><span>,</span> <span>'w'</span><span>)</span> <span>as</span> <span>outfile</span><span>:</span>
    <span>json</span><span>.</span><span>dump</span><span>(</span><span>db</span><span>[</span><span>-</span><span>50</span><span>:],</span> <span>outfile</span><span>,</span> <span>indent</span><span>=</span><span>2</span><span>)</span>
</code></pre></div></div> <h2 id="posting-to-discord"> <a href="#posting-to-discord"></a> Posting to Discord </h2> <p>Now we’ve got a script that works nicely in the terminal, let’s get it posting to the Discord webhook we created earlier. To create a nice embed, we’re going to use the <code>discord_webhook</code> library, which can be installed with <code>pip install discord_webhook</code> (or <code>pip3</code>, depending on your setup). We’ll import the bits we need at the top of our file with:</p> <div><div><pre><code><span>from</span> <span>discord_webhook</span> <span>import</span> <span>DiscordWebhook</span><span>,</span> <span>DiscordEmbed</span>

<span>webhook_url</span> <span>=</span> <span>"https://discord.com/api/webhooks/..."</span>
</code></pre></div></div> <p>Replace the above URL with your webhook URL you created earlier.</p> <h3 id="building-the-embed"> <a href="#building-the-embed"></a> Building the embed </h3> <p>Our current loop simply prints out the name of the new post in the terminal. We could simply post the title to Discord, but Discord supports rich embeds - so why not make use of them?</p> <p>Reddit posts come in three formats: text, image, and video. We know a post is a text post if the <code>thumbnail</code> property is set to <code>self</code>. Posts also contain a handy <code>is_video</code> property which identify video posts, and if a post matches neither of these then it’s an image post.</p> <p>Unfortunately, Discord doesn’t currently support embedding videos that are playable within the chat client, so we’ll use the thumbnail and add some information to show that the post is a video.</p> <div><div><pre><code><span>webhook</span> <span>=</span> <span>DiscordWebhook</span><span>(</span><span>url</span><span>=</span><span>webhook_url</span><span>)</span>

<span>permalink</span> <span>=</span> <span>f"https://www.reddit.com</span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'permalink'</span><span>]</span><span>}</span><span>"</span>

<span>if</span> <span>post</span><span>[</span><span>'data'</span><span>][</span><span>'thumbnail'</span><span>]</span> <span>==</span> <span>'self'</span><span>:</span> <span># text post
</span>    <span>embed</span> <span>=</span> <span>DiscordEmbed</span><span>(</span><span>title</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'title'</span><span>],</span> <span>url</span><span>=</span><span>permalink</span><span>,</span> <span>description</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'selftext'</span><span>])</span>
    <span>embed</span><span>.</span><span>set_footer</span><span>(</span><span>text</span><span>=</span><span>f"Posted by </span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'author'</span><span>]</span><span>}</span><span>"</span><span>)</span>

<span>elif</span> <span>post</span><span>[</span><span>'data'</span><span>][</span><span>'is_video'</span><span>]:</span> <span># video post
</span>    <span>embed</span> <span>=</span> <span>DiscordEmbed</span><span>(</span><span>title</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'title'</span><span>],</span> <span>url</span><span>=</span><span>permalink</span><span>)</span>
    <span>embed</span><span>.</span><span>set_image</span><span>(</span><span>url</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'thumbnail'</span><span>])</span>
    <span>embed</span><span>.</span><span>set_footer</span><span>(</span><span>text</span><span>=</span><span>f"Video posted by </span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'author'</span><span>]</span><span>}</span><span>"</span><span>)</span>

<span>else</span><span>:</span> <span># image post
</span>    <span>embed</span> <span>=</span> <span>DiscordEmbed</span><span>(</span><span>title</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'title'</span><span>],</span> <span>url</span><span>=</span><span>permalink</span><span>)</span>
    <span>embed</span><span>.</span><span>set_image</span><span>(</span><span>url</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'url'</span><span>])</span>
    <span>embed</span><span>.</span><span>set_footer</span><span>(</span><span>text</span><span>=</span><span>f"Image posted by </span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'author'</span><span>]</span><span>}</span><span>"</span><span>)</span>
</code></pre></div></div> <p>Once the above code has executed, we have a webhook object, and an embed object. To add the newly created embed in to the webhook request and execute it, we simply do:</p> <div><div><pre><code><span>webhook</span><span>.</span><span>add_embed</span><span>(</span><span>embed</span><span>)</span>
<span>webhook</span><span>.</span><span>execute</span><span>()</span>
</code></pre></div></div> <p>Which is pretty self-explanatory. We could capture the output of <code>webhook.execute()</code> to check whether things went ok. One problem we typically encounter is being rate limited if we use the webhook in quick succession. A simple workaround for this is to <code>import time</code> at the top of the file, and then add a <code>time.sleep(1)</code> after the execution above, to pause for a second after each webhook post.</p> <h2 id="fin"> <a href="#fin"></a> Fin </h2> <p><img src="https://danwalker.com/python-discord-reddit-feed/discord-feed.png" alt="Discord feed"></p> <p>Run the script on a cronjob, and voila!</p> <p>I keep a single small Digital Ocean VPS which hosts all my Discord bots and scrapers. An example cronjob to execute every 5 minutes might for this script could look like:</p> <div><div><pre><code><span>*</span>/5 <span>*</span> <span>*</span> <span>*</span> <span>*</span> /usr/bin/python /root/scripts/reddit2discord.py <span>&gt;&gt;</span> /dev/null 2&gt;&amp;1
</code></pre></div></div> <p>Some ideas to extend this script further could include filtering out certain posts, highlighting posts from certain authors, or using arguments with <code>argparse</code> to make the script more flexible.</p> <p>You can also combine subreddits in the URL to pull from multiple subreddits, for example: <code>https://www.reddit.com/r/discordapp+python/new/.json</code></p> <p>The full code can be found (and starred if you found it helpful) as a Gist <a href="https://gist.github.com/danwalkeruk/7b471a095c645f96456ec2dd3d4bc87f">here</a>.</p> <p>Enjoy your new #reddit-feed ✌️</p> </div> </article> <!--comments-->    <!--end comments--> </main>   </div></div>]]>
            </description>
            <link>https://danwalker.com/python-discord-reddit-feed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937851</guid>
            <pubDate>Fri, 30 Oct 2020 00:37:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons learned from launch HN as an open source project]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937661">thread link</a>) | @cheeseblubber
<br/>
October 29, 2020 | https://www.papercups.io/blog/launch | <a href="https://web.archive.org/web/*/https://www.papercups.io/blog/launch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.papercups.io/blog/launch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937661</guid>
            <pubDate>Fri, 30 Oct 2020 00:11:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deterministic Overconfidence]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937648">thread link</a>) | @keyboardman
<br/>
October 29, 2020 | https://leimao.github.io/blog/Deterministic-Overconfidence/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Deterministic-Overconfidence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Standard deep learning only learns a single model that could best represent the training data, rather than model ensembles which Bayesian learning learns. When it comes to prediction, given an input, the model could only predict one output value. Therefore, standard deep learning models for regression and classification do not capture model uncertainty. In classification, predictive probabilities obtained at the end of the pipeline, such as the softmax output, are often erroneously interpreted as model confidence.</p>



<p>Standard deep learning model only learns $y = f(x)$, whereas Bayesian model learns $p(\mathbf{y}|x)$, where $\mathbf{y}$ is an univariate or multivariate variable. Statistically, the predicted value $y$ from standard deep learning model is sampled from the distribution $p(\mathbf{y}|x)$ that Bayesian model predicts, i.e., $y \sim p(\mathbf{y}|x)$. In terms of regression, $y$ is usually a scalar value, we could evaluate the prediction uncertainty or confidence using metrics such as variance or standard deviation. In terms of classification, $y$ is usually an array that sums to $1.0$, we could evaluate the prediction uncertainty or confidence using metrics such as Shannon entropy. The Shannon entropy for standard deep learning classification model is $H(y)$, whereas the Shannon entropy for Bayesian classification model is usually computed using $H(\mathbb{E}(\mathbf{y}))$.</p>



<p>In this blog post, I would like to systematically discuss the deterministic overconfidence issues of uncertainty quantification in standard deep learning.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="multivariate-jensens-inequality">Multivariate Jensen’s Inequality</h4>

<p>In my previous blog post on <a href="https://leimao.github.io/blog/Multivariate-Jensen-Inequality/">“Multivariate Jensen’s Inequality”</a>, we have proved Jensen’s inequality for the multivariate case.</p>



<p>If $\mathbf{X} \in \mathbb{R}^n$ is random multivariate variable and $f: \mathbb{R}^n \rightarrow \mathbb{R}$ is a convex function, then</p><p>

\[f(\mathbb{E}[\mathbf{X}]) \leq \mathbb{E}[f(\mathbf{X})]\]

</p><p>Similarly, if $f$ is a concave function, then</p><p>

\[f(\mathbb{E}[\mathbf{X}]) \geq \mathbb{E}[f(\mathbf{X})]\]

</p><h3 id="shannon-entropy">Shannon Entropy</h3>

<p>The discrete case of <a href="https://leimao.github.io/blog/Entropy-Perplexity/">Shannon entropy</a> is defined as follows.</p><p>

\[H(p) = - \sum_{i=1}^{n} p(x_i) \log_b p(x_i)\]

</p><p>where $n$ is the number of discrete states, $p(x_i)$ is the probability of the system being in the state $i$, and $\sum_{i=1}^{n} p(x_i) = 1$.</p>



<p>Shannon entropy could be used for measuring the uncertainty of a system, such as a machine learning classifier model.</p>



<p>For example, if a binary classifier predicts an input $x$ to be class $y^{+}$ and $y^{-}$ with a probability of $p = (0.999, 0.001)$. The Shannon entropy $H(p) \approx 0$, meaning that there is almost no uncertainty with the prediction and the system is almost 100% sure about the prediction. On the other hand, when $p = (0.500, 0.500)$, the Shannon entropy, if using $b = 2$, $H(p) = 1.0$ which is the largest entropy when using $b = 2$. This means that the uncertainty is the largest and the system is 100% unsure about the prediction.</p>



<p>Shannon entropy is strictly concave with respect to $p$. Here we would provide a quick proof.</p>



<p><em>Proof</em></p>



<p>We have defined the space of probabilities for $p$.</p><p>

\[P = \{(p_1, p_2, \cdots, p_n): 0 &lt; p_i &lt; 1, \sum_{i=1}^{n} p_i = 1 \}\]

</p><p>Given $p \in P$, and a real-numbered vector $q = (q_1, q_2, \cdots, q_n) \in \mathbb{R}^n$ such that $\sum_{i=1}^{n} q_i = 0$ and $q \neq \mathbf{0}$, there must exist a small range $\lambda \in [u, v]$ where $p + \lambda q \in P$. Then we have</p><p>

\[H(p + \lambda q) = - \sum_{i=1}^{n} (p_i + \lambda q_i) \log_b (p_i + \lambda q_i)\]

</p><p>The derivatives with respect to $\lambda$ are</p><p>

\[\begin{align}
\frac{d H}{d \lambda} &amp;= - \sum_{i=1}^{n} \Big [ q_i \log_b (p_i + \lambda q_i) + (p_i + \lambda q_i) \frac{1}{(p_i + \lambda q_i) \ln b} \Big] \\
&amp;= - \sum_{i=1}^{n} \Big [ q_i \log_b (p_i + \lambda q_i) + \frac{1}{\ln b} \Big] \\
&amp;= - \sum_{i=1}^{n} q_i \log_b (p_i + \lambda q_i) + \frac{n}{\ln b} \\
\end{align}\]

\[\begin{align}
\frac{d^2 H}{d \lambda^2} &amp;= - \sum_{i=1}^{n} \Big[ q_i  \frac{q_i}{(p_i + \lambda q_i) \ln b} \Big]\\
&amp;= - \frac{1}{\ln b} \sum_{i=1}^{n} \Big[ \frac{q_i^2}{(p_i + \lambda q_i)} \Big]\\
\end{align}\]

</p><p>Because $p + \lambda q \in P$, $0 &lt; p_i + \lambda q_i &lt; 1$ for any $i \in [1, n]$. Therefore,</p><p>

\[\begin{align}
\frac{d^2 H}{d \lambda^2} &lt; 0
\end{align}\]

</p><p>This concludes the proof that Shannon entropy is strictly concave with respect to $p$.</p>

<h3 id="deterministic-overconfidence">Deterministic Overconfidence</h3>

<p>Deterministic overconfidence states that for classification models, we have</p><p>

\[\mathbb{E}(H(\mathbf{y})) \leq H(\mathbb{E}(\mathbf{y}))\]

</p><p>In layman’s terms, this means that predicting a single output given an input using the standard deep learning model is very <strong>likely</strong> to have lower Shannon entropy compared to the expected value of Shannon entropy uncertainty from Bayesian model ensembles.</p>



<p>A concrete example is from the Shannon entropy computed from the probabilities using softmax function published in Yarin Gal’s paper <a href="https://arxiv.org/abs/1506.02142">“Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning”</a>.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-10-11-Deterministic-Overconfidence/overconfidence.png">
    <figcaption>Binary Cross Entropy Deterministic Overconfidence</figcaption>
</figure>
</div>

<p>We are looking at the figure (b) in particular. If the input to the softmax function is the logits from the standard deep learning model, the output $y$ will be mostly likely the expected value $\mathbb{E}(\mathbf{y}) \approx 1.0$. Therefore, the Shannon entropy $H(y) \approx 0$ and $\mathbb{E}(H(\mathbf{y})) \approx 0.0$, meaning that the model is 100% sure most of the time about the predicted class even though the model has never seen the input $x$ and has to do extrapolation in order to predict. This suggest that apply the uncertainty quantification to the standard deep learning model is erroneous.</p>



<p>Let’s further take a look at what the Shannon entropy for the Bayesian model predictions. The Bayesian model predicts the distribution $\mathbf{y}$, and we could compute the expected value of the Shannon entropy $\mathbb{E}(H(\mathbf{y}))$. We could see from the figure that a lot of samples $y \sim p(\mathbf{y}|x)$ are away from $1.0$, therefore $\mathbb{E}(\mathbf{y})$ should be smaller than $1.0$, and $H(\mathbb{E}(\mathbf{y}))$ should be larger than $0$.</p>



<p>This analysis matches our statement of deterministic overconfidence that</p><p>

\[\mathbb{E}(H(\mathbf{y})) \leq H(\mathbb{E}(\mathbf{y}))\]

</p><h3 id="proof-to-deterministic-overconfidence">Proof to Deterministic Overconfidence</h3>

<p>The proof to deterministic overconfidence is extremely simple, given the prerequisites that have been shown early in the post.</p>



<p>Because Shannon entropy $H$ is strictly concave even for the multivariate case, we apply the multivariate Jensen’s inequality, we have</p><p>

\[\mathbb{E}(H(\mathbf{y})) \leq H(\mathbb{E}(\mathbf{y}))\]

</p><p>This concludes the proof.</p>

<h3 id="extensions">Extensions</h3>

<p>We have discussed the deterministic overconfidence for classification models. How about regression models. The short answer is that there is also deterministic overconfidence for regression models. If the uncertainty is measured using variance, without showing the proof formally, variance is also a concave function. By applying the multivariate Jensen’s inequality as we did for the Shannon entropy, we could also reach the same conclusion for regression models.</p>

<h3 id="caveats">Caveats</h3>

<p>The proof to deterministic overconfidence from the <a href="https://docs.aws.amazon.com/prescriptive-guidance/latest/ml-quantifying-uncertainty/app-a.html">AWS Prescriptive Guidance</a> is incorrect. In case AWS changes the web content, the PDF version of the doc could be found <a href="https://leimao.github.io/downloads/blog/2020-10-11-Deterministic-Overconfidence/quantifying-uncertainty-in-deep-learning-systems.pdf">here</a> in the Appendix A section.</p>



<p>There are two major issues in their argument and proof.</p>



<p>The deterministic overconfidence was not only restricted to using softmax but also other activation functions.</p>



<p>The major mistake they made is that the random variable $\mathbf{u}$ was defined between $[-\infty, +\infty]$, and it could not be separated into two regions and apply Jensen’s inequality separately.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://leimao.github.io/blog/Multivariate-Jensen-Inequality/">Multivariate Jensen’s Inequality</a></li>
  <li><a href="https://leimao.github.io/blog/Entropy-Perplexity/">Shannon Entropy</a></li>
  <li><a href="https://leimao.github.io/downloads/blog/2020-10-11-Deterministic-Overconfidence/chapShannon.pdf">Shannon Entropy’s Concavity</a></li>
  <li><a href="https://arxiv.org/abs/1506.02142">Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Deterministic-Overconfidence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937648</guid>
            <pubDate>Fri, 30 Oct 2020 00:09:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Standard Bits, an ultra lo-fi video game named after the Mac's graphics blitter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937606">thread link</a>) | @doomlaser
<br/>
October 29, 2020 | https://doomlaser.itch.io/standardbits#game | <a href="https://web.archive.org/web/*/https://doomlaser.itch.io/standardbits#game">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="view_game_page_11950"><p>A downloadable game for Windows and macOS</p><div><div><div><div><div><table><tbody><tr><td>Updated</td><td><abbr title="10 October 2020 @ 02:00"><span></span> 21 days ago</abbr></td></tr><tr><td>Status</td><td><a href="https://itch.io/games/released">Released</a></td></tr><tr><td>Platforms</td><td><a href="https://itch.io/games/platform-windows">Windows</a>, <a href="https://itch.io/games/platform-osx">macOS</a></td></tr><tr><td>Rating</td><td><div title="5.0" itemprop="aggregateRating" itemtype="http://schema.org/AggregateRating" itemscope=""><div content="5.0" itemprop="ratingValue"></div><p><span content="3" itemprop="ratingCount">(3)</span></p></div></td></tr><tr><td>Author</td><td><a href="https://doomlaser.itch.io/">Doomlaser</a></td></tr><tr><td>Genre</td><td><a href="https://itch.io/games/genre-adventure">Adventure</a></td></tr><tr><td>Tags</td><td><a href="https://itch.io/games/tag-abstract">Abstract</a>, <a href="https://itch.io/games/tag-artgame">artgame</a>, <a href="https://itch.io/games/tag-atmospheric">Atmospheric</a>, <a href="https://itch.io/games/tag-experimental">Experimental</a>, <a href="https://itch.io/games/tag-exploration">Exploration</a>, <a href="https://itch.io/games/tag-glitch">glitch</a>, <a href="https://itch.io/games/tag-minimalist">Minimalist</a>, <a href="https://itch.io/games/tag-psychedelic">psychedelic</a>, <a href="https://itch.io/games/tag-walking-simulator">Walking simulator</a>, <a href="https://itch.io/games/tag-weird">weird</a></td></tr><tr><td>Average session</td><td><a href="https://itch.io/games/duration-minutes">A few minutes</a></td></tr><tr><td>Inputs</td><td><a href="https://itch.io/games/input-keyboard">Keyboard</a>, <a href="https://itch.io/games/input-x360">Xbox controller</a>, <a href="https://itch.io/games/input-gamepad">Gamepad (any)</a>, <a href="https://itch.io/games/input-joystick">Joystick</a>, <a href="https://itch.io/games/input-wiimote">Wiimote</a>, <a href="https://itch.io/games/input-playstation">Playstation controller</a>, <a href="https://itch.io/games/input-joy-con">Joy-Con</a></td></tr><tr><td>Accessibility</td><td><a href="https://itch.io/games/accessibility-highcontrast">High-contrast</a>, <a href="https://itch.io/games/accessibility-textless">Textless</a></td></tr><tr><td>Links</td><td><a rel="nofollow noopener" href="http://doomlaser.com/trekking-across-the-northeast-for-gamma-256-and-blip/">Homepage</a></td></tr></tbody></table></div></div></div><div><h2 id="comments">Comments</h2><p><a href="https://itch.io/login?return_to=https%3A%2F%2Fdoomlaser.itch.io%2Fstandardbits" data-register_action="comment">Log in with itch.io</a> to leave a comment.</p><div id="community_topic_posts_widget_29320"><div><div data-post="{&quot;user_id&quot;:43197,&quot;id&quot;:424865}" id="post-424865"><div><a href="https://itch.io/profile/toster12d3"></a><div><div><p>Omg I saw this game on ExperimentalGameplayDotCom years ago!</p><p>It's one of my favorite hm.. objects from there. A pure exploration experience. Thank you for that!<br></p></div></div></div></div></div></div></div></div><div><div><p id="video_embed_widget_90473"><iframe frameborder="0" allowfullscreen="" src="//www.youtube.com/embed/4mkonvxtT9Y"></iframe></p></div><p><a href="https://img.itch.zone/aW1hZ2UvNTkyMDEvMjY2MjcyLmdpZg==/original/bgTKnU.gif" target="_blank" data-image_lightbox="true"><img src="https://img.itch.zone/aW1hZ2UvNTkyMDEvMjY2MjcyLmdpZg==/347x500/X9%2Bu4%2F.gif"></a></p></div></div></div></div>]]>
            </description>
            <link>https://doomlaser.itch.io/standardbits#game</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937606</guid>
            <pubDate>Fri, 30 Oct 2020 00:02:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Way to Plug a Human Brain into a Computer: Via Veins]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937571">thread link</a>) | @mercurialshark
<br/>
October 29, 2020 | https://www.wired.com./story/a-new-way-to-plug-a-human-brain-into-a-computer-via-veins/ | <a href="https://web.archive.org/web/*/https://www.wired.com./story/a-new-way-to-plug-a-human-brain-into-a-computer-via-veins/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><span>The hard part</span> of connecting a gooey, thinking brain to a cold, one-ing and zero-ing computer is getting information through your thick skull—or mine, or anyone’s. The whole point of a skull, after all, is keeping a brain safely separate from [waves hands at everything]. </p><p>So if that brain isn’t yours, the only way to tell what’s going on inside it is inference. People make very educated guesses based on what that brain tells a body to do—like, if the body makes some noises that you can understand (that’s speech) or moves around in a recognizable way. That’s a problem for people trying to understand how the brain works, and an even bigger problem for people who because of injury or illness can’t move or speak. Sophisticated imaging technologies like functional magnetic resonance can give you some clues. But it’d be great to have something more direct. For decades, technologists have been trying to get brains to interface with computer keyboards or robot arms, to get meat to commune with silicon.</p><p>On Wednesday, a team of scientists and engineers showed results from a promising new approach. It involves <a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.nature.com/articles/nbt.3428#Bib1&quot;}" href="https://www.nature.com/articles/nbt.3428#Bib1" rel="nofollow noopener" target="_blank">mounting electrodes</a> on an expandable, springy tube called a stent and threading it through a blood vessel that leads to the brain. In tests on two people, the researchers literally went for the jugular, running a stent-tipped wire up that vein in the throat and then into a vessel near the brain’s primary motor cortex, where they popped the spring. The electrodes snuggled into the vessel wall and started sensing when the people’s brains signaled their intention to move—and sent those signals wirelessly to a computer, via an infrared transmitter surgically inserted in the subjects’ chests. In an <a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://jnis.bmj.com/content/early/2020/10/23/neurintsurg-2020-016862&quot;}" href="https://jnis.bmj.com/content/early/2020/10/23/neurintsurg-2020-016862" rel="nofollow noopener" target="_blank">article</a> published in the <em>Journal of NeuroInterventional Surgery</em>, the Australian and US researchers describe how two people with paralysis due to amyotrophic lateral sclerosis (better known as Lou Gehrig’s disease) used such a device to send texts and fool around online by brain-control alone.</p><p>“Self-expanding stent technology has been well demonstrated in both cardiac and neurological applications to treat other disease. We just use that feature and put electrodes on top of the stent,” says Thomas Oxley, an interventional neurologist and CEO of Synchron, the company hoping to commercialize the technology. “It’s fully implantable. Patients go home in a couple of days. And it’s plug-and-play.”</p><p>It took training once the subjects got home. The electrode-studded stent could pick up signals from the brain, but machine-learning algorithms have to figure out what those signals—imperfect reflections of a mind at work even under ideal conditions—actually represent. But after a few weeks of work, both patients could use an eye tracker to move a cursor and then click with a thought, using the implant. It doesn’t sound like much, but that was enough for both of them to send text messages, shop online, and otherwise perform activities of digital daily life.</p><p>The Food and Drug Administration hasn’t approved what Oxley calls a “stentrode” for widespread use yet, and the company is still chasing funding for more tests, but these preliminary results suggest that it’s a functioning brain-computer interface. The signal it receives isn’t packed full of information. For now, all the stentrode is picking up is one bit of information—either a telepathic mouse-click or the absence of that click. But for some applications, maybe that’s enough. “There’s been a lot of talk about data and channels, and really what should matter is, have you delivered a life-changing product to the patient?” Oxley says. “Just with a handful of outputs restored to the patient that they’re in control of, we’ve got them controlling Windows 10.”</p></div></div><div><div><p>Much more ambitious brain-computer interfaces and neural prosthetics have been in the news lately. Last month, Elon Musk’s company Neuralink <a href="https://www.wired.com/story/neuralink-is-impressive-tech-wrapped-in-musk-hype/">demonstrated</a> a wireless BCI with more than a thousand flexible electrodes, designed to be inserted directly into a brain by a specialized robot surgeon. (The company has so far only shown short-term use in pigs.) Inserting electrodes is tricky; while it’s true that brain surgery isn’t exactly rocket science, it has risks whether the surgeon is a robot or not. Even flexible, thin electrodes like those that Neuralink demonstrated are invasive enough that the brain tries to defend against them, coating them with glial cells that reduce their ability to conduct the electrical impulses they’re looking for. And while implanted electrodes like those of the more commonly used “Utah array” can get clear signals from individual neurons, understanding what those signals mean is still science in progress. Plus, the brain sloshes around like jelly in a donut; fixed-in-place electrodes can damage it. But get it right and they can do more than brain research. “Locked-in” patients with ALS have used them as <a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.nejm.org/doi/10.1056/NEJMoa1608085&quot;}" href="https://www.nejm.org/doi/10.1056/NEJMoa1608085" rel="nofollow noopener" target="_blank">successful brain-computer interfaces</a>, though they require training, maintenance, surgery, and so on.</p><p>Meanwhile, electrodes placed directly onto the scalp can pick up brain waves—electroencephalograms, or EEGs—but those lack the spatial detail of implanted electrodes. Neuroscientists know, very roughly, which part of the brain does what, but the more you know about which neurons are firing, the better you can tell what they’re firing about.</p><p>A more recent innovation, electrocorticography, places a mesh of electrodes directly onto the surface of the brain. In combination with smart spectral processing of the signals those electrodes pick up, ECoG is good enough to translate action in the part of the motor cortex that controls the lips, jaw, and tongue into <a href="https://www.wired.com/story/machine-reads-your-mind-talks/">text or even speech</a>. And there are other approaches. <a href="https://www.wired.com/story/brain-machine-interface-isnt-sci-fi-anymore/">CTRL-labs</a>, which Facebook <a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.bloomberg.com/news/articles/2019-09-23/facebook-to-buy-startup-for-controlling-computers-with-your-mind&quot;}" href="https://www.bloomberg.com/news/articles/2019-09-23/facebook-to-buy-startup-for-controlling-computers-with-your-mind" rel="nofollow noopener" target="_blank">bought</a> for perhaps as much as $1 billion in 2019, tries to get motor signals from neurons in the wrist. <a href="https://www.wired.com/story/inside-the-race-to-build-a-brain-machine-interface/">Kernel</a> uses functional near-infrared spectroscopy on the head to sense brain activity.</p><p>Oxley and his colleagues’ stentrode, if it keeps showing good results, will fit somewhere along the spectrum between implanted electrodes and EEG. Closer to the first thing than the second, its inventors hope. But it’s still early days. “The core technology and the core idea is super cool, but given where they’re accessing the signals from, my expectation would be that this is a relatively low-fidelity signal relative to other brain-machine interface strategies,” says Vikash Gilja, who runs the Translational Neural Engineering Lab at UC San Diego. “We at least know that high-density ECoG recording from the surface of the brain can convey information beyond what is being shown in this paper.”</p><p>A possible problem: Tissue conducts electrical impulses, but the electrodes in the stent are picking up signals from the brain through the cells of the blood vessel. That lowers signal content. “If we were to take those cortical surface recordings and compare them to Utah array experiments—the bulk of clinical experience with implanted electrodes—I would say the style of recording in ECoG is a rate limiter,” Gilja says. (Just for transparency, I should point out that Gilja has done for-pay work with BCI companies including Neuralink, with whom Synchron could theoretically compete someday.)</p><p>So it might not be good enough for neuroscience, but it could be plenty useful for a person with paralysis who wants a low-maintenance BCI that doesn’t require drilling through the skull. “There’s a trade-off between how invasive you want to be and at what level you collect information,” says Andrew Pruszynski, a neuroscientist at Western University in Canada. “This is trying to get to the middle ground, to insert a catheter close to the neural activity. It’s obviously invasive, but certainly not as invasive as putting electrodes into the brain.”</p></div></div><div><div><p>And there’s more work to come. Oxley’s team hopes to expand their study to more human subjects. They’ll be looking for possible side effects, like the chance that the stent could contribute to strokes (though this seems less likely as it embeds in the vessel walls, a process called endothelialization). They might find better locations for the stent, in blood vessels adjacent to other brain areas of interest; anywhere within 2 millimeters of a vessel big enough to accommodate the stentrode is fair game, Oxley says. The software could stand some improving, in terms of figuring out what the brain actually means when it emits its electrical bells and whistles, and some of their tests suggest the system could pick up more informational detail—like which specific muscle the users were trying to contract. That could lead to more useful prosthetics or control of devices beyond Windows 10. “The motor system, right now, is what’s going to deliver therapy for people who are paralyzed,” Oxley says. “But when we start to engage with other areas of the brain, you begin to see how the technology is going to open up brain processing power.” It’s hard to predict what might happen when scientists actually figure out how to get inside someone’s head.</p><hr><p>More Great WIRED Stories</p><ul><li>📩 Want the latest on tech, science, and more? <a href="https://www.wired.com/newsletter?sourceCode=BottomStories">Sign up for our newsletters</a>!</li><li>High science: <a href="https://www.wired.com/story/this-is-my-brain-on-salvia/?itm_campaign=BottomRelatedStories_Sections_5&amp;itm_content=footer-recirc">This is my brain on salvia</a></li><li>The pandemic closed borders—<a href="https://www.wired.com/story/the-pandemic-closed-borders-and-stirred-a-longing-for-home/?itm_campaign=BottomRelatedStories_Sections_5&amp;itm_content=footer-recirc">and stirred a longing for home</a></li><li>The cheating scandal that <a href="https://www.wired.com/story/stones-poker-cheating-scandal/?itm_campaign=BottomRelatedStories_Sections_5&amp;itm_content=footer-recirc">ripped the poker world apart</a></li><li>How to trick out your <a href="https://www.wired.com/story/customize-iphone-home-screen-widgets-aesthetic-ios14/?itm_campaign=BottomRelatedStories_Sections_5&amp;itm_content=footer-recirc">iPhone home screen in iOS 14</a></li><li>The women who <a href="https://www.wired.com/story/the-women-who-invented-video-game-music/?itm_campaign=BottomRelatedStories_Sections_5&amp;itm_content=footer-recirc">invented video game music</a></li><li>🎮 WIRED Games: Get the latest <a href="https://www.wired.com/tag/video-games/?itm_campaign=BottomRelatedStories_Sections_5&amp;itm_content=footer-recirc">tips, reviews, and more</a></li><li>🎧 Things not sounding right? Check out our favorite <a href="https://www.wired.com/gallery/best-wireless-headphones/?itm_campaign=BottomRelatedStories&amp;itm_content=footer-recirc">wireless headphones</a>, <a href="https://www.wired.com/gallery/best-soundbars/?itm_campaign=BottomRelatedStories&amp;itm_content=footer-recirc">soundbars</a>, and <a href="https://www.wired.com/gallery/best-bluetooth-speakers/?itm_campaign=BottomRelatedStories&amp;itm_content=footer-recirc">Bluetooth speakers</a></li></ul></div></div></div></div>]]>
            </description>
            <link>https://www.wired.com./story/a-new-way-to-plug-a-human-brain-into-a-computer-via-veins/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937571</guid>
            <pubDate>Thu, 29 Oct 2020 23:58:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Setup Django with React]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937453">thread link</a>) | @rbanffy
<br/>
October 29, 2020 | https://mattsegal.dev/django-react.html | <a href="https://web.archive.org/web/*/https://mattsegal.dev/django-react.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>It's not too hard to get started with either Django or React. Both have great documentation and there are lots of tutorials online.
The tricky part is getting them to work together. Many people start with a Django project and then decide that they want to "add React" to it.
How do you do that though? Popular React scaffolding tools like <a href="https://github.com/facebook/create-react-app">Create React App</a> don't offer you a clear way to integrate with Django, leaving you to figure it out yourself. Even worse, there isn't just one way to set up a Django/React project. There are dozens of <a href="https://mattsegal.dev/django-spa-infrastructure.html">possible methods</a>, each with different pros and cons. Every time I create a new project using these tools I find the options overwhelming.</p>
<p>I think that most people should start with a setup that is as close to vanilla Django as possible: you take your existing Django app and sprinkle a little React on it to make the frontend more dynamic and interactive. For most cases, creating a completely seperate "single page app" frontend creates a lot of complexity and challenges without providing very much extra value for you or your users.</p>
<p>In this series of posts I will present an opinionated guide on how to setup and deploy a Django/React webapp. The focus will be on keeping things simple, incremental and understanding each step. I want you to be in a position to debug any problems yourself. At the end of each post, you should have a working project that you can use.</p>
<p>I'm going to assume that you know:</p>
<ul>
<li>the <a href="https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web">basics of web development</a> (HTML, CSS, JavaScript)</li>
<li>the <a href="https://docs.djangoproject.com/en/3.1/intro/tutorial01/">basics of Django</a> (views, templates, static files)</li>
<li>the <a href="https://reactjs.org/tutorial/tutorial.html">basics of React</a> (components, props, rendering)</li>
</ul>
<p>I'm <strong>not</strong> going to assume that you know anything about Webpack, Babel, or any other JavaScript toolchain insanity.</p>
<h2>Example project</h2>
<p>The example code for this guide is hosted on <a href="https://github.com/MattSegal/django-react-guide">this GitHub repo</a>. The code for each section is available as a Git branch:</p>
<ul>
<li><a href="https://github.com/MattSegal/django-react-guide/tree/part-1-initial-django">Starting point</a></li>
<li><a href="https://github.com/MattSegal/django-react-guide/tree/part-2-add-webpack">Adding Webpack</a></li>
<li><a href="https://github.com/MattSegal/django-react-guide/tree/part-3-add-babel-and-react">Adding Babel and React</a></li>
</ul>
<p>Before you start the rest of the guide, I recommend setting up the example project by cloning the repo and following the instructions in the <a href="https://github.com/MattSegal/django-react-guide/blob/part-1-initial-django/README.md">README</a>:</p>
<div><pre><span></span><code>git clone https://github.com/MattSegal/django-react-guide.git
</code></pre></div>

<h2>Django and static files</h2>
<p>Before we dig into React, Babel and Webpack, I want to make sure that we have a common understanding around how static files work in Django:</p>
<p><img alt="views and static files" src="https://mattsegal.dev/views-static.png"></p>
<p>The approach of this guide will be to re-use a lot of this existing setup. We will create an additional that system inserts our React app's JavaScript into a Django static files folder.</p>
<p><img alt="views and static files plus mystery system" src="https://mattsegal.dev/views-static-mystery.png"></p>
<h2>Why can't we just write React in a single static file?</h2>
<p>Why do we need to add a new system? Django is pretty complicated already. Can't we just write our React app in a single JavaScript file like you usually do when writing JavaScript for webpages? The answer is yes, you totally can! You can write a complete React app in a single HTML file:</p>
<div><pre><span></span><code><span>&lt;</span><span>html</span><span>&gt;</span>
<span>&lt;</span><span>body</span><span>&gt;</span>
  <span>&lt;!-- React mount point --&gt;</span>
  <span>&lt;</span><span>div</span> <span>id</span><span>=</span><span>"app"</span><span>&gt;&lt;/</span><span>div</span><span>&gt;</span>
  <span>&lt;!-- Download React library scripts --&gt;</span>
  <span>&lt;</span><span>script</span> <span>crossorigin</span> <span>src</span><span>=</span><span>"https://unpkg.com/<a href="https://mattsegal.dev/cdn-cgi/l/email-protection" data-cfemail="b5c7d0d4d6c1f58483">[email&nbsp;protected]</a>/umd/react.development.js"</span><span>&gt;&lt;/</span><span>script</span><span>&gt;</span>
  <span>&lt;</span><span>script</span> <span>crossorigin</span> <span>src</span><span>=</span><span>"https://unpkg.com/<a href="https://mattsegal.dev/cdn-cgi/l/email-protection" data-cfemail="0173646062752c656e6c413037">[email&nbsp;protected]</a>/umd/react-dom.development.js"</span><span>&gt;&lt;/</span><span>script</span><span>&gt;</span>
  <span>&lt;</span><span>script</span><span>&gt;</span>
    <span>// Define the React app</span>
    <span>const</span> <span>App</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
      <span>const</span> <span>[</span><span>count</span><span>,</span> <span>setCount</span><span>]</span> <span>=</span> <span>React</span><span>.</span><span>useState</span><span>(</span><span>0</span><span>)</span>
      <span>const</span> <span>onClick</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>setCount</span><span>(</span><span>c</span> <span>=&gt;</span> <span>c</span> <span>+</span> <span>1</span><span>)</span>
      <span>return</span> <span>React</span><span>.</span><span>createElement</span><span>(</span><span>'div'</span><span>,</span> <span>null</span><span>,</span>
        <span>React</span><span>.</span><span>createElement</span><span>(</span><span>'h1'</span><span>,</span> <span>null</span><span>,</span> <span>'The count is '</span> <span>+</span> <span>count</span><span>),</span>
        <span>React</span><span>.</span><span>createElement</span><span>(</span><span>'button'</span><span>,</span> <span>{</span> <span>onClick</span><span>:</span> <span>onClick</span> <span>},</span> <span>'Count'</span><span>),</span>
      <span>)</span>
    <span>}</span>
    <span>// Mount the app to the mount point.</span>
    <span>const</span> <span>root</span> <span>=</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'app'</span><span>)</span>
    <span>ReactDOM</span><span>.</span><span>render</span><span>(</span><span>React</span><span>.</span><span>createElement</span><span>(</span><span>App</span><span>,</span> <span>null</span><span>,</span> <span>null</span><span>),</span> <span>root</span><span>)</span>
  <span>&lt;/</span><span>script</span><span>&gt;</span>
<span>&lt;/</span><span>body</span><span>&gt;</span>
<span>&lt;/</span><span>html</span><span>&gt;</span>
</code></pre></div>
<p>Why don't we just do this? There are a few issues with this approach of writing React apps:</p>
<ul>
<li>We can't use <a href="https://reactjs.org/docs/introducing-jsx.html">JSX</a> syntax in our JavaScript</li>
<li>It's harder to break our JavaScript code up into modules</li>
<li>It's harder to install/use external libraries</li>
</ul>

<h2>Webpack</h2>
<p>The example code for this section <a href="https://github.com/MattSegal/django-react-guide/tree/part-1-initial-django">starts here</a> and <a href="https://github.com/MattSegal/django-react-guide/tree/part-2-add-webpack">ends here</a>.</p>
<p>We need a tool that helps us use JSX, and it would be nice to also have a "module bundling system" which lets us install 3rd party libraries and split our JavaScript code up into lots of little files. For this purpose, we're going to use <a href="https://webpack.js.org/">Webpack</a>. Webpack is going to take our code, plus any 3rd party libraries that we want to install and combine them into a single JS file.</p>
<p><img alt="webpack" src="https://mattsegal.dev/webpack.png"></p>
<p>In this step we will just to create a minimal working Webpack setup. We're not goint try to use React yet. By the end of this section, we won't have added any new JavaScript features, but Webpack will be working.</p>
<p>To use Webpack you need to first install <a href="https://nodejs.org/en/">NodeJS</a> so that you can run JavaScript outside of your web browser. You need to be able to run <code>node</code> and <code>npm</code> (the Node Package Manager) before you can continue.</p>
<p>First, go into the example project and create a new folder called <code>frontend</code>.
We'll start by just copying over the existing JavaScript that is used by the Django app in <a href="https://github.com/MattSegal/django-react-guide/blob/part-1-initial-django/backend/todos/static/todos/main.js">main.js</a>. We're going to copy this into a "source code" folder at <code>frontend/src/index.js</code>.</p>
<div><pre><span></span><code><span>// frontend/src/index.js</span>
<span>const</span> <span>btn</span> <span>=</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'click'</span><span>)</span>
<span>btn</span><span>.</span><span>addEventListener</span><span>(</span><span>'click'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>alert</span><span>(</span><span>'You clicked the button!'</span><span>))</span>
</code></pre></div>
<p>Inside of the <code>frontend</code> folder, install Webpack using <code>npm</code> as follows:</p>
<div><pre><span></span><code>npm init --yes
npm install webpack webpack-cli
</code></pre></div>
<p>Now is a good time to update your <code>.gitignore</code> file to exclude <code>node_modules</code>. Next, we need to add a file that tells Webpack what to do, which is called <code>webpack.config.js</code></p>
<div><pre><span></span><code><span>// frontend/webpack.config.js</span>
<span>const</span> <span>path</span> <span>=</span> <span>require</span><span>(</span><span>'path'</span><span>)</span>
<span>const</span> <span>webpack</span> <span>=</span> <span>require</span><span>(</span><span>'webpack'</span><span>)</span>
<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>{</span>
  <span>// Where Webpack looks to load your JavaScript</span>
  <span>entry</span><span>:</span> <span>{</span>
    <span>main</span><span>:</span> <span>path</span><span>.</span><span>resolve</span><span>(</span><span>__dirname</span><span>,</span> <span>'src/index.js'</span><span>),</span>
  <span>},</span>
  <span>mode</span><span>:</span> <span>'development'</span><span>,</span>
  <span>// Where Webpack spits out the results (the myapp static folder)</span>
  <span>output</span><span>:</span> <span>{</span>
    <span>path</span><span>:</span> <span>path</span><span>.</span><span>resolve</span><span>(</span><span>__dirname</span><span>,</span> <span>'../backend/myapp/static/myapp/'</span><span>),</span>
    <span>filename</span><span>:</span> <span>'[name].js'</span><span>,</span>
  <span>},</span>
  <span>plugins</span><span>:</span> <span>[</span>
    <span>// Don't output new files if there is an error</span>
    <span>new</span> <span>webpack</span><span>.</span><span>NoEmitOnErrorsPlugin</span><span>(),</span>
  <span>],</span>
  <span>// Where find modules that can be imported (eg. React) </span>
  <span>resolve</span><span>:</span> <span>{</span>
    <span>extensions</span><span>:</span> <span>[</span><span>'*'</span><span>,</span> <span>'.js'</span><span>,</span> <span>'.jsx'</span><span>],</span>
    <span>modules</span><span>:</span> <span>[</span>
        <span>path</span><span>.</span><span>resolve</span><span>(</span><span>__dirname</span><span>,</span> <span>'src'</span><span>),</span>
        <span>path</span><span>.</span><span>resolve</span><span>(</span><span>__dirname</span><span>,</span> <span>'node_modules'</span><span>),</span>
    <span>],</span>
  <span>},</span>
<span>}</span>
</code></pre></div>
<p>Finally let's make it easy to run Webpack by including an entry in the "scripts" section of our <code>package.json</code> file:</p>
<div><pre><span></span><code><span>// frontend/package.json</span>
<span>{</span>
  <span>// ...</span>
  <span>"scripts"</span><span>:</span> <span>{</span>
    <span>"dev"</span><span>:</span> <span>"webpack --watch --config webpack.config.js"</span>
  <span>},</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div>
<p>The <code>--watch</code> flag is particularly useful: it makes Webpack re-run automatically on file change. Now we can run Webpack using <code>npm</code>:</p>

<p>You will now see that the contents of your <code>main.js</code> file has been replaced with a crazy looking <code>eval</code> statement. If you check your Django app at <code>http://localhost:8000</code> you'll see that the JavaScript on the page still works, but it's now using the Webpack build output at <code>http://localhost:8000/static/myapp/main.js</code> </p>
<div><pre><span></span><code><span>// backend/myapp/static/myapp/main.js</span>
<span>eval</span><span>(</span><span>"const btn = document.getElementById('click')\nbtn.addEventListener('click', () =&gt; alert('You clicked the button!'))\n\n\n//# sourceURL=webpack://frontend/./src/index.js?"</span><span>);</span>
</code></pre></div>
<p>This file is the Webpack build output. Webpack has taken our source file (<code>index.js</code>) and transformed it into an output file (<code>main.js</code>): </p>
<p><img alt="webpack minimal" src="https://mattsegal.dev/webpack-minimal.png"></p>
<p>So now we have Webpack working. It's not doing anything particularly useful or interesting yet, but all the plumbing has been set up.</p>

<h2>Source code vs. build outputs</h2>
<p>It's a common newbie mistake to add Webpack build outputs like <code>main.js</code> to source control. It's a mistake because source control is for "source code", not "build artifacts". A build artifact is a file created by a build or compliation process. The reason you don't add build artifacts is because they're redundant: they are fully defined by the source code, so adding them just bloats the repo without adding any extra information. Even worse, having a mismatch between source code and build artifacts can create nasty errors that are hard to find. Some examples of build artifacts:</p>
<ul>
<li>Python bytecode (.pyc) file,s which are built from .py files by the Python interpeter</li>
<li>.NET bytecode (.dll) files, built from compiling C# code</li>
<li>Executable (.exe) files, build from compiling C code</li>
</ul>
<p>None of these things should go in source control unless there's a special reason to keep them. In general they should be kept out of Git using the <code>.gitignore</code> file.</p>
<p>My approach for this project is to create a special Webpack-only folder in Django's static file called "build", which is ignored by Git.
To achieve this, you need to update your <code>webpack.config.js</code> file:</p>
<div><pre><span></span><code><span>// frontend/webpack.config.js</span>
<span>// ...</span>
<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>{</span>
  <span>// ...</span>
  <span>output</span><span>:</span> <span>{</span>
      <span>path</span><span>:</span> <span>path</span><span>.</span><span>resolve</span><span>(</span><span>__dirname</span><span>,</span> <span>'../backend/myapp/static/myapp/build/'</span><span>),</span>
      <span>filename</span><span>:</span> <span>'[name].js'</span><span>,</span>
  <span>},</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div>
<p>You will need to restart Webpack for these changes to take effect. Then you can add <code>build/</code> to your <code>.gitignore</code> file.
Finally, you will need to update the static file link in your Django template:</p>
<div><pre><span></span><code><span>&lt;!-- backend/myapp/templates/myapp/index.html --&gt;</span>
<span>&lt;</span><span>script</span> <span>src</span><span>=</span><span>"{% static 'myapp/build/main.js' %}"</span><span>&gt;&lt;/</span><span>script</span><span>&gt;</span>
</code></pre></div>

<h2>Adding React</h2>
<p>The example code for this section <a href="https://github.com/MattSegal/django-react-guide/tree/part-2-add-webpack">starts here</a> and <a href="https://github.com/MattSegal/django-react-guide/tree/part-3-add-babel-and-react">ends here</a>.</p>
<p>Now that Webpack is working, we can add React. Let's start by installing React in our <code>frontend</code> folder:</p>
<div><pre><span></span><code>npm install react react-dom
</code></pre></div>
<p>Now we can use React in our JavaScript source code. Let's re-use the small counter app I created earlier:</p>
<div><pre><span></span><code><span>// frontend/src/index.js</span>
<span>import</span> <span>React</span> <span>from</span> <span>'react'</span>
<span>import</span> <span>ReactDOM</span> <span>from</span> <span>'react-dom'</span>

<span>// Define the React app</span>
<span>const</span> <span>App</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>[</span><span>count</span><span>,</span> <span>setCount</span><span>]</span> <span>=</span> <span>React</span><span>.</span><span>useState</span><span>(</span><span>0</span><span>)</span>
  <span>const</span> <span>onClick</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>setCount</span><span>(</span><span>c</span> <span>=&gt;</span> <span>c</span> <span>+</span> <span>1</span><span>)</span>
  <span>return</span> <span>React</span><span>.</span><span>createElement</span><span>(</span><span>'div'</span><span>,</span> <span>null</span><span>,</span>
    <span>React</span><span>.</span><span>createElement</span><span>(</span><span>'h1'</span><span>,</span> <span>null</span><span>,</span> <span>'The count is '</span> <span>+</span> <span>count</span><span>),</span>
    <span>React</span><span>.</span><span>createElement</span><span>(</span><span>'button'</span><span>,</span> <span>{</span> <span>onClick</span><span>:</span> <span>onClick</span> <span>},</span> <span>'Count'</span><span>),</span>
  <span>)</span>
<span>}</span>
<span>// Mount the app to the mount point.</span>
<span>const</span> <span>root</span> <span>=</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'app'</span><span>)</span>
<span>ReactDOM</span><span>.</span><span>render</span><span>(</span><span>React</span><span>.</span><span>createElement</span><span>(</span><span>App</span><span>,</span> <span>null</span><span>,</span> <span>null</span><span>),</span> <span>root</span><span>)</span>
</code></pre></div>
<p>Now if you go to <code>http://localhost:8000/</code> you should see a simple counter. If you …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mattsegal.dev/django-react.html">https://mattsegal.dev/django-react.html</a></em></p>]]>
            </description>
            <link>https://mattsegal.dev/django-react.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937453</guid>
            <pubDate>Thu, 29 Oct 2020 23:44:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prototyping with Python – The Fuzzing Book]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937438">thread link</a>) | @rbanffy
<br/>
October 29, 2020 | https://www.fuzzingbook.org/beta/html/PrototypingWithPython.html | <a href="https://web.archive.org/web/*/https://www.fuzzingbook.org/beta/html/PrototypingWithPython.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div>
<pre>triangle(1, 6, 1) = 'isosceles #3'
triangle(2, 1, 3) = 'scalene'
triangle(1, 5, 8) = 'scalene'
triangle(3, 2, 7) = 'scalene'
triangle(2, 6, 3) = 'scalene'
triangle(7, 8, 6) = 'scalene'
triangle(5, 7, 7) = 'isosceles #2'
triangle(3, 8, 7) = 'scalene'
triangle(5, 1, 8) = 'scalene'
triangle(8, 4, 8) = 'isosceles #3'
</pre>
</div>

</div><div>

<div>
<pre>triangle:1 def triangle(a, b, c):                  (c = 1, b = 2, a = 2)
triangle:2     if a == b:                          (c = 1, b = 2, a = 2)
triangle:3         if b == c:                      (c = 1, b = 2, a = 2)
triangle:6             return 'isosceles #1'       (c = 1, b = 2, a = 2)
triangle:6             return 'isosceles #1'       (c = 1, b = 2, a = 2)
</pre>
</div>

</div><div>

<p>
<svg height="476pt" viewBox="0.00 0.00 1882.50 476.00" width="1883pt" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 472)">
<title>%3</title>
<polygon fill="#ffffff" points="-4,4 -4,-472 1878.5,-472 1878.5,4 -4,4" stroke="transparent"></polygon>
<!-- 0 -->
<g id="node1">
<title>0</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="119" y="-447.3">FunctionDef</text>
</g>
<!-- 1 -->
<g id="node2">
<title>1</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="50.5" y="-374.3">"triangle"</text>
</g>
<!-- 0&#45;&#45;1 -->
<g id="edge1">
<title>0--1</title>
<path d="M166.5,-432C166.5,-432 123.1482,-411.819 89.449,-396.1314" fill="none" stroke="#000000"></path>
</g>
<!-- 2 -->
<g id="node3">
<title>2</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="127.5" y="-375.3">arguments</text>
</g>
<!-- 0&#45;&#45;2 -->
<g id="edge2">
<title>0--2</title>
<path d="M166.5,-432C166.5,-432 166.1287,-411.9478 165.8386,-396.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 9 -->
<g id="node10">
<title>9</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="481" y="-375.3">If</text>
</g>
<!-- 0&#45;&#45;9 -->
<g id="edge9">
<title>0--9</title>
<path d="M166.5,-432C166.5,-432 384.3686,-395.5762 462.2396,-382.5575" fill="none" stroke="#000000"></path>
</g>
<!-- 3 -->
<g id="node4">
<title>3</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="44.5" y="-303.3">arg</text>
</g>
<!-- 2&#45;&#45;3 -->
<g id="edge3">
<title>2--3</title>
<path d="M159.5,-360C159.5,-360 114.7843,-336.327 84.5663,-320.3292" fill="none" stroke="#000000"></path>
</g>
<!-- 5 -->
<g id="node6">
<title>5</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="116.5" y="-303.3">arg</text>
</g>
<!-- 2&#45;&#45;5 -->
<g id="edge5">
<title>2--5</title>
<path d="M159.5,-360C159.5,-360 148.3599,-339.9478 139.6566,-324.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 7 -->
<g id="node8">
<title>7</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="188.5" y="-303.3">arg</text>
</g>
<!-- 2&#45;&#45;7 -->
<g id="edge7">
<title>2--7</title>
<path d="M159.5,-360C159.5,-360 175.0962,-339.9478 187.2807,-324.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 4 -->
<g id="node5">
<title>4</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="57.5" y="-230.3">"a"</text>
</g>
<!-- 3&#45;&#45;4 -->
<g id="edge4">
<title>3--4</title>
<path d="M57.5,-287.8314C57.5,-277 57.5,-263.2876 57.5,-252.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 6 -->
<g id="node7">
<title>6</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="129.5" y="-230.3">"b"</text>
</g>
<!-- 5&#45;&#45;6 -->
<g id="edge6">
<title>5--6</title>
<path d="M129.5,-287.8314C129.5,-277 129.5,-263.2876 129.5,-252.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 8 -->
<g id="node9">
<title>8</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="201.5" y="-230.3">"c"</text>
</g>
<!-- 7&#45;&#45;8 -->
<g id="edge8">
<title>7--8</title>
<path d="M201.5,-287.8314C201.5,-277 201.5,-263.2876 201.5,-252.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 10 -->
<g id="node11">
<title>10</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="352" y="-303.3">Compare</text>
</g>
<!-- 9&#45;&#45;10 -->
<g id="edge10">
<title>9--10</title>
<path d="M507.5,-360C507.5,-360 456.4182,-338.1078 419.3042,-322.2018" fill="none" stroke="#000000"></path>
</g>
<!-- 18 -->
<g id="node19">
<title>18</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="643" y="-303.3">If</text>
</g>
<!-- 9&#45;&#45;18 -->
<g id="edge18">
<title>9--18</title>
<path d="M507.5,-360C507.5,-360 582.7014,-331.7995 624.4147,-316.157" fill="none" stroke="#000000"></path>
</g>
<!-- 33 -->
<g id="node34">
<title>33</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1219" y="-303.3">If</text>
</g>
<!-- 9&#45;&#45;33 -->
<g id="edge33">
<title>9--33</title>
<path d="M507.5,-360C507.5,-360 1068.6377,-317.9147 1200.1543,-308.0509" fill="none" stroke="#000000"></path>
</g>
<!-- 11 -->
<g id="node12">
<title>11</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="256.5" y="-231.3">Name</text>
</g>
<!-- 10&#45;&#45;11 -->
<g id="edge11">
<title>10--11</title>
<path d="M375.5,-288C375.5,-288 330.7843,-264.327 300.5663,-248.3292" fill="none" stroke="#000000"></path>
</g>
<!-- 14 -->
<g id="node15">
<title>14</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="345.5" y="-230.3">Eq</text>
</g>
<!-- 10&#45;&#45;14 -->
<g id="edge14">
<title>10--14</title>
<path d="M375.5,-288C375.5,-288 364.3599,-267.9478 355.6566,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 15 -->
<g id="node16">
<title>15</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="400.5" y="-231.3">Name</text>
</g>
<!-- 10&#45;&#45;15 -->
<g id="edge15">
<title>10--15</title>
<path d="M375.5,-288C375.5,-288 391.0962,-267.9478 403.2807,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 12 -->
<g id="node13">
<title>12</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="201.5" y="-158.3">"a"</text>
</g>
<!-- 11&#45;&#45;12 -->
<g id="edge12">
<title>11--12</title>
<path d="M265.5,-216C265.5,-216 241.7344,-195.9478 223.1675,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 13 -->
<g id="node14">
<title>13</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="273.5" y="-158.3">Load</text>
</g>
<!-- 11&#45;&#45;13 -->
<g id="edge13">
<title>11--13</title>
<path d="M265.5,-216C265.5,-216 268.4707,-195.9478 270.7916,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 16 -->
<g id="node17">
<title>16</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="345.5" y="-158.3">"b"</text>
</g>
<!-- 15&#45;&#45;16 -->
<g id="edge16">
<title>15--16</title>
<path d="M409.5,-216C409.5,-216 385.7344,-195.9478 367.1675,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 17 -->
<g id="node18">
<title>17</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="417.5" y="-158.3">Load</text>
</g>
<!-- 15&#45;&#45;17 -->
<g id="edge17">
<title>15--17</title>
<path d="M409.5,-216C409.5,-216 412.4707,-195.9478 414.7916,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 19 -->
<g id="node20">
<title>19</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="555" y="-231.3">Compare</text>
</g>
<!-- 18&#45;&#45;19 -->
<g id="edge19">
<title>18--19</title>
<path d="M657.5,-288C657.5,-288 630.3923,-267.9478 609.2145,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 27 -->
<g id="node28">
<title>27</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="660" y="-231.3">Return</text>
</g>
<!-- 18&#45;&#45;27 -->
<g id="edge27">
<title>18--27</title>
<path d="M657.5,-288C657.5,-288 667.8975,-267.9478 676.0205,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 30 -->
<g id="node31">
<title>30</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="799" y="-231.3">Return</text>
</g>
<!-- 18&#45;&#45;30 -->
<g id="edge30">
<title>18--30</title>
<path d="M657.5,-288C657.5,-288 741.9072,-260.7067 790.7051,-244.9277" fill="none" stroke="#000000"></path>
</g>
<!-- 20 -->
<g id="node21">
<title>20</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="472.5" y="-159.3">Name</text>
</g>
<!-- 19&#45;&#45;20 -->
<g id="edge20">
<title>19--20</title>
<path d="M580.5,-216C580.5,-216 543.6076,-194.1078 516.803,-178.2018" fill="none" stroke="#000000"></path>
</g>
<!-- 23 -->
<g id="node24">
<title>23</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="561.5" y="-158.3">Eq</text>
</g>
<!-- 19&#45;&#45;23 -->
<g id="edge23">
<title>19--23</title>
<path d="M580.5,-216C580.5,-216 573.4446,-195.9478 567.9325,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 24 -->
<g id="node25">
<title>24</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="616.5" y="-159.3">Name</text>
</g>
<!-- 19&#45;&#45;24 -->
<g id="edge24">
<title>19--24</title>
<path d="M580.5,-216C580.5,-216 600.1809,-195.9478 615.5566,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 21 -->
<g id="node22">
<title>21</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="417.5" y="-86.3">"b"</text>
</g>
<!-- 20&#45;&#45;21 -->
<g id="edge21">
<title>20--21</title>
<path d="M481.5,-144C481.5,-144 457.7344,-123.9478 439.1675,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 22 -->
<g id="node23">
<title>22</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="489.5" y="-86.3">Load</text>
</g>
<!-- 20&#45;&#45;22 -->
<g id="edge22">
<title>20--22</title>
<path d="M481.5,-144C481.5,-144 484.4707,-123.9478 486.7916,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 25 -->
<g id="node26">
<title>25</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="561.5" y="-86.3">"c"</text>
</g>
<!-- 24&#45;&#45;25 -->
<g id="edge25">
<title>24--25</title>
<path d="M625.5,-144C625.5,-144 601.7344,-123.9478 583.1675,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 26 -->
<g id="node27">
<title>26</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="633.5" y="-86.3">Load</text>
</g>
<!-- 24&#45;&#45;26 -->
<g id="edge26">
<title>24--26</title>
<path d="M625.5,-144C625.5,-144 628.4707,-123.9478 630.7916,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 28 -->
<g id="node29">
<title>28</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="717.5" y="-159.3">Str</text>
</g>
<!-- 27&#45;&#45;28 -->
<g id="edge28">
<title>27--28</title>
<path d="M696.8554,-215.8314C703.625,-205 712.1953,-191.2876 718.9917,-180.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 29 -->
<g id="node30">
<title>29</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="741.5" y="-86.3">"equilateral"</text>
</g>
<!-- 28&#45;&#45;29 -->
<g id="edge29">
<title>28--29</title>
<path d="M733.2758,-143.8314C734.9306,-133 737.0255,-119.2876 738.6869,-108.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 31 -->
<g id="node32">
<title>31</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="844.5" y="-159.3">Str</text>
</g>
<!-- 30&#45;&#45;31 -->
<g id="edge31">
<title>30--31</title>
<path d="M832.8273,-215.8314C837.7917,-205 844.0765,-191.2876 849.0606,-180.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 32 -->
<g id="node33">
<title>32</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="889.5" y="-86.3">"isosceles #1"</text>
</g>
<!-- 31&#45;&#45;32 -->
<g id="edge32">
<title>31--32</title>
<path d="M865.575,-143.8314C870.3889,-133 876.4833,-119.2876 881.3163,-108.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 34 -->
<g id="node35">
<title>34</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1135" y="-231.3">Compare</text>
</g>
<!-- 33&#45;&#45;34 -->
<g id="edge34">
<title>33--34</title>
<path d="M1236.5,-288C1236.5,-288 1209.7637,-267.9478 1188.8759,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 42 -->
<g id="node43">
<title>42</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1247" y="-231.3">Return</text>
</g>
<!-- 33&#45;&#45;42 -->
<g id="edge42">
<title>33--42</title>
<path d="M1236.5,-288C1236.5,-288 1249.8682,-267.9478 1260.312,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 45 -->
<g id="node46">
<title>45</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1585" y="-231.3">If</text>
</g>
<!-- 33&#45;&#45;45 -->
<g id="edge45">
<title>33--45</title>
<path d="M1236.5,-288C1236.5,-288 1483.0627,-250.7048 1566.374,-238.1031" fill="none" stroke="#000000"></path>
</g>
<!-- 35 -->
<g id="node36">
<title>35</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1056.5" y="-159.3">Name</text>
</g>
<!-- 34&#45;&#45;35 -->
<g id="edge35">
<title>34--35</title>
<path d="M1161.5,-216C1161.5,-216 1126.694,-194.6418 1100.8614,-178.7899" fill="none" stroke="#000000"></path>
</g>
<!-- 38 -->
<g id="node39">
<title>38</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1145.5" y="-158.3">Eq</text>
</g>
<!-- 34&#45;&#45;38 -->
<g id="edge38">
<title>34--38</title>
<path d="M1161.5,-216C1161.5,-216 1155.5586,-195.9478 1150.9169,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 39 -->
<g id="node40">
<title>39</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1200.5" y="-159.3">Name</text>
</g>
<!-- 34&#45;&#45;39 -->
<g id="edge39">
<title>34--39</title>
<path d="M1161.5,-216C1161.5,-216 1182.2949,-195.9478 1198.541,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 36 -->
<g id="node37">
<title>36</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1001.5" y="-86.3">"b"</text>
</g>
<!-- 35&#45;&#45;36 -->
<g id="edge36">
<title>35--36</title>
<path d="M1065.5,-144C1065.5,-144 1041.7344,-123.9478 1023.1675,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 37 -->
<g id="node38">
<title>37</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1073.5" y="-86.3">Load</text>
</g>
<!-- 35&#45;&#45;37 -->
<g id="edge37">
<title>35--37</title>
<path d="M1065.5,-144C1065.5,-144 1068.4707,-123.9478 1070.7916,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 40 -->
<g id="node41">
<title>40</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1145.5" y="-86.3">"c"</text>
</g>
<!-- 39&#45;&#45;40 -->
<g id="edge40">
<title>39--40</title>
<path d="M1209.5,-144C1209.5,-144 1185.7344,-123.9478 1167.1675,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 41 -->
<g id="node42">
<title>41</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1217.5" y="-86.3">Load</text>
</g>
<!-- 39&#45;&#45;41 -->
<g id="edge41">
<title>39--41</title>
<path d="M1209.5,-144C1209.5,-144 1212.4707,-123.9478 1214.7916,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 43 -->
<g id="node44">
<title>43</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1296.5" y="-159.3">Str</text>
</g>
<!-- 42&#45;&#45;43 -->
<g id="edge43">
<title>42--43</title>
<path d="M1281.8367,-215.8314C1287.4028,-205 1294.4494,-191.2876 1300.0376,-180.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 44 -->
<g id="node45">
<title>44</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1329.5" y="-86.3">"isosceles #2"</text>
</g>
<!-- 43&#45;&#45;44 -->
<g id="edge44">
<title>43--44</title>
<path d="M1314.5468,-143.8314C1317.5555,-133 1321.3646,-119.2876 1324.3852,-108.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 46 -->
<g id="node47">
<title>46</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1496" y="-159.3">Compare</text>
</g>
<!-- 45&#45;&#45;46 -->
<g id="edge46">
<title>45--46</title>
<path d="M1603.5,-216C1603.5,-216 1574.5356,-195.9478 1551.9072,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 54 -->
<g id="node55">
<title>54</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1636" y="-159.3">Return</text>
</g>
<!-- 45&#45;&#45;54 -->
<g id="edge54">
<title>45--54</title>
<path d="M1603.5,-216C1603.5,-216 1625.0376,-195.9478 1641.8638,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 57 -->
<g id="node58">
<title>57</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1768" y="-159.3">Return</text>
</g>
<!-- 45&#45;&#45;57 -->
<g id="edge57">
<title>45--57</title>
<path d="M1603.5,-216C1603.5,-216 1705.4239,-187.0321 1759.9692,-171.5298" fill="none" stroke="#000000"></path>
</g>
<!-- 47 -->
<g id="node48">
<title>47</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1424.5" y="-87.3">Name</text>
</g>
<!-- 46&#45;&#45;47 -->
<g id="edge47">
<title>46--47</title>
<path d="M1523.5,-144C1523.5,-144 1492.6587,-123.6898 1468.8048,-107.9812" fill="none" stroke="#000000"></path>
</g>
<!-- 50 -->
<g id="node51">
<title>50</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1513.5" y="-86.3">Eq</text>
</g>
<!-- 46&#45;&#45;50 -->
<g id="edge50">
<title>46--50</title>
<path d="M1523.5,-144C1523.5,-144 1519.7866,-123.9478 1516.8855,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 51 -->
<g id="node52">
<title>51</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1568.5" y="-87.3">Name</text>
</g>
<!-- 46&#45;&#45;51 -->
<g id="edge51">
<title>46--51</title>
<path d="M1523.5,-144C1523.5,-144 1546.5229,-123.9478 1564.5096,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 48 -->
<g id="node49">
<title>48</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1369.5" y="-14.3">"a"</text>
</g>
<!-- 47&#45;&#45;48 -->
<g id="edge48">
<title>47--48</title>
<path d="M1433.5,-72C1433.5,-72 1409.7344,-51.9478 1391.1675,-36.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 49 -->
<g id="node50">
<title>49</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1441.5" y="-14.3">Load</text>
</g>
<!-- 47&#45;&#45;49 -->
<g id="edge49">
<title>47--49</title>
<path d="M1433.5,-72C1433.5,-72 1436.4707,-51.9478 1438.7916,-36.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 52 -->
<g id="node53">
<title>52</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1513.5" y="-14.3">"c"</text>
</g>
<!-- 51&#45;&#45;52 -->
<g id="edge52">
<title>51--52</title>
<path d="M1577.5,-72C1577.5,-72 1553.7344,-51.9478 1535.1675,-36.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 53 -->
<g id="node54">
<title>53</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1585.5" y="-14.3">Load</text>
</g>
<!-- 51&#45;&#45;53 -->
<g id="edge53">
<title>51--53</title>
<path d="M1577.5,-72C1577.5,-72 1580.4707,-51.9478 1582.7916,-36.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 55 -->
<g id="node56">
<title>55</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1666.5" y="-87.3">Str</text>
</g>
<!-- 54&#45;&#45;55 -->
<g id="edge55">
<title>54--55</title>
<path d="M1666.0422,-143.8314C1668.75,-133 1672.1781,-119.2876 1674.8967,-108.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 56 -->
<g id="node57">
<title>56</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1697.5" y="-14.3">"isosceles #3"</text>
</g>
<!-- 55&#45;&#45;56 -->
<g id="edge56">
<title>55--56</title>
<path d="M1684.0422,-71.8314C1686.75,-61 1690.1781,-47.2876 1692.8967,-36.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 58 -->
<g id="node59">
<title>58</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1792.5" y="-87.3">Str</text>
</g>
<!-- 57&#45;&#45;58 -->
<g id="edge58">
<title>57--58</title>
<path d="M1796.5281,-143.8314C1798.3333,-133 1800.6187,-119.2876 1802.4311,-108.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 59 -->
<g id="node60">
<title>59</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1828.5" y="-14.3">"scalene"</text>
</g>
<!-- 58&#45;&#45;59 -->
<g id="edge59">
<title>58--59</title>
<path d="M1811.3039,-71.8314C1814.7639,-61 1819.1442,-47.2876 1822.618,-36.4133" fill="none" stroke="#000000"></path>
</g>
</g>
</svg>

</p>

</div><div>

<div>
<pre>['z3.And((a == b), (b == c))',
 'z3.And((a == b), z3.Not(b == c))',
 'z3.And(z3.Not(a == b), (b == c))',
 'z3.And(z3.Not(a == b), z3.Not(b == c), (a == c))',
 'z3.And(z3.Not(a == b), z3.Not(b == c), z3.Not(a == c))']
</pre>
</div>

</div><div>

<div>
<pre>[b = 1, a = 1, c = 1] equilateral
[b = 1, a = 1, c = 2] isosceles #1
[b = 2, a = 1, c = 2] isosceles #2
[b = 2, a = 1, c = 1] isosceles #3
[b = 3, a = 1, c = 2] scalene
</pre>
</div>

</div><div>
<div>
<div>
<div><h2 id="The-Virtues-of-Prototyping">The Virtues of Prototyping<a href="#The-Virtues-of-Prototyping">¶</a></h2><p>One neat thing about prototyping (with Python or whatever) is that it allows you to fully focus on your <em>approach</em>, rather than on the infrastructure. Very obviously, this is useful for <em>teaching</em> – you can use examples as the ones above in a lecture to very quickly communicate essential techniques of program analysis and test generation.</p>
<p>But prototyping has more advantages. A Jupyter Notebook (like this one) documents how you developed your approach, together with examples, experiments, and rationales – and still focusing on the essentials. If you write a tool the "classical" way, you will eventually deliver thousands of lines of code that do everything under the sun, but only once you have implemented everything will you know whether things actually work. This is a huge risk, and if you still have to change things, you will have to refactor things again and again. Furthermore, for anyone who will work on that code later, it will take days, if not weeks, to re-extract the basic idea of the approach, as it will be buried under loads and loads of infrastructure and refactorings.</p>
<p>Our consequence at this point is that we now implement new ideas <em>twice</em>:</p>
<ul>
<li><p>First, we implement things as a notebook (as this one), experimenting with various approaches and parameters until we get them right.</p>
</li>
<li><p>Only once we have the approach right, and if we have confidence that it works, we reimplement it in a tool that works on large scale programs. This can still take weeks to months, but at least we know we are on a good path.</p>
</li>
</ul>
<p>Incidentally, it may well be that the original notebooks will have a longer life, as they are simpler, better documented, and capture the gist of our novel idea. And this is how several of the notebooks in this book came to be.</p>
</div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.fuzzingbook.org/beta/html/PrototypingWithPython.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937438</guid>
            <pubDate>Thu, 29 Oct 2020 23:42:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bizarre Design Choices in Zoom’s End-to-End Encryption]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 37 (<a href="https://news.ycombinator.com/item?id=24937298">thread link</a>) | @notRobot
<br/>
October 29, 2020 | https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/?hac | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/?hac">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Zoom recently announced that they were going to make end-to-end encryption available to all of their users–not just customers.</p>



<figure><div>

</div></figure>



<p>This is a good move, especially for people living in countries with <a href="https://soatok.blog/2020/07/02/how-and-why-america-was-hit-so-hard-by-covid-19/">inept leadership that failed to address the COVID-19 pandemic</a> and therefore need to conduct their work and schooling remotely through software like Zoom. I enthusiastically applaud them for making this change.</p>



<div><figure><img data-attachment-id="1333" data-permalink="https://soatok.blog/soatoktelegrams2020-08/" data-orig-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-08" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=512" src="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png 512w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=150 150w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>End-to-end encryption, on by default, is a huge win for everyone who uses Zoom. (Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<p>The end-to-end encryption capability arrives on the heels of their acquisition of <a href="https://keybase.io/">Keybase</a> in earlier this year. Hiring a team of security experts and cryptography engineers seems like a good move overall.</p>



<p>Upon hearing this news, I decided to be a good neighbor and take a look at their source code, with the reasoning, “If so many people’s privacy is going to be dependent on Zoom’s security, I might as well make sure they’re not doing something ridiculously bad.”</p>



<p>Except I couldn’t find their source code anywhere online. But they did publish <a href="https://github.com/zoom/zoom-e2e-whitepaper">a white paper on Github</a>…</p>







<h2>Disclaimers</h2>



<p>What follows is the opinion of some guy on the Internet with a fursona–so whether or not you choose to take it seriously should be informed by this context. It is not the opinion of anyone’s employer, nor is it endorsed by Zoom, etc. Tell your lawyers to calm their nips.</p>



<p>More importantly, I’m not here to hate on Zoom for doing a good thing, nor on the security experts that worked hard on making Zoom better for their users. The responsibility of security professionals is to the users, after all.</p>



<p>Also, these aren’t zero-days, so don’t try to lecture me about “responsible” disclosure. (That term is also <a href="https://adamcaudill.com/2015/11/19/responsible-disclosure-is-wrong/">problematic</a>, by the way.)</p>



<p>Got it? Good. Let’s move on.</p>







<h2>Bizarre Design Choices in Version 2.3 of Zoom’s E2E White Paper</h2>



<p>Note: I’ve altered the screenshots to be white text on a black background, since my blog’s color scheme is darker than a typical academic PDF. You can find the source <a href="https://github.com/zoom/zoom-e2e-whitepaper/blob/d3be2a5a3e16be04f1199b92630f180ba79cb51c/zoom_e2e.pdf">here</a>.</p>



<h3>Cryptographic Algorithms</h3>



<div><figure><img data-attachment-id="1744" data-permalink="https://soatok.blog/zoom-e2e-02/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png" data-orig-size="784,652" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-02" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png" alt=""></figure></div>



<p>It’s a little weird that they’re calculating a signature over SHA256(Context) || SHA256(M), considering Ed25519 uses SHA512 internally.</p>



<p>It would make just as much sense to sign Context || M directly–or, if pre-hashing large streams is needed, SHA512(Context || M).</p>



<div><figure><img data-attachment-id="1740" data-permalink="https://soatok.blog/zoom-e2e-01/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png" data-orig-size="1039,788" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-01" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png" alt=""></figure></div>



<p>At the top of this section, it says it uses libsodium’s <code>crypto_box</code> interface. But then they go onto… not actually use it.</p>



<p>Instead, they wrote their own protocol using HKDF, two SHA256 hashes, and XChaCha20-Poly1305.</p>



<p>While secure, this isn’t <em>really</em> using the crypto_box interface.</p>



<p>The only part of the libsodium interface that’s being used is <code><a href="https://github.com/jedisct1/libsodium/blob/927dfe8e2eaa86160d3ba12a7e3258fbc322909c/src/libsodium/crypto_box/curve25519xsalsa20poly1305/box_curve25519xsalsa20poly1305.c#L35-L46">crypto_box_beforenm()</a></code>, which could easily have been a call to <code>crypto_scalarmult()</code>instead (since they’re passing the output of the scalar multiplication to HKDF anyway).</p>







<p>Also, the SHA256(a) || SHA256(b) pattern returns. Zoom’s engineers must love SHA256 for some reason.</p>



<p>This time, it’s in the additional associated data for the XChaCha20-Poly1305. </p>



<p>Binding the ciphertext and the signature to the same context string is a sensible thing to do, it’s just the concatenation of SHA256 hashes is a bit weird when SHA512 exists.</p>



<h3>Meeting Leader Security Code</h3>



<div><figure><img data-attachment-id="1746" data-permalink="https://soatok.blog/zoom-e2e-03/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png" data-orig-size="760,733" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-03" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png" alt=""></figure></div>



<p>Here we see Zoom using the a SHA256 of a constant string (“<code>Zoombase-1-ClientOnly-MAC-SecurityCode</code>“) in a construction that tries but fails to be HMAC.</p>



<p>And then they concatenate it with the SHA256 hash of the public key (which is already a 256-bit value), and then they hash the whole thing again.</p>



<p>It’s redundant SHA256 all the way down. The redundancy of “MAC” and “SecurityCode” in their constant string is, at least, consistent with the rest of their design philosophy.</p>



<p>It would be a real shame if double-hashing carried the risk of <a href="https://eprint.iacr.org/2013/382">invalidating security proofs</a>, or if <a href="https://cseweb.ucsd.edu/~mihir/papers/kmd5.pdf">the security proof for HMAC</a> required a high Hamming distance of padding constants and this design decision also later <a href="https://eprint.iacr.org/2012/684.pdf">saved HMAC from related-key attacks</a>.</p>



<h3>Hiding Personal Details</h3>



<figure><img data-attachment-id="1750" data-permalink="https://soatok.blog/zoom-e2e-04/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png" data-orig-size="739,603" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-04" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=739" alt="" srcset="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png 739w, https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=150 150w, https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=300 300w" sizes="(max-width: 739px) 100vw, 739px"></figure>



<p>Wait, you’re telling me Zoom was aware of HMAC’s existence this whole time?</p>



<div><figure><img data-attachment-id="1202" data-permalink="https://soatok.blog/soatoktelegrams2020-02/" data-orig-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-02" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=512" src="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png 512w, https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=150 150w, https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>I give up!</figcaption></figure></div>



<h2>Enough Pointless Dunking, What’s the Takeaway?</h2>



<p>None of the design decisions Zoom made that I’ve criticized here are security vulnerabilities, but they do demonstrate an early lack of cryptography expertise in their product design.</p>



<p>After all, the weirdness is almost entirely contained in section 3 of their white paper, which describes the “Phase I” of their rollout. So what I’ve pointed out here appears to be mostly legacy cruft that wasn’t risky enough to bother changing in their final design.</p>



<p>The rest of their paper is pretty straightforward and pleasant to read. Their design makes sense in general, and each phase includes an “Areas to Improve” section.</p>



<p>All in all, if you’re worried about the security of Zoom’s E2EE feature, the only thing they can really do better is to publish the source code (and link to it from the whitepaper repository for ease-of-discovery) for this feature so independent experts can publicly review it.</p>



<p>However, they seem to be getting a lot of mileage out of the experts on their payroll, so I wouldn’t count on that happening.</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/?hac</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937298</guid>
            <pubDate>Thu, 29 Oct 2020 23:23:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Margin analytics using Kubernetes, Stripe and Octane]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937290">thread link</a>) | @akhanolk
<br/>
October 29, 2020 | https://www.getoctane.io/per-customer-margins-using-stripe-and-kubernetes | <a href="https://web.archive.org/web/*/https://www.getoctane.io/per-customer-margins-using-stripe-and-kubernetes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
          
            
            <figure><img src="https://cdn.spark.app/media/self3/image/blank_diagram_16_0i05x5f_w720.png" alt="Margin analytics"></figure><p><span>[The picture above depicts the results of a real-time margin analysis experiment, overlaying AWS infrastructure costs and Stripe revenue]</span></p><p>A simple (naive?) approach to a complicated problem!</p><p>Let's set the scene. I'm a subscription-based SaaS company running expensive cloud infrastructure (on Kubernetes) that is shared across all of my customers.</p><p>Today, I can approximate my total margin using monthly revenue from Stripe and my infrastructure bill from AWS. However, I have no insights into how each customer contributes to margin. Given <strong>margin per customer</strong>, I could answer several valuable questions:</p><ul><li><strong>Who are my good (high-margin) customers and who are my bad (low/negative-margin) customers?</strong></li><li><strong>How are my margins changing as my business grows?</strong></li><li><strong>How are changes to my products affecting my profits?</strong></li></ul><p>The solution here can be complicated. </p><p>Assuming that my cost is primarily cloud infrastructure costs, to getÂ&nbsp;<strong>cost per customer*</strong>, first I need to set up monitoring layers to properly measure customer usage. Then, I need to enrich the usage data with cloud prices. To complicate matters further, I need to consolidate and store this data long-term to maintain historical views of my business across my distributed infrastructure. Finally, I need to join this data withÂ&nbsp;<strong>revenue per customer**</strong>.</p><p>Fortunately, my customers are segmented by jobs (i.e., pods, namespaces, and(or) clusters). In this case,Â&nbsp;<strong>cost per customer </strong>is approximately the cost of a customer's namespace. I can track cost per namespace using the <strong><span><a href="https://getoctane.io/">Octane</a></span></strong> Cost API and join myÂ&nbsp;<strong>revenue per customer</strong>Â&nbsp;using the <strong><span><a href="https://stripe.com/">Stripe</a></span></strong> API. Through these integrations, I can extract real-timeÂ&nbsp;<strong>margin per customer</strong>.</p><p><span>[Important to note that we understand that many SaaS companies will not have customers segmented by namespaces. For purposes of blog post we have chosen to simplify the problem]</span></p><p>Here are main components and steps to complete:</p><p><strong>cost per customer</strong>:</p><ol><li>(pre-requisite) set upÂ&nbsp;<strong><span><a href="https://getoctane.io/">Octane</a></span></strong>Â&nbsp;and connect cluster(s) to measure infrastructure costs</li><li>set up Octane accounts to track namespaces (I've chosen to segment customers by namespace for this example)</li><li>fetch costs for the customer accounts</li></ol><p><strong>revenue per customer</strong>:</p><ol><li>(pre-requisite) set upÂ&nbsp;<span><a href="https://stripe.com/">Stripe</a></span>Â&nbsp;to track customer subscriptions</li><li>fetch Stripe subscriptions and compute the expected charge for a given time range</li></ol><p><strong>margin per customer:</strong>Â&nbsp;</p><ol><li>formula: (<strong>revenue per customer</strong>Â&nbsp;-Â&nbsp;<strong>cost per customer</strong>) /Â&nbsp;<strong>revenue per customer</strong></li></ol><h2>Getting Started</h2><p>I did some pre-requisite steps to get the data I needed to get real-time cost per customer (Octane) and revenue per customer (Stripe).</p><p><strong>Set upÂ&nbsp;</strong><strong><span><a href="https://getoctane.io/">Octane</a></span></strong></p><ul><li>Register / Login</li><li>Add Kubernetes cluster</li></ul><p><strong> Set upÂ&nbsp;</strong><strong><span><a href="https://stripe.com/">Stripe</a></span></strong></p><ul><li>Register / Login</li><li>Create customers</li><li>Add subscriptions for customers</li></ul><h3>Cost per customer</h3><p>Now, that our tools are setup, I need to start leveraging them to get real-time margin. First let's get cost per customer data. I begin by setting up a mapping from the Stripe customer list to the Kubernetes customer namespaces.</p><pre># Import python libraries
import pandas as pd
import pprint
import requests
HOURS_TO_SECONDS = 60.0 * 60.0
# Octane API URL
OCTANE_URL = "https://hasura.cloud.getoctane.io/v1/graphql"
# Set up time range for computing cost and revenue
LOOKBACK_HOURS = 4
START_TIME = pd.Timestamp.utcnow() - pd.Timedelta(hours=LOOKBACK_HOURS)
# Set up mapping from customer to corresponding namespace in Kubernetes clusters
CUSTOMERS = {
    "Slow Sally": {
        "namespace": "slow-sally"
    },
    "Stingy Sid": {
        "namespace": "stingy-sid"
    },
    "Mike SpendALot": {
        "namespace": "mike-spendalot"
    },
    "Jamie Jay": {
        "namespace": "jamie-jay"
    },
    "John Du": {
        "namespace": "john-du"
    }
}</pre><p>Next, I need to send a login request to the Octane API to fetch an access token for further requests.</p><pre>login_mutation = """
mutation Login{
    login(args: {username: "EMAIL_ADDRESS", password: "PASSWORD"}){
        accessToken
    }
}
"""
res = requests.post(OCTANE_URL, json={"query": login_mutation})
if res.status_code != 200:
    raise Exception('Failed login request')
access_token = res.json().get('data', {}).get('login', {}).get('accessToken', "")
auth_headers = {"Authorization": f"Bearer {access_token}"}</pre><p>Once I am authenticated, I need to create an Octane grouping (account) for each customer, specifying the corresponding namespace.</p><pre># addAccount creates a logical grouping of costs in Octane
add_account_mutation = """
mutation AddAccount{
    addAccount(args: {accountName: "%s", aggregationType: "namespace", aggregationRegex: "%s"}){
        id
    }
}
"""
# Loops through CUSTOMERS to create groupings in Octane
for name, details in CUSTOMERS.items():
    add_account_request = {
        "query": add_account_mutation % (name, details["namespace"])
    }
    res = requests.post(OCTANE_URL, json=add_account_request, headers=auth_headers)
    if res.status_code != 200:
        raise Exception('Failed add account request')</pre><h4>Now that Octane knows how to group real-time cloud costs by customer, I am ready to query for those costs. </h4><pre>account_cost_query = """
query CostQuery {
    pod_cost_aggregate(where: {end_time: {_gte: "%s"}, pod: {account_pods: {account: {name: {_eq: "%s" } } } } }) {
        aggregate {
            sum {
                cost
            }
        }
    }
}
"""
for name in CUSTOMERS:
    get_costs_request = {
        "query": account_cost_query % (START_TIME, name)
    }
    res = requests.post(OCTANE_URL, json=get_costs_request, headers=auth_headers)
    if res.status_code != 200:
        raise Exception('Failed getting account costs')
    cost = res.json().get('data', {}).get('pod_cost_aggregate', {}).get('aggregate', {}).get('sum', {}).get('cost')
    CUSTOMERS[name]['cost'] = cost
print(pd.DataFrame(CUSTOMERS))</pre><p>Great! Now, I have a side by side comparison of customers (namespaces) and cost (spend).</p><figure><img src="https://cdn.spark.app/media/self3/image/screen_shot_2020_10_20_at_7.58.02_pm_w720.png" alt=""></figure><figure><img src="https://cdn.spark.app/media/self3/image/screen_shot_2020_10_20_at_9.05.35_pm_w720.png" alt=""></figure><p><span>[The graph above was pulled from Octane UI]</span></p><p>As you can see in the tables and graphs above, I have real-time visibility into our most expensive customers (Mike SpendALot) and cost-efficient customers (stingy-sid, slow-sally).  </p><h3>Revenue per customer</h3><h4><span>Now that I have cost per customer, I need to overlay that data with revenues from Stripe to get real-time margins per customer.</span></h4><p>First, I start by getting customer subscriptions. </p><pre>import stripe
stripe.api_key = 'STRIPE_API_KEY'
customers = { customer.id: customer for customer in stripe.Customer.list().data}
subscriptions = { subscription.customer: subscription for subscription in stripe.Subscription.list().data}</pre><p>Now I need to convert subscriptions to revenue. Revenue is extrapolated from the unit price of a customer subscription. <span>[Note that revenue structure may be more complex when using other Stripe features (e.g. metered billing, discounts, trials, etc.)].</span></p><pre>for customer in customers:
    subscription = subscriptions.get(customer)
    if subscription:
        customer_name = customers[customer].name
        customer_subscription_price = subscription.get('items', {}).get('data')[0].price
        interval_seconds = pd.Timedelta(f"{customer_subscription_price.recurring.interval_count} {customer_subscription_price.recurring.interval}").total_seconds()
        price_per_hour = (customer_subscription_price.unit_amount / 100.0) / (interval_seconds / HOURS_TO_SECONDS)
        CUSTOMERS[customer_name]['revenue'] = price_per_hour * LOOKBACK_HOURS
print(pd.DataFrame(CUSTOMERS))</pre><figure><img src="https://cdn.spark.app/media/self3/image/screen_shot_2020_10_20_at_7.59.30_pm_w720.png" alt=""></figure><p>Excellent, now I have customer, cost, and revenue grouped together. All that is left to do is compute margins. </p><pre>for name, details in CUSTOMERS.items():
    CUSTOMERS[name]['pct_margin'] = 100 * (details['revenue'] - details['cost']) / details['revenue']
print(pd.DataFrame(CUSTOMERS))</pre><figure><img src="https://cdn.spark.app/media/self3/image/blank_diagram_17_w720.png" alt="Margin analytics"></figure><p>Viola! I have calculated real-time margins per customer. I can quickly see that Mike SpendAlot is bring me the lowest percent margins. </p><h3>Conclusion</h3><p>Calculating customer cost for SaaS companies is complex. By leveraging Octane and Stripe,Â&nbsp;I can capture, segment, and visualize customer costs in real-time to answer valuable business questions. The example above enabled us to differentiate between my low and high margin customers (Stingy Sid vs Mike SpendALot). It allowed us to do it real-time and on an ongoing basis, which is especially useful as my products, customers and business evolve.</p><p><span>I hope to spark discussion around the potential of leveraging infrastructure to inform business performance. I've made several assumptions and simplifications around the complexities of margin as there is no cookie-cutter solution. </span></p><p>If you have any thoughts or questions we would love to hear from you - email me at akash@getoctane.io.</p><p><em><span>*I define cost per customer as the recurring infrastructure costs attributed to a customer's usage.  Please note that infrastructure may only be a part of recurring costs.  Cost of revenue can include other significant components not covered here (e.g. DevOps, customer success, support). </span></em></p><p><em><span>**In this walk-through, there is a single revenue stream. However, SaaS companies may have multiple revenue streams including professional services. It is important to compute margin separately for different revenue streams.</span></em></p>
          
          
        </article></div>]]>
            </description>
            <link>https://www.getoctane.io/per-customer-margins-using-stripe-and-kubernetes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937290</guid>
            <pubDate>Thu, 29 Oct 2020 23:22:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dependency inference in Pants 2.0.0: Precise caching without the boilerplate]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24937228">thread link</a>) | @stuhood
<br/>
October 29, 2020 | https://blog.pantsbuild.org/dependency-inference/ | <a href="https://web.archive.org/web/*/https://blog.pantsbuild.org/dependency-inference/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<!--kg-card-begin: markdown--><p>As discussed <a href="https://blog.pantsbuild.org/introducing-pants-v2/">in our post announcing Pants v2</a>, it's clear that Python has "grown up" by gaining facilities to help it to scale to larger projects. But as codebases grow and tool counts increase, more Python codebases need build tools. While you could write bespoke scripts to coordinate each of your tools, using Pants brings benefits like caching, concurrency, introspection, a simple and uniform user experience, and more!</p>
<p>Unfortunately, scalable build tools have historically meant a significant boilerplate burden: scattering <code>BUILD</code> files throughout your repository and then needing to edit both your code and the redundant dependency information in build definitions.</p>
<p>But it doesn’t have to be that way! Pants v2 supports the precise caching, concurrency, and introspection that you need to scale your repository, with up to <strong>90%</strong> less <code>BUILD</code> boilerplate, thanks to… Dependency inference!</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="scalingup">Scaling up</h2>
<p>Pants supports repos of all sizes with minimal boilerplate, but it is particularly helpful in repositories containing multiple deployable or publishable projects, each with potentially different requirements or interpreters: aka, monorepos.</p>
<p>Monorepos have lots of benefits (no dependency conflicts, atomic cross-project commits, easy top-to-bottom continuous integration, linear change history), but essential to making them scale are the abilities to:</p>
<ol>
<li>test, check, and deploy precisely the portion of the repository that is relevant to you</li>
<li>cache builds and tests to avoid re-building when unrelated code has changed</li>
<li>manage and configure the variety of tooling that users of the repository will want to use</li>
</ol>
<p>It's critical in a monorepo to be able to test, check, and deploy exactly the relevant portion of your code, ideally with zero impact from changes in unrelated parts of the codebase. For example: if you have three libraries <code>A</code>, <code>B</code>, and <code>C</code>, which depend on one another in a chain like <code>A -&gt; B -&gt; C</code>, a monorepo that builds from source using Pants allows you to completely ignore versioning (and <code>setup.py</code> files, per-project <code>requirements.txt</code>, etc) while you edit library <code>C</code>, even if you are running the tests for library <code>A</code>. If you have ten other projects (or one thousand!) in your repository and only a few of them depend on <code>C</code>, you'd like to avoid ever running tests or mypy for the unrelated libraries while editing <code>C</code>.</p>
<p>And in those cases when you <em>do</em> want to take advantage of a monorepo's top-to-bottom integration testing by running "all of your dependent's tests" (or maybe just typecheck them with Mypy!), you'd like to do that as quickly as possible by taking advantage of caching, concurrency, or transparently executing them on a cluster of machines using remote execution.</p>
<p>To enable this scalability, monorepo build tools like Pants v1 and Bazel required that the dependencies between libraries and files were declared in <code>BUILD</code> files. These dependencies were then used to determine which portions of the repository needed to be built, and which files needed to be included in cache keys.</p>
<p>"But wait", you say! "Doesn't that mean we've traded editing <code>setup.py</code> and <code>requirements.txt</code> files for every library for editing <code>BUILD</code> files for every library?" In most tools, that would be the case: but not in Pants v2! Pants v2 is different.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="dependencyinference">Dependency inference</h2>
<p>Pants 2.0.0 almost entirely eliminates the boilerplate of declaring dependencies between libraries thanks to "Dependency inference". Dependency inference is roughly what it sounds like: Pants supports discovering the dependencies between Python libraries by parsing <code>import</code> statements (and you can <a href="https://www.pantsbuild.org/docs/plugins-overview">use our powerful plugin API</a> to infer other dependencies, such as by parsing a Django settings file, YAML config, etc).</p>
<p>Rather than adding an <code>import</code> statement to your code resulting in your tests failing because you forgot to <em>also</em> update a <code>BUILD</code> file, Pants will use your newly added <code>import</code> statement to infer that that file now has a dependency within the repository (or outside it via your <code>requirements.txt</code>). When designing inference, we strove to remove boilerplate without introducing magic, so <code>BUILD</code> files are still used to declare any metadata your library might have (the version of the Python interpreter to use, etc), and can be used to <a href="https://www.pantsbuild.org/docs/targets#dependencies-and-dependency-inference">override or extend</a> the inferred dependencies.</p>
<p>Even better, Pants infers these dependencies <em>at the file level</em>. Rather than adding a dependency from "the library named <code>A</code>" to "the library named <code>B</code>" (or "target" in monorepo parlance), Pants tracks that "file <code>a.py</code> depends on file "<code>b.py</code>". Rather than staring at the content of your <code>BUILD</code> files to (attempt to?) understand your dependencies, you can use Pants' dependency introspection tools to easily explore them at the file level: <code>./pants dependencies $file</code>.</p>
<p>In practice, we’ve found that inferred file-level dependencies can reduce the total per-file dependency count by an average of <strong>30%</strong> (improving cache hit rates), and reduce the size of <code>BUILD</code> files by up to <strong>90%</strong> (reducing boilerplate)! See our docs for <a href="https://www.pantsbuild.org/docs/how-does-pants-work#dependency-inference">a real world example</a>.</p>
<p>And critically (as we’ll discuss in further posts!), dependency inference is both 1) very safe, and 2) very fast. Because Pants invokes processes hermetically using SHA256 fingerprinting and strong sandboxes (your test frameworks, your linters, mypy, everything), failing to infer a dependency can never cause the wrong things to be cached. And because the core of Pants is implemented in Rust — and uses a daemon, parallelism, and very-fine-grained memoization — inference won’t slow you down!</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="demonstration">Demonstration</h2>
<p>To show what it’s like to use dependency inference, we’ll quickly add a feature with assistance from some new first and third party dependencies (from sources and PyPI, respectively).</p>
<p>We’ll start with a broken test that expects TOML files to be supported by a library in a different directory:</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/1.gif" alt=""></figure><!--kg-card-begin: markdown--><p>Because we’re curious, we’ll start by asking Pants whether the library already (directly) depends on TOML:</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/2.gif" alt=""></figure><!--kg-card-begin: markdown--><p>Nope. Only YAML. But let’s add the <code>import</code> statement and see what happens…</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/3.gif" alt=""></figure><!--kg-card-begin: markdown--><p>Voila! This file now declares a dependency on TOML via the <code>import</code> statement, without any modifications to <code>BUILD</code> files. But we’re not finished: neither the flake8 linter nor the customer will be satisfied with an unused <code>import</code>! Let’s finish adding the feature, and then re-run the test.</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/4.gif" alt=""></figure><!--kg-card-begin: markdown--><p>Ok, TOML is clearly being used: but this time our test needs tweaking. To fix it we can import a <code>TomlSerializer</code> helper class from a second library (another new dependency!). We already know that we don’t need to check the <code>BUILD</code> file to see whether this test declares a dependency on the library, so we can just focus on our code!:</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/5.gif" alt=""></figure><!--kg-card-begin: markdown--><p>Great: our test is now passing! To fix it, we edited two files and introduced two new dependencies -- but we didn’t need to edit any <code>BUILD</code> files, despite these files living in different targets!</p>
<p>Finally, let’s confirm the critical monorepo scalability property that edits to unrelated files don’t invalidate the caching of our new test. Although this test is quick, there are a few hundred files in this repository, and plenty of other tests that could take long enough to result in coffee breaks!:</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/6.gif" alt=""></figure><!--kg-card-begin: markdown--><p>Excellent! Thanks to dependency inference’s file level precision, our test is still quickly and correctly cached, even after editing neighboring files in the target! Productivity preserved; mission accomplished.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="conclusion">Conclusion</h2>
<p>The precise, always-accurate dependencies in Pants have a lot of benefits:</p>
<ol>
<li>teams can quickly get started using Pants</li>
<li><code>BUILD</code> files (or <code>requirements.txt</code>/<code>setup.py</code> files) can't go out of sync with the code, because you don't need to repeat all of your <code>import</code> statements there</li>
<li>the cache keys for processes (and thus the number of cache hits and amount of rebuilding) are more accurate and much more fine-grained than you would ever write by hand</li>
</ol>
<p>If you're interested in speeding-up and scaling-up your builds without the boilerplate, the <a href="https://www.pantsbuild.org/docs/community">Pants community would love to help</a>!</p>
<!--kg-card-end: markdown-->
			</section></div>]]>
            </description>
            <link>https://blog.pantsbuild.org/dependency-inference/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937228</guid>
            <pubDate>Thu, 29 Oct 2020 23:14:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The most advanced VPN and unblocker with industry-first features]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24937073">thread link</a>) | @Oeck
<br/>
October 29, 2020 | http://www.oeck.com/features/ | <a href="https://web.archive.org/web/*/http://www.oeck.com/features/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<!--XF:EXTRA_OUTPUT-->

		

		

		
	

		
	<!--[if lt IE 9]><div class="blockMessage blockMessage&#45;&#45;important blockMessage&#45;&#45;iconic">You are using an out of date browser. It  may not display this or other websites correctly.<br />You should upgrade or use an <a href="https://www.google.com/chrome/browser/" target="_blank">alternative browser</a>.</div><![endif]-->


		
			<div>
			
				
					
				

				
					<p>The things that make us different.</p>
				
			
				
			</div>
		

		<div>
			

			<div>
				
				<div>

	



	
	
	










	<div>
	<div data-aos="fade-up">
		<div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/smartRouting.png">
			</p>
			<div>
				<div>
					<p><img src="http://www.oeck.com/assets/images/web/png/500/smartRouting.png"></p><p>
					<span>smartRouting</span>
					<br>
					Oeck takes away the need of connecting to a specific region to access streaming content. Get access to the latest shows from around the world without ever switching regions. Our revolutionary smartRouting unblocks some of the most popular services from around the globe. Enjoy fast, automated access to itv in the UK - Hulu in the US - iView in Australia and many more. Simply connect to the VPN location closest to you and we take care of the rest! 
					</p>
					
				</div>				
			</div>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/deviceProfiles.png"></p><p>
				<span>Device Profiles</span>
				<br>
				Device Profiles allow you to take your VPN functionality to the next level. This handy feature allows you to set preferences for streaming services and traffic filtration on a per-device level.
					By doing this you can quickly set up a childs device to block adult content whilst keeping your other devices untouched. It also allows you to set up devices with different streaming regions.
					For example, you can have Netflix USA on one device, Netflix UK on another and Netflix Germany on yet another, whilst all the while being connected to the VPN region closest to you!
				</p>
				
			</div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/deviceProfiles.png">
			</p>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/adBlocker.png">
			</p>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/adBlocker.png"></p><div>
				<p><span>Cerberus</span>
				<br>
				Get powerful device-level filtering to prevent dangerous content reaching your family and devices. Our unique online guardian Cerberus is the must-have feature for families and individuals. Choose which content to block and prevent threats before they occur. Simply create a profile for your device and select the Cerberus services required.
					</p><p>
					
					You can filter Ads, Malware and Phishing, Adult and Social Networking sites individually or combined!
				</p></div>
				
			</div>
		</div>
	</div>
</div>

<div>
	<div>
		<div>
			<div>
				<p><span>Security</span>
					<br>
					<span>Built deep into our network and culture.</span>
				</p>
				<div data-aos="fade-up"><p>
					We secure your privacy using industry-leading encryption standards, on servers that we own. Our zero hard drive system won’t store any of your data, ever! Quickly block dangerous sites and services at the DNS level to prevent ads, malware, phishing sites and more.
					</p>
					
				</div>
			</div>
		</div>
	</div>	
</div>

<div>
	<div>
		<div data-aos="fade-up">
			<p><span>AES-256</span>
				<br>
				<span>Encryption</span>
			</p>
			<p><span>4096-bit</span>
				<br>
				<span>Key Exchange</span>
			</p>
			<p><span>Zero</span>
				<br>
				<span>Hard Drives</span>
			</p>
			<p><span>Zero</span>
				<br>
				<span>Logging</span>
			</p>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/portForwarding.png">
			</p>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/portForwarding.png"></p><p>
				<span>Advanced Port Forwarding</span>
				<br>
				This is a simple but handy feature with a twist. We issue you ports and you enable ports you select on your device profile(s). Then you simply tell us which port you would like to forward to. No need to configure your client or software to suit us. As an added bonus, you get your very own custom domain name per port. Regardless of which VPN region you connect to, your port-forwarding will always work!
				</p>
				
			</div>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/customFilter.png"></p><p>
				<span>Custom DNS Filter</span>
				<br>
				Our built-in DNS filter allows you to decide what internet traffic you want hitting your device(s). Simply populate your filter list with websites that you want blocked and Oeck's VPN will follow those rules and block the traffic. Domain black lists can be set on a per-device level, which makes is perfect for parents who would like to restrict what their children can access. Best of all, it is completely unique to you.
				</p>
				
			</div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/customFilter.png">
			</p>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/customDNS.png">
			</p>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/customDNS.png"></p><p>
				<span>Secondary DNS</span>
				<br>
				A feature built for advanced users. Secondary DNS allows you to specify a DNS service to use that will bypass Oeck's DNS. To further simplify the feature, you can still allow Oeck to take control of some of the DNS queries and leave others up to your Secondary DNS.
				</p>
				
			</div>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/serverSelection.png"></p><p>
				<span>Automatic Server Selection</span>
				<br>
				When selecting a VPN region to connect to, our network runs a check of the available servers and resources within that region. It then calculates which server will be the best server for you to connect to. It takes into account the available system resources of each server and so it will always connect you to the best available server. No more server surfing ever again!
				</p>
				
			</div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/serverSelection.png">
			</p>
		</div>
	</div>
</div>




	




</div>
				
			</div>

			
		</div>

		

		
	</div>
</div></div>]]>
            </description>
            <link>http://www.oeck.com/features/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937073</guid>
            <pubDate>Thu, 29 Oct 2020 22:53:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Tesla's “Full Self-Driving” Beta Is Dangerous]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24937068">thread link</a>) | @edward
<br/>
October 29, 2020 | http://www.autonocast.com/blog/2020/10/29/205-why-teslas-full-self-driving-beta-is-dangerous | <a href="https://web.archive.org/web/*/http://www.autonocast.com/blog/2020/10/29/205-why-teslas-full-self-driving-beta-is-dangerous">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main" data-content-field="main-content" data-controller="FadeInContent">

        <div data-content-field="main-content" data-item-id="5f9adc49f143a331a74f81e2">
  
  <div>
    <p><time datetime="2020-10-29" pubdate="">
      <p><span>Oct </span><span>29</span>
      </p>
    </time></p><h2 data-content-field="title"><time datetime="2020-10-29" pubdate="">Oct 29 </time>#205: Why Tesla's "Full Self-Driving" Beta Is Dangerous</h2>

    
  </div>
  

  <div>
    <article id="article-5f9adc49f143a331a74f81e2">
      
      
      <div data-controller="BlogProgressBar">
        
        
        <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1603984847303" id="item-5f9adc49f143a331a74f81e2"><div><div><div data-block-type="2" id="block-9a8824872b6136df9550"><p>Tesla's deployment of a "limited beta" version of its "Full Self-Driving" software to public roads raises a number of important issues around how and why AV developers test safely on public roads. With Kirsten just getting back from vacation, Alex and Ed walk her through the most immediate concerns... plus, Alex shares what it's like to be trained as a professional AV safety driver.</p></div></div></div></div></div>

        

        

        <section>
          
        </section>
      </div>
      

    </article>
  </div>



<section>
  <!--
  --><a href="http://www.autonocast.com/blog/2020/10/23/204-nancy-sun-and-randol-aikin-of-ike">
    
    <span>
      
      <h2><time datetime="2020-10-23" pubdate="">Oct 23 </time>#204: Nancy Sun and Randol Aikin of Ike</h2>
    </span>
  </a>
</section>



  
    
        
        <section id="related" data-controller="RelatedPostImages">
          <article id="article-5ac569d0758d4611a989addb" data-item-id="5ac569d0758d4611a989addb" data-item-title="#67: Another Autopilot Crash">
                

                

              </article><article id="article-5c924e0df4e1fc4c55436848" data-item-id="5c924e0df4e1fc4c55436848" data-item-title="135: The Autonocast's SXSW Panel On Automated Driving Terminology">
                

                

              </article><article id="article-5c94f2f14192023ec16f89c2" data-item-id="5c94f2f14192023ec16f89c2" data-item-title="136: Lessons Learned In The Year Since The Death Of Elaine Herzberg">
                

                

              </article>
        </section>
      
  
</div>

      </div></div>]]>
            </description>
            <link>http://www.autonocast.com/blog/2020/10/29/205-why-teslas-full-self-driving-beta-is-dangerous</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937068</guid>
            <pubDate>Thu, 29 Oct 2020 22:52:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Debuggers Work: Getting and Setting x86 Registers, Part 2: Xsave]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937023">thread link</a>) | @fcambus
<br/>
October 29, 2020 | https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-2/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>In the previous part of this article, I have described the basic methods
of getting and setting the baseline registers of 32-bit and 64-bit x86
CPUs.  I have covered General Purpose Registers, baseline Floating-Point
Registers and Debug Registers along with their <code>ptrace(2)</code> interface.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/xsave.svg" alt="XSAVE"></p>

<p>In the second part, I would like to discuss the <code>XSAVE</code> family
of instructions.  I will describe the different variants of this
instruction as well as explain the differences between them and their limitations.
Afterwards, I will compare the <code>ptrace(2)</code> API used to access its data
on Linux, FreeBSD and NetBSD.  Other systems such as OpenBSD
or DragonFly BSD do not provide requests to retrieve or set extended
registers, so the comparison may help them design their own APIs.</p>

<p>As I’ve explained earlier, the discussed instructions are necessary
to implement <em>context switching</em> — the mechanism used by the Operating
System to run multiple threads and processes quasi-simultaneously
on the same processor.  In order to perform that, the kernel needs
to be able to save the values of all registers used by the program,
and restore them afterwards.  This information is also exposed
to debuggers in order to provide them with means to introspect and alter
the state of debugged programs.</p>

<p>The instructions described in the first part were sufficient to describe
the registers used up to the early generations of Intel Core CPUs.
However, as the next generations of processors introduced new
instruction sets, it eventually became necessary to introduce new
registers as well.  In 2011, the <abbr title="Advanced Vector Extensions">AVX</abbr>
extensions present first in Intel’s Sandy Brige and afterwards in AMD’s
Bulldozer microarchitecture doubled the sizes of earlier XMM registers,
creating 16 new YMM registers.</p>

<p>The new registers can be used to store twice as large vectors of data,
and perform operations on all of their elements simultaneously.  This
is particularly useful for heavy computations, for example in multimedia
or cryptographic applications.  Examples of programs that can explicitly
take advantage of AVX instructions to improve their performance include
the FFmpeg media decoding and encoding library or OpenCV image manipulation
library.</p>

<p>As applications start using the new registers, it becomes necessary
for the kernel to be able to save and restore them as part of context
switching — otherwise the programs would lose data!  The <code>XSAVE</code>
instruction set serves exactly that purpose.  It was introduced
in the newer versions of Intel Core microarchitecture (2008).  It is
used both in the 64-bit and 32-bit mode (although 32-bit programs can use
only a subset of the exposed registers).</p>

<p>The <code>XSAVE</code> instruction extends the format used by <code>FXSAVE</code> to
include additional register sets.  However, unlike the earlier saving
instructions, it is not strictly limited to a fixed data set.  Instead,
it makes it possible to introduce support for new CPU extensions without
the necessity of adding a next <code>XSAVE</code> variant or breaking
compatibility with existing software.  Furthermore, it accounts
for the possibility that some processors may choose not to implement
interim instruction sets.</p>

<h2 id="the-state-components">The State Components</h2>

<p><code>XSAVE</code> revolves around the concept of <em>State Components</em>.  A state
component represents a single subset of data that can be saved or
restored independently.  There are two special state components
corresponding to the original <code>FXSAVE</code> instruction: the x86 state
component, and the SSE state component.  Further instruction sets
introduce one or more components each.</p>

<p>In modern processors, there are two kinds of state components: user state
components and supervisor state components.  The former group represent
regular registers that are accessible to userspace programs, the latter
involves privileged registers that should not be exposed to regular
programs.</p>

<p>The individual state components are controlled via the <em>State Component
Bitmap</em>.  This bitmap is used by <code>XSAVE</code> to determine which
instruction sets to save, and by <code>XRSTOR</code> to determine which to
restore (or reset).  Enabling the respective bits causes additional
data to be saved to the memory, effectively requiring larger storage
area.</p>

<p>In order to make it possible to save a particular state component
or to use the respective registers in a program, the kernel needs
to enable its tracking in one of the control registers.  These control
registers are XCR0 for user components, and IA32_XSS for supervisor
components.  Both use the same bit numbers as the state component
bitmap.</p>

<table>
  <caption>State Component Bitmap</caption>
  <tbody><tr>
    <th>Bit</th>
    <th>Instr. set</th>
    <th>User <abbr title="State Component">SC</abbr> (XCR0)</th>
    <th>Supervisor <abbr title="State Component">SC</abbr> (IA32_XSS)</th>
    <th>Size (bytes)</th>
  </tr>
  <tr>
    <td>0</td>
    <td>x87</td>
    <td><abbr title="x87 FPU control registers and ST(0)..ST(7) registers">x87 state</abbr></td>
    <td>reserved</td>
    <td rowspan="2">512</td>
  </tr>
  <tr>
    <td>1</td>
    <td><abbr title="Streaming SIMD Extensions">SSE</abbr></td>
    <td><abbr title="XMM0..XMM15 and MXCSR registers">SSE state</abbr></td>
    <td>reserved</td>
  </tr>
  <tr>
    <td>2</td>
    <td><abbr title="Advanced Vector Extensions">AVX</abbr></td>
    <td><abbr title="Higher 128 bits of YMM0..YMM15 registers (lower 128 bits overlap with XMM registers)">YMM_Hi128</abbr></td>
    <td>reserved</td>
    <td>256</td>
  </tr>
  <tr>
    <td>3</td>
    <td rowspan="2"><abbr title="Memory Protection Extensions">MPX</abbr></td>
    <td><abbr title="Bound Registers BND0..BND3">BNDREGS</abbr></td>
    <td>reserved</td>
    <td>64</td>
  </tr>
  <tr>
    <td>4</td>
    <td><abbr title="Bound Control and Status Registers">BNDCSR</abbr></td>
    <td>reserved</td>
    <td>16</td>
  </tr>
  <tr>
    <td>5</td>
    <td rowspan="3"><abbr title="512-bit extensions to Advanced Vector Extensions">AVX-512</abbr></td>
    <td><abbr title="Opmask registers K0..K7">opmask</abbr></td>
    <td>reserved</td>
    <td>64</td>
  </tr>
  <tr>
    <td>6</td>
    <td><abbr title="Higher 256 bits of ZMM0..ZMM15 registers (lower 256 bits overlap with YMM registers)">ZMM_Hi256</abbr></td>
    <td>reserved</td>
    <td>512</td>
  </tr>
  <tr>
    <td>7</td>
    <td><abbr title="16 higher ZMM registers (ZMM16..ZMM31)">Hi16_ZMM</abbr></td>
    <td>reserved</td>
    <td>1024</td>
  </tr>
  <tr>
    <td>8</td>
    <td><abbr title="Processor Trace">PT</abbr></td>
    <td>reserved</td>
    <td><abbr title="Control registers of PT extension">PT</abbr></td>
    <td>72</td>
  </tr>
  <tr>
    <td>9</td>
    <td><abbr title="Protection Key Rights for User Pages">PKRU</abbr></td>
    <td><abbr title="Protection Key Rights for User Pages register">PKRU</abbr></td>
    <td>reserved</td>
    <td>4</td>
  </tr>
  <tr>
    <td>13</td>
    <td><abbr title="Hardware Duty Cycling">HDC</abbr></td>
    <td>reserved</td>
    <td><abbr title="Hardware Duty Cycling state">HDC</abbr></td>
    <td>8</td>
  </tr>
</tbody></table>

<h2 id="the-xsave-area-format">The XSAVE Area Format</h2>

<p>The data format used by the <code>XSAVE</code> instruction is called the <em>XSAVE
Area</em>.  The XSAVE Area consists of three parts: the 512-byte <em>legacy
region</em> that is the same as used by <code>FXSAVE</code> instruction, followed
by the 64-byte <em>XSAVE header</em> containing information about the data
present in the XSAVE Area, followed by the variably sized <em>extended
region</em> used to store additional state components.</p>

<p>Similarly to <code>FXSAVE</code>, all <code>XSAVE</code> instructions have their -64
counterparts (e.g. <code>XSAVE64</code>) that differ in the way FIP and FDP
registers are saved in the legacy region.  More information on this,
along with a table describing the legacy region in detail, can be found
in the previous part of the article,
<a href="https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-1/#fxsave-vs-fxsave64">FXSAVE vs FXSAVE64</a> section.</p>

<p>The XSAVE header currently contains two 64-bit fields whose values
correspond to the state-component bitmaps: XSTATE_BV and XCOMP_BV.
XSTATE_BV is written by <code>XSAVE</code> to indicate that a particular state
component has been written to the extended region, and read by
<code>XRSTOR</code> to determine whether the component is to be restored
from this region (bit set) or reset to the default state (bit clear).
XCOMP_BV is written by the compacting variants of <code>XSAVE</code> to indicate
that the compact form of XSAVE Area is being used and which components
are present in it, and read by <code>XRSTOR</code> to distinguish this format.</p>

<table>
  <caption>The XSAVE header layout</caption>
  <tbody><tr>
    <th>64</th>
    <th>0</th>
    <th>bits</th>
  </tr>
  <tr>
    <td>XCOMP_BV</td>
    <td>XSTATE_BV</td>
    <td>0</td>
  </tr>
  <tr>
    <td rowspan="3" colspan="2">reserved</td>
    <td>128</td>
  </tr>
  <tr>
    <td>256</td>
  </tr>
  <tr>
    <td>384</td>
  </tr>
</tbody></table>

<p>The extended region can be written either in the standard or compact
format.  In the standard format, each state component is placed
at a fixed offset defined by the processor (and available via
<code>CPUID</code>).  If some of the state components are skipped, the relevant
portion of XSAVE Area is gapped to preserve offsets of the successive
components.  In the compact format, the skipped components do not take
up space, and the remaining components are shifted to minimize space
usage.  Therefore, the offsets depend on the components actually being
written, and need to be calculated by software for every invocation.</p>

<table>
  <caption>Example XSAVE Area format</caption>
  <tbody><tr>
    <th>Standard format</th>
    <th>Compact format</th>
  </tr>
  <tr>
    <td>Legacy area<br><small>(512 bytes)</small></td>
    <td>Legacy area<br><small>(512 bytes)</small></td>
  </tr>
  <tr>
    <td>XSAVE header<br><small>(64 bytes)</small></td>
    <td>XSAVE header<br><small>(64 bytes)</small></td>
  </tr>
  <tr>
    <td><abbr title="Higher 128 bits of YMM0..YMM15 registers (lower 128 bits overlap with XMM registers)">YMM_Hi128</abbr><br><small>(256 bytes)</small></td>
    <td><abbr title="Higher 128 bits of YMM0..YMM15 registers (lower 128 bits overlap with XMM registers)">YMM_Hi128</abbr><br><small>(256 bytes)</small></td>
  </tr>
  <tr>
    <td rowspan="2">unused (<abbr title="Memory Protection Extensions">MPX</abbr> +
    <abbr title="Advanced Vector Extensions">AVX</abbr>-512)<br><small>(1680 bytes)</small></td>
    <td><abbr title="Processor Trace extensions">PT</abbr><br><small>(72 bytes)</small></td>
  </tr>
  <tr>
    <td rowspan="2">(not allocated)</td>
  </tr>
  <tr>
    <td><abbr title="Processor Trace extensions">PT</abbr><br><small>(72 bytes)</small></td>
  </tr>
</tbody></table>

<h2 id="invoking-xsave">Invoking XSAVE</h2>

<p>There are a few preliminary steps that need to be done before invoking
any of the <code>XSAVE</code> family of instructions.  I will shortly list them
now.</p>

<p>Firstly, the support for the instruction needs to be verified
via <code>CPUID</code>.  Strictly speaking, the same is also true for <code>FXSAVE</code>.</p>

<p>Secondly, the state tracking needs to be enabled.  This means setting
appropriate state component bits in XCR0 for user state components,
and in IA32_XSS for supervisor state components.  The appropriate XSAVE
bit also needs to be set in the Control Register CR4.  All of this
is done by the kernel.</p>

<p>Thirdly, a buffer large enough for the XSAVE Area needs to be obtained.
The program should use <code>CPUID</code> instruction to obtain the needed
size.  The buffer needs to be aligned to 64 bytes.  Usually, it may
be convenient to zero the buffer first, to avoid having to be careful
e.g. about <code>XSAVE</code> leaving unused XSTATE_BV bytes unmodified.</p>

<p>Finally, the requested state component bitmap needs to be put into
the register pair EDX:EAX (the higher 32 bits into EDX, lower into EAX
— this is a common i386 convention for 64-bit integers).  Once this
is done, <code>XSAVE</code> can be invoked.</p>

<p>Afterwards, another series of <code>CPUID</code> calls are necessary to obtain
offsets or sizes and alignment requirements to process the contents
of the XSAVE Area.</p>

<p>The listing below presents a simple program that calls <code>XSAVE</code> three
times with different register sets modified.</p>

<pre><code>#include &lt;assert.h&gt;
#include &lt;inttypes.h&gt;
#include &lt;stdint.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;

struct xsave {
    uint8_t legacy_area[512];
    union {
        struct {
            uint64_t xstate_bv;
            uint64_t xcomp_bv;
        };
        uint8_t header_area[64];
    };
    uint8_t extended_area[];
};

int main() {
    uint32_t buf_size = 0;
    uint32_t avx_offset = 0;
    uint8_t avx_bytes[32];
    struct xsave* buf[3];
    int i;
    for (i = 0; i &lt; sizeof(avx_bytes); ++i)
        avx_bytes[i] = i;

    __asm__ __volatile__ (
        /* check CPUID support for XSAVE and AVX */
        "mov $0x01, %%eax\n\t"
        "cpuid\n\t"
        "mov $0x04000000, %%eax\n\t"  /* bit 26 - XSAVE */
        "and %%ecx, %%eax\n\t"
        "jz .cpuid_end\n\t"
        "mov $0x10000000, %%eax\n\t"  /* bit 28 - AVX */
        "and %%ecx, %%eax\n\t"
        "jz .no_avx\n\t"
        /* get AVX offset */
        "mov $0x0d, %%eax\n\t"
        "mov $0x02, %%ecx\n\t"
        "cpuid\n\t"
        "mov %%ebx, %1\n\t"
        "\n"
        ".no_avx:\n\t"
        /* get XSAVE area size for current XCR0 */
        "mov $0x0d, %%eax\n\t"
        "xor %%ecx, %%ecx\n\t"
        "cpuid\n\t"
        "mov %%ebx, %0\n\t"
        "\n"
        ".cpuid_end:\n\t"
        : "=m"(buf_size), "=m"(avx_offset)
        :
        : "%eax", "%ebx", "%ecx", "%edx"
    );

    if (buf_size == 0) {
        printf("no xsave support\n");
        return 1;
    }

    printf("has avx: %s\n", …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-2/">https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-2/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937023</guid>
            <pubDate>Thu, 29 Oct 2020 22:46:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Sun is more active now than over the last 8000 years (2004)]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24937001">thread link</a>) | @firebaze
<br/>
October 29, 2020 | https://www.mpg.de/research/sun-activity-high | <a href="https://web.archive.org/web/*/https://www.mpg.de/research/sun-activity-high">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  
  <p>An international team of scientists has reconstructed the Sun's activity over the last 11 millennia and forecasts decreased activity within a few decades</p>
  

  

  <p>The activity of the Sun over the last 11,400 years, i.e., back to the end of the last ice age on Earth, has now for the first time been reconstructed quantitatively by an international group of researchers led by Sami K. Solanki from the Max Planck Institute for Solar System Research (Katlenburg-Lindau, Germany). The scientists have analyzed the radioactive isotopes in trees that lived thousands of years ago. As the scientists from Germany, Finland, and Switzerland report in the current issue of the science journal "Nature" from October 28, one needs to go back over 8,000 years in order to find a time when the Sun was, on average, as active as in the last 60 years. Based on a statistical study of earlier periods of increased solar activity, the researchers predict that the current level of high solar activity will probably continue only for a few more decades.</p>
  
  
<figure data-description="A large sunspot observed on the Sun in early September 2004. The field of view encompasses around 45,000 by 30,000 km of the Sun’s surface - the entire earth would fit into the area several times over. Sunspots appear dark because the strong magnetic field in the them suppresses the transport of energy through gas flow. In the central dark area of the sunspot (umbra) the magnetic field is perpendicular to the surface, whereas in the lighter coloured periphery (penumbra) the magnetic field is largely horizontal to the surface. The image was captured by Vasily Zakharov with a one-meter solar telescope on the island of La Palma. The telescope is operated by the Institute for Solar Physics of the Royal Swedish Academy of Sciences." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          A large sunspot observed on the Sun in early September 2004. The field of view encompasses around 45,000 by 30,000 km of the Sun’s surface - the entire earth would fit into the area several times over. Sunspots appear dark because the strong magnetic field in the them suppresses the transport of energy through gas flow. In the central dark area of the sunspot (umbra) the magnetic field is perpendicular to the surface, whereas in the lighter coloured periphery (penumbra) the magnetic field is largely horizontal to the surface. The image was captured by Vasily Zakharov with a one-meter solar telescope on the island of La Palma. The telescope is operated by the Institute for Solar Physics of the Royal Swedish Academy of Sciences.
        </p>
        <p>
          © Max Planck Institute for Solar System Research
        </p>
    </figcaption>
</figure>


<p>The research team had already in 2003 found evidence that the Sun is more active now than in the previous 1000 years. A new data set has allowed them to extend the length of the studied period of time to 11,400 years, so that the whole length of time since the last ice age could be covered. This study showed that the current episode of high solar activity since about the year 1940 is unique within the last 8000 years. This means that the Sun has produced more sunspots, but also more flares and eruptions, which eject huge gas clouds into space, than in the past. The origin and energy source of all these phenomena is the Sun's magnetic field.</p>

<p>Since the invention of the telescope in the early 17th century, astronomers have observed sunspots on a regular basis. These are regions on the solar surface where the energy supply from the solar interior is reduced owing to the strong magnetic fields that they harbour. As a consequence, sunspots are cooler by about 1,500 degrees and appear dark in comparison to their non-magnetic surroundings at an average temperature of 5,800 degrees. The number of sunspots visible on the solar surface varies with the 11-year activity cycle of the Sun, which is modulated by long-term variations. For example, there were almost no sunspots seen during the second half of the 17th century.</p>

<p>For many studies concerning the origin of solar activity and its potential effect on long-term variations of Earth's climate, the interval of time since the year 1610, for which systematic records of sunspots exist, is much too short. For earlier times the level of solar activity must be derived from other data. Such information is stored on Earth in the form of "cosmogenic" isotopes. These are radioactive nuclei resulting from collisions of energetic cosmic ray particles with air molecules in the upper atmosphere. One of these isotopes is C-14, radioactive carbon with a half life of 5730 years, which is well known from the C-14 method to determine the age of wooden objects. The amount of C-14 produced depends strongly on the number of cosmic ray particles that reach the atmosphere. This number, in turn, varies with the level of solar activity: during times of high activity, the solar magnetic field provides an effective shield against these energetic particles, while the intensity of the cosmic rays increases when the activity is low. Therefore, higher solar activity leads to a lower production rate of C-14, and vice versa.</p>

<p>By mixing processes in the atmosphere, the C-14 produced by cosmic rays reaches the biosphere and part of it is incorporated in the biomass of trees. Some tree trunks can be recovered from below the ground thousands of years after their death and the content of C-14 stored in their tree rings can be measured. The year in which the C-14 had been incorporated is determined by comparing different trees with overlapping life spans. In this way, one can measure the production rate of C-14 backward in time over 11,400 years, right to the end of the last ice age. The research group have used these data to calculate the variation of the number of sunspots over these 11,400 years. The number of sunspots is a good measure also for the strength of the various other phenomena of solar activity.</p>

<p>The method of reconstructing solar activity in the past, which describes each link in the complex chain connecting the isotope abundances with the sunspot number with consistent quantitative physical models, has been tested and gauged by comparing the historical record of directly measured sunspot numbers with earlier shorter reconstructions on the basis of the cosmogenic isotope Be-10 in the polar ice shields. The models concern the production of the isotopes by cosmic rays, the modulation of the cosmic ray flux by the interplanetary magnetic field (the open solar magnetic flux), as well as the relation between the large-scale solar magnetic field and the sunspot number. In this way, for the first time a quantitatively reliable reconstruction of the sunspot number for the whole time since the end of the last ice age could be obtained.</p>
<figure data-description="Top: Reconstructed sunspot activity (10 year average) for the last 11,400 years based on C-14 data (blue curve) and the directly observed historical sunspot data since 1610 (red curve). The reliable C-14 data ends around the year 1900 so that the sharp increase in sunspot activity in the 20th century does not appear in the graph. The reconstruction shows clearly that a comparable period of high sunspot activity previously existed over 8000 years ago. Below: An enlarged section of the upper graph (hatched area) with several episodes of higher sun activity; comparable to the 20th century." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Top: Reconstructed sunspot activity (10 year average) for the last 11,400 years based on C-14 data (blue curve) and the directly observed historical sunspot data since 1610 (red curve). The reliable C-14 data ends around the year 1900 so that the sharp increase in sunspot activity in the 20th century does not appear in the graph. The reconstruction shows clearly that a comparable period of high sunspot activity previously existed over 8000 years ago. Below: An enlarged section of the upper graph (hatched area) with several episodes of higher sun activity; comparable to the 20th century.
        </p>
        <p>
          © Max Planck Institute for Solar System Research
        </p>
    </figcaption>
</figure>


<p>Because the brightness of the Sun varies slightly with solar activity, the new reconstruction indicates also that the Sun shines somewhat brighter today than in the 8,000 years before. Whether this effect could have provided a significant contribution to the global warming of the Earth during the last century is an open question. The researchers around Sami K. Solanki stress the fact that solar activity has remained on a roughly constant (high) level since about 1980 - apart from the variations due to the 11-year cycle - while the global temperature has experienced a strong further increase during that time. On the other hand, the rather similar trends of solar activity and terrestrial temperature during the last centuries (with the notable exception of the last 20 years) indicates that the relation between the Sun and climate remains a challenge for further research.</p>
  
</div></div>]]>
            </description>
            <link>https://www.mpg.de/research/sun-activity-high</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937001</guid>
            <pubDate>Thu, 29 Oct 2020 22:44:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Run your own free Stock Checker]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24936750">thread link</a>) | @gunnr15
<br/>
October 29, 2020 | https://jaydlawrence.dev/check-if-items-are-in-stock-online-for-free/ | <a href="https://web.archive.org/web/*/https://jaydlawrence.dev/check-if-items-are-in-stock-online-for-free/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <h2 id="the-problem">The Problem</h2><p>While looking for parts for a PC online during the Nvidia RTX 3080 drought of late 2020, I really wanted a way to automate checking various websites to see if there were any RTX 3080s in stock / available to purchase.</p><h2 id="out-of-the-box-solutions">Out of the box solutions</h2><p>There are some solutions that exist online that use browser plugins or will do the checking for you on their servers.</p><p>If they have a free solution, it is usually very limited, like <a href="https://distill.io/">distill.io</a> which allows only 30 notifications emails each month. I tried using them but I burnt through the 30 emails pretty quickly with 30 false positives in a couple of days.</p><h2 id="my-solution">My Solution</h2><p>I decided to build my own solution using <a href="https://nodejs.org/">NodeJs</a> and <a href="https://www.selenium.dev/documentation/en/webdriver/">Selenium webdriver</a>.</p><p>Selenium webdriver uses your local browser to visit the various sites and has tools to pull data from the pages it visits.</p><p>With that in mind, I created a package to visit predefined sites, retrieve text from a specified element and compare it to a specified value.</p><p>When there is a difference, it can notify you via <a href="https://pushover.net/">Pushover</a> or <a href="https://mail.google.com/">Gmail</a>, or both.</p><p>My package is available on <a href="https://github.com/jaydlawrence/stock-checker/">GitHub</a>.</p><figure><a href="https://github.com/jaydlawrence/stock-checker"><div><p>jaydlawrence/stock-checker</p><p>Contribute to jaydlawrence/stock-checker development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>GitHub</span></p></div><p><img src="https://avatars3.githubusercontent.com/u/1242060?s=400&amp;v=4"></p></a></figure><h2 id="running-it-yourself">Running it yourself</h2><p>If you would like to use the package yourself, the instructions are available in the README.md of the project.</p><p>If you are not familiar with GitHub or NodeJs apps, here is a quick summary of the extra steps:</p><h3 id="download-the-project-from-github-">Download the project from GitHub.</h3><p>It should be available as a zip archive, download that and extract it.</p><figure><img src="https://jaydlawrence.dev/content/images/2020/10/Screen-Shot-2020-10-22-at-4.44.14-PM.png"></figure><h3 id="install-nodejs">Install NodeJs</h3><p>Installing NodeJs will differ depending on your operating system.</p><p>Check their website for more details. </p><p><a href="https://nodejs.org/en/download/">https://nodejs.org/en/download/</a></p><h3 id="use-npm-to-install-the-dependencies">Use NPM to install the dependencies</h3><p>When node is installed you will have access to the package manager that comes with it, called NPM.</p><p>Use whichever shell or command prompt you have access to, to navigate to the project directory and then install with:</p><!--kg-card-begin: markdown--><pre><code>npm install
</code></pre>
<!--kg-card-end: markdown--><h3 id="follow-the-readme-md-instructions">Follow the README.md instructions</h3><p>From here, you should be able to follow the instructions in the project documentation.</p><h3 id="getting-the-xpaths-that-you-need">Getting the XPaths that you need</h3><p>In Google Chrome, there is a built in tool to get the XPath from a particular element.</p><p>Start by right-clicking on the element you want to monitor and select, inspect.</p><figure><img src="https://jaydlawrence.dev/content/images/2020/10/Screen-Shot-2020-10-22-at-4.57.20-PM.png"><figcaption>Inspect Element with Chrome</figcaption></figure><p>Then it reveals the HTML code for the element. Right click on this element and select copy and then Copy XPath.</p><figure><img src="https://jaydlawrence.dev/content/images/2020/10/Screen-Shot-2020-10-22-at-4.58.16-PM.png"></figure><p>You can then paste this in the config.</p><!--kg-card-begin: markdown--><pre><code>  {
    "url": "https://www.newegg.ca/asus-geforce-rtx-3080-rog-strix-rtx3080-o10g-gaming/p/N82E16814126457",
    "xPath": "//*[@id=\"app\"]/div[2]/div[1]/div/div/div[1]/div[1]/div[1]",
    "expected": "OUT OF STOCK",
    "description": "New Egg - ASUS RTX3080 Strix"
  },
</code></pre>
<!--kg-card-end: markdown--><p>You will have to escape any quotation marks in the XPath.</p><!--kg-card-begin: markdown--><p>So if there is a <code>"</code> in the middle of the XPath, replace it with <code>\"</code>.</p>
<!--kg-card-end: markdown--><p>If you want to double check the XPath and the text value that it gets, you can use the Chrome extension called <a href="https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl">XPath Helper</a>.</p><figure><a href="https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl"><div><p>XPath Helper</p><p>Extract, edit, and evaluate XPath queries with ease.</p><p><img src="https://ssl.gstatic.com/chrome/webstore/images/icon_144px.png"><span>‏سوق Chrome الإلكتروني</span></p></div><p><img src="https://lh3.googleusercontent.com/iFXsBT4tpTPho9MSuLb1Rr_83KjP5bLOQLVpIyCPG3UoTXZIocYKw-82cQBIenRz5u8sJeIekg=w128-h128-e365-rj-sc0x00ffffff"></p></a></figure><p>If you open the extension on your target page and paste your XPath in and it will show what text it finds.</p><figure><img src="https://jaydlawrence.dev/content/images/2020/10/image.png"></figure><h2 id="tips-for-setting-the-cron">Tips for setting the Cron</h2><p>Wikipedia has a good overview of what the Unix Cron is and how it works.</p><p><a href="https://en.wikipedia.org/wiki/Cron">https://en.wikipedia.org/wiki/Cron</a></p><p>When setting the cron to run your search, keep in mind that some websites will block your computer if you hit them too often.</p><p>I have found that setting it to 5 minutes works well for me.</p><!--kg-card-begin: markdown--><pre><code>*/5 * * * * /path_to_script/stock-checker/run.sh
</code></pre>
<!--kg-card-end: markdown-->
                </div>
            </section></div>]]>
            </description>
            <link>https://jaydlawrence.dev/check-if-items-are-in-stock-online-for-free/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24936750</guid>
            <pubDate>Thu, 29 Oct 2020 22:15:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DARPA’s new sub hunting weapon is shrimp]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24936736">thread link</a>) | @Gaishan
<br/>
October 29, 2020 | https://www.sandboxx.us/blog/darpas-newest-sub-hunting-weapon-is-shrimp/ | <a href="https://web.archive.org/web/*/https://www.sandboxx.us/blog/darpas-newest-sub-hunting-weapon-is-shrimp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>DARPA’s effort to track undersea life’s behavior as a means to detect enemy submarines has just entered its second phase. In the first phase, DARPA’s Persistent Aquatic Living Sensors (PALS) program sought to prove that sea life would respond to the presence of a submarine in a measurable way. With that seemingly confirmed, the second stage of the program will focus on developing sensors that can identify that behavior and relay a warning back to manned locations aboard a ship or onshore.</p><p>While the science is complex, the premise behind the PALS program is fairly simple. Undersea life tends to behave in a certain way when it senses the presence of a large and foreign object like a submarine. By broadly tracking the behavior of sea life, PALS aims to measure and interpret that behavior to make educated guesses about what must be causing it. In other words, by constantly tracking the behavior of nearby wildlife, PALS sensors can notice a significant change, compare it to a library of known behaviors, and predict a cause… like an enemy submarine, even if a submarine was stealthy enough to otherwise evade detection.</p><div><figure><picture>
<source type="image/webp" data-lazy-srcset="https://www.sandboxx.us/wp-content/uploads/2020/10/PALSConceptFinal.jpg.webp 800w, https://www.sandboxx.us/wp-content/uploads/2020/10/PALSConceptFinal-300x134.jpg.webp 300w, https://www.sandboxx.us/wp-content/uploads/2020/10/PALSConceptFinal-768x342.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 800px) 100vw, 800px">
<img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" alt="darpa" data-lazy-srcset="https://www.sandboxx.us/wp-content/uploads/2020/10/PALSConceptFinal.jpg 800w, https://www.sandboxx.us/wp-content/uploads/2020/10/PALSConceptFinal-300x134.jpg 300w, https://www.sandboxx.us/wp-content/uploads/2020/10/PALSConceptFinal-768x342.jpg 768w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://www.sandboxx.us/wp-content/uploads/2020/10/PALSConceptFinal.jpg">
</picture>
<figcaption>Artist’s rendering of DARPA’s PALS Program. (DARPA)</figcaption></figure></div><p>With enough data about how animals react to the presence of an enemy vessel as compared to how animals react to the presence of a large predator or more common undersea threat, PALS could serve as an early warning system when enemy subs approach.</p><blockquote><p>“Because marine organisms are ubiquitous in their environments, self-replicating, and largely self-sustaining, sensing systems that use marine organisms as their foundation would be discreet, cost-effective, and provide persistent undersea surveillance with a minimal logistical footprint.”</p><cite>–<em>Dr. Lori Adornato, PALS program manager</em></cite></blockquote><p>Encroaching enemy submarines are extremely difficult to detect, even with modern surveillance technology. The ocean is vast, and even America’s massive Navy can’t hope to police all of it. The U.S. Navy is currently developing crewless surface ships in a variety of forms, including the ACTUV Sea Hunter that will eventually be tasked with hunting submarines in its own right — but even with a fleet of drone ships, the Navy will still need highly effective underwater sensors to catch the attention of these vessels. DARPA’s PALS program would theoretically leverage existing wildlife to that end.</p><div><figure><picture>
<source type="image/webp" data-lazy-srcset="https://www.sandboxx.us/wp-content/uploads/2020/10/25702146834_c23aa793ab_b-1.jpg.webp 1024w, https://www.sandboxx.us/wp-content/uploads/2020/10/25702146834_c23aa793ab_b-1-300x200.jpg.webp 300w, https://www.sandboxx.us/wp-content/uploads/2020/10/25702146834_c23aa793ab_b-1-768x512.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" alt="darpa" data-lazy-srcset="https://www.sandboxx.us/wp-content/uploads/2020/10/25702146834_c23aa793ab_b-1.jpg 1024w, https://www.sandboxx.us/wp-content/uploads/2020/10/25702146834_c23aa793ab_b-1-300x200.jpg 300w, https://www.sandboxx.us/wp-content/uploads/2020/10/25702146834_c23aa793ab_b-1-768x512.jpg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://www.sandboxx.us/wp-content/uploads/2020/10/25702146834_c23aa793ab_b-1.jpg">
</picture>
<figcaption>The Sea Hunter program is another sub-hunting initiative originally championed by DARPA. (DoD image)</figcaption></figure></div><blockquote><p>“Raytheon BBN is working with snapping shrimp for use in a passive bi-static sonar system; Northrop Grumman Systems Corporation is also working with snapping shrimp, using the snap as the input pulse for a 3D acoustic imaging system; and a third team from Florida Atlantic University uses Goliath Grouper as their biological sensor.”</p><p>“Naval Undersea Warfare Center – Newport Division is a government partner on the program, using an ecosystem approach to determine if an unmanned underwater vehicle has passed by a reef.”</p><cite>-DARPA Press Release</cite></blockquote><p>The need for a reliable means of submarine detection has grown in importance in recent years, as Russia diverts military funding toward its submersible fleet, and China continues production of subs like the Jin-class Type 094. With China’s rapidly growing Navy posing a threat to American interests in the Pacific and Russia’s sub fleet operating in the Atlantic, the United States has a greater need for a reliable means of submarine detection than it has at any point since the Cold War.</p><p>The Pentagon <a href="https://www.sandboxx.us/blog/dod-map-shows-russian-and-chinese-subs-are-too-close-for-comfort/">recently released</a> a map showing the travel paths of Russian and Chinese naval vessels, alongside important undersea cables, as a part of its 2021 National Defense Authorization Act request, commonly referred to as the DoD’s budget. The map clearly shows the heavy traffic in both The Atlantic and Pacific oceans, with Russian subs encroaching on America’s eastern seaboard and Chinese submarines creeping up in the west.</p><figure><picture>
<source type="image/webp" data-lazy-srcset="https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1-1128x750.jpg.webp 1128w, https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1-300x199.jpg.webp 300w, https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1-768x511.jpg.webp 768w, https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1.jpg.webp 1536w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1128px) 100vw, 1128px">
<img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1-1128x750.jpg 1128w, https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1-300x199.jpg 300w, https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1-768x511.jpg 768w, https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1.jpg 1536w" data-lazy-sizes="(max-width: 1128px) 100vw, 1128px" data-lazy-src="https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1-1128x750.jpg">
</picture>
<figcaption>(Courtesy of the Dept. of Defense)</figcaption></figure><blockquote><p>“Our new reality is that when our sailors toss the lines over and set sail, they can expect to be operating in a contested space once they leave Norfolk,”&nbsp;U.S. Navy Vice Admiral Andrew “Woody” Lewis said earlier this year.</p><p>“Our ships can no longer expect to operate in a safe haven on the East Coast or merely cross the Atlantic unhindered to operate in another location.</p></blockquote><p>The threat posed by Russia’s submarines, in particular, seems to have prompted the U.S. Navy to re-establish its Second Fleet tasked with Atlantic defense. In March of 2018, Russian officials announced that they had successfully sent a fleet of nuclear attack submarines to America’s Eastern Seaboard. According to their claims, several submarines took up positions 12 miles off the coast of American military installations, remained there undetected, and then sailed back home.</p><blockquote><p>“This mission has been accomplished, the submarines showed up in the set location in the ocean and returned to base,” the commander of the submarine squadron, Sergey Starshinov, was&nbsp;<a href="https://www.rt.com/news/421471-russian-nuclear-subs-us-drills/">quoted</a>&nbsp;as saying at the time.</p></blockquote><p>The United States did not formally respond to these claims, and with good reason. If the United States were to refute Russia’s submarine-based boasting, Russia could easily claim that the U.S.’ submarine defenses are simply too ineffective to spot them as they approach. If the U.S. instead announced that they were aware of the submarines and tracked them throughout, it would prompt the Russian Navy to find ways to circumvent the form of detection America did leverage. Instead, in what seemed to be a direct response to Russia’s claims, the U.S. Navy brought the Second Fleet out of proverbial mothballs and tasked it with policing the very body of water Russia claimed to dominate with its nuclear submarines.</p><p><em>Combined feature images courtesy of WikiMedia Commons</em></p></div><div><div><div> <picture>
<source type="image/webp" data-lazy-srcset="https://www.sandboxx.us/wp-content/uploads/2020/03/86346554_10157610801926084_4479145792984055808_n.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E">
<img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" alt="" data-lazy-src="https://www.sandboxx.us/wp-content/uploads/2020/03/86346554_10157610801926084_4479145792984055808_n.jpg">
</picture>
</div><div><h3>Alex Hollings</h3><p>Alex Hollings is a writer, dad, and Marine veteran who specializes in foreign policy and defense technology analysis. He holds a master’s degree in Communications from Southern New Hampshire University, as well as a bachelor’s degree in Corporate and Organizational Communications from Framingham State University.</p></div></div></div></div>]]>
            </description>
            <link>https://www.sandboxx.us/blog/darpas-newest-sub-hunting-weapon-is-shrimp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24936736</guid>
            <pubDate>Thu, 29 Oct 2020 22:14:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Flutter Multi-Platform Ecosystem with Chris Sells]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24936522">thread link</a>) | @daliso
<br/>
October 29, 2020 | https://www.dartdevshow.com/episodes/the-flutter-multi-platform-ecosystem-with-chris-sells | <a href="https://web.archive.org/web/*/https://www.dartdevshow.com/episodes/the-flutter-multi-platform-ecosystem-with-chris-sells">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.dartdevshow.com/episodes/the-flutter-multi-platform-ecosystem-with-chris-sells</link>
            <guid isPermaLink="false">hacker-news-small-sites-24936522</guid>
            <pubDate>Thu, 29 Oct 2020 21:53:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Use Status Reports Effectively in Remote Work Environment?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24936129">thread link</a>) | @markshepard
<br/>
October 29, 2020 | https://www.airsend.io/blog/index.php/2020/09/28/how-to-use-status-reports-in-remote-work-communication/ | <a href="https://web.archive.org/web/*/https://www.airsend.io/blog/index.php/2020/09/28/how-to-use-status-reports-in-remote-work-communication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2512">
	

	




	<div>
		
<div><figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/09/wechat-1-1024x576.png" alt="" width="732" height="411" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/09/wechat-1-1024x576.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/09/wechat-1-300x169.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/09/wechat-1-768x432.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/09/wechat-1-1536x864.png 1536w, https://www.airsend.io/blog/wp-content/uploads/2020/09/wechat-1-2048x1152.png 2048w" sizes="(max-width: 732px) 100vw, 732px"></figure></div>



<p>In our <a href="https://www.airsend.io/blog/index.php/2020/09/07/a-complete-guide-to-digital-communication-for-remote-teams-part-1/">guide on remote work communication</a>, we mentioned the importance of status reports to keep everyone on the same page.  Here is an expansion of that. In this blog post, we’re going to talk about the importance of status reports in remote work, how to implement status reports, some tips on making status reports work for you, and how we do our status reports using AirSend.</p>



<h2>Why Status Reports Are Important</h2>



<p>In short, status reports keeps everyone in sync with each other and help keep you on track, both of which are increasingly important in a remote work setting.</p>



<p>As a team crosses a certain number of people it becomes harder to keep all people, groups, and teams in sync with each other. People working in one area or function  might not be aware that it might impact or affect other areas inadvertently or there are other unknown ramifications of the work they are doing.</p>



<p>Distributing that information across everyone becomes challenging. Using Team meetings etc. to communicate statuses become ineffective as it either takes too long or wastes time. </p>



<p>Status reports increase the visibility of the work you are doing and raise the overall profile and awareness of initiatives and new projects across the whole team. Also, status reports are a work journal for yourself and help you focus on what needs to be done every week and brings clarity and purpose.</p>



<h2>How to Implement Status Reports</h2>



<p>Like most things, consistency is key in successful implementation of status reports. Here are some guidelines to follow:</p>



<ul><li>Have everyone on the team add their weekly status report to a set location. We use an AirSend Channel to collect ours.</li><li>Make sure everyone sends status reports weekly (ideally at end of the day on Friday) to wrap up your week.</li><li>For easy filtering, everyone should use the same subject keywords. For example, ‘<strong>status report w/e 7/14/2017</strong>‘ (‘status report’ is the keyword, w/e just says week ending and the week).</li><li>Make sure everyone knows what to put in their reports, which brings us to:</li></ul>



<h2>What Status Reports Should Communicate</h2>



<p>Status reports should communicate a few essential things:</p>



<ul><li>What you got done last week (Be as specific as you can, details are ok)</li><li>What problems or challenges you overcame, and what problems you still face and are working on</li><li>What you plan to accomplish or work on next week</li><li>Any other information worth sharing (upcoming time off, achievements outside work, etc)</li></ul>



<h2>Additional Status Report Pointers</h2>



<ul><li>Everyone needs to send out status reports</li><li>Status reports are meant to communicate first, so make it readable and useful</li><li>Sometimes, the simplest way is to keep adding notes on work done in the week and send it out at the end of the week. It becomes hard to remember all the things that were done at the end of the week.</li><li>Sometimes, for certain work, it might be hard to write reports (for example for tech support which deals with 100s of emails in a week). In those cases, pick a sample of the most important or interesting problems that you worked on during the week.&nbsp;</li><li>Make the next week section a realistic plan of action for yourself. Please don’t dump your entire sprint action list there unless you really plan to complete it by then.</li><li>Status reports are the #1 way to communicate the work you are doing and the progress you are making, so make sure to showcase the achievements and the tough problems you tracked and solved. This will include customer support sessions for specific problems and what happened there.</li><li>If you learned something new this week please share that.</li><li>If you are undergoing training, please share your training guide and the progress you made there.</li><li>If you took courses outside, please share that.</li><li>A status report is a communication and a showcase about you to the entire team, so take some pride in how it is crafted and how it is sent.&nbsp;</li></ul>



<h2>Status Reports in AirSend</h2>



<p>As mentioned before, we use a Weekly Status Reports Channel in AirSend to share our weekly status reports. This works well for us because it’s easy to format messages using Markdown and share images and other files in AirSend. Below are some actual screenshots of our status report Channel.</p>



<h3>Messages and Attachments</h3>



<figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Messages-and-Images-01-1-1024x573.png" alt="" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Messages-and-Images-01-1-1024x573.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Messages-and-Images-01-1-300x168.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Messages-and-Images-01-1-768x430.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Messages-and-Images-01-1-1536x860.png 1536w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Messages-and-Images-01-1-2048x1146.png 2048w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></figure>



<h3>Important Information in the Wiki</h3>



<figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Wiki-01-1-1024x575.png" alt="" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Wiki-01-1-1024x575.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Wiki-01-1-300x169.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Wiki-01-1-768x431.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Wiki-01-1-1536x863.png 1536w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Wiki-01-1-2048x1150.png 2048w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></figure>



<h3>Task Tracking in Actions</h3>



<figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Actions-01-1-1024x575.png" alt="" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Actions-01-1-1024x575.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Actions-01-1-300x168.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Actions-01-1-768x431.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Actions-01-1-1536x863.png 1536w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Actions-01-1-2048x1150.png 2048w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></figure>



<p>We hope this was useful to you! </p>



<p>Until next time,</p>



<p>The AirSend Team</p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://www.airsend.io/blog/index.php/2020/09/28/how-to-use-status-reports-in-remote-work-communication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24936129</guid>
            <pubDate>Thu, 29 Oct 2020 21:26:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Efficient GPU Path Rendering Using Scanline Rasterization]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24935685">thread link</a>) | @vg_head
<br/>
October 29, 2020 | http://kunzhou.net/zjugaps/pathrendering/ | <a href="https://web.archive.org/web/*/http://kunzhou.net/zjugaps/pathrendering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<h2>Abstract</h2>
<p>
We introduce a novel GPU path rendering method based on scanline rasterization, which is highly work-efficient but traditionally considered as GPU hostile. Our method is parallelized over boundary fragments, i.e., pixels directly intersecting the path boundary. Non-boundary pixels are processed in bulk as horizontal spans like in CPU scanline rasterizers, which saves a significant amount of winding number computation workload. The distinction also allows the majority of our algorithm steps to focus on boundary fragments only, which leads to highly balanced workload among the GPU threads. In addition, we develop a ray shooting pattern that minimizes the global data dependency when computing winding numbers at anti-aliasing samples. This allows us to shift the majority of winding-number-related workload to the same kernel that consumes its result, which saves a significant amount of GPU memory bandwidth. Experiments show that our method gives a consistent 2.5× speedup over state-of-the-art alternatives for high-quality rendering at Ultra HD resolution, which can increase to more than 30× in extreme cases. We can also get a consistent 10× speedup on animated input.
</p>
<p><img src="http://kunzhou.net/zjugaps/pathrendering/gpu-scanline.png" width="1000" alt="" title=""> <br>
</p></div> <!-- span10 -->

</div><div>
<div>
<h2>BibTeX</h2>
<pre>@article {GPUpathtracingSA16,
title = {Efficient GPU Path Rendering Using Scanline Rasterization},
author = {Rui Li and Qiming Hou and Kun Zhou}
journal = {ACM Transactions on Graphics},
volume = {35},
number = {6},
pages = {},
year = {2016}
}
</pre>
</div>



</div></div>]]>
            </description>
            <link>http://kunzhou.net/zjugaps/pathrendering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24935685</guid>
            <pubDate>Thu, 29 Oct 2020 20:52:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For Complex Applications, Rust Is as Productive as Kotlin]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24935355">thread link</a>) | @dochtman
<br/>
October 29, 2020 | https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="preamble">
<div>
<p>In this article, we will compare one apple (IntelliJ Rust) to one orange (rust-analyzer) to reach general and sweeping conclusions.
Specifically, I want to present a case study supporting the following claim:</p>
<p>For complex applications, Rust is as productive as Kotlin.</p>
<p>For me, this is an unusual claim to argue: I always thought exactly the opposite, but I am not so sure now.
I came to Rust from C++.
I was of the opinion that this is a brilliant low-level language and always felt puzzled at people writing higher-level things in Rust.
Clearly, choosing Rust means taking a productivity hit, and using Kotlin, C# or Go just makes much more sense if you can afford GC.
My <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">list of Rust criticisms</a> starts with this objection.</p>
<p>What moved my position in the other direction was my experience as the lead developer of rust-analyzer and IntelliJ Rust.
Let me introduce the two projects.</p>
<p><a href="https://github.com/intellij-rust/intellij-rust"><strong>IntelliJ Rust</strong></a> is the plugin for IntelliJ Platform, providing Rust support.
In effect, it is a Rust compiler front-end, written in Kotlin and making use of language-support features of the platform.
These features include lossless syntax trees, a parser generator, persistence and indexing infrastructure, among others.
Nonetheless, as programming languages differ lot, the bulk of logic for analyzing Rust is implemented in the plugin itself.
Presentational features like completion list come from the platform, but most of the language semantics is hand-written.
IntelliJ Rust also includes a bit of a Swing GUI.</p>
<p><a href="https://github.com/rust-analyzer/rust-analyzer"><strong>rust-analyzer</strong></a> is an implementation of
<a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a> for Rust.
It is a Rust compiler front-end written from scratch with an eye towards IDE support.
It makes heavy use of <a href="https://github.com/salsa-rs/salsa">salsa</a> library for incremental computations.
Beyond the compiler itself, rust-analyzer includes code for managing long-lived multithreaded process of the language server itself.</p>
<p>The projects are essentially equivalent in scope — rust compiler front-ends suitable for IDEs.
The two biggest differences are:</p>
<div>
<ul>
<li>
<p>IntelliJ Rust is a plugin, so it can re-use code and design patterns of the surrounding platform.</p>
</li>
<li>
<p>rust-analyzer is the second system, so it leverages experience of IntelliJ Rust for a from-scratch design.</p>
</li>
</ul>
</div>
<p>The internal architecture of the two projects also differs a lot.
In terms of <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">Three Architectures</a>, IntelliJ Rust is map-reduce, and rust-analyzer is query-based.</p>
<p>Writing an IDE-ready compiler is a high-level task.
You don’t need to talk to the operating system directly.
There are some fancy data structures and concurrency here and there, but they are also high-level.
It’s not about implementing crazy lock-free schemes, it’s about maintaining application state and sanity in the multithreaded world.
The bulk of the compiler is symbolic manipulation, arguably best suited for lisp.
Picking a VM-based language for such task (for example, OCaml), doesn’t have any intrinsic downsides.</p>
<p>At the same time, the task is pretty complex and unique.
The ratio of “your code” vs “framework code” when implementing features is much higher than in a typical CRUD backend.</p>
<p>Now that the projects are introduced, lets take two roughly equivalent slices of history.</p>

<p>Both are about 2 years old, with 1-1.5 developers working full time and vibrant and thriving community of open-source contributors.
There are 52k lines of Kotlin and 66k lines of Rust.</p>
<p>Both delivered roughly equivalent feature sets at that time.
To be honest, I still don’t really believe this :)
rust-analyzer started from zero, it didn’t have a decade worth of Java classes to bootstrap from, and the productivity drop between Kotlin and Rust is supposed to be huge.
But it’s hard to argue with reality.
Instead, let me try to reflect on my experience building both, and to try to explain Rust’s surprising productivity.</p>
</div>
</div>
<div>
<h2 id="_learning_curve">Learning Curve</h2>
<div>
<p>It’s easy to characterize Kotlin’s learning curve — it is nearly zero.
I’ve started IntelliJ Rust without Kotlin experience and never felt that I need to specifically learn Kotlin.</p>
<p>When I switched to rust-analyzer, I was pretty experienced with Rust.
I would say that one definitely needs to deliberately learn Rust, it’s hard to pick it up on the go.
Ownership and aliasing control are novel concepts (even if you come from C++), and taking holistic approach to learning them pays off.
After the initial learning step the ride is generally smooth.</p>
<p>By the way, this is the perfect place to plug our Rust courses and tailor-made <a href="https://ferrous-systems.com/training/">trainings</a> :-)
The next <a href="https://ferrous-systems.com/training/#package-intro-training">introduction to Rust</a> is happening this December!</p>
</div>
</div>
<div>
<h2 id="_modularity">Modularity</h2>
<div>
<p>This I think is the biggest factor.
Both projects are moderately large in terms of scope as well as in terms of amount of source code.
I believe that the only way to ship big things is to split them in independent-ish chunks and implement the chunks separately.</p>
<p>I also find most of the languages I am familiar with to be pretty horrible with respect to modularity.
More generally, I am amused with FP vs OO debate, as it seems that “why no one does modules right?” is a more salient issue.</p>
<p>Rust is one of the few languages which has first-class concept of libraries.
Rust code is organized on two levels:</p>
<div>
<ul>
<li>
<p>as a tree of inter-dependent modules inside a crate</p>
</li>
<li>
<p>and as a directed acyclic graph of crates</p>
</li>
</ul>
</div>
<p>Cyclic dependencies are allowed between the modules, but not between the crates.
Crates are units of reuse and privacy: only crate’s public API matters, and it is crystal clear what crate’s public API is.
Moreover, crates are anonymous, so you don’t get name conflicts and dependency hell when mixing several versions of the same crate in a single crate graph.</p>
<p>This makes it very easy to make two pieces of code <strong>not</strong> depend on each other (non-dependencies are the essence of modularity): just put them in separate crates.
During code review, only changes to Cargo.tomls need to be monitored carefully.</p>
<p>At the time of comparison, rust-analyzer is split into 23 internal crates, with a handful general-purposed ones released on crates.io.
In contrast, IntelliJ Rust is a single Kotlin module, where everything can depend on everything else.
Although internal organization of IntelliJ Rust is pretty clean, it’s not reflected in the file system layout and build system, and needs constant maintenance.</p>
</div>
</div>
<div>
<h2 id="_build_system">Build System</h2>
<div>
<p>Managing project’s build takes significant amount of times, and has multiplicative effect on everything else.</p>
<p>Rust’s build system, <a href="https://doc.rust-lang.org/cargo/index.html">Cargo</a>, is very good.
It’s not perfect, but it is a breath of fresh air after Java’s <a href="https://gradle.org/">Gradle</a>.</p>
<p>Cargo’s trick is that it doesn’t try to be a general purpose build system.
It can only build Rust projects, and it has rigid expectation about the project structure.
It’s impossible to opt out of the core assumptions.
Configuration is a static non-extensible TOML file.</p>
<p>In contrast, Gradle allows free-form project structure, and is configured via a Turing complete language.
I feel like I’ve spend more time learning Gradle than learning Rust!
Running <code>wc -w</code> gives 182_817 words for Rust book, and 280_506 for Gradle’s user guide.</p>
<p>Additionally, Cargo is just faster than Gradle in most cases.</p>
<p>Of course, the biggest downside is that custom build logic is not expressible in Cargo.
Both projects needs substantial amount of logic beyond mere compilation to deliver the final result to the user.
For rust-analyzer, this is handled by hand-written Rust script, which works perfectly at this scale.</p>
</div>
</div>
<div>
<h2 id="_ecosystem">Ecosystem</h2>
<div>
<p>Language-level support for libraries and top-notch build system/package manager allow for a thriving ecosystem.
rust-analyzer relies on third-party libraries much more than IntelliJ Rust.
Some parts of rust-analyzer are also published to crates.io for other projects to reuse.</p>
<p>Additionally, low-level nature of the Rust programming language often allows for “perfect” library interfaces.
Interfaces which exactly reflect the underlying problem, without imposing intermediate language-level abstractions.</p>
</div>
</div>
<div>
<h2 id="_basic_conveniences">Basic Conveniences</h2>
<div>
<p>I feel that Rust is significantly more productive when it comes to basic language nuts and bolts — structs, enums, functions, etc.
This is not specific to Rust — any ML-family language has them.
However, Rust is the first industrial language which wraps these features in a nice package, not constrained by backwards compatibility.
I want to list specific features which I think allow producing maintainable code faster in Rust</p>
<p><em>Emphasis on data over behavior</em>.
Aka, Rust is not an OOP language.
The core idea of OOP is that of dynamic dispatch — which code is invoked by a function call is decided at runtime (late binding).
This is a powerful pattern which allows for flexible and extensible system.
The problem is, extensibility is costly!
It’s better only to apply it in certain designated areas.
Designing for extensibility by default is not cost effective.
Rust puts static dispatch front and center: it is mostly clear whats going on by just reading the code, as it is independent of runtime types of the objects.</p>
<p>One small syntactic thing I enjoy about Rust is how it puts fields and methods into different blocks syntactically:</p>
<div>
<div>
<pre><code data-lang="rust"><span>struct</span> <span>Person</span> <span>{</span>
  <span>first_name</span><span>:</span> <span>String</span><span>,</span>
  <span>last_name</span><span>:</span> <span>String</span><span>,</span>
<span>}</span>

<span>impl</span> <span>Person</span> <span>{</span>
    <span>fn</span> <span>full_name</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
        <span>...</span>
    <span>}</span>
<span>}</span></code></pre>
</div>
</div>
<p>Being able to see at a glance all the fields makes understanding the code much simpler.
Fields convey much more information than methods.</p>
<p><em>Sum types</em>.
Rust’s humbly named enums are full algebraic data types.
This means that you can express the idea of disjoint union:</p>
<div>
<div>
<pre><code data-lang="rust"><span>enum</span> <span>Either</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span> <span>{</span> <span>A</span><span>(</span><span>A</span><span>),</span> <span>B</span><span>(</span><span>B</span><span>)</span> <span>}</span></code></pre>
</div>
</div>
<p>This is hugely useful in day-to-day programming in the small, and some times during programming in the large as well.
To give one example, one of the core concepts for an IDE are references and definitions.
A definition a like <code>let foo = 92;</code> assigns a name to an entity which can be used down a line.
A reference like <code>foo + 90</code> <em>refers</em> to some definition.
When you ctrl-click on reference, you go to the definition.</p>
<p>Natural way to model that in Kotlin is by adding <code>interface Definition</code> and <code>interface Reference</code>.
The problem is, some things are …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</a></em></p>]]>
            </description>
            <link>https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24935355</guid>
            <pubDate>Thu, 29 Oct 2020 20:28:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Does Deno mean goodbye to Node.js?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24935265">thread link</a>) | @jerodsanto
<br/>
October 29, 2020 | https://www.stackbuilders.com/news/welcome-deno-does-this-mean-goodbye-to-node-js | <a href="https://web.archive.org/web/*/https://www.stackbuilders.com/news/welcome-deno-does-this-mean-goodbye-to-node-js">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>During the last 10 years, Node.js has become a big player in the backend framework market, powering several large scale applications across the globe. Meanwhile, JavaScript has also evolved greatly, not only because of the efforts of its development team, but also based on community feedback. However, integrating some of these new language features into a 10-year-old framework is not really straightforward, and has a high level of complexity.</p>
<p>Therefore we could say that Node.js’ architecture hasn’t evolved as fast as the language. As a basic example, Node.js is still based on callbacks, while there are far better ways to deal with asynchronicity in modern JavaScript. This is something that its creator, Ryan Dahl, has acknowledged in the past few years, and it has moved him to work on a new framework that addresses some of these issues. It is called Deno, and in the following article, we would like to explore some of its concepts to determine if it will render Node.js obsolete.</p>
<h2 id="what-is-deno">What is Deno?</h2>
<p>First of all, you should know that Deno is not a fork of Node.js. It’s a modern runtime for JavaScript and TypeScript, implemented from scratch by Ryan Dahl in 2018. It was built on <a href="https://v8.dev/">V8</a> just like Node.js, but Deno was written with <a href="https://www.rust-lang.org/">Rust</a> and <a href="https://tokio.rs/">Tokio</a>. The runtime was designed with TypeScript in mind, and for that reason Deno supports TypeScript without extra configurations or tooling.</p>
<p>Deno was built to improve security and help increase productivity in developers using the latest JavaScript features. At the time this article was written, Deno’s version is 1.4.0. It’s a stable release, so it’s a good time to go over its main features and learn how you can use them for your application.</p>
<h2 id="features">Features</h2>
<h3 id="typescript-out-of-the-box">TypeScript out of the box:</h3>
<p>TypeScript is powerful. This superset of JavaScript allows us to use types, interfaces, classes, inheritance, modules, generics, and other awesome things. However, it can be a bit tricky when using it with Node.js, because we need to install a module for TypeScript support and some tools to transpile the code. It also requires some additional configurations through tsconfig.json. However, after all of this setup, the JavaScript files that get compiled from TypeScript work pretty well with Node.js.</p>
<p>Deno offers native support for TypeScript at its 3.9 version. For it to run nothing else needs to be installed, and no compilation step is needed since Deno transpiles the code behind the scenes. It is also possible to run the code with a custom <code>tsconfig.json</code> file to customize how Deno compiles your code.</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a><span># Using a custom tsconfig.json file</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span>deno</span> run -c tsconfig.json my-application.ts</span></code></pre></div>
<h3 id="url-imports">URL imports:</h3>
<p>Node.js projects have a <code>package.json</code> file that contains relevant information for your project. It also holds the dependency list that you’ll be using. Deno handles this part in a completely different way. The <code>package.json</code> file is not used anymore in favor of <code>ES Modules</code>. In order to use modules in a Deno project, you will need to reference each module with its URL or file path.</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a># Import <span>module</span> <span>server</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span>import</span> <span>{</span>serve<span>}</span> <span>from</span> “https<span>:</span><span>//deno.land/std/http/server.ts”</span></span></code></pre></div>
<p>When the application is executed for the first time, Deno downloads and caches all modules in a global cache. It is possible to store them in a custom directory using the <code>$DENO_DIR</code> environment variable. With this approach, Deno decentralizes the modules and your project will not have a large <code>node_modules</code> folder.</p>
<p>To keep module versions locked, it is possible to create a lock file with the <code>--lock</code> and <code>--lock-write</code> flags.</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1"></a><span># Create/update the lock file "lock.json"</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span>deno</span> cache --lock=lock.json --lock-write src/my-application.ts</span></code></pre></div>
<h3 id="secure-by-default">Secure by Default:</h3>
<p>Deno has some security measures in place to disallow potentially dangerous operations. By default, the code is executed in a secure sandbox, so it is not possible to access the network, file system, or environment unless you explicitly allow it. You can do this by adding flags when running the application. These are enabled by default in Node.js, which makes it insecure in some cases.</p>
<p>As a quick overview of what can be enabled we have the following flags:</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1"></a><span># Enable environment access with Deno.env.get</span></span>
<span id="cb4-2"><a href="#cb4-2"></a><span>deno</span> run --allow-env my-application.ts</span>
<span id="cb4-3"><a href="#cb4-3"></a></span>
<span id="cb4-4"><a href="#cb4-4"></a><span>#Enable high resolution time measurement (used for profiling)</span></span>
<span id="cb4-5"><a href="#cb4-5"></a><span>deno</span> run --allow-hrtime my-application.ts</span>
<span id="cb4-6"><a href="#cb4-6"></a></span>
<span id="cb4-7"><a href="#cb4-7"></a><span>#Enable network access</span></span>
<span id="cb4-8"><a href="#cb4-8"></a><span># This is used in cases where we want to fetch from external servers</span></span>
<span id="cb4-9"><a href="#cb4-9"></a><span># or when we want to expose a port from our server</span></span>
<span id="cb4-10"><a href="#cb4-10"></a><span>deno</span> run --allow-net=https://example.com my-application.ts</span>
<span id="cb4-11"><a href="#cb4-11"></a></span>
<span id="cb4-12"><a href="#cb4-12"></a><span># Enable plugin usage</span></span>
<span id="cb4-13"><a href="#cb4-13"></a><span>deno</span> run --allow-plugin my-application.ts</span>
<span id="cb4-14"><a href="#cb4-14"></a></span>
<span id="cb4-15"><a href="#cb4-15"></a><span># Enable filesystem access</span></span>
<span id="cb4-16"><a href="#cb4-16"></a><span># To read a file or directory with Deno.open, or write to a file</span></span>
<span id="cb4-17"><a href="#cb4-17"></a><span># or  directory with Deno.writeFile</span></span>
<span id="cb4-18"><a href="#cb4-18"></a><span>deno</span> run --allow-read=awesome.txt my-application.ts</span>
<span id="cb4-19"><a href="#cb4-19"></a><span>deno</span> run --allow-write=awesome.txt my-application.ts</span>
<span id="cb4-20"><a href="#cb4-20"></a></span>
<span id="cb4-21"><a href="#cb4-21"></a><span># Enable subprocess execution with Deno.run</span></span>
<span id="cb4-22"><a href="#cb4-22"></a><span>deno</span> run --allow-run my-application.ts</span>
<span id="cb4-23"><a href="#cb4-23"></a></span>
<span id="cb4-24"><a href="#cb4-24"></a><span># Disable all security checks</span></span>
<span id="cb4-25"><a href="#cb4-25"></a><span>deno</span> run --allow-all my-application.ts</span></code></pre></div>
<h3 id="built-in-utilities">Built-in utilities:</h3>
<p>In Deno, we have some nice tools available out of the box. This means that we don’t need to install any additional libraries for some common development tasks. At a glance, these utilities are:</p>
<p><strong>Debugger:</strong> Like Node, Deno supports the V8 Inspector Protocol, which means that it’s possible to debug the program in any client that supports it. This consists mainly of two commands:</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1"></a><span># Debugging flags</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span>#   --inspect      : Allows debugger attachment at any point</span></span>
<span id="cb5-3"><a href="#cb5-3"></a><span>#   --inspect-brk  : Pause execution on first line</span></span>
<span id="cb5-4"><a href="#cb5-4"></a><span># Usage:</span></span>
<span id="cb5-5"><a href="#cb5-5"></a><span>deno</span> run --inspect-brk</span></code></pre></div>
<p>From this point, all you have to do is open your client and the program will stop on the first line, allowing you to set up breakpoints where you need to. For VSCode you can add the entry point and arguments to your <code>launch.json</code> to enable it.</p>
<p><strong>Formatter:</strong> In Node.js applications, it’s common to add a linter tool (typically ESLint) with a formatter like Prettier so the code is standardized. Deno has this feature built into it. You can access it by simply running <code>deno fmt</code></p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1"></a><span>deno</span> fmt          <span>#Formats everything in the current tree</span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span>deno</span> fmt file1.ts <span>#Formats a single file</span></span>
<span id="cb6-3"><a href="#cb6-3"></a><span>deno</span> fmt --check  <span># Checks if files are formatted correctly</span></span></code></pre></div>
<p><strong>Bundler:</strong> Bundling is a task that is currently done with webpack, gulp or Grunt in Node.js applications. We can use Deno’s bundler when we want to pack a module together with its dependencies and this will generate a single module we can reference from other files. These bundles can also be loaded in the web browser.</p>
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1"></a><span>deno</span> bundle https://foo.bar/test.ts test.bundle.js</span></code></pre></div>
<p>After that, we can import it from another JavaScript file or using a <code>&lt;script&gt;</code> tag in our HTML with the <code>type=”module”</code> property.</p>
<p><strong>Dependency inspector:</strong> We can display a tree structure of our dependencies using the <code>deno info</code> command, followed by the URL we want to inspect. This is similar to <code>npm ls</code> in Node</p>
<div id="cb8"><pre><code><span id="cb8-1"><a href="#cb8-1"></a><span>deno</span> info https://deno.land/std/uuid/test.ts</span>
<span id="cb8-2"><a href="#cb8-2"></a><span>local</span>: /Users/foo/Library/Caches/deno/deps/https/deno.land/997789467b3621b5d93c6b18bf8b275f35057b24f934c2508e3d1ef52cd51644</span>
<span id="cb8-3"><a href="#cb8-3"></a><span>type</span>: TypeScript</span>
<span id="cb8-4"><a href="#cb8-4"></a><span>compiled</span>: /Users/foo/Library/Caches/deno/gen/https/deno.land/std/uuid/test.ts.js</span>
<span id="cb8-5"><a href="#cb8-5"></a><span>map</span>: /Users/foo/Library/Caches/deno/gen/https/deno.land/std/uuid/test.ts.js.map</span>
<span id="cb8-6"><a href="#cb8-6"></a><span>deps</span>:</span>
<span id="cb8-7"><a href="#cb8-7"></a><span>https</span>://deno.land/std/uuid/test.ts</span>
<span id="cb8-8"><a href="#cb8-8"></a>  ├─┬ <span>https</span>://deno.land/std/uuid/tests/isNil.ts</span>
<span id="cb8-9"><a href="#cb8-9"></a>  │ ├─┬ <span>https</span>://deno.land/std/testing/asserts.ts</span>
<span id="cb8-10"><a href="#cb8-10"></a>  │ │ ├── <span>https</span>://deno.land/std/fmt/colors.ts</span>
<span id="cb8-11"><a href="#cb8-11"></a>  │ │ └── <span>https</span>://deno.land/std/testing/diff.ts</span>
<span id="cb8-12"><a href="#cb8-12"></a>  │ └─┬ <span>https</span>://deno.land/std/uuid/mod.ts</span>
<span id="cb8-13"><a href="#cb8-13"></a>  │   ├─┬ <span>https</span>://deno.land/std/uuid/v1.ts</span>
<span id="cb8-14"><a href="#cb8-14"></a>  <span>.</span></span>
<span id="cb8-15"><a href="#cb8-15"></a>  <span>.</span></span>
<span id="cb8-16"><a href="#cb8-16"></a>  <span>.</span></span></code></pre></div>
<h3 id="asynchronous-handling">Asynchronous handling:</h3>
<p>JavaScript asynchronous operations have evolved over time. The standard way of making an asynchronous call was through the use of callbacks. Recently we’ve gotten better ways to handle these operations, by using Promises, async/await syntax or generators. For that reason, Deno has taken advantage of these modern features.</p>
<p>All async actions in Deno return a promise. This is interesting because the <code>await</code> keyword is supported on the top level and there is no need to define the function with the <code>async</code> keyword. This approach allows us to write more readable code when working with asynchronism.</p>
<div id="cb9"><pre><code><span id="cb9-1"><a href="#cb9-1"></a><span>// Await some asynchronous operation</span></span>
<span id="cb9-2"><a href="#cb9-2"></a><span>let</span> file <span>=</span> <span>await</span> <span>Deno</span><span>.</span><span>open</span>(<span>'./my-file.txt'</span>)<span>;</span></span>
<span id="cb9-3"><a href="#cb9-3"></a></span>
<span id="cb9-4"><a href="#cb9-4"></a><span>// Awaiting when starting the server</span></span>
<span id="cb9-5"><a href="#cb9-5"></a><span>import</span> <span>{</span> serve <span>}</span> <span>from</span> <span>'https://deno.land/std/http/server.ts'</span><span>;</span></span>
<span id="cb9-6"><a href="#cb9-6"></a></span>
<span id="cb9-7"><a href="#cb9-7"></a><span>const</span> server <span>=</span> <span>serve</span>(<span>{</span> port<span>:</span> <span>3000</span> <span>}</span>)<span>;</span></span>
<span id="cb9-8"><a href="#cb9-8"></a></span>
<span id="cb9-9"><a href="#cb9-9"></a><span>for</span> <span>await</span> (<span>const</span> req <span>of</span> server)<span>{</span></span>
<span id="cb9-10"><a href="#cb9-10"></a>  <span>req</span><span>.</span><span>respond</span>(<span>{</span> body<span>:</span> <span>'Running server!!'</span> <span>}</span>)<span>;</span></span>
<span id="cb9-11"><a href="#cb9-11"></a><span>}</span></span></code></pre></div>
<p>Deno supports promises out of the box. In the first example, the <code>await</code> keyword waits until <code>Deno.open</code> is resolved and its result is stored in the <code>file</code> variable. In the second example, <code>server</code> is an async iterator and the <code>for await</code> keywords are used to iterate them, each item will be a new incoming request.</p>

<p>Deno has incredible features, but there are two points that I think can be improved: - The permission flags could be handled in a different way like using a file that allows us to set the flags. If your code needs almost all the permissions you will have to use a long command. However, this is not a big issue on itself. - About the dependencies, NodeJS has a better project organization and the <code>lock</code> file is generated automatically. With Deno your dependencies will be placed in one directory, and to lock the dependencies you need to run an additional command. This might not be a good developer experience, but the community is working on some alternatives to change this.</p>
<p>Another point I would like to mention is regarding the examples and tutorials. On the NodeJS side, you can find a lot of examples/tutorials of any library or functionality you may need, while with Deno there are few examples/tutorials. But it will increase in the future for sure.</p>
<p>In this <a href="https://github.com/stackbuilders/deno-example">link</a> you will find a small example using Deno and Typescript that shows how to create routes with the <code>oak</code> module, submit data from a form and generate a CSV file with the provided data.</p>
<h2 id="conclusion">Conclusion:</h2>
<p>Deno is a good alternative for increasing security that allows us to use TypeScript without extra configurations or …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.stackbuilders.com/news/welcome-deno-does-this-mean-goodbye-to-node-js">https://www.stackbuilders.com/news/welcome-deno-does-this-mean-goodbye-to-node-js</a></em></p>]]>
            </description>
            <link>https://www.stackbuilders.com/news/welcome-deno-does-this-mean-goodbye-to-node-js</link>
            <guid isPermaLink="false">hacker-news-small-sites-24935265</guid>
            <pubDate>Thu, 29 Oct 2020 20:21:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You Shouldn’t Sell Your SaaS Business]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24935241">thread link</a>) | @andygcook
<br/>
October 29, 2020 | https://chrisgimmer.com/why-you-shouldnt-sell-your-saas-business/ | <a href="https://web.archive.org/web/*/https://chrisgimmer.com/why-you-shouldnt-sell-your-saas-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>If you run a SaaS business,&nbsp;there&nbsp;are plenty of great reasons why you might want to sell it one day. Whether you’re looking to take some chips off the table or move on to the next project, it can often make a lot of sense.</p>
<p>If you are thinking about selling, you’ll find that there is no shortage of resources on <a href="https://feinternational.com/blog/saas-metrics-value-saas-business/" target="_blank" rel="noopener noreferrer">how to value a SaaS business</a>&nbsp;and <a href="https://tylertringas.com/selling-my-bootstrapped-saas-business/" target="_blank" rel="noopener noreferrer">how to go about selling it</a>. However, there’s not nearly as much emphasis placed on the merits of holding on to a SaaS business and going the distance.</p>
<p>As someone who’s run a SaaS business for the past 5 years and someone who’s participated in a few acquisition talks, I’ve grown to appreciate some of the benefits of maintaining ownership. As a result, I thought it would be interesting to present some of the reasons why you might NOT want to sell your SaaS business.</p>
<p>Now, my goal here is not to convince you to never sell your business. In fact, I think it’s important to operate your business as though you <em>could</em>&nbsp;sell if you wanted to.</p>
<p>Rather, my goal is simply to point out some of the things you might not be thinking of. That way, you can make a more informed decision about whether or not it makes sense to sell your business after considering all of your own unique circumstances.</p>
<p>I also want to point out that for the sake of this post I’m mainly talking about “financial acquisitions” where buyers are typically offering 3-5x multiples of annual <a href="https://www.quietlightbrokerage.com/sellers-discretionary-income/" target="_blank" rel="noopener noreferrer">seller’s discretionary earnings (SDE)</a>. If a strategic buyer comes along and offers you a crazy multiple for your business,&nbsp;then you should probably take the deal.</p>
<p>With that out of the way, here are some of the reasons you might not want to sell your SaaS business.</p>
<h2 id="h.sdhy6tlrdfd1">1. You’ll probably leave money on the table</h2>
<p>Back in 2017, I met a fairly well known marketer and founder who’s acquired a few SaaS apps and grew them into highly profitable businesses. After chatting with him for a while, he mentioned that if we were ever considering selling Snappa to let him know.</p>
<p>At the time, we weren’t actively looking to sell Snappa but I was curious to find out how they would value our business and what valuation he’d be willing to pay.</p>
<p>After sharing some of our metrics and describing how we ran the business, him and his business partner passed on making an offer. He mentioned&nbsp;that they couldn’t find any low hanging fruit and felt that acquiring it for more than a 3x SDE multiple would leave them with little margin of safety. At the time, we were only doing $33k in monthly recurring revenue (MRR) so even if we had sold for a 5x multiple we would have left <strong>significant</strong>&nbsp;money on the table.</p>
<p>Fast forward to the spring of 2019 and we received an email from a potential acquirer who’s been very interested in Snappa over the past few years. Every time he expressed interest in buying Snappa, I politely declined and said we didn’t have much interest in selling given the growth trajectory we were on.</p>
<p>This time around, he seemed very motivated to make a deal and was throwing around multiples on the very high end of what a financial acquisition would typically go for. After sharing our metrics and opening up the books, he made a very attractive offer which kicked off due diligence from the both of us.</p>
<p>Long story short, some issues cropped up during the deal and we ultimately pulled out of it. The good news is that it ended up being a <em>huge</em>&nbsp;blessing in disguise and completely changed my thoughts around selling our business.</p>
<p>Bringing it back to financials though, we again would have left <strong>a lot </strong>of money on the table had we sold. While we were negotiating a sale price, Snappa was generating $67k MRR. Today, Snappa generates $134k MRR, which is exactly <strong>double</strong>&nbsp;what we were generating just a year and a half ago!</p>
<p>More importantly, Snappa has gotten even more profitable as we’ve continued to spread more revenue over fewer costs. To put this all into perspective, we could probably sell Snappa for 2.5x more today than we could have back in the spring of 2019.</p>
<p>To illustrate this even more clearly, here’s a graph showing our all-time MRR and when these potential deals were being discussed.</p>
<p><img loading="lazy" src="https://chrisgimmer.com/wp-content/uploads/2020/10/acquisition-talks.jpg" alt="acquisition talks" width="1600" height="688" srcset="https://chrisgimmer.com/wp-content/uploads/2020/10/acquisition-talks.jpg 1600w, https://chrisgimmer.com/wp-content/uploads/2020/10/acquisition-talks-300x129.jpg 300w, https://chrisgimmer.com/wp-content/uploads/2020/10/acquisition-talks-1024x440.jpg 1024w, https://chrisgimmer.com/wp-content/uploads/2020/10/acquisition-talks-768x330.jpg 768w, https://chrisgimmer.com/wp-content/uploads/2020/10/acquisition-talks-1536x660.jpg 1536w" sizes="(max-width: 1600px) 100vw, 1600px"></p><p>You can see that our business has grown consistently over time and that selling it at any point along the way would have been a mistake. Although this post suffers from survivorship bias and our growth has accelerated due to the coronavirus, it is not uncommon at all for SaaS businesses to continue growing for many years. After all, this is the biggest benefit of starting a SaaS business; it might take a while to get going but once you’ve got product/market fit they usually keep compounding.</p>
<p>The ultimate point I want to make is this:</p>
<p><em>If your business continues to grow (even modestly), it will never make sense to sell it for a 3-5x SDE multiple, strictly from a financial standpoint. </em></p>
<p>The only caveat here is whether or not you can deploy the sale proceeds into another project/investment that will yield an ever higher rate of return than your current business.</p>
<p>It’s also worth mentioning that if your SDE gets high enough, holding out for the sake of more money becomes less important. If you net $3M – $5M after-tax from the sale of your SaaS business and park the proceeds in an index fund, <a href="https://www.mrmoneymustache.com/2012/05/29/how-much-do-i-need-for-retirement/" target="_blank" rel="noopener noreferrer">a safe withdrawal rate of 4%</a>&nbsp;would give you $120k – $200k of income. This would essentially give you an infinite runway if you really just want to move on to the next thing.</p>
<h2 id="h.5qi198x8pile">2. You’ll lose a reliable income stream</h2>
<p>When you’re thinking about selling your business, visualizing a huge chunk of cash in your bank account sounds very appealing. If your SaaS generates $25k of SDE per month, you could sell it for somewhere between $1M – $1.5M.</p>
<p>Aside from the large tax bill you’ll have to pay, there are other issues with trading a reliable income stream for a lump sum of cash…</p>
<p>Without an additional income stream, you will need to dip into that $1M in order to pay for your living expenses. If you don’t get another project off the ground in a reasonable time frame, you will then start depleting your savings.</p>
<p>The other problem is that cash in your bank account will continue to rot and lose purchasing power every single year. And with interest rates currently pegged at 0%, you’ll be forced to invest this money in the stock market (<a href="https://chrisgimmer.com/bitcoin-reserve-asset/">or bitcoin</a>) just to keep up with inflation.</p>
<p>Now imagine if you sold your SaaS business back in February 2019 and you parked your money in an S&amp;P 500 index fund. Just one month later, $1M would have decreased to $672k. How would that make you feel? Would you have stomached the volatility?</p>
<p>Fortunately, the markets have rebounded very quickly (mostly thanks to QE + stimulus), but the S&amp;P 500 is currently trading below the February 2019 peak. This means that, financially speaking, you’d be worse off today than you would have been when you sold your business.</p>
<h2 id="h.xutqxbophzg7"><img loading="lazy" src="https://chrisgimmer.com/wp-content/uploads/2020/10/sp500-return.jpg" alt="S&amp;P 500 returns" width="1600" height="939" srcset="https://chrisgimmer.com/wp-content/uploads/2020/10/sp500-return.jpg 1600w, https://chrisgimmer.com/wp-content/uploads/2020/10/sp500-return-300x176.jpg 300w, https://chrisgimmer.com/wp-content/uploads/2020/10/sp500-return-1024x601.jpg 1024w, https://chrisgimmer.com/wp-content/uploads/2020/10/sp500-return-768x451.jpg 768w, https://chrisgimmer.com/wp-content/uploads/2020/10/sp500-return-1536x901.jpg 1536w" sizes="(max-width: 1600px) 100vw, 1600px"></h2>
<p>In my case, short-term volatility doesn’t bother me at all when it comes to investing. When the market crashed in March, I watched my portfolio of high growth tech stocks get crushed along with my personal investment in bitcoin. However, I didn’t panic or make any rash decisions because I don’t rely on these investments to pay the bills or perform in the short-term. Thanks to this patience, my portfolio has not only recovered, but it has significantly outperformed the broader market this year.</p>
<p>One of the reasons I was able to remain calm is because I have a SaaS business that kicks off reliable cash flow. This allows me to focus my investing on highly attractive long-term opportunities without worrying about short-term volatility. So far in my investing career, this has worked out very well.</p>
<p>If we had sold Snappa and I needed to protect my nest egg, I likely would have changed my investing approach to something more conservative in order to avoid big drawdowns. This would have put me in a much worse position than I’m in today.</p>
<h2 id="h.3uryscj59qwu">3. Acquisitions can be distracting</h2>
<p>When selling a business, something that often gets overlooked is the time, resources, and mental energy that’s required during the process. Depending on the size and complexity of the deal, you may need to dedicate the majority of your time over several months to ensure that the deal closes. If you want a detailed account of what this can look like, I really enjoyed <a href="https://www.startupsfortherestofus.com/episodes/episode-298-a-startup-acquisition-story" target="_blank" rel="noopener noreferrer">Rob Walling’s account of the Drip acquisition</a>.</p>
<p>Every hour that you spend on acquisition talks or due diligence is an hour that you’re not spending on growing your businesses. Also, the further down the process you get, and the more time that you sink in, the more demoralizing it becomes if the deal doesn’t close.</p>
<p>Another thing worth considering is how you choose to communicate with employees. Obviously, you don’t want to tell your employees about an acquisition at the LOI stage when the buyer hasn’t done the full due diligence. However, as part of the due diligence, or as the deal approaches closing, you may need to loop in some of your key employees. If the deal doesn’t go through, your employees could then get spooked and start looking for opportunities elsewhere if they think you’re going to sell the company.</p>
<h2 id="h.cvcpn4f4m311">4. You’ll have to say goodbye to your team</h2>
<p>Speaking of employees, <a href="https://chrisgimmer.com/building-a-great-team/">building an amazing team</a>&nbsp;has been one of the most rewarding parts about being a founder. It truly is a joy to work with every single person on our team. Although we only hired our first employee in 2016, I’m happy to say that not a single person has left the company.</p>
<p>In addition to all the time we’ve spent working together remotely, we’ve also had some amazing in-person experiences and created lasting memories that I’ll never forget. For these reasons, it would be really hard to say goodbye to all of the great people that I work with.</p>
<p>From a business perspective, ‘A’ players are also worth their weight in gold and are not easily replaced. Given the inherent leverage embedded in a SaaS business, a programmer or marketer who’s 2x better than their counterpart can realistically provide 5x better returns for the business.</p>
<p>If you sell off the business and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrisgimmer.com/why-you-shouldnt-sell-your-saas-business/">https://chrisgimmer.com/why-you-shouldnt-sell-your-saas-business/</a></em></p>]]>
            </description>
            <link>https://chrisgimmer.com/why-you-shouldnt-sell-your-saas-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24935241</guid>
            <pubDate>Thu, 29 Oct 2020 20:18:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying for Apple Entrepreneur Camp for Black Founders]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24935152">thread link</a>) | @oivviopolite
<br/>
October 29, 2020 | https://liberationtech.net/applying-for-apple-entrepreneur-camp-for-black-founders/ | <a href="https://web.archive.org/web/*/https://liberationtech.net/applying-for-apple-entrepreneur-camp-for-black-founders/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
            
            <div id="ajax-container">
<div>
  <article>
      
      <div>
          <p>Apple is running an "Entrepreneur Camp" for black founders and applications are open. As far as I can tell it's their first go at it. Previously they've run events for female founders.</p>
<p>If you get in you'll supposedly get access to assistance from Apple engineers. I don't know how extensive that access will actually be, but I'm dying to find out. Here's my application. Apple's questions are in bold and my answers in regular. Wish me luck :)</p>

<p><strong>Organization</strong></p>
<p><strong>Apple Entrepreneur Camp is for organizations worldwide with a Black founder, co-founder, or CEO. Each organization may bring up to three attendees. The Black founder, co-founder, or CEO and at least one Black developer (if not a sole proprietorship) must attend. The third attendee may be any racial background.</strong></p>
<p>Oivvio Polite</p>
<p><strong>App Name</strong></p>
<p>Season</p>
<p><strong>Website</strong></p>
<p><a href="https://seasonpods.com/">seasonpods.com</a></p>
<p><strong>Describe your organization’s mission in one sentence.</strong></p>
<p>Ultimately to liberate people through the use of technology, but on a day to day basis I run it to pay the bills :)</p>
<p>Season is a podcast player containing only limited series and audio drama where one story is told over multiple episodes. These kinds of podcasts are very popular but are sort of shoehorned in to the podcast format that is centered around free standing episodes, feeds and subscriptions. In a regular podcast player it can actually be a bit tricky to 1) find this content and 2) to play all episodes in the right order.</p>
<p><strong>Company Size</strong></p>
<p>Sole proprietorship/single person business</p>
<p><strong>Number of Black Developers Employed by Your Company</strong></p>
<p>1 - 2</p>
<p><strong>What is the technical skill level of your development team on Apple platforms?</strong></p>
<p>Intermediate</p>
<p><strong>Has your organization received any investments or grants from external investors?</strong></p>
<p>No</p>
<p><strong>Do you plan to raise money in the future?</strong></p>
<p>No</p>
<p><strong>Are you the founder, co-founder, or CEO?</strong></p>
<p>Yes</p>
<p><strong>If selected, will you be managing your organization’s involvement with the program?</strong></p>
<p>Yes</p>
<h2>Your App</h2>
<p><strong>Apple Entrepreneur Camp is designed to provide code level assistance as you create your next generation app using native Apple technologies. You must have a developed app or fully functional build that you can demo live.</strong></p>
<p><strong>How far along are you in the development of your app?</strong></p>
<p>Available on the App Store</p>
<p><strong>TestFlight, App Store, or .IPA download link</strong></p>
<p><a href="https://apps.apple.com/se/app/season-podcasts/id1504295207">https://apps.apple.com/se/app/season-podcasts/id1504295207</a></p>
<p><strong>Tell us about the app you’re developing. What problem is it trying to solve?</strong></p>
<p>The app is live in the App Store but limited to Sweden for the time being. Here's the TestFlight link: <a href="https://testflight.apple.com/join/OPSYw5qV">https://testflight.apple.com/join/OPSYw5qV</a> usable in all regions.</p>
<p>Season is a podcast player containing only limited series and audio drama where one story is told over multiple episodes. These kinds of podcasts are very popular but are sort of shoehorned in to the podcast format that is centered around standalone episodes, feeds and subscriptions.</p>
<p>In a regular podcast player it can actually be a bit tricky to 1) find this content and 2) play all episodes in the right order.</p>
<p><strong>Who is your app intended for and what solutions do they currently use? What’s unique about your solution?</strong></p>
<p>People who enjoy binging on well produced limited series and audio drama podcasts. Today they are using Apple podcasts and Spotify. Limited series are heavily over represented in the Apple podcasts charts which is a strong indicator that an app specifically for this kind of content could do well.</p>
<p>Half of what makes Season better is the curation. If you're into limited series Season makes it sooo much easier to find stuff you'll like. The other half is the player experience that is tailored to multi episode shows, using the <strong>season</strong> rather than the feed as it's central organizational unit.</p>
<p><strong>On which platforms do you plan to release your app?</strong></p>
<p>iOS</p>
<p>iPadOS</p>
<p><strong>What key Apple technologies have you integrated or do you plan to integrate into your app?</strong></p>
<p>SwiftUI</p>
<p><strong>What developer tools do you currently use?</strong></p>
<p>Xcode</p>
<p><strong>What programming languages do you currently use for app development?
Swift</strong></p>
<p>Swift</p>
<h2>The Future</h2>
<p><strong>Describe your strategy and road map for apps on Apple platforms, including new deployments, over the next 6, 12, or 24 months.</strong></p>
<p>I just released the app to the App Store last week, limiting it to the Swedish region. Over the next two months, using feedback from early users, I'll be polishing the app. I'm not really adding any features I'm just making the ones that are already in there look and work better. When that's done, hopefully before the end of the year I'll release to all regions. In early 2021 I hope to be able to focus more on getting the word out and reaching users.</p>
<p><strong>What would you like to gain from attending?</strong></p>
<p>Access to Apple engineers to help me with the code sounds like a complete dream. There have been so many times throughout this project that I've wished for something like that. I don't think that you'll be shocked to hear that your docs aren't always that helpful.</p>
<p>Beyond coding, getting more insights into the business side of having an app in the store would be tremendous. (This is my weak point. I have zero business experience.) Other than building a great app, what can I do to find my users?</p>
<p>Also getting to connect with other black techies would be fun.</p>
<p><strong>How would you define your success after attending?</strong></p>
<p>I'm sure this would be a great learning experience outside of any other outcomes. But viewed as a step on my journey to being successful as an indie app developer I'd also like to but a quantitative measure on it.
Let's say 10000 daily users by the end of 2021!</p>
<p><strong>If you are a for-profit business, how does your organization plan to sell and market its products/services?</strong></p>
<p>I plan to sell ad-space in the app for podcasts. A couple of other small podcast players are already doing this so it's a proven business model. I'm rather confident that I can make that work as long as I'm able to get a sufficient amount of users.</p>
<p><strong>If you've shared or considered sharing your coding knowledge and enthusiasm for computer science with others, let us know.</strong></p>
<p>I've done some teaching to design and illustration-students at a local arts collage (<a href="https://www.konstfack.se/">Konstfack</a>) here in Stockholm. I really enjoy it and would like to do more of it but the amount time of time I can devote to teaching is limited since the pay is abysmal.</p>
      </div>
  </article>
</div>
            </div>
	</div></div>]]>
            </description>
            <link>https://liberationtech.net/applying-for-apple-entrepreneur-camp-for-black-founders/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24935152</guid>
            <pubDate>Thu, 29 Oct 2020 20:11:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Good Judgment and Decision-Making: The Science and Practice]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24934909">thread link</a>) | @maxan
<br/>
October 29, 2020 | https://max2c.com/on-good-judgment-and-decision-making-science-practice/ | <a href="https://web.archive.org/web/*/https://max2c.com/on-good-judgment-and-decision-making-science-practice/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4018">
			
	<!-- .entry-header -->

	<div>
		
<p>Imagine you’ve made two decisions. One has resulted in a loss of 10 thousand dollars, while the other resulted in a gain of 10 thousand dollars. Would you say that the former was a bad decision, and the latter was a good one?</p>



<p>The first response that usually comes to everyone’s mind is “of course, the second decision was better”. But this is not necessarily the case. Can you think of a scenario where your response would be the opposite?</p>



<p>I’ve been thinking and reading about decision-making for many years while trying to put everything I learned into practice. Below, I summarize the strategies and mental models that I personally found most useful.</p>



<h2>The Process vs. The Outcome</h2>



<p>We all have a natural tendency to judge decisions based on their outcomes. This is not the worst heuristic, as there is a correlation between the quality of decisions and outcomes. But this heuristic has a major flaw — it doesn’t account for luck and incomplete information.</p>



<p>An individual can make a bad impulse decision yet get lucky and get a positive outcome. An extreme example could be buying a lottery ticket and winning. A less extreme example could be taking a high-stakes risky business decision without putting much thought into it. Should those decisions still be considered <em>good?</em></p>



<p>On the other hand, another individual might dedicate the appropriate time to making a business decision, follow a thorough process, analyze all the available information, make the reasonable conclusions, and make an educated long-term bet. Now imagine that the business environment transforms in the upcoming years in a way <em>that could not have been predicted.</em> So the decision leads to a negative outcome. For example, a product launch fails. Does it mean the decision was bad?</p>



<p>Arguably, the first individual made a bad decision, and the second one made a good one. This might contradict conventional wisdom, but if you really think about it, the first person simply got lucky after following a bad process. And the second person did everything they could to make the optimal decision and took a calculated risk. That the outcome wasn’t positive in this particular case doesn’t tell us much about the person’s decision-making ability or judgment.</p>



<p>One reason it’s so hard to evaluate the process instead of the outcome in the business context is that it flies in the face of many other best practices. Hiring managers believe that past performance is the best predictor of success. Leaders extol results-driven culture. OKRs are set around outcomes — not processes.</p>



<p>But a deeper reason is that it’s more difficult to evaluate and establish processes. It’s much easier to evaluate results. Evaluating processes would require a deeper understanding of the context and how that context has evolved over time. It would also require disentangling various drivers of the outcome. You might be thinking… Who’s got time for <em>that</em>?</p>



<p>Realistically, I don’t see the outcome-based evaluation of decisions going away completely any time soon. But it doesn’t mean we cannot iteratively improve the process so we get better over time.</p>



<p>So what can we do to improve the process?</p>



<h2>Decision Journal</h2>



<p>A simple yet powerful idea is to document big decisions. Just like venture capitalists prepare <a href="https://www.bvp.com/memos" target="_blank" rel="noreferrer noopener">detailed investment memos</a> before investing in startups where they weigh all the pros and cons, we can also write summaries for big decisions in business and life.</p>



<p>In addition to outlining all the available options and considering their pros and cons, here are some additional things to consider.</p>



<h2>The Main Goal and Frameworks</h2>



<p>Asking “what are we optimizing for?” might sound obvious but clarifying what you’re optimizing for can simplify the entire process. </p>



<p>Asking this question is particularly useful when a group of people is making a decision. You might assume that everyone has the same goal in mind, but once you ask, you might realize that people might have different opinions about the most important goal or metric to optimize for.</p>



<p>And if you’re into spreadsheets, you can even come up with a list of criteria and assign weights to calculate the expected outcomes. For example:</p>



<div><figure><img loading="lazy" src="https://max2c.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-13.36.33.png" alt="Decision-making framework: options, criteria, weights, payoffs, and expected value." width="786" height="245" srcset="https://max2c.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-13.36.33.png 1048w, https://max2c.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-13.36.33-480x149.png 480w, https://max2c.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-13.36.33-666x207.png 666w, https://max2c.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-13.36.33-768x239.png 768w" sizes="(max-width: 786px) 100vw, 786px"></figure></div>



<p>Expected value = the probability of a certain outcome * the payoff in case of this outcome. </p>



<p>The payoff can either be expressed in monetary value or subjectively perceived value — for example, how happy you would be on the 10-point scale.</p>



<p>Developing a framework like this can be useful for thinking and clarifying what really matters to you and aligning with others. But quantifying things can also give you a false sense of confidence so I’d use this approach with caution.</p>



<p>Want to take it up a notch? Look into <a href="https://en.wikipedia.org/wiki/Decision_tree" target="_blank" rel="noreferrer noopener">decision trees</a>.</p>



<h2>Expected Value vs. the Worst Possible Downside</h2>



<p>Besides considering the most likely outcome or the expected value, I find it very useful to consider the worst possible downside.</p>



<p>Imagine you have two investment opportunities. One is expected to grow 7% annually on average in the long-term and the other is expected to grow 10%. Based on this information alone, the second one looks like a better investment. At least until you account for volatility. The extreme case of volatility is that the investment goes to zero or close to zero.</p>



<p>I personally find it useful to think about the worst possible outcome I would be comfortable with in addition to considering the expected value.</p>



<p>What if I told you that the value of the first investment has less than a 0.01% chance of dropping to near zero, while the value of the second investment has a 20% chance of doing so, how would it change your decision?</p>



<h2>A Portfolio of Bets</h2>



<p>Your response to the previous question might have been “it depends”. It might depend on a number things — such as your risk aversion, personal situation, or whether this is the only investment or one of many.</p>



<p>The portfolio approach is often used in finance. It’s been shown that most people would be better off allocating most of their investments into low-fee portfolios that track the overall market rather than picking individual stocks. Similarly, venture capitalists always spread out their investments across many startups.</p>



<p>And a similar framework can be applied in business and life — it’s sometimes useful to ask yourself a question “am I making and testing multiple bets here or primarily committing to one thing?”</p>



<h2>Optionality vs. Efficiency</h2>



<p>It’s useful to consider the trade-off between future optionality and efficiency.</p>



<p>Some business decisions might bring in more revenue or reduce costs, but they reduce your future options. Many companies optimize for efficiency so they could grow faster or improve their bottom line. Generally, public markets and quarterly financial reporting also incentivize them to do so. But sometimes over-optimizing leads to reduced optionality in the future.</p>



<p>Nassim Taleb developed and popularized the idea of <a href="https://en.wikipedia.org/wiki/Antifragility" target="_blank" rel="noreferrer noopener">antifragility</a> which is highly related to optionality. Wikipedia describes antifragility as “a property of systems that increase in capability to thrive as a result of stressors, shocks, volatility, noise, mistakes, faults, attacks, or failures”.</p>



<p>What’s interesting is that sometimes building a system like this or putting yourself in a situation like this requires a certain redundancy which is the opposite of efficiency.</p>



<p>The PPE shortage in the US during the 2020 COVID-19 pandemic is sometimes viewed as a recent example of optimizing for efficiency at the expense of optionality. If you focus on efficiency and optimize for the short-term demand, you might choose to store only a limited amount “just in case” and purchase the equipment from countries that can provide it at a lowest cost. However, if you want to optimize for optionality, resilience, and antifragility, you might choose to have more redundant storage and manufacture some equipment internally — so you don’t rely on other countries as much.</p>



<p>Similarly, certain choices in life and business create more options in the future than others.</p>



<h2>Let People Form Their Own Opinions First</h2>



<p>To quote Daniel Kahneman, a Nobel prize-winning psychologist and economist:</p>



<p><em>“Subjectively, it feels like you believe in something because you have the arguments for it. But it works the other way around. You believe in the conclusion, and then you create supporting arguments. That’s fundamental. Why do people believe in these conclusions? Partly because people we love and trust believe in the same conclusion.”</em></p>



<p>Our brains are naturally biased to pay attention to what others believe and generally follow them. So if one person in a group confidently announces their opinion first, many people will be likely to follow them. You can see this effect on steroids if that first-to-speak person is a boss.</p>



<p>This is why it’s usually better to ask people to form their opinions first and, ideally, write them down before discussing them with others. I made sure my team utilized this strategy when running customer research and focus groups with multiple people being interviewed at a time. Before discussing a topic as a group, we would present participants with a question and then ask them to write their opinions before discussing them. This always leads to a greater diversity of ideas.</p>



<h2>First Principles Thinking</h2>



<p>It’s also been shown that people are more likely to accept evidence that is supporting their pre-existing beliefs and more likely to challenge evidence that is contradicting them. <a href="https://en.wikipedia.org/wiki/Motivated_reasoning" target="_blank" rel="noreferrer noopener">Motivated reasoning</a> and <a href="https://en.wikipedia.org/wiki/Confirmation_bias" target="_blank" rel="noreferrer noopener">confirmation bias</a> are well researched.</p>



<p>First-principles reasoning is the opposite of that. You don’t reason by analogy, assume that things can only be the way they are today, or copy what others believe.</p>



<p>Instead, you start with the underlying, well-established facts and build your beliefs and conclusions independently based on these facts.</p>



<p>Or you can start by considering commonly held beliefs and deconstructing them with the “<a href="https://en.wikipedia.org/wiki/Five_whys" target="_blank" rel="noreferrer noopener">five whys</a>” …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://max2c.com/on-good-judgment-and-decision-making-science-practice/">https://max2c.com/on-good-judgment-and-decision-making-science-practice/</a></em></p>]]>
            </description>
            <link>https://max2c.com/on-good-judgment-and-decision-making-science-practice/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934909</guid>
            <pubDate>Thu, 29 Oct 2020 19:53:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview: Amiga Artist Jim Sachs (2020)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24934813">thread link</a>) | @erickhill
<br/>
October 29, 2020 | https://www.amigalove.com/viewtopic.php?f=5&t=1618 | <a href="https://web.archive.org/web/*/https://www.amigalove.com/viewtopic.php?f=5&t=1618">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.amigalove.com/viewtopic.php?f=5&amp;t=1618</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934813</guid>
            <pubDate>Thu, 29 Oct 2020 19:47:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Learn Machine Learning and Deep Learning: A Guide for Software Engineers]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24934686">thread link</a>) | @renanmoura
<br/>
October 29, 2020 | https://renanmf.com/machine-learning-and-deep-learning-software-engineers/ | <a href="https://web.archive.org/web/*/https://renanmf.com/machine-learning-and-deep-learning-software-engineers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Introduction</h2><p>The subject of Artificial Intelligence picks my interest and I’m constantly studying and trying new things in this field.</p><p>It is notorious how the technologies related to Natural Language Processing, Computer Vision and such have emerged and evolved into solutions used by millions of users every day.</p><p>Even though people use the term "Artificial Intelligence", we are still far away from something as advanced as a Skynet from the Terminator movies.</p><p>The most common subfield of AI used today is the one called Machine Learning, which, in its turn, has Deep Learning as subfield steeply growing every day for quite some time now.</p><p>In this guide, I aim to describe a path to follow for software engineers to begin understanding how Machine Learning works and how to apply it to your projects.</p><p>Yeah, you can just go to Google API’s or Amazon and pick some magical API to do Speech Recognition for you, but the value of knowing how it works, why it works and even more, how to make your own API as a Service and tune it to your specific needs is incredible.</p><p>Remember, as a developer, every tool is a new power.</p><p>I’ve read, watched and gone through all these resources until the end, even got a paid certification for some, even though it is not necessary to learn, I find myself more engaged to finish when I have some deadline and assessment to prove I actually learned the material.</p><p>Let’s dive into the topics.</p><h2>The Basics: Math!</h2><p>Maybe you never had the chance to study some college-level math, or you did study it but you can’t remember most of the stuff because JavaScript and CSS took all the memory of those topics away.</p><p>There are 3 topics you must know beforehand, or at least have a decent grasp of to follow any good material on ML and DL: Linear Algebra, Calculus and Statistics.</p><p>If you’d like to go deep in learning the math needed to ML and DL, you can look for MIT OpenCourseWare classes like Professor Strang’s renowned <a href="https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/">Linear Algebra</a> class.</p><p>I’ve watched it in college in parallel with my regular class and it is very good.</p><p>But, let’s face it, most people have no time for that or the patience.</p><p>So I will give you the crash course for the 3 topics mentioned above.</p><h3>Linear Algebra</h3><p>Just watch the whole series <a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Essence of Linear Algebra</a> from the Youtube channel 3Blue1Brown.</p><p>The guy makes visual explanations of once hard concepts incredibly easy!</p><p>It is very far in terms of content compared to Professor Strang’s, but it’s enough, to begin with, and you can go after other topics as you advance in ML and DL.</p><h3>Calculus</h3><p>Guess what?</p><p>3Blue1Brown also has a whole series on Calculus on Youtube for you to watch for free: <a href="https://www.youtube.com/watch?v=WUvTyaaNkzM&amp;list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr">Essence of Calculus</a>.</p><p>Again, he is very good at giving you the intuition of why and how rather than just throw some random equations on your face.</p><h3>Statistics</h3><p>This is a whole field that, in my opinion, you can learn as needed, a good reference is <a href="https://www.amazon.com/Practical-Statistics-Data-Scientists-Essential/dp/1491952962">Practical Statistics for Data Scientists: 50 Essential Concepts</a>.</p><p>An objective book with some good examples for every concept.</p><p>Fast to read too.</p><p>As the title implies, it is more suitable for Data Scientists, but understanding some basics of statistics is always good and this is what this is book is for.</p><p>You won’t become a statistician after reading it, but you will learn some good stuff.</p><h2>The Bypassed: Machine Learning</h2><p>Everybody wants to jump straight into Deep Learning and be the cool guy training a single model for a week on a 12GB GPU.</p><p>But to get Deep Learning right, you need to go through Machine Learning first!</p><h3>Start from the beginning</h3><p>The concepts, the train of thought, the "feeling" of how things work start here and there is no one else more capable of teaching those concepts than Professor Andrew Ng in his course <a href="https://www.coursera.org/learn/machine-learning">Machine Learning</a>.</p><p>You may think this course is old and outdated, well, technology-wise, maybe, but conceptually-wise, it is better than anything else out there.</p><p>Professor Ng makes it easy to understand the math applied in every technique he teaches and gives you a solid understanding of what happens underneath in a very short and concise course.</p><p>All the exercises are made in Octave, a free version of Matlab of sorts, and you finish the course implementing your own Neural Network!</p><p>The syntax in Octave is easy to grasp for any programmer, so don’t let that be a barrier for you.</p><p>Once you finish the course, you will have implemented all the major algorithms and will be able to solve several prediction problems.</p><h3>Random Forests</h3><p>I said all the major algorithms, right?</p><p>Actually, there is but one flaw in Andrew Ng’s course, he doesn’t cover Random Forests.</p><p>An awesome complement to his course is fast.ai’s <a href="http://course18.fast.ai/ml">Introduction to Machine Learning for Coders</a>.</p><p>Jeremy Howard goes super practical on the missing piece in Ng’s course covering a topic that is, for many classical problems, the best solution out there.</p><p>Fast.ai’s approach is what is called Top-Down, meaning they show you how to solve the problem and then explain why it worked, which is the total opposite of what we are used to in school.</p><p>Jeremy also uses real-world tools and libraries, so you learn by coding in industry-tested solutions.</p><h2>Deep Learning</h2><p>Finally!</p><p>The reason why we are all here, Deep Learning!</p><p>Again, the best resource for it is Professor Ng’s course, actually, a series of courses.</p><p>The <a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a> is composed of 5 courses total going from the basics and evolving on specific topics such as language, images, and time-series data.</p><p>One nice thing is that he continues from the very end of his classical Machine Learning course, so it just feels like an extension of the first course.</p><p>The math, the concepts, the notion of how and why it works, he delivers it all very concisely like few I’ve seen.</p><p>The only drawback is that he uses <a href="https://www.tensorflow.org/">Tensorflow</a> 1.x (Google’s DL Framework) in this course, but that’s minimal detail in my opinion since the explanations and exercises are so well delivered.</p><p>You can pick up the most recent version of the framework relatively easy and to do so there is the final piece of this guide, a book.</p><h3>Too much stuff, give me something faster</h3><p>This book might be the only thing you need to start, it is Aurélien Géron’s <a href="https://www.amazon.com.br/Hands-Machine-Learning-Scikit-Learn-TensorFlow-ebook/dp/B07XGF2G87">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems</a>.</p><p>It covers a lot, from classical Machine Learning to the most recent Deep Learning topics. Good examples and exercises using industry-grade frameworks and libraries.</p><p>I dare say that, if you are really in a rush, you can skip everything I said before and just go for the book.</p><p>You will miss a good amount of information contained on the other resources mentioned, but the practical and actionable knowledge from Géron’s book is enough to work on many ideas for your next project.</p><p>If you feel limited after only reading the book, go back and study the rest of the material, it will fill in the gaps you might have and give you a more solid understanding.</p><h2>What about Framework X or Y?</h2><p>"Hey, I’ve heard about PyTorch and that other framework or library X everybody talks about".</p><p>As a Software Engineer, you know better than anyone how fast technology evolves.</p><p>Don’t go crazy for that, after you learn the basics in this guide, you can easily go, for instance, on <a href="https://pytorch.org/">PyTorch</a> documentation or any other library or framework of sorts and learn how to use it in a week or two.</p><p>The techniques, the concepts, are all the same, it is only a matter of syntax and application or even tastes that you might have for any given tool.</p><h2>Conclusion</h2><p>To wrap it up, I want to say that, even though it might seem a lot, I tried to remove all the noise and at the end of the process, you will feel confident that you understand what is happening behind the curtains, the jargons and even be able to read some papers published in the field to keep up with the latest advances.</p><p>TL;DR Here is the list of resources mentioned in sequence:</p><ul><li><a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Essence of Linear Algebra</a></li><li><a href="https://www.youtube.com/watch?v=WUvTyaaNkzM&amp;list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr">Essence of Calculus</a></li><li><a href="https://www.coursera.org/learn/machine-learning">Machine Learning</a></li><li><a href="http://course18.fast.ai/ml">Introduction to Machine Learning for Coders</a></li><li><a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a></li><li><a href="https://www.amazon.com.br/Hands-Machine-Learning-Scikit-Learn-TensorFlow-ebook/dp/B07XGF2G87">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems</a></li></ul></div></div>]]>
            </description>
            <link>https://renanmf.com/machine-learning-and-deep-learning-software-engineers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934686</guid>
            <pubDate>Thu, 29 Oct 2020 19:37:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “Future Self” Savings Method]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24934679">thread link</a>) | @uxisnotui
<br/>
October 29, 2020 | https://ozchen.com/future-self-savings-method/ | <a href="https://web.archive.org/web/*/https://ozchen.com/future-self-savings-method/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-29003" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>In 2016, I began saving up for an experiment living as a <a href="https://ozchen.com/quit-digital-nomad/" target="_blank" rel="noreferrer noopener">digital nomad</a>. It was the first time I had to seriously think about what my “runway” would be. How long would my money last if I were to have no income coming in, and I wanted to continue traveling? </p>



<p>I decided to take a small bets experiment, figuring that 2 months abroad would be a enough to gauge what this digital nomad life is all about.</p>



<p>I calculated my monthly expenses – rent, food, all the big items – and created a “travel fund” worth at least 2 months of expenses. Even if the South American countries I was interested in had a lower cost of living, I wanted a wider margin to account for unexpected expenses like flights, having to get an emergency AirBnB, and shenanigans. </p>



<p>I came back from that trip with a little more money leftover than I had budgeted…and it felt good. </p>



<p>I got my first taste of buying myself future months and I wasn’t going back. </p>



<h3>Conventional financial advice promotes two extremes</h3>



<p>The typical financial advice rest on two points: </p>



<p>On one hand, build an emergency fund. Experts like <a href="https://www.daveramsey.com/blog/quick-guide-to-your-emergency-fund">Dave Ramsey</a> suggesting a starter fund of $1000.</p>



<p>On the other hand, think about retirement—which could be hundreds of thousands, or millions of dollars. <br></p>



<blockquote><p>Fidelity Investments recommends that “a 40-year old should have a nest egg twice her annual income; by age 50, the egg should be four times income and at age 60, retirement savings should be six times current income.” (<a aria-label="Zacks (opens in a new tab)" rel="noreferrer noopener" href="https://finance.zacks.com/should-nest-egg-retire-4445.html" target="_blank">Zacks</a>)</p></blockquote>



<p>This super long term outlook is hard to relate to, especially for younger people starting out in the workforce, saddled with student loan debt and without much savings. </p>



<p>There needs to be an aspirational stage, something that feels more within reach between setting up an emergency fund (basic) and planning for retirement (advanced). </p>



<figure><img loading="lazy" width="960" height="367" src="https://i2.wp.com/ozchen.com/wp-content/uploads/freedom-fund-vs-emergency-fund-retirement-illustration.png?resize=960%2C367&amp;ssl=1" alt="" srcset="https://i2.wp.com/ozchen.com/wp-content/uploads/freedom-fund-vs-emergency-fund-retirement-illustration.png?w=1280&amp;ssl=1 1280w, https://i2.wp.com/ozchen.com/wp-content/uploads/freedom-fund-vs-emergency-fund-retirement-illustration.png?resize=768%2C293&amp;ssl=1 768w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></figure>



<p>According to <a href="https://www.bankrate.com/banking/savings/financial-security-march-2019/">Bankrate</a>, 21% of Americans don’t save <em>any</em> of their annual income.</p>



<p>On the contrary, “Four in 10 identify themselves as aggressive short-term savers, where they excel at putting money aside for a specific purpose, like a trip or wedding, but aren’t consistently setting aside money for the future.” (<a href="https://www.marketwatch.com/story/this-is-why-americans-dont-save-even-when-they-know-better-2019-02-25">MarketWatch</a>). </p>



<p>This shows that people are incentivized to save for tangible things.</p>



<p>Taking in those insights, we can apply the psychological trick of chunking: <br><strong>Simplify things by breaking them down I into digestible chunks. </strong></p>



<h3>How the Future Self Savings Method works </h3>



<p>Here’s what I found more motivating: <strong>buy myself one future month at a time.</strong> A rough calculation:</p>



<ol><li>Figure out monthly expenses. (I use the last 12 months’ average)</li><li>Pad that number by 10-20%</li><li>Every time you save that number, you’ve bought your future self a month!</li></ol>



<p>Let’s mull over that last point. </p>



<blockquote><p>Every time you save a month’s worth of expenses, you’ve bought your future self a month of freedom.</p></blockquote>



<div><p>Say that your average living expenses is $3000.</p><p>Because we can’t predict inflation or how the value of the dollar will change, let’s pad that amount by 20%. </p></div>



<p>$3000 x 1.2 = $3600. </p>



<p>Now, every time you save $3600, you just bought your future self another month of worry-free expense.  </p>



<h3>The psychology of earning “financially free” months</h3>



<p>What would it take to <strong>buy yourself a year of freedom? </strong></p>



<p>Using our previous illustration, that’d look like $3000 x 1.2 x 12 = <strong>$43,200</strong>.</p>



<p>For about the cost of a new car, you can buy yourself 1 year of freedom to being a digital nomad, try starting a small business, or explore a career change. </p>



<div><figure><img loading="lazy" width="960" height="533" src="https://i1.wp.com/ozchen.com/wp-content/uploads/future-self-savings-method-vacation-fund-calendar-budget.png?resize=960%2C533&amp;ssl=1" alt="" srcset="https://i1.wp.com/ozchen.com/wp-content/uploads/future-self-savings-method-vacation-fund-calendar-budget.png?w=1355&amp;ssl=1 1355w, https://i1.wp.com/ozchen.com/wp-content/uploads/future-self-savings-method-vacation-fund-calendar-budget.png?resize=768%2C427&amp;ssl=1 768w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></figure></div>



<p>It’s fun to model out: <em>how fast can I buy myself future months?</em> </p>



<p>Say that someone takes home $6000 a month after taxes, and sets her “future self month expenses” at a generous $3600. If she divide that budget by income, and multiply by 12, she would arrive at the number of months it takes to earn 1 year off. </p>



<figure><img loading="lazy" width="946" height="378" src="https://i2.wp.com/ozchen.com/wp-content/uploads/build-freedom-fund-calculation.jpg?resize=946%2C378&amp;ssl=1" alt="" srcset="https://i2.wp.com/ozchen.com/wp-content/uploads/build-freedom-fund-calculation.jpg?w=946&amp;ssl=1 946w, https://i2.wp.com/ozchen.com/wp-content/uploads/build-freedom-fund-calculation.jpg?resize=768%2C307&amp;ssl=1 768w" sizes="(max-width: 946px) 100vw, 946px" data-recalc-dims="1"><figcaption>( Free month number / Take home income ) x 12 = The number of months it takes to earn 1 year off</figcaption></figure>



<p>Obviously it can be difficult to save that much money (that’s a 60% savings rate). But this type of illustration can be another guidepost in figuring out personal budgets, salary raises, or just aspirational numbers for increasing income and decreasing expenses. </p>



<p><strong>Imagine that for every month you work, you’ve earned yourself a free future month</strong>. </p>



<p>Now imagine that for every month you work, you’ve earned yourself <strong>two</strong> future months. Whoa!</p>



<p>This idea becomes even more powerful when combined with decreasing expenses and investing your money.</p>



<p>That’s why I think saving for  <strong>financially free months</strong> is a powerful idea. </p>



<h3>Not an emergency fund, but a Freedom fund.</h3>



<p>You might be thinking: “isn’t this just an emergency fund?” </p>



<p>A freedom fund just extends the idea of an emergency fund for aspirational purposes. </p>



<p>If you’re like me and don’t want to live a “deferred life” (nod to Tim Ferriss), then the Future Self Savings Method may be an motivating idea. </p>



<figure><blockquote><p><strong>Deferred life plan: </strong><br>Work your ass off for decades, then enjoy that money when you’re less able to</p><cite>YEAH, NO THANKS</cite></blockquote></figure>



<p>The Future Self Savings Method has the subtle effect of reorienting my relationship with money:</p>



<blockquote><p>[BEFORE] “How much money do I want to save?” </p><p>[AFTER] “How much <strong>time</strong> do I want to make?” </p></blockquote>



<p>Now, instead deferring my life decades out, I can more confidently plan on the order of months and years.</p>



<p><strong>How much much freedom do you want to have saved?</strong></p>



<hr>



<p><em>Afterwords</em></p>



<p>I haven’t studied the FIRE (financially independent, retire early) movement that closely. Maybe this is just the same thing. </p>



<p>This article may feel the most relatable to those making $75k and beyond. But I think the Future Self Savings Method is still a lot more actionable than “I want to be rich / a millionaire someday” </p>



<p>This reorients my relationship with money from “How much money do I want to save?” to “How much free time do I want in the future?” </p>



<p>Saving for a rainy day and setting yourself up with a safety net <em>is</em> crucial, especially when you consider that nearly <a href="https://www.washingtonexaminer.com/news/nearly-half-americans-live-paycheck-to-paycheck-bank-survey">half of Americans live paycheck to paycheck</a>, and more than half do not have an emergency fund that can cover 3 months of expenses. That became devastatingly clear when Covid hit and the government starting sending out $1200 checks. </p>



<p>But psychologically, an emergency fund is not that motivating. Backup plans are important, but doesn’t create aliveness.</p>


		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article></div>]]>
            </description>
            <link>https://ozchen.com/future-self-savings-method/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934679</guid>
            <pubDate>Thu, 29 Oct 2020 19:37:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't contribute anything relevant in web forums]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24934569">thread link</a>) | @todsacerdoti
<br/>
October 29, 2020 | https://karl-voit.at/2020/10/23/avoid-web-forums/ | <a href="https://web.archive.org/web/*/https://karl-voit.at/2020/10/23/avoid-web-forums/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<ul>
<li>Updates
<ul>
<li>2020-10-25 Comment by Erik</li>
</ul></li>
</ul>

<p>

If you're, for example, contributing to a <a href="https://en.wikipedia.org/wiki/Reddit">reddit</a> thread about something which is irrelevant or anything with only a short-term relevance, this article does not apply to you right now.

</p>

<p>

However, as soon as you're helping somebody solving an interesting issue, summarize your experiences with something or write anything that might be cool to be around in a couple of years as well, you do provide potential high-value content. My message to all those authors is: <b>don't use web-based forums</b>.

</p>

<p>

TL;DR: all of the content of closed, centralized services will be lost in the long run. Choose the platform you contribute to wisely now instead of learning through more large data loss events later-on.

</p>

<p>

The longer version is worth your time:

</p>

	  <header><h2>What Do I Mean With Web-Based Forums Here?</h2></header>

<p>

In this article, I'm using the term "web-based forums" as an umbrella term for closed, centralized services like <a href="https://en.wikipedia.org/wiki/Reddit">Reddit</a>, <a href="https://en.wikipedia.org/wiki/Hacker_News">Hacker News</a>, <a href="https://en.wikipedia.org/wiki/Slashdot">Slashdot</a>, Facebook, or any other web-based forum where you are able to add comments, articles, and so forth in most cases only after creating an account.

</p>

<p>

Typically, those services don't provide any possibility to extract or synchronize content. They don't offer open APIs that allow users to choose among different and open user interfaces. They are owned and operated by private companies.

</p>

<p>

Please note that when I'm going to mention more or less only reddit as an example in the next sections, this is because reddit is the only web-based forum <a href="https://www.reddit.com/user/publicvoit">I'm familiar with</a> to a certain level. This does not mean that reddit is worse than other closed, centralized web-based forums. Not at all.

</p>

	  <header><h2>So What's the Issue With Web-Based Forums?</h2></header>

<p>

There is not one issue. There are several things where web-based forums don't qualify for being a platform for quality content. Let's take a look at some of them.

</p>

<p>

I'm glad you're still reading this article and I hope you bear with me until the end of it. Most people will realize and learn about having contributed lots and lots of high-value information only when platforms are down for good. And this is what makes me really sad. It is just like you know that one building of the Library of Alexandria is going to burn down in a few years and people still bring many unique copies of high-quality books into its shelves, unaware of destroying knowledge this way.

</p>

	  <header><h3>Issue: No Backup, No Distribution</h3></header>

<p>

For reasons and examples stated <a href="https://karl-voit.at/cloud">in this article</a>, any centralized web-based service will go offline some day. Some sooner, some later. Popularity is not even a guarantee that a service gets continued, as you can see with <a href="https://killedbygoogle.com/">hundreds of (partly) very well known and used Google services that were shut down</a>. Nothing will be on the web forever. Most people are not aware of this fact. The books set on this machine are more likely to survive history than all of your reddit/Facebook/... contributions:

</p>

<figure>
<img src="https://karl-voit.at/2020/10/23/avoid-web-forums/2019-10-05T22.56.47%20Buchdruckmuseum%20-%20Linotype%20-%20Tastatur%20--%20cliparts%20typography%20history%20publicvoit%20-%20scaled%20width%20630.jpg" alt="" width="630">
<figcaption>A Linotype machine.</figcaption>
</figure>

<p>

So when you begin to be aware of this fact, you might want to think of things you can do to mitigate data loss when services are discontinued or "sunrized" as some marketing experts say.

</p>

<p>

You could, for example, back-up the data of this service. By providing the information on multiple servers, chances are high that not all of them are lost at the same time.

</p>

<p>

This requires certain properties. For example, you need to be able to duplicate the service on multiple servers. To be able to do so, you'll need not only the data but also the software that is providing access to the service. When different organization are running mirrored servers, it is required to openly share the data and software. This can be ensured by using Open Source software or at least open APIs and a business model that does not rely on keeping data and technical things a secret.

</p>

<p>

All major commercial services such as reddit, Facebook and so forth keep everything a secret that is not ultimately necessary to use their services. Their software is a secret, they don't offer open APIs or only very crippled ones, you don't have the possibility to get to the raw data. So no luck there. You do have <a href="https://en.wikipedia.org/wiki/Vendor_lock-in">a lock-in situation</a>.

</p>

<figure>
<img src="https://karl-voit.at/2020/10/23/avoid-web-forums/2020-10-23%20Oatmeal_-_reaching_people_on_the_internet%20--%20publicvoit%20-%20scaled%20width%20630.png" alt="" width="630">
<figcaption>https://theoatmeal.com/comics/reaching_people</figcaption>
</figure>

<p>

Even with personal blogs, "fragile" as they are, you are able to use the <a href="https://archive.org/web/">Wayback Machine of the Internet Archive</a> to back up your blog. For example, every page on my blog contains a link to its archive in the page footer. This ensures that you can not only browse the latest version of all of my blog articles in case of a server breakdown. This also enables you to browse all previous version, probably changed over time. Go ahead, try a few "Archive" links of my articles. If any of my articles start with an "Updates:" section, you know for sure that there are older versions accessible via the Internet Archive.

</p>

<p>

The Wayback Machine does not archive reddit threads. It can not properly back up Facebook pages. <a href="https://help.archive.org/hc/en-us/articles/360004651732-Using-The-Wayback-Machine">It's blinded by corporate secrecy</a> when it comes to archive content for the upcoming generations:

</p>

<blockquote>Why isn't the site I'm looking for in the archive?<br>
Some sites may not be included because the automated crawlers were
unaware of their existence at the time of the crawl. It's also
possible that some sites were not archived because they were password
protected, blocked by robots.txt, or otherwise inaccessible to our
automated systems. Site owners might have also requested that their
sites be excluded from the Wayback Machine.</blockquote>

<p>

Summarizing the things mentioned above: without very good support for data export, service duplication, open standards, any content you provide in closed web-based services will be lost just as <a href="https://www.nytimes.com/2019/03/19/business/myspace-user-data.html">MySpace already lost twelve years of content just so</a>, just to mention one big example.

</p>

	  <header><h3>Issue: User Interface Dictatorship</h3></header>

<p>

When you grew up only knowing centralized web-based forums, you can not imagine the many advantages of having the freedom to choose your preferred user interface. While some people might think this is a minor issue, let me explain a few examples where this makes a huge difference.

</p>

<p>

The first example starts with something that might only annoy people. With comments like on <a href="https://www.reddit.com/r/emacs/comments/hfamm7/those_who_have_tried_out_multiple_zettelkasten/fvx9vu5/">this thread</a>, you clutter up other people's interface for personal gain. It's selfish and distracts from the information consumption.

</p>

<p>

The reason why people are using such reminder bots is multi-fold. First, they don't use a proper todo management system that would be able to remind them to read a certain article in a few days. They externalize this inability to the web-based forum and all of its other users. <a href="https://karl-voit.at/tags/pim">I'm working on fixing these educational issues</a>. Secondly, there is no way to have features that you can use that do not affect other people's interface.

</p>

<p>

Consider people with visual impairment do have special needs. <a href="https://tinyurl.com/y6ncgvjt">The WHO reports</a> an estimate of 285 million people that do are visually impaired, ninety percent of them living in developing countries. Those are not numbers you can simply ignore. It is obvious that they do need different kind of interfaces. Either they have to use a high-contrast interface, highly unusual interface scaling factors, an interface that avoids certain color combinations, text-to-speech systems or <a href="https://en.wikipedia.org/wiki/Braille#Braille_reading">Braille readers</a> that are able to extract the content properly.

</p>

<p>

If a web-based services that - remember from before - does not offer proper open APIs and which does not implement said features, all those people simply can not participate and you can not profit from their knowledge and experience.

</p>

<p>

And even when you think that this is just a minority I can provide examples where everybody profits from choosing his or her own interface.

</p>

<p>

Some services are providing interfaces that aren't working properly on small displays or mobile devices in general. In these cases, without any ability to switch to an alternative app or web-page, you are locked out even with perfect eyesight.

</p>

<p>

When you're using an web-based forum that does not provide the feature that already read articles are marked or collapsed, you need to skim though a thread completely and re-read content to find out new postings when re-visiting the thread after a while. Our time should not spent on senseless tasks like this.

</p>

<p>

Alternative interfaces might provide advanced rating features based on your personal taste and choice so that you are able to filter out the most relevant articles easily and do not clutter your view with irrelevant articles at all. This is also called "scoring". It can be based on keywords, the amount of personal contributions to a longer thread, friendship relationships from your contact management, and so forth.

</p>

<p>

Some people prefer navigating using the keyboard. Either by personal taste or by physical restrictions. If the web-based centralized service only supports mouse-based navigation, you can not use this service.

</p>

<p>

I could continue with examples like that. The common theme is: when one particular centralized web-based forum is not implementing all of those nice features you need or like, you can not use them properly.

</p>

	  <header><h3>Issue: Rule Monopoly and Subjective Censorship</h3></header>

<p>

When you do live in a society with certain set of (legal) rules, providers of relevant web-based forums have to follow and enforce some of them. However, the issue is that this kind of censorship is and will always be related to a particular culture and society at a specific time.

</p>

<p>

For example, in Germany and Austria, being a <a href="https://en.wikipedia.org/wiki/Nazism">Nazi</a> is punishable by law. In the USA, freedom-loving people think fans of the human monsters that tortured and murdered millions of Jews in the Second World War need the possibility to express their personal "opinion". As you can see, there is a different point of view in-between the lines when I write about Nazis compared to an author from the USA who values "freedom of speech" higher than "being a die-hard fan of mass murders". It's a very difficult topic you can not enforce with a world-wide service.

</p>

<p>
</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://karl-voit.at/2020/10/23/avoid-web-forums/">https://karl-voit.at/2020/10/23/avoid-web-forums/</a></em></p>]]>
            </description>
            <link>https://karl-voit.at/2020/10/23/avoid-web-forums/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934569</guid>
            <pubDate>Thu, 29 Oct 2020 19:27:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[J2 open processor: a clean-room open-source processor using the SuperH ISA]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24934474">thread link</a>) | @beefhash
<br/>
October 29, 2020 | https://www.j-core.org/index.html | <a href="https://web.archive.org/web/*/https://www.j-core.org/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p><a href="#intro">Intro</a> <a href="#what">What is it</a>
<a href="#quick">Quick start</a>,

<a name="intro">
</a></p><h2><a name="intro">J2 open processor</a></h2><a name="intro">

</a><p><a name="intro">J-core is a clean-room open source processor and SOC design using the
</a><a href="http://www.shared-ptr.com/sh_insns.html">SuperH instruction set</a>,
implemented in VHDL and available royalty and patent free under a <a href="https://www.j-core.org/jcore-license.txt">BSD license</a>.</p>

<p>The rest of this page explains how to compile and install a "bitstream" file
to implement this processor in a cheap (about $50)
<a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGA</a>
board, then how to build Linux for that board and boot it to a shell prompt.</p>

<p>The steps are (roughly):</p>

<ul>
<li><a href="#get_hardware">Get an FPGA board</a> (the cheapest option
we've written a build target for is the Numato Mimas v2).</li>
<li><a href="#download_bitstream">Download a bitstream</a> (or build one
yourself from our VHDL source code).</li>
<li><a href="#flash_bitstream">Flash the bitstream to onboard SPI flash</a>
(via USB).</li>
<li><a href="#vmlinux">Download vmlinux</a> (or build Linux yourself from
source) and copy it to an sdcard.</li>
<li><a href="#serial">Boot the board</a> connected to a serial terminal
(also via USB) to a Linux shell prompt.</li>
</ul>

<a name="what">
<h3>What is this processor?</h3>

</a><p><a name="what">The </a><a href="https://en.wikipedia.org/wiki/SuperH">SuperH processor</a>
is a Japanese design developed by Hitachi in the late 1990's. As a second
generation hybrid RISC design it was easier for compilers to generate good
code for than earlier RISC chips, and it recaptured much of the code density
of earlier CISC designs by using fixed length 16 bit instructions (with
32 bit register size and address space), using microcoding to allow
some instructions to perform multiple clock cycles of work. (Earlier pure
risc designs used one instruction per clock cycle even when that served
no purpose but to make the code bigger and exhaust the encoding space.)</p>

<p>Hitachi developed 4 generations of SuperH.
SH2 made it to the United states in the Sega Saturn game console, and
SH4 powered the Sega Dreamcast. They were also widely used in areas outside
the US cosumer market, such as the japanese automative industry.</p>

<p>But during the height of SuperH's development, the
<a href="https://en.wikipedia.org/wiki/1997_Asian_financial_crisis">1997 asian economic crisis</a> caused Hitachi to tighten its belt, eventually
partnering with Mitsubishi to spin off its microprocessor division
into <a href="http://www.hitachi.us/press/archive/10032002">a new company</a>
called "Renesas". This new company did not inherit the Hitachi
engineers who had designed SuperH, and Renesas' own
<a href="https://en.wikipedia.org/wiki/SuperH#SH-5">attempts at further
development on SuperH</a> didn't even interest enough customers for the result
to go ito production. Eventually Renesas moved on to new designs it had
developed entirely in-house, and SuperH receded in importance to them...
until the patents expired.</p>

<p>Then Jeff Dionne (a hardware engineer who wandered into Linux long enough
to create the <a href="http://www.uclinux.org/">uClinux</a> project back in
the 1990's, handing it off when he moved to Japan and went back to
hardware in 2003) created a new processor design compatible with the
SuperH instruction set, publicly releasing the first version under a BSD
liense in 2015. This new design is called j-core instead of superh because the
trademarks haven't expired.</p>

<p>The first j-core generation, j2, is compatible with the
<a href="https://en.wikipedia.org/wiki/SuperH#SH-2">sh2</a> instruction set,
which means Linux and gcc and such required only minor tweaking to support
this processor. Current linux, gcc, binutils, and
musl-libc versions support j-core out of the box. (QEMU supports sh4,
which is backwards compatible with sh2 userspace but requires its own
kernel.)</p>

<p>J2 adds two backported sh3 barrel shift instructions (SHAD and SHLD)
to improve compiler efficiency, and a new cmpxchg
(mnemonic CAS.L Rm, Rn, @R0 opcode 0010-nnnn-mmmm-0011,
based on the IBM 360 instruction) for futexs and SMP. Support for these
is already upstream in vanilla Linux and gcc/binutils (linux
"make ARCH=sh j2_defconfig" and gcc "./configure
--target=sh2eb-linux-muslfdpic --with-cpu=mj2").</p>

<p>In 2015 the j-core developers gave an <a href="http://events.linuxfoundation.org/sites/events/files/slides/Turtles%20all%20the%20way.pdf">introductory presentation</a> about it at Linuxcon Japan, which was
<a href="https://lwn.net/Articles/647636/">covered by Linux Weekly News</a>.
In 2016 the developers gave a j-core design walkthrough presentation at ELC
(<a href="https://www.j-core.org/talks/ELC-2016.pdf">slides</a>, <a href="https://www.youtube.com/watch?v=lZGHbMS882w">video</a>).</p>

<p>J2 is a nommu processor because sh2 (the processor in the Sega Saturn
game console) was, and the last sh2 patent expired in October 2014.
The sh4 processor (dreamcast) has an mmu, but the last sh4 patents don't
exire until 2016. (Update: we're probably implementing a
<href=http: lists.j-core.org="" pipermail="" j-core="" 2017-march="" 000558.html="">simpler MMU design
which will run the same userspace software but require kernel and QEMU
updates, which we'll submit upstream when ready.)</href=http:></p>

<p>J-core's design is small and simple. As open source hardware it can be
manufactured cheaply (about 3 cents per processor) and audited for NSA
backdoors or
<a href="http://www.theregister.co.uk/2015/08/12/lenovo_firmware_nasty/">vendor
backdoors</a> or
<a href="http://hothardware.com/news/researchers-discover-rootkit-exploit-in-intel-processors-that-dates-back-to-1997">exploitable firmware bugs</a>,
and allows systems built without hidden extra processors in things like
<a href="http://s3.eurecom.fr/~zaddach/docs/Recon14_HDD.pdf">storage devices</a>
and <a href="http://arstechnica.com/security/2014/07/this-thumbdrive-hacks-computers-badusb-exploit-makes-devices-turn-evil/">USB controllers</a>
easily repurposed into spyware.</p>

<p>The <a href="http://lists.j-core.org/">j-core mailing
list</a> is the best place for further information or to ask questions.</p>

<a name="quick">
<h3>Quick start on hardware</h3>

<p>The theory is you flash a "bitstream" file into an FPGA board's onboard
SPI flash to configure the FPGA to act like a j2 processor. This
bitstream includes a small bootloader that attempts to load a file called
"vmlinux" from an sd card, providing a linux kernel with root filesystem
in initramfs using a serial console.</p>

<p>To do this, you need an FPGA board, microsd card, bitstream, vmlinux
file with bundled initramfs, an sdcard writer, and a computer with a
USB connection (to write the SPI flash and connect to the serial console;
we used a Linux laptop but macs work too).</p>

<h4 id="get_hardware">1) Get some hardware.</h4>
</a><ul><a name="quick">
</a><li><a name="quick"></a><p><a name="quick"><strong>Numato</strong>:
The cheapest usable FPGA development board ($50 US) the j2 build system
currently targets is the
</a><a href="http://numato.com/fpga-boards/xilinx/spartan6/mimas-v2-spartan-6-fpga-development-board-with-ddr-sdram.html">Numato Mimas v2</a>
(also available <a href="http://www.amazon.com/Numato-Mimas-Spartan-Development-Board/dp/B00RL7FCQW">on amazon</a>).
It contains a Xlinux "Spartan 6" LX9 FPGA that can run a J2 at 50mhz,
64 megs of SDRAM, USB2 mini-B, and a micro-sd card slot.</p>

<p>You will probably also need a USB mini-B cable (the kind playstation
controllers use, not the kind android phones use), a
<a href="http://www.amazon.com/s/?keywords=usb+sd+card+adapter">USB microsd
card adapter</a>, and a blank microsd card. The Numato has a builtin USB serial
converer, so its "serial port" is already USB. (This USB port can also power
the board, and Numato provides a python script that writes
bitstreams to the onboard SPI flash through it. Alas it's also hardwired
to operate at 19200 bps (there's a
<a href="http://langster1980.blogspot.com/2016/06/linux-on-mimas-v2.html">firmware
update to 115200</a> but numato
<a href="https://community.numato.com/threads/how-download-a-firmware-from-linux.130/">only provides a windows tool</a> to update it.)</p>
</li>
</ul>

<p>The main downsides of the Numato board (other than the slow serial port)
are that it doesn't have ethernet, and it can't do SMP. (A single instance
of the processor with the cache disabled takes up about 60% of an LX9's
capacity.) So as an upgrade we're working on the
<a href="https://www.j-core.org/turtle">Turtle Board</a>.</p>

<p>(J-core's early development was done on an
<a href="https://www.avnet.com/shop/us/p/kits-and-tools/development-kits/avnet-engineering-services-ade--1/aes-s6mb-lx9-g-3074457345628965461">avnet
microboard</a> but that's more expensive and doesn't have a built-in sdcard
reader, so needs an add-on board to boot Linux. You can find
<a href="https://tingcao.wordpress.com/category/lx9-microboard/">more
about that board here</a>. If you want to port j-core
to other FPGA boards, ask on the mailing list and we'll describe how or
write up more docs.)</p>

<p>The rest of this page describes using the Numato board.</p>

<h4 id="download_bitstream">2) Get/install a bitstream.</h4>

<p>The point of open hardware is that you can build a bitstream from
the VHDL source code, but for your initial smoketesting you probably
want to grab <a href="https://www.j-core.org/downloads/binaries/mimas_v2.bin">a known working
binary</a> and install that first.</p>

<p>To build your own bitstream from VHDL source:</p>

<ul>
<li><a href="https://www.j-core.org/bitcomp.html">Install the Xilinx
bitstream compiler</a></li>
<li><a href="http://landley.net/aboriginal/bin/cross-compiler-sh2elf.tar.gz">Install the sh2 bare metal compiler</a> (to build the ROM bootloader).
It doesn't require a specific install location, you can extract it into
your home directory if you like.</li>
<li>Download
the <a href="https://www.j-core.org/downloads/source/jcore-source-latest.tar.gz">latest
bitstream source</a></li>
<li>Enter xilinx context and add the cross-compiler-sh2elf/bin directory to
your $PATH so sh2elf-cc and friends are available, and cd into the bitstream
source directory.</li>
<li>Fix the toolchain prefix with: <code>sed -i 's/sh2-elf-/sh2elf-/g' $(grep -rl sh2-elf- .)</code>
[TODO: check this in]</li>
<li>Run <code>make mimas_v2</code>. (Other targets are available under targets/boards.)</li>
<li>Your bitstream should wind up in <code>output/*/mimas_v2.bin</code>. [TODO: why the
date directory? That's not how package builds work, have output, overwrite
output when you rebuild. And make clean not deleting this? Really?]</li>
</ul>

<p>The reason the bare metal compiler is different from the
<a href="http://landley.net/aboriginal/bin/cross-compiler-sh2eb.tar.gz">sh2
Linux compiler</a> (other than not containing a C library) is different
function prefixes. Since low level code like the ROM bootloader (which runs
when the processor starts up and loads vmlinux off the sdcard) is written
in assembly, it manually refers to prefixed function names. Although there
is a command line option to change the prefixes, the compiler contains library
code (such as libgcc.a) that has to match the calling conventions of the
rest of the code.</p>

<h4 id="flash_bitstream">3) Flash the bitstream to the board.</h4>

<p>Numato
<a href="https://github.com/numato/samplecode/raw/master/FPGA/MimasV2/tools/configuration/python/MimasV2Config.py">provides</a>
a GPL-licensed python3 tool to flash bitstreams onto their board.
[TODO: port to python 2]</p>

<p>To use it:</p>
<ul>
<li>Nobody ever has python 3 installed, so:
<code>apt-get install python3 python3-serial</code></li>
<li>Flip the black switch on the board (between the VGA and USB ports)
towards the USB side. This is the "flash" position.</li>
<li>Connect the board to your Linux box with a USB mini-B cable. (The
kind playstation controlers use, not the kind android phones use.)</li>
<li><code>sudo python3 MimasV2Config.py /dev/ttyACM0 mimas_v2.bin</code></li>
<li>Flip the switch back towards the VGA side. This is the "boot" position.</li>
</ul>

<p>The above assumes the Numato serial port shows up as <code>/dev/ttyACM0</code>,
which is almost always the case.</p>

<p>Note: <strong>Ubuntu 14.04</strong> decided that any serial device plugged into
a post-2014 computer MUST be a modem (a type of hardware used with telephone
land lines back in the 20th century), and have a hotplug daemon send
random AT commands at any new serial device, which confuses the Numato
firmware loader. If you are not particpating in the Great Modem Revival,
you need to <code>sudo service modemmanager stop</code>.
See <a href="http://community.numato.com/threads/solved-mimas-v2-programming-in-linux.15/page-2#post-186">here</a> for details.</p>

<h4 id="serial">4) Hook up a serial console.</h4>

<p>Nomato's serial port implementation only connected data send and receive
lines, meaning it doesn't provide hardware flow control. This confuses terminal
programs that expect RTS and CTS (let alone DTR or DSR). We can use the stty
tool to tell Linux not to care, then use a simple terminal program that
won't try to fiddle with this itself.</p>

<p>Since the <code>/dev/ttyACM0</code> device goes away each time you unplug and
replug the USB cable (which conveniently power cycles the board),
we can combine these two commands into a single command line in the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.j-core.org/index.html">https://www.j-core.org/index.html</a></em></p>]]>
            </description>
            <link>https://www.j-core.org/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934474</guid>
            <pubDate>Thu, 29 Oct 2020 19:20:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A12 – Advancing Network Transparency on the Desktop]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24934296">thread link</a>) | @todsacerdoti
<br/>
October 29, 2020 | https://arcan-fe.com/2020/10/28/a12-advancing-network-transparency-on-the-desktop/ | <a href="https://web.archive.org/web/*/https://arcan-fe.com/2020/10/28/a12-advancing-network-transparency-on-the-desktop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<p>This article is is the main course to the appetiser that was <a href="https://arcan-fe.com/2018/11/16/the-x-network-transparency-myth/">The X Network Transparency Myth</a> (2018). In it, we will go through how the pieces in the Arcan ecosystem tie together to advance the idea of network transparency for the desktop and how it sets the stage for a fully networked desktop.</p>



<p>Some of the points worth recalling from the X article are:</p>



<ol><li>‘transparency’ is evaluated from the perspective of the user; it is not even desirable for the underlying layers to be written so that they operate the same for local rendering as they would across a network. The local-optimal case is necessarily different from the remote one, the mechanisms are not the same and the differences will keep on growing organically with the advancement of hardware and display/rendering techniques.</li><li>side-band protocols splitting up the desktop into multiple IPC systems for audio, meta, fonts, … increases the difficulty to succeed with anything close to a transparent experience, as the network layer needs to take all of these into consideration as well as trying to synchronise them.</li></ol>



<p>To add a little to the first argument: it should also not be transparent to the window manager as some actions have drastically different impact on the user interface side to security and expectations. For example, Clipboard/DND locally is not (supposed to be) a complicated thing. When applied across a network, however, such things can degrade the experience for anything else. Other examples is that you want to block some sensitive inputs from being accidentally forwarded to a networked window and so on, it has happened in the past that the wrong sudo password has, indeed, been sent to the wrong ssh session.</p>



<p>This target has been worked on for a long time, as suggested by this part from the <a href="https://www.youtube.com/watch?v=3O40cPUqLb">old demo</a> from 2012/2013. Already back then the drag/slice to compose-transform-and-share case exposed out of compositor sharing and streaming; something that only now is appearing elsewhere in a comparably limited form.</p>



<p>We are on the third or fourth re-implementation of the idea, and the first one that is considered having a good enough of a design to commit to using and building upon. There are many fascinating nuances to this problem that only appear when you ‘try to go to 11’.</p>



<p>As per usual, parts of this post will be quite verbose and technical. Here are some shortcuts to jump around so that you don’t lose interest from details that seem irrelevant to you.</p>



<ul><li><a href="#primitives">Basic primitives: Arcan-net, A12 and SHMIF</a></li><li><a href="#usecases">Example Usecases</a></li><li><a href="#protocol">Protocol State and Development</a></li><li><a href="#explained">Demo Explained</a></li></ul>



<h2 id="demo">Demos</h2>



<p>Starting with some short clips of the development progress – and then work through the tools and design needed to make this happen. It might be short, but there is a whole world of nuance and detail to it.</p>



<p>(~early 2019) – forced compression, OSX viewer, (bad) audio:</p>



<figure></figure>



<p>Composited Xarcan (desktop to pinephone), compression based on window type:</p>



<figure><p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/CIWZdEkgPfM?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</p></figure>



<p>Here is a native arcan client with crypto, local GPU “hot-unplug” to software rendering handover and compression negotiation (h264):</p>



<figure><p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/_RSvk7mmiSE?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</p></figure>



<p>Here is ‘server-side’ text rendering of text-only windows, font, style and size controlled by presenting device — client migrates back when window is closed:</p>



<figure></figure>



<p><span>In the videos, you can see (if you squint) instances of </span><em>live migration</em><span> between display servers over a network, with a few twists. For example, the decorations, input mapping, font preferences and other visuals change to match the machine that the client is currently </span><em>presenting</em><span> on and that audio also comes along, because </span><a href="https://arcan-fe.com/2017/10/05/awk-for-realtime-multimedia/">Arcan does multimedia</a><span>, not only video. </span></p>



<p><span>What is less visible is that the change in border colour, a security feature in </span><a href="http://durden.arcan-fe.com/">Durden</a><span>, is used to signify that the window comes from a networked source, a property that can also be used to filter sensitive actions. The neo-vim window in the video even goes so far as to have its text surfaces rendered server side, as its </span><a href="https://github.com/letoram/nvim-arcan">UI driver</a><span> is written using our terminal-protocol liberated </span><a href="https://github.com/letoram/arcan/wiki/TUI">TUI API.</a> This is also why the font changes; it is the device you&nbsp;<em>present</em> on that defines visuals and input response, not the device you run the program on.</p>



<p>Also note how the clients “jumps” back when the window is closed on the remote side; this is one of the many payoffs from having a systemic mindset when it comes to&nbsp; ‘<a href="https://arcan-fe.com/2017/12/24/crash-resilient-wayland-compositing/">crash resilience</a>‘ – the IPC system itself is designed in such a way that <em>necessary</em> state can b<span>e reconstructed and&nbsp;</span><em>dynamic</em><span>&nbsp;state is tracked and renegotiated when needed. The effect is that a client is forcefully detached from the current display server with the instruction of switching to another.</span> The keystore (while a work in progress) allows you to define the conditions for when and how it jumps to which machines and picks keys accordingly.</p>



<p>That dynamic state is tracked and can be renegotiated as a ‘reset’ matters on the client level as well, the basic set of guaranteed features when a client opens a local connection roughly generalises between all imaginable window management styles. Those that are dynamically (re-) negotiated cannot be relied upon. So when a client is migrated to a user that has say, accessibility needs, or is in a <a href="https://arcan-fe.com/2018/03/29/safespaces-an-open-source-vr-desktop/">VR environment</a>, the appropriate extras gets added when the client connects there, and then removed when it moves somewhere else. This is an essential primitive for network transparency as a collaboration feature.</p>



<h2 id="primitives">Basic Primitives: Arcan-net, SHMIF and A12</h2>



<p>There are three building blocks in play here, a tool called <em>arcan-net&nbsp;</em>which combines the two others:&nbsp;<em>A12</em> and <a href="https://github.com/letoram/arcan/wiki/SHMIF">SHMIF</a>.</p>



<p>A12 is a <span>‘work in progress’ protocol – it’s not </span><em>the</em><span>&nbsp;</span><a href="https://www.x.org/wiki/Development/X12/">X12</a><span> that some people called for, but it’s “</span><em>a”</em><span> twelve. It strives to be remote optimal – compression tactics based on connectivity, content type and context of use, deferred (presentation side) rendering with data-native representation when possible (pixel buffers as a last resort, not the default); support caching of common states such as fonts; handle cancellation of normally ‘atomic’ operations such as clipboard cut and paste and so on.</span></p>



<p>SHMIF is the IPC system and API used to work with most other parts of Arcan. It is designed to be locally optimal: shared memory and system ABI in lock free ring-buffers preferred over socket/pipe pack/unpack transfers; minimal sustained set of system calls needed (for least-privilege sandboxing); resource allocations on a strict regimen (DoS prevention and exploit mitigation); fixed based set of necessary capabilities and user-controlled opt-in for higher level ones.</p>



<p><span>SHMIF has a large number of features that were specifically picked for correcting the wrongs done to X- like network transparency by the gradual introduction of side-bands and good old fashioned negligence. Part of this is that <em>all necessary and sufficient data exchange</em> used to compose a desktop goes over <em>the same</em> IPC system — one that is free of unnecessary Linuxisms to boot. While it would hurt a bit and take some effort, there are few stops for packing our bags and going someplace else, heck it used to run on Windows and still works on OSX. Rumour has it there are iOS and Android versions hidden away somewhere.</span></p>



<p><span>Contrast this with other setups where you need a large weave of IPC systems to get the same job done; Wayland for video and some input and some metadata; PulseAudio for audio; PipeWire for some video and some audio; D-Bus for some metadata and controls; D-Conf for some other metadata; Spice/RFB(VNC)/RDP for composited desktop sharing; Waypipe for partial Wayland sharing, X11 for partial X / XWayland sharing: SSH+VT***+Terminal emulator for CLI/TUI and less unsafe Waypipe / X11 transport; Synergy for mouse and keyboard and clipboard and so on. Each of these with their own take (or lack thereof) on authentication and synchronization, implementing many of the most difficult tasks again and again in incompatible ways yet still end up with features missing and exponentially more lines of code when compared to the solution here.</span></p>



<p>Back to Arcan-net. It exposes an a12 server and an a12 client, as well as acting as a shmif server, a shmif client and taking care of managing authentication keys. In that sense it behaves like any old network proxy. While not going too far into the practical details, showing off some of the setup might help.</p>



<p>On the active display server side:</p>



<pre>void@123.213.132.1# arcan-net -l 31337</pre>



<p>This will listen for incoming connections on the marked port, and map them to the currently active local connection point. <span>To dive further into the connection point concept, either read the comparison between </span><a href="https://arcan-fe.com/2018/10/17/arcan-versus-xorg-approaching-feature-parity/">Arcan vs Xorg</a><span> or simply think ‘Desktop UI address’; The WM exports named connection points and assigns different policies based on that.</span></p>



<p><span>On the client side we can have the complex-persistent option that forwards new clients as they come:</span></p>



<pre><em>arcan-net</em> -s <em>netdemo</em> <em>123.213.132.1 31337</em><br>ARCAN_CONNPATH=netdemo one_arcan_client &amp;<br>ARCAN_CONNPATH=netdemo another_arcan_client &amp;</pre>



<p>Or the one-time simpler version which forks/exec arcan-net and inherits the connection primitive needed to setup a SHMIF connection:</p>



<pre>ARCAN_CONNPATH=a12://keyid@host:port one_arcan_client</pre>



<p>Or, and this is important for understanding the demo, an api function through the WM:</p>



<pre>target_devicehint(client_vid,"a12://keyid@", true)</pre>



<p>This triggers the SHMIF implementation tied to the window of a client to disconnect from the current display server connection, connect to a remote one through arcan-net, then tell the application part of the client to rebuild essential state as the previous connection has, in a sense, ‘crashed’. The same mechanism is then used to define a fallback (‘should the connection be lost, go here instead’). This is the <em>self-healing</em> aspect of proper <em>resilience</em>.</p>



<p>There are WM APIs for all the possible network sharing scenarios so it can be handled as user interfaces without any command line work.</p>



<p>I mentioned ‘authentication’ before, where is that happening? So this is another part of the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arcan-fe.com/2020/10/28/a12-advancing-network-transparency-on-the-desktop/">https://arcan-fe.com/2020/10/28/a12-advancing-network-transparency-on-the-desktop/</a></em></p>]]>
            </description>
            <link>https://arcan-fe.com/2020/10/28/a12-advancing-network-transparency-on-the-desktop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934296</guid>
            <pubDate>Thu, 29 Oct 2020 19:07:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Great Business: Advice You Won't Take (and Will Regret Not Taking)]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24934026">thread link</a>) | @rjyoungling
<br/>
October 29, 2020 | https://www.younglingfeynman.com/essays/advice | <a href="https://web.archive.org/web/*/https://www.younglingfeynman.com/essays/advice">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ba050bc6dcf9223f8459"><div><p>A while ago, I was talking to a founder of a startup. We were talking about his experience before and after finding product/market fit.</p><p>I asked him if he could boil down his experience into 1 piece of important advice I could share with The Younglings. He did.</p><p>But it was the way he said it, rather than what he said, that stuck with me.</p><p><em>His answer, because I don’t wanna leave you hanging, was that ‘you will overbuild and it will be a mistake’.</em></p><p>The way he said it was: ‘It is impossible to follow this advice but…’</p><p>That made me think of the advice I could give that I know is impossible to take yet true. The result of that is the essay you’re reading right now.</p><p><em>The irony that this essay is a list is not lost on me. My hatred for superficial business insider listicles has become a running joke. That said, I think this will be a worthwhile exception.</em></p><p>Let’s get right into it.</p><p>If you’re extremely ambitious, the prospect of the ‘disruptive innovation’ of an industry can seem daunting. Where do you even start?</p><p>I am not a big fan of TAM at all. VC’s (and other investors) are biased. They’ll give you self-serving advice. They want you to think big.</p><p><em>More on TAM in: </em><a href="https://www.younglingfeynman.com/essays/tam" target="_blank"><em>Should You Worry About TAM And SAM?</em></a></p><p>Why? Because they don’t care about you as an individual. You’re fungible. As long as of the 100 investments they make, a few become unicorns, that’s perfectly fine!&nbsp;</p><p>While I do think there’s a good case to be made for thinking big and solving the hardest problems on the planet, it’s actually incredibly rare for a founder to start there.</p><p>Take Elon Musk, for example. Tesla, SpaceX, The Boring Company, Neuralink, etc. All incredibly ambitious.</p><p>But his first company? A videogame when he was in his early teens. His first startup? A precursor to Google maps.&nbsp;</p><p>That’s all much more doable.</p><p>He even said in an interview that he probably wouldn’t have been able to start with SpaceX and that he advises against starting with a company that is that capital intensive.&nbsp;</p><p><em>I’ve been unable to find the source. I’ll continue to search for the video on YouTube and I’ll add it to the references if I find it.</em></p><p>In fact, I don’t know of a single founder that started their company with this huge vision. What usually happens is lying. Founders (or PR) will whitewash their history ex-post facto.</p><p>Something that <a href="https://mashable.com/article/mark-zuckerberg-lying-about-facebook/?europe=true" target="_blank">Zuckerburg was recently called out</a> for.</p><p>The Collinson brothers have often <a href="https://www.youtube.com/watch?v=9DUQ7_7Pj_c" target="_blank">pointed out that had they known Stripe would’ve been this hard, they might not have started it at all</a>.</p><p>So to come back to my question in the first paragraph, where do you even start?</p><p>With 1 person. You!&nbsp;</p><p>Think about a problem you have. Or think about something that you really want to see in the world.</p><p>Then try to see if there are other people like you.&nbsp;</p><p>Forget about scale. Forget about world domination. Forget about Fortune lists.&nbsp;</p><p>Focus on your tiny audience and just build something that improves their lives. According to them, not according to you.&nbsp;</p><p>Get to a point where they love it. Get to a point where they would be deeply sad if your solution went away.</p><p><em>More on architecting user love in: </em><a href="https://www.younglingfeynman.com/essays/deeplove" target="_blank"><em>Do You Have Customers Who Deeply Love You?</em></a></p><p><em>In case you’re suffering from a restless, intellectual brain that just can’t stop asking: ‘But how do I scale?’, the answer is: ‘Keep finding more people’. How much you make people’s lives better (on the X-axis) multiplied by a lot of people (on the Y-axis), is what’ll create a large business.</em></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1592418092968_20301"><div><p><em>Avoid the red bar, and start with the bright blue bar. Even if your company is already creating revenue, you might not have that bright blue bar… a small set of raving fans that absolutely love your product. Then grow that bright blue bar along the Y-axis. In theory, you could also grow the red bar along the X-axis to get the same surface area. In practice that never works out.</em></p><p>There are a small number of ‘non-obvious, capital intensive startups’ (to borrow <a href="https://en.wikipedia.org/wiki/Chamath_Palihapitiya" target="_blank">Chamath</a>’s lexicon).&nbsp;</p><p>In those cases, you probably can’t be profitable from the beginning.&nbsp;</p><p><em>Unless you’re very creative and have a long time horizon. For example, one might have been able to start Tesla by starting Boosted Boards, then launching into new categories until you eventually get to cars. Dyson did a similar thing from vacuums to hand dryers to fans to blow dryers to cars. </em><a href="https://www.bbc.com/news/business-50004184" target="_blank"><em>Unfortunately, they’ve announced they’re pulling out</em></a><em>.</em></p><p>But I believe most small businesses and startups should be profitable from the beginning and scale or hover just below profitability.</p><p>It’s a mistake to solely focus on growth in hopes of one day pulling the magical profitability lever and suddenly being profitable.</p><p>Hope makes for a poor business strategy and the reason you hear about Google is that it’s so rare. More often than not it just doesn’t work out. [1]</p><p>If you do decide to put growth over profitability, you should know your numbers and be clearly able to articulate why it’s a good idea.</p><p>I’d rather see a Lambda School than a Homejoy.</p><p><em>Austen raised after being profitable (= knowing his LTV, CAC, churn etc.) in order to fund faster growth and compress the timeline. Adora raised while not knowing exactly what LTV and CAC would end up being. Although there are always many factors, the biggest one was that acquiring customers was too expensive and they had poor retention. This obviously doesn’t mean Austen is better than Adora. Adora is a legend and she added many leaves to the tree of entrepreneurial science. It just means that Adora took a more risky approach and that has a smaller chance of working out.</em></p><p>You know who obsessively focuses on the competition? People that have run out of ideas.</p><p>If you:</p><ol data-rte-list="default"><li><p>Have a clear grasp of what fucking sucks in this world.&nbsp;</p></li><li><p>A good solution for fixing it.&nbsp;</p></li><li><p>And, a group of people that love your product,</p></li></ol><p>then that’ll take up all of your time.</p><p>Obviously, the competition sucks otherwise the problem or the need wouldn't exist. They would’ve solved it. [2]</p><p>Correctly identifying a real problem, or a need that a certain audience has as well, and then building a solution that they love, is already hard enough.</p><p>Trying to simultaneously focus on what the competition is doing (or even worse, might do) is near impossible. [3]</p><p>If you're doing your job correctly, you’ll hear what the competition is up to anyway. But if that heavily affects your decision-making process, you’re doing it wrong.</p><p><em>1 important exception to this is if your company relies mainly on psychological innovation. Oatly struggled even though they had a great product. It wasn’t until </em><a href="https://thechallengerproject.com/blog/2016/oatly" target="_blank"><em>they brought in a guy with the necessary expertise in psychological innovation</em></a><em> (John Schoolcraft) that they were able to scale. He realized that they were mimicking the competition and by looking at what they were doing, he could make sure Oatly steered clear of that and develop its own voice.</em></p><p><em>More on psychological innovation in this essay series: </em><a href="https://www.younglingfeynman.com/essays/illogical" target="_blank"><em>Why Your Business Needs More Weird Ideas</em></a><em>.</em></p><p>Young companies don’t get killed by big companies. They fail to follow point 1 on this list. They make something mediocre, or they solve a problem that doesn’t exist, or they build something to address a need that no one has.</p><p>When Jack Dorsey built Twitter, he wasn’t solving a problem. He was addressing a need… his own. It’s possible that in an alternate but nearly identical universe, he is an outlier and people just aren’t that into Twitter.&nbsp;</p><p>But as it so happens, his colleagues at <a href="https://www.businessinsider.com/how-twitter-was-founded-2011-4?international=true&amp;r=US&amp;IR=T" target="_blank">Odeo</a> loved it and it started to spread.</p><p>Keep iterating your business model canvas, or pivot, until you've succeeded in making a product that makes people bang down your door to get it. [4]</p><p>To quote Andy Rachleff (created modern product/market fit theory inspired by Don Valentine):</p><blockquote><p>‘[…]if you’re really good at execution but the dogs don’t want to eat the dog food, you have no chance of winning.’</p></blockquote><p>I thought it would be nice to end this list on the advice that kicked it off.</p><p>Get your idea into the hands of users as quickly as humanly possible. Your brain is lying to you when it tells you that the first impression should be polished and amazing and that Reid Hoffman is wrong when he says:</p><blockquote><p>‘If you’re not embarrassed by the first version of your product, you’ve launched too late!’</p></blockquote><p>Remember that your brain is wrong in this case. It’s your friend, but like an overprotective mom, it doesn’t want you to get hurt. So it’ll try to trick you (successfully I might add) that you should do anything except the things that actually matter.</p><p>This is the core insight of Noah Kagan’s eminent <a href="https://www.youtube.com/watch?v=BwbtSPQ8jAY" target="_blank">Validation Theory</a>.</p><p>The reason why you shouldn’t overbuild is because you’re making a lot of assumptions, and nearly all of those assumptions are wrong.</p><p>The quicker you’re able to identify which ones are wrong the better because it’ll save resources.</p><p>Imagine spending 6 years and $500K engineering a $3500 robot that walks dogs and picks up dog poop. When you try to sell it you learn ‘ain’t nobody wanna spend $3.5K on your dog walking pooper scooper’. You could’ve avoided this by presenting a few people with your idea and ask them to prepay. When you inevitably hear: ‘yeah… uhm, that’s gonna be a hard pass for me chief!’, then you can iterate to something that would be <strong>excited</strong> to pay for.</p><p>Don’t feel bad about ignoring the advice on this list. While everything is true, your brain will find some excuse and you will buy into it. We all do, myself included.</p><p>This seems to be like parents warning you about a bad girl/boy when you’re a teenager. You just need to experience it before it sinks in.</p><p>Then why did I write this essay?</p><p>Because part of me hopes there are a few competitive people that’ll be like: ‘Don’t tell me what I can’t do!’</p><p>And for the rest of the people reading this, when you make these mistakes, I hope you’re able to recognize that you’re making them sooner and are able to course-correct faster.</p><p><em>[1] Again, be mindful of who gives you this advice. VC’s most likely. For them, it’s a win/win situation. If they give you an A round and push you to grow hard, your paper valuation will increase, they can use that to raise more capital. That means they’ll make more money because of their management fee.&nbsp;</em></p><p><em>T…</em></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.younglingfeynman.com/essays/advice">https://www.younglingfeynman.com/essays/advice</a></em></p>]]>
            </description>
            <link>https://www.younglingfeynman.com/essays/advice</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934026</guid>
            <pubDate>Thu, 29 Oct 2020 18:47:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft releases preview of Lobe training app for machine-learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24933975">thread link</a>) | @mrafiee
<br/>
October 29, 2020 | https://www.lobe.ai/tour | <a href="https://web.archive.org/web/*/https://www.lobe.ai/tour">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.lobe.ai/tour</link>
            <guid isPermaLink="false">hacker-news-small-sites-24933975</guid>
            <pubDate>Thu, 29 Oct 2020 18:44:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mall real estate company collected 5M images of shoppers]]>
            </title>
            <description>
<![CDATA[
Score 225 | Comments 148 (<a href="https://news.ycombinator.com/item?id=24933583">thread link</a>) | @voisin
<br/>
October 29, 2020 | https://www.cbc.ca/news/politics/cadillac-fairview-5-million-images-1.5781735?cmp=rss | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/cadillac-fairview-5-million-images-1.5781735?cmp=rss">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The real estate company behind some of Canada's most popular shopping centres embedded cameras inside its digital information kiosks at 12 shopping malls in major Canadian cities&nbsp;to collect millions of images — and used facial recognition technology without customers' knowledge or consent —&nbsp;according to a new investigation by the federal, Alberta and B.C. privacy commissioners.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5499879.1584406507!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/covid-19-pandemic-stores-closed.JPG"></p></div><figcaption>Cadillac Fairview, the real estate company behind some of Canada's most popular shopping centres, embedded cameras inside its digital information kiosks at 12 shopping malls across Canada, according to a new investigation.<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure><p><span><p>The real estate company behind some of Canada's most popular shopping centres embedded cameras inside its digital information kiosks at 12 shopping malls in major Canadian cities&nbsp;to collect millions of images — and used facial recognition technology without customers' knowledge or consent —&nbsp;according to a new investigation by the federal, Alberta and B.C. privacy commissioners.</p>  <p>"Shoppers had no reason to expect their image was being collected by an inconspicuous camera, or that it would be used, with facial recognition technology, for analysis," said federal Privacy Commissioner Daniel Therrien&nbsp;in a statement.</p>  <p>"The lack of meaningful consent was particularly concerning given the sensitivity of biometric data, which is a unique and permanent characteristic of our body and a key to our identity."</p>  <p>According to the report, the technology&nbsp;Cadillac Fairview used&nbsp;— known as "anonymous video analytics" or AVA— took temporary digital images of the faces of individuals within the field of view of the camera in the directory.</p>  <p><strong><em>WATCH: Shoppers' privacy violated at major Canadian malls: Privacy commissioners:</em></strong></p>  <p><span><span><div><div role="button" tabindex="0" title="Shoppers’ privacy violated at major Canadian malls: Privacy commissioners"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/949/527/mall-privacy-daigle-291020.jpg" alt=""></p></div></div></div><span>Cadillac Fairview, the real estate company behind some of Canada’s biggest malls, violated the privacy of shoppers by collecting five million images without consent from cameras inside digital information kiosks, an investigation by federal, British Columbia and Alberta privacy commissioners found.<!-- --> <!-- -->2:01</span></span></span></p>  <p>It then used facial recognition software to convert those images into biometric numerical representations of&nbsp;individual faces, about five million images&nbsp;in total.</p>  <p>That sensitive personal information could be used to identify individuals based on their unique facial features, said&nbsp;the commissioners.</p>    <p>The report said the company also kept about 16 hours of video recordings, including some audio, which it had captured during a testing phase at two malls.</p>  <p>Cadillac Fairview said it&nbsp;used AVA technology&nbsp;to assess foot traffic and track shoppers' ages and genders&nbsp;— but not to identify individuals.&nbsp;</p>  <p>The company also argued shoppers were made aware of the activity through decals it placed on shopping mall entry doors that warned cameras were being used for "safety and security" and included the web address for Cadillac Fairview's&nbsp;privacy policy.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/chinook-centre-directory.jpg 300w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/chinook-centre-directory.jpg 460w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/chinook-centre-directory.jpg 620w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/chinook-centre-directory.jpg 780w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/chinook-centre-directory.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/chinook-centre-directory.jpg"></p></div><figcaption>This directory in Chinook Centre mall in south Calgary uses facial recognition technology.<!-- --> <!-- -->(Sarah Rieger/CBC)</figcaption></figure></span></p>  <p>But the commissioners said that&nbsp;wasn't good enough and did not meet the standard for meaningful consent.&nbsp;</p>  <p>"An individual would not, while using a mall directory, reasonably expect their image to be captured and used to create a biometric representation of their face, which is sensitive personal information, or for that biometric information to be used to guess their approximate age and gender," they wrote.</p>  <p>The privacy watchdogs also took issue with the way the&nbsp;five&nbsp;million images were stored.</p>  <p>Cadillac Fairview&nbsp;said the&nbsp;images taken by camera were briefly analyzed then deleted&nbsp;—&nbsp;but investigators found that the sensitive biometric information generated from the images was being stored in a centralized database by&nbsp;a third-party company,</p>  <p>"Our investigation revealed that&nbsp;[Cadillac Fairview Corporation Limited's]&nbsp;AVA&nbsp;service provider had collected and stored approximately five million numerical representations of faces on&nbsp;CFCL's behalf, on a decommissioned server, for no apparent purpose and with no justification," notes the investigation.</p>  <p>"Cadillac Fairview stated that it was unaware that the database of biometric information existed, which compounded the risk of potential use by unauthorized parties or, in the case of a data breach, by malicious actors."</p>  <h2>Company&nbsp;says technology couldn't identify people</h2>  <p>The company said the technology was used&nbsp;to detect the presence of a human face and&nbsp;assign it&nbsp;"within milliseconds"&nbsp;to an approximate age and gender category and maintains it&nbsp;did not store any images during the pilot program and was not capable of recognizing anyone.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/eaton-centre-decal.jpg 300w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/eaton-centre-decal.jpg 460w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/eaton-centre-decal.jpg 620w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/eaton-centre-decal.jpg 780w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/eaton-centre-decal.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/eaton-centre-decal.jpg"></p></div><figcaption>The decal found on the entrance doors of the CF Toronto Eaton Centre<!-- --> <!-- -->(Office of the Privacy Commissioner report)</figcaption></figure></span></p>  <p>"The five million representations referenced in the [Office of the Privacy Commissioner]&nbsp;report are not faces. These are sequences of numbers the software uses to anonymously categorize the age range and gender of shoppers in the camera's view," Cadillac Fairview spokesperson Jess Savage&nbsp;said in a statement to CBC News.</p>  <p>"The&nbsp;OPC report concludes there is no evidence that CF was using any technology for the purpose of identifying individuals."</p>  <p>CF&nbsp;suspended its&nbsp;use of cameras&nbsp;back in 2018&nbsp;when provincial and federal privacy commissioners launched their probe&nbsp;<a href="https://www.cbc.ca/news/canada/calgary/calgary-malls-1.4760964">following a CBC investigation</a>.</p>  <p>In a statement to CBC News on Thursday, the company said it has deleted the data.</p>  <p>"We subsequently deactivated directory cameras and the numerical representations and associated data have since been deleted," said&nbsp;Savage.</p>  <p>"We take the concerns of our visitors seriously and wanted to ensure they were acknowledged and addressed."</p>  <p>However, the three commissioners said they have concerns about the company's plans going forward.</p>    <p>"The commissioners remain concerned that Cadillac Fairview refused their request that it commit to ensuring express, meaningful consent is obtained from shoppers should it choose to redeploy the technology in the future," said&nbsp;the commissioners'&nbsp;statement.</p>  <h2>No fines under Canadian law</h2>  <p>Savage said Cadillac Fairview&nbsp;accepted and implemented all the recommendations&nbsp;"with the exception of those that speculate about hypothetical future uses of similar technology."</p>  <p>The investigation found the technology was used&nbsp;in five provinces&nbsp;at the following malls:</p>  <ul>   <li>CF Market Mall (Calgary)</li>   <li>CF Chinook Centre (Calgary)</li>   <li>CF Richmond Centre (Richmond, B.C.)</li>   <li>CF Pacific Centre (Vancouver)</li>   <li>CF Polo Park (Winnipeg)</li>   <li>CF Toronto Eaton Centre (Toronto)</li>   <li>CF Sherway Gardens (Toronto)</li>   <li>CF Fairview Mall (Toronto)</li>   <li>CF Lime Ridge (Hamilton, Ont.)</li>   <li>CF Markville Mall (Markham, Ont.)</li>   <li>CF Galeries d'Anjou&nbsp;(Montreal)</li>   <li>CF Carrefour Laval (Laval, Que.)</li>  </ul>  <p>Ann Cavoukian,&nbsp;executive director at the Global Privacy and Security by Design Centre,&nbsp;said a case like this would lead to millions of dollars in fines if it had happened&nbsp;in the United States.</p>  <p>"The commissioners are doing the best they can with the limited resources they have," she said.</p>  <p>"What we have to insist upon is that private&nbsp;sector entities like Cadillac Fairview step up and protect their customers' privacy. Otherwise, why are the customers going to continue shopping there?"</p>  <p>B.C. Information and Privacy Commissioner&nbsp;Michael McEvoy&nbsp;said&nbsp;the fact he and his counterparts can't issue a fine in a&nbsp;case like this should make the case for stronger powers at both the federal and provincial levels.</p>  <p>"Fines in a case like this would have been a consideration. It is an incredible shortcoming of Canadian law," he said.</p>  <p>"We as privacy regulators don't have any authority to levy fines on companies that violate peoples'&nbsp;personal information and that should really change."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/cadillac-fairview-5-million-images-1.5781735?cmp=rss</link>
            <guid isPermaLink="false">hacker-news-small-sites-24933583</guid>
            <pubDate>Thu, 29 Oct 2020 18:22:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A guide to PocketQubes (tiny satellites)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24933262">thread link</a>) | @kartikkumar
<br/>
October 29, 2020 | https://blog.satsearch.co/2020-10-28-pocketqube-satellites-and-ancillary-products-on-the-global-marketplace | <a href="https://web.archive.org/web/*/https://blog.satsearch.co/2020-10-28-pocketqube-satellites-and-ancillary-products-on-the-global-marketplace">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p><em>This is a market segment roundup initially developed in collaboration with <a href="https://satsearch.co/suppliers/alba-orbital" title="alba orbital on satsearch" target="_blank">Alba Orbital</a> and focussing on companies that offer products and services in the PocketQube picosatellite form factor.</em></p>



<p>Electronic and structural miniaturisation of space components and sub-systems has led to a variety of innovations in recent years.</p>

<p>A wide range of parts and components have been manufactured with increasingly smaller physical footprints, and this has reduced the overall size of complete systems.</p>

<p>The costs and lead times of such systems have also decreased, while the range of possible in-orbit applications and technology available has grown. This has been driven by greater use of commercial-of-the-shelf (COTS) components and the commercial availability of a wider range of products, parts and materials with flight heritage.</p>

<p>In addition, the growth in both research and commercial interest in space applications, along with an increase in new entrants and innovation to the market, has led to greater demand for more compatible, interoperable, and modular products.</p>

<p>Over the years this has led to the emergence of standardised physical form factor satellites such as CubeSats and PocketQubes.</p>

<p><a href="https://satsearch.co/suppliers/alba-orbital" target="_blank"><img src="https://raw.githubusercontent.com/satsearch/satsearch-blog/master/assets/201028_satsearch_alba_orbital_unicorn_1.png" alt="alba orbital on satsearch"></a>
  </p>
<p><em>The Unicorn-1 satellite designed by <a href="https://satsearch.co/suppliers/alba-orbital" title="alba orbital on satsearch" target="_blank">Alba Orbital</a> - for the European Space Agency’s first PocketQube mission (<a href="http://www.albaorbital.com/unicorn-1" title="alba orbital unicorn-1 mission" target="_blank">credit</a>).</em></p>



<p>PocketQubes are very small satellites that are often used for research purposes. They were <a href="https://en.wikipedia.org/wiki/PocketQube" title="pocketqubes on wikipedia" target="_blank">first developed</a> based on work at Morehead State University (MSU) and Kentucky Space, USA, in 2009. They were originally called PocketQubs.</p>

<p>A PocketQube is a 5cm cube and typically has a launch mass of no more than 250g.</p>

<p>In small satellite form factor terminology a 5 x 5 x 5 cm<sup>3</sup> cube is also known as <strong>1p</strong> and PocketQube satellites are products that are usually organised by size according to the number of p they feature – in the same way that U is used for CubeSats.</p>

<p>In this post we take a look at a variety of PocketQube products, systems, and suppliers around the world offering hardware and services for this segment of the market.</p>



<h2 id="pocketqube-products-on-the-global-marketplace">PocketQube products on the global marketplace</h2>

<p>In the section below you can see a variety of products and services related to PocketQubes that are available on the market.</p>

<p>These listings will be updated when new PocketQube products are added to the global marketplace for space at <a href="https://satsearch.co/" title="the global marketplace for space" target="_blank">satsearch.co</a> - so please check back for more or <a href="https://satsearch.us10.list-manage.com/subscribe/post?u=c80ec0b3e92164736b768fa12&amp;id=862b97e1e0">sign up for our mailing list</a> for all the updates.</p>

<p><strong>You can click on any of the links or images below to find out more about the systems. If you’d like more detail please submit a request for a quote, documentation, introduction, or further information on each of the products listed or <a href="https://satsearch.co/request" title="space procurement on the global marketplace for space" target="_blank">send us a more general query to discuss your specific needs</a>), and we will use our global networks of suppliers to find a system to meet your specifications.</strong></p>



<h3 id="the-1d-mgse-for-pocketqubes-by-murb-space">The <a href="https://satsearch.co/products/murbspace-1d-mgse-for-pocket-qubes" title="1d mgse for pocketqubes by murb space on satsearch" target="_blank">1D MGSE for PocketQubes</a> by <a href="https://satsearch.co/suppliers/murbspace" title="murb space on satsearch" target="_blank">MURB Space</a></h3>

<p><a href="https://satsearch.co/products/murbspace-1d-mgse-for-pocket-qubes" target="_blank"><img src="https://satsearch.s3.eu-central-1.amazonaws.com/product-images/satsearch_n0d5mo_murb_space_1d_mgse.png" alt="1D MGSE for PocketQubes on satsearch"></a>
</p>

<p><a href="https://satsearch.co/membership" target="_blank"><img src="https://blog.satsearch.co/assets/satsearch_member_badge.png" alt="Satsearch member" width="100"></a>

</p>



<p>MURB Space develops engineering solutions for small satellite integrators designed to improve assembly, integration and testing (AIT) processes. The 1D Mechanical and Ground Support Equipment (1D MGSE) was created to facilitate and shorten AIT processes for PocketQube satellite development, while ensuring that hardware can still satisfy the strict quality requirements expected in the space industry.</p>

<p>Manual AIT activities have to be carried out with care, consuming significant time and resources for reporting and safety procedures. The 1D MGSE is a dedicated tool for AIT processes that can help reduce the number of steps, the effort, and the resources needed during picosatellite development as well as cut down on errors, by significantly reducing the number of manual tasks.</p>



<h3 id="pocketqube-satellites-sub-systems-and-services-by-alba-orbital-ltd">PocketQube satellites, sub-systems and services by <a href="https://satsearch.co/suppliers/alba-orbital" title="alba orbital on satsearch" target="_blank">Alba Orbital Ltd.</a></h3>

<p><a href="https://satsearch.co/products/alba-orbital-pocket-qube-deployer-albapod" target="_blank"><img src="https://satsearch.s3.eu-central-1.amazonaws.com/product-images/satsearch_product-image_snura2_alba_orbital_pocket_qube_deployer_albapod.jpg" alt="alba orbital albapod on satsearch"></a>
   <a href="https://satsearch.co/products/alba-orbital-pocketqube-1p-structure" target="_blank"><img src="https://satsearch.s3.eu-central-1.amazonaws.com/product-images/satsearch_ma1jbw_alba_orbital_pocketqube_1p_structure.jpg" alt="alba orbital Pocketqube 1P Structure on satsearch"></a>
   <a href="https://satsearch.co/services/alba-orbital-pocket-qube-launch" target="_blank"><img src="https://satsearch.s3.eu-central-1.amazonaws.com/product-images/satsearch_product-image_qr6vfk_alba_orbital_pocket_qube_launch.JPG" alt="alba orbital pocketqube launch on satsearch"></a>
</p>



<p>Alba Orbital provides a range of modular PocketQube platforms, ground station solutions, launch services, payloads, consultancy services, and other products.</p>

<p>The <a href="https://satsearch.co/products/alba-orbital-pocketqube-1p-structure" title="Pocketqube 1P Structure by alba orbital on satsearch" target="_blank">Pocketqube 1P Structure</a> is a 50 x 50 x 50 mm<sup>3</sup> satellite chassis with a skeletonized wall structure. It weighs 0.069 kg and has an operating temperature range of 223—363 K.</p>

<p>Alba Orbital’s <a href="https://satsearch.co/products/alba-orbital-pocket-qube-deployer-albapod" title="PocketQube Deployer Albapod on satsearch" target="_blank">PocketQube Deployer Albapod</a> enables the deployment of one or multiple PocketQubes into orbit. It is suitable for 1p, 1.5p, 2p or 3p PocketQube format satellites and has a 10mm envelope for larger deployables and antennas. It is compatible with MR-FOD style PocketQubes and features tabbed systems designed to reduce contact points from 4 to 2 in order to minimise risk. The Albapod can be integrated onto any launch vehicle and there is also a 96p variant available for PocketQube constellation deployment.</p>

<p>Alba Orbital’s <a href="https://satsearch.co/services/alba-orbital-pocket-qube-launch" title="alba orbital pocketqube launch service on satsearch" target="_blank">launch service</a> has been developed to offer regular, reliable and cost-effective launch opportunities to companies, universities and other PocketQube teams. Alba Orbital has developed partnerships with a variety of launch companies and brokers and utilises the AlbaPod Deployer (detailed above) as part of the launch service.</p>

<p>At the time of writing Alba Orbital has launched more PocketQube satellites into orbit than any other organisation</p>



<h3 id="pocketqube-structures-by-gauss">PocketQube structures by <a href="https://satsearch.co/suppliers/gauss" title="GAUSS pocketqube structures on satsearch" target="_blank">G.A.U.S.S.</a></h3>

<p><a href="https://satsearch.co/suppliers/gauss/products" target="_blank"><img src="https://satsearch.s3.eu-central-1.amazonaws.com/product-images/satsearch_c09khq_gauss_srl_1u_cubesat.png" alt="GAUSS PocketQube products on satsearch"></a>
</p>



<p>G.A.U.S.S. manufactures a range of PocketQube size structure products for various satellite form factors. Alongside the hardware provided G.A.U.S.S. also offers support for design and FEM analysis for both standard and customized structures according to the client’s needs.</p>

<p>Solutions are available for a variety of cases including; deployable systems, interfaces for structural tests and IOD/IOV platforms. The individual PocketQube products are:</p>

<ul>
  <li><strong><a href="https://satsearch.co/products/gauss-1.5p-pocketqube" title="1p pocketqube on satsearch" target="_blank">1p PocketQube</a></strong></li>
  <li><strong><a href="https://satsearch.co/products/gauss-1.5p-pocketqube" title="1.5p pocketqube on satsearch" target="_blank">1.5p PocketQube</a></strong></li>
  <li><strong><a href="https://satsearch.co/products/gauss-2p-pocketqube" title="2p pocketqube on satsearch" target="_blank">2p PocketQube</a></strong></li>
  <li><strong><a href="https://satsearch.co/products/gauss-3p-pocketqube" title="3p pocketqube on satsearch" target="_blank">3p PocketQube</a></strong></li>
</ul>



<h3 id="the-pocketqube-solar-panel-by-dhv-technology">The <a href="https://satsearch.co/products/dhv-technology-pocketqube-solar-panel" title="dhv technology Pocketqube Solar Panel on satsearch" target="_blank">Pocketqube Solar Panel</a> by <a href="https://satsearch.co/suppliers/dhv-technology" title="dhv technology on satsearch" target="_blank">DHV Technology</a></h3>

<p><a href="https://satsearch.co/products/dhv-technology-pocketqube-solar-panel" target="_blank"><img src="https://satsearch.s3.eu-central-1.amazonaws.com/product-images/satsearch_ioqji9_dhv_technology_pocketqube_solar_panel.png" alt="Pocketqube Solar Panel on satsearch"></a>
</p>



<p>The DHV Technology Pocketqube Solar Panel has been developed to bring solar power to picosatellites. It features Spectrolab TASJ solar cells and is available in 1p, 2p and 3p formats as well as customized sizes. It is manufactured from PCB low thickness polyimide substrate and features the following electrical parameters, under the conditions 1 sun, AM 1.5G (1000 W/m<sup>2</sup>) 25°C:</p>

<ul>
  <li>I<sub>SC</sub> = 31 mA</li>
  <li>I<sub>mp</sub> = 28 mA</li>
  <li>V<sub>OC</sub> = 15.12 V</li>
  <li>V<sub>mp</sub> = 13.14 V</li>
  <li>P<sub>mp</sub> = 368 mW</li>
</ul>



<h3 id="pocketqube-development-services-by-fossa-systems">PocketQube development services by <a href="https://satsearch.co/suppliers/fossa" title="fossa systems on satsearch" target="_blank">Fossa Systems</a></h3>

<p><a href="https://satsearch.co/suppliers/fossa" target="_blank"><img src="https://satsearch.s3.eu-central-1.amazonaws.com/supplier-images/logo_2nqap3_fossa.png" alt="Pocketqube development services by Fossa Systems on satsearch"></a>
</p>



<p>Fossa Systems provides a range of development services for picosatellite manufacturers and operators for Low Earth Orbit (LEO) applications, with a focus on integrated and high-performance PocketQube platforms. FOSSA Systems acquired flight heritage in 2019 in missions such as FOSSASAT-1 which demonstrated a LoRa IOT telecommunications satellite sized at 5cm and weighing under 250g.</p>

<p>The company offers integrated PocketQube hardware solutions, sub-system level PocketQube components, consulting and launch services and is also developing a range of cutting-edge equipment including ADCS systems, PocketQube propulsion systems and EO payloads for picosatellites.</p>



<p><strong><em>Thanks for reading! If you would like further help identifying a PocketQube or picosatellite product or service for your needs, <a href="https://satsearch.co/request">please click here to send us a query</a> and we’ll use our extended global networks of suppliers to find the information you need.</em></strong></p>

<p><strong><em>Have you noticed that your company isn’t included in this article? <a href="https://blog.satsearch.co/cdn-cgi/l/email-protection#eb82858d84ab988a9f988e8a998883c58884">Simply send us an email today</a>, and we’d be happy to work with you to showcase your products to the satsearch community!</em></strong></p>

    </div></div>]]>
            </description>
            <link>https://blog.satsearch.co/2020-10-28-pocketqube-satellites-and-ancillary-products-on-the-global-marketplace</link>
            <guid isPermaLink="false">hacker-news-small-sites-24933262</guid>
            <pubDate>Thu, 29 Oct 2020 18:03:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trump vs. Biden. Whose side is ecommerce on?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24933119">thread link</a>) | @Elons_baby
<br/>
October 29, 2020 | https://grinteq.com/blog/trump-vs-biden-whose-side-is-ecommerce-on | <a href="https://web.archive.org/web/*/https://grinteq.com/blog/trump-vs-biden-whose-side-is-ecommerce-on">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><img src="https://mc.yandex.ru/watch/50400562" alt=""></p>
    
    <!-- /Yandex.Metrika counter -->
    <meta name="google-site-verification" content="gQ3ei9ukMGhD1QJgdTqR12Tn7iPtswqPconmlhUgyKI">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    
    



<!-- Google Tag Manager (noscript) -->

<!-- End Google Tag Manager (noscript) -->



<div>
    <div>
        <div>
            <p>Trump vs Biden. Whose Side is E-commerce On?</p>
            <p>Let the battle begin!</p>
        </div>
        
        <div>
            <p><img src="https://grinteq.com/assets/design/Blog_images/0.jpg"></p>
        </div>
        
        <p>Less than a week left before the Americans elect the new President. It’s difficult to predict which way the votes will go, but the one thing we can confidently claim—e-commerce space won’t be the same. We do not pretend to be political experts, but in this article, we’ll examine how the e-commerce business could change or be affected in either scenario. Let the battle begin!</p>
    </div>
</div>

<section>
    
    <div>
        <div>
            <div>
    <p>Known Present vs Unknown Future</p>
    
    <p><img src="https://media.giphy.com/media/3o6QLoYiFxEgHrYyxa/source.gif"></p>
    
    <div>
        <div><p>Okaaay… To start with, let’s mention that this battle can’t be fair.&nbsp;</p><p>

<strong>Why so?</strong> We have been witnessing Trump’s politics for 4 years already, and after analyzing its main results, we can build some hypotheses for the next few years. As for the win of the Democratic Party, we can just rely on Biden’s presidential campaign and believe that all the promises will come true <em>*coughs twice*</em>.</p><p>

Unfortunately, we won’t hear the direct overview of the e-commerce future from both sides, but this industry is highly affected by factors such as taxation, trade policy, foreign relations, laws, and capital flow.</p><p>

So, let’s start our little analysis.</p></div>

    </div>
</div><div>
    <p>Round 1. Taxation</p>
    
    <p><img src="https://media.giphy.com/media/rA4UF5rHBZHt6/giphy.gif"></p>
    
    <div>
        

<ul>
	<li><strong>Red corner</strong></li>
</ul>



<div><p><strong>What’s done.</strong> In their pre-pandemic budget proposal, the Trump administration promised to extend the massive <a href="https://www.investopedia.com/taxes/trumps-tax-reform-plan-explained/" target="_blank"><strong>Tax Cuts and Jobs Acts</strong></a>, which was signed in 2017 and had become the largest overhaul made in the last 30 years in tax code.</p><p>

<strong>For people...</strong>the law saved the previous structure of seven individual income tax brackets, but the majority of rates were lowered. The maximum rate for income over $500,000 has fallen by up to 37% from 39,6%. The lowest rate remained at 10%.&nbsp;</p><p>

<strong>For business...</strong>Trump created a single corporate tax rate of 21% and canceled the corporate alternative minimum tax.</p><p>

In combination with local and state taxes, the new statutory rate is now equal to 26.5% (the average weighted of EU countries - 26.9%).</p><p>

<strong>What to expect?</strong> Those who support the idea of low corporate tax rates believe that due to such measures companies won't look for more attractive business conditions abroad and the amount of M&amp;A international deals will decrease.</p></div>

<ul>
	<li><strong>Blue corner</strong></li>
</ul>



<div><p><strong>What’s the plan?</strong> In their <a href="https://www.investopedia.com/comparing-the-economic-plans-of-trump-and-biden-4843240" target="_blank">10-year released plan</a>, the Democrats suggested rolling back the corporate tax cuts, reducing incentives for tax havens, evasion, and outsourcing, and closing any loopholes in the tax code that encourage wealth, not work.</p><p>

As Democrats traditionally bet on corporate income taxes, Biden is planning to raise its rate to 28% from the current 21%.&nbsp;</p><p>

He wants to apply Social Security taxes to income above $400,000 and levy at least a 15% tax on book income of large corporations.&nbsp;</p><p>

<strong>As for business...</strong>no company "should absolutely be in a position where they pay no tax and make billions and billions and billions of dollars," <strong>Biden said</strong>. So, Amazon-like companies will have to contribute more funds to the country budget, IF the law is signed. <em>Poor Jeff.</em></p><p>

For those, whose annual income is higher than $1 million, it's supposed to gain tax capital and dividends at regular rates.</p><p>


<strong>What about e-commerce?</strong></p><p>

<strong>Personal taxes.</strong> If Trump wins, he will likely extend the 2017 tax overhaul for individuals. As for Biden, in case of victory, he will roll back tax cuts.&nbsp;</p><p>

Good cop/bad cop.</p><p>

Due to lower personal taxes, the spendable income is growing, as well as the purchasing power of buyers, and individuals start to spend more money, including shopping online. A point for Trump here.</p><p>

<strong>Corporate taxes.</strong> Lower corporate taxes that Trump suggests are clearly more favorable for e-commerce. It means companies will have much more resources to invest in business processes and innovation, which would lead to increased productivity and more sales in the end.</p><p>

If Biden is elected, his tax policy may have a negative impact on the whole business sphere, including e-commerce, forcing companies to search for more favorable tax rates and structures, and register their headquarters abroad.</p><p>

If this hypothesis actually turned out true, and a large part of companies were to relocate, it would carry a significant blow to the U.S. economy, multiplied by the COVID pandemic.</p><p>

<strong>Amazon time.</strong> Both candidates claim their willingness to fight Amazon, which shared <strong><a href="https://techcrunch.com/2018/07/13/amazons-share-of-the-us-e-commerce-market-is-now-49-or-5-of-all-retail-spend/" target="_blank">49% of the US e-commerce market</a></strong> ($256,7 billion) or 5% of all retail spend in 2018.</p><p>

Amazon pays taxes at <a href="https://www.investopedia.com/insights/amazon-effect-us-economy/#citation-3" target="_blank"><strong>an average rate of 13%</strong></a> ($33,3 billion), nearly half of the average rate companies from the S&amp;P 500 pay. Other big corporations like Facebook, Alphabet, and Apple also pay taxes at a rate significantly lower than the average.</p><p>

<strong>Good news for mid-sized companies.</strong> If the corporate tax rate was to increase for large enterprise and tech giants, their rapid expansion would slow down, giving the chances for smaller retailers to get a larger market share.</p></div>

    </div>
</div><div>
    <p>Round 2. Human Capital and Labour Productivity</p>
    
    <p><img src="https://media.giphy.com/media/3o6QL2hWeeBHlcZ8qs/source.gif"></p>
    
    <div>
        <ul>
	<li><strong>Red corner</strong></li>
</ul>



<div><p>As any other President, Donald Trump dreamt about a low unemployment rate and the creation of thousands of new jobs for American citizens. To complete the goal, his administration developed a range of stimulating measures.&nbsp;</p><p>

At least...they tried.</p><p>

<strong>Trump’s anti-record. </strong>Due to trade tariffs, hundreds of new jobs <a href="https://www.brookings.edu/policy2020/votervital/did-trumps-tariffs-benefit-american-workers-and-national-security/" target="_blank"><strong>appeared</strong></a><strong> </strong>in import-competing industries. But in general, tariffs benefited some workers at the expense of others.</p><p>

The Covid-19 was another factor that contributed to Trump's ‘record’ when the number of job losses became the worst of any American president. Sad story, but to be fair, other presidents never faced anything as pervasive as COVID-19.</p><p>

<strong>Against automation.</strong> Trump argues against increased automation and wants to protect American workers from being displaced by machines.&nbsp;</p><p>

Automation is the fuel of e-commerce and a perfect way to save time, effort, money, and keep a social distance.&nbsp;</p><p>

Cute Amazon robots bringing your groceries right to your door...</p><p>

Magical drones flying supplies through your window...&nbsp;</p><p>

Won’t we see them? Nooooo :(</p><p>

<strong>Banned visas.</strong> Instead of investing in technology development, Trump has banned worker visas. Such a step will definitely have a negative impact not only on Silicon Valley, where nearly <a href="https://www.mercurynews.com/2018/01/17/h-1b-foreign-citizens-make-up-nearly-three-quarters-of-silicon-valley-tech-workforce-report-says/" target="_blank"><strong>three-quarters of techies</strong></a> are foreign but also on the whole tech sector, including e-commerce.</p><p>

Yes, e-commerce businesses may easily and successfully transition to remote, but this process will take some period of time.</p></div>

<ul>
	<li><strong>Blue corner</strong></li>
</ul>



<div><p><strong>In contrast to Trump...</strong>Biden respects immigrants and understands the value of attracting global talent to the country.</p><p>

He suggests updating the immigration policy and rethinking the response to the Covid-19 consequences.&nbsp;</p><p>

<strong>Against outsourcing.</strong> In addition to the 28% corporate tax, Biden <strong><a href="https://joebiden.com/wp-content/uploads/2020/09/Buy-America-fact-sheet.pdf" target="_blank">promises</a></strong> a 10% Offshoring Penalty surtax, on profits of any production by a US company overseas for sales back to the US.&nbsp;</p><p>

Totally, companies would have paid a <strong>30.8% tax rate</strong> on any such profits.</p><p>

Such rules will force companies to use offshore resources illegally or to hire only local specialists with higher rates. Again, this added value will be included in the final price of the goods.</p><p>

Seems that inflation will become a new President of America…</p><p>

Biden will also cancel all deductions and expenses write-offs for moving jobs or production overseas, instead, offering these jobs to American workers.</p><p>


<strong>What does it mean for e-commerce?</strong></p><p>

<strong>Fewer immigrants - more outsourcing.</strong> An average web store creates way fewer jobs than a physical store. <em>(thanks to automation and cunning)</em></p><p>

For instance, Amazon has a team of 1 mln. people worldwide.&nbsp;</p><p>

Sounds impressive.&nbsp;</p><p>

Until the moment you find out that Walmart <a href="https://corporate.walmart.com/newsroom/company-facts#:~:text=Walmart%20employs%20more%20than%202.2,million%20in%20the%20U.S.%20alone." target="_blank"><strong>employs</strong></a> more than 2.2 million associates around the world — nearly 1.5 million in the U.S. alone.&nbsp;</p><p>

Very often, you don’t even need to rent a big office to hire the team.&nbsp;</p><p>

<strong>Thanks to globalization and digitalization...</strong>it’s now easier to find a skilled specialist overseas than inside the country where the competition for talents is much higher.&nbsp;</p><p>

Immigration has contributed immensely to America’s economic success, making it a global leader in tech.&nbsp;</p><p>

Trump’s banning of worker visas has made many tech companies think about opening offices in Canada and other countries that allow immigration or increase hiring of distributed teams.&nbsp;</p><p>

<strong>Hiring remote teams</strong> and agencies is a solution that may become even more popular than it is. Imagine that you get access to a pool of talent from all over the world and can choose the best of them. Software development is one of the industries that widely use outsourcing because of the complexity and diversity of skills needed for each project.</p><p>

<a href="https://grinteq.com/e-commerce?utm_source=blog&amp;utm_medium=article&amp;utm_campaign=elections" target="_blank"><strong>See how you can get an awesome e-commerce customer experience &gt;&gt;&gt;</strong></a></p><p>

Biden is against outsourcing, Trump is against immigrant workers.&nbsp;</p><p>

And we should make this choice.</p><p>

<strong>The new reality.</strong> Perhaps, the only positive moment of the Covid-19 spread is the fact that companies realized that our world won’t be the same anymore. Remote work, outsourcing services, staff optimization, and automation are the keys to this new working reality.&nbsp;</p><p>

Although many people, including Trump, argue against the automatization of business, we can't imagine the new world without it.&nbsp;We already see the examples of partially (like Amazon Go) and fully automated shops (like ‘dark stores’ by The Whole Foods).&nbsp;</p><p>

And that is the future.</p><p>

<strong>In terms of technology...</strong>Biden’s position looks more attractive, though some moments look contradictory.</p><p>

His support of small and mid-sized tech businesses can improve the consumer welfare standard and maintain greater competition in the marketplace.&nbsp;</p><p>

At the same time, tech giants like Amazon, Google, Facebook, and others have contributed a lot to the U.S. economy, and if they face some strict regulations, it may lead to some countermeasures from their side (e.g. moving offices to …</p></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://grinteq.com/blog/trump-vs-biden-whose-side-is-ecommerce-on">https://grinteq.com/blog/trump-vs-biden-whose-side-is-ecommerce-on</a></em></p>]]>
            </description>
            <link>https://grinteq.com/blog/trump-vs-biden-whose-side-is-ecommerce-on</link>
            <guid isPermaLink="false">hacker-news-small-sites-24933119</guid>
            <pubDate>Thu, 29 Oct 2020 17:50:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spread of a novel SARS-CoV-2 variant across Europe in summer 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932985">thread link</a>) | @jcfrei
<br/>
October 29, 2020 | https://www.unibas.ch/en/News-Events/News/Uni-Research/Spread-of-a-novel-SARS-CoV-2-variant-across-Europe-in-summer-2020.html | <a href="https://web.archive.org/web/*/https://www.unibas.ch/en/News-Events/News/Uni-Research/Spread-of-a-novel-SARS-CoV-2-variant-across-Europe-in-summer-2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    


    <div>
        <p>In Europe alone, hundreds of different variants of the new coronavirus SARS-CoV-2 are currently circulating, distinguished by mutations in their genomes. However, only very few of these variants have spread as successfully and become as prevalent as the newly identified variant, named <em>20A.EU1</em>.</p>

<p>The researchers at the University of Basel, ETH Zürich in Basel and the SeqCOVID-Spain consortium analyzed and compared virus genome sequences collected from Covid-19 patients all across Europe to trace the evolution and spread of the pathogen (see box). Their analysis suggests that the variant originated in Spain during the summer. The earliest evidence of the new variant is linked to a super-spreading event among agricultural workers in the north-east of Spain. The variant moved into the local population, expanding quickly across the country, and now accounts for almost 80% of the sequences from Spain.</p>

<p>“It is important to note that there is currently no evidence the new variant’s spread is due to a mutation that increases transmission or impacts clinical outcome,” stresses Dr. Emma Hodcroft of the University of Basel, lead author of the study. The researchers believe that the variant’s expansion was facilitated by loosening travel restrictions and social distancing measures in summer.</p>

<h4><strong>Similar pattern as in spring in Spain</strong></h4>

<p>“We see a similar pattern with this variant in Spain as we did in the spring,” advises Professor Iñaki Comas, co-author on the paper and head of the SeqCOVID-Spain consortium. “One variant, aided by an initial super-spreading event, can quickly become prevalent across the country.”</p>

<p>From July, <em>20A.EU1</em> moved with travelers as borders opened across Europe, and has now been identified in twelve European countries. It has also been transmitted from Europe to Hong Kong and New Zealand. While initial introductions of the variant were likely from Spain directly, the variant may then have continued to spread onward from secondary countries.</p>

<p>Currently, <em>20A.EU1</em> accounts for 90% of sequences from the UK, 60% of sequences from Ireland, and between 30 and 40% of sequences in Switzerland and the Netherlands. This makes this variant currently one of the most prevalent in Europe. It has also been identified in France, Belgium, Germany, Italy, Latvia, Norway, and Sweden.</p>

<h4><strong>Travel facilitated the spread</strong></h4>

<p>Genetic analysis indicates that the variant travelled at least dozens and possibly hundreds of times between European countries. “We can see the virus has been introduced multiple times in several countries and many of these introductions have gone on to spread through the population,” says Professor Tanja Stadler of ETH Zürich, one of the study’s principal investigators, “This isn’t a case of one introduction just happening to do well.”</p>

<p>Though the rise in prevalence of <em>20A.EU1</em> corresponds with the increasing number of cases observed in many European countries this autumn, the study’s authors caution against interpreting the new variant as a cause for the rise in cases. “It is not the only variant circulating in recent weeks and months,” says Professor Richard Neher of the University of Basel, one of the study’s principal investigators. “Indeed, in some countries with significant increases in Covid-19 cases, like Belgium and France, other variants are prevalent.”</p>

<p>Analysis of the summertime SARS-CoV-2 prevalence in Spain and travel data show that these factors may explain how <em>20A.EU1</em> spread so successfully. Spain’s relatively high number of cases and popularity as a holiday destination may have allowed multiple opportunities for introductions, some of which may have grown into larger outbreaks through risky behaviors after returning home.</p>

<p>The study’s authors highlight the importance of evaluating how border controls and travel restrictions worked in containing SARS-CoV-2 transmissions over the summer, and the role travel has played. “Long-term border closures and severe travel restrictions aren’t feasible or desirable,” explains Hodcroft, “but from the spread of <em>20A.EU1</em> it seems clear that the measures in place were often not sufficient to stop onward transmission of introduced variants this summer. When countries have worked hard to get SARS-CoV-2 cases down to low numbers, identifying better ways to ‘open up’ without risking a rise in cases is critical.”</p>

<h4><strong>Assessing the phenotype of the new variant</strong></h4>

<p>The new variant was first identified by Hodcroft during an analysis of Swiss sequences using the ‘Nextstrain’ platform, developed jointly by the University of Basel and the Fred Hutchinson Cancer Research center in Seattle, Washington. <em>20A.EU1</em> is characterized by mutations that modify amino-acids in the spike, nucleocapsid, and ORF14 proteins of the virus.</p>

<p>Though the present state of knowledge does not indicate <em>20A.EU1</em>’s spread was due to a change in transmissibility, the authors are currently working with virology labs to examine any potential impact the spike mutation, known as S:A222V, may have on the SARS-CoV-2 virus’ phenotype. They also hope to soon receive access to data that would allow them to assess any clinical implications of the variant.</p>

<p>Also, the study’s authors emphasize the importance of monitoring the rise of new variants like <em>20A.EU1</em> closely: “It is only through sequencing the viral genome that we can identify new SARS-CoV-2 variants when they arise and monitor their spread within and between countries,” adds Neher, “But the number of sequences we have varies widely between countries, and we might be able to identify rising variants sooner with faster and more regular sequencing efforts across Europe.”</p>

<p><em>A high-resolution image is available in the <a href="https://www.unibas.ch/en/News-Events/Media-Database.html">media database</a>.</em></p>

    </div>
</div><section>
    
    <div>
    	<p>The ‘Nextstrain’ platform was started in 2015 with the goal of allowing real-time tracking of pathogens via genetic sequencing and hoping to help forecast the future spread of viruses. Nextstrain takes advantage of the small mistakes viruses make when they replicate: The platform creates a ‘family tree’ that shows how different samples are related. This allows scientists to track how viruses spread around the world and through time. Nextstrain has been applied to many pathogens, including those that cause influenza, Zika, Ebola, Tuberculosis, and of course, Covid-19. The Neher lab at the University of Basel currently maintains the Nextstrain analyses of SARS-CoV-2 sequences for most countries in Europe as well as a dedicated analysis for Switzerland.</p>

<p>The SeqCOVID-Spain consortium is aimed to understand the transmission patterns of SARS-CoV-2 in Spain and in connection with the rest of the world. It is contributed by more than 30 clinical institutions to get a nationwide representation of the viral diversity.</p>

    </div>
</section><div>
    


        <div>
            <p><strong>Original publication</strong></p>

<p>Emma B. Hodcroft, Moira Zuber, Sarah Nadeau, Iñaki Comas, Fernando Gonzalez Candelas, SeqCOVID-SPAIN consortium, Tanja Stadler and Richard A. Neher<br>
<a href="https://www.medrxiv.org/content/10.1101/2020.10.25.20219063v1" target="_blank">Spread of a SARS-CoV-2 variant through Europe in summer 2020</a><br>
medRxiv (2020), DOI: 10.1101/2020.10.25.20219063</p>



<p><strong>Further information</strong></p>

<p>Dr. Emma Hodcroft, University of Basel, Biozentrum, email: <a href="mailto:emma.hodcroft@unibas.ch">emma.hodcroft@unibas.ch</a> (fast response time, please email to schedule a call)</p>

<p>Prof. Dr. Tanja Stadler, ETH Zürich, Department of Biosystems Science and Engineering, phone <a href="tel:+41 61 387 34 10">+41 61 387 34 10</a>, email: <a href="mailto:tanja.stadler@bsse.ethz.ch">tanja.stadler@bsse.ethz.ch</a></p>

<p>Prof. Dr. Iñaki Comas Espadas, Biomedicine Institute of Valencia (IBV), Spanish Research Council (CSIC), phone <a href="tel:+34 96 339 3773">+34 96 339 3773</a>, email: <a href="mailto:icomas@ibv.csic.es">icomas@ibv.csic.es</a></p>

        </div>

</div></div>]]>
            </description>
            <link>https://www.unibas.ch/en/News-Events/News/Uni-Research/Spread-of-a-novel-SARS-CoV-2-variant-across-Europe-in-summer-2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932985</guid>
            <pubDate>Thu, 29 Oct 2020 17:37:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodcover's (YC S17) Series A Funding: Accelerating Affordable Renters Insurance]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24932805">thread link</a>) | @ddispaltro
<br/>
October 29, 2020 | https://www.goodcover.com/blog/goodcovers-series-a-funding-accelerating-affordable-renters-insurance-offering-in-california-and-beyond/ | <a href="https://web.archive.org/web/*/https://www.goodcover.com/blog/goodcovers-series-a-funding-accelerating-affordable-renters-insurance-offering-in-california-and-beyond/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>At Goodcover, our mission is to elevate financial peace of mind with affordable and effective insurance for all. We <a href="https://www.goodcover.com/blog/announcing-goodcover-renters-insurance/">launched</a> earlier this year with our first product, modern renters insurance. Today we’re announcing funding that will accelerate delivering on that mission.</p><p>Our $7.5M Series A financing is led by Goodwater Capital, with participation from Fuel Capital, Broadhaven Ventures, Global Founders Capital, Liquid 2, and TransRe. We’re especially thrilled to collaborate with the team at Goodwater and their dedicated background in consumer technology who’ve helped fund companies such as Monzo, ZeroDown, and Zumper.</p><h2 id="next-step-bring-affordable-renters-insurance-to-more-states">Next Step: bring affordable renters insurance to more states</h2><p>Today, Goodcover’s renters insurance is only available in California. With this funding we will begin to roll out nationally, helping to bring affordable, effective financial peace of mind to as many people as possible. &nbsp;</p><p>Getting Goodcover launched in one state was a huge process (for gory details read <a href="https://news.ycombinator.com/item?id=22368112">this HN post</a>), but fortunately that was the heavy lifting. While we plan to eventually be available in all 50 states, launching an insurance offering in each one is a separate process - especially with a novel cooperative model like ours - so we’ll be announcing them as soon we can. &nbsp;</p><p>If you want to be notified when Goodcover starts up in your state, please <a href="http://www.goodcover.com/join">click here</a> to drop in your zip and email to let us know.</p><p>PS - I’ve focused on the fact that we’ll roll out renters in more states, but the truth is our mission demands that we offer more than just renters Insurance. We are working on home and condo as well, and evaluating opportunities in auto and life insurances, so stay tuned.</p><h2 id="member-cooperative-the-fair-model">Member Cooperative: The Fair Model</h2><p>Critical to our success has been our relationship with Goodcover Members - and this starts with our cooperative model that makes insurance fairer and more approachable. As promised when we launched, after a fixed fee we take only what’s needed to cover claims, returning the rest back to members. &nbsp;This is how insurance began - neighbors protecting neighbors - but it is a foreign concept in insurance today. The model works and we’ve proudly returned 1.89% of premium through our <a href="https://www.goodcover.com/blog/2020-member-dividend/">Member Dividend this year</a>. </p><p>Members who don’t want to keep the funds returned to them have the option of contributing them to our Goodpool fund, which is used for good – such as offering <a href="https://www.goodcover.com/blog/free-insurance-for-medical-responders-covid19/">free insurance to medical and other frontline workers fighting COVID-19</a>.</p><h2 id="introducing-the-goodprice-guarantee">Introducing the Goodprice Guarantee</h2><p>It’s also no secret that a large part of Goodcover’s popularity has been the “affordable” part of our mission. On average we are 48% less expensive than legacy providers, but we’ve clocked up to 72% less! We’ve done the work to create efficient, affordable, modern insurance -- we have no middlemen, no agents, no paperwork, no superbowl ads -- we’ve cut out waste with a streamlined digital experience and passed the savings on to members. </p><p>That said, if you have never heard of Goodcover before and are checking us out for the first time, it’s hard to know whether you are getting a good deal, or whether there’s some sort of gotcha. Well, you are, and there isn’t - but it’s our job to prove it to you. &nbsp;We get it, it’s easy to get overwhelmed browsing sales ridden comparison sites that look to complicate a pretty simple thing.</p><p>So, we’re introducing the Goodprice Guarantee. If after joining, you find a better deal somewhere else, simply send us your new policy offer - we’ll refund your Goodcover premium fully. </p><h2 id="hiring-join-us-">Hiring! Join Us.</h2><p>We’ve got a lot to do, so we’re going to need help! Join our all-remote team, we’re looking for: <a href="https://angel.co/company/goodcover-co/jobs/1038060-design-lead">Design Lead</a>, <a href="https://angel.co/company/goodcover-co/jobs/299516-senior-backend-engineer">Senior Backend Engineer</a>, <a href="https://angel.co/company/goodcover-co/jobs/1038024-senior-frontend-engineer">Senior Frontend Engineer</a>, licensed agents to support the Member Experience, Growth Marketers, and everything in between. If you don’t see a specific role open send us a note to <a href="mailto:careers@goodcover.com">careers@goodcover.com</a>.</p><h2 id="get-covered">Get Covered</h2><p>Finally, our continual PSA: if you’ve never had renters insurance there’s no better time to start than today (especially given the tragic wildfires that ravaged the west coast). It starts at $5 a month, you can cancel anytime, it takes only a few minutes (record time is 57 seconds!)... There is no reason not to have it, yet we see so many people who are not protected. Please get it, if not with us, with someone, to protect yourself and your family from unnecessary pain.</p><p>If you’re insured already, send us your policy to <a href="mailto:compare@goodcover.com">compare@goodcover.com</a> and we’ll send you back a detailed coverage comparison showing you how much you can save. If you like what you see, you can join instantly, and we’ll do the work of cancelling and refunding your old policy for you.</p><h2 id="thank-you-members-thank-you-team">Thank you members, thank you team</h2><p>This is a big day for Goodcover - I am so thankful for all the hard work and persistence of the team and everything you have done so far - and I am excited for what we’ll do next.</p><p>And to Goodcover Members - thank you for trusting us with your insurance. We know it’s an act of faith to contribute your real hard earned money in exchange for the promise that we’ll be there when you need us. We’ll make you proud!<br></p><p>Chris Lotz</p><p>CEO and co-founder</p></div></div></div>]]>
            </description>
            <link>https://www.goodcover.com/blog/goodcovers-series-a-funding-accelerating-affordable-renters-insurance-offering-in-california-and-beyond/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932805</guid>
            <pubDate>Thu, 29 Oct 2020 17:20:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git Shared Hosting Quirk]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932793">thread link</a>) | @zdw
<br/>
October 29, 2020 | https://daniel-lange.com/archives/165-Git-shared-hosting-quirk.html | <a href="https://web.archive.org/web/*/https://daniel-lange.com/archives/165-Git-shared-hosting-quirk.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
    
        <nav id="primary-nav">
        

        <ul><li><a href="https://daniel-lange.com/">Blog</a></li><li><a href="https://daniel-lange.com/pages/software.html">Software</a></li><li><a href="https://daniel-lange.com/pages/contact.html">Contact</a></li></ul>
    </nav>
        <div>
        <main id="content">
        
            <article id="post_165">
        <header>
            <h2><a href="https://daniel-lange.com/archives/165-Git-shared-hosting-quirk.html">Git shared hosting quirk</a></h2>

            
        </header>

        <div>
        <p><a href="https://daniel-lange.com/categories/2-IT"><img title="IT: Information Technology" alt="IT" src="https://daniel-lange.com/uploads/IT.serendipityThumb.jpg"></a></p><p>Show <a href="https://github.com/torvalds/linux/blob/b4061a10fc29010a610ff2b5b20160d7335e69bf/drivers/hid/hid-samsung.c#L113-L118">https://github.com/torvalds/linux/blob/b4061a10fc29010a610ff2b5b20160d7335e69bf/drivers/hid/hid-samsung.c#L113-L118</a> to a friend.</p>

<p>Oops 'eh? Yep, Linux has been backdoored.</p>

<p>Well, or not.</p>

<p><a href="https://mricon.com/">Konstantin Ryabitsev</a> explains it nicely in a <a href="https://lists.zx2c4.com/pipermail/cgit/2020-October/004571.html">cgit mailing list email</a>:</p>

<blockquote>
It is common for git hosting environments to configure all forks of the
same repo to use an "object storage" repository. For example, this is
what allows git.kernel.org's 600+ forks of linux.git to take up only
10GB on disk as opposed to 800GB.

One of the side-effects of this setup is that any object in the shared
repository can be accessed from any of the forks, which periodically
confuses people into believing that something terrible has happened.
</blockquote>

<p>The hack was <a href="https://github.com/torvalds/linux/commit/b4061a10fc29010a610ff2b5b20160d7335e69bf#diff-b2b8b8422630002a41cf5901247f9a6af2cc8d000fc792ef7aae9ea1f393f8b4">discussed on Github in Dec 2018</a> 
when it was discovered. I forgot about it again but Konstantin's mail brought the memory back and I think it deserves more attention.</p>

<p>I'm sure putting some illegal content into a fork and sending a made up "blob" URL to law enforcement would go quite far.
Good luck explaining the issue. <i>"Yes this is my repo"</i> but <i>"no, no that's not my data"</i> ... <i>"yes, it <u>is</u> my repo but not my data"</i> ... <i>"no we don't want that data either, really"</i> ... <i>"but, but there is nothing we can do, we host on github...<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>"</i>.</p>



                </div>
                
        

        <!--
        <rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
                 xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/"
                 xmlns:dc="http://purl.org/dc/elements/1.1/">
        <rdf:Description
                 rdf:about="https://daniel-lange.com/feeds/ei_165.rdf"
                 trackback:ping="https://daniel-lange.com/comment.php?type=trackback&amp;entry_id=165"
                 dc:title="Git shared hosting quirk"
                 dc:identifier="https://daniel-lange.com/archives/165-Git-shared-hosting-quirk.html" />
        </rdf:RDF>
        -->

                                            
        

        
            <a id="feedback"></a>
                        

        
    </article>
        



        </main>
                
        </div>

    
</div></div>]]>
            </description>
            <link>https://daniel-lange.com/archives/165-Git-shared-hosting-quirk.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932793</guid>
            <pubDate>Thu, 29 Oct 2020 17:18:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Fexprs and Defmacro]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24932701">thread link</a>) | @sea6ear
<br/>
October 29, 2020 | https://www.brinckerhoff.org/scraps/joe-marshall-on-FEXPRS-and-DEFMACRO.txt | <a href="https://web.archive.org/web/*/https://www.brinckerhoff.org/scraps/joe-marshall-on-FEXPRS-and-DEFMACRO.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.brinckerhoff.org/scraps/joe-marshall-on-FEXPRS-and-DEFMACRO.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932701</guid>
            <pubDate>Thu, 29 Oct 2020 17:09:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Open-source, fully customizable voice and chat widgets for the web]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24932588">thread link</a>) | @JanKoenig
<br/>
October 29, 2020 | https://www.jovo.tech/news/2020-10-29-jovo-for-web-v3-2 | <a href="https://web.archive.org/web/*/https://www.jovo.tech/news/2020-10-29-jovo-for-web-v3-2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/jovo-for-web.jpg"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/jovo-for-web.jpg" alt="Jovo for Web Open Source Voice and Chat" title="Introducing Jovo for Web: Customizable Voice and Chat for the Browser"></a></p><p>With the release <code>v3.2</code> of the <a href="https://github.com/jovotech/jovo-framework">Jovo Framework</a>, we're excited to present a completely revamped web integration.</p><p><em>Jovo for Web</em> allows you to build fully customizable voice and chat apps that work in the browser. And it even comes with 4 open source templates (gifs below!) that help you get started.</p><ul>
<li><a href="#jovo-for-web-features">Jovo for Web Features</a></li>
<li><a href="#select-from-4-starter-templates">Select from 4 Starter Templates</a>
<ul>
<li><a href="#standalone-voice-experience">Standalone Voice Experience</a></li>
<li><a href="#voice-overlay">Voice Overlay</a></li>
<li><a href="#chat-widget">Chat Widget</a></li>
<li><a href="#embedded-chat">Embedded Chat</a></li>
</ul></li>
<li><a href="#more-new-features">More New Features</a></li>
<li><a href="#how-to-update">How to Update</a>
<ul>
<li><a href="#breaking-changes">Breaking Changes</a></li>
</ul></li>
<li><a href="#a-big-thank-you">A Big Thank You</a></li>
</ul><p><em>Like what we're doing? <a href="https://opencollective.com/jovo-framework">Support us on Open Collective!</a></em> </p><h2 id="jovo-for-web-features"><a href="#jovo-for-web-features">Jovo for Web Features</a></h2><p>Let's build voice and chat apps for the browser!</p><p>In our <a href="https://www.context-first.com/introducing-jovo-v3-the-voice-layer/">v3 announcement</a>, we already mentioned that Jovo works with web apps and websites thanks to the <a href="https://www.context-first.com/introduction-voice-multimodal-interactions/">RIDR Lifecycle</a> and <a href="https://www.jovo.tech/news/www.jovo.tech/marketplace">Jovo Marketplace</a>.</p><p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/jovo-web-ridr-lifecycle.jpg"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/jovo-web-ridr-lifecycle.jpg" alt="Jovo for Web RIDR Lifecycle" title="Integrate ASR and NLU into Web Apps with Jovo and RIDR"></a></p><p>Today, we're thrilled to announce a completely improved verson of our <strong>Jovo for Web</strong> platform.</p><p>Features include:</p><ul>
<li>Support for speech, text, and touch input</li>
<li>Multimodal: Complex visual and audio output possible</li>
<li>Open source and fully customizable</li>
<li><a href="#select-from-4-starter-templates">4 starter templates</a> built with modern technologies like Vue.js and Tailwind CSS</li>
</ul><p>We can't wait to see and hear what you build with this!</p><h2 id="select-from-4-starter-templates"><a href="#select-from-4-starter-templates">Select from 4 Starter Templates</a></h2><p>To help you get started quickly, we built 4 templates with Vue.js and Tailwind CSS that implement use cases for both voice and chat.</p><h3 id="standalone-voice-experience"><a href="#standalone-voice-experience">Standalone Voice Experience</a></h3><blockquote>
<p>Find this starter on GitHub: <a href="https://github.com/jovotech/jovo-starter-web-standalone">github.com/jovotech/jovo-starter-web-standalone</a></p>
</blockquote><p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-standalone.gif"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-standalone.gif" alt="Jovo Starter: Standalone Voice Experience" title="Introducing Jovo for Web: Customizable Voice and Chat in the Browser"></a></p><p>This starter brings your voice experiences into the browser as a standalone web app. This can be seen as an experience equivalent to a smart display. Many Alexa Skills and Google Actions like voice games can be brought to the web using this template.</p><p>The starter includes:</p><ul>
<li>a push-to-talk button</li>
<li>a display of the transcribed speech above the button</li>
<li>app output at the top of the screen</li>
<li>conversational logic that switches to dark/light mode using custom web actons</li>
</ul><p><a href="https://www.jovo.tech/demos/starter-web-standalone">Check out the demo here!</a> Hold the button and say "<em>switch to dark mode.</em>"</p><h3 id="voice-overlay"><a href="#voice-overlay">Voice Overlay</a></h3><blockquote>
<p>Find this starter on GitHub: <a href="https://github.com/jovotech/jovo-starter-web-overlay">github.com/jovotech/jovo-starter-web-overlay</a></p>
</blockquote><p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-overlay.gif"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-overlay.gif" alt="Jovo Starter: Voice Overlay" title="Introducing Jovo for Web: Customizable Voice and Chat in the Browser"></a></p><p>This starter adds a speech input button as an overlay to an existing website or web app. Voice interactions like search, customizations, and deep access of features could be added using the overlay.</p><p>The starter includes:</p><ul>
<li>a push-to-talk button</li>
<li>a display of the transcribed speech left to the button</li>
<li>conversational logic that switches to dark/light mode using custom web actons</li>
</ul><p><a href="https://www.jovo.tech/demos/starter-web-overlay">Check out the demo here!</a> Hold the button and say "<em>switch to dark mode.</em>"</p><h3 id="chat-widget"><a href="#chat-widget">Chat Widget</a></h3><blockquote>
<p>Find this starter on GitHub: <a href="https://github.com/jovotech/jovo-starter-web-chatwidget">github.com/jovotech/jovo-starter-web-chatwidget</a></p>
</blockquote><p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-chatwidget.gif"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-chatwidget.gif" alt="Jovo Starter: Open Source Chat Widget" title="Introducing Jovo for Web: Customizable Voice and Chat in the Browser"></a></p><p>This starter adds a classic chat widget to your website. Think chatbots and conversational experiences for customer support and more.</p><p>The starter includes:</p><ul>
<li>a bottom-right toggle button</li>
<li>text input and quick replies</li>
<li>conversational logic that asks the user to open the Jovo Docs (redirect not working on iOS due to platform limitations)</li>
</ul><p><a href="https://www.jovo.tech/demos/starter-web-chatwidget">Check out the demo here!</a></p><h3 id="embedded-chat"><a href="#embedded-chat">Embedded Chat</a></h3><blockquote>
<p>Find this starter on GitHub: <a href="https://github.com/jovotech/jovo-starter-web-embeddedchat">github.com/jovotech/jovo-starter-web-embbeddedchat</a></p>
</blockquote><p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-embeddedchat.gif"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-embeddedchat.gif" alt="Jovo Starter: Open Source Embedded Chat" title="Introducing Jovo for Web: Customizable Voice and Chat in the Browser"></a></p><p>This starter adds a customizable chat interface to your website that can be used for things like conversational landing pages, FAQs, mobile chat support, and much more.</p><p>The starter includes:</p><ul>
<li>fullsize chat component that can be embedded into an existing website</li>
<li>text input and quick replies</li>
<li>conversational logic that asks the user to open the Jovo Docs (redirect not working on iOS due to platform limitations)</li>
</ul><p><a href="https://www.jovo.tech/demos/starter-web-embeddedchat">Check out the demo here!</a></p><h2 id="more-new-features"><a href="#more-new-features">More New Features</a></h2><p>Alongside the big launch of Jovo for Web, we also shipped some other improvements and bug fixes with the help of our community. <a href="https://github.com/jovotech/jovo-framework/blob/master/CHANGELOG.md">You can find the full changelog here</a>.</p><ul>
<li>We released Google Conversational Actions. <a href="https://www.jovo.tech/news/2020-10-08-google-conversational-actions-builder">Find the announcement here</a>.</li>
<li>New analytics integration: <a href="https://www.jovo.tech/marketplace/jovo-analytics-onedash">OneDash</a>. <em>Thanks to <a href="https://github.com/StepanU">StepanU</a>!</em></li>
<li><a href="https://github.com/jovotech/jovo-framework/pull/838">Dialogflow Genesys integration</a>. <em>Thanks to <a href="https://github.com/dominik-meissner">Dominik Meissner</a>!</em></li>
</ul><h2 id="how-to-update"><a href="#how-to-update">How to Update</a></h2><blockquote>
<p><a href="https://www.jovo.tech/docs/installation/upgrading">Learn more in the Jovo Upgrading Guide</a>.</p>
</blockquote><p>To update to the latest version of Jovo, use the following commands:</p><h3 id="breaking-changes"><a href="#breaking-changes">Breaking Changes</a></h3><p>The "Jovo Web Client" and "Jovo Web Platform" were completely refactored for this release.</p><h2 id="a-big-thank-you"><a href="#a-big-thank-you">A Big Thank You</a></h2><p>Thanks a lot to all the contributors of this release. Everyone of the Jovo core team worked together to make this happen! Special thanks to Max who started working on the web integration more than a year ago as part of his bachelor's thesis.</p><p>Community and core contributors:</p><ul>
<li><a href="https://github.com/StepanU">StepanU</a></li>
<li><a href="https://github.com/dominik-meissner">Dominik Meissner</a></li>
<li><a href="https://github.com/rubenaeg">Ruben Aegerter</a></li>
<li><a href="https://github.com/KaanKC">Kaan Kilic</a></li>
<li><a href="https://github.com/m-ripper">Max Ripper</a></li>
<li><a href="https://github.com/aswetlow">Alex Swetlow</a></li>
</ul><p>And to everyone else who helped with ideas and feature requests in the <a href="https://www.jovo.tech/slack">Jovo Slack</a> and <a href="https://community.jovo.tech/">Jovo Community Forum</a>!</p>
</article></div>]]>
            </description>
            <link>https://www.jovo.tech/news/2020-10-29-jovo-for-web-v3-2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932588</guid>
            <pubDate>Thu, 29 Oct 2020 16:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5M Canadian shoppers' images collected at mall kiosks]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932467">thread link</a>) | @anonymousab
<br/>
October 29, 2020 | https://www.ctvnews.ca/canada/5-million-canadian-shoppers-images-collected-at-mall-kiosks-privacy-commissioner-1.5166162 | <a href="https://web.archive.org/web/*/https://www.ctvnews.ca/canada/5-million-canadian-shoppers-images-collected-at-mall-kiosks-privacy-commissioner-1.5166162">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>OTTAWA -- 
	Without customers’ knowledge, more than five million images of Canadian shoppers were collected through facial recognition software used by Cadillac Fairview, a parent company of malls across the country, <a href="https://www.priv.gc.ca/en/opc-actions-and-decisions/investigations/investigations-into-businesses/2020/pipeda-2020-004/" target="_blank">according to an investigation by privacy officials.</a></p>
<p>
	The federal privacy commissioner reported Thursday that Cadillac Fairview contravened federal and provincial privacy laws by embedding cameras inside digital information kiosks at 12 shopping malls across Canada, and captured users’ images without their consent.</p>
<p>
	The facial recognition software installed in Cadillac Fairview’s “wayfinding” directories was called “Anonymous Video Analytics (AVA) and through cameras installed behind protective glass, was used in Canadian malls for a brief testing period in 2017 and then was in-use between May and July of 2018.</p>
<p>
	The software took temporary digital images of the faces of any individual within the field of view of the camera inside the directory and converted the images into biometric numerical representations of each face and used that information to compile demographic information about mall visitors.</p>
<p>
	According to the report, the technology was used in directories at the following locations:</p>
<ul>
	<li>
		CF Market Mall in Alberta</li>
	<li>
		CF Chinook Centre in Alberta</li>
	<li>
		CF Richmond Centre in British Columbia</li>
	<li>
		CF Pacific Centre in British Columbia</li>
	<li>
		CF Polo Park in Manitoba</li>
	<li>
		CF Toronto Eaton Centre in Ontario</li>
	<li>
		CF Sherway Gardens in Ontario</li>
	<li>
		CF Lime Ridge in Ontario</li>
	<li>
		CF Fairview Mall in Ontario</li>
	<li>
		CF Markville Mall in Ontario</li>
	<li>
		CF Galeries d’Anjou in Quebec</li>
	<li>
		CF Carrefour Laval in Quebec</li>
</ul>
<p>
	According to a statement from Privacy Commissioner of Canada Daniel Therrien, the company said the goal of its cameras was to “analyze the age and gender of shoppers and not to identify individuals.”</p>
<p>
	The corporation said that it did not collect personal information because the images were briefly looked at and then deleted, however the information generated from the images was being stored by a third-party contractor called Mappedin, which Cadillac Fairview said it was unaware of.</p>
<p>
	“When asked the purpose for such collection, Mappedin was unable to provide a response, indicating that the person responsible for programming the code no longer worked for the company,” reads the report.</p>
<p>
	Therrien notes in his report that Cadillac Fairview not being aware of Mappedin’s storage of the information “compounded the risk of potential use by unauthorized parties or, in the case of a data breach, by malicious actors.”</p>
<p>
	In an interview on CTV’s Power Play, Deputy Commissioner Brent Homan called it a “massive invasion of privacy” and not one that shoppers would have expected while at the mall. Homan said that one of the lessons Canadians should take away from this report is that facial recognition software is available for companies to use, and while they encourage entities to ask for consent before deploying it on the public, that’s not always the case.&nbsp;</p>
<p>
	Cadillac Fairview—one of the largest owners and operators of retail and other properties in North America—“expressly disagreed” with the investigation’s findings, telling the commissioners that there were decals placed on shopping mall entry doors noting their privacy policy.</p>
<p>
	These stickers directed visitors to visit guest services to obtain a copy of the company’s privacy policy, but when the investigators asked a guest services employee at the Eaton location in Toronto, the employee was “confused by the request” and so Therrien found the stickers to be an “insufficient” measure.</p>
<p>
	“Shoppers had no reason to expect their image was being collected by an inconspicuous camera, or that it would be used, with facial recognition technology, for analysis,” said Therrien in a statement. “The lack of meaningful consent was particularly concerning given the sensitivity of biometric data, which is a unique and permanent characteristic of our body and a key to our identity.”</p>
<p>
	The investigation was launched in 2018, following several media reports about information kiosks in malls being equipped with unmarked cameras to monitor visitor demographics. Their examination in this case included visiting Cadillac Fairview’s Toronto headquarters to interview key personnel, viewing the AVA technology inside the wayfinding directories in action, and extracting records from the directories for forensic analysis.</p>
<p>
	The existence of the software came to light after a user posted an image to Reddit of a display screen at the CF Chinook Centre in Calgary showing coding language including “FaceEncoder” and “FaceAnalyzer.”</p>
<p>
	Commissioner Therrien’s office worked with Alberta Information and Privacy Commissioner Jill Clayton as well as the Information and Privacy Commissioner of British Columbia Michael McEvoy on the investigation.</p>
<p>
	“Not only must organizations be clear and up front when customers’ personal information is being collected, they must also have proper controls in place to know what their service providers are doing behind the scenes with that information,” Clayton said in a statement.</p>
<p>
	The trio of commissioners have expressed concern that the company hasn’t accepted their request to commit to ensuring meaningful and express consent is obtained from shoppers in the future should it choose to redeploy similar technology in the future.</p>
<p>
	In a statement provided to CTV News, Cadillac Fairview notes that the issue has been resolved, the data deleted, and the cameras have been deactivated. As well, the facial recognition software is no longer in use, but the company says it will not commit to its approach to “hypothetical future uses of similar technology.”</p>
<p>
	“The five million representations referenced in the OPC report are not faces. These are sequences of numbers the software uses to anonymously categorize the age range and gender of shoppers in the camera’s view,” the company said. “We thank the Privacy Commissioner for the report and recommendations on how to further strengthen our privacy practices and agree that the privacy of our visitors must always be a top priority.”&nbsp;</p>
                                              </div></div>]]>
            </description>
            <link>https://www.ctvnews.ca/canada/5-million-canadian-shoppers-images-collected-at-mall-kiosks-privacy-commissioner-1.5166162</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932467</guid>
            <pubDate>Thu, 29 Oct 2020 16:48:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automated String Deobfuscation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932452">thread link</a>) | @todsacerdoti
<br/>
October 29, 2020 | https://www.securify.nl/blog/dynamic-string-deobfuscation-on-android | <a href="https://web.archive.org/web/*/https://www.securify.nl/blog/dynamic-string-deobfuscation-on-android">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="introduction">Introduction</h2>
<p>A couple years ago when I analyzed Android malware at <a href="https://www.threatfabric.com/">Threat Fabric</a> we encountered a time consuming problem.
Obfuscated strings, a lot of malware did it and most of them in different ways.
Strings are definitely useful while analyzing malware, they give out a lot of information about what is happening under the hood.</p>
<p>At first we wrote a custom plugin for our decompiler for every type of string obfuscation we encountered.
However, this was very time consuming, so I tried to come up with a more efficient solution.
In this blogpost I will be going over my proposed solution, explain how it works, why I did some things the way I did and the challenges.</p>
<h2 id="problem-definition">Problem definition</h2>
<p>As briefly discussed in the introduction, our main problem is string obfuscation. Here I will be explaining the problem more in-depth, so skip ahead if you are already familiar.</p>
<p>When reverse engineering Android malware, or any malware for that matter, malware authors will try their best to hide their intentions from analysts. Let's look at a real-life sample.</p>
<div data-language="java"><pre><code><span>package</span> <span>com<span>.</span>threesuchm</span><span>;</span>

<span>import</span> <span>android<span>.</span>app<span>.</span>admin<span>.</span></span><span>DeviceAdminReceiver</span><span>;</span>
<span>import</span> <span>android<span>.</span>content<span>.</span></span><span>Context</span><span>;</span>
<span>import</span> <span>android<span>.</span>content<span>.</span></span><span>Intent</span><span>;</span>

<span>public</span> <span>class</span> p044x <span>extends</span> <span>DeviceAdminReceiver</span> <span>{</span>
   <span>public</span> <span>void</span> <span>onDisabled</span><span>(</span><span>Context</span> var1<span>,</span> <span>Intent</span> var2<span>)</span> <span>{</span>
      <span>double</span><span>.</span><span>ifdf</span><span>(</span>var1<span>,</span> <span>class</span><span>.</span><span>fddo</span><span>(</span><span>"8aa669cb198f9845042291e46b13a0c1"</span><span>)</span><span>,</span> <span>false</span><span>)</span><span>;</span>
   <span>}</span>

   <span>public</span> <span>void</span> <span>onEnabled</span><span>(</span><span>Context</span> var1<span>,</span> <span>Intent</span> var2<span>)</span> <span>{</span>
      <span>double</span><span>.</span><span>ifdf</span><span>(</span>var1<span>,</span> <span>class</span><span>.</span><span>fddo</span><span>(</span><span>"8aa669cb198f9845042291e46b13a0c1"</span><span>)</span><span>,</span> <span>true</span><span>)</span><span>;</span>
   <span>}</span>

   <span>public</span> <span>void</span> <span>onReceive</span><span>(</span><span>Context</span> var1<span>,</span> <span>Intent</span> var2<span>)</span> <span>{</span>
      <span>super</span><span>.</span><span>onReceive</span><span>(</span>var1<span>,</span> var2<span>)</span><span>;</span>
   <span>}</span>
<span>}</span></code></pre></div>
<p>Let's unpack this. Something which immediately catches the eye is the use of <code>double</code> here, because in Java the <code>double</code> is a primitive data type and they seem to call a rather strange method. Upon further analysis of the malware it seems they have made their own class which they called <code>double</code>. They probably did this because they attempted to trip up decompilers and more novice analysts.</p>
<p>Another similar type of obfuscation can be seen within the parenthesis of the aforementioned method call. Now suppose we wanted to know what the <code>onEnabled</code> method here does. Firstly they call the following method:</p>
<div data-language="java"><pre><code><span>public</span> <span>static</span> <span>void</span> <span>ifdf</span><span>(</span><span>Context</span> var0<span>,</span> <span>String</span> var1<span>,</span> <span>Boolean</span> var2<span>)</span> <span>{</span>
    var0<span>.</span><span>getSharedPreferences</span><span>(</span><span>class</span><span>.</span><span>fddo</span><span>(</span><span>"83a276cc"</span><span>)</span><span>,</span> <span>0</span><span>)</span><span>.</span><span>edit</span><span>(</span><span>)</span><span>.</span><span>putBoolean</span><span>(</span>var1<span>,</span> var2<span>)</span><span>.</span><span>apply</span><span>(</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>This method alters the Shared Preferences of the app. As you can see this method takes three arguments,
<code>Context</code>, a <code>String</code> and a <code>Boolean</code>. If we now look at the call site again we can see that the following is passed as a <code>String</code>:</p>
<div data-language="java"><pre><code><span>class</span><span>.</span><span>fddo</span><span>(</span><span>"8aa669cb198f9845042291e46b13a0c1"</span><span>)</span></code></pre></div>
<p>The keyword <code>class</code> is used here, but this is also a class they made themselves, just like <code>double</code>. The signature of this method is:</p>
<div data-language="java"><pre><code><span>public</span> <span>static</span> <span>String</span> <span>fddo</span><span>(</span><span>String</span> var0<span>)</span></code></pre></div>
<p>In other words, it is a method which takes a <code>String</code> and returns a <code>String</code>.
This is what we call string obfuscation. The actual <code>String</code> used here does not appear in the
decompiled code, but is computed at runtime.
So if I want to know what <code>String</code> is computed there, I would need to reverse engineer the method which computes the <code>String</code>.
These methods can be lengthy, there can also be a couple of different ones. More importantly, I need to reverse engineer every obfuscation method for every sample I analyze.
As there are a infinite ways of implementing string obfuscation, reverse engineering string obfuscation is a never-ending endeavour.</p>
<p>SHA256 hash of the sample used:</p>
<p><code>b918f476abaf16b19b0115f22e85a0e2b5946e3b9cb386bf80d5785698472961</code></p>
<h2 id="architecture">Architecture</h2>
<p><img src="https://www.datocms-assets.com/21957/1602234083-stringdeobfuscation.png"></p>
<p>Deobfuscation will be achieved through code injection. We will inject code into every app on the device so we can communicate with it. A server will run on the device which will receive information from my decompiler which runs on my computer. The decompiler first analyzes the code, extracts all necessary information and sends it to the server. The server will send this information to the target-app.
The injected code inside of the target-app will then use this information to hook the deobfuscation method and call it with the provided arguments.
This will result in the deobfuscated strings. These will be sent back to the server, which will send this back to my decompiler, which will show up in my view instead of the method call to deobfuscate a string.</p>
<h3 id="server">Server</h3>
<p>The server running on the Android device opens a socket and waits for a connection. My decompiler will connect to it and send it some information, like the following:</p>
<div data-language="json"><pre><code><span>{</span>
    <span>"data"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"static"</span><span>:</span> <span>true</span><span>,</span>
            <span>"methodName"</span><span>:</span> <span>"test"</span><span>,</span>
            <span>"className"</span><span>:</span> <span>"ObfuscationMethods"</span><span>,</span>
            <span>"locationPackage"</span><span>:</span> <span>"nl.securify.stringobfuscationtest"</span><span>,</span>
            <span>"arguments"</span><span>:</span> <span>[</span>
                <span>{</span>
                    <span>"type"</span><span>:</span> <span>"Ljava/lang/String;"</span><span>,</span>
                    <span>"arg"</span><span>:</span> <span>"test"</span>
                <span>}</span>
            <span>]</span>
        <span>}</span>
    <span>]</span><span>,</span>
    <span>"manifestPackagename"</span><span>:</span> <span>"nl.securify.stringobfuscationtest"</span>
<span>}</span></code></pre></div>
<p>This JSON contains all the information necessary to look for the app <code>nl.securify.stringobfuscationtest</code> and calling the <code>test</code> method in class <code>ObfuscationMethods</code> with single <code>String</code> argument <code>"test"</code>.  The server will broadcast this JSON to all the apps on the device using an <code>Intent</code>. The server exposes an <code>IntentService</code> which will receive the deobfuscated strings. Once our target app has send the deobfuscated strings to the <code>IntentService</code>, the server returns it to my decompiler.</p>
<h3 id="code-injection">Code injection</h3>
<p>To achieve code injection we will use the Xposed framework which makes it relatively easy to inject code into an app. The injected code will register a Broadcast Receiver. So every app on the device now exposes a Broadcast Receiver which we can talk to! We essentially created our own API inside of all the other apps on our device.</p>
<p>Upon receiving a broadcast message we will check if the server is requesting something from us. If not, we stop. If it is the current app the server is requesting, the app will read all the information. Using the information it will call the specified methods with the specified arguments. The results of these method calls are the deobfuscated strings. Once all the methods have been called the injected code will send the deobfuscated strings to the server using an <code>Intent</code>. The response will look like this:</p>
<div data-language="json"><pre><code><span>{</span>
    <span>"deobfuscated"</span><span>:</span> <span>[</span>
        <span>"Foobar"</span>
    <span>]</span>
<span>}</span></code></pre></div>
<p>Currently deobfuscation is limited to static-methods only, luckily most string obfuscation solutions use static methods.</p>
<h3 id="client">Client</h3>
<p>Currently I have only implemented a client for the JEB decompiler. The plugin analyzes the currently opened class, searches for predefined signatures, e.g.: A method call which is static, takes a String as input and returns a String as output. It will create a JSON payload like the one in the Server section, send it to the server and wait for a response. Once the response is received the strings will show up in my view instead of method calls to deobfuscate strings.</p>
<p>As the protocol is simple, it should not be too complicated to add support for more decompilers. The biggest hurdle is getting the analysis right.</p>
<h2 id="considerations">Considerations</h2>
<h3 id="why-dynamically">Why dynamically?</h3>
<p>Firstly because it required less work. To me it seemed easier to use code injection as a means to deobfuscate strings than to write my own emulator or use someone else's emulator (which were mostly buggy and hard to use at the time of developing this).</p>
<h3 id="why-xposed">Why Xposed?</h3>
<p>Another attractive <a href="https://github.com/securifybv/xposed-deobfuscation-module">tool</a> would be Frida. Frida is a great tool which I use daily while pentesting mobile apps. However, at the time of developing this tool I was less acquainted with Frida and more so with Xposed. Also, Xposed proves to be more stable than Frida most of the time.</p>
<h2 id="challenges">Challenges</h2>
<h3 id="hookability">Hookability</h3>
<p>For the deobfuscation to succeed we need to be able to hook the app.
However, this can pose to be a challenge.</p>
<p>When analyzing an older malware sample it would check if its C2 (Command &amp; Control) server was up.
If it was not, it would quit and therefore significantly increase the level of difficulty to deobfuscate strings.
I am pretty certain there exists a solution to this, I just have not come around to research what it is.</p>
<p>Lots of Android malware also turned off their main component. This ensures the user does not see the app icon in the app drawer.
But this also means that when the malware terminates itself, you cannot start it by sending a normal <code>Intent</code>.</p>
<p>Also RASP solutions which detect and (technically) prevent hooking will make it harder to use this solution for deobfuscation.</p>
<h2 id="when-to-use">When to use?</h2>
<p>This <a href="https://github.com/securifybv/xposed-deobfuscation-module">tool</a>  can be used when dealing with <code>String</code> obfuscation on the Java layer. Although not every type of obfuscation is supported, it would not be complicated to add support for more ways of <code>String</code> obfuscation on the Java layer.</p>
<h2 id="conclusion">Conclusion</h2>
<p>There is definitely lots that can be improved upon, but it is a nice start.
Whenever I have had to deal with string obfuscation on the Java layer, this tool has helped me deobfuscate most of them.
I hope this tool can help others facing the same issues.</p>
<p>Thanks for reading.</p></div></div>]]>
            </description>
            <link>https://www.securify.nl/blog/dynamic-string-deobfuscation-on-android</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932452</guid>
            <pubDate>Thu, 29 Oct 2020 16:47:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mourning My Father by Open Sourcing Our Code]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932411">thread link</a>) | @tcgarvin
<br/>
October 29, 2020 | https://www.tcgarvin.com/trafcap | <a href="https://web.archive.org/web/*/https://www.tcgarvin.com/trafcap">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><img alt="Pete Garvin" width="100%" src="https://www.tcgarvin.com/images/dad-compressed.jpg"></p><p><em>Tl;dr: I miss my dad.  I <a href="https://github.com/protectus/pfring-to-mongo">published</a> some of the code we wrote together.</em></p><h3>Background</h3><p>The phone call was short.  I asked how he was feeling, and if they had figured out what was going on yet. Dad evaded. They were still getting answers, he said. That was all I needed to hear.  I walked to the nearby park in the Fall air, sat on a bench under a remote tree, and lost my composure.</p><p>Sobbing is a really weird sound, I thought to myself. Gasps and sniffs, heaves, tears, borderline hyperventilation. I was not used to hearing these noises come from me, especially when I had nothing more than my gut to inform my fears.</p><p>But I'd heard it in his voice. Everything was not alright. The world was ending.</p><p>As I grew up, it always seemed a little irrational to me that my deepest terror was losing my dad. At 15 years old, then 20, 25, I never really heard anyone around me talking about how vitally important their dads were to them. And besides, it’s natural that a son lose his father, rather than a father lose his son. Right? And yet, even after the birth of my own sons reoriented my hopes and fears, the only anxiety late at night that could consistently latch onto my mind — and not let go — was how much I couldn’t bear to lose Dad.  Now my literal nightmares materialized.</p><p>Today is the first aniversary of Pete Garvin's death. He died of cancer 4 weeks after his initial diagnosis. The weather report says it will rain all day today from the hurricane. A family friend told me the rain is from him for us, and I believe her.</p><h2>My Motivations, In Brief</h2><p>Before he fell ill, Dad and I would meet one evening a week at his office in Akron and work on little things around his company, <a href="https://www.protectus.com/">Protectus LLC</a>.  I had helped him build the technology side of the company for a couple of years when I got out of school, and the weekly get together was a good way to exercise parts of my brain that my full-time jobs did not.  It wasn’t lost on me how privileged I was to spend so much time literally being paid to hang out with my own father.  When I look at my career so far, I can trace my success to 3 people.  Dad is at the top of that list.</p><p>I want Dad to be here with me.  I want him to look over my shoulder at this stupid website and tell me that he thinks dark mode is harder to read.  I want to find a way to keep a part of him alive with me, just a little longer.</p><p>So, I’m trying to finalize our last project together.</p><h2>The Project</h2><p>Protectus was built around a product called <a href="https://www.protectus.com/sentry/">the Sentry</a>.  At its core, the Sentry is a combination network sensor and analytics engine.  It reads bytes off the wire, does some deep (and shallow) packet inspection, and dumps information into a local MongoDB database for post-hoc analysis.  Then there’s a web app that facilitates queries and reports.  I wrote the frontend right out of school, and Dad took responsibility for the ingest script.  We designed everything together, spent untold hours in front of the whiteboard diagramming, discussing, and deciding.</p><p><img alt="Dad's whiteboard" width="100%" src="https://www.tcgarvin.com/images/whiteboard-compressed.jpg"><em><small>This is the last whiteboarding Dad and I did.  Notice the contributions for/by my son in the corner.  I can't bring myself to erase any of it.</small></em></p><p>Neither of us were rockstar developers.  Dad’s coding style was informed by C code from the 80s and 90s, with lots of illegible variable names and clever routines that didn't always explain what they were doing.  My code architecture was overly clever and immature, abusing inheritance trees and creating all sorts of extranious abstractions that probably have not aged well.</p><p>We did do some things right, and shipped new Sentry devices to all our existing customers with a year or two of my coming on board.</p><p>The Sentry was not a big commercial success.  I left the company for IBM, and Dad eventually decided to shift cleanly from a product + services company to just a services company.  The Sentry stopped being the main event for the company, and began to be spoken of as just a tool in the toolbox.</p><p>Part of the shift in the Sentry strategy was to open source core parts of the product.  We started with the ingest scripts.  This involved cleaning up the code a bit, and doing some careful git history surgery.  The idea was to publish not just the code, but ship a `pip install`-able module on PyPi.</p><p>I’ve given up on shipping an installable Python module.  PF_RING dropped their repo for the version of Ubuntu we were using to build on Travis, and I don’t have the time or interest to keep the build running.  But I do want to share the code.</p><p><a href="https://github.com/protectus/pfring-to-mongo">Here's the code.</a></p><p>The code itself is probably not very interesting unless you're into parsing network traffic or aggregating it into Mongo. There are some instructions for getting a dev build running, if you're really keen.  This post isn't really about that.</p><p><img alt="Trafcap Contributors" width="100%" src="https://www.tcgarvin.com/images/trafcap-contributors.jpg"><em><small>Dad and I wrote all the code.  This graph shows a partial history of the ingest code I've released, which was more Dad's than mine.</small></em></p><h2>Seeing Dad in the Code</h2><p>In preparing the code to be released, I spent some time browsing git history and its contents.  At first I was caught off guard by how potent seeing his comments was.  It’s not like he left jokes around or anything, but this this codebase (including a lot that I’m not open sourcing today) has his heart and soul in it.</p><pre><code><span><span># Adding vlan id - PFG - April 2014</span><span>
</span></span><span><span></span><span># No way of knowing how long the packet is so add vlan id after timestamp.</span><span>
</span></span><span><span></span><span># If field after timestamp contains dots or colons, then it is a src (mac or ip).</span><span>
</span></span><span><span></span><span># Otherwise, it must be a vlan id.</span><span>
</span></span><span><span></span><span>if</span><span> pkt </span><span>and</span><span> </span><span>not</span><span> doc:
</span></span><span><span>    </span><span># If no vlan id present</span><span>
</span></span><span><span>    </span><span>if</span><span> </span><span>b'.'</span><span> </span><span>in</span><span> pkt[</span><span>1</span><span>] </span><span>or</span><span> </span><span>b':'</span><span> </span><span>in</span><span> pkt[</span><span>1</span><span>]:
</span></span><span><span>        </span><span>if</span><span> pkt[</span><span>4</span><span>] </span><span>in</span><span> pc.leaked_protos_to_ignore: </span><span>return</span><span> (), []
</span></span><span><span>        msg = pkt[</span><span>5</span><span>]
</span></span><span><span>        </span><span>for</span><span> i </span><span>in</span><span> </span><span>range</span><span>(</span><span>6</span><span>, </span><span>len</span><span>(pkt), </span><span>1</span><span>):
</span></span><span><span>            msg = msg + </span><span>b" "</span><span> + pkt[i]
</span></span><span><span>            </span><span># Ensure msg length does not exceed Mongo's Index Key Limit</span><span>
</span></span><span><span>            </span><span>if</span><span> </span><span>len</span><span>(msg) &gt; </span><span>512</span><span>: 
</span></span><span><span>                msg = msg[:</span><span>512</span><span>] + </span><span>b'...'</span><span>
</span></span><span><span>                </span><span>break</span></span></code></pre><p><em><small><a href="https://github.com/protectus/pfring-to-mongo/blob/673415fb721e879f2b3aac9da52dd0454f29f111/trafcap/trafcapEthernetPacket.py#L268">Source</a></small></em></p><p>Dad, your code could be incredibly, uh, organic.  And not always the most deliberate. (sorry) It is exactly what you would expect from a solo C programmer circa 1990, which is basically what dad was.  He would write a passable algorithm the first time, and then tweaked it with if statements over time, resulting in code that was less and less maintainable.  Even though we were working in Python (which I think he really liked), his code structure was the good old C standby of “throw a bunch of functions into a file”.  The mess of code above started out more copacetically.</p><pre><code><span><span># Adding vlan id - PFG - April 2014</span><span>
</span></span><span><span></span><span># No way of knowing how long the packet is so add vlan id after timestamp.</span><span>
</span></span><span><span></span><span># If field after timestamp contains dots or colons, then it is a src (mac or ip).</span><span>
</span></span><span><span></span><span># Otherwise, it must be a vlan id.</span><span>
</span></span><span>         
</span><span><span></span><span>if</span><span> pkt </span><span>and</span><span> </span><span>not</span><span> doc:
</span></span><span><span>    </span><span># If no vlan id present</span><span>
</span></span><span><span>    </span><span>if</span><span> </span><span>'.'</span><span> </span><span>in</span><span> pkt[</span><span>1</span><span>] </span><span>or</span><span> </span><span>':'</span><span> </span><span>in</span><span> pkt[</span><span>1</span><span>]:
</span></span><span><span>        msg = pkt[</span><span>5</span><span>]
</span></span><span><span>        </span><span>for</span><span> i </span><span>in</span><span> </span><span>range</span><span>(</span><span>6</span><span>, </span><span>len</span><span>(pkt), </span><span>1</span><span>):
</span></span><span><span>            msg = msg + </span><span>" "</span><span> + pkt[i]</span></span></code></pre><p><em><small><a href="https://github.com/protectus/pfring-to-mongo/blob/821b42c5a8c68b0f2ca4b50773f391724eeea592/python/protectus-sentry/protectus_sentry/trafcap/trafcapEthernetPacket.py#L233">Source</a></small></em></p><p>... Still not beautiful, and you have to know what pkt and doc are, because they’re definitely not self-documenting, but you know, better.</p><p>And the stuff really worked. Dad understood better than most the value of simplicity in software architecture.  Even though our system was spread across several processes, and each process might interact directly with the database, (a pattern that elicits shrieks of rage from most software designers I know,) every interaction was well documented and the documentation strictly updated.  The flow of data was one-directional, and the state space was kept under tight control.  We were careful not to introduce too many dependencies.  The only frameworks we used were Debian Packaging, Pyramid, and BackboneJS.  Everything else was a library.  Though much of it was handwritten, the documentation was at least as good as any enterprise dev team I’ve encountered since. (Though not as good as most open source projects I’ve seen)</p><p>As we scaled the Sentry onto higher volume networks, Python started to groan a bit under the load.  I ported a bunch of his ingest code to Cython over a few months, and Lo, his “let’s code this like it’s C” approach fit really intuitively with Cython’s “let’s turn this into C” approach.</p><p>You can’t buy the kind of startup experience I got working with Dad.  Every mistake I made, every design decision, I was the one who had to take responsibility with the repercussions, just because we were a two-man shop, and he trusted me.  I haven’t found that kind of learning environment anywhere else.</p><p>Technical things I learned from or with Dad:</p><ul><li>Early on we recognized the value a monorepo could bring, years before anyone used that word</li><li>I hammered together a CI/CD pipeline from batch scripts. We judged Jenkins to be more infrastructure than we needed</li><li>Instead of local environments, we developed remotely on instances of production environments, sidestepping an entire class of deployment issues</li><li>We maintained multiple release channels and used feature flags to let us quickly respond to customers who wanted more now, without endangering customers who were happy with stability</li><li>We managed an entire fleet of machines with only a few hours a month to coordinate software upgrades</li></ul><p><strong>More important yet</strong> was the concept Dad gave me that wearing lots of hats is fun.  If you're from the future, wondering if I'd be a good fit at your company, just know that I will probably not be happy doing only one kind of work.  With Dad, I:</p><ul><li>Slung Code in Python, Cython, JS and Bash</li><li>Administered a Xen VM farm</li><li>Designed a product UI</li><li>Obtained my GPEN certification and performed pen testing against clients (because we were a security company)</li><li>Used my own product to monitor client networks for security incidents</li><li>Solicited customer feedback to improve my product</li><li>Did sales engineering and support</li><li>Designed implemented and shipped a marketing site (yes it's bad, but it's mine)</li><li>Designed and chose chips for a custom form factor Ethernet tap, and worked with the hardware design firm to design and then test their prototypes</li></ul><p><strong>Even more important yet</strong> were the non-work things Dad taught me.  But that's a little out of scope today.</p><h2>I …</h2></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tcgarvin.com/trafcap">https://www.tcgarvin.com/trafcap</a></em></p>]]>
            </description>
            <link>https://www.tcgarvin.com/trafcap</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932411</guid>
            <pubDate>Thu, 29 Oct 2020 16:43:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Social learning and peer selection lead to polarized beliefs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932379">thread link</a>) | @bldavies
<br/>
October 29, 2020 | https://bldavies.com/blog/polarized-beliefs-social-networks/ | <a href="https://web.archive.org/web/*/https://bldavies.com/blog/polarized-beliefs-social-networks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<p>Suppose 50 people each have four friends.
Everyone believes that some proposition—say, “corporate tax rates should be higher”—is either true or false, with equal probability and independently of everyone else.
Consequently, the social network among the 50 people is unsorted with respect to peoples’ beliefs.
However, the network’s structure changes over time, in discrete time steps, according to two rules:</p>
<ol>
<li>everyone updates their belief to match the majority within their friend group (comprised of themselves and their neighbours in the network), defaulting to their previous belief to break ties;</li>
<li>edges appear between people who hold the same belief and disappear between people who hold different beliefs, both with probability 0.01.</li>
</ol>
<p>The first rule describes a “social learning” process: people update their beliefs to match the majority among their friends.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>
The second rule describes a “peer selection” process: people choose friends who share the same beliefs.
These two processes can lead to polarized beliefs, even if there is no polarization before the processes begin.
I demonstrate this phenomenon in the figure below, which plots the beliefs and connections in a simulated network after zero, 10, 20, and 30 time steps.
The figure shows how people grow increasingly connected to others with the same belief and decreasingly connected to others with the opposing belief.</p>
<p><img src="https://bldavies.com/blog/polarized-beliefs-social-networks/figures/networks-1.svg" alt=""></p>
<p>The social learning and peer selection processes can lead to polarization both together and separately.
I justify this claim in the figure below.
The left-hand panel plots the network’s “assortativity coefficient,” which measures the overall correlation among friends’ beliefs.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>
This coefficient equals one when all neighbours share the same beliefs (complete polarization) and equals zero when edges are “as random.”
The right-hand panel plots the proportion of people in the network who update their belief at each time step.
Both panels present means and 95% confidence intervals across 30 simulated networks, each with randomized initial beliefs.</p>
<p><img src="https://bldavies.com/blog/polarized-beliefs-social-networks/figures/network-attributes-1.svg" alt=""></p>
<p>The social learning process leads to positive sorting because, by construction, people increasingly share the same beliefs as their friends.
The peer selection process leads to positive sorting because, by construction, edges increasingly connect people with common beliefs only.
The two processes work together to isolate the subnetworks of people who believe the proposition is true and false.
Interestingly, most belief updates occur very early: after about five time steps, most of the structural changes in the social network result from edge creations and deletions rather than from belief updates.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>See <a href="https://bldavies.com/blog/degroot-learning-social-networks/">my blog post on DeGroot learning</a> for more discussion of social learning processes. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>See <a href="https://arxiv.org/abs/cond-mat/0209450v2">Newman (2003)</a> for a definition and discussion of the assortativity coefficient. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>


</div></div>]]>
            </description>
            <link>https://bldavies.com/blog/polarized-beliefs-social-networks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932379</guid>
            <pubDate>Thu, 29 Oct 2020 16:40:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The future of AppSec and why I joined r2c]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932357">thread link</a>) | @mooreds
<br/>
October 29, 2020 | https://r2c.dev/blog/2020/future-of-appsec-why-r2c/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/future-of-appsec-why-r2c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p>Sometimes, it feels like things happen for a reason.</p>
<p>After a series of unexpected events, I now find myself as Head of Security Research at <a href="https://r2c.dev/" target="_blank" rel="noopener">r2c</a>, the company behind the open source static analysis tool <a href="https://github.com/returntocorp/semgrep" target="_blank" rel="noopener">Semgrep</a>, and I couldn’t be more excited about my role, the company, and the future of application security (AppSec).</p>
<p>In this post I’m going to discuss why I’m betting on r2c, and where I think application security is headed.</p>
<h2>An academic wake up call</h2>
<p><em>A Tale as Old as Time: Things are different outside academia</em> </p>
<p>While I was a young, fresh-faced PhD student at the University of California, Davis, my colleagues and I pursued a number of research projects involving static analysis, and I even interned at Fortify, which was an up-and-coming static analysis security testing (SAST) vendor at the time.</p>
<p>I was amazed and enthralled by the power of static analysis to find bugs and improve software security at scale. Thoughts of other advanced topics like symbolic execution, abstract interpretation, and more joyfully danced through my head like a child’s dreams of presents at Christmas.</p>
<p>So when I joined NCC Group as a security consultant, I couldn’t wait to see the tools my colleagues used. After all, these are some of the top security testers in the world, brought in by most of the largest, and biggest name companies to improve the security of their software.</p>
<p>So what secret tools did these legendary security consultants use?</p>
<ol>
<li>Burp Suite</li>
<li>An editor like Emacs, Vim, or VS Code</li>
<li>Aaaand... <code>grep</code> (Pro-tip: use <a href="https://github.com/BurntSushi/ripgrep" target="_blank" rel="noopener">ripgrep</a>, it’s much faster)</li>
</ol>
<p>How could this be? How could such advanced approaches and tools exist and yet so few people use them?</p>
<p>It would take a few years, and off-the-record conversations with security engineers from dozens of companies, but eventually I found some answers.</p>
<h2>Static analysis in the real world™</h2>
<p>As a security consultant performing penetration tests, I quickly saw why we preferred <code>grep</code>: </p>
<ul>
<li>Above all, consultants are <em>time limited</em> - they need to find bugs yesterday, and don’t have time to set up tools, run multi hour scans, and triage hundreds of false positives. Any tool needs to a) be useful out of the box, b) be able to get up and running in minutes, and c) provide real value.</li>
<li>Consultants rarely receive source code in buildable form, which is required by many tools. Again, a consultant <em>could</em> in theory work to build the source code, but that could easily become a time sink that wastes valuable testing time.</li>
<li>Most commercial static analysis tools have licensing models that make consultant use infeasible. Companies may charge by lines of code scanned, number of repos or developers, or some other factor that either doesn’t make sense or is cost prohibitive for lean consulting firms.</li>
<li>Most commercial static analysis tools are hard to customize - if there’s a code-base specific anti-pattern or bug class you’d like to find, writing and validating a custom check might take hours. That is, once you’ve already put in hours or days learning how to write custom rules in the first place.</li>
</ul>
<p>But what was keeping <em>companies</em>, with bigger teams and more time and budget, from embracing static analysis?</p>
<h3>Legacy SAST: slow, noisy, and out of touch</h3>
<p>During my final few years at NCC Group, I was fortunate to have the opportunity to moderate DevSecOps focused panels all around the world featuring senior security leaders from companies including Netflix, Dropbox, Apple, Slack, Datadog, Etsy, DocuSign, and more.</p>
<p>And as a security consultant, I led a number of projects around helping companies scale their AppSec programs, embrace automation, and tune and roll out a SAST tool they had purchased.</p>
<p>Here are a few things I learned:</p>
<ul>
<li>Security teams are tired of tools that deluged them with false positives. They can’t send results directly to developers without damaging their relationships with engineering, but the small AppSec teams don’t have time to triage the results.</li>
<li>
<p>Most SAST tools require onboarding and tuning by a domain expert in order to really provide value. Tuning and writing custom rules, despite being high leverage, tend to be complex tasks and require days or weeks of focused time to become competent.</p>
<ul>
<li>I was willing to put in that time because it was a topic I already had interest and a background in, but for most AppSec teams, they don’t have this in-house expertise and/or there are other more pressing matters-- they can’t dedicate one of their headcount for a few weeks to become proficient in the tool. Thus many SAST installations languish.</li>
</ul>
</li>
<li>Many SAST buyers (e.g., heads of AppSec or CISOs) <em>didn’t</em> <em>actually expect</em> the tool to provide security value, but rather were buying it to tick a compliance checkbox. This (initially) surprised but saddened me.</li>
<li>Due to the price and complexity of customization, even very advanced, forward thinking AppSec teams were rolling their own static analysis solutions - which were often collections of regexes!</li>
<li>Most importantly, AppSec teams were starting to <strong>view security differently</strong>. More on this below.</li>
</ul>
<p>Some anecdotes:</p>
<ul>
<li>
<p>A mid-sized, rapidly growing startup said they had paid around $150,000 for a popular SAST tool whose output was <em>1 medium severity issue</em> in the past year.</p>
<ul>
<li>I considered asking them to pay me $150K and then I’d manually test until I found 1 medium severity issue and then leave, but unfortunately I did not.</li>
</ul>
</li>
<li>
<p>In our off-the-record <a href="https://appsecus2018.sched.com/event/GkdM/empowering-modern-development-with-security-automation-trials-and-tribulations-from-the-trenches" target="_blank" rel="noopener">AppSec USA 2018 panel</a>, my friend Zane Lackey asked the audience, “Who here is happy with their current SAST solution?” In a standing room only conference room with a few hundred people, not a single person raised their hand.</p>
<ul>
<li>A senior sales professional at one of the big vendors came up to Zane afterwards and had some strong opinions on why their product was useful 😅</li>
</ul>
</li>
</ul>
<p>The <strong>biggest thing</strong> that stuck out to me though, after spending hundreds to thousands of hours in this space, both sounds obvious but is perhaps initially unintuitive:</p>
<blockquote>
<p>It’s <strong>impossible</strong> to find every bug, no matter how advanced your tools are. Instead, the <strong>key to scaling security</strong> is to build <strong>secure-by-default libraries</strong> and tools that developers can use to prevent entire classes of vulnerabilities by construction, and then <strong>make sure developers use them</strong>.</p>
</blockquote>
<p>This is what forward-thinking security teams at companies like Google, Microsoft, Facebook, Netflix, Dropbox, and more believe and have been investing in for <em>years *(see our Global AppSec SF 2020 <a href="https://r2c.dev/global-appsec-sf-2020" target="_blank" rel="noopener">slides</a> for more details and examples</em>)*.</p>
<p>This is not to say that bug finding (manually or with tools) doesn’t have a role, because it does, but rather that it’s not the highest leverage area security teams can invest in.</p>
<h3>A crisis of faith</h3>
<p>At this point I began to question my own goals, personal priorities, and beliefs about security in general - was I really pushing the industry forward, manually finding bugs in different applications?</p>
<p>It was also painful continually seeing companies pay so much for solutions they were unhappy with.</p>
<h2>Enter: r2c</h2>
<p>Naively, I started building my own static analysis tool - something simple and lightweight that fits easily into how modern security teams work. However, I soon found that building and maintaining a production quality tool yourself is A Lot of Work™.</p>
<p>In a random stroke of luck, my friend from grad school, <a href="https://twitter.com/defreez" target="_blank" rel="noopener">Daniel DeFreez</a>, told me about this small, SF-based startup called r2c, who were also building a lightweight static analysis tool.</p>
<p>I grabbed lunch with the team and attended a few of their meetups, and was surprised to find how closely our views of the future of security were aligned.</p>
<p>One day I said to Isaac, one of r2c’s co-founders and CEO, “You know, I think you should hire for a role like <code>&lt;this&gt;</code>,” and proceeded to pitch him my dream role, which was an unusual blend of everything: being a pro user of the product and influencing product direction, working closely with marketing to create and share security research that meaningfully pushes the industry forward, and much more.</p>
<p>To my surprise, he chatted with the team, and they ended up agreeing! 😍</p>
<h2>Why I joined r2c</h2>
<p>I joined r2c primarily for two reasons: </p>
<ol>
<li>I believed they were on an ideal trajectory for helping shape the future of AppSec, and </li>
<li>I was impressed by the quality of the team and its culture.</li>
</ol>
<p>Let’s get into both in a bit more detail.</p>
<h3>The future of AppSec: killing bug classes via secure defaults</h3>
<p>This topic merits its own post (and maybe blog series), but I wanted to at least touch on it here. For more info, see Isaac and I’s Global AppSec SF 2020 <a href="https://r2c.dev/global-appsec-sf-2020" target="_blank" rel="noopener">slides.</a></p>
<p>Historically, the security industry has focused on vulnerability identification, via pen testing, bug bounty, SAST, DAST, internal testing, and more. However, this is reactive and in general doesn’t prevent future vulnerabilities from being introduced.</p>
<p>However, there have been some promising developments - modern web frameworks like Django, Ruby on Rails, and others have a number of secure defaults and built-in guardrails that make potentially dangerous tasks safe by default, including context sensitive output encoding (prevent XSS), tight integration with object relational mappers (prevent SQL injection), and more. In my and many others’ opinions, <em>this</em> is why overall web security has improved, not all of the fancy bug finding tools we’ve built.</p>
<p>Forward thinking security teams at companies like Google, Microsoft, Facebook, Microsoft, Netflix, Dropbox, and many others have gone even further than what’s provided out of the box in common frameworks, creating secure libraries for parsing XML, authentication and authorization, mutual TLS between services, secret management, and many more.</p>
<blockquote>
<p>The future of AppSec is a one-two punch of secure defaults + lightweight enforcement of those defaults.</p>
</blockquote>
<p>That way developers can do what they do best: rapidly build scalable, complex software that brings business value to your customers, and not have to constantly be wary of all of the subtle nuances that could lead to a vulnerability.  In an ideal world, <strong>security should be completely transparent to developers</strong>.</p>
<p>By being fast, easily customizable, and open …</p></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://r2c.dev/blog/2020/future-of-appsec-why-r2c/">https://r2c.dev/blog/2020/future-of-appsec-why-r2c/</a></em></p>]]>
            </description>
            <link>https://r2c.dev/blog/2020/future-of-appsec-why-r2c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932357</guid>
            <pubDate>Thu, 29 Oct 2020 16:37:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Large inequality in international energy footprints between income groups]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24932205">thread link</a>) | @tonyedgecombe
<br/>
October 29, 2020 | https://sci-hub.tf/10.1038/s41560-020-0579-8 | <a href="https://web.archive.org/web/*/https://sci-hub.tf/10.1038/s41560-020-0579-8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://sci-hub.tf/10.1038/s41560-020-0579-8</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932205</guid>
            <pubDate>Thu, 29 Oct 2020 16:25:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Augmentation in Python: Everything You Need to Know]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932171">thread link</a>) | @patrycjaneptune
<br/>
October 29, 2020 | https://neptune.ai/blog/data-augmentation-in-python | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/data-augmentation-in-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p>In machine learning (<strong>ML</strong>), if the situation when the model does not generalize well from the training data to unseen data is called <strong>overfitting</strong>. As you might know, it is one of the trickiest obstacles in applied machine learning.&nbsp;</p>



<p>The first step in tackling this problem is to actually know that your model is <strong>overfitting<em>. </em></strong>That is where proper <a href="https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right" target="_blank" rel="noreferrer noopener nofollow">cross-validation</a> comes in.</p>



<p>After identifying the problem you can prevent it from happening by applying regularization or training with more data. Still, sometimes you might not have additional data to add to your initial dataset. Acquiring and labeling additional data points may also be the wrong path. Of course, in many cases, it will deliver better results, but in terms of work, it is time-consuming and expensive a lot of the time.</p>



<p>That is where <a href="https://www.techopedia.com/definition/28033/data-augmentation" target="_blank" rel="noreferrer noopener nofollow"><strong>Data Augmentation</strong></a> (<strong>DA</strong>) comes in.</p>



<p>In this article we will cover:</p>



<ul><li>What is <strong>Data Augmentation</strong> – definition, the purpose of use, and techniques</li><li>Built-in augmentation methods in <strong>DL</strong> frameworks – <strong>TensorFlow</strong>, <strong>Keras</strong>, <strong>PyTorch</strong>, <strong>MxNet</strong></li><li>Image <strong>DA</strong> libraries – <strong>Augmentor</strong>, <strong>Albumentations</strong>, <strong>ImgAug</strong>, <strong>AutoAugment</strong>, <strong>Transforms</strong></li><li>Speed comparison of these libraries&nbsp;</li><li><strong>Best practices</strong>, tips, and tricks&nbsp;</li></ul>






<h2>What is Data Augmentation</h2>



<p><strong>Data Augmentation</strong> is a technique that can be used to artificially expand the size of a training set by creating modified data from the existing one. It is a good practice to use <strong>DA</strong> if you want to prevent <strong>overfitting</strong>, or the initial dataset is too small to train on, or even if you want to squeeze better performance from your model.</p>



<div><p>Let’s make this clear, <strong>Data Augmentation</strong> is not only used to prevent <strong>overfitting</strong>. In general, having a large dataset is crucial for the performance of both <strong>ML</strong> and <strong>Deep Learning</strong> (<strong>DL</strong>) models. However, we can improve the performance of the model by augmenting the data we already have. It means that <strong>Data Augmentation</strong> is also good for enhancing the model’s performance.</p><p>In general, <strong>DA</strong> is frequently used when building a <strong>DL</strong> model. That is why throughout this article we will mostly talk about performing <strong>Data Augmentation</strong> with various <strong>DL</strong> frameworks. Still, you should keep in mind that you can augment the data for the <strong>ML</strong> problems as well.</p></div>



<p>You can augment:</p>



<ol><li>Audio</li><li>Text</li><li>Images</li><li>Any other types of data</li></ol>



<p>We will focus on image augmentations as those are the most popular ones. Nevertheless, augmenting other types of data is as efficient and easy. That is why it’s good to remember some common techniques which can be performed to augment the data.</p>



<h3><strong>Data Augmentation techniques</strong></h3>



<p>We can apply various changes to the initial data. For example, for images we can use:</p>



<ol><li><strong>Geometric transformations</strong> – you can randomly flip, crop, rotate or translate images, and that is just the tip of the iceberg</li><li><strong>Color space transformations</strong> – change RGB color channels, intensify any color</li><li><strong>Kernel filters</strong> – sharpen or blur an image&nbsp;</li><li><strong>Random Erasing</strong> – delete a part of the initial image</li><li><strong>Mixing images</strong> – basically, mix images with one another. Might be counterintuitive but it works</li></ol>



<p>For text there are:</p>



<ol><li><strong>Word/sentence shuffling</strong></li><li><strong>Word replacement</strong> – replace words with synonyms</li><li><strong>Syntax-tree manipulation</strong> – paraphrase the sentence to be grammatically correct using the same words</li><li>Other described in the article about <a href="https://neptune.ai/blog/data-augmentation-nlp" target="_blank" rel="noreferrer noopener nofollow">Data Augmentation in NLP</a></li></ol>



<p>For audio augmentation you can use:</p>



<ol><li><strong>Noise injection</strong></li><li><strong>Shifting</strong></li><li><strong>Changing the speed of the tape</strong></li><li>And many more</li></ol>



<p>Moreover, the greatest advantage of the augmentation techniques is that you may use all of them at once. Thus, you may get plenty of unique samples of data from the initial one.</p>






<h2>Data Augmentation in Deep Learning</h2>



<p>As mentioned above in <a href="https://towardsdatascience.com/data-augmentation-for-deep-learning-4fe21d1a4eb9" target="_blank" rel="noreferrer noopener nofollow"><strong>Deep Learning,</strong> <strong>Data Augmentation</strong></a> is a common practice. Therefore, every DL framework has its own augmentation methods or even a whole library. For example, let’s see how to apply image augmentations using built-in methods in TensorFlow (TF) and Keras, PyTorch, and <strong>MxNet</strong>.<br></p>






<h3><strong>Data Augmentation in TensorFlow and Keras</strong></h3>



<p>To augment images when using <strong>TensorFlow</strong> or <strong>Keras</strong> as our <strong>DL</strong> framework we can:</p>



<ul><li>Write our own augmentation pipelines or layers using <strong>tf.image</strong>.</li><li>Use <strong>Keras</strong> preprocessing layers</li><li>Use <strong>ImageDataGenerator</strong></li></ul>



<h4><strong>Tf.image</strong></h4>



<p>Let’s take a closer look on the first technique and define a function that will visualize an image and then apply the flip to that image using <strong>tf.image</strong>. You may see the code and the result below.</p>



<pre><span><span>def</span> <span>visualize</span><span>(original, augmented)</span>:</span>
    fig = plt.figure()
    plt.subplot(<span>1</span>,<span>2</span>,<span>1</span>)
    plt.title(<span>'Original image'</span>)
    plt.imshow(original)

    plt.subplot(<span>1</span>,<span>2</span>,<span>2</span>)
    plt.title(<span>'Augmented image'</span>)
    plt.imshow(augmented)
    flipped = tf.image.flip_left_right(image)
    visualize(image, flipped)</pre>



<div><figure><img loading="lazy" width="375" height="148" src="https://i2.wp.com/neptune.ai/wp-content/uploads/image-augmentation.png?resize=375%2C148&amp;ssl=1" alt="image augmentation" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/image-augmentation.png?w=375&amp;ssl=1 375w, https://i2.wp.com/neptune.ai/wp-content/uploads/image-augmentation.png?resize=300%2C118&amp;ssl=1 300w" sizes="(max-width: 375px) 100vw, 375px" data-recalc-dims="1"></figure></div>



<p>For finer control you can write your own augmentation pipeline. In most cases it is useful to apply augmentations on a whole dataset, not a single image. You can implement it as follows.</p>



<pre><span>import</span> tensorflow_datasets <span>as</span> tfds 

<span><span>def</span> <span>augment</span><span>(image, label)</span>:</span>
  image = tf.cast(image, tf.float32)
  image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])
  image = (image / <span>255.0</span>)
  image = tf.image.random_crop(image, size=[IMG_SIZE, IMG_SIZE, <span>3</span>])
  image = tf.image.random_brightness(image, max_delta=<span>0.5</span>)
  <span>return</span> image, label

(train_ds, val_ds, test_ds), metadata = tfds.load(
    <span>'tf_flowers'</span>,
     split=[<span>'train[:80%]'</span>, <span>'train[80%:90%]'</span>, <span>'train[90%:]'</span>],
     with_info=<span>True</span>,
     as_supervised=<span>True</span>,)

train_ds = train_ds
            .shuffle(<span>1000</span>)
            .map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)
            .batch(batch_size)
            .prefetch(AUTOTUNE)</pre>



<p>Of course, that is just the tip of the iceberg. <strong>TensorFlow</strong> API has plenty of augmentation techniques. If you want to read more on the topic please check the <a href="https://www.tensorflow.org/tutorials/images/data_augmentation?hl=en" target="_blank" rel="noreferrer noopener nofollow">official documentation </a>or <a href="https://www.wouterbulten.nl/blog/tech/data-augmentation-using-tensorflow-data-dataset/" target="_blank" rel="noreferrer noopener nofollow">other articles</a>.</p>



<h4><strong>Keras preprocessing&nbsp;</strong></h4>



<p>As mentioned above, <strong>Keras</strong> has a variety of preprocessing layers that may be used for <strong>Data Augmentation</strong>. You can apply them as follows.</p>



<pre>data_augmentation = tf.keras.Sequential([
     layers.experimental.preprocessing.RandomFlip(<span>"horizontal_and_vertical"</span>),
     layers.experimental.preprocessing.RandomRotation(<span>0.2</span>)])

image = tf.expand_dims(image, <span>0</span>)
plt.figure(figsize=(<span>10</span>, <span>10</span>))

<span>for</span> i <span>in</span> range(<span>9</span>):
  augmented_image = data_augmentation(image)
  ax = plt.subplot(<span>3</span>, <span>3</span>, i + <span>1</span>)
  plt.imshow(augmented_image[<span>0</span>])
  plt.axis(<span>"off"</span>)</pre>



<div><figure><img loading="lazy" width="572" height="507" src="https://i0.wp.com/neptune.ai/wp-content/uploads/data-augmentation-in-keras.png?resize=572%2C507&amp;ssl=1" alt="data augmentation in keras" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/data-augmentation-in-keras.png?w=572&amp;ssl=1 572w, https://i0.wp.com/neptune.ai/wp-content/uploads/data-augmentation-in-keras.png?resize=300%2C266&amp;ssl=1 300w" sizes="(max-width: 572px) 100vw, 572px" data-recalc-dims="1"></figure></div>



<h4><strong>Keras ImageDataGenerator</strong></h4>



<p>Also, you may use <strong>ImageDataGenerator</strong> (<strong>tf.keras.preprocessing.image.ImageDataGenerator</strong>) that generates batches of tensor images with real-time <strong>DA</strong>.</p>



<pre>datagen = ImageDataGenerator(rotation_range=<span>90</span>)
datagen.fit(x_train)


<span>for</span> X_batch, y_batch <span>in</span> datagen.flow(x_train, y_train, batch_size=<span>9</span>):
    <span>for</span> i <span>in</span> range(<span>0</span>, <span>9</span>):
        pyplot.subplot(<span>330</span> + <span>1</span> + i)
        pyplot.imshow(X_batch[i].reshape(img_rows, img_cols, <span>3</span>))
        pyplot.show()
    <span>break</span>
</pre>



<div><figure><img loading="lazy" src="https://i1.wp.com/neptune.ai/wp-content/uploads/image-data-generator.png?resize=768%2C437&amp;ssl=1" alt="image data generator" width="768" height="437" srcset="https://i1.wp.com/neptune.ai/wp-content/uploads/image-data-generator.png?resize=1024%2C583&amp;ssl=1 1024w, https://i1.wp.com/neptune.ai/wp-content/uploads/image-data-generator.png?resize=300%2C171&amp;ssl=1 300w, https://i1.wp.com/neptune.ai/wp-content/uploads/image-data-generator.png?resize=768%2C437&amp;ssl=1 768w, https://i1.wp.com/neptune.ai/wp-content/uploads/image-data-generator.png?w=1230&amp;ssl=1 1230w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1"></figure></div>



<hr>



<p><strong>See related articles:&nbsp;</strong></p>



<ul><li><a href="https://neptune.ai/blog/keras-loss-functions" target="_blank" rel="noreferrer noopener nofollow">Keras Loss Functions: Everything You Need To Know</a></li><li><a href="https://neptune.ai/blog/keras-metrics" target="_blank" rel="noreferrer noopener nofollow">Keras Metrics: Everything You Need To Know</a></li><li><a href="https://docs.neptune.ai/integrations/keras.html" target="_blank" rel="noreferrer noopener nofollow">Neptune-Keras Integration</a></li></ul>



<hr>






<h3><strong>Data Augmentation in PyTorch and MxNet</strong></h3>



<h4><strong>Transforms in Pytorch</strong></h4>



<p><strong>Transforms</strong> library is the augmentation part of the <strong>torchvision</strong> package that consists of popular datasets, model architectures, and common image transformations for <strong>Computer Vision</strong> tasks.&nbsp;</p>



<p>To install <strong>Transforms</strong> you simply need to install<strong> torchvision</strong>:</p>



<pre>pip3 install torch torchvision
</pre>



<p><strong>Transforms</strong> library contains different image transformations that can be chained together using the <strong>Compose</strong> method. Functionally, <strong>Transforms has a variety of augmentation techniques implemented</strong>. You can combine them by using <strong>Compose</strong> method. Just check the <a href="https://pytorch.org/docs/stable/torchvision/transforms.html" target="_blank" rel="noreferrer noopener nofollow">official documentation</a> and you will certainly find the augmentation for your task.</p>



<p>Additionally, there is the <strong>torchvision.transforms.functional</strong> module. It has various functional transforms that give fine-grained control over the transformations. It might be really useful if you are building a more complex augmentation pipeline, for example, in the case of segmentation tasks.</p>



<p>Besides that, <strong>Transforms</strong> doesn’t have a unique feature. It’s used mostly with <strong>PyTorch</strong> as it’s considered a built-in augmentation library.</p>



<hr>



<p><strong>See related articles:</strong></p>



<ul><li><a href="https://neptune.ai/blog/pytorch-lightning-neptune-integration" target="_blank" rel="noreferrer noopener nofollow">How to Keep Track of PyTorch Lightning Experiments with Neptune</a></li></ul>



<hr>



<p><strong>Sample usage of PyTorch Transforms</strong></p>



<p>Let’s see how to apply augmentations using <strong>Transforms</strong>. You should keep in mind that <strong>Transforms </strong>works only with <strong>PIL</strong> images. That is why you should either read an image in <strong>PIL</strong> format or add the necessary transformation to your augmentation pipeline.</p>



<pre><span>from</span> torchvision <span>import</span> transforms <span>as</span> tr
<span>from</span> torchvision.transfroms <span>import</span> Compose

pipeline = Compose(
             [tr.RandomRotation(degrees = <span>90</span>),
              tr.RandomRotation(degrees = <span>270</span>)])

augmented_image = pipeline(img = img)</pre>



<p>Sometimes you might want to write a custom <strong>Dataloader</strong> for the training. Let’s see how to apply augmentations via <strong>Transforms</strong> if you are doing so.</p>



<pre><span>from</span> torchvision <span>import</span> transforms
<span>from</span> torchvision.transforms <span>import</span> Compose <span>as</span> C

<span><span>def</span> <span>aug</span><span>(p=<span>0.5</span>)</span>:</span>
    <span>return</span> C([transforms.RandomHorizontalFlip()], p=p)

<span><span>class</span> <span>Dataloader</span><span>(object)</span>:</span>
    <span><span>def</span> <span>__init__</span><span>(self, train, csv, transform=None)</span>:</span>
        ...

    <span><span>def</span> <span>__getitem__</span><span>(self, index)</span>:</span>
        ...
        img = aug()(**{<span>'image'</span>: img})[<span>'image'</span>]
        <span>return</span> img, target

    <span><span>def</span> <span>__len__</span><span>(self)</span>:</span>
        <span>return</span> len(self.image_list)

trainset = Dataloader(train=<span>True</span>, csv=<span>'/path/to/file/'</span>, transform=aug)</pre>



<h4><strong>Transforms in MxNet</strong></h4>



<p><strong>Mxnet</strong> also has a built-in augmentation library called <strong>Transforms </strong>(<strong>mxnet.gluon.data.vision.transforms</strong>). It is pretty similar to <strong>PyTorch Transforms</strong> library. There is pretty much nothing to add. Check the <strong>Transforms</strong> section above if you want to find more on this topic. General usage is as follows.</p>



<p><strong>Sample usage of MxNet Transforms</strong></p>



<pre>color_aug = transforms.RandomColorJitter(
                               brightness=<span>0.5</span>,
                               contrast=<span>0.5</span>,
                               saturation=<span>0.5</span>,
                               hue=<span>0.5</span>)</pre></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/data-augmentation-in-python">https://neptune.ai/blog/data-augmentation-in-python</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/data-augmentation-in-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932171</guid>
            <pubDate>Thu, 29 Oct 2020 16:23:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Context on Software Transactional Memory in Ruby]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932113">thread link</a>) | @pvsukale3
<br/>
October 29, 2020 | https://chrisseaton.com/truffleruby/ruby-stm/ | <a href="https://web.archive.org/web/*/https://chrisseaton.com/truffleruby/ruby-stm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<header>

<h2><a href="https://chrisseaton.com/">Chris Seaton</a>, 28 October 2020</h2>


</header>

<p>There’s a proposal to add <em>Software Transactional Memory</em>, or <em>STM</em>, to the Ruby programming language. This is part of a wider effort to add better support for concurrency and parallelism in Ruby, and in particular the idea of <em>ractors</em>. A concept has been <a href="https://bugs.ruby-lang.org/issues/17261">proposed</a> and <a href="https://github.com/ruby/ruby/pull/3652">implemented</a> by Koichi Sasada.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/testBoard.gif" width="50%">
<figcaption>An animation of the algorithm we're going to use as an example of STM - we'll explain this later on</figcaption>
</figure>

<p>This article gives some context on what STM is, how you use it, and why you might want to use it. We’ll show an application which is well-suited to STM and we’ll use this to talk about the benefits, issues, and some open questions.</p>

<p>We’ll finish by setting a challenge for STM in Ruby.</p>

<p>I wrote the first half of my PhD on STM, and the second half on Ruby, so I’ve got quite a bit of experience with both and the idea of their combination is very interesting to me.</p>

<h2 id="why-might-we-want-an-stm">Why might we want an STM?</h2>

<p>Let’s say we’re a bank managing many bank accounts. Each account has a total. We get a never-ending stream of requests to move a sum of money <code>m</code> from an account <code>a</code> to account <code>b</code>.</p>

<div><div><pre><code><span>loop</span> <span>do</span>
  <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
  <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
  <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
<span>end</span>
</code></pre></div></div>

<p>Something not everyone may know about Ruby is that <code>x += y</code> is equivalent to writing <code>t = x; x = t + y</code>. We’ll write that out in full to make that clear to ourselves.</p>

<div><div><pre><code><span>loop</span> <span>do</span>
  <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
  <span>a_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
  <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>a_balance</span> <span>-</span> <span>m</span>
  <span>b_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>b</span><span>]</span>
  <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>=</span> <span>b_balance</span> <span>+</span> <span>m</span>
<span>end</span>
</code></pre></div></div>

<p>We’ve got a lot of transfers to run through, so we’ll have multiple threads processing these transfers.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>a_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
      <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>a_balance</span> <span>-</span> <span>m</span>
      <span>b_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>b</span><span>]</span>
      <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>=</span> <span>b_balance</span> <span>+</span> <span>m</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>We’ve got a few problems here now. With all these threads running at the same time, what happens if two threads are putting money into your account concurrently?</p>

<div><div><pre><code><span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>100</span>

<span># thread 1                        # thread 2</span>
<span>balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
  <span># balance = 100</span>
                                  <span>balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
                                    <span># balance = 100</span>
<span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>balance</span> <span>+</span> <span>10</span>
  <span># accounts[a] = 110</span>
                                  <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>balance</span> <span>+</span> <span>10</span>
                                    <span># accounts[a] = 110</span>
</code></pre></div></div>

<p>The two transfers have run, but your balance is 110. The other 10 has been lost - this is called a <em>lost update</em>, meaning it’s as if the update was never made.</p>

<p>Also consider what happens if the thread crashes after taking money from <code>a</code> but before putting it into <code>b</code>? The transfer would be applied partially and again we’d lose money.</p>

<p>We need to use some kind of <em>synchronization</em> on our accounts. Ruby has <em>mutual exclusion locks</em> or <em>mutexes</em>, so we can try using those.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>locks</span><span>[</span><span>a</span><span>].</span><span>synchronize</span> <span>do</span>
        <span>locks</span><span>[</span><span>b</span><span>].</span><span>synchronize</span> <span>do</span>
          <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
          <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Does this work? What if we process a transfer from account 1001 to account 1002 on one thread at the same time as processing a transfer from account 1002 to 1001, so the other way around, at the same time?</p>

<p>The first thread will try to lock 1001 and then 1002. The second thread will try to lock 1002 and then 1001. If the first thread gets as far as locking 1001, and the second as far as locking 1002, then both will be waiting for the opposite lock and will never release the lock they already have. We will be in <em>deadlock</em>.</p>

<p>If we always acquired locks in the same order, by collecting them up first and sorting them, we could fix this.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>x</span><span>,</span> <span>y</span> <span>=</span> <span>[</span><span>a</span><span>,</span> <span>b</span><span>].</span><span>sort</span>
      <span>locks</span><span>[</span><span>x</span><span>].</span><span>synchronize</span> <span>do</span>
        <span>locks</span><span>[</span><span>y</span><span>].</span><span>synchronize</span> <span>do</span>
          <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
          <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Now in both transfers account 1001 is locked first and 1002 is locked second. That will work.</p>

<p>We have to make up a somewhat artificial requirement to explain the next issue, but consider if for some good reason we wanted to transfer to one account if we had a lot of money, and a different account if we only had a little money. Maybe if we’re rich this month we donate to charity, otherwise we unfortunately need to save for ourselves.</p>

<div><div><pre><code>if account balance &gt; 1000
  transfer 10 to charity
else
  transfer 10 to savings
end
</code></pre></div></div>

<p>We’ll talk about accounts <code>a</code>, <code>b</code>, and <code>c</code>, now, and a threshold of money <code>t</code>.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>,</span> <span>t</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>x</span><span>,</span> <span>y</span><span>,</span> <span>z</span> <span>=</span> <span>[</span><span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>].</span><span>sort</span>
      <span>locks</span><span>[</span><span>x</span><span>].</span><span>synchronize</span> <span>do</span>
        <span>locks</span><span>[</span><span>y</span><span>].</span><span>synchronize</span> <span>do</span>
          <span>locks</span><span>[</span><span>z</span><span>].</span><span>synchronize</span> <span>do</span>
            <span>if</span> <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>&gt;</span> <span>t</span>
              <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
              <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
            <span>else</span>
              <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
              <span>accounts</span><span>[</span><span>c</span><span>]</span> <span>+=</span> <span>m</span>
            <span>end</span>
          <span>end</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>It’s starting to get very complicated. And this locks more than it needs to - it locks both <code>b</code> and <code>c</code> but then only uses one of them. If you use <code>b</code> in the end, ideally another thread could be serving a transfer to <code>c</code> at the same time, but you’ve locked it and it can’t. Imagine if instead of two potential accounts it was thousands and you had to lock them all. Imagine if you couldn’t work out at all which account you’d be transferring to until you started the transfer - then you’d never be able to process two transfers at the same time.</p>

<p>At this point as well we’re likely to start to make errors trying to do all this locking and ordering of locks and things.</p>

<p>Stepping back and taking it all in, we can draw up some requirements for what we need.</p>

<ul>
  <li><em>atomicity</em> - that all writes in the transfer are applied or none are applied</li>
  <li><em>consistency</em> - meaning that our data structures are always valid - the total sum of money never changes</li>
  <li><em>isolation</em> - meaning one transfer does not interfere with another</li>
  <li><em>durability</em> - meaning that when applied the transfer is available to all subsequent transactions</li>
</ul>

<p>Ideally a library or the language could do this all for us. We’d like to be able to write almost what we originally wrote, but with just an annotation to make the code inside a block atomic, consistent, isolated, and the result durable.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>atomically</span> <span>do</span>
        <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
        <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>This is what a <em>transactional</em> memory can let us do. It will automatically monitor what you read and write inside the <code>atomically</code> block, which is a <em>transaction</em>, and will make sure it is either applied fully or not, that the balance of the whole system is always consistent, that transactions do not see the result of each other partially applied, and that writes appear and stay.</p>

<p>It may be implemented using the code we eventually arrived at ourselves, or it could do something else instead. In practice how it is often implemented is that
reads and writes are stored in a log, then at the end the transaction works out if anyone else has written locations that you’ve read. If they have then the values you read are no longer valid, so your transaction <em>conflicts</em> with another, is <em>aborted</em> and retries, reading the locations again. When it eventually does not conflict with any other transactions it is <em>committed</em> and succeeds. This means you don’t need to lock everything up-front, which means you avoid the problem of what happens if you may potentially need every account. Locking everything up-front is called <em>pessimistic locking</em>. We’re moving to <em>optimistic locking</em></p>

<h2 id="the-proposed-stm">The proposed STM</h2>

<p>Koichi’s <a href="https://bugs.ruby-lang.org/issues/17261">proposed</a> STM for Ruby, in combination with his proposed <em>ractors</em> (similar to <em>actors</em>) would look like this.</p>

<div><div><pre><code><span>accounts</span> <span>=</span> <span>9999</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>Thread</span><span>::</span><span>TVar</span><span>.</span><span>new</span><span>(</span><span>100</span><span>)</span> <span>}</span>

<span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span> <span>*</span><span>accounts</span> <span>do</span> <span>|*</span><span>accounts</span><span>|</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>Thread</span><span>.</span><span>atomically</span> <span>do</span>
        <span>accounts</span><span>[</span><span>a</span><span>].</span><span>value</span> <span>-=</span> <span>m</span>
        <span>accounts</span><span>[</span><span>b</span><span>].</span><span>value</span> <span>+=</span> <span>m</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>He’s using a <code>Ractor</code> but you can think of it as a thread for the purposes of this article. Instead of an array of account balances, we now have an array of <code>TVar</code> objects that contain values. A <code>TVar</code> is a <em>transactional variable</em>. Only these variables are transactional - not any other Ruby value you read or write. His design requires that the <code>TVar</code> objects you’re going to use are passed into the <code>Ractor</code>, due to rules about sharing that aren’t relevant for this article.</p>

<p>This looks good, doesn’t it!</p>

<h2 id="a-more-complex-application">A more complex application</h2>

<p>Let’s consider a larger application, in order to illustrate further and to talk about some issues and open questions. The <a href="https://github.com/chrisseaton/ruby-stm-lee-demo">code is available on GitHub</a>.</p>

<p>Let’s say it’s our job to lay out the wires on a circuit board. We get a board with <em>pads</em> (connections to components mounted on the board) and a list of <em>routes</em> that we need to draw between these pads. There are a great many pads and routes, there isn’t much space on the tiny board, and another catch is that it’s very expensive to have wires crossing each other. Let’s say it’s exponentially more expensive for more deeply stacked wires.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/minimal.svg" width="25%">
<figcaption>A minimal board and a solution</figcaption>
</figure>

<p>In this minimal example we we can see two routes, and how they have to cross each other.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/mainboard.svg" width="50%">
<figcaption>A processor module board and a solution</figcaption>
</figure>

<p>This example is a processor module and shows what kind of scale we might want to be working at. This board has many longer routes which are more likely to conflict.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/memboard.svg" width="50%">
<figcaption>A memory module board and a solution</figcaption>
</figure>

<p>This example is a memory module. It has many shorter routes which we may expect to conflict less.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/testBoard.svg" width="50%">
<figcaption>The test board we'll use and a solution</figcaption>
</figure>

<p>We’ll use this test board, which is somewhere between all these extremes.</p>

<p>There’s an algorithm to lay each routes, and it actually produces an optimal solution for an individual route, but not for all routes. It’s called <em>Lee’s algorithm</em> and was published back in 1960. We’ll …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrisseaton.com/truffleruby/ruby-stm/">https://chrisseaton.com/truffleruby/ruby-stm/</a></em></p>]]>
            </description>
            <link>https://chrisseaton.com/truffleruby/ruby-stm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932113</guid>
            <pubDate>Thu, 29 Oct 2020 16:18:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Joe Knows Electronics – The End of an Amazon Era]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932052">thread link</a>) | @sjackso
<br/>
October 29, 2020 | https://joeknowselectronics.com/the-end-of-an-amazon-era | <a href="https://web.archive.org/web/*/https://joeknowselectronics.com/the-end-of-an-amazon-era">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="5e3b555a" data-element_type="widget" data-widget_type="theme-post-content.default">
<div>
<p>Joe Knows Electronics has had a long relationship with Amazon. We started out as an Amazon seller in April of 2010. At that time LEDS were only available on Amazon in a quantity of 1 at a cost of around $1 each + $3.99 shipping. We saw an opportunity to fill a void. We started selling 25 packs of LEDs for $5.99 with free prime shipping.</p>
<p>After finding success in selling LEDs we moved on to provide other parts like resistors and capacitors. We stuck to that original idea of bundling components to maximize value. For resistors, rather than just sell one ohm value we sold 86 together. Most parts that someone might need could be purchased together for a single low price.</p>
<p>At first we sourced pre-made kits from China but quickly learned that people wanted more, both in terms of quality as well as organization. We undertook the task of setting up production to make thousands of kits a month, each containing hundreds of parts. It required hiring people, setting up a factory, and setting up a business process to manage all of it. The end result was the capacitor and resistor kits that became famous.</p>
<div><figure><img loading="lazy" width="300" height="300" src="https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-300x300.png" alt="" srcset="https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-300x300.png 300w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-1024x1024.png 1024w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-150x150.png 150w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-768x768.png 768w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-1536x1536.png 1536w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-600x600.png 600w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-100x100.png 100w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-64x64.png 64w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2.png 2000w" sizes="(max-width: 300px) 100vw, 300px"></figure></div>
<p>Then growth stagnated for the same reason we were successful. Working within the Amazon system meant producing products that met a certain price, size, and complexity target. If a product was too cheap the Amazon fees would be higher than the cost of the product itself. The shipping costs for a small product shipped under the prime program were the same as shipping a larger product like our resistor kit. If a product was too simple there were 1000 (literally) other sellers undercutting each other to sell that same product. Only products that were too complicated and time consuming for sane people to manufacture, like our resistor kits, could find success and profitability. However, most electronics products don’t have a range of components that make sense as a large kit. There were some attempts to strike out at the fringes of what components people might buy but we never found success like we did in our core capacitor and resistor kits. The magic of Amazon that gave us life was also smothering our ability to grow.</p>
<p>Over the years we continued to produce our handful of core products and we did the job well. Products stayed in stock and quality was consistent. We cut costs where possible and made the process more efficient.</p>
<p>Over the same years Amazon also got greedy. We went from paying 10% commission to 15%. Instead of a fulfillment cost per order plus a low fee on extra units in the same order they started charging the full fulfillment cost on every single unit. On top of that Amazon started listing our products on page 3 of results or worse unless we spent 20-40% of the retail price in advertising. The walls were closing in over the years and there was no clear answer. Amazon makes up the majority of all online e-commerce, our sales were consistent, and it made sense to keep up the status quo rather than erase everything and try again. We made the product to work well with Amazon’s pricing structure and they wouldn’t make as much sense if sold on our own website. We also didn’t have the variety of products to sustain our own website. We made just a few SKUs in massive industrial volume.</p>
<p>In 2019 sales had fallen to the point where we were scaling down production in a major way. It was time for a change so we came up with a plan. It was a radical plan to phase out all of our products and move away from Amazon completely. Rather than sell larger assortments of parts we would sell those same parts as smaller assortments. We would abandon Amazon Prime and create our own prime in a way. Many of these smaller assortments could be purchased together to build your own kit. All of the components would follow a standardized packaging scheme. Components like resistors could be ordered in a smaller range of 12 values or as a complete set like what was available in our older set of 86. This had the following advantages:</p>
<ul><li>Lower cost per component than our existing component kits.</li><li>Easier for customers to reorder commonly used parts without reordering all parts in a kit.</li><li>Mix and match parts like resistors and capacitors to build your own kit rather than buy a bunch of parts not needed for a project.</li><li>Easier for us to produce</li><li>Not reliant on Amazon’s fulfillment</li><li>Able to sell cheaper components as single items rather than as a larger kit containing many items.</li></ul>
<p>It was a great plan. The secret operation to overthrow Amazon was underway. The first products, our resistors, were a couple of months away from being available on our website when the empire (Amazon) struck back. In August we received an email from Amazon stating that our Amazon account had been suspended due to us having more than one Amazon seller account. But of course we don’t. We appealed their decision at least a dozen times but each time they simply state that we need to provide evidence that we don’t have a second account. They had given us an impossible task to prove that we don’t have something. We fell victim to the guilty until proven innocent policy of Amazon. There was no way for us to get in touch with a real person at Amazon. So that’s it. Tens of thousands of orders shipped via Amazon over the years comes to an abrupt end like turning off a light. We were already on our way out the door. Maybe an Amazon AI detected as much and they used an impossible to solve task as an excuse to kick us out.</p>
<p>We were left in an awkward position. The new products weren’t ready yet. The old products had nowhere to be sold. We ended up selling all of our Amazon inventory at cost to another Amazon seller. We rushed to finish production of the new products. Our core product, resistors, are now in stock with the updated packaging. We will be releasing hundreds of new products under a strict monthly schedule.</p>
<p>The apparent moral of this story is that Amazon is evil. But we already all know that. They gave us a great opportunity in the beginning. We’ve now broken free of their chains completely and we’re going to build the best darn electronics supply store the world has ever seen. The vision is clear and the route has been mapped out. We will have the lowest price on a per component basis available from any US based online store.</p>
<p>Sometimes it takes a bit of pain to push us to where we need to be. That’s true in both business and in life.</p>
</div>
</div></div>]]>
            </description>
            <link>https://joeknowselectronics.com/the-end-of-an-amazon-era</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932052</guid>
            <pubDate>Thu, 29 Oct 2020 16:13:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing Semgrep and r2c]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24931985">thread link</a>) | @pabloest
<br/>
October 29, 2020 | https://r2c.dev/blog/2020/introducing-semgrep-and-r2c/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/introducing-semgrep-and-r2c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p>Free, fast, <a href="https://github.com/returntocorp/semgrep" target="_blank" rel="noopener">open-source</a>, offline, customizable. These are not often words that describe code scanning tools, and that's a shame.</p>
<p>We founded r2c to bring world-class security tools to developers based on our conviction that software will run the most exciting parts of the future: everything from medical equipment to robots to autonomous cars. The security process should not be the foe but rather the enabler of rapid software development. If developers lack tooling that is easy to set up and understand—or if a developer has to convince their manager to spend a few million dollars on advanced security tools each time they change jobs, the future is bleak.</p>
<p>Before founding r2c, we worked on security and developer tools for large companies and governments. It was eye-opening to see that despite massive budgets, their security programs were generally a generation or more behind the tech giants. When it came to security tools for developers, most teams were jaded about scanning code for vulnerabilities; they hated the tools they had to use and usually ignored them beyond doing the minimum necessary to satisfy a compliance checkbox.</p>
<p>What about code scanning at places like Facebook, Apple, Amazon, Netflix, and Google? They don't generally use traditional commercial security tools which ask "how can we find every bug?" Instead, they focus on custom tooling that can build guardrails for developers. This doesn't require million-dollar tools, PhDs in program analysis, or days of compute time. It looks much more like unit tests for security.</p>
<p>We believe there is a gap between traditional compliance tools and simple linters that's ripe for a new approach, and we were fortunate to find partners from Redpoint Ventures and Sequoia Capital who agreed. With them, we raised a $13M Series A round of funding to build a security tool that developers might actually love. We've been working on it quietly for a while now, and we're finally ready to announce it to the world!</p>
<h2>Semgrep</h2>
<p><a href="https://semgrep.dev/" target="_blank" rel="noopener">Semgrep</a>, our open-source product, is specifically designed for eradicating bug classes.
Developers and security engineers can say "this is the safe pattern we always use for (e.g. parsing XML)", write a rule in a few minutes, and enforce that on every editor save, commit, and pull request.</p>
<p>Semgrep is ideal for building security guardrails: start by using frameworks designed with security in mind, then automatically flag code that strays from the <a href="https://semgrep.dev/explore" target="_blank" rel="noopener">secure-by-default path</a>. This is an approach used by <a href="https://landing.google.com/sre/resources/foundationsandprinciples/srs-book/" target="_blank" rel="noopener">Google</a>, <a href="https://about.fb.com/news/2019/01/designing-security-for-billions/" target="_blank" rel="noopener">Facebook</a>, <a href="https://homes.cs.washington.edu/~mernst/pubs/continuous-compliance-ase2020.pdf" target="_blank" rel="noopener">Amazon</a>, Dropbox, Stripe, <a href="https://medium.com/@NetflixTechBlog/scaling-appsec-at-netflix-6a13d7ab6043" target="_blank" rel="noopener">Netflix</a>, and others—a topic <a href="https://events.bizzabo.com/OWASPGlobalAppSec/agenda/session/315858" target="_blank" rel="noopener">Clint Gibler and I presented on at Global AppSec 2020</a>. This approach increases developer productivity, reduces attack surface, minimizes the areas for human inspection and audit, and allows the security team to scalably protect code written by thousands of developers.</p>
<p>The idea behind Semgrep is simple: it feels like a regular search (grep) but is syntax-aware. You can <a href="https://semgrep.dev/learn" target="_blank" rel="noopener">learn Semgrep</a> in a few minutes! And Semgrep can be used for <a href="https://semgrep.dev/explore" target="_blank" rel="noopener">more than just security</a> issues: performance, internationalization, or just annoyances <a href="https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns" target="_blank" rel="noopener">committed by accident</a>.</p>
<p><span>
      <a href="https://r2c.dev/static/730ca8541e43ed871d2edb7c02226b0c/bde6a/semgrep-foo-small.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Semgrep pattern example" title="Semgrep pattern example" src="https://r2c.dev/static/730ca8541e43ed871d2edb7c02226b0c/bde6a/semgrep-foo-small.png" srcset="https://r2c.dev/static/730ca8541e43ed871d2edb7c02226b0c/bde6a/semgrep-foo-small.png 283w" sizes="(max-width: 283px) 100vw, 283px" loading="lazy">
  </a>
    </span></p>
<p><code>$ semgrep -e foo(1)</code> matches all equivalent variations. <a href="https://semgrep.dev/s/ievans:python-exec" target="_blank" rel="noopener">See a live example of matching <em>exec</em> calls</a></p>
<h2>What's Next?</h2>
<p>Semgrep started as an open-source project at Facebook and we're lucky to have its original author, Yoann Padioleau, on our team at r2c. Since we released the first post-Facebook version (0.4) earlier this year, we've released 25 new versions, added support for 8 new languages, reworked the parsers so we could collaborate with Github on <a href="https://tree-sitter.github.io/" target="_blank" rel="noopener">tree-sitter</a>, been joined by thousands of enthusiastic GitHub followers, and seen over 100K pulls of the Semgrep Docker image.</p>
<p>Our roadmap contains more program analysis features to support the sorts of secure-by-default enforcement that large technology companies are already leveraging so heavily (constant propagation, taint tracking, and more), as well as support for many more languages.</p>
<h2>Batteries Included</h2>
<p>Along with this release of Semgrep, we're announcing the availability of <a href="https://semgrep.dev/" target="_blank" rel="noopener">Semgrep Community</a>, a free, hosted service for managing Semgrep CI as well as Semgrep Teams, a paid service which adds additional features for managing Semgrep that are useful for enterprises. Both these offerrings provide SaaS infrastructure for operating a modern AppSec program. They enable central definition of code standards for your projects and show results where you already work: GitHub, GitLab, Slack, Jira, VS Code, and more.</p>
<p>We're also excited that <a href="https://semgrep.dev/explore" target="_blank" rel="noopener">Semgrep Registry</a> already has 900+ rules written by r2c and the community—you can start running on your project right now! Or if you like to DIY, <a href="https://semgrep.dev/editor" target="_blank" rel="noopener">try writing your own</a>.</p></div></div></div></section></div>]]>
            </description>
            <link>https://r2c.dev/blog/2020/introducing-semgrep-and-r2c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931985</guid>
            <pubDate>Thu, 29 Oct 2020 16:07:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't ruin your company when going remote with bad HR processes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931904">thread link</a>) | @designerdusko
<br/>
October 29, 2020 | https://www.ahoyteam.com/from-office-to-remote | <a href="https://web.archive.org/web/*/https://www.ahoyteam.com/from-office-to-remote">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="readonline"><p><h3>Read full guide online</h3><h3>Transitioning to a fully remote company in times of change</h3></p><div><h3>Introduction</h3><p>As the world changes in times of the COVID-19 pandemic, businesses are having to quickly adapt, not only for their consumers, but also to protect their employees. Many companies are needing to implement full work-from-home policies, and support their staff during this change. At Ahoy Team, we’ve built our company on helping companies transition to remote work, while upholding great company culture and accountability for asynchronous, and distributed teams. <br>During this time, we wanted to help by sharing some of our top tips for transitioning to a fully remote company. As we adjust to our new normal, some of these tips might outlast the lockdown as we begin to interact as teams again. <br></p><ol role="list"><li><a href="#section1"><strong>First steps as you go remote</strong></a></li><li><a href="#section2"><strong>Help employees set up work environment at home </strong></a></li><li><a href="#section3"><strong>Help teams run effective meetings</strong></a></li><li><a href="#section4"><strong>Keep employees informed</strong></a></li><li><a href="#section5"><strong>How to maintain company culture</strong></a></li><li><a href="#section6"><strong>When it returns to normal</strong></a></li></ol><p><em>Each chapter will include examples of workflows that could be implemented through AhoyTeam platform.</em><br></p></div><div id="section1"><p><strong>SECTION 1.</strong></p><h3><strong>First steps as you go remote</strong></h3><p>So, chances are as you’re reading this your company has already been forced to work from home. You likely emailed employees informing them that your office location was closing, and sent them well wishes. This is an unprecedented time for all of us, so it’s important to play catch up now with the things that help with remote culture. <br></p><ol role="list"><li>Start now by emailing your leadership team. Empower them to answer frequently asked questions, host virtual town hall meetings, and offer virtual ‘office hours’. During times of crisis, employees often need more reassurance and are likely to ask questions repeatedly- stress makes it difficult for information to stick for all of us, and the answers are likely changing rapidly. If you missed anything in your original ‘everybody go home’ email, don’t hesitate to share another one. Strong leadership and regular communication helps to maintain morale and support during this time. </li><li>Update documentation, or create a hub page on your employee portal or intranet to help employees find things. Nobody wants to be sifting through lots of information trying to find what they need- surface relevant information to them. Outline any policies, such as insurance benefits, sick leave and absence policies, and contact information they might need. </li><li><strong>Remote meetings: </strong>As you switch your meetings to remote, be mindful of the additional pressure employees may be under and lead with compassion. Remind your employees during each meeting that their mental health is the priority, that it is ok to have interruptions as people try to navigate family life and childcare, and ask yourself if meetings are really necessary. Different employee personalities may find virtual meetings stressful, so don’t default to a meeting when an email could work just as well. </li><li>Research other tools that could help and ensure everyone has access to them. While now isn’t the time for huge changes and big roll outs, tools such as Slack can be a quick, easy to implement way to keep people connected. Look for small changes that can relieve pressure and increase collaboration.</li><li>Create a Slack or communication channel. How does Slack fit into all of this? Well, in place of team members seeing each other every day and spending time together in meetings or over lunch hours, companies can create bonds by utilising technology to allow employees to spend time with each other. Create a dedicated channel for COVID-19 updates, and allow space for fun and distraction. </li></ol><div><div><div><p><img src="https://uploads-ssl.webflow.com/5d31a928f970eef3b21792ac/5f5b40121273b19baecc579e_ahoyslack.svg" loading="lazy" height="50" alt=""></p><h4><strong>Boost social interactions in remote setup</strong><br></h4></div></div></div><div><div><div><p><img src="https://uploads-ssl.webflow.com/5d31a928f970eef3b21792ac/5f5b40121273b19baecc579e_ahoyslack.svg" loading="lazy" height="50" alt=""></p><h4><strong>Slack culture 101 onboarding for each employee</strong><br></h4></div></div></div></div><div id="section2"><p><strong>SECTION 2.</strong></p><h3>Help employees set up work environment at home</h3><p>Not everyone has worked from home before, and may find it a challenge. As a leader, you can help by ensuring that people have things that they need.<br></p><p>Physical tips:</p><ol role="list"><li><strong>Make sure they have the devices they need:<br></strong>- Bluetooth headsets for remote calls<br>- Seperate keyboards and mice for reducing wrist strain<br>- Ergonomic chairs, or the means to reimburse chairs<br>- Additional monitors, if your employees normally use them i.e programmers or finance</li><li><strong>Make sure employees have access to the software they need:<br></strong>- Ensure they can download Zoom, Google Hangouts, or similar video conferencing software<br>- Update your safety and security policies to reduce additional concerns. Ensure VPN can handle the additional traffic.</li><li><strong>Share physical health tips, such as videos on stretching and how to adjust your chair properly </strong>- without being in an office your employees are not getting their usual assessments. </li><li><strong>Make a quick and easy process for employees to report cases and symptoms. </strong>Make it easy for them to get support from their manager, HR, health care provider, and do not make them jump through any additional administrative hoops to do so.</li><li><strong>Provide health and safety information to help employees navigate the noise</strong>, such as cleaning information, and the latest confirmed government advice. For some people, they are struggling to navigate through less-than-ideal spaces, so communication and mental health is important.</li></ol><div><div><div><p><img src="https://uploads-ssl.webflow.com/5d31a928f970eef3b21792ac/5f5b40121273b19baecc579e_ahoyslack.svg" loading="lazy" height="50" alt=""></p><h4><strong>Simple weekly employee health check (COVID-19 version)</strong><br></h4></div></div></div><p>Mental tips:</p><ol role="list"><li><strong>Remind your employees that it is ok to be working surrounded by laundry, or with a child on their lap, during this time. </strong>Share anecdotes and funny pictures of your workspace to remind employees we’re all in this together.</li><li><strong>Make sure that your employees know who their main POC is in case they need help navigating working from home. </strong>If you already have remote workers, consider making them remote work ‘champions’, who can share their tips. </li><li><strong>Remind employees to separate their work and home environments wherever possible, </strong>by closing a door on their office, packing away their laptop, or changing their clothes to mark a difference between ‘work’ and ‘home’ time. </li><li><strong>You can also generate positivity by creating community activities </strong>like virtual workouts, virtual volunteering, or lunch hours to maintain positive relationships. <strong><br></strong></li><li><strong>Make sure to share your expectations and make sure they are manageable for people. </strong>Some members of staff may find it exceptionally helpful to understand that the 9am stand up meeting is critical, but that they can alternate with a colleague on another one to reduce the pressure. Make sure to communicate your expectations around working hours, and consider if you can make this more flexible for both your employees and your customers. </li><li><strong>Link to resources for people, such as mental health resources, and make it easily available on employee intranet. </strong>Create community activity like content by wellness specialists, watch parties or book clubs. Enable a forum for your employees to share content with each other, such as Mindfulness meditation videos, podcasts, tips and ideas of what’s working for them. </li></ol></div><div id="section3"><p><strong>SECTION 3.</strong></p><h3><strong>Help teams run effective meetings</strong></h3><p>As all meetings switch to virtual, help your teams make effective use of their time and maximise meeting effectiveness. This is not just for your company- it also helps employees get more time back and remain focused, which is going to help with mental health.<br></p><p>Set up a good meeting rhythm to help stay connected, such as weekly 1-2-1s with managers, team calls and a company all hands. Share basic meeting tips for remote communication, which can help remind employees how to streamline their daily tasks and spend more time with family or community. <br></p><ul role="list"><li><strong>Always have an agenda for a meeting. </strong>If there isn’t an agenda, empower employees to ask, or switch it to an email</li><li><strong>Keep minutes from meetings, </strong>or record calls, to help absent, time-zone separated or employees with childcare problems to catch up</li><li><strong>Start and end meetings on time. </strong>For some employees, the fact they are working from home and enjoying the conversation means meetings can drag on. Being on time helps reduce stress for busy parents, and manages expectations across teams. </li><li><strong>Be flexible. </strong>Meetings should be at a time that causes minimal disruption for all members</li><li><strong>Have a facilitator. </strong>People are coping with the pandemic differently, and having a facilitator means that person can support the rest of the team keeping the meeting productive.</li><li><strong>Start the meeting with wins. </strong>Thank your team for their hard work, focus on the positives, and then move on to alignment and troubleshooting. </li></ul><div><div><div><p><img src="https://uploads-ssl.webflow.com/5d31a928f970eef3b21792ac/5f5b40121273b19baecc579e_ahoyslack.svg" loading="lazy" height="50" alt=""></p><h4><strong>Written Daily Standup</strong><br></h4></div></div></div><div><div><div><p><img src="https://uploads-ssl.webflow.com/5d31a928f970eef3b21792ac/5f5b40121273b19baecc579e_ahoyslack.svg" loading="lazy" height="50" alt=""></p><h4><strong>Schedule weekly Zoom calls with actionable task before and after the call</strong><br></h4></div></div></div></div><div id="section4"><p><strong>SECTION 4.</strong></p><h3><strong>Keep employees informed</strong></h3><p>The more transparent you can be with your team and employees, the more they will be able to minimise stress and predict any difficult decisions you may need to make down the road. There’s no silver bullet and single answer to this, but you can help keep employees safe and engaged by improving how you communicate with them.<br></p><ul role="list"><li><strong>Create open, transparent communication channels such as Slack, to share news and information. </strong>In times of uncertainty, it’s even more important to have a single hub where people can ask questions and share updates. </li><li><strong> Be upfront and honest on team calls about company finances. </strong>It’s not easy, but people are concerned about their income, and the more you can share, along with any safeguards you’re putting in place to help reduce layoffs (such as government or tax claims), the better. People will speculate anyway, so it’s important to give them clarity, even if it’s bad news. </li><li><strong>Enable collaboration.</strong> Working remotely can make communication difficult- we tend to forget all those natural conversations that happen by virtue of proximity. Slack lets you work collaboratively by bringing tagging and chat into documents. Be available, and be mindful of any miscommunication that can happen more readily without non-verbal cues. </li><li><strong>Make it easy to find information. </strong>Surface Slack channels where key information is brought to the forefront- people will have a lot of questions for IT, HR and facilities teams in particular. </li></ul></div><div id="section5"><p><strong>SECTION 5.</strong></p><h3><strong>How to maintain company culture</strong></h3><p>For a remote team, company culture is critical. A common misconception (that I’m here to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ahoyteam.com/from-office-to-remote">https://www.ahoyteam.com/from-office-to-remote</a></em></p>]]>
            </description>
            <link>https://www.ahoyteam.com/from-office-to-remote</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931904</guid>
            <pubDate>Thu, 29 Oct 2020 15:59:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chaos Engineering: System Resiliency in Practice (Free eBook)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931833">thread link</a>) | @pavanyara
<br/>
October 29, 2020 | https://www.verica.io/book/ | <a href="https://web.archive.org/web/*/https://www.verica.io/book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="block-block_5f75bae1cc92f">
  <div>
  	
  	<div>
  					<div>
				<p>Complex systems become fragile in unexpected and unpredictable ways. The authors of this book go deep explaining the core practices and providing real-world stories and practical advice on how teams are using the ideas around Chaos Engineering to make their systems more resilient.</p>
				<p><img src="https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/Bitmap-1.png">
				</p>
				<div>
					<p><strong>Michael Loop</strong>
					</p>
					<p>
					Former VP of Engineering at Slack   				</p>
			</div>
		</div>
								<div>
				<p>I found this book as a great resource in understanding and leveraging Chaos principles in my profession as a leader of a team of engineers, responsible for mitigating the risks and ensuring the “high availability” of multiple products. I highly recommend it to those in software design/development/quality engineering. who want to learn more about how Chaos engineering can help you to proactively extract the possible risks by leveraging well explained methodologies.</p>
				<p><img src="">
				</p>
				
		</div>
								<div>
				<p>An excellent guide to the state of the art in Chaos Engineering.</p>
				<p><img src="https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/cockcroft.png">
				</p>
				
		</div>
				
  </div>
  	
  </div>
</div></div>]]>
            </description>
            <link>https://www.verica.io/book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931833</guid>
            <pubDate>Thu, 29 Oct 2020 15:54:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forget It and Set It]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931780">thread link</a>) | @abyx
<br/>
October 29, 2020 | https://avivbenyosef.com/forget-it-and-set-it/ | <a href="https://web.archive.org/web/*/https://avivbenyosef.com/forget-it-and-set-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1843">
	
	
	<!-- .entry-header -->

	
	<div>
		
<p>Being a consultant, you won’t be surprised to hear that I am often involved in helping companies go through changes. One common aspect that I see, either as I’m working with my clients or when they tell me about their failed past attempts, is that the executives often hold a much too simplistic view on how changes should be done.</p>



<p>Ideally, everyone would like to be able to announce a change, like a new process, and move on—the team would immediately adapt and make sure that everything works smoothly, letting you know if there are any issues. Unfortunately, that’s not the case in most organizations. Once the initiative is handed off, it gets derailed, abandoned, or progresses much too slowly. Let’s unpack the issues that cause this to happen.</p>



<h3>Losing Momentum</h3>



<p>Change focus from your own perspective as an executive for a second, and consider what’s happening from one of your team members’ point of view. How would you feel if someone would swoop in, declare a new change, and then run along to do the next thing? As an executive, you might see this as delegating and empowering. However, it can be interpreted as capricious and merely passing a hot potato.</p>



<p>Even if your team initially started working on this in good faith, when the first setbacks are encountered they need something to help them push through. That’s harder to achieve when it seems like leadership is disinterested.</p>



<p>We’ve all seen caricatures that portray the differences between types of leaders: one yells “go and do this” from the side, while the other charges forward yelling “follow me!” Which one would you be more inclined to listen to?</p>



<p>This is even worse when the leaders are assigned tasks and don’t do them (or communicate that they have). Since you’re always modeling behavior for your people, they pick this up and deduct that this effort is just not that important.</p>



<h3>Fixing Your Attitude</h3>



<p>Here are some ground rules for effective changes:</p>



<ul><li>Be accountable. If you have tasks on your plate, do them and do them on time. Otherwise, you cannot complain when others fail to do their part.</li><li>Be timely. It doesn’t matter that you’re higher up in the org chart. If you set a date, stick to it. Others will find great excuses as well if you let them.</li><li>Be transparent. When you make progress, it should be visible so everyone can see that you’re putting your money where your mouth is, spending your time on this as well.</li><li>Be involved. You don’t have to take the lead, but you should know what’s going on and show interest in the progress and decisions.</li><li>If you cannot participate, put your best people on it.<br></li></ul>



<p>Yes, you might eventually be able to start some of these without being involved later, but you’re likely not there yet. At a later point, you’ll be able to assign a few champions to push a matter forward. Just not today.</p>



<p>Once you have gained enough trust by running successful changes like these, it will become easier. Remember, Rome wasn’t built in a day.</p>
 <div data-ck-version="6">   <div>   <div>     <h3>Get the Tech Executive Operating System</h3>     <p>Get the best newsletter for tech executives online. Tailored for your daily work. Weekly, short, and packed with exclusive insights.</p>            <!--  Form starts here  -->        </div>  </div>  </div>    			</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
</article></div>]]>
            </description>
            <link>https://avivbenyosef.com/forget-it-and-set-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931780</guid>
            <pubDate>Thu, 29 Oct 2020 15:49:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What could the polls be missing this Presidential election?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931725">thread link</a>) | @dsaavy
<br/>
October 29, 2020 | https://www.melovedata.com/what-could-the-polls-be-missing-in-this-presidential-election/ | <a href="https://web.archive.org/web/*/https://www.melovedata.com/what-could-the-polls-be-missing-in-this-presidential-election/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<div>
<div>
<p>Recently I wrote an article on the <a href="https://www.melovedata.com/twitter-still-hasnt-unlocked-the-new-york-posts-account/" target="_blank" rel="noreferrer noopener">New York Post’s Twitter account still being locked</a>. This is still the case,  and it made me brainstorm many other topics associated with elections . This thinking session brought up the topic of polls and predictions. How accurate are they? Why were many polls so far off in 2016? Why do polls seem to tighten the closer to election day? [<a href="https://slate.com/news-and-politics/2008/10/why-do-polls-always-tighten-right-before-an-election.html" target="_blank" rel="noreferrer noopener">1</a>][<a href="https://www.politifact.com/factchecks/2008/dec/01/barack-obama/elections-tighten-almost-every-time/" target="_blank" rel="noreferrer noopener">2</a>]</p>



<p>Many polls are predicting Biden to <a href="https://projects.fivethirtyeight.com/2020-election-forecast/" target="_blank" rel="noreferrer noopener">win by a large margin</a>, and many of the points I make below indicate factors that could make the margin much smaller. The one factor that could cause a greater margin than predicted would be an increase in Black and Hispanic voter participation. This is due to the fact that Biden still holds majority over those demographics so an increase in the total number of voters would benefit him the greatest.</p>



<h3>Here’s what I think the polls could be missing</h3>



<h5>Narrowing party registration gaps, especially in swing states.</h5>



<p>There are indications that <a href="https://www.cbsnews.com/news/voter-registration-republicans-swing-states-narrow-gap/" target="_blank" rel="noreferrer noopener">Republicans have significantly closed the registered voter gap</a>, especially in swing states. Trump narrowly won the 2016 election in many of these states, so a lesser difference between registered Democrats and registered Republicans could indicate Trump holding his lead in swing states. Of course, non-affiliated voters still hold a large chunk (often 20%+) in swing states, so nothing is set in stone.</p>



<h5>Unwillingness for people to truthfully poll, especially for a candidate like Donald Trump. </h5>



<p>Some studies have shown that people are <a href="https://www.cloudresearch.com/resources/blog/election-2020-poll-respondent-honesty/" target="_blank" rel="noreferrer noopener">unwilling to share their vote choice with polls</a>. The study linked states that around 11.7% of Republicans don’t share their truthful choice with polls, 10.5% of non-afiiliated, and 5.4% of Democrats. That’s certainly not insignificant.</p>



<h5>Shifting demographics in the Black and Hispanic vote. </h5>



<p>If the Black and Hispanic vote turnout is the same or less than 2016, this will be a net negative impact for the Democratic party. <a href="https://fivethirtyeight.com/features/trump-is-losing-ground-with-white-voters-but-gaining-among-black-and-hispanic-americans/" target="_blank" rel="noreferrer noopener">Trump closed the polling gap from 2016 between both these demographics</a> (although still doesn’t poll above 50% for either demographic). So if the total pie of votes for Black and Hispanic voters doesn’t increase, Trump takes a bigger portion of a pie the same size as 2016.</p>



<h5>Increasing distrust of media and technology amongst conservatives.</h5>



<p>If a person doesn’t trust the news, believes they’re being censored, or is generally less trusting in institutions, why would they answer truthfully to polls? Why would they participate in the polls in the first place?  Are polls even further off than the “shy” voters study linked in the truthful poll section above?</p>



<h5>Unknown voter turnout for the Black and Hispanic vote.</h5>



<p>2016 saw a decrease in participation with these two demographics. If participation is higher than anticipated, it will significantly benefit Biden and result in a landslide win.</p>



<h3>Wrapping it up</h3>



<p>While many polls try to adjust for factors like these, it’s impossible to accurately measure all the variables associated with elections. For example, every time that Florida has seen under a 4% party registration spread, Republicans have won the state, anything above 4%, the Democrats have won. Right now the spread is under 2%. But mail-in voting will be at an all time high, so will overall participation increase or are only active voters shifting their voting method? </p>



<p>Many polls will correctly predict the election within their margin of error. The only issue is that it’s not useful in states consistently decided by less than the typical margin of error (like <a href="https://en.wikipedia.org/wiki/2016_United_States_presidential_election_in_Pennsylvania" target="_blank" rel="noreferrer noopener">Pennsylvania </a>and <a href="https://en.wikipedia.org/wiki/2016_United_States_presidential_election_in_Florida" target="_blank" rel="noreferrer noopener">Florida</a>).</p>
</div>




</div>



<hr>



<p>Enjoy the content? Subscribe below to get notifications of new posts and access to subscriber giveaways.</p>



	<div data-blog-id="177716820">
		<div>
			
			
				<p>
					Processing…				</p>
				<p>
					Success! You're on the list.				</p>
				<p>
					Whoops! There was an error and we couldn't process your subscription. Please reload the page and try again.				</p>

					</div>
	</div>
	

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://www.melovedata.com/what-could-the-polls-be-missing-in-this-presidential-election/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931725</guid>
            <pubDate>Thu, 29 Oct 2020 15:45:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Illustrated Transformer Visualizing machine learning one concept at a time]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931724">thread link</a>) | @mrfusion
<br/>
October 29, 2020 | https://jalammar.github.io/illustrated-transformer/ | <a href="https://web.archive.org/web/*/https://jalammar.github.io/illustrated-transformer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><span>Discussions:
<a href="https://news.ycombinator.com/item?id=18351674">Hacker News (65 points, 4 comments)</a>, <a href="https://www.reddit.com/r/MachineLearning/comments/8uh2yz/p_the_illustrated_transformer_a_visual_look_at/">Reddit r/MachineLearning (29 points, 3 comments)</a>
</span>
<br>
<span>Translations: <a href="https://blog.csdn.net/yujianmin1990/article/details/85221271">Chinese (Simplified)</a>, <a href="https://tips-memo.com/translation-jayalmmar-transformer">Japanese</a>, <a href="https://nlpinkorean.github.io/illustrated-transformer/">Korean</a>, <a href="https://habr.com/ru/post/486358/">Russian</a>, <a href="https://hackernoon.com/el-transformador-ilustrado-una-traduccion-al-espanol-0y73wwp">Spanish</a></span>
<br>
<span>Watch: MIT’s <a href="https://youtu.be/53YvP6gdD7U?t=432">Deep Learning State of the Art</a> lecture referencing this post</span></p>

<p>In the <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">previous post, we looked at Attention</a> – a ubiquitous method in modern deep learning models. Attention is a concept that helped improve the performance of neural machine translation applications. In this post, we will look at <strong>The Transformer</strong> – a model that uses attention to boost the speed with which these models can be trained. The Transformers outperforms the Google Neural Machine Translation model in specific tasks. The biggest benefit, however, comes from how The Transformer lends itself to parallelization. It is in fact Google Cloud’s recommendation to use The Transformer as a reference model to use their <a href="https://cloud.google.com/tpu/">Cloud TPU</a> offering. So let’s try to break the model apart and look at how it functions.</p>

<p>The Transformer was proposed in the paper <a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a>. A TensorFlow implementation of it is available as a part of the <a href="https://github.com/tensorflow/tensor2tensor">Tensor2Tensor</a> package. Harvard’s NLP group created a <a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">guide annotating the paper with PyTorch implementation</a>. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.</p>

<h2 id="a-high-level-look">A High-Level Look</h2>
<p>Let’s begin by looking at the model as a single black box. In a machine translation application, it would take a sentence in one language, and output its translation in another.</p>

<p><img src="https://jalammar.github.io/images/t/the_transformer_3.png">
</p>

<!--more-->

<p>Popping open that Optimus Prime goodness, we see an encoding component, a decoding component, and connections between them.</p>

<p><img src="https://jalammar.github.io/images/t/The_transformer_encoders_decoders.png">
</p>

<p>The encoding component is a stack of encoders (the paper stacks six of them on top of each other – there’s nothing magical about the number six, one can definitely experiment with other arrangements). The decoding component is a stack of decoders of the same number.</p>

<p><img src="https://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png">
</p>

<p>The encoders are all identical in structure (yet they do not share weights). Each one is broken down into two sub-layers:</p>

<p><img src="https://jalammar.github.io/images/t/Transformer_encoder.png">
</p>

<p>The encoder’s inputs first flow through a self-attention layer – a layer that helps the encoder look at other words in the input sentence as it encodes a specific word. We’ll look closer at self-attention later in the post.</p>

<p>The outputs of the self-attention layer are fed to a feed-forward neural network. The exact same feed-forward network is independently applied to each position.</p>

<p>The decoder has both those layers, but between them is an attention layer that helps the decoder focus on relevant parts of the input sentence (similar what attention does in <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">seq2seq models</a>).</p>

<p><img src="https://jalammar.github.io/images/t/Transformer_decoder.png">
</p>

<h2 id="bringing-the-tensors-into-the-picture">Bringing The Tensors Into The Picture</h2>

<p>Now that we’ve seen the major components of the model, let’s start to look at the various vectors/tensors and how they flow between these components to turn the input of a trained model into an output.</p>

<p>As is the case in NLP applications in general, we begin by turning each input word into a vector using an <a href="https://medium.com/deeper-learning/glossary-of-deep-learning-word-embedding-f90c3cec34ca">embedding algorithm</a>.</p>



<p><img src="https://jalammar.github.io/images/t/embeddings.png">
  <br>
  Each word is embedded into a vector of size 512. We'll represent those vectors with these simple boxes.
</p>

<p>The embedding only happens in the bottom-most encoder. The abstraction that is common to all the encoders is that they receive a list of vectors each of the size 512 – In the bottom encoder that would be the word embeddings, but in other encoders, it would be the output of the encoder that’s directly below. The size of this list is hyperparameter we can set – basically it would be the length of the longest sentence in our training dataset.</p>

<p>After embedding the words in our input sequence, each of them flows through each of the two layers of the encoder.</p>

<p><img src="https://jalammar.github.io/images/t/encoder_with_tensors.png">
  <br>

</p>

<p>Here we begin to see one key property of the Transformer, which is that the word in each position flows through its own path in the encoder. There are dependencies between these paths in the self-attention layer. The feed-forward layer does not have those dependencies, however, and thus the various paths can be executed in parallel while flowing through the feed-forward layer.</p>

<p>Next, we’ll switch up the example to a shorter sentence and we’ll look at what happens in each sub-layer of the encoder.</p>

<h2 id="now-were-encoding">Now We’re Encoding!</h2>

<p>As we’ve mentioned already, an encoder receives a list of vectors as input. It processes this list by passing these vectors into a ‘self-attention’ layer, then into a feed-forward neural network, then sends out the output upwards to the next encoder.</p>

<p><img src="https://jalammar.github.io/images/t/encoder_with_tensors_2.png">
  <br>
  The word at each position passes through a self-attention process. Then, they each pass through a feed-forward neural network -- the exact same network with each vector flowing through it separately.
</p>

<h2 id="self-attention-at-a-high-level">Self-Attention at a High Level</h2>
<p>Don’t be fooled by me throwing around the word “self-attention” like it’s a concept everyone should be familiar with. I had personally never came across the concept until reading the Attention is All You Need paper. Let us distill how it works.</p>

<p>Say the following sentence is an input sentence we want to translate:</p>

<p>”<code>The animal didn't cross the street because it was too tired</code>”</p>

<p>What does “it” in this sentence refer to? Is it referring to the street or to the animal? It’s a simple question to a human, but not as simple to an algorithm.</p>

<p>When the model is processing the word “it”, self-attention allows it to associate “it” with “animal”.</p>

<p>As the model processes each word (each position in the input sequence), self attention allows it to look at other positions in the input sequence for clues that can help lead to a better encoding for this word.</p>

<p>If you’re familiar with RNNs, think of how maintaining a hidden state allows an RNN to incorporate its representation of previous words/vectors it has processed with the current one it’s processing. Self-attention is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing.</p>

<p><img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization.png">
  <br>
  As we are encoding the word "it" in encoder #5 (the top encoder in the stack), part of the attention mechanism was focusing on "The Animal", and baked a part of its representation into the encoding of "it".
</p>

<p>Be sure to check out the <a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb">Tensor2Tensor notebook</a> where you can load a Transformer model, and examine it using this interactive visualization.</p>

<h2 id="self-attention-in-detail">Self-Attention in Detail</h2>
<p>Let’s first look at how to calculate self-attention using vectors, then proceed to look at how it’s actually implemented – using matrices.</p>

<p>The <strong>first step</strong> in calculating self-attention is to create three vectors from each of the encoder’s input vectors (in this case, the embedding of each word). So for each word, we create a Query vector, a Key vector, and a Value vector. These vectors are created by multiplying the embedding by three matrices that we trained during the training process.</p>

<p>Notice that these new vectors are smaller in dimension than the embedding vector. Their dimensionality is 64, while the embedding and encoder input/output vectors have dimensionality of 512. They don’t HAVE to be smaller, this is an architecture choice to make the computation of multiheaded attention (mostly) constant.</p>



<p><img src="https://jalammar.github.io/images/t/transformer_self_attention_vectors.png">
  <br>
  Multiplying <span>x1</span> by the <span>WQ</span> weight matrix produces <span>q1</span>, the "query" vector associated with that word. We end up creating a "query", a "key", and a "value" projection of each word in the input sentence.
</p>



<div><p>What are the “query”, “key”, and “value” vectors?
</p><p>

They’re abstractions that are useful for calculating and thinking about attention. Once you proceed with reading how attention is calculated below, you’ll know pretty much all you need to know about the role each of these vectors plays.</p></div>

<p>The <strong>second step</strong> in calculating self-attention is to calculate a score. Say we’re calculating the self-attention for the first word in this example, “Thinking”. We need to score each word of the input sentence against this word. The score determines how much focus to place on other parts of the input sentence as we encode a word at a certain position.</p>

<p>The score is calculated by taking the dot product of the <span>query vector</span> with the <span>key vector</span> of the respective word we’re scoring. So if we’re processing the self-attention for the word in position <span>#1</span>, the first score would be the dot product of <span>q1</span> and <span>k1</span>. The second score would be the dot product of <span>q1</span> and <span>k2</span>.</p>



<p><img src="https://jalammar.github.io/images/t/transformer_self_attention_score.png">
  <br>

</p>



<p>The <strong>third and forth steps</strong> are to divide the scores by 8 (the square root of the dimension of the key vectors used in the paper – 64. This leads to having more stable gradients. There could be other possible values here, but this is the default), then pass the result through a softmax operation. Softmax normalizes the scores so they’re all positive and add up to 1.</p>



<p><img src="https://jalammar.github.io/images/t/self-attention_softmax.png">
  <br>

</p>

<p>This softmax score determines how much each word will be expressed at this position. Clearly the word at this position will have the highest softmax score, but sometimes it’s useful to attend to another word that is relevant to the current word.</p>



<p>The <strong>fifth step</strong> is to multiply each value vector by the softmax score (in preparation to sum them up). The intuition here is to keep intact the values of the word(s) we want to focus on, and drown-out irrelevant words (by multiplying them by tiny numbers like 0.001, for example).</p>

<p>The <strong>sixth step</strong> is to sum up the weighted value vectors. This produces the output of the self-attention layer at this position (for the first word).</p>



<p><img src="https://jalammar.github.io/images/t/self-attention-output.png">
  <br>
</p>

<p>That concludes the self-attention calculation. The resulting vector is one we can send along to the feed-forward neural network. In the actual implementation, however, this calculation is done in matrix form for faster processing. So let’s look at that now that we’ve seen the intuition of the calculation on the word level.</p>

<h2 id="matrix-calculation-of-self-attention">Matrix Calculation of Self-Attention</h2>
<p><strong>The first step</strong> is to calculate the Query, Key, and Value matrices. We do that by packing our embeddings into a matrix <span>X</span>, and multiplying it by the weight matrices we’ve trained (<span>WQ</span>, <span>WK</span>, <span>WV</span>…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jalammar.github.io/illustrated-transformer/">https://jalammar.github.io/illustrated-transformer/</a></em></p>]]>
            </description>
            <link>https://jalammar.github.io/illustrated-transformer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931724</guid>
            <pubDate>Thu, 29 Oct 2020 15:45:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Good Parts]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931721">thread link</a>) | @_query
<br/>
October 29, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There’s been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it’s ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That’s how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It’s really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it’s highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it’s finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there’s now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it’s finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931721</guid>
            <pubDate>Thu, 29 Oct 2020 15:44:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizations as a Company of One]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24931633">thread link</a>) | @jnfr
<br/>
October 29, 2020 | https://lunchbag.ca/company-of-one/ | <a href="https://web.archive.org/web/*/https://lunchbag.ca/company-of-one/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<p><span>
				Written on <time datetime="2020-05-18 16:00:00 +0000 UTC">May 18, 2020</time>
			</span>
		</p>
		

<p>Hello! 👋 My name is Jen and I’m the founder, engineer, designer and customer support at <a href="https://lunchmoney.app/">Lunch Money</a>, a personal finance and budgeting web app.</p>

<p>In short, I am a company of one. I answer the customer support emails and I code and deploy new features. I also manage the <a href="https://developers.lunchmoney.app/" target="_blank">API docs</a> and <a href="https://support.lunchmoney.app/" target="_blank">knowledge base</a>, poke around the logs when there are issues, write the <a href="https://lunchmoney.app/sample_newsletter" target="_blank">bi-monthly newsletters</a> and I designed the logo!</p>

<p>As the company scales, so too must all aspects of my work which I break down into 4 parts: customer support, engineering, product and marketing.</p>

<p><strong>Finding opportunities for process optimization is honestly one of the more fun parts of running a business</strong>. I greatly attribute these to how I’ve been able to stay both solo &amp; sane up until now, currently with 600+ users and $45,000 ARR. In this post, I’m excited to share some of my most successful strategies along with anecdotes from my experience working on Lunch Money.</p>



<p>In the last 14 days, here’s what I got done across all departments:</p>

<ul>
<li><strong>Product:</strong> Launched an internal beta testers program and two sets of new features to test</li>
<li><strong>Engineering:</strong> Wrapped up a 2-week long refactor of some core components on the client-side</li>
<li><strong>Engineering:</strong> Launched a major feature: advanced transaction filters</li>
<li><strong>Engineering:</strong> Closed 13 tickets related to feature improvements and bug fixes</li>
<li><strong>Marketing:</strong> Sent out a newsletter outlining the latest new features</li>
<li><strong>Marketing:</strong> This blog post</li>
<li><strong>Marketing:</strong> Added new pages to the marketing site (<a href="https://lunchmoney.app/features/rules">Rules</a> and <a href="https://lunchmoney.app/features/collaboration">Collaboration</a>) and updated the icons in <a href="https://lunchmoney.app/features">Features</a></li>
<li><strong>Support:</strong> Received 239 inbound support tickets and sent out 358 emails</li>
</ul>

<p>What makes all this work bearable for me is the fact that there is so much variety (which, of course, is the spice of life!). I love being able to switch between tasks to keep the job interesting and my mind refreshed while still being productive overall.</p>

<p><em>Case in point: I just finished a major refactor and pushed out 2 major features to beta, so writing this blog post right now feels like a vacation for my brain.</em></p>

<p>To state the obvious, I enjoy being hyper-efficient (without burning myself out, of course). Even though I am a single person, I can still automate, optimize and parallelize processes.</p>



<h2 id="implement-safeguards">Implement safeguards</h2>

<p><i>Ah, the blissful beginnings of Lunch Money when I’d push code directly to production several times a day.</i></p>

<p>At 500+ users now, those days are long gone and I’ve since needed to adopt the more boring but responsible approach of implementing safeguards to prevent shipping faulty code.</p>

<p>For one, <b>I’ve been thoroughly reviewing my own code before every change</b>. Every major feature, improvement and bug fix lives in a feature branch that I still, by habit from the corporate days, prepend with <code>jen/</code>. After verifying everything works great locally, I make sure to take a break first, whether that’s working on a completely unrelated task, going for a meal or going to bed. The point of this is to ensure that I’m code reviewing with a clear head.</p>

<p>While adhering to these standards of code reviewing myself may add extra time to my overall process, it potentially saves hours of bug-fixing, answering related support tickets and self-loathing (I’m half-kidding here) down the line if I accidentally ship bad code.</p>

<center><blockquote><p lang="en" dir="ltr">New phase of Lunch Money– no more pushing major features straight to production 🤯😂 <a href="https://t.co/RYsz7BnU3L">https://t.co/RYsz7BnU3L</a></p>— Jen (@lunchbag) <a href="https://twitter.com/lunchbag/status/1256987437600927744?ref_src=twsrc%5Etfw">May 3, 2020</a></blockquote> </center>

<p><b>I also recently implemented an internal beta-testing program open to Lunch Money subscribers.</b> With more users accessing my app on a regular basis, the stakes are higher to ship a version that’s as bug-free as possible.</p>

<p>As an engineering team of one, it’s nearly impossible to always get it right the first time, despite having tests (what if I missed an edge case?) or testing locally extensively (how I think my users will use a feature is not always so).</p>

<p>The beta-testing program has provided some additional benefits. It’s nice to have a cohort of users with whom I can have a more candid conversation about Lunch Money and it’s also a great way to show users that their feedback is valued!</p>

<h2 id="automate-later-than-you-need-to">Automate later than you need to</h2>

<p>While automating tasks can save a lot of time in the long-term, it doesn’t always make sense to automate right off the bat.</p>

<p><img src="https://imgs.xkcd.com/comics/is_it_worth_the_time.png"><span>Obligatory XKCD comic (<a href="https://xkcd.com/1205/" target="_blank">link</a>)</span></p>

<p>Automating too late is not a bad thing. I’ll have done the manual work enough times to understand how to eventually automate the task and what edge cases to look out for. I equate it to doing a job yourself before hiring someone– it’s always better to grok the requirements first to some degree so you can understand how to best utilize who you’ve brought on (and appreciate them more!).</p>

<p>I manually triggered the emails for bi-monthly account summaries for months because I wasn’t confident the sending cadence was reasonable. After observing open rates and collecting user feedback, these are now automated to go out on the 5th &amp; 25th of every month.</p>

<p>Something that I’m glad I didn’t spend the time to automate at all was the referral program. If an existing user refers a new user and the new user subscribes to a plan, then both users will receive credit for 1 month.</p>

<p>In the end, the referral program only brought on 11 extra users. It was not a pain at all to manually process rewards for those who did. If I had spent time conjuring up all the edge cases and automating this process, it would not have been worth the time investment.</p>

<h2 id="keep-low-hanging-fruits-in-the-back-pocket">Keep low-hanging fruits in the back pocket</h2>

<p>In my task management system, I use a tag (🍏) to denote which tasks are low-hanging fruits. For the uninitiated, low-hanging fruits are quick tasks that are easy to knock out, such as one-liners or 5-minute fixes.</p>

<p><img src="https://media.giphy.com/media/YP1Jb0JNc7kqFDbdjm/giphy.gif"></p>

<p>I find that keeping these around and tackling them on days when you feel generally unmotivated can really help raise spirits. Still being able to get something completed and shipped is a great way to get out of a slump.</p>



<h2 id="timing-marketing-pushes">Timing marketing pushes</h2>

<p>At Lunch Money, a big part of the business is using the services of Plaid for bank syncing. Plaid charges on a monthly basis which means that if a user signs up on April 30, connects a bank account immediately and doesn’t end up subscribing at the end of their 14-day trial, they will charge me for this user in both April &amp; May’s invoices.</p>

<p>This realization coupled with my intense aversion to paying more than I need to has shaped a lot of practices at Lunch Money.</p>

<p>For one, the data retention policy used to be 30 days which means if your trial ends and you didn’t put in your billing information, your data will be deleted in 30 days. This certainly guarantees that I’ll be overpaying for churned users and is the reason why the data retention policy has since been revised to 5 days.</p>

<p>In total, a user who does not end up subscribing can spend up to 26 days in the Lunch Money system. This comprises of a 14-day trial, the potential for a 1 week trial extension and a 5 day grace period. Assuming enough users connect their bank accounts, the best way to minimize my costs for churned users is to ensure their lifetimes are within one calendar month.</p>

<p><img src="https://lunchbag.ca/uploads/calendar-1.png"></p>

<p>As a result, I always schedule marketing pushes such as blog posts and product launches in the first few days of the month. When I came to this realization, my next Plaid bill went down for the first time.</p>

<h2 id="merging-marketing-and-engineering-for-a-combo-win">Merging marketing and engineering for a combo win</h2>

<p>Taking this a step further, the perk of having a spike in new users is that their trial periods more-or-less overlap. Usually when a new user signs up, they will poke around the product and maybe send in a bug report, a feature request or another piece of feedback. If I reply and address their feedback by putting in a fix or shipping their requested feature within days, more often than not, they end up converting into a happy customer.</p>

<p>I’ve therefore identified the following cycle to maximize potential conversions from spikes in user signups:</p>

<p><img src="https://lunchbag.ca/uploads/gantt-2.png"></p>

<p>After a marketing push, let’s say a product launch, I will see an immediate increase in signups lasting about 3 days and then slowly trailing off.</p>

<p>Over the next few days, I’ll start hearing from these new users via support tickets. I prioritize responding to them and I get to work. Showing these users that I’m committed to improving Lunch Money based on their feedback is a great and honest sales tactic.</p>

<p>About 3 days before the initial wave of user trials ends, I wrap up my engineering sprint and send out a newsletter detailing the latest features and improvements. This re-enforces to new users that the product is under continuous development.</p>

<p>Finally, I have a drip campaign that automatically notifies users a few days before their trial expires and on the actual date of expiry. This period of time is when I typically see most users convert 🤞.</p>



<p>I used to think that if I were to hire someone, it would first be a customer support agent but I’ve since been moving away from that idea. Users are constantly surprised (in a good way!) when they realize the founder is responding to their bug reports or feature requests directly.</p>

<p><strong>Consistently providing great customer support is a long-term investment for Lunch Money</strong> as it is undoubtedly a great way to turn customers into champions. As I receive and respond to support tickets, I’m also able to identify and overhaul the common sources of trouble for users.</p>

<p>I’ve always believed that customer support would be the most important and the hardest part of the business to scale, especially if I have the goal of staying a company of one.</p>

<p>Corroborating data from <a href="https://emailmeter.com/">EmailMeter</a> and my database, it seems my changes are making a difference. Despite a growing user base, inbound support emails remain fairly steady!</p>

<p><img src="https://lunchbag.ca/uploads/screen-shot-2020-05-21-at-4-20-15-pm.png"><span>Handling support on my own should be sustainable at least for the foreseeable future!</span></p>

<h2 id="how-do-support-tickets-work-at-lunch-money">How do support tickets work at Lunch Money?</h2>

<p>A feedback button is located at the bottom right corner of every page. Clicking on it opens up a text area wherein users can submit feature requests, questions, bug …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lunchbag.ca/company-of-one/">https://lunchbag.ca/company-of-one/</a></em></p>]]>
            </description>
            <link>https://lunchbag.ca/company-of-one/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931633</guid>
            <pubDate>Thu, 29 Oct 2020 15:36:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case Against the Singularity]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24931612">thread link</a>) | @joubert
<br/>
October 29, 2020 | http://www.furidamu.org/blog/2020/05/03/the-case-against-the-singularity/ | <a href="https://web.archive.org/web/*/http://www.furidamu.org/blog/2020/05/03/the-case-against-the-singularity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article_text">
    <p>From Musk's <a href="https://twitter.com/elonmusk/status/495759307346952192">"Potentially more dangerous than nukes." tweet</a>, increased funding for the Machine Intelligence Research Institute (MIRI) to the founding of cross-industry groups like the <a href="https://www.partnershiponai.org/">Partnership on AI</a>, AI is being taken more seriously.</p>
<p>One worry that is sometimes cited, as in the book <a href="https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies">Superintelligence</a><sup><a href="http://www.furidamu.org/cache/blog_2020_05_03_the-case-against-the-singularity/en.wikipedia.org_wiki_Superintelligence/en.wikipedia.org/wiki/superintelligence:_paths,_dangers,_strategies/index.html">cache</a></sup> by Nick Bostrom, is that once we reach human-level AI, it might rapidly improve itself past anything humans can envision, becoming impossible to control. This is called "Singularity", because anything after such a point is unforseeable.</p>
<p>The argument for a Singularity rests on the fact that a hypothetical AI could devote all its resources to improving itself, use its new found abilities to improve itself even faster, and thus increase its capabilities exponentially:</p>
<p><img alt="linear return on investment" src="http://www.furidamu.org/images/2020-05-02-singularity-linear.png"></p>
<p>But how likely is such a scenario?</p>
<p>With nearly 8 years since AlexNet and more than 5 since DQN, we can examine the track record of deep learning to give us some intuition.</p>
<p>In deep reinforcement learning, Atari has long been the domain of choice for many researchers, attracting fierce competition to obtain the best score. (Reinforcement learning concerns itself with how agents should interact with their environment to maximise some measure of reward.)</p>
<p>If we plot the scores obtained in various top papers against the number of environment interactions of the agent - a rough measure of training effort - we obtain the following plot:</p>
<p><img alt="Atari score vs environment fames" src="http://www.furidamu.org/images/2020-05-02-singularity-atari.png"></p>
<p>More effort does indeed lead to better performance, but note that the x-axis is logarithmic! To obtain constant improvements in score, an agent needs to expend exponentially more effort.</p>
<p>Similar relationships hold in other domains. Let's take one I'm most familiar with, the playing strength of AlphaGo Zero, measured in Elo, over the course of 40 days of training (as reported in the AlphaGo Zero paper):</p>
<p><img alt="AlphaGo Zero elo vs training time" src="http://www.furidamu.org/images/2020-05-02-singularity-elo.png"></p>
<p>Again, increased training leads to better performance, and again note the logarithmic x-axis - except in this case, the return on training effort seems even worse.</p>
<p>Using what we learned from these domains - $\text{capability} = log(\text{effort})$ - and applying it to our original AI self-improvement graph, we end up with:</p>
<p><img alt="logarithmic return on investment" src="http://www.furidamu.org/images/2020-05-02-singularity-log.png"></p>
<p>Far from an explosion of ability, improvement seems to peter out and become slower and slower.</p>
<p>In fact, this phenomenon is not constrained to machine learning or AI - similar results seem to hold for other fields of research. In <a href="https://web.stanford.edu/~chadj/IdeaPF.pdf">Are Ideas Getting Harder to Find?</a><sup><a href="http://www.furidamu.org/cache/blog_2020_05_03_the-case-against-the-singularity/web.stanford.edu_~chadj_IdeaPF.pdf/web.stanford.edu/~chadj/ideapf.pdf">cache</a></sup> Bloom et al provide convincing evidence that while the number of researchers has been growing for decades, research productivity and output has actually been declining! </p>
<p><img alt="number of researchers and researcher productivity over time" src="http://www.furidamu.org/images/2020-05-02-singularity-productivity.png"></p>
<p>Figure 2 from <a href="https://web.stanford.edu/~chadj/IdeaPF.pdf">Are Ideas Getting Harder to Find?</a>, consistent with decreasing return on effort.</p>
<p>Not only is there no free lunch, lunch gets more expensive every day.</p>

  </div></div>]]>
            </description>
            <link>http://www.furidamu.org/blog/2020/05/03/the-case-against-the-singularity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931612</guid>
            <pubDate>Thu, 29 Oct 2020 15:34:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A State of Feast]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931596">thread link</a>) | @willempienaar
<br/>
October 29, 2020 | https://blog.feast.dev/post/a-state-of-feast | <a href="https://web.archive.org/web/*/https://blog.feast.dev/post/a-state-of-feast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><h3>Introduction</h3><p>Two years ago we first announced the launch of Feast, an open source feature store for machine learning. Feast is an operational data system that solves some of the key challenges that ML teams encounter while productionizing machine learning systems.<br>‍<br>Recognizing that ML and Feast have advanced since we launched, we take a moment today to discuss the past, present and future of Feast. We consider the more significant lessons we learned while building Feast, where we see the project heading, and why teams should consider adopting Feast as part of their operational ML stacks.</p><h3>Background</h3><p>Feast was developed to address the challenges faced while productionizing data for machine learning. In our original <a href="https://cloud.google.com/blog/products/ai-machine-learning/introducing-feast-an-open-source-feature-store-for-machine-learning">Google Cloud article</a>, we highlighted some of these challenges, namely:</p><ol role="list"><li>Features aren’t reused.</li><li>Feature definitions are inconsistent across teams.</li><li>Getting features into production is hard.</li><li>Feature values are inconsistent between training and serving.</li></ol><p>Whereas an industry to solve data transformations and data-quality problems already existed, our focus for shaping Feast was to overcome operational ML hurdles that exist between data science and ML engineering. Toward that end, our initial aim was to provide:</p><ol role="list"><li><strong>Registry</strong>: The registry is a common catalog with which to explore, develop, collaborate on, and publish new feature definitions within and across teams. It is the central interface for all interactions with the feature store.&nbsp;</li><li><strong>Ingestion: </strong>A means for continually ingesting batch and streaming data and storing consistent copies in both an offline and online store. This layer automates most data-management work and ensures that features are always available for serving.</li><li><strong>Serving: </strong>A feature-retrieval interface which provides a temporally consistent view of features for both training and online serving. Serving improves iteration speed by minimizing coupling to data infrastructure, and prevents training-serving skew through consistent data access.</li><li><strong>Monitoring: </strong>Tools that allow operational teams to monitor and act on the quality and accuracy of data consumed by models. This is achieved through the generation of statistics, metrics, logs, alerts, and data validation.<br></li></ol><p>Guided by this design, we co-developed and shipped Feast with our friends over at Google. We then open sourced the project in early 2019, and have since been running Feast in production and at scale. In our follow up blog post, <a href="https://blog.gojekengineering.com/feast-bridging-ml-models-and-data-efd06b7d1644">Bridging ML Models and Data</a>, we touched on the impact Feast has had at companies like Gojek.</p><h3>Feast today</h3><p>Teams, large and small, are increasingly searching for ways to simplify the productionization and maintenance of their ML systems at scale. Since open sourcing Feast, we’ve seen both the demand for these tools and the activity around this project soar. Working alongside our open source community, we’ve released key pieces of our stack throughout the last year, and steadily expanded Feast into a robust feature store. Highlights include:</p><ul role="list"><li>Point-in-time correct queries that prevent feature data leakage.</li><li>A query optimized table-based data model in the form of feature sets.</li><li>Storage connectors with implementations for Cassandra and Redis Cluster.</li><li>Statistics generation and data validation through TFDV integration.</li><li>Authentication and authorization support for SDKs and APIs.</li><li>Diagnostic tooling through request/response logging, audit logs, and Statsd integration.<br></li></ul><figure id="w-node-85ee3bb9c25b-dcb020c5"><a href="https://uploads-ssl.webflow.com/5f96e7a5ea43eef2c8a67238/5f972549f25eb027d6ece6ef_zVSoBgsmId8I089VKWFm1LQc9FFOsOdNBxvDIiAqD2282Fs9ruoOsngQ9P4RFvQnd5myA9jBxKM0Yz5r6jQEPAzCNChIlXdAH9Kf6s5yYTfQAKgX5JgMvS-9T_Z1swcaQTA0JoD5.png" target="_blank"><p><img src="https://uploads-ssl.webflow.com/5f96e7a5ea43eef2c8a67238/5f972549f25eb027d6ece6ef_zVSoBgsmId8I089VKWFm1LQc9FFOsOdNBxvDIiAqD2282Fs9ruoOsngQ9P4RFvQnd5myA9jBxKM0Yz5r6jQEPAzCNChIlXdAH9Kf6s5yYTfQAKgX5JgMvS-9T_Z1swcaQTA0JoD5.png" alt=""></p></a></figure><p>Feast has grown more rapidly than initially anticipated, with multiple large companies, including&nbsp;Agoda, Gojek, Farfetch, Postmates, and Zulily adopting and/or contributing to the project. We’ve also been working closely with other open source teams, and we are excited to share that Feast is now a <a href="https://www.kubeflow.org/docs/components/feature-store/">component in Kubeflow</a>. Over the coming months we will be enhancing this integration, making it easier for users to deploy Feast and Kubeflow together.</p><h3>Lessons learned</h3><p>Through frequent engagement with our community and by way of running Feast in production ourselves, we’ve learned critical lessons:<br></p><p><strong>Feast requires too much infrastructure:</strong> Requiring users provision a large system is a big ask. A minimal Feast deployment requires Kafka, Zookeeper, Postgres, Redis, and multiple Feast services.&nbsp;</p><p>‍<strong>Feast lacks composability: </strong>Requiring all infrastructural components be present in order to have a functional system removes all modularity.</p><p><strong>Ingestion is too complex: </strong>Incorporating a Kafka-based stream-first ingestion layer trivializes data consistency across stores, but the complete ingestion flow from source to sink can still mysteriously fail at multiple points.<br></p><p><strong>Our technology choices hinder generalization: </strong>Leveraging technologies like BigQuery, Apache Beam on Dataflow, and Apache Kafka has allowed us to move faster in delivering functionality. However, these technologies now impede our ability to generalize to other clouds or deployment environments.<br></p><h3>The future of Feast</h3><blockquote><em>“Always in motion is the future.” <br></em>- Yoda, The Empire Strikes Back</blockquote><p>While feature stores have already become essential systems at large technology companies, we believe their widespread adoption will begin in 2021. We also foresee the release of multiple managed feature stores over the next year, as vendors seek to enter the burgeoning operational ML market.<br></p><p>As we’ve discussed, feature stores serve both offline and production ML needs, and therefore are primarily built by engineers for engineers. What we need, however, is a feature store that's purpose-built for data-science workflows. Feast will move away from an infrastructure-centric approach toward a more localized experience that does just this: builds on teams’ existing data-science workflows.&nbsp;<br></p><p>The lessons we’ve learned during the preceding two years have crystallized a vision for what Feast should become: <strong>a light-weight modular feature store</strong>. One that’s easy to pick up, adds value to teams large and small, and can be progressively applied to production use cases that span multiple teams, projects, and cloud-environments. We aim to reach this by applying the following design principles:<br></p><p><strong>1. Python-first: </strong>First-class support for running a minimal version of Feast entirely from a notebook, with all infrastructural dependencies becoming optional enhancements.&nbsp;</p><ul role="list"><li>Encourages quick evaluation of the software and ensures Feast is user friendly&nbsp;</li><li>Minimizes the operational burden of running the system in production</li><li>Simplifies testing, developing, and maintaining Feast</li></ul><p><strong>2. Production-ready:</strong> A collection of battle-tested components built for production.&nbsp;</p><ul start="" role="list"><li>Manages high-scale operational workloads for both training and serving</li><li>Integrates with industry-standard monitoring systems for both data and services</li><li>Provides a simplified architecture that facilitates diagnostics and debugging</li></ul><p><strong>3. Composability:</strong> Modular components with clear extension, integration, and upgrade points that allow for high composability.</p><ul start="" role="list"><li>Grants teams the flexibility to adopt specific Feast components&nbsp;</li><li>Incentivizes defining clear component boundaries and data contracts</li><li>Eliminates barriers on teams intending to swap in their existing technologies</li></ul><p><strong>4. Cloud-agnostic:</strong> Removal of all hard coupling to cloud-specific services, and inclusion of portable technologies like Apache Spark for data processing and Parquet for offline storage.</p><ul start="" role="list"><li>Enables deployment into all cloud and on-premise environments</li><li>Introduces a rich set of storage and integration options through Spark I/O</li><li>Improves development velocity by allowing all infrastructure to run locally<br></li></ul><figure id="w-node-b5b591ffcad9-dcb020c5"><a href="https://uploads-ssl.webflow.com/5f96e7a5ea43eef2c8a67238/5f97254aa9c2f27c4a6393bf_-C6hAXrV6r0JnUj72l9bINmweqgwUXXw_HATEc1UMeN9SCeW_9kPDUvCtr2dpRTOMW7Un4gghBGdhR4aoJscmJEMHORcG2xu8Fh4QqLMspjN5jCbi6muBNYOId56K4tbQCsGj1hy.png" target="_blank"><p><img src="https://uploads-ssl.webflow.com/5f96e7a5ea43eef2c8a67238/5f97254aa9c2f27c4a6393bf_-C6hAXrV6r0JnUj72l9bINmweqgwUXXw_HATEc1UMeN9SCeW_9kPDUvCtr2dpRTOMW7Un4gghBGdhR4aoJscmJEMHORcG2xu8Fh4QqLMspjN5jCbi6muBNYOId56K4tbQCsGj1hy.png" alt=""></p></a><figcaption>Feast is the bridge between models and data</figcaption></figure><h3>Next Steps</h3><p>Our vision for Feast is not only ambitious, but actionable. Our next release, Feast 0.8, is the product of collaborating with both our open source community and our friends over at <a href="https://tecton.ai/">Tecton</a>.</p><ol role="list"><li><strong>Python-first: </strong>We are migrating all core logic to Python, starting with training dataset retrieval and job management, providing a more responsive development experience.</li><li><strong>Modular ingestion: </strong>We are shifting to managing batch and streaming ingestion separately, leading to more actionable metrics, logs, and statistics and an easier to understand and operate system.</li><li><strong>Support for AWS: </strong>We are replacing GCP-specific technologies like Beam on Dataflow with Spark and adding native support for running Feast on AWS, our first steps toward cloud-agnosticism.&nbsp;&nbsp;</li><li><strong>Data-source integrations: </strong>We are introducing support for a host of new data sources (Kinesis, Kafka, S3, GCS, BigQuery) and data formats (Parquet, JSON, Avro), ensuring teams can seamlessly integrate Feast into their existing data-infrastructure.</li></ol><h3>Get involved</h3><p>We’ve been inspired by the soaring community interest in and contributions to Feast. If you’re curious to learn more about our mission to build a best-in-class feature store, or&nbsp;are looking to build your own: Check out our resources, say hello, and get involved!<br></p><ul role="list"><li>Project website: <a href="https://feast.dev/">feast.dev</a></li><li>Come and say hello to us in <a href="https://join.slack.com/t/kubeflow/shared_invite/zt-cpr020z4-PfcAue_2nw67~iIDy7maAQ">#Feast</a></li><li>Our documentation: <a href="https://docs.feast.dev/">docs.feast.dev</a></li><li>GitHub repository: <a href="https://github.com/feast-dev/feast">feast-dev/feast</a>‍</li></ul><p>‍</p></div></div></div></div>]]>
            </description>
            <link>https://blog.feast.dev/post/a-state-of-feast</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931596</guid>
            <pubDate>Thu, 29 Oct 2020 15:33:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp to x86-64: Labelled procedure calls]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24931577">thread link</a>) | @tekknolagi
<br/>
October 29, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-11/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-11/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><span data-nosnippet="">
<em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> – <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-10/">previous</a></em>
</span></p>

<p>Welcome back to the Compiling a Lisp series. Last time, we learned about Intel
instruction encoding. This time, we’re going to use that knowledge to compile
procedure calls.</p>

<p>The usual function expression in Lisp is a <code>lambda</code> — an anonymous function
that can take arguments and close over variables. Procedure calls are <em>not</em>
this. They are simpler constructs that just take arguments and return values.</p>

<p>We’re adding procedure calls first as a stepping stone to full closure support.
This will help us get some kind of internal calling convention established and
stack manipulation figured out before things get too complicated.</p>

<p>After this post, we will be able to support programs like the following:</p>

<div><div><pre><code><span>(</span><span>labels</span> <span>((</span><span>add</span> <span>(</span><span>code</span> <span>(</span><span>x</span> <span>y</span><span>)</span> <span>(</span><span>+</span> <span>x</span> <span>y</span><span>)))</span>
         <span>(</span><span>sub</span> <span>(</span><span>code</span> <span>(</span><span>x</span> <span>y</span><span>)</span> <span>(</span><span>-</span> <span>x</span> <span>y</span><span>))))</span>
    <span>(</span><span>labelcall</span> <span>sub</span> <span>4</span> <span>(</span><span>labelcall</span> <span>add</span> <span>1</span> <span>2</span><span>)))</span>
<span>; =&gt; 1</span>
</code></pre></div></div>

<p>and even this snazzy factorial function:</p>

<div><div><pre><code><span>(</span><span>labels</span> <span>((</span><span>factorial</span> <span>(</span><span>code</span> <span>(</span><span>x</span><span>)</span> 
            <span>(</span><span>if</span> <span>(</span><span>&lt;</span> <span>x</span> <span>2</span><span>)</span> <span>1</span> <span>(</span><span>*</span> <span>x</span> <span>(</span><span>labelcall</span> <span>factorial</span> <span>(</span><span>-</span> <span>x</span> <span>1</span><span>)))))))</span>
    <span>(</span><span>labelcall</span> <span>factorial</span> <span>5</span><span>))</span>
<span>; =&gt; 120</span>
</code></pre></div></div>

<p>These are fairly pedestrian snippets of code but they demonstrate some new
features we are adding, like:</p>

<ul>
  <li>A new <code>labels</code> form that all programs will now have to look like</li>
  <li>A new <code>code</code> form for describing procedures and their parameters</li>
  <li>A new <code>labelcall</code> expression for calling procedures</li>
</ul>

<p>Ghuloum does not explain why he does this, but I imagine that the <code>labels</code> form
was chosen over allowing multiple separate top-level bindings because it is
easier to parse and traverse.</p>

<h3 id="big-ideas">Big ideas</h3>

<p>In order to compile a program, we are going to traverse every binding in the
<code>labels</code>. For each binding, we will generate code for each <code>code</code> object.</p>

<p>Compiling <code>code</code> objects requires making an environment for their parameters.
We’ll establish a calling convention later so that our compiler knows where to
find the parameters.</p>

<p>Then, once we’ve emitted all the code for the bindings, we will compile the
body. The body may, but is not required to, contain a <code>labelcall</code> expression.</p>

<p>In order to compile a <code>labelcall</code> expression, we will compile all of the
arguments provided, save them in consecutive locations on the stack, and then
emit a <code>call</code> instruction.</p>

<p>When all of these pieces come together, the resulting machine code will look
something like this:</p>

<div><div><pre><code>mov rsi, rdi  # prologue
label0:
  label0_code
label1:
  label1_code
main:
  main_code
</code></pre></div></div>

<p>You can see that all of the <code>code</code> objects will be compiled in sequence,
followed by the body of the <code>labels</code> form.</p>

<s>
Because I have not yet figured out how to start executing at somewhere other
than the beginning of the generated code, and because I don't store generated
code in any intermediate buffers, and because we don't know the sizes of any
code in advance, I do this funky thing where I emit a `jmp` to the body code.

If you, dear reader, have a better solution, please let me know.
</s>

<p><strong>Edit:</strong> <em>jsmith45</em> gave me the encouragement I needed to work on this again.
It turns out that storing the code offset of the beginning of the <code>main_code</code>
(the <code>labels</code> body) adding that to the <code>buf-&gt;address</code> works just fine. I’ll
explain more below.</p>

<h3 id="a-calling-convention">A calling convention</h3>

<p>We’re not going to use the System V AMD64 ABI. That calling convention requires
that parameters are passed first in certain registers, and then on the stack.
Instead, we will pass all parameters on the stack.</p>

<p>This makes our code simpler, but it also means that at some point later on, we
will have to add a different kind of calling convention so that we can call
foreign functions (like <code>printf</code>, or <code>exit</code>, or something). Those functions
expect their parameters in registers. We’ll worry about that later.</p>

<p>If we borrow and adapt the excellent diagrams from the Ghuloum tutorial, this
means that right before we make a procedure call, our stack will look like
this:</p>

<blockquote>
  <p>Stack illustration courtesy of <a href="https://leonardschuetz.ch/">Leonard</a>.</p>
</blockquote>

<p>You can see the first return point at <code>[rsp]</code>. This is the return point placed
by the caller of the <em>current</em> function.</p>

<p>Above that are whatever local variables we have declared with <code>let</code> or perhaps
are intermediate values from some computation.</p>

<p>Above that is a blank space reserved for the second return point. This is the
return point for the <em>about-to-be-called</em> function. The <code>call</code> instruction will
fill in after evaluating all the arguments.</p>

<p>Above the return point are all the outgoing arguments. They will appear as
locals for the procedure being called.</p>

<p>Finally, above the arguments, is untouched free stack space.</p>

<p>The <code>call</code> instruction decrements <code>rsp</code> and then writes to <code>[rsp]</code>. This means
that if we just emitted a <code>call</code>, the first local would be overwritten. No
good. Worse, the way the stack would be laid out would mean that the locals
would look like arguments.</p>

<p>In order to solve this problem, we need to first adjust <code>rsp</code> to point to the
last local. That way the decrement will move it below the local and the return
address will go between the locals and the arguments.</p>

<p>After the <code>call</code> instruction, the stack will look different. Nothing will have
actually changed, except for <code>rsp</code>. This change to <code>rsp</code> means that the callee
has a different view:</p>

<blockquote>
  <p>Stack illustration courtesy of <a href="https://leonardschuetz.ch/">Leonard</a>.</p>
</blockquote>

<p>The empty colored in spaces below the return point indicate that the values on
the stack are “hidden” from view, since they are above (higher addresses than)
<code>[rsp]</code>. The called function will <em>not</em> be able to access those values.</p>

<p>If the called function wants to use one of its arguments, it can pull it off
the stack from its designated location.</p>

<blockquote>
  <p>One unfortunate consequence of this calling convention is that Valgrind does
not understand it. Valgrind cannot understand that the caller has placed data
on the stack specifically for the callee to read it, and thinks this is a
move/jump of an uninitialized value. This means that we get some errors now
on these labelcall tests.</p>
</blockquote>

<p>Eventually, when the function returns, the <code>ret</code> instruction will pop the
return point off the stack and jump to it. This will bring us back to the
previous call frame.</p>

<p>That’s that! I have yet to find a good tool that will let me visualize the
stack as a program is executing. GDB probably has a mode hidden away somewhere
undocumented that does exactly this. Cutter sort of does, but it’s finicky in
ways I don’t really understand. Maybe one day <a href="http://akkartik.name/">Kartik</a>’s
x86-64 Mu fork will be able to do this.</p>

<h3 id="building-procedure-calls-in-small-pieces">Building procedure calls in small pieces</h3>

<p>In order for this set of changes to make sense, I am going to explain all of
the pieces one at a time, top-down.</p>

<p>First, we’ll look at the new-and-improved <code>Compile_entry</code>, which has been
updated to handle the <code>labels</code> form. This will do the usual Lisp entrypoint
setup and some checks about the structure of the AST.</p>

<p>Then, we’ll actually look at compiling the <code>labels</code>. This means going through
the bindings one-by-one and compiling their <code>code</code> objects.</p>

<p>Then, we’ll look at what it means to compile a <code>code</code> object. Hint: it’s very
much like <code>let</code>.</p>

<p>Last, we’ll tie it all together when compiling the body of the <code>labels</code> form.</p>

<h3 id="compiling-the-entrypoint">Compiling the entrypoint</h3>

<p>Most of this code is checking. What used to just compile an expression now
validates that what we’ve passed in at least vaguely looks like a well-formed
<code>labels</code> form before picking it into its component parts: the <code>bindings</code> and
the <code>body</code>.</p>

<div><div><pre><code><span>int</span> <span>Compile_entry</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>node</span><span>)</span> <span>{</span>
  <span>assert</span><span>(</span><span>AST_is_pair</span><span>(</span><span>node</span><span>)</span> <span>&amp;&amp;</span> <span>"program must have labels"</span><span>);</span>
  <span>// Assume it's (labels ...)</span>
  <span>ASTNode</span> <span>*</span><span>labels_sym</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>node</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_is_symbol</span><span>(</span><span>labels_sym</span><span>)</span> <span>&amp;&amp;</span> <span>"program must have labels"</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_symbol_matches</span><span>(</span><span>labels_sym</span><span>,</span> <span>"labels"</span><span>)</span> <span>&amp;&amp;</span>
         <span>"program must have labels"</span><span>);</span>
  <span>ASTNode</span> <span>*</span><span>args</span> <span>=</span> <span>AST_pair_cdr</span><span>(</span><span>node</span><span>);</span>
  <span>ASTNode</span> <span>*</span><span>bindings</span> <span>=</span> <span>operand1</span><span>(</span><span>args</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_is_pair</span><span>(</span><span>bindings</span><span>)</span> <span>||</span> <span>AST_is_nil</span><span>(</span><span>bindings</span><span>));</span>
  <span>ASTNode</span> <span>*</span><span>body</span> <span>=</span> <span>operand2</span><span>(</span><span>args</span><span>);</span>
  <span>return</span> <span>Compile_labels</span><span>(</span><span>buf</span><span>,</span> <span>bindings</span><span>,</span> <span>body</span><span>,</span> <span>/*labels=*/</span><span>NULL</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p><code>Compile_entry</code> dispatches to <code>Compile_labels</code> for iterating over all of the
labels. <code>Compile_labels</code> is a recursive function that keeps track of all the
labels so far in its arguments, so we start it off with an empty <code>labels</code>
environment.</p>

<h3 id="compiling-labels">Compiling labels</h3>

<p>In <code>Compile_labels</code>, we have first a base case: if there are no labels we
should just emit the body.</p>

<div><div><pre><code><span>int</span> <span>Compile_labels</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>bindings</span><span>,</span> <span>ASTNode</span> <span>*</span><span>body</span><span>,</span>
                   <span>Env</span> <span>*</span><span>labels</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_nil</span><span>(</span><span>bindings</span><span>))</span> <span>{</span>
    <span>buf</span><span>-&gt;</span><span>entrypoint</span> <span>=</span> <span>Buffer_len</span><span>(</span><span>buf</span><span>);</span>
    <span>// Base case: no bindings. Compile the body</span>
    <span>Buffer_write_arr</span><span>(</span><span>buf</span><span>,</span> <span>kEntryPrologue</span><span>,</span> <span>sizeof</span> <span>kEntryPrologue</span><span>);</span>
    <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>body</span><span>,</span> <span>/*stack_index=*/</span><span>-</span><span>kWordSize</span><span>,</span> <span>/*varenv=*/</span><span>NULL</span><span>,</span>
                   <span>labels</span><span>));</span>
    <span>Buffer_write_arr</span><span>(</span><span>buf</span><span>,</span> <span>kFunctionEpilogue</span><span>,</span> <span>sizeof</span> <span>kFunctionEpilogue</span><span>);</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div></div>

<p>We also set the buffer entrypoint location to the position where we’re going to
emit the body of the <code>labels</code>. We’ll use this later when executing, or later in
the series when we emit ELF binaries. You’ll have to add a field <code>word
entrypoint</code> to your <code>Buffer</code> struct.</p>

<p>We pass in an empty <code>varenv</code>, since we are not accumulating any locals along
the way; only labels. For the same reason, we give a <code>stack_index</code> of
<code>-kWordSize</code> — the first slot.</p>

<p>If we <em>do</em> have labels, on the other hand, we should deal with the first label.
This means:</p>

<ul>
  <li>pulling out the name and the code object</li>
  <li>binding the name to the <code>code</code> location (the current location)</li>
  <li>compiling the <code>code</code></li>
</ul>

<p>And then from there we deal with the others recursively.</p>

<div><div><pre><code><span>int</span> <span>Compile_labels</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>bindings</span><span>,</span> <span>ASTNode</span> <span>*</span><span>body</span><span>,</span>
                   <span>Env</span> <span>*</span><span>labels</span><span>)</span> <span>{</span>
  <span>// ....</span>
  <span>assert</span><span>(</span><span>AST_is_pair</span><span>(</span><span>bindings</span><span>));</span>
  <span>// Get the next binding</span>
  <span>ASTNode</span> <span>*</span><span>binding</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>bindings</span><span>);</span>
  <span>ASTNode</span> <span>*</span><span>name</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>binding</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_is_symbol</span><span>(</span><span>name</span><span>));</span>
  <span>ASTNode</span> <span>*</span><span>binding_code</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>AST_pair_cdr</span><span>(</span><span>binding</span><span>));</span>
  <span>word</span> <span>function_location</span> <span>=</span> <span>Buffer_len</span><span>(</span><span>buf</span><span>);</span>
  <span>// Bind the name to the location in the instruction stream</span>
  <span>Env</span> <span>entry</span> <span>=</span> <span>Env_bind</span><span>(</span><span>AST_symbol_cstr</span><span>(</span><span>name</span><span>),</span> <span>function_location</span><span>,</span> <span>labels</span><span>);</span>
  <span>// Compile the binding function</span>
  <span>_</span><span>(</span><span>Compile_code</span><span>(</span><span>buf</span><span>,</span> <span>binding_code</span><span>,</span> <span>&amp;</span><span>entry</span><span>));</span>
  <span>return</span> <span>Compile_labels</span><span>(</span><span>buf</span><span>,</span> <span>AST_pair_cdr</span><span>(</span><span>binding…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-11/">https://bernsteinbear.com/blog/compiling-a-lisp-11/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-11/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931577</guid>
            <pubDate>Thu, 29 Oct 2020 15:31:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Std: Visit is everything wrong with modern C++]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931552">thread link</a>) | @mmm_grayons
<br/>
October 29, 2020 | https://bitbashing.io/std-visit.html | <a href="https://web.archive.org/web/*/https://bitbashing.io/std-visit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <!--
Sorry once again for the infrequent posts.
I've been busy.
Originally, because I was supposed to get married this summer.
Then because my fiancée cheated on me while I was watching my grandfather die
and moved in with the other guy the following week.
So that's been fun, but I'm trying to get back into some more productive habits.
Hopefully that includes blogging regularly.
-->

<h2 id="sum-types-and-you">Sum Types and You</h2>

<p>Let’s talk about a simple, yet powerful concept in programming: <em>sum types</em>.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>A sum type, also called a <em>discriminated union</em>,
can hold one (and only one) of several types of things.
For example, consider some settings in an
<a href="https://en.wikipedia.org/wiki/INI_file">INI</a>-like configuration file.
Let’s say that each setting must be a string, an integer, or a Boolean value.
If we wanted to roll our own solution in C++, we might write something resembling:</p>

<div><pre><code><span>struct</span> <span>Setting</span> <span>{</span>
    <span>union</span> <span>{</span>
        <span>string</span> <span>str</span><span>;</span>
        <span>int</span> <span>num</span><span>;</span>
        <span>bool</span> <span>b</span><span>;</span>
    <span>};</span>
    <span>enum</span> <span>Type</span> <span>{</span> <span>Str</span><span>,</span> <span>Int</span><span>,</span> <span>Bool</span> <span>};</span>
    <span>Type</span> <span>tag</span><span>;</span>
<span>};</span>

<span>// Map settings to their names.
</span><span>using</span> <span>Settings</span> <span>=</span> <span>unordered_map</span><span>&lt;</span><span>string</span><span>,</span> <span>Setting</span><span>&gt;</span><span>;</span>
</code></pre>
</div>

<p>Here be dragons, though, since we must always remember to:</p>

<ul>
  <li>
    <p>Update <code>tag</code> whenever assigning a new value.</p>
  </li>
  <li>
    <p>Only retrieve the correct type from the union (according to <code>tag</code>).</p>
  </li>
  <li>
    <p>Call constructors and destructors at appropriate times for all non-trivial types.
(<code>string</code> is the only one here, but you could imagine similar
scenarios with others.)</p>
  </li>
</ul>

<p>If a step is ever forgotten, the object falls into an
inconsistent state and there shall be wailing and gnashing of teeth.
You could encapsulate all this trickery and interact with the type
through a series of methods—e.g., <code>getType()</code>, <code>asBool()</code>,
<code>asString()</code>, and so on—but this is quite verbose.
It also just shifts the problem onto whoever implements these methods; they
still need to carefully maintain the invariants with no help from the language.</p>

<p>It would be much nicer if a general-purpose sum type was provided by the standard
library.
In C++17, we finally get one!
It’s called <a href="http://en.cppreference.com/w/cpp/utility/variant"><code>std::variant</code></a>.
Let’s take a look.</p>

<h2 id="using-stdvariant">Using <code>std::variant</code></h2>

<p><code>variant</code> is a class template that takes, as template parameters, the types
it could hold.
For the example above,
we could define a setting as a <code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span></code>.
Assigning a value to a <code>variant</code> works just like you might expect:</p>
<div><pre><code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span> <span>mySetting</span> <span>=</span> <span>string</span><span>(</span><span>"Hello!"</span><span>);</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>42</span><span>;</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>false</span><span>;</span>
</code></pre>
</div>

<p>Once we put a value into a <code>variant</code>, we’ll eventually want to look at what that
value is, and just as importantly, what the type of the value is.
This is where the fun begins.
Some languages offer dedicated <em>pattern matching</em> syntax for the task,
such as:</p>
<div><pre><code><span>match</span> <span>(</span><span>theSetting</span><span>)</span> <span>{</span>
    <span>Setting</span><span>::</span><span>Str</span><span>(</span><span>s</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A string: {}"</span><span>,</span> <span>s</span><span>),</span>
    <span>Setting</span><span>::</span><span>Int</span><span>(</span><span>n</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"An integer: {}"</span><span>,</span> <span>n</span><span>),</span>
    <span>Setting</span><span>::</span><span>Bool</span><span>(</span><span>b</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A boolean: {}"</span><span>,</span> <span>b</span><span>),</span>
<span>};</span>
</code></pre>
</div>
<p>but this didn’t make the cut for C++17.<sup id="fnref:2"><a href="#fn:2">2</a></sup>
Instead we’re given a companion function called <code>std::visit</code>.
It takes the <code>variant</code> you want to examine, along with
some <em>visitor</em> that is callable for each type in the variant.</p>

<p>How do we define such a visitor?
One way is to create an object that overloads the call operator
for relevant types:</p>
<div><pre><code><span>struct</span> <span>SettingVisitor</span> <span>{</span>
    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>int</span> <span>n</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"An integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>n</span><span>);</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A boolean: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
    <span>}</span>
<span>};</span>
</code></pre>
</div>

<p>This seems terribly verbose, and it gets even worse
if we want our visitor to capture or modify some other state.
Hmm—<a href="https://stackoverflow.com/a/7627218">lambdas</a> are perfect
for capturing state.
What if we could build a visitor from those?</p>
<div><pre><code><span>make_visitor</span><span>(</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>int</span> <span>d</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>d</span><span>);</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>)</span>
</code></pre>
</div>
<p>That’s a bit better, but the standard library doesn’t provide any sort of
<code>make_visitor</code> to combine the lambdas into a callable object for us.
We’ll need to define it ourselves.</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>;</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>,</span> <span>class</span><span>...</span> <span>Frest</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>,</span> <span>Frest</span><span>...</span><span>&gt;</span> <span>:</span> <span>F0</span><span>,</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>,</span> <span>Frest</span><span>...</span> <span>rest</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>),</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span><span>(</span><span>rest</span><span>...)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
    <span>using</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>&gt;</span> <span>:</span> <span>F0</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>auto</span> <span>make_visitor</span><span>(</span><span>Fs</span><span>...</span> <span>fs</span><span>)</span>
<span>{</span>
    <span>return</span> <span>overload</span><span>&lt;</span><span>Fs</span><span>...</span><span>&gt;</span><span>(</span><span>fs</span><span>...);</span>
<span>}</span>
</code></pre>
</div>

<p>Here we use C++11’s <a href="http://en.cppreference.com/w/cpp/language/parameter_pack">variadic templates</a>.
They must be defined recursively, so we create some base case <code>F0</code>,
then use that to define a cascading set of constructors for <code>overload</code>,
each of which peels off a lambda argument and adds it to the type
as a call operator.</p>

<p>If this seems troublesome, fear not! C++17 will offer a new syntax
that reduces all of the above to:</p>
<div><pre><code><span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>struct</span> <span>overloaded</span> <span>:</span> <span>Ts</span><span>...</span> <span>{</span> <span>using</span> <span>Ts</span><span>::</span><span>operator</span><span>()...;</span> <span>};</span>
<span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>overloaded</span><span>(</span><span>Ts</span><span>...)</span> <span>-&gt;</span> <span>overloaded</span><span>&lt;</span><span>Ts</span><span>...</span><span>&gt;</span><span>;</span>
</code></pre>
</div>
<p>Easy, right? But if don’t like any of these options, you could
use C++17’s compile-time conditionals instead:</p>
<div><pre><code><span>[](</span><span>auto</span><span>&amp;</span> <span>arg</span><span>)</span> <span>{</span>
    <span>using</span> <span>T</span> <span>=</span> <span>std</span><span>::</span><span>decay_t</span><span>&lt;</span><span>decltype</span><span>(</span><span>arg</span><span>)</span><span>&gt;</span><span>;</span>

    <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>string</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>int</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>bool</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>}</span>
</code></pre>
</div>

<p>Much better, no?</p>

<h2 id="no">No.</h2>

<p>The rigmarole needed for <code>std::visit</code> is entirely insane.
We started with a simple goal: look at the contents of a sum type.
To accomplish this meager mission, we had to:</p>

<ol>
  <li>
    <p>Define a function object, which requires a lot of
boilerplate, <em>or</em></p>
  </li>
  <li>Define our behavior with lambdas, which required:
    <ul>
      <li>An understanding of variadic templates, in all their recursively-defined fun, <em>or</em></li>
      <li>A familiarity with variadic <code>using</code> declarations, fresh on the scene from C++17.</li>
    </ul>

    <p><em>or</em></p>
  </li>
  <li>Use compile-time conditionals, which require you to know
about—and grok—the new <code><span>constexpr</span> <span>if</span></code> syntax, along with
<code>type_traits</code> fun like
<code>std::decay</code>.</li>
</ol>

<p>None of these concepts are too enigmatic if you’re an experienced C++ developer,
but several are certainly “advanced” features of the language.
Things have really gone sideways if we need to know so much
to do something so simple.</p>

<h2 id="how-did-we-get-here">How did we get here?</h2>

<p>My goal isn’t to disparage the folks on the ISO C++ committee
who picked this approach.
I’ve had beers with some of them,
and they’re smart, kind, hardworking people.
I’m sure that I’m missing important context since I’ve never sat in on a
standards meeting or read all of the relevant
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/">committee papers</a>.
But from an outsider’s perspective, the disparity in complexity between the
problem being solved (“What’s in here?”)
and the solutions is just nuts.
How do you teach this without overwhelming a beginner with all this other…
stuff?
Is it expected to be common knowledge for your everyday programmer?
(And if the goal of adding <code>variant</code> to the standard library <em>isn’t</em> to
make it a tool for the masses, shouldn’t it be?)
The very least C++17 could do—if the committee didn’t have the time or resources
to get pattern matching into the language—is provide something akin to <code>make_visitor</code>.
But that too is left as an exercise for the user.</p>

<p>If I had to guess how we ended up this way,
I’d assume it comes down to confirmation bias.
Maybe when a bunch of really smart people who know how
<a href="http://en.cppreference.com/w/cpp/language/sfinae">SFINAE</a> works offhand
and don’t flinch when they see the likes of</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>F</span><span>&gt;</span>
<span>typename</span> <span>std</span><span>::</span><span>enable_if</span><span>&lt;!</span><span>std</span><span>::</span><span>is_reference</span><span>&lt;</span><span>F</span><span>&gt;::</span><span>value</span><span>,</span> <span>int</span><span>&gt;::</span><span>type</span>
<span>foo</span><span>(</span><span>F</span> <span>f</span><span>)</span>
<span>{</span>
    <span>// ...
</span><span>}</span>
</code></pre>
</div>

<p>get together, the result is something like <code>std::visit</code>.
Nobody proclaims that the emperor has no clothes, or that it’s completely
bonkers to expect the average user to build an overloaded callable
object with recursive templates just to see if the thing they’re looking at
holds an <code><span>int</span></code> or a <code><span>string</span></code>.</p>

<p>I’m also not here to claim that C++ is too complicated for its own good,
but it’s certainly more complicated than it has to be.
Scott Meyers, the guy who wrote <em>Effective&nbsp;C++</em> and <em>Effective Modern&nbsp;C++</em>,
has made similar noises in <a href="http://www.ustream.tv/recorded/47947981">recent</a>
<a href="https://youtu.be/RT46MpK39rQ?t=29m51s">talks</a>.
To paraphrase Meyers, I’m sure each member of the committee cares very much
about avoiding needless complexity and making the language easier to use.
But if you look at the results of their work, it’s hard to tell.
The accidental complexity just keeps stacking up.</p>

<h2 id="where-are-we-headed">Where are we headed?</h2>

<p>There’s a reason C++ is so widely used, especially in systems programming.<sup id="fnref:3"><a href="#fn:3">3</a></sup>
It can be incredibly expressive, yet gives you nearly full control of your hardware.
The tooling around it is some of the most mature of any programming language
out there, bar C.
It supports a ridiculous number of platforms.</p>

<p>But even if you set aside all the historical baggage, it has some serious shortcomings.
Spend any amount of time messing with D and you’ll quickly realize that
metaprogramming needn’t require self-flagellation and insane syntax.
Play with Rust and <!-- Hi, PCJ --> you’ll feel like <code>unique_ptr</code>
and <code>shared_ptr</code>—which themselves have been a breath of fresh air—are
a bad joke.
The fact that we still handle dependencies in 2017
by literally copy-pasting files into each other with <code><span>#include</span></code>
macros is <em>obscene</em>.</p>

<p>You get the impression, based on what ends up in the ISO standards and what
you hear in conference talks,
that those driving C++ are trying to eliminate some of these shortcomings by
glomming nice bits from other languages onto it.
That’s a great idea on its face,
but these features often seem to arrive half-baked.
While C++ isn’t going away any time soon,
it feels like the language is constantly playing a clumsy game of catchup.</p>

<hr>

<p>In spite of all of this,
I’ll be busy encouraging my coworkers to use <code>variant</code> if anybody needs me.
Sum types are such a useful concept that they’re worth the pain,
and <a href="https://www.youtube.com/watch?v=wvtFGa6XJDU">to quote Jon Kalb</a>,
“If you can’t program in a language with ugly warts, maybe C++ isn’t the language
you should be programming in.”</p>

<hr>



  </article></div>]]>
            </description>
            <link>https://bitbashing.io/std-visit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931552</guid>
            <pubDate>Thu, 29 Oct 2020 15:28:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tesla raises the price of Full Self-Driving to $10k]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931529">thread link</a>) | @iqtidar
<br/>
October 29, 2020 | https://www.teslaoracle.com/2020/10/29/tesla-raises-the-price-of-full-self-driving-to-10k/ | <a href="https://web.archive.org/web/*/https://www.teslaoracle.com/2020/10/29/tesla-raises-the-price-of-full-self-driving-to-10k/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5893">

	
<!-- .entry-header -->

	<figure>

		<!-- .featured-media-inner -->

	</figure><!-- .featured-media -->

	
	<div>

		<div>

			
<figure>
<amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="4076643206" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
  
</amp-ad>
</figure>



<p>Tesla (TSLA) has finally increased the price of its optional Autopilot Full Self-Driving (FSD) software package to $10,000 as <a href="https://www.teslaoracle.com/2020/10/22/tesla-fsd-price-will-go-up-by-2000-starting-next-week-says-elon-musk/">hinted by Elon Musk last week</a>. </p>



<p>The price hike is the result of a successful limited release of the FSD Beta software to selected Tesla Early Access Program members and other drivers considered as “safe &amp; cautious” by the automaker. </p>



<p>Several of these select beta testers of the Tesla FSD early release version are also social media influencers with thousands of followers. This is helping Tesla create the much-needed hype and marketing as these Tesla owners are sharing <a href="https://www.teslaoracle.com/2020/10/22/watch-these-short-video-clips-of-tesla-fsd-beta-and-be-amazed/">short video clips</a> and extensive testing videos of FSD Beta.</p>



<p>Tesla CEO Elon Musk has continuously warned throughout the years that as Tesla FSD matures and new features are released, the package will get more expensive with the time. The amount of R&amp;D and testing budget that Tesla has invested in exploring Full Self-Driving capabilities in the past few years is now coming to fruition.</p>



<p>A poll on Twitter asked the Tesla community what would be the next price milestone for the FSD package? Options were $11k, $12.5k, $15k, or $20k+ — most people thought it would be $12,500 and it will come as soon as 3-6 months.</p>



<figure><div>
<amp-twitter width="600" height="480" layout="responsive" data-tweetid="1321718880159424517" data-width="550" data-dnt="true" i-amphtml-layout="responsive"><i-amphtml-sizer></i-amphtml-sizer><blockquote data-width="550" data-dnt="true" placeholder=""><p lang="en" dir="ltr">…And when do you expect we’ll see the next price hike?</p>— The Kilowatts <amp-img src="https://s.w.org/images/core/emoji/12.0.0-1/72x72/1f697.png" alt="🚗" width="72" height="72" noloading="" layout="intrinsic" data-amp-original-style="height: 1em; max-height: 1em;" i-amphtml-layout="intrinsic"><img src="https://s.w.org/images/core/emoji/12.0.0-1/72x72/1f697.png" alt="🚗" width="72" height="72" data-amp-original-style="height: 1em; max-height: 1em;" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzcyJyB3aWR0aD0nNzInIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><amp-img src="https://s.w.org/images/core/emoji/12.0.0-1/72x72/26a1.png" alt="⚡" width="72" height="72" noloading="" layout="intrinsic" data-amp-original-style="height: 1em; max-height: 1em;" i-amphtml-layout="intrinsic"><img src="https://s.w.org/images/core/emoji/12.0.0-1/72x72/26a1.png" alt="⚡" width="72" height="72" data-amp-original-style="height: 1em; max-height: 1em;" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzcyJyB3aWR0aD0nNzInIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img> (@klwtts) <a href="https://twitter.com/klwtts/status/1321718880159424517?ref_src=twsrc%5Etfw">October 29, 2020</a></blockquote></amp-twitter>
</div></figure>



<div><figure><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/06/Tesla-Model-Y-Accessories_small.jpg" alt="" width="508" height="360" layout="intrinsic" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/06/Tesla-Model-Y-Accessories_small.jpg" alt="" width="508" height="360" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzM2MCcgd2lkdGg9JzUwOCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img><figcaption>– Sponsored –</figcaption></figure></div>



<p>In my opinion, the next FSD package price will be around $12k and it will come within the next 1 year or so — this thought comes as a result of my years of studying and writing about Tesla and interaction with the community.</p>



<p>And as soon as Elon Musk’s dream of a Robotaxi fleet materializes, the price of Full Self-Driving will increase exponentially, might even cross the $20k barrier because of its commercial value. </p>



<p>For potential customers not willing to spend $10,000 on <a href="https://www.teslaoracle.com/tag/full-self-driving/">Tesla Autopilot FSD</a>, the basic safety with AEB and Lane Assist is always there, this price hike should not hinder Tesla’s mission of sustainable transportation globally.</p>



<p>Source: Tesla <a href="https://www.tesla.com/model3/design#autopilot">online car configurator</a>.</p>



<p>Stay tuned for more and more Tesla news, videos, and updates, follow us on:<br><a rel="noreferrer noopener" href="https://news.google.com/publications/CAAqBwgKMOarmgswgLayAw" target="_blank">Google News</a>&nbsp;|&nbsp;<a rel="noreferrer noopener nofollow" href="https://flipboard.com/@TeslaOracle" target="_blank">Flipboard</a>&nbsp;|&nbsp;<a rel="noreferrer noopener nofollow" href="https://feedly.com/i/subscription/feed%2Fhttps%3A%2F%2Fwww.teslaoracle.com%2Ffeed%2F" target="_blank">RSS (Feedly)</a>.</p>



<figure>
<amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="7514654329" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
  
</amp-ad>
</figure>



<h4>Related Articles:</h4>



		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<div>
		
		<!-- .post-meta-wrapper -->

		<div>
	<!-- .author-name -->
	<div>
		<p>Iqtidar has been writing about Tesla, Elon Musk, and EVs for more than 3 years on XAutoWorld.com, many of his articles have been republished on CleanTechnica and InsideEVs, maintains a healthy relationship with the Tesla community across the Social Media sphere.</p>
		<p><a href="https://www.teslaoracle.com/author/iqtidarali/" rel="author">
			View Archive 		</a>
	</p></div><!-- .author-description -->
</div><!-- .author-bio -->

	</div><!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article></div>]]>
            </description>
            <link>https://www.teslaoracle.com/2020/10/29/tesla-raises-the-price-of-full-self-driving-to-10k/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931529</guid>
            <pubDate>Thu, 29 Oct 2020 15:26:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-driving Roborace car drives directly into a wall]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931486">thread link</a>) | @taytus
<br/>
October 29, 2020 | https://clips.twitch.tv/ColdbloodedCredulousTriangleArsonNoSexy | <a href="https://web.archive.org/web/*/https://clips.twitch.tv/ColdbloodedCredulousTriangleArsonNoSexy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://clips.twitch.tv/ColdbloodedCredulousTriangleArsonNoSexy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931486</guid>
            <pubDate>Thu, 29 Oct 2020 15:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security Tenets for Mobile Applications]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931469">thread link</a>) | @mekinpesen
<br/>
October 29, 2020 | https://www.mekinpesen.com/mobile-security/security-tenets-for-mobile-applications/ | <a href="https://web.archive.org/web/*/https://www.mekinpesen.com/mobile-security/security-tenets-for-mobile-applications/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="genesis-content"><article aria-label="Security Tenets for Mobile Applications" itemref="breakthrough-page-title" itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text">
<p>There is hardly a day without a security or privacy issue affecting mobile applications. A considerable amount of mobile apps, including popular ones, lack certain security and privacy requirements. When you survey current best-practices or secure frameworks, you will see a whole bunch of conditions and to-do. But there should be minimum requirements for hardening and securing any mobile applications from scratch.</p>



<p>I will try to present the essence of security commandments for mobile applications, especially for enterprise-level apps, without addressing a specific mobile operating system. Here is the most important security requirements or standards for securing/hardening mobile applications:</p>



<ol><li>All communication and functions of a mobile application should be carried out over TLS/SSL or HTTPS channel.</li><li>The authentication mechanism of an enterprise mobile applications must rely on its directory services (Active Directory or so on) and/or SSO (Single Sign-On) feature.</li><li>According to the importance of the mobile application, <strong>a two-factor authentication (2FA) mechanism</strong> should be forced in the application.</li><li>In an enterprise, all inhouse mobile applications should be distributed and used with a mobile device management (MDM) system. And inhouse applications should never be published on public app stores.</li><li>The backend of a mobile application should be designed to operate in <strong>a three-tiered structure</strong> as a web/mobile server, an application server and a database.</li><li>There should be <strong>a strong session handling/management</strong>. Mobile apps should have a session timeout, a manual session termination (logout) and a remote logout mechanism. Also, for each user session, independently and uniquely generated tokens or security key parameters should be used.</li><li>Apps should support <strong>remote wipe</strong> from a stolen or lost device.</li><li><strong>Runtime protection:</strong> No sensitive information should be saved or stored on the device while the application is running (runtime). The data should only be processed at runtime and then destroyed after closing the application.&nbsp;For the data that need to be stored in the mobile device, there should be an encryption mechanism.</li><li>User codes and passwords should not be used or stored as hardcoded.</li><li>The application should only be authorized for the device resources it will use.</li><li>If there is sensitive data usage or access on the application, an encryption must be used on device.</li><li>Apps, especially enterprise apps, should never run on the rooted or jailbroken mobile devices. So, apps should always have a <strong>jailbreaking control</strong> mechanism.</li><li><strong>Tamper-detection and tamper-protection:</strong> The integrity of the apps must be ensured. There should always be an integrity check on the server-side for any changes to the installation files against tampering or intervention.</li><li>Android Firebase App Indexing feature should not be used for enterprise apps.</li><li>For enterprise apps, <strong>any analytics or performance analysis</strong> of the mobile application should not be monitored with 3rd party services. For this purpose, you may need to follow your regulations or governance practices. Also, all external 3rd party functions such as Google Tag Manager, ad manager, Facebook Connect that originate from the development environment should be disabled.</li><li>The mobile application should always be verified on the server-side via a <strong>device ID or token control mechanism</strong>.</li><li>SSL/TLS pinning should be used in apps.</li><li>All traffic from the mobile application’s form fields must also be encrypted.</li><li><strong>“Custom” encryption and hashing algorithms</strong> designed by developers should never be used in the mobile application. You should choose at least AES-256 in symmetric encryptions, and at least SHA-256 for hashing.</li><li>While storing data in iOS or Android, “<strong>secure container</strong>” structure should be used.</li><li><strong>To prevent the message from being intercepted or changed</strong> at any layer in service calls made in the application, cryptographic hash values of each transaction message should be generated by utilizing a predetermined private key, and these hash values should be crosschecked on the service side.</li><li><strong>To prevent the replaying attack</strong> which repeats service calls in the application, a randomly generated key/nonce value should be added in the cryptographic hash calculation and by this way, each message’s uniqueness must be ensured. Also, if the unique messages are repeated, the related call/transaction should be blocked.</li><li>The session opened by going through the security steps in the application should be verified in each call/request/transaction.</li><li>The information in the messages incoming/outgoing from the app to the servers should be encrypted.</li><li><strong>Authorization and permission control</strong> should be done for each transaction at the application and the service layer.</li><li>You should not only use or rely on the mobile operating system/device’s built-in key chains, containers or security mechanism.</li><li>At all stages in the service layer, <strong>error/fault management</strong> should be implemented and recorded.</li><li><strong>Log records</strong> of all successful and unsuccessful service requests/responses should be created for monitoring and audit purposes.</li><li>You should follow <strong>static code analysis/review and security testing</strong> throughout the SDLC.</li></ol>



<p>Besides above, I strongly advise you to follow the instructions published in in <a rel="noreferrer noopener" href="https://owasp.org/www-project-mobile-security/" data-type="URL" data-id="https://owasp.org/www-project-mobile-security/" target="_blank">the OWASP Mobile Security Project</a>.</p>







<p><em>The featured painting above is “<a rel="noreferrer noopener" href="https://myforevertravel.com/ataturk-museum-ankara/" data-type="URL" data-id="https://myforevertravel.com/ataturk-museum-ankara/" target="_blank">Mustafa Kemal Pasha, speaker of the Turkish Grand National Assembly and Commander-in-Chief, Fevzi Pasha, Chief of General Staff, Kazim Karabekir Pasha, Commander of Eastern Front and Ismet Pasha, Commander of Western Front, leave for the front.</a>” <em>from Atatürk Museum Ankara</em>.</em></p>
</div></article><h2>Reader Interactions</h2>
		

		
		

		</main></div></div>]]>
            </description>
            <link>https://www.mekinpesen.com/mobile-security/security-tenets-for-mobile-applications/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931469</guid>
            <pubDate>Thu, 29 Oct 2020 15:20:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Rust for a simple hardware project]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931388">thread link</a>) | @bschwindHN
<br/>
October 29, 2020 | https://blog.tonari.no/rust-simple-hardware-project | <a href="https://web.archive.org/web/*/https://blog.tonari.no/rust-simple-hardware-project">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this post we'll cover new hardware additions to <a href="https://tonari.no/" rel="noopener" target="_blank">tonari</a> and some of the work and research that went into powering that hardware. We're <a href="https://blog.tonari.no/why-we-love-rust" rel="noopener" target="_blank"><m>big fans of the Rust programming language</m></a> but before this project we hadn't ever used it for embedded hardware. <m>We'll go over our hardware requirements, some possible solutions, some reasons (excuses) for choosing Rust for the job, and provide a primer for getting into embedded programming with Rust. We'll end it with some photos of the absurd-looking hardware we created and our thoughts on doing all this work in Rust.</m></p><p>This article gets fairly technical with lots of acronyms and code snippets. We tried to spell out all the acronyms but let us know if we missed any!</p><p>If you want to skip straight to the code, you can find it here:</p><p><a href="https://github.com/tonarino/panel-firmware" rel="noopener" target="_blank">https://github.com/tonarino/panel-firmware</a></p><a href="#motivations" id="motivations"><h2><m>Motivations</m></h2></a><p>Recently at tonari, we wanted to add a few new product features that give users and ourselves a bit more control over how we manage the environment around tonari. None of these features had a clear solution using our current hardware design, so we looked at this as an opportunity to think about how we might integrate new hardware and controllers into our system in the near-term and longer-term.</p><figure><picture><source srcset="https://blog.tonari.no/images/c792e597-24e3-4e4a-98bb-3da838fd1c67-cropped_hero.jpg.optimized.webp" type="image/webp"><source srcset="https://blog.tonari.no/images/c792e597-24e3-4e4a-98bb-3da838fd1c67-cropped_hero.jpg.optimized.jpg"><img src="https://blog.tonari.no/images/c792e597-24e3-4e4a-98bb-3da838fd1c67-cropped_hero.jpg.optimized.jpg"></picture><figcaption><p>The current tonari hardware with overhead lights, share screen on the left, and volume control below.</p></figcaption></figure><a href="#volume-control-for-shared-audio" id="volume-control-for-shared-audio"><h3>Volume control for shared audio</h3></a><p>tonari users can share video and audio content — e.g. <m>YouTube videos</m> or screen mirroring — to both sides via a <m>secondary 'share screen' next to the main tonari screen</m>. We don't always have an easy way to optimize volume levels for this content, so we want to offer a simple and consistent way to increase or decrease the volume of shared audio, so that users on either side can find a comfortable balance between content and voices.</p><a href="#quiet-mode" id="quiet-mode"><h3>Quiet mode</h3></a><p>Though tonari is always on, we completely acknowledge that sometimes people need privacy, or just some <m>peace and quiet</m>. I've been known to get a tiny bit loud when playing video games near tonari (or at least that's what <m>t</m>he neighbors have told me). We want everyone to have the ability to easily enable a 'quiet mode' for this situation. The interface should be simple and accessible, so we prefer a physical hardware interface (such as buttons or dials) instead of a special app or complicated touch screen menus.</p><a href="#dynamic-lighting" id="dynamic-lighting"><h3>Dynamic lighting</h3></a><p><m>Lighting conditions change throughout the day based on weather, time or day, or other things happening around tonari. Just like having a camera flash on a phone, having more control of the lighting can help us provide better image quality for both sides. So we want to have good overhead lighting above tonari, and be able to control the color temperature and brightness, to be able to adjust better to each environment and situation.</m></p><a href="#summary-of-requirements" id="summary-of-requirements"><h2>Summary of requirements</h2></a><p>Based on the above features and motivations, we <m>need</m>ed the following:</p><ul><li>Some sort of volume controller</li><li>Interactive hardware, e.g. a button, to put tonari into 'quiet mode'</li><li>Software control of the overhead lights</li><li>The possibility to add more hardware components later as our needs grow</li><li>Wired communication, for reliability and simplicity</li></ul><a href="#hardware-selection" id="hardware-selection"><h2>Hardware selection</h2></a><a href="#volume-hardware" id="volume-hardware"><h3>Volume hardware</h3></a><p><m>Selecting hardware for volume control was fairly simple since there are only a few reasonable choices:</m></p><ul><li>Potentiometer — A variable resistor or voltage divider which changes resistance values as you rotate it</li><li>Rotary encoder — If you've ever used a volume dial that you can spin forever, that was most likely a rotary encoder. They can give you absolute rotation values, or incremental values depending on the type. Their output is digital, whereas a potentiometer is analog.</li><li>Up/down buttons </li><li>Touch screen</li></ul><p>We wanted the ability to reset the volume after a period of time so someone doesn't leave tonari in a muted state and confuse the next person who uses it. If we wanted to use a potentiometer with that restriction, it would need to be motor-controlled so we can reset it. These kinds of potentiometers are often seen on fancy audio equipment. We would need to include code to drive the motor appropriately and the price per-part is high compared to a simple potentiometer or rotary encoder.</p><p>Touch screens were immediately ruled out for being way too general-purpose and requiring much more code to implement.</p><figure><picture><source srcset="https://blog.tonari.no/images/ada061a5-45bd-44c3-b6c7-e116fb7dca84-IMG_7150.jpg.optimized.webp" type="image/webp"><source srcset="https://blog.tonari.no/images/ada061a5-45bd-44c3-b6c7-e116fb7dca84-IMG_7150.jpg.optimized.jpg"><img src="https://blog.tonari.no/images/ada061a5-45bd-44c3-b6c7-e116fb7dca84-IMG_7150.jpg.optimized.jpg"></picture><figcaption><p>(the kind of thing we're trying to avoid...)</p></figcaption></figure><p>Up/down buttons could work and be a very simple solution, but they're not very satisfying and are borderline annoying when you need to change the volume by a large margin.</p><p>That left us with rotary encoders. They're very inexpensive, fairly easy to write firmware to read from one, they can tell you which direction they're turning and roughly how fast, and some even come combined with a push button. They're not perfect, especially the cheaper ones which can have noise in the output, but for our uses they seemed like the right choice.</p><a href="#lighting-hardware" id="lighting-hardware"><h3>Lighting hardware</h3></a><p>Lighting was a little less straightforward. All we knew was that we wanted control over brightness and color temperature, and ideally they could provide a high lumen output. "Smart" lighting like Phillips Hue was out of the question — they're more consumer oriented and typically require apps with a bluetooth or WiFi connection in order to control them.</p><p>Some brief research into this problem introduced me to DALI — Digital Addressable Lighting Interface. I read up on DALI for a few minutes and was convinced it was something we wanted to stay far away from. It's likely useful for huge networks of lights in warehouses or something like that, but for our situation where we're only controlling a few lights in the immediate area, it looked like extreme overkill.</p><p>Another complication is <a href="https://www.bhphotovideo.com/explora/video/tips-and-solutions/flicker-free-lights-and-why-they-are-important-you" rel="noopener" target="_blank"><m>light flicker</m></a>. Put simply, any sort of lighting flicker in a video is headache-inducing and unacceptable, especially at the wall-sizes tonari works at. We evaluated as many LED light bars as we could get our hands on, testing them on our camera setups at various frame rates. The funny thing about Japan is that their electrical system is split more or less down the middle: it's 60Hz in the west and 50Hz in the east.</p><figure><picture><source srcset="https://blog.tonari.no/images/a1f7994d-1403-4fd1-a9e4-844328e1cbdf-frequencies_map.jpg.optimized.webp" type="image/webp"><source srcset="https://blog.tonari.no/images/a1f7994d-1403-4fd1-a9e4-844328e1cbdf-frequencies_map.jpg.optimized.jpg"><img src="https://blog.tonari.no/images/a1f7994d-1403-4fd1-a9e4-844328e1cbdf-frequencies_map.jpg.optimized.jpg"></picture><figcaption><p>(Source: <a href="http://www.rikuden.co.jp/eng_electricity/frequencies.html" rel="noopener" target="_blank">http://www.rikuden.co.jp/eng_electricity/frequencies.html</a>)</p></figcaption></figure><p>We run our cameras at 60 FPS when we can but sometimes in the 50Hz region we have to drop to 50 FPS to remove light flicker <m>from the existing light sources</m>. Any light we select has to exhibit zero flicker at 50 and 60 FPS.</p><p>After our tests, we settled on Daiko LED light bars. They don't have flicker at the frame rates we run, they're affordable, bright, they support brightness and color temperature control, and their hardware control circuit seemed simple enough to plug in a custom controller.</p><p>Their brightness and color temperature seemed to be completely controlled by PWM (<a href="https://en.wikipedia.org/wiki/Pulse-width_modulation" rel="noopener" target="_blank">pulse-width modulation</a>) — it was written right on the dimmer panel. After a quick check of the provided dimmer with a multimeter and pocket oscilloscope, we learned that the PWM frequency was 1 KHz and the input voltage was +12V.</p><figure><picture><source srcset="https://blog.tonari.no/images/0f385e0d-96db-43eb-bb02-cb0762929e5f-IMG_0054.jpg.optimized.webp" type="image/webp"><source srcset="https://blog.tonari.no/images/0f385e0d-96db-43eb-bb02-cb0762929e5f-IMG_0054.jpg.optimized.jpg"><img src="https://blog.tonari.no/images/0f385e0d-96db-43eb-bb02-cb0762929e5f-IMG_0054.jpg.optimized.jpg"></picture><figcaption><p>Measuring the PWM duty cycle via a pocket oscilloscope</p></figcaption></figure><video src="https://blog.tonari.no/images/ac5e031e-c107-4a17-a052-fc787e5afc43-IMG_0056.mov" controls="" alt="An video from Notion" loop="" muted="" autoplay=""></video><p>So to recap:</p><ul><li><m>We'll use</m> a rotary encoder with pushbutton for volume control and extra user interactions</li><li>Daiko LED light bars will be used</li><li>We need a microcontroller which can interface with a rotary encoder and generate a 1 KHz PWM signal (pretty much any microcontroller can...)</li></ul><a href="#surveying-of-possible-solutions" id="surveying-of-possible-solutions"><h2><m>Surveying</m> of possible solutions</h2></a><p>I personally have a small amount of microcontroller experience, mostly with the ESP8266 and ESP32, and a bit on the Arduino AVR boards. I was very close to just going with the ESP32 — I know it and it's packed with peripherals — WiFi, bluetooth, SPI, PWM, serial UART, etc. It's super cheap and widely available. <m>I'm actually quite confident an ESP32 solution would have worked perfectly well, but I wanted to push myself a bit and learn something new. At least, that's what I tell myself, but in reality I wanted an excuse to try running </m><m><m>Rust on an embedded platform</m></m><m>.</m></p><p>As it turns out, there is <a href="https://mabez.dev/blog/posts/esp-rust-ecosystem/" rel="noopener" target="_blank">significant progress</a> being made on running Rust on the ESP32, so that will soon be an option. For now, the main way to run code on the ESP32 is through the official "esp-idf" (Espressif IoT Development Framework), using C.</p><p>I can write the ESP32 firmware in C and it'll get the job done, but it's not too fun to write <m>when you know Rust</m>. <m> We already have an existing successful Rust codebase, so anyone who can work on that code can fairly easily jump over to working on Rust firmware</m>. Having our main codebase and the firmware share languages means it will be easy to write a communication library that is shared between the two. The Rust compiler and its borrow-checking rules and type system means less errors at runtime such as configuring the wrong pins for a peripheral, initializing things in the wrong order, or trying to use a resource in two places at once. On top of that, learning new things in Rust is almost always fun and the compile times which would normally be somewhat painful are gone as embedded projects typically don't use the standard library or any heavy dependencies.</p><p>For embedded Rust today, the most popular microcontroller family seems to be the STM32 series by STMicroelectronics. I had ordered a few STM32 board variations several months prior on Aliexpress when I heard about them being recommended for Rust development.</p><p>I was still a little uncertain if this was the right path or if I was heading into a world of hurt so I experimented with the boards a bit. I began looking at some Rust documentation for one of the microcontroller families and ended up on <a href="https://docs.rs/stm32f1xx-hal/0.6.1/stm32f1xx_hal/qei/index.html" rel="noopener" target="_blank">their documentation</a>, wondering what <code>QEI</code> stood for. It's Quadrature Encoder Interface, which is a type of rotary encoder, and happens to be the kind of encoder I purchased to experiment on! The STM32 chips have built-in hardware for decoding rotary encoders??? No way, that's too convenient. I wrote up a quick sample, connected the encoder to the correct pins on the microcontroller, and I was getting valid input from turning the dial, just like that. I was sold.</p><a href="#getting-started-with-embedded-rust" id="getting-started-with-embedded-rust"><h2><m>Getting started</m> with embedded Rust</h2></a><p>When I was researching the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.tonari.no/rust-simple-hardware-project">https://blog.tonari.no/rust-simple-hardware-project</a></em></p>]]>
            </description>
            <link>https://blog.tonari.no/rust-simple-hardware-project</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931388</guid>
            <pubDate>Thu, 29 Oct 2020 15:14:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MemgraphDB: Why and how we implemented Bolt Protocol v4]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24931364">thread link</a>) | @karimtr
<br/>
October 29, 2020 | https://memgraph.com/blog/memgraph-1-2-release-implementing-the-bolt-protocol-v4 | <a href="https://web.archive.org/web/*/https://memgraph.com/blog/memgraph-1-2-release-implementing-the-bolt-protocol-v4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Introduction</h3>
<p>Today, we’re proud to announce the release of <a href="https://memgraph.com/download">Memgraph 1.2</a>, which significantly improves Memgraph’s compatibility with the broader graph ecosystem. This makes it easier for developers and data scientists to work with Memgraph using their favourite tools.</p>
<p>One of the biggest changes in this release, is the addition of Bolt v4 and v4.1 support.</p>
<p>In this post, we will explore what exactly is the Bolt protocol, what it brings to the table, and how we implemented it into Memgraph.</p>
<h2>The Bolt Protocol</h2>
<p>If you’re thinking about using Memgraph in your application, one of the
requirements is the possibility of querying Memgraph directly from your
application with as little effort as possible. You can achieve that by writing
drivers for the Memgraph server in the language you want to support. Drivers are
special libraries that follow predefined rules, aka a protocol, to communicate between
your application and a server.</p>
<p>Instead of defining its own rules, Memgraph decided to use Neo4j’s protocol
called <a href="https://7687.org/">Bolt</a>. There are 3 important reasons for this
decision:</p>
<ol>
<li>Defining a protocol is not easy</li>
<li>Neo4j also uses <a href="https://www.opencypher.org/">Cypher</a> (that doesn’t mean that the Bolt protocol can’t be used for other query languages!)</li>
<li>By supporting Neo4j’s protocol we automatically become compatible with their drivers</li>
</ol>
<p>The drivers that Neo4j currently maintains are:</p>
<ul>
<li><a href="https://github.com/neo4j/neo4j-java-driver">Java Driver</a></li>
<li><a href="https://github.com/neo4j/neo4j-javascript-driver">JavaScript Driver</a></li>
<li><a href="https://github.com/neo4j/neo4j-dotnet-driver">.NET Driver</a></li>
<li><a href="https://github.com/neo4j/neo4j-python-driver">Python Driver</a></li>
<li><a href="https://github.com/neo4j/neo4j-go-driver">Go Driver</a></li>
</ul>
<p>In other words, by making our server compatible with the Bolt protocol, you can
use Memgraph in any of the languages and frameworks listed above just by using
Neo4j’s libraries.</p>
<h3>Bolt Protocol Rule Examples</h3>
<p>First, we need to know how to exchange messages. Bolt exchanges its messages using a request-response pattern between the client and the server. Each request message can be followed by zero or record messages  which are then followed by one summary message. The different possibilities for record messages depends on the type of the request message.</p>
<hr>
<p><strong>NOTE</strong></p>
<p>A record message is a type of message which contains records, aka result rows.</p>
<hr>
<p>Also, we need to know how to serialize our data. Bolt uses its own
<a href="https://7687.org/packstream/packstream-specification-1.html#version1">PackStream</a> which provides specification for serializing a bunch of different types of data. It is fully compatible with the types
supported by Cypher. We won’t go into details but every type is defined with its marker, its size and its data.</p>
<p><img src="https://i.imgur.com/2GkXojm.png" alt=""></p>
<p><em>Source:</em> <em><a href="https://7687.org/packstream/packstream-specification-1.html">https://7687.org/packstream/packstream-specification-1.html</a></em></p>
<p>One of those types is a structure. The size of the structure defines how many fields
it contains and the fields can be of any other type. But we’re missing an
important information. How do we know what the structure represents? Structures
carry additional data, its tag byte. This tag tells us what does the structure
represent. We’re now half way through to understanding how to define request and
response messages.</p>
<p>We can’t expect that our data will always be small enough to send it all at
once. To solve this problem, Bolt defines how the message is chunked. Each chunk
is starts with two-byte header that tells us the size of chunk data in bytes
followed by the chunk data itself. Now, we have another problem. How do we know
if we received the last chunk of message? We just add a marker! In our case we
append to the end of the last chunk <code>00 00</code>.</p>
<p>Now, we have everything we need to define our messages. We can define each type
of request/response message as a unique structure, having a unique set of fields.
We can send the defined structure using the chunking method defined before.
We’re set! We can serialize and deserialize messages now!</p>
<h4>Bolt Protocol Specifications</h4>
<p>A good protocol specification should contain as much information as possible.
Without enough information, we can only guess how our server or client should
behave in some situations, causing a lot of headache for every developer that
tries to implement that protocol.</p>
<p>So, as a good protocol, Bolt defines how to parse different types of request
message and send the correct response message. It defines how each request
message looks and what to send as a response message in each possible
situation. Also, it defines the state of server after each request message and
its outcome.</p>
<p>If want to delve deeper into the Bolt Protocol specifications, you can find everything <a href="https://7687.org/">here</a>.</p>
<hr>
<p><strong>NOTE</strong></p>
<p>Implementing rules is not hard, but to do it efficiently requires a lot of
careful planning and having a good understanding of how the protocol works.</p>
<hr>
<h2>Evolution of the Bolt Protocol</h2>
<p>As with any software, protocols are susceptible to change. Bolt defines it’s
version using major and minor versions. At the start of each connection, the
client needs to do a handshake with the server.</p>
<p>The handshake is really simple and consists of only two steps:</p>
<ul>
<li>client sends at most 4 versions it supports, sorted by priority</li>
<li>server responds with the first version in the list it supports</li>
</ul>
<h3>But doesn’t Memgraph support Bolt protocol?</h3>
<p>Yes, Memgraph does support the Bolt protocol. But up until now, it only supported Bolt v1, while the current version is 4.1. By looking at the handshake process we can conclude that the client can support <strong>at most</strong> four versions. The logical thinking is that the client will always support the latest 4 versions. At the time of writing this, the latest version is v4.1, which pushed v1 out of the support list, making us, and everyone else that wanted to try Memgraph using Neo4j’s drivers, very sad.</p>
<p><img src="https://i.imgur.com/OC6Tzd2.png" alt=""></p>
<hr>
<p><strong>NOTE</strong></p>
<p>It’s important to emphasize that after version 1.0, newer versions weren’t documented,
which made keeping up with the newer versions really hard. But, after v4.1, Neo4j
decided to document every version nicely making our lives much easier. Thanks
Neo4j!</p>
<hr>
<h2>The Road to Bolt v4.(1)</h2>
<p>Since Memgraph was only compatible with the first version of the Bolt protocol, we had three major and one minor version change to catch up with.Most of it was just some basic additions to the already existing messages, but there were also some bigger changes. For example, we made the decision to preserve support for Bolt v1. This has been very challenging as one of the hardest things in programming is making bigger changes to an existing code while not breaking the old behaviour.</p>
<h3>Supporting multiple versions</h3>
<p>Handling a code that behaves differently for each version can be hard. After we
decide on a version for a specific connection, we need to be careful which messages
are allowed for that version, which response should each message produce, what
parameters are allowed, and many more things. And to do that while reusing as much
of code as possible, with the addition of keeping the readability can be a challenge.
The only real advice I can give you here is write as many tests that will cover as
much as possible because a smallest detail can make your server misbehave while
implementing a support for a protocol.</p>
<h3>Making transaction handling easier and more powerful</h3>
<p>In Bolt v3, new request messages for handling transactions were added. Those messages
are for starting an explicit transaction and ending the transaction by
committing or rollbacking the changes.
Because we already had support for transactions and you could already do
the same thing by running queries consisting of <code>BEGIN</code>, <code>COMMIT</code> and <code>ROLLBACK</code>
commands, the only thing we had to do was add functions that directly run those
queries when the corresponding request was received.</p>
<h3>Getting some results from here and some from there</h3>
<p>The biggest change to the Bolt protocol was the change to the <code>PULL</code> and
<code>DISCARD</code> message.
Before we delve deeper, let’s explain those messages.
When you want to run a query on a server using Bolt messages, first you need to
send a <code>RUN</code> message that contains the query we want to execute. To get the results
of the query we send a <code>PULL</code> message, and if we want to discard the results,
we simply send the <code>DISCARD</code> message. The natural way of handling this is preparing
the query when we receive the <code>RUN</code> message and executing it when we receive the
<code>PULL</code> message. Additionally, to avoid wasting memory, we don’t keep the result, we
just forward it to the encoder and send it directly to the client.</p>
<p>In Bolt v1, there were <code>PULL_ALL</code> and <code>DISCARD_ALL</code> messages. As their name suggests,
the only options you had was all or nothing. Taking this into account, we developed
a solution that would simply stream all the results to the client after it receives
<code>PULL_ALL</code> message. But, since v4.0, things got a little more complicated.
The <code>PULL_ALL</code> message was renamed to <code>PULL</code>. Additionally, the <code>PULL</code> message can come with some extra parameters.</p>
<p><img src="https://i.imgur.com/4ibg9Db.png" alt=""></p>
<h4><code>n</code> parameter</h4>
<p>You can now pull an arbitrary number of results. This small change implies a lot of
changes to the existing code. The easiest solution would be to execute the query on the
first pull and save all of the results in memory. After that, for each pull, we just
send next <code>n</code> results. Even though it’s the easiest solution to implement, it’s too
inefficient memory-wise. Taking this into account, we have a hard requirement of
keeping the old, lazy behaviour while not keeping any of the results in memory.</p>
<p>There are different types of queries and each query demands a different approach to
achieve this behaviour. Queries with a constant size of the result, like profiling and
explain queries, can have a simple vector of results from which the results are
lazily pulled. For most of the queries that have variable size of the result, we
prepare all the necessary resources for the execution and ask for the next result only
when it’s needed after which the results are streamed instantly to the client.
The resources are cleaned after the <code>PULL</code> request that returned the
last result. This is possible because of Memgraph’s lazy way of handling the execution.</p>
<p>The query that was surprisingly the hardest to implement lazily was the <code>DUMP</code> query.
By itself, it’s really simple to implement this query. You analyse different parts of
your database and, as a result, send a query that defines that part. For example, we
iterate each vertex in our database, and we send back …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://memgraph.com/blog/memgraph-1-2-release-implementing-the-bolt-protocol-v4">https://memgraph.com/blog/memgraph-1-2-release-implementing-the-bolt-protocol-v4</a></em></p>]]>
            </description>
            <link>https://memgraph.com/blog/memgraph-1-2-release-implementing-the-bolt-protocol-v4</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931364</guid>
            <pubDate>Thu, 29 Oct 2020 15:13:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How UX Copy Drives Better Business Results]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931351">thread link</a>) | @tomericco
<br/>
October 29, 2020 | https://www.frontitude.com/blog/how-ux-copy-drives-better-business-results | <a href="https://web.archive.org/web/*/https://www.frontitude.com/blog/how-ux-copy-drives-better-business-results">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="HeroSection"><div><p>You probably remember those days when the term “UX” was formed. It was around the early 2000s when product companies started to realize that not only should their products look good, but they should also be easy to use. Throughout these years, product companies embraced new terms and methodologies to fulfill this new standard: Design Components (or Symbols), Design Systems, Responsive Web Design (RWD), and more. A new title was formed - the UX Designer. As a result, a new wave of tools came up to support this transition: Sketch, Adobe XD, and Figma (among others) empowered UX professionals to fulfill the new requirements.</p><div><h3><strong>The rise of UX Writing</strong></h3><p>Until recent years, it was mostly about visual design. Another ingredient of the user experience, the textual content, was pretty much neglected. But not anymore. These days, product companies have started to realize the importance of it and its effect on the overall user experience and business performance. Just like the transition in visual design, this one is also forming new terms and methodologies: Microcopy, UX Copy, UX Writing, Content Design, Content Style Guide, and more. Also here, a new title was formed - the UX Writer, which is something between a Copywriter and a UX Designer. This new profession has led to new books (our favorite, <a href="https://www.microcopybook.com/" target="_blank">Microcopy - The Complete Guide</a>), courses (such as <a href="https://uxwritinghub.com/" target="_blank">UX Writing Hub’s</a>), conferences (such as <a href="https://www.uxwriterconference.com/" target="_blank">UX Writer</a>), and communities that came out to support the learning and training of these new professionals.</p></div><div><p><a href="#"><img src="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f992eedd7b266f594c98aa7_business-metrics-cover.jpg" loading="lazy" sizes="(max-width: 479px) 92vw, (max-width: 767px) 93vw, 680px" srcset="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f992eedd7b266f594c98aa7_business-metrics-cover-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f992eedd7b266f594c98aa7_business-metrics-cover.jpg 1260w" alt=""></a></p><p>Photo by David Travis (Unsplash)<a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"></a><br></p></div><div><h3><strong>It’s all about the business</strong></h3><p>Both of the transitions mentioned above took (and are still taking) place for only a single reason: it’s good for business. The success of digital products (mainly websites, mobile apps, and web apps) is measured by a few metrics, which may vary from product to product, but are usually based on conversion rates, click-through rates, and retention. Good UX copy affects the aforementioned business metrics by effortlessly guiding users through an experience to an intended goal or objective.</p><p>To make this statement more concrete, we have gathered a few up-to-date real-world examples from the community, where better UX copy has significantly improved business metrics.<br></p></div><div><h3><strong>Case study #1: Increase user retention by speaking your users’ language</strong></h3><p><a href="https://preply.com/" target="_blank">Preply</a> is an educational platform that connects more than 100,000 students with tutors worldwide for personalized language lessons online. <a href="http://www.linkedin.com/in/viktoria-kosiak" target="_blank">Viktoria Kosiak</a>, a UX Writer at Preply, describes how they improved key metrics of their business by testing and changing UX copy at the heart of their product.</p><p><br>Viktoria: “A core part of Preply’s product is a system for scheduling lessons. Students have two ways of planning their learning: schedule individual lessons by choosing each date manually (<em>One-by-one</em>), or set up a recurring routine where lessons are scheduled automatically each week (<em>Weekly</em>).”</p></div><div><p><a href="#"><img src="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb8b955bd956f9704c_preply1.jpg" loading="lazy" sizes="(max-width: 479px) 92vw, (max-width: 767px) 93vw, 680px" srcset="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb8b955bd956f9704c_preply1-p-500.jpeg 500w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb8b955bd956f9704c_preply1-p-800.jpeg 800w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb8b955bd956f9704c_preply1-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb8b955bd956f9704c_preply1.jpg 1426w" alt=""></a></p><p>Scheduling lessons UI before the copy change (Preply)<br></p></div><div><p>“We believe that learning is effective when it’s regular. Plus, students with a weekly schedule are the ones with better retention, so promoting weekly lessons has always been in the best interest of our business.”</p><p>“The problem was that the number of scheduled weekly lessons was lower than we expected. According to the <a href="https://www.nngroup.com/articles/user-centric-language/" target="_blank">Features vs. Benefits approach</a>, <em>Weekly lessons</em> is focused on the way the feature works, rather than the user benefit.”</p><p><br>“To focus more clearly on the benefits of a weekly schedule, our solution was to change the copy from <em>Weekly lessons</em> to <em>Regular lessons</em>. We also knew from user interviews that our customers used the word <em>regular</em> to speak positively about forming a learning habit. Under this test, we also changed <em>One-by-one lessons</em> to <em>Single lessons</em> because we thought it would be easier to understand when seen next to <em>Regular lessons</em>.”</p></div><div><p><a href="#"><img src="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fa41891a144778ed6c_preply2.jpg" loading="lazy" sizes="(max-width: 479px) 92vw, (max-width: 767px) 93vw, 680px" srcset="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fa41891a144778ed6c_preply2-p-800.jpeg 800w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fa41891a144778ed6c_preply2-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fa41891a144778ed6c_preply2.jpg 1543w" alt=""></a></p><p>Using users’ language to name the lesson type has increased the number of scheduled regular lessons by 11% (Preply)<br></p></div><div><h4><strong>Business impact</strong></h4><p>The Preply team reports a significant increase of 11%(!) in the number of <em>regular lessons scheduled</em>. Also, they’ve identified a significant increase of 7.8% in one of their key business metrics: <em>hours bought on the platform</em>.</p></div><div><h3><strong>Case study #2: Increase click-through rate (CTR) by adding clarity</strong></h3><p><a href="https://fundbox.com/" target="_blank">Fundbox</a> is a B2B fintech startup that offers a revolving line of credit to small- and medium-sized businesses in the US. <a href="https://twitter.com/YaelBenDavid" target="_blank">Yael Ben-David</a>, a UX Writer at Fundbox, describes how the company increased revenue with a few copy changes.</p><p>Yael: “In our product, the most important touchpoint for revenue, is the Draw Pane, which is a dialogue users use to draw funds. It can be opened through the user dashboard using a button with the label <em>Draw Funds</em>. It seemed like users were too scared to click it since it sounded very final. They thought it would immediately pull funds into their account and they wouldn't have a chance to review the repayment terms first. They never finished drawing because of that.”</p><p><br>“To make it clearer, we changed the CTA from <em>Draw Funds</em> to <em>Review &amp; Draw</em>.”</p></div><div><p><a href="#"><img src="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb1d99c05198df5683_fundbox1.jpg" loading="lazy" sizes="(max-width: 479px) 92vw, (max-width: 767px) 93vw, 680px" srcset="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb1d99c05198df5683_fundbox1-p-500.jpeg 500w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb1d99c05198df5683_fundbox1-p-800.jpeg 800w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb1d99c05198df5683_fundbox1-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb1d99c05198df5683_fundbox1.jpg 1600w" alt=""></a></p><p>A call-to-action button that is more empathetic to the user’s headspace and better manages expectations led to a higher CTR (Fundbox)<br></p></div><div><h4><strong>Business impact</strong></h4><p>One of the core metrics at Fundbox is <em>whether users draw funds in the first 7 days after approval</em>, which is a strong indicator of customer LTV (lifetime value). After the change in the copy, a significant improvement was shown in this metric, and in credit draws overall.</p></div><div><h3><strong>Case study #3: Reduce sales team calls by being more informative</strong></h3><p>It’s Fundbox again! This time, a few copy changes saved a lot of manual labor for their sales team. Yael is here again to tell us about it.</p><p>Yael: “As I mentioned before, the Draw Pane is a critical point in our product, which is where users draw funds. Many users didn’t understand the terms for repaying the funds, and so obviously, they didn’t draw. Reps would then reach out to explain the terms on the phone, and then the user would be comfortable drawing.”</p><p>“We ran an A/B test:</p><ol role="list"><li>We removed some of the copy from the tab headers to prevent confusion—users weren’t sure whether we were showing the weekly payment (principal + fees) or only the fees. The information appears lower down in a clearer way so we didn’t need it here, too.</li><li>We added a tooltip to preempt questions and hesitations users had around the weekly fees.</li><li>We added <em>Max</em> to <em>total repayment</em> since there is a way that users can save on fees and actually never end up paying the full amount of fees. Without saying <em>Max</em> it looked like no matter what, they would end up paying back this whole amount.”</li></ol></div><div><p><a href="#"><img src="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fbce23b43214f25407_fundbox2.jpg" loading="lazy" sizes="(max-width: 479px) 92vw, (max-width: 767px) 93vw, 680px" srcset="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fbce23b43214f25407_fundbox2-p-500.jpeg 500w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fbce23b43214f25407_fundbox2-p-800.jpeg 800w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fbce23b43214f25407_fundbox2-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fbce23b43214f25407_fundbox2.jpg 1600w" alt=""></a></p><p>A few copy changes in the Draw Pane significantly reduced sales team calls (Fundbox)<br></p></div><div><h4><strong>Business impact</strong></h4><p>The sales team reported a significant decrease in the time they spent helping users through this point of friction.<br></p></div><div><h3><strong>Case study #4: Reduce support tickets by giving a heads up</strong></h3><p><a href="https://www.gong.io/" target="_blank">Gong.io</a> provides a revenue intelligence platform created to improve calls and demos for sales teams. <a href="https://www.linkedin.com/in/naomipapoushado/" target="_blank">Naomi Papoushado</a>, the Galactic Viceroy of Content Excellence at Gong.io, tells us how, by adding a piece of informational UX copy, they solved a technical issue that caused plenty of support tickets.</p><p>Naomi: “We got a bunch of support tickets where users were trying to associate a call with an account when they were a CRM Lead and not a CRM Contact.”<br></p></div><div><p><a href="#"><img src="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531f9229cf04f13c31064_gong1.jpg" loading="lazy" sizes="(max-width: 479px) 92vw, (max-width: 767px) 93vw, 680px" srcset="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531f9229cf04f13c31064_gong1-p-500.jpeg 500w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531f9229cf04f13c31064_gong1.jpg 778w" alt=""></a></p><p>Associating call CTA (Gong.io)<br></p></div><div><p>“People wanted to assign the call to a CRM Lead, but the option to associate the call was unavailable. They couldn’t understand why it wasn't working. So they’d open a ticket for the Support team, thinking it’s a bug in our system.”</p><p>“The Support team appealed to us (the UX team) about this issue. We chose to solve this by giving users a clear message explaining which accounts can be assigned with the call, and how to resolve the issue.”<br></p></div><div><p><a href="#"><img src="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb96b9ca6674e16de1_gong2.jpg" loading="lazy" sizes="(max-width: 479px) 92vw, (max-width: 767px) 93vw, 680px" srcset="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb96b9ca6674e16de1_gong2-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb96b9ca6674e16de1_gong2.jpg 1538w" alt=""></a></p><p>A clear explanation of the issue and a suggestion solution have significantly reduced support tickets (Gong.io)<br></p></div><div><h4><strong>Business impact</strong></h4><p>A short time after this change was released, Gong.io’s Support team reported zero(!) support tickets opened for this specific issue. It’s amazing how a small piece of text can save users so much frustration, and the Support team precious time.<br></p></div><div><h3><strong>Bottom line</strong></h3><p>The rise of UX Writing, which is taking place these days, is not just a flash in the pan. It’s proven that investing in creating great UX copy is a positive ROI deal. The examples above show that great UX copy not only enhances the user experience, but can also release bottlenecks at the core of your product and move the needle when it comes to business metrics.</p><h4><em>Looking for more examples like those we showed here? Asking yourself how you can deliver great UX copy at scale? We’re going to write about it in-depth in future posts. If you’re finding this interesting, </em><a href="#Blog-Subscribe-Form"><em>subscribe below</em></a><em> to get new posts to your inbox right when they’re out of the oven.</em><br></h4></div><div id="Demo-Form" data-w-id="5e1eb963-7815-90d1-c6f0-24fe8ff5b72d"><h2>Want to get more stories?</h2><p>Stay in the know with more stories about UX, content, workflows, and in between. You’ll be the first to know when we post new content.</p><div id="Blog-Subscribe-Form"><div id="form-success-message"><p><strong>You have successfully subscribed for updates!</strong><a href="https://calendly.com/baraksi/frontitude-demo" target="_blank"><span><br></span></a></p></div><div><p>Oops! Something went wrong. Please try again<br>or contact us at hi@frontitude.com</p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.frontitude.com/blog/how-ux-copy-drives-better-business-results</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931351</guid>
            <pubDate>Thu, 29 Oct 2020 15:12:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My AWS toolbox – tools, plugins and applications]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931347">thread link</a>) | @mradzikowski
<br/>
October 29, 2020 | https://betterdev.blog/my-aws-toolbox/ | <a href="https://web.archive.org/web/*/https://betterdev.blog/my-aws-toolbox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Developers, like all specialists, discover and collect their favorite tools over time. Having a good, proven set of tools makes the work easier and more pleasant. We can focus on getting the job done. Sometimes eliminating minor inconveniences or improving a small element of everyday activity makes the greatest impact on the comfort of work.</p>



<p>It’s not always easy to find the best tools. There is a wide choice. More importantly, everyone has different habits and preferences. The best way is to test them yourself and see what suits you.</p>



<p>To help a little bit with that, here I present a collection of my AWS tools. These are applications, plugins, and extensions that I use in my daily work with AWS.</p>



<h2><span id="cli"></span>CLI<span></span></h2>



<h3><span id="aws_cli"></span>AWS CLI<span></span></h3>



<p>The <a href="https://aws.amazon.com/cli/"><strong>AWS CLI</strong></a> is the obvious first position on this list. After all, sometimes it’s just quicker to do something in the CLI. Other times we need to wrap some process interacting with AWS in a simple script.</p>



<p>The AWS CLI v2 has some nice features, such as improved command completion. I’m using a <a href="https://fishshell.com/">fish shell</a> in the terminal and AWS CLI <a href="https://github.com/aws/aws-cli/issues/1079">does not natively provide</a> command completion for it. Fortunately, fish is extremely good with completions, so the fix is quite easy. It’s enough to add one (quite long) line to the config file and it works like a charm.</p>



<p><code>~/.config/fish/config.fish</code>:</p>



<pre><code>test -x (which aws_completer); and complete --command aws --no-files --arguments '(begin; set --local --export COMP_SHELL fish; set --local --export COMP_LINE (commandline); aws_completer | sed \'s/ $//\'; end)'</code></pre>







<div><figure><a href="https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion.png" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion.png" alt="AWS CLI v2 completion in fish shell" width="1027" height="106" srcset="https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion.png 2054w, https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion-300x31.png 300w, https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion-1024x106.png 1024w, https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion-768x79.png 768w, https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion-1536x159.png 1536w, https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion-2048x211.png 2048w" sizes="(max-width: 1027px) 100vw, 1027px"></a><figcaption>AWS CLI v2 completion in fish</figcaption></figure></div>



<h3><span id="asp_plugin_for_ohmyfish"></span>asp plugin for oh-my-fish<span></span></h3>



<p>As mentioned above, I’m using a fish shell. True beauty and power of it can be unlocked with <a href="https://github.com/oh-my-fish/oh-my-fish">Oh My Fish</a>, which is basically a plugin and theme manager for the shell.</p>



<p>The OMF plugin I use daily when working with AWS is <a href="https://github.com/m-radzikowski/omf-plugin-asp"><strong>asp</strong></a>. It’s a small, handy plugin that allows changing the currently selected AWS profile. I took it over from the original author and I’m its maintainer right now.</p>



<div><figure><img loading="lazy" src="https://betterdev.blog/app/uploads/2020/10/fish-asp-plugin.png" alt="Oh My Fish asp plugin for AWS profile change" width="245" height="223" srcset="https://betterdev.blog/app/uploads/2020/10/fish-asp-plugin.png 489w, https://betterdev.blog/app/uploads/2020/10/fish-asp-plugin-300x273.png 300w" sizes="(max-width: 245px) 100vw, 245px"><figcaption>Oh My Fish asp plugin</figcaption></figure></div>



<p>If you are using zsh instead of fish, a <a href="https://github.com/ohmyzsh/ohmyzsh/blob/master/plugins/aws/README.md">similar plugin</a> exists also for <a href="https://github.com/ohmyzsh/ohmyzsh">Oh My Zsh</a>.</p>



<h2><span id="infrastructure_as_code"></span>Infrastructure as Code<span></span></h2>



<h3><span id="serverless_framework"></span><img loading="lazy" width="94" height="150" src="https://betterdev.blog/app/uploads/2020/10/serverless-framework-logo.png" alt=""> Serverless Framework<span></span></h3>



<p>The <a href="https://www.serverless.com/"><strong>Serverless Framework</strong></a> is the most basic tool for my work with AWS. The built-in functionalities and number of community plugins accelerate infrastructure development. Even when creating just “ordinary” stacks, without any Lambda functions or other plugin-driven resources, writing CloudFormation with syntax extended by Serverless (for example, with variables) is far easier.</p>



<p>While CloudFormation is not always the best, it’s the default IaC for AWS and supported by them. The Serverless Framework is, in fact, building and deploying normal CloudFormation templates. That gives me confidence that I’m depending mostly on AWS, without additional parties. Anything that is not directly supported by Serverless or its plugins can be created using raw CloudFormation in the stack. This makes the IaC, the critical element of systems, stable and powerful.</p>



<div><figure><img loading="lazy" width="350" height="419" src="https://betterdev.blog/app/uploads/2020/10/serverless-stack-with-cf.png" alt="Sample Serverless stack with raw CloudFormation resource" srcset="https://betterdev.blog/app/uploads/2020/10/serverless-stack-with-cf.png 350w, https://betterdev.blog/app/uploads/2020/10/serverless-stack-with-cf-251x300.png 251w" sizes="(max-width: 350px) 100vw, 350px"><figcaption>Sample Serverless stack with raw CloudFormation resource</figcaption></figure></div>



<h2><span id="chrome_extensions"></span>Chrome extensions<span></span></h2>



<h3><span id="aws_extend_switch_roles"></span><img loading="lazy" width="128" height="128" src="https://betterdev.blog/app/uploads/2020/10/aws-extend-switch-roles-icon.jpg" alt=""> AWS Extend Switch Roles<span></span></h3>



<p>If you are working on multiple AWS accounts and/or using various roles, then you must know the pain of switching between them in the AWS Console. The site remembers your past roles, so you don’t have to provide the role name and account ID every time. At least as long as you have no more than 5 of them. That’s the limit of roles history, after which they are overridden.</p>



<p>Here to help comes <a href="https://chrome.google.com/webstore/detail/aws-extend-switch-roles/jpmkfafbacpgapdghgdpembnojdlgkdl"><strong>AWS Extend Switch Roles</strong></a> extension. The configuration is dead simple – you just copy the content of <code>~/.aws/config</code> file. From that point, when you click on the extension icon, you will get a nice, filterable list of all defined roles to choose from. And you can have as many of them as you need.</p>



<div><figure><img loading="lazy" width="436" height="290" src="https://betterdev.blog/app/uploads/2020/10/aws-extend-switch-roles-plugin-1.png" alt="AWS Extend Switch Role extension" srcset="https://betterdev.blog/app/uploads/2020/10/aws-extend-switch-roles-plugin-1.png 436w, https://betterdev.blog/app/uploads/2020/10/aws-extend-switch-roles-plugin-1-300x200.png 300w, https://betterdev.blog/app/uploads/2020/10/aws-extend-switch-roles-plugin-1-360x240.png 360w" sizes="(max-width: 436px) 100vw, 436px"><figcaption>AWS Extend Switch Role extension</figcaption></figure></div>



<p>Available also for <a href="https://addons.mozilla.org/en-US/firefox/addon/aws-extend-switch-roles3/">Firefox</a>.</p>



<h3><span id="aws_simple_iconification_service"></span><img loading="lazy" width="128" height="128" src="https://betterdev.blog/app/uploads/2020/10/aws-simple-iconification-service-icon.jpg" alt=""> AWS Simple Iconification Service<span></span></h3>



<p>This one is from the category “small but delightful”. <a href="https://chrome.google.com/webstore/detail/aws-simple-iconification/edagjlhogddnlkbkllibfhbekpcdppbk"><strong>AWS Simple Iconification Service</strong></a> extension fixes favicons in AWS Console.</p>



<p>The fact that half of the service pages in AWS Console has one of two versions of the same default favicon (<img loading="lazy" width="16" height="16" src="https://betterdev.blog/app/uploads/2020/10/aws-favicon-1.png" alt=""> and <img loading="lazy" width="16" height="16" src="https://betterdev.blog/app/uploads/2020/10/aws-favicon-2.png" alt="">) is somehow astonishing. The fact that the other half has favicons in a few different styles, from 3D to flat, is just amusing. Well, we all know that the UI is not the AWS team priority, and the whole site looks a little bit like a Frankenstein’s monster.</p>



<p>But identical or inconsistent favicons are not only hurting someone’s sensitive UI feelings. It also makes it more difficult to quickly find one of 15 currently open AWS Console tabs during development. Or, worse case, while looking for the cause of an error on the production on some pleasant Friday afternoon.</p>



<p>With the Iconification extension, all services have their own favicons, from the official AWS architecture icons.</p>



<div><figure><img loading="lazy" width="719" height="86" src="https://betterdev.blog/app/uploads/2020/10/aws-simple-iconification-service-comparison.png" alt="" srcset="https://betterdev.blog/app/uploads/2020/10/aws-simple-iconification-service-comparison.png 719w, https://betterdev.blog/app/uploads/2020/10/aws-simple-iconification-service-comparison-300x36.png 300w" sizes="(max-width: 719px) 100vw, 719px"><figcaption>AWS Simple Iconification Service – favicon comparison</figcaption></figure></div>



<p>Available also for <a href="https://addons.mozilla.org/pl/firefox/addon/simple-iconification-service/">Firefox</a>.</p>



<h2><span id="ide_plugins"></span>IDE plugins<span></span></h2>



<h3><span id="aws_toolkit_for_jetbrains"></span>AWS Toolkit for JetBrains<span></span></h3>



<p>We can argue what IDE is the best, but for me, it’s always the ones from the JetBrains stable. Thus that list could not be missing the <a href="https://aws.amazon.com/intellij/"><strong>AWS Toolkit for JetBrains</strong></a> IDE.</p>



<p>There is a slowly growing list of services that the plugin supports. As I’m not building SAM applications, so far most useful for me are the S3, CloudWatch, and CloudFormation interfaces. Being able to operate with them directly from the IDE, sometimes easier and faster than going through the AWS Console in the browser, is really handy.</p>



<div><figure><img loading="lazy" width="533" height="295" src="https://betterdev.blog/app/uploads/2020/10/aws-toolkit-for-jetbrains.png" alt="" srcset="https://betterdev.blog/app/uploads/2020/10/aws-toolkit-for-jetbrains.png 533w, https://betterdev.blog/app/uploads/2020/10/aws-toolkit-for-jetbrains-300x166.png 300w" sizes="(max-width: 533px) 100vw, 533px"><figcaption>AWS Toolkit for JetBrains menu</figcaption></figure></div>



<p>The plugin works with all JetBrains IDE (IntelliJ, WebStorm, PyCharm, Rider, etc.).</p>



<h3><span id="aws_toolkit_for_vs_code"></span>AWS Toolkit for VS Code<span></span></h3>



<p>The <a href="https://aws.amazon.com/visualstudiocode/"><strong>AWS Toolkit for Visual Studio Code</strong></a> is a little bit younger brother of the Toolkit for JetBrains. Their development goes with similar, but not identical paths. Some features are available sooner in one of them.</p>



<p>I’m not using VS Code on a daily basis, but the AWS Toolkit for it is one of the reasons I launch it. It provides Amazon States Language graph preview, which is a great help when working a lot with Step Functions.</p>



<div><figure><a href="https://betterdev.blog/app/uploads/2020/10/vscode-step-functions-preview.png" target="_blank" rel="noopener noreferrer"><img loading="lazy" width="1024" height="597" src="https://betterdev.blog/app/uploads/2020/10/vscode-step-functions-preview-1024x597.png" alt="Step Function graph preview in VS Code" srcset="https://betterdev.blog/app/uploads/2020/10/vscode-step-functions-preview-1024x597.png 1024w, https://betterdev.blog/app/uploads/2020/10/vscode-step-functions-preview-300x175.png 300w, https://betterdev.blog/app/uploads/2020/10/vscode-step-functions-preview-768x448.png 768w, https://betterdev.blog/app/uploads/2020/10/vscode-step-functions-preview.png 1275w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>Step Function graph preview in VS Code (<a href="https://docs.aws.amazon.com/toolkit-for-vscode/latest/userguide/bulding-stepfunctions.html">source</a>)</figcaption></figure></div>



<p>This will stay on the list for now, at least until the <a href="https://github.com/aws/aws-toolkit-jetbrains/issues/584">same feature</a> is not available in the Toolkit for JetBrains.</p>



<h3><span id="serverless_framework_plugin"></span>Serverless Framework plugin<span></span></h3>



<p>The <a href="https://plugins.jetbrains.com/plugin/14537-serverless-framework-completion-navigation-syntax"><strong>Serverless Framework Completion/Navigation/Syntax</strong></a> plugin for IntelliJ provides support for writing Serverless stacks. While rather basic, it can help a lot. First, it warns of references to non-existing files or resources. Furthermore, the ability to click on the resource name or path and jump straight to the code is very useful and minimizes the scrolling and clicking through files.</p>



<h2><span id="architecture_diagrams"></span>Architecture diagrams<span></span></h2>



<p>Picture tells more than a thousand words. And a good software architecture diagram can tell more than any other kind of documentation. Especially when working in microservice or serverless environment.</p>



<h3><span id="omnigraffle"></span><img loading="lazy" width="65" height="65" src="https://betterdev.blog/app/uploads/2020/10/omnigraffle-logo.png" alt=""> OmniGraffle<span></span></h3>



<p>The <strong><a href="https://www.omnigroup.com/omnigraffle">OmniGraffle</a></strong> is a paid and Mac-only application for prototyping, design, and diagramming. My case is the latter and the application does a good job in that area. After remembering only a few shortcuts the work is intuitive and fast. Even if you are pedantic like me and everything on the diagram must be exactly aligned, with OmniGraffle it’s quick to do.</p>



<div><figure><a href="https://betterdev.blog/app/uploads/2020/10/omnigraffle-example.png" target="_blank" rel="noopener noreferrer"><img loading="lazy" width="1024" height="470" src="https://betterdev.blog/app/uploads/2020/10/omnigraffle-example-1024x470.png" alt="" srcset="https://betterdev.blog/app/uploads/2020/10/omnigraffle-example-1024x470.png 1024w, https://betterdev.blog/app/uploads/2020/10/omnigraffle-example-300x138.png 300w, https://betterdev.blog/app/uploads/2020/10/omnigraffle-example-768x352.png 768w, https://betterdev.blog/app/uploads/2020/10/omnigraffle-example.png 1168w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>OmniGraffle AWS architecture example</figcaption></figure></div>



<p>The nice feature is the <a href="https://stenciltown.omnigroup.com/">Stenciltown</a> – community-driven library of “stencils”. Stencils are packs of graphics that you can add and use in the OmniGraffle. Apart from that, there are also paid stencils over the internet.</p>



<p>If you use OmniGraffle and need AWS icons, <a href="https://stenciltown.omnigroup.com/stencils/aws-architecture-icons-light-all-2020-04/">here</a> is a stencil from me.</p>



<p>And if you want to create a stencil on your own, here is my tool that will do it for you: <a href="https://github.com/m-radzikowski/omnigraffle-stencil">OmniGraffle Stencil generator</a>.</p>



<h3><span id="diagrams_net_/_draw_io"></span><img loading="lazy" width="57" height="57" src="https://betterdev.blog/app/uploads/2020/10/diagrams-net-logo.png" alt=""> diagrams.net / draw.io<span></span></h3>



<p>The OmniGraffle app is great to use but has several drawbacks. It’s for macOS only and paid. Sometimes you cannot expect everyone to use it.</p>



<p>For such cases, I use <a href="https://www.diagrams.net/"><strong>diagrams.net</strong></a> (<a href="https://www.diagrams.net/blog/move-diagrams-net">previously known as draw.io</a>). It’s free and works in the browser, so everyone can edit the diagrams. And for Confluence, it’s really worth to buy an add-on that integrates it. Having editable diagrams in the same place as the rest of the documentation is the best thing possible.</p>



<div><figure><a href="https://betterdev.blog/app/uploads/2020/10/diagrams-net-example.png" target="_blank" rel="noopener noreferrer"><img loading="lazy" width="946" height="428" src="https://betterdev.blog/app/uploads/2020/10/diagrams-net-example.png" alt="" srcset="https://betterdev.blog/app/uploads/2020/10/diagrams-net-example.png 946w, https://betterdev.blog/app/uploads/2020/10/diagrams-net-example-300x136.png 300w, https://betterdev.blog/app/uploads/2020/10/diagrams-net-example-768x347.png 768w" sizes="(max-width: 946px) 100vw, 946px"></a><figcaption>diagrams.net AWS architecture example</figcaption></figure></div>



<p>Sadly, in comparison with OmniGraffle, while diagrams.net win in the accessibility category, the usability and user experience is, in my opinion, worse. Not bad, just worse.</p>



<h2><span id="summary"></span>Summary<span></span></h2>



<p>It’s not an especially long list. There are a lot more tools, toolkits, extensions, and plugins on the internet. From quite a few that I revied and tested only the ones above survived the time trial. Maybe some list of “tools for AWS that I do not use” can appear someday?</p>



<p>Of course, apart from AWS-related tools, there are a lot of different ones that I use. But it also may be a topic for another post.</p>



<p>Maybe you have some tools not listed here that you find extremely useful when working with AWS? Or at least ones that solve some minor inconveniences – that’s important as well. If so, let me know in the comments, and I will be happy to check them out!</p>



<p>Toolbox icon in the featured image made by <a href="https://smashicons.com/">Smashicons</a> from <a href="https://www.flaticon.com/">www.flaticon.com</a></p>
</div></div>]]>
            </description>
            <link>https://betterdev.blog/my-aws-toolbox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931347</guid>
            <pubDate>Thu, 29 Oct 2020 15:11:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data model extension approach to integration]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931311">thread link</a>) | @tablet
<br/>
October 29, 2020 | https://blog.fibery.io/fibery-approach-to-integration/ | <a href="https://web.archive.org/web/*/https://blog.fibery.io/fibery-approach-to-integration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<p>Fibery is a tool that connects different processes together. Think about Strategic Goals and Product Management, or Customers  Feedback and Ideation. It can replace many work management tools, but not all. Quite often you do want to use another tool like HubSpot, Intercom, or GitHub for a specific or complex process. How to provide natural and seamless connections between all these tools?</p>
<h2>Data Models</h2>
<p><small><a href="https://blog.fibery.io/the-knowledge-organization/">Here is the article</a> that describes various approaches to data models and explains why we selected the flexible one.</small> 
</p>
<p><strong>Data Model</strong> is an abstract model that organizes elements of data and defines how they relate to one another. Check the picture below that shows a simple data model:</p>
<p><span>
      <span></span>
  <img alt="data model" title="data model" src="https://blog.fibery.io/static/4955b0d9871b6c6c4e8624b22b447cb6/99f37/data-model.png" srcset="https://blog.fibery.io/static/4955b0d9871b6c6c4e8624b22b447cb6/6b2ea/data-model.png 275w,
https://blog.fibery.io/static/4955b0d9871b6c6c4e8624b22b447cb6/dd45a/data-model.png 550w,
https://blog.fibery.io/static/4955b0d9871b6c6c4e8624b22b447cb6/99f37/data-model.png 1100w,
https://blog.fibery.io/static/4955b0d9871b6c6c4e8624b22b447cb6/573d3/data-model.png 1650w,
https://blog.fibery.io/static/4955b0d9871b6c6c4e8624b22b447cb6/821da/data-model.png 2200w,
https://blog.fibery.io/static/4955b0d9871b6c6c4e8624b22b447cb6/8078c/data-model.png 2218w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>The main elements of the data model are:</p>
<ul>
<li><strong>Type</strong> represents data with fields. Like Type Goal has Name, Description, Deadline, and Priority</li>
<li><strong>Relation</strong> connects Types together. Like Goal has many Features.</li>
<li><strong>App</strong> is just a logical group of Types for convenience.  </li>
</ul>
<p>In most work management tools, data model is fixed. Let’s say, if you check the picture above, you can’t introduce User Stories or Epics, you just have Features and Tasks in Product Dev. App.</p>
<h2>A traditional approach to integration</h2>
<p>If you take almost any existing work management software like Trello or Asana, you will see that all integrations are hardcoded. Let’s say, you can link GitLab Merge Requests to Cards in Trello, but that is not automatic and you can’t link build status to a Card. Indeed, Trello has its own data model and it’s hard to extend it with an external tool domain. <strong>Every integration is hardcoded and provides fixed extension points</strong>.</p>
<p>The main problem with this approach is that <strong>the integration creator should foresee all important cases</strong>. Sometimes it’s easy to do, but in general, it’s a very hard problem. </p>
<ul>
<li>What if you want to see a list of recent builds with statuses? </li>
<li>What if you want to attach Merge Requests to Features instead of Tasks? </li>
<li>What if you want to visualize the latest Merge Request status for a Bug? </li>
</ul>
<p>What if we’ll not hardcode integrations, but just extend the data model? What if we’ll fetch data from an external system and allow you to do whatever you want with the data: connect entities together, visualize entities, and enhance entities with more data?</p>
<h2>External App → Fibery: Extend Data Model</h2>
<p>Fibery has an unfair advantage, it has a flexible data model 😜. It means <strong>Fibery can replicate the data model of any external tool</strong>. For example, it can fetch Companies, Contacts, Conversations, and Tags from Intercom and connect them together. Or it can fetch Projects, Branches, and Merge Requests from GitLab and connect them.</p>
<p><span>
      <span></span>
  <img alt="integration sync1" title="integration sync1" src="https://blog.fibery.io/static/76fb5d26dd57300be53a6a0387baa858/99f37/integration-sync1.png" srcset="https://blog.fibery.io/static/76fb5d26dd57300be53a6a0387baa858/6b2ea/integration-sync1.png 275w,
https://blog.fibery.io/static/76fb5d26dd57300be53a6a0387baa858/dd45a/integration-sync1.png 550w,
https://blog.fibery.io/static/76fb5d26dd57300be53a6a0387baa858/99f37/integration-sync1.png 1100w,
https://blog.fibery.io/static/76fb5d26dd57300be53a6a0387baa858/573d3/integration-sync1.png 1650w,
https://blog.fibery.io/static/76fb5d26dd57300be53a6a0387baa858/821da/integration-sync1.png 2200w,
https://blog.fibery.io/static/76fb5d26dd57300be53a6a0387baa858/31df8/integration-sync1.png 2366w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>Usually, you can’t freely manipulate data from an external system, but in Fibery you can do interesting things. Here are some examples:</p>
<ol>
<li>Automatically connect GitHub Pull Requests to User Stories.</li>
<li>Highlight text in Intercom Chats and create new Features/Bugs/Insights from them.</li>
<li>Automatically connect Chats from Intercom to Accounts from HubSpot CRM.</li>
<li>Create a field on a Feature that shows the status of the last GitLab Merge Request.</li>
<li>Create a chart that shows new HubSpot Accounts registration per month.</li>
<li>Create a Table that shows all GitLab Merge Requests attached to User Stories.</li>
</ol>
<h4>Automatically connect GitHub Pull Requests to User Stories.</h4>
<p>In this video, I show the flow of connecting Pull Requests to User Stories using auto-linking in Fibery.</p>

<h4>Highlight text in Intercom Chats and create new Features/Bugs/Insights from them.</h4>
<p>Here we already exported conversations from Intercom and I attach feedback to an Idea.</p>
<figure>
    <img src="https://blog.fibery.io/3ffce0a89b17fba0ada1779ff6bf4664/intercom-link.gif" alt="Option 2 looks like this: highlight text in Intercom Chats and create new Features/Bugs/Insights from them.">
    <figcaption></figcaption> 
</figure>
<h2>Native and Integration Types: The Great Unification</h2>
<p>It all means that Fibery native data and external systems data is unified, there is no difference between them!</p>
<p><small><b>Type</b> represents data: Task, Feature, Project, Vacation, Meeting, Asset, etc. Integration Types are created from an external system, Native Types are created manually in Fibery. </small> 
</p>
<p>Here is the snapshot of a Fibery workspace. As you see, there is not much difference between Integration and Native Types.</p>
<p><span>
      <span></span>
  <img alt="external data" title="external data" src="https://blog.fibery.io/static/7a21259ac51c142203f150b19aaf58fe/ddced/external-data.jpg" srcset="https://blog.fibery.io/static/7a21259ac51c142203f150b19aaf58fe/35f54/external-data.jpg 275w,
https://blog.fibery.io/static/7a21259ac51c142203f150b19aaf58fe/d7854/external-data.jpg 550w,
https://blog.fibery.io/static/7a21259ac51c142203f150b19aaf58fe/ddced/external-data.jpg 1100w,
https://blog.fibery.io/static/7a21259ac51c142203f150b19aaf58fe/670dc/external-data.jpg 1650w,
https://blog.fibery.io/static/7a21259ac51c142203f150b19aaf58fe/a40a7/external-data.jpg 2200w,
https://blog.fibery.io/static/7a21259ac51c142203f150b19aaf58fe/f145d/external-data.jpg 2320w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>Data unification unfolds the whole power of Fibery visualizations, connections, and enhancements for the external data. On an abstract level, you can create Views from it (Table, Board, Timeline), you can create Charts, you can add your own custom fields, thus augmenting imported data.</p>
<figure>
    <span>
      <span></span>
  <img alt="For example, for Intercom you can see a list of Conversations, create a chart that shows the most popular Tags, and connect Conversations to Accounts" title="For example, for Intercom you can see a list of Conversations, create a chart that shows the most popular Tags, and connect Conversations to Accounts" src="https://blog.fibery.io/static/a836119b2b4bbe1bfd098cf1d24948de/99f37/integration-value.png" srcset="https://blog.fibery.io/static/a836119b2b4bbe1bfd098cf1d24948de/6b2ea/integration-value.png 275w,
https://blog.fibery.io/static/a836119b2b4bbe1bfd098cf1d24948de/dd45a/integration-value.png 550w,
https://blog.fibery.io/static/a836119b2b4bbe1bfd098cf1d24948de/99f37/integration-value.png 1100w,
https://blog.fibery.io/static/a836119b2b4bbe1bfd098cf1d24948de/573d3/integration-value.png 1650w,
https://blog.fibery.io/static/a836119b2b4bbe1bfd098cf1d24948de/821da/integration-value.png 2200w,
https://blog.fibery.io/static/a836119b2b4bbe1bfd098cf1d24948de/8aace/integration-value.png 2732w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span>
    <figcaption>For example, for Intercom you can see a list of Conversations, create a chart that shows the most popular Tags, and connect Conversations to Accounts</figcaption>
  </figure>
<p>From the end-user perspective, internal/external data distinction does not exist, all data is here and readily available. </p>
<p>Here I create a chart that shows new Intercom Companies registration per month.</p>

<p>You can add Integration Types into existing Apps, or you can create new Apps that consist of Integration Types only. </p>
<p>The potential is huge. Eventually, it will be possible to bring all important data from external systems into a single place (Fibery) and connect the data. Let’s explore just one example.</p>
<p>Imagine, you are a software development company and use tools like GitLab, Intercom, HubSpot &amp; Google Analytics. You decided to use Fibery for work management. What benefits you can have by syncing the data between these external systems in Fibery? </p>
<p>Let’s focus on Accounts. Accounts are tracked in HubSpot and now you have all of them in Fibery. You can connect all Intercom conversations into Accounts and find the most active customers or leads. You can also connect Google Analytics data and track Accounts activity right there. You can mix all important data about Accounts in a single system.</p>
<p>Now let’s focus on Features. You can connect Merge Requests to Features and see Feature status. Then you can link feedback on Features from Intercom. Finally, you can track what Accounts requested what Features to make customer discovery calls or notify customers about feature completion.</p>
<figure>
    <span>
      <span></span>
  <img alt="Several external systems are connected together in Fibery" title="Several external systems are connected together in Fibery" src="https://blog.fibery.io/static/7bc86ad310e0b2b2704d48d8c7b453b5/99f37/integration-2.png" srcset="https://blog.fibery.io/static/7bc86ad310e0b2b2704d48d8c7b453b5/6b2ea/integration-2.png 275w,
https://blog.fibery.io/static/7bc86ad310e0b2b2704d48d8c7b453b5/dd45a/integration-2.png 550w,
https://blog.fibery.io/static/7bc86ad310e0b2b2704d48d8c7b453b5/99f37/integration-2.png 1100w,
https://blog.fibery.io/static/7bc86ad310e0b2b2704d48d8c7b453b5/573d3/integration-2.png 1650w,
https://blog.fibery.io/static/7bc86ad310e0b2b2704d48d8c7b453b5/821da/integration-2.png 2200w,
https://blog.fibery.io/static/7bc86ad310e0b2b2704d48d8c7b453b5/8aace/integration-2.png 2732w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span>
    <figcaption>Several external systems are connected together in Fibery</figcaption>
  </figure>
<p>When you have everything in sync in a single place, it opens up <em>unexpected</em> ways to handle feedback and customers interactions. </p>
<h2>Fibery → External App: Actions</h2>
<p><small>NOTE: This part of the integration strategy is not implemented yet. </small> 
</p>
<p>Everything above was about one-way-sync. But how to initiate actions in external systems? For example, create a new Merge Request from a Feature? Send a message to a Slack channel? We are going to solve this via Action concept. </p>
<p><strong>Action</strong> will be a first-class citizen in Fibery ecosystem. Here are some Action properties:</p>
<ul>
<li>Operate on native and integration Types.</li>
<li>Compose new Actions from existing Actions.</li>
<li>Invoke Action from different places: Button, console, Batch action, context menu, API call. </li>
</ul>
<figure>
    <span>
      <span></span>
  <img alt="Action concept and how it interacts with Types, UI, and Rules" title="Action concept and how it interacts with Types, UI, and Rules" src="https://blog.fibery.io/static/b34df8b394ecd5c56c3e7d0e388b04ce/99f37/actions-schema.png" srcset="https://blog.fibery.io/static/b34df8b394ecd5c56c3e7d0e388b04ce/6b2ea/actions-schema.png 275w,
https://blog.fibery.io/static/b34df8b394ecd5c56c3e7d0e388b04ce/dd45a/actions-schema.png 550w,
https://blog.fibery.io/static/b34df8b394ecd5c56c3e7d0e388b04ce/99f37/actions-schema.png 1100w,
https://blog.fibery.io/static/b34df8b394ecd5c56c3e7d0e388b04ce/573d3/actions-schema.png 1650w,
https://blog.fibery.io/static/b34df8b394ecd5c56c3e7d0e388b04ce/821da/actions-schema.png 2200w,
https://blog.fibery.io/static/b34df8b394ecd5c56c3e7d0e388b04ce/8aace/actions-schema.png 2732w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span>
    <figcaption>Action concept and how it interacts with Types, UI, and Rules</figcaption>
  </figure>
<p>To add Actions for any external system it will be required to implement a basic unified protocol.</p>
<p>This is just a hint into Actions future. Later Actions will become a part of <strong>Automation Rules</strong> module, where we will finally glue together Types, Events, and Actions.</p>
<h2>Conclusion</h2>
<p>We believe <em>Data and Actions unification</em> will empower Fibery to:</p>
<ol>
<li>Fetch all important data from any external system.</li>
<li>Connect data from various systems together, augment the data, and give people more insights into their work processes.</li>
<li>Do many actions from a single place and reduce tools distractions.</li>
</ol>
<p>And for us it will mean that we can implement integrations to the new systems extremely fast 💪.</p>
<p>We just <a href="https://help.fibery.io/en/articles/4539674-integration-basics">released Data Sync for several external Apps: Intercom, GitHub, GitLab and Trello</a>. Next steps are to add more external systems, implement Actions and make everything public to boost third-party integrations.</p>
<p>🦊 <a href="https://fibery.io/sign-up">Get your Fibery account</a>.</p></section></div>]]>
            </description>
            <link>https://blog.fibery.io/fibery-approach-to-integration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931311</guid>
            <pubDate>Thu, 29 Oct 2020 15:09:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An illustration of why running code during import is a bad idea (and how it hap]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930905">thread link</a>) | @todsacerdoti
<br/>
October 29, 2020 | https://utcc.utoronto.ca/~cks/space/blog/python/ImportTimeCodeStall | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/python/ImportTimeCodeStall">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>An illustration of why running code during <code>import</code> is a bad idea (and how it happens anyway)</h2>

	<p><small>October 29, 2020</small></p>
</div><div><p>It's a piece of received wisdom in Python programming that while
you can make your module run code when it's <code>import</code>'d, you normally
shouldn't. Importing a module is supposed to be both fast and
predictable, doing as little as possible. But this rule is not always
followed, and when it's not followed you can get <a href="https://twitter.com/thatcks/status/1321312639604137986">bad results</a>:</p>

<blockquote><p>If you've remotely logged in to a Fedora machine (and have no console
session there) and the python3-keyring package is installed, 'python3
-c "import keyring"' takes 25 seconds or so as the module tries to
talk to keyrings on import and waits for some long timeouts. Nice
work.</p>
</blockquote>

<p>(The <a href="https://github.com/jaraco/keyring">keyring</a> module (<a href="https://pypi.org/project/keyring/">also</a>) provides "an easy way to access the
system keyring service".)</p>

<p>On the one hand this provides yet another poster child of why running
code on import is very bad, since merely importing a module should
clearly not stop your Python program for 25 seconds. On the other
hand, I think that this case makes an interesting illustration of
how it is possible to drift into this state through a reasonably
sensible API choice.</p>

<p>Keyring has a notion of <em>backends</em>, which actually talk to the
various different system keyring services. To use keyring, you need
to pick a backend to use and initialize it, and by 'you' we mean
'keyring', because people calling keyring just want to use a generic
API without having to care what backend is in use on this system.
So when you import the <code>keyring</code> module, <a href="https://github.com/jaraco/keyring/blob/master/keyring/core.py">core.py</a>
picks and initializes a backend during the import:</p>

<blockquote><pre># init the _keyring_backend
init_backend()
</pre>
</blockquote>

<p>Automatically selecting and initializing a backend on import means
that keyring's API is ready for callers to use right away without
any further work. This is a friendly API, but assumes that everyone
who imports keyring will go on to use it. While this sounds reasonable,
a Python program may only need to talk to the keyring for some
operations under some circumstances, and may mostly never use it.
One such program is <a href="https://github.com/pypa/pip/pull/8687">pip</a>,
which needs the keyring only rarely but imports it all of the time.</p>

<p>(Unconditional imports are the obvious and Pythonic thing to do.
People look at you funny if your program does '<code>import</code>' in a
function or a class, and it's harder to use the result.)</p>

<p>However, selecting the backend on import has a drawback, at least
on Linux, which is that keyring has to figure out which system
keyring services are actually active right now, because in the Linux
way there's more than one of them (keyring supports <a href="https://secretstorage.readthedocs.io/en/latest/">SecretStorage</a> and direct use
of <a href="https://en.wikipedia.org/wiki/KWallet">KWallet</a>, plus third
party plugins). Since keyring has decided to choose the backend it
will use at import time, it has to determine which of its supported
system keyring services are active at import time.</p>

<p>Some of keyring's backends determine whether or not the corresponding
system service is active by trying to make a <a href="https://en.wikipedia.org/wiki/D-Bus">DBus</a> connection to the service.
Under the right (or the wrong) circumstances, <a href="https://github.com/jaraco/keyring/issues/473">this DBus action
can stall for a significant amount of time</a>. For instance, you
can see this in <a href="https://github.com/jaraco/keyring/blob/master/keyring/backends/kwallet.py">the kwallet backend code</a>;
it attempts to get the DBus object /modules/kwalletd5 from
org.kde.kwalletd5. Under some circumstances, this DBus action can
fail only after a long timeout, and now you have a 25 second <code>import</code>
delay.</p>

<p>This import delay isn't a simple case where the keyring module is
running a bunch of heavyweight code. Instead keyring is doing a
potentially dangerous operation by talking to an outside service
during import. It's not necessarily obvious that this is happening,
because you need to understand both what happens in a specific
backend and what's done at import time (and in isolation each piece
sounds sensible). And a lot of time talking to the outside service
will either work fine and be swift, or will fail immediately.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/python/ImportTimeCodeStall</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930905</guid>
            <pubDate>Thu, 29 Oct 2020 14:37:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Single use kitchen gadgets and the Unix philosophy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930858">thread link</a>) | @mcrittenden
<br/>
October 29, 2020 | https://critter.blog/2020/10/29/single-use-kitchen-gadgets-and-the-unix-philosophy/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/10/29/single-use-kitchen-gadgets-and-the-unix-philosophy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-2737">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Alton Brown famously hates single use kitchen gadgets, which he calls <em>unitaskers</em>:</p>



<figure><p><span><iframe width="580" height="327" src="https://www.youtube.com/embed/FgFeVlw2Ywg?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</p></figure>



<p>And yet the Unix philosophy says that programs should “do one thing and do it well.” Why does it work for command line tools but not kitchen gadgets?</p>



<p><em>(You may say “uh, because kitchen gadgets have nothing to do with command line tools?” And you’re right, but shut up. I’m cooking up a metaphor here.)</em></p>



<p>The answer is that Unix programs are chain-able. They integrate with each other. You can pipe the output from one into the input of another. That’s actually the lesser known second part of the Unix philosophy: “Write programs to work together.”</p>



<p>Kitchen gadgets are standalone. You can’t hook a strawberry slicer up to an egg cooker and expect magic to happen.</p>



<p>There’s a lesson here. Standalone development tools with generic inputs and outputs are good. Those tools follow the Unix philosophy. </p>



<p>But standalone development tools that you can’t pipe together are bad. Those are the single use kitchen gadgets of the development world. It’d be better to choose a tool that does many things than a tool that does one thing and only works in a silo.</p>



<p>I like to talk about Unix vs. Me-nix vs. We-nix (get it?).</p>



<ul><li><strong>The Unix philosophy: “Do one thing and do it well.”</strong></li><li><strong>The Me-nix philosophy: “Do one thing and go to hell.”</strong></li><li><strong>The We-nix philosophy: “Do lots of things pretty well.”</strong></li></ul>



<p>To take a real life example: say you’re building a recommendation engine. You could reach for something like AWS Personalize, a single use kitchen gadget (aka a Me-nix tool). Or you could grab something like Neo4j, a graph database that does lots of things including recommendations (aka a We-nix tool).</p>



<p>Go with AWS Personalize and you’ll be happy as long as you’re in its core use case. But say you grow out of that. Maybe you need to store and retrieve some arbitrary data about the user. Then it’s time to integrate. </p>



<p>And since integration with AWS Personalize isn’t as simple as piping, you’re going to have a bad time. You’ll be dealing with duplicate user records stored in many systems. You’ll need data in one system to inform data in the other. It all gets very mucky.</p>



<p>If only you had ditched the Me-nix tool and reached for the We-nix tool. You could have had a single source of truth for all of that arbitrary data, <em>and</em> generated recommendations based on it. </p>



<p>My rule of thumb is that Unix tools are best, but if you can’t find one, choose a We-nix tool over a Me-nix tool.</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/10/29/single-use-kitchen-gadgets-and-the-unix-philosophy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930858</guid>
            <pubDate>Thu, 29 Oct 2020 14:34:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ownership in the Age of DRM]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930824">thread link</a>) | @0goel0
<br/>
October 29, 2020 | https://goel.io/drm-ownership | <a href="https://web.archive.org/web/*/https://goel.io/drm-ownership">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>I’ve been thinking about what it means to own something. The definition that resonated the most with me is this<sup><a href="#footnote1">1</a></sup>:</p>

<blockquote>
  <p>You own what you can pass down</p>
</blockquote>

<p>It used to be common decades ago for people to pass down their property including media (vinyl records, disks, cassettes). You paid for hard assets that you owned.</p>

<p>Objectively, it’s easier to hold on to, and pass down, digital assets - you just have to change the “ownership” field in a database, or hand over a hard drive.</p>

<p>Instead, we got <a href="https://www.eff.org/issues/drm">Digital Rights Management</a>. DRM comprises of tools to lock down <em>who</em> has access to content, <em>where</em> it can be accessed, and for <em>how long</em>.</p>

<p>Simply put, if you buy an album on iTunes, it’s DRM protected. You cannot watch it on an Android device. Legally, you can’t even share it with your partner or family.</p>

<p>If you buy an ebook on Amazon, you merely get a license to read it. If Amazon decides they don’t like you as a customer and delete your account, you lose your book. Or, if your Kindle dies, you can’t just open the book on your computer or phone.</p>

<p>Using DRM, media companies can prosecute anyone that trying to transfer a Blu-Ray movie to their own computer.</p>

<p>That’s not ownership. In the digital age, we merely borrow when we “buy”.</p>

<p>To me, I only own media if:</p>

<ul>
  <li>I can store it on any device I own</li>
  <li>I can transfer it freely between devices I own</li>
  <li>I can consume it through any device<sup><a href="#footnote2">2</a></sup></li>
  <li>The seller cannot take it away from me</li>
  <li>I can transfer ownership freely</li>
</ul>

<p>Based on that criteria, the following are not ownership:</p>

<ul>
  <li>Netflix, Spotify, Pandora (is that still a thing) etc</li>
  <li>iTunes</li>
  <li><a href="https://www.salon.com/2013/03/01/do_you_truly_own_your_e_books/">Kindle books</a></li>
  <li>Blu-Ray disks (and some DVDs)</li>
  <li>Gaming console disks, or digital games (Steam)</li>
</ul>

<p>The only media marketplace I use that meets that criteria is <a href="https://bandcamp.com/">Bandcamp</a> where you buy music directly from artists and get to download it.</p>

<p><img src="https://goel.io/assets/img/posts/2020/2020-07-02-ownership-drm.png" alt="">
<em><a href="https://nadasurf.bandcamp.com/">Nada Surf</a> is an awesome alt-rock band!</em></p>

<p>I prefer straight up MP3 files. That’s what doing digital media the right way looks like.</p>

<p>Don’t get me wrong. For creators piracy is a big problem. Some common reasons for piracy and illegal media sharing are:</p>

<ul>
  <li>Not available in consumers’ region</li>
  <li>Delayed release in consumers’ region</li>
  <li>Not convenient to purchase</li>
  <li>Not convenient to consume the media (DRM)</li>
</ul>

<p>However, DRM is not a solution. It’s a duct tape on a crumbling building.</p>

<p>I do recognize that creators have bills and should be paid fairly for their work. I will continue to pay for my media (that’s both “bought” and <em>bought</em>) as well support creators directly (Patreon etc).</p>

<hr>

<p><a name="footnote1">1</a>: I did not come up with this, but I also can’t find out where I read/watched/listened this idea. If you do, let me know.</p>

<p><a name="footnote2">2</a>: I don’t necessarily mean that if the latest video or audio codec is not supported on Android for example, then the media encoded in that codec breaks my criterion. However the codec spec must be open and not proprietary for alternative implementations.</p>

  </div></div>]]>
            </description>
            <link>https://goel.io/drm-ownership</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930824</guid>
            <pubDate>Thu, 29 Oct 2020 14:31:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Graph Neural Networks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930676">thread link</a>) | @nikita30
<br/>
October 29, 2020 | https://heartbeat.fritz.ai/introduction-to-graph-neural-networks-c5a9f4aa9e99 | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/introduction-to-graph-neural-networks-c5a9f4aa9e99">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><h2 id="47cc">Graph neural networks — their need, real-world applications, and basic architecture with the NetworkX library</h2><div><div><div><p><a href="https://medium.com/@nikitasharma_43692?source=post_page-----c5a9f4aa9e99--------------------------------" rel="noopener"><img alt="Nikita Sharma" src="https://miro.medium.com/fit/c/96/96/1*vEIrEpXU4y727YADsJSNaA.jpeg" width="48" height="48"></a></p></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="An image of a light fixture with multiple bulbs. All of the lights are connected with straight or bent lines to the plug." src="https://miro.medium.com/max/4156/1*gkanLNHVltDw3AjHv54JWg.jpeg" width="2078" height="3320" srcset="https://miro.medium.com/max/552/1*gkanLNHVltDw3AjHv54JWg.jpeg 276w, https://miro.medium.com/max/1104/1*gkanLNHVltDw3AjHv54JWg.jpeg 552w, https://miro.medium.com/max/1280/1*gkanLNHVltDw3AjHv54JWg.jpeg 640w, https://miro.medium.com/max/1400/1*gkanLNHVltDw3AjHv54JWg.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/38/1*gkanLNHVltDw3AjHv54JWg.jpeg?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@bracht?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Fabio Bracht</a> on <a href="https://unsplash.com/s/photos/connection?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Unsplash</a></figcaption></figure><p id="5781">In this post, we are going to investigate a relatively newer field in deep learning which involves graphs — a very important and widely used data structure. This post encompasses the basics of graphs, the amalgamation of graphs and deep learning, and a basic idea about graph neural networks and their applications. We will also briefly discuss on how to build graphs with a Python library called NetworkX</p><p id="e390"><em>So, let’s dive right in!</em></p><p id="d06d">In the world of computer science, graphs are a type of data structure having two components: Nodes (or vertices) and edges, which connect two nodes. Thus, a graph can be defined as a collection of loosely inter-connected nodes via edges.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7954/1*1ASEWlSzqsGJdDwht4Pi0Q.jpeg" width="3977" height="1690" srcset="https://miro.medium.com/max/552/1*1ASEWlSzqsGJdDwht4Pi0Q.jpeg 276w, https://miro.medium.com/max/1104/1*1ASEWlSzqsGJdDwht4Pi0Q.jpeg 552w, https://miro.medium.com/max/1280/1*1ASEWlSzqsGJdDwht4Pi0Q.jpeg 640w, https://miro.medium.com/max/1400/1*1ASEWlSzqsGJdDwht4Pi0Q.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*1ASEWlSzqsGJdDwht4Pi0Q.jpeg?q=20"></p></div></div></div><figcaption>Image Source: <a href="https://medium.com/data-structures-and-algorithms/graph-dd2b72c32f1f" rel="noopener">https://medium.com/data-structures-and-algorithms/graph-dd2b72c32f1f</a></figcaption></figure><p id="8e01">The<strong> </strong>nodes of a graph can be homogenous with all nodes having a similar structure, or heterogenous nodes having different types of structure. The edges define the relationship one node has with another. Edges can be bidirectional (from one node u to another v and vice versa), or unidirectional (from one node u to another node v). Edges can also be weighted — having a weight assigned to the edge that might depict the edge’s cost or importance.</p><p id="b3da"><em>An example:</em> Let us suppose a graph to be considered as a network of cities — the cities under observation being nodes and the roads connecting them being edges. Now, there can be various types of relevant problems that can be solved with graphs, such as finding out the shortest distance between cities (where roads can also be weighted as per the condition of the roads or traffic), or finding the cities which are well-connected to each other, etc.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1300/1*ao-FSJHJ-cGU_yYCxTOA3A.png" width="650" height="404" srcset="https://miro.medium.com/max/552/1*ao-FSJHJ-cGU_yYCxTOA3A.png 276w, https://miro.medium.com/max/1104/1*ao-FSJHJ-cGU_yYCxTOA3A.png 552w, https://miro.medium.com/max/1280/1*ao-FSJHJ-cGU_yYCxTOA3A.png 640w, https://miro.medium.com/max/1300/1*ao-FSJHJ-cGU_yYCxTOA3A.png 650w" sizes="650px" data-old-src="https://miro.medium.com/max/60/1*ao-FSJHJ-cGU_yYCxTOA3A.png?q=20"></p></div></div><figcaption>Image Source: <a href="https://www.raywenderlich.com/773-swift-algorithm-club-graphs-with-adjacency-list" rel="noopener">https://www.raywenderlich.com/773-swift-algorithm-club-graphs-with-adjacency-list</a></figcaption></figure><h2 id="878f">What are Graph Neural Networks (GNN)?</h2><p id="85e3">Graphs have tremendous expressive powers and are therefore gaining a lot of attention in the field of machine learning. Every node has an embedding associated with it that defines the node in the data space. Graph neural networks refer to the neural network architectures that operate on a graph. The aim of a GNN is for each node in the graph to learn an embedding containing information about its neighborhood (nodes directly connected to the target node via edges). This embedding can then be used for different problems like node labelling, node prediction, edge prediction, etc.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2286/1*7VzFWjVoAdqrDBRQWCPvnA.png" width="1143" height="508" srcset="https://miro.medium.com/max/552/1*7VzFWjVoAdqrDBRQWCPvnA.png 276w, https://miro.medium.com/max/1104/1*7VzFWjVoAdqrDBRQWCPvnA.png 552w, https://miro.medium.com/max/1280/1*7VzFWjVoAdqrDBRQWCPvnA.png 640w, https://miro.medium.com/max/1400/1*7VzFWjVoAdqrDBRQWCPvnA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*7VzFWjVoAdqrDBRQWCPvnA.png?q=20"></p></div></div></div><figcaption>Each node and its neighborhood</figcaption></figure><p id="8b2f">Thus, after having embeddings associated with each node, we can convert edges by adding feed forward neural network layers and combine graphs and neural networks.</p><h2 id="b3df">Need for Graph Neural Networks</h2><p id="e37c">The need for graph neural networks arose from the fact that a lot of data available to us is in an unstructured format. Unstructured data is data that has not been processed or does not have a pre-defined format which makes it difficult to analyze. Examples of such data are audio, emails, and social media postings. To make sense of this data and to derive inferences from it, we need a structure that defines a relationship between these unstructured data points. The existing machine learning architectures and algorithms do not seem to perform well with these kinds of data. The primary advantages of graph neural networks are:</p><ol><li id="02e9">The graph data structure has proven tremendously successful in the field of computer science while working with unstructured data.</li><li id="43bd">Graphs are helpful in defining concepts which are abstract, like relationships between entities. Since each node in the graph is defined by its connections and neighbors, graph neural networks can capture the relationships between nodes in an efficient manner.</li></ol><p id="7936">Thus, developing GNNs for handling data like social network data, which is highly unstructured, is an exciting amalgamation of graphs and machine learning which holds a lot of potential.</p><h2 id="2fd5">Real-Life Applications of Graph Neural Network</h2><p id="58cb">Being introduced recently in 2018, the GNNs still have a lot of real-life applications because their architecture resonates with the irregularity in data collected from various sources. Currently, GNNs have been the hot topic for:</p><p id="6e5a"><strong>Social Network Analysis</strong> — Similar posts prediction, tags prediction, and recommending content to users.</p><p id="d34c"><strong>Natural Sciences </strong>— GNNs have also gained popularity in dealing with molecular interactions like protein-protein interactions.</p><p id="8b9e"><strong>Recommender Systems </strong>— A heterogenous graph can be used to capture relationships between users and items to recommend relevant items to a buyer.</p></div></div></section><section><div><div><p id="a689">After we have the basic structure of the graph neural network (nodes with their embeddings and edges with feed forward layers), we can move forward to understanding how GNNs actually work.</p><p id="0827">The basic idea is to learn neighborhood embeddings by aggregating information from a node’s neighbors via edges using neural networks.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2310/1*lPaI-f9FdVIQCmui2ljn2g.png" width="1155" height="537" srcset="https://miro.medium.com/max/552/1*lPaI-f9FdVIQCmui2ljn2g.png 276w, https://miro.medium.com/max/1104/1*lPaI-f9FdVIQCmui2ljn2g.png 552w, https://miro.medium.com/max/1280/1*lPaI-f9FdVIQCmui2ljn2g.png 640w, https://miro.medium.com/max/1400/1*lPaI-f9FdVIQCmui2ljn2g.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*lPaI-f9FdVIQCmui2ljn2g.png?q=20"></p></div></div></div><figcaption>Image source: <a href="http://snap.stanford.edu/proj/embeddings-www/files/nrltutorial-part2-gnns.pdf" rel="noopener">http://snap.stanford.edu/proj/embeddings-www/files/nrltutorial-part2-gnns.pdf</a></figcaption></figure><h2 id="0f02">Neighborhood Aggregation or Message Passing</h2><p id="99a1">Message passing refers to passing and receiving information between nodes about its neighborhood. Consider a target node having its initial embeddings: It receives information from its neighbors passed via edge neural networks. Data from these edges are aggregated (many techniques are used, like max pooling, averaging, etc.,) and passed to the activation unit of a node to get a new set of embeddings for the node. Every node in the initial setup has features x_v. The embeddings for each node after message passing can be defined as:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1708/1*XI7j33ktxcDbdqlHiUSBoQ.png" width="854" height="134" srcset="https://miro.medium.com/max/552/1*XI7j33ktxcDbdqlHiUSBoQ.png 276w, https://miro.medium.com/max/1104/1*XI7j33ktxcDbdqlHiUSBoQ.png 552w, https://miro.medium.com/max/1280/1*XI7j33ktxcDbdqlHiUSBoQ.png 640w, https://miro.medium.com/max/1400/1*XI7j33ktxcDbdqlHiUSBoQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*XI7j33ktxcDbdqlHiUSBoQ.png?q=20"></p></div></div></div><figcaption>taken from the research paper: <a href="https://arxiv.org/pdf/1812.08434.pdf" rel="noopener">https://arxiv.org/pdf/1812.08434.pdf</a></figcaption></figure><p id="f694">Where <em>x_ne[v]</em> denotes the features of the neighbors of <em>v, x_co[v]</em> is the edge features connected to <em>v, h_ne[v] </em>is the embedding of the neighbors of v.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2184/1*ysh3sKgHjKAsPWaoX_TA7g.jpeg" width="1092" height="612" srcset="https://miro.medium.com/max/552/1*ysh3sKgHjKAsPWaoX_TA7g.jpeg 276w, https://miro.medium.com/max/1104/1*ysh3sKgHjKAsPWaoX_TA7g.jpeg 552w, https://miro.medium.com/max/1280/1*ysh3sKgHjKAsPWaoX_TA7g.jpeg 640w, https://miro.medium.com/max/1400/1*ysh3sKgHjKAsPWaoX_TA7g.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*ysh3sKgHjKAsPWaoX_TA7g.jpeg?q=20"></p></div></div></div><figcaption>Image Source: <a href="http://snap.stanford.edu/proj/embeddings-www/files/nrltutorial-part2-gnns.pdf" rel="noopener">http://snap.stanford.edu/proj/embeddings-www/files/nrltutorial-part2-gnns.pdf</a></figcaption></figure><p id="21ec">In the above figure, hₐ⁽¹⁾ is the initial embedding of the node, hNₐ⁽¹⁾ is the aggregated embeddings of its neighbors. Combining these and passing to the node’s activation unit or filter will provide the new embedding for node A, which will also contain information about its neighbors. In this manner, each node gets a new set of embeddings for itself which determines its position in the graph. With various iterations or K layers of message passing, a node learns more and more about its neighborhood and its distant neighbors as well.</p><p id="34e2">Eventually, each node has a rough idea about the complete graph (or a part of it, depending on the number of iterations and node-node distance/path or layers considered).</p><p id="5d4b"><em>An example:</em> Consider a graph with social media posts as nodes. Now, if these nodes have embeddings and are labelled with tags like romance, science, comedy, etc., we get a new post and we need to provide it with a tag. Using the existing network and embeddings, neighborhood aggregation will help us predict the labels and embeddings for the unseen node.</p><p id="9d39"><strong>Advantage:</strong> Rather than running the entire algorithm again, we can just use embeddings of the neighbors to determine the locality of the new post. Therefore, GNN-based recommendation can be more efficient and scalable than other traditional machine learning recommendation algorithms out there for dealing large datasets.</p><p id="3b81">Graphs are used with various existing neural network architectures to yield promising results for various machine learning problems. The two most dominant networks are discussed briefly below.</p><h2 id="e7ab">Graph Convolutional Networks (GCNs)</h2><p id="9760">Convolutional neural networks(CNNs) have been vastly used for image classification and segmentation problems. Convolutional operation refers to applying a spatial filter to the input image and getting a feature map as a result.</p><p id="50dc"><em>You can read more about CNNs </em><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener"><em>here</em></a><em>.</em></p><p id="0205">GCNs refer to applying a spatially moving filter over the nodes of the graph which contains embeddings or data relevant to each node to get a feature representation of each node. Stacking a number of convolutional layers like a regular CNN can also be done to incorporate information from larger neighborhoods.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3200/1*gzid1GA297zfpZm1IWIDOQ.png" width="1600" height="796" srcset="https://miro.medium.com/max/552/1*gzid1GA297zfpZm1IWIDOQ.png 276w, https://miro.medium.com/max/1104/1*gzid1GA297zfpZm1IWIDOQ.png 552w, https://miro.medium.com/max/1280/1*gzid1GA297zfpZm1IWIDOQ.png 640w, https://miro.medium.com/max/1400/1*gzid1GA297zfpZm1IWIDOQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*gzid1GA297zfpZm1IWIDOQ.png?q=20"></p></div></div></div><figcaption>Image source: <a href="https://www.experoinc.com/post/node-classification-by-graph-convolutional-network" rel="noopener">https://www.experoinc.com/post/node-classification-by-graph-convolutional-network</a></figcaption></figure><h2 id="a5c8">Graph Auto-Encoder Networks</h2><p id="b199">Auto-encoders are neural networks which consist of two networks combined via a bottleneck layer: An encoder, which downsamples the input by passing it through convolutional filters to provide the compact feature representation of the image, and a decoder<strong> </strong>which takes the representation provided by the encoder as input and tries to re-construct the input according to the same.</p><p id="1547">You can read more about auto-encoders <a href="https://en.wikipedia.org/wiki/Autoencoder" rel="noopener">here</a>.</p><p id="2eed">Graph auto-encoders try to learn a compact representation of the graph and then re-construct the graph using the decoder. They can be used to learn graph embeddings and hence can be used for predicting embeddings for un-seen nodes and to classify newer nodes into existing categories within the graph.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1658/1*ywcpaQbVybK3BYm7gO_xAw.jpeg" width="829" height="270" srcset="https://miro.medium.com/max/552/1*ywcpaQbVybK3BYm7gO_xAw.jpeg 276w, https://miro.medium.com/max/1104/1*ywcpaQbVybK3BYm7gO_xAw.jpeg 552w, https://miro.medium.com/max/1280/1*ywcpaQbVybK3BYm7gO_xAw.jpeg 640w, https://miro.medium.com/max/1400/1*ywcpaQbVybK3BYm7gO_xAw.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*ywcpaQbVybK3BYm7gO_xAw.jpeg?q=20"></p></div></div></div><figcaption>Image source: <a href="https://www.frontiersin.org/articles/10.3389/fdata.2019.00002/full" rel="noopener">https://www.frontiersin.org/articles/10.3389/fdata.2019.00002/full</a></figcaption></figure><p id="74b3"><em>Other kinds of graph neural networks like spatial and temporal graph neural networks, generative graph neural networks, recurrent graph neural networks, etc., have also been developed.</em></p><p id="f4ee">NetworkX, as mentioned in its documentation, is a “Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.”<em> </em>Let’s learn how to build graphs with NetworkX:</p><p id="f7b4"><strong>Install NetworkX:</strong></p><pre><span id="0b40">pip install networkx</span></pre><p id="c40f"><strong>Creating a graph:</strong></p><pre><span id="2aa8"><strong>import</strong> <strong>networkx</strong> <strong>as</strong> <strong>nx</strong><br>G = nx.Graph()<br>#defines an empty graph</span></pre><p id="dabb"><strong>Adding nodes to the graph:</strong></p><pre><span id="01dc">#adds node 1<br>G.add_node(1)<br>#adds nodes from any iterable like list<br>G.add_nodes_from([2, 3])</span></pre><p id="b044"><strong>Adding edges to the graph:</strong></p><pre><span id="687a">#adding an edge from first node to another<br>G.add_edge(1, 2)<br>#adding edges from a list<br>G.add_edges_from([(1, 2), (1, 3)])<br>#adding a weighted edge<br>G.add_edge(1, 2, weight=4.5)</span></pre><p id="3a10">In this manner, we can construct a graph that we want to work on. Here is a simple example to find the shortest path between two nodes:</p><pre><span id="2163">import networkx as nx<br>G = nx.Graph()<br>G.add_ed…</span></pre></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://heartbeat.fritz.ai/introduction-to-graph-neural-networks-c5a9f4aa9e99">https://heartbeat.fritz.ai/introduction-to-graph-neural-networks-c5a9f4aa9e99</a></em></p>]]>
            </description>
            <link>https://heartbeat.fritz.ai/introduction-to-graph-neural-networks-c5a9f4aa9e99</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930676</guid>
            <pubDate>Thu, 29 Oct 2020 14:19:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The digital world has become primary – the physical world is now just the mirror]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930323">thread link</a>) | @lawschool333
<br/>
October 29, 2020 | https://www.pairagraph.com/dialogue/5e569e6fbc944e998c79502820c3b0c9/1?2 | <a href="https://web.archive.org/web/*/https://www.pairagraph.com/dialogue/5e569e6fbc944e998c79502820c3b0c9/1?2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.pairagraph.com/dialogue/5e569e6fbc944e998c79502820c3b0c9/1?2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930323</guid>
            <pubDate>Thu, 29 Oct 2020 13:38:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I built a dashboard template and sold it for $90.000]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930252">thread link</a>) | @pixelcave
<br/>
October 29, 2020 | https://pixelcave.com/blog/how-i-built-a-dashboard-template-and-sold-it-for-90000-usd | <a href="https://web.archive.org/web/*/https://pixelcave.com/blog/how-i-built-a-dashboard-template-and-sold-it-for-90000-usd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-content">
                        <p>I bought my first PC back in 1998 and started experimenting with web design a few years later. It was amazing how easily you could create web pages with rich content and navigate between them just like in interactive desktop apps. Let’s not talk about all those texture backgrounds along with animated gifs that no one could resist using. It was a playground and I loved it.</p>

<p>Microsoft Frontpage and Macromedia Dreamweaver (which was later acquired by Adobe) were the first tools I used to design and code websites just for the fun of it. At first, it was a more ‘what you see is what you get’ (WYSIWYG) approach but soon, I started playing more directly with HTML and CSS through Dreamweaver’s code editor.</p>

<p>A passion was born with various fun web projects being built on the side. I loved that aspect and while I was studying for my bachelor’s degree in Informatics, I got involved with all the web projects I could find. Those included web development and helped me improve my skills in those areas as well.</p>

<p>The idea that I might be able to work online from my home quickly became an obsession back then. In 2009, demand for web applications was rising, so I started experimenting with dashboard templates and eventually, 3 projects were created and released in the next 3 years.</p>

<p>I built them in my free time while I was working with a tech company on a few web apps and studying for my master’s degree at the same time. They did just ok but a whole new world was opened in front of me.</p>

<p>Unfortunately, due to the various responsibilities I had at the time, I kept postponing any further action but I eventually did a dynamic comeback in 2013 when I was ready to put all my energy into designing and coding dashboard templates full-time.</p>

<h3>Passionate with UI design</h3>

<p>You’ve heard before that you need to love your work if you would like to be successful but that’s only half the story. Loving what you do can motivate you, inspire you and make things a bit easier but that’s not necessarily enough in the long run.</p>

<p>I was and I am extremely passionate with UI design and coding. Back then, I used Photoshop to design each project and afterwards, I did my best to code it into HTML/CSS and make sure it works great in each major desktop and mobile browser. I used to spend so many hours testing and making sure that the result would be as perfect as possible based on my skills.</p>

<p>In 2013, I was able to build and release 3 more projects which were built with love and care. That’s also when the mottos “Crafted with love” and “Happy coding” came to life and follow pixelcave since then. The templates did good but unfortunately it was nothing sustainable.</p>

<p>I loved what I was doing and felt really good designing and coding but that on its own wasn’t enough. I needed to start thinking differently because if the whole plan didn’t work out, pixelcave most probably wouldn’t exist today.</p>

<h3>What people need</h3>

<p>I knew that I needed to deliver value to the people using those projects and save them time, so I had to do a far better job researching their needs before even start creating the next project, <a href="https://pixelcave.com/products/proui">ProUI</a>. It might seem obvious now but wasn’t the case back then.</p>

<p>I went through all the feedback (emails and comments) I had received from the first 3 projects and kept putting together a list of all the things people liked, struggled with, or wish they had. A few things on the list kept coming back, so I knew that those were crucial, and I had to prioritize them.</p>

<p>Next up, I researched public feedback regarding similar projects and got a feeling of what didn’t work and the problems most of the people were having when using such products. There were many issues that also kept coming back, so I’ve already had a good list of features and solutions that I had to work on ProUI.</p>

<p>What kept me researching for a while was the feeling that creating another project in the same way, would give me the same mediocre results. You can’t expect to have a different outcome when doing the same things repeatedly. I’m glad I’ve followed that path before getting my hands dirty and start coding the new template.</p>

<h3>Deliver under pressure</h3>

<p>This project was everything back then because its success or failure would completely change my life. If it didn’t work, it was the end of my working from home career and I had to completely change my approach and start looking for alternatives. There was no money or time to waste and for my mind, it was a matter of survival, I wanted it to succeed so much.</p>

<p>That was the perfect timing and the pressure helped me take it very seriously. I tried to be positive and passionate about the result and kept working day and night towards making a great product. It’s funny how pressure can help or harm your work. I have experienced both outcomes in the past but thankfully it was one of the things that pushed me forward, helped me overcome my fears and boosted my creativity. ProUI was live and the pressure had delivered. Sales started coming in, a new world appeared in front of my eyes and I knew that nothing was going to be the same again.</p>

<h3>Be original</h3>

<p>ProUI was designed and coded from scratch by hand. In contrary to the way other products were created by only using readymade layouts, navigation elements and other major building blocks, ProUI foundation was based on a solid structure built exclusively for it. I think that’s what gave it an identity in the first place and helped it in the long run.</p>

<p>I did my best to implement many popular features, provide solutions to issues people were experiencing, make a template that is straightforward, easy to use and most importantly that works as advertised. When inspiration hit, personal design touches were applied to make the design original and give it the feeling of a fresh experience.</p>

<h3>Test everything like crazy</h3>

<p>Testing was one of the main features of ProUI and continue being for all current projects. It might be simpler now with most popular browsers being chromium-based but that wasn’t the case back in the days. Internet Explorer 8 was the baseline and the newly introduced popularity of mobile browsers with their own set of issues wasn’t making things any better.</p>

<p>Responsive design was in its glory days and started becoming mainstream back in 2013 but testing tools weren’t on par yet. I still remembered resizing the browser like 1000 times each day to ensure that all content would appear as supposed to from mobile screens up to desktop monitors.</p>

<p>Testing on devices was also a big issue because I only had access to 2 older smartphones. New devices kept releasing at the time with various browsers popping up, so my solution was to visit stores for testing on their promo devices! I uploaded versions of the work-in-progress template to the demo server and tested it against various devices, from Macbooks to iPhones, iPads, and latest Android devices.</p>

<p>One of the main issues people were experiencing at the time was the poor mobile performance, so I was determined to make ProUI as fast and responsive as possible. During my visits, I kept notes and tried to fix the bugs when I got back home on the fly hoping that they will work. Of course, that wasn’t always the case, so visiting the stores became part of my weekly work schedule! I switched stores occasionally, so it doesn’t get too awkward...</p>

<p>Thankfully, the effort fulfilled its purpose and ProUI was released in a good stable state. I kept visiting the stores for a few months though (before I was able to get my hands on my own testing devices) to handle any reported bugs. My goal was to always reply in less than 24hrs during business days to support requests (something that I still do), so there were days of me rushing through stores to handle the situation. I tried to keep it cool with my responses despite the store situation (how professional is to test against demo devices in a store?) but in the end, I want to believe that the effort and care I gave, really paid off and helped ProUI be as bug free as possible.</p>

<h3>Balance time and delivery</h3>

<p>I learned that you must keep a balance between the features you want to implement in your project and the time it takes you to do it. It’s far better to integrate less and put your project out there sooner than trying to make it as complete as possible.</p>

<p>While building ProUI, bills kept coming in, which in the end I think helped me because I had to put it out there as quickly as possible. That might not made it the perfect release I might had in my mind but in the end, ProUI provided value and helped people in their projects.</p>

<h3>Not knowing stuff</h3>

<p>This is important and seems to apply in everything I do. As you learn more about your product’s market or about the tech you are using, it gets harder and harder to put something out there. You analyze everything way too much and easily spot the things that might go, or you do wrong.</p>

<p>There was this guy, who started selling WordPress plugins without knowing much about the market but focused on creating great products. After managing to reach 1 million in sales, he stated that if he knew the things he discovered afterwards, he would probably have never started selling WordPress plugins in the first place because it would be too difficult for him.</p>

<p>It was early days, and this is how I felt when I was building ProUI. It was liberating not analyzing what works and what doesn’t and focus on the product itself. Since then, I try to keep a balance between the things I discover and the things I want to experiment with when working on something. It’s exactly like the designer who redesigns his website and before he even finishes, he already finds the new design awful. Don’t be like that, try to fight back!</p>

<h3>Being perfect is subjective</h3>

<p>I would describe myself as perfectionist, but I try not to. Thankfully, the characterization does not apply, most of the time. When you are aiming for perfection, the only one you satisfy is yourself. You set the bar of perfection based on the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pixelcave.com/blog/how-i-built-a-dashboard-template-and-sold-it-for-90000-usd">https://pixelcave.com/blog/how-i-built-a-dashboard-template-and-sold-it-for-90000-usd</a></em></p>]]>
            </description>
            <link>https://pixelcave.com/blog/how-i-built-a-dashboard-template-and-sold-it-for-90000-usd</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930252</guid>
            <pubDate>Thu, 29 Oct 2020 13:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The all-new Open Web Components (new site, and setup)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930209">thread link</a>) | @d4kmor
<br/>
October 29, 2020 | https://open-wc.org/blog/the-all-new-open-web-components/ | <a href="https://web.archive.org/web/*/https://open-wc.org/blog/the-all-new-open-web-components/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper"><div><main><img src="https://open-wc.org/blog/the-all-new-open-web-components/images/blog-header.jpg" alt=""><p>It has been an incredibly busy year for Open Web Components. A lot has happened behind the scenes and there is still more to come.</p><p>Let's talk about the obvious first.</p><h2 id="the-all-new-open-web-components-website"><a href="#the-all-new-open-web-components-website"></a>The all-new Open Web Components website</h2><p>As you may have noticed we completely restructured all our content. There is now a clear distinction between Guides and Documentation.</p><p>In <a href="https://open-wc.org/guides/">Guides</a> we focus more on step by step explanations while <a href="https://open-wc.org/docs/">Documentation</a> is meant as a reference book where you can look up all available options and configuration.</p><p>In Guides you can find some of our most popular pages like <a href="https://open-wc.org/guides/developing-components/codelabs/">Codelabs</a>, <a href="https://open-wc.org/guides/developing-components/code-examples/">Code Examples</a> or <a href="https://open-wc.org/guides/developing-components/publishing/">Publishing</a>. However we also added a complete new <a href="https://open-wc.org/guides/community/getting-started/">Community</a> section which showcases web component communities you can join and different Base Libraries and Component Libraries you should check out.</p><p>We also made the FAQ pages more prominent in a new knowledge section. There we share things like how <a href="https://open-wc.org/guides/knowledge/attributes-and-properties/">attributes and properties</a> or <a href="https://open-wc.org/guides/knowledge/events/">events</a> work.</p><p>Technically the new website is built using <a href="https://open-wc.org/blog/the-all-new-open-web-components/11ty.dev">eleventy</a>, <a href="https://rollupjs.org/">rollup</a>, and our own tools like Web Dev Server, Rollup HTML plugin, and MDJS. We use a service worker that caches the static HTML pages.</p><h2 id="cleaned-up-our-repo"><a href="#cleaned-up-our-repo"></a>Cleaned up our repo</h2><p>Over the last years, we have created different projects and recommendations. During this time certain projects have become deprecated as we moved on to different tools or approaches.</p><p>This doesn't mean that we've completely dropped support for these projects. While we don't feature them on the main website, we still maintain and support these projects. We don't develop any new features or functionalities, but we will continue to support bugfixes and in some cases update along with the dependent tooling.</p><p>The documentation for our legacy projects is maintained in the GitHub readmes:</p><h3 id="legacy-projects"><a href="#legacy-projects"></a>Legacy projects</h3><ul><li><a href="https://github.com/open-wc/es-dev-server">es-dev-server</a>: we rebranded it as <a href="https://modern-web.dev/docs/dev-server/overview/">web-dev-server</a></li><li><a href="https://github.com/open-wc/legacy/tree/master/packages/testing-karma">testing-karma</a> &amp; <a href="https://github.com/open-wc/legacy/tree/master/packages/karma-esm">karma-esm</a>: we now recommend <a href="https://modern-web.dev/docs/test-runner/overview/">web-test-runner</a></li><li><a href="https://github.com/open-wc/legacy/tree/master/packages/testing-karma-bs">testing-karma-bs</a>: we now recommend <a href="https://modern-web.dev/docs/test-runner/overview/">web-test-runner</a> &amp; <a href="https://modern-web.dev/docs/test-runner/browser-launchers/browserstack/">@web/test-runner-browserstack</a></li><li><a href="https://github.com/open-wc/legacy/tree/master/packages/rollup-plugin-index-html">rollup-plugin-index-html</a>: we now recommend <code>@web/rollup-plugin-html</code></li><li><a href="https://github.com/open-wc/legacy/tree/master/packages/webpack-import-meta-loader">webpack-import-meta-loader</a>: we now recommend <a href="https://www.npmjs.com/package/babel-plugin-bundled-import-meta">babel-plugin-bundled-import-meta</a></li><li><a href="https://github.com/open-wc/legacy/tree/master/packages/building-webpack">building-webpack</a>: we now recommend rollup over webpack</li><li><a href="https://github.com/open-wc/legacy/tree/master/packages/webpack-index-html-plugin">webpack-index-html-plugin</a>: we now recommend rollup over webpack</li><li><a href="https://github.com/open-wc/legacy/tree/master/packages/storybook-addon-web-components-knobs">storybook-addon-web-components-knobs</a>: storybook v6 has a new better knobs system</li></ul><p>We also moved out our <a href="https://github.com/open-wc/create">create</a> Generators into a dedicated repository - which is only our first step as we will later automate updating it's dependencies via a bot so you can always be sure you get the latest versions.</p><p>As we <a href="https://github.com/open-wc/open-wc/issues/1681">announced before</a>, we have moved some generic tools and recommendations to our new <a href="http://modern-web.dev/">Modern Web</a> project.</p><h2 id="change-our-setup"><a href="#change-our-setup"></a>Change our setup</h2><p>On top of moving out all "dusty" code, we changed the setup of our repository.</p><p>We are now using <a href="https://github.com/atlassian/changesets">changesets</a> to gives us more control about what gets released and how. With <a href="https://github.com/features/actions">github actions</a> we run our tests on multiple node versions (12 &amp; 14) and windows at the same time so we can make sure our tools don't break.</p><p>Additionally, our web testing is now performed by <a href="https://modern-web.dev/docs/test-runner/overview/">Web Test Runner</a> which runs web tests in all evergreen browsers within a GitHub action.</p><h2 id="return-focus-to-web-components"><a href="#return-focus-to-web-components"></a>Return focus to Web Components</h2><p>With all those general web development packages moved to <a href="https://modern-web.dev/">Modern Web</a> and all those legacy packages move out of the repo we can bring our focus back to web components.</p><p>You will see more web component specific guides and tools coming up.</p><p>One of those is our just recently released <a href="https://open-wc.org/docs/linting/eslint-plugin-lit-a11y/overview/">eslint-plugin-lit-a11y</a>. It features more than 20 rules that will help you write more accessible lit-html templates.</p><h2 id="issues-and-discussions"><a href="#issues-and-discussions"></a>Issues and discussions</h2><p>We do have a fair share of open issues which makes it sometimes hard to see/understand what are actual bugs/issues and what are feature requests or questions. Additionally, with all these packages some issues probably are not relevant anymore. We plan to clean this up in the upcoming weeks by</p><ol><li>Moving issues to the appropriate repository (if it's code got moved)</li><li>Moving feature requests into <a href="https://github.com/open-wc/open-wc/discussions">github discussions</a></li><li>This will leave only actual bugs in our <a href="https://github.com/open-wc/open-wc/issues">issue list</a> 💪</li></ol><p>We do hope this will make navigating out Github Page easier.</p><h2 id="joining-modern-web"><a href="#joining-modern-web"></a>Joining Modern Web</h2><p>This now also makes it more apparent that we are part of the <a href="https://modern-web.dev/discover/about/">Modern Web Family</a>.</p><p>So be sure to follow Modern Web on <a href="https://twitter.com/modern_web_dev">Twitter</a> and if you like what you see please consider sponsoring the project on <a href="https://opencollective.com/modern-web">Open Collective</a>.</p><p>Written with ♥️ &nbsp; by the Open Web Components Core Team</p></main></div></div></div>]]>
            </description>
            <link>https://open-wc.org/blog/the-all-new-open-web-components/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930209</guid>
            <pubDate>Thu, 29 Oct 2020 13:24:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Image of the Bulge of the Milky Way]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24930095">thread link</a>) | @colinprince
<br/>
October 29, 2020 | https://noirlab.edu/public/images/noirlab2027a/ | <a href="https://web.archive.org/web/*/https://noirlab.edu/public/images/noirlab2027a/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://noirlab.edu/public/images/noirlab2027a/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930095</guid>
            <pubDate>Thu, 29 Oct 2020 13:11:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to be a confident, new web developer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930080">thread link</a>) | @amontgomery19
<br/>
October 29, 2020 | https://blog.alanmontgomery.co.uk/how-to-be-a-confident-new-web-developer | <a href="https://web.archive.org/web/*/https://blog.alanmontgomery.co.uk/how-to-be-a-confident-new-web-developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1603933334983/ghrvJSKj5.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text">
<p>This may seem really simple, but sometimes just doing it, works. A lot of the time you will hesitate when wanting to try something different in web development. For example, if you have an idea of how to implement functionality, my advice is just to do it! Try it out. If it doesn't work, try something else - it's the best way to self learn as well after you have learned the basics and fundamentals.</p>

<p>Seeking good experienced advice from a web developer who knows what they are talking about is a great way to solidify and help you understand a problem. If you're stuck on an issue and you really can't understand how to fix or implement it, then sometimes, asking a senior or more experienced web developer will benefit you. They can pass knowledge and expertise on to you which you'll never forget!</p>

<p>I find a lot of times if I've hit a problem in web development I can't solve, taking a quick 5-minute break and coming back to the code helps massively. You can clear your head in the space of 5 minutes, get a new perspective on things, and get fresh ideas. Most of the time it works and it can work for you too!</p>
<p>These are just some pointers to keep in mind when you are developing and implementing new ideas/solutions after you've learnt the fundamentals and basics.</p>
<p>Ps. I've recently started a YouTube channel for coding tutorials, would love to see you over there.
<a target="_blank" href="https://bit.ly/alanmontgomerycoding">Alan Montgomery - Coding Tutorials</a></p>
<p>I also have an online course to help you get started as a web developer if you're only getting into it👇
<a target="_blank" href="https://beginnerwebdevelopment.com/">https://beginnerwebdevelopment.com</a></p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.alanmontgomery.co.uk/how-to-be-a-confident-new-web-developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930080</guid>
            <pubDate>Thu, 29 Oct 2020 13:09:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deploying a production ready Kubernetes Node+React platform in under 15 minutes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930062">thread link</a>) | @dominiek
<br/>
October 29, 2020 | https://blog.bedrock.io/deploying-a-production-ready-kubernetes-node-react-platform-in-under-15-minutes/ | <a href="https://web.archive.org/web/*/https://blog.bedrock.io/deploying-a-production-ready-kubernetes-node-react-platform-in-under-15-minutes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.bedrock.io/content/images/size/w300/2020/10/davide-cantelli-TczSLeQmn9M-unsplash.jpg 300w,
                            https://blog.bedrock.io/content/images/size/w600/2020/10/davide-cantelli-TczSLeQmn9M-unsplash.jpg 600w,
                            https://blog.bedrock.io/content/images/size/w1000/2020/10/davide-cantelli-TczSLeQmn9M-unsplash.jpg 1000w,
                            https://blog.bedrock.io/content/images/size/w2000/2020/10/davide-cantelli-TczSLeQmn9M-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.bedrock.io/content/images/size/w2000/2020/10/davide-cantelli-TczSLeQmn9M-unsplash.jpg" alt="Deploying a production ready Kubernetes Node+React platform in under 15 minutes">
            </figure>

            <section>
                <div>
                    <p><a href="https://github.com/bedrockio/bedrock-core">Bedrock Core</a> is an Open Source template that includes micro services, components and patterns that tie together Kubernetes, Elasticsearch, MongoDB, Node.js and React.</p><p>Bedrock Core was developed by me and several software developer friends over the past years in response to the fragmented application development landscape. It started out as a template to keep our own sanity, but over time we’ve improved on this with every production deployment.</p><p>I think APIs, data and infrastructure automation are corner stones of any modern application. The components inside Bedrock Core all work together and have been meticulously chosen to reduce the friction of developing production-grade platforms.</p><p>In this article I’ll show you how easy it is to create your own stack that includes full cloud ownership, DevOps automation, SysOps playbooks, JSON APIs, an API Portal, User Management and much more.</p><h3 id="generating-your-code-base">Generating Your Code Base</h3><p>To get started, run this in your Terminal to generate a new project: </p><pre><code>curl -s https://get.bedrock.io | bash
</code></pre><p>This script will prompt for your project name and intended domain:</p><figure><img src="https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.29.20-PM.png" alt="" srcset="https://blog.bedrock.io/content/images/size/w600/2020/10/Screen-Shot-2020-10-21-at-12.29.20-PM.png 600w, https://blog.bedrock.io/content/images/size/w1000/2020/10/Screen-Shot-2020-10-21-at-12.29.20-PM.png 1000w, https://blog.bedrock.io/content/images/size/w1600/2020/10/Screen-Shot-2020-10-21-at-12.29.20-PM.png 1600w, https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.29.20-PM.png 2062w" sizes="(min-width: 720px) 720px"></figure><p>You can let this script push to an empty Github repository or you can manually push it after the fact.</p><h3 id="your-mono-repo">Your Mono Repo</h3><p>You'll now have a mono repository that holds your entire platform:</p><ul><li><code>deployment/</code> - Kubernetes &amp; Terraform deployment automation and playbooks. This includes a full features backup system and data store deployment (Mongo, Elasticsearch, Data pipeline) for your platform.</li><li><code>services/api</code> - A Node.js API, enabled with authentication middleware, OpenAPI, Mongoose ORM and other best practices.</li><li><code>services/web</code> - A React Single Page App (SPA) that can interact with that API. Includes React Router, authentication screens, placeholder, API portal, dashboard and a repository of components and helper functions.</li><li>Documentation for all aspects of your new platform (Github markdown)</li><li>CI system</li></ul><figure><img src="https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.31.24-PM.png" alt="" srcset="https://blog.bedrock.io/content/images/size/w600/2020/10/Screen-Shot-2020-10-21-at-12.31.24-PM.png 600w, https://blog.bedrock.io/content/images/size/w1000/2020/10/Screen-Shot-2020-10-21-at-12.31.24-PM.png 1000w, https://blog.bedrock.io/content/images/size/w1600/2020/10/Screen-Shot-2020-10-21-at-12.31.24-PM.png 1600w, https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.31.24-PM.png 2260w" sizes="(min-width: 720px) 720px"><figcaption>Your CI system is already running using Github Actions</figcaption></figure><p>You can explore what this looks like simply by browsing the Bedrock Core repository: <a href="https://github.com/bedrockio/bedrock-core">https://github.com/bedrockio/bedrock-core</a></p><h3 id="your-first-deploy">Your First Deploy</h3><p>With a single script Bedrock Core can provision your infrastructure. All you need to do is create an empty Google Cloud project with a valid billing account. I recommend creating a new Google Cloud project for every environment (staging, production) - for security, separation and billing reasons.</p><pre><code>./deployment/scripts/provision_gcloud staging my-project-name</code></pre><p>All of this and much more is all described in the <code>deployments/README.md</code> documentation.</p><p>This script may prompt you to install G-Cloud CLI and Terraform if you haven't yet. The process can take up to a couple of minutes and will do the following:</p><ul><li>Enable the right services (e.g. Compute, Container) inside Google Cloud</li><li>Reserve IP addresses and auto-set these in the Kubernetes config files</li><li>Use Terraform to provision GCS Buckets, Disks and Kubernetes Cluster nodes</li><li>Use Docker to build and deploy all <code>services/</code></li></ul><p>Once completed, the script will show you the domains it's expecting:</p><figure><img src="https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.35.26-PM.png" alt="" srcset="https://blog.bedrock.io/content/images/size/w600/2020/10/Screen-Shot-2020-10-21-at-12.35.26-PM.png 600w, https://blog.bedrock.io/content/images/size/w1000/2020/10/Screen-Shot-2020-10-21-at-12.35.26-PM.png 1000w, https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.35.26-PM.png 1342w" sizes="(min-width: 720px) 720px"></figure><p>These can be changed at any time by modifying the Kubernetes configuration (e.g. <code>deployment/environments/staging/services/api-deployment.yml</code>) - More about this can be found in the SysOps playbooks.</p><figure><img src="https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.36.13-PM.png" alt="" srcset="https://blog.bedrock.io/content/images/size/w600/2020/10/Screen-Shot-2020-10-21-at-12.36.13-PM.png 600w, https://blog.bedrock.io/content/images/size/w1000/2020/10/Screen-Shot-2020-10-21-at-12.36.13-PM.png 1000w, https://blog.bedrock.io/content/images/size/w1600/2020/10/Screen-Shot-2020-10-21-at-12.36.13-PM.png 1600w, https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.36.13-PM.png 2260w" sizes="(min-width: 720px) 720px"><figcaption>Your Kubernetes Cluster is now running in Google Cloud</figcaption></figure><figure><img src="https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.35.56-PM.png" alt="" srcset="https://blog.bedrock.io/content/images/size/w600/2020/10/Screen-Shot-2020-10-21-at-12.35.56-PM.png 600w, https://blog.bedrock.io/content/images/size/w1000/2020/10/Screen-Shot-2020-10-21-at-12.35.56-PM.png 1000w, https://blog.bedrock.io/content/images/size/w1600/2020/10/Screen-Shot-2020-10-21-at-12.35.56-PM.png 1600w, https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.35.56-PM.png 2260w" sizes="(min-width: 720px) 720px"><figcaption>We highly recommend using Cloudflare to take care of DNS, SSL and CDN</figcaption></figure><p>Congratulations, your new platform is ready!</p><h3 id="running-locally">Running Locally</h3><p>So let's make some changes to our platform to get familiar with our codebase. In order to run the entire stack simply run Docker Compose your root:</p><pre><code>docker-compose up</code></pre><p>This will run MongoDB, the <code>services/api</code> and the <code>services/web</code> services. You can now access your app at <a href="http://localhost:2200/">http://localhost:2200</a>.</p><p><em>Note: You can also run your stack "naked" (without Docker) by executing <code>yarn start</code> in each service (requires MongoDB to be running locally).</em></p><p>Running the API will automatically create the needed database objects for you including the configured <code>ADMIN_EMAIL</code> and <code>ADMIN_PASSWORD</code> user. These will be displayed in the API console output.</p><p>You can now log into your dashboard where you will see the following:</p><ul><li>Example models - Shops &amp; Products - with full Create, Read, Update &amp; Delete (CRUD) functionality.</li><li>User management UI</li><li>User authentication flows (forgot password, login, logout, etc.)</li><li>API Portal - Curation-friendly powered by Github Markdown and OpenAPI</li></ul><figure><img src="https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.32.15-PM.png" alt="" srcset="https://blog.bedrock.io/content/images/size/w600/2020/10/Screen-Shot-2020-10-21-at-12.32.15-PM.png 600w, https://blog.bedrock.io/content/images/size/w1000/2020/10/Screen-Shot-2020-10-21-at-12.32.15-PM.png 1000w, https://blog.bedrock.io/content/images/size/w1600/2020/10/Screen-Shot-2020-10-21-at-12.32.15-PM.png 1600w, https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.32.15-PM.png 2260w" sizes="(min-width: 720px) 720px"><figcaption>Third party developers can integrate easily using your API portal.</figcaption></figure><h3 id="changing-the-ui">Changing the UI</h3><p>The code for the SPA is located in <code>services/web</code> and uses React, React Router and Semantic UI. The components communicate directly with the JSON API with simple utility functions - no complicated middleware.</p><p>Directory structure:</p><ul><li><code>src/index.html</code> - The server-side HTML that's used to load the assets and app. Used by Webpack to inject headers.</li><li><code>src/App.js</code> - The React Router that drives all SPA routing.</li><li><code>src/screens</code> - Every major screen (e.g. Products, Shops) that have routes to them.</li><li><code>src/components</code> - <a href="https://github.com/bedrockio/bedrock-core/tree/master/services/web/src/components">Various helper components</a> that can be used on top of Semantic UI.</li><li><code>src/utils</code> - <a href="https://github.com/bedrockio/bedrock-core/tree/master/services/web/src/utils">Various utility functions</a>. </li><li><code>src/assets</code> - Media files. The <code>src/assets/icon.svg</code> will automatically get converted to all the needed Favicon formats by Webpack.</li></ul><p>By default, the app uses React Semantic UI which provides theming capabilities on a large repository of components. Things such as fonts, primary colors, etc. can be easily edited by <a href="https://github.com/bedrockio/bedrock-core/tree/master/services/web#theming">changing the theme configuration</a>.</p><p>The <code>src/screens</code> components follow the information architecture set by the React Router ( <code>src/App.js</code>). So the CRUD UI for Shop/Products can be found in the following files:</p><ul><li><code>src/screens/Shop/Products.js</code> - A table view that lists products for a given Shop.</li><li><code>src/modals/EditProduct.js</code> - A Modal view that is used to Create or Update the Product object.</li></ul><p>These routes interact with the API in a standard rest structure <code>PATCH /1/products/:id</code> and <code>POST /1/products</code>. </p><p>For a full overview please see the <a href="https://github.com/bedrockio/bedrock-core/tree/master/services/web#bedrock-web">documentation</a> in <code>services/web/README.md</code>.</p><h3 id="changing-the-api">Changing the API</h3><p>The code for the JSON API that's used by the UI can be found in <code>services/api</code> and has the following directory structure:</p><ul><li><code>src/lib/utils</code> - Various helper functions</li><li><code>src/lib/__tests__</code> - Library level unit tests (Jest)</li><li><code>src/models</code> - Mongoose ORM models</li><li><code>src/v1</code> - Koa route files with Joi validators</li><li><code>src/v1/__openapi__</code> - OpenAPI documentation for each API</li><li><code>src/v1/__tests__</code> - API routes tests</li><li><code>src/app.js</code> - Main entry point into the API</li></ul><p>So making changes to the example Product model would typically involve changing the following files:</p><ul><li><code>src/models/product.js</code> - The model</li><li><code>src/v1/products.js</code> - The KOA Router with validators</li><li><code>src/v1/__tests__/products.js</code> - The unit test for the API routes</li><li><code>src/v1/__openapi__/products.json</code> - The API documentation for that route.</li></ul><h3 id="deploying-your-changes">Deploying your Changes</h3><p>Once you've made changes to any of the services, you can deploy the API using a single command:</p><pre><code>./deployment/scripts/deploy staging api
./deployment/scripts/deploy staging web</code></pre><p>This will build a new Docker container, push it and perform a rolling update of the new image.</p><figure><img src="https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.36.33-PM.png" alt="" srcset="https://blog.bedrock.io/content/images/size/w600/2020/10/Screen-Shot-2020-10-21-at-12.36.33-PM.png 600w, https://blog.bedrock.io/content/images/size/w1000/2020/10/Screen-Shot-2020-10-21-at-12.36.33-PM.png 1000w, https://blog.bedrock.io/content/images/size/w1600/2020/10/Screen-Shot-2020-10-21-at-12.36.33-PM.png 1600w, https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.36.33-PM.png 2258w" sizes="(min-width: 720px) 720px"><figcaption>Your custom platform is now live!</figcaption></figure><p><em>Note: All the steps in this article are also shown in this <a href="https://vimeo.com/443474352">15 minute video</a> that shows some example changes to the UI and the API.</em></p><h3 id="stay-tuned">Stay Tuned</h3><p>This is the first in a series of posts that elaborate on <a href="https://blog.bedrock.io/">Bedrock.io</a>. We are adding a lot more automation and tools to further reduce development friction and enhance platform capabilities.</p><p>In the mean time, give it a try, hack away, and <a href="https://bedrock.io/docs">reach out to us</a> if you'd like to be involved!</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.bedrock.io/deploying-a-production-ready-kubernetes-node-react-platform-in-under-15-minutes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930062</guid>
            <pubDate>Thu, 29 Oct 2020 13:07:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Something Old, Creatively and Lovingly Remade]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24929994">thread link</a>) | @marcacohen
<br/>
October 29, 2020 | https://mco.dev/under-pressure/ | <a href="https://web.archive.org/web/*/https://mco.dev/under-pressure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
            <div>
              <p>I love when an artist covers a great old song, not just following the original formula, but adding something special.</p>
<p>Johnny Cash’s version of Nine Inch Nails’ <em>Hurt</em> comes to mind. This one is in the same class of originality. An unlikely duo, Karen O and Willie Nelson, took a song just about everyone knows and loves and totally made it their own. Enjoy…</p>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/MEU-7uga_4A" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
              
            </div>
          </div></div>]]>
            </description>
            <link>https://mco.dev/under-pressure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929994</guid>
            <pubDate>Thu, 29 Oct 2020 12:58:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[While (auto x=y; z)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24929980">thread link</a>) | @ingve
<br/>
October 29, 2020 | https://quuxplusone.github.io/blog/2020/10/28/while-with-initializer/ | <a href="https://web.archive.org/web/*/https://quuxplusone.github.io/blog/2020/10/28/while-with-initializer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>This question has come up at least twice on the cpplang Slack now. C++ keeps
adding more and more knobs to <code>if</code> and <code>for</code> and <code>switch</code>; why hasn’t it
messed with <code>while</code>? Specifically, why isn’t there a “two-part while loop”?</p>

<p>C++ offers the following control structures (where “<code>init</code>” represents
the choice of either a declaration or an expression-statement):</p>

<div><div><pre><code>if (z)                     // '98
if (auto z=w)              // '98
if (init; z)               // C++17
if (init; auto z=w)        // C++17

if constexpr (z)           // all C++17
if constexpr (auto z=w)
if constexpr (init; z)
if constexpr (init; auto z=w)

for (init; z; ++x)         // '98
for (init; auto z=w; ++x)  // '98
for (auto e : r)           // C++11
for (init; auto e : r)     // C++20

while (z)                  // '98
while (auto z=w)           // '98
do { ... } while (z)       // '98

switch (z)                 // '98
switch (auto z=w)          // '98
switch (init; z)           // C++17
switch (init; auto z=w)    // C++17
</code></pre></div></div>

<p>Notably missing from the middle of this list: <code>while (init; z)</code> and
<code>while (init; auto z=w)</code>.</p>

<p>The reason <code>while (init; cond)</code> is missing is that there are two
reasonable interpretations of what it might mean. The Committee could
pick one behavior to be “correct”; but if they did that, programmers
would inevitably write the construct expecting the <em>other</em> behavior,
and then they’d have bugs.</p>

<h2 id="option-1-evaluate-the-init-only-once">Option 1: Evaluate the init only once</h2>

<p>Kirit Sælensminde offered the following use-case:</p>

<div><div><pre><code>auto cursor = getCursor();
while (auto item = cursor.next()) {
    use(item);
}
</code></pre></div></div>

<p>If this is your use-case, then it might seem unfortunate that you can’t
combine the declaration of <code>cursor</code> into the <code>while</code>-loop; it has to
“leak” into the outer scope. You might <em>want</em> to write</p>

<div><div><pre><code>while (auto c = getCursor(); auto item = c.next()) {
    use(item);
}
</code></pre></div></div>

<p>It turns out that you can actually write this loop in a way
that’s just as short, and arguably clearer (since it uses only
C++98 features): just use a <code>for</code> loop instead!</p>

<div><div><pre><code>for (auto c = getCursor(); auto item = c.next(); ) {
    use(item);
}
</code></pre></div></div>

<h2 id="option-2-evaluate-the-init-every-time">Option 2: Evaluate the init every time</h2>

<p>The other use-case for which you might want a two-part <code>while</code> loop is:</p>

<div><div><pre><code>int ch;
while ((ch = getchar()) != EOF) {
    use(ch);
}
</code></pre></div></div>

<p>If this is your use-case, then it might seem unfortunate that you can’t
combine the declaration of <code>ch</code> into the <code>while</code>-loop; it has to
“leak” into the outer scope. (And go uninitialized, too!) You might <em>want</em> to write</p>

<div><div><pre><code>while (int ch = getchar(); ch != EOF) {
    use(ch);
}
</code></pre></div></div>

<p>I’m not aware of any clean way to write this loop that avoids leaking
<code>ch</code> into the outer scope. I mean, I don’t consider any of these “clean”:</p>

<div><div><pre><code>for (int ch; (ch = getchar()) != EOF; ) {
    use(ch);
}

for (int ch = getchar(); ch != EOF; ch = getchar()) {
    use(ch);
}

while (true) {
    if (int ch = getchar(); ch != EOF) {  // C++17
        use(ch);
    } else {
        break;
    }
}
</code></pre></div></div>

<hr>

<p>So, given that there’s a clean way to write Option 1 already, and no equally clean way
to write Option 2, shouldn’t the Committee simply add Option 2 to the language? <strong>No.</strong></p>

<p>We can’t give programmers the ability to write</p>

<div><div><pre><code>while (int ch = getchar(); ch != EOF) { ... }
</code></pre></div></div>

<p>without <em>also</em> giving them the ability to shoot themselves in the foot with</p>

<div><div><pre><code>while (auto c = getCursor(); auto item = c.next()) {
    // repeatedly fetch the list and process just its first item,
    // over and over, forever
}
</code></pre></div></div>

<p>I’m happy to keep programming without a complicated “two-part <code>while</code> loop,”
if it means that other programmers are happily prevented from shooting themselves
in the foot.</p>

  </div></div>]]>
            </description>
            <link>https://quuxplusone.github.io/blog/2020/10/28/while-with-initializer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929980</guid>
            <pubDate>Thu, 29 Oct 2020 12:55:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Autonomous Security: Pushing Security Automation to the Next Level]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24929693">thread link</a>) | @alaeddine
<br/>
October 29, 2020 | https://blog.ostorlab.co/autonomous-security-scanning.html | <a href="https://web.archive.org/web/*/https://blog.ostorlab.co/autonomous-security-scanning.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2>Overview</h2>
<p>The Autonomous Cars Industry defines <a href="https://www.truecar.com/blog/5-levels-autonomous-vehicles/">6 levels of driverless vehicles</a>: </p>
<ul>
<li>L0 - No automation</li>
<li>L1 - Driver Assistance</li>
<li>L2 - Partial Automation</li>
<li>L3 - Conditional Automation</li>
<li>L4 - High Automation</li>
<li>L5 - Full Automation.</li>
</ul>
<p>While the world of SRE (Site Reliability Engineering) has already adopted the term <code>Autonomous System</code> to refer to the
judicious application of automation, the word <code>Autonomous Security</code> is not widely used by the Security industry.</p>
<blockquote>
<p>For SRE, automation is a force multiplier, not a panacea. Of course, just multiplying 
force does not naturally change the accuracy of where that force is applied: doing automation 
thoughtlessly can create as many problems as it solves. Therefore, while we believe that 
software-based automation is superior to manual operation in most circumstances, better 
than either option is a higher-level system design requiring neither of them—an autonomous system. 
Or to put it another way, the value of automation comes from both what it does and its 
judicious application.</p>
</blockquote>
<p>While no one will disagree that Security Automation is critical to scale security ops within any
organization. The size, diversity, and complexity in which we are operating make the current approach of having
humans and manual processes to address the volume vulnerabilities and incidents not so scalable. Scaling teams will
eventually be limited by how many people we can hire, scaling processes will eventually cripple an organization's
productivity.</p>
<p>The goal of <code>Autonomous Security</code> is to automate the decision process. In the context of vulnerability scanning, for instance, this
might take the form of <strong>quarantining a vulnerable machine, setting up a firewall rule or deploying a patch</strong>, in the 
context of incident response, this might take the form <strong>dumping memory for forensic analysis and reducing access to critical systems</strong>.</p>
<p>Achieving this high degree of automation cannot be done without effective technology and a feedback loop to measure what
works, what does not and detect what is missing.</p>
<p>The following article coins the term <code>Autonomous Security</code> in the context
of Security Scanning and outlines the required technological blocks and policies. The end goal is to automate
containment and use a feedback loop to address missing parts and blind spots.</p>
<p><img alt="alt text" src="https://blog.ostorlab.co/static/img/autonomous.png" title="Autonomous Loop"></p>
<p>The document defines 5 tiers to reflect the different maturity levels. In the next sections, we will define each block
and how its maturity level can be enhanced while achieving the goal of a fully <code>Autonomous System</code>.</p>
<table>
<thead>
<tr>
<th>Concept</th>
<th>T0</th>
<th>T1</th>
<th>T2</th>
<th>T3</th>
<th>T4</th>
</tr>
</thead>
<tbody>
<tr>
<td>Inventory &amp; Discovery</td>
<td>No Inventory</td>
<td>Manual Inventory</td>
<td>Partially Automated Inventory</td>
<td>Fully Automated Inventory</td>
<td>Fully Automated Inventory with discovery</td>
</tr>
<tr>
<td>Policy</td>
<td>No Policy</td>
<td>Patching Policy</td>
<td>Patching + Black Swan Policy</td>
<td>Patching + Black Swan + Freshness Policy</td>
<td>Patching + Black Swan + Freshness + Enforcement Policy</td>
</tr>
<tr>
<td>Scanning</td>
<td>Occasional Scanning</td>
<td>Low frequency Scheduled Scans</td>
<td>Scheduled Scans</td>
<td>Scheduled Scans and Continuous Event-based Monitoring</td>
<td>Scheduled Scans, Continuous Event-based Monitoring with historical tracking</td>
</tr>
<tr>
<td>Containment</td>
<td>Manual Remediation</td>
<td>Manual</td>
<td>Semi-automated</td>
<td>Automated</td>
<td>Automated + Enforcement</td>
</tr>
<tr>
<td>D&amp;M</td>
<td>No Dashboard</td>
<td>Scan Dashboard</td>
<td>Coverage, Scan and Fixes</td>
<td>Coverage, Scan, Fixes and Exec</td>
<td>Coverage, Scan, Fixes, Devs, Ops and Exec</td>
</tr>
</tbody>
</table>
<h3>1. Inventory &amp; Discovery</h3>
<p>Inventory consists of listing assets and collecting useful metadata like ownership, usage (Prod vs. Dev), and targeting information, for
instance listing all the desktop machines within your organization and collecting metadata like MAC address, IP address,
and employee owner.</p>
<p>Inventory is used for security scanning to schedules scans, assign vulnerabilities for fixes, present an aggregated
view of the security of an environment and drive strategic remediation.</p>
<p>Inventory is difficult to maintain when it is purely security focused and is better if it is not operated by the security
team. Inventory maintenance is challenge both; from a technical and a  process perspective. In most cases and environments <strong>we are
faced with the need to keep inventory of assets with different and contradicting requirements</strong>, such as highly
volatile vs. immutable assets, low volume with frequent changes vs. high volumes with rare changes, or 
ambiguous vs. hierarchical ownership. Hence, building and maintaining an infrastructure that copes with all of these requirements is a very challenging problem.</p>
<blockquote>
<p>For example scanning desktop machines vs. database servers, desktops routinely change IP addresses and have a single owner, while a database
server rarely changes an IP address, and the services they run; have separate owners.</p>
</blockquote>
<p>Moreover, Inventory can benefit a wide range of usages, like tracking consumption (financial), monitoring deployments (production),
hence, making it is easier to maintain if driven by production as it is usually the best way to keep it up to date.</p>
<blockquote>
<p>As a case in point, the newly open-sourced project <code>Backstage</code> by Spotify <a href="https://github.com/spotify/backstage">Backstage</a>. According
to the team behind the project, because the <code>Backstage</code> provides the tools to create and monitor deployments, it has naturally became the source of
truth of their inventory.</p>
</blockquote>
<p>While an up-to-date inventory is ideal, it is practically not achievable due to blind spots caused by human interaction or technological limitations.</p>
<p>As it is taxing to determine blind spots, <strong>Inventory should always be augmented with an external discovery component</strong>
that tries to locate respective blind spots. Discovery should continuously attempt to find the loopholes that remain uncovered.</p>
<p>The discovery system is not limited to technical tools, like domain name brute forcing, but can also resort to other
means, like tracking payment done with enterprise credit card to find non listed cloud projects for instance.</p>
<h3>2. Scanning</h3>
<p>Scanning has 3 dimensions, namely scheduling, orchestration and detection that are as follows:</p>
<h4>2.1 Scheduling</h4>
<p>Scheduling addresses the question of when to scan; it is either time based or event based. Time-based like for instance once a day.
Event based like at each submit or every time a new container is created. The scheduling is driven by the asset lifetime and the vulnerability report lifetime.</p>
<blockquote>
<p>Not all assets are equal when it comes to scheduling, for instance scanning a public website requires a continuous
time based rules, while containers for instance require an event based to scan at creation and the detection of a new
CVE affecting one of the container dependencies.</p>
</blockquote>
<p>Event-based scanning is always preferred over time based scans as we narrow the window of when things can get wrong.
It is unfortunately not always possible. Take for instance black box scanning of a website, without any measure of
how things are changing or evolving, the only option we have is a time-based approach.</p>
<blockquote>
<p>Current time-based approach can be drastically enhanced by avoiding full re-scans and building on previous scan results and coverage.
Take for instance scanning a website, instead of doing full crawl with every scan, scanner can use previous crawls to
speed up scans, detect changes and focus tests.</p>
</blockquote>
<p>A fully <code>Autonomous Security</code> pipeline doesn't need to hammer an asset with continuous scans, but can take a smarter
approach. If an asset is a static website and it hasn't changed in the last 6 months, the system should be able to
lower the frequency of scans.</p>
<h4>2.2 Orchestration</h4>
<p>Orchestration defines how to handle the lifecycle of a scan, like what to do in the case
of a failure, whom to notify during the different phases of a scan, should a set of extra
resolution steps or notification get triggered, should a duplicate dedicated environment get 
created for scanning.</p>
<blockquote>
<p>With service mesh type architecture (e.g. Istio), it is possible to create a <code>testing garden</code>
by duplicating a set of services for scanning, route scanning traffic to the new mesh based
on a header value for instance and apply quota to access shared components like a database or a message queue.</p>
</blockquote>
<p>Orchestration is typically critical for compliance regimes, like PCI-DSS or FedRamp. A fully <code>Autonomous Security</code> pipeline
can define a set a hooks to trigger business oriented logic, like notify certain people, update certain dashboards,
generate certain reports, etc.</p>
<h4>2.3 Detection</h4>
<p>Detection is usually what most people think of when we talk about security scanning. As important as it is, it is
only one cog in a large machinery.</p>
<p>Proper detection must reduces false positives and negatives and take context to rate severity. Finding the correct
balance the suits the size of an organization and the severity of an environment is an important balance.</p>
<p>Creating a map of the type of assets owned by an organization and creating a coverage map is helpful to identify
missing capabilities, an simplified map could be as simple as:</p>
<div><pre><span></span><code><span>* Network</span><span>:</span>
    <span>* IPv4</span><span>:</span> <span>CHECK</span> 
    <span>* IPv6</span><span>:</span> <span>MISSING</span>

<span>* Web</span><span>:</span>
    <span>* Known Vulnz</span><span>:</span> <span>CHECK</span>
    <span>* non-SPA</span><span>:</span> <span>CHECK</span>
    <span>* SPA</span><span>:</span> <span>MISSING</span>
    <span>* Authenticated</span><span>:</span> <span>MISSING</span>

<span>* Mobile</span><span>:</span>
    <span>* Android</span><span>:</span> <span>CHECK</span>
    <span>* iOS</span><span>:</span> <span>CHECK</span>
    <span>* Mobile Backend</span><span>:</span> <span>CHECK</span>

<span>* Cloud</span><span>:</span>
    <span>* VM</span><span>:</span> <span>MISSING</span>
    <span>* Containers</span><span>:</span> <span>CHECK</span>
    <span>* Serverless</span><span>:</span> <span>MISSING</span>

<span> </span><span>...</span>
</code></pre></div>
<p>or as complex as :</p>
<div><pre><span></span><code><span>* Web</span><span>:</span>
    <span>* SQL Injection</span><span>:</span>
      <span>* Postgrs</span><span>:</span>
        <span>* WHERE Clause</span><span>:</span> <span>CHECK</span>
        <span>* FROM Clause</span><span>:</span> <span>MISSING</span>
        <span>* ORDER Clause</span><span>:</span> <span>LIMITED</span>
</code></pre></div>
<blockquote>
<p>While detection is a <strong>VERY</strong> large topic, a common complaint in this space is that security vendors often
over-promise and under-delivered space. <a href="https://www.helpnetsecurity.com/2020/10/23/cybersecurity-is-failing-due-to-ineffective-technology/">This is good resource on why the security industry is failing due to ineffective technology</a></p>
</blockquote>
<p>All security solutions can be split into 2 technological pieces, an <code>Analysis Engine</code> and set of <code>Rules</code>. The engine is typically
what takes a program, a website, an IP and performs a set transformations or interactions.</p>
<p>Example of <code>Analysis Engines</code>:</p>
<ul>
<li><strong>Dependency fingerprint engine</strong>: Find dependencies and 3rd party components.</li>
<li><strong>Taint Engine</strong>: Generate object-oriented graph taint to find link between sources and sinks.</li>
<li><strong>Dynamic Engine</strong>: Collect stack traces, methods and parameters.</li>
<li><strong>Fuzz Engine</strong>: Injects inputs and collects data flow and crash reports.</li>
</ul>
<p>The engine outputs are then …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ostorlab.co/autonomous-security-scanning.html">https://blog.ostorlab.co/autonomous-security-scanning.html</a></em></p>]]>
            </description>
            <link>https://blog.ostorlab.co/autonomous-security-scanning.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929693</guid>
            <pubDate>Thu, 29 Oct 2020 12:20:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secrets of the best product teams]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24929484">thread link</a>) | @scotthtaylor
<br/>
October 29, 2020 | https://st.im/secrets-of-the-best-product-teams/ | <a href="https://web.archive.org/web/*/https://st.im/secrets-of-the-best-product-teams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Travelling back in time to 2004, the “World Wide Web” was dominated by Microsoft, AOL, and Jeeves. (the)Facebook had just launched, and it would be three more years until the first iPhone. I was just fifteen, and didn’t have many friends. I did, however, have a keen interest in computers, and was blown away by the connectivity of the Internet. It wasn’t long before I started immersing myself in the coding languages that powered it -- building websites that I wanted to use, but didn’t yet exist.</p><p>I didn’t know it back then, but I was dipping my toes in the waters of <strong>product management</strong>, or <strong>product</strong> as it’s better known now.</p><p>Product essentially being the ability to work with a multidisciplinary team of people and build a simple solution to a real customer problem in a way that meets the needs of the business. All with an understanding of how design, business, technology and users intersect and overlap.</p><p>Back then product management was more associated with enterprise software, with Product Managers (PMs) being concentrated in the likes of Cisco and Oracle.</p><p>As Internet adoption exploded over the next decade and startups became part of everyday life, PMs were no longer building highly specialised or corporate software exclusively. They were the founders building stuff that helped with everything from dating through to grabbing a taxi. They were also building products in larger corporates; for example Gmail within Google.</p><p>The PM concept had hit the mainstream. </p><p>Amazon, Google, Facebook, Netflix, Tesla -- the list could go on -- have all successfully scoped out, built, and launched products that are used by billions of people. All because they have a solid product culture, that connects all the dots. It’s hard to imagine a modern-day tech company not having ‘product’ at their core.</p><p>With this context, I wanted to talk about the secrets that I’ve noticed in high performing product teams over the years. So whether you’re an early stage startup working on achieving product/market fit, or a growth stage company working on scale, or even a large corporate trying to regain your ability to consistently deliver new value to your customers, I’m sure that there will be something to takeaway.</p><h2 id="making-sure-the-basics-are-covered">Making sure the basics are covered </h2><p>Before jumping into the secrets, I want to make sure we’re on the same page with regard to the basics. Without these being covered no product team will be able to have consistent break-out success.</p><!--kg-card-begin: markdown--><pre><code>def sum_product(n): 
    s = 0 
    while n: 
        vision +
        functionality +
        technology +
        user experience design +
        monetisation +
        acquisition +
        offline experience
    return s
</code></pre>
<!--kg-card-end: markdown--><p>Distilling it down to first principles, I think ‘product’ is really about evaluating opportunities and determining what gets built and delivered to customers. Everything stems from this. And to do it successfully, you must:</p><ol><li>Understand your customer,</li><li>Understand the data, and</li><li>Understand your business and the industry it operates in</li></ol><p>Understanding the customer means you’re an expert on their issues, pains, desires, and how they think. Without this, you’re just guessing. And it has to be a mix of both quantitative and qualitative learning. </p><p>Understanding the data covers a wide gamut, not only the ability to understand your customer but to know what they’re doing with your product. Successful products need to be loved by your customers but also need to work for your business. This means knowing who your stakeholders are and the constraints they operate under.</p><p>Finally understanding your market. You need to know who your competitors are – in addition to key trends, customer behaviours and expectations.</p><p>Each of these principles deserves its own in-depth post – but, for now, I wanted to provide some brief context before touching on the lesser known secrets. </p><h2 id="first-you-need-a-big-mission">First, you need a big mission</h2><p>It’s critical for your team to be organised around something that’s motivating. </p><p>It has to be a mission that’s worthwhile. Something that gets them out of bed. But it also has to be somewhat ambiguous, or unattainable, as well. Think of Elon Musk’s mission for SpaceX – to colonise Mars. </p><p>This helps people become missionaries. It also helps align the skills of the people that are potentially going to be working on the product. Finally, it serves as a filter. A filter for people who are able to connect the dots, from the potentially mundane tasks of today to the exciting vision of tomorrow. These are the people that you want around you. Those who can’t connect the dots, will naturally fall by the wayside.</p><p>Next, even though the <em>mission</em> may sound crazy, this doesn’t mean the <em>vision</em> is.</p><p>The product vision has to be consumer centric yet aligned with the mission. The product team are usually the ones translating that mission into reality. And that’s what the vision helps you do. </p><p>Product are usually the ones initiating the conversation around what the product vision should be, because we’re the ones talking to the customer.</p><p>So an idea might be seeded by the founders or execs, hypothesising about an area of opportunity. But it’s only once you start interacting with the customer, that you can say, “Oh yeah, that’s a good idea” or, “No that’s an awful idea, let’s not do that.”</p><p>The product vision gives the organisation its purpose, and we only want people in our organisation that are excited about, and dedicated to this vision —missionaries. PM thought leader Marty Cagan describes this well:</p><blockquote>There are many benefits of product teams, but a big goal is captured best by a quote from John Doerr, the famous Silicon Valley venture capitalist: “we need a team of missionaries, not teams of mercenaries.” Mercenaries build whatever they’re told to build. Missionaries are true believers in the vision and are committed to solving problems for their customers. <br></blockquote><h2 id="next-a-finger-on-the-pulse-of-product-evolution">Next, a finger on the pulse of product evolution</h2><p>The best product teams I know are currently, as I type this, immersing themselves in artificial intelligence and machine learning. They understand that AI is the next general purpose technology – something that will affect the world, and an opportunity that usually only comes along once in a generation. </p><p>These teams understand that scale economies accrue to first movers in AI, and second movers will find it difficult to catch up. By adopting early they reap the rewards of a positive feedback loop. They will capture early customers who, in turn, will create more data for the product. Resulting in a virtuous cycle that gives them a real, tangible and defensible advantage.</p><p>AI is transcending every industry. PMs used to be confined to just the tech sector, but the PMs of tomorrow will be needed in industries as diverse as farming and transportation; &nbsp;construction and medicine. Knowing how the AI product life cycle differs from that which has gone before will be a core competitive advantage.</p><p>An ingrained culture of continuous improvement and evolution is at the heart of every high performing team. The key is to be continuously scanning the market for trends and evolutions, not just in the markets for which you are building products, but in how and why.</p><h2 id="it-s-not-a-finite-game">It’s not a finite game</h2><p>Strong product teams don’t think in terms of a first or second half of the game – &nbsp;trying to get points on the board. But rather, they think of it as an infinite game. Always trying to get better. Understanding that there’s mastery beyond where they are, at every step.</p><p>This means they’re always going to beat their competition, because the competition is always going to be seeking this quarterly result, or that end event. Maybe ’the event’ is an IPO or an acquisition. Whereas the high performing team isn’t focussed on any particular business event, they’re seeking, “What’s the best possible outcome for this brand?”; “What’s the best possible outcome for this customer?”</p><p>This fundamentally changes the mentality of the team and the nature of how they show up every day. </p><p>It also relates to open mindedness – is your team open to new learning? Or do they assume they know everything?</p><p>The open mindset reminds your team of the idea that you’re not perfect, that you could fail, and that you may not have the answer. You need to have a culture where it’s okay to say “I don’t know” even when someone might expect you to.</p><h2 id="safe-psychological-spaces">Safe psychological spaces</h2><p>Do your team members feel like they can express an opinion or share what they think without feeling like they’re going to be repressed by your opinion, or that of the loudest person in the room? &nbsp;</p><p>Strong product teams don't look for consensus. They understand that innovation and collaboration are not correlated to consensus. </p><p>People should be encouraged to share their opinions. They can have disagreements about approaches but there needs to be an open forum where people have an opportunity to share. </p><p>A common problem is that people go to work and they don’t feel like they can express their opinions because they've got a structure, or a manager, or a situation that doesn’t allow for that to happen. </p><p>Safe psychological space is something that managers and leaders of high performing teams work a lot on. And it’s never over. You're always changing it because you're always bringing new people in. And every time you bring a new person in, you’ve got a change in dynamic. How do you make sure those people feel safe and that the people that who were previously interacting in a safe way don’t feel like they’re being adjusted in some way that’s negative.</p><h2 id="many-other-contributing-factors">Many other contributing factors</h2><p>The selection of secrets I’ve offered here are just a few of my favourites. </p><p>Others on the shortlist include:</p><ol><li>Empowerment and accountability -- ensuring that your team members are assigned problems to solve, rather than just given lists of features to build.</li><li>Communication and storytelling -- people buy stories, not products and the best product teams understand that storytelling transcends everything.</li><li>Going above and beyond -- related to the ‘missionaries’ point at the start of this article, always aim for …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://st.im/secrets-of-the-best-product-teams/">https://st.im/secrets-of-the-best-product-teams/</a></em></p>]]>
            </description>
            <link>https://st.im/secrets-of-the-best-product-teams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929484</guid>
            <pubDate>Thu, 29 Oct 2020 11:48:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Page Load Time Comparison of Raspberry Pi 3 and 4 Web Servers]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24929444">thread link</a>) | @sT370ma2
<br/>
October 29, 2020 | https://cheapskatesguide.org/articles/raspberry-pi-3-4-web-server.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/raspberry-pi-3-4-web-server.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/raspberry-pi-3-4-web-server.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929444</guid>
            <pubDate>Thu, 29 Oct 2020 11:43:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sudden Changes in UI: Why It's a Bad Move]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24929443">thread link</a>) | @allending
<br/>
October 29, 2020 | https://blog.snappymob.com/sudden-changes-in-ui-why-its-a-bad-move | <a href="https://web.archive.org/web/*/https://blog.snappymob.com/sudden-changes-in-ui-why-its-a-bad-move">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>There’s a reason why change aversion in users is so often spoken about in the world of digital consumerism <span>— </span>human beings love their comfort zones. In the grand scheme of things, we seek out what is familiar to us for a sense of security.</p>
<!--more-->
<p>Keeping your software product updated is important, but it’s also important to make sure the perfective changes you make are within the bounds of what your users are familiar and comfortable with.</p>
<p>Now, what kinds of changes might we be referring to?&nbsp;</p>
<p>The types of changes that can be introduced in a software product are changes in infrastructure, functionality, and interface. Among them, interface changes incite the biggest reactions from users. That’s because it’s the most forefront part of a product that they see and interact with <span>— layout, tabs, fonts, colors, buttons, animation, etc</span>.</p>
<p><span>When introducing changes in this aspect of your product, both psychology and history say you should take it slow.</span></p>
<h2><strong>What Psychology Tells Us&nbsp;</strong></h2>
<p>To discuss why sudden and major UI changes backfire from a psychological point of view, we have to address change aversion.&nbsp;</p>
<p>There have been many cases where consumers refused to adapt to a new product, even if it was objectively “better”. One good example would be the introduction of the <a href="https://www.dvorak-keyboard.com/"><span>Dvorak keyboard</span></a> in the 1930s.</p>
<p>Even&nbsp;though the Dvorak keyboard promoted objectively better physical ergonomics, people refused to move from the QWERTY keyboard <span>—</span> simply because they were used to it.&nbsp;</p>
<p>Why is that?</p>
<h3><strong>Users Want to Feel Smart</strong></h3>
<p>It’s widely taught by UIUX experts like Rohan Puri and Robert Youmans, that users are aversive to change because “change makes them feel dumb”. When using your product, users want to feel in control, like they know what they’re doing.&nbsp;</p>
<p>Especially for neurodivergent users, big and sudden changes in UI can be disorienting. When you change things around all at once, you’re also making your users relearn what they’d previously mastered before <span>— and that takes time and energy. In other words, you’re giving them work to do.</span></p>
<p>If you’re an app or web developer, always remember that your users aren’t sitting next to you, watching you iterate and develop from scratch. Your interface may seem simple to you because you’ve familiarized with it as you worked on it, but that’s not the case for them.</p>
<h3><strong>Value is Invisible</strong></h3>
<p>Confirming many real-life cases, a study by Rosman et al on <a href="https://www.researchgate.net/publication/262411663_On_user_behaviour_adaptation_under_interface_change"><span>user behaviour adaptation under interface change</span></a> found that it takes many tries for a user to feel comfortable enough with an interface that was initially unfamiliar to them, before they “conﬁdently choose it and realise the potential beneﬁts”.</p>
<p>Because the bulk of your revamp’s value is neither visible nor instantly detectable, more impatient users might poorly estimate the efﬁciency of your improved UI and “prematurely abandon it” in that particular time frame.</p>
<p>After all, if they don’t see an increase in value, why would they like that you changed what was already working for them?</p>
<h2><strong>What History Tells Us</strong></h2>
<p>Negative feedback from a large number of users can spread like wildfire on social media. Needless to say, that can be really detrimental to your brand and product.</p>
<p>If you’re a startup just starting out with a small user base, you have more leeway for major UI redesigns while you figure out your brand and voice. As your product grows, however, so does the need to prioritize your users’ preferences.&nbsp;</p>
<p>Some companies with really big user bases learned the hard way so we don’t have to.&nbsp;</p>
<h3><strong>What Happened with Digg</strong></h3>
<p>In 2010, Digg, a news aggregate site very much like reddit, launched a redesign that caused them to lose 35% of their users nearly instantly.</p>
<p>In the Digg v4 update, the site was heavily revamped visually and functionally. Among many of the sudden changes, the downvote button was removed, users could no longer save posts to favorites or posts videos,&nbsp; their Upcoming page was gone, and the overall focus was shifted from user-submitted content to publisher-submitted content.&nbsp;</p>
<p>This major change didn’t just disorient their users. It took control away from them. With the new system, posts by publishers and sponsors flooded the front page, while posts by regular users were practically invisible.&nbsp;</p>
<p>The result of this? A mass exodus. Users either flooded the site with protest links (many of which were links to Reddit, their biggest competitor) or immediately migrated to Reddit.&nbsp;</p>
<h3><strong>What Happened with eBay</strong></h3>
<p>Once, eBay decided to change the background color of many of their site’s pages from bright yellow to white. Even though this change may seem like an obvious aesthetic choice today, it caused a ruckus on the internet (and in the team’s mailbox) when it first happened, forcing them to revert to yellow.</p>
<p>eBay didn’t give up on their vision, though. They came up with a strategy to go subtle, and designed an algorithm that faded the background from yellow to white, one shade at a time, over a few months. This time, the internet was still. The change was taking place so gradually that their users didn’t notice it was happening.</p>
<h2><strong>How Do You Safely Revamp?</strong></h2>
<p>Now that storytime is over, let’s talk about what we can learn from them. How can you revamp your product while being wary of change aversion?&nbsp;</p>
<p>Obviously, getting complaints from users doesn’t mean you should stop updating your app or website. <span>M</span>aintenance is necessary for your product to thrive and continue thriving.<span> The secret lies in </span><em><span>how</span></em><span> you execute it.</span></p>
<h3><strong>Change Little and Often</strong></h3>
<p>Instead of giving your users a whole new interface to relearn at one go, introduce a little change at a time. Habits take time to unlearn. Giving users one small redirection at a time is a lot less disorienting and burdensome for them.</p>
<h3><strong>Give Users a Heads-up&nbsp;</strong></h3>
<p>Before you launch your redesign, give users time to prepare for it. This will dampen the impact of the launch and reduce the risk of shocking them into frustration with your product.&nbsp;</p>
<h3><strong>Spell Out the Values</strong></h3>
<p>As mentioned before, values are invisible. Users don’t always immediately see the benefits of your new interface when they first try it. Instead of waiting for them to figure the maze out on their own, give them the lowdown on how the changes you’ve implemented are designed to solve the problems they face.</p>
<h3><strong>Provide Guidance</strong></h3>
<p>Part of spelling out the values of your redesign is by easing your users’ transition to your new interface. When you provide tutorials and demonstratives, you’re also teaching them how the new design improves their experience on your app or website.</p>
<h3><strong>Provide Options</strong></h3>
<p>It’s always good to give your users the option to switch back to the old interface. Provide them a toggle switch or button to revert to the old version, and place it somewhere easily accessible.</p>
<h3><strong>Welcome Feedback</strong></h3>
<p>Give your users an outlet or channel through which they can directly communicate with your team. Whether it’s a form on your website, or simply an email address they can write to specifically for complaints and feedback, it’s always good to let your users know that you’re listening.</p>
<h2><strong>We’re Here to Help</strong></h2>
<p>Snappymob is equipped with software developers and designers who understand user behavior. Our team has helped clients from startups to large corporations, within and beyond Malaysia, launch successful revamps and redesigns.</p>
<p>With our help, you can rest assured that your redesigns launch safely. Click <a href="https://www.snappymob.com/contact"><span>here</span></a> to reach out to us!</p>
</span></p><p><label>app design</label></p>
        
      </div></div>]]>
            </description>
            <link>https://blog.snappymob.com/sudden-changes-in-ui-why-its-a-bad-move</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929443</guid>
            <pubDate>Thu, 29 Oct 2020 11:43:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For Complex Applications, Rust Is as Productive as Kotlin]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24929335">thread link</a>) | @todsacerdoti
<br/>
October 29, 2020 | https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="preamble">
<div>
<p>In this article, we will compare one apple (IntelliJ Rust) to one orange (rust-analyzer) to reach general and sweeping conclusions.
Specifically, I want to present a case study supporting the following claim:</p>
<p>For complex applications, Rust is as productive as Kotlin.</p>
<p>For me, this is an unusual claim to argue: I always thought exactly the opposite, but I am not so sure now.
I came to Rust from C++.
I was of the opinion that this is a brilliant low-level language and always felt puzzled at people writing higher-level things in Rust.
Clearly, choosing Rust means taking a productivity hit, and using Kotlin, C# or Go just makes much more sense if you can afford GC.
My <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">list of Rust criticisms</a> starts with this objection.</p>
<p>What moved my position in the other direction was my experience as the lead developer of rust-analyzer and IntelliJ Rust.
Let me introduce the two projects.</p>
<p><a href="https://github.com/intellij-rust/intellij-rust"><strong>IntelliJ Rust</strong></a> is the plugin for IntelliJ Platform, providing Rust support.
In effect, it is a Rust compiler front-end, written in Kotlin and making use of language-support features of the platform.
These features include lossless syntax trees, a parser generator, persistence and indexing infrastructure, among others.
Nonetheless, as programming languages differ lot, the bulk of logic for analyzing Rust is implemented in the plugin itself.
Presentational features like completion list come from the platform, but most of the language semantics is hand-written.
IntelliJ Rust also includes a bit of a Swing GUI.</p>
<p><a href="https://github.com/rust-analyzer/rust-analyzer"><strong>rust-analyzer</strong></a> is an implementation of
<a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a> for Rust.
It is a Rust compiler front-end written from scratch with an eye towards IDE support.
It makes heavy use of <a href="https://github.com/salsa-rs/salsa">salsa</a> library for incremental computations.
Beyond the compiler itself, rust-analyzer includes code for managing long-lived multithreaded process of the language server itself.</p>
<p>The projects are essentially equivalent in scope — rust compiler front-ends suitable for IDEs.
The two biggest differences are:</p>
<div>
<ul>
<li>
<p>IntelliJ Rust is a plugin, so it can re-use code and design patterns of the surrounding platform.</p>
</li>
<li>
<p>rust-analyzer is the second system, so it leverages experience of IntelliJ Rust for a from-scratch design.</p>
</li>
</ul>
</div>
<p>The internal architecture of the two projects also differs a lot.
In terms of <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">Three Architectures</a>, IntelliJ Rust is map-reduce, and rust-analyzer is query-based.</p>
<p>Writing an IDE-ready compiler is a high-level task.
You don’t need to talk to the operating system directly.
There are some fancy data structures and concurrency here and there, but they are also high-level.
It’s not about implementing crazy lock-free schemes, it’s about maintaining application state and sanity in the multithreaded world.
The bulk of the compiler is symbolic manipulation, arguably best suited for lisp.
Picking a VM-based language for such task (for example, OCaml), doesn’t have any intrinsic downsides.</p>
<p>At the same time, the task is pretty complex and unique.
The ratio of “your code” vs “framework code” when implementing features is much higher than in a typical CRUD backend.</p>
<p>Now that the projects are introduced, lets take two roughly equivalent slices of history.</p>

<p>Both are about 2 years old, with 1-1.5 developers working full time and vibrant and thriving community of open-source contributors.
There are 52k lines of Kotlin and 66k lines of Rust.</p>
<p>Both delivered roughly equivalent feature sets at that time.
To be honest, I still don’t really believe this :)
rust-analyzer started from zero, it didn’t have a decade worth of Java classes to bootstrap from, and the productivity drop between Kotlin and Rust is supposed to be huge.
But it’s hard to argue with reality.
Instead, let me try to reflect on my experience building both, and to try to explain Rust’s surprising productivity.</p>
</div>
</div>
<div>
<h2 id="_learning_curve">Learning Curve</h2>
<div>
<p>It’s easy to characterize Kotlin’s learning curve — it is nearly zero.
I’ve started IntelliJ Rust without Kotlin experience and never felt that I need to specifically learn Kotlin.</p>
<p>When I switched to rust-analyzer, I was pretty experienced with Rust.
I would say that one definitely needs to deliberately learn Rust, it’s hard to pick it up on the go.
Ownership and aliasing control are novel concepts (even if you come from C++), and taking holistic approach to learning them pays off.
After the initial learning step the ride is generally smooth.</p>
<p>By the way, this is the perfect place to plug our Rust courses and tailor-made <a href="https://ferrous-systems.com/training/">trainings</a> :-)
The next <a href="https://ferrous-systems.com/training/#package-intro-training">introduction to Rust</a> is happening this December!</p>
</div>
</div>
<div>
<h2 id="_modularity">Modularity</h2>
<div>
<p>This I think is the biggest factor.
Both projects are moderately large in terms of scope as well as in terms of amount of source code.
I believe that the only way to ship big things is to split them in independent-ish chunks and implement the chunks separately.</p>
<p>I also find most of the languages I am familiar with to be pretty horrible with respect to modularity.
More generally, I am amused with FP vs OO debate, as it seems that “why no one does modules right?” is a more salient issue.</p>
<p>Rust is one of the few languages which has first-class concept of libraries.
Rust code is organized on two levels:</p>
<div>
<ul>
<li>
<p>as a tree of inter-dependent modules inside a crate</p>
</li>
<li>
<p>and as a directed acyclic graph of crates</p>
</li>
</ul>
</div>
<p>Cyclic dependencies are allowed between the modules, but not between the crates.
Crates are units of reuse and privacy: only crate’s public API matters, and it is crystal clear what crate’s public API is.
Moreover, crates are anonymous, so you don’t get name conflicts and dependency hell when mixing several versions of the same crate in a single crate graph.</p>
<p>This makes it very easy to make two pieces of code <strong>not</strong> depend on each other (non-dependencies are the essence of modularity): just put them in separate crates.
During code review, only changes to Cargo.tomls need to be monitored carefully.</p>
<p>At the time of comparison, rust-analyzer is split into 23 internal crates, with a handful general-purposed ones released on crates.io.
In contrast, IntelliJ Rust is a single Kotlin module, where everything can depend on everything else.
Although internal organization of IntelliJ Rust is pretty clean, it’s not reflected in the file system layout and build system, and needs constant maintenance.</p>
</div>
</div>
<div>
<h2 id="_build_system">Build System</h2>
<div>
<p>Managing project’s build takes significant amount of times, and has multiplicative effect on everything else.</p>
<p>Rust’s build system, <a href="https://doc.rust-lang.org/cargo/index.html">Cargo</a>, is very good.
It’s not perfect, but it is a breath of fresh air after Java’s <a href="https://gradle.org/">Gradle</a>.</p>
<p>Cargo’s trick is that it doesn’t try to be a general purpose build system.
It can only build Rust projects, and it has rigid expectation about the project structure.
It’s impossible to opt out of the core assumptions.
Configuration is a static non-extensible TOML file.</p>
<p>In contrast, Gradle allows free-form project structure, and is configured via a Turing complete language.
I feel like I’ve spend more time learning Gradle than learning Rust!
Running <code>wc -w</code> gives 182_817 words for Rust book, and 280_506 for Gradle’s user guide.</p>
<p>Additionally, Cargo is just faster than Gradle in most cases.</p>
<p>Of course, the biggest downside is that custom build logic is not expressible in Cargo.
Both projects needs substantial amount of logic beyond mere compilation to deliver the final result to the user.
For rust-analyzer, this is handled by hand-written Rust script, which works perfectly at this scale.</p>
</div>
</div>
<div>
<h2 id="_ecosystem">Ecosystem</h2>
<div>
<p>Language-level support for libraries and top-notch build system/package manager allow for a thriving ecosystem.
rust-analyzer relies on third-party libraries much more than IntelliJ Rust.
Some parts of rust-analyzer are also published to crates.io for other projects to reuse.</p>
<p>Additionally, low-level nature of the Rust programming language often allows for “perfect” library interfaces.
Interfaces which exactly reflect the underlying problem, without imposing intermediate language-level abstractions.</p>
</div>
</div>
<div>
<h2 id="_basic_conveniences">Basic Conveniences</h2>
<div>
<p>I feel that Rust is significantly more productive when it comes to basic language nuts and bolts — structs, enums, functions, etc.
This is not specific to Rust — any ML-family language has them.
However, Rust is the first industrial language which wraps these features in a nice package, not constrained by backwards compatibility.
I want to list specific features which I think allow producing maintainable code faster in Rust</p>
<p><em>Emphasis on data over behavior</em>.
Aka, Rust is not an OOP language.
The core idea of OOP is that of dynamic dispatch — which code is invoked by a function call is decided at runtime (late binding).
This is a powerful pattern which allows for flexible and extensible system.
The problem is, extensibility is costly!
It’s better only to apply it in certain designated areas.
Designing for extensibility by default is not cost effective.
Rust puts static dispatch front and center: it is mostly clear whats going on by just reading the code, as it is independent of runtime types of the objects.</p>
<p>One small syntactic thing I enjoy about Rust is how it puts fields and methods into different blocks syntactically:</p>
<div>
<div>
<pre><code data-lang="rust"><span>struct</span> <span>Person</span> <span>{</span>
  <span>first_name</span><span>:</span> <span>String</span><span>,</span>
  <span>last_name</span><span>:</span> <span>String</span><span>,</span>
<span>}</span>

<span>impl</span> <span>Person</span> <span>{</span>
    <span>fn</span> <span>full_name</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
        <span>...</span>
    <span>}</span>
<span>}</span></code></pre>
</div>
</div>
<p>Being able to see at a glance all the fields makes understanding the code much simpler.
Fields convey much more information than methods.</p>
<p><em>Sum types</em>.
Rust’s humbly named enums are full algebraic data types.
This means that you can express the idea of disjoint union:</p>
<div>
<div>
<pre><code data-lang="rust"><span>enum</span> <span>Either</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span> <span>{</span> <span>A</span><span>(</span><span>A</span><span>),</span> <span>B</span><span>(</span><span>B</span><span>)</span> <span>}</span></code></pre>
</div>
</div>
<p>This is hugely useful in day-to-day programming in the small, and some times during programming in the large as well.
To give one example, one of the core concepts for an IDE are references and definitions.
A definition a like <code>let foo = 92;</code> assigns a name to an entity which can be used down a line.
A reference like <code>foo + 90</code> <em>refers</em> to some definition.
When you ctrl-click on reference, you go to the definition.</p>
<p>Natural way to model that in Kotlin is by adding <code>interface Definition</code> and <code>interface Reference</code>.
The problem is, some things are …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</a></em></p>]]>
            </description>
            <link>https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929335</guid>
            <pubDate>Thu, 29 Oct 2020 11:27:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iceland paves the way for remote (tele)workers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24929202">thread link</a>) | @justkd
<br/>
October 29, 2020 | https://www.government.is/news/article/2020/10/27/-Foreign-experts-can-work-remotely-in-Iceland/ | <a href="https://web.archive.org/web/*/https://www.government.is/news/article/2020/10/27/-Foreign-experts-can-work-remotely-in-Iceland/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
<div><article data-last-modified="2020-10-27 17:36:00" data-category="type:News"><header><strong><time>October 27, 2020 </time><span>Ministry of Industries and Innovation, Ministry of Justice, Ministry of Finance and Economic Affairs</span></strong></header><div><figure><a href="https://www.government.is/library/01-Ministries/Ministry-of-Industries-and-Innovation/IMG_4200.jpg" data-lightbox="news-image" data-title="Ms. Áslaug Arna Sigurbjörnsdóttir, Minister of Justice, Ms. Þórdís Kolbrún Reykfjörð Gylfadóttir, Minister of Tourism, Industry and Innovation, Mr. Bjarni Benediktsson, Minister of Finance and Economic affairs."><img src="https://www.government.is/library/01-Ministries/Ministry-of-Industries-and-Innovation/IMG_4200.jpg?proc=singleNewsItem" alt="Ms. Áslaug Arna Sigurbjörnsdóttir, Minister of Justice, Ms. Þórdís Kolbrún Reykfjörð Gylfadóttir, Minister of Tourism, Industry and Innovation, Mr. Bjarni Benediktsson, Minister of Finance and Economic affairs. - mynd"></a><span></span></figure></div><section><p>The Minister of Tourism, Industry, and Innovation, the Minister of Justice and the Minister of Finance and Economic Affairs have put in place measures to enable non-EEA foreign nationals to reside in Iceland for up to six months and telework for foreign companies. With the measure, those foreign citizens, who are exempt from the visa requirements, will be allowed to apply for a long-term visa in Iceland for teleworkers and bring their families without having to move their legal domicile to the country or obtain Icelandic ID numbers.</p>
<p>In the wake of the COVID-19 epidemic, many companies around the world have made significant changes to the way they operate and are now increasingly allowing and encouraging their staff to telework. The result is that in many instances the staff member can choose their home environment, irrespective of the location of their workplace.</p>
<p>Ms. Þórdís Kolbrún Reykfjörð Gylfadóttir, Minister of Tourism, Innovation and Industry:</p>
<p><em><span>“We need to shape our export industry, based on ingenuity and by making it easier for foreign nationals to work from Iceland, we add value, knowledge and connections in Iceland that support our innovation environment.”</span></em></p>
<p>At the initiative of the Minister of Innovation, in collaboration with the Ministry of Justice and Ministry of Finance and Economic Affairs, an authorization has been implemented for those who are permanently employed with foreign companies so that they can stay and work in Iceland for up to six months. Until now the authorisation has only been for 90 days. In order to be granted permission for this longer stay, the person in question must demonstrate an employment relationship, income and health insurance. The Icelandic government will keep looking into the matter to find ways of extending the time period, but for now regulations have been changed to accommodate the six month period.</p>
<p>Mr. Bjarni Benediktsson, Minister of Finance and Economic Affairs:</p>
<span>“<em>We want to ensure that with regards to taxation, there is nothing to prevent the possibility of temporarily allowing individuals working for foreign companies to work from Iceland. We believe that these individuals will bring with them valuable experience and connections that will benefit Iceland on its path to economic recovery from effects of the Covid-19 pandemic</em><span>”</span>&nbsp;</span>
<p>Ms. Áslaug Arna Sigurbjörnsdóttir, Minister of Justice:&nbsp;</p>
<p>
<span>“<em>Fast technological developments call for us to be open and flexible to the growing opportunities available to us that arise when more employers encourage teleworking. The regulatory framework must take this into account.</em>”</span></p>
<p>Promote Iceland will provide further information and handle promotion of the initiative: <a href="https://www.government.is/cdn-cgi/l/email-protection#1f68706d745f767c7a737e717b31766c"><span data-cfemail="f5829a879eb59c969099949b91db9c86">[email&nbsp;protected]</span></a>.&nbsp;</p></section><h2>Tags</h2></article></div>

</div><div>
<div>
<p>This website uses cookies to ensure you get the best experience on our website. <a href="https://www.government.is/default.aspx?pageid=c7a1ba64-7428-4803-90e2-cbce7fd71d9b">Read more</a></p>
</div>
</div></div>]]>
            </description>
            <link>https://www.government.is/news/article/2020/10/27/-Foreign-experts-can-work-remotely-in-Iceland/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929202</guid>
            <pubDate>Thu, 29 Oct 2020 11:07:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Story: 2 People, No Funding, $700k+ ARR in Less Than 3 Years]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24929051">thread link</a>) | @yosid
<br/>
October 29, 2020 | https://provesrc.com/blog/celebrating-3-years/ | <a href="https://web.archive.org/web/*/https://provesrc.com/blog/celebrating-3-years/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p><strong>TLDR:</strong> Stories and takeaways from growing ProveSource from 0 to $700k ARR as a 2-person team in less than 3 years and with no funding.</p>
<p><img loading="lazy" src="https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover.png" alt="3 year story provesource" width="1920" height="1080" srcset="https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover.png 1920w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-300x169.png 300w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-1024x576.png 1024w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-768x432.png 768w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-1536x864.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<h2><strong>Our false start</strong></h2>
<p>We started the company in June 2015 with no real idea.</p>
<p>Most people we know fail to ever get started because they’re looking for the perfect idea.</p>
<p>As the founder of Instagram famously said:</p>
<p>“It’s about going through false starts. The best companies in the world have all had predecessors. YouTube was a dating site. You always have to evolve into something else.”</p>
<p>We brainstormed for several days and because both myself and Natan (my co-founder) are very good with mobile app development (iOS &amp; Android) we decided to build a personalization platform for mobile apps and sell it to enterprises.</p>
<p>Around 2.5 years later, having invested almost $100k out of our own pockets, having done hundreds of calls and demos with huge enterprises and dozens of Proof of Concepts, we decided it’s time to move on…</p>
<p>It felt awful – like you’re killing something you love, but it had to be done.</p>
<p>That was our “false start”. But more on that another time.</p>
<p><strong>🧠 Lesson learned:</strong></p>
<p>The sooner you kill an idea that is getting no traction, even if it’s super hard because it’s your baby, the less painful it is. The more time and resources you devote, the harder it becomes to pull out in case things don’t work out.</p>
<h2><strong>Starting over – The lean way</strong></h2>
<p>In January 2018 we decided to start working on a new SaaS product.</p>
<p>The idea was to “steal” the social proof hack that Booking.com was using (e.g. 5 people booked this hotel, etc.) and create a platform from it – a social proof marketing platform.</p>
<p>This time, because we were running on fumes, both in terms of cash and motivation, we decided to validate the idea first.</p>
<p>We had a single purpose in mind – getting 100 leads interested in our product.</p>
<p>We created a landing page that showcased our new idea as a real product, including pricing, a signup button, and all – a social proof marketing platform for mobile apps.</p>
<p><img loading="lazy" src="https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps.png" alt="" width="1920" height="1080" srcset="https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps.png 1920w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-300x169.png 300w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-1024x576.png 1024w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-768x432.png 768w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-1536x864.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<p>The fastest way to get targeted traffic to your website is to use Google Ads targeting the brand names of the biggest players in your niche.</p>
<p>So we did that.</p>
<p>We also posted the landing page anywhere we could think of: Reddit, ProductHunt, BetaList, social media, wherever…</p>
<p>About one month and – $300 later, we had around 200 leads that wanted to try out ProveSource.</p>
<p>We were finally making progress!</p>
<p>We figured that even if only 1% of them converted, we would already have 2 paying customers.</p>
<p><strong>🧠 Lesson learned:</strong></p>
<p>You can easily get traction without having a product.</p>
<p>Just buy a domain, build a landing page, and go validate your business idea.</p>
<p>We usually create landing pages to validate products using plain HTML and Airtable, to send the leads we collect from the forms. No fancy designs, no expensive CRM.</p>
<h2><strong>Making our first dollar $</strong></h2>
<p>Next goal – how do we make a dollar?</p>
<p>That is, unlike our previous product which made practically $0 in 2.5 years.</p>
<p>We created a rule that whenever we launch a new product, all our efforts will be towards making our first dollar, so we can have real-life validation.</p>
<p>So we have 200 people interested in ProveSource.</p>
<p>Now we needed to give them a product and get them to pay.</p>
<p>We built the leanest MVP possible:</p>
<ul>
<li>A product just for website owners (mobile was too small of a niche).</li>
<li>You could only show how many page visitors you had on your website.</li>
<li>The whole UI and UX should be super simple. No menus and extra buttons, don’t give users a reason to abandon your product.</li>
</ul>
<p>Did you forget your password and need to reset it? Sorry, no can do.</p>
<p>Did we accidentally change your password when you logged in? Oops, we’re on it.</p>
<p>What are onboarding and email automation? Dunno, don’t care.</p>
<p>April 2018 – we are approached by a Facebook Group admin that is interested in promoting our product to his group as a “lifetime deal” (LTD).</p>
<p>This means selling a lifetime subscription to your product for a one-off payment ranging from $39-$99.</p>
<p>We’ve never heard of this before so we thought long and hard about the consequences of selling a lifetime deal and how it would position the product and our company…</p>
<p>We decided to go with the deal and ran it with the group for 1 week.</p>
<p>We generated over $7k revenue, got tons of feedback, ideas for product improvements, tons of bugs were discovered in the process, which taught us the value of having live chat support.</p>
<p><strong>🧠 Lesson learned:</strong></p>
<p>In hindsight, there were no real consequences, only advantages to running a lifetime deal.</p>
<p>Sure, you have a few dozens of customers that are not paying you on a recurring basis – but they help a lot in the beginning when you need the cash and the validation.</p>
<p>Once we were done with the LTD we started pushing the product in all marketing channels and to our 200 user waiting list. None of them converted by the way.</p>
<p>A couple of days later we got our first monthly subscription customer ($19/month).</p>
<p>It was an amazing moment, validating that you indeed have a real business opportunity in your hands.</p>
<h2><strong>Our “wow moment”</strong></h2>
<p>During the next months, we focused on spreading the word, squashing bugs, and doing tons of support for our existing customers.</p>
<p>How did we decide what to build next?</p>
<ul>
<li>We learned to ask questions about our product’s value. Why do people buy our product? Is it because they want to increase conversions? How do we help them achieve that?</li>
<li>We brainstormed about what it means to be a social proof platform.</li>
<li>We heard our customers’ feedback</li>
<li>We learned from competitors; but not too much. We found that those who only copy will always lag behind.</li>
</ul>
<p>This whole process has to be accompanied by analytics and metrics.</p>
<p>You don’t have to measure each and every step or A/B test you do, though.</p>
<p>We don’t really do it, to this day.</p>
<p>A lot of product leaders talk about the “wow effect” or “wow moment” – if you want to retain users, make them say “wow”.</p>
<p>For Facebook, for example, their “wow moment” is logging into their platform and seeing familiar faces. That’s why they make sure that during sign up, you connect with as many people you know on Facebook as possible.</p>
<p>In our case, we focused on improving our user onboarding.</p>
<p>Since the product requires users to install a javascript snippet on their website, we put a big emphasis on making that process as easy as possible.</p>
<p>Our thought was – if users can see a social proof notification on their website, they’ll get to that “wow moment”.</p>
<p>We can see a very close correlation between successful onboarding and someone becoming a paying customer.</p>
<p>The funnel looks like this:</p>
<ul>
<li>8-10% of visitors will signup.</li>
<li>70% of those signups will complete the onboarding.</li>
<li>7-10% of those users who are onboarded will eventually become paying customers.</li>
</ul>
<p><img loading="lazy" src="https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel.png" alt="ProveSource Signups Funnel" width="1920" height="1080" srcset="https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel.png 1920w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-300x169.png 300w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-1024x576.png 1024w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-768x432.png 768w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-1536x864.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<p><strong>🧠 Lesson learned:</strong></p>
<p>Find what your “wow moment” is in your users’ experience, and make sure you get users to experience it as early in the onboarding process as possible. That way you can spend a lot on User Acquisition activities because the users you bring in end up becoming paying customers and sticking with you.</p>
<h2><strong>Our First Growth “Hack”</strong></h2>
<p>After we added some “necessary” features like showing recent sales and polishing the product to have fewer bugs – we wanted to grow bigger, we wanted to scale up, we wanted to get more exposure.</p>
<p>How do you scale a notifications product that is essentially an add-on for websites?</p>
<p>You build integrations for all website builders.</p>
<p>So we worked hard on adding more and more integrations: <a href="https://wordpress.org/plugins/provesource/">WordPress plugin</a>, <a href="https://apps.shopify.com/provesource">Shopify app</a>, Magento plugin, Wix app, <a href="https://zapier.com/apps/provesource/integrations">Zapier</a>, <a href="https://www.bigcommerce.com/apps/provesource-social-proof/">BigCommerce</a>, and more.</p>
<p>All of these marketplaces and app stores proved to be really good traffic sources and traction channels for us, each with its own audience and unique requirements.</p>
<p>Today, around 20% of our customers and revenue comes from Shopify alone.</p>
<h2><strong>Scaling past 2 people</strong></h2>
<p>Being a two-person team that does development, marketing, support, accounting, and more is tough. But it also teaches you a lot, you learn so much about your business, your audience, and your customers.</p>
<p>And that gives you the experience you need on what to look for when hiring someone to take over some of your responsibilities.</p>
<p>In September 2019 we decided it’s time to scale the team.</p>
<p>After all, a great company can’t be just 2 people, right?</p>
<p>Naturally, a software company’s first hire would be a developer.</p>
<p>Bringing Dima to the team, allowed us to build more integrations faster, and scale the company beyond its initial stage.</p>
<p>So we now have tons of integrations, pretty much with any large marketing or website platform out there.</p>
<p>We also scaled and optimized our Google and Facebook ads as much as we could.</p>
<p>We optimized our product onboarding rate, increased prices, added great features, and made it even easier to use the product, by adding tooltips, auto-suggestions, wizards, and more.</p>
<p>We were growing at a steady rate, so what could possibly be bothering us?</p>
<p>Well, we didn’t know how to grow faster, or what to do next.</p>
<p>We came up with a few ideas:</p>
<ul>
<li>Bring a Growth team member to scale our marketing efforts and bring new ideas to the table.</li>
<li>Since our product offering is strong and we couldn’t think about any impactful feature we could develop – we thought about zooming out of our product’s initial market.</li>
<li>Build a new product – we have no investors so we are free to make any decision we want about the company’s direction. Investors often block the founders from doing whatever is best for the company and push for a point where they can exit.</li>
</ul>
<h2><strong>Building a new product</strong></h2>
<p>At this point, we decided to build another product to scale the company further.</p>
<p>We had these questions in mind before picking what to work on:</p>
<ul>
<li>How big is the market, is it potentially bigger than our current product?</li>
<li>Would our existing customers be customers of this new product too?</li>
<li>What do our existing customers need and are willing to pay for?</li>
</ul>
<p>Adding ProveSource to your website is great, but, there is a critical prerequisite to making it work for you and your website: traffic. If your website has no traffic, you won’t be able to generate social proof.</p>
<p>Here’s the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://provesrc.com/blog/celebrating-3-years/">https://provesrc.com/blog/celebrating-3-years/</a></em></p>]]>
            </description>
            <link>https://provesrc.com/blog/celebrating-3-years/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929051</guid>
            <pubDate>Thu, 29 Oct 2020 10:41:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flash Loans]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928762">thread link</a>) | @theocs
<br/>
October 29, 2020 | https://blog.cfelde.com/2020/10/flash-loans/ | <a href="https://web.archive.org/web/*/https://blog.cfelde.com/2020/10/flash-loans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p>What would you do if you could borrow a near unlimited amount of money, only need to pay the interest, and not need to provide any collateral?</p>
<p>Sure, we have something like that with credit cards, at an outrageous interest rate, and with fairly small credit limits. But what if I’d give you this non-collateralized loan for just 0.09%?</p>
<p>Sure, you’d think, I’m happy to rip you off. But here’s the thing, you can’t rip me off, and I’m not scamming you.</p>
<p>The above is possible with something called flash loans, a new type of financial instrument, only possible on blockchains like Ethereum.</p>
<p>In short, it’s a DeFi protocol where you obtain the loan at the start of your transaction, do whatever you want to do with it, and then return it back with interest at the end of the same transaction. If you’re unable to return it, the flash loan protocol fails, failing the transaction, rolling back the whole set of actions as if nothing happened.</p>
<p>This only works because everything that happens within one transaction is atomic. It either all happens as described or nothing is saved to the blockchain state.</p>
<p>Having access to liquidity this cheaply opens a huge amount of opportunity, but also headaches. An example of a flash loan provider is <a href="https://aave.com/flash-loans">Aave</a>, with their, as of writing this, 0.09% fee.</p>
<p>There’s been a few examples of this causing issues. Offering anyone access to this much liquidity enables smart people to explore and exploit insecure protocols. Examples include <a href="https://medium.com/dragonfly-research/flash-loans-why-flash-attacks-will-be-the-new-normal-5144e23ac75a">a couple of attacks on the margin trading protocol bZx</a>, and more recently <a href="https://forum.makerdao.com/t/urgent-flash-loans-and-securing-the-maker-protocol/4901">an attack on the governance voting system used by MakerDAO</a>, the system behind the 2 billion dollar <a href="https://makerdao.com/">DAI</a> stablecoin.</p>
<p>Taking a step back, its not like flash loans themselves are causing these issues. Anyone could with similar liquidity, without using flash loans, trigger the same set of conditions. Instead, what flash loans enable, is firstly a very efficient tool to enable a lot of great things, and secondly an opportunity to highlight issues that need fixing in insecure or inefficient blockchain protocols. No hacks needed, they’re just pointing out the obvious.</p>
<p>A typical use case of where flash loans add much benefit to everyone involved is when you’d like to change the collateral used for minting DAI. With a flash loan you can cheaply get access to the liquidity needed to make this swap in one transaction, rather than the usual multi transaction setup. This brings more stability to the DAI ecosystem, and removes price movement risks you’d otherwise expose yourself to if you had to perform this swap over multiple transactions.</p>
<p>So flash loans are here to stay, and they’ll help shore up bad protocols, and enable more efficient financial transactions. Another example of where DeFi delivers tools not available in <a href="https://www.ledger.com/defi-vs-cefi-how-defi-measures-up">the old CeFi world</a>.</p>
</div>
</div></div>]]>
            </description>
            <link>https://blog.cfelde.com/2020/10/flash-loans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928762</guid>
            <pubDate>Thu, 29 Oct 2020 09:51:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[  You will need a subscription license to access Qt 6 (non-LGPL)]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24928720">thread link</a>) | @deng
<br/>
October 29, 2020 | https://www.qt.io/faq/what-happens-to-my-perpetual-licenses-once-i-convert-to-subscription | <a href="https://web.archive.org/web/*/https://www.qt.io/faq/what-happens-to-my-perpetual-licenses-once-i-convert-to-subscription">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><span><span>Yes. If your </span><span>Qt licenses are perpetual, you may continue to use the product in perpetuity after your maintenance expires.&nbsp; Access to product and technical support will only be available via the purchase of an Extended Maintenance Contract for software releases that are end-of-life. If you opt not to renew, please note that Qt will not guarantee to support software versions acquired with a perpetual license.</span></span></p>
<p><span><span>Please note, you will need a subscription license to access Qt 6.</span></span></p>
<!--more-->
<p><span><span>Qt versions can be viewed <a href="https://wiki.qt.io/QtReleasing" rel="noopener">here</a>.</span></span></p>
</span></p></div>]]>
            </description>
            <link>https://www.qt.io/faq/what-happens-to-my-perpetual-licenses-once-i-convert-to-subscription</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928720</guid>
            <pubDate>Thu, 29 Oct 2020 09:44:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Better User Guides with Annotated Screenshots]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928677">thread link</a>) | @perrys
<br/>
October 29, 2020 | https://www.goodannotations.com/tools/annotate-screenshot | <a href="https://web.archive.org/web/*/https://www.goodannotations.com/tools/annotate-screenshot">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><h2>Large range of annotation tools</h2><p>Add helpful informations to your screenshots that help guide your audience, using our online annotation tool. You can choose to use our simple point and click label creation tool that automatically creates an annotation label where ever you click on the screenshot, or you can choose from a number of professionally designed callout elements within the text tool. We've created sticky notes, annotations markups and even a great element for showing your audience what to do and what not to do. Our Draw Tool lets you draw arrows to direct your annotations and you can draw rectangles and circles that highlight important sections of your screenshot!</p><h2>Use text based annotations to provide context</h2><p>When you've picked your favourite set of annotation elements, the next thing that you need to do is add text to provide a context to the annotation you are making. We've made this super simple and easy to do in our online tool, all you need to do do is add the annotation element you like the look of, then double click to enter text editing and you just start typing away. Our elements either resize to fit the text you type or are elements like sticky notes that are kept limited on purpose to help you keep to the point and reduce the amount users have to read to understand whats going on.</p><h2>Customize your annotations for your brand</h2><p>Our annotation elements already look great and are designed to look professionbal and fit any situation you might use them for. However if keping to a brand design guideline is important to you then we've built in customization that allows you to make the changes you need to keep your brand on point. Use our easy to use and simple customization tools by clicking the element you want to update and play with the style options in the options pane that will appear. Update colours, text formatting and much more! Now you can place your screenshots on your branded website or email campaigns so that your customers recognise where the screenshot is from instantly!</p><h2>All our annotation tools are online</h2><p>Whatever device you are working from, there is no need for you to install any apps or software with Good Annotations. All our Annotation Tools are online and can be accessed by a browser like Chrome. This means our app works on your mac, windows, linux or even chromebook device. We also built our tools so that they are simple, no need for you to be a graphic designer to be able to use them. We tried to make our UI resemble applications you might youse on a daily basis like Microsoft Word or Google Docs. </p></div></div></div></div>]]>
            </description>
            <link>https://www.goodannotations.com/tools/annotate-screenshot</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928677</guid>
            <pubDate>Thu, 29 Oct 2020 09:35:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sponsoring Tiptap]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24928523">thread link</a>) | @hanspagel
<br/>
October 29, 2020 | https://blog.ueber.io/post/sponsoring-tiptap/ | <a href="https://web.archive.org/web/*/https://blog.ueber.io/post/sponsoring-tiptap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Too many open source developers abandon their projects because they can’t sustain their work. Funding the development, maintenance, and support of an open source project can be challenging. Let’s find out together how this can work for tiptap.</p>

<p>There is a significant advantage to make such thoughts for tiptap. This advantage is you. With so many people using, talking about, and contributing to tiptap, we felt the tailwind to start the <a href="https://blog.ueber.io/post/our-plan-for-tiptap-2/">development of tiptap 2</a> confidently.</p>
<p>Now that we are knee-deep in the development, we don’t want this journey to end with the release of tiptap 2. There are too many plans and ideas for making it even better for you and everybody. We need to find a way to sustain our work on it.</p>
<p>And we are in this together, aren’t we? You want to work with an always up to date package, and you want to have reliable support if something is not working out, and you want the coolest newest features. That’s why we ask you to contribute to the thinking behind the project and why we make everything around it as transparent as our codebase already is.</p>
<h2 id="the-rough-idea">The rough idea</h2>
<p>After evaluating <a href="https://blog.ueber.io/post/monetizing-open-source/">a few different ways to monetize an open source project</a> and having strong opinions against a few of them, we focused on one idea. Internally, we refer to it as <em>tiptap pro</em>. Nothing is defined here, not even the name, or if it needs a name at all. However, there is a rough idea of it. First of all, let us be clear with that:</p>
<p><strong>The whole codebase is going to stay open and accessible for everyone. No matter where you come from or what you plan to do, you should be able to start your project with tiptap.</strong></p>
<p>On top of that, we plan to provide professional users (developers and companies who make money with tiptap) with additional, valuable benefits. Those benefits, and only those, will require your sponsorship.</p>

<p>There is still much work to be done to show what we’ve got to you. Nevertheless, we are very proud of the parts we’ve tackled already and invited very few people to chat with us in private ways, which is fantastic for our current development phase.</p>
<p>The precise and constructive feedback from the teams, familiar with the current version of tipap, guides our work. That’s valuable for us and everyone who is waiting for the new version.</p>
<p>That said, nothing we do should be private. We want everything to be open, transparent, and accessible, and a closed community won’t. While we think it could give a great benefit for a few users, we don’t believe the community would benefit from it equally and abandoned the idea.</p>
<h3 id="2-labeled-issues-and-contributions">#2 Labeled issues and contributions</h3>
<p>From now on, all issues and pull requests created by sponsors of our organization will automatically get a <code>sponsor 💖</code> label attached. It’s just a tiny change but helps us make extra sure to jump in those contributions as soon as possible and support the people who support us.</p>
<p>That said, we hope to get funding for the development to a level that makes it possible to put enough time into the project, to help everyone quickly, professionally, and equally. That’s what we aim for.</p>
<h3 id="3-professional-extensions">#3 Professional extensions</h3>
<p>The power of tiptap is its extensibility, and with tiptap 2 we will double down on that. The new version will start with fewer extensions, but we plan to add many more extensions.</p>
<p>A few of those extensions are complicated to build, have complex requirements, will probably need more maintenance and support, and are likely to be used in a professional context.</p>
<p>With <em>tiptap pro</em>, we’d like to ask people who use those extensions in a commercial product to <a href="https://github.com/sponsors/ueberdosis" target="_blank" rel="nofollow noopener noreferrer">sponsor the further development, maintenance, and support</a> of those extensions.</p>
<p>But we won’t ask people using it for personal projects, university projects, open source projects, or other non-profit projects to sponsor us.</p>
<h2 id="does-that-sound-right-to-you">Does that sound right to you?</h2>
<p>We’re excited to hear your thoughts on this. We want to take this journey with all of you! Reach out to us <a href="https://twitter.com/hanspagel/status/1321738829468999682" target="_blank" rel="nofollow noopener noreferrer">on Twitter</a>, <a href="https://github.com/ueberdosis/tiptap/issues/547" target="_blank" rel="nofollow noopener noreferrer">on GitHub</a>, on <a href="https://news.ycombinator.com/item?id=24928523" target="_blank" rel="nofollow noopener noreferrer">HackerNews</a> or <a href="mailto:hans.pagel@ueber.io" target="_blank" rel="nofollow noopener noreferrer">send an email to me</a>!</p>
</section></div>]]>
            </description>
            <link>https://blog.ueber.io/post/sponsoring-tiptap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928523</guid>
            <pubDate>Thu, 29 Oct 2020 09:02:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What do apples and software have in common?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928491">thread link</a>) | @nonoesp
<br/>
October 29, 2020 | https://sketch.nono.ma/apples-and-software | <a href="https://web.archive.org/web/*/https://sketch.nono.ma/apples-and-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    <div>

    
          <svg data-name="sketch.nono.ma" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 600 153"><defs></defs><title>Sketch.Nono.MA</title><path d="M182.51,57.42v1.29a8.6,8.6,0,0,0,.48,3.47,1.85,1.85,0,0,0,1.82,1c1.34,0,2-1.05,2-3.14a8,8,0,0,0-.12-1.42,6.27,6.27,0,0,0-.44-1.38,11.32,11.32,0,0,0-.84-1.52c-.36-.54-.81-1.17-1.36-1.9l-2.22-3.23c-.71-1-1.3-1.92-1.77-2.72a18.44,18.44,0,0,1-1.13-2.28,10,10,0,0,1-.61-2,11.93,11.93,0,0,1-.17-2,6.9,6.9,0,0,1,1.79-5,6.43,6.43,0,0,1,4.84-1.85,6,6,0,0,1,3.86,1.23,5.77,5.77,0,0,1,2,3.43c.06.28.11.53.14.74a6.16,6.16,0,0,1,.07.69c0,.25,0,.57,0,1v1.57l-4.4.43c0-.83,0-1.42,0-1.79a6.37,6.37,0,0,0-.12-1.07c-.16-1.33-.78-2-1.86-2-1.24,0-1.86,1-1.86,3a9.55,9.55,0,0,0,.07,1.26,4.32,4.32,0,0,0,.39,1.21,16.05,16.05,0,0,0,1,1.66l1.77,2.66,2.27,3.23a21.45,21.45,0,0,1,2.4,4.58,12.66,12.66,0,0,1,.84,4.34,6.61,6.61,0,0,1-1.7,4.89,6.53,6.53,0,0,1-4.85,1.71,6.34,6.34,0,0,1-6.55-4.73,14.33,14.33,0,0,1-.29-3.26v-.83a8.51,8.51,0,0,1,.05-.88Z"></path><path d="M211.28,66.84h-4.69l-3.33-15L201.32,57v9.8h-4.54V35.11h4.54V47.05l4.4-11.94h4.6l-4.07,10.71Z"></path><path d="M226.51,35.11V39.3h-6.38v8.8h4.45v4.18h-4.45V62.65h6.77v4.19H215.59V35.11Z"></path><path d="M234.59,39.3h-4.21V35.11h13.15V39.3h-4.4V66.84h-4.54Z"></path><path d="M259.92,55.52c0,.85.06,1.51.08,2s0,.91,0,1.36q0,8.46-6.53,8.46-6.33,0-6.33-7.61V42.25q0-7.61,6.33-7.61Q260,34.64,260,43V44a13.8,13.8,0,0,1-.1,1.45h-4.54a12,12,0,0,0,.09-1.21v-1a10.26,10.26,0,0,0-.4-3.54,1.54,1.54,0,0,0-1.58-.93,1.44,1.44,0,0,0-1.43.69,6.93,6.93,0,0,0-.36,2.77V59.67a6.93,6.93,0,0,0,.36,2.77,1.44,1.44,0,0,0,1.43.69,1.56,1.56,0,0,0,1.56-.88,9,9,0,0,0,.42-3.36c0-.53,0-1,0-1.49s0-1.09-.07-1.88Z"></path><path d="M270.13,52.28V66.84h-4.55V35.07h4.55v13h3.57v-13h4.55V66.84H273.7V52.28Z"></path><path d="M283.91,62.08h4.54v4.76h-4.54Z"></path><path d="M309.34,66.84h-4.55l-5.22-16.65V66.84H295V35.11h3.85l5.91,18.7V35.11h4.55Z"></path><path d="M328.34,58.75c0,1,0,1.73,0,2.33s-.08,1.12-.14,1.55a4.63,4.63,0,0,1-.29,1.09,7.46,7.46,0,0,1-.53,1,5.56,5.56,0,0,1-2.25,1.92,7.4,7.4,0,0,1-6.24,0,5.56,5.56,0,0,1-2.25-1.92,7.46,7.46,0,0,1-.53-1,5.11,5.11,0,0,1-.31-1.09,10.43,10.43,0,0,1-.15-1.55c0-.6,0-1.38,0-2.33V43.15c0-.95,0-1.73,0-2.33a10.28,10.28,0,0,1,.15-1.54,5.21,5.21,0,0,1,.31-1.1,7.39,7.39,0,0,1,.53-1,5.63,5.63,0,0,1,2.25-1.88,7.4,7.4,0,0,1,6.24,0,5.63,5.63,0,0,1,2.25,1.88,7.39,7.39,0,0,1,.53,1,4.72,4.72,0,0,1,.29,1.1c.06.42.11.94.14,1.54s0,1.38,0,2.33ZM323.8,41.38a3.47,3.47,0,0,0-.43-2,1.6,1.6,0,0,0-1.41-.6,1.62,1.62,0,0,0-1.39.6,3.29,3.29,0,0,0-.45,2V60.57a3.51,3.51,0,0,0,.42,2,2,2,0,0,0,2.81,0,3.33,3.33,0,0,0,.45-2Z"></path><path d="M348.84,66.84H344.3l-5.23-16.65V66.84h-4.54V35.11h3.85l5.92,18.7V35.11h4.54Z"></path><path d="M367.84,58.75c0,1,0,1.73,0,2.33s-.08,1.12-.14,1.55a4.63,4.63,0,0,1-.29,1.09,7.46,7.46,0,0,1-.53,1,5.56,5.56,0,0,1-2.25,1.92,7.4,7.4,0,0,1-6.24,0,5.56,5.56,0,0,1-2.25-1.92,7.46,7.46,0,0,1-.53-1,5.11,5.11,0,0,1-.31-1.09,10.43,10.43,0,0,1-.15-1.55c0-.6,0-1.38,0-2.33V43.15c0-.95,0-1.73,0-2.33a10.28,10.28,0,0,1,.15-1.54,5.21,5.21,0,0,1,.31-1.1,7.39,7.39,0,0,1,.53-1,5.63,5.63,0,0,1,2.25-1.88,7.4,7.4,0,0,1,6.24,0,5.63,5.63,0,0,1,2.25,1.88,7.39,7.39,0,0,1,.53,1,4.72,4.72,0,0,1,.29,1.1c.06.42.11.94.14,1.54s0,1.38,0,2.33ZM363.3,41.38a3.38,3.38,0,0,0-.43-2,1.6,1.6,0,0,0-1.41-.6,1.62,1.62,0,0,0-1.39.6,3.29,3.29,0,0,0-.45,2V60.57a3.42,3.42,0,0,0,.43,2,1.62,1.62,0,0,0,1.41.59,1.64,1.64,0,0,0,1.39-.59,3.33,3.33,0,0,0,.45-2Z"></path><path d="M374.37,62.08h4.55v4.76h-4.55Z"></path><path d="M397.19,35.11h5.42V66.84h-3.87V44.44L395,66.84H393l-3.77-22.4v22.4h-3.77V35.11h5.32L394,50.9Z"></path><path d="M412.62,66.84h-4.36l4.4-31.73h5.81l4.2,31.73h-4.4l-.82-7.14h-4.06Zm2.8-26-1.55,14.7H417Z"></path><path d="M96.84,97.69c-1.56,0-2.5.76-2.5,1.8s1.21,1.63,2.34,1.9l1.3.32c2.08.5,4,1.59,4.06,4s-1.93,4.09-5.24,4.09-5.26-1.54-5.36-4.29H93.9c.1,1.45,1.31,2.15,2.88,2.15s2.75-.79,2.76-2-1-1.53-2.48-1.91l-1.58-.41c-2.27-.58-3.68-1.72-3.68-3.71,0-2.44,2.17-4.07,5.07-4.07s4.93,1.65,5,4H99.44C99.32,98.38,98.33,97.69,96.84,97.69Z"></path><path d="M103.78,95.76h2.44v7.61h.17l3.73-4.16H113l-4,4.47,4.25,5.89h-2.93l-3.16-4.43-.9,1v3.48h-2.44Z"></path><path d="M113.33,104.45c0-3.19,1.94-5.37,4.91-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C115.24,109.77,113.33,107.7,113.33,104.45Zm7.3-1a2.3,2.3,0,0,0-2.36-2.43,2.5,2.5,0,0,0-2.51,2.43Z"></path><path d="M129.83,101.1h-2v5.36c0,1,.49,1.2,1.11,1.2a3.12,3.12,0,0,0,.71-.1l.41,1.91a4.8,4.8,0,0,1-1.43.24c-1.84.06-3.26-.9-3.24-2.85V101.1h-1.47V99.21h1.47V96.73h2.44v2.48h2Z"></path><path d="M131,104.43c0-3.16,1.91-5.35,5-5.35,2.53,0,4.28,1.47,4.45,3.72H138a2,2,0,0,0-2.09-1.75c-1.5,0-2.51,1.25-2.51,3.34s1,3.39,2.51,3.39A2,2,0,0,0,138,106h2.33c-.18,2.2-1.84,3.74-4.44,3.74C132.82,109.77,131,107.57,131,104.43Z"></path><path d="M144.42,109.57H142V95.76h2.39V101h.12a3,3,0,0,1,3.09-1.89c2.15,0,3.56,1.39,3.56,3.9v6.59H148.7v-6.22a2,2,0,0,0-2-2.21,2.15,2.15,0,0,0-2.24,2.36Z"></path><path d="M152.8,104.45c0-3.19,1.94-5.37,4.91-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C154.71,109.77,152.8,107.7,152.8,104.45Zm7.3-1a2.3,2.3,0,0,0-2.36-2.43,2.49,2.49,0,0,0-2.51,2.43Z"></path><path d="M170.09,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c2,.43,2.9,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.15-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.45-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.69-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M178,106.66c0-2.33,1.92-2.93,3.93-3.15,1.83-.19,2.57-.22,2.57-.93v0c0-1-.62-1.59-1.76-1.59a2.06,2.06,0,0,0-2.12,1.31l-2.28-.32c.54-1.89,2.21-2.86,4.39-2.86,2,0,4.21.82,4.21,3.56v6.93h-2.35v-1.42h-.08a3.21,3.21,0,0,1-3,1.63C179.52,109.78,178,108.7,178,106.66Zm6.5-.8v-1.23a7.34,7.34,0,0,1-2.24.51c-1.09.15-1.9.55-1.9,1.48s.72,1.37,1.74,1.37A2.21,2.21,0,0,0,184.53,105.86Z"></path><path d="M191.5,109.57h-2.45V99.21h2.34V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59H195.7v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M199.83,104.41c0-3.46,1.89-5.33,4.28-5.33a3.08,3.08,0,0,1,3,1.84h.1V95.76h2.45v13.81h-2.4v-1.63h-.15a3.13,3.13,0,0,1-3,1.81C201.66,109.75,199.83,107.82,199.83,104.41Zm7.39,0c0-2-.86-3.31-2.44-3.31s-2.46,1.38-2.46,3.31.85,3.36,2.46,3.36S207.22,106.4,207.22,104.39Z"></path><path d="M222.15,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c1.95.43,2.9,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.14-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.45-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.7-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M231.42,101.1h-2v5.36c0,1,.49,1.2,1.11,1.2a3.12,3.12,0,0,0,.71-.1l.41,1.91a4.8,4.8,0,0,1-1.43.24c-1.84.06-3.25-.9-3.24-2.85V101.1h-1.47V99.21h1.47V96.73h2.44v2.48h2Z"></path><path d="M232.53,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S232.53,107.64,232.53,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.51,1.52-2.51,3.42.83,3.39,2.51,3.39S240,106.32,240,104.43Z"></path><path d="M244.15,99.21h2.36v1.73h.11a2.6,2.6,0,0,1,2.56-1.88,5.79,5.79,0,0,1,.87.07v2.25a4.54,4.54,0,0,0-1.13-.14,2.21,2.21,0,0,0-2.33,2.24v6.09h-2.44Z"></path><path d="M251.11,96.42a1.42,1.42,0,1,1,1.42,1.32A1.38,1.38,0,0,1,251.11,96.42Zm.19,2.79h2.44v10.36H251.3Z"></path><path d="M255.43,104.45c0-3.19,1.94-5.37,4.9-5.37,2.55,0,4.74,1.6,4.74,5.23v.75h-7.22a2.55,2.55,0,0,0,2.64,2.81,2.17,2.17,0,0,0,2.2-1.33l2.28.25c-.44,1.8-2.09,3-4.51,3C257.34,109.77,255.43,107.7,255.43,104.45Zm7.3-1a2.31,2.31,0,0,0-2.36-2.43,2.48,2.48,0,0,0-2.51,2.43Z"></path><path d="M272.72,102.19a1.82,1.82,0,0,0-1.91-1.29c-1,0-1.8.48-1.79,1.18s.41,1,1.46,1.21l1.77.37c2,.43,2.91,1.33,2.92,2.81,0,2-1.84,3.3-4.43,3.3s-4.14-1.12-4.44-3l2.38-.23a1.85,1.85,0,0,0,2.05,1.41c1.16,0,1.93-.53,1.93-1.24s-.44-1-1.39-1.18l-1.77-.37c-2-.41-2.92-1.41-2.91-2.92,0-1.92,1.69-3.14,4.18-3.14s3.84,1.12,4.17,2.87Z"></path><path d="M281.25,95.76h2.44v5.16h.1a3.09,3.09,0,0,1,3-1.84c2.4,0,4.28,1.87,4.28,5.33s-1.83,5.34-4.27,5.34a3.14,3.14,0,0,1-3-1.81h-.14v1.63h-2.4Zm4.83,12c1.61,0,2.46-1.42,2.46-3.36s-.83-3.31-2.46-3.31-2.44,1.3-2.44,3.31S284.52,107.75,286.08,107.75Z"></path><path d="M292.27,113.33l.57-2c1.07.31,1.77.22,2.23-.92l.25-.66-3.76-10.58h2.59l2.39,7.83h.1l2.4-7.83h2.59l-4.18,11.71a3.65,3.65,0,0,1-3.64,2.68A4.33,4.33,0,0,1,292.27,113.33Z"></path><path d="M318.74,109.57h-2.23l-6.5-9.41h-.12v9.41h-2.5V95.76h2.24l6.5,9.41h.12V95.76h2.49Z"></path><path d="M320.53,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S320.53,107.64,320.53,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.5,1.52-2.5,3.42.82,3.39,2.5,3.39S328,106.32,328,104.43Z"></path><path d="M334.59,109.57h-2.44V99.21h2.33V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.56,1.41,3.55,3.9v6.59H338.8v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M342.91,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.92,5.34-5,5.34S342.91,107.64,342.91,104.43Zm7.45,0c0-1.9-.82-3.42-2.48-3.42s-2.5,1.52-2.5,3.42.83,3.39,2.5,3.39S350.36,106.32,350.36,104.43Z"></path><path d="M362,95.76l4.1,10h.16l4.1-10h3.06v13.81h-2.4v-9.49h-.13l-3.81,9.45h-1.8l-3.81-9.47h-.13v9.51H359V95.76Z"></path><path d="M375.47,106.66c0-2.33,1.92-2.93,3.93-3.15,1.83-.19,2.56-.22,2.56-.93v0c0-1-.62-1.59-1.75-1.59a2.06,2.06,0,0,0-2.12,1.31l-2.28-.32c.54-1.89,2.21-2.86,4.39-2.86,2,0,4.21.82,4.21,3.56v6.93h-2.35v-1.42H382a3.21,3.21,0,0,1-3,1.63C377,109.78,375.47,108.7,375.47,106.66Zm6.5-.8v-1.23a7.41,7.41,0,0,1-2.24.51c-1.09.15-1.91.55-1.91,1.48s.73,1.37,1.75,1.37A2.21,2.21,0,0,0,382,105.86Z"></path><path d="M386.49,99.21h2.37v1.73H389a2.58,2.58,0,0,1,2.55-1.88,5.92,5.92,0,0,1,.88.07v2.25a4.54,4.54,0,0,0-1.13-.14,2.21,2.21,0,0,0-2.34,2.24v6.09h-2.44Z"></path><path d="M399.47,101.1h-2.05v5.36c0,1,.5,1.2,1.11,1.2a3.33,3.33,0,0,0,.72-.1l.41,1.91a4.88,4.88,0,0,1-1.44.24c-1.83.06-3.25-.9-3.24-2.85V101.1h-1.47V99.21H395V96.73h2.44v2.48h2.05Z"></path><path d="M401.13,99.21h2.45v10.36h-2.45Zm1.8-4.44h2.39l-2.07,3.08h-1.83Z"></path><path d="M408.15,109.57h-2.44V99.21H408V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59h-2.44v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M416.47,104.45c0-3.19,1.93-5.37,4.9-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C418.38,109.77,416.47,107.7,416.47,104.45Zm7.29-1A2.3,2.3,0,0,0,421.4,101a2.5,2.5,0,0,0-2.51,2.43Z"></path><path d="M427.66,108l5.34-6.7v-.08h-5.17v-2H436v1.67l-5.09,6.58v.09h5.26v2h-8.5Z"></path><path d="M441.63,109.57l4.87-13.81h3.08l4.87,13.81h-2.67l-1.14-3.4h-5.2l-1.14,3.4Zm8.33-5.41-1.87-5.57H448l-1.87,5.57Z"></path><path d="M458.24,109.57h-2.45V95.76h2.45Z"></path><path d="M459.92,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S459.92,107.64,459.92,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.5,1.52-2.5,3.42.82,3.39,2.5,3.39S467.37,106.32,467.37,104.43Z"></path><path d="M474,109.57h-2.44V99.21h2.33V101H474a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59h-2.44v-6.22a2,2,0,0,0-2-2.21A2.12,2.12,0,0,0,474,103.5Z"></path><path d="M488.7,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c1.95.43,2.91,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.14-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.44-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.7-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M492.35,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S492.35,107.64,492.35,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.51,1.52-2.51,3.42.83,3.39,2.51,3.39S499.8,106.32,499.8,104.43Z"></path></svg>
    
    

            <p><img src="https://nono.imgix.net/img/u/sketch-191109_apple-fruit-04-and-software-have-in-common.jpg?auto=format%2Ccompress&amp;ixlib=php-3.3.0&amp;w=2500"></p>

    <p><a href="https://sketch.nono.ma/updates-are-available">Software, as fruit, rots.</a> If you leave it there for long enough it will go bad, and programs stop working. When the dependencies of a program and the environment in which it runs get updated, different pieces of code break. You need to re-write parts of it to make it compatible with the latest "breaking changes."</p>
<p>Code maintenance is a labor of love—and even more when your software is open source as other programs might rely on it.</p>
<p>The biggest platform to share and find open-source software is GitHub. The "stars" of a project are the code-equivalent to Instagram or Facebook likes, usually indicative of how likely a repository of code is to withstand the test of time, as they often represent not only the size of a project's community but how quickly code gets fixed when it breaks.</p>


  </div>



  </div><div>
      <p><img src="https://nono.imgix.net/folio/images/veil.gif" data-src="https://nono.imgix.net/img/u/sketch-nono-ma-logo.svg"></p>
<hr>
<p>
My sketches and stories, in&nbsp;your&nbsp;inbox.
</p>

<p><span>One email per week. No spam ever.</span></p>

<p><img src="https://sketch.nono.ma/img/u/profile-nono-ma-sketch.jpg" alt="Pencil sketch of Nono Martínez Alonso.">
</p>


      </div></div>]]>
            </description>
            <link>https://sketch.nono.ma/apples-and-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928491</guid>
            <pubDate>Thu, 29 Oct 2020 08:56:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Sleep Specialist Opinion]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928366">thread link</a>) | @nquryshi
<br/>
October 29, 2020 | https://getontology.com/sleep | <a href="https://web.archive.org/web/*/https://getontology.com/sleep">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://getontology.com/sleep</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928366</guid>
            <pubDate>Thu, 29 Oct 2020 08:27:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Weimarization of the American Republic]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928340">thread link</a>) | @barry-cotter
<br/>
October 29, 2020 | https://www.americanpurpose.com/articles/weimarization-american-republic/ | <a href="https://web.archive.org/web/*/https://www.americanpurpose.com/articles/weimarization-american-republic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

<article>
    <figure id="feature-image-figure">
    <img data-src="/content/images/2020/10/weimarization-1.jpg" alt="" src="https://www.americanpurpose.com/content/images/2020/10/weimarization-1.jpg">
  </figure>



    <section>
      <!--kg-card-begin: html--><p>
    <span>“T</span>he Democratic Party,” wrote the late Walter Laqueur, was “liberal and slightly left-of-centre in outlook, progressive but not too much so, in favour of reform but afraid of going too far. . . . They had quite a few professors among their leading supporters and also some bankers and industrialists, but for the majority of academics . . . [it] was quite unacceptable.” Bourgeois parties “are never militant, almost by definition”—and the “Democratic Party was perhaps the least militant of all.”</p><!--kg-card-end: html--><p>Central to its impotence, Laqueur believed, was “the mood of an activist younger generation.” An “unthinking, aimless radicalism,” which “preferred drums to speeches and parades to long and inconclusive discussions,” could “turn left or right or lead nowhere at all.” Not just on college campuses: “Contempt for ‘the system,’” its “vested interests, cliques, and party caucuses,” permeated the middle class. Leftists “attacked the Republic and all it stood for as something that was rotten through and through,” while conservatives thought “‘the system’ so corrupt that any political order that succeeded it would be an improvement”—even as they complained (correctly) that “the left was anti-patriotic.” Both sides “were unhappy, though for different reasons, with . . . the existing state of affairs.” “There was not the slightest willingness to take each other’s point of view seriously, let alone to compromise.” </p><p>That, at any rate, is how Laqueur saw Weimar Germany with the benefit of hindsight.</p><!--kg-card-begin: html--><p>
    <span>A</span>merica is not Weimar. We have not lost a World War or been forced to pay war debt; we’ve had 250 years of democracy, not 25; Trump isn’t Hitler, and Biden, whatever his faults, isn’t calling for communism. There is street violence, but a lot less of it—for unlike Weimar, we do not generally let paramilitary groups supplant the police, Seattle’s “autonomous zone” being the exception that proves the rule.
</p><!--kg-card-end: html--><p>But the exceptions are mounting. In Portland, protestors <a href="https://www.newsweek.com/protesters-attempt-create-autonomous-zone-portland-graffiti-smoke-pigs-precinct-1513743">attempted to create</a> an autonomous zone of their own by barricading the area with stolen property and blocking the exits of a nearby police precinct; “going to burn the building down,” one man threatened. In Minneapolis, a precinct actually did burn down after it was <a href="https://www.nbcnews.com/news/us-news/protests-looting-erupt-again-minneapolis-area-following-death-george-floyd-n1216881">set ablaze</a> by “demonstrators,” two of whom (<a href="https://www.startribune.com/charges-minneapolis-brothers-destroyed-property-inside-third-precinct/571450752/">both white</a>) were subsequently charged. In Kenosha, riots claimed two lives and several more city blocks, which <a href="https://twitter.com/joshglancy/status/1299734436792197120">were</a> “indistinguishable from a war zone” by the time the dust settled. </p><p>And throughout the country, from <a href="https://www.nytimes.com/2020/06/23/nyregion/nyc-shootings-surge.html">New York City</a> to <a href="https://www.chicagotribune.com/news/criminal-justice/ct-chicago-police-six-month-crime-stats-20200626-wqsf3rebavaldex7v54ozqsnxe-story.html">Chicago</a> to <a href="https://www.washingtonpost.com/local/public-safety/davon-mcneal-shot/2020/07/05/16390c1a-bec6-11ea-b178-bb7b05b94af1_story.html">Washington, DC</a>, shootings have surged alongside looting—in some places, <a href="https://www.newsday.com/long-island/nypd-shootings-increase-1.46044819">by over 400 percent</a>—destroying lives and livelihoods in their wake.</p><p>On its own, this would hardly warrant comparison with Weimar. Crime and violence are as American as apple pie, and street fighting, though aesthetically German, has plenty of precedent in the U.S. What recalls interwar Germany is not the chaos itself, but the way it has been excused, even encouraged, by those notionally in a position to stop it—many of whom seem ambivalent about whether the republic it threatens deserves defense. Examples of this excuse-making include, but are not limited to:</p><ol><li>The true <a href="https://unherd.com/2020/07/the-ugly-truth-about-the-blm-protests/">but trivial claim</a> that the protests have been “mostly” peaceful.</li><li>The argument, made by a <a href="https://www.politico.com/news/magazine/2020/06/03/of-course-destruction-of-property-is-violence-299759">Pulitzer-winning <em>New York Times</em> journalist</a>, that “destroying property, which can be replaced, is not violence.”</li><li>A <a href="https://thenewinquiry.com/in-defense-of-looting/">widely-circulated essay</a>, written during the Ferguson protests of 2014, that defends looting as a “righteous,” attention-grabbing tactic in the fight against white supremacy. (The author subsequently elaborated her arguments in a <a href="https://www.npr.org/sections/codeswitch/2020/08/27/906642178/one-authors-argument-in-defense-of-looting">controversial interview</a> with NPR.)</li></ol><p>It is telling that, despite reaching the same conclusion, these excuses all contradict one another. If violence were extraordinarily rare (1), there would be no reason to deny its status <em>as</em> violence (2), or to defend its tactical value (3)—whereas if looting <em>weren’t</em> violent, if it didn’t disrupt or endanger life, its attention-grabbing power would be extraordinarily diminished. The contradictions suggest that elite alegality isn’t rooted in any specific principle, but rather a kind of inchoate radicalism: a vague, burn-it-down impulse increasingly common across the political spectrum, whose ends are drifting farther and farther apart. If the 2016 election <a href="https://www.vox.com/2016/7/18/12210500/diagnosed-dysfunction-republican-party">seemed to confirm</a> the existence of “asymmetric” polarization, the 2020 tumult suggests that polarization can only remain asymmetric for so long. </p><p>And as the symmetries grow more apparent, the shadow of Weimar grows longer still. Much has been made—<a href="https://www.the-american-interest.com/2018/11/12/resilient-democracies/">too much</a>—of what are ultimately very weak parallels between Donald Trump and Adolf Hitler. But though<strong> </strong>Trump’s America looks nothing like Nazi Germany, it <em>has </em>developed echoes of the Republic from which Nazism arose—echoes that implicate the left no less than the right. Weimar was not, as is sometimes suggested, a good society beset by bigots and bad luck. It was a febrile, dysfunctional culture in which few voters, and even fewer elites, believed in the Republic they eventually dissolved. We often hear about the perils of “<a href="https://www.thenation.com/article/archive/trump-impeachment-journalism/">bothsidesism</a>,” of treating “fascists” and “anti-fascists” as equivalent threats. Yet in the collapse of Weimar Germany, both sides played an important role.</p><!--kg-card-begin: html--><p>
    <span>T</span>o be fair, Weimar didn’t have a whole lot to work with. One of the things it did not have—or rather had stolen—was a well-defined founding. Officially, it began outside the German Reichstag on November 9, 1918, where the Social Democratic minister Philipp Scheidemann proclaimed the birth of the Republic. But unofficially, it began at Hohenzollern Palace two hours later, when the communist leader Karl Liebknecht proclaimed a Republic of his own—the first of many such putsches by Germany’s leftmost wing. The repeated attempts to overthrow the government, and the fact that the Social Democrats, like the communists, claimed to be committed Marxists, made it easy for the right to blame instability on the left, and for the masses to associate that instability with Weimar's socialist architects.
</p><!--kg-card-end: html--><p>But many republics, including ours, had violent foundings. What made Weimar special, as the <a href="https://www.amazon.com/Weimar-Republic-Crisis-Classical-Modernity/dp/0809015560">historian Detlev Peukert put it</a>, was that it “was not marked by an event that served as an old-fashioned but politically unifying . . . moment in national history, along the lines of the American Declaration of Independence.” It had two competing proclamations, two rival origin stories, which meant that there was “no legitimizing founding ritual” to sustain “active commitment to the new order.” Germans did, of course, debate which story was the true one. That it was debated at all both signaled and intensified a profound lack of legitimacy, an open wound ripe for infection. </p><p>These disagreements—less about facts than about symbolism—did not mean collapse was inevitable. (Weimar survived the 1920s, after all.) But they did mean that there were few common reference points to rein in polarization, and more chances for insurgent ideologies—never mind actual insurgents—to gain steam. </p><p>Weimar had no shortage of radicals; centrists, on the other hand, were a dying breed. The intelligentsia fell roughly into one of two camps: leftists who hated everything about Germany, from its culture to its constitution; and rightists who hated the constitution because it was insufficiently German—which is to say, insufficiently authoritarian. The last group dominated the universities, whose reliance on public funds did not dampen their rancor toward the Republic. In fairness, those funds hadn’t stopped the academic job market from cratering after WWI, which meant that even the best-credentialed thinkers were often precariously employed. With few prospects in the existing system, the intellectual class saw little reason to defend it, and had an easy time rationalizing its destruction. The upshot was that college-educated civil servants typically hated the Republic they were serving, as did judges, policymakers, and educators. Ditto artists, journalists, and playwrights, though these professions skewed left. </p><p>Beyond their shared anti-Republicanism, all that the two sides had in common was their contempt for one another. The left derided the right as backwards-looking and chauvinistic, while the right derided the left as self-hating and unpatriotic—all of which, it must be said, was true. Kurt Tucholsky, Weimar’s leading leftwing satirist, complained that “the German spirit was poisoned almost beyond recovery,” and that “German democracy [was] a facade and a lie.” “There is no secret of the Germany army I would not hand over readily to a foreign power,” he bragged in 1931, a boast that did not exactly endear him to the people who took power in ‘33. Those people, of course, were just as Tucholsky described them: irredeemable, backwards bigots whose deaths could not come soon enough.</p><p>But the Nazis never won more than a plurality of the vote—and most conservative elites were not Nazis. (Indeed, several became their victims.) What united the right was not a particular political program, but a general sense of grievance against the far left and republican center, distinct groups it would often synonymize. Marxism, modernism, liberalism—these were all shades of the same thing, corruptions of the old order. An equal but opposite elision occured on the left, with the communists calling everyone to their right—including the Social Democrats—fascists, an unfair charge that many leftwing intellectuals nonetheless echoed. The result of these stereo-stereotypes was threefold.</p><p>First, they exacerbated Weimar’s crisis of legitimacy. If the Republic lacked a founding ritual, the elites were in no hurry to invent one; rather, the “center” was so widely anathematized that it effectively didn’t exist. In one case, <a href="https://www.warhistoryonline.com/instant-articles/communists-allied-with-nazis.html">the communists even endorsed a Nazi referendum</a> to overthrow the Social Democratic government in Prussia, on the theory that social democracy was a greater threat than National Socialism. Status …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.americanpurpose.com/articles/weimarization-american-republic/">https://www.americanpurpose.com/articles/weimarization-american-republic/</a></em></p>]]>
            </description>
            <link>https://www.americanpurpose.com/articles/weimarization-american-republic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928340</guid>
            <pubDate>Thu, 29 Oct 2020 08:23:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Add WhatsApp Chat Button to your website for free]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928309">thread link</a>) | @marky_nolan
<br/>
October 29, 2020 | https://www.wati.io/whatsapp-chat-button/ | <a href="https://web.archive.org/web/*/https://www.wati.io/whatsapp-chat-button/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          		<div data-elementor-type="wp-page" data-elementor-id="9963" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="8c37f33" data-element_type="section">
						<div>
				<div>
				<div data-id="49453f9" data-element_type="column">
			<div>
					<div>
				<div data-id="ee6f3ef" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2><span>Generate WhatsApp Live Chat Widget</span></h2>		</p>
				</div>
				
				<div data-id="d273749" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="html.default">
				<div>
			
<div>
    <div>
        <div>
            <p>
                Chat Button Settings
            </p>
            <p>
                Customise chat button settings - Choose chat button design, Set color &amp; change CTA text.
            </p>
            <p><b>Button Style</b>: All possible &amp; attractive button designs.
            </p>
            <p><b>Background Color</b>: Choose any color to get personalize WhatsApp Chat button.
            </p>
        </div>
    </div>
    <div>
        <div>
            
            
            <div>
                <div>
                    <p>Position</p>
                    <p>Bottom-Left
                       Bottom-Right
                    </p>
                </div>
                
            </div>
        </div>
    </div>
</div>

<div>
    <div>
        <div>
            <p>Chat Widget settings</p>
            <p>Customize the chat widget heading, help text and change settings as you wish.</p>
        </div>
    </div>
    <div>
        <div>
            
            <div>
                <div>
                    <p>Phone Number with country code</p>
                    
                </div>
            </div>
            
            
            
            <div>
                <div>
                    <p>Open widget by default</p>
                    <p>True
                        False
                    </p>
                </div>
                <div>
                    <p>Chat Widget Preview</p>
                    <div id="whatsappChatWidgetPreview">
                        <div>
                            <div id="whatsappChatWidgetHeaderPreview"><p><img src="https://cdn.clare.ai/wati/images/WATI_logo_square_2.png" id="whatsappChatWidgetBrandImagePreview" alt="Brand Image"></p><div>
                                    <p>WATI</p>
                                    <p>Typically replies within a day</p>
                                </div>
                                <p><img src="https://cdn.shopify.com/s/files/1/0070/3666/5911/files/Vector.png?574"></p>
                            </div>
                            <div>
                                <div>
                                    <p>WATI</p>
                                    <p>Hi, there!
                                        <br>How can I help you?</p>
                                </div>
                            </div>
                            
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

		</div>
				</div>
				
				
				
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
		        </div>
    </div></div>]]>
            </description>
            <link>https://www.wati.io/whatsapp-chat-button/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928309</guid>
            <pubDate>Thu, 29 Oct 2020 08:19:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is data quality and how to improve it]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928298">thread link</a>) | @mmanja
<br/>
October 29, 2020 | https://www.keboola.com/blog/data-quality | <a href="https://web.archive.org/web/*/https://www.keboola.com/blog/data-quality">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Learn more about data quality, its importance for your business, and how to improve it. </p><div><p>We’ve all heard the war stories born out of wrong data:</p><ol role="list"><li>Important packages are sent to the wrong customer.</li><li>Double payments are made to suppliers due to corrupted invoicing records.</li><li>Sales opportunities are missed because of incomplete product records.<br></li></ol><p>These stories don’t just make you and your company look like fools, they also cause great economic damages. And the more your enterprise relies on data, the greater the potential for harm.<br></p><p>Here, we take a look at what data quality is and how the entire data quality management process can be improved.</p><h2>What is data quality?&nbsp;</h2><p>Defining data quality is an elusive task. Even though we have an intuitive feeling that it relates to data of high standards, the exact definition is tough to pin down.&nbsp;Various institutions, academics, and industry experts have tried to specify the characteristics of data integrity in their definitions of data quality.&nbsp;<br>‍</p><p>For example, Fleckenstein and Fellows (2018) refer to high-quality data as data that<br></p><blockquote><em>"are fit for their intended uses in operations, decision making and planning</em>"</blockquote><p>In a similar vein, the National Institute of Standards and Technology defines data quality as:</p><blockquote>"<em>the usefulness, accuracy, and correctness of data for its application</em>"&nbsp;</blockquote><p>So, unless we are a student trying to pass an exam in data management processes, why do we care about these definitions?<br></p><p>It’s clear from the definitions above that both are oriented towards the pragmatic aspects of data quality. <strong>Having high-quality data allows us to plan, make decisions, and use data in various applications.</strong><br></p><p>But why does <em>this </em>matter?<br></p><p>Data quality has huge ramifications on the business’s bottom line. Having a clear understanding (definition) of what constitutes data quality allows us to measure and fix it.<br></p><p>Let’s dive deeper into why data quality is so important.<br></p><h2>Why is data quality important?</h2><p>The war stories mentioned in the introduction speak volumes about the importance of data. But the quality of data is important for a multitude of other reasons:</p><ol role="list"><li><strong>Data quality affects the bottom line</strong>. Low-quality or corrupted data will affect your business operations from a financial standpoint. From increased expenses when making mistakes (returns of goods sold, double invoicing, etc.) to loss of financial opportunities (negotiating lower supply costs, missing out on sales due to incomplete data or lack of customer trust, etc.), low-quality data costs more than it first might seem.</li><li><strong>Data quality affects trust in data</strong>. When issues with data quality are discovered, you lose trust. Customers may not trust you because you’ve made mistakes, while business leaders might not find the data reliable for decision-making. Whatever the case, low data quality has long-term damaging effects on the reputation of data and the people who take care of it.</li><li><strong>High-quality data is necessary for data products</strong>. We’re running businesses in an age when more and more products depend on data. Whether it’s applications that use customer data to provide services (financial investment apps, sports apps, etc.) to machine learning products that base their entire performance on data, having high-quality data for your product is the same as having high-quality fuel for your rocket ship. Unless the fuel is of a superior standard, the rocket is not going to fly. Or as machine learning engineers say: “Garbage in, garbage out.” Bad data is just not going to cut it. Ensuring that data is as good as it possibly can be is a prerequisite for a high-performing product line.<br></li></ol><h2>What are the common data quality issues?	</h2><p>There are as many issues with data quality as there are data experts with war stories.&nbsp;<br></p><p>Ask any data engineer or architect and they will gladly share how a database design or analytics implementation led to a massive business debacle.&nbsp;<br>To understand the recurrent issues surrounding data quality, we have to group these issues around common themes, which are known as the dimensions of data quality.<br></p><p>There are multiple dimensions of data quality which matter:&nbsp;</p><ol role="list"><li><strong>Data accessibility or availability</strong>. Access to data is necessary if we want to analyze it and draw conclusions that lead to profitable business insights. Issues regarding data accessibility can happen at any stage along the <a href="https://www.keboola.com/blog/etl-process-overview" target="_blank">ETL pipeline</a>. Our data collection could be broken, skipping the import of some datasets into our database, or we could encounter a problem with sharing permissions, which prevents analysts from accessing the data required for their analysis. This also hinders the collaboration between different analysts because they lack access to the data that is needed to work together.</li><li><strong>Data accuracy or correctness</strong>. Accuracy refers to how well the data reflects the real world that it’s trying to describe. This characteristic of data quality is hard to specify in data-quality standards because accuracy issues take on many forms, from changing addresses that are not updated within customer records to misspellings and wrongful insertions. Data accuracy is usually asserted by applying business rules within the <a href="https://www.keboola.com/blog/etl-process-overview" target="_blank">data cleansing</a> process, which checks the data for correctness.&nbsp;</li><li><strong>Data completeness or comprehensiveness</strong>. Missing data values always present an issue within data operations. Ensuring that the records are complete is one of the characteristics of high-quality data. During the <a href="https://www.keboola.com/blog/the-ultimate-guide-to-data-cleaning" target="_blank">data cleaning</a> process, the data assets with missing values are either removed or they are imputed with the best estimates as replacements.</li><li><strong>Data consistency, coherence, or clarity</strong>. When two records about the same unit hold conflicting information, they are not just inconsistent - they also dampen your ability to make data-driven decisions. And let’s not even think about the regulatory compliance issues you can get into if your financial reports show inconsistent data...</li><li><strong>Data relevance, pertinence, or usefulness</strong>. You might have collected all of the data in the world, but it’s completely useless if it’s not relevant to your analysis and your business. Collecting relevant or useful data (and discarding the rest) is part of data quality assurance.</li><li><strong>Data timeliness or latency</strong>. How quickly is the data available to us? If there is a delay between collecting data from its data sources and analyzing it, we could lose out on the potential of real-time analytics. If the delays are even longer, we might produce reports before all of the data is available, thus painting an incorrect picture between what is reported (with missing data) and what is actually true (with delayed data).&nbsp;</li><li><strong>Data uniqueness</strong>. Some data is unique by design, such as the UUID number of your product, or the identity of your customers. The common issue in data quality is record duplication, whereby the same information is inserted multiple times. This issue usually arises during data entry, especially if it’s done manually.</li><li><strong>Data validity or reasonableness</strong>. Valid data are those that are in line with the business or technical constraints. For example, your customer is probably not 140 years old, so it’s likely that there’s a validity issue here. But validity does not just refer to semantic constraints (such as age). It also includes the distribution of data and its aggregated metrics. Looking at the mean, median, mode, standard deviations, outliers, and other statistical characteristics allows you to discern the validity of your data.<br></li></ol><h2>Who is responsible for data quality?</h2><p>Data quality is everyone’s business because good data quality allows everyone to trust the process and do their best work. However, depending on the type of operations you run, different people might be responsible for asserting high-quality data.<br></p><p>In enterprises and cross-organizational deployments, there is usually a data management team in charge of asserting data quality. The team comprises a data manager, who oversees the entire data quality assurance operation, as well as practitioners who resolve technical conflicts and data stewards. The latter are responsible for communicating data quality issues and problem resolutions across the silos within the business.<br></p><p>In smaller organizations, startups, and home-businesses, the responsibility often falls on the shoulders of the ‘data person’ (data scientist, business analyst, or data engineer) or someone from the IT department.&nbsp;<br></p><p>How do these teams and individuals achieve high-quality data? They go through the cycle of data quality management and improve it.<br></p><h2>How to improve data quality</h2><p>There is a process of best practices when improving the quality of your data:</p><ol role="list"><li><strong>Start by setting up a data governance framework</strong>. The data governance framework specifies which standards you will follow and what business requirements and rules need to be applied to achieve high-quality data. This also includes regulatory compliance, i.e. how your data quality practices fulfill the European Union's General Data Protection Regulation (GDPR) and/or California Consumer Privacy Act (CCPA) regulations.&nbsp;</li><li><strong>Set up KPIs or goals for data quality</strong>. Identify the data quality dimensions that need fixing and specify them as KPIs. A common way to assess how much ‘data accuracy’ has been improved is to measure the number of data assets (tables, databases, ETL pipelines, etc.) that you have checked for accuracy issues. Make sure that you also set up a logging system for data quality reporting.</li><li><strong>Profile data and establish a list of issues</strong>. Data profiling refers to the analysis of data which produces a report on data distribution, frequencies, central tendencies, and deviations. This can then be used in understanding the structural level of data. Use this and other analyses to compile a list of issues which need fixing.</li><li><strong>Fix the issues</strong>. It’s as simple as that - fix them. This is usually done by data practitioners (hands-on data managers, data engineers, and data scientists) by cleaning the data (we have written a long guide on the <a href="https://www.keboola.com/blog/the-ultimate-guide-to-data-cleaning" target="_blank">best practices for cleaning data - check it out here</a>). Be sure to log every fix so that you can generate a report of …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.keboola.com/blog/data-quality">https://www.keboola.com/blog/data-quality</a></em></p>]]>
            </description>
            <link>https://www.keboola.com/blog/data-quality</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928298</guid>
            <pubDate>Thu, 29 Oct 2020 08:16:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to build an amazing router and firewall with OpenBSD: Part 1]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928202">thread link</a>) | @URfejk
<br/>
October 29, 2020 | https://unixsheikh.com/tutorials/how-to-build-an-amazing-router-and-firewall-with-openbsd-part-1-introduction.html | <a href="https://web.archive.org/web/*/https://unixsheikh.com/tutorials/how-to-build-an-amazing-router-and-firewall-with-openbsd-part-1-introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<div id="abstract"><p>In this multi-part tutorial I'm going to show you how you can use cheap and "low end" hardware to build an amazing router with firewalling capabilities, DNS, DHCP and much much more, using the fantastic OpenBSD operating system. I am going to use a setup in which the router segments the local area network (LAN) into separate networks, one for the grown-ups in the house, one for the children, and one for public facing servers, such as a private web server or mail server. I'll also show you how you can use DNS to effectively block out most ads, porn, and many harmful websites on the Internet. Last, but not least, I'll show you how you can use the firewall to block outgoing telemetric data from computers running Microsoft Windows, NVIDIA graphics drivers, etc. The router can also be used on small to mid-size offices.</p><p>If you don't need a segmented network, but simply need a solid firewall and/or DNS server, you can still use the tutorial as I am going to guide you step by step introducing and setting up one solution at a time.</p></div>

<h3>Table of contents</h3>
<ul>
<li><a href="#why-a-firewall">Why a firewall?</a></li>
<li><a href="#the-hardware">The hardware</a></li>
<li><a href="#the-network">The network</a></li>
<li><a href="#why-openbsd">Why OpenBSD?</a></li>
</ul>

<h2 id="why-a-firewall">Why a firewall?</h2>
<p>Almost no matter how you connect to the Internet from your home or office you need a real firewall between you and the modem or router that your ISP has provided you with.</p>
<p>I have worked for quite some time in the ISP business and if there is one thing I can tell you for sure, it is that not only do they rarely keep your modem or router firmware up to date, they almost always use some of the most miserable products on the market.</p>
<p>One of the sources for most of the SPAM email on the Internet originates from consumer market modems and routers that has been compromised.</p>
<p>With a firewall between you and the Internet, meaning the modem or router from your ISP, you can not only protect your computers much better, but you can also monitor the traffic that comes and goes to and from your house, and you can react to situations that might call for an alarm.</p>
<p>Without a firewall between your local network and the ISP modem or router you could basically consider this an open door policy, like leaving the door to your house wide open, because you cannot trust the equipment from your ISP.</p>
<p>At one particular ISP I have even witnessed how some employees used to hack into customers computers using the services that the ISP provided. Of course the ISP didn't know that at the time, but this illustrates my point very well.</p>
<p>It is always a really good idea to put a real firewall between your local network and your ISP and with OpenBSD you get a very solid solution.</p>

<h2 id="the-hardware">The hardware</h2>
<p>You don't have to buy expensive hardware to get an effective router and firewall for your house or office. Even with cheap and "low end" hardware you can get a very solid solution.</p>
<p>I have build multiple setups using the <a href="https://www.asrock.com/mb/Intel/Q1900DC-ITX/">ASRock Q1900DC-ITX</a> motherboard that comes with an Intel Quad-Core Celeron processor.</p>
<p><img src="https://unixsheikh.com/includes/img/asrock-q1900dc-itx.png" alt="ASRock Q1900DC-ITX motherboard"></p>
<p>I'll admit, it's a pretty "crappy" motherboard, but it gets the job done and I have several builds that have run very solid for many years on gigabit networks with full saturation and the firewall, DNS, etc. working "overtime" and the CPU hardly breaks a sweat. This is contrary to the extremely expensive Soekris, which people used to recommend, that typically ran less powerful Intel Atom processors not capable of saturating a gigabit network.</p>
<p>The ASRock Q1900DC-ITX motherboard has the advantage that it comes with a DC-In Jack that is compatible with a 9~19V power adapter, making it very power saving.</p>
<p>The ASRock Q1900DC-ITX motherboard is no longer sold, but I'm just using it as an example because I have used several of these boards in the past.</p>
<p>I have also used the ASRock Q1900-ITX (it doesn't come with the DC-In Jack) combined with a PicoPSU.</p>
<p><img src="https://unixsheikh.com/includes/img/picopsu.png" alt="PicoPSU power supply"></p>
<p>You can find different brands and versions of the PicoPSU, some are better quality than others. I have two different brands, the original and a cheaper knockoff, both performing very well and they save quite a bit of power contrary to running with a normal power supply that typically requires at least 10 watts more.</p>
<p>Lastly, I am using a cheap Intel knockoff quad port NIC found on Ebay like this one:</p>
<p><img src="https://unixsheikh.com/includes/img/intel-quad-nic.png" alt="Intel Quad NIC"></p>
<p>Now before you start condemning me for using low end hardware, I know it is better to use quality hardware, especially on a network that you care about, but this tutorial is about how you can get away with using fairly cheep hardware and still get an extremely useful product that will continue to serve you well for many years - at least that is my experience.</p>
<p>I recommend that you look for a low power mini ITX board with hardware <a href="https://www.openbsd.org/amd64.html">supported by OpenBSD</a> such as an Intel Celeron or Intel i3 processor. These boards are typically cheap, less power hungry, and they don't take up very much space. I don't recommend using the Intel Atom CPU if you have a gigabit network as they usually choke because they can't handle the amount of traffic, but your milage may vary. Also, I have never had any luck finding any useful AMD boards because the CPU usually would require much more power than the Intel counterpart - however my experience with AMD is mostly outdated and I haven't used AMD for many years. I also don't recommend older dual core Intel CPU's, they will work perfectly, but they also require more power.</p>
<p>Oh, and then you need a couple of cheap gigabit switches too for the segmented LANs, at least if you have more than one computer you want to connect to the same LAN :)</p>

<h2 id="the-network">The network</h2>
<p>A router is basically a device that regulate network traffic between two or more separate networks. The router will ensure that network traffic intended for the local network doesn't run out into the wild on the Internet and traffic on the Internet, that is not intended for your local network, stays on the Internet.</p>
<p><strong>Note</strong>: Just for information, a router is sometimes also referred to as a gateway, which generally is alright in layman's terms, but in truth a real gateway joins dissimilar systems. An example of a gateway would be a device that joins a PC network with a  telecommunications network.</p>
<p>In this tutorial we're building a router and we have 4 different but similar networks to work with. One is the Internet and the other three are the internally segmented LANs. Some people prefer to work with virtual LANs, but in this tutorial I'm going to use the quad port NIC from above. You can achieve the same result by using multiple one port NICs if you prefer that, you just have to make sure that you have enough room and free PCI slots on the motherboard. You can also use the Ethernet port on the motherboard itself, but it depends on the driver and support for the device. I have had no problems using the typical Realtek PCI gigabit Ethernet controller that normally comes with many motherboards even though I recommend Intel over Realtek.</p>
<p>Of course you don't need to segment the network into several parts if you don't need that, and it will be very easy to change the things I setup in this tutorial, but I have decided to use this approach in order to show you how you can protect your children by segmenting their network into a separate LAN that not only gets ad and porn blocking using DNS (all the segments gets that), but you can even whitelist the parts of the Internet you want them to have access to. The last part about whitelisting is difficult and generally not recommended unless your children are very small and only requires very limited access, but it is doable with some work.</p>
<p>This is an illustration of the network we're going to setup:</p>
<pre><code>
                       Internet
                          |
                    xxx.xxx.xxx.xxx
                    ISP Modem (WAN)
                      10.24.0.23
                          |
                       OpenBSD
                      10.24.0.50
                  (router/firewall)
                          |
     -------------------------------------------
     |                    |                    |
    NIC1                 NIC2                 NIC3
192.168.1.1          192.168.2.1          192.168.3.1
LAN1 switch          LAN2 switch          LAN3 switch
     |                    |                    |
     -- 192.168.1.2       -- 192.168.2.2       -- 192.168.3.2
     |  Grown-up PC       |  Child PC1         |  Public web server
                          |
                          -- 192.168.2.3
                          |  Child PC2
</code></pre>
<p>The IP addresses that begins with 10 are whatever IP addresses your ISP router gives you, in my case it looks similar to the above. The IP addresses beginning with 192 are IP addresses that we're going to use in our local network.</p>
<p>I have not dealt with any kind of wireless connectivity in this setup. Wireless chip firmware is notoriously buggy and exploitable and I recommend you don't use any kind of wireless connections if you can do without. If you do require wireless connections I strongly recommend that you disable wireless access completely from the ISP modem or router (if possible), and then buy the best wireless router you can find and put it behind the firewall in an isolated segment instead. That way should your wireless device ever be compromised you can better control the outcome and limit the damage. You can further setup the wireless router such that any devices connected to it have their own IPs that pass directly through the wireless router, but at the same time block traffic directly originating from the router itself. That way you can prevent the wireless router from "phoning home". You can also get a wireless adapter supported by OpenBSD and have your OpenBSD machine run as the actual access point, however I much prefer to segment the wireless part to either a separate wireless router or another OpenBSD machine serving as a wireless access point behind the firewall itself. Also, as of writing (as far as I know) none of the OpenBSD wireless drivers are fully without problems.</p>

<h2 id="why-openbsd">Why OpenBSD?</h2>
<p>In truth, you can get a similar setup running almost any …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://unixsheikh.com/tutorials/how-to-build-an-amazing-router-and-firewall-with-openbsd-part-1-introduction.html">https://unixsheikh.com/tutorials/how-to-build-an-amazing-router-and-firewall-with-openbsd-part-1-introduction.html</a></em></p>]]>
            </description>
            <link>https://unixsheikh.com/tutorials/how-to-build-an-amazing-router-and-firewall-with-openbsd-part-1-introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928202</guid>
            <pubDate>Thu, 29 Oct 2020 07:58:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FakeMBAM: Backdoor delivered through software updates]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928188">thread link</a>) | @URfejk
<br/>
October 29, 2020 | https://decoded.avast.io/janvojtesek/fakembam-backdoor-delivered-through-software-updates/ | <a href="https://web.archive.org/web/*/https://decoded.avast.io/janvojtesek/fakembam-backdoor-delivered-through-software-updates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2217">

                    
                    
                    
                    <div>
                        
<p>Many applications can be updated automatically and without any user interaction. This is commonly considered a good practice from the security point of view, since it allows for quick distribution of patches for critical vulnerabilities. However, automatic updates also carry an additional risk because they allow the software developers to push arbitrary code to users’ machines. Unfortunately, users often have no choice but to trust the developers that they will only use the update channel for its intended purpose and that they will protect it from malicious third parties.</p>



<p>In this blog post, we’ll show that this trust might sometimes be misplaced. Specifically, we’ll show how one torrent client and three adblockers surreptitiously installed the FakeMBAM backdoor through automatic updates. We reverse engineered this backdoor and describe its inner workings in the second part of this post.</p>



<h2>An unexpected infection vector</h2>



<p>We recently <a href="https://blog.avast.com/fake-malwarebytes-installation-files-distributing-coinminer" target="_blank" rel="noreferrer noopener">reported on a fake Malwarebytes installer</a> that we detected on over 100,000 machines protected by Avast. This installer attempted to pass itself off as the legitimate Malwarebytes installer, mimicking it to a great extent – it was distributed under the same filename, it used the same icon and it created a Malwarebytes installation directory containing legitimate PE files digitally signed by Malwarebytes. However, that was all just a pretense, because the installer did not actually install Malwarebytes. In fact, the installer’s main purpose was to open a backdoor to attacker-controlled servers in order to give its operators the ability to push additional malicious payloads to the infected machines.&nbsp;</p>



<div><figure><img loading="lazy" width="829" height="509" src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/map_logo.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/map_logo.png 829w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/map_logo-300x184.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/map_logo-768x472.png 768w" sizes="(max-width: 829px) 100vw, 829px"><figcaption>A map illustrating the distribution of Avast users protected from the FakeMBAM backdoor. The backdoor is most active in Russia, Ukraine and Kazakhstan.</figcaption></figure></div>



<p>In our first report, we stated that we did not know how this fake installer was being distributed. Since then, we spent some time reverse engineering the malware and investigating its infection vector. We found that the fake installer was pushed to the victims’ machines through automatic updates of one torrent client (<code>download[.]studio</code>) and three adblockers (<code>netshieldkit[.]com</code>, <code>myadblock[.]com</code> and <code>netadblock[.]com</code>). Listed on the websites of these applications are three different companies that are supposedly behind these applications, “Sigma Software”, “GRAND MEDIA, TOV” and “Birmon Software”. However, based on high code similarities and shared infrastructure (and on the fact that they all distributed the very same piece of malware), we consider it very likely that there is one actor behind all four applications.&nbsp;</p>



<h3>Download Studio</h3>



<p>To investigate the infection vector used to distribute the fake installer, we first turned to the metadata that was submitted to us when we detected the installer in the wild. This provided us with two important clues: The installers were supposed to be executed with the command line arguments <code>/SP- /VERYSILENT /SUPPRESSMSGBOXES /NORESTART /NOCANCEL /NOICONS</code>, by a process named <code>dstudio-gui.exe</code>. The first clue suggested that the installer was not supposed to be spread through social engineering, because the above arguments instruct Inno Setup to install software silently in the background. The second clue hinted at the possible suspect: Download Studio.</p>



<div><figure><img loading="lazy" width="1024" height="699" src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/ds_website-1024x699.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/ds_website-1024x699.png 1024w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/ds_website-300x205.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/ds_website-768x524.png 768w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/ds_website.png 1163w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A screenshot of the Download Studio product page.</figcaption></figure></div>



<p>Download Studio is a free torrent client popular in Russia and Ukraine. It features an embedded library of torrent files, offering a wide selection of movies, software, video games, music and more. As is usually the case with torrent downloaders, there is a lot of copyrighted material that can be easily downloaded for free using this software, which seems to be the main reason why it is so widespread. Download Studio is detected by some anti-malware software as a potentially unwanted program (PUP) or as riskware, because it encourages illegal behavior and puts its users at risk through downloading torrents of unknown origin.</p>



<div><figure><img loading="lazy" width="1024" height="639" src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/ds_screenshot-1024x639.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/ds_screenshot-1024x639.png 1024w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/ds_screenshot-300x187.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/ds_screenshot-768x479.png 768w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/ds_screenshot.png 1234w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A screenshot of Download Studio’s movie library.</figcaption></figure></div>



<p>To clear up some potential confusion, let us state that there is also another piece of software named Download Studio: <a href="http://www.conceiva.com/products/downloadstudio/default.asp" target="_blank" rel="noreferrer noopener">a download manager developed by Conceiva</a>. Apart from the name, this software has nothing in common with the torrent client described in this blog post and there is therefore no reason to doubt its legitimacy. In the rest of this blog post, the name Download Studio will denote the torrent client described in the previous paragraph.</p>



<p>Since Download Studio can be used to download various software, it would make sense to think that the fake Malwarebytes installer was distributed through it as a regular torrent file (after all there were 609 results when we searched for “Malwarebytes” inside Download Studio). However, that would not explain the command line arguments that we observed in the wild. They simply indicated that running the installer was not a user-initiated action and that the user might not have been aware of the installer at all. Furthermore, the number of users that we protected from the fake installer matched our estimates of the number of Avast users running Download Studio, which made it look like Download Studio itself was somehow responsible. Therefore, we decided to reverse engineer it to see if it contained hidden malicious code.&nbsp;</p>



<p>We immediately found some evident code similarities with the FakeMBAM backdoor. Both Download Studio and the backdoor were developed using the Qt framework and they both used the very same string obfuscation methods. One of the obfuscation methods was particularly interesting, because it was not very effective at, well, obfuscation. It consisted of XORing the obfuscated string twice with the same mask, so the plaintext was clearly visible in the disassembly.</p>



<figure><ul><li><figure><img loading="lazy" width="333" height="525" src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/obf_dstudio-1.png" alt="" data-id="2296" data-full-url="https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/obf_dstudio-1.png" data-link="https://decoded.avast.io/?attachment_id=2296" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/obf_dstudio-1.png 333w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/obf_dstudio-1-190x300.png 190w" sizes="(max-width: 333px) 100vw, 333px"></figure></li><li><figure><img loading="lazy" width="332" height="539" src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/obf_backdoor-1.png" alt="" data-id="2297" data-full-url="https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/obf_backdoor-1.png" data-link="https://decoded.avast.io/?attachment_id=2297" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/obf_backdoor-1.png 332w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/10/obf_backdoor-1-185x300.png 185w" sizes="(max-width: 332px) 100vw, 332px"></figure></li></ul><figcaption>Obfuscation of the string <code>.tmp</code> as seen in Download Studio (left) and in the FakeMBAM backdoor (right).</figcaption></figure>



<p>Other code similarities were found in a piece of code that computed HMAC of custom HTTP headers or in a piece of code that created scheduled tasks using the <code>ITaskService </code>COM interface. We also found that Download Studio contained a string with the exact command line arguments that we mentioned earlier. These arguments were used to execute application updates silently in the background. By reverse engineering Download Studio, we also found that the application updates are supposed to be executed from a temporary directory the name of which can be described by the regular expression <code>ds-\d{7}\.tmp</code>, which further matched our metadata from detections of the fake installer.</p>



<div><figure><img src="https://lh6.googleusercontent.com/EYMmgDsZBnHuIzdKo7GQt5DdYt6l7syDb4q3c1qFhXzhW4qMCp8SuY2yl0csbOzTBRbt-0p5zDqgY5X8BM4SdnQN1b1nSG7neF4-80rOm2-x9HK7ci-S7XagvX8tXUcUJQjwcmb-" alt=""><figcaption>Disassembled snippet of Download Studio, showing the code responsible for execution of automatic updates.</figcaption></figure></div>



<p>At this point, it seemed almost certain that the backdoor was distributed through the automatic updates of Download Studio. However, we wanted to be absolutely sure that this was the case, so we monitored the updates and logged the filename and hash of each observed update. This gave us the following list:</p>



<figure><table><tbody><tr><td>SHA-256</td><td>filename</td></tr><tr><td><code>16d0559067f3cc0ab19e22b935ac90d44897f09f3426f858498dfd7e667c4bda</code></td><td><code>updater.exe</code></td></tr><tr><td><code>1d77fdc7f1b1efc8bdb0938cacc713baa70a2549412ce0be18adf2ebd133cb70</code></td><td><code>updater-full.exe</code></td></tr><tr><td><code>333dd34d3efc4ded71b36f5fc38bce67de71f80b7fab43358a36e8ba7d4df0f0</code></td><td><code>updater.exe</code></td></tr><tr><td><code>5822d2b9717cc2a87ba54173587a3808e17f5961f42f5b1702c4a75950ecd4f6</code></td><td><code>updater.exe</code></td></tr><tr><td><code>6754c5e7d3c03f4e2bf29b013b1a0d532b7f4e8e145da82e6973376785938f65</code></td><td><code>DS-updater-1.8.0.0-full.exe</code></td></tr><tr><td><code>9c112b452ce839536a5cd4a3d8f4999adcb03dc3af5cbd86ca3a477c5b75127b</code></td><td><code>updater.exe</code></td></tr><tr><td><code>b1acc87c7b010f4aafbe03cd70a6452679de07ef31bc2d5701de63d573654615</code></td><td><code>updater.exe</code></td></tr><tr><td><code>b3359c92cd87bd39ecbf8159666f2c7e123903751654bb8aefd714e23f8e7f7f</code></td><td><code>updater.exe</code></td></tr><tr><td><code>b4039b6a15af681d7c02d1ff798f41023a378668b32132761c8cdffd648a5a5d</code></td><td><code>DS-updater-1.8.0.0.exe</code></td></tr><tr><td><code>c759c6fffe3d32424f8b29b58ee5cb11d68be5f27e50ba1d1a4755fb56602f7d</code></td><td><code>updater.exe</code></td></tr><tr><td><code>dfb1a78be311216cd0aa5cb78759875cd7a2eeb5cc04a8abc38ba340145f72b9</code></td><td><code>MBSetup.exe</code></td></tr><tr><td><code>f2caa14fd11685ba28068ea79e58bf0b140379b65921896e227a0c7db30a0f2c</code></td><td><code>MBSetup.exe</code></td></tr></tbody></table></figure>



<p>Just based on the filenames alone, the last two entries immediately stand out. Indeed, while all the previous entries correspond to legitimate updates of Download Studio, the last two hashes are the fake Malwarebytes installers that we have been investigating. They were executed in the same way as all the other automatic updates, silently in the background and without the users’ awareness.&nbsp;</p>



<p>This means that someone tried to infect all users of Download Studio with the FakeMBAM backdoor. While we do not know precisely what happened behind the scenes, there are three possible scenarios that come to mind. The first one would be that the developers of Download Studio wished to “monetize” their large install base in a very unethical way. Code reuse between Download Studio and the FakeMBAM backdoor would suggest that this could be the case. Another explanation is that the backdoor was spread by a group of rogue employees who acted without the knowledge of the rest of the company. Finally, it is also possible that some unknown attacker hacked Download Studio and carried out a successful supply chain attack.</p>



<p>We were looking for some answers and so we reached out to the developers of Download Studio, asking about the backdoor. They claimed that they detected a security incident on their continuous integration server in August 2020 and that they have since thoroughly investigated this incident and put additional security measures in place. They did not respond to our additional inquiries about how many of their users could be impacted by this incident and if they notified the impacted users.</p>



<h3>Adblockers</h3>



<p>Download Studio was not the only software that distributed the FakeMBAM backdoor. We also found three adblockers whose automatic updates were abused in the same fashion. These adblockers are NetShield Kit (<code>netshieldkit[.]com</code>), My AdBlock (<code>myadblock[.]com</code>) and …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://decoded.avast.io/janvojtesek/fakembam-backdoor-delivered-through-software-updates/">https://decoded.avast.io/janvojtesek/fakembam-backdoor-delivered-through-software-updates/</a></em></p>]]>
            </description>
            <link>https://decoded.avast.io/janvojtesek/fakembam-backdoor-delivered-through-software-updates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928188</guid>
            <pubDate>Thu, 29 Oct 2020 07:53:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Deep]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928173">thread link</a>) | @brendt_gd
<br/>
October 29, 2020 | https://sebastiandedeyne.com/going-deep/ | <a href="https://web.archive.org/web/*/https://sebastiandedeyne.com/going-deep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p><a href="https://sebastiandedeyne.com/going-deep/"><time datetime="2020-10-20">October 20, 2020</time>
| 1 min read</a></p></header><section><div><p>I recently stumbled across an over 5 year old <a href="https://news.ycombinator.com/item?id=8902739">comment</a> on Hacker News about performance.</p><blockquote><p>Lots of people make the mistake of thinking there’s only two vectors you can go to improve performance, high or wide.</p><ul><li>High - throw hardware at the problem, on a single machine</li><li>Wide - Add more machines</li></ul><p>There’s a third direction you can go, I call it “going deep”. Today’s programs run on software stacks so high and so abstract that we’re just now getting around to redeveloping (again for like the 3rd or 4th time) software that performs about as well as software we had around in the 1990s and early 2000s</p><p>Going deep means stripping away this nonsense and getting down closer to the metal, using smart algorithms, planning and working through a problem and seeing if you can size the solution to running on one machine as-is.</p></blockquote><p>The author talks about “high” and “wide” hardware changes, but this can apply to software too. It’s easier to throw a cache at a slow piece of code than going deep and fixing it.</p><p>No need to look far, Electron is built on this principle. We’re adding heavy runtimes to support multiple platforms instead of staying close to the metal, and we pay the price in performance.</p><p>In general, it’s easier to add than subtract.</p><p>Which leads me to Derek Siver’s thoughts on <a href="https://sive.rs/subtract">subtraction</a>.</p><blockquote><p>Life can be improved by adding, or by subtracting. The world pushes us to add, because that benefits them. But the secret is to focus on subtracting.</p><p>The adding mindset is deeply ingrained. It’s easy to think I need something else. It’s hard to look instead at what to remove.</p></blockquote><p>Adding is often a short-term solution. This isn’t necessarily a bad thing: time and budget restrictions are real problems. Adding often accrues more debt than subtracting, that’s the price we pay. Adding doesn’t save time, it lends time.</p></div></section></article></div>]]>
            </description>
            <link>https://sebastiandedeyne.com/going-deep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928173</guid>
            <pubDate>Thu, 29 Oct 2020 07:50:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book Review: “Live Not by Lies”]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928165">thread link</a>) | @johntfella
<br/>
October 29, 2020 | https://conciliarpost.com/reviews/book-reviews/book-review-live-not-by-lies/ | <a href="https://web.archive.org/web/*/https://conciliarpost.com/reviews/book-reviews/book-review-live-not-by-lies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>A lot can change in three years.Â&nbsp;</span></p><p><span>In March of 2017, I found myself sitting in my New Haven apartment, with just a few months to go before graduating from law school, penning a </span><a href="https://www.google.com/search?client=safari&amp;rls=en&amp;q=ehrett+benedict+option&amp;ie=UTF-8&amp;oe=UTF-8"><span>review</span></a><span> of Rod Dreherâ€™s buzzy new book, </span><a href="https://www.amazon.com/Benedict-Option-Strategy-Christians-Post-Christian/dp/0735213291"><i><span>The Benedict Option</span></i><span>.</span></a><span> While I appreciated its diagnosis of modern thought and clarion call to action, Iâ€™ll admit that I didnâ€™t buy into its full vision. Following the unexpected results of the 2016 election and the prospect of a federal government under unified Republican control, I thought the bookâ€™s dire depictions of creeping post-Christian orthodoxies were prematureâ€”and I had no interest whatsoever in (what I understood to be) a call to public disengagement. At the end of the day, I was relatively sanguine about the future of â€œliberalâ€� discourse (in the best sense) in the academic world, coupled with an influential Christian witness in the public sphere. I was, in short, fully â€œ</span><a href="https://www.patheos.com/blogs/betweentwokingdoms/2019/06/the-death-of-liberal-democracy-a-few-notes-on-the-ahmari-french-controversy/"><span>Team French</span></a><span>.â€�Â&nbsp;</span></p><p><span>The world looks different now, though. Since graduating, Iâ€™ve spent my professional career at ground zero of current debates over religious liberty and the place of people of faith in public lifeâ€”from serving in the federal judicial system in California and Texas, to writing numerous </span><a href="https://www.supremecourt.gov/DocketPDF/19/19-431/121116/20191101154131639_Little%20Sisters%20Amicus%20Brief%20TO%20FILE.pdf"><span>amicus</span></a> <a href="https://www.supremecourt.gov/DocketPDF/19/19-431/137551/20200309164825846_Little%20Sisters%20Merits%20Amicus%20Brief%20TO%20FILE.pdf"><span>briefs</span></a><span> at a large D.C. law firm, and finally to working on these issues on Capitol Hill. Institutionally, I have every incentive in the world to believe that American cultural pathologies can be addressed through better policy, or at least that some sort of uneasy political equilibrium can be brokered.Â&nbsp;</span></p><p><span>But despite my best efforts, Iâ€™ve come to see that Dreher was right: there needs to be a â€œPlan Bâ€� for the future of American Christianity. What Matthew Arnold </span><a href="https://www.poetryfoundation.org/poems/43588/dover-beach"><span>called</span></a><span> the â€œmelancholy, long, withdrawing roarâ€� of the sea of faith continues to echo across the American landscape, and the shapes of thoroughly post-Christian ideologies are now coming into view. Revival has indeed come to America, as so many Christians prayedâ€”but not a Christian revival.</span><span>Â&nbsp;</span></p><p><span>Dreherâ€™s latest book, </span><a href="https://www.amazon.com/Live-Not-Lies-Christian-Dissidents/dp/0593087399"><i><span>Live Not By Lies: A Manual for Christian Dissidents</span></i></a><span>, is something of a manifesto for this moment. At once both darker and more hopeful than its predecessor, it is ruthlessly clear-eyed about the precise threats it identifies, and yet equally clear-eyed about the ways in which ordinary Christians ought to respond to them. Perhaps most significantly, the book feels uncommonly personal, thanks to its heavy reliance on the stories of Eastern European Christians who lived through the Soviet Unionâ€™s totalitarianismâ€”an analogy to the status quo that, as Dreher repeatedly points out, is admittedly imperfect, but that nevertheless provides a foundation for important reflections.</span></p><p><span>Much of </span><i><span>The Benedict Option</span></i><span> outlined an extended genealogy of the Western predicament (in the style of Brad Gregoryâ€™s </span><a href="https://www.amazon.com/Unintended-Reformation-Religious-Revolution-Secularized/dp/0674088050"><i><span>The Unintended Reformation</span></i></a><span>, Richard Weaverâ€™s </span><a href="https://www.amazon.com/Richard-M-Weaver/dp/022609006X/ref=sr_1_1?crid=1YWMGX6DZ0I5U&amp;dchild=1&amp;keywords=idea+have+consequences&amp;qid=1596043224&amp;s=books&amp;sprefix=ideas+have+%2Cstripbooks%2C268&amp;sr=1-1"><i><span>Ideas Have Consequences</span></i></a><span>, and Patrick Deneenâ€™s </span><a href="https://www.amazon.com/Why-Liberalism-Failed-Politics-Culture/dp/0300240023/ref=sr_1_1_sspa?crid=3994184DHHDAN&amp;dchild=1&amp;keywords=why+liberalism+failed&amp;qid=1596043235&amp;s=books&amp;sprefix=why+li%2Cstripbooks%2C270&amp;sr=1-1-spons&amp;psc=1&amp;spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUEyQUhQMThJWEU4U0o5JmVuY3J5cHRlZElkPUEwMDAzNzE1MVJaMlJCQ01LU09HQyZlbmNyeXB0ZWRBZElkPUEwNTY1NDA3MTg4M1E5MkI5STQ4USZ3aWRnZXROYW1lPXNwX2F0ZiZhY3Rpb249Y2xpY2tSZWRpcmVjdCZkb05vdExvZ0NsaWNrPXRydWU="><i><span>Why Liberalism Failed</span></i></a><span>), but </span><i><span>Live Not By Lies </span></i><span>takes a different tack. This time around, Dreher sees danger ahead as a result of the confluence of three specific intersecting elements: cultural decadence and stagnation, a neo-religious progressive ideology, and the rise of â€œsurveillance capitalism.â€�</span></p><p><b>The Age of Decay</b></p><p><span>The American public, Dreher argues, is ripe for unrest. As a long line of social scientistsâ€”from </span><a href="https://www.amazon.com/Bowling-Alone-Collapse-American-Community/dp/0743203046"><span>Robert Putnam</span></a><span> to </span><a href="https://www.amazon.com/Coming-Apart-State-America-1960-2010/dp/030745343X/ref=pd_lpo_14_t_2/131-4027336-5851305?_encoding=UTF8&amp;pd_rd_i=030745343X&amp;pd_rd_r=e9c8da75-0443-4cda-b566-2704261e1249&amp;pd_rd_w=vwR1j&amp;pd_rd_wg=FicQv&amp;pf_rd_p=7b36d496-f366-4631-94d3-61b87b52511b&amp;pf_rd_r=NH2ATV9JB56AGKC40PHQ&amp;psc=1&amp;refRID=NH2ATV9JB56AGKC40PHQ"><span>Charles Murray</span></a><span>â€”has argued for years, American civil society has grown thin and deracinated. Rates of church attendance and community participation are down, fewer and fewer Americans have close real-life friends or host in-person gatherings, and an ever-increasing number of human interactions are channeled through a handful of powerful online platforms. (The ongoing COVID-19 pandemic, of course, has only accelerated these trends.)Â&nbsp;</span></p><p><span>Worse, faith in institutionsâ€”with the exception of the militaryâ€”has cratered. There is widespread cynicism, particularly among younger Americans, about the self-dealing of governmental branches, corporations, religious organizations, and countless other entities. It is increasingly difficult to see how a flourishing society can be built on foundations that are rottenâ€”or at least believed to be rotten by a large majority. Unless one accepts Ross Douthatâ€™s recent </span><a href="https://www.patheos.com/blogs/betweentwokingdoms/2020/03/the-decadent-society-misses-the-mark/"><span>argument</span></a><span> that the current state of â€œdecadenceâ€� can go on indefinitely, it certainly seems like something has to change.</span></p><p><b>The Great Awokening</b></p><p><span>Â&nbsp;</span><span>Nature, of course, abhors a vacuumâ€”and under conditions of socioeconomic stagnation and widespread disillusionment, itâ€™s only natural that nontraditional manifestations of human beingsâ€™ innate religious impulses have emerged.</span></p><p><span>To that end, Dreher discusses at length the emergence, within the last 5-6 years, of what a number of writers have called the â€œsocial justice movementâ€� (Dreher tends to use the pejorative â€œsocial justice warrior,â€� or â€œSJWâ€�) and what Wesley Yang </span><a href="https://twitter.com/wesyang/status/1130852792929677312"><span>describes</span></a><span> as the â€œsuccessor ideologyâ€�â€”the successor, that is, to liberal democracy. Philosophically, Dreher argues, this movement is loosely structured around five central tenets: (1) the central fact of human existence is power and how it is used; (2) there is no such thing as objective truth; there is only power; (3) identity politics sorts oppressed from oppressor; (4) intersectionality is social justice ecumenism; (5) language creates human realities.</span><span>Â&nbsp;</span></p><p><span>This movement largely rejects what is seen as the â€œclass reductionismâ€� of orthodox Marxism (that is, its failure to emphasize other axes of oppression, such as race and gender), but nevertheless shares classical Marxismâ€™s commitment to a broad narrative of inevitable historical progress. Just as traditional Marxism represented itself as an â€œobjectiveâ€� science, the successor ideology frames itself as supra-ideological by generating reams of peer-reviewed material within academic disciplines that are </span><i><span>a priori</span></i><span> committed to its governing premises. And so, on this view, right-thinking and science-minded people have an absolute duty to help society move from a benighted history of oppression into a more just and equitable future, even if that future can only be vaguely conceived. (No slogan better exemplifies this than the ubiquitous demand that one stand on the â€œright side of history.â€�) For the committed activist, </span><i><span>everyone</span></i><span>â€”not merely isolated idealistsâ€”needs to be a part of that process.Â&nbsp;</span><span>Â&nbsp;</span></p><p><b>The Invisible Hand</b></p><p><span>As Dreher explains, the last few years have witnessed a rapid and (for those of a conservative temperament) alarming transformation of American capitalism. While for decades, companies adopted a fairly apolitical attitude toward public lifeâ€”as Michael Jordan put it, â€œRepublicans buy sneakers tooâ€�â€”recent years have taught that thereâ€™s good money to be made in adopting aggressive stances on political and cultural issues.</span></p><p><span>Nowhere, Dreher notes, has this tendency been more pronounced than in the world of â€œbig tech.â€� Not only are the largest tech companies accumulating unheard-of amounts of data on their users (a point Dreher draws from Shoshana Zuboffâ€™s </span><a href="https://www.amazon.com/Age-Surveillance-Capitalism-Future-Frontier/dp/1541758005/ref=sr_1_1?crid=2XPALZ08A8IAB&amp;dchild=1&amp;keywords=the+age+of+surveillance+capitalism&amp;qid=1596043284&amp;s=books&amp;sprefix=the+age+of+sur%2Cstripbooks%2C179&amp;sr=1-1"><span>work</span></a><span>), but virtually every day brings another example of technology giants deploying their platform rules unevenly or in a discriminatory manner. Conservative opinion websites (well above Breitbart quality level) </span><a href="https://nypost.com/2020/07/22/ex-google-worker-says-bug-may-have-exposed-conservative-blacklist/"><span>mysteriously disappear</span></a><span> from Google search results. Amazon gives the Southern Poverty Law Centerâ€”which </span><a href="https://www.dailysignal.com/2020/05/21/conservatives-ask-amazon-to-end-splcs-role-as-hate-group-sheriff/"><span>labels</span></a><span> Christian organizations like the Family Research Council and Alliance Defending Freedom as â€œhate groupsâ€� due to their stance on LGBT rights issuesâ€”veto power over eligibility for its AmazonSmile charitable giving program. Twitter </span><a href="https://www.hollywoodreporter.com/news/unplanned-movie-twitter-account-briefly-suspended-1198343"><span>censors</span></a><span> pro-life accounts while </span><a href="https://www.timesofisrael.com/as-twitter-checks-trump-khamenei-account-left-alone-despite-pleas-from-israel/"><span>permitting</span></a><span> Iranâ€™s Ayatollah Khameini to threaten the total destruction of Israel. On and on it goes, with no real end in sight.</span></p><p><span>In part, it seems to me, this patchwork pattern of enforcement is likely a product of the ungrounded approach to regulating free speech many tech platforms have adopted. The prevailing approach, it appears, is inclined to credit almost any claim asserted by enough people under the banner of â€œhuman rightsâ€�â€”an approach which tends to rule out any questioning or invalidation of a group-based identity one happens to claim. Conservatives, many of whom would hold that not all identity-based claims reflect legitimate human rights issues, are generally loath to expand the category of what counts as â€œhuman rights.â€� But arguments to that effect are easily framed as impediments to â€œprogressâ€� and expressions of â€œhateâ€�: who wants to stand in the way of â€œhuman rightsâ€� or be on the â€œwrong side of historyâ€� after all? And so, deprived of any real metaphysical underpinnings, the discourse ends up </span><a href="https://www.patheos.com/blogs/betweentwokingdoms/2019/11/is-human-rights-too-inflated-an-ideal/"><span>rigged</span></a><span> in favor of ever-more-expansive rights-claims, and ever-narrower boundaries of permitted expression.</span></p><p><span>Violation of those boundaries, of course, comes at a heavy price. Itâ€™s no wonder that, following a </span><a href="https://www.theatlantic.com/ideas/archive/2020/06/stop-firing-innocent/613615/"><span>handful</span></a><span> of high-profile denunciations of ordinary people, â€œcancel cultureâ€� is in the </span><a href="https://harpers.org/a-letter-on-justice-and-open-debate/"><span>news</span></a><span> right now, Those not inclined to see the current Twitter-mob culture as a problem tend to treat these cases as isolated instances that do not reflect a greater trend. Perhaps. But it is not at all difficult to conceive of what a truly </span><i><span>totalizing</span></i><span> â€œcancel cultureâ€� might look like, or how close we are to that reality.</span></p><p><span>Imagine a world in which you are simultaneously fired from your job, cut off by banks and credit-card companies no longer wishing to transact with you, and denied access to any prominent technology platforms like Apple, Google, Facebook, Twitter, Uber, DoorDashâ€”with the reasons for your â€œcancellationâ€� preserved in perpetuity. (Do you really think any of these companies would hold the line in the face of a social media activist avalanche?) Worse, the power of surveillance capitalism obliterates the possibility of simply moving to a new town, finding a new job, and reinventing oneself. You are abandoned into permanent nonperson status (unless …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://conciliarpost.com/reviews/book-reviews/book-review-live-not-by-lies/">https://conciliarpost.com/reviews/book-reviews/book-review-live-not-by-lies/</a></em></p>]]>
            </description>
            <link>https://conciliarpost.com/reviews/book-reviews/book-review-live-not-by-lies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928165</guid>
            <pubDate>Thu, 29 Oct 2020 07:48:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with Hashnode]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928120">thread link</a>) | @kmhmubin
<br/>
October 29, 2020 | https://mubinsodyssey.com/getting-started-with-hashnode | <a href="https://web.archive.org/web/*/https://mubinsodyssey.com/getting-started-with-hashnode">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1603956252941/I7k2XbtM3.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p><a target="_blank" href="https://hashnode.com/@kmhmubin/joinme">Hashnode</a> is a free blogging platform with an amazing community that allows you to publish articles on your own domain. On October 27, 2020, Hashnode achieves <strong>Product of the day</strong> on <a target="_blank" href="https://www.producthunt.com/posts/hashnode-platform">Producthunt</a>.</p>
<p>Hashnode gaining popularity because of its unique features and easy to use. It has lots of built-in features that every technical blogger needs. Let's find out what makes hashnode different.</p>
<h2 id="free">Free</h2>
<p>Traditional blog websites require a custom domain and hosting. And it's not cheap. Setting up those and make it fully functional requires a lot of time and technical knowledge. As a beginner, you might not own a custom domain or any of those skills which require setup. To solve this problem, Hashnode offers you a unique subdomain, which allows you to publish your content totally free.</p>
<h2 id="custom-domain">Custom Domain</h2>
<p>Haahnode offers you to add your custom domain to your existing blog. You can set up a custom domain with a CNAME record. </p>
<h2 id="customization">Customization</h2>
<p>You can personalize and customize your blog as you need. You can make your blog look different by adding custom CSS. Not only custom CSS, but you can also add third-party widgets.</p>

<p>Hashnode has an amazing community. You can meet new people every day. You can get help from others or sharing your thought with others. Hashnode also offers you an exclusive <a target="_blank" href="https://discord.gg/9KVywS">Discord Channel</a>, where you can directly talk with the founding members of Hashnode.</p>
<h2 id="learn-from-others">Learn from others</h2>
<p>On Hashnode, you can follow other developers. You can read their content and follow them so that your favorite writer publishes a post you get notified immodestly. </p>
<h2 id="draft-sharing">Draft Sharing</h2>
<p>I personally like this feature. If you are new to writing, you always feel that is it enough or lack something or fully explain what I wanted to. To answer all of those content, you can share your draft with others. They can read your draft and give you a lot of feedback.</p>
<h2 id="other-features">Other features</h2>
<p>Some of the other features are</p>
<ul>
<li>Get automated backups of your articles on your private GitHub repo</li>
<li>Use GitHub as a source for your articles</li>
<li>Automatic HTTPS</li>
<li>Fast CDN</li>
<li>Built-in newsletter service</li>
</ul>
<p>The good thing is that you can always request new features, which are implemented depending on usefulness. </p>
<h2 id="conclusion">Conclusion</h2>
<p>If you want to start publishing your own articles without worries and want an amazing community, Hashnode is for you.</p>
<p>In the next lesson, we’ll learn how to set up Hashnode for you.</p>
<hr>
<p>🚩👉 If it was useful to you, please Like/Share to reach others as well. Please hit the <strong><em>Subscribe</em></strong> button at the top of the page to get an email notification on my latest posts.</p>
<p>You can @ me on <strong>Twitter</strong> (<a target="_blank" href="https://twitter.com/kmhmubin">kmhmubin</a>) with comments, or feel free to follow.</p>
<p>The cover image is an improvisation on top of the work from <a target="_blank" href="https://www.freepik.com/vectors/people">freepik</a>.</p>
</div></div></section></div>]]>
            </description>
            <link>https://mubinsodyssey.com/getting-started-with-hashnode</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928120</guid>
            <pubDate>Thu, 29 Oct 2020 07:34:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Connect a Barcode Scanner to an Electron Desktop App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24928099">thread link</a>) | @kornatzky
<br/>
October 29, 2020 | https://yoramkornatzky.com/post/connect-a-barcode-scanner-to-an-electron-desktop-app | <a href="https://web.archive.org/web/*/https://yoramkornatzky.com/post/connect-a-barcode-scanner-to-an-electron-desktop-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div data-type-cleanup="true">
<p><a href="https://www.electronjs.org/">Electron</a> is a cross-platform framework for building desktop apps with JavaScript, HTML, and CSS. </p>
<p>In agricultural, industrial, and logistics integrated facilities, such desktop apps often need to read information from barcodes and QR codes printed on real-life physical objects. </p>
<p><img src="https://cdn-images.postach.io/09bd0397-0710-42f1-8919-9b1de0319ead/ce07e1db-ca22-6788-0271-799da9a1db81/6c2930d7-e6bf-3f81-e9a3-c442058c2d6d.png"></p>
<p><img src="https://cdn-images.postach.io/09bd0397-0710-42f1-8919-9b1de0319ead/ce07e1db-ca22-6788-0271-799da9a1db81/82db0290-1e17-6945-cfda-5209bf26c0a6.png"></p>
<p>Such barcodes and QR codes are scanned with a barcode scanner such as <a href="http://www.zebra.com/DS4308">Zebra DS4305 Digital Scanner</a> connected to the computer with a USB connector.</p>
<p><img src="https://cdn-images.postach.io/09bd0397-0710-42f1-8919-9b1de0319ead/ce07e1db-ca22-6788-0271-799da9a1db81/bc21ecf7-8096-0a7f-3769-7f7f85f0a99e.png"></p>
<p>Receiving the code into the Electron app turns up to be very simple. The scanner is viewed as a keyboard. </p>
<p>So if you have in the HTML an <code>input</code> element,</p>
<pre><code>&lt;input id="codeInput"/&gt;
</code></pre>
<p>And we focus the program on the input field, using JavaScript,</p>
<pre><code>document.getElementById("codeInput").focus();
</code></pre>
<p>The scanner reads the code into the input field like it was typed in by the keyboard.</p>

</div>
</div></div>]]>
            </description>
            <link>https://yoramkornatzky.com/post/connect-a-barcode-scanner-to-an-electron-desktop-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928099</guid>
            <pubDate>Thu, 29 Oct 2020 07:27:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bootstrapped to €14m in ARR with Emeric Ernoult of Agorapulse]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928083">thread link</a>) | @Mike-Dane
<br/>
October 29, 2020 | https://keevi.io/from-bootstrapped-to-14m-in-10-years-with-emeric-ernoult-of-agorapulse | <a href="https://web.archive.org/web/*/https://keevi.io/from-bootstrapped-to-14m-in-10-years-with-emeric-ernoult-of-agorapulse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-id="4dcbfdb" data-element_type="section">
						<div>
							<div>
					<div data-id="dbc9a3e" data-element_type="column">
			<div>
							<div>
						<div data-id="9040520" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><a href="https://www.linkedin.com/in/ernoult/?originalSubdomain=fr"><span>Emeric Ernoult</span></a><span>, Co-Founder at Agorapulse joins </span><a href="https://www.linkedin.com/in/hammadakbar/"><span>Hammad Akbar</span></a><span> in this episode of Launch Legends Podcast.</span></p><h2>Key Stats on Agorapulse</h2><ul><li><a href="https://www.agorapulse.com/"><span>Agorapulse</span></a><span> ARR was </span><span>€</span><span>140,000 in 2011.</span></li><li><span>In 2013-2014, Agorapulse was adding </span><span>€1000 MRR per month.</span></li><li><span>Broke even in 2015 and reached </span><span>€</span><span>100,000 MRR.</span></li><li><span>Now, it’s adding around </span><span>€</span><span>45,000 MRR per month.</span></li><li><span>€14m in ARR in 2020.&nbsp;</span></li><li><span>Got 7000 customers.</span></li></ul><h2>Key Takeaways</h2><ul><li><span>Making a product does not matter, what matters is how you market your product.</span></li><li><span>Pivot to new ideas when the existing idea is not producing any result.</span></li><li><span>Realize that when you are bootstrapped, your product is always limited</span></li><li><span>Develop a saas software that a person in the company is using on a daily basis.</span></li><li><span>You move slowly when you are bootstrapped and have limited resources.</span></li><li><span>When you are bootstrapped, your growth is slow and you lose a lot of business to big players who have raised funding.</span></li><li><span>Customer churn rate helps you determine whether a business is sustainable or not.</span></li><li><span>Content and SEO are the major source of traction.</span></li><li><span>Attend conferences to build relationships which can be beneficial during a product launch.</span></li><li><span>Work hard in the initial years to reach out to a place where you want to be.</span></li><li><span>Building a good product is not enough, there should be a way for letting the world know about it.</span></li><li><span>The effort you put initially might not be enough at the later stage of the business.</span></li><li><span>Look at the growth and progress of the last six months to determine if you should continue with the idea or not.</span></li><li><span>If you don’t see the needle moving in the right direction then stop following the same strategy.</span></li><li><span>If you have been stagnated, another six months would produce the same result.</span></li><li><span>If there is a little bit of improvement, then keep going.</span></li><li><span>Don’t expect progress to be massive.</span></li><li><span>Think long term</span></li><li><span>What you will do today will determine where you reach in the future.</span></li><li><span>Paid marketing is not a solution when it comes to product launch.</span></li><li><span>Word of mouth gives better results when you are launching a new product.</span></li><li><span>You should be clear enough what is needed to get the results at a later stage.</span></li><li><span>Always reinvent yourself.</span></li><li><span>One has to be ambitious to grow.</span></li><li><span>You need to be different from others.&nbsp;</span></li></ul><h2>Transcription</h2><p><b>Hammad:</b></p><p><span>Thank you very much for being on the show. So </span><a href="https://www.agorapulse.com/"><span>Agorapulse</span></a><span>, I know you told me you’ve got around $14 million in revenue, subject to exchange rate, because I know you calculate everything in euros, and you’ve got 7,000 customers and most of the customers are coming through your inbound efforts. So before we get there let’s talk about who you are and what you were doing before </span><a href="https://www.agorapulse.com/"><span>Agorapulse</span></a><span> and why did you start the company?</span></p><p><b>Emeric:</b></p><p><span>Thanks for having me. I’m </span><a href="https://www.linkedin.com/in/ernoult/?originalSubdomain=fr"><span>Emeric</span></a><span>, I’m a French citizen born in New York. So I also have the US passport which makes me a funny beast because I’m both American and French, which is a weird mix. I started my career as a business lawyer in 1995. So that’s my background. It didn’t last for long because I did that for five years and started my first company in 2000 with my co-founder Ben, who is still my co-founder today. So basically Ben and I started this company, the company behind </span><a href="https://www.agorapulse.com/"><span>Agorapulse</span></a><span> in July of 2000, 20 years ago. And, we’ve tried to be successful many many times, pivoting many different times as well, and eventually started the Agorapulse in November of 2011.</span></p><p><b>Hammad:</b></p><p><span>So Emeric, I am cutting you there. When you say that you are pivoting, what was the company you started in 2000. And what did you pivot to?&nbsp;</span></p><p><b>Emeric:</b></p><p><span>It was a b2b SaaS already. It was called communities at the time. It did sound a lot like Facebook, but it was in 2000, it was in France, it was in French. So it was not a success. A lot of my friends keep telling me you invented Facebook for Facebook and I keep replying to them, the hundreds of people have invented Facebook before Facebook like Friendster, six degrees and </span><a href="https://myspace.com/"><span>Myspace</span></a><span>.</span></p><p><span>So a lot of people had this idea that social networking should be a thing before it was a thing and I always wanted them, but it didn’t work. And I was too early, we had debates with my co-founder at the time about the word social network, he didn’t like it. We launched that at a time when social networking was not a thing and people didn’t agree on what it meant so that it tells you something.&nbsp;</span></p><p><span>We did that until 2009, approximately. And, what we did in the meantime is we created a b2b Saas that was white labeled for brands. And that’s what we’ve lived with in terms of making revenue and money between 2001 to 2012. So basically we were customizing the affinities. That was the named solution, putting CSS, HTML, CSS, and different codes and SSO and that kind of stuff.</span></p><p><span>So a brand could create its own community of passionate people about anything or bloggers or stuff like that. An American company did the same thing. It was creating your own social network. That’s what we were doing. But we started that year before them.</span></p><p><span>And, I like to say that, Marc Andreessen was behind inc. And I like to say that I was as smart as Marc Andreessen as we both failed at creating a b2b Saas software that allows all people to create their own social networks and yeah in 2011, we were trying to sell this, build your own social network to brands.</span></p><p><span>And every brand I was talking to were like, nah, nah we go on Facebook and do something there. It was like an introductory 10 meetings like that. I told my co-founder that’s it, you know, we can’t fight Facebook. This thing is going to take over the world.</span></p><p><span>We heard do something on Facebook or we give up. I’m fed up of making little money. Just to give you perspective in 2011, our ARR was </span><span>€</span><span>140,000. That’s what I make in three days or four days right now. So that was my ARR back then. So it gives you an idea of, you know, how far we have come.</span></p><p><b>Hammad:</b></p><p><span>How much were you taking home at that time?</span></p><p><b>Emeric:</b></p><p><span>Nothing. I was not taking home anything. You can’t take home anything when you’re making so little money? My co-founder was getting a little because he was single and he had to. My wife was making some money and I had unemployment allowance for a while and I did other jobs on the side. So I always struggled for a long time.</span></p><p><span>It was years and years of being minimum wage, unemployment, side gigs. I did run companies for clients as a manager for several years where I was basically running their company from Monday through Thursday and doing mine on Friday, Saturday and Sunday.&nbsp;</span></p><p><span>So that’s kind of that kind of like until we got somewhere, we have </span><a href="https://www.agorapulse.com/"><span>Agorapulse</span></a><span> which broke even in 2015. And finally I was free.</span></p><p><b>Hammad:</b></p><p><span>Let’s talk about how you transitioned from your previous Saas company to this one. What was the product development strategy? How long did that take and how long before you actually achieve product market fit?</span></p><p><b>Emeric:</b></p><p><span>Well, you know, you have to realize that when you’re bootstrapped your product is always very limited, somewhat not great for a long time. so what the product looked like in the very early days, it was a Facebook contest and promotion. That’s what it was. And then, you know, we added a couple of components to reply to fake comments on the wall.</span></p><p><span>So basically it was only Facebook. It was mostly contest and promotion, because that was a big thing at the time. And we started making some money with that and we had some level of growth when we had some level of product market fit with that alone.</span></p><p><span>But then we realized that the customer churn was very high. Okay. What do we do? So the churn should not be too high because that was a point solution. Funny, you mentioned that in the conversation earlier we had. This book contest and promotion was not a system of record. It was a point solution and that’s not good.</span></p><p><span>So we said, how do we do, how do we become a system of record? We have to be the b2b Saas software that a job in the company is using on a daily basis, or at least on a weekly basis. What is this? It’s a social media management tool. It’s a tool where they go every day to reply to posts who do all that stuff.</span></p><p><span>Let’s do that. Who does that? Whose tweet was doing that at the time? </span><a href="https://sproutsocial.com/"><span>SproutSocial</span></a><span> was not even doing that because they were on Twitter only in 2012. Well it started as a Twitter only and then expanded to the other stuff. And we said, okay, we need to do that. So if we need to do that and stick to people, can they do that only on Facebook?</span></p><p><span>No, they’re not interested. We need to have at least Twitter. That was 2012. Again Instagram was not a thing, LinkedIn barely. And so we started to add Twitter to the mix and then it was okay, now we have Facebook, Twitter, what do you want? And then, they also want this and they also want that. And so in the early days when you bootstrapped, let’s say you’re 15% of where you should be to be a good decent legitimate player in the field of social media management tools, which is a system of record for social media managers or community managers and then because you’re bootstrapped your dev team is very very small. The dev team has been three people for a long time with three people between 2012 and 2013 for the beginning of 2014. So you move slowly because you have very little resources and your product is not perfect.&nbsp;</span></p><p><span>So I would tell you we had product market fit for a full blown social media management tool, it probably was the end of 2016. That means that before that growth is slow it’s there, but it’s slow and you lose a lot of business to big players who have raised money and stuff like that.</span></p><p><span>So you have to be ready to be very patient.&nbsp;</span></p><p><b>Hammad:</b></p><p><span>Emeric, a couple of questions. I mean, first of all, it’s amazing, you stuck with it for five years until you actually brought real traction, but it takes a lot of patience and you just have to stick with it. So from 2011 until 2012, you figured out that what you have in the Facebook contest is not going to be the sustainable business. My question is if it was customer feedback or you just figured out that, look, this is not gonna work.</span></p><p><b>Emeric:</b></p><p><span>We looked at the churn rate. We saw the churn number and we said, there’s no way this is a sustainable business 20% mrr churn every month. Ask …</span></p></div></div></div></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://keevi.io/from-bootstrapped-to-14m-in-10-years-with-emeric-ernoult-of-agorapulse">https://keevi.io/from-bootstrapped-to-14m-in-10-years-with-emeric-ernoult-of-agorapulse</a></em></p>]]>
            </description>
            <link>https://keevi.io/from-bootstrapped-to-14m-in-10-years-with-emeric-ernoult-of-agorapulse</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928083</guid>
            <pubDate>Thu, 29 Oct 2020 07:23:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started With Postgres 13 on Ubuntu 20.04]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928008">thread link</a>) | @i_have_to_speak
<br/>
October 29, 2020 | https://pgdash.io/blog/postgres-13-getting-started.html?h | <a href="https://web.archive.org/web/*/https://pgdash.io/blog/postgres-13-getting-started.html?h">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          
          <p>Setup and start using the latest PostgreSQL version
</p>
        </div>
      </div><div>
        <div>
          <div>
            <p>PostgreSQL 13, the latest release of the Postgres database software, comes with many 
<a href="https://www.postgresql.org/docs/13/release-13.html">under-the-hood improvements</a>.
While being the most popular and versatile open-source RDBMS around, it is not
the easiest to setup and get started. Read on to learn how you can get going
with the latest version of Postgres on the latest LTS version of the Ubuntu
server.</p>

<h3 id="installation">Installation</h3>

<p>Ubuntu 20.04 comes with Postgres 12 from it’s <em>universe</em> repository. Since we
want version 13, we can directly use the PostgreSQL project’s official
<a href="https://wiki.postgresql.org/wiki/Apt">APT repository</a>.
This repository contains binaries for Ubuntu 20.04, and also includes packages
for various extensions that you might want to install later.</p>

<p>Let’s setup the repository like this (note that “focal” is the code name for
Ubuntu 20.04):</p>

<figure><pre><code data-lang="shell"><span># add the repository</span>
<span>sudo tee</span> /etc/apt/sources.list.d/pgdg.list <span>&lt;&lt;</span><span>END</span><span>
deb http://apt.postgresql.org/pub/repos/apt/ focal-pgdg main
</span><span>END

</span><span># get the signing key and import it</span>
wget https://www.postgresql.org/media/keys/ACCC4CF8.asc
<span>sudo </span>apt-key add ACCC4CF8.asc

<span># fetch the metadata from the new repo</span>
<span>sudo </span>apt-get update</code></pre></figure>

<p>We can now install the PostgreSQL server and other command-line tools using:</p>

<figure><pre><code data-lang="shell"><span>sudo </span>apt-get <span>install</span> <span>-y</span> postgresql-13</code></pre></figure>

<p>The installation does a few things:</p>

<ul>
  <li>It installs the PostgreSQL server, utilities and a command-line client called
<strong>psql</strong>.</li>
  <li>It creates a Linux system user called <strong>postgres</strong>.  All data files are owned
by this user, and all processes run as this user.</li>
  <li>It creates a <em>database cluster</em> (see below). In this cluster, it creates a
database, also called <strong>postgres</strong>.</li>
  <li>It creates one PostgreSQL user (<em>not</em> the Linux system user), also called
<strong>postgres</strong>. This PostgreSQL user has superuser privileges.</li>
</ul>

<p>You can see this is beginning to get confusing!</p>

<h3 id="database-clusters">Database Clusters</h3>

<p>In Postgres terms, we now have a single database cluster up and running. A
single database cluster can contain one or more databases. In the database
cluster that we now have, there is a database called “postgres”. (There are
also a couple of “template” databases that we can ignore for now.)</p>

<p>A database cluster is managed by a main postgres process called the <em>postmaster</em>.
It spawns various child processes that either perform various system tasks or
handle incoming client connections. Have a look at the currently running
processes:</p>

<figure><pre><code data-lang="text">alice@ubu:~$ ps -o uname,pid,ppid,cmd -H -U postgres
USER         PID    PPID CMD
postgres    4880       1 /usr/lib/postgresql/13/bin/postgres -D /var/lib/postgresql/13/main -c config_file=/etc/postgresql/13/main/postgresql.conf
postgres    4882    4880   postgres: 13/main: checkpointer
postgres    4883    4880   postgres: 13/main: background writer
postgres    4884    4880   postgres: 13/main: walwriter
postgres    4885    4880   postgres: 13/main: autovacuum launcher
postgres    4886    4880   postgres: 13/main: stats collector
postgres    4887    4880   postgres: 13/main: logical replication launcher</code></pre></figure>

<p>Here the postmaster process is 4880 and it has spawned 6 child processes that
handle various housekeeping activities. You can also see the location of the
cluster (<code>/var/lib/postgresql/13/main</code>) and the location of the configuration
file (<code>/etc/postgresql/13/main/postgresql.conf</code>).</p>

<h3 id="reloading-and-restarting">Reloading and Restarting</h3>

<p>At various times, you may need to <em>reload</em> or <em>restart</em> your Postgres server.
Reloading causes Postgres to re-examine it’s configuration files and apply the
changes. If there are no changes to the configuration files, nothing bad happens.
Reloading does not disturb the currently connected clients. To reload your
Postgres server, you can do:</p>

<figure><pre><code data-lang="shell"><span>sudo </span>systemctl reload postgresql</code></pre></figure>

<p>Some configuration changes will take effect only after you restart the server.
This is more disruptive and will disconnect all connected clients. To restart,
you can:</p>

<figure><pre><code data-lang="shell"><span>sudo </span>systemctl restart postgresql</code></pre></figure>

<h3 id="log-files">Log Files</h3>

<p>As you can see, there is a systemd service called <code>postgresql</code> that you can
use to control the postmaster. If the service does not start, you can check
it’s status to check for error messages:</p>

<figure><pre><code data-lang="shell">alice@ubu:~<span>$ </span><span>sudo </span>systemctl status postgresql
● postgresql.service - PostgreSQL RDBMS
     Loaded: loaded <span>(</span>/lib/systemd/system/postgresql.service<span>;</span> enabled<span>;</span> vendor preset: enabled<span>)</span>
     Active: active <span>(</span>exited<span>)</span> since Thu 2020-10-29 04:52:29 UTC<span>;</span> 25min ago
   Main PID: 4557 <span>(</span><span>code</span><span>=</span>exited, <span>status</span><span>=</span>0/SUCCESS<span>)</span>
      Tasks: 0 <span>(</span>limit: 1075<span>)</span>
     Memory: 0B
     CGroup: /system.slice/postgresql.service

Oct 29 04:52:29 ubu systemd[1]: Starting PostgreSQL RDBMS...
Oct 29 04:52:29 ubu systemd[1]: Finished PostgreSQL RDBMS.</code></pre></figure>

<p>The PostgreSQL server writes a log file, which you can check for more detailed
error messages. This file is located at <code>/var/log/postgresql/postgresql-13-main.log</code>:</p>

<figure><pre><code data-lang="shell">alice@ubu:~<span>$ </span><span>cat</span> /var/log/postgresql/postgresql-13-main.log
2020-10-29 04:52:34.096 UTC <span>[</span>4880] LOG:  starting PostgreSQL 13.0 <span>(</span>Ubuntu 13.0-1.pgdg20.04+1<span>)</span> on x86_64-pc-linux-gnu, compiled by gcc <span>(</span>Ubuntu 9.3.0-10ubuntu2<span>)</span> 9.3.0, 64-bit
2020-10-29 04:52:34.097 UTC <span>[</span>4880] LOG:  listening on IPv4 address <span>"127.0.0.1"</span>, port 5432
2020-10-29 04:52:34.099 UTC <span>[</span>4880] LOG:  listening on Unix socket <span>"/var/run/postgresql/.s.PGSQL.5432"</span>
2020-10-29 04:52:34.106 UTC <span>[</span>4881] LOG:  database system was shut down at 2020-10-29 04:52:31 UTC
2020-10-29 04:52:34.112 UTC <span>[</span>4880] LOG:  database system is ready to accept connections</code></pre></figure>

<h3 id="connecting-to-your-postgres-server">Connecting to Your Postgres Server</h3>

<p>Now that we have our server up and running, let’s try to connect to it. By default,
the server listens only for:</p>

<ul>
  <li>TCP connections from 127.0.0.1 on port 5432, and</li>
  <li>Unix domain sockets in /var/run/postgresql</li>
</ul>

<p>Because of the default configuration, the only way to connect to the server
right now is via the Unix socket from a process that is running as the
system user <em>postgres</em>. Let’s run the standard interactive client <em>psql</em> like
this:</p>

<figure><pre><code data-lang="shell">alice@ubu:~<span>$ </span><span>sudo</span> <span>-u</span> postgres psql postgres
psql <span>(</span>13.0 <span>(</span>Ubuntu 13.0-1.pgdg20.04+1<span>))</span>
Type <span>"help"</span> <span>for </span>help.

<span>postgres</span><span>=</span><span>#</span></code></pre></figure>

<p>Here we’re running psql as the system user postgres (“sudo -u postgres psql”)
and connecting to the database called “postgres” (the last “postgres” on the
command-line.) The “postgres=#” prompt indicates the name of the currently
connected database (“postgres”) and that we have superuser privileges (“#” as opposed to
“$”).</p>

<p>The connection happened via Unix sockets (this is the default method in psql).
Since by default the postgres user does not have a password and the default
configuration requires password authentication for TCP connections, it is not
possible to connect over 127.0.0.1:5432 right now.</p>

<h3 id="allowing-incoming-connections-from-an-internal-network">Allowing Incoming Connections From an Internal Network</h3>

<p>First let’s change the configuration to allow connections from an internal
network. Assuming our server’s IP on this network is 10.1.2.3, we can edit
the main configuration file at <code>/etc/postgresql/13/main/postgresql.conf</code> and
change the lines:</p>

<figure><pre><code data-lang="text">#listen_addresses = 'localhost'         # what IP address(es) to listen on;
                                        # comma-separated list of addresses;
                                        # defaults to 'localhost'; use '*' for all</code></pre></figure>

<p>to:</p>

<figure><pre><code data-lang="text">listen_addresses = 'localhost,10.1.2.3'</code></pre></figure>

<p>We also need to tell Postgres to use password authentication for connections
coming in from these networks. For this, edit another configuration file
called <code>/etc/postgresql/13/main/pg_hba.conf</code> and change the line:</p>

<figure><pre><code data-lang="text">host    all             all             127.0.0.1/32            md5</code></pre></figure>

<p>to:</p>

<figure><pre><code data-lang="text">host    all             all             127.0.0.1/32            scram-sha-256
host    all             all             10.1.0.0/16             scram-sha-256</code></pre></figure>

<p>(Assuming the internal network is 10.1.0.0/16.)</p>

<p>We’ve also changed the default <code>md5</code> method to the newer and more secure
<code>scram-sha-256</code>. All other occurances of <code>md5</code> in the file should also be
replaced with <code>scram-sha-256</code>. If your application or database driver does not
support this method, continue to use the <code>md5</code> method instead.</p>

<p>For these changes to take effect, you need to restart the server:</p>

<figure><pre><code data-lang="shell"><span>sudo </span>systemctl restart postgresql</code></pre></figure>

<h3 id="creating-a-regular-user-and-database">Creating a Regular User and Database</h3>

<p>We’re almost there!</p>

<p>We can now create a regular user that our application can connect as, and a
database over which it has full control. Connect as the superuser <em>postgres</em>
locally from the server machine to do this:</p>

<figure><pre><code data-lang="shell">alice@ubu:~<span>$ </span><span>sudo</span> <span>-u</span> postgres psql postgres
psql <span>(</span>13.0 <span>(</span>Ubuntu 13.0-1.pgdg20.04+1<span>))</span>
Type <span>"help"</span> <span>for </span>help.

<span>postgres</span><span>=</span><span># SET password_encryption = 'scram-sha-256';</span>
SET
<span>postgres</span><span>=</span><span># CREATE USER alice PASSWORD 's3cr3tp@ss';</span>
CREATE ROLE
<span>postgres</span><span>=</span><span>#</span></code></pre></figure>

<p>(Omit the first command if you want to use <code>md5</code> instead.) This created a user
called <em>alice</em> with the password <em>s3cr3tp@ss</em>. Let’s also create a database
which this user will own:</p>

<figure><pre><code data-lang="shell"><span>postgres</span><span>=</span><span># CREATE DATABASE app1 OWNER alice;</span>
CREATE DATABASE
<span>postgres</span><span>=</span><span>#</span></code></pre></figure>

<p>The database is called <em>app1</em>. Since <em>alice</em> owns this database, all operations
within the database (like creating tables, inserting rows) are allowed if the
application connects as the user <em>alice</em>.</p>

<p>Let’s try connecting as <em>alice</em>, over the network:</p>

<figure><pre><code data-lang="shell">~<span>$ </span>psql <span>-h</span> 10.1.2.3 <span>-U</span> alice app1
Password <span>for </span>user alice:
psql <span>(</span>13.0 <span>(</span>Ubuntu 13.0-1.pgdg20.04+1<span>))</span>
SSL connection <span>(</span>protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off<span>)</span>
Type <span>"help"</span> <span>for </span>help.

<span>app1</span><span>=&gt;</span></code></pre></figure>

<p>Cool! We’re now connected to the database <em>app1</em> as the user <em>alice</em>.</p>

<h3 id="deleting-databases-backing-up-and-restoring">Deleting Databases, Backing up and Restoring</h3>

<p>Here are a few tricks that can help as you continue working with your Postgres
server:</p>

<h4 id="deleting-a-database">Deleting a database</h4>

<p>You can delete the database you just created (“app1”), like this:</p>

<figure><pre><code data-lang="shell">alice@ubu:~<span>$ </span>psql <span>-h</span> 127.0.0.1 <span>-U</span> alice app1
Password <span>for </span>user alice:
psql <span>(</span>13.0 <span>(</span>Ubuntu 13.0-1.pgdg20.04+1<span>))</span>
SSL connection <span>(</span>protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off<span>)</span>
Type <span>"help"</span> <span>for </span>help.

<span>app1</span><span>=&gt;</span> <span>\c</span> postgres
SSL connection <span>(</span>protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off<span>)</span>
You are now connected to database <span>"postgres"</span> as user <span>"alice"</span><span>.</span>
<span>postgres</span><span>=&gt;</span> DROP …</code></pre></figure></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pgdash.io/blog/postgres-13-getting-started.html?h">https://pgdash.io/blog/postgres-13-getting-started.html?h</a></em></p>]]>
            </description>
            <link>https://pgdash.io/blog/postgres-13-getting-started.html?h</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928008</guid>
            <pubDate>Thu, 29 Oct 2020 07:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Useful Shell Prompt]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927968">thread link</a>) | @quyleanh
<br/>
October 28, 2020 | https://solovyov.net/blog/2020/useful-shell-prompt/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/useful-shell-prompt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>There are only a few apps I use every day and shell — ZSH — is one of the most used. It’s been that way since the beginning of the ’00s and back then I spent a lot of time configuring my prompt to be a good balance between compact/readable and useful. I found that I dislike fancy two-line prompts, information on a right-hand side (because of its awkward behavior), and stuff like that. So the result looks like that:</p>
<pre><code>piranha@rigel ~&gt; █
</code></pre>
<p>where <code>█</code> is a cursor. It shows username, <code>@</code> to separate it from hostname - or <span><code>#</code></span> if this is uid 0 shell, then hostname, and a home-abbreviated path. One of the fancy things is that space before the cursor is Unicode glyph <code>\u00A0</code> - non-breaking space - which is bound in ZLE to delete everything to the beginning of a line. Unfortunately, this does not work with Terminal.app, so it just sits there waiting for a better time. This setup along with colors had no changes for over a decade.</p>
<p>But a week ago a saw a <a href="https://twitter.com/thingskatedid/status/1316081732467081217">tweet</a> with an idea to change prompt’s prompt (the <code>&gt;</code> thingie) to a red color when previous command exited with an error status. This motivated me to cleanup and update my prompt to a newer conventions. This is a result:</p>
<p><img alt="prompt screenshot" src="https://solovyov.net/media/prompt.jpg" height="60px" width="127px"></p>
<p>You can see I removed my username since it really gives me no information, no reason to spend space on that. I also really like white background, but if you don’t, changing colors is easy — I’ll explain how everything works.</p>
<p>Let’s break down it bit by bit. The prompt syntax is a little hard on the eyes - in case if you have ideas on how to write this so next time I won’t have to dig deep into ZSH documentation, I’ll be glad to listen.</p>
<pre><code>p_at='%(!.%F{red}%B#%b%f.@)'
</code></pre>
<p>In this case, few things are interesting:</p>
<ul>
<li><code>%(x.if-true.if-false)</code> construct (documented <a href="http://zsh.sourceforge.net/Doc/Release/Prompt-Expansion.html#Conditional-Substrings-in-Prompts">here</a>) shows either <code>@</code> if I’m a normal user or a red <span><code>#</code></span> if I’m a root.</li>
<li><code>!</code> there means “True if the shell is running with privileges”.</li>
<li>You can clearly see <code>@</code> after the second dot, but what does <code>%F{red}%B#%b%f</code> mean? <code>%B</code> means “start bold”, <code>%b</code> means “end bold”.</li>
<li><code>%F</code>/<code>%f</code> duo is “start/stop color” - it can either accept old-style color numbers (where 1 is red) or color names, which is easier to understand.</li>
</ul>
<pre><code>p_host='%F{blue}%m%f'
p_path='%F{blue}%~%f'
</code></pre>
<p>Those are easy to understand, just refer to <a href="http://zsh.sourceforge.net/Doc/Release/Prompt-Expansion.html">documentation</a> — <code>%m</code> is a hostname before the first dot, <code>%~</code> is a path where <code>$HOME</code> is abbreviated to <code>~</code>.</p>
<pre><code>p_pr='%(?.%F{blue}.%F{red})&gt;%f'
</code></pre>
<p>This is a new part. <code>?</code> means “True if exit status of the last command was 0”. So if a command exited nicely (with a status code 0), then it’s going to be blue <span><code>&gt;</code></span>, in other case it’s going to be red <span><code>&gt;</code></span>. Voila! :-)</p>
<p>End result looks like this:</p>
<pre><code>p_at='%(!.%F{red}%B#%b%f.@)'
p_host='%F{blue}%m%f'
p_path='%F{blue}%~%f'
p_pr='%(?.%F{blue}.%F{red})&gt;%f'

PS1="$p_at$p_host $p_path$p_pr "
unset p_at p_host p_path p_pr
</code></pre>
<p>You can see I’m unsetting color in every variable and unset those variables — cleaning up after yourself is a valuable habit, especially with a shell. :-)</p>
<p>I’m pretty sure the same could be done for bash (or tclsh, or whatever), but I’m not using it so… If anybody wants to contribute a similar configuration for other shells, I’ll gladly link to a post or add it here.</p>
</div></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/useful-shell-prompt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927968</guid>
            <pubDate>Thu, 29 Oct 2020 06:51:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The remote work tools we'd love to see next year]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927955">thread link</a>) | @dmonn
<br/>
October 28, 2020 | https://nohq.co/blog/the-remote-work-tools-wed-love-to-see-in-2021/ | <a href="https://web.archive.org/web/*/https://nohq.co/blog/the-remote-work-tools-wed-love-to-see-in-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>In 2020, we were happy to have talked to <strong>94</strong> (!) remote tool companies about what they are up to. With more than a dozen we talked a little closer and many of them we've shown you. However, amongst the sea of amazing new innovations in the remote work space, we still found gaps.</p>
<p>Struggles we've heard from remote teams that don't have a solution yet. Solutions that are missing that little something to make them amazing. These are our wishes for the next year.</p>

<h2>Operations</h2>
<p>Running an internationally distributed team has a lot of challenges to overcome, but the most rigid of them all are international regulations and specializations when it comes to running a multi-national organization.</p>
<p>The operations side of remote work is usually deemed pretty unsexy. It's all about working with regulators, shaking hands and most likely an expensive journey to expand in a lot of countries. Hard work, but one that wouldn't go unappreciated.</p>

<h3>1. Better payment gateways for remote teams</h3>
<p>For how far we've come with remote work, we really haven't made a ton of strides with cross-continental payments. In my first-ever remote job, I used to get paid from a regular US corporate bank account directly to my swiss bank account. Payments got routed wrongly here and there, the fees were sky-high and the payments often took a week to get to me.</p>
<p>Since then, we've made a stride or two. With something like <a href="https://bit.ly/3kzvDyo">TransferWise,</a> you can make the whole process a little bit speedier and cheaper. Transfers now only take 1-2 working days and are fairly transparent. Even better: Fees and availability aren't confined to one nation, TransferWise is almost available anywhere.</p>
<p>Then, there are online wallets like Venmo and PayPal. They are really handy to guarantee instant transfers at a cheap price and are very handy for folks that are unbanked. Skipping the dusty banking infrastructure? All for it!</p>
<p>And then, of course, there's cryptocurrency. Now, Bitcoin &amp; co. were never meant to become investment instruments. In the past year, I asked to get paid for something through crypto twice. The payments were instant, extremely cheap (<em>I paid around $0.001 in fees</em>) and my bank didn't ask me about that weird big-money-transfer from the US. Now, if it only was easier to access.</p>

<p><img src="https://nohq.co/media/undraw_online_payments_luau.png" alt="" width="600" height="370"></p>

<p>So, how does the payment gateway of the future look like? Well, first of all, it should be accessible. Too many financial services are confined to the US, Canada and the UK. It should also be internationally receivable. While a bank transfer almost goes anywhere, I've heard multiple times now that people would prefer not getting foreign direct-to-bank payments to accounts in India, for example. The remote payment stack accounts for that.</p>
<p>Finally, waiting for your pay stub and then the money a couple of days later really doesn't fit in the internet age anymore. <strong>Maybe you can leverage cryptocurrency and existing infrastructure to create something instant, simple and internationally accessible?</strong></p>

<h3>2. Making 401k international</h3>
<p>When it comes to retirement benefits, many remote companies don't take it 100% seriously just yet and according to the latest surveys, employees don't mind either. With work-life balance as a commonly cited benefit, being remote in itself is an amazing perk. People are happy to take a pay cut or even let go of their retirement benefits.</p>
<p>Even if a company is <a href="https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/#general-and-entity-benefits">open to having a 401k</a>, doing it the "right" away is almost impossible with every country having its own system. From the <a href="https://de.wikipedia.org/wiki/Pensionskasse">Pensionskasse</a> in Germany to the <a href="https://en.wikipedia.org/wiki/Pensions_in_Japan">EPS</a> in Japan, countries run their own systems that are usually not accessible to foreign entities.</p>
<p>This might not seem important at first, but according to <a href="http://www.mit.edu/~vchern/papers/ch_401k.pdf">researchers at MIT</a> and multiple financial advisories, taking part in and maxing out 401k accounts (and subsequent alternatives in other countries) is a cornerstone to building life-changing wealth. For all personal finance lovers out there, not having that option may be a dealbreaker. Offering 401k and other retirement benefits is about to get a lot more important.</p>
<p>Our idea: <strong>What can a private company build within the regulations that allows for true, employer-matched and internationally available retirement accounts?</strong> Piggy-back off existing infrastructure and regulations? Sell gold bars and store them in a few storage units? Some sort of e-insurance? Again, cryptocurrency? We'd love to hear ideas.</p>

<h3>3. Benefits that are not only show</h3>
<p>For most remote companies, "perks" and "benefits" under the hood only mean a bit more money. In all remote jobs I've had so far, I've claimed my perk payouts as part of my regular salary payout. That means additional taxable income, not what perks are about.</p>
<p>Let me explain. A few years ago, my friend got hired at a very generous company local to us. He got a generous salary but was additionally able to lease a car through the company, set up a subscription for lunch delivery and for a while was even able to rent a room out of the company's real estate arm. The costs of that were deducted directly from his salary. As a result of that, he paid a few $1,000 less in taxes than in the previous years.</p>
<p>Many of those perks – from a company car to new Macbook – are much easier to reimburse in cash for remote companies, so no pre-tax perks at all. <strong>As a potential new service, what can you do to make this happen?</strong></p>
<p>One option is to hire through one of the many <a href="https://nohq.co/hire/">EOR services</a> that specialize in providing a full-service. For many companies that already have their payroll in order, that's not interesting though. You could save people multiple $1,000s in taxes here, so it's a service you don't have to sell for cheap.</p>

<h2>Communication</h2>
<p>Communication is still the king of all remote tools. Out of the many tools we've seen this year, probably 2/3 were in the communication and collaboration space of some sort. So, what gaps are supposed to still be there? Let's walk through it.</p>

<h3>4. All-hands meetings that work</h3>
<p>I believe meetings are largely figured out. This year, we've seen some iterations on the traditional meeting experience, but most of them are a minor improvement for teams that have an amazing product-fit. One thing that isn't solved yet is large, moderated all-hands meetings.</p>
<p>All-hands meetings are meetings that include all, or at least most of the company in the same meeting. The meeting experience is fundamentally different from your standard small group meeting: The speaker is in focus and other participants rarely speak.</p>
<p>The relationship between speaker and listener is quite clear – one speaker, many participants (often over 100) that should be able to speak when called to do so but not otherwise. The experience of such meetings has improved with new meeting software, compared to teams that had to make-do with Skype &amp; co., but it's still not seamless.</p>

<p><em>"At some point, to have everyone on a Skype call for an all-hands meeting, we would have two laptops set up next to each other and have one laptop call half the company and the other laptop call the other half of the company. That was nonsense ðŸ˜„"</em></p>
<p><strong><a href="https://nohq.co/blog/michael-fey-of-1password/">Michael Frey, VP Engineering at 1Password</a></strong></p>

<p>The last time I had an all-hands meeting on Zoom, things didn't go great. Some people called in and were unable to mute themselves. People tried to ask questions but got interrupted by either the speaker or another person in the audience.</p>
<p>With over 100 participants, latency was all over the place and the worst part – the meeting host had a disconnect at some point in the meeting and while the room was able to continue, the recording stopped there. A third of the team was not able to re-play the meeting.</p>
<p>I believe all-hands meetings warrant a new piece of tech that is rarely used – probably only for larger talks and announcements once a month – but works for that type of meeting every single time, including server-side recording, low latency, speaking requests and a larger range of moderation features.</p>

<h3>5. Communication &amp; Writing Training</h3>
<p>Communication and writing skills have been essential requirements for modern remote teams that largely rely on sparse and long-form communication. Many talented people struggle with that, are either not used or accommodated to typing a lot of simply prefer the face-to-face way of doing things.</p>
<p>Just like we build our knowledge worker's skills using education stipends, conferences, courses and books, we should also start looking into active communication training.</p>
<p>In the past, I have benefitted from coaching a lot in my career. Coaches have helped me push through some tough professional issues and have helped me build a small successful business. In the future, coaching will not only be interesting for hard skills but possibly even more soft skills. Getting continuous training in communication and writing will be popular with goal-getters and teams alike.</p>
<p>Now, I'm not necessarily advocating for plain and simple writing training. <a href="https://www.grammarly.com/">Grammarly</a> has put an automated writing coach in many author's pockets, but what if you could push that further? Remind you that you didn't give a status update in a while? Notifying you if your text lacks some context or reads passive-aggressive. Grammarly works great, even as I am writing this post, but it's not an end-to-end communication coach, just an integral part of it. <strong>We'd love to see something new in that space.</strong></p>

<h3>6. Asynchronous Brainstorm</h3>
<p>A consistent piece of feedback we've gotten this year is that teams struggle to find a good way to brainstorm new innovations. Remote work is amazing to get into a deep state, collect some thoughts and find new ideas, but when it comes to collaboration and getting those thoughts out, it gets more difficult.</p>
<p>The way we've learned to brainstorm in the professional world is using visualizations. We like to draw mind maps or sketch graphs on a whiteboard. Filling out the blank space can indeed yield new ideas and has helped really innovative teams come up with amazing ideas.</p>

<p><img src="https://nohq.co/media/undraw_miro_qvwm.png" alt="" width="600" height="407"></p>

<p>The options we have to do so across the globe are not always fitting to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nohq.co/blog/the-remote-work-tools-wed-love-to-see-in-2021/">https://nohq.co/blog/the-remote-work-tools-wed-love-to-see-in-2021/</a></em></p>]]>
            </description>
            <link>https://nohq.co/blog/the-remote-work-tools-wed-love-to-see-in-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927955</guid>
            <pubDate>Thu, 29 Oct 2020 06:48:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Things Don't Scale]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927952">thread link</a>) | @r4um
<br/>
October 28, 2020 | http://blog.vickiboykis.com/2017/05/10/good-things-don%27t-scale/ | <a href="https://web.archive.org/web/*/http://blog.vickiboykis.com/2017/05/10/good-things-don%27t-scale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      


<article>
  
  <p><time datetime="2017-05-10T00:00:00-04:00">05/10/17</time>
    <span></span>
  </p>
  <hr>
  <p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/viking.jpeg" alt="viking"></p>

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
<p><strong>Table of Contents</strong></p>

<ul>
  <li><a href="#flyover-country">Flyover Country</a></li>
  <li><a href="#welcome-to-iceland-heres-some-j%C3%BAn%C3%ADus-meyvant">Welcome to Iceland. Here’s some Júníus Meyvant</a></li>
  <li><a href="#iceland-is-for-humans">Iceland is for humans</a></li>
  <li><a href="#from-lice-to-nice">From lice to nice</a></li>
  <li><a href="#small-is-weird-small-is-good">Small is weird. Small is good.</a></li>
  <li><a href="#big-is-hard---for-countries-and-the-internet-too">Big is hard - for countries, and the internet, too</a></li>
  <li><a href="#where-to-now">Where to now?</a></li>
  <li><a href="#this-is-where-i-leave-you">This is where I leave you</a></li>
  <li><a href="#further-reading-on-iceland">Further Reading on Iceland</a></li>
</ul>

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

<h2 id="flyover-country">Flyover Country</h2>

<p>When I was younger and my family finally made it <a href="http://blog.vickiboykis.com/2014/05/upward-immigrant-toy-mobility-in-the-wild-1990s/">to the American middle class</a>, we went on vacations to Europe. Plane travel was a lot more boring in the days before cell phones, and I would spend a significant amount of any given flight tracking the progress of the tiny plane icon on the flickering screen. When Godthab, Greenland, and then the tiny dot labeled Reykjavik appeared on the legend, I knew we were close to our destination across the Atlantic.</p>

<p>For most traveling Americans, until very recently, Iceland was no more than a flyover destination. But the <a href="https://en.wikipedia.org/wiki/2008%E2%80%932011_Icelandic_financial_crisis">2008 financial crisis</a>, the eruption of <a href="https://en.wikipedia.org/wiki/Eyjafjallaj%C3%B6kull">Eyjafjallajökull</a>, and the filming of Game of Thrones <a href="http://icelandmag.visir.is/article/thingvellir-featured-first-episode-season-4-game-thrones">there</a>, combined with aggressive marketing and low pricing by Iceland’s two airlines have drastically improved Iceland’s standing on the map.</p>

<p>Today, if you talk to any pour-over coffee drinker living within driving distance of an Ikea, there’s a seventy-six bajillion percent chance they’ve been. Since over <a href="https://www.vox.com/new-money/2016/10/18/13261804/iceland-tourism-on-the-rise">1.5 million tourists hit Iceland last year</a> it really seems like everyone I know has either been, or is headed north.</p>

<p>In spite of all that, Iceland is still not a country Americans really pay attention to. I mean, we don’t care about most things that aren’t Kardashian, but Iceland, nestled way up against the Arctic Circle with a population smaller than Cleveland, can be easy to overlook.  As such, I had no preconceived notions going in. But, almost immediately I was won over.</p>

<h2 id="welcome-to-iceland-heres-some-júníus-meyvant">Welcome to Iceland. Here’s some Júníus Meyvant</h2>

<p>What amazed me the most was that there is a USB charging port right next to the TV screen of my Icelandair flight. I’ve flown an average amount, and nowhere yet have I seen this feature in economy class on American planes.</p>

<p>At first glance, this, seems like a totally banal yuppie thing to get excited about. But if you are flying with a smartphone, it’s a HUGE relief not to have to worry about charging in the airport where you land, saving battery, and generally running around like crazy on what should be your vacation or business trip. You just plug in, and you’re ready to go. It’s a really small thing that makes a huge difference in peace of mind for travelers.</p>

<p>As we boarded, Icelandair also played <a href="https://soundcloud.com/recordrecords/junius-meyvant-neon-experience-1">soft mood music</a> from a <a href="https://play.spotify.com/user/icelandair">Spotify playlist</a>. To someone who is used to traveling within the American flight culture, where you’re lucky if the flight attendants throwing $14 bags of peanuts at you hit in the general vicinity of your torso, it was all very new. And, of course, you could track the flight path on your phone free of charge.</p>

<p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/flightrack.PNG" alt="viking"></p>

<p>It so happened that we went to Iceland because Mr. B was invited to a bachelor party there.  In my day, these parties were held at local dive bars where the floor was more Miller Lite than laminate, but that was before Instagram. I decided to tag along for a couple days before the party, because Iceland was so close, and because it’s been a while since I’ve travelled further than the distance between the crib and the couch.</p>

<p>We got in at six in the morning, but even in my red-eyed haze, I could see just how pristine everything at Keflavík Airport was. My freshly-charged phone immediately connected to Iceland’s Vodafone network without a glitch.  “We’re here. Everything is clean and smells like Ikea,” I texted my mom.</p>

<p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/airport.png" width="400"></p>

<p>I had already booked a ticket on <a href="https://www.re.is/flybus/">Flybus</a>, which goes from Keflavík to Reykjavik, online, so all we had to do was get on and wait. I’ve never been brave enough to take public transportation from the airport anywhere I’ve been, including even Israel, where I speak the language, but the website made it so easy. The bus, like the plane, had Wi-Fi, a feature we’d see being offered again and again on buses, in cafes, restaurants, and bookstores, like a lure to trap urban Americans wearing plaid button-downs.</p>

<h2 id="iceland-is-for-humans">Iceland is for humans</h2>

<p>From the get-go, there were a lot of things in Iceland that seemed like they were out of a fairy tale about what an ideal human life should look like, at least from the perspective of someone living in the United States.</p>

<p>For example, on our first day, our guide from <a href="http://www.iheartreykjavik.net/">I Heart Reykjavik</a>, took us on a walk through Reykjavik, stopping at a small building that looked like something out of Goldilocks and the Three Bears. “That’s the prime minister’s office,” she told us. “No guards, nothing. He just goes about his work here.” We walked on, towards another two-story building that looked like an office for a small-to-medium business.</p>

<p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/Althingi.JPG" alt="viking"></p>

<p>It was the national Parliament, the Alþingi. “It’s made up of 48% women,” our guide said.  “We’re just short of 50%,” she continued ruefully. I have to admit, I had a sharp intake of breath. It sounded like an impossible miracle. But in Iceland, equality, and more importantly, humanity, shows itself in lots of different ways.</p>

<p>There is the USB charger so you don’t have to coddle your smartphone like an animal.  In the big picture, there is <a href="https://grapevine.is/mag/articles/2017/05/05/poll-most-icelanders-support-equal-pay-law/">gender equality</a>. Not only do women make up a large percentage of the workforce, but childcare is heavily subsidized, costing something like <a href="https://www.theguardian.com/commentisfree/2014/oct/28/iceland-women-feminist-paradise-gender-gap-pay">$180 a month per child</a> for eight hours of childcare, including food. Mr. B and I personally pay $800/month, and I know our daycare is on the cheaper end.</p>

<p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/woke.JPG" alt="viking"></p>

<p>There is also a large <a href="https://grapevine.is/news/2017/05/03/only-3400-unemployed-in-iceland/">social safety net</a>, healthcare, and all the goodies that make Scandinavia – Scandinavia.</p>

<p>Additionally, I felt more like a treasured guest than a potential criminal when passing through Icelandic customs, more than I can say for my trip back to the country where I’m actually a citizen.</p>

<p>But there is a lot of humanity in the small things, too. For example, the tap water is not only potable, but delicious.</p>

<p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/water.jpeg" width="400"></p>

<p>When we went to buy a bottle of water at the supermarket, the clerk looked at us like we were crazy. “You know it’s the same thing in the tap,” she said, motioning for us to put the bottle back. The shower water smells like sulfur, because all of Iceland gets its cold water from a glacier, and hot water from <a href="http://wakeupreykjavik.com/the-icelandic-water/">geothermal heating.</a></p>

<p>Then, there’s the matter of the prisons. The <a href="http://www.icenews.is/2016/05/26/old-prison-in-reykjavik-center-gets-a-new-role/#axzz4gOqBvd8b">old town prison in Reykjavik</a>, which had no wire fence around it, or even bars on the windows, grew too small (it can only house 16 prisoners) and is being reconsidered for repurpose as a cultural center.  The current prison population of Iceland is <a href="http://www.icenews.is/2016/05/26/old-prison-in-reykjavik-center-gets-a-new-role/#axzz4gOqBvd8b">153</a>, or less than one tenth of one percent of the population.</p>

<p>Oh, and everyone speaks nearly perfect English.</p>

<p>It seems very, very hard to find anything wrong with Iceland. Until you get to the financial crisis of 2008, when the three largest banks folded, the currency plummeted, and unparalleled levels of corruption were exposed in the government, leading to massive unemployment and genuine fear and panic.</p>

<p>But even as large and traumatic as that <a href="https://www.thebalance.com/iceland-financial-crisis-bankruptcy-and-economy-3306347">devastating moment of extremely poor judgement for the country</a>, was, Iceland now seems to have passed it, i<a href="http://www.bbc.com/news/business-35485876">f not with flying colors</a>, at least with more wisdom and grace than the U.S. could muster up during its own fall.  It’s true that the krona has fallen and Iceland experienced a brain drain after the crisis. But it’s also true that a restructuring of the economy has led to a significant decrease in unemployment. The bankers that caused the 2008 financial crisis <a href="https://www.bloomberg.com/news/features/2016-03-31/welcome-to-iceland-where-bad-bankers-go-to-prison">are also in prison</a>, where they “spend their days doing laundry, working out in the jailhouse gym, and browsing the Internet.” “Sometimes they go horseback riding,” our guide said.</p>

<p>The economy has been on the upswing since 2011, particularly with a lot of strength in the tourism sector, which the Icelandic government is heavily pushing - probably the reason all my friends have known about it. The low cost of the airfare to Iceland relative to Europe or even the West Coast in America, thanks to the <a href="http://www.nytimes.com/1994/06/03/business/filling-a-trans-atlantic-air-niche.html?pagewanted=all">hub and spoke model</a> (Iceland is a huge place for flights from Europe and the United States to connect, thus maximizing capacity and optimizing costs for travelers), is huge.</p>

<h2 id="from-lice-to-nice">From lice to nice</h2>

<p>How did Iceland get to this point?  Originally settled in the 10th century by Vikings (and any <a href="http://www.irishtimes.com/news/why-people-in-iceland-look-just-like-us-1.1104676">Irish slaves</a> they picked up on the way), the island was not a very hospitable place.  When the settlers first came, there were almost no native animal species, so they had to bring by boat all the livestock they could to survive. There were also few trees, meaning most houses were made of mud and turf. Life was simply miserable for the first thousand years of Iceland’s existence.</p>

<p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/thingvallir.JPG" alt="viking"></p>

<p>Also, the weather in Iceland is terrible. There are two seasons: rain, and <a href="https://en.wikipedia.org/wiki/Laki">lava</a>. Exposed to both the Arctic wind and laid bare to all the vagaries of the Atlantic Ocean, it rains at least a little every day, in spurts. It was sunny for maybe 15 minutes that I was there. On a particularly windy day, we went <a href="http://eldhestar.is/">riding</a> on the <a href="http://www.visiticeland.com/things-to-do/activities/the-icelandic-horse">small, sturdy horses</a> that are descendants of the original horses the Vikings brought over (no imports are allowed to keep the purity of the breed), and all I could think about, instead of focusing on the beautiful, broody landscape of Hveragerði was about how many Vikings died of pneumonia and ear infections.</p>

<p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/us.JPG" alt="viking"></p>

<p>Things got marginally better over the centuries with more established trade routes, but as late as the the 1800s, men were climbing vertical cliffs plunging to the sea to steal sea bird eggs from ledges. Without these natural “pantries”, a large amount of Icelanders would likely have starved. If you weren’t killed by hunger, the climate, or <a href="https://en.wikipedia.org/wiki/Turkish_Abductions">random Turkish raiding parties</a>,  there were always the eagles, one of the only native bird species to grace the island.</p>

<p>The economy really kicked into gear when exposed to the economic crosswinds of World War II, and, of course the British and the Americans. Once the economy took off, it’s been going. Iceland is now diversified away …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.vickiboykis.com/2017/05/10/good-things-don%27t-scale/">http://blog.vickiboykis.com/2017/05/10/good-things-don%27t-scale/</a></em></p>]]>
            </description>
            <link>http://blog.vickiboykis.com/2017/05/10/good-things-don%27t-scale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927952</guid>
            <pubDate>Thu, 29 Oct 2020 06:48:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UbuntuDDE Groovy Gorilla Release Note]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927837">thread link</a>) | @reddotX
<br/>
October 28, 2020 | https://ubuntudde.com/blog/ubuntudde-remix-groovy-gorilla-release-note/ | <a href="https://web.archive.org/web/*/https://ubuntudde.com/blog/ubuntudde-remix-groovy-gorilla-release-note/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-26358" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>Hello community! Firstly, on behalf of the team and myself,  I’d like to thank the UbuntuDDE Remix Community and our precious donors, patrons, sponsors, supporters and well-wishers for motivating and supporting us for our next release.  We had an outstanding journey of 6 months after the successful launch of UbuntuDDE Remix 20.04 LTS in April and we hope you’ll love the distribution more with this release. </p>



<p>In the past 6 months, we had few ups and downs but finally got our way to successfully port the beautiful and modern desktop environment from Deepin v20. Personally, I’d like to thank Felix Yan (from Arch Linux), David Mohammed (from Ubuntu Budgie) and everyone else for always supporting and helping us throughout the journey.</p>





<p>And today, we’re back with another exciting release, UbuntuDDE Remix 20.10 codenamed “groovy” (Groovy Gorilla) . Groovy is a non-LTS release which will have support for the next nine months till July 2021. This release can be considered as the most awaited release for the community as it is shipped with the fresh new Deepin Desktop Environment from Deepin v20.</p>




<h3>Key features of UbuntuDDE Remix Groovy</h3>



<ul><li>Ubuntu 20.10 Groovy base system.</li><li>Deepin Desktop Environment from Deepin v20.</li><li>New native applications preinstalled including Deepin Music, Device Manager, Deepin Movies, Image Viewer, Boot Maker,  System Monitor, Deepin Calculator, Deepin Text Editor, Deepin Terminal and more.</li><li>Firefox 81.0.2 as default web browser.</li><li>LibreOffice 7.0.2.2 as default office package.</li><li>Latest Ubuntu base packages preinstalled.</li><li>Linux Kernel 5.8.0 and Kwin window manager as default ported from Deepin’s fork of Kwin.</li><li>New beautiful wallpapers and assets from the UbuntuDDE Remix Team and Deepin.</li><li>Calamares Installer for easy Installation of the Distribution.</li><li>Snap plugin for Software Center preinstalled.</li><li>Future more exciting software packages through OTA updates.</li></ul>



<h3>Bug fixes after Beta release</h3>



<ul><li>Added: Open As Administrator on right click.</li><li>Added : Refresh button on right click.</li><li>Fixed: WiFi Network not showing nearest AP.</li><li>Fixed: Black shadow frame across the window.</li><li>Fixed: Rounded corners on the Dock.</li><li>Fixed: Blur on Notification Panel.</li><li>Fixed: Magic Lamp Effect not working properly.</li><li>Fixed: Lock screen wallpaper not changing.</li><li>Fixed: Minor glitches in windows manager.</li><li>Other minor bug fixes and improvements.</li></ul>



<h3>Recommended System Requirements</h3>



<div>
<div><div>




<div>
<div><div><div>
<figure><img src="https://i1.wp.com/images-na.ssl-images-amazon.com/images/I/51i8W+KevmL._SX258_BO1,204,203,200_.jpg?resize=190%2C250&amp;ssl=1" "&amp;ssl="1&quot;" alt="" width="190" height="250" data-recalc-dims="1"></figure>
</div></div></div>



<div><div><div>
<h2><span></span>CompTIA A+ Certification All-in-One Exam Guide, Tenth Edition<span></span></h2>



<p>This bestselling on-the-job reference and test preparation guide has been fully revised for the new 2019 CompTIA A+ exam objectives.</p>




</div></div></div>
</div>
</div></div></div>
<p>RAM: Minimum of 4 GB.<br>Drive Space: At least 20 GB free space.<br>CPU: At least 2 GHz Processor or better.</p>



<p>To try/install the Operating System, head towards our <a aria-label=" (opens in a new tab)" rel="noreferrer noopener" href="https://ubuntudde.com/download/" target="_blank">Download page</a> and to support our project financially, visit our <a href="https://ubuntudde.com/donate/">Donate page</a>. Learn more about this release, please visit the <a href="https://ubuntudde.com/features/">Features page</a> and checkout some screenshot collection in our <a aria-label="Digital Assets page (opens in a new tab)" rel="noreferrer noopener" href="https://ubuntudde.com/digital-assets/" target="_blank">Digital Assets page</a>.</p>



<p>If you encounter any issue or need help from the awesome community, visit our <a aria-label="Support page. (opens in a new tab)" href="https://ubuntudde.com/support/" rel="noreferrer noopener" target="_blank">Support page</a>. To report an issue or search for an existing bug, visit our <a href="https://github.com/ubuntudde/bugs" target="_blank" rel="noopener">Github Issue Tracker</a>.</p>







<p>Regards,<br><strong>Arun Kumar Pariyar,</strong><br>Project Lead, UbuntuDDE Remix</p>
<!-- AI CONTENT END 2 -->

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article></div>]]>
            </description>
            <link>https://ubuntudde.com/blog/ubuntudde-remix-groovy-gorilla-release-note/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927837</guid>
            <pubDate>Thu, 29 Oct 2020 06:25:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Object Oriented PHP]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927751">thread link</a>) | @brendt_gd
<br/>
October 28, 2020 | https://front-line-php.com/object-oriented | <a href="https://web.archive.org/web/*/https://front-line-php.com/object-oriented">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            
<div>
    <p>Alan Kay, the inventor of the term “object-oriented programming”, told a story once during a talk more than 20 years ago. You can build a dog house using only a hammer, nails, planks, and just a little bit of skill. I figure even I would be able to build it given enough time. Once you've built it you've earned the skills and know-how, and could apply it to other projects. Next, you want to build a cathedral, using the same approach with your hammer, nails, and planks. It's a 100 times larger, but you've done this before — right? It'll only take a little longer.</p>

    <p>While the scale went up by a factor of 100, its mass went up by a factor of 1.000.000 and its strength only by 10.000. Inevitably, the building will collapse. Some people plaster over the rubble, make it into a pyramid and say it was the plan all along; but you and I know what really went on.</p>

    <p>Alan used this metaphor to explain a critical problem he saw with “modern OOP” 20 years ago. I think it still holds today: we've taken the solution to a problem — OO code — we've scaled it by a factor of 100, and expected it to work the same way. Today still, we don't think enough about architecture — which is rather crucial if you're building a cathedral — we use the OO solutions we learned without any extra thought. Most of us learned OO in isolation with small examples, and rarely at scale. In most real life projects, you cannot simply apply the patterns you've learned and expect everything to fall into place the same way it did with Animals, Cats, and Dogs.</p>
    <p>This reckless scaling of OO code is what cause many people to voice their disapproval of it in recent years. Personally I believe OOP is as good a tool as any other — functional programming being the modern-day popular contestant — <em>if</em> used correctly.</p>
    <p>My takeaway from Alan's vision is that each object is a little program on its own, with its own internal state. Objects send messages between each other — packages of immutable data — which other objects can interpret and react to. You can't write all code this way, and that's fine — it's fine to not blindly follow these rules.
        Still, I have experienced the positive impact of this mindset first hand. Thinking of objects as little standalone programs, I started writing parts of my code in a different style. I hope that, now that we're going to look at OOP, you'll keep Alan's ideas in mind. Don't blindly apply patterns and principles. Try to look at what you're building as a whole.</p>
    <h2 id="the-pitfall-of-inheritance"><a href="#the-pitfall-of-inheritance">#</a> The pitfall of inheritance</h2>
    <p>I found it difficult to believe at first, but classes and inheritance have nothing to do with OOP the way Alan envisioned it. That doesn't mean they are bad things per se, but it <em>is</em> good to think about their purpose and how we can use, as well as abuse them.
        Alan's vision only described objects — it didn't describe how those objects were created. Classes were added later as a convenient way to manage objects, but they are only an implementation detail, not the core idea of OOP. With classes came inheritance, another a useful tool when used correctly. That hasn't been the case though: the problem Alan tried to address 20 years ago still exists today.</p>
    <p>One of the acclaimed strengths of OOP is that it models our code in ways humans think about the world. In reality though, we rarely think in terms of abstractions and inheritance. Instead of using inheritance in places where it actually makes sense, we've been abusing it as a way to share code, and to configure objects in an obscure way.
        I'm going to show you a great example that illustrates this problem, though I want to say up front that it isn't my own: it's Sandi Metz's, a great teacher on the subject of OOP. Let's take a look.</p>
    <p>There's a children's nursery rhyme called “The House That Jack Built” (it's also a horror movie but that's unrelated).
        It starts like this:</p>
    <pre><code>This is the house that Jack built.</code></pre>
    <p>Every iteration there's a sentence added to it:</p>
    <pre><code>This is the malt that lay in
        the house that Jack built.</code></pre>
    <p>And next:</p>
    <pre><code>This is the rat that ate
        the malt that lay in
        the house that Jack built.</code></pre>
    <p>Get it? This is the final poem:</p>
    <pre><code>This is the horse and the hound and the horn that belonged to
        the farmer sowing his corn that kept
        the rooster that crowed in the morn that woke
        the priest all shaven and shorn that married
        the man all tattered and torn that kissed
        the maiden all forlorn that milked
        the cow with the crumpled horn that tossed
        the dog that worried
        the cat that killed
        the rat that ate
        the malt that lay in
        the house that Jack built.</code></pre>
    <p>Let's code this together, I'll be using PHP. We're going to make a program that you can ask a given iteration, and it will produce the poem up until that point. Let's do it in an OO way. We start by adding all parts into a data array within a class; let's call that class <code><span>PoemGenerator</span></code> — sounds very OO, right? Good.</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    <span>private</span> <span>static</span> <span>array</span> <span>$data</span> = [
        <span>'the horse and the hound and the horn that belonged to'</span>,
        <span>'the farmer sowing his corn that kept'</span>,
        <span>'the rooster that crowed in the morn that woke'</span>,
        <span>'the priest all shaven and shorn that married'</span>,
        <span>'the man all tattered and torn that kissed'</span>,
        <span>'the maiden all forlorn that milked'</span>,
        <span>'the cow with the crumpled horn that tossed'</span>,
        <span>'the dog that worried'</span>,
        <span>'the cat that killed'</span>,
        <span>'the rat that ate'</span>,
        <span>'the malt that lay in'</span>,
        <span>'the house that Jack built'</span>,
    ];
}</code></pre>
    <p>Now let's add two methods <code><span>generate</span></code> and <code><span>phrase</span></code>. <code><span>generate</span></code> will return the end result, and <code><span>phrase</span></code> is an internal function that glues the parts together.</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    

    <span>public</span> <span><span>function</span> <span>generate</span><span>(<span>int</span> $number)</span>: <span>string</span>
    </span>{
        <span>return</span> <span>"This is {$this-&gt;<span>phrase</span>($number)}."</span>;
    }

    <span>protected</span> <span><span>function</span> <span>phrase</span><span>(<span>int</span> $number)</span>: <span>string</span>
    </span>{
        $parts = <span>array_slice</span>(<span>self</span>::<span>$data</span>, -$number, $number);

        <span>return</span> <span>implode</span>(<span>"\n        "</span>, $parts);
    }
}</code></pre>
    <p>It seems like our solution works: we can use <code><span>phrase</span></code> to take x-amount of items from the end of our data array and implode those into one phrase; next we use <code><span>generate</span></code> to wrap the final result with <code>This is</code> and <code>.</code>. By the way, I implode on that spaced delimiter just to format the output a little nicer.</p>
    <pre><code>$generator = <span>new</span> <span>PoemGenerator</span>();

$generator-&gt;<span>generate</span>(<span>4</span>);




</code></pre>
    <p>Exactly what we'd expect the result to be.</p>
    <hr>
    <p>Then comes along… a new feature request. Let's build a <em>random</em> poem generator: it will randomise the order of the phrases. How do we solve this in a clean way without copying and duplicating code? Inheritance to the rescue — right?
        First let's do a little refactor, let's add a protected <code><span>data</span></code> method, so that we have a little more flexibility in what it actually returns:</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    <span>protected</span> <span><span>function</span> <span>phrase</span><span>(<span>int</span> $number)</span>: <span>string</span>
    </span>{
        $parts = <span>array_slice</span>(<span><span>$this</span>-&gt;<span>data</span>()</span>, -$number, $number);

        <span>return</span> <span>implode</span>(<span>"\n        "</span>, $parts);
    }

<span>    <span>protected</span> <span><span>function</span> <span>data</span><span>()</span>: <span>array</span>
    </span>{
        <span>return</span> [
            <span>'the horse and the hound and the horn that belonged to'</span>,
            
            <span>'the house that Jack built'</span>,
        ];
    }</span>}</code></pre>
    <p>Next we build our <code><span>RandomPoemGenerator</span></code>:</p>
    <pre><code><span><span>class</span> <span>RandomPoemGenerator</span> <span>extends</span> <span>PoemGenerator</span>
</span>{
    <span>protected</span> <span><span>function</span> <span>data</span><span>()</span>: <span>array</span>
    </span>{
        $data = <span>parent</span>::<span>data</span>();

        <span>shuffle</span>($data);

        <span>return</span> $data;
    }
}</code></pre>
    <p>How great is inheritance! We only needed to override a small part of our code, and everything works just as expected!</p>
    <pre><code>$generator = <span>new</span> <span>RandomPoemGenerator</span>();

$generator-&gt;<span>generate</span>(<span>4</span>);</code></pre>
    <pre><code>This is the priest all shaven and shorn that married
        the cow with the crumpled horn that tossed
        the man all tattered and torn that kissed
        the rooster that crowed in the morn that woke.</code></pre>
    <p>Awesome!</p>
    <hr>
    <p>Once again… a new feature request: an echo generator: it repeats every line a second time. So you'd get this:</p>
    <pre><code>This is the malt that lay in the malt that lay in
        the house that Jack built the house that Jack built.</code></pre>
    <p>We can solve this; inheritance — right?</p>
    <p>Let's again do a small refactor in <code><span>PoemGenerator</span></code>, just to make sure our code stays clean! Let's extract the array slicing functionality in <code><span>phrase</span></code> to its own method, because that's a better separation of concerns — which we learned is a good thing!</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    

    <span>protected</span> <span><span>function</span> <span>phrase</span><span>(int $number)</span>: <span>string</span>
    </span>{
        $parts = <span><span>$this</span>-&gt;<span>parts</span>($number)</span>;

        <span>return</span> <span>implode</span>(<span>"\n        "</span>, $parts);
    }

<span>    <span>protected</span> <span><span>function</span> <span><span>parts</span></span><span>(int $number)</span>: <span>array</span>
    </span>{
        <span>return</span> <span>array_slice</span>(<span>$this</span>-&gt;<span>data</span>(), -$number, $number);
    }</span>}</code></pre>
    <p>Having refactored this, implementing <code><span>EchoPoemGenerator</span></code> is again very easy:</p>
    <pre><code><span><span>class</span> <span>EchoPoemGenerator</span> <span>extends</span> <span>PoemGenerator</span>
</span>{
    <span>protected</span> <span><span>function</span> <span>parts</span><span>(<span>int</span> $number)</span>: <span>array</span>
    </span>{
        <span>return</span> <span>array_reduce</span>(
            <span>parent</span>::<span>parts</span>($number),
            <span>fn</span> (<span><span>array</span></span> $output, <span>string</span> $line) =&gt; [...$output, <span>"{$line} {$line}"</span>],
            []
        );
    }
}</code></pre>
    <p>Can we take a moment to appreciate the power of inheritance? We've created two different implementations of our original <code><span>PoemGenerator</span></code>, and have <em>only</em> overridden the parts that differ from it in <code><span>RandomPoemGenerator</span></code> and <code><span>EchoPoemGenerator</span></code>. We've even used SOLID principles to ensure that our code is decoupled so that it's easy to override specific parts. This is what great OOP is about — right?</p>
    <hr>
    <p>One more time… another feature request: please make one more implementation, one that combines both the random and echo behaviour: <code><span>RandomEchoPoemGenerator</span></code>.</p>
    <p>Now what? Which class will that one extend?</p>
    <p>If we're extending <code><span>PoemGenerator</span></code>, we'll have to override both our <code><span>data</span></code> and <code><span>parts</span></code> methods, essentially copying code from both <code><span>RandomPoemGenerator</span></code> and <code><span>EchoPoemGenerator</span></code>. That's bad design, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://front-line-php.com/object-oriented">https://front-line-php.com/object-oriented</a></em></p>]]>
            </description>
            <link>https://front-line-php.com/object-oriented</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927751</guid>
            <pubDate>Thu, 29 Oct 2020 06:06:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Image Scaling Attacks]]>
            </title>
            <description>
<![CDATA[
Score 416 | Comments 67 (<a href="https://news.ycombinator.com/item?id=24927655">thread link</a>) | @wendythehacker
<br/>
October 28, 2020 | https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/ | <a href="https://web.archive.org/web/*/https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag “huskyai” to see related posts.</p>
<ul>
<li><a href="https://embracethered.com/blog/posts/2020/husky-ai-walkthrough/">Overview</a>: How Husky AI was built, threat modeled and operationalized</li>
<li><a href="https://embracethered.com/blog/posts/2020/husky-ai-threat-modeling-machine-learning/">Attacks</a>: Some of the attacks I want to investigate, learn about, and try out</li>
</ul>
<p>A few weeks ago while preparing demos for my GrayHat 2020 - Red Team Village presentation I ran across “Image Scaling Attacks” in <a href="https://www.usenix.org/system/files/sec20-quiring.pdf">Adversarial Preprocessing: Understanding and Preventing Image-Scaling Attacks in Machine Learning</a> by Erwin Quiring, et al.</p>
<p>I thought that was so cool!</p>
<h2 id="what-is-an-image-scaling-attack">What is an image scaling attack?</h2>
<p>The basic idea is to hide a smaller image inside a larger image (it should be about 5-10x the size). The attack is easy to explain actually:</p>
<ol>
<li>Attacker crafts a malicious input image by hiding the desired target image inside a benign image</li>
<li>The image is loaded by the server</li>
<li>Pre-processing resizes the image</li>
<li>The server acts and makes decision based on a different image then intended</li>
</ol>
<p>My goal was to hide a husky image inside another image:</p>
<p><a href="https://embracethered.com/blog/images/2020/image-rescale-attack.gif"><img src="https://embracethered.com/blog/images/2020/image-rescale-attack.gif" alt="Image Rescaling Attack"></a></p>
<p>Here are the two images I used - before and after the modification:
<a href="https://embracethered.com/blog/images/2020/image-rescaling-attack-schoenbrunn.png"><img src="https://embracethered.com/blog/images/2020/image-rescaling-attack-schoenbrunn.png" alt="Image Rescaling Attack"></a></p>
<p>If you look closely, you can see that the second image does have some strange dots all around. But this is not noticable when viewed in smaller version.</p>
<p>You can find the code on <a href="https://github.com/EQuiw/2019-scalingattack">Github</a>. I used Google Colab to run it, and there were some errors initialy but it worked - let me know if interested and I can clean up and share the Notebook also.</p>
<h2 id="rescaling-and-magic-happens">Rescaling and magic happens!</h2>
<p>Now, look what happens when the image is loaded and resized with <code>OpenCV</code> using default settings:</p>
<p><a href="https://embracethered.com/blog/images/2020/image-rescaling-attack.png"><img src="https://embracethered.com/blog/images/2020/image-rescaling-attack.png" alt="Image Rescaling Attack"></a></p>
<p>On the left you can see the original sized image, and on the left the same image downsized to 128x128 pixels.</p>
<p><strong>That’s amazing!</strong></p>
<p>The downsized image is an entirely different picture now! Of course I picked a husky, since I wanted to attack “Husky AI” and find another bypass.</p>
<h2 id="implications">Implications</h2>
<p>This can have a set of implications:</p>
<ol>
<li><strong>Training process:</strong> Images that poisen the training data (as pre-processing rescales images)</li>
<li><strong>Model queries:</strong> The model might predict on a different image than the one the user uploaded</li>
<li><strong>Non ML related attacks:</strong> This can also be an issue in other, non machine learning areas.</li>
</ol>
<p>I guess security never gets boring, there is always something new to learn.</p>
<h2 id="mitigations">Mitigations</h2>
<p>Turns out that Husky AI uses PIL and that was not vulnerable to this attack by default.</p>
<p>I got lucky, because initially Husky AI did use <code>OpenCV</code> and it’s default settings to resize images. But for some reason I changed that early on (not knowing it would also mitigate this attack).</p>
<p>If you use <code>OpenCV</code> the issue can be fixed by using the <code>interpolation</code> argument when calling the <code>resize</code> API to not have it use the default.</p>
<p>Hope that was useful and interesting.</p>
<p>Cheers,
Johann.</p>
<p><a href="https://twitter.com/wunderwuzzi23">@wunderwuzzi23</a></p>
<h2 id="references">References</h2>
<ul>
<li>Adversarial Preprocessing: Understanding and Preventing Image-Scaling Attacks in Machine Learning (<a href="https://www.usenix.org/system/files/sec20-quiring.pdf">https://www.usenix.org/system/files/sec20-quiring.pdf</a>) (Erwin Quiring, TU Braunschweig)</li>
<li><a href="https://github.com/EQuiw/2019-scalingattack">https://github.com/EQuiw/2019-scalingattack</a></li>
</ul>

  </section></div>]]>
            </description>
            <link>https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927655</guid>
            <pubDate>Thu, 29 Oct 2020 05:48:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Firearms by the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24927649">thread link</a>) | @lettergram
<br/>
October 28, 2020 | https://austingwalters.com/firearms-by-the-numbers/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/firearms-by-the-numbers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3517">

<div>
<p>Firearms (guns) are one of the hot button issues in the United States and globally. I’m sure it is understandable why — pull the trigger and something dies. Killing is the primary purpose of a firearm. Naturally, this leads many to be fearful of firearms, but should people be fearful?</p>
<p>When I started writing this, I wanted to answer:</p>
<blockquote><p>Are firearms inherently unsafe?</p>
<p>Should firearms be banned, as many believe?</p></blockquote>
<p>It’s quite ambitious. One may believe you can just find an answer on a website / paper somewhere or is obvious. Unfortunately, the reality is far more complicated and has turned this into my longest article to date.</p>
<p>It’s been said,</p>
<blockquote><p>Guns don’t kill people, people kill people. <em>– unknown</em></p></blockquote>
<p>Many agree and many others strongly disagree. That divisiveness has made firearms a political issue, leading to a plethora of bias studies, inaccurate analysis, and more. Thus, to answer these questions I had to go through the data myself; I pulled <a href="#Data_Tooling">data from the CDC, FBI, RAND, Census and others</a> and completed my own analysis.</p>
<h4>Introduction</h4>
<p>Due to the nature of this analysis, it is important to highlight some items upfront.</p>
<p>1. The United States is often the focus throughout the analysis. This is because the United States has an abundance of firearms, a relatively uniform society and the most available &amp; accurate records.</p>
<p>2. This analysis focuses on general trends. Specific situations vary wildly, even in the same region: country, state, county, city, and neighborhood situations vary. As such, I caution making detailed / specific inference, beyond what the data explicitly shows (in the general case).</p>
<p>3. Some important data is lacking, such as socioeconomic status associated with crimes. This makes it very difficult to isolate confounding factors and leads to confusion / lack of definitive answer(s).</p>
<p>The goal of this analysis was to analyze available (and unbiased) data as in-depth as enabled, with no particular outcome in mind. <em>If new data comes in that materially changes what can be inferred, I’ll attempt to update the analysis.</em> With that in mind, I want to highlight that I dive into demographic information and I found some surprises. Politics seems to stifle this topic and in fact the truth. Instead I went to the data, I hope you can find it as interesting as I do.</p>
<blockquote><p>The truth is not for all men, but only for those who seek it.<br>
– Ayn Rand</p></blockquote>
<p>If anything in this analysis was missed,<strong> please feel free to reach out or leave comments.</strong></p>


<p>Globally, firearms are highly controlled, particularly in the Europe and Asia. In contrast, the United States has more firearms held by it’s citizens than the rest of the world combined.<a href="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png" alt="" width="1107" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-768x477.png 768w" sizes="(max-width: 1107px) 100vw, 1107px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-768x477.png 768w"></a>The real question — do the number of firearms really matter? From the graph above, it’s clear China, Russia and Iran have a high number of military firearms when compared civilian held firearms (and I suspect most civilian held firearms are former military, in countries such as China, Russia ,Iran, India, etc). In contrast, the “<a href="https://en.wikipedia.org/wiki/Free_World" target="_blank" rel="noopener noreferrer">free world</a>” has an order of magnitude more civilian firearms, when compared to military firearms.</p>
<p>Clearly, what matters to “<a href="https://en.wikipedia.org/wiki/Second_World" target="_blank" rel="noopener noreferrer">second world</a>” is having a large military arsenal, when compared to civilian held firearms.</p>
<p>It can be argued an unarmed society allows the military to impose their will, allowing countries to maintain the status quo and avoiding violent revolutions overthrowing the government.</p>
<h2><span id="Homicides_Firearms_Globally"></span>Homicides &amp; Firearms Globally<span></span></h2>
<p>In the “free world,” the main concern surrounding firearms are homicides &amp; suicides, with homicides being the most concerning. Below is a comparison of homicides by firearm deaths per 100,000 people across the globe.</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png" alt="" width="1228" height="677" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png 1228w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-300x165.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-1024x565.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-768x423.png 768w" sizes="(max-width: 1228px) 100vw, 1228px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png 1228w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-300x165.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-1024x565.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-768x423.png 768w"></a>When we compare the world, a few things become clear:</p>
<ol>
<li>The America’s, Caribbean and Africa have a much higher firearm homicide rate</li>
<li>The United States has the highest firearm homicide rate of a “<a href="https://en.wikipedia.org/wiki/First_World" target="_blank" rel="noopener noreferrer">first world</a>” country</li>
<li>Europe has the lowest firearm homicide rate globally</li>
</ol>
<p>What’s not clear, is whether or not firearms are really leading the increased firearm homicide rate.</p>
<p>Are homicides just naturally higher in these regions?</p>
<h2><span id="Firearm_Death_Rate_per_Firearm"></span>Firearm Death Rate per Firearm<span></span></h2>
<p>Below is an argument from the Amnesty International’s website:</p>
<blockquote><p>governments [with] poor regulation of the possession and use of <strong>guns lead to violence</strong> and that they must tackle this now through strict controls on guns and effective interventions in communities suffering high levels of gun violence.</p>
<p>– <a href="https://www.amnesty.org/en/what-we-do/arms-control/gun-violence/" target="_blank" rel="noopener noreferrer">Amnesty International</a></p></blockquote>
<p>The key statement is:</p>
<blockquote><p>Guns lead to violence</p></blockquote>
<p>The statement above implies a couple of things:</p>
<ol>
<li>Gun volume and violence are correlated</li>
<li>As the number of guns increase, violence increases</li>
</ol>
<p>There are a few ways to invalidate / validate this statement. The clearest method is to simply compare firearm deaths per firearm. If firearms lead to more violence, we should see the ratio of firearm deaths to firearms (firearm deaths / firearms) staying constant (or growing at a constant rate). This ratio should stay or grow at a constant rate because as the firearm count increases, the firearm homicides should increase (keeping the ratio constant). We could also assume a direct correlation if “guns lead to violence” as it would probably occur at some constant rate.</p>
<p>Below you can see the comparison between firearm deaths and firearms:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png" alt="" width="1313" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png 1313w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-300x157.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-1024x536.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-768x402.png 768w" sizes="(max-width: 1313px) 100vw, 1313px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png 1313w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-300x157.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-1024x536.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-768x402.png 768w"></a>As seen in the chart, the Caribbean, South America, Africa have a high number of firearm deaths per firearm, Columbia having one death per five hundred firearms. In contrast, “First World” (Europe and the United States) has a much lower number of fatalities per firearm, the United States having only one death per ten thousand firearms.</p>
<h3><span id="Firearms_vs_Homicide_Rate"></span>Firearms vs Homicide Rate<span></span></h3>
<p>For further evidence firearms aren’t correlated with violence, it’s possible to directly compare the number of firearms vs homicides:<a href="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png" alt="" width="1107" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-768x477.png 768w" sizes="(max-width: 1107px) 100vw, 1107px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-768x477.png 768w"></a>Across the bottom of the chart you can see all the countries with high homicide rates. The United States stands out clearly, if firearms were correlated with homicides we’d expect the U.S. to have many more homicides than it currently does. It does not appear more firearms are correlated with more homicides, in fact the trend line shows the opposite to be true (more firearms are correlated to less homicides).</p>
<p>For a final validation, we can compare firearms against homicides and firearm homicides against total homicides. Both should have a similar growth rate, if there was a correlation.</p>
<figure id="attachment_3617" aria-describedby="caption-attachment-3617"><a href="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png" alt="" width="1107" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-768x477.png 768w" sizes="(max-width: 1107px) 100vw, 1107px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-768x477.png 768w"></a><figcaption id="caption-attachment-3617">* United States represented by a Star</figcaption></figure>
<p>It’s important to note the graph is a logarithmic comparison for homicides and homicides by firearm (firearms per 100k Inhabitants are not logarithmic). The trend line comparison of Total Homicides and Homicides by Firearm is linear, but because the comparison is logarithmic, it appears exponential on the chart.</p>
<p>It is clear as homicides increase, homicides by firearm increase (blue data points). In contrast, when there are more firearms, homicides by firearm remain flat (purple data points), implying more firearms do not cause increase the number of homicides involving a firearm.</p>
<p>Further, you can see the blue star representing the United States homicide rate to homicide firearm deaths is right where it is expected. However, the purple star, representing the United States homicide rate to firearms per 100k inhabitants, is way outside the norm.</p>
<p>To summarize,</p>
<blockquote><p>Globally, as the firearm homicide rate increases, the total homicide rate increases; as the prevalence of firearms increase, the homicide rate <span>does not increase</span>.</p></blockquote>

<p>The United States is clearly the largest holder of firearms in the world, most states have more firearms than entire countries. Fun fact:</p>
<blockquote><p>Texans and the Chinese military have the same number of firearms.</p></blockquote>
<p>Clearly, there’s a culture of gun ownership in the United States. When the United States was formed it had just fought a war of independence and regularly combated Native Americans, settling North America by force. Even today, the <a href="https://en.wikipedia.org/wiki/United_States_National_Guard" target="_blank" rel="noopener noreferrer">United States National Guard</a> is one of the largest militias in the world.</p>
<blockquote><p>A well regulated Militia, being necessary to the security of a free State, the right of the people to keep and bear Arms, shall not be infringed.<br>
–<a href="https://constitution.congress.gov/constitution/amendment-2/"> Constitution of the United States</a></p></blockquote>
<p>Without diving into politics, the constitution &amp; culture has enabled the United States to be relatively unique. Firearms are regulated, but just barely. Generally, citizens can do everything from carrying a firearms in public to purchasing assault rifles, flamethrowers, <a href="https://en.wikipedia.org/wiki/Minigun" target="_blank" rel="noopener noreferrer">miniguns</a>, rocket launcher(s), etc. Often the only requirement is obtaining permit to own weapons, after that you can regularly purchase as many firearms as you’d like.</p>
<p>As seen in the previous section, the United States does have a higher (on average) number of firearm deaths. However, this doesn’t necessarily tell the whole story. In the prior section, we focused on the homicide rate. In the following sections, the focus will expand as uniform data collection, similar social norms and a widespread framework for law makes comparisons much easier.</p>
<p>Some topics we will explore here are:</p>
<ul>
<li>Suicide vs homicide vs accidental rates</li>
<li>The type of weapons used in homicides</li>
<li>How demographics impact firearm fatalities</li>
<li>How firearm fatalities compare to other fatalities</li>
</ul>
<h2><span id="Suicides_Homicides_in_the_United_States"></span>Suicides &amp; Homicides in the United States<span></span></h2>
<p>First, it is also important to highlight just how small the number of firearm related homicides really are, when compared to all deaths. On average, the total (suicide, homicide &amp; accidental) number of firearm related fatalities account for about 1.33% of all deaths in the United States (firearm related homicides account for ~0.44% of all deaths) and it varies wildly between states.</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png" alt="" width="736" height="855" srcset="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png 736w, https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal-258x300.png 258w" sizes="(max-width: 736px) 100vw, 736px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png 736w, https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal-258x300.png 258w"></a></p>
<p>Perhaps the most important item to discuss is that this is the “<em>firearm fatality rate</em>“, often conflated with the “<em>firearm homicide rate</em>” by political pundits. While all fatalities are unfortunate, most American’s would argue there is a different between <em>suicides</em> and <em>homicides</em>. Some states, such as Washington, support medically assisted suicides (for the terminally ill).</p>
<p>Below is a comparison between accidents, suicides and homicides by firearms in the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://austingwalters.com/firearms-by-the-numbers/">https://austingwalters.com/firearms-by-the-numbers/</a></em></p>]]>
            </description>
            <link>https://austingwalters.com/firearms-by-the-numbers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927649</guid>
            <pubDate>Thu, 29 Oct 2020 05:45:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Roq – Demonstrating low μs response times for algorithmic trading]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927623">thread link</a>) | @thraneh
<br/>
October 28, 2020 | https://roq-trading.com/posts/latency_experiment/ | <a href="https://web.archive.org/web/*/https://roq-trading.com/posts/latency_experiment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><section></section><section><div><div><div><h2>Latency Experiment</h2><div><ul>Posted by<li><span>Hans Erik Thrane</span>
on 2020-09-20</li></ul></div></div><div><div><div><p>The purpose is to demonstrate the host specific latency profile using a
reasonably realistic trading setup.
By following the steps outlined in this document, you should be in a position
to measure latencies on your own server configuration.</p><div id="summary"><h2>1&nbsp;&nbsp;&nbsp;Summary</h2><p>The test setup includes a Deribit gateway and two connected clients.</p><p>The gateway connects to Deribit's testnet.</p><p>Both clients will automatically respond to ping messages sent by the gateway.</p><p>Client #1 will subscribe all symbols from the gateway.</p><p>Client #2 is a simple trading strategy which will manage orders
through the gateway.
This client only needs to subscribe a single symbol.</p><p>All components will be configured for low latency.</p><p>This document will</p><ul><li>Describe<ul><li>A typical server configuration</li><li>How to install and configure the software</li><li>How to extract latency metrics from the running gateway</li></ul></li><li>Demonstrate<ul><li>Function profiling</li><li>Internal ping latency</li><li>Internal round-trip latency</li><li>External latency</li></ul></li></ul></div><div id="preparations"><h2>2&nbsp;&nbsp;&nbsp;Preparations</h2><div id="platform"><h3>2.1&nbsp;&nbsp;&nbsp;Platform</h3><p>This is the server configuration used for testing</p><ul><li>AMD EPYC 3251 8-Core Processor</li><li>Hyper threading disabled in the BIOS</li><li>Ubuntu 18.04 LTS</li><li>Kernel boot command-line includes <code>isolcpu=1-6</code></li><li>Dynamic frequency scaling disabled using <code>tuned-adm profile network-latency</code></li><li>Docker CE installed</li><li>Prometheus and Grafana running on same host (as Docker containers)</li></ul><div><p>Note</p><p>A true low latency configuration should use RSS (receive packet steering), IRQ
balancing, have local timer interrupts disabled, etc.
However, these are advanced topics and not required for most use-cases.</p></div><p>Knowing the NUMA architecture is very important if you want to achieve the
lowest inter-process latencies</p><pre>$ lstopo --no-io
Machine <span>(</span>31GB<span>)</span> + Package L#0
  L3 L#0 <span>(</span>8192KB<span>)</span>
    L2 L#0 <span>(</span>512KB<span>)</span> + L1d L#0 <span>(</span>32KB<span>)</span> + L1i L#0 <span>(</span>64KB<span>)</span> + Core L#0 + PU L#0 <span>(</span>P#0<span>)</span>
    L2 L#1 <span>(</span>512KB<span>)</span> + L1d L#1 <span>(</span>32KB<span>)</span> + L1i L#1 <span>(</span>64KB<span>)</span> + Core L#1 + PU L#1 <span>(</span>P#1<span>)</span>
    L2 L#2 <span>(</span>512KB<span>)</span> + L1d L#2 <span>(</span>32KB<span>)</span> + L1i L#2 <span>(</span>64KB<span>)</span> + Core L#2 + PU L#2 <span>(</span>P#4<span>)</span>
    L2 L#3 <span>(</span>512KB<span>)</span> + L1d L#3 <span>(</span>32KB<span>)</span> + L1i L#3 <span>(</span>64KB<span>)</span> + Core L#3 + PU L#3 <span>(</span>P#5<span>)</span>
  L3 L#1 <span>(</span>8192KB<span>)</span>
   L2 L#4 <span>(</span>512KB<span>)</span> + L1d L#4 <span>(</span>32KB<span>)</span> + L1i L#4 <span>(</span>64KB<span>)</span> + Core L#4 + PU L#4 <span>(</span>P#2<span>)</span>
   L2 L#5 <span>(</span>512KB<span>)</span> + L1d L#5 <span>(</span>32KB<span>)</span> + L1i L#5 <span>(</span>64KB<span>)</span> + Core L#5 + PU L#5 <span>(</span>P#3<span>)</span>
   L2 L#6 <span>(</span>512KB<span>)</span> + L1d L#6 <span>(</span>32KB<span>)</span> + L1i L#6 <span>(</span>64KB<span>)</span> + Core L#6 + PU L#6 <span>(</span>P#6<span>)</span>
   L2 L#7 <span>(</span>512KB<span>)</span> + L1d L#7 <span>(</span>32KB<span>)</span> + L1i L#7 <span>(</span>64KB<span>)</span> + Core L#7 + PU L#7 <span>(</span>P#7<span>)</span>
</pre><p>We will be running the gateway on processor #1.</p><p>The lowest latencies can be achieved if we run clients on processor #4 and #5
since they reside on the same node as processor #1.</p><p>We will include an experiment to measure the cross-connect between the two nodes.
That can be achieved by running one of the clients on processor #3, for example.</p><p>Further readings</p><ul><li><a href="https://roq-trading.com/docs/tutorials/deployment/ubuntu/">How to configure an Ubuntu server</a></li></ul></div><div id="prerequisites"><h3>2.2&nbsp;&nbsp;&nbsp;Prerequisites</h3><p>Download Miniconda</p><pre>wget -N https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh
</pre><p>Install Miniconda</p><pre>bash Miniconda3-latest-Linux-x86_64.sh -b -u -p ~/miniconda3
</pre><p>Activate conda</p><pre><span>source</span> ~/miniconda3/bin/activate
</pre><div><p>Note</p><p>You should repeat this step whenever you open a new terminal
window and you need to access your conda environment.</p></div><p>Install the required packages</p><pre>conda install <span>\
</span>    --channel https://roq-trading.com/conda/stable <span>\
</span>    roq-deribit <span>\
</span>    roq-samples <span>\
</span>    roq-test
</pre><p>Further readings</p><ul><li><a href="https://roq-trading.com/docs/tutorials/conda/">How to install Miniconda and how to use conda</a></li><li><a href="https://roq-trading.com/docs/reference/gateways/crypto/roq-deribit/">Deribit reference documentation</a></li></ul></div><div id="gateway"><h3>2.3&nbsp;&nbsp;&nbsp;Gateway</h3><p>Let's create a config file named <code>deribit.toml</code>.
You can start by copying the template</p><pre>cp <span>$CONDA_PREFIX</span>/share/roq/deribit/config.toml deribit.toml
</pre><p>Edit the config file and update with your Deribit API key and secret</p><pre><span>[symbols]</span>
  <span>include</span> <span>=</span> <span>".*"</span>
  <span>exclude</span> <span>=</span> <span>"USDT-.*

[accounts]

  [accounts.A1]
  master = true
  login = "</span><span>YOUR_DERIBIT_LOGIN_GOES_HERE</span><span>"
  secret = "</span><span>YOUR_DERIBIT_SECRET_GOES_HERE</span><span>"
  symbols = "</span><span>.</span><span>*</span><span>"

[users]

  [users.test]
  password = "</span><span>1234</span><span>"
  symbols = "</span><span>.</span><span>*</span><span>"

  [users.trader]
  password = "</span><span>secret</span><span>"
  accounts = [ "</span><span>A1</span><span>" ]
  symbols = [ "</span><span>BTC-</span><span>.</span><span>*"</span> <span>]</span>
  <span>monitor_period_secs</span> <span>=</span> <span>60</span>
  <span>ban_period_secs</span> <span>=</span> <span>300</span>
  <span>request_limit</span> <span>=</span> <span>10</span>
</pre><div><p>Note</p><p>Update with your specific details.</p><p>You can search for <code>YOUR_DERIBIT</code> and change accordingly.</p></div><p>It is convenient to create flag file named <code>deribit.gflags</code>
with the following content</p><pre><span>--name</span><span>=</span><span>deribit</span>
<span>--metrics-listen-address</span><span>=</span><span>1234</span>
<span>--fix-uri</span><span>=</span><span>tcp://test.deribit.com:9881</span>
<span>--ws-uri</span><span>=</span><span>wss://test.deribit.com/ws/api/v2</span>
<span>--loop-sleep-nsecs</span><span>=</span><span>0</span>
<span>--loop-timer-freq-nsecs</span><span>=</span><span>250</span>
</pre><div><p>Note</p><p>You can read more about gflags and flag files
<a href="https://gflags.github.io/gflags/#flagfiles">here</a>.</p></div><p>The gateway can now be started like this</p><pre>roq-deribit <span>\
</span>  --config-file <span>"deribit.toml"</span> <span>\
</span>  --flagfile <span>"deribit.gflags"</span> <span>\
</span>  --loop-cpu-affinity<span>=</span><span>1</span> <span>\
</span>  --client-listen-address ~/deribit.sock
</pre><p>Further readings</p><ul><li><a href="https://roq-trading.com/docs/tutorials/gateways/">How to install and configure gateways</a></li><li><a href="https://roq-trading.com/docs/reference/gateways/crypto/roq-deribit/">Deribit reference documentation</a></li></ul></div><div id="client-1"><h3>2.4&nbsp;&nbsp;&nbsp;Client #1</h3><p>Started like this</p><pre>roq-samples-example-4 <span>\
</span>  --name <span>"test"</span> <span>\
</span>  --exchange <span>"deribit"</span> <span>\
</span>  --symbols <span>".*"</span> <span>\
</span>  --dispatcher-affinity <span>4</span> <span>\
</span>  ~/deribit.sock
</pre></div><div id="client-2"><h3>2.5&nbsp;&nbsp;&nbsp;Client #2</h3><p>Started like this</p><pre>roq-test <span>\
</span>  --name <span>"trader"</span> <span>\
</span>  --exchange <span>"deribit"</span> <span>\
</span>  --symbol <span>"BTC-PERPETUAL"</span> <span>\
</span>  --dispatcher-affinity <span>5</span> <span>\
</span>  --enable-trading <span>\
</span>  ~/deribit.sock
</pre></div></div><div id="testing"><h2>3&nbsp;&nbsp;&nbsp;Testing</h2><div id="metrics"><h3>3.1&nbsp;&nbsp;&nbsp;Metrics</h3><p>Gateway metrics can be retrieved from the HTTP interface</p><pre>curl -s http://localhost:1234/metrics <span>2</span>&gt;<span>&amp;</span><span>1</span> <span>|</span> less
</pre><p>For example, profiling information</p><pre><span>#</span> TYPE roq_profile histogram
<span>roq_profile_bucket{source="deribit", connection="ws", function="parse", le="500"} 0
roq_profile_bucket{source="deribit", connection="ws", function="parse", le="1000"} 0
roq_profile_bucket{source="deribit", connection="ws", function="parse", le="2000"} 0
roq_profile_bucket{source="deribit", connection="ws", function="parse", le="5000"} 795
roq_profile_bucket{source="deribit", connection="ws", function="parse", le="10000"} 8471
roq_profile_bucket{source="deribit", connection="ws", function="parse", le="20000"} 8884
roq_profile_bucket{source="deribit", connection="ws", function="parse", le="+Inf"} 8895
roq_profile_sum{source="deribit", connection="ws", function="parse"} 6.13741e+07
roq_profile_count{source="deribit", connection="ws", function="parse"} 8895</span>
</pre><p>This collection represents a histogram of all measurements since the gateway started.
Each bucket has a total count for observations less-than or equal-to the number of nanoseconds,
starting with 500 and ending with infinity.
The sum is the total nanoseconds spent in the function.
The count is the total number of times the function has been called.</p><p>Prometheus allows you to capture a time-series of these metrics and then compute
incremental statistics.</p><p>For example, this would be the average processing time over a 1 minute rolling window</p><pre>irate(roq_profile_sum[1m]) / on (source, connection, function)
irate(roq_profile_count[1m])
</pre><p>And this would be a conditional distribution, the percentage of events where processing time is larger
than 5 microseconds</p><pre>1 - irate(roq_profile_bucket{le="5000"}[1m]) / on (source, connection, function)
irate(roq_profile_count[1m])
</pre><p>Further readings</p><ul><li><a href="https://prometheus.io/docs/practices/histograms/">Histograms</a></li></ul></div><div id="function-profiling"><h3>3.2&nbsp;&nbsp;&nbsp;Function Profiling</h3><p>The following charts are lifted straight from Grafana using
the Prometheus queries outlined in the previous section</p><p>First the average processing time at different measurement points</p><p>Then the conditional processing time</p></div><div id="internal-ping-latency"><h3>3.3&nbsp;&nbsp;&nbsp;Internal Ping Latency</h3><p>For this example we run two instances of Client #1.</p><p>The first instance (<code>test</code>) runs on processor #4 which is located
on the same NUMA node where the gateway is running.</p><p>The second instance (<code>trader</code>) runs on processor #3 which is on
a different NUMA node.</p><p>These are average 1-way heartbeat ping latencies between the gateway
and the clients</p><p>As expected, inter-process latencies are worse for the second instance.</p></div><div id="internal-round-trip-latency"><h3>3.4&nbsp;&nbsp;&nbsp;Internal Round Trip Latency</h3><p>The <code>roq-test</code> program is used to test order management.
It waits, creates an order, waits again, it cancels the order
and finally it terminates when the order is indeed cancelled.</p><pre><span>I0920 09:39:43.255401 107190 application.cpp:55] ===== START =====
I0920 09:39:43.255441 107190 application.cpp:56] Process: name="roq-test", version="0.4.3", type="", git="", date="Sep 16 2020", time="06:02:37"
I0920 09:39:43.255546 107190 service.cpp:39] The metrics service will *not* be started
I0920 09:39:43.256109 107190 controller.cpp:108] Dispatching...
I0920 09:39:43.256121 107190 controller.cpp:112] Starting event loop thread...
I0920 09:39:43.256161 107190 controller.cpp:126] Thread affinity 5
I0920 09:39:43.256253 107191 controller.cpp:148] Event loop thread is now running
I0920 09:39:44.267789 107191 session_manager.cpp:44] Connecting "unix:///var/tmp/roq-deribit.sock"
I0920 09:39:44.273765 107191 session.cpp:38] Adding name="deribit" (user_id=5)
I0920 09:39:44.273853 107190 pollster.cpp:403] Adding name="deribit" (user_id=5)
I0920 09:39:44.273870 107190 strategy.cpp:132] Connected
I0920 09:39:44.273917 107190 strategy.cpp:140] Downloading market data ...
I0920 09:39:44.273921 107190 strategy.cpp:169] Market data is READY
I0920 09:39:44.274311 107190 strategy.cpp:150] download_end={account="", max_order_id=0}
I0920 09:39:44.274314 107190 strategy.cpp:154] Download market data has COMPLETED
I0920 09:39:44.274317 107190 strategy.cpp:143] Downloading account data ...
I0920 09:39:44.274322 107190 strategy.cpp:182] Order manager is READY
I0920 09:39:44.274325 107190 strategy.cpp:150] download_end={account="A1", max_order_id=1000}
I0920 09:39:44.274327 107190 strategy.cpp:157] Download account data has COMPLETED
I0920 09:39:44.274328 107190 strategy.cpp:274] *** INSTRUMENT READY ***
I0920 09:39:44.395049 107190 strategy.cpp:261] *** READY TO TRADE ***
I0920 09:39:44.395222 107190 strategy.cpp:56] create_order={account="A1", order_id=1001, exchange="deribit", symbol="BTC-PERPETUAL", side=BUY, quantity=1.0, order_type=LIMIT, price=10959.5, time_in_force=GTC, position_effect=UNDEFINED, execution_instruction=UNDEFINED, stop_price=nan, max_show_quantity=nan, order_template=""}
I0920 09:39:44.395259 107190 strategy.cpp:225] order_ack={account="A1", order_id=1001, type=CREATE_ORDER, origin=GATEWAY, status=FORWARDED, error=UNDEFINED, text="", gateway_order_id=10000001, external_order_id="", …</span></pre></div></div></div></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://roq-trading.com/posts/latency_experiment/">https://roq-trading.com/posts/latency_experiment/</a></em></p>]]>
            </description>
            <link>https://roq-trading.com/posts/latency_experiment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927623</guid>
            <pubDate>Thu, 29 Oct 2020 05:41:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NASA releases a playlist of eerie sounds the space makes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927354">thread link</a>) | @conse_lad
<br/>
October 28, 2020 | https://sparkonit.com/2020/10/29/space-sounds/ | <a href="https://web.archive.org/web/*/https://sparkonit.com/2020/10/29/space-sounds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><!-- #search-container -->

	<!-- #toggle-sidebar -->

	<!-- #masthead -->

	<div id="content">

	<main id="main">

		
<article id="post-39273">
	<!-- .entry-header -->

		<p>
		What Sound Does The Space Make? 	</p><!-- .entry-summary -->
	
	<div>
		
<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->

<p><span>Just in time for this Halloween, </span><span>the National Aeronautics and Space Administration (NASA) uploaded their collection of eerie sounds our Solar System makes on Soundcloud late Wednesday.&nbsp;</span></p>
<p><span>“You’ve heard the creaks, cracks, and cackling noises of our universe before,” reads the playlist’s description. “Using data from our spacecraft, our scientists gathered NEW sinister sounds from the depths of space in time for Halloween.”</span></p>
<p><span>There’s no sound in space, but these spooky sounds being featured on this playlist came from the waves of plasma flows NASA’s spacecraft tumbled on while soaring to the depths of our universe.</span></p>
<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->


<p><span>Plasma waves festoon the space around the Universe, where they chuck magnetic fields back and forth. This continuous motion of the magnetic fields produces rhythmic </span><span>dissonance that is imperceptible to our ears. But some of NASA’s spacecraft have been attired with instruments </span><span>capable of capturing these sounds.&nbsp;</span></p>
<p><span>Well, with more than thousands of hits since launched, I thought it was time to celebrate the spookiness with my friends here on <a href="https://sparkonit.com/">Sparkonit</a>. Enjoy!</span></p>



<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->



	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->

<!-- #comments -->

	</main><!-- #main -->


<!-- #secondary -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
	</div><!-- #content -->

	<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://sparkonit.com/2020/10/29/space-sounds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927354</guid>
            <pubDate>Thu, 29 Oct 2020 04:52:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Bad Parts, part 1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927352">thread link</a>) | @andrenth
<br/>
October 28, 2020 | https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1 | <a href="https://web.archive.org/web/*/https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><i>See a typo? Have a suggestion?
<a target="_blank" rel="nofollow" href="https://github.com/snoyberg/snoyman.com/edit/master/content/posts/haskell-bad-parts-1.md">Edit this page on Github</a>
</i>
</p>
<p>There’s a popular book called “JavaScript: The Good Parts.” And there’s a common meme around the relative size of that book versus “JavaScript: The Definitive Guide.”</p>
<p><img src="https://i.imgur.com/wIf3EJh.jpg"></p><p>Haskell is in my opinion a far more well designed and coherent language than JavaScript. However, it’s also an old language with some historical baggage. And in many ways it’s a bleeding edge research language that sometimes includes… half-baked features. And due to an inconsistent set of rules around backwards compatibility, it sometimes will break code every six months, and sometimes keep strange decisions around for decades.</p>
<blockquote><div lang="en" dir="ltr"><p>True mastery of Haskell comes down to knowing which things in core libraries should be avoided like the plague.</p><p>* foldl<br>* sum/product<br>* Data.Text.IO<br>* Control.Exception.bracket (use unliftio instead, handles interruptible correctly)</p><p>Just as some examples</p></div>— Michael Snoyman (@snoyberg) <a href="https://twitter.com/snoyberg/status/1321049221697544193?ref_src=twsrc%5Etfw">October 27, 2020</a></blockquote> 
<p>After a request and some tongue-in-cheek comments in that thread, I decided a longer form blog post was in order. I’m going to start off by expanding on the four examples I gave in that tweet. But there are many, many more examples out there. If there’s more interest in seeing a continuation of this series, please let me know. And if you have pet peeves you’d like me to address, input will be very welcome.</p>
<h2>What is a “bad part”</h2>
<p>Very rarely is there such a thing as a language feature, function, type, or library that is so egregiously bad that it should never, ever be used. Null is of course the billion dollar mistake, but it’s still incredibly useful in some cases. So when I say that something is a “bad part” of Haskell, I mean something along these lines:</p>
<ul>
<li>A rarely-useful feature has been promoted to a position of prominence</li>
<li>A function has major downsides that are not documented</li>
<li>There’s an unexpected performance implication</li>
</ul>
<p>There’s a large tendency in the Haskell community to be overly literal in responding to blog posts. Feel free to do that to your heart’s content. But this caveat serves as a word of warning: I’m not going to caveat each one of these with an explanation of “yes, but there’s this one corner case where it’s actually useful.”</p>
<h2>Why attack Haskell?</h2>
<p>Since I’m a Haskeller and advocate of the language, you may be wondering: why am I attacking Haskell? I don’t see this as an attack. I <em>do</em> wish we could fix these issues, and I think it’s a fair thing to say that the problems I’m listing are warts on the language. But every language has warts. I’m writing this because I’ve seen these kinds of things break real world projects. I’ve seen these failures manifest at runtime, defeating yet again the false claim that “if it compiles it works.” I’ve seen these become nefarious time bombs that disincentivize people from ever working with Haskell in the future.</p>
<p>I hope by calling these out publicly, I can help raise awareness of these problems. And then, either we can fix the problems at their source or, more likely, get more widespread awareness of the issue.</p>
<p>Also, because it feels appropriate, I’m going to take a more jovial tone below. I personally find it easier to beat up on a language I love like that.</p>
<h2>foldl</h2>
<p>Duncan Coutts <a href="https://www.well-typed.com/blog/2014/04/fixing-foldl/">already did this one</a>. <code>foldl</code> is broken. It’s a bad function. Left folds are supposed to be strict, not lazy. End of story. Goodbye. Too many space leaks have been caused by this function. We should gut it out entirely.</p>
<p>But wait! A lazy left fold makes perfect sense for a <code>Vector</code>! Yeah, no one ever meant that. And the problem isn’t the fact that this function exists. It’s the <strong>name</strong>. It has taken the hallowed spot of the One True Left Fold. I’m sorry, the One True Left Fold is strict.</p>
<p>Also, side note: we can’t raise linked lists to a position of supreme power within our ecosystem and then pretend like we actually care about vectors. We don’t, we just pay lip service to them. Until we fix the wart which is overuse of lists, <code>foldl</code> is only ever used on lists.</p>
<p>OK, back to this bad left fold. This is all made worse by the fact that the true left fold, <code>foldl'</code>, is not even exported by the <code>Prelude</code>. We Haskellers are a lazy bunch. And if you make me type in <code>import Data.List (foldl')</code>, I just won’t. I’d rather have a space leak than waste precious time typing in those characters.</p>
<p>Alright, so what should you do? Use an alternative prelude that doesn’t export a bad function, and does export a good function. If you really, really want a lazy left fold: add a comment, or use a function named <code>foldlButLazyIReallyMeanIt</code>. Otherwise I’m going to fix your code during my code review.</p>
<h2>sum/product</h2>
<p>The <code>sum</code> and <code>product</code> functions are implemented in terms of <code>foldr</code>. Well, actually <code>foldMap</code>, but list’s <code>foldMap</code> is implemented in terms of <code>foldr</code>, and lists are the only data structure that exist in Haskell. “Oh, but <code>foldr</code> is the good function, right?” Only if you’re folding a function which is lazy in its second argument. <code>+</code> and <code>*</code> are both strict in both of their arguments.</p>
<p>If you’re not aware of that terminology: “strict in both arguments” means “in order to evaluate the result of this function/operator, I need to evaluate both of its arguments.” I can’t evaluate <code>x + y</code> without knowing what <code>x</code> and <code>y</code> are. On the other hand, <code>:</code> (list cons) is lazy in its second argument. Evaluating <code>x : y</code> doesn’t require evaluating <code>y</code> (or, for that matter, <code>x</code>). (For more information, see <a href="https://www.fpcomplete.com/haskell/tutorial/all-about-strictness/">all about strictness</a>.)</p>
<p>“But wait!” you say. “What if I have a custom data type with a custom typeclass instance of <code>Num</code> that has a custom <code>+</code> and/or <code>*</code> that is in fact lazy in the second argument! Then <code>sum</code> and <code>product</code> are perfect as they are!”</p>
<p>That’s true. Now go off and write your own <code>lazySum</code> and <code>lazyProduct</code>. 99 times out of 100, or more likely 999,999 times out of 1,000,000, we want the fully strict version.</p>
<p>“But it doesn’t matter, GHC will optimize this away.” Maybe. Maybe not. Stop relying on GHC’s optimizer to convert horribly inefficient code into not efficient code. (But I digress, we’ll talk about why the <code>vector</code> package is bad another time.)</p>
<h2>Data.Text.IO</h2>
<p>I’ve already covered this one once before when I told everyone to <a href="https://www.snoyman.com/blog/2016/12/beware-of-readfile">beware of <code>readFile</code></a>. In that blog post, I talk about a bunch of <code>String</code> based I/O functions, especially the titular <code>readFile</code>, which is obnoxiously exported by <code>Prelude</code>. Those are bad, and I’ll reiterate why in a second. But <code>Data.Text.IO</code> is arguably far worse. The reason is that there’s pretty good awareness in the community that <code>String</code>-based I/O is bad. Even though the <code>String</code> part is the least of our worries, it does a good job of scaring away the uninitiated.</p>
<p>But <code>Data.Text.IO</code> is a wolf in sheep’s clothing. We’re all told by people who think they can tell people how to write their Haskell code (<em>cough</em> me <em>cough</em>) that we should exorcise <code>String</code> from our codebases and replace it in all cases with <code>Text</code>. Attacking the <code>Text</code> type is a topic for another time. But the problem is that by cloaking itself in the warm embrace of <code>Text</code>, this module claims more legitimacy than it deserves.</p>
<p>The only module worse in this regard is <code>Data.Text.Lazy.IO</code>, which should be buried even deeper.</p>
<p>OK, what exactly am I on about? Locale sensitive file decoding. It’s possible that this has been the number one example of a Haskell bug in the wild I’ve encountered in my entire career. Not the spooky memory leak. Partial functions like <code>head</code> randomly throwing exceptions are up there, but don’t quite rise to prominence.</p>
<p>You see, when you are dealing with file formats, there is typically an actual, defined format. YAML, XML, JSON, and many others give a lot of information about how to serialize data, including character data, into raw bytes. We want to be consistent. We want to write a file in one run of the program, and have it read in a separate run. We want to write the file on a Windows machine and read it on a Linux machine. Or we want to interact with programs in other languages that read or write data in a consistent format.</p>
<p>Locale sensitive file encoding and decoding laughs in our face. When you use <code>Data.Text.IO.readFile</code>, it plays a mind reading game of trying to deduce from clues you don’t care about which character encoding to use. These days, on the vast majority of systems used by native English speakers, this turns out to be UTF-8. So using <code>readFile</code> and <code>writeFile</code> typically “just works.” Using functions from <code>Data.Text.IO</code> looks safe, and can easily get hidden in a large PR or a library dependency.</p>
<p>That’s when all hell breaks loose. You ship this code. You run it in a Docker container. “Oops, you forgot to set the <code>LANG</code> env var, Imma crash.” But it’s worse than that. Typically things will work well for weeks or months, because it can often be a long time before someone tries to encode a non-ASCII character.</p>
<p>The same kind of thing happens regularly to Stack. Someone adds a new feature that writes and reads a file. The code passes all integration tests. And then someone in Russia with a weird Windows code page set and a Cyrillic character in their name files a bug report 2 years later about how they can’t build anything, and we sheepishly tell them to run <code>chcp 65001</code> or build in <code>c:\</code>.</p>
<p>Friends don’t let friends use <code>Data.Text.IO</code>.</p>
<p>“Oh, but <code>putStrLn</code> is fine!” Yeah, maybe. It’s also potentially slow. And it will throw a runtime exception due to character encoding mismatches. Just use a good logging library. That’s why we have one in <code>rio</code>.</p>
<p><strong>EDIT</strong> Since so many people have asked: instead of <code>readFile</code>, I recommend using <a href="https://www.stackage.org/haddock/lts-16.20/rio-0.1.19.0/RIO.html#v:readFileUtf8"><code>readFileUtf8</code></a>, which is available from <a href="https://github.com/commercialhaskell/rio"><code>rio</code></a>.</p>
<h2>Control.Exception.bracket</h2>
<p>This is by far the least objectionable of the bad things in this list. I included it because the entire original tweet was inspired by a coworker telling me about a bug he ran into because of this function.</p>
<p>Async exceptions are subtle. Very, very subtle. Like, super duper subtle. I’ve devoted a large percentage to my Haskell teaching career towards them. Async exceptions are a concept that don’t truly exist in most other languages. They require rewiring the way your brain works for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1">https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1</a></em></p>]]>
            </description>
            <link>https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927352</guid>
            <pubDate>Thu, 29 Oct 2020 04:51:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Journey to Delivering a Faster Experience at Skroutz.gr]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927349">thread link</a>) | @aloukissas
<br/>
October 28, 2020 | https://engineering.skroutz.gr/blog/speed-the-journey-to-delivering-a-faster-experience-at-skroutz-gr/ | <a href="https://web.archive.org/web/*/https://engineering.skroutz.gr/blog/speed-the-journey-to-delivering-a-faster-experience-at-skroutz-gr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<p>We’ve always placed the user experience first, here at Skroutz. Since a performant application is essential for a seamless journey, speed has always been at our core.</p>

<p>Our rapidly evolving environment -the number of development teams, the adoption of new technologies, the addition of new features etc.- gradually slowed us down.</p>

<p>We knew we had to take action.</p>

<p>For this, we formed a non-typical task-force team to speed us up. We identified the problems, chose our measurement tools and methods and took the plunge.</p>

<p>Measuring performance is not an easy task. It involves both user perception and strictly defined metrics and thresholds.</p>

<p>In order to improve the speed, we tried various solutions. Some worked. Some didn’t. Below you can read in short the key takeaways.</p>

<p><strong>Assets</strong>. Our main goal was to optimize the number and timing of requests. By initially loading only the necessary above the fold images and fine tuning our lazy loading mechanisms, we noticed significant gains in terms of initial requests (almost half in our Product page and up to 30 less in our Listing) and therefore some worthy improvement in Speed Index metrics (in some cases up to ~4.5%).</p>

<p><strong>HTML</strong>. Excessive DOM size was one of our most critical performance bottlenecks. Our Product pages (the most important section) could reach up to ~8k nodes in some cases, far from Google’s proposal of 1,5k.<br>
We tried various solutions involving windowing (rejected), async loading product cards’ content and showing less user reviews (by risking losing valuable user generated content).<br>
What did make a huge difference was timing: Loading the information when it actually needed to exist. This was achieved by implementing a mechanism that would notify each card when it was about to appear in the viewport. The only element needed beforehand was a single-node placeholder. In some cases the DOM nodes were reduced by 45%, which results in an increase of ~10 points in our overall Lighthouse score!</p>

<p><strong>CSS</strong>. Although our styling architecture was in pretty good shape, we thought it might be worth trying critical CSS. The concept was to initially load only the necessary styles for rendering anything above-the fold. This would improve metrics such as First Contentful Paint &amp; Largest Contentful Paint while making the loading feel faster. It turned out that the above metrics were too slightly improved compared to the effort needed to add it in our pipeline. In short, this didn’t work for us.</p>

<p><strong>Javascript</strong>. Moving gradually from static to interactive pages caused code bloating, especially at the Javascript side. Our main JS file was including lots of libraries that were not used in every page. This is a problem, especially for mobile devices, due to the fact that JS runs in the main thread.<br>
Our actions, directed to reduce our webpack bundle size in order to release main thread calculations for the initial load, and iterate over the Redux architecture to improve speed after user interaction, led to slightly better performance.</p>

<p>During this journey, we also started addressing some issues on new <strong>Web Vitals</strong> user-centric metrics. We mainly focused on visual stability, by eliminating any layout shifts.</p>

<p>After a year’s work, we <strong>made Skroutz.gr faster</strong>. And more stable.</p>

<p>If you are interested in more details, and you’re ready for a deeper technical dive, make yourself a coffee and keep on reading (it will take ~30 minutes to read).</p>

<hr>

<blockquote>
  <p><strong>Table of Contents</strong></p>

  <p><a href="#a-brief-history">A Brief History</a> <br></p>

  <p><a href="#speed-not-a-metric-but-a-users-issue">Speed: not a Metric, but a Users’ Issue</a> <br></p>

  <p><a href="#evolution-of-performance-metrics-from-speed-index-to-core-web-vitals">Evolution of Performance Metrics: from Speed Index to Core Web Vitals</a> <br>
  › <a href="#pagespeed-insights-psi">Pagespeed Insights (PSI)</a> <br>
  › <a href="#core-web-vitals">Core Web Vitals</a> <br></p>

  <p><a href="#the-problems-of-skroutzgr">The Problems of Skroutz.gr</a> <br>
  › <a href="#html">HTML</a> <br>
  › <a href="#css">CSS</a> <br>
  › <a href="#javascript">Javascript</a> <br>
  › <a href="#assets">Assets</a> <br></p>

  <p><a href="#the-journey-what-worked-and-what-didnt">The Journey: What Worked and What Didn’t</a> <br>
  › <a href="#assets-networking">Assets</a> <br>
  › <a href="#html-1">HTML</a> <br>
  › <a href="#css-1">CSS</a> <br>
  › <a href="#javascript-1">Javascript</a> <br>
  › <a href="#core-web-vitals-cumulative-layout-shifts-cls-issues">Core Web Vitals: Cumulative Layout Shift (CLS)</a> <br></p>

  <p><a href="#onwards---closing">Onwards - Closing</a> <br></p>
</blockquote>


<p><a href="https://www.skroutz.gr/" target="_blank">Skroutz.gr</a> was always a quite fast and sophisticated web application.</p>

<p>Speed has always been a critical component for <a href="https://www.skroutz.gr/" target="_blank">Skroutz.gr</a> since we believe
that for a modern web experience, it’s important to get fast and stay fast.</p>

<p>Historically, the biggest problem we were facing regarding speed (and the biggest blessing at the same time),
was the really huge amount of content (DOM) in some of our most popular pages, which contains a lot of shops and user-generated content, like reviews, questions, etc.
This problem becomes bigger and bigger as we add extra information for Products and Categories or extra services
(we have developed a <a href="https://www.skroutz.gr/ecommerce/landing">Marketplace functionality</a> where users can buy directly from Skroutz.gr).</p>

<p>Back in 2016, the huge DOM of some pages was causing crashes due to memory restrictions in some devices (i.e. iPad),
while at the same time the performance was poor, in terms of rendering and painting.
<a href="https://engineering.skroutz.gr/blog/Skroutz-redesign-how-we-designed-and-implemented-our-own-Design-System/#html" target="_blank">To solve these issues at that time</a>,
we started requesting and rendering elements asynchronously.</p>

<p>However, since <a href="https://engineering.skroutz.gr/blog/Skroutz-redesign-how-we-designed-and-implemented-our-own-Design-System/" target="_blank">our last major redesign in 2016</a>,
lots of things have changed.</p>

<p>Facts like the rapidly growing number of development teams, the adoption of new technologies (i.e. React js, CSS Grid),
the addition of more and more features in our pages, etc., led to worse rendering performance, despite the fact that today
there are better and more powerful devices our applications are running on.</p>

<p>Rendering speed took a backseat.</p>

<p>On the other hand, one of the main questions we’re regularly asking ourselves here at Skroutz, is whether our website responds to our users’ expectations and what we can do in order to help them with their buying decisions. When it comes to user experience, speed matters.</p>

<p>Today, consumers are more demanding than they’ve ever been. When they weigh up the experience on a site, they aren’t just
comparing it with their competitors, they’re rating it against the best in class services they use every day.</p>

<p>Being of “Moderate Speed” was not acceptable for us, so we decided to take action in order to resolve the issues.</p>

<p>We formed a non-typical task-force team, consisting of engineers, SEO-ers and product owners and we started working on,
in order to improve our speed.</p>

<p>In the following, we describe things we did, how we measured our actions, what worked for us, what didn’t work, and some
takeaways from our experience during the journey.</p>

<hr>


<p>Imagine you’re walking through an unfamiliar city to get to an important appointment. <br>
You walk through various streets and city centers on your way. But here and there, there are slow automatic doors
you have to wait for to open and unexpected construction detours lead you astray. All of these events interrupt
your progress, increase stress and distract you from reaching your destination.</p>

<p>People using the web are also on a journey, with each of their actions constituting one step in what would ideally be a continuous flow.
And just like in the real world, they can be interrupted by delays, distracted from their tasks and led to make errors. <br>
These events, in turn, can lead to reduced satisfaction and abandonment of a site or the whole journey.</p>

<p>In both cases, removing interruptions and obstacles is the key to a smooth journey and a satisfied user
[<a href="https://blog.chromium.org/2020/05/the-science-behind-web-vitals.html" target="_blank">chromium blog</a>].</p>

<p>When it comes to user experience, speed matters. A
<a href="https://www.ericsson.com/en/press-releases/2016/2/streaming-delays-mentally-taxing-for-smartphone-users-ericsson-mobility-report" target="_blank">consumer study</a>
shows that the <strong>stress response to delays in mobile speed are similar to that of watching a horror movie or solving
a mathematical problem</strong>, and greater than waiting in a checkout line at a retail store [<a href="https://web.dev/why-speed-matters/" target="_blank">ref</a>]. <br></p>

<p>Website performance is crucial to a web application’s success. <br></p>

<p>Amazon found that each additional 1/10th of a second of load time corresponded with a 1% reduction in sales.
Walmart found that for every second they improved their page load times they added an additional 2% to their conversion rate
[<a href="https://www.alphabetcreative.com/speed-matters-website-performance-and-perception/" target="_blank">ref</a>].
EBay saw a 0.5% increase in “Add to Cart” count for every 100 milliseconds improvement in search page loading time
[<a href="https://web.dev/shopping-for-speed-on-ebay/" target="_blank">ref</a>].</p>

<p>Besides conversion rates, you may know that <a href="https://webmasters.googleblog.com/2018/01/using-page-speed-in-mobile-search.html" target="_blank">Google uses the performance of a website as a ranking factor</a> in search results as well!</p>

<p>In his book <a href="https://www.nngroup.com/books/usability-engineering/" target="_blank">Usability Engineering (1993), Jakob Nielsen</a>*
identifies three main response time limits.</p>

<ul>
  <li><strong>0.1 second</strong> — Operations that are completed in 100ms or fewer will feel instantaneous to the user.
This is the gold standard that one should aim for when optimising your websites.</li>
  <li><strong>1 second</strong> — Operations that take 1 second to finish are generally OK, but the user will feel the pause.
If all operations take 1 second to complete, a website may feel a little sluggish.</li>
  <li><strong>10 seconds</strong> — If an operation takes 10 seconds or more to complete, the user may switch over to a new tab,
or give up on the website completely (this depends on what operation is being completed.
For example, users are more likely to stick around if they’ve just submitted their card details in the checkout
than if they’re waiting to load a product page).</li>
</ul>

<p>* <em>Since these limits published back in 1993, as internet speed have increased and we are now browsing the web
at a lightning pace, there is a speculation that the upper limit is pretty smaller, close to 5 seconds or even lower.</em></p>

<p><strong>Takeaway: Performance is important</strong>! It can mean the difference between making a sale, or losing a customer to the competition.</p>

<hr>


<p>Performance is a foundational aspect of good user experiences.</p>

<p><strong>But what exactly is Performance?</strong></p>

<p>And how do we put a page in the fast or in the slow bucket?</p>

<p>Users of the web expect that the pages they visit will be fastly rendered, interactive and smooth.
Pages should not only load quickly, but also run well; scrolling should be stick-to-finger fast, and animations and interactions should be silky smooth.</p>

<p>Performance is more about user perception and less about the actual, objective duration.
How fast a website feels like it’s loading and rendering has a greater impact on user experience than how fast the website actually loads and renders.</p>

<p>How fast or slow something feels like, depends a lot on whether the user is actively or passively waiting for this thing to happen. Waits can have an active and passive phase. When …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engineering.skroutz.gr/blog/speed-the-journey-to-delivering-a-faster-experience-at-skroutz-gr/">https://engineering.skroutz.gr/blog/speed-the-journey-to-delivering-a-faster-experience-at-skroutz-gr/</a></em></p>]]>
            </description>
            <link>https://engineering.skroutz.gr/blog/speed-the-journey-to-delivering-a-faster-experience-at-skroutz-gr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927349</guid>
            <pubDate>Thu, 29 Oct 2020 04:51:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Small Scale Community Development Work]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927340">thread link</a>) | @DoreenMichele
<br/>
October 28, 2020 | http://www.eclogiselle.com/2020/10/small-scale-development-work.html | <a href="https://web.archive.org/web/*/http://www.eclogiselle.com/2020/10/small-scale-development-work.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-3519297355200665670"><p>
If you are in a small community, you may feel that "planning and development" work are out of reach. You may feel you simply don't have the resources to do any such thing.

</p><p>
If you are feeling that way, you probably are confusing the bureaucratic window dressing of big city planning processes for "planning." But that's not what planning and development are.
</p><p>
That's just how big organizations manage a process at scale that involves a large number of people. It's mostly not relevant to your needs.

</p><p>
At a smaller scale, planning and development can be boiled down to the essentials of doing some research, setting some goals and executing. It can potentially be done by one person part time with no official title. 

</p><hr><p>

I homeschooled my two adult sons. So for some years I ran a small school under the laws of the state of California with just two students.

</p><p>
My husband was listed as the administrator but I did most of the work involved in educating our sons and running a small school under the laws of the state of California. I researched the curriculum and did most of the teaching and so forth. 

</p><p>
People tend to be intimidated by the idea of teaching their own children because they look at what public schools do and it looks overwhelming to try to replicate that with the resources available to a family. People imagine they need to actively teach their kids for eight hours a day every day, plus grade everything and design the curriculum and so forth.

</p><p>
The reality is that homeschooling is unlike sending your kids to public school because a lot of the things that public schools do are done to manage the scale involved in having so many students. A lot of that is not only unnecessary if you homeschool your own children, it is actively counterproductive and has no place in a homeschool setting.

</p><p>
When students get to public school, they may line up outside the classroom waiting for it to open. When you homeschool, your kids will already be in the building. 

</p><p>
When the day starts at public school, the teacher takes roll call to make sure all their students are acconted for. If you have two students, you don't need to do roll call. You know if both of your kids are present without reading out their names from a list and having them answer back that they are "Here."

</p><p>

Assessment at public schools often involves multiple choice tests because those are easier for a teacher to grade when you are trying to assess twenty or more students and you get a different set of twenty or more students every year. It's not necessary to follow that pattern when you have just two students and they are the same two kids every year.

</p><p>

Assessment in my two-student school involved printing off state standards twice a year for the grades of my two sons and checking off all the things I knew for a fact they could do competently. If I wasn't sure, I just observed them for a few days.

</p><p>
Once in a while, I had to actually ask them a few questions or otherwise check to see what they could do, but it was rare. I basically never gave them tests of the sort found in public school.
</p><p>
One study found that in an eight hour day at public school, most students spent only an hour or two actually learning. The rest of their time was spent changing classrooms, taking roll call, having lunch and so forth.

</p><p>
This fits with California state law at the time. When I was a homeschooling parent, one option to be legal was to hire a tutor for your children for three hours a day.
</p><p>
Not eight hours. Just three hours.
</p><p>
The one-on-one attention a parent or tutor can give to a child accomplishes a great deal more in a short period of time than what happens when a public school teacher has to keep track of and deal with twenty or more students. 
</p><p>
Not only do you not need to actively teach your kids eight hours a day, it's too intensive to try. You and they would soon both suffer burn out at that pace.

</p><p>
Eight hours a day of schooling only makes sense when much of that time is spent on lunch, recess and bureaucratic processes. It is absolutely overkill if you try to spend that much time actively teaching a child one-on-one.


</p><p>

Of course, there were some bureaucratic processes we could not escape. We did have to file paperwork with the state of California annually. We did have to pick a name for the school and we did have to officially assign roles where I was listed as the teacher and my husband was listed as the administrator. We did keep records of their schoolwork.

</p><hr><p>

Generally speaking, planning and development work for a small town or unincorporated community should look more like homeschooling than like public school. The bureaucratic processes found in bigger cities mostly are not going to be helpful at a very small scale. 
</p><p>

Just like with homeschooling, most bureaucratic processes will be actively counterproductive for small scale development work. Of course you will need to comply with certain things, just like we needed to file paperwork annually and keep some records to legally homeschool. 
</p><p>
But you should actively seek to avoid having your valuable time consumed with the bureaucratic window dressing parts of planning and economic development. If you want to be effective doing small scale development work, you want to identify the parts that matter and actively ditch the parts that are merely bureaucratic processes aimed at managing a planning process on a large scale with many people. 

</p><p>

Metaphorically, you want to keep the "three hours of learning" and ditch the "five hours of bureaucratic processes" like I did as a homeschooling parent.

</p><ul><li>
You will want to put together some basic information about where the community stands currently and what some of the pain points are.
</li><li>
Based on a list of assets and pain points, you will want to set some goals. 
</li><li>
From there, you should seek to provide solutions for the least amount of time and effort possible.
</li></ul><p>

Try hard to avoid scenarios where you tell yourself "First, we need x before we can do y." In many cases, that amounts to making excuses rather than making plans.

</p><p>
If poverty is an issue, try to find answers in the here and now, such as <a href="http://writepay.blogspot.com/">earning money online</a> or helping locals raise some of their own food. You could start a community garden or even just check your <a href="https://www.gardeningknowhow.com/extension-search">local County Extension</a> office for <a href="https://www.reddit.com/r/CitizenPlanners/comments/fn3jno/county_extension_services/">help putting out information on container gardening</a>.
</p><p>
If physical health is a concern, don't tell yourself that your tiny town needs a doctor or hospital that it can't possibly support. Instead, start a healthy recipe club, a community garden or a walking club. Diet and exercise are both first lines of defense for good health and are immediately accessible by anyone.

</p><p>


Of course, as you grow your needs and processes may need to change and there can certainly be value in jumping through the hoops to do things in a more formal way. Sometimes, that's the only way to access state funds, federal technical assistance and similar.
</p><p>
Just make sure you have a good reason to jump through those hoops and you aren't doing it because you imagine "That's how development works because that's what they do in bigger cities." If there isn't a concrete payoff that cannot be achieved without jumping through those hoops, it's possibly just bureaucratic window dressing that your small community can ill afford to waste its limited resources on.




</p></div>
</div></div>]]>
            </description>
            <link>http://www.eclogiselle.com/2020/10/small-scale-development-work.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927340</guid>
            <pubDate>Thu, 29 Oct 2020 04:49:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Which best practices would you add to this list?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927327">thread link</a>) | @jonnylangefeld
<br/>
October 28, 2020 | https://jonnylangefeld.com/blog/how-to-write-a-go-api-the-ultimate-guide | <a href="https://web.archive.org/web/*/https://jonnylangefeld.com/blog/how-to-write-a-go-api-the-ultimate-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        


        <article itemscope="" itemtype="http://schema.org/BlogPosting">
  

  <div itemprop="articleBody">
    <p><img src="https://jonnylangefeld.com/assets/posts/gopher.svg" width="35%"></p>

<p>“TIL” (<a href="https://www.urbandictionary.com/define.php?term=TIL">today I learned</a>) is an acronym I recently discovered (Example usage: “TIL what TIL means”). Since I’m ESL (<a href="https://www.urbandictionary.com/define.php?term=ESL">English as Second Language</a>) I use the urban dictionary a lot to look up these acronyms. “TIL” turned out to be a very useful term, because it’s true: One never stops learning. And so it happened that I started this blog writing about <a href="https://jonnylangefeld.com/blog/python-flask-base-project">a Python Flask API</a> and continued with a three part series on <a href="https://jonnylangefeld.com/blog/how-to-write-a-go-api-part-1-webserver-with-iris">how to write a go API</a>. And while there is a lot of valuable information in those posts, today I am writing about what I learned since then and what my current set of best practices is to write an efficient and production ready API.</p>

<p>Reading many blogs myself, I sometimes miss context on given examples. So I published a sample repo which can be found on <a href="https://jonnylangefeld/go-api">github</a>. Every code example in this post links to the source lines of this repo.</p>

<p>The following paragraphs feature a large set of best practices and why I like them. Send me an <a href="https://jonnylangefeld.com/about#contactform">email</a> or tweet me <a href="https://twitter.com/jonnylangefeld">@jonnylangefeld</a> if you feel like something is missing!</p>

<!--more-->

<p><strong>Table of Contents</strong></p>

<ul>
  <li><a href="#1-project-scaffolding">1. Project Scaffolding</a></li>
  <li><a href="#2-the-toolsgo-pattern">2. The tools.go Pattern</a></li>
  <li><a href="#3-command-line-flags-with-pflag">3. Command Line Flags With pflag</a></li>
  <li><a href="#4-structured-logging-with-zap">4. Structured Logging With zap</a></li>
  <li><a href="#5-graceful-exits">5. Graceful Exits</a></li>
  <li><a href="#6-log-version-on-startup">6. Log Version on Startup</a></li>
  <li><a href="#7-define-types-in-their-own-package">7. Define Types in Their Own Package</a></li>
  <li><a href="#8-chi-as-http-framework">8. chi as HTTP Framework</a></li>
  <li><a href="#9-custom-middlewares">9. Custom Middlewares</a></li>
  <li><a href="#10-pagination">10. Pagination</a></li>
  <li><a href="#11-database-integration-with-gorm">11. Database Integration With gorm</a></li>
  <li><a href="#12-database-integration-tests-with-dockertest">12. Database Integration Tests With dockertest</a></li>
  <li><a href="#13-api-integration-tests-with-gomock">13. API Integration Tests With gomock</a></li>
  <li><a href="#14-render-responses-with-go-chirender">14. Render Responses With go-chi/render</a></li>
  <li><a href="#15-documentation-as-code-with-http-swagger">15. Documentation as Code With http-swagger</a></li>
  <li><a href="#16-staged-dockerfile">16. Staged Dockerfile</a></li>
</ul>

<h3 id="1-project-scaffolding">1. Project Scaffolding</h3>

<p>I use the following tree as project layout. More packages can be added under <code>pkg</code>.</p>
<div><div><pre><code>├── Dockerfile
├── Makefile
├── docs                    # automatically generated by `make docs`
├── go.mod
├── go.sum
├── main.go                 # main.go in the root rather than in `/cmd` directory
├── pkg
│&nbsp;&nbsp; ├── api                 # containing all API related functions and the router
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── api.go
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── api_test.go
│&nbsp;&nbsp; │&nbsp;&nbsp; └── operations.go
│&nbsp;&nbsp; ├── db                  # all database interactions happen in here
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── db.go
│&nbsp;&nbsp; │&nbsp;&nbsp; └── db_test.go
│&nbsp;&nbsp; ├── middelware          # for custom middlewares
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── context.go
│&nbsp;&nbsp; │&nbsp;&nbsp; └── logger.go
│&nbsp;&nbsp; └── types               # our types get a separate package
│&nbsp;&nbsp;     └── types.go
├── readme.md
└── tools.go                # tools.go to manage tool versions via go.mod
</code></pre></div></div>

<p>With that out of the way, lets look into the <code>main.go</code> file.</p>

<h3 id="2-the-toolsgo-pattern">2. The tools.go Pattern</h3>

<p>I’m really a fan of managing tool dependencies also through go modules. That pins their versions and includes them in my vendor directory. Marco Franssen wrote in-depth about this pattern in <a href="https://marcofranssen.nl/manage-go-tools-via-go-modules/">this blog post</a>.</p>

<h3 id="3-command-line-flags-with-pflag">3. Command Line Flags With <a href="https://github.com/spf13/pflag">pflag</a></h3>

<p>There are many ways to work with command line flags and configurations in go. One can go fancy with <a href="https://github.com/spf13/viper"><code>viper</code></a> or stay simple with go’s built in <code>flags</code> package. I like <a href="https://github.com/spf13/pflag"><code>pflag</code></a> because of it’s simplicity and similarity to go’s own package, yet it offers POSIX/GNU-style flags making it more natural to use on your command line. The <a href="https://jonnylangefeld/go-api">sample repo</a> contains an example usage:</p>

<div><div><pre><code><span>func</span> <span>init</span><span>()</span> <span>{</span>
	<span>pflag</span><span>.</span><span>StringVarP</span><span>(</span><span>&amp;</span><span>addr</span><span>,</span> <span>"address"</span><span>,</span> <span>"a"</span><span>,</span> <span>":8080"</span><span>,</span> <span>"the address for the api to listen on. Host and port separated by ':'"</span><span>)</span>
	<span>pflag</span><span>.</span><span>Parse</span><span>()</span>
<span>}</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/main.go#L22-L25">source</a></em>)</sup></p>

<p>Pflag comes with help built in:</p>

<div><div><pre><code>$ go-api -h
Usage of go-api:
  -a, --address string   the address for the api to listen on. Host and port separated by ':' (default ":8080")

</code></pre></div></div>

<h3 id="4-structured-logging-with-zap">4. Structured Logging With <a href="https://github.com/uber-go/zap">zap</a></h3>

<p>This is certainly an opinionated decision, but my favorite logger is <a href="https://github.com/uber-go/zap">zap</a>. It can be configured in all kinds of ways, but I like to keep it very simple. This is the configuration I use:</p>

<div><div><pre><code><span>// configure logger</span>
<span>log</span><span>,</span> <span>_</span> <span>:=</span> <span>zap</span><span>.</span><span>NewProduction</span><span>(</span><span>zap</span><span>.</span><span>WithCaller</span><span>(</span><span>false</span><span>))</span>
<span>defer</span> <span>func</span><span>()</span> <span>{</span>
    <span>_</span> <span>=</span> <span>log</span><span>.</span><span>Sync</span><span>()</span>
<span>}()</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/main.go#L34-L38">source</a></em>)</sup></p>

<p>Which gives me a beautiful log output like the following:</p>

<div><div><pre><code><span>{</span><span>"level"</span><span>:</span><span>"info"</span><span>,</span><span>"ts"</span><span>:</span><span>1601686510.597971</span><span>,</span><span>"msg"</span><span>:</span><span>"starting up API..."</span><span>,</span><span>"version"</span><span>:</span><span>"v1.0.0"</span><span>}</span><span>
</span><span>{</span><span>"level"</span><span>:</span><span>"info"</span><span>,</span><span>"ts"</span><span>:</span><span>1601686510.70517</span><span>,</span><span>"msg"</span><span>:</span><span>"ready to serve requests on :8080"</span><span>}</span><span>
</span><span>{</span><span>"level"</span><span>:</span><span>"info"</span><span>,</span><span>"ts"</span><span>:</span><span>1601686516.446462</span><span>,</span><span>"msg"</span><span>:</span><span>"served request"</span><span>,</span><span>"proto"</span><span>:</span><span>"HTTP/1.1"</span><span>,</span><span>"method"</span><span>:</span><span>"GET"</span><span>,</span><span>"path"</span><span>:</span><span>"/articles"</span><span>,</span><span>"lat"</span><span>:</span><span>0.002087763</span><span>,</span><span>"status"</span><span>:</span><span>200</span><span>,</span><span>"size"</span><span>:</span><span>13</span><span>,</span><span>"reqId"</span><span>:</span><span>"C02C864PLVDL/gESGYmlmCu-000001"</span><span>}</span><span>
</span><span>{</span><span>"level"</span><span>:</span><span>"info"</span><span>,</span><span>"ts"</span><span>:</span><span>1601686521.3242629</span><span>,</span><span>"msg"</span><span>:</span><span>"served request"</span><span>,</span><span>"proto"</span><span>:</span><span>"HTTP/1.1"</span><span>,</span><span>"method"</span><span>:</span><span>"GET"</span><span>,</span><span>"path"</span><span>:</span><span>"/orders"</span><span>,</span><span>"lat"</span><span>:</span><span>0.002300746</span><span>,</span><span>"status"</span><span>:</span><span>200</span><span>,</span><span>"size"</span><span>:</span><span>13</span><span>,</span><span>"reqId"</span><span>:</span><span>"C02C864PLVDL/gESGYmlmCu-000002"</span><span>}</span><span>
</span><span>{</span><span>"level"</span><span>:</span><span>"info"</span><span>,</span><span>"ts"</span><span>:</span><span>1601686525.5588071</span><span>,</span><span>"msg"</span><span>:</span><span>"gracefully shutting down"</span><span>}</span><span>

</span></code></pre></div></div>

<h3 id="5-graceful-exits">5. Graceful Exits</h3>

<p>This one is not ultimately necessary but I’ve seen it a lot and ensures cleanup tasks when the API is shutting down. A graceful exit is implemented by making a channel in the beginning of your program and listening for a certain event, like this one for a keyboard interrupt:</p>

<div><div><pre><code><span>// gracefully exit on keyboard interrupt</span>
<span>c</span> <span>:=</span> <span>make</span><span>(</span><span>chan</span> <span>os</span><span>.</span><span>Signal</span><span>,</span> <span>1</span><span>)</span>
<span>signal</span><span>.</span><span>Notify</span><span>(</span><span>c</span><span>,</span> <span>os</span><span>.</span><span>Interrupt</span><span>,</span> <span>syscall</span><span>.</span><span>SIGTERM</span><span>)</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/main.go#L30-L32">source</a></em>)</sup></p>

<p>At the end of the program, after starting the webserver in a go routine (see #5), we react to the signal:</p>

<div><div><pre><code><span>&lt;-</span><span>c</span>
<span>log</span><span>.</span><span>Info</span><span>(</span><span>"gracefully shutting down"</span><span>)</span>
<span>os</span><span>.</span><span>Exit</span><span>(</span><span>0</span><span>)</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/main.go#L58-L61">source</a></em>)</sup></p>

<h3 id="6-log-version-on-startup">6. Log Version on Startup</h3>

<p>This one is also minor, but it turns out to be very useful to see the version by just reading the logs for debugging. It makes it clear which exact code base ran the code and resulted in a potential error.</p>

<p>The version is injected by using an unset <code>version</code> variable in the <code>main.go</code> file and setting it via the build command (for instance in your <code>Makefile</code>):</p>

<div><div><pre><code>VERSION ?<span>=</span> <span>$(</span>shell git describe <span>--match</span> <span>'v[0-9]*'</span> <span>--tags</span> <span>--always</span><span>)</span>

build:
	@go build <span>-ldflags</span> <span>"-X main.version=</span><span>$(</span>VERSION<span>)</span><span>"</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/Makefile#L1-L4">source</a></em>)</sup></p>

<p>In the <code>main.go</code> file you can use the version as follows (after instantiating it via <code>var version string</code>):</p>

<div><div><pre><code><span>// print current version</span>
<span>log</span><span>.</span><span>Info</span><span>(</span><span>"starting up API..."</span><span>,</span> <span>zap</span><span>.</span><span>String</span><span>(</span><span>"version"</span><span>,</span> <span>version</span><span>))</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/main.go#L40-L41">source</a></em>)</sup></p>

<h3 id="7-define-types-in-their-own-package">7. Define Types in Their Own Package</h3>

<p>Types should be reusable. Let’s say someone was to build a command line interface interacting with your API, they would appreciate if they could just import your API types. So we define types as <code>struct</code>s in <code>pkg/types/types.go</code> (we will get to the struct tags and the doc strings later):</p>

<div><div><pre><code><span>// Article is one instance of an article</span>
<span>type</span> <span>Article</span> <span>struct</span> <span>{</span>
	<span>// The unique id of this item</span>
	<span>ID</span> <span>int</span> <span>`gorm:"type:SERIAL;PRIMARY_KEY" json:"id" example:"1"`</span>
	<span>// The name of this item</span>
	<span>Name</span> <span>string</span> <span>`gorm:"type:varchar;NOT NULL" json:"name" example:"Skittles"`</span>
	<span>// The price of this item</span>
	<span>Price</span> <span>float64</span> <span>`gorm:"type:decimal;NOT NULL" json:"price" example:"1.99"`</span>
<span>}</span> <span>// @name Article</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/pkg/types/types.go#L10-L18">source</a></em>)</sup></p>

<h3 id="8-chi-as-http-framework">8. <a href="https://github.com/go-chi/chi">chi</a> as HTTP Framework</h3>

<p>My http framework of choice these days is <a href="https://github.com/go-chi/chi">go-chi/chi</a> (upon recommendation by <a href="https://twitter.com/elsesiy">@elsesiy</a> - thank you!) for its light weight, idiomatic implementation, but mainly for its 100% compatibility with <code>net/http</code> allowing you to use any existing middleware.</p>

<p>The server is started as go routine and listens on the configured address:</p>

<div><div><pre><code><span>// start the api server</span>
<span>r</span> <span>:=</span> <span>api</span><span>.</span><span>GetRouter</span><span>(</span><span>log</span><span>,</span> <span>dbClient</span><span>)</span>
<span>go</span> <span>func</span><span>()</span> <span>{</span>
    <span>if</span> <span>err</span> <span>:=</span> <span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>addr</span><span>,</span> <span>r</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>log</span><span>.</span><span>Error</span><span>(</span><span>"failed to start server"</span><span>,</span> <span>zap</span><span>.</span><span>Error</span><span>(</span><span>err</span><span>))</span>
        <span>os</span><span>.</span><span>Exit</span><span>(</span><span>1</span><span>)</span>
    <span>}</span>
<span>}()</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/main.go#L49-L56">source</a></em>)</sup></p>

<p>The router gets configured in the <code>api</code> package, setting the db client and the logger:</p>

<div><div><pre><code><span>func</span> <span>GetRouter</span><span>(</span><span>log</span> <span>*</span><span>zap</span><span>.</span><span>Logger</span><span>,</span> <span>dbClient</span> <span>db</span><span>.</span><span>ClientInterface</span><span>)</span> <span>*</span><span>chi</span><span>.</span><span>Mux</span> <span>{</span>
	<span>r</span> <span>:=</span> <span>chi</span><span>.</span><span>NewRouter</span><span>()</span>
	<span>r</span><span>.</span><span>Use</span><span>(</span><span>middleware</span><span>.</span><span>RequestID</span><span>)</span>
	<span>SetDBClient</span><span>(</span><span>dbClient</span><span>)</span>
	<span>if</span> <span>log</span> <span>!=</span> <span>nil</span> <span>{</span>
		<span>r</span><span>.</span><span>Use</span><span>(</span><span>m</span><span>.</span><span>SetLogger</span><span>(</span><span>log</span><span>))</span>
	<span>}</span>
	<span>buildTree</span><span>(</span><span>r</span><span>)</span>

	<span>return</span> <span>r</span>
<span>}</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/pkg/api/api.go#L31-L41">source</a></em>)</sup></p>

<p>The tree of requests looks in code just as it would like in a folder structure. Every sub request is attached to its parent. Here is an example request tree, that handles articles and orders for a store:</p>

<div><div><pre><code><span>func</span> <span>buildTree</span><span>(</span><span>r</span> <span>*</span><span>chi</span><span>.</span><span>Mux</span><span>)</span> <span>{</span>
	<span>r</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/swagger"</span><span>,</span> <span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
		<span>http</span><span>.</span><span>Redirect</span><span>(</span><span>w</span><span>,</span> <span>r</span><span>,</span> <span>r</span><span>.</span><span>RequestURI</span><span>+</span><span>"/"</span><span>,</span> <span>http</span><span>.</span><span>StatusMovedPermanently</span><span>)</span>
	<span>})</span>
	<span>r</span><span>.</span><span>Get</span><span>(</span><span>"/swagger*"</span><span>,</span> <span>httpSwagger</span><span>.</span><span>Handler</span><span>())</span>

	<span>r</span><span>.</span><span>Route</span><span>(</span><span>"/articles"</span><span>,</span> <span>func</span><span>(</span><span>r</span> <span>chi</span><span>.</span><span>Router</span><span>)</span> <span>{</span>
		<span>r</span><span>.</span><span>With</span><span>(</span><span>m</span><span>.</span><span>Pagination</span><span>)</span><span>.</span><span>Get</span><span>(</span><span>"/"</span><span>,</span> <span>ListArticles</span><span>)</span>

		<span>r</span><span>.</span><span>Route</span><span>(</span><span>"/{id}"</span><span>,</span> <span>func</span><span>(</span><span>r</span> <span>chi</span><span>.</span><span>Router</span><span>)</span> <span>{</span>
			<span>r</span><span>.</span><span>Use</span><span>(</span><span>m</span><span>.</span><span>Article</span><span>)</span>
			<span>r</span><span>.</span><span>Get</span><span>(</span><span>"/"</span><span>,</span> <span>GetArticle</span><span>)</span>
		<span>})</span>

		<span>r</span><span>.</span><span>Put</span><span>(</span><span>"/"</span><span>,</span> <span>PutArticle</span><span>)</span>
	<span>})</span>

	<span>r</span><span>.</span><span>Route</span><span>(</span><span>"/orders"</span><span>,</span> <span>func</span><span>(</span><span>r</span> <span>chi</span><span>.</span><span>Router</span><span>)</span> <span>{</span>
		<span>r</span><span>.</span><span>With</span><span>(</span><span>m</span><span>.</span><span>Pagination</span><span>)</span><span>.</span><span>Get</span><span>(</span><span>"/"</span><span>,</span> <span>ListOrders</span><span>)</span>

		<span>r</span><span>.</span><span>Route</span><span>(</span><span>"/{id}"</span><span>,</span> <span>func</span><span>(</span><span>r</span> <span>chi</span><span>.</span><span>Router</span><span>)</span> <span>{</span>
			<span>r</span><span>.</span><span>Use</span><span>(</span><span>m</span><span>.</span><span>Order</span><span>)</span>
			<span>r</span><span>.</span><span>Get</span><span>(</span><span>"/"</span><span>,</span> <span>GetOrder</span><span>)</span>
		<span>})</span>

		<span>r</span><span>.</span><span>Put</span><span>(</span><span>"/"</span><span>,</span> <span>PutOrder</span><span>)</span>
	<span>})</span>
<span>}</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/pkg/api/api.go#L43-L70">source</a></em>)</sup></p>

<h3 id="9-custom-middlewares">9. Custom Middlewares</h3>

<p>In the tree above, you can spot the usage of</p>

<div><div><pre><code>		<span>r</span><span>.</span><span>Route</span><span>(</span><span>"/{id}"</span><span>,</span> <span>func</span><span>(</span><span>r</span> <span>chi</span><span>.</span><span>Router</span><span>)</span> <span>{</span>
			<span>r</span><span>.</span><span>Use</span><span>(</span><span>m</span><span>.</span><span>Article</span><span>)</span>
			<span>r</span><span>.</span><span>Get</span><span>(</span><span>"/"</span><span>,</span> <span>GetArticle</span><span>)</span>
		<span>})</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/pkg/api/api.go#L52-L55">source</a></em>)</sup></p>

<p>Custom middlewares live in the <code>middleware</code> package. <code>m</code> is our custom middleware, imported through</p>

<div><div><pre><code><span>m</span> <span>"github.com/jonnylangefeld/go-api/pkg/middelware"</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/pkg/api/api.go#L13">source</a></em>)</sup></p>

<p>Custom middlewares are very powerful. They are basically an injection into the sequence of handlers of the api and can do anything ‘along the way’. In this instance we know we are in a part of our router tree, that will always require the article object pulled from the database. So we inject a custom middleware, that does exactly that for us and injects it into the context of the request. The context is available through the entire handler chain, so for any succeeding handler our object will be available.</p>

<p>The following middelware is the <code>http.Handler</code> we used above via <code>r.Use(m.Article)</code> and injects the article object into the context.</p>

<div><div><pre><code><span>// Article middleware is used to load an Article object from</span>
<span>// the URL parameters passed through as the request. In case</span>
<span>// the Article could not be found, we stop here and return a 404.</span>
<span>func</span> <span>Article</span><span>(</span><span>next</span> <span>http</span><span>.</span><span>Handler</span><span>)</span> <span>http</span><span>.</span><span>Handler</span> <span>{</span>
	<span>return</span> <span>http</span><span>.</span><span>HandlerFunc</span><span>(</span><span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
		<span>var</span> <span>article</span> <span>*</span><span>types</span><span>.</span><span>Article</span>

		<span>if</span> <span>id</span> <span>:=</span> <span>chi</span><span>.</span><span>URLParam</span><span>(</span><span>r</span><span>,</span> <span>"id"</span><span>);</span> <span>id</span> <span>!=</span> <span>""</span> <span>{</span>
			<span>intID</span><span>,</span> <span>err</span> <span>:=</span> <span>strconv</span><span>.</span><span>Atoi</span><span>(</span><span>id</span><span>)</span>
			<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
				<span>_</span> <span>=</span> <span>render</span><span>.</span><span>Render</span><span>(</span><span>w</span><span>,</span> <span>r</span><span>,</span> <span>types</span><span>.</span><span>ErrInvalidRequest</span><span>(</span><span>err</span><span>))</span>
				<span>return</span>
			<span>}</span>
			<span>article</span> <span>=</span> <span>DBClient</span><span>.</span><span>GetArticleByID</span><span>(</span><span>intID</span><span>)</span>
		<span>}</span> <span>else</span> <span>{</span>
			<span>_</span> <span>=</span> <span>render</span><span>.</span><span>Render</span><span>(</span><span>w</span><span>,</span> <span>r</span><span>,</span> <span>types</span><span>.</span><span>ErrNotFound</span><span>())</span>
			<span>return</span>
		<span>}</span>
		<span>if</span> <span>article</span> <span>==</span> <span>nil</span> <span>{</span>
			<span>_</span> <span>=</span> <span>render</span><span>.</span><span>Render</span><span>(</span><span>w</span><span>,</span> <span>r</span><span>,</span> <span>types</span><span>.</span><span>ErrNotFound</span><span>())</span>
			<span>return</span>
		<span>}</span>

		<span>ctx</span> <span>:=</span> <span>context</span><span>.</span><span>WithValue</span><span>(</span><span>r</span><span>.</span><span>Context</span><span>(),</span> <span>ArticleCtxKey</span><span>,</span> <span>article</span><span>)</span>
		<span>next</span><span>.</span><span>ServeHTTP</span><span>(</span><span>w</span><span>,</span>…</code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jonnylangefeld.com/blog/how-to-write-a-go-api-the-ultimate-guide">https://jonnylangefeld.com/blog/how-to-write-a-go-api-the-ultimate-guide</a></em></p>]]>
            </description>
            <link>https://jonnylangefeld.com/blog/how-to-write-a-go-api-the-ultimate-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927327</guid>
            <pubDate>Thu, 29 Oct 2020 04:47:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Todo apps are meant for robots]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927203">thread link</a>) | @w1nter
<br/>
October 28, 2020 | https://blog.frantic.im/all/todo-apps-are-meant-for-robots/ | <a href="https://web.archive.org/web/*/https://blog.frantic.im/all/todo-apps-are-meant-for-robots/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In&nbsp;my lifetime I’ve tried a&nbsp;dozen todo apps. In&nbsp;the&nbsp;beginning they all seem different, novel and&nbsp;special. Slick UI, shortcuts, tags, subtasks, the&nbsp;list goes on&nbsp;and&nbsp;on.</p>
<p>But&nbsp;all our stories were the&nbsp;same: I start using the&nbsp;new app, then after awhile I stop using it.</p>
<p>Up until the&nbsp;last week I thought the&nbsp;problem was in&nbsp;myself (you probably think so too). After all, <a href="https://gettingthingsdone.com/">David Allen</a> seems to&nbsp;have figured this shit out. Also there are people leaving long 5 star reviews on&nbsp;every major todo list app, they discuss them on&nbsp;forums, recommend them to&nbsp;friends.</p>
<p>But&nbsp;then I read <a href="https://notes.andymatuschak.org/Close_open_loops?stackedNotes=z5tiFxnNKMZCnc8G9R1N51L5hknyRGmyCQx18&amp;stackedNotes=z8aZybuJJopS5fL7TnPou2JcmCsBUJeqirbBh&amp;stackedNotes=z5vXaKVAPBNKAAi9RXNudduhyGadGXqtMVTEs">Andy Matuschak’s notes</a>, and&nbsp;it really resonated with me. What if I’m a&nbsp;left-handed person in&nbsp;the&nbsp;world of&nbsp;right-handed tools? All popular todo apps out there have the&nbsp;same problems:</p>

<ol start="1">
<li>Willpower needed to&nbsp;make decisions is a&nbsp;limited resource. And&nbsp;most TODO apps are lazy and&nbsp;don’t consider the&nbsp;impact on&nbsp;your willpower. You want to&nbsp;postpone a&nbsp;task? Please enter the&nbsp;exact date to&nbsp;postpone this to. Which project to&nbsp;add this to? Tags? Subtasks? The&nbsp;amount of&nbsp;things one can customize is really large, but&nbsp;making all this decisions has a&nbsp;cost.</li>
</ol>
<ol start="2">
<li>Long lists are overwhelming. TODO apps are all about lists. And&nbsp;these lists tend to&nbsp;get large when the&nbsp;tasks inflow exceeds the&nbsp;tasks outflow (i.e. every modern knowledge worker’s queue). Looking at&nbsp;the&nbsp;ever-growing list of&nbsp;things that need to&nbsp;get done is not&nbsp;inspiring to&nbsp;say the&nbsp;least. As&nbsp;the&nbsp;lists get longer, there’s less and&nbsp;less chance that anything from it will get done, which also decreases the&nbsp;motivation to&nbsp;look into these lists. Removing stuff without getting it done is also painful, it requires a&nbsp;complex emotional and&nbsp;rational decision to&nbsp;be made (see the&nbsp;point about the&nbsp;willpower above).</li>
</ol>
<ol start="3">
<li>Sense of&nbsp;accomplishment is important but&nbsp;rare in&nbsp;the&nbsp;digital world. When you mark a&nbsp;task as&nbsp;done in&nbsp;your TODO app, it just hides it. That’s it, no&nbsp;reward, no&nbsp;sense of&nbsp;accomplishment (unless you make your own). I think that’s why some people like Trello or&nbsp;pen-and-paper TODO list: when you get something done, you can see a&nbsp;card moved or&nbsp;a&nbsp;text crossed out. An&nbsp;artifact that proves there was a&nbsp;task here, and&nbsp;now it’s done. Now you are one step closer to&nbsp;your goal.</li>
</ol>
<ol start="4">
<li>We need to&nbsp;trust our systems. GTD works only when you follow the&nbsp;rules. If you let your inbox grow unbound, the&nbsp;whole point about GTD gets lost and&nbsp;you also start losing trust in&nbsp;GTD. Another negative feedback loop. I’ve never seen a&nbsp;TODO app that lets you recover from this downward spiral.</li>
</ol>
<ol start="5">
<li>Tasks are not&nbsp;the&nbsp;same. Get milk, write an&nbsp;essay, plan a&nbsp;vacation, reconnect with a&nbsp;friend. These are things of&nbsp;different magnitude, different emotional connection, different context and&nbsp;time commitment. Some tasks aren’t even tasks, e.&nbsp;g. simply items to&nbsp;keep track of&nbsp;or&nbsp;be reminded of. But&nbsp;TODO apps treat them the&nbsp;same. They get the&nbsp;similar looking rows neatly organized in&nbsp;a&nbsp;unified interface.</li>
</ol>
<ol start="6">
<li>Sometimes humans need help. A&nbsp;little nudge here and&nbsp;there can make a&nbsp;huge difference. It’s also very personal: different things work for&nbsp;different types of&nbsp;people. I’ve made a&nbsp;list of&nbsp;strategies to&nbsp;help me get things done, and&nbsp;ended up with 13 items (things like “extract the&nbsp;next smallest step as&nbsp;a&nbsp;separate task” or&nbsp;“work on&nbsp;it for&nbsp;just 2 minutes”). Thirteen! Guess how many nudges all my TODO apps have? Zero (except the&nbsp;deadline push notification reminder which just adds anxiety).</li>
</ol>
<ol start="7">
<li>Context is important. We are tired in&nbsp;the&nbsp;evening and&nbsp;have less willpower. <a href="https://www.youtube.com/watch?v=GmFwRkl-TTc">Getting a&nbsp;small task done first thing in&nbsp;the&nbsp;morning can boost our confidence and&nbsp;energy levels</a>. Work tasks are better be hidden during the&nbsp;weekend. Sophisticated TODO apps have the&nbsp;flexibility to&nbsp;do this, but&nbsp;they require a&nbsp;lot of&nbsp;investment in&nbsp;configuration</li>
</ol>
<p>I now see all TODO apps as&nbsp;a&nbsp;shallow copy-pasta of&nbsp;the&nbsp;same rigid, inhuman, anxiety-inducing template.</p>
<p>But&nbsp;there’s hope!</p>
<p>In&nbsp;fact the&nbsp;advanced solution technology lies in&nbsp;the&nbsp;hands of&nbsp;productivity enemies: social media apps and&nbsp;games. Instagram, TikTok and&nbsp;Candy Crush have figured all this out. They know how to&nbsp;make you do something with very little willpower. They know how to&nbsp;present information in&nbsp;a&nbsp;way that’s not&nbsp;overwhelming. They give you rewards for&nbsp;doing things. Hints, nudges, suggestions.</p>
<p>I think there’s plenty of&nbsp;room for&nbsp;TODO innovations.</p>
<p>As&nbsp;for&nbsp;me -- I’m not&nbsp;registering a&nbsp;domain name for&nbsp;a&nbsp;new pet project. Not&nbsp;yet :)</p>
</div></div>]]>
            </description>
            <link>https://blog.frantic.im/all/todo-apps-are-meant-for-robots/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927203</guid>
            <pubDate>Thu, 29 Oct 2020 04:26:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sale of Amateur Radio AMPRnet TCP/IP Addresses Raised $108M]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24927037">thread link</a>) | @todsacerdoti
<br/>
October 28, 2020 | https://www.icqpodcast.com/news/2020/10/25/sale-of-amateur-radio-amprnet-tcpip-addresses-raised-108m | <a href="https://web.archive.org/web/*/https://www.icqpodcast.com/news/2020/10/25/sale-of-amateur-radio-amprnet-tcpip-addresses-raised-108m">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-7b3dd6c3950208794ea7"><div><p>President of Amateur Radio Digital Communications (ARDC) has confirmed they received $108 million from Amazon for 4 million amateur radio TCP/IP addresses </p><p>Since its allocation to Amateur Radio in the mid-1980s, Internet network 44 (44.0.0.0/8), known as the AMPRNet™, has been used by amateur radio operators to conduct scientific research and to experiment with digital communications over the radio with a goal of advancing the state of the art of Amateur Radio networking, and to educate amateur radio operators in these techniques.</p><p>Amateur Radio Digital Communications (ARDC) is a non-profit California corporation formed to further these goals.</p><p>In mid-2019 a block (44.192.0.0/10) of approximately four million AMPRNet™ IP addresses, out of the 16 million available, was sold to Amazon by ARDC but it is only now that the sale price has been released. Amazon paid $27 for each IPv4 address.</p></div></div></div>]]>
            </description>
            <link>https://www.icqpodcast.com/news/2020/10/25/sale-of-amateur-radio-amprnet-tcpip-addresses-raised-108m</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927037</guid>
            <pubDate>Thu, 29 Oct 2020 03:57:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to walk upright and stop living in a cave]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24927008">thread link</a>) | @taylorlunt
<br/>
October 28, 2020 | https://taylor.gl/blog/9/ | <a href="https://web.archive.org/web/*/https://taylor.gl/blog/9/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    
    <div>
      
<p>
<a href="https://taylor.gl/">Home</a>

  
  
  <a href="https://taylor.gl/"> </a>

  
  
  »
  
  <a href="https://taylor.gl/blog/"> Blog</a>

</p>

<p><span>
  Reading time: 9 minutes.

  Written in 2020.
</span></p>

<p>Call me arrogant, but I’d rather optimize my indoor environment than try to spend more time in the capricious outdoors. I think it’s defeatism to give up on improving our indoor spaces and resign ourselves to the fickle weather and seasons. </p>
<p>If I was going to create an ideal environment for a human, I think there are several things I would include that we routinely fail to include in our homes and offices.</p>
<h3 id="lighting">Lighting</h3>
<p>Our indoor lighting situation usually sucks. The fact that “natural lighting” is a selling point in real estate shows how terrible a job we are doing in this department. We rely on the sun naturally providing us with sufficient light, and if it’s an overcast day or the days have grown shorter in the winter, then I guess we’re shit out of luck. </p>
<p>Usually, indoor areas are around 50-500 lux. This is hundreds of times dimmer than the sunlight. Clearly, we weren’t designed to thrive in such dim environments, and science does verify a connection between brighter light and alertness. If we don’t want to be sleepy like it’s nighttime, we shouldn’t light our rooms like it’s nighttime. For some, the effects of dim lighting go beyond simple lethargy and, especially in the winter, cause serious mood problems like seasonal affective disorder or the winter blues. This is common, but it’s not necessary. Bright light, particularly blue light, can also generally boost mood and may be a comparable stimulant to caffeine. (Those who are prone to mania should be careful, as intense light can trigger mania or hypomania in those predisposed.) Brighter lighting can also help circadian rhythm issues (which I, for example, have struggled with for years), both by entraining your circadian rhythm so your body better knows when it’s day, and by shortening it if it’s too long. </p>
<p>Lighting isn’t as expensive as it used to be, so we can do better than we have in the past. The cost of electricity for LED lighting is now negligible, and the only real factor is the cost of the bulbs themselves. Reaching for the full 100,000 lux of sunlight would still be prohibitively expensive, but going for at least 10,000 lux is doable with only a few hundred dollars. I won’t go into specifics here, but you can get more information on specific lighting setups <a href="https://www.lesswrong.com/posts/hC2NFsuf5anuGadFm/how-to-build-a-lumenator">here</a> or <a href="https://meaningness.com/metablog/sad-light-lumens">here</a>. In particular, get bulbs with a color temperature close to sunlight (5600k), but make sure the bulbs have a <span>good<span>good means 90+</span></span> Color Rendering Index (CRI), otherwise the light will feel harsh.</p>
<p>I recommend putting any bright lighting you buy for your home on electrical timers so you don’t accidentally leave them on during the evening and screw up your sleep. You may also want to set your phone/computer brightness on a timer, if you can. The goal is to mimic the natural day/night cycle of our evolutionary environment, but without all the pesky volatility of nature. You can get programs like f.lux too, which reduce the amount of blue light emitted by your device in the evening, but in my experience this isn’t good enough and reducing the actual brightness of the device at night is also important.</p>
<p>“But what about vitamin D? Just go outside!” This is terrible advice, and I hear it too often. Sunlight is a powerful carcinogen, and vitamin D supplements are not, and they’re cheap. </p>
<h3 id="carbon-dioxide">Carbon dioxide</h3>
<p>Carbon MON-oxide is the deadly one you probably already have a monitor for in your house. Carbon DI-oxide is the feeble cousin of carbon monoxide, but it still has a negative effect on human health: <span>high (but common)<span>1,000 ppm or higher</span></span> levels impairs our ability to think. Just what you don’t want in an office. High levels may also have a negative long-term impact in other areas of our health. </p>
<p>Hold your breath. When it sucks and you decide to start breathing again, it’s carbon dioxide buildup, not lack of oxygen, causing you to feel panic and the need to breath. Carbon dioxide is a toxin. And we breath it out into poorly ventilated rooms, where the levels can rise to double or triple what they are <span>outdoors<span>around 400 ppm</span></span>.</p>
<p>Several studies have shown significant (temporary) cognitive impairments due to carbon dioxide levels over 1,000 ppm, but such levels are <span>common<span>I recently bought a carbon dioxide meter and found such levels in my home.</span></span> in poorly ventilated shared spaces. Fortunately, the solution is simple: open a window. Unfortunately, this doesn’t work when it’s raining, or when it’s too hot outside, or when it’s too cold outside… In particular, I have to contend with Canadian winters, which means opening the window is a valid strategy for a minority of the year unless I buy an expensive heat recovery ventilator. I don’t have a good solution for mitigating carbon dioxide buildup in the winter. Let me know if you do.</p>
<p>And, by the way, plants won’t work. They won’t suck up nearly enough carbon dioxide. You would need hundreds of plants per person, or roughly a dozen full-size trees per person, to offset the carbon dioxide exhaled by humans in a room.</p>
<p>A fun fact: if we don’t stop pumping carbon dioxide into the atmosphere, then in about a century, carbon dioxide <em>outdoors</em> may reach cognitively impairing levels. Then what do we do? </p>
<h3 id="temperature-and-humidity">Temperature and Humidity</h3>
<p>High/low humidity and high/low temperature both lead to discomfort and lower scores on concentration measures. People generally have temperature under control, or at least it’s something they’re aware of. Humidity is less common to measure, but a $10 hygrometer should help you get your indoor space to the ideal 30-50% humidity range if it isn’t already. Air conditioners also tend to reduce humidity as well as temperature, so air-condition in the summer and use a humidifier in the winter.</p>
<p>At night, drop the temperature a few degrees if you can; It’s easier to sleep in a cool room. I wonder how many hours of sleep have been reclaimed already due to the advent of smart thermostats.</p>
<h3 id="background-noise">Background Noise</h3>
<p>I imagine this factor is more subjective than the others, but too loud is distracting, even aggrivating; too quiet makes your sniffles and sighs painfully audible to others, and so is distracting. Uneven background noise like traffic is worse than the uniform background noise of white noise or trickling water. Bad background noise leads to poorer cognition and focus.</p>
<p>It’s easy to be bothered by noise and not realize it until the noise stops and a wave of relief finally makes you aware of how annoyed you were by the sound. Noise issues are happily easy to control: earplugs or noise-cancelling headphones will generally do the trick. It would be utopic to eliminate bothersome noise from the environment altogether, but it’s not necessary. </p>
<h3 id="segregation-of-activities">Segregation of Activities</h3>
<p>A heroin addict who normally takes their dose in their car decides one day to inject in their bathroom. They die of an overdose, even though they took the same amount they normally do. Why? Our brains maintain associations with different environments. If you normally inject heroin when you get in your car, then your body starts to prepare you for the drug as soon as you get in the car. Drug tolerance, then, is partly environmental. (This <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1196296/">actually happened</a> and happens regularly.) Your mind and body are affected by your environment due to Pavlovian conditioning. When the bell rings, the dog salivates. When the lunch bell rings, so do you. </p>
<p>One common piece of advice given by doctors to insomniacs is to only use your bed for sleeping and for sex, and it’s good advice. If you use your bed for reading, studying, and watching TV, then your mind will not form a strong association between the bed and sleep, and you will have a harder time falling asleep. </p>
<p>Likewise, if you do all your slacking off at the same desk you do your work at, you will probably have a harder time focusing. Even having your smartphone within your field of view while you work has been shown to reduce focus. So it wouldn’t hurt to have different areas for work and play, and to not eat at your desk. (And even different user accounts on your computer for work and non-work, if you don’t find that idea to be a pain in the ass like I do.)</p>
<p>We also form associations not just with space, but with time. Hence another piece of common sleep hygeine advice: go to sleep at the same time every night. Your body will learn to expect sleep at that time. Likewise, people who eat at the same time every day eat with their bodies prepared to receive food, and so are less likely to become obese. Studies have shown this. Unfortunately, setting every aspect of your life to a clock can make you feel like a robot, so I usually don’t tolerate such rigidity in my life. But it’s worth thinking about.</p>
<h3 id="conclusion">Conclusion</h3>
<ul>
<li>Brighter lights for your poor eyes</li>
<li>Better ventilation for your poor lungs</li>
<li>Optimal temperature and humidity for your poor skin</li>
<li>Less distracting background noise for your poor ears</li>
<li>Activity-specific areas for your poor brain</li>
</ul>
<p>I also think the aesthetics of most of our indoor environments could use an upgrade, but I don’t have much to say on the subject besides simply saying so. (Though I would bet: green lush &gt; grey drab.)</p>
<p>We sometimes act like we are just <span>machines<span>caffeine in ⟶ code out</span></span>, but we are not. We’re mushy creatures with delicate bodies and delicate minds, too. And we evolved for one specific environment. There is no guarantee that the indoor environment which is cheapest to produce is going to be just as good for us as a bespoke imitation of our evolutionary environment, and in fact it is not. I think life would be more pleasant if people took these factors more serously when designing indoor environments, and our work would be more efficient and less prone to mistakes.</p>


    </div>
  </section></div>]]>
            </description>
            <link>https://taylor.gl/blog/9/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927008</guid>
            <pubDate>Thu, 29 Oct 2020 03:52:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA['Digital natives' first generation with a lower IQ than their parents]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24926594">thread link</a>) | @respinal
<br/>
October 28, 2020 | https://moneytrainingclub.com/2020/10/28/alarming-trend-between-digital-natives-and-their-iq-digital-trends-spanish/ | <a href="https://web.archive.org/web/*/https://moneytrainingclub.com/2020/10/28/alarming-trend-between-digital-natives-and-their-iq-digital-trends-spanish/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="primary">

                
<article id="post-70774">

    <div>
        
<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->


<div id="dt-post-content">
<p>A recently published book in France warns about how digital devices are seriously affecting the neural development of children and young people.</p>
<p>The text is called <em>The digital cretin factory</em> and it was written by Michel Desmurget, director of research at the French National Institute of Health.</p>
<p>In an interview with the <a href="https://www.bbc.com/mundo/noticias-54554333.amp" target="_blank" rel="noopener noreferrer">BBC</a>, the author of the work, which has become a bestseller in his country, assures that today’s young people are the first generation in history with a lower IQ than the previous one.</p>
<p>“Researchers have observed in many parts of the world that IQ increased from generation to generation.  This was called the ‘Flynn effect’, in reference to the American psychologist who described this phenomenon.  But recently, this trend began to be reversed in several countries ”, says the researcher.</p>
<p>“In those countries, digital natives are the first children to have a lower IQ than their parents.  It is a trend that has been documented in Norway, Denmark, Finland, the Netherlands, France, etc. ”.</p>
<p>Although the specific factors involved in this phenomenon have not yet been determined, it has been proven that the time a child spends in front of a screen would have an important effect on their IQ.</p>
<p>Thus, according to the author, when the use of television or video games increases, IQ and cognitive development tend to decrease.</p>
<p>This would directly affect the main foundations of our intelligence, such as language, concentration, memory and culture in general, which would end up causing a significant drop in academic performance.</p>
<h2>Why is this happening?</h2>
<p>According to Desmurget, dependence on screens and digital devices is associated with a decrease in the quality and quantity of family interactions, as well as a decrease in the time spent on other activities that can be more enriching.</p>
<p>Sleep disruption, overestimation of attention, intellectual under-stimulation (the brain cannot unfold its full potential) and the adoption of an excessively sedentary lifestyle are also involved.</p>
<p>Michel Desmurget, with studies at the Massachusetts Institute of Technology (MIT) and the University of California, criticizes the enormous amount of time that today’s children spend in front of digital devices.</p>
<p>“On average, almost three hours a day for 2-year-olds, about five hours for 8-year-olds and more than seven hours for adolescents,” he explains.</p>
<p>“This means that before reaching the age of 18, our children will have spent the equivalent of 30 school years in front of recreational screens or, if you prefer, 16 years of full-time work!  It is simply crazy and irresponsible ”.</p>
<h4>
<p>		Editor’s Recommendations	</p></h4>


</div>
</div>

<p>					var stage = 0;
					var options = {"dt:theme":{"assets":{"js_uri":"https://es.digitaltrends.com/wp-content/themes/digitaltrends-es-2018/assets/scripts","parent_js_uri":"https://es.digitaltrends.com/wp-content/themes/dt-stardust/assets/scripts","css_uri":"https://es.digitaltrends.com/wp-content/themes/digitaltrends-es-2018/assets/styles","parent_css_uri":"https://es.digitaltrends.com/wp-content/themes/dt-stardust/assets/styles","image_uri":"https://es.digitaltrends.com/wp-content/themes/digitaltrends-es-2018/assets/images","parent_image_uri":"https://es.digitaltrends.com/wp-content/themes/dt-stardust/assets/images","font_uri":"https://es.digitaltrends.com/wp-content/themes/digitaltrends-es-2018/assets/fonts","parent_font_uri":"https://es.digitaltrends.com/wp-content/themes/digitaltrends-es-2018/assets/fonts"},"tos_url":null,"pp_url":null},"dt:snowplow":{"session_context_schema":"iglu:com.digitaltrends/session/jsonschema/1-0-2","ad_settings_context_schema":"iglu:com.digitaltrends/ads/jsonschema/1-0-0","content_cookie":"dtContent","content_context_schema":"iglu:com.digitaltrends/content/jsonschema/1-0-1"},"facebook":{"facebook:app:id":"803626527068006","facebook:channel_url":"https://es.digitaltrends.com/fb-channel.php","facebook:page:id":"digitaltrendsenespanol","jssdk-src":"//connect.facebook.net/es_LA/all.js"},"twitter":{"handle":"DigitalTrendsEs"},"dt:cc":{"cc_tracking":{"amazon":{"params":{"tag":"dt-es-20"},"click_id":"ascsubtag","patterns":["http[s]?://(www.)?amazon.com(.mx)?/.*","http[s]?://(www.)?amazon.es/.*","http[s]?://amzn.to/.*","http[s]?://amzn.com/.*","http[s]?://a.co/.*"]},"apple":{"params":[],"patterns":["http[s]?://apple.sjv.io/.*"]},"avantlink":{"params":[],"click_id":"ctc","patterns":["http[s]?://(www.)?avantlink.com/.*"]},"awin":{"params":[],"click_id":"clickref","patterns":["http[s]?://www.awin1.com/.*"]},"cj-affiliate":{"params":[],"click_id":"sid","patterns":["http[s]?://www.anrdoezrs.net","http[s]?://anrdoezrs.net","http[s]?://commission-junction.com","http[s]?://dpbolvw.net","http[s]?://apmebf.com","http[s]?://jdoqocy.com","http[s]?://kqzyfj.com","http[s]?://qksrv.net","http[s]?://tkqlhce.com","http[s]?://qksz.net","http[s]?://emjcd.com","http[s]?://afcyhf.com","http[s]?://awltovhc.com","http[s]?://ftjcfx.com","http[s]?://lduhtrp.net","http[s]?://tqlkg.com","http[s]?://awxibrm.co","http[s]?://cualbr.com","http[s]?://rnsfpw.net","http[s]?://vofzpwh.com","http[s]?://yceml.net"],"path_regex_replace":{"pattern":"(http[s]?)(.*)(http[s]?)(.*)([?|&amp;]sid=)(.*)","replacement":"$1$2sid/$6/$3$4","required_url_part":"/dlg/"}},"cloudcity_adapter":{"params":[],"click_id":"subid1","patterns":["http[s]?://ccp.digitaltrends.com/go/cpp/","http[s]?://cc-stage.isvc.tech/go/cpp/"]},"connexity_sylikes":{"params":[],"click_id":"afCampaignId","patterns":["http[s]?://link.sylikes.com/.*"]},"connexity_bizrate":{"params":[],"click_id":"af_campaign_id","patterns":["http[s]?://rd.bizrate.com/.*"]},"ebay":{"params":[],"patterns":["http[s]?://rover.ebay.com/.*"]},"flex-offers":{"params":[],"patterns":["http[s]?://track.flexlinkspro.com/.*"]},"impact-radius":{"params":[],"click_id":"subid1","patterns":["http[s]?://99designs.qvig.net","http[s]?://acehardware.dttq.net","http[s]?://adidas.njih.net","http[s]?://adorama.rfvk.net","http[s]?://airbnb.vaz6fn.net","http[s]?://allenedmonds.ojrq.net","http[s]?://apple.sjv.io","http[s]?://appsumo.8odi.net","http[s]?://atom-tickets.pxf.io","http[s]?://avocadomattress.n5ka.net","http[s]?://backcountry.tnu8.net","http[s]?://belkin.evyy.net","http[s]?://bestbuy.7tiv.net","http[s]?://bigcommerce.zfrcsk.net","http[s]?://birch.fziv.net","http[s]?://blue-apron.evyy.net","http[s]?://blueapron.i3zp.net","http[s]?://bombfell.l9yg.net","http[s]?://burstoralcare.bts6.net","http[s]?://case-mate.kxyi.net","http[s]?://casemate.kxyi.net","http[s]?://casetify.evyy.net","http[s]?://casetify.hyyc7q.net","http[s]?://casper.5ad6.net","http[s]?://cbs-allaccess.qflm.net","http[s]?://cbsallaccess.qflm.net","http[s]?://cocoavia.sjv.io","http[s]?://codespark.j4ib.net","http[s]?://coinbase-consumer.sjv.io","http[s]?://constant-contact.evyy.net","http[s]?://constant-contact.ibfwsl.net","http[s]?://cratejoy.jgpt48.net","http[s]?://creditkarma.myi4.net","http[s]?://cyberghost.sjv.io","http[s]?://designer-living.evyy.net","http[s]?://dicks-sporting-goods.ryvx.net","http[s]?://disneyplus.bn5x.net","http[s]?://door-dash.5vju.net","http[s]?://dreamcloudsleep.xuok.net","http[s]?://drip.pxf.io","http[s]?://eddie-bauer-us.ygwk.net","http[s]?://eddiebauerus.ygwk.net","http[s]?://eight-sleep.ioym.net","http[s]?://espn.zlbu.net","http[s]?://fanatics.ncw6.net","http[s]?://felixgray.ntaf.net","http[s]?://flaviar.5d3x.net","http[s]?://freshdirect.bpu9.net","http[s]?://getcairn.w9v5.net","http[s]?://getquip.d67ag4.net","http[s]?://gettyimages.68w6.net","http[s]?://glassesusa.7eer.net","http[s]?://go.corsair.com","http[s]?://go.web.plus.espn.com","http[s]?://gobble.sjv.io","http[s]?://goto.target.com","http[s]?://goto.walmart.com","http[s]?://gotomeeting.zvbf.net","http[s]?://grasshopper.o9o4.net","http[s]?://grenco-science.evyy.net","http[s]?://harrys.3tvl.net","http[s]?://helix-sleep.tkjf.net","http[s]?://homedepot.sjv.io","http[s]?://hotspotshield.bvrd.net","http[s]?://house.r2oa.net","http[s]?://intego.7eer.net","http[s]?://istockphoto.6q33.net","http[s]?://kohls.sjv.io","http[s]?://leesa-sleep.lvuv.net","http[s]?://leesasleep.lvuv.net","http[s]?://lending-club-smb.sjv.io","http[s]?://lenovo.vzew.net","http[s]?://letsgetchecked.7no9.net","http[s]?://levelsleep.xuvt.net","http[s]?://linkto.hrblock.com","http[s]?://lootcrate.znvt.net","http[s]?://lorex-flir.obak77.net","http[s]?://lorex-flir.sjv.io","http[s]?://lumin.7w7o67.net","http[s]?://macpaw.audw.net","http[s]?://mancrates.ln72.net","http[s]?://manscaped.sjv.io","http[s]?://massdrop.7eer.net","http[s]?://mcafee-consumer-affiliate.mpye.net","http[s]?://mgemi.pxf.io","http[s]?://microsoft.msafflnk.net","http[s]?://mint-mobile.58dp.net","http[s]?://mvmt.7eer.net","http[s]?://nakedwines.sjv.io","http[s]?://nautilus.atkw.net","http[s]?://nectar.xovt.net","http[s]?://nixon.wkq9.net","http[s]?://noom.8utb.net","http[s]?://nordvpn.sjv.io","http[s]?://onemore.pxf.io","http[s]?://ooma.vqi8.net","http[s]?://packsproject.33qw.net","http[s]?://partners.alamo.com","http[s]?://partners.enterprise.com","http[s]?://partners.hotwire.com","http[s]?://photoscom.pxf.io","http[s]?://purple.e9jo.net","http[s]?://qustodio.sjv.io","http[s]?://razer.a9yw.net","http[s]?://scentbird.7eer.net","http[s]?://scotchporter.5l5h.net","http[s]?://sentrypc.7eer.net","http[s]?://setapp.sjv.io","http[s]?://shipt.58mq.net","http[s]?://shutterstock.7eer.net","http[s]?://smarthome.4hyab9.net","http[s]?://sportsline.evyy.net","http[s]?://spot-and-tango.i5md.net","http[s]?://squarespace.syuh.net","http[s]?://summitsoft.evyy.net","http[s]?://sunsoil.mzte.net","http[s]?://thehomedepotca.2t23.net","http[s]?://thumbtack.57ib.net","http[s]?://treehouse.7eer.net","http[s]?://tuftandneedle.attfm2.net","http[s]?://ultimate-ears.dubn.net","http[s]?://untuckit.9znn.net","http[s]?://wismo.sjv.io","http[s]?://www.fubo.tv","http[s]?://xfinity.ulvh.net","http[s]?://yaasa.cw3o.net","http[s]?://ziprecruiter.fdcm73.net"]},"pepperjam":{"params":[],"patterns":["http[s]?://(www.)?pntrs.com/.*","http[s]?://(www.)…</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://moneytrainingclub.com/2020/10/28/alarming-trend-between-digital-natives-and-their-iq-digital-trends-spanish/">https://moneytrainingclub.com/2020/10/28/alarming-trend-between-digital-natives-and-their-iq-digital-trends-spanish/</a></em></p>]]>
            </description>
            <link>https://moneytrainingclub.com/2020/10/28/alarming-trend-between-digital-natives-and-their-iq-digital-trends-spanish/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926594</guid>
            <pubDate>Thu, 29 Oct 2020 02:51:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Context on STM in Ruby]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24926537">thread link</a>) | @kposehn
<br/>
October 28, 2020 | https://chrisseaton.com/truffleruby/ruby-stm/ | <a href="https://web.archive.org/web/*/https://chrisseaton.com/truffleruby/ruby-stm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<header>

<h2><a href="https://chrisseaton.com/">Chris Seaton</a>, 28 October 2020</h2>


</header>

<p>There’s a proposal to add <em>Software Transactional Memory</em>, or <em>STM</em>, to the Ruby programming language. This is part of a wider effort to add better support for concurrency and parallelism in Ruby, and in particular the idea of <em>ractors</em>. A concept has been <a href="https://bugs.ruby-lang.org/issues/17261">proposed</a> and <a href="https://github.com/ruby/ruby/pull/3652">implemented</a> by Koichi Sasada.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/testBoard.gif" width="50%">
<figcaption>An animation of the algorithm we're going to use as an example of STM - we'll explain this later on</figcaption>
</figure>

<p>This article gives some context on what STM is, how you use it, and why you might want to use it. We’ll show an application which is well-suited to STM and we’ll use this to talk about the benefits, issues, and some open questions.</p>

<p>We’ll finish by setting a challenge for STM in Ruby.</p>

<p>I wrote the first half of my PhD on STM, and the second half on Ruby, so I’ve got quite a bit of experience with both and the idea of their combination is very interesting to me.</p>

<h2 id="why-might-we-want-an-stm">Why might we want an STM?</h2>

<p>Let’s say we’re a bank managing many bank accounts. Each account has a total. We get a never-ending stream of requests to move a sum of money <code>m</code> from an account <code>a</code> to account <code>b</code>.</p>

<div><div><pre><code><span>loop</span> <span>do</span>
  <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
  <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
  <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
<span>end</span>
</code></pre></div></div>

<p>Something not everyone may know about Ruby is that <code>x += y</code> is equivalent to writing <code>t = x; x = t + y</code>. We’ll write that out in full to make that clear to ourselves.</p>

<div><div><pre><code><span>loop</span> <span>do</span>
  <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
  <span>a_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
  <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>a_balance</span> <span>-</span> <span>m</span>
  <span>b_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>b</span><span>]</span>
  <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>=</span> <span>b_balance</span> <span>+</span> <span>m</span>
<span>end</span>
</code></pre></div></div>

<p>We’ve got a lot of transfers to run through, so we’ll have multiple threads processing these transfers.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>a_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
      <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>a_balance</span> <span>-</span> <span>m</span>
      <span>b_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>b</span><span>]</span>
      <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>=</span> <span>b_balance</span> <span>+</span> <span>m</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>We’ve got a few problems here now. With all these threads running at the same time, what happens if two threads are putting money into your account concurrently?</p>

<div><div><pre><code><span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>100</span>

<span># thread 1                        # thread 2</span>
<span>balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
  <span># balance = 100</span>
                                  <span>balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
                                    <span># balance = 100</span>
<span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>balance</span> <span>+</span> <span>10</span>
  <span># accounts[a] = 110</span>
                                  <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>balance</span> <span>+</span> <span>10</span>
                                    <span># accounts[a] = 110</span>
</code></pre></div></div>

<p>The two transfers have run, but your balance is 110. The other 10 has been lost - this is called a <em>lost update</em>, meaning it’s as if the update was never made.</p>

<p>Also consider what happens if the thread crashes after taking money from <code>a</code> but before putting it into <code>b</code>? The transfer would be applied partially and again we’d lose money.</p>

<p>We need to use some kind of <em>synchronization</em> on our accounts. Ruby has <em>mutual exclusion locks</em> or <em>mutexes</em>, so we can try using those.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>locks</span><span>[</span><span>a</span><span>].</span><span>synchronize</span> <span>do</span>
        <span>locks</span><span>[</span><span>b</span><span>].</span><span>synchronize</span> <span>do</span>
          <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
          <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Does this work? What if we process a transfer from account 1001 to account 1002 on one thread at the same time as processing a transfer from account 1002 to 1001, so the other way around, at the same time?</p>

<p>The first thread will try to lock 1001 and then 1002. The second thread will try to lock 1002 and then 1001. If the first thread gets as far as locking 1001, and the second as far as locking 1002, then both will be waiting for the opposite lock and will never release the lock they already have. We will be in <em>deadlock</em>.</p>

<p>If we always acquired locks in the same order, by collecting them up first and sorting them, we could fix this.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>x</span><span>,</span> <span>y</span> <span>=</span> <span>[</span><span>a</span><span>,</span> <span>b</span><span>].</span><span>sort</span>
      <span>locks</span><span>[</span><span>x</span><span>].</span><span>synchronize</span> <span>do</span>
        <span>locks</span><span>[</span><span>y</span><span>].</span><span>synchronize</span> <span>do</span>
          <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
          <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Now in both transfers account 1001 is locked first and 1002 is locked second. That will work.</p>

<p>We have to make up a somewhat artificial requirement to explain the next issue, but consider if for some good reason we wanted to transfer to one account if we had a lot of money, and a different account if we only had a little money. Maybe if we’re rich this month we donate to charity, otherwise we unfortunately need to save for ourselves.</p>

<div><div><pre><code>if account balance &gt; 1000
  transfer 10 to charity
else
  transfer 10 to savings
end
</code></pre></div></div>

<p>We’ll talk about accounts <code>a</code>, <code>b</code>, and <code>c</code>, now, and a threshold of money <code>t</code>.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>,</span> <span>t</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>x</span><span>,</span> <span>y</span><span>,</span> <span>z</span> <span>=</span> <span>[</span><span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>].</span><span>sort</span>
      <span>locks</span><span>[</span><span>x</span><span>].</span><span>synchronize</span> <span>do</span>
        <span>locks</span><span>[</span><span>y</span><span>].</span><span>synchronize</span> <span>do</span>
          <span>locks</span><span>[</span><span>z</span><span>].</span><span>synchronize</span> <span>do</span>
            <span>if</span> <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>&gt;</span> <span>t</span>
              <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
              <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
            <span>else</span>
              <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
              <span>accounts</span><span>[</span><span>c</span><span>]</span> <span>+=</span> <span>m</span>
            <span>end</span>
          <span>end</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>It’s starting to get very complicated. And this locks more than it needs to - it locks both <code>b</code> and <code>c</code> but then only uses one of them. If you use <code>b</code> in the end, ideally another thread could be serving a transfer to <code>c</code> at the same time, but you’ve locked it and it can’t. Imagine if instead of two potential accounts it was thousands and you had to lock them all. Imagine if you couldn’t work out at all which account you’d be transferring to until you started the transfer - then you’d never be able to process two transfers at the same time.</p>

<p>At this point as well we’re likely to start to make errors trying to do all this locking and ordering of locks and things.</p>

<p>Stepping back and taking it all in, we can draw up some requirements for what we need.</p>

<ul>
  <li><em>atomicity</em> - that all writes in the transfer are applied or none are applied</li>
  <li><em>consistency</em> - meaning that our data structures are always valid - the total sum of money never changes</li>
  <li><em>isolation</em> - meaning one transfer does not interfere with another</li>
  <li><em>durability</em> - meaning that when applied the transfer is available to all subsequent transactions</li>
</ul>

<p>Ideally a library or the language could do this all for us. We’d like to be able to write almost what we originally wrote, but with just an annotation to make the code inside a block atomic, consistent, isolated, and the result durable.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>atomically</span> <span>do</span>
        <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
        <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>This is what a <em>transactional</em> memory can let us do. It will automatically monitor what you read and write inside the <code>atomically</code> block, which is a <em>transaction</em>, and will make sure it is either applied fully or not, that the balance of the whole system is always consistent, that transactions do not see the result of each other partially applied, and that writes appear and stay.</p>

<p>It may be implemented using the code we eventually arrived at ourselves, or it could do something else instead. In practice how it is often implemented is that
reads and writes are stored in a log, then at the end the transaction works out if anyone else has written locations that you’ve read. If they have then the values you read are no longer valid, so your transaction <em>conflicts</em> with another, is <em>aborted</em> and retries, reading the locations again. When it eventually does not conflict with any other transactions it is <em>committed</em> and succeeds. This means you don’t need to lock everything up-front, which means you avoid the problem of what happens if you may potentially need every account. Locking everything up-front is called <em>pessimistic locking</em>. We’re moving to <em>optimistic locking</em></p>

<h2 id="the-proposed-stm">The proposed STM</h2>

<p>Koichi’s <a href="https://bugs.ruby-lang.org/issues/17261">proposed</a> STM for Ruby, in combination with his proposed <em>ractors</em> (similar to <em>actors</em>) would look like this.</p>

<div><div><pre><code><span>accounts</span> <span>=</span> <span>9999</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>Thread</span><span>::</span><span>TVar</span><span>.</span><span>new</span><span>(</span><span>100</span><span>)</span> <span>}</span>

<span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span> <span>*</span><span>accounts</span> <span>do</span> <span>|*</span><span>accounts</span><span>|</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>Thread</span><span>.</span><span>atomically</span> <span>do</span>
        <span>accounts</span><span>[</span><span>a</span><span>].</span><span>value</span> <span>-=</span> <span>m</span>
        <span>accounts</span><span>[</span><span>b</span><span>].</span><span>value</span> <span>+=</span> <span>m</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>He’s using a <code>Ractor</code> but you can think of it as a thread for the purposes of this article. Instead of an array of account balances, we now have an array of <code>TVar</code> objects that contain values. A <code>TVar</code> is a <em>transactional variable</em>. Only these variables are transactional - not any other Ruby value you read or write. His design requires that the <code>TVar</code> objects you’re going to use are passed into the <code>Ractor</code>, due to rules about sharing that aren’t relevant for this article.</p>

<p>This looks good, doesn’t it!</p>

<h2 id="a-more-complex-application">A more complex application</h2>

<p>Let’s consider a larger application, in order to illustrate further and to talk about some issues and open questions. The <a href="https://github.com/chrisseaton/ruby-stm-lee-demo">code is available on GitHub</a>.</p>

<p>Let’s say it’s our job to lay out the wires on a circuit board. We get a board with <em>pads</em> (connections to components mounted on the board) and a list of <em>routes</em> that we need to draw between these pads. There are a great many pads and routes, there isn’t much space on the tiny board, and another catch is that it’s very expensive to have wires crossing each other. Let’s say it’s exponentially more expensive for more deeply stacked wires.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/minimal.svg" width="25%">
<figcaption>A minimal board and a solution</figcaption>
</figure>

<p>In this minimal example we we can see two routes, and how they have to cross each other.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/mainboard.svg" width="50%">
<figcaption>A processor module board and a solution</figcaption>
</figure>

<p>This example is a processor module and shows what kind of scale we might want to be working at. This board has many longer routes which are more likely to conflict.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/memboard.svg" width="50%">
<figcaption>A memory module board and a solution</figcaption>
</figure>

<p>This example is a memory module. It has many shorter routes which we may expect to conflict less.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/testBoard.svg" width="50%">
<figcaption>The test board we'll use and a solution</figcaption>
</figure>

<p>We’ll use this test board, which is somewhere between all these extremes.</p>

<p>There’s an algorithm to lay each routes, and it actually produces an optimal solution for an individual route, but not for all routes. It’s called <em>Lee’s algorithm</em> and was published back in 1960. We’ll …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrisseaton.com/truffleruby/ruby-stm/">https://chrisseaton.com/truffleruby/ruby-stm/</a></em></p>]]>
            </description>
            <link>https://chrisseaton.com/truffleruby/ruby-stm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926537</guid>
            <pubDate>Thu, 29 Oct 2020 02:41:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Falsehoods programmers believe about addresses (2013)]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 62 (<a href="https://news.ycombinator.com/item?id=24926417">thread link</a>) | @gk1
<br/>
October 28, 2020 | https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/ | <a href="https://web.archive.org/web/*/https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Perhaps you've read posts like <a href="http://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/">Falsehoods Programmers Believe About Names</a>
and <a href="http://infiniteundo.com/post/25326999628/falsehoods-programmers-believe-about-time">Falsehoods programmers believe about time</a>.
Maybe you've also read <a href="http://wiesmann.codiferes.net/wordpress/?p=15187&amp;lang=en">Falsehoods programmers believe about geography</a>.</p>

<p>Addressing is a fertile ground for incorrect assumptions, because everyone's used to dealing with addresses and 99% of the time they seem so simple.
Below are some incorrect assumptions I've seen made, or made myself, or had reported to me.
(If you want to look up an address for a UK postcode or vice-versa to confirm what I'm telling you, try the <a href="http://www.royalmail.com/postcode-finder/">Royal Mail Postcode Finder</a>)</p>

<!-- Composition of building numbers -->

<ul>
<li><p><strong>An address will start with, or at least include, a building number.</strong></p>

<p>Counterexample: Royal Opera House, Covent Garden, London, WC2E 9DD, United Kingdom.</p></li>
<li><p><strong>When there is a building number, it will be all-numeric.</strong></p>

<p>Counterexample: 1A Egmont Road, Middlesbrough, TS4 2HT</p>

<p>4-5 Bonhill Street, London, EC2A 4BX</p></li>
<li><p><strong>No buildings are numbered zero</strong></p>

<p>Counterexample: 0 Egmont Road, Middlesbrough, TS4 2HT</p></li>
<li><p><strong>Well, at the very least no buildings have negative numbers</strong></p>

<p>Guy Chisholm provided this counterexample: Minusone Priory Road, Newbury, RG14 7QS</p>

<p>(none of the databases I've checked render this as -1)</p></li>
<li><p><strong>We can put those funny numbers into the building name field, as no buildings have both a name and a funny number</strong></p>

<p>Counterexample: Idas Court, 4-6 Princes Road, Hull, HU5 2RD</p></li>
<li><p><strong>When there's a building name, there won't be a building number (or vice-versa)</strong></p>

<p>Counterexample: Flat 1.4, Ziggurat Building, 60-66 Saffron Hill, London, EC1N 8QX, United Kingdom</p></li>
<li><p><strong>A building number will only be used once per street</strong></p>

<p>The difference between 50 Ammanford Road, Tycroes, Ammanford, SA18 3QJ and 50 Ammanford Road, Llandybie, Ammanford, SA18 3YF is about 4 miles (<a href="https://maps.google.co.uk/maps?q=SA18+3QJ+to+SA18+3YF">Google Maps</a>).</p></li>
<li><p><strong>When there's line with a number in an address, it's the building number.</strong></p>

<p>Counterexample: Flat 18, Da Vinci House, 44 Saffron Hill, London, EC1N 8FH, United Kingdom</p>

<p>You also get suite numbers, floor numbers, unit numbers, and organisations with numbers in their names.</p>

<p>Adrien Piérard contributes an address from Japan with fifteen digits in six separate numbers (five if you count the zip code as a single number). The format is: 980-0804 (zip code), Miyagi-ken (prefecture) Sendai-shi (city) Aoba-ku (ward) Kokubuncho (district) 4-10-20 (sub-district-number block-number lot-number) Sendai (building name) 401 (flat number).</p></li>
<li><p><strong>OK, the first line starting with a number then</strong></p>

<p>Counterexample: 3 Store, 311-318 High Holborn, London, WC1V 7BN</p></li>
<li><p><strong>A building will only have one number</strong></p>

<p>Benton Lam offers this address from the Hong Kong Special Administrative Region - it has both a number on its road (14) and in its group of buildings (3): 15/F, Cityplaza 3, 14 TaiKoo Wan Road, Island East, HKSAR</p></li>
<li><p><strong>The number of buildings is the difference between the highest and lowest building numbers</strong></p>

<p>Tibor Schütz points out building numbers may be skipped - for example, on a street where even-numbered buildings are on one side, odd numbers on the other; multiple buildings sharing the same number (such as where a new house has been built) and buildings with more than one number.</p>

<p>Cyrille Chépélov and Sami Lehtinen tell me in Antibes, France and rural Finland some buildings are numbered based on the distance from the start of the road - such as Longroad 65 for the building 750m from the start of longroad.</p></li>
<li><p><strong>If the addresses on the left of the road are even, the addresses on the right must be odd</strong></p>

<p>Cyrille Chépélov points out that in places, <a href="https://maps.google.fr/maps?q=48.857415,2.467167">Boulevard Théophile Sueur, Montreuil, Seine-Saint-Denis, France</a> has evens-only on both sides. The two sides are also in different cities and Départements.</p></li>
<li><p><strong>A building name won't also be a number</strong></p>

<p>Ben Tilly reports on Ten Post Office Sq, Boston MA 02109 USA - which is not, reportedly, the same as 10 Post Office Sq, Boston MA 02109 USA.</p></li>
<li><p><strong>Well, at least you can omit leading zeros</strong></p>

<p>Shaun Crampton reports living at 101 Alma St, Apartment 001, Palo Alto - where apartments 1 and 001 were on different floors.</p></li>
<li><p><strong>A street with a building A will not also have a building Alpha</strong></p>

<p>Douglas Perreault reports he lived in a block within a condo association; it was a large association, with blocks A through Z then Alpha, Beta, Gamma, Delta, and Theta. Mail and deliveries were often misrouted from block Alpha to block A and vice-versa. His address at the time was: 14100 N 46th St., Alpha 39, Tampa, FL 33613</p></li>
</ul>

<!-- Composition of street names -->

<ul>
<li><p><strong>A street name won't include a number</strong></p>

<p>8 Seven Gardens Burgh, WOODBRIDGE, IP13 6SU (pointed out by Raphael Mankin)</p></li>
<li><p><strong>OK, but numbers in street names are expressed as words, not digits</strong></p>

<p>Jan Jongboom reports streets can be numbered in the Netherlands - for example, Plein 1944 in Nijmegen.</p></li>
<li><p><strong>When there's a numbered street and a house number, there will be a separator between them</strong></p>

<p>Another from Jan Jongboom: Gondel 2695, Lelystad, means area Gondel, street 26, number 95</p></li>
<li><p><strong>Street names always end in descriptors like 'street', 'avenue', 'drive', 'square', 'hill' or 'view'</strong></p>

<p>They don't always - for example: Piccadilly, London, W1J 9PN</p></li>
<li><p><strong>OK, but when they do have a descriptor there will only be one</strong></p>

<p>A street name can be entirely descriptors: 17 Hill Street, London, W1J 5LJ or <a href="https://en.wikipedia.org/wiki/Avenue_Road">Avenue Road, Toronto, Ontario</a>.</p></li>
<li><p><strong>OK, but when they do have a descriptor it will be at the end</strong></p>

<p>French addresses use prefix descriptors like 'rue', 'avenue', 'place' and 'allee'.</p></li>
<li><p><strong>OK, but if there's a descriptor it'll be at the start or end of the street name.</strong></p>

<p>Or the middle, like 3 Bishops Square Business Park, Hatfield, AL10 9NA</p></li>
<li><p><strong>OK, but at the very least you wouldn't name a town Street</strong></p>

<p><a href="https://maps.google.co.uk/maps?q=Street,+Somerset">Actually there's a town called Street in Somerset, UK</a>.</p></li>
<li><p><strong>Street numbers (and building numbers) don't contain fractions</strong></p>

<p>Dan, Fred Kroon, David Underwood and Daniel Dickison submitted examples of fractional street numbers like <a href="https://maps.google.com/maps?q=43rd%20%C2%BD%20st,%20Pittsburgh,%20PA">43rd ½ St, Pittsburgh, PA</a>, and of fractional building numbers. These can be written in unicode (43rd ½ St), as a fraction with a slash (43 1/2) or as a decimal (43.5)</p>

<p>Gene Wirchenko reports a fractional building number: 1313 1/2 Railroad Ave Bellingham WA 98225-4729</p></li>
<li><p><strong>Street names don't recurr in the same city</strong></p>

<p><a href="https://maps.google.co.uk/maps?q=from:W3+6LJ+to:W5+5DB+to:N8+7PB+to:SE25+6EP+to:E13+0AJ+to:E17+7LD+to:NW10+4LX+to:N1+9TR+to:E1+6PG+to:NW1+0JH+to:W14+8NL+to:SE13+6AD+to:SW19+5DX+to:E11+2AJ+to:SW19+2AE+to:E6+2HJ+&amp;saddr=W3+6LJ&amp;daddr=W5+5DB+to:N8+7PB+to:SE25+6EP+to:E13+0AJ+to:E17+7LD+to:NW10+4LX+to:N1+9TR+to:E1+6PG+to:NW1+0JH+to:W14+8NL+to:SE13+6AD+to:SW19+5DX+to:E11+2AJ+to:SW19+2AE+to:E6+2HJ">Here's a map of the following addresses:</a></p>

<ul>
<li>High Street, London, W3 6LJ</li>
<li>High Street, London, W5 5DB</li>
<li>High Street, London, N8 7PB</li>
<li>High Street, London, SE25 6EP</li>
<li>High Street, London, E13 0AJ</li>
<li>High Street, London, E17 7LD</li>
<li>High Street, London, NW10 4LX</li>
<li>Islington High Street, London, N1 9TR</li>
<li>Shoreditch High Street, London, E1 6PG</li>
<li>Camden High Street, London, NW1 0JH</li>
<li>Kensington High Street, London, W14 8NL</li>
<li>Lewisham High Street, London, SE13 6AD</li>
<li>High Street Wimbledon, London, SW19 5DX</li>
<li>High Street Wanstead, London, E11 2AJ</li>
<li>High Street Colliers Wood, London, SW19 2AE</li>
<li>High Street North, London, E6 2HJ </li>
</ul></li>
<li><p><strong>But street names don't recurr in close proximity</strong></p>

<p>Julian Fleischer provides an example from Bocholt in Germany showing several roads in close proximity all called <a href="https://maps.google.com/maps?q=51.853945,6.615334">Up de Welle</a>.</p></li>
<li><p><strong>An address will be comprised of road names</strong></p>

<p>Kirk Kerekes spent several years using an address of the form "2 mi N then 3 mi W of Jennings, OK 74038" which regularly got successful deliveries. Mike Riley used to mail the Very Large Array radio telescope at "50 miles (80 km) West of Socorro, New Mexico, USA"</p>

<p>Sam pointed me to <a href="http://www.menomoneefallsnow.com/news/99857214.html">Menomonee Falls</a> where houses are addressed using Milwaukee County's grid system instead of house numbers - giving addresses like N88 W16541 Foobar St.</p>

<p>Andy Monat sent the following address example, from a <a href="http://ciapa.tulane.edu/uploads/1_EE_2012_Acceptance_Packet_INFORMATION-1340749206.pdf">semester abroad program at Tulane University </a>: CIAPA, 50 meters north of the Hypermas/Walmart of Curridabat, San Jose, Costa Rica. Adrien Piérard and Luke Allardyce point out street names are seldom used in Japan - instead, districts and blocks and lot numbers are used (more info on the <a href="https://en.wikipedia.org/wiki/Japanese_addressing_system">Wikipedia entry for the Japanese addressing system</a>).  A <a href="http://www.worldpress.org/Americas/592.cfm">2002 World Press Review report</a> gave this sample address: From where the Chinese restaurant used to be, two blocks down, half a block toward the lake, next door to the house where the yellow car is parked, Managua, Nicaragua. Shaun Crampton sent <a href="https://vianica.com/nicaragua/practical-info/14-addresses.html">an article with more details and examples of the Nicaraguan system</a>. Stig Brautaset pointed out <a href="http://www.bbc.co.uk/news/magazine-14806350">a BBC article about post in Kabul</a> gives this example: "Hamid Jaan, behind Darul-Aman palace". Nathan Fellman reports similar addressing is used in Nicaragua and Costa Rica.</p>

<p>Paul Puschmann and Tibor Schütz pointed out the city of <a href="http://de.wikipedia.org/wiki/Quadratestadt">Mannheim in Germany is sometimes called Quadratestadt (City of Squares)</a> as the city centre is arranged in a grid, with blocks assigned a letter (along the north-south axis) and a number (along the east-west axis) then buildings numbered by block number. So an example address at numbers 6 to 13 on block R 5 would be: Institut für Deutsche Sprache, R 5, 6-13, D-68161 Mannheim </p>

<p>Leoni Lubbinge gives an example of a South African address: Part 84, Strydfontein 306 JR, Pretoria which means the 84th plot of the farm Strydfontein 306 JR.</p></li>
</ul>

<!-- Elements being present or absent -->

<ul>
<li><p><strong>A road will have a name</strong></p>

<p>Plenty of roads like driveways, onramps and the aisles of carparks don't have names. Some roads in Japan also don't have names, as <a href="https://en.wikipedia.org/wiki/Japanese_addressing_system">the prevalent addressing system works on districts, subdistricts, blocks, lots and lot numbers</a>.</p>

<p>Peter Kenway points out in America some homes are addressed as Rural Routes, where numbers are allocated to boxes on a route covering multiple roads. For example: Box 1234, R.R. 1, Winthrop, ME 04364.</p></li>
<li><p><strong>A road will only have one name</strong></p>

<p>Many different roads, from Goswell Road in London to Regent Road in Edinburgh, make up the 410 mile <a href="https://en.wikipedia.org/wiki/A1_road_%28Great_Britain%29">A1</a>. And while there may only be one "1 Goswell Road" and only one "1 Regent Road" there are multiple buildings numbered 1 on the road designated A1.</p>

<p>Roads may also be named in multiple languages. For example, in Ireland roads may be named in both English and Irish</p></li>
<li><p><strong>Addresses will only have one street</strong></p>

<p>The Royal Mail have what they call a 'dependent street' - for example: 6 Elm Avenue, Runcorn Road, Birmingham, B12 8QX, United Kingdom (Runcorn Road is the street, Elm Avenue is the stubby 'dependent street' and isn't unique within the city. <a href="http://maps.google.co.uk/maps?q=B12+8QX">Google Maps</a> )</p>

<p>Another counterexample: Rogue Hair, 1 Hopton Parade, Streatham High Road, London, SW16 …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/">https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/</a></em></p>]]>
            </description>
            <link>https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926417</guid>
            <pubDate>Thu, 29 Oct 2020 02:25:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ireland was WAY beyond my expectations. Why you have to go]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24926249">thread link</a>) | @adeiji1
<br/>
October 28, 2020 | https://graffitiapp.co/story/ireland | <a href="https://web.archive.org/web/*/https://graffitiapp.co/story/ireland">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://graffitiapp.co/story/ireland</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926249</guid>
            <pubDate>Thu, 29 Oct 2020 01:55:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Violated a Code of Conduct]]>
            </title>
            <description>
<![CDATA[
Score 1157 | Comments 879 (<a href="https://news.ycombinator.com/item?id=24926214">thread link</a>) | @tosh
<br/>
October 28, 2020 | https://www.fast.ai/2020/10/28/code-of-conduct/ | <a href="https://web.archive.org/web/*/https://www.fast.ai/2020/10/28/code-of-conduct/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p><span>Written: 28 Oct 2020 by <i>Jeremy Howard</i></span></p><blockquote>
<p><em>Update Oct 20, 2020</em>: NumFOCUS <a href="https://numfocus.org/blog/jeremy-howard-apology">has apologized</a> to me. I accept their apology. I do not accept their assertion that “At the time of the interview, the committee had not determined that there was a violation of the code of conduct, only that there were two complaints filed and being examined.” The email to set up the call said “We would like to schedule a meeting so that we can discuss the results of our investigation with you” - nothing further. During the call, the committee stated the list of violations, and said “that is what the reporters stated, and what we found”. I asked why they didn’t take a statement from me before that finding, and they said “we all watched the video, so we could see for ourselves the violation”. The committee offered in their apology email to me to have a follow-up discussion, and I declined the offer.</p>
</blockquote>
<blockquote>
<p>Summary: NumFOCUS found I violated their Code of Conduct (CoC) at JupyterCon because my talk was not “kind”, because I said Joel Grus was “wrong” regarding his opinion that Jupyter Notebook is not a good software development environment. Joel (who I greatly respect, and consider an asset to the data science community) was not involved in NumFOCUS’s action, was not told about it, and did not support it. NumFOCUS did not follow their own enforcement procedure and violated their own CoC, left me hanging for over a week not even knowing what I was accused of, and did not give me an opportunity to provide input before concluding their investigation. I repeatedly told their committee that my emotional resilience was low at the moment due to medical issues, which they laughed about and ignored, as I tried (unsuccessfully) to hold back tears. The process has left me shattered, and I won’t be able to accept any speaking requests for the foreseeable future. I support the thoughtful enforcement of Code of Conducts to address sexist, racist, and harassing behavior, but that is not what happened in this case.</p>
</blockquote>
<h2 id="overview">Overview</h2>
<p>In my recent JupyterCon keynote, “I Like Jupyter Notebooks” (re-recording provided at the bottom of this post, if you’re interested in seeing it for yourself), I sought to offer a rebuttal to Joel Grus’ highly influential JupyterCon presentation “<a href="https://www.youtube.com/watch?v=7jiPeIFXb6U">I Don’t Like Notebooks</a>”. Joel claimed in his talk that Jupyter is a poor choice for software development and teaching, and I claimed in my talk that it is a good choice. The NumFOCUS committee found me guilty of violating their code of conduct for having not been “kind” in my disagreement with Joel, and for “insulting” him. The specific reasons given were that:</p>
<ul>
<li>I said that Joel Grus was “wrong”</li>
<li>I used some of his slides (properly attributed) and a brief clip from one of his videos to explain why I thought he was wrong</li>
<li>That I made “a negative reference” to his prior talk</li>
<li>I was also told that “as a keynote speaker” I would “be held to a higher standard than others” (although this was not communicated to me prior to my talk, nor what that higher standard is)</li>
</ul>
<p>Code of Conducts can be a useful tool, when thoughtfully created and thoughtfully enforced, to address sexism, racism, and harassment, all of which have been problems at tech conferences. Given the <a href="https://medium.com/tech-diversity-files/if-you-think-women-in-tech-is-just-a-pipeline-problem-you-haven-t-been-paying-attention-cb7a2073b996">diversity issues in the tech industry</a>, it is important that we continue the work of making conferences more inclusive, particularly to those from marginalized backgrounds. Having a code of conduct with explicit rules against violent threats, unwelcome sexual attention, repeated harassment, sexually explicit pictures, and other harmful behavior is the first step towards addressing and stopping those behaviors. The JupyterCon code provides the following examples of unacceptable behavior, none of which are at all similar to what I did (i.e. saying that someone was wrong on a technical topic, and explaining how and why):</p>
<ul>
<li>Violent threats or violent language directed against another person</li>
<li>Discriminatory jokes and language</li>
<li>Posting sexually explicit or violent material</li>
<li>Posting (or threatening to post) other people’s personally identifying information (“doxing”)</li>
<li>Personal insults, especially those using racist or sexist terms</li>
<li>Unwelcome sexual attention</li>
<li>Advocating for, or encouraging, any of the above behavior</li>
<li>Repeated harassment of others. In general, if someone asks you to stop, then stop</li>
</ul>
<p>My experience with the NumFOCUS code of conduct raises a few key issues:</p>
<ul>
<li>The CoC enforcement process involved conflicting &amp; changing information, no opportunity for me to give input, the stress of a long wait of unknown duration with no information about what I was accused of or what would happen next, and the committee members violated their own CoC during the process</li>
<li>There were two totally different Codes of Conduct with different requirements linked in different places</li>
<li>I was held to a different, undocumented and uncommunicated standard</li>
<li>The existence of, or details about, the CoC were not communicated prior to confirmation of the engagement</li>
<li>CoC experts recommend avoiding requirements of politeness or other forms of “proper” behavior, but should focus on a specific list of unacceptable behaviors. The JupyterCon CoC, however, is nearly entirely a list of “proper” behaviors (such as “Be welcoming”, “Be considerate”, and “Be friendly”) that are vaguely defined</li>
<li>CoC experts recommend using a CoC that focuses on a list of unacceptable behaviors. Both the codes linked to JupyterCon have such a link, and none of the unacceptable behavior examples are in any way related or close to what happened in this case. But NumFOCUS nonetheless found me in violation.</li>
</ul>
<p>I would rather not have to write this post at all. However I know that people will ask about why my talk isn’t available on the JupyterCon site, so I felt that I should explain exactly what happened. In particular, I was concerned that if only partial information became available, the anti-CoC crowd might jump on this as an example of problems with codes of conduct more generally, or might point at this as part of “cancel culture” (a concept I vehemently disagree with, since what is referred to as “cancellation” is often just “facing consequences”). Finally, I found that being on the “other side” of a code of conduct issue gave me additional insights into the process, and that it’s important that I should share those insights to help the community in the future.</p>
<h2 id="details">Details</h2>
<p>The rest of this post is a fairly detailed account of what happened, for those that are interested.</p>
<h3 id="my-talk-at-jupytercon">My talk at JupyterCon</h3>
<p>I recently gave a talk at <a href="https://jupytercon.com/">JupyterCon</a>. My partner Rachel gave a <a href="https://www.youtube.com/watch?v=frc7FgheUj4">talk at JupyterCon</a> a couple of years ago, and had a wonderful experience, and I’m a huge fan of Jupyter, so I wanted to support the project. The conference used to be organized by O’Reilly, who have always done a wonderful job of conferences I’ve attended, but this year the conference was instead handled by <a href="https://numfocus.org/">NumFOCUS</a>.</p>
<p>For my talk, I decided to focus on Jupyter as a literate and <a href="https://www.fast.ai/2019/12/02/nbdev/">exploratory programming environment</a>, using <a href="https://nbdev.fast.ai/">nbdev</a>. One challenge, however, is that two years earlier Joel Grus had given a brilliant presentation called <a href="https://www.youtube.com/watch?v=7jiPeIFXb6U">I Don’t Like Notebooks</a> which had been so compelling that I have found it nearly impossible to talk about programming in Jupyter without being told “you should watch this talk which explains why programming in Jupyter is a terrible idea”.</p>
<p>Joel opened and closed his presentation with some light-hearted digs at me, since I’d asked him ahead of time <em>not</em> to do such a presentation. So I thought I’d kill two birds with one stone, and take the opportunity to respond directly to him. Not only was his presentation brilliant, but his slides were hilarious, so I decided to directly parody his talk by using (with full credit of course) some of his slides directly. That way people that hadn’t seen his talk could both get to enjoy the fantastic content, and also understand just what I was responding to. For instance, here’s how Joel illustrated the challenge of running cells in the right order:</p>
<figure>
<img srcset="https://www.fast.ai/images/numfocus/joel-order.png 2w" sizes="1px" src="https://www.fast.ai/images/numfocus/joel-order.png">
</figure>
<p>I showed that slide, explaining that it’s Joel’s take on the issue, and then followed up with a slide showing how easy it actually is to run all cells in order:</p>
<figure>
<img srcset="https://www.fast.ai/images/numfocus/jeremy-order.png 2w" sizes="1px" src="https://www.fast.ai/images/numfocus/jeremy-order.png">
</figure>
<p>Every slide included a snippet from Joel’s title slide, which, I explained, showed which slides were directly taken from his presentation. I was careful to ensure I did not modify any of his slides in any way. When first introducing his presentation, I described Joel as “a brilliant communicator, really funny, and wrong”. I didn’t make any other comments about Joel (although, for the record, I think he’s awesome, and highly recommend <a href="https://www.amazon.com/Data-Science-Scratch-Principles-Python/dp/1492041130">his book</a>.</p>
<h3 id="the-code-of-conduct-violation-notice">The Code of Conduct violation notice</h3>
<p>A week later, I received an email telling me that two CoC reports were filed regarding my JupyterCon keynote presentation. I was told that “The Code of Conduct Enforcement Team is meeting tomorrow to review the incident and will be contacting you to inform you of the nature of the report and to understand your perspective”.</p>
<p>The CoC wasn’t mentioned at all until after I’d been invited to speak, had accepted, and had completed the online registration. I had reviewed it at that time, and had been a bit confused. The email I received linked to a <a href="https://jupytercon.com/codeofconduct/">JupyterCon Code of Conduct</a>, but that in turn didn’t provide much detail about what is and isn’t OK, and that in turn linked to a different <a href="https://numfocus.org/code-of-conduct">NumFOCUS Code of Conduct</a>. A link was also provided to <a href="https://numfocus.typeform.com/to/ynjGdT">report violations</a>, which also linked to and named the NumFOCUS CoC.</p>
<p>I was concerned that I had done something which might be viewed as a violation, and looked forward to hearing about the nature of the report and having a chance to share my perspective. I was heartened that JupyterCon documented that they follow the <a href="https://numfocus.org/code-of-conduct/response-and-enforcement-events-meetups">NumFOCUS Enforcement Manual</a>. I was also heartened that the manual has a section “Communicate with the Reported Person about the Incident” which says they will “Let the reported person tell someone on the CoC response team their side of the story; the person who receives their side of the story should be prepared to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.fast.ai/2020/10/28/code-of-conduct/">https://www.fast.ai/2020/10/28/code-of-conduct/</a></em></p>]]>
            </description>
            <link>https://www.fast.ai/2020/10/28/code-of-conduct/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926214</guid>
            <pubDate>Thu, 29 Oct 2020 01:47:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remix – a new JavaScript framework from the authors of React Router]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24926162">thread link</a>) | @prezjordan
<br/>
October 28, 2020 | https://remix.run/features | <a href="https://web.archive.org/web/*/https://remix.run/features">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><h3 id="smart-code-splitting">Smart code splitting</h3><p>No matter which page your user lands on, the total footprint of a Remix app is about 50kb over the network (including dependencies). It doesn't matter how large your application gets, each page only downloads what it needs, which is actually pretty uncommon in the React ecosystem.</p><p>React apps are typically built two ways: bundle everything into one enormous file (yikes!) or code split into multiple bundles to load on demand. The apps that code split usually send down a very large build manifest, listing every asset you could possibly need. That means as you add files and pages to your site, the footprint of <em>every page</em> grows.</p><p>Remix never loads more code than the page the user is looking at. You can have 10 or 10,000 routes, the footprint for each remains constant. Just because you added some routes to the photo viewer doesn't mean the contact page gets bigger over the network.</p><h3 id="beyond-heavy-javascript-in-the-browser">Beyond heavy JavaScript in the browser</h3><p>Do you ever look at some of the pages on your website and think "why does this need to download any JavaScript at all?". We do too. Go ahead and open the dev tools on this page you're reading right now.</p><p>Yeah, you, open the dev tools.</p><p>That's right, no JavaScript! This is a marketing page with nothing interactive but links. There's no reason to load JavaScript here. You might think "but wouldn't you be able to speed up the transitions if you loaded in a client side router?" Great question. The answer is, not always.</p><p>Open the devtools again. You'll note in the network tab that we've already loaded in the "/buy" page with a link response header. When you click "buy" (please click buy), the browser already has the page and will navigate there immediately. It can't get faster than that.</p><p>With Remix, you have full control of how your app is delivered at every route. Load a bunch of JavaScript for a really interactive page, or skip it for a static page. Preload a page you think they'll navigate to, or only load that page when they navigate to it. It's all up to you.</p><h3 id="closing-the-gap-between-production-and-development-builds">Closing the gap between production and development builds</h3><p>Remember that one time you were implementing dark mode and put a <code>window.matchMedia</code> in state? Remember how everything was awesome until you deployed and then suddenly the production server was crashing? That's right, there is no window on the server and you weren't server rendering in dev!</p><p>Remember when you pushed some new CSS to production and your elements started bouncing around because your CSS lib was moving style tags around in production but not dev?</p><p>Remember when the requests for code split resources in development seemed fine but in production they were widly different and included way more in them than expected?</p><p>Production bugs live in the delta between development and production environments. Remix closes that gap.</p><p>Remix server renders the same in development as production, loads CSS the same (<code>&lt;link/&gt;</code>, ofc) and code splits the same. How can we do this? We only build the page you're looking at in development, so we can build it like production in a few milliseconds.</p><h3 id="a-refreshing-take-on-css">A refreshing take on CSS</h3><p>Remix lets you use the CSS skills you already have. While we love the innovation that has happened in the CSS-in-JS space, and you can use them in Remix, we provide a back-to-basics approach with a twist.</p><p>One of the trickiest parts of CSS and highly dynamic websites is knowing when to apply it and when to remove it. Because of nested routes, we know the layouts that are being rendered and which aren't. As the user navigates around Remix automatically loads and unloads the styles for the layouts on the page.</p><p>It might sound like no big deal at first, but once you try it you'll realize it's quite powerful.</p><p>Remix also adds a few improvements to CSS like auto prefixing and nesting, and support for tailwind out of the box, but other than that, we keep it simple.</p><h3 id="so-much-more">So much more</h3><p>Perhaps the most unique thing about Remix is that there's hardly any API at all. It gets out of your way wherever it can to allow you to use the web and React the way they were each designed. You have control over every entry point into your app, from the initial request handler to the deepest matching route's meta tags. No plugins, no complicated rendering abstractions, just React and HTTP as designed.</p><h3 id="who-is-remix">Who is Remix?</h3><p>We're Michael Jackson (no, not that one) and Ryan Florence. We've been running the company <a href="https://reacttraining.com/">React Training</a> since 2015. We've taught hundreds of teams and thousands of people at top companies around the world how to get the most out of React while also working our open source projects: React Router, Unpkg, and Reach UI. Before that, we worked on some of the apps at <a href="https://www.alexa.com/topsites/countries/US">the most visited sites on the internet</a> like Twitter (twitter.com) and Canvas (instructure.com).</p><p>As trainers and open source authors, we've seen where teams struggle with React, and we've struggled with these things ourselves! We're now dedicated to helping you build better websites with Remix.</p></article></div>]]>
            </description>
            <link>https://remix.run/features</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926162</guid>
            <pubDate>Thu, 29 Oct 2020 01:35:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Has death due to Covid-19 become less common?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24926073">thread link</a>) | @hn_smarky
<br/>
October 28, 2020 | https://smarky7cd.github.io/covid19/ | <a href="https://web.archive.org/web/*/https://smarky7cd.github.io/covid19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <nav>
    <ul>
      <li><a href="https://smarky7cd.github.io/">Home</a></li>
      <li><a href="https://smarky7cd.github.io/blog">Blog</a></li>
      <li><a href="https://smarky7cd.github.io/research">Research</a></li>
    </ul>
  </nav>

  <div>

    

<p><img src="https://smarky7cd.github.io/covid19/sams_covid_data.png" alt="Sam's Covid Data"></p><p><a href="https://covid.cdc.gov/covid-data-tracker/#trends_dailytrendsdeaths" target="_blank">CDC Data</a></p>



  </div>



</div>]]>
            </description>
            <link>https://smarky7cd.github.io/covid19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926073</guid>
            <pubDate>Thu, 29 Oct 2020 01:21:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Update: The Quest 2 jailbreak has been officially verified]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24926025">thread link</a>) | @vrfinal
<br/>
October 28, 2020 | https://www.vrfinal.com/update-quest-2-jailbreak-has-been-verified/ | <a href="https://web.archive.org/web/*/https://www.vrfinal.com/update-quest-2-jailbreak-has-been-verified/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Last week, <a href="https://www.vrfinal.com/oculus-founder-offers-a-further-5000-reward-for-quest-2-jailbreakers/">we reported that someone had claimed the $10,000 bounty to jailbreak the Oculus Quest 2</a>. Well, this week it's been officially verified.</p><p><em>Mozilla</em>'s Robert Long and <em>Oculus</em> Founder Palmer Luckey came together last week to put up $5000 each as a reward for the task. They also promised that, after a round of crowdfunding, the final bounty would be <em>even higher</em>. Of course, it didn't take long for someone to claim it.</p><p>However, Long soon explained on his Discord server that, after congratulating the budding hacker, he had directed the jailbreaker to "a team of security and legal professionals who can evaluate this claim and determine how to responsibly publish these findings."</p><p>And this week, in a statement on Twitter, Long announced that the claimant's efforts had been verified:</p><figure><img src="https://www.vrfinal.com/content/images/2020/10/ElRXLEpUUAAVKzM.png" alt=""><figcaption>(Credit: @arobertlong, Twitter)</figcaption></figure><p>But now the project has hit a bump in the road and the team have some hard questions to answer. After all, is the jailbreak even legal?</p><p>XR Safety Initiative researchers were able to verify the successful method and are now hard at work "gathering assurances" for other successful jailbreakers to protect them from legal retaliation from Oculus.</p><p>Long has asked other successful hackers to get in touch, explaining that XRSI's "legal and security expertise [have] been crucial in pushing this effort forward":</p><blockquote>"If you are one of those researchers, we urge you to contact us and share the details in a secure manner. Contact XR Safety Initiative XRSI via info@xrsi.org or Use Signal 510-990-4438"</blockquote><figure><img src="https://www.vrfinal.com/content/images/2020/10/goroman-oculus-2-6-e1602602129217-768x431.jpeg" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/10/goroman-oculus-2-6-e1602602129217-768x431.jpeg 600w, https://www.vrfinal.com/content/images/2020/10/goroman-oculus-2-6-e1602602129217-768x431.jpeg 768w" sizes="(min-width: 720px) 720px"><figcaption>The successful jailbreak was reported with incredible speed, but now the real challenge begins. (Credit: RoadToRV)</figcaption></figure><p>The jailbreaking grey area revolves around the practice's relationship with "Right to Repair" - a framework which legally gives users full control over the hardware and software they purchase. The practice is already widely accepted in the smartphone world, but the XRSI organisation is campaigning to extend it's use to VR headsets.</p><p>If it all works out, I think the successful hacker is deserving of his $10,000+ reward. And if they can ensure it is legally kosher, the jailbreak will be great news for Oculus Quest 2 fans, too.</p><p><a href="https://www.vrfinal.com/facebook-confirms-that-logging-into-multiple-quest-headsets-wont-get-you-banned/">Especially while the controversy around the Facebook account requirement continues to develop</a>...</p>
          </div></div>]]>
            </description>
            <link>https://www.vrfinal.com/update-quest-2-jailbreak-has-been-verified/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926025</guid>
            <pubDate>Thu, 29 Oct 2020 01:13:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Corning Announces Pixelligent Partnership, to Develop Next Gen VR Optics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24926021">thread link</a>) | @vrfinal
<br/>
October 28, 2020 | https://www.vrfinal.com/corning-inc-announces-pixelligent-tech-partnership/ | <a href="https://web.archive.org/web/*/https://www.vrfinal.com/corning-inc-announces-pixelligent-tech-partnership/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Corning Incorporated, the creators of the damage resistant "Gorilla Glass," have today announced a "strategic agreement" with Pixelligent Technologies - the world-leading supplier of compound materials.</p><p>Corning Incorporated is one of the world's biggest manufacturers of optical materials - providing high-refractive index glass which has enabled augmented and mixed reality headset manufacturers to deliver ever-greater AR image quality.</p><figure><img src="https://www.vrfinal.com/content/images/2020/10/https___specials-images.forbesimg.com_imageserve_499670178_0x0.jpg" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/10/https___specials-images.forbesimg.com_imageserve_499670178_0x0.jpg 600w, https://www.vrfinal.com/content/images/size/w1000/2020/10/https___specials-images.forbesimg.com_imageserve_499670178_0x0.jpg 1000w, https://www.vrfinal.com/content/images/2020/10/https___specials-images.forbesimg.com_imageserve_499670178_0x0.jpg 1199w" sizes="(min-width: 720px) 720px"><figcaption>The company announced a "strategic partnership" with Pixelligent, looking to move forward it's AR plans. (Credit: Corning)</figcaption></figure><p>The partnership is said to centred around Pixelligent's optically transparent compounds and Corning's glass manufacturing technology. But what will each company be bringing to the table? And what do they hope to achieve?</p><p>Well, Pixelligent are providing their PixClear polymers. These materials harness zirconia and titania-based nanocrystals in order to increase the refractive index of the optics they produce. Their optically transparent polymers will be central to Corning's plans for Next Gen optics.</p><p>Meanwhile, Corning already have vast experience producing flat, high-index glass wafers for a number of leading AR device manufactures. Some big names have been banking on the <em>Gorilla Glass </em>maker, considering that tech giant <em>Apple</em> have invested upwards of $450 million into the company since 2017.</p><p>A statement from Corning claims the partnership aims to "help reduce product-development time and expand availability of AR devices."</p><p>I must say, a collaboration between Pixelligent's <em>PixClear </em>and Corning's <em>Gorilla Glass </em>would certainly be a sight to behold for all you fans of advanced manufacturing materials!</p><figure><img src="https://www.vrfinal.com/content/images/2020/10/apple-store-green-leaf-9787-1.jpg" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/10/apple-store-green-leaf-9787-1.jpg 600w, https://www.vrfinal.com/content/images/size/w1000/2020/10/apple-store-green-leaf-9787-1.jpg 1000w, https://www.vrfinal.com/content/images/2020/10/apple-store-green-leaf-9787-1.jpg 1600w" sizes="(min-width: 720px) 720px"><figcaption>What does this mean for the future? Well, we may now know one of Apple VR's key manufacturing components. (Credit: Apple)</figcaption></figure><p>But what does this industry development mean for the future of VR? Well, rumours have been circulating for some time that <a href="https://www.vrfinal.com/apples-iphone-12-pro-to-have-lidar-scanner-for-instant-ar-capabilities/">Apple is looking make it's mark on the AR space</a>, <a href="https://www.vrfinal.com/apples-new-patents-an-indication-of-entry-into-the-vr-and-ar-space/">perhaps even looking to produce it's own AR headset</a>. We may now know one of Apple VR's key manufacturing components.</p><p>It's not just Apple stepping up their game, too. <a href="https://www.vrfinal.com/huawei-announces-upgraded-vr-glass-with-6dof/">Huawei today announced an upgraded VR Glass with 6DoF!</a></p>
          </div></div>]]>
            </description>
            <link>https://www.vrfinal.com/corning-inc-announces-pixelligent-tech-partnership/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926021</guid>
            <pubDate>Thu, 29 Oct 2020 01:13:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Beam Marches Forward]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24925973">thread link</a>) | @andrenth
<br/>
October 28, 2020 | https://underjord.io/the-beam-marches-forward.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-beam-marches-forward.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2020-10-26</small>
        <p>The BEAM is the virtual machine that Erlang and Elixir runs on. It is widely cited as a battle-tested piece of software though I don’t know in which wars it has seen action. It has definitely paid its dues in the telecom space as well as globally scaled projects such as Whatsapp and Discord. It is well suited to tackle soft-realtime distributed systems with heavy concurrency. It has been a good platform chugging along. And with a small team at Ericsson responsible for much of its continuing development it has been managed in a deeply pragmatic way. Erlang has always been a bit of a secret and silent success. Almost no-one uses it if you look at market shares. But among the ones that use it there seems to be a very positive consensus. And then Elixir came and caused a bit of a boom. I think the BEAM has benefited from Elixir and Elixir wouldn’t exist without the BEAM. With that bit of background I’d like to shine a light on some cool developments that I think makes the BEAM more interesting or even uniquely interesting in the future.</p>
<h2 id="the-jit-is-here-soon-otp-24">The JIT is here (soon, OTP 24)</h2>
<p>With OTP 24 landing sometime next year we are going to get the a JIT for the BEAM. Based on the project <a href="https://github.com/asmjit/asmjit">AsmJit</a> this will mean that some BEAM code will be translated to native instructions. It will not be the kind of warm-up-for-performance-gains JIT that I’ve heard of in PyPy but rather significantly simpler. The goal of the project was to introduce a JIT that could give performance gains for some cases but would not cause any performance regressions. A pragmatic and laudable approach. Considering this made the Jason JSON-library (written in Elixir) beat the Jiffy JSON-library (written as a C NIF) in <strong>some</strong> tests I think this has the potential to obviate the need for some NIF implementations. Avoiding reaching out to the lower level code that is more capable but more dangerous is a good win.</p>
<p>Anyone running RabbitMQ should look forward to the update as measurements indicate 30-50% increased message throughput. Which is a nice thing to get for no code changes at all.</p>
<p>Pushing the performance of the BEAM closer to native is magnificent. To be clear the BEAM is already quite a good performer. I would put Erlang and Elixir at the abstraction level of languages like Python/Ruby/Node.js. Python and Ruby are poor performers. The Python ML stuff all goes into C++ or similar for performance. I’ve worked a bunch with Python and the things I hear from the Ruby world makes them sound quite equivalent in performance. They are a bit slow and can only <a href="https://underjord.io/more-than-one-thing-at-a-time.html">do one thing at a time</a>. Node.js is a bit different. It can do multiple things at a time, if you append asterisks and squint. It does it largely the same way Python + Gevent does it. This approach is incredibly susceptible to CPU-bound work causing head-of-line blocking. It becomes the single most important consideration for building a performant application “get to IO, don’t compute”. V8 that Node.js runs on is heavily optimized and fast for such a dynamic language. I think the BEAM provides a better approach that can deliver comparable results without as many footguns (opportunities for shooting yourself in the foot). But getting better at the raw crunching is a big gain with this JIT implementation and I look forward to the release.</p>
<h2 id="lumen---static-compilation--wasm">Lumen - Static compilation &amp; WASM</h2>
<p>The <a href="https://getlumen.org/">Lumen project</a> is a huge effort by a gang of open source developers and DockYard to implement a compiler (and more) that can take Elixir and Erlang into the browser. By solving that they end up solving static compilation for Erlang and Elixir as well. So this isn’t compiling and shipping the BEAM to the browser. This is a faithful reimplementation of the BEAM functionality in a way that allows it to be compiled statically. It uses LLVM and requires quite a bit of effort both in development and in wrangling the Web Assembly work group process stuff to make sure that the standard is not entirely run by Object-Oriented Programming needs.</p>
<p>I don’t think Lumen will replace the BEAM. The BEAM has a brilliant track record for long-running services and distributed computing that the Lumen project do not even attempt to achieve right now. Instead the Lumen project will allow Elixir and Erlang to move into spaces where the BEAM might be a bit too heavy and still provide the same guarantees. Typically I see it being good for command line tools, web frontends (super interesting to consider the Actor model going there), serverless/edge computing and potentially with WASM competing with Docker as a delivery mechanism for code in Kubernetes, using something like <a href="https://github.com/deislabs/krustlet">Krustlet</a> (<a href="https://player.fm/series/software-sessions/webassembly-on-the-server-with-krustlet">good podcast episode on WASM/Krustlet</a>). It’s probably Cloud Native or something. Who knows.</p>
<p>What gives Lumen the potential to be a better fit in these circumstances is that it can optimize for filesize (by cutting out hot code updates) and it is likely able to start much faster. Lumen is written in Rust. Which seems to be the popular choice around Web Assembly from what I’ve seen. Lumen is still an early release project and not fit for production. But it is beeing actively pushed forward.</p>
<h2 id="nerves---an-iot-platform-with-minimal-suck">Nerves - An IoT platform with minimal suck</h2>
<p>The <a href="https://www.nerves-project.org/">Nerves project</a> is fantastic. I’m a hardware hobbyist, not an IoT dev but I’ve worked a fair bit with Nerves and it is so, so good. What Nerves gives you when working with a Raspberry Pi for example is a way to let your code run all of the device. The BEAM is basically your operating system on top of a minimal Linux installation. The Linux you have is based on the solid foundation of Buildroot so it is quite feasible to modify it as you see fit. The big idea is that if you are running a Linux-level SBC already you might as well build on something that gives you the guarantees of the BEAM.</p>
<p>Beyond that the default setup encodes a lot of good embedded practices by default so that you avoid bricking devices with firmware updates, you get easy support for pushing firmware over the network or USB and much, much more.</p>
<p>There are a ton of good libraries for sensors and assorted hardware, as well as the common protocols like GPIO/SPI/I2C/UART. Networking support is well considered and has been reworked since I first started using Nerves a few years back (and it worked well then too). BLE is getting more and more good support recently.</p>
<p>The project also created <a href="https://www.nerves-project.org/nerveshub">NervesHub</a> which is a solution for managing a fleet of devices by securely providing firmware updates, allowing the switching on of a remote console on devices if that’s a need on your product. I think the most recent stuff is a UI revamp and some serious work on binary diffed patches to minimize firmware update sizes for data-constrained deployments.</p>
<p>This is very much a production project and people are shipping hardware with Nerves. It keeps marching forward.</p>
<h2 id="the-beam-can-be-your-entire-application">The BEAM can be your entire application</h2>
<p>Saša Jurić, author of the much-acclaimed Elixir in Action book has produced a library called <a href="https://github.com/sasa1977/site_encrypt">site_encrypt</a>. It allows you to handle LetsEncrypt configuration without a separate webserver or actually using certbot.</p>
<p>Now this library is good and meaningful in its own right but the underlying idea is why I bring it up. The BEAM can be your entire application. This is something I’ve realized over time. Where in Python you would reach for Gunicorn to run you Django app and Nginx to protect Gunicorn from the big bad world.. The BEAM is made for this. Introducing an intermediate layer of Nginx (or another HTTP server) might actually be detrimental in that you now have two things you need to configure correctly and two pools of multi-core processing workers that care about this request/response cycle and can independently screw it up.</p>
<p>The BEAM was always built for this. OTP has a lot weird corners where you find interesting libraries such as <code>wx</code> for WxWidgets (window management) and <code>ssh</code> for both SSH client and server work I believe. Because it is meant to be delivered as a full solution. It can run and manage multiple different types of work inside of it. Gracefully. It doesn’t replace Kubernetes for the large deployment or polyglot environments. But it might very well mean you don’t actually need to go there early. Or you can reduce how much Ops you need in your Dev. If your entire stack is Elixir or Erlang front to back I think you have empowered your developers significantly.</p>
<p>There is already a move towards this where tools are converging that give us a lot of things out of the box that we’d otherwise need to move outside our application for. These are pragmatic 80-90% solutions. The normal solutions are still all there if you need to reach for them. But maybe you don’t. I see these as moves in the same vein:</p>
<ul>
<li>LiveView - We can reduce the amount of frontend we need to build that isn’t BEAM code (Elixir or Erlang), in some cases get rid of it entirely.</li>
<li>Live Dashboard - Application insights right in your application stack instead of pushing them out to another solution.</li>
<li>Phoenix PubSub - Distributed PubSub without requiring coordination via something like Redis.</li>
<li>Phoenix Channels - Distributed PubSub over WebSockets using the above PubSub to coordinate delivery.</li>
<li>Phoenix Presence - Distribute Presence. A CRDT-powered thing for maintaining information about if someone is connected to a channel or not, like chatrooms and online/offline. Using Channels.</li>
</ul>
<p>Lowering complexity by keeping the solutions in a system you understand well is potentially very powerful. At some point many projects will need to pick up external dependencies such as Nginx, Redis or whatever. But I think there is something compelling about building your application inside a system that can do all of it quite well. Elixir and Phoenix already have significant mind-share in the startup world. I wouldn’t be surprised if this ends up being a very popular solution for startups. No frontend-specific code for the MVP, no New Relic or Mixpanel bill we make do with the Live Dashboard. Distribution is Erlang distribution + Swarm/Horde/Libcluster or something …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://underjord.io/the-beam-marches-forward.html">https://underjord.io/the-beam-marches-forward.html</a></em></p>]]>
            </description>
            <link>https://underjord.io/the-beam-marches-forward.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925973</guid>
            <pubDate>Thu, 29 Oct 2020 01:03:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Trying More Leads You to Achieve Less]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24925858">thread link</a>) | @victorbreder
<br/>
October 28, 2020 | https://breder.org/1/ | <a href="https://web.archive.org/web/*/https://breder.org/1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>2020-10-26</p>

<p>For some weeks now I've been fantasizing about creating this blog. I've thought about creating an HTTP server from scratch just to serve it on a Linode instance, writing a static blog engine to generate the HTML from Markdown, besides every other kinds of over-engineering just for fun.</p>

<p>I've also compiled a list with a dozen blogs I enjoy the most. Then I've tried to distill what are their qualities that makes me enjoy them, and how I may achieve those in my own blog.</p>

<p>Well, as you may see, this is my first post. Doing all of the above lead me to not start any blog at all.</p>

<p>This may be called "analysis paralysis", "over-engineering" or "perfect is the enemy of the good". Whatever it may be, I'm done with it now.</p>

<p>The most valuable thing is to produce something and put it out in the world. All the planning, engineering, thinking exists just to support that. With no realization, no "getting started", ultimately there's no value to be generated at all.</p>

<p>This is obvious in hindsight, but it's very easy to forget this lesson.</p>

<p>So, what have <em>you</em> been putting off through planning and fantasizing? What is keeping you from just <em>doing</em> what you want to do? Can't you get started right now or are you avoiding it by doing easier things? And by doing what you are doing, are you generating any value for yourself or for anyone?</p>

</div></div>]]>
            </description>
            <link>https://breder.org/1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925858</guid>
            <pubDate>Thu, 29 Oct 2020 00:43:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Growth Mindset vs. Fixed Mindset: What Cognitive Psychology Tells Us]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24925855">thread link</a>) | @victorbreder
<br/>
October 28, 2020 | https://breder.org/2/ | <a href="https://web.archive.org/web/*/https://breder.org/2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>2020-10-26</p>

<p>The <em>Growth Mindset</em> research is one of the most impacting developments of cognitive psychology. Spearheaded by the decades of research of the psychologist Carol Dweck, it reveals how our <em>beliefs</em> about intelligence and skill shape our performance.</p>

<p>This research brilliantly sidesteps the long debate of "nature vs nurture", or how much are our intelligence, talent or skill brought up by our intrinsic genes or by our extrinsic environment and actions. The focus is on the <em>belief</em> itself that the individual holds.</p>

<p>Dweck has shown that individuals with a <em>Growth Mindset</em>, that believe that intelligence can be developed and skill is acquired through effortful practice, end up being more successful. This happens because such individuals tend to embrace challenges, push out of their zone of comfort and accept negative feedback.</p>

<p>On the other hand, individuals with a <em>Fixed Mindset</em>, that believe that intelligence is bestowed upon birth and not developed thereafter, end up being less successful. They tend to deal worse with setbacks, seeing failures as permanent testaments of their limitations. Because of this, they tend to avoid new situations and challenges above their level of skill. As a self-fulfilling prophecy, they end up not further developing their skills.</p>

<p>Dweck has also shown that we are strongly biased towards a Fixed Mindset, but with conscious effort it is possible to rewire ourselves to be more oriented towards a Growth Mindset. The psychologist has urged parents and teachers to instill in kids a Growth Mindset by praising the effort they put in instead of seemingly natural intelligence or talent.</p>

<p>The book <a href="https://www.amazon.com/gp/product/B000FCKPHG/">"Mindset: The New Psychology of Success"</a> is a great read and goes into details of how the Growth Mindset was studied and how one can become more growth-oriented.</p>

</div></div>]]>
            </description>
            <link>https://breder.org/2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925855</guid>
            <pubDate>Thu, 29 Oct 2020 00:43:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4.5-bil­lion-year-old ice on comet 'fluffi­er than cap­puc­ci­no froth']]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24925843">thread link</a>) | @sohkamyung
<br/>
October 28, 2020 | https://www.dlr.de/content/en/articles/news/2020/04/20201028_4_5-billion-year-old-ice-on-comet-fluffier-than-cappuccino-froth.html | <a href="https://web.archive.org/web/*/https://www.dlr.de/content/en/articles/news/2020/04/20201028_4_5-billion-year-old-ice-on-comet-fluffier-than-cappuccino-froth.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <section>
    <div>
        
                                                                                    
                                                                                                                                                                    
                                                            
                    







	<div>
		<div>
		    <div>
		        <div>
		        	

<div>
	




<picture>
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-s-path-on-comet-67p.jpg?__blob=normal&amp;v=2__ifc640w" media="(max-width: 640px)">
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-s-path-on-comet-67p.jpg?__blob=normal&amp;v=2__ifc1024w" media="(max-width: 1024px)">
	<img src="https://www.dlr.de/content/en/images/2020/4/philae-s-path-on-comet-67p.jpg?__blob=normal&amp;v=2__ifc1920w" alt="Philae’s path on comet 67P">
</picture>
	
	<div>
		<p><span>Phi­lae’s path on comet 67P</span></p>
		<p><span>Image</span>
		1/11,
		<span>Credit: </span>	





	
	
		ESA/Rosetta/MPS for OSIRIS Team MPS/UPD/LAM/IAA/SSO/INTA/UPM/DASP/IDA
	



	</p></div>
	<div>
		<div>
			<h3>Philae’s path on comet 67P</h3><p>
			The Phi­lae re­search mod­ule sep­a­rat­ed from ESA's Roset­ta or­biter on 12 Novem­ber 2014 in or­der to land on Comet 67P/Churyu­mov-Gerasi­menko. Af­ter sev­en hours of freefall, it touched the Ag­ilkia land­ing site (top left out­side the im­age) at walk­ing pace as planned. How­ev­er, Phi­lae could not an­chor it­self be­cause the an­chor har­poons pro­vid­ed for this pur­pose did not ac­ti­vate. Due to the low grav­i­ty, Phi­lae bounced off the sur­face, rose to a height of more than one kilo­me­tre, col­lid­ed with a cliff edge while falling, touched the comet's sur­face a sec­ond time (TD2) and fi­nal­ly came to a halt af­ter two hours (TD3). The lo­ca­tion of TD2 was un­known un­til re­cent­ly and could on­ly now be re­con­struct­ed. Phi­lae was lo­cat­ed in a place with suf­fi­cient sun­light to pro­duce enough en­er­gy to run its ten ex­per­i­ments for ap­prox­i­mate­ly 60 hours.
			
				</p>
			
		</div>
	</div>
</div>



<div>
	
		
	




		
			
				
				
					
						
					






				
			
		

    <div>
    	<p><span>Phi­lae's sec­ond touch­down site, be­fore ar­riv­ing at its fi­nal lo­ca­tion</span></p>
		<p><span>Video</span>
		2/11,
		<span>Credit: </span>
			





	
	
		Images: ESA/Rosetta/MPS for OSIRIS Team MPS/UPD/LAM/IAA/SSO/INTA/UPM/DASP/IDA; Analysis: O’Rourke et al (2020) 
	



	</p></div>

	
		<div>
			<div>
				<h3>Philae's second touchdown site, before arriving at its final location</h3>
				
					<p><strong>Credit: </strong>	





	
	
		Images: ESA/Rosetta/MPS for OSIRIS Team MPS/UPD/LAM/IAA/SSO/INTA/UPM/DASP/IDA; Analysis: O’Rourke et al (2020) 
	


</p>
				

				
					<p><strong>Length: </strong>00:00:28</p><p>
				
				Roset­ta’s Phi­lae lan­der touched down on Comet 67P/Churyu­mov-Gerasi­menko on 12 Novem­ber 2014 and made mul­ti­ple con­tacts with the sur­face be­fore ar­riv­ing at its fi­nal rest­ing place. Its sec­ond touch­down site was re­cent­ly iden­ti­fied just 30 me­tres away from its fi­nal po­si­tion. This an­i­ma­tion shows how Phi­lae flew across the sur­face to­wards skull face, in­ter­act­ing with the sur­face – as shown in the in­sets – be­fore ar­riv­ing at its fi­nal lo­ca­tion.
				</p>
			</div>
		</div>
	
</div>



<div>
	




<picture>
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philaes-two-minutes-on-td2.gif?__blob=normal&amp;v=2__ifc640w" media="(max-width: 640px)">
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philaes-two-minutes-on-td2.gif?__blob=normal&amp;v=2__ifc1024w" media="(max-width: 1024px)">
	<img src="https://www.dlr.de/content/en/images/2020/4/philaes-two-minutes-on-td2.gif?__blob=normal&amp;v=2__ifc1920w" alt="Philae’s two minutes on TD2 (Touchdown 2)">
</picture>
	
	<div>
		<p><span>Phi­lae’s two min­utes on TD2 (Touch­down 2)</span></p>
		<p><span>Image</span>
		3/11,
		<span>Credit: </span>	





	
	
		 Images: ESA/Rosetta/MPS for OSIRIS Team MPS/UPD/LAM/IAA/SSO/INTA/UPM/DASP/IDA; Data: ESA/Rosetta/Philae/ROMAP; Analysis: O’Rourke et al (2020)
	



	</p></div>
	<div>
		<div>
			<h3>Philae’s two minutes on TD2 (Touchdown 2)</h3><p>
			An­i­ma­tion show­ing how Roset­ta’s Phi­lae lan­der moved through touch­down site two on Comet 67P/Churyu­mov-Gerasi­menko on 12 Novem­ber 2014. Ini­tial­ly trav­el­ling in a down­ward di­rec­tion, Phi­lae slides down the edge of a boul­der (1) and flips ver­ti­cal­ly, ro­tat­ing like a wind­mill to pass be­tween two boul­ders (2) ex­pos­ing lay­ers of ice in the crevice walls with its feet. A dust wall was cre­at­ed by the wind­mill ac­tion, push­ing through the dust that had heaped up be­tween the boul­ders up to that point in time. The crevice is about 2.5 m long and is curved with a width of 1–1.5 m, al­low­ing Phi­lae to pass through. Phi­lae then stamps a 25 cm im­print of the top of the lan­der in­to the comet’s sur­face (3) – a hole made by the top of the SD2 (Sam­pling, Drilling and Dis­tri­bu­tion de­vice) tow­er that sticks up above the top of Phi­lae can be recog­nised. Phi­lae then climbed out of the crevice, knock­ing off ma­te­ri­al from an over­hang (4a) and was pushed down again with its top sur­face, cre­at­ing an im­pres­sion in the dust cor­re­spond­ing to the ‘eye’ of the fea­ture that re­sem­bles a skull (4b).
			
				</p>
			
		</div>
	</div>
</div>


<div>
	




<picture>
	<source srcset="https://www.dlr.de/content/en/images/2020/4/comet-ice-in-the-shape-of-a-skull-on-67p.gif?__blob=normal&amp;v=3__ifc640w" media="(max-width: 640px)">
	<source srcset="https://www.dlr.de/content/en/images/2020/4/comet-ice-in-the-shape-of-a-skull-on-67p.gif?__blob=normal&amp;v=3__ifc1024w" media="(max-width: 1024px)">
	<img src="https://www.dlr.de/content/en/images/2020/4/comet-ice-in-the-shape-of-a-skull-on-67p.gif?__blob=normal&amp;v=3__ifc1920w" alt="Comet ice in the shape of a skull on 67P">
</picture>
	
	<div>
		<p><span>Comet ice in the shape of a skull on 67P</span></p>
		<p><span>Image</span>
		4/11,
		<span>Credit: </span>	





	
	
		ESA/Rosetta/MPS for OSIRIS Team MPS/UPD/LAM/IAA/SSO/INTA/UPM/DASP/IDA; O’Rourke et al (2020)
	



	</p></div>
	<div>
		<div>
			<h3>Comet ice in the shape of a skull on 67P</h3><p>
			Roset­ta’s Phi­lae lan­der touched down on Comet 67P/Churyu­mov-Gerasi­menko on 12 Novem­ber 2014 and made mul­ti­ple con­tacts with the sur­face be­fore ar­riv­ing at its fi­nal rest­ing place. The comet to­pog­ra­phy at Phi­lae’s sec­ond touch­down site re­sem­bles the shape of a skull with a point­ed ‘hat’ when viewed from above. This gif shows the fea­ture that re­sem­bles a skull face, with Phi­lae su­per­im­posed for scale (Phi­lae’s ‘body’ mea­sures about 1 m across, and each leg is 1.5 m long). Phi­lae’s body com­pressed in­to the ice-dust scenery to cre­ate the skull’s right eye. The dark re­gion just above the skull’s right eye is the en­trance to a gap be­tween the two boul­ders nick­named ‘skull-top ridge’, where Phi­lae act­ed like a wind­mill to pass be­tween them.
			
				</p>
			
		</div>
	</div>
</div>


<div>
	




<picture>
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-s-contact-with-the-comet-put-into-regional-context.jpg?__blob=normal&amp;v=3__ifc640w" media="(max-width: 640px)">
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-s-contact-with-the-comet-put-into-regional-context.jpg?__blob=normal&amp;v=3__ifc1024w" media="(max-width: 1024px)">
	<img src="https://www.dlr.de/content/en/images/2020/4/philae-s-contact-with-the-comet-put-into-regional-context.jpg?__blob=normal&amp;v=3__ifc1920w" alt="Philae’s contact with the comet put into regional context">
</picture>
	
	<div>
		<p><span>Phi­lae’s con­tact with the comet put in­to re­gion­al con­text</span></p>
		<p><span>Image</span>
		5/11,
		<span>Credit: </span>	





	
	
		Images: Touchdown 1: ESA/Rosetta/Philae/ROLIS/DLR; all other images: ESA/Rosetta/MPS for OSIRIS Team MPS/UPD/LAM/IAA/SSO/INTA/UPM/DASP/IDA; Analysis: O’Rourke et al (2020)
	



	</p></div>
	<div>
		<div>
			<h3>Philae’s contact with the comet put into regional context</h3><p>
			Phi­lae’s flight across the sur­face of Comet 67P/Churyu­mov-Gerasi­menko on 12 Novem­ber 2014 saw the lan­der strike the sur­face in mul­ti­ple lo­ca­tions. This graph­ic sum­maris­es the main touch­down sites. At 15:35 UTC Phi­lae made first con­tact with the sur­face at Ag­ilkia – the im­age shown here was tak­en by Phi­lae’s own cam­era, RO­LIS, be­fore touch­down, ap­prox­i­mate­ly 40 me­tres from the sur­face. Phi­lae then took flight across the Hat­mehit de­pres­sion on the ‘top’ of the small comet lobe, col­lid­ing with a cliff edge at 16:20 UTC. This set it on course with the sec­ond touch­down site, where it in­ter­act­ed with the sur­face mul­ti­ple times over a pe­ri­od of two min­utes start­ing at around 17:24 UTC. Phi­lae ar­rived at its fi­nal rest­ing place at Aby­dos, about 30 m away, at 17:31 UTC. The im­age has been en­hanced to al­low Phi­lae, hid­ing in the shad-ows just 30 me­tres away from the sec­ond touch­down lo­ca­tion, to be seen.
			
				</p>
			
		</div>
	</div>
</div>


<div>
	




<picture>
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-leaves-traces-at-contact-point-two.jpg?__blob=normal&amp;v=2__ifc640w" media="(max-width: 640px)">
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-leaves-traces-at-contact-point-two.jpg?__blob=normal&amp;v=2__ifc1024w" media="(max-width: 1024px)">
	<img src="https://www.dlr.de/content/en/images/2020/4/philae-leaves-traces-at-contact-point-two.jpg?__blob=normal&amp;v=2__ifc1920w" alt="Philae leaves traces at contact point two">
</picture>
	
	<div>
		<p><span>Phi­lae leaves traces at con­tact point two</span></p>
		<p><span>Image</span>
		6/11,
		<span>Credit: </span>	





	
	
		Images: ESA/Rosetta/MPS for OSIRIS Team MPS/UPD/LAM/IAA/SSO/INTA/UPM/DASP/IDA; Daten: ESA/Rosetta/Philae/ROMAP; Analysis: O’Rourke et al. (2020)
	



	</p></div>
	<div>
		<div>
			<h3>Philae leaves traces at contact point two</h3><p>
			This com­pi­la­tion shows the mea­sure­ments record­ed by Phi­lae's ROMAP in­stru­ment – a mag­ne­tome­ter with a boom – dur­ing the sec­ond touch­down on Comet 67P/Churyu­mov-Gerasi­menko on 12 Novem­ber 2014, along­side OSIRIS im­ages tak­en lat­er, which show ev­i­dence of the key mo­ments of Phi­lae's con­tacts with the sur­face (and the re­con­struct­ed po­si­tions of Phi­lae pro­ject­ed on­to them). Sig­na­tures rel­a­tive to the lan­der were record­ed in the mag­ne­tome­ter da­ta from the ROMAP boom when the boom phys­i­cal­ly moved by hit­ting an ob­sta­cle on the sur­face, bend­ing slight­ly (the boom pro­trudes 48 cen­time­tres from the lan­der). This pro­duced a char­ac­ter­is­tic set of 'peaks' in the ROMAP da­ta, which pro­vid­ed an es­ti­mate of the du­ra­tion of Phi­lae's pen­e­tra­tion of the ice. The da­ta could al­so be used to es­ti­mate the ac­cel­er­a­tion of Phi­lae dur­ing these con­tacts. They show that Phi­lae spent al­most two full min­utes at touch­down point two and made con­tact with the sur­face sev­er­al times. Phi­lae first moved down­wards, slid­ing down the edge of a cliff (1) and ro­tat­ing ver­ti­cal­ly like a wind­mill to pass be­tween two boul­ders (2), ex­pos­ing lay­ers of ice in the crevices with its spi­der legs. The 'wind­mill ac­tion' cre­at­ed a wall of dust through which Phi­lae pushed it­self. The gap is ap­prox­i­mate­ly 2.5 me­tres long, curved, and has a width of 1–1.5 me­tres. Then Phi­lae pushed a 25-cen­time­tre im­print of the top of the lan­der in­to the sur­face of the comet (3) – a hole cre­at­ed by the top of the SD2 (Sam­pling, Drilling and Dis­tri­bu­tion De­vice) tow­er. Phi­lae then rose out of the crevice, was pressed down again by an over­hang (4a), its up­per sur­face cre­at­ing an im­pres­sion in the dust that pressed the 'eye' in­to the skull (4b).
			
				</p>
			
		</div>
	</div>
</div>


<div>
	




<picture>
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-s-magnetometer-measurements-on-td2.jpg?__blob=normal&amp;v=4__ifc640w" media="(max-width: 640px)">
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-s-magnetometer-measurements-on-td2.jpg?__blob=normal&amp;v=4__ifc1024w" media="(max-width: 1024px)">
	<img src="https://www.dlr.de/content/en/images/2020/4/philae-s-magnetometer-measurements-on-td2.jpg?__blob=normal&amp;v=4__ifc1920w" alt="Philae’s magnetometer measurements on TD2">
</picture>
	
	<div>
		<p><span>Phi­lae’s mag­ne­tome­ter mea­sure­ments on TD2</span></p>
		<p><span>Image</span>
		7/11,
		<span>Credit: </span>	





	
	
		ESA/Rosetta/Philae/ROMAP
	



	</p></div>
	<div>
		<div>
			<h3>Philae’s magnetometer measurements on TD2</h3><p>
			The high­ly sen­si­tive mag­ne­tome­ter ROMAP built un­der the di­rec­tion of the Tech­ni­cal Uni­ver­si­ty of Braun­schweig for the Roset­ta mis­sion was switched on dur­ing Phi­lae's de­scent from the or­biter to the comet's sur­face. It con­tin­u­ous­ly record­ed the (very weak) mag­net­ic field da­ta in three ax­i­al di­rec­tions (mag­net­ic field com­po­nent in x-di­rec­tion = blue, y = or­ange, z = grey) with a mea­sur­ing rod al­most half a me­tre long from the first con­tact with the sur­face un­til the probe came to a fi­nal stand­still. The scale on the left in­di­cates the mag­ni­tude of the mag­net­ic flux den­si­ty in the unit nan­otes­la. For com­par­i­son: the in­ter­stel­lar medi­um has a mag­net­ic field strength of up to 10 nan­otes­la, while the Earth's mag­net­ic field has about five thou­sand times this val­ue in Ger­many. From the mea­sure­ments, it was pos­si­ble to re­con­struct the course of the bumpy on­ward flight of Phi­lae down to the sec­ond af­ter the first touch­down. Now the long-sought ‘touch­down point 2’ (TD2) has al­so be …</p></div></div></div></div></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dlr.de/content/en/articles/news/2020/04/20201028_4_5-billion-year-old-ice-on-comet-fluffier-than-cappuccino-froth.html">https://www.dlr.de/content/en/articles/news/2020/04/20201028_4_5-billion-year-old-ice-on-comet-fluffier-than-cappuccino-froth.html</a></em></p>]]>
            </description>
            <link>https://www.dlr.de/content/en/articles/news/2020/04/20201028_4_5-billion-year-old-ice-on-comet-fluffier-than-cappuccino-froth.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925843</guid>
            <pubDate>Thu, 29 Oct 2020 00:41:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating Realistic Test Traffic Using Markov Chains]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24925655">thread link</a>) | @tinrab
<br/>
October 28, 2020 | https://outcrawl.com/markov-chains-test-traffic/ | <a href="https://web.archive.org/web/*/https://outcrawl.com/markov-chains-test-traffic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This article shows how you can generate realistic user traffic for testing purposes by sampling requests in production and generating fake ones using <a href="https://en.wikipedia.org/wiki/Markov_chain">Markov chains</a>.</p>
<p>Example code is available on <a href="https://github.com/tinrab/rusty-markov-traffic">GitHub</a>.</p>
<h2 id="Markov-chains">Markov chains<a href="#Markov-chains" aria-label="Markov chains permalink"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 4 24 16"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2>
<p>A Markov chain is a stochastic model telling us probability of an event based on previously observed events.
Probability of next event <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">X_{n+1}</annotation></semantics></math></span></span> is determined by last known event <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>X</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(X_{n+1}|X_{n})</annotation></semantics></math></span></span> or previous <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> events, which gives us a Markov chain of order <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span>:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>n</mi></msub><mo>=</mo><msub><mi>x</mi><mi>n</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>X</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>X</mi><mrow><mi>n</mi><mo>−</mo><mi>m</mi></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>−</mo><mi>m</mi></mrow></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>n</mi><mo>&gt;</mo><mi>m</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">P(X_{n}=x_{n}|X_{n-1}=x_{n-1},...,X_{n-m}=x_{n-m}), n\gt m.</annotation></semantics></math></span></span></span></p><p>We can track actual user behaviour and build a model by counting events and calculating weighted probabilities for each event based on events preceding them.</p>
<p>For example, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span></span> users finished writing a blog post.
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn></mrow><annotation encoding="application/x-tex">9</annotation></semantics></math></span></span> users later published it and one of them trashed it.
This gives us probabilities <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>P</mi><mi>o</mi><mi>s</mi><mi>t</mi><mi>P</mi><mi>u</mi><mi>b</mi><mi>l</mi><mi>i</mi><mi>s</mi><mi>h</mi><mi>e</mi><mi>d</mi><mi mathvariant="normal">∣</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>t</mi><mi>F</mi><mi>i</mi><mi>n</mi><mi>i</mi><mi>s</mi><mi>h</mi><mi>e</mi><mi>d</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0.9</mn></mrow><annotation encoding="application/x-tex">P(PostPublished|PostFinished)=0.9</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>P</mi><mi>o</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>r</mi><mi>a</mi><mi>s</mi><mi>h</mi><mi>e</mi><mi>d</mi><mi mathvariant="normal">∣</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>t</mi><mi>F</mi><mi>i</mi><mi>n</mi><mi>i</mi><mi>s</mi><mi>h</mi><mi>e</mi><mi>d</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">P(PostTrashed|PostFinished)=0.1</annotation></semantics></math></span></span>.
We can then selected a random event with <a href="https://en.wikipedia.org/wiki/Fitness_proportionate_selection">roulette wheel selection</a>.</p>
<p>This is useful for stress or smoke testing when you need some fake traffic that resembles real users.</p>
<h2 id="Implementation">Implementation<a href="#Implementation" aria-label="Implementation permalink"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 4 24 16"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2>
<p>Let's declare a struct for a Markov chain.
Map <code>occurrences</code> will hold event counts <code>BTreeMap&lt;T, usize&gt;</code> for any previous series of events <code>Vec&lt;T&gt;</code>.</p>
<div data-language="rust"><pre><code><span>#[derive(Clone)]</span>
<span>pub</span> <span>struct</span> MarkovChain<span>&lt;</span>T<span>&gt;</span>
<span>where</span>
    T<span>:</span> Clone <span>+</span> Ord<span>,</span>
<span>{</span>
    order<span>:</span> <span>usize</span><span>,</span>
    occurrences<span>:</span> BTreeMap<span>&lt;</span>Vec<span>&lt;</span>T<span>&gt;</span><span>,</span> BTreeMap<span>&lt;</span>T<span>,</span> <span>usize</span><span>&gt;&gt;</span><span>,</span>
    memory<span>:</span> Vec<span>&lt;</span>T<span>&gt;</span><span>,</span>
    rng<span>:</span> ThreadRng<span>,</span>
<span>}</span></code></pre></div>
<p>To build a model we have to go through all observed events and count the number of times <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span>-th event occured after all <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>&gt;</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">n&gt;m</annotation></semantics></math></span></span> events.
We also track last known <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> events inside the <code>memory</code> vector, which will be used to generate the next event.</p>
<div data-language="rust"><pre><code><span>impl</span><span>&lt;</span>T<span>&gt;</span> MarkovChain<span>&lt;</span>T<span>&gt;</span>
<span>where</span>
    T<span>:</span> Clone <span>+</span> Ord<span>,</span>
<span>{</span>
    <span>pub</span> <span>fn</span> <span>update</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> events<span>:</span> <span>&amp;</span><span>[</span>T<span>]</span><span>)</span> <span>{</span>
        <span>let</span> events<span>:</span> Vec<span>&lt;</span>_<span>&gt;</span> <span>=</span> events<span>.</span><span>to_vec</span><span>(</span><span>)</span><span>;</span>
        <span>for</span> history <span>in</span> events<span>.</span><span>windows</span><span>(</span><span>self</span><span>.</span>order <span>+</span> <span>1</span><span>)</span> <span>{</span>
            
            <span>let</span> previous <span>=</span> history<span>[</span><span>0</span><span>..</span><span>self</span><span>.</span>order<span>]</span><span>.</span><span>to_vec</span><span>(</span><span>)</span><span>;</span>
            <span>let</span> current <span>=</span> history<span>.</span><span>last</span><span>(</span><span>)</span><span>.</span><span>cloned</span><span>(</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
            
            <span>self</span><span>.</span>occurrences
                <span>.</span><span>entry</span><span>(</span>previous<span>)</span>
                <span>.</span><span>or_default</span><span>(</span><span>)</span>
                <span>.</span><span>entry</span><span>(</span>current<span>)</span>
                <span>.</span><span>and_modify</span><span>(</span><span><span>|</span>count<span>|</span></span> <span>*</span>count <span>+=</span> <span>1</span><span>)</span>
                <span>.</span><span>or_insert</span><span>(</span><span>1</span><span>)</span><span>;</span>
        <span>}</span>
        
        <span>self</span><span>.</span>memory<span>.</span><span>reserve</span><span>(</span><span>self</span><span>.</span>order<span>)</span><span>;</span>
        <span>for</span> event <span>in</span> events<span>.</span><span>into_iter</span><span>(</span><span>)</span><span>.</span><span>rev</span><span>(</span><span>)</span><span>.</span><span>take</span><span>(</span><span>self</span><span>.</span>order<span>)</span> <span>{</span>
            <span>self</span><span>.</span>memory<span>.</span><span>insert</span><span>(</span><span>0</span><span>,</span> event<span>)</span><span>;</span>
        <span>}</span>
        <span>self</span><span>.</span>memory<span>.</span><span>truncate</span><span>(</span><span>self</span><span>.</span>order<span>)</span><span>;</span>
    <span>}</span>
    </code></pre></div>
<p>The <code>generate_from</code> function takes in the memory, finds occurrences and chooses an event from those.
We use <a href="https://docs.rs/rand/0.7.3/rand/seq/trait.SliceRandom.html#tymethod.choose_weighted">choose_weighted</a> function provided by the <a href="https://crates.io/crates/rand">rand</a> crate.</p>
<div data-language="rust"><pre><code><span>pub</span> <span>fn</span> <span>generate_from</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> memory<span>:</span> <span>&amp;</span><span>[</span>T<span>]</span><span>)</span> <span>-&gt;</span> Option<span>&lt;</span>T<span>&gt;</span> <span>{</span>
    <span>assert_eq!</span><span>(</span>memory<span>.</span><span>len</span><span>(</span><span>)</span><span>,</span> <span>self</span><span>.</span>order<span>,</span> <span>"invalid memory size"</span><span>)</span><span>;</span>
    <span>if</span> <span>let</span> Some<span>(</span>occurrences<span>)</span> <span>=</span> <span>self</span><span>.</span>occurrences<span>.</span><span>get</span><span>(</span>memory<span>)</span> <span>{</span>
        
        
        <span>let</span> occurrence_counts<span>:</span> Vec<span>&lt;</span>_<span>&gt;</span> <span>=</span> occurrences
            <span>.</span><span>iter</span><span>(</span><span>)</span>
            <span>.</span><span>map</span><span>(</span><span><span>|</span>(event, count)<span>|</span></span> <span>(</span>event<span>.</span><span>clone</span><span>(</span><span>)</span><span>,</span> <span>*</span>count<span>)</span><span>)</span>
            <span>.</span><span>collect</span><span>(</span><span>)</span><span>;</span>
        
        occurrence_counts
            <span>.</span><span>choose_weighted</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>.</span>rng<span>,</span> <span><span>|</span>(_, count)<span>|</span></span> <span>*</span>count<span>)</span>
            <span>.</span><span>map</span><span>(</span><span><span>|</span>(event, _)<span>|</span></span> event<span>)</span>
            <span>.</span><span>ok</span><span>(</span><span>)</span>
            <span>.</span><span>cloned</span><span>(</span><span>)</span>
    <span>}</span> <span>else</span> <span>{</span>
        
        None
    <span>}</span>
<span>}</span></code></pre></div>
<p>After generating a new event, we update the internal memory.
Next events will then be calculated from the most recent memory.</p>
<div data-language="rust"><pre><code><span>pub</span> <span>fn</span> <span>generate</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> update_memory<span>:</span> <span>bool</span><span>)</span> <span>-&gt;</span> Option<span>&lt;</span>T<span>&gt;</span> <span>{</span>
    <span>let</span> last_memory <span>=</span> <span>self</span><span>.</span>memory<span>.</span><span>clone</span><span>(</span><span>)</span><span>;</span>
    <span>if</span> <span>let</span> Some<span>(</span>next<span>)</span> <span>=</span> <span>self</span><span>.</span><span>generate_from</span><span>(</span><span>&amp;</span>last_memory<span>)</span> <span>{</span>
        <span>if</span> update_memory <span>{</span>
            
            <span>self</span><span>.</span>memory<span>.</span><span>insert</span><span>(</span><span>0</span><span>,</span> next<span>.</span><span>clone</span><span>(</span><span>)</span><span>)</span><span>;</span>
            <span>self</span><span>.</span>memory<span>.</span><span>truncate</span><span>(</span><span>self</span><span>.</span>order<span>)</span><span>;</span>
        <span>}</span>
        Some<span>(</span>next<span>)</span>
    <span>}</span> <span>else</span> <span>{</span>
        None
    <span>}</span>
<span>}</span></code></pre></div>
<p>We can also write an iterator that returns generated events.</p>
<div data-language="rust"><pre><code><span>pub</span> <span>struct</span> MarkovChainIter<span>&lt;</span><span>'a</span><span>,</span> T<span>&gt;</span>
<span>where</span>
    T<span>:</span> Clone <span>+</span> Ord<span>,</span>
<span>{</span>
    chain<span>:</span> <span>&amp;</span><span>'a</span> <span>mut</span> MarkovChain<span>&lt;</span>T<span>&gt;</span><span>,</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>'a</span><span>,</span> T<span>&gt;</span> Iterator <span>for</span> MarkovChainIter<span>&lt;</span><span>'a</span><span>,</span> T<span>&gt;</span>
<span>where</span>
    T<span>:</span> Clone <span>+</span> Ord<span>,</span>
<span>{</span>
    <span>type</span> Item <span>=</span> T<span>;</span>

    <span>fn</span> <span>next</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Option<span>&lt;</span><span>Self</span><span>::</span>Item<span>&gt;</span> <span>{</span>
        <span>self</span><span>.</span>chain<span>.</span><span>generate</span><span>(</span><span>true</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>impl</span><span>&lt;</span>T<span>&gt;</span> MarkovChain<span>&lt;</span>T<span>&gt;</span>
<span>where</span>
    T<span>:</span> Clone <span>+</span> Ord<span>,</span>
<span>{</span>
    <span>pub</span> <span>fn</span> <span>iter</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> MarkovChainIter<span>&lt;</span>T<span>&gt;</span> <span>{</span>
        MarkovChainIter <span>{</span> chain<span>:</span> <span>self</span> <span>}</span>
    <span>}</span>
    
<span>}</span></code></pre></div>
<h2 id="Example">Example<a href="#Example" aria-label="Example permalink"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 4 24 16"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2>
<p>To see it in action, we declare an enum of all possible actions.
Of course, these can be way more complicated in the real world use-case.</p>
<div data-language="rust"><pre><code><span>#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]</span>
<span>enum</span> UserAction <span>{</span>
    SignIn<span>,</span>
    SignOut<span>,</span>
    CreateTodo<span>,</span>
    DeleteTodo<span>,</span>
    ListTodos<span>,</span>
<span>}</span></code></pre></div>
<p>We build a chain from a sample of actions.</p>
<div data-language="rust"><pre><code><span>let</span> <span>mut</span> chain <span>=</span> MarkovChain<span>::</span><span>new</span><span>(</span><span>1</span><span>)</span><span>;</span>
<span>let</span> actions <span>=</span> <span>vec!</span><span>[</span>
    UserAction<span>::</span>SignIn<span>,</span>
    UserAction<span>::</span>ListTodos<span>,</span>
    UserAction<span>::</span>CreateTodo<span>,</span>
    UserAction<span>::</span>CreateTodo<span>,</span>
    UserAction<span>::</span>SignOut<span>,</span>
    UserAction<span>::</span>SignIn<span>,</span>
    UserAction<span>::</span>ListTodos<span>,</span>
    UserAction<span>::</span>DeleteTodo<span>,</span>
    UserAction<span>::</span>DeleteTodo<span>,</span>
    UserAction<span>::</span>CreateTodo<span>,</span>
    UserAction<span>::</span>CreateTodo<span>,</span>
    UserAction<span>::</span>SignOut<span>,</span>
    UserAction<span>::</span>SignIn<span>,</span>
    UserAction<span>::</span>ListTodos<span>,</span>
    UserAction<span>::</span>CreateTodo<span>,</span>
    UserAction<span>::</span>DeleteTodo<span>,</span>
    UserAction<span>::</span>CreateTodo<span>,</span>
    UserAction<span>::</span>DeleteTodo<span>,</span>
    UserAction<span>::</span>ListTodos<span>,</span>
    UserAction<span>::</span>DeleteTodo<span>,</span>
    UserAction<span>::</span>SignOut<span>,</span>
<span>]</span><span>;</span>
chain<span>.</span><span>update</span><span>(</span><span>&amp;</span>actions<span>)</span><span>;</span></code></pre></div>
<p>Then generate a few actions.</p>
<div data-language="rust"><pre><code><span>for</span> action <span>in</span> chain<span>.</span><span>iter</span><span>(</span><span>)</span><span>.</span><span>take</span><span>(</span><span>16</span><span>)</span> <span>{</span>
    <span>if</span> action <span>==</span> UserAction<span>::</span>SignIn <span>{</span>
        <span>println!</span><span>(</span><span>"## New session ##"</span><span>)</span><span>;</span>
    <span>}</span>
    <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> action<span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>Which gives us the following output.</p>
<div data-language="bash"><pre><code><span><span data-user="root" data-host="localhost"></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span>cargo run --example traffic

SignIn
ListTodos
DeleteTodo
SignOut

SignIn
ListTodos
DeleteTodo
DeleteTodo
CreateTodo
SignOut

SignIn
ListTodos
CreateTodo
CreateTodo
CreateTodo
DeleteTodo</code></pre></div>
<p>Notice how after each <code>SignIn</code> there's a <code>ListTodos</code>, which means <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>L</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>o</mi><mi>d</mi><mi>o</mi><mi>s</mi><mi mathvariant="normal">∣</mi><mi>S</mi><mi>i</mi><mi>g</mi><mi>n</mi><mi>I</mi><mi>n</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">P(ListTodos|SignIn)=1</annotation></semantics></math></span></span>.
Built model can represent inherent rules of our application.
Some series of actions will not be generated, those having probability <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span>, which is a lot better than uniformly generated random data.</p>
<p>Some combination of actions might not be possible, because they'd break business rules.
Those can be filtered out, or left in to test invalid requests.</p>
<h2 id="Conclusion">Conclusion<a href="#Conclusion" aria-label="Conclusion permalink"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 4 24 16"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2>
<p>We can do much more with this.
This was only a brief introduction to a handy tool that can be used to generate some fake requests.</p>
<p>Sample code is available on <a href="https://github.com/tinrab/rusty-markov-traffic">GitHub</a>.</p></div></div>]]>
            </description>
            <link>https://outcrawl.com/markov-chains-test-traffic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925655</guid>
            <pubDate>Thu, 29 Oct 2020 00:10:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The idea DOES matter: How I pre-validate my SaaS startup ideas with a checklist]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24925642">thread link</a>) | @alfarez
<br/>
October 28, 2020 | https://farez.me/how-to-pick-a-saas-startup-idea-a-pre-validation-checklist/ | <a href="https://web.archive.org/web/*/https://farez.me/how-to-pick-a-saas-startup-idea-a-pre-validation-checklist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://farez.me/content/images/size/w300/2020/10/cover.jpg 300w,
                            https://farez.me/content/images/size/w600/2020/10/cover.jpg 600w,
                            https://farez.me/content/images/size/w1000/2020/10/cover.jpg 1000w,
                            https://farez.me/content/images/size/w2000/2020/10/cover.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://farez.me/content/images/size/w2000/2020/10/cover.jpg" alt="How I evaluate my SaaS startup ideas with a pre-validation checklist">
            </figure>

            <section>
                <div>
                    <p>For founders, this question comes up a lot:</p><blockquote>“I have too many startup ideas. I don’t know which idea to focus on.”</blockquote><p>It certainly did for me. </p><p>I have been building SaaS products for the last few years, with bad to mediocre results. Each one taught me something new. Each one revealed one or two factors about the idea that I wish I knew BEFORE working on it.</p><p>For example, if there is a HUGE population with the problem I'm solving, then there's a better chance of me surviving despite incumbents and competitors. Larger pie, more slices to go round.</p><p>If I had known how to evaluate these ideas beforehand, I would have saved a lot of time. It won't be a guarantee of success, but it would have helped increase my odds.</p><p>I wanted to know what else I should know before starting work on an idea, so I researched articles, podcasts and videos with successful founders to find out how they evaluate ideas.</p><p>The result is a <strong>30-point checklist</strong>, curated from over 40 founders, that I want to share with you below. </p><p>Having a list makes it easy, and even fun, to evaluate your ideas in a structured and repeatable way. Think of it as <strong>due diligence</strong> you're doing before investing your time in your idea.</p><h2 id="but-ideas-don-t-matter-execution-does-">"But ideas don't matter. Execution does!"</h2><p>The intention of this advice is good, but, I feel this is misleading.</p><p>Given two ideas, executing on the one that has a better chance of succeeding will yield better results. Executing on a bad idea wastes time, money, and motivation.</p><p>Would you not want to know if an idea is a "good idea" before you spend lots of time and money trying to validate it?</p><p>If you think evaluating an idea before investing time and money in it isn't practical, then tell that to angel investors. They have to - they can't afford to give away money based on hunches. In their world, it's called due diligence.</p><blockquote>"Ideas mean everything and nothing at the same time. They mean everything, because you can 10x your odds of success by simply picking a better one. They mean nothing, because with bad execution you'll achieve nothing, no matter how good the idea." — Alex West, <a href="http://cyberleads.co/">cyberleads.co</a></blockquote><h2 id="the-saas-idea-evaluation-checklist">The SaaS idea evaluation checklist</h2><p>So here's the list I'm using. I have grouped them into 3 groups:</p><ul><li>Must-haves: Don't even start without having all of these.</li><li>Should-haves: The more you have of these, the better your chances.</li><li>Nice-to-haves: Not essential, but really helps if you do have them.</li></ul><h3 id="must-haves">Must-haves</h3><p>1. <strong>Solves a very specific problem</strong>. What's the specific problem you are aiming to solve?</p><p>2. <strong>Targets a very specific niche</strong>. Which specific group of people has that problem?</p><p>3. <strong>Has a large enough market</strong>. How big is this market? Is it enough to meet your business goal? A large market also means there's room for competitors.</p><p>4. <strong>Will generate profit</strong>. How much will it cost to run this business, and will you be able to turn a profit? Obvious, but a surprising number of founders don't work this out until much later!</p><p>5. <strong>Can operate profitably without the founder</strong>. Can this business grow profitably without you?</p><h3 id="should-haves">Should-haves</h3><p>6. <strong>Solves my own problem</strong>. Are you building this for yourself? Great start if you are!</p><p>7. <strong>"Hair on fire" problem</strong>. Will your customers need your solution urgently? Or is it not that important?</p><p>8. <strong>Frequently occurring problem</strong>. How often does someone have this problem? Hourly, daily, or at most weekly, would be best.</p><p>9. <strong>Growing market with this problem</strong>. More and more people are having this problem every day. More and more people will want your solution.</p><p>10. <strong>This is a mandatory problem</strong>. For example, this there's been a change in law and your customers need a solution. Like GDPR.</p><p>11. <strong>Customers are small businesses</strong>. These are the best customers to have because they have money, are motivated to spend, and has short lead times.</p><p>12. <strong>Founder has built an audience in target group</strong>. Do you already have followers or subscribers that have this problem.</p><p>13. <strong>Can be launched quickly</strong>. The faster you can launch, the quicker you can learn, and the quicker you get to revenue.</p><p>14. <strong>Clear customer acquisition channel</strong>. You can think of at least one obvious way to reach your target customers and offer your solution.</p><p>15. <strong>Founder - market fit</strong>. Do you know this market well?</p><p>16. <strong>Founder - product fit</strong>. Are you the right person to create this solution? Do you need to build a team?</p><p>17. <strong>Founder unfair advantage</strong>. Are you one of only a handful of people who can build on this idea? E.g. you own a patent.</p><p>18. <strong>You love serving this market</strong>. Will you enjoy talking to and serving this group of customers day in and day out? Do you genuinely want to help them?</p><p>19. <strong>Market is proven</strong>. Are people already paying money to solve this problem? Are your competitors making tonnes of money?</p><p>20. <strong>Arduous but not impossible</strong>. Is this a problem that not many people want to solve because it's so troublesome? Is it a solution that requires a lot of "<a href="http://paulgraham.com/schlep.html">schlep</a>"?</p><p>21. <strong>Unique value proposition</strong>. Are you providing novel solution to the problem? Perhaps focusing on a small part of the bigger problem and providing a focused, but effective, solution?</p><p>22. <strong>Can be a sellable asset</strong>. Can this business become an asset that you can sell later?</p><p>23. <strong>No monopolies</strong>. Are the incumbents monopolies that can wipe you out in 2 seconds?</p><h3 id="nice-to-haves">Nice-to-haves</h3><p>24. <strong>Market is highly motivated</strong>. The market is willing to spend money on anything that will improve their lives or work.</p><p>25. <strong>The market has the purchasing power</strong>. They have the money to spend on your solution.</p><p>26. <strong>Able to pre-sell the solution</strong>. Are you able to pre-sell the solution, as a way to validate demand?</p><p>27. <strong>The problem is not sexy</strong>. Sexy products get people excited, but also attracts more competitors. There's money being made on problems that don't get mentioned in TechCrunch or Wired.</p><p>28. <strong>The solution is simple</strong>. Is your solution simpler to understand and use than your competitor's?</p><p>29. <strong>Target customers exist as communities</strong>. Do your customers hang out online together? This helps with word of mouth traffic.</p><p>30. <strong>Quick time to first customer</strong>. Are you able to get your first paying customer within 4 weeks? Or quicker, relative to your other ideas?</p><h2 id="how-to-use-this-checklist">How to use this checklist</h2><p>To make it easy for you, I have created a checklist in a Google Sheet with all the criteria above. Just make a copy of it and then use it to quickly tick off attributes of your idea, and to find gaps in research that you may need to do. I've included one idea as an example - a simple Shopify analytics app for store owners.</p><p><strong>✅ </strong><a href="https://docs.google.com/spreadsheets/d/101Hi6atV5cY3R4Fb39jWv7slS2Tth3Ti54fAMrVODno/edit?usp=sharing"><strong>Get the SaaS Idea Evaluation Sheet here</strong></a><strong>.</strong></p><p>Here's how I use the scoring sheet:</p><ul><li>As a way to score and compare my ideas before I pick the next one to work on. For this, I assign points to the criteria in each category and then just sum up the ones that the idea has.</li><li>As a checklist for questions I should be asking myself.</li><li>As a way to evaluate other people's ideas, when they ask, "do you think this is a good idea?".</li></ul><blockquote>"The Idea Matters - A bad idea, executed well, will not make a good business" — Dan Norris, The 7 Day Startup</blockquote><h2 id="if-you-want-more-">If you want more...</h2><p>This post is a short version of an eBook I am creating, titled <a href="https://gumroad.com/l/evaluatesaas">"How to pick a good SaaS idea: A pre-validation guide and evaluation checklist"</a>. </p><p>In the eBook I include:</p><ul><li>Descriptions, example startups, supporting resources, and quotes from founders, for each criteria.</li><li>A Google Sheet for automatically scoring and comparing your ideas.</li><li>A beautifully formatted PDF scoring sheet, for printing out.</li><li>PDF, MOBI, and ePub versions.</li></ul><p>If you feel that this will help you, then you can pre-order the eBook at the discounted pre-sale price of<strong> $4.99</strong>: click the button below or click <a href="https://gumroad.com/l/evaluatesaas">https://gumroad.com/l/evaluatesaas</a> now.</p><!--kg-card-begin: html-->
<p><a href="https://gum.co/evaluatesaas?wanted=true" target="_blank">Buy the eBook</a></p><!--kg-card-end: html-->

                    <br><hr>
                    <p><strong>Don't miss the next post</strong>. Sign up to my newsletter:</p>
                    
                    <p><strong>Are you on Twitter?</strong> It would be nice to connect. <a href="https://twitter.com/farez">Follow me on Twitter (@farez)</a>, and do say hello!</p>

                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://farez.me/how-to-pick-a-saas-startup-idea-a-pre-validation-checklist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925642</guid>
            <pubDate>Thu, 29 Oct 2020 00:07:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RIAA's War on YouTube-Dl]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24925542">thread link</a>) | @samizdis
<br/>
October 28, 2020 | https://pluralistic.net/2020/10/28/trumpcicles/#yt-dl | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/10/28/trumpcicles/#yt-dl">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1538">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
youtube-dl, 1201, dmca, github, microsoft, riaa, omaha, trump, logistics, administrative incompetence, maga, nebraska

Summary:
RIAA's war on youtube-dl; Trump abandons supporters to freeze

URL:
https://pluralistic.net/2020/10/28/trumpcicles/

Title:
Pluralistic: 28 Oct 2020 trumpcicles

Bullet:
🥉

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Boing Boing (https://boingboing.net/), Slashdot (https://slashdot.org/).

--><br>
<a href="https://pluralistic.net/2020/10/28/trumpcicles/"><img src="https://i1.wp.com/craphound.com/images/28Oct2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/28Oct2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/10/28/trumpcicles/#yt-dl">RIAA's war on youtube-dl</a>: The rise of the resistance.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/10/28/trumpcicles/#omaha">Trump abandons supporters to freeze</a>: More death cult shit.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/10/28/trumpcicles/#retro">This day in history</a>: 2005, 2015, 2019
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/10/28/trumpcicles/#bragsheet">Colophon</a>: Recent publications, upcoming appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="yt-dl"></a><br>
<img src="https://i0.wp.com/craphound.com/images/ytdl.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/ytdl.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Late last week, the RIAA sent a legal threat to Github, claiming that the popular (and absolutely lawful) tool youtube-dl (which allows users to download Youtube videos for offline viewing, editing and archiving) violated Section 1201 of the #DMCA.</p>
<p><a href="https://pluralistic.net/2020/10/24/1201-v-dl-youtube/#1201">https://pluralistic.net/2020/10/24/1201-v-dl-youtube/#1201</a></p>
<p>Even by the heavy-handed standards of the RIAA – a monopolist's "association" dominated by only three members – this was extraordinary. The law in question derives much of its efficacy from its vagueness, which chills software developers from risking its severe penalties.</p>
<p>DMCA1201 is an "anti-circumvention" law, banning the distribution of tools that bypass "effective means of access control" for copyrighted work, with a $500k fine and a 5-year sentence for a first violation.</p>
<p>Thus 1201 gives companies the power to felonize any action, even lawful ones. All you need to do is design a product so that using it in ways that you dislike requires bypassing "access controls" and presto! Your preferences are laws – "Felony contempt of business-model."</p>
<p>That's how Apple makes it a crime for me to write an app and sell it to you for your Iphone without giving Apple 30% of the purchase price. It's how Medtronic makes it a crime to fix its ventilators. It's how HP makes it a crime to refill a printer cartridge.</p>
<p>For all its centrality to modern commerce, 1201 has seen precious few cases litigated to judgment, so its contours remain fuzzy. That works to companies' advantage. They know that risk-averse competitors, security researchers and investors steer wide to avoid violating it.</p>
<p>Who wants to risk a wrong guess about the lawfulness of your activities that can land you in prison for 5 years?</p>
<p>There have been moments when the RIAA's rage brought us close to litigating key features of 1201, but cooler heads prevailed and they surrendered rather than putting their theories in front of a judge and risking a narrowing of 1201.</p>
<p><a href="https://www.eff.org/cases/felten-et-al-v-riaa-et-al7/">https://www.eff.org/cases/felten-et-al-v-riaa-et-al7/</a></p>
<p>In threatening youtube-dl, RIAA is risking a lot. Like what is an "effective means of access control"? There's an argument that goes, "If I can bypass it, how was it 'effective'?" That was tried in the 2600 case over Decss, and it didn't fly.</p>
<p><a href="https://www.eff.org/effector/15/14">https://www.eff.org/effector/15/14</a></p>
<p>But while the courts were reluctant to decide how stout an access control must be to acquire statutory protection, they were unsympathetic to the arguments of the defunct file-sharing tool Aimster, which used Pig Latin to "encrypt" its filenames.</p>
<p>They argued that RIAA enforcers violated 1201 by "decrypting" them. This was quickly dismissed by courts, putting a floor under what "effective" means: "stronger than Pig Latin, weaker than Decss."</p>
<p><a href="https://news.slashdot.org/story/01/03/06/1448236/aimster-uses-pig-latin-encryption-to-defeat-riaa">https://news.slashdot.org/story/01/03/06/1448236/aimster-uses-pig-latin-encryption-to-defeat-riaa</a></p>
<p>The "access controls" that youtube-dl bypasses are (AFAIK) somewhere within those two bounds – basically a lot of obfuscation, but not encryption. If this goes to trial, "obfuscation" methods could end up being fair game for circumvention.</p>
<p>The other thorny question RIAA is raising here is standing – they're arguing that since some of their members' works are restricted by Google's access controls, then they have the right to sue over circumvention, even if Google doesn't mind.</p>
<p>If this question is ruled on, then it could go badly for RIAA irrespective of the ruling. If the court rules that only the creator of an access-control can invoke DMCA 1201, the list of potential aggressors under 1201 dwindles to a mere handful.</p>
<p>If the court rules that the RIAA <em>does</em> have standing, then that means that every single rightsholder whose works are implicated by an access control would ALSO have standing.</p>
<p>If the day comes that the RIAA's members want to break with a Big Tech music company (like Youtube, say!), and authorize their customers to jailbreak their music and take it with them to a rival service, any other rightsholder with a file on Youtube could stop this.</p>
<p>Indeed, under this theory, there may be no way of <em>ever</em> authorizing a circumvention – you'd need cooperation from every implicated rightsholder and the access-control's creator. The RIAA's members strongly value their own self-determination and this could really hurt them.</p>
<p>Will this go to trial? It's hard to say. Certainly, the RIAA has firehosed around so many complaints that they've created a cohort of potential defendants who might be willing to take their chances in court.</p>
<p>As Torrentfreak reports, before hitting Github, RIAA sent out notices in Germany – to Uberspace (the youtube-dl project's host) and to former project maintainer Philipp Hagemeister (no longer involved).</p>
<p><a href="https://torrentfreak.com/riaas-youtube-dl-takedown-ticks-of-developers-and-githubs-ceo-201027/">https://torrentfreak.com/riaas-youtube-dl-takedown-ticks-of-developers-and-githubs-ceo-201027/</a></p>
<p>And Natfriedman, Github's CEO, joined the developers' IRC channel to offer support (he told Torrentfreak, "We want to help the youtube-dl maintainers defeat the DMCA claim so that we can restore the repo").</p>
<p><a href="https://twitter.com/t3rr4dice/status/1320660235363749888">https://twitter.com/t3rr4dice/status/1320660235363749888</a></p>
<p>The notice seems to have radicalized the company: "We are thinking about how GitHub can proactively help developers in more DMCA cases going forward, and take a more active role in reforming/repealing 1201."</p>
<p>Interestingly, Github's owner, Microsoft, is an RIAA member.</p>
<p>In the meantime, copies of the youtube-dl sourcecode have proliferated as developers and activists have mirrored it in protest of the RIAA's heavy hand.</p>
<p>DMCA 1201 is unconstitutional: that's an argument EFF is making in its lawsuit on behalf of Matthew Green and Andrew "bunnie" Huang, which seeks to overturn the law.</p>
<p><a href="https://www.eff.org/cases/green-v-us-department-justice">https://www.eff.org/cases/green-v-us-department-justice</a></p>
<p>A legal reckoning over 1201 is long overdue, thanks to the tactical cowardice of RIAA, which has run from the victims that stood up to its bullying rather than risking a day in court and the law's judicial overturn. EFF's suit has been slow going, plagued by long delays.</p>
<p>It's never good to be on the receiving end of legal threats from wealthy, powerful, connected industry groups. But here might be a case that finally drives a stake through 1201's heart. It's not a silver lining, but at least it's something.</p>
<hr>
<p><a name="omaha"></a><br>
<img src="https://i2.wp.com/craphound.com/images/3123103199_9a80d2b0cb_h.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/3123103199_9a80d2b0cb_h.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Trumpism is an incompetent death cult. The movement's incompetence (embodied by the inability of many of its worst monsters to keep their jobs long enough to enact their key policies) finally met its match with the pandemic, though.</p>
<p>When the plague started, Trumpism's thought-leaders rushed to advise the elderly voters who constitute its base that they should engage in high-risk conduct:</p>
<p><a href="https://pluralistic.net/2020/04/04/a-mind-forever-voyaging/#receipts-r-us">https://pluralistic.net/2020/04/04/a-mind-forever-voyaging/#receipts-r-us</a></p>
<p>They insisted that the answer to the plague was for the "free market" to decide which countermeasures would save our lives:</p>
<p><a href="https://pluralistic.net/2020/04/23/riot-baby/#carolyn-goodman">https://pluralistic.net/2020/04/23/riot-baby/#carolyn-goodman</a></p>
<p>And when that failed, they literally told old people it was their moral duty to commit suicide-by-virus in order to save the economy:</p>
<p><a href="https://www.vanityfair.com/news/2020/03/dan-patrick-coronavirus-grandparents">https://www.vanityfair.com/news/2020/03/dan-patrick-coronavirus-grandparents</a></p>
<p>Now, as Trump desperately hauls his mouldering carcass through the precincts he needs to swing for him after he spent half a year telling them to kill themselves, he's tripped over his own tie, hospitalizing his few remaining stalwarts.</p>
<p><a href="https://www.usatoday.com/story/news/politics/2020/10/28/omaha-trump-rally-thousands-attendees-stranded-cold-after-event/3760175001/">https://www.usatoday.com/story/news/politics/2020/10/28/omaha-trump-rally-thousands-attendees-stranded-cold-after-event/3760175001/</a></p>
<p>Last night, Trump rallied his heavily comorbid base at Nebraska’s Eppley Airfield, finishing his speech and flying off in his presidential jet as temperatures plummeted to 34' (about 1' C).</p>
<p>The thousands of attendees he left behind were at the mercy of the kind of grifter Trump gets to throw rallies for him. Unfortunately for them, that's the kind of grifter who provides no shelter for attendees and takes four hours to bus them all offsite.</p>
<p>"We need at least 30 more buses" – Omaha officer on the scene.</p>
<p>Many experienced hypothermia. At least seven attendees were hospitalized. Law enforcement reported elderly attendees were "frozen cold unable to move with an altered mental status."</p>
<p><a href="https://twitter.com/omaha_scanner/status/1321301704470597638?ref_src=twsrc%5Etfw">https://twitter.com/omaha_scanner/status/1321301704470597638?ref_src=twsrc%5Etfw</a></p>
<p>The fact that he can't bestir himself from attempting to murder his supporters until <em>after</em> election-day really says it all.</p>
<p>(<i>Image: <a href="https://www.flickr.com/photos/paulcole/3123103199/">Paul Cole</a>, <a href="https://creativecommons.org/licenses/by-nc/2.0/">CC BY-NC</a>, modified</i>)</p>
<hr>
<p><a name="retro"></a><br>
<img src="https://i0.wp.com/craphound.com/images/wayback-machine-hed-796x416.png?resize=796%2C416&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/wayback-machine-hed-796x416.png?resize=796%2C416&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>#15yrsago Science shouldn’t use copyright to silence Creationists <a href="https://web.archive.org/web/20051031024524/http://www.corante.com/copyfight/archives/2005/10/27/copyright_and_the_evolution_wars.php">https://web.archive.org/web/20051031024524/http://www.corante.com/copyfight/archives/2005/10/27/copyright_and_the_evolution_wars.php</a></p>
<p>#5yrsago The two brilliant, prescient 20th century science fiction novels you should read this election season <a href="https://memex.craphound.com/2015/10/28/the-two-brilliant-prescient-20th-century-science-fiction-novels-you-should-read-this-election-season/">https://memex.craphound.com/2015/10/28/the-two-brilliant-prescient-20th-century-science-fiction-novels-you-should-read-this-election-season/</a></p>
<p>#5yrsago Modular spiral staircase system for trees <a href="http://www.canopystair.com/">http://www.canopystair.com/</a></p>
<p>#5yrsago The more unequal your society is, the more your laws will favor the rich <a href="http://america.aljazeera.com/opinions/2015/10/the-more-unequal-the-country-the-more-the-rich-rule.html">http://america.aljazeera.com/opinions/2015/10/the-more-unequal-the-country-the-more-the-rich-rule.html</a></p>
<p>#1yrago The penniless hero of the ransomware epidemic has written more decryptors than anyone else <a href="https://www.propublica.org/article/the-ransomware-superhero-of-normal-illinois">https://www.propublica.org/article/the-ransomware-superhero-of-normal-illinois</a></p>
<hr>
<p><a name="bragsheet"></a><br>
<img src="https://i1.wp.com/craphound.com/images/colophonimages.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/colophonimages.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Today's top sources: Boing Boing (<a href="https://boingboing.net/">https://boingboing.net/</a>), Slashdot (<a href="https://slashdot.org/">https://slashdot.org/</a>).</p>
<p>Currently writing: My next novel, "The Lost Cause," a post-GND novel about truth and reconciliation. Yesterday's progress: 540 words (77815 total).</p>
<p>Currently reading: Harrow the Ninth, Tamsyn Muir</p>
<p>Latest podcast: Someone Comes to Town, Someone Leaves Town (part 20) <a href="https://craphound.com/news/2020/10/25/someone-comes-to-town-someone-leaves-town-part-20/">https://craphound.com/news/2020/10/25/someone-comes-to-town-someone-leaves-town-part-20/</a></p>
<p>Upcoming …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2020/10/28/trumpcicles/#yt-dl">https://pluralistic.net/2020/10/28/trumpcicles/#yt-dl</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2020/10/28/trumpcicles/#yt-dl</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925542</guid>
            <pubDate>Wed, 28 Oct 2020 23:54:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I used YouTube-dl and audacity to guess the top speed of the SSC car]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24925352">thread link</a>) | @speedgoose
<br/>
October 28, 2020 | https://fungiboletus.github.io/ssc-rpm/ | <a href="https://web.archive.org/web/*/https://fungiboletus.github.io/ssc-rpm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  

  <p>A few days ago, the YouTube algorithm suggested to me and many other a BBC TopGear video about a new world record
    for the
    fastest <em>production</em> car.</p>

  <iframe width="560" height="315" src="https://www.youtube.com/embed/N22JfNHiC1k" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

  <p>SSC North America, a sports car manufacturer, claims in this video to have reached 532.8km/h with their latest car
    (331mph if you still didn't get the memo about the
    world using metric units). It's a single run and the video doesn't include the second run driving back to the
    starting point. A real speed record for cars is the mean of the two runs to take into account elevation changes and
    wind. Still, it's <em>a lot</em> faster than the previous official world record held by Bugatti on their dedicated
    track at
    431km/h, or the non-official world record of Koenigsegg at 447km/h.</p>

  <p>You can argue whether these cars are production cars, or the utility to drive at such high speeds when after each
    run of a few seconds you need to change the tires, the wheels, and sometimes the engine. You can also wonder why our
    societies still invest in fast supercars cars when they should prioritize low consumption electric cars. Or you can
    reflect on the point of building cars at all, shouldn't we bike and develop more public transports? I
    was impressed by this record. I like fast cars, I own a Bugatti Chiron in Lego.</p>

  <p>You may have guessed, the record is perhaps invalid. Many people did question the record, by computing the average
    speed on the road section shown on the video or doing the maths of the aerodynamics force involved at such extremely
    high speeds for example.</p>

  <p>Yesterday, Misha Charoudin who is a professional driver and a vlogger published a video of him and a friend
    discussing the record attempt with some technical details, such as the gearbox ratios and the wheels
    dimensions of the car. Using this information, I got the idea to try computing the maximum speed using an audio
    frequency spectrum analysis. The idea is to use the engine sound to guess the car real speed. Everything is
    connected, it should be straightforward.</p>

  <iframe width="560" height="315" src="https://www.youtube.com/embed/fSNRKBj_hUE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

  <h3>Step 1: Download the record attempt video using youtube-dl.</h3>

  <p><code>youtube-dl --list-formats https://www.youtube.com/watch?v=N22JfNHiC1k</code></p>
  <p>I selected the format with the highest audio bitrate.</p>
  <p><code>youtube-dl --format 251 https://www.youtube.com/watch?v=N22JfNHiC1k</code></p>

  <h3>Step 2: Extract the audio from the video.</h3>

  <p>There is a ffmpeg command to extract the audio from the video, but I used VLC because I didn't feel like installing
    ffmpeg and searching for the right command. I exported to FLAC because it's a lossless format compatible with
    Audacity.</p>

  <img src="https://fungiboletus.github.io/ssc-rpm/vlc-convert.png" alt="Screenshot of VLC to convert the video to audio">

  <h3>Step 3: Loading the audio file in Audacity</h3>

  <img src="https://fungiboletus.github.io/ssc-rpm/audacity-load.png" alt="Screenshot of the audio file in Audacity">

  <p>The file is in stereo, but the analysis is simpler in mono. I used the "Split stereo to mono" option and deleted
    one of the track. It doesn't matter which one, but to be sure I tried both and I obtained the same final
    result.</p>

  <img src="https://fungiboletus.github.io/ssc-rpm/audacity-split.png" alt="Screenshot of the context menu to select split stereo to mono">

  <h3>Step 4: Setting up the spectrogram</h3>

  <p>I selected the spectrogram view, a very cool feature of Audacity.</p>
  <img src="https://fungiboletus.github.io/ssc-rpm/audacity-spectrogram.png" alt="Screenshot of the context menu to select the spectrogram view">
  <br>
  <img src="https://fungiboletus.github.io/ssc-rpm/spectrogram.png" alt="Spectrogram">

  <p>Nothing is very visible yet, it's mostly (wind) noise. So I tried a few settings and after some tries, I got
    something a lot more interesting. I used the highest window size and ignored the frequencies above 600Hz as I'm more
    interested in the main harmonic frequencies of the engine. I also resized the spectrogram view.</p>

  <img src="https://fungiboletus.github.io/ssc-rpm/spectrogram-settings.png" alt="Screenshot of the spectrogram view settings">
  <br>
  <img src="https://fungiboletus.github.io/ssc-rpm/nice-spectrogram.png" alt="A nicer spectrogram">

  <h3>Step 5: Analysing the spectrogram</h3>

  <p>The lines are harmonic frequencies of the car components, such as the gearbox, the engine, the wheels,
    etc. One line is particularly visible, and thanks to the gearshifts it's easy to guess that it's one harmonic
    related to the engine sound.</p>
  <img src="https://fungiboletus.github.io/ssc-rpm/spectrogram-explained.png" alt="An explained version of the spectrogram">

  <p>I then zoomed on the part when the car is the fastest in the video, and selected the audio where the harmonic is at
    its highest pitch. I then plotted the spectrum in the analyze menu, to have a more precise idea of the frequency.
    Finding out where is the corresponding peak in the chart is a bit difficult but it's for sure the one at 251Hz.</p>

  <img src="https://fungiboletus.github.io/ssc-rpm/audacity-selection.png" alt="Selection of the audio at the maximum speed">
  <br>
  <img src="https://fungiboletus.github.io/ssc-rpm/frequency-analysis.png" alt="Frequency analysis of the video sound at the maximum speed">

  <h3>Step 6: Computing the engine RPM</h3>

  <p>So after that, I knew that at the highest speed, my nice engine harmonic had a frequency of 251Hz. I only needed to
    figure out the formula to compute the RPM from this harmonic frequency. Thankfully, the video from Misha includes
    data with the engine RPM at two points in time. The dashboard is blurred in the YouTube video of record, I wonder
    why,
    but according to the Misha video SSC also published on Instagram videos with a not blurred dashboard,
    allowing them to know the RPM at two points in time.</p>

  <p>I also quickly searched the formula and found out it was something like
    <code>RPM = 60 * frequency * something</code>. The main thing is that we need to convert from Hz to RPM and it's
    linear.</p>

  <p>Using audacity I analyzed the frequencies of the same harmonic. I got 243Hz at 1m21, for about 7300rpm, and 189Hz
    at 1m37 for about 5400rpm. My formula was, therefore, <code>RPM = 30 * frequency</code>.</p>

  <p>Finally, to compute the engine RPM at the maximum speed, I multiplied the frequency of the harmonic by 30. So
    <code>251 * 30 = 7530 rpm</code>.</p>

  <h3>Step 7: Getting the final speed</h3>

  <p>Computing the car speed from the engine RPM is simple if you have the data, you know how fast the engine rotates
    and you need to know how fast the wheels rotate, and their size.</p>

  <p>Good news, SSC <a href="https://www.sscnorthamerica.com/news/jerod-shelby-explains-world-record">gave us the
      data.</a> We rear wheels had <code>89.125</code> inches of circumference, <code>2.263775</code> meters. The final
    drive ratio was <code>2.92</code> and the sixth gear, the one used for the record had a ratio of <code>0.757</code>.
  </p>

  <p>The gearbox ratios are different than in the Misha video. I think they didn't know SSC had used a specific gearbox.
    We got a final drive ratio of <code>3.167</code> and a sixth gear ratio of <code>0.784</code>.

  </p><p>Putting everything together, we have
    <code>speed = rear_wheel_circumference * rpm / 60 / final_drive_ratio / sixth_gear_ratio</code>.</p>

  <p>With SSC data, at <code>7530</code> rpm it means <code>128.5m/s</code> or <code>460.8km/h</code> or
    <code>286.3mph</code>. Still above the previous records.</p>
  <p>With Misha's video data, at <code>7530</code> rpm it means <code>114.4m/s</code> or <code>411.9km/h</code> or
    <code>255.9mph</code>.</p>

  <h3>Who is right?</h3>

  <p>SSC <a href="https://www.sscnorthamerica.com/news/jerod-shelby-explains-world-record">announced</a> that the engine
    was at <code>8600rpm</code> at the maximum speed, but I&nbsp;computed <code>7530rpm</code>. I may have used some wrong
    data
    when estimating the RPM, though I like the cleanness of my formula: <code>RPM = 30 * frequency</code>.</p>

  <br>
  <hr>
  <p>Antoine - 21/10/2020</p>



</div>]]>
            </description>
            <link>https://fungiboletus.github.io/ssc-rpm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925352</guid>
            <pubDate>Wed, 28 Oct 2020 23:28:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Use US Stock Data to Build Apps or Platforms]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24925148">thread link</a>) | @Finage
<br/>
October 28, 2020 | https://blog.finage.co.uk/2020/10/28/how-to-use-u-s-stock-historical-api-and-real-time-websocket/ | <a href="https://web.archive.org/web/*/https://blog.finage.co.uk/2020/10/28/how-to-use-u-s-stock-historical-api-and-real-time-websocket/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
<p>Finage is a financial data provider that’s known for its strong backend and high performance. The Finage WS (FWS) Engine is keeping the connection alive and providing high performance. Let’s dive into the system. </p>







<p>Finage offers VPS (Virtual Private Server) for every customer that subscribed to any professional WebSocket package. This means you’ll have more control over your server. You can check the total connections, server CPU, and more. </p>







<h2 id="u-s-stock-historical-api">
	<span>
		<span>U.S STOCK HISTORICAL API</span>
	</span>
</h2>



<p>After your <em><strong>WebSocket subscription</strong></em>, Finage will create two keys for you. </p>



<p><strong>ADDRESS_KEY</strong>:  This is used to create your own personal address. For example, if your ADDRESS_KEY is “abcd1234” then you’ll have a WebSocket address like <strong>abcd1234.finage.ws </strong>to create a connection.</p>



<p><br><strong>SOCKET_KEY</strong>&nbsp;= This key is like a API_KEY. You need to use this key to create a connection on your server. In addition to this, the FWS engine checks the incoming connection’s IP address, if it’s not in the whitelist, then rejects the connection. For example, if your SOCKET_KEY is “<strong><code>SOCKET_KEY2R2TZMRNTRG...</code></strong>“. Then you can use the address given below to create a connection.</p>



<h2 id="wss-abcd1234-finage-ws-tokensocket_key2r2tzmrntrg">
	<span>
		<span><strong><em><code>wss://abcd1234.finage.ws/?token=SOCKET_KEY2R2TZMRNTRG... </code></em></strong></span>
	</span>
</h2>



<p>This address is your own and can only be used by you.</p>







<p>After the connection, you can <strong>subscribe</strong> a symbol with the command given below;</p>



<pre><code>{<br>     "action":"subscribe",<br>     "symbols":"AAPL"<br>}</code></pre>



<p>Also, you can subscribe more than one symbol at one time</p>



<pre><code>{<br>     "action":"subscribe",<br>     "symbols":"AAPL,AMZN,TESLA"<br>}</code></pre>







<p>Unsubscribing a symbol is easy also;</p>



<pre><code>{<br>     "action":"unsubscribe",<br>     "symbols":"AAPL"<br>}</code></pre>







<p>You’ll get the responses from the server after your subscription. </p>







<pre><code>[{<br>     "symbol": "AAPL",<br>     "ask": 111.82,<br>     "bid": 111.8,<br>     "timestamp": 1603920820567<br>}]</code></pre>







<p>Finage also has open, high, low, close (<strong>OHLC</strong>) and <strong>volume</strong> values. We can add it to your response and edit your responses according to your needs. In Finage, you can define your own rules. </p>







<h2 id="u-s-stock-historical-api-2">
	<span>
		<span>U.S Stock Historical API</span>
	</span>
</h2>



<p>Finage has <strong>30-Year Historical U.S. Stock API</strong>. In our packages, the default package is <strong>15-Year Historical U.S Stock API</strong>. According to your needs, you can customize your professional package. </p>







<p>It’s easy to use Finage’s historical API. After your subscription, we will define an API KEY to your account. You can see your API KEY in the dashboard (<a rel="noreferrer noopener" href="https://moon.finage.co.uk/" target="_blank">https://moon.finage.co.uk</a>).</p>



<p>For example, let’s see the APPLE’s <strong>OHLC</strong> and <strong>Volume</strong> data in <em>2005-02-03</em> ;</p>



<p><a href="https://api.finage.co.uk/HISTORY/STOCK/OPEN-CLOSE?STOCK=AAPL&amp;DATE=2005-02-03&amp;APIKEY=YOUR_API_KEY">https://api.finage.co.uk/history/stock/open-close?stock=AAPL&amp;date=2005-02-03&amp;apikey=YOUR_API_KEY</a></p>



<p>After the request, you will get a response like;</p>



<pre>{
    "symbol":"AAPL",
    "open":79.1,
    "high":79.43,
    "low":77.33,
    "close":77.81,
    "volume":13089041,
    "from":"2005-02-03"
}</pre>











<p>With Finage, you have the freedom to customize, edit and create your own rules on the system without any coding or extra fees. Our tech team is always ready to help you out.</p>







<p>Let’s get started.</p>



<p><a href="mailto:info@finage.co.uk" target="_blank" rel="noreferrer noopener">info@finage.co.uk</a></p>



<p><a href="https://finage.co.cuk/" data-type="URL" data-id="https://finage.co.cuk">finage.co.uk</a></p>

		</div></div>]]>
            </description>
            <link>https://blog.finage.co.uk/2020/10/28/how-to-use-u-s-stock-historical-api-and-real-time-websocket/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925148</guid>
            <pubDate>Wed, 28 Oct 2020 22:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we work in the open as a company building an open core product]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24925072">thread link</a>) | @andyjih_
<br/>
October 28, 2020 | https://www.grouparoo.com/blog/how-grouparoo-works-as-a-team | <a href="https://web.archive.org/web/*/https://www.grouparoo.com/blog/how-grouparoo-works-as-a-team">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><small>Tagged in <a href="https://www.grouparoo.com/blog/category/operations"><span>Operations</span></a>&nbsp;<a href="https://www.grouparoo.com/blog/category/company"><span>Company</span></a>&nbsp;<!-- --> <br>By<!-- --> <a href="https://www.grouparoo.com/blog/author/andy_jih">Andy Jih</a> <!-- -->on <!-- -->2020-10-27</small></p><p><span><p>When Brian, Evan, and I first talked about starting a company, we already had some ideas in mind about what we might want to do differently from our past roles. The three of us had all worked together before at <a href="http://taskrabbit.com/" target="_blank" rel="nofollow noopener noreferrer">TaskRabbit</a>, but since we were starting a brand new company, we decided to approach how we would work from a first principles approach. I thought we’d share some tidbits about how we work right now.</p><p><img alt="The Grouparoo team at our founding meeting" src="https://www.grouparoo.com/posts/how-grouparoo-works-as-a-team/team-photo.jpg"></p><h3>Remote-first and asynchronous-first</h3><p>We view these two principles as distinct, but how these two principles interact is often intertwined. We decided to make the company remote-first for a few reasons. First, the three of us all live in different areas (ok, Brian and I are both in the SF Bay Area, but we’re easily 60 minutes apart so let’s just say we’re in different areas for convenience’s sake 😅). Additionally, we believe that there is good talent everywhere, not just around the major tech hubs or cities. We’d all had varying degrees of experience working remotely, but few of us had done so from the start. Starting remote from the beginning of the company actually wasn’t too challenging. We’d all used <a href="http://slack.com/" target="_blank" rel="nofollow noopener noreferrer">Slack</a>, Google Meet/Zoom, Github, and various other tools for our past roles, so the tools weren't particularly new to us. We’ve also been very happy with <a href="https://tuple.app/" target="_blank" rel="nofollow noopener noreferrer">Tuple</a>, a screen-sharing tool made specifically for pair programming. The ability to use someone else’s mouse and keyboard remotely really approximated the pair-programming experience we were used to (sidenote that we're still bummed that Slack bought ScreenHero and did approximately nothing with that product before shutting it down).</p><p>The trickier part for us was moving to asynchronous working. We were mostly used to sitting in the same room as our colleagues. Often with the tap on the shoulder or a slack message, you can pull their attention away. Many studies have shown that getting into a <a href="https://en.wikipedia.org/wiki/Flow_(psychology)" target="_blank" rel="nofollow noopener noreferrer">flow-state</a> (having uninterrupted time to focus) improves people’s satisfaction with their work as well as their work output. One of the many cultural practices that I loved from my time at <a href="http://stripe.com/" target="_blank" rel="nofollow noopener noreferrer">Stripe</a> was how nearly every decision or idea was written in a document. Writing your thoughts in a document both helps you think through what your ideas are, and then additionally, having a document gives people time to digest and respond. We've adopted this practice here at Grouparoo, and it's worked pretty well for us so far. That isn’t to say writing docs is the best approach for all instances, but it’s a solid default stance to take.</p><p>We do still meet synchronously when it’s warranted; we have daily “stand-ups” in a video chat, and we have a weekly planning meeting on Monday and a weekly demo/retro. If we ever chat in Slack and there’s a fair amount of back-and-forth, we’ll propose we jump into a call in case that could help eliminate confusion about our discussion.</p><h3>Meeting IRL is great (when it can happen)</h3><p>While our default is async and remote, meeting in-person is still very important to us. Before COVID, we would meet in-person once a month for a day-long “on-site”. During those days, we’d brainstorm our plans for the month, discuss strategy and the roadmap, goals, and have a team dinner (and maybe a team game of Civilization).</p><p>While we haven’t been able to meet IRL since March 2020, we’ve moved these full-day “on-sites” online. That said, they haven’t taken the same form. Attending a full-day on-site IRL can be draining; attending a full-day <strong>online</strong> on-site is mind-numbing. We’re now spreading them out into a few 60-90 minute meetings across a couple of days, and doing more pre-work so the discussions can be more focused. I wouldn’t say we’re 100% nailing this process, but we’re still learning and evolving with each month.</p><p>Since we aren’t able to meet IRL, we’ve taken to playing games online for some non-work activities. Most recently we played some Settlers of Catan!</p><p><img alt="The Grouparoo team plays a friendly game of Settlers of Catan" src="https://www.grouparoo.com/posts/how-grouparoo-works-as-a-team/team-catan.jpeg"></p><h3>Default to open</h3><p>When we decided to build an open-source product, we found ourselves asking over and over again “should this feature be open-source/free or paid?” Asking that question for every roadmap item could get exhausting, so we decided to take a framework-approach to how we’d think about open-ness. We landed on, by default, everything we do will be open, from our <a href="https://github.com/grouparoo/grouparoo" target="_blank" rel="nofollow noopener noreferrer">core project</a>, our <a href="https://www.grouparoo.com/roadmap" target="_blank" rel="nofollow noopener noreferrer">roadmap</a>, and even our <a href="https://github.com/grouparoo/www.grouparoo.com" target="_blank" rel="nofollow noopener noreferrer">marketing site</a>. That said, there are some artifacts that we don't keep open, such as pay and our longer-term strategy. That said, we have all of those docs available privately to all of our team members (in Github, of course).</p><h3>Snapshot</h3><p>Most of what I shared is just a snapshot of how we work right now in October 2020. One of the most exciting parts about growing the team is that the culture and practices of the company will (and should!) change and evolve. We don’t presume to have the answers to everything, so we’re very excited to bring in new team members and for them to contribute ideas to how we can work better together. <a href="http://grouparoo.com/jobs" target="_blank" rel="nofollow noopener noreferrer">We’re hiring!</a></p></span></p><br><div role="alert"><div><p><img src="https://www.grouparoo.com/_next/static/images/andy_jih-0eebb98acb7e40f0e3b81672c92ea91c.png"></p></div></div></div></div>]]>
            </description>
            <link>https://www.grouparoo.com/blog/how-grouparoo-works-as-a-team</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925072</guid>
            <pubDate>Wed, 28 Oct 2020 22:49:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Copying is the way design works]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24925039">thread link</a>) | @headalgorithm
<br/>
October 28, 2020 | https://matthewstrom.com/writing/copying/ | <a href="https://web.archive.org/web/*/https://matthewstrom.com/writing/copying/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <p>
            This is a very short book about copying. Its contents, unless
            otherwise noted, are licensed under
            <a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noopener">CC-BY SA 4.0</a>
            (more on that in a bit). You can download, copy, remix, excerpt,
            change, and repost it however you see fit.
        </p>
        <p>I</p>
        <p>
            <strong>Charles Eames</strong> said
            it best: “We don’t do ‘art’ — we solve problems.”<sup><a href="#fn1" id="fnref1">1</a></sup>
        </p>

        <p>
            To buy furniture in 1950, you had to choose between affordable and
            enduring, between rugged and fashionable. Charles and Ray designed a
            chair that was all the above and sold it for $20.95.<sup><a href="#fn2" id="fnref2">2</a></sup>
            They called it the LCW.<sup><a href="#fn3" id="fnref3">3</a></sup>
        </p>

        <p>
            The LCW embodies the Eames’ obsession with simplicity in material
            and method. “We want to make the best for the most for the least,”
            they said.<sup><a href="#fn4" id="fnref4">4</a></sup>
            The design was revolutionary: in 1999, <em>Time</em> magazine called
            the LCW “the best design of the century.”<sup><a href="#fn5" id="fnref5">5</a></sup>
            Today, you can buy a brand new LCW from Herman Miller (the
            officially licensed manufacturer of Eames products) for $1,195.
        </p>
        <p>
            Or, you can buy a chair called the “Fathom” from a company called
            Modway for $145.
        </p>
        <p>Functionally and aesthetically, the chairs are identical.</p>
    </div>
    <div>
        <figure>
            <div>
                <p><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/0b07ec2420d962333516565bbf3c484cc8b2ca4f/e52a1/images/copying-1.jpg" alt="Eames Molded Plywood Lounge Chair"></p><figcaption>
                    Eames Molded Plywood Lounge Chair<br>© Herman Miller
                </figcaption>
            </div>
            <div>
                <p><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/e244c88f486534fd5ef1b92be27de149fb5d95a4/6a616/images/copying-2.jpg" alt="Modway Fathom"></p><figcaption>Modway Fathom<br>© Modway</figcaption>
            </div>
        </figure>
    </div>
    <div>
        <p>
            There’s an LCW from 1946 in MOMA’s collection. It’s one of the very
            first ever made. Most people would call it the original LCW.
        </p>
        <p>
            Charles and Ray Eames sold the manufacturing rights for their
            furniture to Herman Miller in 1947. Collectors call the LCWs made in
            the ’40s and ’50s “originals.” But in some sense, these — and the
            more recently manufactured Herman Miller versions — are copies of
            that LCW in the MOMA collection.
        </p>
        <p>
            And then there’s the Modway Fathom. It’s clearly a copy, an
            unlicensed one at that. But at $145 (the equivalent of $12.78 in
            1947) it’s more affordable than the LCW was when it was first
            manufactured and sold. In spirit, it’s more of an original than any
            LCW: the best, for the most, for the least.
        </p>
        <hr>
        <p>
            I’m sharing this story because it demonstrates a surprising fact:
            what makes something “original” (the first, the best, the most
            famous, the most true) or a “copy” (an identical copy, an
            unauthorized replica, an interpretation or a remix) isn’t always
            obvious — or important.
        </p>
        <p>
            I’m a designer. As a designer, I feel the need to be original. If
            you’re a designer, or even if you’re just interested in design, you
            probably feel the need to be original, too. We tend to worship
            inventors and originators, designers who were trailblazing and
            innovative. And we copy them.
        </p>
        <p>
            This oxymoron of a craft can drive a person crazy. There’s lots of
            space between originality and industry, authorship and
            acknowledgement, riffing and ripping. I wrote this very short book
            to explore that space.
        </p>
        <p>
            Some people have been frustrated by copying, refused to accept it,
            and struggled with every ounce of their strength against it. Other
            people have used copying to their advantage, whether to improve
            themselves, build a community, or subvert authority.
        </p>
        <p>I’ve only been able to have a career in design because I copied.</p>
        <p>
            I hope that by the time you’ve finished reading, you’ll see how
            important copying is. Right or wrong, virtue or vice, copying is the
            way design works.
        </p>
        <p>II</p>
        <p>
            <strong>Steve Jobs copied.</strong>
            “Great artists steal,” he said, quoting Pablo Picasso (or was it
            Stravinsky? T. S. Eliot?<sup><a href="#fn6" id="fnref6">6</a></sup>). Jobs and Apple copied many designs in their early days, most
            notably from a Xerox research laboratory in Palo Alto. The story
            goes like this:
        </p>
        <p>
            In the early 20th century, Xerox was a pioneer of office technology.
            By the middle of the century, computers were getting smaller and
            more affordable, and Xerox knew they’d have to work hard to keep
            their market dominance. In 1970, The Xerox Palo Alto Research Center
            — Xerox PARC — was founded to explore the future of the “paperless
            office.”
        </p>
        <p>
            Within two years, Xerox PARC had designed a groundbreaking computer
            called the Alto. One of its innovations was a graphical user
            interface: programs and files were displayed in virtual windows
            which users navigated using a mouse. It was an eerily accurate
            picture of what personal computers would look like 30 years later.
        </p>
        <p>
            Jef Raskin, leader of the Macintosh project at Apple, had seen
            Xerox’s work. He wanted Steve Jobs to see it for himself, and set up
            a meeting.
        </p>
        <p>
            “I thought it was the best thing I’d ever seen in my life,” Jobs
            said of the Alto’s user interface. “Within ten minutes it was
            obvious to me that all computers would work like this some day.”
        </p>
        <p>
            When the Macintosh was released in 1984, it featured a graphical
            user interface. Programs and files were displayed in virtual windows
            which users navigated using a mouse.
        </p>
        <p>It was just like the Alto.</p>
    </div>
    <div>
        <figure>
            <div>
                <p><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/08f14f2c6bb50c5a76d1d2f55afdf8225ea016da/d6ad1/images/copying-3.jpg" alt="Xerox Alto Operating System"></p><figcaption>
                    Xerox Star Operating System<br>© Xerox
                </figcaption>
            </div>
            <div>
                <p><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/4a9ba3ffa923511892c05b85e016dad99982b3b7/fe2ca/images/copying-4.jpg" alt="Apple Macintosh Operating System"></p><figcaption>
                    Apple Macintosh Operating System<br>© Apple
                </figcaption>
            </div>
        </figure>
    </div>
    <div>
        <p>Steve Jobs didn’t like to be copied.</p>
        <p>
            In 1985, a year after the Macintosh was launched, Apple sued a
            company called Digital Research Interactive for copying the
            Macintosh’s user interface. Digital Research settled out of court,
            and changed the appearance of its icons, windows, and mouse
            pointers.<sup><a href="#fn7" id="fnref7">7</a></sup>
        </p>
        <p>
            In 1990, Apple sued both Microsoft and Hewlett-Packard. The case was
            a repeat: Microsoft’s Windows and HP’s NewWave featured designs that
            Apple claimed were copies of the Macintosh’s operating system. But
            early licensing agreements between Apple and Microsoft made it
            unclear if any infringement took place; the case was thrown out.
        </p>
        <p>
            In the middle of Apple’s case against Microsoft, Xerox sued Apple,
            hoping to establish its rights as the inventor of the desktop
            interface. The court threw out this case, too, and questioned why
            Xerox took so long to raise the issue.<sup><a href="#fn8" id="fnref8">8</a></sup>
            Bill Gates later reflected on these cases: “we both had this rich
            neighbor named Xerox ... I broke into his house to steal the TV set
            and found out that [Jobs] had already stolen it.”<sup><a href="#fn9" id="fnref9">9</a></sup>
        </p>
        <p>
            The rampant copying fueling the explosive growth of consumer
            computers meant that by 1990, the desktop user interface was
            ubiquitous; it was impossible to determine who originated any part
            of it, or who copied who. The quest to stake their claim nearly
            consumed Apple. But when they emerged, they had learned a thing or
            two. Today, Apple holds more than 2,300 design patents.<sup><a href="#fn10" id="fnref10">10</a></sup>
        </p>
    </div>
    <div>
        <figure>
            <img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/c6e3a601fe1273b3e15343f0d9bf3e0505307772/032f8/images/copying-5.jpg" alt="Apple's design patent for a device with rounded corners">
            <figcaption>
                Apple's design patent for a device with rounded corners
            </figcaption>
        </figure>
    </div>
    <div>
        <p>
            This story ends in 2011, with Apple suing Samsung for copying the
            design of its software and hardware products. One of the most
            remarkable claims: Samsung broke the law when it sold “a rectangular
            product with four evenly rounded corners.”<sup><a href="#fn11" id="fnref11">11</a></sup>
        </p>
        <p>
            The court rejected Apple’s claim to own rounded rectangles. But it
            upheld the other claims, fining Samsung a blistering $539 million
            for patent violations.
        </p>
        <p>
            Designers copy. We steal like great artists. But when we see a copy
            of our work, we’re livid. Jobs, on Google’s Android: “I will spend
            my last dying breath if I need to, and I will spend every penny of
            Apple’s $40 billion in the bank, to right this wrong. I’m going to
            destroy Android, because it’s a stolen product.”<sup><a href="#fn12" id="fnref12">12</a></sup>
        </p>
        <p>
            Steve Jobs was unmatched in his visionary dedication to innovation.
            But he never came to terms with the inevitability of copying.
        </p>
        <p>III</p>
        <p>
            <strong>John Carmack had </strong>a
            different relationship with copying. For him, copying was a way to
            learn, a challenge to overcome, and a source of new ideas.
        </p>
        <p>
            Carmack was — still is — a brilliant coder. He’s best known for
            programming the ultraviolent and action-packed first-person shooters
            <em>Doom</em> and <em>Quake</em>. Those games pushed the limits of
            consumer computers and defined a genre. But his first real
            breakthrough game was simpler, cuter, more whimsical. It was called
            <em>Commander Keen</em>.
        </p>
        <p>
            Growing up in the early ’90s, I …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://matthewstrom.com/writing/copying/">https://matthewstrom.com/writing/copying/</a></em></p>]]>
            </description>
            <link>https://matthewstrom.com/writing/copying/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925039</guid>
            <pubDate>Wed, 28 Oct 2020 22:45:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: C++ ORM built with Oat++]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24924989">thread link</a>) | @lganzzzo
<br/>
October 28, 2020 | https://oatpp.io/docs/components/orm/ | <a href="https://web.archive.org/web/*/https://oatpp.io/docs/components/orm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <p>Oat++ ORM framework is a set of generalized interfaces and their implementations to make it easy to work with databases.</p> <p>It's based on an <a href="https://oatpp.io/docs/components/dto/">object-mapping framework</a> and ensures data consistency when manipulating with data.
Also, it integrates perfectly with other Oat++ components ensuring seamless data-flow in the application
(example: from REST to database, from the database to REST).</p>  <h2 id="high-level-overview"><a href="#high-level-overview">#</a> High-Level Overview</h2> <h3 id="declare-dbclient"><a href="#declare-dbclient">#</a> Declare DbClient</h3> <p>The main component you are going to work with is the <a href="https://oatpp.io/api/latest/oatpp/orm/DbClient/">DbClient</a>.
You may treat it as the main point interfacing with your data. Here you declare database queries and manage database schema migrations.</p> <p>Database queries are declared with the help of code-gen macros.<br>
DbClient code generation section must begin with
<code>#include OATPP_CODEGEN_BEGIN(DbClient)</code> and must be closed with
<code>#include OATPP_CODEGEN_END(DbClient)</code>.<br> <em>Do not forget to close the code generation section in order to avoid macro conflicts later in the code!</em></p> <h3 id="create-dbclient-component-and-connect-to-database"><a href="#create-dbclient-component-and-connect-to-database">#</a> Create DbClient Component And Connect to Database</h3> <p>DbClient is a heavy object - you want to instantiate it once and then inject it in whatever places you are going to use it.</p> <p><strong>Note:</strong></p> <ul><li><code>ConnectionProvider</code> and <code>ConnectionPool</code> objects can be reused by multiple <code>Executors</code> unless it's
prohibited by a database-specific implementation.</li> <li><code>Executor</code> can be reused by multiple DbClients unless it's prohibited by a database-specific implementation.</li></ul> <h3 id="dbclient-usage-example"><a href="#dbclient-usage-example">#</a> DbClient Usage Example</h3> <p>Output:</p> <h2 id="supported-databases"><a href="#supported-databases">#</a> Supported Databases</h2> <h3 id="available-database-adaptors"><a href="#available-database-adaptors">#</a> Available Database Adaptors</h3> <table><thead><tr><th>Adaptor</th> <th>Database</th> <th>Limitations</th> <th>Example Project</th></tr></thead> <tbody><tr><td><a href="https://github.com/oatpp/oatpp-sqlite" target="_blank" rel="noopener noreferrer">oatpp-sqlite</a></td> <td>SQLite</td> <td><strong>Full feature support</strong></td> <td><a href="https://github.com/oatpp/example-crud" target="_blank" rel="noopener noreferrer">example-crud</a></td></tr> <tr><td><a href="https://github.com/oatpp/oatpp-postgresql" target="_blank" rel="noopener noreferrer">oatpp-postgresql</a></td> <td>PostgreSQL</td> <td>Doesn't support all postgres types</td> <td><a href="https://github.com/oatpp/example-postgresql" target="_blank" rel="noopener noreferrer">example-postgresql</a></td></tr></tbody></table> <h3 id="libraries-hierarchy"><a href="#libraries-hierarchy">#</a> Libraries Hierarchy</h3> <p>The main <strong>oatpp</strong> module contains ORM interfaces only. In order to "plug" a specific database,
you have to link the corresponding adaptor (ex.: <strong>oatpp-sqlite</strong>).</p> <h2 id="dbclient"><a href="#dbclient">#</a> DbClient</h2> <h3 id="declare-a-query"><a href="#declare-a-query">#</a> Declare a Query</h3> <h3 id="query-with-parameters"><a href="#query-with-parameters">#</a> Query With Parameters</h3> <p>During execution the expression <code>username=:username</code> will be changed to <code>username='&lt;username-parameter-value&gt;'</code> and
parameter value will be properly escaped according to its type.</p> <h3 id="query-with-dto-as-a-parameter"><a href="#query-with-dto-as-a-parameter">#</a> Query With DTO as a Parameter</h3> <p>For complex queries, it's more convenient to use DTO objects as for parameters set. Thus you ensure the correct order of arguments.</p> <p><strong>Note:</strong><br>
The query template variable names are now starting with <code>user</code>, like <code>user.username</code> -
where <code>user</code> is the name of the DTO parameter, and <code>username</code> is the name of DTO field.</p> <ul><li><strong>Yes</strong>, you can specify a path to nested DTO fields like <code>:user.path.to.nested.field</code>.</li> <li><strong>Yes</strong>, you can have multiple DTO parameters in the query, and you can mix DTO parameters with regular parameters.</li></ul> <h3 id="query-with-prepared-statement"><a href="#query-with-prepared-statement">#</a> Query With Prepared Statement</h3> <p><strong>Note</strong>:<br>
The database adapter may ignore this.
For example:</p> <ul><li>SQLite is always using prepared statements to execute queries thus <strong>oatpp-sqlite</strong> will ignore this parameter.</li> <li>PostgreSQL has a special method to execute prepared statements thus <strong>oatpp-postgresql</strong> will not ignore this parameter.</li></ul> <h3 id="execute-an-arbitrary-query"><a href="#execute-an-arbitrary-query">#</a> Execute An Arbitrary Query</h3> <p>To execute an arbitrary query use <a href="https://oatpp.io/api/latest/oatpp/orm/DbClient/#dbclient-executequery">DbClient::executeQuery()</a> method.<br>
Use this method when it's needed to dynamically build a query.</p> <p>You can add parameters using parameters map:</p> <p>When building parameters map dynamically you have to use <code>std::unordered_map::insert()</code> method.<br>
The <code>[]</code> operator WON'T work.</p> <p>To build a query string it's recommended to use <a href="https://oatpp.io/api/latest/oatpp/core/data/stream/BufferStream/#bufferoutputstream">oatpp::data::stream::BufferOutputStream</a>.</p> <h3 id="enable-type-interpretations"><a href="#enable-type-interpretations">#</a> Enable Type Interpretations</h3> <p>When using custom or non-standard types as parameters in <code>QUERY</code> macro,
as well as when reading query results to custom/non-standard structures, you have to
explicitly enable corresponding type interpretations.</p> <p>The recommended place to do it - is the constructor:</p> <h4 id="query-with-custom-type-parameter"><a href="#query-with-custom-type-parameter">#</a> Query With Custom Type Parameter</h4> <h4 id="map-query-result-to-custom-type"><a href="#map-query-result-to-custom-type">#</a> Map Query Result To Custom Type</h4> <h3 id="transactions"><a href="#transactions">#</a> Transactions</h3> <p>Use <a href="https://oatpp.io/api/latest/oatpp/orm/DbClient/#dbclient-begintransaction">DbClient::beginTransaction()</a> method to begin a transaction.<br>
All queries MUST be executed on the same transaction connection.</p> <p><strong>Note:</strong><br>
Transaction will be automatically rollback if <a href="https://oatpp.io/api/latest/oatpp/orm/Transaction/#transaction-commit">Transaction::commit()</a> method
was not called.</p> <h2 id="executing-queries"><a href="#executing-queries">#</a> Executing Queries</h2> <p>The <code>queryResult</code> here is the <a href="https://oatpp.io/api/latest/oatpp/orm/QueryResult/">oatpp::orm::QueryResult</a> object.
All queries return <code>oatpp::orm::QueryResult</code>.</p> <h3 id="mapping-results"><a href="#mapping-results">#</a> Mapping Results</h3> <p>Available result mappings depend on the database adapter but here are some examples (that work for oatpp-sqlite and oatpp-postgresql)...</p> <h4 id="map-everything-using-previously-decalred-userdto-and-display-results"><a href="#map-everything-using-previously-decalred-userdto-and-display-results">#</a> Map everything using previously decalred <code>UserDto</code> and display results</h4> <p>For more info on how to declare a DTO - see <a href="https://oatpp.io/docs/components/dto/">oatpp::DTO</a></p> <p>Output:</p> <h4 id="map-everything-using-oatpp-any-and-display-results"><a href="#map-everything-using-oatpp-any-and-display-results">#</a> Map everything using <code>oatpp::Any</code> and display results</h4> <p>Output:</p> <h3 id="managing-connections"><a href="#managing-connections">#</a> Managing Connections</h3> <p>All declared queries have an <a href="https://oatpp.io/api/latest/oatpp/orm/Connection/">oatpp::orm::Connection</a> as the last parameter.<br>
If the connection is not specified(<code>nullptr</code>), then the new connection will be opened to execute that query.</p> <p><strong>Note:</strong></p> <p>The <code>queryResult</code> object holds a connection. The connection won't return to the connection pool until <code>queryResult</code> is destroyed.</p> <h2 id="connection-pool"><a href="#connection-pool">#</a> Connection Pool</h2> <p>It's always a good idea to use a connection pool when working with a database.</p> <p><strong>Note:</strong>
SQLite is used as an example here. For other databases declaration is similar.</p> <h2 id="schema-migration"><a href="#schema-migration">#</a> Schema Migration</h2> <p>Use <a href="https://oatpp.io/api/latest/oatpp/orm/SchemaMigration/">SchemaMigration</a> to do schema migrations!<br>
The recommended place to do schema migrations is the constructor of your DbClient.</p> <h3 id="overview"><a href="#overview">#</a> Overview</h3> <p><strong>Note:</strong></p> <ul><li>Version MUST start from <code>1</code>.</li> <li>Version MUST be incremented by <code>1</code>.</li> <li>In case of an error changes will be rolled back to the last successfully applied version.</li></ul> <h3 id="schema-name"><a href="#schema-name">#</a> Schema Name</h3> <p>If you have multiple Schemas in your database you can manage migrations of each one independently.
For this specify a version control table suffix:</p> <p><strong>Note:</strong>
It is recommended to have one DbClient per schema!</p> <h2 id="examples-projects"><a href="#examples-projects">#</a> Examples projects</h2> <ul><li><a href="https://github.com/oatpp/example-crud" target="_blank" rel="noopener noreferrer">example-crud</a> - Using oatpp ORM with SQLite.</li> <li><a href="https://github.com/oatpp/example-postgresql" target="_blank" rel="noopener noreferrer">example-postgresql</a> - Using oatpp ORM with PostgreSQL.</li></ul></div></div>]]>
            </description>
            <link>https://oatpp.io/docs/components/orm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24924989</guid>
            <pubDate>Wed, 28 Oct 2020 22:40:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The case for building web apps client-first]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24924810">thread link</a>) | @EGreg
<br/>
October 28, 2020 | https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/ | <a href="https://web.archive.org/web/*/https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>Now that 2020 is here, let’s look at what we can expect from the next decade in software. As Web developers, our solutions can help shape the organizations we work for. The tools we build and the architectural decisions we make have a compounding effect on society at large. What are the new trends, and will they help empower or enslave people?</p>
<h2>The Old Trends</h2>
<p>The trends in the last 10-20 years have led to more and more <a href="https://qbix.com/blog/2017/08/20/centralization-and-open-source/">centralization of the Web</a>, consolidation of power in the hands of the largest services (Facebook, Google, Amazon, Reddit) and their extended ecosystems. Between these and the large publications, the “independent Web” has suffered a tremendous setback.  Most people and organizations trust large corporations with proprietary algorithms to manage their data, identity and brand. This has led to <a href="https://qbix.com/blog/2019/03/08/how-qbix-platform-can-change-the-world/">massive new issues for individuals and society</a>, involving governments and corporations, and how we all relate to one another. Attempts to resolve these issues have spawned some projects to <a href="https://qbix.com/blog/2017/08/30/the-future-of-decentralization/">decentralize the Web</a>.</p>
<p>When the Web was born, browsers rendered HTML documents, and there was very little support for client-side programming. Whatever Javascript support was introduced over the next decade was inconsistent because of the <a href="https://en.wikipedia.org/wiki/Browser_wars">browser wars</a>, and led to <a href="http://www.jqueryvsmootools.com/">Javascript libraries</a> to bridge the gap, of which jQuery emerged as the winner. The last 10 years saw the rise of <a href="https://angular.io/">Angular</a> and <a href="https://reactjs.org/">React</a>, new versions of <a href="https://developer.mozilla.org/en-US/docs/Web/Guide/HTML/HTML5">Javascript</a> and <a href="https://developer.mozilla.org/en-US/docs/Web/API">HTML5 Web APIs</a>, which finally made front-end Web programming a powerful proposition on the most widely deployed platform in the world.</p>
<h2>Client-First Web Apps</h2>
<p>As Javascript was maturing, a conventional wisdom has developed among most Web developers, that you should render the HTML on the client side, and then progressively enhance it with Javascript. This was considered best practice and recommended by pretty much every authority from <a href="https://www.freecodecamp.org/news/what-is-progressive-enhancement-and-why-it-matters-e80c7aaf834a/">2009</a> to <a href="https://www.freecodecamp.org/news/what-is-progressive-enhancement-and-why-it-matters-e80c7aaf834a/">2018</a>.</p>
<p>In this decade, Web developers will turn this conventional wisdom on its head, and start to consider progressive enhancement to go the other way:</p>
<ol>
<li>First, develop static HTML, CSS and Javascript</li>
<li>Make Javascript fetch data from servers, render it on the client</li>
<li>Progressively enhance the site for older environments (Server-rendered HTML)</li>
</ol>
<p>What follows are multiple reasons for why this is the better approach going forward. <span>This one shift in how we approach Web development will have profound technological and societal implications.</span></p>
<h2 id="distributing-software">Distributing Software</h2>
<p><strong>1. Separation of concerns.</strong> It pays to decouple the rendering of an interface from the delivery of code / markup. That way we are not tied to one type of app delivery — that of a server on the web sending our executable code. We are able to <a href="https://en.wikipedia.org/wiki/Sideloading">sideload apps</a>, download them from <a href="https://developer.apple.com/documentation/bundleresources">app stores</a>, and update specific files when they have changed. And we use one language for each task, too: JS is the code. HTML / Handlebars / etc. can be used for templates / markup. CSS is used for presentation. JSON or XML is used for data. After you have done this, if you want to pre-render HTML on a server for AJAX, you can, but will start to feel “dirty” as you’ll be coupling things unnecessarily again. Things are going this way as <a href="https://www.gatsbyjs.org/blog/2019-10-15-free-headless-cms/">headless CMSes</a> are making an appearance, while <a href="https://cordova.apache.org/">Cordova</a>, <a href="https://ionicframework.com/">Ionic</a> and <a href="https://facebook.github.io/react-native/">React Native</a> represent other ways of delivering code through app stores.</p>
<p><strong>2. Trust. </strong> You can’t trust what code is running remotely (although Signal <a href="https://signal.org/blog/private-contact-discovery/">has been experimenting</a> with using <a href="https://software.intel.com/en-us/articles/innovative-technology-for-cpu-based-attestation-and-sealing">Software Guard Extensions</a> by CPU makers, originally designed for DRM, to go the other way and ensure what code runs on a server). But even if you can, you have no guarantee some other process won’t steal or corrupt your data. The <a href="https://en.wikipedia.org/wiki/Trusted_computing_base">Trusted Computing Base</a> should not include arbitrary amounts of remote sites shipping code at any time. Decoupling how the code is loaded (see point #1) onto your client allows you or your user agent to verify checksums and certify that it is indeed the code you think it is. And it is that code that should be managing your data and using the personal keys on your device. Package managers and app stores will be able to distribute code that has been audited by third-party security firms, and people will be able to trust them.</p>
<p><strong>3. Decentralization of Code.</strong> As the next decade unfolds, we will find that&nbsp;code bases don’t necessarily have to live shrink-wrapped on a specific server. Rather, clients can use multiple interoperable software modules and versions and can have multiple app stores and distributors in the future helping maintain repos and package managers for end-users and organizations. We will probably see automated package management become more user friendly in the 2020s, as we already have a docker container culture, we have browser based package managers etc.</p>
<h2 id="data-ownership">Data Ownership</h2>
<p><strong>4. Decentralization of Data.</strong> This is the big one in terms of effect on society. By having web servers render your webpage, you are implicitly locking yourself and your organization into the type of model where the servers store and access the data in a private database. They have enough data to render everything, apply access control rules to manage what you can read and write, and so on. Instead, we as a society need to empower people and their client side apps, and push the logic of fetching data, caching it and assembling it to the <a href="https://continuations.com/post/108271329110/tedxnewyork-big-and-bot-policy-proposals">user agents</a>. We can use <a href="https://en.wikipedia.org/wiki/Capability-based_security">capabilities</a> / <a href="https://www.oauth.com/oauth2-servers/access-tokens/">access tokens</a> for data instead of a centralized site rendering HTML. <span>In this way, always inverting the progressive enhancement is an <em><span>activist</span></em> position to change society against the abuses of power </span><a href="https://qbix.com/blog/2019/03/08/how-qbix-platform-can-change-the-world/">like the ones listed here</a>.</p>
<p><strong>5. Reliability</strong> After the 2015 ISIS attacks in Paris, countries around the world expressed solidarity with the French people. French colors were flown, but similar-sized attacks at the same time by ISIS in <a href="https://www.nytimes.com/2015/11/16/world/middleeast/beirut-lebanon-attacks-paris.html?smid=tw-nytimesworld&amp;smtyp=cur&amp;_r=0">Beirut</a> were totally forgotten. Facebook rolled out a feature to customize one’s profile with the French flag superimposed, but only the French flag. So we used the Qbix Platform to quickly build a small app called <a href="https://customizemypic.com/">customizemypic.com</a> to allow anyone to change their profile picture to a flag of their choice. The goal was to make a statement and express solidarity with people in Beirut, Baghdad and other areas hard hit by terrorism. Today, that same app is no longer able to do its core function because Facebook <a href="https://developers.facebook.com/blog/post/2018/04/24/new-facebook-platform-product-changes-policy-updates/">removed any way for users to give permissions to apps</a> to upload a photo on their behalf. This is what happens when you rely on third parties to announce what you can and cannot do with your own profile picture. The most extreme reliability is achieved by an <a href="http://offlinefirst.org/">offline-first</a> approach, which is a close cousin of the client-first trend that will grow in the 2020s.</p>
<p><strong>6. End to End Encryption.</strong> Server-side rendering perpetuates a culture where the server has all the data unencrypted. Even if the data is encrypted at rest, the served holds all the decryption keys and is one central target for hackers, government agencies, and advertisers. Rendering things client-side goes hand-in-hand with a culture of people storing their own keys on devices of their choice, and letting key management and password management be the domain of operating systems and trusted computing bases, not random websites.</p>
<h2 id="Data Delivery">Data Delivery</h2>
<p><strong>7. Bandwidth.</strong> Ever since <a href="https://www.youtube.com/watch?v=rm8FAHGJB3M">Steve Jobs presented WebObjects</a>, we have wanted sites to render dynamically. Well, that often involves looping through various items and rendering each one. It is extremely wasteful to send the HTML results of rendering hundreds of items to a client, when you could have just sent the data, which would then be “hydrated” into 5. templates by the client. However, I can understand pre-rendering just the items above the fold (if one could estimate this number, not knowing the size of the window on the first request).</p>
<p><strong>8. Caching Issues.</strong> Often, you have subtle and pervasive changes on every page when a person is logged in vs out. (I should remark that “logging in” into a site itself is an artifact of “centralized” thinking, but I digress.) Their avatar might be rendered in various places. New links are shown that might not be available otherwise. And new information may be shown that access control and discovery suggestions determines they can see. If you render everything on the served, there is no way to cache most of the fragments of the page, because they are changing. If you render client-side, all this comes for free.</p>
<h2 id="next-steps">Next Steps for Web Developers</h2>
<p>So by now you may be convinced that “client-first” is a good design pattern and progressive enhancement can be implemented later, by “speeding up” the first render, and by making it available to “dumb” crawlers and user agents who don’t execute Javascript in 2020. Here is how that would actually look, in actionable terms:</p>
<p><strong>9. Preloading. </strong>Okay, now that you are rendering everything client-side, you can implement a mechanism to preload data from the server. Perhaps put all the JSON in one file and send it over on the first render. Which — remember — happens only when you use a Web Browser to visit a page directly, a very specific scenario. Every other request besides that, including subsequent requests from a web browser, don’t need this preload. It’s an extra flair you can add for that specific use case. So the preloaded data comes and your Javascript will already have it and will render the HTML synchronously and quickly.</p>
<p><strong>10. Static Site Generation. </strong>The most popular static site generators today are still pretty narrow in their use-case. They help with blogs and publishing, eg <a href="https://jekyllrb.com/">Jekyll</a>, <a href="https://gohugo.io/">Hugo</a>, etc. But if you already have a dynamic site, you can sort of transform it into a static site by having a server-side script request some (dynamically specified) set of pages and render them to some related static html documents, and then begin sending 301 redirects on the dynamic pages to permanently tell browsers to go to the static pages in the future. (Because rewriting all links in your site may be infeasible). This approach runs into problems I described in point 5 — so a naive approach would only work for publicly accessible pages …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/">https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/</a></em></p>]]>
            </description>
            <link>https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24924810</guid>
            <pubDate>Wed, 28 Oct 2020 22:24:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taskcluster's DB (Part 1) – Azure to Postgres]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24924715">thread link</a>) | @headalgorithm
<br/>
October 28, 2020 | http://code.v.igoro.us/posts/2020/10/tc-db-part-1.html | <a href="https://web.archive.org/web/*/http://code.v.igoro.us/posts/2020/10/tc-db-part-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div><p>This is a deep-dive into some of the implementation details of <a href="https://taskcluster.net/">Taskcluster</a>.
Taskcluster is a platform for building continuous integration, continuous deployment, and software-release processes.
It’s an <a href="https://github.com/taskcluster/taskcluster">open source project</a> that began life at Mozilla, supporting the Firefox build, test, and release systems.</p>

<p>The Taskcluster “services” are a collection of microservices that handle distinct tasks: the queue coordinates tasks; the worker-manager creates and manages workers to execute tasks; the auth service authenticates API requests; and so on.</p>



<p>Until April 2020, Taskcluster stored its data in Azure Storage tables, a simple NoSQL-style service similar to AWS’s DynamoDB.
Briefly, each Azure table is a list of JSON objects with a single primary key composed of a partition key and a row key.
Lookups by primary key are fast and parallelize well, but scans of an entire table are extremely slow and subject to API rate limits.
Taskcluster was carefully designed within these constraints, but that meant that some useful operations, such as listing tasks by their task queue ID, were simply not supported.
Switching to a fully-relational datastore would enable such operations, while easing deployment of the system for organizations that do not use Azure.</p>

<h2 id="always-be-migratin">Always Be Migratin’</h2>

<p>In April, we migrated the existing deployments of Taskcluster (at that time all within Mozilla) to Postgres.
This was a “forklift migration”, in the sense that we moved the data directly into Postgres with minimal modification.
Each Azure Storage table was imported into a single Postgres table of the same name, with a fixed structure:</p>

<pre><code>create table queue_tasks_entities(
    partition_key text,
    row_key text,
    value jsonb not null,
    version integer not null,
    etag uuid default public.gen_random_uuid()
);
alter table queue_tasks_entities add primary key (partition_key, row_key);
</code></pre>

<p>The <a href="https://github.com/helfi92/taskcluster/blob/6b3220305124388803da060811d8ea584f92aefe/infrastructure/tooling/src/importer/importer.js">importer</a> we used was specially tuned to accomplish this import in a reasonable amount of time (hours).
For each known deployment, we scheduled a downtime to perform this migration, after extensive performance testing on development copies.</p>

<p>We considered options to support a downtime-free migration.
For example, we could have built an adapter that would read from Postgres and Azure, but write to Postgres.
This adapter could support production use of the service while a background process copied data from Azure to Postgres.</p>

<p>This option would have been very complex, especially in supporting some of the atomicity and ordering guarantees that the Taskcluster API relies on.
Failures would likely lead to data corruption and a downtime much longer than the simpler, planned downtime.
So, we opted for the simpler, planned migration.
(we’ll revisit the idea of online migrations in part 3)</p>

<p>The database for <a href="https://firefox-ci-tc.services.mozilla.com/">Firefox CI</a> occupied about 350GB.
The other deployments, such as the <a href="https://community-tc.services.mozilla.com/">community deployment</a>, were much smaller.</p>

<h2 id="database-interface">Database Interface</h2>

<p>All access to Azure Storage tables had been via the <a href="https://github.com/taskcluster/azure-entities">azure-entities</a> library, with a limited and very regular interface (hence the <code>_entities</code> suffix on the Postgres table name).
We wrote an implementation of the same interface, but with a Postgres backend, in <a href="https://github.com/taskcluster/taskcluster/tree/23e2fb746068f6e647946347eebffddd5e1b93fb/libraries/entities">taskcluster-lib-entities</a>.
The result was that none of the code in the Taskcluster microservices changed.
Not changing code is a great way to avoid introducing new bugs!
It also limited the complexity of this change: we only had to deeply understand the semantics of azure-entities, and not the details of how the queue service handles tasks.</p>

<h2 id="stored-functions">Stored Functions</h2>

<p>As the <a href="https://github.com/taskcluster/taskcluster/tree/23e2fb746068f6e647946347eebffddd5e1b93fb/libraries/entities">taskcluster-lib-entities</a> README indicates, access to each table is via five stored database functions:</p>

<ul>
  <li><code>&lt;tableName&gt;_load</code> - load a single row</li>
  <li><code>&lt;tableName&gt;_create</code> - create a new row</li>
  <li><code>&lt;tableName&gt;_remove</code> - remove a row</li>
  <li><code>&lt;tableName&gt;_modify</code> - modify a row</li>
  <li><code>&lt;tableName&gt;_scan</code> - return some or all rows in the table</li>
</ul>

<p>Stored functions are functions defined in the database itself, that can be redefined within a transaction.
<a href="http://code.v.igoro.us/posts/2020/10/tc-db-part-2.html">Part 2</a> will get into why we made this choice.</p>

<h3 id="optimistic-concurrency">Optimistic Concurrency</h3>

<p>The <code>modify</code> function is an interesting case.
Azure Storage has no notion of a “transaction”, so the azure-entities library uses an optimistic-concurrency approach to implement atomic updates to rows.
This uses the <code>etag</code> column, which changes to a new value on every update, to detect and retry concurrent modifications.
While Postgres can do much better, we replicated this behavior in taskcluster-lib-entities, again to limit the changes made and avoid introducing new bugs.</p>

<p>A modification looks like this in Javascript:</p>
<pre><code>await task.modify(task =&gt; {
  if (task.status !== 'running') {
    task.status = 'running';
    task.started = now();
  }
});
</code></pre>

<p>For those not familiar with JS notation, this is calling the <code>modify</code> method on a task, passing a modifier function which, given a task, modifies that task.
The <code>modify</code> method calls the modifier and tries to write the updated row to the database, conditioned on the etag still having the value it did when the task was loaded.
If the etag does not match, <code>modify</code> re-loads the row to get the new etag, and tries again until it succeeds.
The effect is that updates to the row occur one-at-a-time.</p>

<p>This approach is “optimistic” in the sense that it assumes no conflicts, and does extra work (retrying the modification) only in the unusual case that a conflict occurs.</p>

<h2 id="whats-next">What’s Next?</h2>

<p>At this point, we had fork-lifted Azure tables into Postgres and no longer require an Azure account to run Taskcluster.
However, we hadn’t yet seen any of the benefits of a relational database:</p>
<ul>
  <li>data fields were still trapped in a JSON object (in fact, some kinds of data were hidden in base64-encoded blobs)</li>
  <li>each table still only had a single primary key, and queries by any other field would still be prohibitively slow</li>
  <li>joins between tables would also be prohibitively slow</li>
</ul>

<p><a href="http://code.v.igoro.us/posts/2020/10/tc-db-part-2.html">Part 2</a> of this series of articles will describe how we addressed these issues.
Then part 3 will get into the details of performing large-scale database migrations without downtime.</p>
</div>
    
    
    
</div></div>]]>
            </description>
            <link>http://code.v.igoro.us/posts/2020/10/tc-db-part-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24924715</guid>
            <pubDate>Wed, 28 Oct 2020 22:14:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No, an Apple search engine is not coming. This data shows why]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24924620">thread link</a>) | @mgh2
<br/>
October 28, 2020 | https://www.businessofbusiness.com/articles/apple-search-engine-is-not-real-google-siri-applebot/ | <a href="https://web.archive.org/web/*/https://www.businessofbusiness.com/articles/apple-search-engine-is-not-real-google-siri-applebot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-section">
    <!-- .sidebar -->

    <section>
      
      

      <p><span>Last week, an article from tech blog </span><a href="https://www.coywolf.news/seo/apple-search-engine/"><span>Coywolf</span></a><span> lit a fire under rumors that Apple could soon launch a search engine to compete with Google. The story went </span><a href="https://www.reddit.com/r/apple/comments/ihfk5w/apple_showing_signs_it_may_soon_launch_a_search/"><span>viral on Reddit</span></a><span>, and it’s easy to see why. Fans (read: shareholders) have long speculated and </span><a href="https://www.reddit.com/r/apple/search?q=search%20engine&amp;restrict_sr=1"><span>hoped</span></a><span> that the company would create a search engine so that Apple, already </span><a href="https://www.cnbc.com/2020/07/31/apple-surpasses-saudi-aramco-to-become-worlds-most-valuable-company.html"><span>the most valuable company in the world</span></a><span>, could grow to even more gargantuan proportions.&nbsp;</span></p>
<p><span>The evidence author Jon Henshaw lays out seems convincing, too. Google pays billions to Apple to remain its default search engine on Safari and iOS devices, and UK regulators, who have a track record of cracking down on Google, are </span><a href="https://www.reuters.com/article/us-apple-google/uk-regulators-take-aim-at-apples-search-engine-deal-with-google-idUSKBN242748"><span>looking to break up the deal</span></a><span>. Should that happen, Apple would be perfectly positioned to launch its own engine and thrive without a Google partnership, especially since Apple has been bolstering its existing search tools like Siri Spotlight and web crawler Applebot.</span></p>
<p><span>It’s easy to get excited about Apple launching a service that could make stocks go crazy, but our advice is to cool your expectations. Our data shows that no, Apple is probably not about to launch a search engine. Let’s explain why.</span></p>


<p><span>Over the last three years, our data shows that job listings on Apple’s site for “Search” or “Search Engineer” positions have increased meaningfully from about 30 listings throughout 2017 to about 70 throughout 2020 so far, which helps explain the improvements to Applebot and Siri Spotlight. But that is still only 70 people who are theoretically working towards building a search engine, and job listings with these keywords took a notable dive over the last month down to 53.&nbsp;</span></p>
<p><span>By comparison, Google revealed in its </span><a href="https://abc.xyz/investor/"><span>latest quarterly filing</span></a><span> that its employee count was 127,498 as of June, and that the largest headcount additions by product were for Google Cloud and Search. That’s not just an anomaly for this quarter, either. The same language was used in its Q1 2020 filing, as well as in its yearly filing for 2019. Between its Q1 and Q2 filings, Google claims to have hired 4,450 employees - we can reasonably assume that a large portion of those hires are dedicated to its search engine. If the rumors are true,&nbsp;</span><span>Apple’s 70 or so listings pale&nbsp;in comparison to the hundreds or possibly even thousands of new additions each month that Google devotes to simply maintaining and updating its search engine.</span></p>
<p><span>The Coywolf article points to the huge number of job listings that pop up on Apple’s site when you search for “</span><a href="https://jobs.apple.com/en-us/search?search=search%20engineer&amp;sort=relevance"><span>search engineers</span></a><span>” as evidence that Apple is ramping up production on a search engine. Why, then, does our data only show 53 listings?</span></p>


<p><span>The answer is that Apple’s jobs site is not only searching for posts with “search engineer” in the title or description, but also those with “search” and “engineer,” substantially inflating the results. Our data shows that Apple currently has around 2,300 open listings that contain the keyword “engineer.” Maybe Apple should hire some search engineers to refine searches for search engineer jobs.</span></p>
<p><span>As some Redditors&nbsp;pointed out, similar articles to Coywolf’s have popped up throughout Apple's history, like when </span><a href="https://www.reddit.com/r/apple/comments/ihfk5w/apple_showing_signs_it_may_soon_launch_a_search/g2zyepe?utm_source=share&amp;utm_medium=web2x&amp;context=3"><span>Applebot was first announced</span></a><span>, and have routinely proven to be false or more indicative of other, smaller moves. Coywolf certainly lays out a compelling case, but a closer look at hiring data reveals that the fabled Apple search engine will remain just that for now.</span></p>
<h3>About the Data:</h3>
<p><span><span><span>Thinknum tracks companies using the information they post online, jobs, social and web traffic, product sales, and app ratings, and&nbsp;creates data sets that measure factors like hiring, revenue, and foot traffic. Data sets may not be fully comprehensive (they only account for what is available on the web), but they can be used to gauge performance factors like staffing and sales.&nbsp;</span></span></span></p>

      

      
    </section><!-- .article-body -->

    
  </div></div>]]>
            </description>
            <link>https://www.businessofbusiness.com/articles/apple-search-engine-is-not-real-google-siri-applebot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24924620</guid>
            <pubDate>Wed, 28 Oct 2020 22:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Clean Code]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24924601">thread link</a>) | @bagerbach
<br/>
October 28, 2020 | https://bagerbach.com/books/clean-code-a-handbook-of-agile-software-craftmanship/ | <a href="https://web.archive.org/web/*/https://bagerbach.com/books/clean-code-a-handbook-of-agile-software-craftmanship/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Small things matter.</p>
<ul>
<li>Know where things are. Naming is crucial.</li>
<li>A piece of code should be where you expect to find it. If not, refactor to get it there.</li>
<li>Don't litter your code with comments and commented-out code that "capture history or wished for the future".</li>
<li>Standardization is important.</li>
<li>Have the discipline to follow the practices. To frequently reflect upon your work — and be willing to change.</li>
</ul>
<p>"In code, refactor mercilessly". Reminds me of a simple writing tip: Imagine that you are paid for each word that you remove, while still keeping the meaning. That's how you write well.</p>
<p>Craftsmanship is the way to write good code. How do we learn it? Knowledge and work. Gain the knowledge (principles, patterns, practices, heuristics) and grind that knowledge into yourself by working hard and practicing.</p>
<p>You could know it all, but without the hard work, you wouldn't be able to put it to practice. Practice and fail. And then try again.</p>
<p>You could skip the case studies in this book, in which case you've read another 'feel good' book about writing good code. Then you've learned nothing. But you can pay close attention to even the smallest details and follow along closely, then you'll learn quite a lot.</p>

<p>If you keep making a mess, it'll slow you down in the long run.</p>
<p>We read more code than we write, so we should make it easier to read — even if that makes it harder to write. But since we can't write it without reading it, we're actually making it easier to write as well. But this is over the long term.</p>
<p>We don't just write clean code. We have to maintain it as well. So keep it clean.</p>

<ul>
<li>Names should reveal intentions. If it requires a comment to explain, it's not a good name</li>
<li>"Avoid Disinformation"</li>
<li>Be very careful with similar names — it can be very misleading (breaking the above rule!)</li>
<li>"Make Meaningful Distinctions" — different names for different things. <code>v1</code> and <code>v2</code> could be <code>source</code> and <code>destination</code> — much better names.</li>
<li>"Noise words are redundant". <code>variable</code> should never appear in a variable name, don't put <code>string</code> in the name of a string, don't make two variables like <code>thing</code> and <code>theThing</code>. Distinguishing names is important.</li>
<li>"Use Pronounceable Names"</li>
<li>"Use Searchable Names"</li>
<li>"Avoid Encodings" — never actually seen this before.</li>
<li>
<p>"Avoid Mental Mapping" — Just because you know what it means, doesn't mean that someone else will.</p>
<ul>
<li>Class names should be nouns or noun phrases, not verbs.</li>
<li>Method names should be verbs or verb phrases. Accessors, mutators, and predicates should be prefixed with <code>get</code>, <code>set</code>, or <code>is</code>.</li>
</ul>
</li>
<li>"Don't Be Cute" — Say what you mean. Jokes are only fun for you and those in on them.</li>
<li>"Pick One Word per Concept" — If you write <code>fetch</code> and not <code>retrieve</code>, stick with it.</li>
<li>"Don't Pun"</li>
<li>"Use Solution Domain Names" — You can use technical terms</li>
<li>"Use Problem Domain Names" — When there are no technical terms, use the name from the problem domain.</li>
<li>"Add Meaningful Context" — If you see an address form, you might see 'state' as a variable. But if you see 'state' alone somewhere, would you assume that it's related to an address? Here, meaningful context could be naming it <code>addrState</code>.</li>
<li>"Don't Add Gratuitous Context"</li>
</ul>

<ul>
<li>Functions should be small.</li>
<li>They should do only one thing.</li>
<li>One Level of Abstraction per Function.</li>
<li>Code should be able to read from the top to bottom. This is <em>The Stepdown Rule</em>.</li>
<li>General rule for switch statements: "they can be tolerated if they appear only once, are used to create polymorphic objects, and are hidden behind an inheritance".</li>
<li>Use descriptive names.</li>
<li>The fewer arguments the better.</li>
<li>They should have no side effects.</li>
<li>They should either do something or answer something. Not both.</li>
<li>Exceptions &gt; Returning Error Codes</li>
<li>Extract Try/Catch blocks into functions of their own.</li>
<li>Error handling is one thing.</li>
<li>Don't Repeat Yourself. The more duplicates, the more has to be changed when necessary. And more room for errors.</li>
<li>You don't have to get all of this perfect in your first try. It is as writing. You can edit and refine.</li>
</ul>

<ul>
<li>Only for when we can't express ourselves well enough with code.</li>
<li>Comments don't make up for bad code.</li>
<li>Explain yourself in code — comments should not be necessary.</li>
<li>
<p><strong>Good comments (if necessary)</strong></p>
<ul>
<li>Legal comments — copyright, authorship, etc.</li>
<li>Informative comments</li>
<li>Explanation of intent</li>
<li>Clarification</li>
<li>Warning of Consequences</li>
<li>Todos</li>
<li>Amplification (of importance)</li>
</ul>
</li>
<li>
<p><strong>Bad comments</strong></p>
<ul>
<li>Mumbling — Commenting because you 'should'</li>
<li>Redundant comments — explaining code that explains itself</li>
<li>Misleading comments — not accurate</li>
<li>Mandated comments</li>
<li>Journal comments — use source control...</li>
<li>Noise comments — restate the obvious, provide no new information</li>
<li>Scary noise — copy pasting and forgetting to change contents</li>
</ul>
</li>
<li>Functions or variables &gt; comments</li>
<li>Don't have commented-out code</li>
<li>Don't have 'attribution comments'. Source control can do that.</li>
<li>No systemwide information in the context of a local comment</li>
<li>Don't put historical discussions or irrelevant descriptions of details into comments.</li>
</ul>

<ul>
<li>Agree upon rules for formatting and be consistent in following them.</li>
<li>Source files names should be simple but explanatory.</li>
<li>Source files shouldn't be too big.</li>
<li>Variables should be declared as close to their usage as possible.</li>
<li>Instance variables should be declared at the top of the class.</li>
<li>If a function calls another, they should be vertically close. The caller should be above the callee, if possible.</li>
<li>In general, a function that is called should be below a function that does the calling.</li>
<li>Short lines — you shouldn't have to scroll to the right.</li>
<li>Indentation is important.</li>
</ul>

<ul>
<li>We want to be free to change the type of variables or implementation on a whim.</li>
<li>"Objects hide their data behind abstractions and expose functions that operate on that data"</li>
<li>"Data structure expose their data and have no meaningful functions"</li>
<li>The Law of Demeter: "a module should not know about the innards of the objects it manipulates"</li>
</ul>

<ul>
<li>"Error handling is important, but if it obscures logic, it's wrong".</li>
<li>Exceptions &gt; return codes</li>
<li>Write <code>Try-Catch-Finally</code> first</li>
<li>Don't return null. And don't pass it either.</li>
</ul>

<ul>
<li>Having bad tests is worse or equal to having no tests.</li>
<li>Readability makes tests clean. Clarity, simplicity, and density of expression. Say a lot with as few expressions as possible.</li>
<li>One assert per test.</li>
<li>A single concept per test.</li>
<li>
<p>Clean tests are <strong>F.I.R.S.T</strong></p>
<ul>
<li>Fast, independent, repeatable, self-validating, and timely.</li>
</ul>
</li>
</ul>

<ul>
<li>Variables first. Then public functions. Private utilities thereafter.</li>
<li>Variables and utility functions should be kept private, but that's not a strict rule.</li>
<li>Classes should be small. It shouldn't have too many responsibilities.</li>
<li>The name of a class should describe it's responsibilities.</li>
<li>The Single Responsibility Principle = classes or modules should only have one responsibility — one reason to change.</li>
<li>Classes should have a small number of instance variables.</li>
<li>Each method should manipulate one or more of those variables. The more variables a method manipulates, the more cohesive it is to the class. We want this cohesion to be high.</li>
</ul>

<ul>
<li>
<p>Design is simple (according to Kent Beck) if it:</p>
<ul>
<li>"Runs all the tests"</li>
<li>"Contains no duplication"</li>
<li>"Expresses the intent of the programmer"</li>
<li>"Minimizes the number of classes and methods"</li>
</ul>
</li>
</ul>

<ul>
<li>Concurrency helps us decouple what gets done from when it gets done.</li>
<li>
<p>Common misconceptions:</p>
<ul>
<li>It always improves performance.</li>
<li>Design doesn't change because of it.</li>
<li>Understanding it is not important when working with a container.</li>
<li>It incurs some overhead.</li>
<li>"Complex concurrency is complex, even for simple problems."</li>
<li>The bugs aren't usually repeatable.</li>
<li>It requires a fundamental change in design strategy.</li>
</ul>
</li>
<li>Limit access to data that may be shared.</li>
<li>Threads should be as independent as possible.</li>
<li>Know your library. Know what's available to you.</li>
<li>
<p>Know your execution models.</p>
<ul>
<li>Producer-Consumer</li>
<li>Readers-Writers.</li>
<li>Dining Philosophers.</li>
</ul>
</li>
<li>To understand those execution models, you might want to know about Bound Resources, Mutual Exclusion, Starvation, Deadlock, and Livelock.</li>
</ul>
</div></div>]]>
            </description>
            <link>https://bagerbach.com/books/clean-code-a-handbook-of-agile-software-craftmanship/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24924601</guid>
            <pubDate>Wed, 28 Oct 2020 22:01:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[macOS Nix Setup]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24924538">thread link</a>) | @enqk
<br/>
October 28, 2020 | https://wickedchicken.github.io/post/macos-nix-setup/ | <a href="https://web.archive.org/web/*/https://wickedchicken.github.io/post/macos-nix-setup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>I recently got a new Macbook, and began setting up the <a href="https://nixos.org/">Nix</a> package manager to
install my developer toolset. I mainly did this to try and have a working setup without
installing <a href="https://brew.sh/">Homebrew</a>. Since I ran into a few issues, I wanted to briefly
document what I did and why in case others wanted to try the same.</p>
<h3 id="why-nix-and-why-not-homebrew-or-macports">Why Nix? (and why not Homebrew or MacPorts?)</h3>
<p>The short answer: hype.</p>
<p>The long answer: I’ve been frustrated with Homebrew’s user experience for years now, and
used this opportunity to start afresh. The default non-Homebrew answer is the venerable
<a href="https://www.macports.org/">MacPorts</a>, which has been around for quite a while. Most people who aren’t
functional programming or build system nerds should probably use MacPorts, as it has been
around long enough to have good support documentation floating around the internet.
Unfortunately I’m a sucker for hermetic builds <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, so I decided to try
Nix.</p>
<p>In addition, Nix has one cool feature I haven’t seen anywhere else: temporarily installing
packages using <code>nix-shell</code>. For example, I can install <code>ripgrep</code> inside a temporary shell,
and the package is automatically cleaned up when I’m done:</p>
<p>There’s a lot of cool stuff <code>nix-shell</code> can do, check out some more examples
<a href="https://ghedam.at/15978/an-introduction-to-nix-shell">here</a>.</p>
<h4 id="why-not-homebrew">Why not Homebrew?</h4>
<p>If Homebrew works for you, then by all means keep using Homebrew! However, I’ve grown
frustrated with it. Homebrew has spent a lot of effort making a software delivery system
work across many iterations of OSX/MacOS, and countless developers have installed <code>brew</code>
as one of the first things on a new Mac. It is with this acknowledgement of the work the
Homebrew developers have put into the software and its resulting success that I offer
these criticisms:</p>
<ol>
<li>
<p>Unpredictable command times. I never know if running <code>brew install</code> or <code>brew upgrade</code>
is going to take 5 seconds or 20 minutes. This usually means knowing if a program or
dependency is being downloaded as a prebuilt binary or compiled on the spot. It would
be nice to signal to the user if compilation is about to happen, so they can plan the
install accordingly.</p>
</li>
<li>
<p>Very slow <code>brew update</code> times. Homebrew’s core package database is a
<a href="https://github.com/Homebrew/homebrew-core">git repository</a>, which is great for enabling collaboration. Nix uses
the <a href="https://github.com/NixOS/nixpkgs">same model</a>, but the difference lies in how the clients get the package
database: <code>brew update</code> does a <code>git pull</code> under the hood, while <code>nix-channel --update</code>
downloads a compressed tarball each time the channel is updated. This means Homebrew
updates can rely on git and GitHub itself as an efficient distribution mechanism,
getting delta updates “for free” without setting up extra infrastructure. However,
this design choice means that the client has to maintain its own git repo –
<a href="https://github.com/Homebrew/brew/issues/4755#issuecomment-416572560"><code>git gc</code> can strike at any time</a>, for example, and slow things down
tremendously. It is also a nightmare for <a href="https://discourse.brew.sh/t/best-practice-for-homebrew-on-travis-brew-update-is-5min-to-build-time/5215">CI</a>, where the lack of
an updated Homebrew git cache can negatively impact build times. Meanwhile,
<code>nix-channel --update</code> runs are very predictable, even if a bit inefficient – you’re
downloading a 16Mb tarball when the channel is updated, but that’s it.</p>
</li>
<li>
<p>Bad interactions when packages are upgraded. I’m not sure exactly why this happens, but
occasionally when certain packages are upgraded (such as <code>python</code> from 3.7 to 3.8),
<a href="https://discourse.brew.sh/t/homebrew-updating-major-python-version-breaks-a-lot-of-things-on-my-system/8545">related packages can break</a>. Because Nix builds are hermetic,
packages should all “work together” regardless of how the system was previously set
up.</p>
</li>
</ol>
<h4 id="why-not-macports">Why not MacPorts?</h4>
<p>To be honest, MacPorts is probably just fine for your needs. I haven’t used it in forever,
but my understanding is that it’s reliable and has plenty of built-up community knowledge
on how to fix things. Take a look at it and see if it fits your needs! I also quickly
found <a href="https://saagarjha.com/blog/2019/04/26/thoughts-on-macos-package-managers/">this post</a> which details some differences between it and
Homebrew. But hey, if you like adventure, give Nix a shot!</p>
<h4 id="why-not-nix">Why not Nix?</h4>
<p>I felt it was honest to include a section like this.</p>
<ol>
<li>
<p>I haven’t done a deep evaluation, but my impression is that Nix is the least documented
and least mature of the bunch. Expect to do a bit more digging to solve issues, but
once you get started it generally just works.</p>
</li>
<li>
<p>Workarounds are currently needed for Catalina and above, especially if you have an
older Mac without a T2 chip.</p>
</li>
<li>
<p>You’ll need to understand a bit of the <a href="https://nixos.wiki/wiki/Nix_Expression_Language">Nix Expression Language</a>. It’s
not as scary as it sounds, but you will have to edit a <code>.nix</code> file to install a
package (there is no CLI equivalent to <code>brew install</code> that I am aware of).</p>
</li>
</ol>
<h3 id="installing-nix">Installing Nix</h3>
<p>Installing Nix requires two phases: installing Nix itself, and then installing
<a href="https://github.com/LnL7/nix-darwin">nix-darwin</a>. The installation methods I know of involve <code>curl</code>ing with an
eventual <code>sudo</code> call inside the script<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. You will have to do something extra if
you’re running Catalina<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> or above.</p>
<ol>
<li>
<p>Install Nix:</p>
<ul>
<li>Pre-Catalina: <code>curl https://nixos.org/nix/install | sh</code> (I haven’t tested this).</li>
<li>Catalina with a T2 chip: <code>sh &lt;(curl -L https://nixos.org/nix/install) --darwin-use-unencrypted-nix-store-volume</code>
(according to the site, “unecrypted” is a misnomer as the chip will encrypt it
anyway).</li>
<li>Catalina without a T2 chip: follow <a href="https://www.philipp.haussleiter.de/2020/04/fixing-nix-setup-on-macos-catalina/">these instructions</a>
<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>.</li>
</ul>
<p>Make sure that <code>nix-build</code> is now in your <code>PATH</code>. You may have to source
<code>$HOME/.nix-profile/etc/profile.d/nix.sh</code> in your shell’s <code>rc</code> file to get this to
work.</p>
</li>
<li>
<p>Install <code>nix-darwin</code>:</p>
<div><pre><code data-lang="sh">nix-build https://github.com/LnL7/nix-darwin/archive/master.tar.gz -A installer ./result/bin/darwin-installer
</code></pre></div><p>You should now have <code>darwin-rebuild</code> in your <code>PATH</code>.</p>
</li>
</ol>
<h3 id="using-nix">Using Nix</h3>
<p>The basic workflow for using Nix is editing <code>~/.nixpkgs/darwin-configuration.nix</code> and then
running <code>darwin-rebuild switch</code> to activate those changes.</p>
<h4 id="editing-darwin-configurationnix">Editing <code>darwin-configuration.nix</code></h4>
<p>Open up <code>~/.nixpkgs/darwin-configuration.nix</code> with your favorite editor. Look at
<code>environment.systemPackages</code>: this is the list of packages you’ll want to install.
<a href="https://nixos.org/guides/nix-pills/basics-of-language.html#idm140737320584496">Nix lists</a> are space-delimited (not comma-delimited). The packages listed
there come from the Nixpkgs channel you’re subscribed to. You can list what packages are
available by running <code>nix-env -qaP</code> or searching <a href="https://search.nixos.org/packages">Nixpkgs</a> online. All the
packages are prepended with <code>pkgs.</code>; I used Nix’s <code>with pkgs;</code> clause to prepend that by
default:</p>
<div><pre><code data-lang="nix">  environment<span>.</span>systemPackages <span>=</span> <span>with</span> pkgs; [
      gitAndTools<span>.</span>gitFull
      byobu
      wget
    ];
</code></pre></div><h4 id="activating-your-changes">Activating your changes</h4>
<p>Once you’re done editing, run <code>darwin-rebuild switch</code> to install your new packages! If you
made an error, <code>darwin-rebuild</code> will let you know and your current environment will not be
affected.</p>
<h4 id="updating-the-package-database">Updating the package database</h4>
<p>If you want to update the package database, you can run</p>
<h4 id="advanced-usage">Advanced usage</h4>
<p>Nix will detect conflicts and error out, such as when two packages install the same
binary. This can happen when <code>python37</code> and <code>python38</code>, for example, both want to create a
binary called <code>pydoc3</code>. To resolve this, you can call <code>lowPrio</code> to declare a package low
priority and have the other package win.</p>
<div><pre><code data-lang="nix">  environment<span>.</span>systemPackages <span>=</span> <span>with</span> pkgs; [
      python37
      (lowPrio python38)
    ];
</code></pre></div><p>(As a side note: once you’ve installed both, look at how quickly you can uninstall and
reinstall each package. It takes between 1 and 2 seconds to uninstall or reinstall
python3.7, which in my opinion is ridiculously fast.)</p>
<h3 id="further-reading">Further reading</h3>
<p>I have to admit that I only have a shallow knowledge of Nix, and the information above
has made it sufficient as a daily replacement for Homebrew. However, there is a rich
ecosystem around Nix that you may want to explore further. Here are a few links to learn
more:</p>
<ul>
<li><a href="https://stackoverflow.com/questions/53335308/what-does-nix-darwin-provide">What does <code>nix-darwin</code> provide?</a></li>
<li>The <a href="https://nixos.wiki/wiki/Nix_Ecosystem">Nix Ecosystem</a></li>
<li>The <a href="https://nixos.wiki/wiki/Nix_Expression_Language">Nix Expression Language</a></li>
<li><a href="https://nixos.org/guides/nix-pills/index.html">“Nix Pills”</a>, a detailed walkthrough of the Nix language and environment</li>
<li>Tips and tricks for using <a href="https://ghedam.at/15978/an-introduction-to-nix-shell"><code>nix-shell</code></a></li>
<li>The online <a href="https://search.nixos.org/packages">Nixpkgs search</a></li>
<li>A helpful <a href="https://nixos.wiki/wiki/Cheatsheet">Nix cheatsheet</a></li>
</ul>
<h3 id="good-luck-and-have-fun">Good luck and have fun!</h3>
<p>I hope this guide was helpful! Thanks to the Nix team for making such a cool package
manager. As I’m relatively new to Nix, feel free to contact me if there’s something I got
wrong or could have explained more clearly. Good luck and have fun with Nix!</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>From the <a href="https://landing.google.com/sre/sre-book/chapters/release-engineering/">Google SRE book</a>: a build that is “insensitive to
the libraries and other software installed on the build machine.” This greatly
increases reliability, because it means that whatever you have installed on your
computer is less likely to affect the build process and the resulting program. This is
similar to <a href="https://www.docker.com/">Dockerizing</a> an application, but less extreme and less
resource-intensive to run. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>This is just as risky as the classic <a href="https://stackoverflow.com/questions/29382739/why-using-curl-sudo-sh-is-not-advised"><code>curl | sudo sh</code></a>.
Unfortunately I can’t find another way to easily install Nix, so I guess you can
download <a href="https://nixos.org/nix/install">https://nixos.org/nix/install</a> and <a href="https://nixos.org/guides/nix-pills/install-on-your-running-system.html#idm140737320801568">compare its signature</a> before
running it. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Catalina gets a lot of shade for its read-only root filesystem and signed
binaries, but I think it’s a step forward for general purpose computing. What I object
to is that signed binaries must be signed with registered Apple developer accounts,
which cost money. It would be nice if that was a bit distributed, so anyone could sign
and Apple maintained a reputation database or something. I’m annoyed at Apple for
mixing good security and OS maintenance practices with total, walled-garden lockdown.
Admittedly, the web has a lot of the <a href="https://xkcd.com/1367/">same security benefits</a>, but we’re not at a
point yet where web apps can compete with native applications. Hopefully we’ll get
there one day. <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>Thanks Philipp for figuring all this out and writing it down! <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>
 </div></div>]]>
            </description>
            <link>https://wickedchicken.github.io/post/macos-nix-setup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24924538</guid>
            <pubDate>Wed, 28 Oct 2020 21:53:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nondeterminism in Scheme (Amb Operator)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24924292">thread link</a>) | @dunefox
<br/>
October 28, 2020 | https://ds26gte.github.io/tyscheme/index-Z-H-16.html#node_chap_14 | <a href="https://web.archive.org/web/*/https://ds26gte.github.io/tyscheme/index-Z-H-16.html#node_chap_14">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="slidecontent">



<p><a name="node_idx_466"></a><a name="node_idx_468"></a><a name="node_idx_470"></a>McCarthy’s nondeterministic operator
<code><span>amb</span></code> [<a href="https://ds26gte.github.io/tyscheme/index-Z-H-24.html#node_bib_25">25</a>,&nbsp;<a href="https://ds26gte.github.io/tyscheme/index-Z-H-24.html#node_bib_4">4</a>,&nbsp;<a href="https://ds26gte.github.io/tyscheme/index-Z-H-24.html#node_bib_33">33</a>] is as old as
Lisp itself, although it is present in no Lisp.
<code><span>amb</span></code> takes zero or more expressions, and makes a
nondeterministic (or “ambiguous”) choice among them,
preferring those choices that cause the program to
converge meaningfully.  Here we will explore an
embedding of <code><span>amb</span></code> in Scheme that makes a depth-first
selection of the ambiguous choices, and uses Scheme’s
control operator <code><span>call/cc</span></code> to backtrack for alternate
choices.  The result is an elegant backtracking
strategy that can be used for searching problem spaces
directly in Scheme without recourse to an extended
language.  The embedding recalls the continuation
strategies used to implement Prolog-style logic
programming [<a href="https://ds26gte.github.io/tyscheme/index-Z-H-24.html#node_bib_16">16</a>,&nbsp;<a href="https://ds26gte.github.io/tyscheme/index-Z-H-24.html#node_bib_7">7</a>], but is sparer because the
operator provided is much like a Scheme boolean
operator, does not require special contexts for its
use, and does not rely on linguistic infrastructure
such as logic variables and unification.</p>

<h2><a href="https://ds26gte.github.io/tyscheme/index-Z-H-1.html#node_toc_node_sec_14.1">14.1&nbsp;&nbsp;Description of <code><span>amb</span></code></a></h2>
<p>An accessible description of <code><span>amb</span></code> and many example
uses are found in the premier Scheme textbook
SICP [<a href="https://ds26gte.github.io/tyscheme/index-Z-H-24.html#node_bib_1">1</a>].  Informally,
<code><span>amb</span></code> takes zero or more expressions and <em>nondeterministically</em> returns the value of <em>one</em> of
them.  Thus,</p>

<pre>(<span>amb</span> <span>1</span> <span>2</span>)
</pre>



<p>may evaluate to 1 <em>or</em> 2.</p>
<p>
<code><span>amb</span></code> called with <em>no</em> expressions has no
value to return, and is considered to <em>fail</em>.
Thus,</p>

<pre>(<span>amb</span>)
<span><tt><strong><i>--&gt;ERROR!!!</i></strong></tt></span> <span>amb</span> <span>tree</span> <span>exhausted</span>
</pre>



<p>(We will examine the wording of the error message later.)</p>
<p>
In particular, <code><span>amb</span></code> is required to return a value if at
least one its subexpressions converges, ie, doesn’t fail.
Thus,</p>

<pre>(<span>amb</span> <span>1</span> (<span>amb</span>))
</pre>



<p>and</p>

<pre>(<span>amb</span> (<span>amb</span>) <span>1</span>)
</pre>



<p>both return 1.</p>
<p>
Clearly, <code><span>amb</span></code> cannot simply be equated to its first
subexpression, since it has to return a <em>non-failing</em>
value, if this is at all possible.  However, this is not
all: The bias for convergence is more stringent than a
merely local choice of <code><span>amb</span></code>’s subexpressions.  <code><span>amb</span></code>
should furthermore return <em>that</em> convergent value
that makes the <em>entire program</em> converge.  In
denotational parlance, <code><span>amb</span></code> is an <em>angelic</em>
operator.</p>
<p>
For example,</p>

<pre>(<span>amb</span> <span>#f</span> <span>#t</span>)
</pre>



<p>may return either <code><span>#f</span></code> or <code><span>#t</span></code>, but in the program</p>

<pre>(<span>if</span> (<span>amb</span> <span>#f</span> <span>#t</span>)
    <span>1</span>
    (<span>amb</span>))
</pre>



<p>the first <code><span>amb</span></code>-expression <em>must</em> return <code><span>#t</span></code>.
If it returned <code><span>#f</span></code>, the <code><span>if</span></code>’s “else” branch would be
chosen, which causes the entire program to fail.</p>

<h2><a href="https://ds26gte.github.io/tyscheme/index-Z-H-1.html#node_toc_node_sec_14.2">14.2&nbsp;&nbsp;Implementing <code><span>amb</span></code> in Scheme</a></h2>
<p>In our implementation of <code><span>amb</span></code>, we will favor
<code><span>amb</span></code>’s subexpressions from left to right.  Ie, the
first subexpression is chosen, and if it leads to overall
failure, the second is picked, and so on.  <code><span>amb</span></code>s occurring
later in the control flow of the program are searched for
alternates before backtracking to previous <code><span>amb</span></code>s.  In
other words, we perform a <em>depth-first</em> search of the
<code><span>amb</span></code> <em>choice tree</em>, and whenever we brush against
failure, we backtrack to the most recent node of the tree
that offers a further choice.  (This is called <em>chronological backtracking.</em>)</p>
<p>
We first define a mechanism for setting the base failure
continuation:</p>

<pre>(<span>define</span> <span>amb-fail</span> <span>'</span><span>*</span>)

(<span>define</span> <span>initialize-amb-fail</span>
  (<span>lambda</span> ()
    (<span>set!</span> <span>amb-fail</span>
      (<span>lambda</span> ()
        (<span>error</span> <span>"amb tree exhausted"</span>)))))

(<span>initialize-amb-fail</span>)
</pre>



<p>When <code><span>amb</span></code> fails, it invokes the continuation bound at
the time to <code><span>amb‑fail</span></code>.  This is the continuation invoked
when all the alternates in the <code><span>amb</span></code> choice tree have been
tried and were found to fail.</p>
<p>
We define <code><span>amb</span></code> as a macro that accepts an indefinite
number of subexpressions.</p>

<pre>(<span>define-macro</span> <span>amb</span>
  (<span>lambda</span> <span>alts...</span>
    <span>`</span>(<span>let</span> ((<span>+prev-amb-fail</span> <span>amb-fail</span>))
       (<span>call/cc</span>
        (<span>lambda</span> (<span>+sk</span>)

          <span>,@</span>(<span>map</span> (<span>lambda</span> (<span>alt</span>)
                   <span>`</span>(<span>call/cc</span>
                     (<span>lambda</span> (<span>+fk</span>)
                       (<span>set!</span> <span>amb-fail</span>
                         (<span>lambda</span> ()
                           (<span>set!</span> <span>amb-fail</span> <span>+prev-amb-fail</span>)
                           (<span>+fk</span> <span>'</span><span>fail</span>)))
                       (<span>+sk</span> <span>,</span><span>alt</span>))))
                 <span>alts...</span>)

          (<span>+prev-amb-fail</span>))))))
</pre>



<p>A call to <code><span>amb</span></code> first stores away, in
<code><span>+prev‑amb‑fail</span></code>, the <code><span>amb‑fail</span></code> value that was
current at the time of entry.  This is because the
<code><span>amb‑fail</span></code> variable will be set to different failure
continuations as the various alternates are tried.</p>
<p>
We then capture the <code><span>amb</span></code>’s <em>entry</em> continuation <code><span>+sk</span></code>, so
that when one of the alternates evaluates to a non-failing
value, it can immediately exit the <code><span>amb</span></code>.</p>
<p>
Each alternate <code><span>alt</span></code> is tried in sequence (the
implicit-<code><span>begin</span></code> sequence of Scheme).</p>
<p>
First, we capture the current continuation <code><span>+fk</span></code>, wrap it
in a procedure and set <code><span>amb‑fail</span></code> to that procedure.  The
alternate is then evaluated as <code>(<span>+sk</span> <span>alt</span>)</code>.  If <code><span>alt</span></code>
evaluates without failure, its return value is fed to the
continuation <code><span>+sk</span></code>, which immediately exits the <code><span>amb</span></code>
call.  If <code><span>alt</span></code> fails, it calls <code><span>amb‑fail</span></code>.  The first
duty of <code><span>amb‑fail</span></code> is to reset <code><span>amb‑fail</span></code> to the value
it had at the time of entry.  It then invokes the failure
continuation <code><span>+fk</span></code>, which causes the next alternate, if
any, to be tried.</p>
<p>
If all alternates fail, the <code><span>amb‑fail</span></code> at <code><span>amb</span></code> entry,
which we had stored in <code><span>+prev‑amb‑fail</span></code>, is
called.</p>

<h2><a href="https://ds26gte.github.io/tyscheme/index-Z-H-1.html#node_toc_node_sec_14.3">14.3&nbsp;&nbsp;Using <code><span>amb</span></code> in Scheme</a></h2>
<p>To choose a number between 1 and 10, one could say</p>

<pre>(<span>amb</span> <span>1</span> <span>2</span> <span>3</span> <span>4</span> <span>5</span> <span>6</span> <span>7</span> <span>8</span> <span>9</span> <span>10</span>)
</pre>



<p>To be sure, as a program, this will give 1, but
depending on the context, it could return any of the
mentioned numbers.</p>
<p>
The procedure <code><span>number‑between</span></code> is
a more abstract way to generate numbers from a given <code><span>lo</span></code>
to a given <code><span>hi</span></code> (inclusive):</p>

<pre>(<span>define</span> <span>number-between</span>
  (<span>lambda</span> (<span>lo</span> <span>hi</span>)
    (<span>let</span> <span>loop</span> ((<span>i</span> <span>lo</span>))
      (<span>if</span> (<span>&gt;</span> <span>i</span> <span>hi</span>) (<span>amb</span>)
          (<span>amb</span> <span>i</span> (<span>loop</span> (<span>+</span> <span>i</span> <span>1</span>)))))))
</pre>



<p>Thus <code>(<span>number‑between</span> <span>1</span> <span>6</span>)</code> will first
generate 1.  Should that fail, the <code><span>loop</span></code> iterates,
producing 2.  Should <em>that</em> fail, we get 3, and
so on, until 6.  After 6, <code><span>loop</span></code> is called with
the number 7, which being more than 6, invokes
<code>(<span>amb</span>)</code>, which causes final failure.   (Recall that
<code>(<span>amb</span>)</code> by itself guarantees
failure.)  At this point, the program containing the
call to
<code>(<span>number‑between</span> <span>1</span> <span>6</span>)</code> will backtrack to the
chronologically previous <code><span>amb</span></code>-call, and try to
satisfy <em>that</em> call in another fashion.</p>
<p>
The guaranteed failure of <code>(<span>amb</span>)</code> can be used to program
<em>assertions</em>.</p>

<pre>(<span>define</span> <span>assert</span>
  (<span>lambda</span> (<span>pred</span>)
    (<span>if</span> (<span>not</span> <span>pred</span>) (<span>amb</span>))))
</pre>



<p>The call <code>(<span>assert</span> <span>pred</span>)</code> insists that <code><span>pred</span></code> be
true.  Otherwise it will cause the current <code><span>amb</span></code> choice
point to fail.<a name="node_call_footnote_Temp_9"></a><sup><small><a href="#node_footnote_Temp_9">1</a></small></sup></p>
<p>
Here is a procedure using <code><span>assert</span></code> that generates a prime
less than or equal to its argument <code><span>hi</span></code>:</p>

<pre>(<span>define</span> <span>gen-prime</span>
  (<span>lambda</span> (<span>hi</span>)
    (<span>let</span> ((<span>i</span> (<span>number-between</span> <span>2</span> <span>hi</span>)))
      (<span>assert</span> (<span>prime?</span> <span>i</span>))
      <span>i</span>)))
</pre>



<p>This seems devilishly simple, except that when called as
a program with any number (say 20), it will produce the
uninteresting first solution, ie, 2.</p>
<p>
We would certainly like to get <em>all</em> the solutions,
not just the first.  In this case, we may want <em>all</em>
the primes below
20.  One way is to explicitly call the failure
continuation left after the program has produced its first
solution.  Thus,</p>

<pre>(<span>amb</span>)
<span>=&gt;</span> <span>3</span>
</pre>



<p>This leaves yet another failure continuation, which can
be called again for yet another solution:</p>

<pre>(<span>amb</span>)
<span>=&gt;</span> <span>5</span>
</pre>



<p>The problem with this method is that the program is
initially called at the Scheme prompt, and successive
solutions are also obtained by calling <code><span>amb</span></code> at the Scheme
prompt.  In effect, we are using different programs (we
cannot predict how many!), carrying over information from a
previous program to the next.  Instead, we would like to be
able to get these solutions as the return value of a
form that we can call in any context.  To this end, we
define the
<code><span>bag‑of</span></code> macro, which returns all
the successful instantiations of its argument.  (If the argument
never succeeds, <code><span>bag‑of</span></code> returns the empty list.)
Thus, we could say,</p>

<pre>(<span>bag-of</span>
  (<span>gen-prime</span> <span>20</span>))
</pre>



<p>and it would return</p>

<pre>(<span>2</span> <span>3</span> <span>5</span> <span>7</span> <span>11</span> <span>13</span> <span>17</span> <span>19</span>)
</pre>



<p>The <code><span>bag‑of</span></code> macro is defined as follows:</p>

<pre>(<span>define-macro</span> <span>bag-of</span>
  (<span>lambda</span> (<span>e</span>)
    <span>`</span>(<span>let</span> ((<span>+prev-amb-fail</span> <span>amb-fail</span>)
           (<span>+results</span> <span>'</span>()))
       (<span>if</span> (<span>call/cc</span>
            (<span>lambda</span> (<span>+k</span>)
              (<span>set!</span> <span>amb-fail</span> (<span>lambda</span> () (<span>+k</span> <span>#f</span>)))
              (<span>let</span> ((<span>+v</span> <span>,</span><span>e</span>))
                (<span>set!</span> <span>+results</span> (<span>cons</span> <span>+v</span> <span>+results</span>))
                (<span>+k</span> <span>#t</span>))))
           (<span>amb-fail</span>))
       (<span>set!</span> <span>amb-fail</span> <span>+prev-amb-fail</span>)
       (<span>reverse!</span> <span>+results</span>))))
</pre>



<p><code><span>bag‑of</span></code> first saves away its entry <code><span>amb‑fail</span></code>.  It
redefines <code><span>amb‑fail</span></code> to a local continuation <code><span>+k</span></code> created within an
<code><span>if</span></code>-test.  Inside the test, the <code><span>bag‑of</span></code> argument <code><span>e</span></code>
is evaluated.
If <code><span>e</span></code> succeeds, its result is collected
into a list called <code><span>+results</span></code>, and the local continuation
is called with the value <code><span>#t</span></code>.  This causes the
<code><span>if</span></code>-test to succeed, causing <code><span>e</span></code> to be <em>retried</em> at its
next backtrack point.  More results for <code><span>e</span></code> are obtained this
way, and they are all collected into <code><span>+results</span></code>.</p>
<p>
Finally, when <code><span>e</span></code> fails, it will call the base
<code><span>amb‑fail</span></code>, which is simply a call to the local
continuation with the value <code><span>#f</span></code>.  This pushes control
past the <code><span>if</span></code>.   We restore <code><span>amb‑fail</span></code> to
its  pre-entry value, and return the <code><span>+results</span></code>.  (The
<code><span>reverse!</span></code> is simply to produce the results in the order
in which they were generated.)</p>

<h2><a href="https://ds26gte.github.io/tyscheme/index-Z-H-1.html#node_toc_node_sec_14.4">14.4&nbsp;&nbsp;Logic puzzles</a></h2>
<p>The power of depth-first search coupled
with backtracking becomes obvious when applied to solving
logic puzzles.  These problems are extraordinarily difficult
to solve procedurally, but can be solved concisely and
declaratively with <code><span>amb</span></code>, without taking anything away
from the charm of solving the puzzle.</p>

<h3><a href="https://ds26gte.github.io/tyscheme/index-Z-H-1.html#node_toc_node_sec_14.4.1">14.4.1&nbsp;&nbsp;The Kalotan puzzle</a></h3>
<p>The Kalotans are a tribe with a peculiar quirk.<a name="node_call_footnote_Temp_10"></a><sup><small><a href="#node_footnote_Temp_10">2</a></small></sup>  Their males always
tell the truth.  Their females never make two consecutive
true statements, or two consecutive untrue statements.</p>
<p>
An anthropologist (let’s call him Worf) has begun to
study them.  Worf does not yet know the Kalotan
language.  One day, he meets a Kalotan (heterosexual)
couple and their child Kibi.  Worf asks Kibi: “Are you
a boy?”  Kibi answers in Kalotan, which of course Worf
doesn’t understand.</p>
<p>
Worf turns to the parents (who know English) for
explanation.  One of them says: “Kibi said: ‘I am a
boy.’ ” The other adds: “Kibi is a girl.  Kibi lied.”</p>
<p>
Solve for the sex of the parents and Kibi.</p>

<p>&nbsp;—&nbsp;</p>
<p>
The solution consists in introducing a bunch of variables,
allowing them to take a choice of values, and
enumerating the conditions on them as a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ds26gte.github.io/tyscheme/index-Z-H-16.html#node_chap_14">https://ds26gte.github.io/tyscheme/index-Z-H-16.html#node_chap_14</a></em></p>]]>
            </description>
            <link>https://ds26gte.github.io/tyscheme/index-Z-H-16.html#node_chap_14</link>
            <guid isPermaLink="false">hacker-news-small-sites-24924292</guid>
            <pubDate>Wed, 28 Oct 2020 21:23:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trypophobia, WebGL Experiment]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24924179">thread link</a>) | @parisianka
<br/>
October 28, 2020 | https://www.hiteshsahu.com/SinkHole | <a href="https://web.archive.org/web/*/https://www.hiteshsahu.com/SinkHole">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.hiteshsahu.com/SinkHole</link>
            <guid isPermaLink="false">hacker-news-small-sites-24924179</guid>
            <pubDate>Wed, 28 Oct 2020 21:09:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How many mistakes do Grandmaster chess players make?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24924076">thread link</a>) | @kwojcicki
<br/>
October 28, 2020 | https://kwojcicki.github.io/blog/CHESS-BLUNDERS | <a href="https://web.archive.org/web/*/https://kwojcicki.github.io/blog/CHESS-BLUNDERS">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <div>
    <div>
      <div>
        <blockquote>
  <p>Code for generating the graphs can be found at <a href="https://github.com/kwojcicki/chess-stats">https://github.com/kwojcicki/chess-stats</a></p>
</blockquote>





<p>Chess, for practical purposes, is solved. Using online platforms players can compare their moves against optimal moves generated by chess engines/AI’s. Centipawn Loss (CPL) is a measure of how suboptimal one’s move is. A centipawn is equal to <code>1/100th</code> of a pawn, meaning a CPL of <code>100</code> indicates the player made a move that lost the equivalent to <code>1</code> pawn. A CPL of <code>100</code> does not necessarily mean you lost a pawn unnecessarily; CPL also takes into account positions and potential mates. <a href="https://lichess.org/faq#acpl">Average Centipawn Loss</a> (ACPL) is the average CPL across a given game. ACPL is a positive number between 0 and infinity. An ACPL near 20 is excellent indicting near perfect play, whereas an ACPL above 300 either means you’re a 3 year old toddler or purposefully losing the game. Being able to calculate ACPL raises the question, is ACPL correlated to one’s <a href="https://en.wikipedia.org/wiki/Elo_rating_system">rating</a>?</p>

<details><summary>In-depth CPL explanation</summary>

<div>

    <p>Let’s examine the following board</p>

    <p><img src="https://kwojcicki.github.io/img/posts/even_game.PNG" alt="Even chess game"></p>

    <p>Both sides have similar pieces and similar positions. <a href="https://stockfishchess.org/">Stockfish</a> gives this board a score of <code>-0.69</code> (i.e. black is up <code>69/100th</code> of a pawn or <code>69</code> Centipawn’s).</p>

    <p>The optimal move is to move your bishop to <code>b4</code>.</p>

    <p><img src="https://kwojcicki.github.io/img/posts/optimal_move.PNG" alt="Average Centipawn Loss vs Rating"></p>

    <p>That board is evaluated at <code>-0.71</code>.</p>

    <p>If instead we played the bishop to <code>c3</code>, Stockfish will reevaluate the board to <code>-0.89</code>.</p>

    <p><img src="https://kwojcicki.github.io/img/posts/bad_move.PNG" alt="Average Centipawn Loss vs Rating"></p>

    <p>Since the optimal move resulted in a board evaluation of <code>-0.71</code> and our move achieved an evaluation of <code>-0.89</code>, our move receives a CPL of <code>-71 - -89 = 18</code>.</p>

  </div>
</details>

<figure>
  <img src="https://kwojcicki.github.io/img/posts/acpl_vs_rating.PNG" alt="Average Centipawn Loss vs Rating">
  <figcaption><b>Fig 1</b>: Rating vs ACPL per game <sup id="a1"><a href="#f1">[1]</a></sup><sup id="a15"><a href="#f15">[1.5]</a></sup></figcaption>
</figure>

<p>The graph shows a negative correlation between rating and ACPL (ACPL decreases as rating increases) which follows common sense; as a player gets better they tend to perform moves that are closer to the optimal.</p>

<p>ACPL, as most performance indicators, require context. A player can achieve an ACPL of 20 in a variety of ways. They can immediately blunder their queen and attempt to stretch out the inevitable<sup id="a2"><a href="#f2">2</a></sup> or they can play an excellent game.</p>

<p>Instead of looking at rating vs ACPL, we’ll look at rating vs move types. Online chess platforms tend to classify moves into several broad categories: best move, good move, inaccuracy (CPL between <code>50-100</code>), mistake (CPL between <code>100-300</code>) and blunder (CPL <code>&gt;200</code>).</p>

<figure>
  <img src="https://kwojcicki.github.io/img/posts/errors_vs_rating.PNG" alt="Errors vs Rating">
  <figcaption><b>Fig 2</b>: Rating vs Errors per game <sup id="a1"><a href="#f1">[1]</a></sup></figcaption>
</figure>

<p>As one would expect, the number of blunders (game losing moves) drastically decreases with rating. It is unclear if the actual CPL per blunder decreases or increases with rating.</p>

<p>What is interesting is how mistakes stay relativity even, this may be due to the examined games being from the <a href="https://en.wikipedia.org/wiki/Fast_chess#:~:text=and%20regular%20ratings.-,Blitz,minutes%20or%20less%20per%20player.&amp;text=The%20USCF%20defines%20blitz%20chess,and%2010%20minutes%20per%20player.">blitz variant</a> of chess. Since the players have a limited time to think they are likely making moves that are good in the short term (<code>3-5</code> moves ahead), but may be suboptimal in <code>10+</code> moves. Realistically, it will be difficult for humans to ever eliminate all mistakes and inaccuracies from their play, but concentrating on reducing one’s blunders even by <code>25%</code> yields incredible gains in ones rating.</p>



<p>In both graphs, it is evident that the correlation factor between errors/ACPL and rating is low. Both are metrics that can be used to estimate the players’ rating in a range, but are unideal to accurately judge a player’s performance. Nonetheless, it is difficult to dispute the notion that better players have better ACPL.</p>



<p><b id="f1">[1]</b> A sample of <code>~2500</code> games was taken using <a href="https://lichess.org/api">Lichess’s API</a>, resulting in <code>~5000</code> ACPL samples being used. Players were pooled in buckets based on their ELO (i.e. the ACPL was averaged for players across <code>700-719</code>, <code>720-739</code> etc). <a href="#a1">↩</a></p>

<p><b id="f15">[1.5]</b> There is a peculiar uptick in ACPL at the very upper ranks likely due to low sampling of <code>2900+</code> rated games. <a href="#a15">↩</a></p>

<p><b id="f2">[2]</b> One can imagine a scenario where the player immediately blunders their queen, causing their initial ACPL to be very high. As the game progresses, since the game is in such a dire position, all the player’s available moves will be roughly of the same quality, meaning any move the player makes will have a CPL close to 0. Eventually, as the number of moves grows larger the initial spike in CPL will be averaged off. <a href="#a2">↩</a></p>

        <br>
         
 




 
        <br>
        
      </div>
    </div>
  </div>
</article></div>]]>
            </description>
            <link>https://kwojcicki.github.io/blog/CHESS-BLUNDERS</link>
            <guid isPermaLink="false">hacker-news-small-sites-24924076</guid>
            <pubDate>Wed, 28 Oct 2020 20:59:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I used GPT-3 to hit Hacker News front page 5 times in 3 weeks]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24924035">thread link</a>) | @masterrr
<br/>
October 28, 2020 | https://vasilishynkarenka.com/gpt-3/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/gpt-3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://vasilishynkarenka.com/content/images/size/w300/2020/10/Screen-Shot-2020-10-28-at-8.24.48-AM.png 300w,
                            https://vasilishynkarenka.com/content/images/size/w600/2020/10/Screen-Shot-2020-10-28-at-8.24.48-AM.png 600w,
                            https://vasilishynkarenka.com/content/images/size/w1000/2020/10/Screen-Shot-2020-10-28-at-8.24.48-AM.png 1000w,
                            https://vasilishynkarenka.com/content/images/size/w2000/2020/10/Screen-Shot-2020-10-28-at-8.24.48-AM.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://vasilishynkarenka.com/content/images/size/w2000/2020/10/Screen-Shot-2020-10-28-at-8.24.48-AM.png" alt="How I used GPT-3 to hit Hacker News front page 5 times in 3 weeks">
            </figure>

            <section>
                <div>
                    <p>Posting on Hacker News is like a box of chocolates – you never know what you’re gonna get. I’ve been submitting since 2017 and never had more than one point. So I stopped trying.</p><p>A month ago, I got access to OpenAI API. After ten minutes of tinkering, I’ve got an idea: what if I could make it write good Hacker News titles for my blog posts? I quickly looked up the most favorited posts, designed the prompt in plain English, and generated my first title. It looked weird. I even doubted for a few minutes if it’s worth sharing. But I was curious – so I closed my eyes and hit submit.</p><p>The post went to the moon with <a href="https://news.ycombinator.com/item?id=24547098">229 points and 126 comments</a> in one day. Fascinated, I continued generating titles (and what would you do?). In three weeks, I got to the front page five times, received 1054 upvotes, and had 37k people come to my site.</p><p>Below is everything I’ve learned building a Hacker News post titles generator with OpenAI API, designing GPT-3 prompts, and figuring out how to apply GPT-3 to problems ranging from sales emails to SEO-optimized blog posts. At the end of the post, I cover the broader implications of GPT-3 that became obvious only after a month of working with the tool. If you’re an entrepreneur or an investor who wants to understand the change this tech will drive, you can read my speculations there.</p><p>If you have no idea what I’m talking about, read more about GPT-3 in <a href="https://www.gwern.net/newsletter/2020/05">Gwern’s post</a> first, or check <a href="https://beta.openai.com/">OpenAI’s website</a> with demo videos. In my work, I assume you’re already familiar with the API on some basic level.</p><p><em>Oct 31 update: After I published the post, 48 people asked how to apply GPT-3 to their problems. To help them get started with the OpenAI API, I started building the first GPT-3 course that covers everything I learned – from use cases to prompt design. If you’re interested, </em><a href="mailto:vasilishynkarenka@gmail.com?subject=GPT-3%20course"><em>email me here</em></a><em>.</em></p><hr><p>After I got an idea for an HN titles app, I needed to understand how to do it with GPT-3. As there were no tutorials on approaching the problem, I went to the playground and began experimenting.</p><h2 id="generating-new-titles">Generating new titles</h2><h3 id="1-finding-the-data">1. Finding the data</h3><p>First, I wanted to see if I could make GPT-3 generate engaging post titles at all. To do that, I needed two things:</p><ol><li>Write a prompt that concisely describes the problem that I want to solve.</li><li>Feed the API some sample data to stimulate the completion.</li></ol><p>I went ahead and searched for the most upvoted HN posts of all time. In a few minutes, I’ve got <a href="https://hn.algolia.com/?query=&amp;sort=byPopularity&amp;prefix&amp;page=0&amp;dateRange=all&amp;type=story">an Algolia page</a> with a list of links. But after skimming through them, I figured out that upvotes wouldn’t work. They are mostly news and poorly reflect what kind of content the community values.</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/10/Screen-Shot-2020-10-28-at-9.18.27-AM.png" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/10/Screen-Shot-2020-10-28-at-9.18.27-AM.png 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/10/Screen-Shot-2020-10-28-at-9.18.27-AM.png 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/10/Screen-Shot-2020-10-28-at-9.18.27-AM.png 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/10/Screen-Shot-2020-10-28-at-9.18.27-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://hn.algolia.com/?query=&amp;sort=byPopularity&amp;prefix&amp;page=0&amp;dateRange=all&amp;type=story">Most upvoted HN posts of all time.</a></figcaption></figure><p>Disappointed, I discarded upvotes as a metric. I needed something that would describe the value people get from the post. Something like... bookmarks?</p><p>I quickly looked up <a href="https://news.ycombinator.com/item?id=24351073">the most favorited HN posts</a>. The idea was simple: people don’t bookmark news. They favorite things they want to explore later.</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/10/Screen-Shot-2020-10-28-at-9.21.11-AM.png" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/10/Screen-Shot-2020-10-28-at-9.21.11-AM.png 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/10/Screen-Shot-2020-10-28-at-9.21.11-AM.png 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/10/Screen-Shot-2020-10-28-at-9.21.11-AM.png 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/10/Screen-Shot-2020-10-28-at-9.21.11-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://observablehq.com/@tomlarkworthy/hacker-favourites-analysis">Most favorited HN posts of all time.</a></figcaption></figure><p>The next step was to grab the data from the list, insert it into the playground, and write a clear and concise prompt.</p><p><em>I actually grab data from the <a href="https://news.ycombinator.com/item?id=24351073">dang’s comment</a> rather than the original post; his list was a global one.</em></p><h3 id="2-designing-a-prompt">2. Designing a prompt</h3><p>The best way to program the API is to write a direct and straightforward task description, as you would do if you were delegating this problem to a human assistant. </p><p>Here’s how my first prompt looked like:</p><blockquote>Generate viral titles for Hacker News (<a href="https://news.ycombinator.com/">https://news.ycombinator.com/</a>) posts. The titles have to be provocative and incentivize users to click on them.</blockquote><p>Data-wise, I needed to clean up the list slightly, get rid of irrelevant stuff like IDs, and choose up to five titles to use as a sample – OpenAI team suggests that selecting three to five titles works best for text generation. If you feed the API more examples, it picks up wrong intents and generates irrelevant completions.</p><p>In a few minutes of Google Sheets work, the cleanup was done, and I had a data set of the most favorited HN post titles of all time. I put together my first prompt and clicked “Generate.”</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/10/Screen-Shot-2020-10-28-at-9.29.16-AM.png" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/10/Screen-Shot-2020-10-28-at-9.29.16-AM.png 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/10/Screen-Shot-2020-10-28-at-9.29.16-AM.png 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/10/Screen-Shot-2020-10-28-at-9.29.16-AM.png 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/10/Screen-Shot-2020-10-28-at-9.29.16-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Cleaned up titles of most favorited HN posts of all time.</figcaption></figure><h3 id="3-tinkering-with-completions">3. Tinkering with completions</h3><p>The first completion was unpromising. The list of titles had too many Ask HNs, and GPT-3 picked up questions as a pattern:</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/10/Screen-Shot-2020-10-28-at-9.40.59-AM.png" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/10/Screen-Shot-2020-10-28-at-9.40.59-AM.png 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/10/Screen-Shot-2020-10-28-at-9.40.59-AM.png 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/10/Screen-Shot-2020-10-28-at-9.40.59-AM.png 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/10/Screen-Shot-2020-10-28-at-9.40.59-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>My first attempt to generate HN titles.</figcaption></figure><p>To fix that, I cut out half Ask HNs from the dataset and began tinkering.</p><p>If there was one thing I could tell someone about GPT-3, it’d be that getting a perfect completion from the first try is a dream. The best stuff comes after dozens of experiments, sometimes after generating completions with the same parameters many times with the Best Of parameter and writing another GPT-3 classifier to discover a good one. Moreover, you need to test the prompt’s quality, data samples, and temperature (“creativity” of responses) individually to understand what you need to improve. </p><p><em>If you’re looking for prompt design tips, head on to chapter 2 of the post.</em></p><p>Here’s a list of experiments I’ve done:</p><ul><li>Edited the prompt many times, including and excluding adjectives from the task description. I tried “catchy,” “provocative,” “thought-provoking,” and many others. The best configuration I’ve got was “Write a short, thought-provoking, and eye-catching post title for a Hacker News (https://news.ycombinator.com/) submission.”</li><li>Split the prompt into two sentences, separating the task and its description. Discovered that one-sentence long prompts work best for simple tasks.</li><li>Played with data samples. I added and removed Ask HNs, randomly sampled from the list of most favorited posts, and tried picking more subjectively thoughtful titles.</li><li>Changed the temperature. The best results came at .9, while anything less than .7 was repetitive and very similar to the samples. Titles generated with temperature 1 were too random and didn’t look like good HN titles at all.</li></ul><p>To judge the quality of completions, I’ve come up with a question: “If I saw this on HN, would I click on it?” This helped me move quickly through experiments because I knew what bad results looked like.</p><p>After half an hour of tinkering, I’ve got the following completion: &nbsp; &nbsp; &nbsp;</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/10/Screen-Shot-2020-10-28-at-9.54.17-AM.png" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/10/Screen-Shot-2020-10-28-at-9.54.17-AM.png 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/10/Screen-Shot-2020-10-28-at-9.54.17-AM.png 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/10/Screen-Shot-2020-10-28-at-9.54.17-AM.png 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/10/Screen-Shot-2020-10-28-at-9.54.17-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>My first good GPT-3 completions for HN titles.</figcaption></figure><p>That’s when I realized that I’m onto something. From the list of generated titles above, I’d click on at least three links just out of curiosity. Especially on “A developer’s guide to getting in shape.”</p><p>What’s even more interesting, the completion above was a result of fine-tuning the API. Title8, What You Love Is Not Your Life’s Work, was originally a part of another completion that was lame. So I cut out the bad stuff, added Title8 to my data sample, and continued generating from there.</p><p>The next step was to see if I could make GPT-3 create a custom title for my blog post.</p><h2 id="generating-custom-titles">Generating custom titles</h2><h3 id="1-changing-the-method">1. Changing the method</h3><p>To make GPT-3 generate custom titles, I needed to change my approach. I was no longer exploring new, potentially interesting headlines but figuring out how to make a good one for a post that was already written. To do that, I couldn’t just tell the API, “hey, generate me a good one.” I needed to show what a good one actually is and give GPT-3 some idea of what the post is about.</p><p>The first thing I changed is the prompt. This was relatively easy because I applied the same model of thinking again – “What would I tell a human assistant if I had to delegate this problem?”</p><p>Here’s a prompt that I used:</p><blockquote>Write a short, thought-provoking, and eye-catching post title for Hacker News (https://news.ycombinator.com/) submission based on a blog post’s provided description.</blockquote><p>One unexpected benefit from tinkering with the prompt is the clarity of thought. When you’re dealing with GPT-3, there’s no way to make it work if you don’t know what you’re doing. You need to express your thought in clear terms. It’s a brilliant natural constraint and one of the most underrated benefits of GPT-3: when you must state clearly what you want to do, you begin to better understand the problem.</p><h3 id="2-updating-the-data">2. Updating the data</h3><p>After I designed a new prompt, I had to update my data set. I went back to my previous experiment, selected five titles from the list of most favorited posts of all time, and wrote a clear and concise description for each of them. Lastly, I wrote a description of my own work that I wanted to generate the title for. I left the title field blank and hit “Generate.”</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/10/Screen-Shot-2020-10-28-at-10.35.59-AM.png" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/10/Screen-Shot-2020-10-28-at-10.35.59-AM.png 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/10/Screen-Shot-2020-10-28-at-10.35.59-AM.png 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/10/Screen-Shot-2020-10-28-at-10.35.59-AM.png 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/10/Screen-Shot-2020-10-28-at-10.35.59-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Updated data set for generating custom HN titles.</figcaption></figure><h3 id="3-experimenting-with-titles">3. Experimenting with titles</h3><p>This time, the completions were shockingly good. Because I’ve already learned how to design a prompt and get the data right, I didn’t have to spend much time tuning the parameters. The only thing I changed was the temperature – the best results came at .92.</p><p>Here’s a list of titles I generated for my post on <a href="https://vasilishynkarenka.com/3-weeks-of-shaolin-kung-fu-in-china/">studying kung fu in China</a>:</p><ul><li>How a Shaolin monk trains Western students</li><li>I went to a Kung Fu school for a month, and I learned 3 lessons that I will never forget</li><li>How I got a Shaolin monk to teach me Kung Fu in China</li><li>What it’s like to study Kung Fu from a Shaolin monk</li><li>21 days in the Shaolin Temple</li><li>An edited transcript of my conversation with my Kung Fu master</li><li>How I learned Kung Fu from a monk in China: The full story</li><li>I Spent a Month with a Kung Fu Master in China</li><li>The Shaolin warrior in the cubicle</li><li>Kamikaze training – A brief study in Kung Fu</li><li>Why I traveled to China to study Kung Fu</li><li>I went to a Shaolin Monastery for 6 months to learn Kung Fu: a true story</li><li>I went to the Shaolin Temple to study Kung Fu, and all I got was this lousy blog post </li><li>The monk and the engineer</li><li>What it’s like studying Kung Fu from Shaolin monks for 6 months</li><li>I went to Shaolin and all I got were Kung Fu lessons</li></ul><p>And, of course, my all-time favorite one:</p><blockquote>When a Shaolin monk met a programmer from the Silicon Valley</blockquote><p>But the best titles didn’t come from completions. The most interesting headlines were the ones I ended up thinking of <em>after</em> I saw the …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/gpt-3/">https://vasilishynkarenka.com/gpt-3/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/gpt-3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24924035</guid>
            <pubDate>Wed, 28 Oct 2020 20:55:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anatomy of a Successful Newsletter Launch]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24923868">thread link</a>) | @timjones
<br/>
October 28, 2020 | https://www.timjones.me/2020/10/28/anatomy-of-a-successful-newsletter-launch.html | <a href="https://web.archive.org/web/*/https://www.timjones.me/2020/10/28/anatomy-of-a-successful-newsletter-launch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
On Monday I launched my newsletter on Substack, <a href="https://mvpsprint.substack.com/">The MVP Sprint</a>. I'm chronicling my journey to validate an idea and build an MVP - adapting the popular <a href="https://www.gv.com/sprint/">Design Sprint</a> methodology to the startup launch process.
</p>

<p>
Going into it, I didn't know what to expect. I've never built in public like this before. I've shared articles in the past that were met with nothing but crickets. But this one was different.
</p>

<p>
<b>I've gained 108 subscribers in the first 48 hours since launch</b>.
</p>

<p>
I'm going to share the blueprint I followed and the metrics it produced to help out future newsletter newbs like myself.
</p>

<h3>Where did I share it?</h3>
<p>Everywhere I could think of! Here's some details on individual channels:</p>

<h4>Indie Hackers</h4>
<p>
I shared <a href="https://www.indiehackers.com/post/after-4-brain-surgeries-i-left-my-6-figure-tech-job-now-i-m-launching-a-startup-in-public-87e569e566">this post</a> in the "Building in Public" group. This seemed like the most relevant place to share it, but with 359 members, I wasn't sure if it would get many eyeballs.
</p>

<p>
As of right now, it has 34 upvotes, 26 comments, and 811 views. Not bad! It started off quite slow, seemed to pick up steam after the IH email newsletter went out, and then picked up a lot more after  <a href="https://twitter.com/IndieHackers/status/1320899528862633985">this shoutout from the @IndieHackers Twitter account</a>.
</p>

<h4>Twitter</h4>
<p>
I shared <a href="https://twitter.com/AnotherTimJones/status/1320801476491595780?s=20">a tweet storm from my personal twitter account</a> to my modest group of &lt;300 followers (at the time). A few of my friends gave me Twitter shoutouts and retweeted me.
</p>

<h4>Linkedin</h4>
<p>
I shared a post on <a href="https://www.linkedin.com/in/tjones4413/">my personal Linkedin</a>. It currently has 72 reactions, 20 comments, and 3,318 views within the news feed.
</p>

<p>
I also tried out the new Linkedin stories, but had &lt;15 views in the first 24 hours. I probably won't do this again. 
</p>

<h4>Reddit</h4>
<p>
I posted in the following subreddits:
</p>
<ul>
<li><a href="https://www.reddit.com/r/startups/comments/jie5an/how_do_you_come_up_with_ideas_for_tech_startups/">r/startups</a></li>
<li><a href="https://www.reddit.com/r/Startup_Ideas/comments/jie8l1/a_startup_idea_is_just_a_recipe/">r/startup_ideas</a></li>
<li><a href="https://www.reddit.com/r/EntrepreneurRideAlong/comments/jielur/after_4_brain_surgeries_i_left_my_6figure_tech/">r/EntrepreneurRideAlong</a> - This one did particularly well with &gt;180 upvotes and 54 comments.</li>
</ul>

<p>
I did my best to give as much value as possible within the posts themselves - only with a modest link at the end to the newsletter. And I tweaked the content for each subreddit to make it more relevant.
</p>

<p>
Outside of a few haters, folks on Reddit were super supportive. I received lots of friendly DM's and emails from people saying they loved the story and even wanted to help out.
</p>

<h4>Instagram</h4>
<p>
I threw together some images on Figma and shared a 2-part story on <a href="https://www.instagram.com/anothertimjones/">my personal Instagram</a> where I have 585 followers. Outside of a few supportive messages from friends, I can't really pull out the IG contribution to subscriber count.
</p>

<div>
	<div>
		<p><img alt="Instagram Story - first screen" src="https://res.cloudinary.com/do0vbqz18/image/upload/v1603899903/MVP%20Sprint/story%201.png">
		</p>
		<p><img alt="Instagram Story - second screen" src="https://res.cloudinary.com/do0vbqz18/image/upload/v1603899903/MVP%20Sprint/story%202.png">
		</p>
	</div>
</div>

<p><i>These are the same assets I used for my Linkedin story.</i></p>

<h4>Medium</h4>
<p>
I tried <a href="https://themvpsprint.medium.com/cooking-up-a-recipe-in-the-startup-kitchen-3597cdcd5f4b">syndicating my first article to Medium</a>. So far it has 12 views and 3 "reads". Not sure if I'll continue this or not. Long-term I'll want to harness the SEO benefits on my own domain and syndicated content without a canonical tag won't do me any favors there.
</p>

<h4>Substack Stats</h4>
<h5>Engagement on <a href="https://mvpsprint.substack.com/p/choose-a-problem">the first article </a>:</h5>
<p><img alt="Article 1 stats" src="https://res.cloudinary.com/do0vbqz18/image/upload/v1603899472/MVP%20Sprint/article%201%20stats.png">
</p>

<p>
The view count feels accurate, but I'm not reading much into the "40 free signups after reading this". Maybe this means lots of people subscribed without reading?
</p>

<h5>Here's the breakdown of visits and and signups by channel:</h5>
<p><img alt="Article 1 stats" src="https://res.cloudinary.com/do0vbqz18/image/upload/v1603899619/MVP%20Sprint/substack%20stats.png">
</p>

<p>
<b>A few thoughts:</b>
</p>
<ul>
<li>I'm guessing that "direct" visitors was actually less than 343. I suspect that some of these are from Instagram (where I didn't include a direct link) and some from users where the referral header wasn't set.</li>
<li>The signup column doesn't add up to even half of my total subscribers, so I'm not reading much into that.</li>
</ul>

<h3> Future Channels</h3>
<ol>
<li><b>Twitter</b> - I'm new to using Twitter in a professional sense, but it's no secret that this <i>could</i> and <i>should</i> be a great channel for me moving forward. I just have to invest in it and find my voice.
</li><li><b>Reddit</b> - Reddit feels like it could be a great tool, but I'll have to experiment with how to consistently engage in a way that drives value and doesn't feel spammy. 
</li><li><b>Linkedin</b> - I have a pretty deep Linkedin network so I'll keep tapping into that.
</li><li><b>Product Hunt</b> - After I have maybe 5-10 articles, I'm planning on spinning up my own landing page and newsletter "stack". At that point, I'll probably throw it up on Product Hunt.
</li></ol>

<h3>Some closing thoughts</h3>
<ul>
<li><b>People want to support you</b> (if you give them the chance) - I sometimes feel awkward asking for help. Maybe some of you are the same. But I realized from this experience that not only can be people be extremely helpful, but they <b>thoroughly enjoy helping</b>, maybe even a bit of  living vicariously through the startup journey.
</li><li><b>Reply to everyone</b> -  I did my best to reply to almost everyone that commented on a post. Not only does this cultivate a deeper connection with readers, but I think it helps to boost the engagement flywheel.
</li></ul>

<p>
That's it! Any advice for me moving forward? <a href="https://twitter.com/anothertimjones">Shoot me a DM on Twitter!</a>
</p>
    </div></div>]]>
            </description>
            <link>https://www.timjones.me/2020/10/28/anatomy-of-a-successful-newsletter-launch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24923868</guid>
            <pubDate>Wed, 28 Oct 2020 20:40:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Dec Emulation Website]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24923707">thread link</a>) | @homarp
<br/>
October 28, 2020 | http://www.avanthar.com/healyzh/decemulation/decemu.html | <a href="https://web.archive.org/web/*/http://www.avanthar.com/healyzh/decemulation/decemu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<p><a href="http://www.avanthar.com/healyzh/decemulation/decemu.html">DEC Emulation Website (Main Page)</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp1emu.html">PDP-1</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp4emu.html">PDP-4</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp6emu.html">PDP-6</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp7emu.html">PDP-7</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp8emu.html">PDP-8</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp9emu.html">PDP-9</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp10emu.html">PDP-10</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp11emu.html">PDP-11</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp15emu.html">PDP-15</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/vax.html">VAX</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/Alpha.html">Alpha</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/MIPS.html">MIPS</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp_fpga.html">FPGA</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/Honeywell_DPS-6.html">Other: Honeywell DPS-6</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/Honeywell_DPS-8.html">Other: Honeywell DPS-8</a></p>
		<p><b><span size="+3">The DEC Emulation Website</span></b></p>
		<p><b>Last Updated:</b> 2018-02-10</p>
		<p><b><span size="+2">Latest News!</span></b></p>
		<dl>
			<dd><span color="#009900">(2018-02-01)</span> Actively cleaning up dead links, or at least noting where there are dead links.  </dd>
            <dd>&nbsp;</dd>
            <dd><span color="#009900">(2018-01-16)</span> Added page for the PDP-6. </dd>
            <dt></dt>
            <dd><span color="#009900">(2017-10-11) </span>
			Starting to update the webpages after a decade long haitus, additionally the webpages just moved from the homedirectory at my old ISP, to a server of mine.
            </dd><dd><span color="#009900">(2011-11-17)</span> It's been way too long since these pages were updated, I'm going to try and get some basic work done on them.            
			  My apologies to those that have been sending me updates. As you might have noticed they haven't been updated. I will be attempting to find them. 
			
		  </dd><dd><span color="#009900">(2006-01-22)</span> Probably the most major website update in the past 2-4 years, all of the pages for PDP-1, PDP-4, PDP-7, PDP-8, PDP-9, PDP-11, PDP-15, VAX, Alpha, and FPGA's have been updated to fix broken links.  All that remains to be updated are the PDP-10, and MIPS pages.		  </dd>
		  <dd><span color="#009900">(2001-12-01)</span> The PDP-10 Emulation page expands to be the DEC Emulation Website.
			</dd><dd>&nbsp;
		</dd></dl>
<p><b><span size="+1">Introduction</span></b></p>
		<p>The purpose of these web pages are to aid people in finding all the bits and pieces that they'll need in order to set up the OS or Software of their choice (if possible) running under an emulator. This site started out as a page about PDP-10 emulation, which will continue to be its main focus.</p>
		<p><b>Note:</b> While the primary focus of this website is <i>emulation</i> of DEC Hardware, I also include any and all hardware documentation that I'm aware of.</p>
		<p><b><span size="+1">Contacting Me</span></b></p>
		<p>If you have any comments about this site I can be reached at <i>healyzh AT avanthar DOT com</i>. If you know of any software or documentation that isn't listed below I'd appreciate knowing about it so that I can provide links when appropriate.</p>
		<p><b><span size="+1">Processor Families</span></b></p>
		<pre><b><u>CPU    Date Bits    Notes</u></b>
<a href="http://www.avanthar.com/healyzh/decemulation/pdp1emu.html">PDP-1</a>  1960 18-bit
PDP-2       24-bit  Never Built, No Emulator Available
PDP-3       36-bit  1 was built by a customer using the DEC Spec, No Emulator Available
<a href="http://www.avanthar.com/healyzh/decemulation/pdp4emu.html">PDP-4</a>  1962 18-bit
PDP-5  1963 12-bit  No Emulator Available
<a href="http://www.avanthar.com/healyzh/decemulation/pdp6emu.html">PDP-6</a>  1964 36-bit
<a href="http://www.avanthar.com/healyzh/decemulation/pdp7emu.html">PDP-7</a>  1965 18-bit
<a href="http://www.avanthar.com/healyzh/decemulation/pdp8emu.html">PDP-8</a>  1965 12-bit
PDP-9  1966 18-bit
<a href="http://www.avanthar.com/healyzh/decemulation/pdp10emu.html">PDP-10</a> 1967 36-bit
<a href="http://www.avanthar.com/healyzh/decemulation/pdp11emu.html">PDP-11</a> 1970 16-bit
PDP-12 1969 12-bit  No Emulator Available
PDP-14              No Emulator Available
<a href="http://www.avanthar.com/healyzh/decemulation/pdp15emu.html">PDP-15</a>      18-bit
PDP-16              No Emulator Available
<a href="http://www.avanthar.com/healyzh/decemulation/vax.html">VAX</a>    1977 32-bit
<a href="http://www.avanthar.com/healyzh/decemulation/MIPS.html">MIPS</a>        32-bit  CPU Simulators only
<a href="http://www.avanthar.com/healyzh/decemulation/Alpha.html">Alpha</a>       64-bit  CPU Simulators only</pre>
		<p><b><span size="+1">DEC Specific Links</span></b></p>
		<ul>
			<li>The <a href="http://www.dittman.net/">DEC Enthusiasts Club has been closed down</a>.
			
			
			
			</li><li><a href="http://www.fpns.net/willy">Will Kranz's</a> <a href="http://www.fpns.net/willy/pdp11/tu58-emu.htm">TU-58 emulation</a> and <a href="http://www.fpns.net/willy/pdp11/pdt11.htm">PDT-11/150</a> pages
			(Dead Links)
			</li><li>The <a href="http://www.mscpscsi.com/">UNIBUS/QBUS MSCP SCSI</a> project is aimed at creating a homebrew MSCP SCSI controller due to the high cost of obtaining a commercial controller.
			
			
			(Dead Link)
			</li><li>The <a href="http://www.chd.dyndns.org/qbus_ide/">CHD - Q22-Bus - ATA Disk Adapter</a> project looks to be on hold
		
			
			(Dead Link)
			</li><li>Information on connecting to <a href="http://www.update.uu.se/%7ebqt/hecnet.html">HECnet</a>, the Hobbyist DECnet, and what is <a href="http://www.avanthar.com:8080/nodes/">active (warning takes a while to collect the information)</a>.
	</li></ul>
		<dl>
			</dl>
		<p><b><span size="+1">Related Links</span></b></p>
		<ul>
			<li>The <a href="http://www.hercules-390.org/">Hercules</a> System/370, ESA/390, and z/Architecture Emulator
			</li><li><a href="http://www.bsp-gmbh.com/turnkey/herc_mvs.html">MVS on your PC</a>, a turnkey Hercules solution
			</li><li>The Hercules <a href="http://www.kiyoinc.com/hercdoc.html">New Users Documentation Effort</a> (Dead Link)</li><li>The <a href="http://www.digital-eel.com/files/dndpage_files/DND.htm">Unofficial DND Home Page</a> (includes copies for TOPS-20 and VMS?), I have to confess, this is my favorite game on my VAX/VMS 5.5-2 system.
		  (2018 - The link has been updated to a new mirror of the page which has links to archive.org)</li><li><a href="http://www.digital-eel.com/files/dndpage_files/classic_mainframe_games.htm">Mainframe Games</a> for DOS
			</li><li>The <a href="http://www.ee.upenn.edu/~jan/eniacproj.html">Eniac-on-a-Chip</a> Project
			(page no longer online)</li><li>The <a href="http://members.iinet.net.au/%7etom-hunter/">Desktop Cyber Emulator</a> Home page.
			</li><li><a href="http://members.optushome.com.au/intaemul/INDEX.HTM">IBM 1401 and 7094 Emulator</a> (unfortunatly this is Windows only, it is written in Delphi 5)
	      </li><li><a href="https://www.qemu.org/">QEMU</a> is an emulator (or family of emulators) that I need to find time to explore.            
		  </li><li>A Wikipedia page, <a href="https://en.wikipedia.org/wiki/Comparison_of_platform_virtualization_software">Comparison of platform virtualization software </a>
	      </li><li>A <a href="http://www.bitsavers.org/pdf/honeywell/Competitive_Timesharing_Offerings_May79.pdf">Honeywell document</a> detailing different Time-Sharing Systems in 1979.     
		</li></ul>
		<dl>
			<dd>&nbsp;
		</dd></dl>
		
		<center>
			<img src="http://www.avanthar.com/healyzh/images/macmade-blkwtbrdrspinmain.gif"></center>
		
		<p><a href="http://www.avanthar.com/healyzh/decemulation/decemu.html">DEC Emulation Website (Main Page)</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp1emu.html">PDP-1</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp4emu.html">PDP-4</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp6emu.html">PDP-6</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp7emu.html">PDP-7</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp8emu.html">PDP-8</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp9emu.html">PDP-9</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp10emu.html">PDP-10</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp11emu.html">PDP-11</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp15emu.html">PDP-15</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/vax.html">VAX</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/Alpha.html">Alpha</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/MIPS.html">MIPS</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp_fpga.html">FPGA</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/Honeywell_DPS-6.html">Other: Honeywell DPS-6</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/Honeywell_DPS-8.html">Other: Honeywell DPS-8</a></p>
	

</div>]]>
            </description>
            <link>http://www.avanthar.com/healyzh/decemulation/decemu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24923707</guid>
            <pubDate>Wed, 28 Oct 2020 20:24:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The things I wished I knew when taking on a business partner]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24923437">thread link</a>) | @gmays
<br/>
October 28, 2020 | https://www.littlemight.com/articles/expensive-lessons-learned-from-a-toxic-business-partnership | <a href="https://web.archive.org/web/*/https://www.littlemight.com/articles/expensive-lessons-learned-from-a-toxic-business-partnership">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Choosing a business partner could be the second most important relationship you ever choose, (the first being who you marry).&nbsp;<br></p><p>To be honest, if you don’t handle it right, ending a business partnership can be more challenging and more expensive than a divorce.&nbsp;<br></p><p>Having done both, trust me I know.&nbsp;<br></p><p>Now 5 years later -- after our “divorce” -- I want to share a little of my story and many of the things I wish I had known to discuss from the beginning.<br></p><p>The truth was I didn’t know what I didn’t know. Now I realize that if we had some hard conversations earlier, we may have had a smoother time ending the partnership.<br></p><p><strong>In this post I’ll share:</strong></p><ul role="list"><li><strong>how things went for me; the ‘A’ years</strong></li><li><strong>how to decide if you need a partner</strong></li><li><strong>qualities you should look for <em>(and what to avoid)</em></strong></li><li><strong>how do you split equity</strong></li><li><strong>the operating agreement; some key things you’ll want in there</strong></li><li><strong>buy/sell agreement</strong></li><li><strong>business partner checklist (a to-do list for following everything in this post)</strong></li><li><strong>other tips from my trauma <em>(lol… but really</em></strong><em>)</em><strong><em>‍</em></strong></li></ul><h3><strong>my story</strong><a href="https://littlemight.com/#"><br></a></h3><p>I started <a href="https://lttlmg.ht/bestself" target="_blank">BestSelf</a>, with my business partner (who I will refer to as 'A') in mid-2015, around 18-months after we initially met. </p><p>In that time we'd hung out in person around 4-5 times. To continue the analogy of business partnership being like marriage, I'd married someone that I'd only been on a few dates with and barely knew. I partnered out of insecurity with someone who talked a good game and seemed strong in the areas I felt weak.This insecurity cost me $$$</p><figure id="w-node-76af6d16a676-3448d0da"><p><img src="https://uploads-ssl.webflow.com/5ea0c87d3db0d2d23479ff47/5f8750eb6f143d07b654067a_partnership-2.jpg" loading="lazy" alt=""></p></figure><p>We met through an entrepreneurship course online and became accountability partners soon after. With him being in New Jersey and me in NYC, we were close enough to be able to meet in person once every few months.&nbsp;<br></p><p>Through being accountability partners we became aware of each other's strengths and complementary skill sets, him with marketing and me with product design and branding.<br></p><p>As background, before <a href="https://lttlmg.ht/bestself">BestSelf</a> was born I had another Shopify store selling graphic design products that was paying all my bills and generating a good living. I considered that business my ‘Freedom vehicle’ as it allowed me to quit my Architecture job but I wasn’t passionate about doing it long-term.<br></p><p>I <em>was</em> deeply passionate about personal development during this time and was always reading and finding ways to upgrade my skills and productivity. I felt like I’d found the cheat code to life and wished I’d been introduced to it sooner. Before I quit my architecture job, I set myself a task to <a href="https://littlemight.com/articles/the-22-books-that-helped-me-quit-my-job" target="_blank">read 22 books around specific topics so I would be ready for the world of entrepreneurship.</a><br></p><p>The <a href="https://lttlmg.ht/journal" target="_blank">Self Journal</a> was later born from my personal struggle for years of finding a planner that would both keep me organized and also help me reach my most important goals.<br></p><p>I decided I wanted to turn the journal I built for myself into a product to sell, because it seemed whenever I showed it to someone they wanted to buy it.&nbsp; I didn’t think this product would be the start of something bigger, I just wanted to bring this product to life.</p><p>It was then I thought having someone who knew sales and marketing would be beneficial so I asked ‘A’ to partner with me on it. He also had his own journaling structure&nbsp; so I felt it was a common interest.<br></p><p><strong>In retrospect, I partnered out of my insecurities around marketing and selling myself. </strong></p><h6>Most entrepreneurs don't have business problems, they have emotional problems disguised as business problems —<strong> and so I disguised my fear of putting myself out there with a business partner.&nbsp;</strong><br></h6><p>And so it began.<br></p><p>The original name we came up with for the company was “Self Improvement Labs”... but I <em>hated</em> it. One weekend when ‘A’ was gone I knew I had to come up with something better to replace it with<em>.</em></p><p><em>(because I don’t like when people criticize something without giving a reasonable alternative).</em><br></p><p>In those 2 days I came up with the idea for <a href="https://lttlmg.ht/bestself">BestSelf</a>, bought the domain BestSelf.co and created a whole branding package. Thankfully there was no pushback, ‘A’ agreed it was a better name and we moved forward.<br></p><p>We launched the Kickstarter campaign in August 2015. I had experience with launching Kickstarter campaigns in the past and so I had a formula for how to do it which helped us a lot. You can read how we did it <a href="https://littlemight.com/articles/kickstarter-step-by-step" target="_blank">here</a>.<br></p><p><strong>We funded in 28 hours and over the course of 34 days we raised over $322,000 which was enough to both create the product for backers and launch the entire business.</strong></p><figure><p><img src="https://uploads-ssl.webflow.com/5ea0c87d3db0d2d23479ff47/5ea0cb1d0f854b10467cf739_5e2a2251be4a7438101d60a6_image.png" alt="funding progress graph"></p></figure><p>We launched our online store in January 2016 and the business continued to grow. We won the <a href="https://littlemight.com/articles/shopify-2016-build-a-business-experience" target="_blank">2016 Shopify Build a Business award</a> in August of 2016 and then in 2017 we scaled 4X and won the Build a BIGGER Business Award.</p><figure id="w-node-ac6b3b3d99ee-3448d0da"><p><img src="https://uploads-ssl.webflow.com/5ea0c87d3db0d2d23479ff47/5f857aa10221b7fa4725f1a6_image5.png" loading="lazy" alt=""></p></figure><figure id="w-node-9ccd9ba5eca2-3448d0da"><p><img src="https://uploads-ssl.webflow.com/5ea0c87d3db0d2d23479ff47/5f857aae7da8462c3bf9000a_image1.png" loading="lazy" alt=""></p></figure><p>When things are going so well business-wise it’s easy for things to run smoothly, it’s like the early dating phase when you don’t have to deal with too much harsh reality yet. Then the pandemic starts and you find out what your relationship is really made of.<br></p><p>By late 2016, while professionally things were still good with the business, cracks began appearing in our personal relationship… the 2016 election was a definite factor here. That was the first time it became clear how differently we saw the world and how opposite our backgrounds were.<br></p><p>In 2017, we’d hired out the majority of his role in marketing and by April 2018 he had stepped away from all business operations - informally anyway.&nbsp;<br></p><p>By informally I mean there was never a discussion of him passing the baton and stepping out, he just suddenly was no longer there. But he was still taking as much money out of the company as I was -- or more.<br></p><p><strong>As you can imagine being a 50/50 partner where one partner is working full-time and the other is completely disconnected is tough — really tough. I was essentially hamstrung on big decisions and company direction. </strong></p><p>And anything I could decide could be overwritten or debated even after I thought it was settled. The same went for team members, as every now and again he'd jump on calls, start giving advice or instruction (without knowing what was even happening) and cause frustration and confusion with team members. </p><p>By early 2019, I was becoming resentful as our distributions were still 50/50 <strong>but I wasn’t getting any salary for the 60+ hour weeks of time I was putting in. </strong>When I brought it up to him, as if he were my boss, he would say <em>“I don’t equate time with value,”</em> yet he wasn’t giving either to the company.<br></p><p>At the same time as he would reject my salary request, he’d post stuff like this on his Instagram:</p><figure id="w-node-be8cd5eaae18-3448d0da"><p><img src="https://uploads-ssl.webflow.com/5ea0c87d3db0d2d23479ff47/5f873b98bd121731d6cf0d21_3-hour-week.jpg" loading="lazy" alt=""></p></figure><h6>Here's a tip, if someone’s telling you running a business is easy — they’re either lying, or trying to <strong>sell</strong> you something.<br></h6><p>In the case of ‘A’, it was both.<br></p><p>Each video “guru” post he’d share taking credit for work that wasn’t his &nbsp;felt like a slap in the face — not just to me but,&nbsp; more importantly, to the team. <strong>Being under-paid (or not paid at all) is one thing, but having my value be dismissed on top of that was actually the bigger issue -- and was the beginning of the end.</strong><br></p><p>I ended up removing him on all social media platforms in mid 2019 because posts like the one above were triggering me.<br></p><p>By July 2019, we finally agreed on a modest salary for me in lieu of taking distributions which I would be made up for later. This still meant that I was getting the same $ amount or less per month as he was but at least now I had an IOU.&nbsp;<br></p><p><em>(I did this as I didn’t want to take more cash out of the business that would negatively impact our growth.)</em><br></p><p>Yay, a salary! <strong>I was now the 3rd highest paid person on my team of 10</strong> -- and getting the same as the person that had done nothing for the company in more than a year.<br></p><figure id="w-node-cc78a0f0c1db-3448d0da"><p><img src="https://uploads-ssl.webflow.com/5ea0c87d3db0d2d23479ff47/5f86195162505211420ac4da_Image%202.JPG" loading="lazy" alt=""></p></figure><p>By the end of 2019, other things happened that I won’t go into. Suffice to say, I was mentally exhausted and felt completely taken advantage of by someone I had trusted.&nbsp;<br></p><p>So we looked for options to get out...either of the business, or at least the partnership.<br></p><p>When numbers around buyout expectations came up, there was a chasm of difference between what ‘A’ felt he deserved and what was realistic -- especially given how much he’d already taken over the last 18 months without working ($400k+).&nbsp;<br></p><p>Taking on investors or another partner seemed like the only option. However, by that point, I had no interest in bringing in someone that may have me ending up in the same place.<br></p><p><strong>Better the devil you know...</strong><br></p><p>Going into 2020 I felt stuck between a rock and a hard place.&nbsp;<br></p><p>On one hand I wanted to grow the business, innovate with new products and keep my team charged. Yet, on the other hand, I knew doing so would mean eventually paying him more in a buyout situation.<br></p><p>Every year I do a yearly review to reflect on the prior year and to set some big goals for the new year. Maybe you’ve seen them. Good, bad and mixed… I've shared my review publicly in <a href="https://littlemight.com/articles/2014-review" target="_blank">2014</a>, <a href="https://littlemight.com/articles/2015-review" target="_blank">2015</a>, <a href="https://littlemight.com/articles/2016-review" target="_blank">2016</a>, <a href="https://littlemight.com/articles/2017-review" target="_blank">2017</a>, <a href="https://littlemight.com/articles/2018-review" target="_blank">2018</a>... right up until this year.<br></p><p><strong>This year I couldn't bring myself to share my review and big goal <em>publicly</em>.</strong><br></p><p><em>(It seems funny now given the dumpster fire that 2020 has been that I just knew putting plans out there might not be the best idea.)</em><br></p><p>The thing I was scared to share publicly was that <strong>my biggest goal for 2020 was to end my business partnership with ‘A’ once and for all.</strong><br></p><p>Between COVID affecting business and other extenuating factors, we could finally agree on a reasonable buyout number in August 2020 -- after over 7 months of negotiation. While it had me taking on a significant amount of personal debt, I was happy to do so because I believe so strongly BestSelf -- and in my incredible team.<br></p><p>As of September 24th 2020 I’m officially 100% owner in <a href="https://lttlmg.ht/bestself" target="_blank">BestSelf</a> - <a href="https://www.instagram.com/p/CFr72LMHSIk/?utm_source=ig_web_copy_link" target="_blank"><strong>official announcement here</strong></a><strong>.</strong><br></p><h6><strong>To say I was excited would be an understatement 🙌🏻</strong></h6><figure id="w-node-8453fbbbca5b-3448d0da"><a href="http://instagram.com/cathryn.lavery" target="_blank"><p><img src="https://uploads-ssl.webflow.com/5ea0c87d3db0d2d23479ff47/5f861a99397936d25e6798ea_giphy%20(9).gif" loading="lazy" alt=""></p></a><figcaption>yay!</figcaption></figure><h3>‍<strong>what I would do differently</strong><br></h3><p>I don’t believe in regrets or wishing things were different - everything worked out as it was meant to and this was a huge learning experience for me.&nbsp;<br></p><blockquote><em>“Don’t wish it was easier, wish you were better”</em> - Jim Rohn</blockquote><p>This famous Jim Rohn quote perfectly fits here, this whole experience taught me a lot about myself and what I’m capable of.&nbsp;<br></p><p>That said… I learned some big lessons that would make me approach any future partnership extremely differently. And I want to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.littlemight.com/articles/expensive-lessons-learned-from-a-toxic-business-partnership">https://www.littlemight.com/articles/expensive-lessons-learned-from-a-toxic-business-partnership</a></em></p>]]>
            </description>
            <link>https://www.littlemight.com/articles/expensive-lessons-learned-from-a-toxic-business-partnership</link>
            <guid isPermaLink="false">hacker-news-small-sites-24923437</guid>
            <pubDate>Wed, 28 Oct 2020 19:58:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Clean CSV Data at the Command Line]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24923360">thread link</a>) | @ethink
<br/>
October 28, 2020 | https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line | <a href="https://web.archive.org/web/*/https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><figure><p><img src="https://uploads-ssl.webflow.com/5f359c073455c743bc873ee4/5f94930788d137b29665878b_clean-csv.jpg" loading="lazy" alt=""></p><figcaption>Photo by <a href="https://unsplash.com/@cdc?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">CDC</a> on <a href="https://unsplash.com/s/photos/covid?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure><p>Have you ever dealt with a big-scary CSV file that has many columns that you don’t want and many records that slow down the process for you to filter and get the desired information? </p><p>This tutorial is about using two command-line programs that can solve these problems; <a href="https://csvkit.readthedocs.io/en/latest/" target="_blank">csvkit</a> and <a href="https://github.com/BurntSushi/xsv" target="_blank">xsv</a>. We will compare the two at the end and see how performant each and when we can use one and not the other in terms of speed especially if we’re processing a large CSV file. In the last blog post, we talked about <a href="https://www.ezzeddinabdullah.com/posts/how-to-clean-text-data-at-the-command-line" target="_blank">how to clean text data at the command line</a> that I recommend to have a look at.</p><h2>Downloading COVID&nbsp;data from covidtracking</h2><p>Let's first download recent coronavirus data across the United States from <a href="https://covidtracking.com/data/download">COVID Tracking Project</a> which is a volunteer organization dedicated to collecting and publishing the data required to understand the COVID-19 outbreak in the US. Btw, The data is published under a <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons CC BY 4.0</a> license.</p><p>Let's do this by downloading the <a href="https://covidtracking.com/data/download/all-states-history.csv">CSV&nbsp;file manually</a> or using <em>curl</em>:</p><div><pre>$ curl -LO https://covidtracking.com/data/download/all-states-history.csv
</pre></div><p><strong>-LO </strong>is a combination of <strong>-L&nbsp;</strong>and <strong>-O</strong></p><ul role="list"><li><strong>-L </strong>is used to make sure if the URL&nbsp;has changed to another location, <em>curl</em> will redo the request on the new redirection link</li><li><strong>-O </strong>this option is used to create an output file of the same name of the requested file name which is <strong>all-states-history.csv </strong>here</li></ul><h2>Printing the CSV&nbsp;file headers</h2><p>Let's first print what column names we have for this <em>all-states.history.csv </em>file:</p><div><pre>$ csvcut -n all-states-history.csv 
  1: date
  2: state
  3: dataQualityGrade
  4: death
  5: deathConfirmed
  6: deathIncrease
  7: deathProbable
  8: hospitalized
  9: hospitalizedCumulative
 10: hospitalizedCurrently
 11: hospitalizedIncrease
 12: inIcuCumulative
 13: inIcuCurrently
 14: negative
 15: negativeIncrease
 16: negativeTestsAntibody
 17: negativeTestsPeopleAntibody
 18: negativeTestsViral
 19: onVentilatorCumulative
 20: onVentilatorCurrently
 21: pending
 22: positive
 23: positiveCasesViral
 24: positiveIncrease
 25: positiveScore
 26: positiveTestsAntibody
 27: positiveTestsAntigen
 28: positiveTestsPeopleAntibody
 29: positiveTestsPeopleAntigen
 30: positiveTestsViral
 31: recovered
 32: totalTestEncountersViral
 33: totalTestEncountersViralIncrease
 34: totalTestResults
 35: totalTestResultsIncrease
 36: totalTestsAntibody
 37: totalTestsAntigen
 38: totalTestsPeopleAntibody
 39: totalTestsPeopleAntigen
 40: totalTestsPeopleViral
 41: totalTestsPeopleViralIncrease
 42: totalTestsViral
 43: totalTestsViralIncrease
</pre></div><p>As you can see, using <strong>csvcut </strong>with the option <strong>-n </strong>can list all the headers we have with their associated order which can help us select some specific columns that we're interested in.</p><h2>Selecting specific columns</h2><p>In this tutorial, we're interested in four columns and these are their descriptions as reported by the COVID&nbsp;Tracking&nbsp;Project:</p><ol start="1" role="list"><li>data:&nbsp;Date on which data was collected by The COVID Tracking Project.</li><li>state: Two-letter abbreviation for the state or territory.</li><li>positive: Total number of <strong>confirmed plus probable cases</strong> of COVID-19 reported by the state or territory</li><li>death:&nbsp;Total <strong>fatalities with confirmed OR probable COVID-19 case diagnosis</strong><br></li></ol><p>Let's see how we can get the first 10 lines of these 4 columns in our CSV&nbsp;file at the command line:</p><div><pre>$ csvcut -c date,state,positive,death all-states-history.csv | head | csvlook 
|       date | state | positive |  death |
| ---------- | ----- | -------- | ------ |
| 2020-10-26 | AK    |   14,413 |     68 |
| 2020-10-26 | AL    |  185,322 |  2,866 |
| 2020-10-26 | AR    |  106,727 |  1,833 |
| 2020-10-26 | AS    |        0 |      0 |
| 2020-10-26 | AZ    |  238,964 |  5,875 |
| 2020-10-26 | CA    |  901,010 | 17,357 |
| 2020-10-26 | CO    |   95,089 |  2,076 |
| 2020-10-26 | CT    |   68,099 |  4,589 |
| 2020-10-26 | DC    |   16,812 |    642 |
</pre></div><p>So <strong>csvcut </strong>with the option <strong>-c </strong>is used here to select the upcoming columns separated by commas. These 10 lines look better aligned with <strong>csvlook</strong></p><p>Note that we could've done that with either of the following commands:</p><div><pre>$ csvcut -c 1,2,22,4 all-states-history.csv | csvgrep -c state -m CA |head | csvlook
$ csvcut -c 1-2,22,4 all-states-history.csv | csvgrep -c state -m CA |head | csvlook
$ csvcut -c 1-2,positive,4 all-states-history.csv | csvgrep -c state -m CA |head | csvlook
</pre></div><p>Meaning you can select the columns with their numbers or ranges or a combination of numbers and column names as strings.</p><p>Take care that this CSV&nbsp;data may differ from yours if you're using the recent data from the COVID&nbsp;Tracking Project on another day than the day this tutorial was written.</p><h2>Filtering information</h2><p>Let's now filter out COVID&nbsp;data at California state:</p><div><pre>$ csvcut -c date,state,positive,death all-states-history.csv | csvgrep -c state -m AL | head | csvlook 
|       date | state | positive | death |
| ---------- | ----- | -------- | ----- |
| 2020-10-26 | AL    |  185,322 | 2,866 |
| 2020-10-25 | AL    |  184,355 | 2,866 |
| 2020-10-24 | AL    |  183,276 | 2,866 |
| 2020-10-23 | AL    |  180,916 | 2,859 |
| 2020-10-22 | AL    |  177,064 | 2,843 |
| 2020-10-21 | AL    |  174,528 | 2,805 |
| 2020-10-20 | AL    |  174,528 | 2,805 |
| 2020-10-19 | AL    |  173,485 | 2,789 |
| 2020-10-18 | AL    |  172,626 | 2,788 |
</pre></div><p>We used here <strong>csvgrep</strong> with the option <strong>-c </strong>to select the column that we’re filtering which is the <em>state </em>here to match <em>AL</em> using <strong>-m </strong>option that matches the pattern we search for.</p><p>I'd like to make sure of this data, so I&nbsp;went to Google and asked how many cases we have at Alabama and this is the answer:</p><figure><p><img src="https://uploads-ssl.webflow.com/5f359c073455c743bc873ee4/5f988fc5968f41509e41fbfe_Screen%20Shot%202020-10-27%20at%2011.22.07%20PM.png" loading="lazy" alt=""></p><figcaption>Image by the Author</figcaption></figure><p>Looks like the data reported by the COVID Tracking Project is close to what Google is reporting having 186K positive cases and 2892 fatalities.</p><p>If you also put another column to show the increase in the positive cases from the previous day, you'd find:</p><div><pre>$ csvcut -c date,state,positive,24,death all-states-history.csv | csvgrep -c state -m AL | head | csvlook
|       date | state | positive | positiveIncrease | death |
| ---------- | ----- | -------- | ---------------- | ----- |
| 2020-10-26 | AL    |  185,322 |              967 | 2,866 |
| 2020-10-25 | AL    |  184,355 |            1,079 | 2,866 |
| 2020-10-24 | AL    |  183,276 |            2,360 | 2,866 |
| 2020-10-23 | AL    |  180,916 |            3,852 | 2,859 |
| 2020-10-22 | AL    |  177,064 |            2,536 | 2,843 |
| 2020-10-21 | AL    |  174,528 |                0 | 2,805 |
| 2020-10-20 | AL    |  174,528 |            1,043 | 2,805 |
| 2020-10-19 | AL    |  173,485 |              859 | 2,789 |
| 2020-10-18 | AL    |  172,626 |              964 | 2,788 |
</pre></div><p>967 positive cases increased from Oct. 26 to Oct. 27 and this number exactly matches what Google reports (+967)&nbsp;below the Total cases number in the image above.</p><h2>Joining two CSVs</h2><p>I'm not familiar with some abbreviations in the state column, so let's have the second CSV file which we can join on to get a cleaner output of CSV data we understand. Let's download it using <em>curl:</em></p><div><pre>$ curl -LO https://gist.githubusercontent.com/afomi/8824ddb02a68cf15151a804d4d0dc3b7/raw/5f1cfabf2e65c5661a9ed12af27953ae4032b136/states.csv
</pre></div><p>This <strong>states.csv</strong><em> </em>file has two columns:&nbsp;<em>State</em> and <em>Abbreviation</em></p><p>Let's see how we can make this interesting join here:</p><div><pre>$ csvjoin -c Abbreviation,state states.csv all-states-history.csv | csvcut -c date,State,Abbreviation,positive,death | head | csvlook 
|       date | State   | Abbreviation | positive | death |
| ---------- | ------- | ------------ | -------- | ----- |
| 2020-10-26 | ALABAMA | AL           |  185,322 | 2,866 |
| 2020-10-25 | ALABAMA | AL           |  184,355 | 2,866 |
| 2020-10-24 | ALABAMA | AL           |  183,276 | 2,866 |
| 2020-10-23 | ALABAMA | AL           |  180,916 | 2,859 |
| 2020-10-22 | ALABAMA | AL           |  177,064 | 2,843 |
| 2020-10-21 | ALABAMA | AL           |  174,528 | 2,805 |
| 2020-10-20 | ALABAMA | AL           |  174,528 | 2,805 |
| 2020-10-19 | ALABAMA | AL           |  173,485 | 2,789 |
| 2020-10-18 | ALABAMA | AL           |  172,626 | 2,788 |
</pre></div><p>Note here that <strong>csvjoin </strong>command takes much time because it's reading both files into memory.</p><p>Here we joined the two CSV files on a column for each CSV; <em>Abbreviation</em> in the first file and <em>state </em>in the second one and then we filtered out 5 columns to view using <strong>csvcut -c </strong></p><p>Also, note that there the second column you filtered out when you joined is gone meaning if you filtered out <em>state (</em>which was the column that has the two-letter abbreviation of the state) it will give an error that 'state' is invalid which means this column is not there anymore.</p><h2>Comparing between xsv and csvkit utilities</h2><p>As we noticed, some commands took much time using csvkit command line utility. Let's see a quick comparison between its command-line tools and their associated ones at xsv.</p><p>All the upcoming commands run are relative to my machine, let's compare one by another:</p><h3>xsv headers vs csvcut -n</h3><div><pre>$ time csvcut -n all-states-history.csv | head
  1: date
  2: state
  3: dataQualityGrade
  4: death
  5: deathConfirmed
  6: deathIncrease
  7: deathProbable
  8: hospitalized
  9: hospitalizedCumulative
 10: hospitalizedCurrently

real	0m0.307s
user	0m0.224s
sys	0m0.077s
</pre></div><p>Time of csvkit's <strong>csvcut -n</strong>: ~307ms </p><div><pre>$ time xsv headers all-states-history.csv | head
1   date
2   state
3   dataQualityGrade
4   death
5   deathConfirmed
6   deathIncrease
7   deathProbable
8   hospitalized
9   hospitalizedCumulative
10  hospitalizedCurrently

real	0m0.013s
user	0m0.008s
sys	0m0.007s
</pre></div><p>Time of xsv's <strong>headers</strong>:&nbsp;~13ms</p><h3>xsv select vs csvcut -c</h3><div><pre>$ time csvcut -c date,state,positive,death all-states-history.csv | head
date,state,positive,death
2020-10-26,AK,14413,68
2020-10-26,AL,185322,2866
2020-10-26,AR,106727,1833
2020-10-26,AS,0,0
2020-10-26,AZ,238964,5875
2020-10-26,CA,901010,17357
2020-10-26,CO,95089,2076
2020-10-26,CT,68099,4589
2020-10-26,DC,16812,642

real	0m0.288s
user	0m0.209s
sys	0m0.073s
</pre></div><p>Time of csvkit's <strong>csvcut -c</strong>: ~288ms</p><div><pre>$ time xsv select date,state,positive,death all-states-history.csv | head
date,state,positive,death
2020-10-26,AK,14413,68</pre></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line">https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line</a></em></p>]]>
            </description>
            <link>https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line</link>
            <guid isPermaLink="false">hacker-news-small-sites-24923360</guid>
            <pubDate>Wed, 28 Oct 2020 19:50:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Defeat Your Impostor Syndrome as a Developer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24923323">thread link</a>) | @renanmoura
<br/>
October 28, 2020 | https://renanmf.com/defeat-your-impostor-syndrome-as-a-developer/ | <a href="https://web.archive.org/web/*/https://renanmf.com/defeat-your-impostor-syndrome-as-a-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Impostor Syndrome is real and if you have never heard of it you can easily google the concept to find an infinite amount of articles about the theme.</p><p>Here is a simple definition of Impostor Syndrome given by Wikipedia to save you the trouble of opening another tab:</p><p>"Impostor syndrome is a psychological pattern in which an individual doubts their skills, talents, or accomplishments and has a persistent internalized fear of being exposed as a "fraud". Despite external evidence of their competence, those experiencing this phenomenon remain convinced that they are frauds, and do not deserve all they have achieved. Individuals with impostorism incorrectly attribute their success to luck or interpret it as a result of deceiving others into thinking they are more intelligent than they perceive themselves to be. While early research focused on the prevalence among high-achieving women, impostor syndrome has been recognized to affect both men and women equally."</p><p>Last week I saw a <a href="https://twitter.com/Swizec/status/1318242994491772928">tweet</a> about a bug on Spotify, the major app when you think about a "music app" these days, even though they have big competitors like Apple Music and YouTube Music.</p><p>When you look for "coffe", the search results worked fine:</p><p><img src="https://renanmf.com/wp-content/uploads/2020/10/spotify_bug_1.png" alt=""></p><p>But when you look for "coffee", the results didn’t show:</p><p><img src="https://renanmf.com/wp-content/uploads/2020/10/spotify_bug_2.png" alt=""></p><p>This is not a big issue, of course, maybe some metadata missing or something else more punctual.</p><p>And this not to bash Spotify as a company, their app is great and, as a developer, I’m a heavy user of their services.</p><p>But this is a good example of how even an established company with a net worth of billions of dollars can make silly mistakes like this.</p><p>After seeing this I <a href="https://twitter.com/renanmouraf/status/1318595074511589380">tweeted</a> about this random idea of a site called "defeat your impostor syndrome", where people would post a collection of gifs and videos of bugs on apps like Twitter, Facebook, YouTube, etc.</p><p>The tag line is "If the big companies making billions have their share of problems, why do you have to be perfect?".</p><p>Since I don’t have the time to work on this, I shared with the world, maybe someone will pick it up and build it.</p><p>The tech space is getting wider every day, no matter what you do.</p><p>It’s easy to feel behind when you are a Java developer and see everybody talking about JavaScript, or if you are a Web Developer and keep reading about Machine Learning and Python and you know zero about both, not to mention the mobile apps development space and many other areas.</p><p>Becoming a good software developer is way more about how you adapt to a given situation than how you are fully prepared for it.</p><p>You will never know everything there is to know and this is ok!</p><p>There are an incredible amount of developers who have lived good lives and made good careers out of a single platform or framework like Ruby on Rails.</p><p>Master the basics well, learn algorithms and data structures, learn object-oriented programming, how to design a database properly, get your fundamentals of vanilla JavaScript rock-solid so you can switch from React to Vue or Angular way more easily.</p><p>If you are a newbie, pick a language and become proficient in it, stop looking for the next shiny thing every week, when you get really god in one, most of the knowledge is transferable.</p><p>Get past the "intro" level in something and move on to the next level, you can read <a href="https://renanmf.com/machine-learning-for-humans-how-to-learn-better-and-faster/">Machine Learning for Humans: how to learn better and faster?</a> to see why this is important and why you should focus.</p></div></div>]]>
            </description>
            <link>https://renanmf.com/defeat-your-impostor-syndrome-as-a-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24923323</guid>
            <pubDate>Wed, 28 Oct 2020 19:47:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Universal Relation Data Modelling Considered Harmful]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24923274">thread link</a>) | @ahachete
<br/>
October 28, 2020 | https://www.ongres.com/blog/universal-relation-data-modelling-considered-harmful/ | <a href="https://web.archive.org/web/*/https://www.ongres.com/blog/universal-relation-data-modelling-considered-harmful/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<main>

        	

	        <section id="post">
	            <p><span>Post</span>
	            </p>

	            <div data-aos="fade-right" data-aos-mirror="false">
	            	
	            	

                    <p> ·
                        <span>Oct 28, 2020</span> ·
                        <span>1 min read</span>
                    </p>

                    

                    

                    <div>
                        
                        <div>
  
  <p><span>Álvaro Hernández</span>
  <span>Founder and CEO</span>
</p></div>
                        
                    </div>
	            </div>

	            <div data-aos="fade-left" data-aos-delay="200" data-aos-mirror="false">
        			
<p>As part of a continued series of blog posts themed about “Relational databases and NoSQL”,
Dr. Michael Stonebraker and I co-authored a new blog post just published on
<a href="https://www.enterprisedb.com/blog/universal-relation-data-modelling-considered-harmful">EnterpriseDB’s blog</a>.</p>
<p>This post discusses the “Universal Relation” data model, which has become trendier recently under
the name of “Single Table Design”, and is frequently used and recommended in DynamoDB. We discuss a sample
DynamoDB application, and run a benchmark analyzing potential conflicts with DynamoDB transactions.
All source code is <a href="https://gitlab.com/ahachete/blog-posts-src/-/tree/master/202009-universal_relation/src">open source and
public</a>. The
source <a href="https://gitlab.com/ahachete/blog-posts-src/-/blob/master/202009-universal_relation/src/relational.sql">also contains a trivial exercise</a>,
not detailed in the blog post, on how to emulate Single Table Design with Postgres views. Not of
real utility, but shows Postgres flexibility.</p>
<p>Previous post on this serie are:</p>
<ul>
<li><a href="https://www.enterprisedb.com/blog/comparison-joins-mongodb-vs-postgresql">Comparison of JOINS: MongoDB vs. PostgreSQL</a></li>
<li><a href="https://www.enterprisedb.com/blog/schema-later-considered-harmful">“Schema Later” Considered Harmful</a></li>
</ul>

        		</div>
            </section>

        	

                            
            </main></div></div>]]>
            </description>
            <link>https://www.ongres.com/blog/universal-relation-data-modelling-considered-harmful/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24923274</guid>
            <pubDate>Wed, 28 Oct 2020 19:43:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Functional Email Server]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24923242">thread link</a>) | @panic
<br/>
October 28, 2020 | https://signalsandthreads.com/building-a-functional-email-server/ | <a href="https://web.archive.org/web/*/https://signalsandthreads.com/building-a-functional-email-server/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<h2 id="000004">00:00:04</h2>

<div><p>Welcome to Signals and Threads, in-depth conversations about every layer of the tech stack from Jane Street. I’m Ron Minsky. </p><p> All right, so, it’s my pleasure today to sit down and have a conversation with Dominick LoBraico about email. In particular, we’re going to talk about a system that Dominick architected and led the development of called Mailcore, which is Jane Street’s own homegrown mail server. </p><p> And I think this is interesting on its own because email is an interesting topic and the whole architecture behind it, but I think it’s also a lens into some interesting questions about software design and how you manage infrastructure, some questions about how you make this choice of when you build your own thing and when you use standard, existing tools, and also some interesting questions about how programming language plays a role in systems design.</p></div>

<h2 id="000048">00:00:48</h2>

<p>Hi, Ron.</p>

<h2 id="000049">00:00:49</h2>

<p>Hey, DLo. So, to get started, can you tell us a little bit about how email works?</p>

<h2 id="000054">00:00:54</h2>

<div><p>Sure. Yeah. So email is based on an old and venerable protocol on the Internet called the Simple Mail Transfer Protocol, SMTP, and SMTP… you can kind of think of it as playing the role that the Postal Service plays in delivering regular mail. It is a way for one server that wants to deliver a message somewhere, to hand that message off to another party, who can get it to its final destination, whether that is the eventual destination server itself or some intermediary who can help you get a little bit closer.
</p><p>Email itself came into fruition, as we know today, in the early days of the Internet, and the protocol itself is very simple. You basically have the actual body of the message itself, which has its own separate format and specification, and then you have a set of instructions for expressing who that message is destined for and who it’s coming from, and so one server connects to another.
</p><p>And it says, “I’ve got a message. It’s coming from so and so, and it’s meant to be delivered to some other person. Here’s the body of the message,” and the receiving server can do with that what it will. It can either say, “Great, I’ll take that, and I’ll be responsible for it from here on out.” It can say, “No, I don’t know anything about that person. You have to find somebody else to deliver that to” or reject it for any number of other reasons, like, “This looks like it has a virus,” or “You’re not allowed to connect to me,” or “I’m not available for receiving mail right now.”</p></div>

<h2 id="000217">00:02:17</h2>

<p>And one thing that always strikes me about email is it’s this kind of wondrous artifact from the early Internet, which is a <em>truly</em> open social network. There’s lots of things that people talk about, right? Could we make existing social networks better and more open and all of that, and email, just <em>is</em> from its initial design; and its complete history has been this very open thing, and as you point out, the core protocols and transports are relatively simple, although there is actually a surprising amount of complexity in the RFCs that tell you how to parse a particular email. The overall system is pretty simple, but there’s a lot of complexity in all of the different players who build systems that actually manage and transfer email around and how they deal with the various problems that happen, like spam and people attacking systems via email and all of that. So the foundations are relatively simple, but the emergent complexity of the system is actually pretty high.</p>

<h2 id="000310">00:03:10</h2>

<p>Like with many protocols of the old Internet, it was designed in a time where the world was much simpler than it is today, especially the Internet-connected world. You know, there were probably 50 institutions that had Internet connections or ARPANET connections at the time, and you didn’t really have to worry that anybody was going to be spamming because barely anybody even know what email was in the first place.</p>

<h2 id="000330">00:03:30</h2>

<div><p>When you start and build a new thing, the early properties of the thing that you build can often be really sticky and really matter in a way that’s kind of hard to predict. So this one early property of being open has stayed there. Email is a thing that anyone can participate in. Organizations can build their own infrastructure to connect to it, and through all the rather large transformations that the email system has gone through, that openness remains as a core property.
</p><p>This is the horrible thing about designing to build a new thing,  when you want to design something new, you have to make a bunch of choices, and clearly, you shouldn’t worry about them that much, because probably the thing you build is going to fail and isn’t going to work out, and even if it does, you’re going to learn more about the problem later, and so you shouldn’t worry too much about the early decisions. But also, some of the early decisions, you don’t know which ones are going to turn out to be very hard to change.</p></div>

<h2 id="000413">00:04:13</h2>

<p>That’s right.</p>

<h2 id="000414">00:04:14</h2>

<p>And you’ll be stuck with them until the end of time.</p>

<h2 id="000416">00:04:16</h2>

<p>And in fact, you know, the big players in email today – obviously Google and Gmail, are a really large percentage of the email sending and receiving on the Internet – but they’re still wrestling with some of those early decisions and some of that openness that are architected in, as they try to figure out how they can make email more secure and how they can protect their users and rein in some of the malicious actors on the Internet, and that’s just a hard thing to do while trying to maintain the existing openness that email has; it cuts both ways I guess.</p>

<h2 id="000445">00:04:45</h2>

<p>That openness, in the end, has a lot of value.</p>

<h2 id="000446">00:04:46</h2>

<p>Absolutely. Yeah.</p>

<h2 id="000448">00:04:48</h2>

<p>So the story here is about how you ended up building the system called Mailcore. What did email at Jane Street look like when you first ran into the problem?</p>

<h2 id="000456">00:04:56</h2>

<div><p>So you might think that there’s really not much special about the way Jane Street uses email compared to any other company, and largely, that’s true. I think we have a few special requirements by dint of the fact that we are in a regulated industry, so we have some requirements around logging for compliance purposes every message that is sent or received by somebody at Jane Street.
</p><p>But other than that, our email system looks pretty similar, or has looked, in the past, pretty similar, to the way an email system in any organization might look, and the rough summary is we have some mail gateways that sit on the outside of our network for receiving email from foreign servers, you know, from external parties, and then we have some mail server, or a set of servers, inside of our network that handle all of the complicated business logic around what to do with those messages.
</p><p>So, in some cases, it’s as simple as receive the message and deliver it into the mailbox of the user if we are the intended recipient. In other cases, it is apply filtering for things like spam and viruses and other things that we might want to extract from messages before we deliver them, do expansion for mailing lists. So if you send an email to some group at Jane Street, you want to be able to expand that group name to the actual list of recipient mailboxes to make sure that it actually ends up in the inboxes of the recipients who it’s destined for. And then this extra compliance implication of making sure that we’re logging all of the right messages with all of the right metadata. </p><p>And at the time that I started, the mail infrastructure here was all based on an open source mail server that has its own config language and is pretty widely used on the Internet at large, and we had about 400 or 500 lines of configuration in the most complex case, I think, for this system to get it to do all of these different things that we wanted it to be able to do.</p></div>

<h2 id="000644">00:06:44</h2>

<p>Great. So that sounds like a reasonable approach in terms of how to build oneself a mail system. What problems did we run into with it?</p>

<h2 id="000650">00:06:50</h2>

<div><p>Yeah, so the biggest problem here, at the end of the day, was the complexity required for configuring this system to do all of the things that we needed it to do. So, now, I said 400 or 500 lines of configuration – that probably doesn’t sound like a huge number, but when it’s in a kind of bespoke configuration language that’s unlike the configuration of any other system and unlike any programming language that a developer or engineer at Jane Street would be familiar with, the complexity of 400 or 500 lines in a foreign language is pretty large and can be a little bit imposing to deal with.
</p><p>In particular, we had some scary near-misses where we realized that we had done the wrong thing in terms of archiving some email for compliance purposes that we were supposed to archive, and luckily, in each of those cases, there were mitigating factors such that it didn’t end up being a big deal, but that near-miss gave us a little bit of a scare because we went and looked at the configuration and wanted to understand how we had gotten ourselves into this position, and it was harder than it felt like it should be to understand what had gone wrong and how to fix it.</p></div>

<h2 id="000750">00:07:50</h2>

<p>It’s maybe also worth mentioning that the problem of logging all of your messages for compliance purposes may sound easy, but it’s made more complicated by the fact that Jane Street is a company that operates in lots of different regulatory regimes and has actually different rules for some of the different places it operates. So even the sort of seemingly simple, “Let’s just write everything down” is more complicated than it might appear at first.</p>

<h2 id="000811">00:08:11</h2>

<p>That’s right, yeah. We have different requirements in terms of what has to be written down and what kinds of metadata we need to store and where the extra copies need to be physically located around the world and things like that, which are reasonable sounding when you think about the human aspects of it, you know, when you reason about, okay, yeah, you need a copy for this and a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://signalsandthreads.com/building-a-functional-email-server/">https://signalsandthreads.com/building-a-functional-email-server/</a></em></p>]]>
            </description>
            <link>https://signalsandthreads.com/building-a-functional-email-server/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24923242</guid>
            <pubDate>Wed, 28 Oct 2020 19:40:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Airline Safety Card Database]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24923155">thread link</a>) | @whimwell
<br/>
October 28, 2020 | https://www.airlinesafetycards.be/Safety%20cards.htm | <a href="https://web.archive.org/web/*/https://www.airlinesafetycards.be/Safety%20cards.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div dir="ltr" width="100%"><tbody><tr><!--msnavigation--><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif"><p>Besides taking pictures of aircraft, I also collect the 
safety cards which you can find on board. You know those plastic or cardboard 
cards that say what to do in case of a crash-landing or ditching. Remember NEVER 
to panic ;-)</p>
<p>
<!--webbot bot="Navigation" S-Orientation="horizontal" S-Rendering="graphics" S-Type="children" B-Include-Home="FALSE" B-Include-Up="FALSE" startspan --><a href="https://www.airlinesafetycards.be/Safety%20cards%20A-AH.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav5'].src=MSFPnav5h.src" onmouseout="if(MSFPhover) document['MSFPnav5'].src=MSFPnav5n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20A-AH.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="A-AH" name="MSFPnav5"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Ai-Air%20E.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav6'].src=MSFPnav6h.src" onmouseout="if(MSFPhover) document['MSFPnav6'].src=MSFPnav6n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Ai-Air%20E.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Ai - Air E" name="MSFPnav6"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Air%20Canada.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav7'].src=MSFPnav7h.src" onmouseout="if(MSFPhover) document['MSFPnav7'].src=MSFPnav7n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Air%20Canada.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Air Canada" name="MSFPnav7"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Air%20France.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav8'].src=MSFPnav8h.src" onmouseout="if(MSFPhover) document['MSFPnav8'].src=MSFPnav8n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Air%20France.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Air France" name="MSFPnav8"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Air%20F-Air%20L.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav9'].src=MSFPnav9h.src" onmouseout="if(MSFPhover) document['MSFPnav9'].src=MSFPnav9n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Air%20F-Air%20L.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Air F - Air L" name="MSFPnav9"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Air%20M-Air%20N.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav10'].src=MSFPnav10h.src" onmouseout="if(MSFPhover) document['MSFPnav10'].src=MSFPnav10n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Air%20M-Air%20N.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Air M - Air N" name="MSFPnav10"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Air%20O-Air%20Z.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav11'].src=MSFPnav11h.src" onmouseout="if(MSFPhover) document['MSFPnav11'].src=MSFPnav11n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Air%20O-Air%20Z.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Air O - Air Z" name="MSFPnav11"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Aira-Airw.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav12'].src=MSFPnav12h.src" onmouseout="if(MSFPhover) document['MSFPnav12'].src=MSFPnav12n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Aira-Airw.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Aira - Airw" name="MSFPnav12"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20AJ-AM.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav13'].src=MSFPnav13h.src" onmouseout="if(MSFPhover) document['MSFPnav13'].src=MSFPnav13n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20AJ-AM.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="AJ-AM" name="MSFPnav13"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20American.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav14'].src=MSFPnav14h.src" onmouseout="if(MSFPhover) document['MSFPnav14'].src=MSFPnav14n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20American.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="American" name="MSFPnav14"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20An-As.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav15'].src=MSFPnav15h.src" onmouseout="if(MSFPhover) document['MSFPnav15'].src=MSFPnav15n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20An-As.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="An-As" name="MSFPnav15"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20At-Az.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav16'].src=MSFPnav16h.src" onmouseout="if(MSFPhover) document['MSFPnav16'].src=MSFPnav16n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20At-Az.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="At-Az" name="MSFPnav16"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Austrian.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav17'].src=MSFPnav17h.src" onmouseout="if(MSFPhover) document['MSFPnav17'].src=MSFPnav17n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Austrian.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Austrian" name="MSFPnav17"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20B-Bo.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav18'].src=MSFPnav18h.src" onmouseout="if(MSFPhover) document['MSFPnav18'].src=MSFPnav18n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20B-Bo.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="B-Bo" name="MSFPnav18"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20British%20Airways.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav19'].src=MSFPnav19h.src" onmouseout="if(MSFPhover) document['MSFPnav19'].src=MSFPnav19n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20British%20Airways.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="British Airways" name="MSFPnav19"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Br-Bz.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav20'].src=MSFPnav20h.src" onmouseout="if(MSFPhover) document['MSFPnav20'].src=MSFPnav20n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Br-Bz.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Br-Bz" name="MSFPnav20"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20C-Ce.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav21'].src=MSFPnav21h.src" onmouseout="if(MSFPhover) document['MSFPnav21'].src=MSFPnav21n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20C-Ce.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="C-Ce" name="MSFPnav21"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Ch-Ck.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav22'].src=MSFPnav22h.src" onmouseout="if(MSFPhover) document['MSFPnav22'].src=MSFPnav22n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Ch-Ck.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Ch-Ck" name="MSFPnav22"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Cl-Cz.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav23'].src=MSFPnav23h.src" onmouseout="if(MSFPhover) document['MSFPnav23'].src=MSFPnav23n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Cl-Cz.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Cl-Cz" name="MSFPnav23"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20D.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav24'].src=MSFPnav24h.src" onmouseout="if(MSFPhover) document['MSFPnav24'].src=MSFPnav24n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20D.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="D" name="MSFPnav24"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Delta.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav25'].src=MSFPnav25h.src" onmouseout="if(MSFPhover) document['MSFPnav25'].src=MSFPnav25n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Delta.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Delta" name="MSFPnav25"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20E-Es.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav26'].src=MSFPnav26h.src" onmouseout="if(MSFPhover) document['MSFPnav26'].src=MSFPnav26n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20E-Es.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="E-Es" name="MSFPnav26"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Et-Ez.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav27'].src=MSFPnav27h.src" onmouseout="if(MSFPhover) document['MSFPnav27'].src=MSFPnav27n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Et-Ez.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Et-Ez" name="MSFPnav27"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20F.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav28'].src=MSFPnav28h.src" onmouseout="if(MSFPhover) document['MSFPnav28'].src=MSFPnav28n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20F.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="F" name="MSFPnav28"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20G.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav29'].src=MSFPnav29h.src" onmouseout="if(MSFPhover) document['MSFPnav29'].src=MSFPnav29n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20G.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="G" name="MSFPnav29"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20H.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav30'].src=MSFPnav30h.src" onmouseout="if(MSFPhover) document['MSFPnav30'].src=MSFPnav30n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20H.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="H" name="MSFPnav30"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20I.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav31'].src=MSFPnav31h.src" onmouseout="if(MSFPhover) document['MSFPnav31'].src=MSFPnav31n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20I.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="I" name="MSFPnav31"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Iberia.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav32'].src=MSFPnav32h.src" onmouseout="if(MSFPhover) document['MSFPnav32'].src=MSFPnav32n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Iberia.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Iberia" name="MSFPnav32"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20J.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav33'].src=MSFPnav33h.src" onmouseout="if(MSFPhover) document['MSFPnav33'].src=MSFPnav33n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20J.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="J" name="MSFPnav33"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20K.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav34'].src=MSFPnav34h.src" onmouseout="if(MSFPhover) document['MSFPnav34'].src=MSFPnav34n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20K.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="K" name="MSFPnav34"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20KLM.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav35'].src=MSFPnav35h.src" onmouseout="if(MSFPhover) document['MSFPnav35'].src=MSFPnav35n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20KLM.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="KLM" name="MSFPnav35"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20L.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav36'].src=MSFPnav36h.src" onmouseout="if(MSFPhover) document['MSFPnav36'].src=MSFPnav36n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20L.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="L" name="MSFPnav36"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Lufthansa.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav37'].src=MSFPnav37h.src" onmouseout="if(MSFPhover) document['MSFPnav37'].src=MSFPnav37n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Lufthansa.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Lufthansa" name="MSFPnav37"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20M-Md.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav38'].src=MSFPnav38h.src" onmouseout="if(MSFPhover) document['MSFPnav38'].src=MSFPnav38n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20M-Md.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="M-Md" name="MSFPnav38"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Me-Mz.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav39'].src=MSFPnav39h.src" onmouseout="if(MSFPhover) document['MSFPnav39'].src=MSFPnav39n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Me-Mz.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Me-Mz" name="MSFPnav39"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20N.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav40'].src=MSFPnav40h.src" onmouseout="if(MSFPhover) document['MSFPnav40'].src=MSFPnav40n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20N.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="N" name="MSFPnav40"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20O.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav41'].src=MSFPnav41h.src" onmouseout="if(MSFPhover) document['MSFPnav41'].src=MSFPnav41n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20O.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="O" name="MSFPnav41"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20P.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav42'].src=MSFPnav42h.src" onmouseout="if(MSFPhover) document['MSFPnav42'].src=MSFPnav42n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20P.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="P" name="MSFPnav42"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Q.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav43'].src=MSFPnav43h.src" onmouseout="if(MSFPhover) document['MSFPnav43'].src=MSFPnav43n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Q.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Q" name="MSFPnav43"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20R.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav44'].src=MSFPnav44h.src" onmouseout="if(MSFPhover) document['MSFPnav44'].src=MSFPnav44n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20R.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="R" name="MSFPnav44"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Sabena.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav45'].src=MSFPnav45h.src" onmouseout="if(MSFPhover) document['MSFPnav45'].src=MSFPnav45n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Sabena.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Sabena" name="MSFPnav45"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20S-SA.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav46'].src=MSFPnav46h.src" onmouseout="if(MSFPhover) document['MSFPnav46'].src=MSFPnav46n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20S-SA.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="S-SA" name="MSFPnav46"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Sb-Sk.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav47'].src=MSFPnav47h.src" onmouseout="if(MSFPhover) document['MSFPnav47'].src=MSFPnav47n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Sb-Sk.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="SB-SK" name="MSFPnav47"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Sl-So.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav48'].src=MSFPnav48h.src" onmouseout="if(MSFPhover) document['MSFPnav48'].src=MSFPnav48n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Sl-So.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Sl-So" name="MSFPnav48"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Sp-Sz.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav49'].src=MSFPnav49h.src" onmouseout="if(MSFPhover) document['MSFPnav49'].src=MSFPnav49n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Sp-Sz.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Sp-Sz" name="MSFPnav49"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20T-Ta.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav50'].src=MSFPnav50h.src" onmouseout="if(MSFPhover) document['MSFPnav50'].src=MSFPnav50n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20T-Ta.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="T-Ta" name="MSFPnav50"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Tc-Th.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav51'].src=MSFPnav51h.src" onmouseout="if(MSFPhover) document['MSFPnav51'].src=MSFPnav51n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Tc-Th.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Tc-Th" name="MSFPnav51"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Ti-Tun.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav52'].src=MSFPnav52h.src" onmouseout="if(MSFPhover) document['MSFPnav52'].src=MSFPnav52n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Ti-Tun.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Ti-Tun" name="MSFPnav52"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20Tur-Tz.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav53'].src=MSFPnav53h.src" onmouseout="if(MSFPhover) document['MSFPnav53'].src=MSFPnav53n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20Tur-Tz.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="Tur-Tz" name="MSFPnav53"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20U.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav54'].src=MSFPnav54h.src" onmouseout="if(MSFPhover) document['MSFPnav54'].src=MSFPnav54n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20U.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="U" name="MSFPnav54"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20United.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav55'].src=MSFPnav55h.src" onmouseout="if(MSFPhover) document['MSFPnav55'].src=MSFPnav55n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20United.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="United" name="MSFPnav55"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20V.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav56'].src=MSFPnav56h.src" onmouseout="if(MSFPhover) document['MSFPnav56'].src=MSFPnav56n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20V.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="V" name="MSFPnav56"></a> <a href="https://www.airlinesafetycards.be/Safety%20cards%20W-Z.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav57'].src=MSFPnav57h.src" onmouseout="if(MSFPhover) document['MSFPnav57'].src=MSFPnav57n.src"><img src="https://www.airlinesafetycards.be/_derived/Safety%20cards%20W-Z.htm_cmp_blitz010_hbtn.gif" width="140" height="40" alt="W-Z" name="MSFPnav57"></a><!--webbot bot="Navigation" i-checksum="2693" endspan --></p>
<p>The list is sorted alphabetically on the name of the company. 
For each company, the cards have been sorted on 'Type'. To go to the 
thumbnails, click on one of the bars above. Then just click on a thumbnail to 
get a bigger picture. All dimensions are in centimeter. This list has been 
updated on 
<b> 
<!--webbot bot="Timestamp" S-Type="EDITED" S-Format="%d/%m/%Y" startspan -->24/07/2020<!--webbot bot="Timestamp" i-checksum="12600" endspan --></b>.</p>
<p>My collection sorted by
<a target="_blank" href="https://1drv.ms/b/s!Aqpo7BmdtPnChsVbJLvSJWuAOPBQJA?e=We6ooA">
company</a>,
<a target="_blank" href="https://1drv.ms/b/s!Aqpo7BmdtPnChsVckTn9KEH8UIlczw?e=hjnCrQ">
country</a> and
<a target="_blank" href="https://1drv.ms/b/s!Aqpo7BmdtPnChsVdSPqSMtfx3DRxQA?e=ODpL0R">
type</a>.</p>
</span><blockquote><span face="Verdana,Arial,Helvetica,sans-serif">
  </span><blockquote><span face="Verdana,Arial,Helvetica,sans-serif">
	<p><u><span size="2">Latest</span></u><span size="2"><u> 
	additions</u>: added on May 23, 2020</span></p>
	<!--mstheme--></span><!--msthemelist--><table>
		<!--msthemelist--><tbody><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9314.jpg">Aeroflot AN-2</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9344.jpg">Air Niugini 
		BOEING 767-300</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9317.jpg">Aviakompania 
		Arkhangelskie Vozdushnye Linie YK-40</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9319.jpg">Azur Air BOEING 
		777-300</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9343.jpg">Biman 
		Bangladesh Airlines BOEING 787-8</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9273.jpg">China Airlines 
		747-F</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9283.jpg">Delta A350-900</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9272.jpg">Dragonair 
		Boeing 747/300 Freighter</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9291.jpg">Egyptair A220 - 
		300</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9275.jpg">Ejército del 
		Aire - 47 Grupo Mixto de FF.AA B707-300 TK17-2 T17-3</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9337.jpg">Eva Air B777F 
		FREIGHTER</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9293.jpg">Eva Air B787</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9274.jpg">Federal Express 
		B-747</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9285.jpg">FlyEgypt B737- 
		700</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9313.jpg">Gill Airways 
		ATR 72</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9312.jpg">Gill Airways 
		SHORTS 330-360</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9343.jpg">GX Airlines 
		A320</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9280.jpg">Hawaiian 
		Airlines A330</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9281.jpg">Hawaiian 
		Airlines B717</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9276.jpg">JAL Japan Air 
		Lines 747F</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9277.jpg">JAL Japan 
		Airlines MD11 INT</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9282.jpg">Malta Air 
		Boeing 737-800</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9324.jpg">Nordavia 
		Regional Airlines AH-24</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9325.jpg">NordStar ATR 
		42-500</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9294.jpg">rotana JET 
		AIRBUS A319</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9336.jpg">Saratov 
		Airlines AH - 148-100B 83 passengers</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9328.jpg">Saratov 
		Airlines YK-42 100 seat</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9329.jpg">Sichuan 
		Airlines A350 panda</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9341.jpg">Singapore 
		Airlines B787-10</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9284.jpg">South African 
		Airways Airbus 350-900</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9292.jpg">Sunday / Scat 
		Airlines B757 Boeing 757-200</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/9278.jpg">VIASA DC-10</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
	<!--msthemelist--></tbody></table><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
	<p><u><span size="2">Earlier</span></u><span size="2"><u> 
	additions</u>: added on April 25, 2020</span></p>
	<!--mstheme--></span><!--msthemelist--><table>
		<!--msthemelist--><tbody><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8517.jpg">Luftwaffe 
		Flugbereitschaft BMVg VFW 614</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8740.jpg">Palair 
		Macedonian BAC 1-11</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8741.jpg">PAWA Dominicana 
		MD 82/83</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8742.jpg">Philippine 
		Airlines AIRBUS A300</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8743.jpg">Philippine 
		Airlines DC-10</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8744.jpg">Philippine 
		Airlines BOMBARDIER Q400</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
	<!--msthemelist--></tbody></table><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
	<p><u><span size="2">Earlier</span></u><span size="2"><u> 
	additions</u>: added on April 18, 2020</span></p>
	<!--mstheme--></span><!--msthemelist--><table>
		<!--msthemelist--><tbody><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8339.jpg">Air Atlanta, 
		Icelandic B747-400 CONVERTED FREIGHTER</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8340.jpg">Air Djibouti 
		operated by: Cardiff Aviation BOEING 737-400</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8365.jpg">AirTanker / 
		Royal Air Force A330</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8343.jpg">Alpha Star 
		Aviation Services A319 HZ-A4</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8413.jpg">ANA B-767-200</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8371.jpg">Braniff A-320</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8425.jpg">British Airways 
		Airbus A321neo</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8377.jpg">CanAir Convair 
		580</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8407.jpg">Cathay Dragon 
		A330 A33C / A33H</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8424.jpg">Czech Air Force 
		Jakovlev JAK - 40 1257</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8388.jpg">Eastern 
		A300Whisperliner</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8389.jpg">Florida Express 
		BAC 1-11</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8313.jpg">Hawaiian 
		Airlines no type</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8390.jpg">Hawaiian DASH 7</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8415.jpg">JAL A300-600R</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8414.jpg">Juneyao Air 
		A321</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8391.jpg">LATAM A 350</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8410.jpg">Malaysia 
		Airlines A350-900</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8362.jpg">sky express ATR 
		42/72</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8409.jpg">Spring japan 
		BOEING 737-800</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8401.jpg">Sunrise Airways 
		BOEING 737-800</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8478.jpg">Turkish 
		Airlines BOEING 777-300 JEM JEN JEP</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
		</span><p><span face="Verdana,Arial,Helvetica,sans-serif"><span size="2">
		<a target="_blank" href="https://www.airlinesafetycards.be/images/safety%20cards/8402.jpg">XTRAirways 
		Boeing 737-400</a></span><!--mstheme--></span><!--msthemelist--></p></td></tr>
	<!--msthemelist--></tbody></table><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
  </span></blockquote><span face="Verdana,Arial,Helvetica,sans-serif">
</span></blockquote><span face="Verdana,Arial,Helvetica,sans-serif">
<p>With the beginning of the new year, I want to set myself some 
collecting targets:</p>
<!--mstheme--></span><!--msthemelist--><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
<p><b><u>Cards I am looking for (contact me if you have any of 
these for TRADE or sale):</u></b></p>
<!--mstheme--></span><!--msthemelist--><table>
	<!--msthemelist--><tbody><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
	<p><b>Old Belgian cards (Sabena, Sobelair, Pomair, Abelag 
	Airways, Belgian Air Force, ...)</b></p><!--mstheme--></span><!--msthemelist--></td></tr>
	<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
	<p><b>Air Congo and Air Zaïre</b></p><!--mstheme--></span><!--msthemelist--></td></tr>
	<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
	<p><b>Air Force One and Marine One</b></p><!--mstheme--></span><!--msthemelist--></td></tr>
	<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
	<p><b>SOFIA 747SP (edition 2010) &amp; other NASA cards (DC-8, ...)</b></p>
	<!--mstheme--></span><!--msthemelist--></td></tr>
	<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
	<p><b>Dutch Government Fokker 70 PH-KBX</b></p><!--mstheme--></span><!--msthemelist--></td></tr>
	<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
	<p><b>Las Vegas Sands L-1011, 747SP, A340-500, 767-300 and 
	737-300/700</b></p><!--mstheme--></span><!--msthemelist--></td></tr>
	<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
	<p><b>ARAMCO Embraer 170</b></p><!--mstheme--></span><!--msthemelist--></td></tr>
	<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
	<p><b>Douglas DC-10 e.g. Orbis</b></p><!--mstheme--></span><!--msthemelist--></td></tr>
	<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
	<p><b>Lockheed TriStar</b></p><!--mstheme--></span><!--msthemelist--></td></tr>
	<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
	<p><b>Boeing 747SP</b></p><!--mstheme--></span><!--msthemelist--></td></tr>
	<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
	<p><b>Caravelle</b></p><!--mstheme--></span><!--msthemelist--></td></tr>
<!--msthemelist--></tbody></table><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
<p>You know, sometimes those cards can be fun... Look for the 
humour in this image taken from the Air Finland 757-200 safety card.</p>
<p><img src="https://www.airlinesafetycards.be/images/FUN.jpg" width="720" height="164"><br>
</p>
<p>It is also very interesting to see what the aircraft interior 
looks like. The next picture shows Berlusconi's A319CJ (Aeronautica Militare 
Italiana).</p>
<p>
<img src="https://www.airlinesafetycards.be/images/A319CJ_detail.jpg" width="720" height="308"></p>
<p>There is this awesome book about safety cards. It's called '<b>Design 
For Impact</b>'. It takes you way back to the very beginning of the safety 
cards, to an era in aviation where men wore high hats and their women fancy 
dresses. It turns out that the first 'real' safety cards were introduced on 
board airplanes in the Thirties. They mostly consisted of written words, where 
today's cards only contain pictures and drawings. Anyway, if any of you is 
looking for an interesting book to read with a lot of pictures of old safety 
cards, then this is a 'must&nbsp;have'.</p>
<p>
<u>My collection:<br>
</u>I have over 9.000 cards and I am rather proud of my collection.</p>
</span><blockquote><span face="Verdana,Arial,Helvetica,sans-serif">
  <!--mstheme--></span><!--msthemelist--><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
</span></blockquote><span face="Verdana,Arial,Helvetica,sans-serif">
<p><u>What do I hope to accomplish? </u></p>
<!--mstheme--></span><!--msthemelist--><table>
	<!--msthemelist--><tbody><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
  <p>First of all, I hope one day to be able to give a complete 
	overview of all the Belgian safety cards ever published. I know this is 
	going to be a near impossible task. But, there is no rush, I have all the 
	time. You could call it a life's work.</p><!--mstheme--></span><!--msthemelist--></td></tr>
	<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
  <p>Secondly, I want to have a safety card from every aircraft I 
	have on photo.</p><!--mstheme--></span><!--msthemelist--></td></tr>
	<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
  <p>Thirdly, as the Lockheed TriStar is my favourite aircraft, the 
	safety cards on board these gracious iron birds are dear to me as well. </p>
  	<!--mstheme--></span><!--msthemelist--></td></tr>
	<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
  <p>Last, but certainly not least: there has to be passion, but it 
	should not become an obsession.</p><!--mstheme--></span><!--msthemelist--></td></tr>
<!--msthemelist--></tbody></table><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
<!--msthemeseparator--><p><img src="https://www.airlinesafetycards.be/_themes/blitz/btzhsepa.gif" width="600" height="10" alt="horizontal rule"></p>
<p>If you are interested, I have some spare cards. Just send me an
<a title="Click here to send me an email." href="mailto:kevin@airlinesafetycards.be?subject=Safety%20cards%20swaplist">
email</a>
and I'm sure we can work something out.</p><p><u><b>Credits</b>:<br>
</u>I would like to dedicate a special thanks to all the people who have helped 
me so far to build this collection. Thank you very much!!!
</p></span><blockquote><span face="Verdana,Arial,Helvetica,sans-serif">
	</span><blockquote><span face="Verdana,Arial,Helvetica,sans-serif">
		<!--mstheme--></span><!--msthemelist--><table>
			<!--msthemelist--><tbody><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
			</span><p><span face="Verdana,Arial,Helvetica,sans-serif">Thanks a lot to Jacques Adrien who has helped me 
			enormously! Jacques, merci beaucoup!<!--mstheme--></span><!--msthemelist--></p></td></tr>
			<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
			</span><p><span face="Verdana,Arial,Helvetica,sans-serif">Thanks Serge!<!--mstheme--></span><!--msthemelist--></p></td></tr>
			<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
			</span><p><span face="Verdana,Arial,Helvetica,sans-serif">Thanks Colin! Merci beaucoup, thanks!<!--mstheme--></span><!--msthemelist--></p></td></tr>
			<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
			</span><p><span face="Verdana,Arial,Helvetica,sans-serif">Thanks Alex!<!--mstheme--></span><!--msthemelist--></p></td></tr>
			<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
			</span><p><span face="Verdana,Arial,Helvetica,sans-serif">Thanks Peter!<!--mstheme--></span><!--msthemelist--></p></td></tr>
			<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
			</span><p><span face="Verdana,Arial,Helvetica,sans-serif">Thanks Eric, a good friend and fellow spotter!<!--mstheme--></span><!--msthemelist--></p></td></tr>
			<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
			</span><p><span face="Verdana,Arial,Helvetica,sans-serif">Thanks to Greg White, for the extremely nice 
			surprises!<!--mstheme--></span><!--msthemelist--></p></td></tr>
			<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
			</span><p><span face="Verdana,Arial,Helvetica,sans-serif">Thanks to KLM!<!--mstheme--></span><!--msthemelist--></p></td></tr>
			<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
			</span><p><span face="Verdana,Arial,Helvetica,sans-serif">Thank you, Wolfgang!<!--mstheme--></span><!--msthemelist--></p></td></tr>
			<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
			</span><p><span face="Verdana,Arial,Helvetica,sans-serif">Thanks a lot Joke (my African supplier), Melissa, Hendrik, Dominique, Wim, 
			Karl, André I &amp; II, Alex, Lisa, ...<!--mstheme--></span><!--msthemelist--></p></td></tr>
			<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
			</span><p><span face="Verdana,Arial,Helvetica,sans-serif">Thanks to fellow collectors: Jan, Umberto, Fabrice, 
			Heiko, Christian, Michael, Robin, Wim, Guy, Ben, Lutz, Eliyahu, 
			Joerg, ...<!--mstheme--></span><!--msthemelist--></p></td></tr>
			<!--msthemelist--><tr><td><img src="https://www.airlinesafetycards.be/_themes/blitz/btzbul1a.gif" width="15" height="15" alt="bullet"></td><td><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
			</span><p><span face="Verdana,Arial,Helvetica,sans-serif">Thanks to Captain Igor and the entire crew!<br>&nbsp;<!--mstheme--></span><!--msthemelist--></p></td></tr>
		<!--msthemelist--></tbody></table><!--mstheme--><span face="Verdana,Arial,Helvetica,sans-serif">
	</span></blockquote><span face="Verdana,Arial,Helvetica,sans-serif">
</span></blockquote><span face="Verdana,Arial,Helvetica,sans-serif">
<p>A special word of gratitude goes to the most friendly <b>crew</b> 
of <b>N757MA</b> 
for their kindness. I hope you all may keep flying the globe for a very long 
time to come!</p></span></td></tr><!--msnavigation--></tbody></div></div>]]>
            </description>
            <link>https://www.airlinesafetycards.be/Safety%20cards.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24923155</guid>
            <pubDate>Wed, 28 Oct 2020 19:33:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learnings from Running a Longevity Startup]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24923116">thread link</a>) | @sarthakjshetty
<br/>
October 28, 2020 | https://www.celinehh.com/year-1-learnings | <a href="https://web.archive.org/web/*/https://www.celinehh.com/year-1-learnings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

      

        

        <div data-content-field="main-content">
          <div data-type="page" data-updated-on="1603911174701" id="page-5f98dba740e38c75e7b2c208"><div><div><div data-block-type="2" id="block-5f98dba740e38c75e7b2c209"><div><p>Oct 27, 2020</p><p>I incorporated Celevity in October 2019. Since then, we’ve gone from a deck and a provisional patent to a team of 12+, a lead drug, and a head brimming with new knowledge and experiences. These are some of my biggest learnings in the last year. </p><h3>Small decisions compound exponentially, especially around team &amp; culture</h3><p>One of the most important things I ever did for our culture was a mistake. The week before a key proof-of-concept study, I decided to completely rework the study design and re-question all of our assumptions. This delayed our timelines and made most of our previous work moot. It also saved the study. </p><p>That was a show not tell moment with our values - it showed the team that truth seeking is the most important thing, and no one has to be scared to tell me if they want to change up something last minute (because I did it myself!). This paved the way to many other close saves. </p><h3>For key relationships, make sure motivations are aligned</h3><p>From investors and advisors to contractors and employees, taking time to understand to fully empathize with their priorities and worries, and not automatically assuming that their motivations are the same as yours, was a hard lesson to embody. As a stereotypical bombastic founder, it was hard for me to comprehend someone <em>not </em>being mission-motivated and not wanting this in the world as badly as I do.</p><p>In hiring, I’ve found that even the most talented person will not perform well if they don’t deeply and truly care about your mission (at least at this stage of the company). In professional relationships, it’s unlikely their motivation is the same as yours, but often motivations can be complimentary. Everything is so much easier when they are. </p><h3>Most catchy startup advice has layers of nuance and conditionals that you wont realize until you’re in the thick of it</h3><p>I hit this one a lot this year, a likely consequence from listening to a few too many startup podcasts. A good example is ‘hire fast, fire fast’. Generally good advice, in my opinion. But no one tells you how difficult it is to execute on that advice, the accusations you’ll face from the person or others, the emotional toll of making a decision that affects someone’s wellbeing, and the ripple effects a firing, even if necessary, can have on the team and how to deal with that. Correct advice? Totally. But far from the full picture. One of my biggest learnings this year was becoming aware of and starting to learn how to predict the nuance and conditionals around things that seem simple from the outside. </p><h3>The line between optimism and naïveté is a wide as a hair </h3><p>To do novel hard things requires optimism that you have some key insight or ability that means you can achieve what others haven’t. You need to be optimistic to trudge through the sludge and to recruit others to your crazy idea long before it’s proven. Naive optimism is so important for building a company and telling a story. But you also need to be paranoid and see around corners. </p><p>Balancing these is difficult - too optimistic and you’ll fall into a trap, too paranoid and you’ll never make a decision. Over the last year, I’ve gained a healthy respect for the challenges ahead of us, moving my natural tendency of optimism a few inches closer to paranoia. I think this will serve us well on this next stage of our journey. </p><p>For me, the hardest part of this was realizing that the optimal balance between optimism and realism differs depending on the situation; what works when facing investors doesn’t work when recruiting, and these two situations differ significantly to the balance you need to hold internally. </p></div></div></div></div></div>
        </div>
      
    </div></div>]]>
            </description>
            <link>https://www.celinehh.com/year-1-learnings</link>
            <guid isPermaLink="false">hacker-news-small-sites-24923116</guid>
            <pubDate>Wed, 28 Oct 2020 19:31:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Privacy Puzzle: A Baffled Voter's Guide to California's Prop 24]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24923003">thread link</a>) | @iaHN
<br/>
October 28, 2020 | https://sandiegoprivacy.org/prop24.html | <a href="https://web.archive.org/web/*/https://sandiegoprivacy.org/prop24.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <p>
      Proposition 24 is a 52-page law that overhauls privacy laws in California. It's so complex that it has split the privacy community, and experts disagree about what it would mean for Californians. Most voices agree Prop 24 has some changes to love, and some to reject. The typical voter is probably very uncertain about whether to vote "Yes" or "No".
    </p>
    <p>
      We are <strong>San Diego Privacy</strong>, a small group of privacy advocates in San Diego, and we'd like to help by offering a neutral analysis. Below you'll find 10 of the biggest issues with Prop 24, along with the main points supporters (the "Yes" side) and opponents (the "No" side) make about that issue.
    </p>
    <p>We suggest you first pick the issues in purple that jump out to you the most. Then, keep count of whether you find the Yes side or the No side more compelling, for the issues you've picked. Last, total up your counts.</p>
    <p>Then, as always, go vote your values.</p>

    <p><strong><i>Update</i></strong>: When you pick the issues below that matter to you, consider <a href="https://drive.google.com/drive/folders/1FSWtcqBEbe-SOUUWZ9d7j_M3Ft1ap5CR?usp=sharing" target="_blank">downloading a shareable image</a> of that issue as well, and posting it on social media to generate discussion.</p>

    <section>
      <div>
        <div>
          <div>
            <p>I feel strongly about <strong>Pay For Privacy</strong></p>
            <div>
              <p>
                <strong>Pay for Privacy</strong> means that if you demand privacy, companies can charge you more for goods and services.
              </p>
              <ul>
                <li>Companies that rely on targeted advertising, like newspapers or free streaming music services, currently rely on targeted ads.</li>
                <li>Some privacy options allow you to block the ability to show you targeted ads.</li>
                <li>Pay-for-privacy is already allowed in existing California law.</li>
              </ul>
            </div>
            <p><a>What is "Pay For Privacy"?</a>
          </p></div>
        </div>
        <div>
          <div>
            <div>
              <div>
                <p>Yes Side Says:</p>
                <li>Says Prop 24 keeps existing pay-for-privacy laws alive.</li>
                  <li>Claims companies who rely on targeted ads, like newspapers, would be imperiled if pay-for-privacy was eliminated.</li>
                
              </div>
              <div>
                <p>
                   <a href="https://medium.com/cr-digital-lab/consumer-reports-urges-californians-to-vote-yes-on-proposition-24-693c26c8b4bd" target="_blank">Consumer Reports says</a> Prop 24 doesn't substantially change pay-for-privacy law from the existing law.
                </p>
                <p>
                   When interviewed, Prop 24 author Alastair Mactaggart warns the newspaper industry would be hit hard if pay-for-privacy options were blocked. (<a href="https://youtu.be/eWOFZOPJm78?t=2186" target="_blank">Union-Tribune video interview</a> with Yes on 24)
                </p>
              </div>
              <p><a>Sources</a>
            </p></div>
          </div>
          <div>
            <div>
              <div>
                <p>No Side Says:</p>
                <li>Says Prop 24 doesnt fix the problem of pay-for-privacy, which is already in current law.</li>
                  <li>Argues privacy is a constitutional right of Californians; it is not for sale.</li>
                  <li>Warns Prop 24 further emboldens businesses to charge consumers for privacy.</li>
                
              </div>
              
              <p><a>Sources</a>
            </p></div>
          </div>
        </div>
      </div>
      <p>
        Authors' Note: It's important to emphasize here that pay-for-privacy is already allowed in current law. Opponents see Prop 24's choice to further expand pay-for-privacy, rather than ban it, as one reason to oppose it.
      </p>
    </section>

    <section>
      <div>
        <div>
          <div>
            <p>I feel strongly about <strong>Global Opt-Out</strong></p>
            <div>
              <p>
                <strong>Global Opt-Out</strong> allows you to set up your privacy options in one place, and have them apply universally. Prop 24 allows companies to ignore those global settings, in some cases.

              </p>
              <ul>
                <li>In the future, you'll be able to set your privacy preferences in one place, rather than at each site or service.</li>
                <li>Prop 24 includes provisions for allowing companies to ignore your global privacy preferences for certain reasons, like if they want you to pay.</li>
                <li>There could be other reasons companies won't have to respect your global privacy preferences.</li>
              </ul>
            </div>
            <p><a>What is Global Opt Out?</a>
          </p></div>
        </div>
        <div>
          <div>
            <div>
              <div>
                <p>Yes Side Says:</p>
                <li>Believes pay-for-privacy means companies must be allowed to ignore your global privacy settings in order to ask you to pay (See "Pay For Privacy" above).</li>
                
              </div>
              <p>
                    The <a href="https://www.wired.com/story/california-prop-24-fight-over-privacy-future/" target="_blank">Wired article</a> covers Yes on 24's argument for why they believe it is important for companies to have the option to ignore your privacy settings.
                </p>
              <p><a>Sources</a>
            </p></div>
          </div>
          <div>
            <div>
              <div>
                <p>No Side Says:</p>
                <li>Argues consumers should be opted-out of all data collection by default.</li>
                  <li>Warns that Prop 24 allows companies to ignore your universal opt-out if they put a "Do Not Sell" button on their site.</li>
                
              </div>
              
              <p><a>Sources</a>
            </p></div>
          </div>
        </div>
      </div>
      <p>
        Authors' Note: This is a good place to note that many privacy advocates believe all efforts to collect your data should require affirmative consent from you, rather than using the "opt-out" model where companies collect your data first, and then require you to ask it be deleted or not collected.
      </p>
    </section>
    <section>
      <div>
        <div>
          <div>
            <p>I'm concerned about privacy law <strong>Enforcement</strong></p>
            <div>
              <p>
                Current privacy laws in California are rarely <strong>enforced.</strong> Only the California Attorney General can enforce California's privacy laws.
              </p>
              <ul>
                <li>California previous privacy agency was previously closed during budget cuts.</li>
                <li>The California attorney general has signaled that they don't have enough resources for enforcement.</li>
                <li>The California attorney general has asked the legislature to allow individuals the right to sue to enforce their privacy.</li>
              </ul>
            </div>
            <p><a>What's going on with enforcement?</a>
          </p></div>
        </div>
        <div>
          <div>
            <div>
              <div>
                <p>Yes Side Says:</p>
                <li>Says Prop 24 establishes a new state enforcement agency, with funding.</li>
                  <li>Says Prop 24 will enable some city and county officials to enforce the law, in addition to the California attorney general.</li>
                
              </div>
              
              <p><a>Sources</a>
            </p></div>
          </div>
          <div>
            <div>
              <div>
                <p>No Side Says:</p>
                <li>Argues individuals should be able to sue companies to enforce their privacy choices, but Prop 24 left that out.</li>
                  <li>Believes the new enforcement agency established by Prop 24 would be underfunded and ineffective.</li>
                
              </div>
              <div>
                <p>
                    Private right of action (the right for individuals to sue) is desired by many privacy organizations, <a href="https://www.eff.org/deeplinks/2020/07/why-eff-doesnt-support-cal-prop-24#:~:text=no%20enforcement%20by%20consumers" target="_blank">including the EFF</a>.
                </p>
                <p>
                   Opponents stated their objection to Prop 24's new enforcement agency in <a href="https://youtu.be/DuWspeTzOA0?t=780" target="_blank">their video interview</a> with the Union-Tribune.
                </p>
              </div>
              <p><a>Sources</a>
            </p></div>
          </div>
        </div>
      </div>
      <p>
        Authors' Note: Privacy advocates feel very strongly that Californians should have the "private right of action," or the right to sue companies to enforce privacy law. It seems to us unlikely that privacy organizations will support overhauls to California's privacy laws without that private right of action being included.
      </p>
    </section> 
    <section>
      <div>
        <div>
          <div>
            <p>I'm concerned about <strong>How Prop 24 Was Created</strong></p>
            <div>
              <p>
                Prop 24 is a 52-page law with so much complexity that even experts disagree on its meaning. It was written privately and then submitted directly to voters.
              </p>
              <ul>
                <li>Alastair Mactaggart wrote Prop 24. It has not been reviewed by the legislature.</li>
                <li>Mactaggart invited some industries to provide changes to Prop 24 as it was drafted.</li>
                <li>Mactaggart helped get California's existing CCPA privacy law passed through the legislature.</li>
              </ul>
            </div>
            <p><a>What's the deal with Prop 24's origins?</a>
          </p></div>
        </div>
        <div>
          <div>
            <div>
              <div>
                <p>Yes Side Says:</p>
                <li>Argues privacy laws are under assault by lobbyists, and Prop 24 is the fastest way to stop that.</li>
                  <li>Warns that there isn't enough enforcement of existing privacy laws, and that Prop 24 provides more enforcement.</li>
                
              </div>
              
              <p><a>Sources</a>
            </p></div>
          </div>
          <div>
            <div>
              <div>
                <p>No Side Says:</p>
                <li>Argues existing privacy laws only started to be enforced three months ago, and that it's too soon to overhaul those privacy laws.</li>
                  <li>Believes the legislature should write and pass future privacy laws, not private parties.</li>
                  <li>Warns that privacy organizations were excluded from writing Prop 24, but that industries were invited.</li>
                
              </div>
              
              <p><a>Sources</a>
            </p></div>
          </div>
        </div>
      </div>
      <p>
        Authors' Note: Due to the way this law is being proposed directly to voters, rather than going through the long process of the legislature, there are a lot of experts disagreeing with each other regarding Prop 24's implications.
      </p>
    </section>
    <section>
      <div>
        <div>
          <div>
            <p>I feel strongly about <strong>Protecting Sensitive Data</strong></p>
            <div>
              <p>
                Prop 24 classifies some types of data as "sensitive," such as race, sexual orientation and precise GPS coordinates, and restricts how companies can use them.
              </p>
              <ul>
                <li>Prop 24 sets up a new class of information called Sensitive Information.</li>
                <li>Sensitive information includes: precise geolocation; race; ethnicity; religion; genetic data; private communications; sexual orientation; and specified health information.</li>
                <li>Fines are tripled for violations of the law for children under the age of 16.</li>
              </ul>
            </div>
            <p><a>What's the …</a></p></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sandiegoprivacy.org/prop24.html">https://sandiegoprivacy.org/prop24.html</a></em></p>]]>
            </description>
            <link>https://sandiegoprivacy.org/prop24.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24923003</guid>
            <pubDate>Wed, 28 Oct 2020 19:20:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sequoia's Political Paradox]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24922957">thread link</a>) | @allenleein
<br/>
October 28, 2020 | https://www.newcomer.co/p/sequoias-political-paradox | <a href="https://web.archive.org/web/*/https://www.newcomer.co/p/sequoias-political-paradox">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1012d1a-2b86-4eb4-9f0b-1f4dde34340e_3000x1996.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1012d1a-2b86-4eb4-9f0b-1f4dde34340e_3000x1996.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/b1012d1a-2b86-4eb4-9f0b-1f4dde34340e_3000x1996.jpeg&quot;,&quot;height&quot;:969,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:3376711,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>Sequoia Capital was always destined to be the subject of my first newsletter. It’s far and away the most influential and successful venture capital firm in the world. It’s dominant in the United States and China, and it has a growing profile in India. It has a stable of early stage bets that it should be cashing in soon and some astounding late stage investments that have already gone public. Sequoia Capital is like LeBron James. He is at once widely recognized as the greatest basketball player in the game right now, and <a href="https://bleacherreport.com/articles/2913030-lebron-james-i-want-my-damn-respect-after-leading-lakers-to-2020-nba-title">still doesn’t think he gets the respect he deserves</a>. </p><p>So far this year, Sequoia has seen public listings from Unity, Snowflake, Sumo Logic, Berkeley Lights, and Lemonade. Airbnb and DoorDash could list later this year. Sequoia started investing in Stripe in its seed round. Business for Sequoia is going great.</p><p>But the firm is interesting right now because<strong> Sequoia’s leader, Doug Leone, is a die-hard, Fox News-watching Republican who supports a president whose policies undermine the firm in big and small ways. </strong>Leone shares Republican memes to his Facebook page, like one from June that reads in all capital letters: “Since liberal governors are allowing protesters to be smashed together like sardines, it’s obvious that coronavirus was never about saving lives, it was about destroying the Trump economy!” Leone is an avid Trump supporter and someone who believes the meritocracy got him where he is today, I’m told. His fervent Republican support has been <a href="https://www.vox.com/recode/2020/8/10/21362401/donald-trump-tiktok-ban-sale-microsoft-doug-leone-sequoia">earning media attention</a>. </p><p>Sequoia’s <strong>Michael Moritz</strong>’s Democratic donations certainly counterbalance <a href="https://www.vox.com/recode/2020/8/10/21362401/donald-trump-tiktok-ban-sale-microsoft-doug-leone-sequoia">Leone’s Republican political giving</a>. (<a href="https://www.fec.gov/data/receipts/individual-contributions/?contributor_employer=Sequoia+capital&amp;two_year_transaction_period=2020&amp;min_date=01%2F01%2F2019&amp;max_date=12%2F31%2F2020">They are both donating aggressively</a> ahead of the election.) That doesn’t change how problematic Leone’s politics are for the firm in a Silicon Valley where Trump’s politics are considered by many (myself included) to be beyond the pale.</p><p>Putting aside Trump’s racist and authoritarian tendencies, how can Sequoia’s leader so viscerally support an anti-China American president when the firm makes so much of its money in China? Leone helped set up Sequoia’s China strategy, but he supports a president who has made attacking China one of his signature issues.</p><p>So much of Sequoia’s financial success depends on its ability to get money into and out of China. <strong>Neil Shen</strong> — an iconic investor in China and one of Sequoia’s stewards — is seen as a candidate to replace Leone whenever he steps aside. Leone’s Republican affinity may have helped the firm navigate Trump’s attack on TikTok, but the long-term hostility toward China will be harder to unwind no matter who wins on Nov. 3. </p><p>Now after four years with China as a political football, would Sequoia’s limited partners accept a China-focused venture capitalist running its global operations? Shen’s success would seem to justify a seat at the top. “Neil Shen is probably going to run that firm long-term,” one rival American VC told me. “He's driving immense returns from China.”</p><p>The decision as to whether Shen, who is based in Hong Kong, would be elevated to run Sequoia would have major ramifications for the fund and for the relations between two superpowers. For the fund, the question is whether Shen would stick around if he were passed over. His reputation in China is so exemplary that he could easily build his own empire. “The question I’ve always asked, and other people ask is, ‘Why does he stay there?’” one well-connected American tech source said. “By straight returns, he’s the most successful investor in the world. He’s in every important China deal in a big way.” And China’s technology industry has been booming.</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0f62ea6b-3552-4daa-a3b4-1f24b6f0331c_2848x1947.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0f62ea6b-3552-4daa-a3b4-1f24b6f0331c_2848x1947.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/0f62ea6b-3552-4daa-a3b4-1f24b6f0331c_2848x1947.jpeg&quot;,&quot;height&quot;:995,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1817501,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>Geopolitically, if Shen were named the head of Sequoia, it would be taken as a sign of goodwill between the two countries. But it would also seem to signal a shift in the balance of power between Silicon Valley and the Chinese technology industry. (On paper, local business heads like Shen run their own businesses independently, while the global managing partner oversees the firm’s operations and culture.) </p><p>I don’t know if globalism snaps back quickly enough to make room for Shen at the helm of America’s top venture capital firm. Personally, I’d bet on <strong>Roelof Botha</strong>, the firm’s U.S. leader. </p><p>It’s always possible Sequoia tries to split the role or that Shen could stick around under Botha’s leadership. Botha scored only two spots behind Shen on the <a href="https://www.forbes.com/midas/list/">Midas list</a> this year. It wouldn’t exactly be an insult if Botha were put in charge. (Botha’s politics aren’t as publicly accessible. Recently <a href="https://twitter.com/roelofbotha/status/1316578275360083969?s=20">on Twitter</a> he accused the New York Times of building “an echo chamber catering to the previously held beliefs of its existing audience” as he <a href="https://theintercept.com/2020/10/11/the-new-york-times-guild-once-again-demands-censorship-for-colleagues/">shared an article</a> about the newspaper’s union demanding “sensitivity readers.” Botha also recently <a href="https://twitter.com/roelofbotha/status/1316588807538405379?s=20">defended his family’s role in</a> South Africa as overseeing a “peaceful transition to democracy rule.”)</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F20ae63fd-fe97-4573-91e4-92bf785746cb_4381x3289.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F20ae63fd-fe97-4573-91e4-92bf785746cb_4381x3289.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/20ae63fd-fe97-4573-91e4-92bf785746cb_4381x3289.jpeg&quot;,&quot;height&quot;:1093,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2110640,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><strong>It’s not just the China issue where the firm’s politics matter. </strong>A Trumpian worldview inhibits the firm’s capacity to recruit women and minority investors. There’s an old guard of venture partners (and my sense is this includes Leone) that believe in a sort of fatalistic meritocracy, where the best talent rises to the top. A younger guard of founders have stopped believing the system works so organically. Sequoia doesn’t have any Black partners and its senior ranks are dominated by men. That puts a lot of unfair pressure on partners like <strong>Jess Lee</strong> to succeed. I’ve heard the firm is making attempts at recruiting a Black investor, which is long overdue. Given that Sequoia is the top venture firm in the world, it should be ahead, not behind on this issue.</p><p>Sequoia’s spokeswoman declined to comment.</p><h2><em><strong>What could Silicon Valley’s politics look like in a Biden presidency?</strong></em></h2><p>I see two possible paths. </p><p><strong>On the one hand</strong>, there’s a strong desire among a subsection of Silicon Valley to go back to business as usual. “What troubles me the most is the increased polarization of U.S. society,” Botha tweeted earlier this month. “There seems to be scant willingness or tolerance – on either side – for joint engagement to address our problems. How do we transcend this disunity so we can work together to build a better future?”</p><p>There are a lot of rich white men who are exhausted by what they might call “woke politics.” You can hear it on Clubhouse. They’d love to get back to building apps without everything having a political lens. And they’d like to return to a world where political ideologies are shrugged off as personal preferences, rather than some sort of Scarlet Letter. </p><p><strong>On the other hand</strong>, I think there’s a world in which people who supported Trump when he was in power look far worse once he’s out of power. Right now, everyone who depends on powerful people, including the media, has an incentive to treat the President like a valid political actor. Leone’s Trump support right now can be positioned as savvy, rather than deplorable. But should Trump leave office, suddenly, the power the president held goes away. Everyone felt much freer to admit that the Iraq War was a disaster once George W. Bush was a lame duck president. If Biden wins big in an election where college educated voters are largely aligned, I think the billionaire Silicon Valley Republican holdouts could look more contemptible than they already do. I’m told Leone is a nice guy and I believe it. But politics isn’t basketball. The election has consequences, and it matters who the most powerful person at the most powerful venture capital firm is rooting for.</p><p><strong>I do also wonder what a post-Trump era (should we be so lucky) looks like in policy and PR shops around Silicon Valley. </strong>There’s a reason that former Romney and McCain operatives have done so well in tech. Democrats don’t think they were trying to destroy the country. But it’s not as if Silicon Valley drew a line in the sand on the Bush years. <strong>Joel Kaplan</strong>, an operative in the Bush administration and during the <a href="https://www.nytimes.com/2006/04/25/washington/limelight-finds-new-white-house-deputy.html">Florida recount effort</a>, is one of the most influential executives at Facebook.</p><p>While plenty of liberal-minded firms and companies will wrestle with the lines of acceptability, some firms are more insulated from criticism than others. <strong>Keith Rabois</strong> may be insufferable on Twitter, but if you’re a fintech company and he wants to invest, it’s harder to say no. And Founders Fund has already cornered the market on, to put it nicely, unconventional thinkers. Sequoia is fundamentally dependent on its firm-wide brand in a way that I think some younger firms are not. </p><p>I don’t think there’s any one partner at Sequoia outside of Shen who feels as vital to a particular sector. The firm is having a lot of success and they’re all excellent at what they do, for sure, but a lot of the credit flows up to the brand the firm has built over decades. “Sequoia is powerful because when they invest in a company,” one unicorn founder said, “suddenly that new company gets all that brand pixie dust.” In a Silicon Valley where employees protest their bosses, will the next generation of founders still see Sequoia the same way if it seems stuck in the past? </p><p>I hope not.</p></div></div>]]>
            </description>
            <link>https://www.newcomer.co/p/sequoias-political-paradox</link>
            <guid isPermaLink="false">hacker-news-small-sites-24922957</guid>
            <pubDate>Wed, 28 Oct 2020 19:16:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paul Graham Essays Categorized by Theme]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24922675">thread link</a>) | @k00b
<br/>
October 28, 2020 | https://loganfrederick.com/2019/12/25/paul-graham-essays-categorized-by-topic/ | <a href="https://web.archive.org/web/*/https://loganfrederick.com/2019/12/25/paul-graham-essays-categorized-by-topic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-747">
	<!-- .entry-header -->

	<div>
		<p>Since I live in a different town from my family, the holidays are the majority of the time I get to spend with my twelve year-old brother (we have a 17 year age gap).</p>
<p>Now that he’s nearly a teenager, he’s almost the age I was when I started thinking independently from family and friends. For me, a big part of that was discovering Paul Graham’s essays. Hopefully one day my brother reads through them (but I won’t force him).</p>
<p>This got me thinking: if I were to recommend them to him, would I want him to read them chronologically? Or should I point him to specific essays based on his interests?</p>
<p>Alternatively, if one were to compile all of Paul’s essays into a collection or a <i>Hackers and Painters</i> sequel, how would it be organized?</p>
<p>So below is my attempt at tagging Paul Graham’s essays by subject matter.</p>

<h2>Startups – General Lessons:</h2>
<ul>
<li><a href="http://paulgraham.com/aord.html"><span>Default Alive or Default Dead?</span></a></li>
<li><a href="http://paulgraham.com/name.html"><span>Change Your Name</span></a></li>
<li><a href="http://paulgraham.com/altair.html"><span>What Microsoft Is this the Altair Basic of?</span></a></li>
<li><a href="http://paulgraham.com/pinch.html"><span>The Fatal Pinch</span></a></li>
<li><a href="http://paulgraham.com/before.html"><span>Before the Startup</span></a></li>
<li><a href="http://paulgraham.com/ds.html"><span>Do Things that Don’t Scale</span></a></li>
<li><a href="http://paulgraham.com/growth.html"><span>Startup = Growth</span></a></li>
<li><a href="http://paulgraham.com/swan.html"><span>Black Swan Farming</span></a></li>
<li><a href="http://paulgraham.com/really.html"><span>What Startups Are Really Like</span></a></li>
<li><a href="http://paulgraham.com/kate.html"><span>What Kate Saw in Silicon Valley </span></a></li>
<li><a href="http://paulgraham.com/ramenprofitable.html"><span>Ramen Profitable</span></a></li>
<li><a href="http://paulgraham.com/13sentences.html"><span>Startups in 13 Sentences</span></a></li>
<li><a href="http://paulgraham.com/artistsship.html"><span>The Other Half of “Artists Ship” </span></a></li>
<li><a href="http://paulgraham.com/badeconomy.html"><span>Why to Start a Startup in a Bad Economy</span></a></li>
<li><a href="http://paulgraham.com/ycombinator.html"><span>A New Venture Animal</span></a></li>
<li><a href="http://paulgraham.com/newthings.html"><span>Six Principles for Making New Things</span></a></li>
<li><a href="http://paulgraham.com/webstartups.html"><span>The Future of Web Startups</span></a></li>
<li><a href="http://paulgraham.com/die.html"><span>How Not to Die</span></a></li>
<li><a href="http://paulgraham.com/startupmistakes.html"><span>The 18 Mistakes That Kill Startups</span></a></li>
<li><a href="http://paulgraham.com/mit.html"><span>A Student’s Guide to Startups</span></a></li>
<li><a href="http://paulgraham.com/marginal.html"><span>The Power of the Marginal</span></a></li>
<li><span><a href="http://paulgraham.com/startuplessons.html">The Hardest Lessons for Startups to Learn</a></span></li>
<li><a href="http://paulgraham.com/start.html">How to Start a Startup</a></li>
</ul>
<h2>Startups – On Location:</h2>
<ul>
<li><a href="http://paulgraham.com/seesv.html"><span>Where to See Silicon Valley</span></a></li>
<li><a href="http://paulgraham.com/pgh.html"><span>How to Make Pittsburgh a Startup Hub</span></a></li>
<li><a href="http://paulgraham.com/hubs.html"><span>Why Startup Hubs Work</span></a></li>
<li><a href="http://paulgraham.com/revolution.html"><span>A Local Revolution?</span></a></li>
<li><a href="http://paulgraham.com/maybe.html"><span>Can You Buy a Silicon Valley? Maybe.</span></a></li>
<li><a href="http://paulgraham.com/cities.html"><span>Cities and Ambition</span></a></li>
<li><a href="http://paulgraham.com/startuphubs.html"><span>Why to Move to a Startup Hub</span></a></li>
<li><a href="http://paulgraham.com/america.html"><span>Why Startups Condense in America</span></a></li>
<li><a href="http://paulgraham.com/siliconvalley.html"><span>How to Be Silicon Valley</span></a></li>
</ul>
<h2>Startups – On Ideas:</h2>
<ul>
<li><a href="http://paulgraham.com/fp.html"><span>Fashionable Problems</span></a></li>
<li><a href="http://paulgraham.com/startupideas.html"><span>How to Get Startup Ideas</span></a></li>
<li><a href="http://paulgraham.com/ambitious.html"><span>Frighteningly Ambitious Startup Ideas</span></a></li>
<li><a href="http://paulgraham.com/hw.html"><span>The Hardware Renaissance</span></a></li>
<li><span><a href="http://paulgraham.com/organic.html">Organic Startup Ideas</a></span></li>
<li><a href="http://paulgraham.com/ideas.html">Ideas for Startups</a></li>
</ul>
<h2>Startups – For Founders:</h2>
<ul>
<li><a href="http://paulgraham.com/safe.html"><span>Why It’s Safe for Founders to Be Nice</span></a></li>
<li><a href="http://paulgraham.com/mean.html"><span>Mean People Fail</span></a></li>
<li><a href="http://paulgraham.com/word.html"><span>A Word to the Resourceful</span></a></li>
<li><a href="http://paulgraham.com/schlep.html"><span>Schlep Blindness</span></a></li>
<li><a href="http://paulgraham.com/founders.html"><span>What We Look for in Founders</span></a></li>
<li><a href="http://paulgraham.com/determination.html"><span>The Anatomy of Determination</span></a></li>
<li><a href="http://paulgraham.com/5founders.html"><span>Five Founders</span></a></li>
<li><a href="http://paulgraham.com/relres.html"><span>Relentlessly Resourceful</span></a></li>
<li><a href="http://paulgraham.com/good.html"><span>Be Good</span></a></li>
<li><span><a href="http://paulgraham.com/notnot.html">Why to Not Not Start a Startup</a></span></li>
<li><a href="http://paulgraham.com/foundersatwork.html">Learning from Founders</a></li>
</ul>
<h2>Startups – On Investors:</h2>
<ul>
<li><a href="http://paulgraham.com/ronco.html"><span>The Ronco Principle</span></a></li>
<li><a href="http://paulgraham.com/corpdev.html"><span>Don’t Talk to Corp Dev</span></a></li>
<li><a href="http://paulgraham.com/fr.html"><span>How to Raise Money</span></a></li>
<li><a href="http://paulgraham.com/herd.html"><span>Investor Herd Dynamics</span></a></li>
<li><a href="http://paulgraham.com/convince.html"><span>How to Convince Investors</span></a></li>
<li><a href="http://paulgraham.com/invtrend.html"><span>Startup Investing Trends</span></a></li>
<li><a href="http://paulgraham.com/airbnb.html"><span>Subject: Airbnb</span></a></li>
<li><a href="http://paulgraham.com/control.html"><span>Founder Control</span></a></li>
<li><a href="http://paulgraham.com/superangels.html"><span>The New Funding Landscape</span></a></li>
<li><a href="http://paulgraham.com/hiresfund.html"><span>High Resolution Fundraising </span></a></li>
<li><a href="http://paulgraham.com/future.html"><span>The Future of Startup Funding </span></a></li>
<li><a href="http://paulgraham.com/angelinvesting.html"><span>How to Be an Angel Investor</span></a></li>
<li><a href="http://paulgraham.com/divergence.html"><span>Could VC be a Casualty of the Recession?</span></a></li>
<li><a href="http://paulgraham.com/fundraising.html"><span>A Fundraising Survival Guide</span></a></li>
<li><a href="http://paulgraham.com/googles.html"><span>Why There Aren’t More Googles</span></a></li>
<li><a href="http://paulgraham.com/equity.html"><span>The Equity Equation</span></a></li>
<li><a href="http://paulgraham.com/guidetoinvestors.html"><span>The Hacker’s Guide to Investors</span></a></li>
<li><a href="http://paulgraham.com/investors.html"><span>How to Present to Investors</span></a></li>
<li><a href="http://paulgraham.com/startupfunding.html"><span>How to Fund a Startup</span></a></li>
<li><span><a href="http://paulgraham.com/vcsqueeze.html">The Venture Capital Squeeze</a></span></li>
<li><a href="http://paulgraham.com/venturecapital.html">A Unified Theory of VC Suckage</a></li>
</ul>
<h2>Philosophy</h2>
<ul>
<li><a href="http://paulgraham.com/sun.html"><span>General and Surprising</span></a></li>
<li><a href="http://paulgraham.com/vb.html"><span>Life is Short</span></a></li>
<li><a href="http://paulgraham.com/work.html"><span>What Doesn’t Seem Like Work?</span></a></li>
<li><a href="http://paulgraham.com/todo.html"><span>The Top of My Todo List</span></a></li>
<li><a href="http://paulgraham.com/prop62.html"><span>This Year We Can End the Death Penalty in California</span></a></li>
<li><a href="http://paulgraham.com/identity.html"><span>Keep Your Identity Small </span></a></li>
<li><a href="http://paulgraham.com/lies.html"><span>Lies We Tell Kids</span></a></li>
<li><a href="http://paulgraham.com/disagree.html"><span>How to Disagree</span></a></li>
<li><a href="http://paulgraham.com/trolls.html"><span>Trolls</span></a></li>
<li><a href="http://paulgraham.com/philosophy.html"><span>How to Do Philosophy</span></a></li>
<li><a href="http://paulgraham.com/stuff.html"><span>Stuff</span></a></li>
<li><a href="http://paulgraham.com/randomness.html"><span>See Randomness</span></a></li>
<li><a href="http://paulgraham.com/love.html"><span>How to Do What You Love</span></a></li>
<li><a href="http://paulgraham.com/bronze.html"><span>Why Smart People Have Bad Ideas</span></a></li>
<li><a href="http://paulgraham.com/gba.html"><span>The Word “Hacker”</span></a></li>
<li><span><a href="http://paulgraham.com/say.html">What You Can’t Say</a></span></li>
<li><a href="http://paulgraham.com/hp.html">Hackers and Painters</a></li>
</ul>
<h2>Wisdom and Knowledge</h2>
<ul>
<li><a href="http://paulgraham.com/nov.html"><span>Novelty and Heresy</span></a></li>
<li><a href="http://paulgraham.com/genius.html"><span>The Bus Ticket Theory of Genius</span></a></li>
<li><a href="http://paulgraham.com/ecw.html"><span>How to Be an Expert in a Changing World</span></a></li>
<li><a href="http://paulgraham.com/know.html"><span>How You Know</span></a></li>
<li><a href="http://paulgraham.com/top.html"><span>The Top Idea in Your Mind </span></a></li>
<li><a href="http://paulgraham.com/selfindulgence.html"><span>How to Lose Time and Money </span></a></li>
<li><a href="http://paulgraham.com/wisdom.html"><span>Is It Worth Being Wise?</span></a></li>
<li><a href="http://paulgraham.com/procrastination.html"><span>Good and Bad Procrastination</span></a></li>
<li><span><a href="http://paulgraham.com/hs.html">What You’ll Wish You’d Known</a></span></li>
<li><a href="http://paulgraham.com/nerds.html">Why Nerds are Unpopular</a></li>
</ul>
<h2>Charisma</h2>
<ul>
<li><span><a href="http://paulgraham.com/pow.html">Charisma / Power</a></span></li>
<li><a href="http://paulgraham.com/charisma.html">It’s Charisma, Stupid</a></li>
</ul>
<h2>Economics</h2>
<ul>
<li><a href="http://paulgraham.com/re.html"><span>The Refragmentation</span></a></li>
<li><a href="http://paulgraham.com/property.html"><span>Defining Property</span></a></li>
<li><a href="http://paulgraham.com/highres.html"><span>The High-Res Society</span></a></li>
<li><a href="http://paulgraham.com/prcmc.html"><span>The Pooled-Risk Company Management Company</span></a></li>
<li><a href="http://paulgraham.com/boss.html"><span>You Weren’t Meant to Have a Boss</span></a></li>
<li><a href="http://paulgraham.com/opensource.html"><span>What Business Can Learn from Open Source</span></a></li>
<li><a href="http://paulgraham.com/hiring.html"><span>Hiring is Obsolete</span></a></li>
<li><span><a href="http://paulgraham.com/bubble.html">What the Bubble Got Right</a></span></li>
<li><a href="http://paulgraham.com/wealth.html">How to Make Wealth</a></li>
</ul>
<h2>Immigration</h2>
<ul>
<li><a href="http://paulgraham.com/95.html"><span>Let the Other 95% of Great Programmers In</span></a></li>
<li><span><a href="http://paulgraham.com/foundervisa.html">The Founder Visa</a></span></li>
<li><a href="http://paulgraham.com/usa.html">Made in USA</a></li>
</ul>
<h2>Inequality</h2>
<ul>
<li><a href="http://paulgraham.com/ineq.html"><span>Economic Inequality</span></a></li>
<li><a href="http://paulgraham.com/unions.html"><span>An Alternative Theory of Unions</span></a></li>
<li><a href="http://paulgraham.com/inequality.html"><span>Inequality and Risk</span></a></li>
<li><span><a href="http://paulgraham.com/gh.html">Great Hackers</a></span></li>
<li><a href="http://paulgraham.com/gap.html">Mind the Gap</a></li>
</ul>
<h2>Patents</h2>
<ul>
<li><a href="http://paulgraham.com/patentpledge.html"><span>The Patent Pledge</span></a></li>
<li><span><a href="http://paulgraham.com/softwarepatents.html">Are Software Patents Evil?</a></span></li>
<li><a href="http://paulgraham.com/6631327.html">6,631,372</a></li>
</ul>
<h2>Credentialism</h2>
<ul>
<li><a href="http://paulgraham.com/lesson.html"><span>The Lesson to Unlearn</span></a></li>
<li><a href="http://paulgraham.com/credentials.html"><span>After Credentials</span></a></li>
<li><a href="http://paulgraham.com/colleges.html"><span>News from the Front</span></a></li>
<li><a href="http://paulgraham.com/judgement.html"><span>Two Kinds of Judgement</span></a></li>
<li><span><a href="http://paulgraham.com/ladder.html">After the Ladder</a></span></li>
<li><a href="http://paulgraham.com/college.html">Undergraduation</a></li>
</ul>
<h2>Math</h2>
<ul>
<li><a href="http://paulgraham.com/bias.html"><span>A Way to Detect Bias</span></a></li>
<li><span><a href="http://paulgraham.com/disc.html">The Risk of Discovery</a></span></li>
<li><a href="http://paulgraham.com/polls.html">Bradley’s Ghost</a></li>
</ul>
<h2>Writing</h2>
<ul>
<li><a href="http://paulgraham.com/talk.html"><span>Write Like You Talk</span></a></li>
<li><a href="http://paulgraham.com/speak.html"><span>Writing and Speaking</span></a></li>
<li><a href="http://paulgraham.com/discover.html"><span>Persuade xor Discover </span></a></li>
<li><a href="http://paulgraham.com/publishing.html"><span>Post-Medium Publishing</span></a></li>
<li><a href="http://paulgraham.com/nthings.html"><span>The List of N Things</span></a></li>
<li><a href="http://paulgraham.com/copy.html"><span>Copy What You Like</span></a></li>
<li><a href="http://paulgraham.com/submarine.html"><span>The Submarine</span></a></li>
<li><a href="http://paulgraham.com/writing44.html"><span>Writing, Briefly</span></a></li>
<li><span><a href="http://paulgraham.com/laundry.html">A Version 1.0</a></span></li>
<li><a href="http://paulgraham.com/essay.html">The Age of the Essay</a></li>
</ul>
<h2>Tech Industry Trends</h2>
<ul>
<li><a href="http://paulgraham.com/tablets.html"><span>Tablets</span></a></li>
<li><a href="http://paulgraham.com/apple.html"><span>Apple’s Mistake</span></a></li>
<li><a href="http://paulgraham.com/segway.html"><span>The Trouble with the Segway</span></a></li>
<li><a href="http://paulgraham.com/twitter.html"><span>Why Twitter is a Big Deal</span></a></li>
<li><a href="http://paulgraham.com/convergence.html"><span>Why TV Lost</span></a></li>
<li><a href="http://paulgraham.com/microsoft.html"><span>Microsoft is Dead</span></a></li>
<li><a href="http://paulgraham.com/web20.html"><span>Web 2.0</span></a></li>
<li><span><a href="http://paulgraham.com/mac.html">Return of the Mac</a></span></li>
<li><a href="http://paulgraham.com/road.html">The Other Road Ahead</a></li>
</ul>
<h2>Computer Programming</h2>
<ul>
<li><a href="http://paulgraham.com/head.html"><span>Holding a Program in One’s Head</span></a></li>
<li><a href="http://paulgraham.com/pypar.html"><span>The Python Paradox</span></a></li>
<li><a href="http://paulgraham.com/iflisp.html"><span>If Lisp is So Great</span></a></li>
<li><a href="http://paulgraham.com/hundred.html"><span>The Hundred-Year Language</span></a></li>
<li><a href="http://paulgraham.com/icad.html"><span>Revenge of the Nerds</span></a></li>
<li><a href="http://paulgraham.com/power.html"><span>Succinctness is Power</span></a></li>
<li><a href="http://paulgraham.com/fix.html"><span>What Languages Fix</span></a></li>
<li><a href="http://paulgraham.com/noop.html"><span>Why Arc Isn’t Especially Object-Oriented</span></a></li>
<li><a href="http://paulgraham.com/diff.html"><span>What Made Lisp Different</span></a></li>
<li><a href="http://paulgraham.com/rootsoflisp.html"><span>The Roots of Lisp</span></a></li>
<li><a href="http://paulgraham.com/langdes.html"><span>Five Questions about Language Design</span></a></li>
<li><a href="http://paulgraham.com/popular.html"><span>Being Popular</span></a></li>
<li><a href="http://paulgraham.com/javacover.html"><span>Java’s Cover</span></a></li>
<li><a href="http://paulgraham.com/avg.html"><span>Beating the Averages</span></a></li>
<li><span><a href="http://paulgraham.com/lwba.html">Lisp for Web-Based Applications</a></span></li>
<li><a href="http://paulgraham.com/progbot.html">Programming Bottom-Up</a></li>
</ul>
<h2>Spam Filtering</h2>
<ul>
<li><a href="http://paulgraham.com/ffb.html"><span>Filters that Fight Back</span></a></li>
<li><span><a href="http://paulgraham.com/better.html">Better Bayesian Filtering</a></span></li>
<li><a href="http://paulgraham.com/spam.html">A Plan for Spam</a></li>
</ul>
<h2>Distractions and Addictions</h2>
<ul>
<li><a href="http://paulgraham.com/addiction.html"><span>The Acceleration of Addictiveness</span></a></li>
<li><a href="http://paulgraham.com/distraction.html"><span>Disconnecting Distraction</span></a></li>
<li><span><a href="http://paulgraham.com/island.html">The Island Test</a></span></li>
<li><a href="http://paulgraham.com/makersschedule.html">Maker’s Schedule, Manager’s Schedule&nbsp;</a></li>
</ul>
<h2>Art and Design</h2>
<ul>
<li><a href="http://paulgraham.com/goodart.html"><span>How Art Can Be Good</span></a></li>
<li><span><a href="http://paulgraham.com/desres.html">Design and Research</a></span></li>
<li><a href="http://paulgraham.com/taste.html">Taste for Makers</a></li>
</ul>
<h2>Y Combinator</h2>
<ul>
<li><span><a href="http://paulgraham.com/whyyc.html">Why YC</a></span></li>
<li><a href="http://paulgraham.com/sfp.html">What I Did this Summer</a></li>
</ul>
<h2>PG’s Life</h2>
<ul>
<li><a href="http://paulgraham.com/kids.html"><span>Having Kids</span></a></li>
<li><a href="http://paulgraham.com/jessica.html"><span>Jessica Livingston</span></a></li>
<li><a href="http://paulgraham.com/vw.html"><span>Snapshot: Viaweb, June 1998</span></a></li>
<li><a href="http://paulgraham.com/yahoo.html"><span>What Happened to Yahoo </span></a></li>
<li><span><a href="http://paulgraham.com/heroes.html">Some Heroes</a></span></li>
<li><a href="http://paulgraham.com/hackernews.html">What I’ve Learned from Hacker News</a></li>
</ul>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

		<!-- .entry-auhtor -->
</article></div>]]>
            </description>
            <link>https://loganfrederick.com/2019/12/25/paul-graham-essays-categorized-by-topic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24922675</guid>
            <pubDate>Wed, 28 Oct 2020 18:53:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nvidia RTX 3070 Review]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24922582">thread link</a>) | @SimonAC
<br/>
October 28, 2020 | https://techplanet.today/post/nvidia-rtx-3070-review | <a href="https://web.archive.org/web/*/https://techplanet.today/post/nvidia-rtx-3070-review">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    
                    <p>Clearly NVIDIA has had issues keeping up with demand for their 3000 series graphics cards. And while they claim that they pushed back the launch of today's RTX 3070 to shore up supply, given that this is positioned as an RTX 2080 Ti killer for 500 bucks US, I doubt anything they've done in the last couple of weeks is going to help. Unless of course, we fire it up on our trusty test bench and it falls way short of expectations.</p>
<p><img src="https://techplanet.today/storage/posts/2020/10/5f99aec1afe00.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99aec1afe00.webp">It looks like as far as NVIDIA's big gaming performance claims go, the RTX 3070 does adjust fine, matching or beating our 2080 Ti Founder's Edition more often than not.<img src="https://techplanet.today/storage/posts/2020/10/5f99aed5afc59.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99aed5afc59.webp"> At least in games that take advantage of it's beefier RT cores, and tensor cores, which are focused on real-time Ray tracing and deep learning workloads respectively.<img src="https://techplanet.today/storage/posts/2020/10/5f99aee2d856b.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99aee2d856b.webp"></p>
<p>There was a time in the past when we might've called NVIDIA's DLSS deep learning upscaling a performance hack and forced their cards to compete with it disabled. <img src="https://techplanet.today/storage/posts/2020/10/5f99af0132b93.webp" alt="NVIDIA RTX 3070 Review" data-src="/storage/posts/2020/10/5f99af0132b93.webp" height="auto">But, there's just no other way to put this. It's gotten really good. <img src="https://techplanet.today/storage/posts/2020/10/5f99af1b9cbb5.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99af1b9cbb5.webp">When we turned all that stuff off, in Wolfenstein: Youngblood though, and forced a more traditional rendering approach, we did observe a small but measurable four to 5% dip in performance. So, it isn't quite a 2080 Ti, but at less than half the price, I don't think anyone's complaining.</p>
<p><img src="https://techplanet.today/storage/posts/2020/10/5f99af303cb7a.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99af303cb7a.webp">Microsoft Flight Simulator, while CPU-bound at virtually any resolution, revealed a curious twist in our story though. The minimum frame rate is lower than the 2080 Ti, but the average is higher, suggesting that while the GPU is fast enough to keep up, there's a memory bandwidth bottleneck in the mix, thanks to the 3070's narrower 256 bit bus. <img src="https://techplanet.today/storage/posts/2020/10/5f99af473da7e.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99af473da7e.webp">It still excels in our parallel Nintendo 64 test but Counter-Strike: Global Offensive sees it fall below the RTX 2080 Ti again.<img src="https://techplanet.today/storage/posts/2020/10/5f99af550f7c4.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99af550f7c4.webp"></p>
<p>Although, we're still talking 450 versus 470 frames per second. So, it's pretty easy to forgive when you look at the bigger picture.</p>
<p>Productivity is another area where NVIDIA's new Ampere architecture GPUs really shine. <img src="https://techplanet.today/storage/posts/2020/10/5f99af6be7eea.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99af6be7eea.webp">Our blender benders on the 3070 went roughly 20 to 30% faster than the 2080 Ti.<img src="https://techplanet.today/storage/posts/2020/10/5f99af7830ed2.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99af7830ed2.webp"> That is a significant improvement, likely down to the sheer number of cooler cores that NVIDIA has packed into this thing, with Samsung's eight nanometer process. <img src="https://techplanet.today/storage/posts/2020/10/5f99af83bd277.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99af83bd277.webp">V-Ray and Redshift show us similar results while OctaneBench shows us once again the difference between having RTX on versus off. <img src="https://techplanet.today/storage/posts/2020/10/5f99af8f33bce.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99af8f33bce.webp">Those RT cores are where this GPU's main advantage comes into play whenever memory bandwidth is an issue. <img src="https://techplanet.today/storage/posts/2020/10/5f99af9ad457a.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99af9ad457a.webp"></p>
<p>Speaking of which, the new SPECviewperf 2020<img src="https://techplanet.today/storage/posts/2020/10/5f99afabd58a6.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99afabd58a6.webp"> shows us that while it's great for rendering, and nearly as good for some other tasks that just need to crunch numbers, a lot of high-end workstation users suffer from the constrained memory bandwidth of consumer cards like this one, and performance of our RTX 3070 fell to as low as 80% of what the last gen RTX 2080 could provide. <img src="https://techplanet.today/storage/posts/2020/10/5f99afb924c74.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99afb924c74.webp"></p>
<p>To be fair to NVIDIA though, that's not what this card is designed to do. It just happens to be a consideration if you're self-employed or working from home and you do need to run these applications during work hours.</p>
<p>If we average all of our results though, we can see that we're hovering right around that magic 100% mark compared to the 2080 Ti, which is extremely impressive. <img src="https://techplanet.today/storage/posts/2020/10/5f99afcff2811.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99afcff2811.webp">Unless the 3070 has an Achilles heel that we haven't found yet. Let's take a closer look then, at our founder's edition card.&nbsp;</p>
<p>It's got the same flow-through cooler design as the RTX 3080, and RTX 3090, but it's super tiny and has the same fan layout as the RTX 20 series, which isn't to say it's light.<img src="https://techplanet.today/storage/posts/2020/10/5f99aff44d33e.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99aff44d33e.webp"> I was surprised at how heavy it is for its size. And I was surprised to see NVIDIA's new radical 12-pin power connector, in the same visually jarring position.</p>
<p>I mean, at least the adapter only requires a single eight pin instead of two.</p>
<p>&nbsp;Interestingly, the grill on the I/O plate is indented a little. <img src="https://techplanet.today/storage/posts/2020/10/5f99b01ecf459.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99b01ecf459.webp">So it bolts directly onto the cooler rather than tabs on the display outputs, making the design feel much sturdier and therefore more likely to survive a drop.</p>
<p>Our card was we're able to ramp to 1.9 to two gigahertz all day long, with its core sitting at RTX 2080 Ti temperatures. <img src="https://techplanet.today/storage/posts/2020/10/5f99b0352813a.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99b0352813a.webp">Which is toastier than our RTX 2070 Super. <img src="https://techplanet.today/storage/posts/2020/10/5f99b03fcf606.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99b03fcf606.webp">But in fairness, the cooler here is significantly smaller which shows just how efficient NVIDIA's pass-through approaches. <img src="https://techplanet.today/storage/posts/2020/10/5f99b04c09108.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99b04c09108.webp">When we look at power consumption<img src="https://techplanet.today/storage/posts/2020/10/5f99b05a934b9.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99b05a934b9.webp"> it was a touch higher over the course of our SPECviewperf run, compared with the RTX 2070 Super, with our peak recorded wattage no higher 253 Watts compared to that card's 224.<img src="https://techplanet.today/storage/posts/2020/10/5f99b06812750.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99b06812750.webp"> This is excellent news because the RTX 3080 guzzled far more power than even the 2080 Ti, and the RTX 3090 sees massive power spikes that can cause mere mortal power supplies to just blink off, thanks to their over current protection.</p>
<p>On that subject, you'll have to forgive me for going back to the previous 3000 series launches again here. But there was yet another power debacle where some powder boards would crash due to a flawed power delivery design. Some brands ended up shipping bad boards all the way to customers. But even ones who didn't like EVGA suffered product delays from not having all the testing and info that they needed in time for launch.</p>
<p>Nobody would go on the record for us blaming NVIDIA for this outright. But as far as we can put together, team green just didn't give their partners enough lead time to flesh out their designs, while they themselves enjoy a massive headstart, putting together revolutionary new coolers for their Ampere cards.</p>
<p>I've given NVIDIA the benefit of the doubt on this so far. But with today's move, it's clear that they are openly and unashamedly competing on an uneven playing field against their own partners.</p>
<p>What have they done today, you might ask? Well look around. Where are all the reviews of non-Founders RTX 3070s, that have normal power connectors on them. Not in any NVIDIA-sanctioned reviews at the embargo lift. Why? Well, because their embargo hasn't lifted yet. It's kind of genius, really. NVIDIA goes and creates a big splash and sells out of their Founder's Edition cards first which they've had longer to perfect. Then their partners rush to launch their competing products with less time to prepare, giving NVIDIA a second wave of review coverage, comparing their product, the GPU itself, with their product, the Founder's Edition card, often quite favorably.</p>
<p>I doubt that anything that I say is going to change NVIDIA's behavior. But, it's a crappy way to treat a partner. And I wanted to make sure that at least they feel bad about it.</p>
<p>On the subject of competition, though, AMD's Radeon announcement is tomorrow, which, again knowing NVIDIA is probably why they carpet-bombed the review cycle. <img src="https://techplanet.today/storage/posts/2020/10/5f99b102e2111.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99b102e2111.webp"></p>
<p>So today, from numbers alone. It was always gonna be easy to recommend the RTX 3070 to anyone in this price range. <img src="https://techplanet.today/storage/posts/2020/10/5f99b1196a0ca.webp" alt="NVIDIA RTX 3070 Review" width="854" height="auto" data-src="/storage/posts/2020/10/5f99b1196a0ca.webp"> The good news, for the entire industry though, is that NVIDIA's supply woes could be AMD's big chance to make a splash with the unveiling of their new Radeon 6000 series. We still don't know for sure what that's gonna look like. But what we do know is that between it, 3070's compelling value, and the potential for deals on last gen cards come Black Friday, it is going to be a good season to buy a gaming rig.</p>
<p><iframe src="https://techplanet.today/storage/settings/April2020/08rLYcVZG5uspJE5KPCf.jpg" width="560" height="314" allowfullscreen="allowfullscreen" data-src="https://www.youtube.com/embed/3XaOeLPztN4" loading="lazy"></iframe></p>
                    
                </article></div>]]>
            </description>
            <link>https://techplanet.today/post/nvidia-rtx-3070-review</link>
            <guid isPermaLink="false">hacker-news-small-sites-24922582</guid>
            <pubDate>Wed, 28 Oct 2020 18:45:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Memory is Ever Alone is a visual conversation between my dad and I]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24922545">thread link</a>) | @giuliomagnifico
<br/>
October 28, 2020 | http://www.catherinepanebianco.com/no-memory-is-ever-alone-1/ | <a href="https://web.archive.org/web/*/http://www.catherinepanebianco.com/no-memory-is-ever-alone-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-yui_3_17_2_1_1595809154702_3915"><div><h2>NO MEMORY IS EVER ALONE</h2><p><em>No Memory is Ever Alone</em> is a visual conversation between my dad and I. He used to bring out a box of slides that he photographed in his late teens and early 20s every Christmas and made us view them on an old projector on our living room wall telling the same stories every year. It was a consistent memory from a childhood where we moved a lot and I never felt like I had a steady “place” to live and create memories.&nbsp; </p><p>I realized that by placing the slides in my current landscape, I created not only a connection between his life and mine, but a trail of memories, each that had its own association for both of us. A lot of these slides are of my mom, they were together almost 60 years. She passed away recently and I feel like her spirit, and all the spirits of the past, are around us. These little vignettes of family life in my current “space” comforts me that she and others are still near, watching over me. They create a “home” for me wherever I go.</p><p>I did not want to Photoshop that connection. Part of the process that was necessary for me was to find the right location and feel my dad’s slides united with how I live today – a place within a place, a memory within a memory.</p></div></div></div>]]>
            </description>
            <link>http://www.catherinepanebianco.com/no-memory-is-ever-alone-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24922545</guid>
            <pubDate>Wed, 28 Oct 2020 18:43:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You Won't Advance Through Coding]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24922474">thread link</a>) | @lupin3ken
<br/>
October 28, 2020 | https://tylerboright.com/nocodepromotion | <a href="https://web.archive.org/web/*/https://tylerboright.com/nocodepromotion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <h2>You Won't Advance Through Coding</h2>
    <small>2020-10-26</small>
    <p>I used to work myself to death.  Not resting, I would try to complete as many tasks as possible each day.  Organized todo lists, itemized jira boards, and productivity hacks littered my second monitor as I did my best to cram as much work into each day as possible.  By the end of the day, I felt exhausted. I thought this was a sign I had a productive day.</p>
    <p>Much to my surprise, I was passed over for promotion.  When asking my manager for feedback, I was told I did a good job and didn't have much to pick at.  I felt I was a top performer.  I mean, hell, I was busting my ass every day to do as much work as possible. I had a stellar performance review.  What was the problem?</p> 
    <p>After this happened a couple of times, I saw others around me promoted on a faster time line and obtain more benefits. Most of them were doing good work as well, but it didn't seem that they were doing more than I was.  Some of them didn't do much work at all.</p>
    <p>I inappropriately attributed my lack of success with company values.  I left that company and moved to one I thought would value my technical expertise and solid work ethic.</p>
    <p>I encountered the same situation at this new company.  It was here that I figured out something was wrong with me.</p>
    <p>I misunderstood what companies value in general, not a particular company's values. Things engineers value in well-written code are almost irrelevant to the actual corporation.  What is valuable to a corporation is creating software that fulfills the customers' needs at a profit.</p>
    <h3>Solve the business problem</h3>
    <p>The ultimate question every business entity cares about is: "does this piece of software solve our problem within the budget afforded it."  Everything else is a non-issue.</p>
    <p>This is the reason there are so many bank systems written in Fortran and older programming languages.  This is also the reason that the co-worker who can't program themselves out of a paper bag can still find a way to remain in the company.</p>
    <p>TDD, language choice, and other hot programmer topics are a complete non-issue to the business side unless they interfere with meeting budget or hurt the business's value proposition.</p>
    <p>Technical chops are secondary to reliability and willingness to work for the salary given.</p>
    <p>Crafting quality software is important to your immediate development team.  But don't expect your VP or CEO (i.e. your actual clients) to applaud you on having built a system with in the hottest framework out there.</p>
    <h3>There is no Meritocracy</h3>
    <p>Corporations do not promote people based on how skilled they are in their craft.  For developer jobs at large corporations, it's nearly impossible to track how valuable a particular developer is.</p>
    <p>Negative work, managing expectations of stakeholders, and whether or not the developer writes good unit tests can affect the influence a developer has over a codebase.  But most of the ways a single developer influences the product are not quantifiable.</p>
    <p>I used to believe that as long as I became the best software developer possible, my advancement would be inevitable.</p>
    <p>When I finally was promoted, it had nothing to do with my technical skills.  It wasn't until I had a long enough tenure at the company to justify being promoted and was <b>put in charge of a project that allowed me to delegate some work to other developers</b> that I finally obtained the coveted senior position I gunned for.</p>
    <p>The combination of time in company and programming away from the keyboard resulted in my promotion.  In fact, during the promotion process, not one time did anyone mentioned how great my code was or how awesome I was at unit testing.  It sucked!</p>
    <h3>Program for yourself</h3>
    <p>Your coding skills are for you alone to enjoy.  Yes, you might work for teams in small enough companies that your actual skill will be more applicable.  On a small team, dead weight and negative work are compounded enough to show if someone isn't pulling their weight.</p>
    <p>Most of the time this will not be the case.  Forge your technical skills to earn implementaton self-confidence.  Solve your own problems.  Scratch that itch.</p>
    <p>There is a giant upside to having solid technical skills.  Although promotions are not determined by coding, if you want to stay in a technically-oriented track and hop between projects or teams, having awesome technical skills will make your life a lot easier.</p>
    <p>Imagine you are put on a team building an application in a language you have never used before.  Regardless of your time in the industry, if you have spent your career painstakingly acquiring deep technical knowledge, learning the new language will be MUCH easier.  It chould prove to be the difference between a couple weeks of learning versus a couple of months.</p>
    <p>Whether you found a job in software because you love to code or learned to code because you wanted a job in software, having solid technical skills will help you wade through bullshit and feel more confident in a particular role. Just remember that they probably won't rocket you up into the C-suite.</p>
</section></div>]]>
            </description>
            <link>https://tylerboright.com/nocodepromotion</link>
            <guid isPermaLink="false">hacker-news-small-sites-24922474</guid>
            <pubDate>Wed, 28 Oct 2020 18:36:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porsche Classifier – Identify Porsche models with 95% accuracy]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24922472">thread link</a>) | @archa
<br/>
October 28, 2020 | https://www.rkpblog.tech/2020/04/porsche-classifier/ | <a href="https://web.archive.org/web/*/https://www.rkpblog.tech/2020/04/porsche-classifier/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				

<h2 id="porsche-classifier-https-porsche-classifier-azurewebsites-net"><a href="https://porsche-classifier.azurewebsites.net/">Porsche Classifier</a></h2>



<p><img src="https://d33wubrfki0l68.cloudfront.net/675336d96deabd0007621a71180bcfb57edb6b11/805fd/images/2020-04-04-porsche_classifier/718.jpg" alt="porsche-718"></p>

<p>Trained using <a href="https://fast.ai/">fastai-v3</a>, <a href="https://pytorch.org/">pytorch</a> and <a href="https://gradient.paperspace.com/">Gradient</a>.
Uses <a href="https://www.mathworks.com/help/deeplearning/ref/resnet50.html">resnet50</a> and trained on a <a href="https://images.nvidia.com/content/pdf/quadro/data-sheets/192195-DS-NV-Quadro-P5000-US-12Sept-NV-FNL-WEB.pdf">Nvidia Quadro P5000</a>.
Built on <a href="https://www.docker.com/">docker</a> and is hosted on <a href="https://azure.microsoft.com/en-in/services/app-service/web/">Microsoft Azure Web Services</a>.
Trained on a dataset of publicly sourced images containing 30000 Porsche car models of varying degree of quality.
Porsche cars, specially the latest generations of the Panamera/Taycan, Macan/Cayenne &amp; 911 / 718 can be pretty tricky to tell apart for a layman who isn’t paying very close attention, which is why I wanted to test out what kind of features this deep learning model would pick up.</p>

<h3 id="creating-your-own-dataset-from-google-images">Creating your own dataset from Google Images</h3>

<p>In this tutorial we will see how to easily create an image dataset through Google Images. Note: You will have to repeat these steps for any new category you want to Google (e.g once for dogs and once for cats).</p>
<div><pre>```python
from fastai.vision import *
```</pre></div>
<h4 id="get-a-list-of-urls">Get a list of URLs</h4>

<h5 id="search-and-scroll">Search and scroll</h5>

<p>Go to Google Images and search for the images you are interested in. The more specific you are in your Google Search, the better the results and the less manual pruning you will have to do.</p>

<p>Scroll down until you’ve seen all the images you want to download, or until you see a button that says ‘Show more results’. All the images you scrolled past are now available to download. To get more, click on the button, and continue scrolling. The maximum number of images Google Images shows is 700.</p>

<p>It is a good idea to put things you want to exclude into the search query, for instance if you are searching for the Eurasian wolf, “canis lupus lupus”, it might be a good idea to exclude other variants:</p>

<p>“canis lupus lupus” -dog -arctos -familiaris -baileyi -occidentalis</p>

<p>You can also limit your results to show only photos by clicking on Tools and selecting Photos from the Type dropdown.</p>

<h3 id="download-into-file">Download into file</h3>

<p>Now you must run some Javascript code in your browser which will save the URLs of all the images you want for you dataset.</p>

<p>In Google Chrome press CtrlShiftj on Windows/Linux and CmdOptj on macOS, and a small window the javascript ‘Console’ will appear. In Firefox press CtrlShiftk on Windows/Linux or CmdOptk on macOS. That is where you will paste the JavaScript commands.</p>

<p>You will need to get the urls of each of the images. Before running the following commands, you may want to disable ad blocking extensions (uBlock, AdBlockPlus etc.) in Chrome. Otherwise the window.open() command doesn’t work. Then you can run the following commands:</p>
<div><pre><code data-lang="python">urls<span>=</span>Array<span>.</span>from(document<span>.</span>querySelectorAll(<span>'.rg_i'</span>))<span>.</span><span>map</span>(el<span>=&gt;</span> el<span>.</span>hasAttribute(<span>'data-src'</span>)?el<span>.</span>getAttribute(<span>'data-src'</span>):el<span>.</span>getAttribute(<span>'data-iurl'</span>));
window<span>.</span><span>open</span>(<span>'data:text/csv;charset=utf-8,'</span> <span>+</span> escape(urls<span>.</span>join(<span>'</span><span>\n</span><span>'</span>)));</code></pre></div>
<h3 id="create-directory-and-upload-urls-file-into-your-server">Create directory and upload urls file into your server</h3>

<p>Choose an appropriate name for your labeled images. You can run these steps multiple times to create different labels.</p>
<div><pre><code data-lang="python">    In [<span>0</span>]:
    folder <span>=</span> <span>'718'</span>
    <span>file</span> <span>=</span> <span>'718.csv'</span>
    In [<span>0</span>]:
    folder <span>=</span> <span>'911'</span>
    <span>file</span> <span>=</span> <span>'911.csv'</span>
    In [<span>0</span>]:
    folder <span>=</span> <span>'cayenne'</span>
    <span>file</span> <span>=</span> <span>'cayenne.csv'</span>
    In [<span>0</span>]:
    folder <span>=</span> <span>'macan'</span>
    <span>file</span> <span>=</span> <span>'macan.csv'</span>
    In [<span>0</span>]:
    folder <span>=</span> <span>'taycan'</span>
    <span>file</span> <span>=</span> <span>'taycan.csv'</span>
    In [<span>0</span>]:
    folder <span>=</span> <span>'panamera'</span>
    <span>file</span> <span>=</span> <span>'panamera.csv'</span></code></pre></div>
<p>You will need to run this cell once per each category.</p>
<div><pre><code data-lang="python">    In [<span>0</span>]:
    path <span>=</span> Path(<span>'data/porsche'</span>)
    dest <span>=</span> path<span>/</span>folder
    dest<span>.</span>mkdir(parents<span>=</span><span>True</span>, exist_ok<span>=</span><span>True</span>)
    In [<span>0</span>]:
    path<span>.</span>ls()
    Out[<span>0</span>]:
    [PosixPath(<span>'data/porsche/cayenne'</span>),
     PosixPath(<span>'data/porsche/panamera.csv'</span>),
     PosixPath(<span>'data/porsche/cayenne.csv'</span>),
     PosixPath(<span>'data/porsche/panamera'</span>),
     PosixPath(<span>'data/porsche/taycan'</span>),
     PosixPath(<span>'data/porsche/911.csv'</span>),
     PosixPath(<span>'data/porsche/taycan.csv'</span>),
     PosixPath(<span>'data/porsche/911'</span>),
     PosixPath(<span>'data/porsche/macan.csv'</span>),
     PosixPath(<span>'data/porsche/718'</span>),
     PosixPath(<span>'data/porsche/718.csv'</span>),
     PosixPath(<span>'data/porsche/macan'</span>)]</code></pre></div>
<p>Finally, upload your urls file. You just need to press ‘Upload’ in your working directory and select your file, then click ‘Upload’ for each of the displayed files.</p>

<p><code>uploaded file</code></p>

<h3 id="download-images">Download images</h3>

<p>Now you will need to download your images from their respective urls.</p>

<p>fast.ai has a function that allows you to do just that. You just have to specify the urls filename as well as the destination folder and this function will download and save all images that can be opened. If they have some problem in being opened, they will not be saved.</p>

<p>Let’s download our images! Notice you can choose a maximum number of images to be downloaded. In this case we will not download all the urls.</p>

<p>You will need to run this line once for every category.</p>
<div><pre><code data-lang="python">In [<span>0</span>]:
classes <span>=</span> [<span>'taycan'</span>,<span>'panamera'</span>,<span>'macan'</span>,<span>'cayenne'</span>,<span>'718'</span>,<span>'911'</span>]
In [<span>0</span>]:
download_images(path<span>/</span><span>file</span>, dest, max_pics<span>=</span><span>500</span>)

    In [<span>0</span>]:
    <span># If you have problems download, try with `max_workers=0` to see exceptions:</span>
    download_images(path<span>/</span><span>file</span>, dest, max_pics<span>=</span><span>20</span>, max_workers<span>=</span><span>0</span>)
    <span>``</span>`

Then we can remove <span>any</span> images that can<span>'t be opened:</span>
<span>`python In [0]: for c in classes: print(c) verify_images(path/c, delete=True, max_size=500) taycan panamera macan cayenne 718 911`</span>

<span>### View data</span>

<span>    ```python</span>
<span>    In [0]:</span>
<span>    np.random.seed(42)</span>
<span>    data = ImageDataBunch.from_folder(path, train=".", valid_pct=0.2,</span>
<span>            ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)</span>

<span>    In [0]:</span>
<span>    #If you already cleaned your data, run this cell instead of the one before</span>
<span>     np.random.seed(42)</span>
<span>     data = ImageDataBunch.from_csv(path, folder=".", valid_pct=0.2, csv_labels='</span>cleaned<span>.</span>csv<span>',</span>
<span>             ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)</span>
<span>    ```</span>

<span>Good! Let'</span>s take a look at some of our pictures then<span>.</span>
<span>``</span>`python
In [<span>0</span>]:
data<span>.</span>classes
Out[<span>0</span>]:
[<span>'718'</span>, <span>'911'</span>, <span>'cayenne'</span>, <span>'macan'</span>, <span>'panamera'</span>, <span>'taycan'</span>]
In [<span>0</span>]:
data<span>.</span>show_batch(rows<span>=</span><span>6</span>, figsize<span>=</span>(<span>7</span>,<span>8</span>))
In [<span>0</span>]:
data<span>.</span>classes, data<span>.</span>c, <span>len</span>(data<span>.</span>train_ds), <span>len</span>(data<span>.</span>valid_ds)
Out[<span>0</span>]:
([<span>'718'</span>, <span>'911'</span>, <span>'cayenne'</span>, <span>'macan'</span>, <span>'panamera'</span>, <span>'taycan'</span>], <span>6</span>, <span>1920</span>, <span>480</span>)</code></pre></div>
<h3 id="train-model">Train model</h3>
<div><pre>```python
In [0]:
learn = cnn_learner(data, models.resnet50, metrics=error_rate)
In [0]:
learn.fit_one_cycle(40)
```</pre></div>
<table>
<thead>
<tr>
<th>epoch</th>
<th>train_loss</th>
<th>valid_loss</th>
<th>error_rate</th>
<th>time</th>
</tr>
</thead>

<tbody>
<tr>
<td>0</td>
<td>2.608914</td>
<td>1.610778</td>
<td>0.606250</td>
<td>00:09</td>
</tr>

<tr>
<td>1</td>
<td>2.229989</td>
<td>1.467350</td>
<td>0.531250</td>
<td>00:09</td>
</tr>

<tr>
<td>2</td>
<td>1.992984</td>
<td>1.457949</td>
<td>0.495833</td>
<td>00:10</td>
</tr>

<tr>
<td>3</td>
<td>1.800289</td>
<td>1.435493</td>
<td>0.481250</td>
<td>00:09</td>
</tr>

<tr>
<td>4</td>
<td>1.639752</td>
<td>1.454458</td>
<td>0.479167</td>
<td>00:09</td>
</tr>

<tr>
<td>5</td>
<td>1.502409</td>
<td>1.400133</td>
<td>0.464583</td>
<td>00:09</td>
</tr>

<tr>
<td>6</td>
<td>1.371669</td>
<td>1.300878</td>
<td>0.450000</td>
<td>00:10</td>
</tr>

<tr>
<td>7</td>
<td>1.258696</td>
<td>1.236995</td>
<td>0.418750</td>
<td>00:09</td>
</tr>

<tr>
<td>8</td>
<td>1.138708</td>
<td>1.241532</td>
<td>0.418750</td>
<td>00:09</td>
</tr>

<tr>
<td>9</td>
<td>1.043424</td>
<td>1.175137</td>
<td>0.406250</td>
<td>00:10</td>
</tr>

<tr>
<td>10</td>
<td>0.984921</td>
<td>1.146469</td>
<td>0.385417</td>
<td>00:10</td>
</tr>

<tr>
<td>11</td>
<td>0.927935</td>
<td>1.169490</td>
<td>0.379167</td>
<td>00:10</td>
</tr>

<tr>
<td>12</td>
<td>0.876125</td>
<td>1.170498</td>
<td>0.391667</td>
<td>00:10</td>
</tr>

<tr>
<td>13</td>
<td>0.825623</td>
<td>1.195051</td>
<td>0.375000</td>
<td>00:10</td>
</tr>

<tr>
<td>14</td>
<td>0.765536</td>
<td>1.155461</td>
<td>0.364583</td>
<td>00:10</td>
</tr>

<tr>
<td>15</td>
<td>0.727942</td>
<td>1.145015</td>
<td>0.381250</td>
<td>00:10</td>
</tr>

<tr>
<td>16</td>
<td>0.688683</td>
<td>1.260339</td>
<td>0.387500</td>
<td>00:10</td>
</tr>

<tr>
<td>17</td>
<td>0.637377</td>
<td>1.175742</td>
<td>0.366667</td>
<td>00:10</td>
</tr>

<tr>
<td>18</td>
<td>0.608817</td>
<td>1.228916</td>
<td>0.385417</td>
<td>00:10</td>
</tr>

<tr>
<td>19</td>
<td>0.572675</td>
<td>1.248361</td>
<td>0.379167</td>
<td>00:09</td>
</tr>

<tr>
<td>20</td>
<td>0.555676</td>
<td>1.256141</td>
<td>0.364583</td>
<td>00:10</td>
</tr>

<tr>
<td>21</td>
<td>0.511557</td>
<td>1.273524</td>
<td>0.375000</td>
<td>00:10</td>
</tr>

<tr>
<td>22</td>
<td>0.483267</td>
<td>1.251337</td>
<td>0.362500</td>
<td>00:10</td>
</tr>

<tr>
<td>23</td>
<td>0.436271</td>
<td>1.288411</td>
<td>0.354167</td>
<td>00:10</td>
</tr>

<tr>
<td>24</td>
<td>0.415738</td>
<td>1.234846</td>
<td>0.364583</td>
<td>00:10</td>
</tr>

<tr>
<td>25</td>
<td>0.397631</td>
<td>1.279648</td>
<td>0.354167</td>
<td>00:10</td>
</tr>

<tr>
<td>26</td>
<td>0.377773</td>
<td>1.224547</td>
<td>0.347917</td>
<td>00:10</td>
</tr>

<tr>
<td>27</td>
<td>0.352112</td>
<td>1.226564</td>
<td>0.339583</td>
<td>00:09</td>
</tr>

<tr>
<td>28</td>
<td>0.338672</td>
<td>1.195467</td>
<td>0.341667</td>
<td>00:10</td>
</tr>

<tr>
<td>29</td>
<td>0.328226</td>
<td>1.212193</td>
<td>0.347917</td>
<td>00:10</td>
</tr>

<tr>
<td>30</td>
<td>0.296725</td>
<td>1.213175</td>
<td>0.339583</td>
<td>00:10</td>
</tr>

<tr>
<td>31</td>
<td>0.290399</td>
<td>1.222019</td>
<td>0.327083</td>
<td>00:10</td>
</tr>

<tr>
<td>32</td>
<td>0.263940</td>
<td>1.222777</td>
<td>0.327083</td>
<td>00:10</td>
</tr>

<tr>
<td>33</td>
<td>0.258763</td>
<td>1.207108</td>
<td>0.322917</td>
<td>00:10</td>
</tr>

<tr>
<td>34</td>
<td>0.253563</td>
<td>1.217487</td>
<td>0.329167</td>
<td>00:10</td>
</tr>

<tr>
<td>35</td>
<td>0.236343</td>
<td>1.217709</td>
<td>0.322917</td>
<td>00:10</td>
</tr>

<tr>
<td>36</td>
<td>0.221070</td>
<td>1.228969</td>
<td>0.325000</td>
<td>00:10</td>
</tr>

<tr>
<td>37</td>
<td>0.230405</td>
<td>1.240643</td>
<td>0.327083</td>
<td>00:10</td>
</tr>

<tr>
<td>38</td>
<td>0.217511</td>
<td>1.230480</td>
<td>0.318750</td>
<td>00:10</td>
</tr>

<tr>
<td>39</td>
<td>0.209594</td>
<td>1.243002</td>
<td>0.318750</td>
<td>00:10</td>
</tr>
</tbody>
</table>
<div><pre><code data-lang="python">    In [<span>0</span>]:
    learn<span>.</span>save(<span>'stage-1'</span>)
    In [<span>0</span>]:
    learn<span>.</span>unfreeze()
    In [<span>0</span>]:
    learn<span>.</span>lr_find()
    <span>25.00</span><span>%</span> [<span>1</span><span>/</span><span>4</span> <span>00</span>:<span>12</span><span>&lt;</span><span>00</span>:<span>37</span>]

<span>``</span>`
epoch <span>|</span> train_loss <span>|</span> valid_loss <span>|</span> error_rate <span>|</span> time
<span>-----</span> <span>|</span> <span>----------</span> <span>|</span> <span>----------</span> <span>|</span> <span>----------</span> <span>|</span> <span>----</span>
<span>0</span> <span>|</span> <span>0.196860</span> <span>|</span> <span>#na# | 00:12</span>

<span>83.33</span><span>%</span> [<span>25</span><span>/</span><span>30</span> <span>00</span>:<span>10</span><span>&lt;</span><span>00</span>:<span>02</span> <span>0.6416</span>]
LR Finder <span>is</span> complete, <span>type</span> {learner_name}<span>.</span>recorder<span>.</span>plot() to see the graph<span>.</span>
<span>``</span>`

In [<span>0</span>]:

<span># If the plot is not showing try to give a start and end learning rate</span>

<span># learn.lr_find(start_lr=1e-5, end_lr=1e-1)</span>

learn<span>.</span>recorder<span>.</span>plot()

In [<span>0</span>]:
learn<span>.</span>fit_one_cycle(<span>2</span>, max_lr<span>=</span><span>slice</span>(<span>3e-5</span>,<span>3e-4</span>))
epoch train_loss valid_loss error_rate time
<span>0</span> <span>0.280386</span> <span>1.524914</span> <span>0.372917</span> <span>00</span>:<span>13</span>
<span>1</span> <span>0.276844</span> <span>1.312542</span> <span>0.345833</span> <span>00</span>:<span>13</span>
In [<span>0</span>]:
learn<span>.</span>save(<span>'stage-2'</span>)

<span>``</span>`
<span>### Interpretation</span>
In [<span>0</span>]:
learn<span>.</span>load(<span>'stage-2'</span>);
In [<span>0</span>]:
interp <span>=</span> ClassificationInterpretation<span>.</span>from_learner(learn)
In [<span>0</span>]:
interp<span>.</span>plot_confusion_matrix()

<span>### Cleaning Up</span>
Some of our top losses aren<span>'t due to bad performance by our model. There are images in our data set that shouldn'</span>t be<span>.</span>

Using the ImageCleaner widget <span>from</span> fastai.widgets we can prune our top losses, removing photos that don<span>'t belong.</span>

<span>```</span>

<span>In [0]:</span>
<span>from fastai.widgets import \*</span>

<span>```</span>
<span>First we need to get the file paths from our top_losses. We can do this with .from_toplosses. We then feed the top losses indexes and corresponding dataset to ImageCleaner.</span>

<span>Notice that the widget will not delete images directly from disk but it will create a new csv file cleaned.csv from where you can create a new ImageDataBunch with the corrected labels to continue training your model.</span>
<span>```</span>

<span>In [0]:</span>
<span>db = (ImageList.from_folder(path)</span>
<span>.split_none()</span>
<span>.label_from_folder()</span>
<span>.transform(get_transforms(), size=224)</span>
<span>.databunch()</span>
<span>)</span>
<span>In [0]:</span>

<span># If you already cleaned your data using indexes from `from_toplosses`,</span>

<span># run this cell instead of the one before to proceed with removing duplicates.</span>

<span># Otherwise all the results of the previous step would be overwritten by</span>

<span># the new run of `ImageCleaner`.</span>

<span>db = (ImageList.from_csv(path, '</span>cleaned<span>.</span>csv<span>', folder='</span><span>.</span><span>')</span>
<span>.split_none()</span>
<span>.label_from_df()</span>
<span>.transform(get_transforms(), size=224)</span>
<span>.databunch()</span>
<span>)</span>

<span>```</span>
<span>Then we create a new learner to use our new databunch with all the images.</span>
<span>```</span>

<span>In [0]:</span>
<span>learn_cln = cnn_learner(db, models.resnet50, metrics=error_rate)</span>

<span>learn_cln.load('</span>stage<span>-</span><span>2</span><span>');</span>
<span>In [0]:</span>
<span>ds, idxs = DatasetFormatter().from_toplosses(learn_cln)</span>
<span>In [0]:</span>

<span># Don'</span>t run this <span>in</span> google colab <span>or</span> <span>any</span> other instances running jupyter lab<span>.</span>

<span># If you do run this on Jupyter Lab, you need to restart your runtime and</span>

<span># runtime state including all local variables will be …</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.rkpblog.tech/2020/04/porsche-classifier/">https://www.rkpblog.tech/2020/04/porsche-classifier/</a></em></p>]]>
            </description>
            <link>https://www.rkpblog.tech/2020/04/porsche-classifier/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24922472</guid>
            <pubDate>Wed, 28 Oct 2020 18:36:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anki Decks with Orgmode]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24922428">thread link</a>) | @brewski
<br/>
October 28, 2020 | https://rgoswami.me/posts/anki-decks-orgmode/ | <a href="https://web.archive.org/web/*/https://rgoswami.me/posts/anki-decks-orgmode/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>Setting up unicode math and <code>orgmode</code> for painless Anki deck building</p></blockquote><h2 id="background">Background</h2><p>A recent <a href="https://news.ycombinator.com/item?id=24878171">Hacker News post</a> reminded me of <a href="https://docs.ankiweb.net/#/getting-started">Anki</a>, and that brought back memories of
my Anki <code>orgmode</code> setup. I thought I’d re-create and immortalize it.</p><p>The standard way of working with Anki, is with a pretty awkward GUI. There are
changes to be made here, which make life a little easier, including the setup of
custom cards, but the inherent concerns of the WYSIWYG editor are basically
insurmountable.</p><figure><img src="https://d33wubrfki0l68.cloudfront.net/68485cf6f823570638998b339d289abd560a2ab7/5f026/ox-hugo/2020-10-27_00-13-31_screenshot.png" alt="Figure 1: Anki GUI"><figcaption><p>Figure 1: Anki GUI</p></figcaption></figure><p>The goal is to get this a better workflow than manual editing of Anki decks.
<code>orgmode</code> is perfect for making cards, especially in the larger context of using
it for storing images and rich <code>pdfs</code>.</p><figure><img src="https://d33wubrfki0l68.cloudfront.net/f5af670548a89a7dfd69002c5529aeeda9d101fb/3e4f8/ox-hugo/2020-10-26_23-53-05_screenshot.png" alt="Figure 2: A pleasant way to make anki decks"><figcaption><p>Figure 2: A pleasant way to make anki decks</p></figcaption></figure><h2 id="methodology">Methodology</h2><p>To accomplish this, we basically need to have the following:</p><dl><dt><a href="https://github.com/louietan/anki-editor">anki-editor</a></dt><dd>This <code>emacs</code> plugin will facilitate the conversion from our <code>orgmode</code> files to the Anki markup</dd><dt><a href="https://github.com/FooSoft/anki-connect">anki-connect</a></dt><dd>We need a server of sorts set up to allow us to push pull and get errors from the running Anki server, this is an Anki plugin</dd><dt><a href="https://ankiweb.net/shared/info/937148547">LaTeX process editor</a></dt><dd>It wouldn’t be much better than manually making cards in Anki if we couldn’t leverage <code>unicode</code> characters, so we need to modify the internal Anki build process for TeX</dd></dl><h3 id="anki-editor">Anki Editor</h3><p>As with all <code>emacs</code> related setup snippets on this site, these should be modified and adapted as needed, especially for those not using <a href="https://github.com/hlissner/doom-emacs/">doom-emacs</a>.</p><div><pre><code data-lang="emacs-lisp"><span>(</span><span>use-package</span> <span>anki-editor</span>
  <span>:after</span> <span>org-noter</span>
  <span>:config</span>
  <span>; I like making decks</span>
  <span>(</span><span>setq</span> <span>anki-editor-create-decks</span> <span>'t</span><span>))</span>
</code></pre></div><p>Also, my <a href="https://dotdoom.rgoswami.me/config.html#text-3">full configuration</a> has additional non-essential quality of life keybindings amongst other things.</p><h3 id="anki-connect">Anki Connect</h3><p><code>CTRL+Shift+A</code> will bring up the addon settings, and Anki has to be restarted after installing the addons. <a href="https://github.com/FooSoft/anki-connect">Anki Connect</a> itself does not need any further configuration, though the <code>readme</code> is very comprehensive.</p><h3 id="tex-setup">TeX Setup</h3><p>The <a href="https://ankiweb.net/shared/info/937148547">LaTeX process editor</a> can be set in two stages, wherein we will first ensure that we can use <code>xelatex</code> and that we can generate an <code>svg</code>.</p><div><pre><code data-lang="json"><span>{</span>
    <span>"svgCommands"</span><span>:</span> <span>[</span>
        <span>[</span>
            <span>"xelatex"</span><span>,</span>
            <span>"--no-pdf"</span><span>,</span>
            <span>"-interaction=nonstopmode"</span><span>,</span>
            <span>"tmp.tex"</span>
        <span>],</span>
        <span>[</span>
            <span>"dvisvgm"</span><span>,</span>
            <span>"--no-fonts"</span><span>,</span>
            <span>"-Z"</span><span>,</span>
            <span>"2"</span><span>,</span>
            <span>"tmp.xdv"</span><span>,</span>
            <span>"-o"</span><span>,</span>
            <span>"tmp.svg"</span>
        <span>]</span>
    <span>]</span>
<span>}</span>
</code></pre></div><p>The <code>png</code> settings can be modified in a similar manner if required, but it is better to generate <code>svg</code> files, which will set up in the cosmetics section. Note that we pass <code>--no-pdf</code> to get the <code>xdv</code> file which has replaced <code>dvi</code> files for <code>xelatex</code>.</p><h3 id="cosmetics">Cosmetics</h3><p>The final aspect of this is to be configured with the GUI. The easiest option is to clone the Basic card type and customize that. <code>CTRL+Shift+N</code> should bring up the card editor. The relevant styles are<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> (from the <code>Cards</code> option):</p><div><pre><code data-lang="css"><span>.</span><span>card</span> <span>{</span>
 <span>font-family</span><span>:</span> <span>Literata</span><span>;</span>
 <span>font-size</span><span>:</span> <span>26</span><span>px</span><span>;</span>
 <span>text-align</span><span>:</span> <span>center</span><span>;</span>
 <span>color</span><span>:</span> <span>black</span><span>;</span>
 <span>background-color</span><span>:</span> <span>white</span><span>;</span>
<span>}</span>
<span>img</span> <span>{</span>
<span>max-height</span><span>:</span><span>1000</span><span>px</span><span>;</span>
<span>height</span><span>:</span> <span>auto</span><span>;</span>
<span>width</span><span>:</span> <span>auto</span><span>;</span>
<span>}</span>
<span>img</span><span>[</span><span>src</span><span>*=</span><span>"latex"</span><span>]</span> <span>{</span>
  <span>vertical-align</span><span>:</span> <span>middle</span><span>;</span>
<span>}</span>
</code></pre></div><p>Now we need setup our TeX headers as well, and enable the <code>Create scalable images with dvisvgm</code> option. The header needs to have (minimally):</p><div><pre><code data-lang="tex"><span>\documentclass</span><span>[12pt]</span><span>{</span>article<span>}</span>
<span>\special</span><span>{</span>papersize=3in,5in<span>}</span>
<span>\usepackage</span><span>{</span>geometry<span>}</span>
<span>\usepackage</span><span>{</span>unicode-math<span>}</span>
<span>\usepackage</span><span>{</span>mathtools<span>}</span>
<span>\pagestyle</span><span>{</span>empty<span>}</span>
<span>\setlength</span><span>{</span><span>\parindent</span><span>}{</span>0in<span>}</span>
<span>\begin</span><span>{</span>document<span>}</span>
</code></pre></div><p>While the <code>footer</code> is simply <code>\end{document}</code>. With this, we have achieved
pretty formatting.</p><figure><img src="https://d33wubrfki0l68.cloudfront.net/75a1682e7c60238799c4e6adb663ae545b367fa1/8d511/ox-hugo/2020-10-26_23-53-25_screenshot.png" alt="Figure 3: Pretty card formatting"><figcaption><p>Figure 3: Pretty card formatting</p></figcaption></figure><h3 id="font-locking">Font Locking</h3><p>Inspired by <a href="https://yiufung.net/post/anki-org/">this post</a>, we will also use <a href="https://github.com/gongzhitaao/orgcss">orgcss</a> to obtain some <code>orgmode</code> font-locking. We will add the following styles:</p><div><pre><code data-lang="css"><span>:</span><span>not</span><span>(</span><span>pre</span><span>)</span> <span>&gt;</span> <span>code</span> <span>{</span>
  <span>padding</span><span>:</span> <span>2</span><span>px</span> <span>5</span><span>px</span><span>;</span>
  <span>margin</span><span>:</span> <span>auto</span> <span>1</span><span>px</span><span>;</span>
  <span>border</span><span>:</span> <span>1</span><span>px</span> <span>solid</span> <span>#ddd</span><span>;</span>
  <span>border-radius</span><span>:</span> <span>3</span><span>px</span><span>;</span>
  <span>background-clip</span><span>:</span> <span>padding-box</span><span>;</span>
  <span>color</span><span>:</span> <span>#333</span><span>;</span>
  <span>font-size</span><span>:</span> <span>$</span><span>code-size</span><span>;</span>
<span>}</span>

<span>.</span><span>org-src-container</span> <span>{</span>
  <span>border</span><span>:</span> <span>1</span><span>px</span> <span>solid</span> <span>#ccc</span><span>;</span>
  <span>box-shadow</span><span>:</span> <span>3</span><span>px</span> <span>3</span><span>px</span> <span>3</span><span>px</span> <span>#eee</span><span>;</span>
  <span>font-family</span><span>:</span> <span>$</span><span>monospace</span><span>;</span>
  <span>font-size</span><span>:</span> <span>$</span><span>code-size</span><span>;</span>
  <span>margin</span><span>:</span> <span>1</span><span>em</span> <span>auto</span><span>;</span>
  <span>padding</span><span>:</span> <span>0.1</span><span>em</span> <span>0.5</span><span>em</span><span>;</span>
  <span>position</span><span>:</span> <span>relative</span><span>;</span>
<span>}</span>

<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span> <span>{</span>
  <span>overflow</span><span>:</span> <span>auto</span><span>;</span>
<span>}</span>

<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>:</span><span>before</span> <span>{</span>
  <span>display</span><span>:</span> <span>block</span><span>;</span>
  <span>position</span><span>:</span> <span>absolute</span><span>;</span>
  <span>background-color</span><span>:</span> <span>#b3b3b3</span><span>;</span>
  <span>top</span><span>:</span> <span>0</span><span>;</span>
  <span>right</span><span>:</span> <span>0</span><span>;</span>
  <span>padding</span><span>:</span> <span>0</span> <span>0.5</span><span>em</span><span>;</span>
  <span>border-bottom-left-radius</span><span>:</span> <span>8</span><span>px</span><span>;</span>
  <span>border</span><span>:</span> <span>0</span><span>;</span>
  <span>color</span><span>:</span> <span>white</span><span>;</span>
  <span>font-size</span><span>:</span> <span>$</span><span>code-size</span><span>;</span>
<span>}</span>

<span>/* from http://demo.thi.ng/org-spec/ */</span>

<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-sh</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"sh"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-bash</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"bash"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-emacs-lisp</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Emacs Lisp"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-R</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"R"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-org</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Org"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-cpp</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"C++"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-c</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"C"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-html</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"HTML"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-js</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Javascript"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-javascript</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Javascript"</span><span>;</span>
<span>}</span>

<span>//</span> <span>More</span> <span>languages</span> <span>from</span> <span>http</span><span>://</span><span>orgmode</span><span>.</span><span>org</span><span>/</span><span>worg</span><span>/</span><span>org-contrib</span><span>/</span><span>babel</span><span>/</span><span>languages</span><span>.</span><span>html</span>

<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-abc</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"ABC"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-asymptote</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Asymptote"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-awk</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Awk"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-C</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"C"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-calc</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Calc"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-clojure</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Clojure"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-comint</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"comint"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-css</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"CSS"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-D</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"D"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-ditaa</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Ditaa"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-dot</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Dot"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-ebnf</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"ebnf"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-forth</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Forth"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-F90</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Fortran"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-gnuplot</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Gnuplot"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-haskell</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Haskell"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-io</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Io"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-java</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Java"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-latex</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"LaTeX"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-ledger</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Ledger"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-ly</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Lilypond"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-lisp</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Lisp"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-makefile</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Make"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-matlab</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Matlab"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-max</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Maxima"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-mscgen</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Mscgen"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-Caml</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Objective"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-octave</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Octave"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-org</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Org"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-perl</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Perl"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-picolisp</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Picolisp"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-plantuml</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"PlantUML"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-python</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Python"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-ruby</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Ruby"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-sass</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Sass"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-scala</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Scala"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-scheme</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Scheme"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-screen</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Screen"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-sed</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Sed"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-shell</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"shell"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-shen</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Shen"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-sql</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"SQL"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-sqlite</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"SQLite"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-stan</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Stan"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-vala</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Vala"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-axiom</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Axiom"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-browser</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"HTML"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-cypher</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Neo4j"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-elixir</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Elixir"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-request</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"http"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-ipython</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"iPython"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-kotlin</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Kotlin"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-Flavored</span> <span>Erlang</span> <span>lfe</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Lisp"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-mongo</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"MongoDB"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-prolog</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Prolog"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-rec</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"rec"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-ML</span> <span>sml</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Standard"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-Translate</span> <span>translate</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Google"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-typescript</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Typescript"</span><span>;</span>
<span>}</span>
<span>.</span><span>org-src-container</span> <span>&gt;</span> <span>pre</span><span>.</span><span>src-rust</span><span>:</span><span>before</span> <span>{</span>
  <span>content</span><span>:</span> <span>"Rust"</span><span>;</span>
<span>}</span>
</code></pre></div><p>However, in the interests of sanity, we will leverage the <a href="https://ankiweb.net/shared/info/1972239816">Syntax Highlighting Anki plugin</a> for managing the actual stylesheets instead of manual edits to each card type.</p><figure><img src="https://raw.githubusercontent.com/ijgnd/syntax-highlighting/master/screenshots/demo%5Fconfig%5Fwith%5Fnm%5Ftoggle%5Faddon.gif" alt="Figure 4: A screencast from the plugin readme"><figcaption><p>Figure 4: A screencast from the plugin readme</p></figcaption></figure><p>At this stage, we have a card which can gracefully handle both XeLaTeX and code in an elegant manner. An example is presented in the next section.</p><h2 id="usage">Usage</h2><p>For the sample card<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> shown, the markup is dead simple.</p><div><pre><code data-lang="org"><span>*</span><span> Basis Vectors</span><span> :math:quantum:linear:</span>
:properties:
:anki_deck: CompChem
:anki_note_type: LaTeX
:ANKI_NOTE_ID: 1603755931922
🔚
<span>**</span> Front
For a three dimensional vector with components $aᵢ,i=1,2,3$ what are the basis vectors?
<span>**</span> Back
This is defined as follows:
$$
\mathbf{a}<span>=\mathbf{e}₁a₁+\mathbf{e}₂a₂+\mathbf{e}₃a₃=</span>∑ᵢ\mathbf{e}ᵢaᵢ
$$
</code></pre></div><p>Essentially:</p><ul><li>Enable and load <code>anki-editor</code><ul><li>Add local variable section to ensure we load <code>anki-editor</code>. This is essentially via <code>eval: (anki-editor-mode)</code> in the Local variables block</li></ul></li><li>Fire up Anki</li><li>Export at will, and continue adding more cards or non-card …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rgoswami.me/posts/anki-decks-orgmode/">https://rgoswami.me/posts/anki-decks-orgmode/</a></em></p>]]>
            </description>
            <link>https://rgoswami.me/posts/anki-decks-orgmode/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24922428</guid>
            <pubDate>Wed, 28 Oct 2020 18:32:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anti-Usage Products]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24922387">thread link</a>) | @sg_gabriel
<br/>
October 28, 2020 | https://blog.saleswhale.com/anti-usage-products-the-next-generation-of-saas-products | <a href="https://web.archive.org/web/*/https://blog.saleswhale.com/anti-usage-products-the-next-generation-of-saas-products">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><em>“Hey Gabriel, why did you fill in N/A for Weekly Active Users in your investor report?”</em></p>
<p><!--more--><em>“Oh, we are not tracking it.”</em></p>
<p><em>“Wait, what? Why? You are a SaaS company, and you are not tracking how many of your users are logging into your platform and using it actively?”</em></p>
<p><em>“Yeah… here’s the thing - I don’t want people to log into my software.”</em></p>
<p><em>“Wait, what?”</em></p>
<p>This was one of the earliest conversations with our investors - almost 3 years ago.</p>
<p>It was an interesting way to start our first investor meeting (our investors would probably describe it as "harrowing").</p>
<p><img src="https://blog.saleswhale.com/hubfs/Screen%20Shot%202020-10-26%20at%2012.18.01%20AM.png" alt="Screen Shot 2020-10-26 at 12.18.01 AM"><span><em>Saleswhale's KPI sheet for investors</em></span></p>
<h2>Thumbing our noses at conventional wisdom</h2>
<p>The prevailing wisdom at the time was the consumerization of SaaS.</p>
<p>The most successful SaaS companies focused on usage - daily active users (DAUs), weekly active users (WAUs), monthly active users (MAUs). Similar to consumer companies.</p>
<p>The poster boys of the "consumerization of the enterprise"-era were Slack, Asana, Zendesk, Trello.</p>
<p>I had other ideas though.</p>
<p>Workflow products were the winning playbook of the previous 5-10 years.</p>
<p>My thesis was that in the next 5-10 years, the next generation of winning SaaS products would be what we call "anti-usage" products.</p>
<p>Products focused on solving a problem and driving outcomes, without requiring users to log in everyday.</p>
<p>This sounds counterintuitive - and I had to spend some time to convince my co-founders and investors in the early days.</p>
<p>Here’s the thought process that led me to the above conclusion.</p>
<h2>The evolution of SaaS products</h2>
<p><strong>First generation of SaaS products</strong></p>
<p>The first generation of cloud-based SaaS products were designed to replace manual systems like spreadsheets (and pen &amp; paper), or clunky, on-premise, client-server products.</p>
<p>Most of them were "<a href="https://venturebeat.com/2016/03/19/how-to-create-a-billion-dollar-saas-company-build-a-system-of-record/" target="_blank" rel="noopener">systems of record</a>" - the ultimate source and "record" of critical business data. And usually, the backbone of business processes.</p>
<p>For example:</p>
<ul>
<li>
<p>Your general ledger is stored in Quickbooks</p>
</li>
<li>
<p>Your customer data is stored in Salesforce</p>
</li>
<li>
<p>Your payroll information is stored in Workday</p>
</li>
</ul>
<p>The main outcome of a system of record is to generate reports / insight.</p>
<p><strong>Second generation of SaaS products</strong></p>
<p>The second generation of SaaS products deal with workflows.</p>
<p>They are task-specific tools that help employees do their jobs — aka. systems of engagement. Most of them integrate with the above mentioned "system of records".</p>
<p>For example:</p>
<ul>
<li>
<p>Your customer support agents live in Zendesk</p>
</li>
<li>
<p>Your sales development reps and account executives live in Outreach or SalesLoft</p>
</li>
<li>
<p>Your digital marketing team lives in Mailchimp, HubSpot or Marketo</p>
</li>
<li>
<p>Your employees use Slack for high-resolution internal communications</p>
</li>
</ul>
<p>The second-generation SaaS vendors understood that <a href="https://techcrunch.com/2013/11/16/from-its-beginnings-in-a-denmark-loft-zendesks-steady-rise-to-the-top-of-the-helpdesk-heap/" target="_blank" rel="noopener">UI and UX were important for workflow products</a>, because people live in it.</p>
<p><em>"'Help desk software didn’t sound that exciting and I had no domain knowledge. I was a canary in a coal mine, but I was obsessive about clean design, and as I saw what existed I realized that companies were being underserved,' says Aghassipour. </em></p>
<p><em>Aghassipour saw the opportunity to create something beautiful in a world where design was an afterthought. Aghassipour told Svane that he would help keep the software 'beautifully simple'."</em></p>
<p>The insertion point: build a simpler, easier to use product, and displace legacy workflow vendors.</p>
<p>This was the consumerization of the enterprise wave - which minted many hundred million ARR companies like Zendesk, Slack and Asana.</p>
<p><strong>Red ocean for systems of record and workflow products</strong></p>
<p>The first and second-generation of SaaS products have one thing in common: they are built on top of human interaction. They essentially replace processes that are previously built on top of paper forms.</p>
<p>People have to key in data, or actively use the software to get to their desired outcome.</p>
<p>But here’s the thing -</p>
<p>The market is quickly <a href="https://chiefmartec.com/2020/04/marketing-technology-landscape-2020-martech-5000/" target="_blank" rel="noopener">getting saturated</a> with systems of records and workflow products.</p>
<p><img src="https://blog.saleswhale.com/hubfs/martech-landscape-2020-martech5000-slide%20(1).jpg" alt="martech-landscape-2020-martech5000-slide (1)">There are only so many tools that a company wants to standardize on. Only so many disparate systems an employee wants to log into daily.</p>
<p>So, if you are a new horizontal workflow provider - sooner or later, you will have to displace incumbents. Or try to build an end-to-end vertical solution. Or re-segment your market.</p>
<p>However -</p>
<p>If you believe the "<a href="https://bothsidesofthetable.com/your-product-needs-to-be-10x-better-than-the-competition-to-win-here-s-why-6168bab60de7" target="_blank" rel="noopener">10X theory of displacement</a>", you will agree that it’s getting harder and harder to build a 10X better product.</p>
<p>Zendesk was able to build a 10X better product than legacy help desk vendors by ruthlessly focusing on UI /UX.</p>
<p>It’s not going to be trivial to invent a help desk product that’s 10X better than Zendesk (essentially 100X better than the original legacy vendors).</p>
<p>UI/UX is becoming table-stakes — it’s not much of a differentiator anymore.</p>
<p>If you want to build a huge SaaS business, like how Salesforce and Zendesk did, you can’t use the same playbook that they used.</p>
<h2>Next Generation of SaaS products</h2>
<p>The next generation of SaaS products are going to be more disruptive.</p>
<p>Instead of providing an interface for human employees to do their work, they seek to reinvent how work is done.</p>
<p>They sit in the background, collect and analyze data, and then shepherd their users towards better outcomes.</p>
<p>For example, revenue intelligence tool Gong sits in the background - and records, transcribes and analyzes sales calls.</p>
<p><img src="https://blog.saleswhale.com/hubfs/Screen%20Shot%202020-10-28%20at%208.08.34%20PM.png" alt="Screen Shot 2020-10-28 at 8.08.34 PM">Gong helps sales teams get automated insights to help them close more deals. Competitor mentions, coaching based on high-performing behavior, and suggested next steps.</p>

<p><img src="https://blog.saleswhale.com/hubfs/Screen%20Shot%202020-10-28%20at%208.01.13%20PM.png" alt="Screen Shot 2020-10-28 at 8.01.13 PM"></p>
<p>Other than setup and occasional maintenance, these products don’t need human interaction/ intervention along their value chain to get to an outcome.</p>
<p>The next generation of SaaS products unilaterally "finds the insights", and “takes the action” on behalf of users.</p>
<p>I call these software "anti-usage products".</p>
<p><strong>A new paradigm for B2B software</strong></p>
<p>In this paradigm, the software becomes the "expert". The user trusts the software to work (mostly) autonomously.</p>
<p>Anti-usage products do not need you to use the product actively.</p>
<p>Because the products understand the problem, and have expert-level domain expertise to propose / run a solution.</p>
<p><u>This requires the product teams who are building the anti-usage product to have a deep and nuanced understanding of the problem to be solved.</u></p>
<p>Anti-usage products are able to work completely autonomously, and yet, are able to deliver outcomes.</p>
<p>Autonomous + Delivering Outcomes = Anti-usage products.</p>
<p><img src="https://blog.saleswhale.com/hubfs/workflow-1@1x%20(1).png" alt="workflow-1@1x (1)">In 5 to 10 years, it’s highly likely that the next wave of billion dollar SaaS companies would be "anti-usage" products.</p>
<p>Here are more examples of up-and-coming "anti-usage" SaaS companies: Zapier, Workato, Tray.io, Metadata.io, People.ai, Segment, and Saleswhale.</p>
<p>Segment just had a 3.2B outcome - <a href="https://techcrunch.com/2020/10/12/twilios-3-2b-segment-acquisition-about-helping-developers-build-data-fueled-apps/">https://techcrunch.com/2020/10/12/twilios-3-2b-segment-acquisition-about-helping-developers-build-data-fueled-apps/</a><u></u></p>
<p><strong>On Metrics (closing the loop on active users)</strong></p>
<p>Josh Elman said that the only metric that matters is how many people are using the product - <a href="https://news.greylock.com/the-only-metric-that-matters-now-with-fancy-slides-232474cf414c">https://news.greylock.com/the-only-metric-that-matters-now-with-fancy-slides-232474cf414c</a><u></u></p>
<p>This is an old paradigm from 2010 - 2019.</p>
<p>It presupposes that if users keep logging in, and performing a certain action, then they are gaining something of value from the product.</p>
<p>However, we wanted to break this paradigm.</p>
<p>The paradigm of retention = product engagement.</p>
<p>You see -</p>
<p>When a product is able to work fully autonomously, and yet, able to deliver outcomes, user engagement is an <em>anti-pattern</em>.</p>
<p>It’s not something that we want to optimize for.</p>
<p>On the contrary, I tell my product team: if our users are logging in <em>too often</em>, it means that our software isn’t autonomous enough, and we have to work harder to sand down the product.</p>
<p>This is counterintuitive, and requires a leap of faith.</p>
<p>But internalizing this logic helps us to build a better product. A product that is laser focused on solving our customers’ problems, and not faux-engagement.</p>
<p><strong>Choosing the right compass metric for anti-usage products</strong></p>
<p>Wait. Where were we? Right. Metrics.</p>
<p>All the above being said, you can’t drive a business without metrics. We still needed a compass metric to approximate the actual outcome we are driving for our users.</p>
<p>So, what did we decide on?</p>
<p><em>The number of qualified sales meetings we deliver for our customers per week.</em></p>
<p><img src="https://blog.saleswhale.com/hubfs/Screen%20Shot%202020-10-28%20at%209.26.25%20PM.png" alt="Screen Shot 2020-10-28 at 9.26.25 PM">Every product decision is filtered through this lens.</p>
<p>From building high-performing messaging suggestions, to auto-segmentation, to auto re-engagement, we ask ourselves: does this feature help our users get more qualified leads autonomously?</p>
<p>And not,<em> "how can we trick our users to log in more often.. so we can stay top-of-mind and justify their purchase."</em></p>
<p>An example of how far we are willing to go in pursuit of this tenet: using <a href="https://blog.saleswhale.com/anti-usage-products-email-as-an-extension-of-product-interface" rel="noopener" target="_blank">emails as an extension of our product interface</a>, to make sure that our users log in as little as possible.</p>
<p>Ultimately, for anti-usage products like Saleswhale, the only thing that matters is the outcome.</p>
<p><strong>Conclusion</strong></p>
<p>Of course, it’s not all roses and rainbows. The "anti-usage" paradigm does <a href="https://blog.saleswhale.com/anti-usage-products-on-pitfalls" rel="noopener" target="_blank">come with some pitfalls</a> which traditional SaaS products do not have.</p>
<p>In spite of these pitfalls however, anti-usage products are here to stay.</p>
<p>In the next 10 years, more and more SaaS products will:</p>
<ul>
<li>
<p>Run in the background, collecting and analyzing data</p>
</li>
<li>
<p>Not require active user input to deliver value</p>
</li>
<li>
<p>Optimize for outcome metrics over engagement metrics</p>
</li>
</ul>
<p>Anti-usage products are the herald to a "log in optional" future.</p></span>
          </p></div>]]>
            </description>
            <link>https://blog.saleswhale.com/anti-usage-products-the-next-generation-of-saas-products</link>
            <guid isPermaLink="false">hacker-news-small-sites-24922387</guid>
            <pubDate>Wed, 28 Oct 2020 18:30:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transhumanism and Augmented Reality – A brave new augmented world]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24922309">thread link</a>) | @brna
<br/>
October 28, 2020 | https://qaautomation.dev/a-brave-new-agumented-world/ | <a href="https://web.archive.org/web/*/https://qaautomation.dev/a-brave-new-agumented-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <!--kg-card-begin: markdown--><h4 id="preface">Preface</h4>
<p>This post is a bundle of thoughts on the near future of Augmented Reality implementations, ways of integration, and introducing new layers of cognition. We are going to talk about AR as a way of enabling transhumanism by broadening the human cognitive and sensory toolbox.<br>
We are not going to be concerned with what is and what is not technologically possible at the moment.</p>
<h4 id="introduction">Introduction</h4>
<p>Have you ever taken a walk and thought about all the accessible information on animals, plants, objects, or even people? How much information is available on the internet? How many facts have you encountered and already forgotten?</p>
<p>Ancient Greeks put an active effort into training and maintaining their memorizing capabilities, and already at this stage of progress, human memory is shifting – or has shifted from remembering facts to remembering how and where to find facts. We are keeping less and less information hardcoded in our permanent memory and are in turn learning how to<br>
consume, process, and find useful data in an endless stream of information and misinformation.</p>
<p>A technologically proficient user has access to a vast volume and spectrum of data at his/her disposal, sitting right in the pocket. The human approach to holding knowledge is evolving as we speak. Heck, it started evolving with the invention of speech. But another significant<br>
change is on the cusp of happening. Our mobile phone interfaces, while serving all the information we need, are still detached from us, having considerable latency when we need to find, show, or input data. With the introduction of AR, AI, and human-computer interfaces, everything is about to change. AR or human augmentation in general will make that data<br>
more accessible and drastically lessen the latency needed for the interaction, making the tools feel more and more as part of ourselves.</p>
<p>Imagine walking down the street. You look around to observe people on the street and notifications start popping up alongside people’s heads. For one person the message says:<br>
"You have seen this person three times this week already"; for another one it states:<br>
"You have five mutual connections and common interests".<br>
Those notifications could also tell you if the person is willing to make new connections, based on previously shared data or facial microexpression analysis. Maybe we have gone too far down the rabbit hole for now, but you<br>
get the idea.</p>
<h3 id="definingarandtranshumanism">Defining AR and Transhumanism</h3>
<p>Merriam-Webster defines Augmented Reality as "an enhanced version of reality created by the use of technology to overlay digital information on an image of something being viewed through a device (such as a smartphone camera)". For the purposes of this post, I would like us not to limit reality to human vision alone.</p>
<p>Merriam-Webster has no definition for Transhumanism, but Wikipedia defines it as a philosophical movement that advocates for the transformation of the human condition by developing and making widely available sophisticated technologies to greatly enhance human intellect and physiology.</p>
<p>The two are getting more and more intertwined as technology advances, so I would like us to redefine AR, if only for this post, as "any technology that enhances or expands the human experience of reality", or maybe even as "practical transhumanism".</p>
<h3 id="augmentationtechnologymilestones">Augmentation technology milestones</h3>
<p>These are some freely set milestones for AR technology.</p>
<ul>
<li>LVL 0 – environment emulation via VR – for developmental fast-tracking</li>
<li>LVL 1 – external IO devices – headsets, glasses, gloves</li>
<li>LVL 2 – embedded IO devices – lenses, external neural signal readers</li>
<li>LVL 3 – tapping into existing sensory and neural networks</li>
<li>LVL 4 – registering new input/output devices in neural networks</li>
</ul>
<h3 id="degreesofaugmentation">Degrees of augmentation</h3>
<p>For the time being, and at least until we master the LVL 4 milestone described above, we are not creating new sensory or actuation systems, we are only hijacking the existing ones. Hi, Neuralink ;). This means that with every bit of information we gain, we are blocking the bandwidth and use for our existing IO mechanisms.In all fairness, people recovering mobility after a severe head trauma are evidence that the brain could possess enough plasticity to use whatever is thrown at it, given we connect the right dots, have enough time and practice. User age could also be a part of the equation.<br>
Sounds easier than it is, I know.</p>
<p>So, the more we augment our existing senses, the more we obstruct our basic physical-world data flow, the need to set some design restriction guidelines will grow. We still have accidents while using mobile phones or headphones, so the question arises: how could we manage a society full of people that overlap and fully cover their field of vision and hearing?<br>
Some safety rules integrated into the tech would be quite handy. Here is an example of defining degrees of augmentation:</p>
<ul>
<li>No augmentation</li>
<li>Info - can be an overlay, but should not block much sensory bandwidth</li>
<li>Safe communication – headset equivalent</li>
<li>Immersive experience – not safe for driving, safe for outdoors</li>
<li>Fully overlaying sensory input with enabled alerts – public safe zones</li>
<li>Fully overlaying sensory input – only for safe zones at home</li>
</ul>
<h3 id="augmentationusagecategories">Augmentation usage categories</h3>
<h4 id="knowledgemanagement">Knowledge management</h4>
<p>At some point, AR should enable access to data from the internet, which should be retrieved and presented without too much user effort, based on surrounding situations and context. Also, the useful data should be categorized and stored for retrieval at a later time.<br>
The interface should be able to combine relevant data and present solutions, statistics, and probabilities.</p>
<p>This could also enable saving verifiable event recordings, snapshots, and transcripts, real-time language translation, or seeing blueprints and instructions while fixing devices.</p>
<h4 id="extendingsensoryreach">Extending sensory reach</h4>
<p>The human sensory reach is already drastically extended with the use of IoT and the internet in general, but there is so much more of existing tech to be integrated into an AR system to extend human senses. Users could see and feel if their home or possessions are safe, or more generally, sense physical-world information streams in real-time.<br>
For example, physical-world data can be processed in parallel with the user experiencing the immediate surroundings. Thus, the user would, for instance, return home and detect certain objects have been moved, etc.</p>
<h4 id="extendingphysicalactuationactionreach">Extending physical actuation/action reach</h4>
<p>Besides our physical reach, most of us have already experienced controlling or affecting the physical-world at a distance. AR could help make the world around us feel more like an extension of our physical bodies.<br>
We could run automated processes upon visual triggers, i.e. unlock the front door without thinking, or control devices, drones, and robotics with ease.</p>
<h4 id="communicationandindividuality">Communication and individuality</h4>
<p>Communication could also be streamlined. We could have an instant connection with anyone around the world, almost as if standing side by side. Communication could play out on several levels, depending on the level of technological advancement, and could be:</p>
<ul>
<li>Restrained – messages and recordings with a delay and opportunity for curation</li>
<li>Unrestrained – conservative – real-time audio-visual communication</li>
<li>Unrestrained – progressive – direct thought transfer in a Neuralink-like brain-computer interface manner</li>
</ul>
<p>We could socialize, play games, or work like never before:<br>
imagine coding while sharing your thought process with a colleague, and also having an "AI" assisted IDE.</p>
<h4 id="extendingthecognitiontoolbox">Extending the cognition toolbox</h4>
<p>Given having a portable AR system and a smart enough underlying OS that replicates our surroundings and anticipates our needs OR an efficient enough way of selecting and using computational tools, we could:</p>
<ul>
<li>see object trajectories</li>
<li>have perfect math at our disposal</li>
<li>know objects, plant life, animals, etc.</li>
</ul>
<p>AI or General AI could, if available, also be used as an intermediary to the available cognition toolbox, to serve the necessary tools and results to the end-user.</p>
<h4 id="pastimeandentertainment">Pastime and entertainment</h4>
<p>I won’t go into great detail here, VR games are already immersive and fun, but try to imagine what they would be like if some freedom is added to the mix. As games and entertainment are presumably most likely to require as much immersion as possible, it will be necessary to consider immersion safety.</p>
<h5 id="vrgamesandapsfullyoverlayingsensoryinput">VR games and APS - fully overlaying sensory input</h5>
<p>Cars, stairs, sudden drops, and obstacles are here to stay, so for any device that can write over your sensory input, a way to risk mitigation must be in place.</p>
<h5 id="endusersafetyzonecalibration">End user safety zone calibration</h5>
<p>Imagine you want to play a full-on VR game somewhere. How could you stay safe and not trip over something or fall over some curb? It is simple, you could just walk around your playground to define its contours and limits. A certain amount of space can even be taken out of the outer limits of the playground, any obstacles are reproduced in-game so you can navigate past them. You start the game and play, and in case you move to the outer limits, the game simply starts to fade away.</p>
<h5 id="safesurfaces">Safe surfaces</h5>
<p>OK, but where else could you use 100% augmentation opacity in the real world? The first thing that comes to mind as safe would be walls. You can project stuff in front of almost any wall and be sure that nothing you can’t see will hit you from that direction, or at least as sure as you are now.</p>
<h5 id="contentkillswitch">Content killswitch</h5>
<p>Another useful feature would be to have the immersive content stop when quiet time or rest is needed, as well as if stress levels are critical.</p>
<h3 id="pitfallsofarandhumanaugmentation">Pitfalls of AR and Human augmentation</h3>
<ul>
<li>Having no signal or battery</li>
<li>Developing a dependence on AR in everyday life</li>
<li>Losing sense of the physical self</li>
<li>Losing individuality</li>
<li>Identifying the AR OS as a part of the personality</li>
</ul>
<h3 id="wecanworkondevelopingartoday">We can work on developing AR today</h3>
<p>I guess we are all well aware of the current limitations of the AR systems, but looking past the non-existing or low tech ways of input and output that we nowadays possess, by emulating non-existing augmentation pathways and …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qaautomation.dev/a-brave-new-agumented-world/">https://qaautomation.dev/a-brave-new-agumented-world/</a></em></p>]]>
            </description>
            <link>https://qaautomation.dev/a-brave-new-agumented-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24922309</guid>
            <pubDate>Wed, 28 Oct 2020 18:24:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Attention, lazy garbage: This bot will insult you until you vote]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24922299">thread link</a>) | @rhinoh
<br/>
October 28, 2020 | https://www.route-fifty.com/tech-data/2020/10/attention-lazy-garbage-bot-will-insult-you-until-you-vote/169624/ | <a href="https://web.archive.org/web/*/https://www.route-fifty.com/tech-data/2020/10/attention-lazy-garbage-bot-will-insult-you-until-you-vote/169624/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    <div>

      <div>
        

        
          
        

        
  
    <div>
      


<div>
  
  <p>Connecting state and local government leaders</p>
</div>

    </div>
  


        
          

          
        

      </div>

      
      <div>

        <div>
          
          <p>
            
              
                
                  



  By


<span><span><a href="https://www.route-fifty.com/voices/kate-queram/13781/?oref=rf-post-author?oref=rf-post-author">Kate Elizabeth Queram</a></span></span>

                
              
            
          </p>

          
            <p><span>|</span>
          

          
            <time datetime="2020-10-28T17:38:00+00:00">
             October 28, 2020
            </time>
          
        </p></div>

        
          <h2>The free service, a product of the nonprofit Fight For The Future, sends daily text messages that urge you—impolitely—to go vote.</h2>
        

        
  <ul>
    
      <li>
        <a href="https://www.route-fifty.com/topic/elections/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Elections
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/innovation/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Innovation
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/information-technology/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Information Technology
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/civic-tech/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Civic Tech
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/state-and-local-government/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                State and Local Government
              </span>
            </span>
          </span>
        </a>
      </li>
    
  </ul>


        





        

      </div>
      

    </div>
  </div><div>
<div>

<div>
<p>If you’re procrastinating on filling out your mail-in ballot or dreading the thought of donning a mask to head to the polls, one national nonprofit might have a solution: free insults, delivered via text message, every day until you vote.</p><p>The <a href="http://www.insultbot.org/" target="_blank">insult bot</a>, a product of <a href="https://www.fightforthefuture.org/" target="_blank">Fight For the Future</a>, a nonpartisan group that advocates for digital rights, launched Wednesday, a mere six days before the Nov. 3 general election. It’s meant specifically as an aggressive last-minute push for procrastinators with a sense of humor who will appreciate—and hopefully be motivated by—a little sarcasm mixed in with frequent reminders to <em>get up and vote already</em>.</p><p>“We wanted to do something that would stand out a bit,” said Caitlin Seeley George, the organization’s campaigns director. “There might be some people out there who really do need this kind of constant, poking reminder to make sure they vote, and we thought that, especially for young people, if we added in some humor and some snark, we might reach them in a different way.”</p><p>The service, free other than standard data and messaging rates, sends periodic texts that “will increase in intensity and aggression through Election Day, until the recipient confirms that they’ve voted," according to a news release. The texts encourage voting in general and do not endorse specific policies or candidates, and their content ranges from name-calling to mild profanity, all peppered with basic voting information (how to look up your local polling place, for example).&nbsp;</p><p>“We’re sending multiple messages per day and trying to splice in some information, but otherwise, it’s a lot of humor,” Seeley George said. “There’s a little bit of cursing, so this is definitely not for people who are uncomfortable with that. We call people lazy, we call them lazy garbage. We call them sea cucumbers.”</p><p>The group, she added, has no specific beef with sea cucumbers.</p><p>“We all love a good sea cucumber,” she said. “But, you know, they’re also slow and lazy.”</p><figure><img alt="" height="800" src="https://www.route-fifty.com/media/ckeditor-uploads/2020/10/28/shutterstock_1307844247.jpg" width="1200">
<figcaption>A sea cucumber, not voting (Shutterstock)</figcaption>
</figure><p>If a recipient never responds or unsubscribes from the messages, the bot will follow up after Election Day to confirm whether they voted. The goal is to increase participation in the election, even if it’s just by a few voters—because sometimes, that’s all it takes to tip a race, Seeley George said.&nbsp;</p><p>“We know that some elections are determined by a handful of votes, so we think it’s worth it if we can get any additional people,” she said. “Our hope is that this catches people’s attention, and a lot of people sign up and share with their friends.”<svg>
<use xlink:href="/static/b/base/svg/spritesheet.svg#icon-rf-shield-alt"></use>
</svg></p></div></div>
</div></div>]]>
            </description>
            <link>https://www.route-fifty.com/tech-data/2020/10/attention-lazy-garbage-bot-will-insult-you-until-you-vote/169624/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24922299</guid>
            <pubDate>Wed, 28 Oct 2020 18:23:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast programming languages: C, C++, Rust, and Assembly]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24922287">thread link</a>) | @krizhanovsky
<br/>
October 28, 2020 | http://tempesta-tech.com/blog/fast-programming-languages-c-c++-rust-assembly | <a href="https://web.archive.org/web/*/http://tempesta-tech.com/blog/fast-programming-languages-c-c++-rust-assembly">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div> <p><i>Posted on October 28, 2020</i></p><p>This article isn't about which programming language is better, instead it discusses the most powerful tool set for development of the fastest server-side system software, such as database engines and HTTPS servers. There are several specific properties of this type of software: </p><ul><li>Relatively large code base, 100,000 lines of C or C++ code and more. While it's possible to write particular, the most 'hot' functions, in Assembly language, it's impractical to write the whole program in Assembly. </li><li>Databases and web servers are mission-critical software - we all got used that our Linux systems with MySQL and Nginx processes work for months and years. There are <a href="https://github.com/tempesta-tech/tempesta/wiki/High-availability">simple high availability</a> best practices mitigating the downtime due to possible crashes, but they're the subject for another article. Meantime, it's worth mentioning that if you really-really care about high availability, then you should build you infrastructure with an assumption that any component of your system may crash at any time, just like <a href="https://lwn.net/Articles/801871/">Facebook does this</a> -the company deploys the recent versions of the Linux kernel as soon as they're available. </li></ul><p>We've been developing the <a href="http://tempesta-tech.com/c++-services">fastest software in C, C++, and Assembly</a> for ages. It's not a surprise that since Rust is <a href="https://en.wikipedia.org/wiki/Rust_(programming_language)">"focused on performance"</a> we're very interested in it. With a bit of skepticism though. Just remember the rise of Java programming language: there were a lot of reports that the JIT compilation produced code faster than C++. Now it's hard to find a case, when C++ is slower than Java, see for example the <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/java.html">benchmark game</a>. It's also worth mentioning that the memory garbage collection (GC) in Java leads to high tail latencies and it's hard or even impossible to do anything with the problem. Golang can not be considered for high performance programming also due to the GC. </p><h2>C or C++? Or both of them?</h2><p> The C programming language dominates in the system programming. An operating system kernel is an example of one of the most sophisticated system software, not only because it deals with hardware directly, but also due to strict performance requirements. The Linux and FreeBSD kernels are written in C, as well as the other UNIX'es and Windows kernels. Let's start the discussion from this bright example of high-performance system software. </p><h3>C++ for operating systems kernel development</h3><p> FreeBSD <a href="https://forums.freebsd.org/threads/driver-building-in-c.35701/">has been supporting C++ modules</a> for a while. While the Linux kernel never supported C++, there was <a href="https://pdos.csail.mit.edu/papers/click:tocs00/paper.pdf">the Click modular router</a> written in C++ and working as a Linux kernel module. If you're interested in C++ applicability for the operating systems kernel development, then you can find quite good discussions in the <a href="https://wiki.osdev.org/C++">C++</a> and <a href="https://wiki.osdev.org/C++_Bare_Bones">Bare bones</a> articles. However, there are fundamental reasons against using C++ for operating system kernel development: </p><ul><li>You do not have <code>libstdc++</code> with <a href="https://en.wikipedia.org/wiki/Run-time_type_information">RTTI</a> and exceptions in the kernel space. Actually, <code>dynamic_cast</code> isn't so frequently used and there are a lot of C++ projects compiled without RTTI. If you need exceptions, then you have to port them into the kernel. <code>libstdc++</code> uses basic C allocations, so it must be significantly reworked for the kernel. </li><li>You can't use the STL and Boost libraries and, in fact, all kernels already have their own libraries. C++ introduces filesystem, threading and networking libraries, which are senseless in an OS kernel. From the other hand, the modern OSes provide advanced synchronization primitives, which are still not available in standard C++ (e.g. there is still no read-write spinlocks in C++). </li><li>The Linux kernel provides number of memory allocators (SLAB, page, <code>vmalloc()</code>, <code>kmalloc()</code>, and so on), thus you have to use <a href="https://en.cppreference.com/w/cpp/language/new"><code>placement new</code></a> and/or just use the C functions for memory allocation and freeing. Aligned memory is crucial for the performance, but you need to write special wrappers to get aligned memory with <code>new</code>. </li><li>Strong type safety isn't so comfortable for system programming when raw memory pointers are frequently casted to some data structures. This is debatable though: while some people are uncomfortable with frequent <code>reinterpret_cast&lt;Foo *&gt;(ptr)</code> instead of short <code>(Foo *)ptr</code>, the others are good with more typing and more type safety. </li><li>C++ <a href="https://en.wikipedia.org/wiki/Name_mangling">name mangling</a>, required for namespaces and function overloading, makes function hard to call from Assembly, so you need to use <code>extern "C"</code>. </li><li>You have to make special code sections for static objects constructors and destructors, <code>.ctor</code> and <code>.dtor</code> correspondingly. </li><li>C++ exceptions can not cross <i>context</i> boundaries, i.e. you can not throw an exception in one thread and catch it in another. The operating system kernel deals with much more complex context model: there are kernel threads, user space processes entering into the kernel, deferred and hardware interruptions. The contexts can preempt each other in voluntarily or cooperative manner, so exception handling of current context could be preempted by another context. There are also memory management and contexts switching code which could conflict with exception handling code. Just like for RTTI, it's possible to implement the mechanism in kernel, but the current standard library can not be used. </li><li>While Clang and G++ support <code>__restrict__</code> extension, the official C++ standard <a href="https://www.quora.com/Why-doesnt-C++-have-an-equivalent-of-Cs-restrict-specifier">does not support</a> it. </li><li>Variable length arrays (VLA) are <a href="https://lwn.net/Articles/749064/">discouraged</a> in the Linux kernel, they are still handy in some scenarios, but are <a href="https://groups.google.com/g/comp.std.c++/c/K_4lgA1JYeg?pli=1">completely unavailable in C++</a>. </li></ul><p> Thus, with C++ in the kernel space you basically have only templates, classes inheritance and some syntax sugar like lambda functions. Since system code is quite rarely requires complicated abstractions and inheritances, then does it still have sense to make effort to use C++ in the kernel space? </p><h3>C++ exceptions</h3><p> This is one of the most <a href="https://herbsutter.com/2010/03/13/trip-report-march-2010-iso-c-standards-meeting/">debatable</a> C++ feature and it deserves a separate chapter. For example, the MySQL project, following to the <a href="https://google.github.io/styleguide/cppguide.html#Exceptions">Google coding style</a>, <a href="https://dev.mysql.com/doc/dev/mysql-server/latest/PAGE_CODING_GUIDELINES.html">doesn't use exceptions</a>. The Google coding style provides the good lists of pros and cons of using exceptions. Here we focus on performance aspects only. </p><p>Exceptions can improve performance when we have to handle error codes in too may places, e.g. (let the functions be inlined and very small) </p><pre><code>
        if (func_1())
            return -EINVAL;
        if (func_2())
            return -EINVAL;
        ....
        if (func_100())
            return -EINVAL;
    </code></pre><p> The problem with the code is that there are extra conditional jumps. Modern CPU are pretty good with branch prediction, but it still hurts performance. In C++ we can just write </p><pre><code>
        try {
            func_1();
            func_2();
            ...
            func_100();
        } catch (...) {
            return -EINVAL;
        }
    </code></pre><p> , so there are no extra conditions in the <i>hot</i> path. However, this isn't for free: most of the functions in your C++ code have to have extra epilogues with a table of exceptions, which these functions can catch, and an appropriate cleanup table. The function epilogues aren't executed in normal workflow, but they increase the size of code causing extra pollution in the CPU instruction cache. You can find great details about C++ exception handling internals in the <a href="https://monoinfinito.wordpress.com/series/exception-handling-in-c/">Nico Brailovsky's blog</a>. </p><h3>Is C++ still good?</h3><p> Yes, it is. Firstly, not the whole code actually must be as fast as possible and in most of the places we don't need custom memory allocation and don't care about exceptions overhead. The most of the projects are developed in the user space and benefit, especially the new ones, from relatively rich C++ standard and Boost libraries (not so rich as Java's though). </p><p>Secondly, the killing feature of C++ is that <b>it is C</b>. If you don't want to use exceptions or RTTI, then you can just switch the features off. Most of C programs can be just compiled with a C++ compiler with very small changes or without any changes at all. As an example, we need only this trivial change </p><pre><code>
    $ diff -up nbody.c nbody-new.cc
        @@ -112,9 +112,9 @@ static void advance(body bodies[]){
             // ROUNDED_INTERACTIONS_COUNT elements to simplify one of the following
             // loops and to also keep the second and third arrays in position_Deltas
             // aligned properly.
        -    static alignas(__m128d) double
        -      position_Deltas[3][ROUNDED_INTERACTIONS_COUNT],
        -      magnitudes[ROUNDED_INTERACTIONS_COUNT];
        +    static double
        +      position_Deltas[3][ROUNDED_INTERACTIONS_COUNT] __attribute__((aligned(16))),
        +      magnitudes[ROUNDED_INTERACTIONS_COUNT] __attribute__((aligned(16)));

             // Calculate the position_Deltas between the bodies for each interaction.
             for(intnative_t i=0, k=0; i &lt; BODIES_COUNT-1; ++i)
    </code></pre><p> to compile <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/program/nbody-clang-8.html">the C program</a> with G++ compiler. The modern C++ compilers provide C compatibility extensions like the <code>__restrict__</code> keyword. You always can write the most performance critical code of a C++ program in C style. If you don't like the <a href="https://250bpm.com/blog:8/">STL containers with an overhead</a>, then you can use <a href="https://www.boost.org/doc/libs/1_74_0/doc/html/intrusive.html">Boost.intrusive</a> or even port a similar container from the Linux kernel or other fast C project -in most of the cases this won't be painful. See for example how a hash table from PostgreSQL, HTrie from <a href="https://github.com/tempesta-tech/tempesta/tree/master/tempesta_db">Tempesta DB</a>, and the Linux kernel read/write spinlocks (all are written in C) were used in a C++ <a href="https://github.com/tempesta-tech/blog/tree/master/htrie">benchmark</a>. </p><p>The last thing which must be mentioned about development of high performance programs in C++ is <a href="https://en.wikipedia.org/wiki/Template_metaprogramming">template metaprogramming</a>. It's very exciting about the modern C++ standards that using templates you can write quite sophisticated logic which is fully computed in the compile time and costs nothing in the run time. </p><h2>GOTO - the power of C</h2> <p><b>A professional tool must allow you to work with it in the most efficient way.</b> The goal of the high-level and high-performance programming languages is to generate the most efficient machine code. Each hardware architecture supports <i>jumps</i>, which means that you can jump to any address by any condition. The closest abstraction for the jumps in the C and C++ programming languages is <code>goto</code> operator. It's not so flexible …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://tempesta-tech.com/blog/fast-programming-languages-c-c++-rust-assembly">http://tempesta-tech.com/blog/fast-programming-languages-c-c++-rust-assembly</a></em></p>]]>
            </description>
            <link>http://tempesta-tech.com/blog/fast-programming-languages-c-c++-rust-assembly</link>
            <guid isPermaLink="false">hacker-news-small-sites-24922287</guid>
            <pubDate>Wed, 28 Oct 2020 18:22:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[P1 – NoisePage from Carnegie Mellon Database Group]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24922217">thread link</a>) | @pbowyer
<br/>
October 28, 2020 | https://noise.page/releases/p1/ | <a href="https://web.archive.org/web/*/https://noise.page/releases/p1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Pittsburgh, PA — This has been a painful journey. After years of impotent performance and correctness checks in the <a href="https://pelotondb.io/">Peloton</a> database project, we found ourselves in a morass of despair and unmaintainable system code. Previous attempts to rectify the many issues with the system proved to be feckless, even with the most brilliant database students and engineers. Rather than continue on with the desiccated husk of a system on life support, we decided to sacrifice our beloved DBMS on the altar of the database gods and start over. It does not help that a certain bike company was able to capture distilled misogyny in a <a href="https://www.nytimes.com/2019/12/03/business/peloton-bike-ad-stock.html">30 second commercial</a> and thus forever ruining a good name for a DBMS.</p>
<p>Two years have passed since then. We now find ourselves in a new world plagued by a pestilence that feeds on imbecilic apathy and stupidity. Despite this setback, we have persevered and continue forward with our research fueled by our unwavering desire to pursue science. </p>
<p>The <a href="https://db.cs.cmu.edu/">Carnegie Mellon Database Group</a> is pleased to announce the first page of the <b>NoisePage</b> database management system. This release is still experimental code and thus should <u>not</u> be used in production environments.</p>
<p>There is currently <u>no</u> support for self-driving operations in this release; it does contain the offline <a href="https://github.com/cmu-db/noisepage/tree/master/benchmark/runner">training data collection framework</a> that is needed to train the DBMS’s internal <i>operating unit</i> models.</p>

</div></div>]]>
            </description>
            <link>https://noise.page/releases/p1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24922217</guid>
            <pubDate>Wed, 28 Oct 2020 18:17:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dec Alpha Emulation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24922214">thread link</a>) | @todsacerdoti
<br/>
October 28, 2020 | http://www.avanthar.com/healyzh/decemulation/Alpha.html | <a href="https://web.archive.org/web/*/http://www.avanthar.com/healyzh/decemulation/Alpha.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<p><a href="http://www.avanthar.com/healyzh/decemulation/decemu.html">DEC Emulation Website (Main Page)</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp1emu.html">PDP-1</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp4emu.html">PDP-4</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp6emu.html">PDP-6</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp7emu.html">PDP-7</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp8emu.html">PDP-8</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp9emu.html">PDP-9</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp10emu.html">PDP-10</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp11emu.html">PDP-11</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp15emu.html">PDP-15</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/vax.html">VAX</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/Alpha.html">Alpha</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/MIPS.html">MIPS</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp_fpga.html">FPGA</a></p>
		<p><b><span size="+3">The DEC Alpha Emulation Webpage</span></b></p>
		<p><b>Last Updated:</b> 2020-09-23</p>
		<p><b><span size="+2">Latest News!</span></b></p>
		<dl>
		  <dd><span color="#009900">(2020-09-23)</span> There is now a <a href="https://github.com/mvorl/es40">fork of ES40</a> available from Martin Vorländer.            
		  </dd><dd><span color="#009900">(2020-09-23)</span> <a href="https://gitlab.com/JonathanBelanger/DECaxp">DECaxp</a> is now on gitlab.
		  </dd><dd>	<span color="#009900">(2019-07-16)</span> There is a new emulator <a href="https://github.com/JonathanBelanger/DECaxp">DECaxp</a> available.  I'm not sure how ready for use it is, but am planning to give it a try. 
		  </dd><dd><span color="#009900">(2018-02-01)</span> Working on major page updates            
			</dd><dd>	<span color="#009900">(2006-01-22)</span> <a href="http://www.softresint.com/charon-axp/index.htm">SRI</a> is working on an Alpha emulator 
			</dd><dd><span color="#009900">(2003-04-03)</span> Added Alpha page.
		
	</dd></dl>
		<p><b><span size="+1">Introduction</span></b></p>
		<p>It is now 2018, and I really need to rewrite the introduction to this page. I'm currently looking to reduce my reliance at home on vintage hardware, and to lower my electricity bill. I've started using SIMH/VAX heavily, and would love an Alpha emulator for the Apps that I can't move over to SIMH/VAX. Plus from what I'm seeing, current Intel-based systems can emulate an Alpha-Based system faster than the fastest Alpha.</p>
		<p>At this point I don't know why anyone would want to emulate an Alpha.  If you are a hobbyist looking to run OpenVMS, take a look at the <a href="http://www.avanthar.com/healyzh/decemulation/vax.html">VAX</a> emulation available, or buy an inexpensive used Alpha.  Having said this I've been watching the ES40 emulator with great interest as at some point this will no longer be true, and at this point it is the emulator with the greatest promise for Hobbyists.</p>
		<p>If you are a commercial user I would seriously recommend looking at an upgrade to Itanium if your applications will run there.  If not I would recommend looking at one of the newer models of Alpha that are still available.  </p>
		<p><b><span size="+1">Table of Contents</span></b></p>
		<ol>
			<li><a href="#emulator">Obtain an emulator</a>
			</li><li><a href="#install">Obtain Installation Documentation</a>
			</li><li><a href="#software">Obtain Software</a>
			</li><li><a href="#docs">Obtain Further Documentation</a>
			</li><li><a href="#moresoftware">Adding Additional Software</a>
			</li><li><a href="#maillists">Mailing Lists</a>
			</li><li><a href="#other">Other</a>
			</li><li><a href="#links">Related Alpha Links</a>
		</li></ol>
		<p><a name="emulator"></a><b><span size="+1">Step 1. Obtain an emulator:</span></b></p>
		<ul>
			<ul>
				<li><a href="https://gitlab.com/JonathanBelanger/DECaxp">DECaxp</a> is being worked on by Jonathan D. Belanger, and he is focused on emulating the 21264. The original github repository can be found here <a href="https://github.com/JonathanBelanger/DECaxp">DECaxp</a>.    
			  </li><li><a href="http://www.camicom.com/es40/">ES40</a> emulator
			(development on the original project has been discontinued, however, it has now been forked several times)
				  <ul>
				    <li>A <a href="https://github.com/SMR11/es40">fork</a> by SMR11</li>
				    <li><a href="https://github.com/fsword7/es40">Fork of ES40</a> by Timothy Stark
				      <ul>
				        <li><a href="https://github.com/promovicz/es40">Fork</a> of Tim Stark's ES40 Fork by Ingo Albrecht</li>
			          </ul>
			        </li>
				    <li>Remy van Elst has <a href="https://raymii.org/s/blog/Installing_the_es40_AlphaServer_emulator_0.18_on_Ubuntu_16.04_and_trying_to_install_openVMS_8.4_on_es40.html">notes</a> on building ES40	0.18	on	Ubuntu 16.04, and trying to install OpenVMS 8.4 on it.</li>
				    <li><a href="https://github.com/mvorl/es40">Fork of ES40</a> by Martin Vorländer			        </li>
		      </ul>              
			  </li><li>Work is being done to add DEC PWS 500au support to SIMH. Current efforts center around implementing the  emulated hardware required to be able to boot the the SRM prompt. 
			    <ul>
			      <li>SRM support is required to be able to boot OpenVMS or Tru64.</li>
			      <li>ARC support may come later, but would require VGA emulation. ARC support is required for Windows NT.</li>
			      <li>Anyone interested, and able to  assist with the effort should contact David T. Hittner via the SIMH email list.</li>
		        </ul>
		      </li>
			  <li><a href="http://www.cs.wisc.edu/~plakal/simplescalar/">SimpleScalar</a>
				processor simulator (now at <a href="http://www.simplescalar.com/">v3.0e</a>)
				appears to implement an EV4 CPU.
			  </li>
			  <li><a href="http://simos.stanford.edu/">SimOS</a> at Stanford, also see this <a href="ftp://simos.stanford.edu/pub/simos">FTP site</a>, and this <a href="ftp://gatekeeper.dec.com/pub/DEC/WRL/simos">FTP site</a>. <span color="red"> (Dead Links)</span>
			  </li>
			  <li><a href="https://www.stromasys.com/solutions/charon-axp/">CHARON-AXP</a> from Stromasys (originally SRI), supports OpenVMS, and Tru64 UNIX 
			  </li>
			  <li><a href="http://www.personalalpha.com/">PersonalAlpha</a> from Emulators International, a subsidiary of SRI, runs on XP and is available for personal use.  It emulates a system with 96MB RAM, Ethernet, two disks, and Ethernet.   Based on the information they provide on the website, it appears that they have limited the speed, and with it only emulating 96MB of RAM, you will run into serious performance problems there.  I've not tried this product out as I prefer to run OpenVMS on real hardware.
				<span color="red"> (no longer available)</span>

			  </li>
			  <li><a href="https://systems.cs.colorado.edu/DistributedSoftware/Aint/">AINT</a><span color="red"> (Dead Link)</span>
		      </li>
			  <li>                
		      </li>
			  <li>Virtutech has some sort of <a href="http://www.virtutech.com/products/model-libraries.html">model libraries</a> that emulate an EV5. 
			
				(Virtutech is no longer around, the link points to Wind River)
				
	          </li>                
			  <li><a href="http://www.migrationspecialties.com/FreeAXP.html">FreeAXP</a> from Migration Specialties                
			    </li><li><a href="http://www.migrationspecialties.com/Emulator-Alpha.html">Avanti &amp; AvantiFlex</a> from Migration Specialties          
		          <ul>
		            <li>Runs OpenVMS&nbsp;6.2 thru 8.4</li>
		            <li>Runs Tru64 UNIX&nbsp;V3.2C thru V5.1B-6/Pk8</li>
	              </ul>
	          </li><li>AlphaVM-Free <span color="red"> (no longer available)</span>
			</li><li>AlphaVM-Basic            
			from EmuVM
			</li><li>AlphaVM-Pro            
			  from <a href="http://www.emuvm.com/">EmuVM</a>
			  </li><li><a href="https://www.avtware.com/vtalpha">vtAlpha</a>                        
			</li><li><a href="https://www.qemu.org/">QEMU</a> is not able to run OpenVMS or Tru64 at this time (Feb. 2018).         
		  </li></ul>
	</ul>
		<p><a name="install"></a><b><span size="+1">Step 2. Obtain Installation Documentation:</span></b></p>
		<p><a name="software"></a><b><span size="+1">Step 3. Obtain Software:</span></b></p>
		<ul>
		            <li>OpenVMS 8.4 and select Layered products are available through the Hobbyist Program</li>
		            <li> Tru64 UNIX - eBay</li>
		            <li><a href="https://wasd.vsm.com.au/">WASD</a> VMS Web Services</li>
		            <li>Process Software's <a href="http://www.process.com/products/multinet/">Multinet</a> TCP/IP Stack is an excellent alternative to the stack that HP ships, and they offer it to Hobbyists with a valid OpenVMS Hobbyist license.</li>
		            <li>Process Software's TCPware TCP/IP Stack</li>
		            <li>Process Software's PMDF Internet Messaging
		            </li>
		            <li>Process Software's PreciseMail Anti-Spam Gateway</li>
		            <li>Oracle RDB (OTN Account required)</li>
    </ul>
		<p><a name="docs"></a><b><span size="+1">Step 4. Obtain Further Documentation</span></b></p>
		<ul>
			<li>&nbsp;
		</li></ul>
		
		<p><a name="moresoftware"></a><b><span size="+1">Step 5. Adding Additional Software</span></b></p>
		<p><a name="maillists"></a><b><span size="+1">Mailing Lists</span></b></p>
		<p><a name="other"></a><b><span size="+1">Other</span></b></p>
		<p><a name="links"></a><b><span size="+1">Related Alpha Links</span></b></p>
		<ul>
		  <li>The&nbsp;<a href="https://www.vmssoftware.com/products_roadmap.html">roadmap</a>&nbsp;on the VMS Software website for future releases of OpenVMS.</li>
    </ul>
		<dl>
			<dd>&nbsp;
		</dd></dl>
		
		<center>&nbsp;</center>
		
		<p><a href="http://www.avanthar.com/healyzh/decemulation/decemu.html">DEC Emulation Website (Main Page)</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp1emu.html">PDP-1</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp4emu.html">PDP-4</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp7emu.html">PDP-7</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp8emu.html">PDP-8</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp9emu.html">PDP-9</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp10emu.html">PDP-10</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp11emu.html">PDP-11</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp15emu.html">PDP-15</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/vax.html">VAX</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/Alpha.html">Alpha</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/MIPS.html">MIPS</a> -- <a href="http://www.avanthar.com/healyzh/decemulation/pdp_fpga.html">FPGA</a></p>
	

</div>]]>
            </description>
            <link>http://www.avanthar.com/healyzh/decemulation/Alpha.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24922214</guid>
            <pubDate>Wed, 28 Oct 2020 18:17:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Public Speaking to Programming: Top Online Courses for Skill-Building]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24921941">thread link</a>) | @asanchez94
<br/>
October 28, 2020 | https://human-jobs.com/2020/10/28/5-favorite-online-courses-skill-buidling/ | <a href="https://web.archive.org/web/*/https://human-jobs.com/2020/10/28/5-favorite-online-courses-skill-buidling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>At Human Jobs, we are obsessed with building skills. Not only is continual learning a key driver for career success, it can also be a source of enormous intellectual satisfaction. There are so many quality resources available online, but today we start with our top 5 online courses for building job skills. They cover a variety of subjects, but all are well-taught and will deliver tangible skills you can use in the real world.</p>
<h4>1. <a href="https://ocw.mit.edu/resources/res-tll-005-how-to-speak-january-iap-2018/index.htm"><em>How to Speak</em> </a>from MIT</h4>
<p>This is a legendary course from MIT focused on public speaking skills for job interviews, lectures, and much more. The professor, Patrick Winston is a charismatic speaker himself – I mean, he ought to be if he is teaching the course. Although geared toward an MIT audience, it is packed with useful tips for people of any educational background.</p>
<p>This “course” is technically just one video, so if you don’t have much free time, an hour with Patrick Winston is an hour well-spent. In his own words: “By the end of the next 60 minutes you will have been exposed to a lot of ideas, some of which you will incorporate into your own repertoire, and they will ensure that you get the maximum opportunity to have your ideas valued and accepted by the people you speak with.” The lectures is freely available on MIT Open Courseware.</p>
<p>Don’t go into another job interview without watching <em>How to Speak </em>first.&nbsp;Check it out <strong><a href="https://ocw.mit.edu/resources/res-tll-005-how-to-speak-january-iap-2018/index.htm">here.</a></strong></p>
<h4>2. <a href="https://www.startupschool.org/"><em>Startup School</em></a> from Y Combinator</h4>
<p>If you are thinking of starting a business, <em>Startup School</em> from Y Combinator (YC) will give you the skills and frameworks for evaluating and growing your idea. YC is the top startup accelerator in the US, which means they know what it takes for a clever idea to become a successful business.</p>
<p><em>Startup School</em> is a great introduction to entrepreneurship, and business more generally, because it forces you to think critically about why some startups succeed and others fail. For people with little background in this area, the lectures are very accessible, use little jargon, and are a great entry-point into the space. The lecturers are really candid, and I found it very refreshing for some frank and pointed views on the startup world.</p>
<p><em>Startup School</em> is free, so check it out <a href="https://www.startupschool.org/"><strong>here.</strong></a></p>
<h4>3. <a href="https://justiceharvard.org/"><em>Justice</em></a> from Harvard</h4>
<p>Michael Sandel is the professor who turns probing moral inquiry into a thrill-ride. <em>Justice</em> offers a whistle-stop tour of different ethical and moral philosophies ranging from the ancients to contemporary philosophers. The course is honestly addictive and always spurred vigorous debate between me ad my friends while watching.</p>
<p>Sandel is a champion of the Socratic method, and his questioning models the kind of critical thought that is so celebrated by humanities students. If sharpening your reasoning skills isn’t enough, then take <em>Justice</em> to challenge your own moral and ethical convictions. Whether you are targeting writing jobs, tutoring jobs, or a career in finance, you will become more analytically and ethically robust after a few lectures of <em>Justice</em>.</p>
<p>Lectures are free from the course website and on YouTube. Check out the course website <a href="https://justiceharvard.org/"><strong>here.</strong></a></p>
<h4>4. <a href="https://www.linkedin.com/learning/excel-2016-essential-training/welcome"><em>Excel Essential Training</em></a> from LinkedIn</h4>
<p>You cannot deny the importance of Excel within the modern economy. Microsoft’s interactive spreadsheet software is everywhere and facility with the program is a huge selling point in job applications. This course from LinkedIn is a thorough introduction to the subjects and it provides a nice interactive format for practicing new techniques. No prior knowledge is necessary, and even people with intermediate Excel skills will benefit.</p>
<p>When I took the course, my Excel skills were reasonably advanced, but I benefitted tremendously from a more detailed understanding of the program. The small tips and best practices I learned have saved me a lot of time and many headaches since finishing the course. Knowledge of Excel will serve you in many different professions, so it is worth committing the hours to become a power user.</p>
<p>Available on LinkedIn Learning <a href="https://www.linkedin.com/learning/excel-2016-essential-training/welcome"><strong>here.</strong></a></p>
<h4>5. <a href="https://www.edx.org/course/cs50s-introduction-to-computer-science"><em>CS50: Introduction to Computer Science</em></a> from Harvard/edX</h4>
<p>If you want to learn to code, CS50 is the place to start. This course from Harvard comes with everything: a dynamic professor, extensive resources, logistical help, problem sets with automatic grading, supplementary lectures from teaching fellows, a user-friendly coding environment, and more.</p>
<p>There is a reason CS50 has a cult following among Harvard undergraduates, many of whom take CS50 as their first computer science course. I took CS50 online and found it absolutely exhilarating. It was challenging, but the course structure and resources made it easy to start. At the outset of a programming course, the number of new tools and concepts is often overwhelming for beginners. In my experience, CS50 does the best job at easing you into the field and building some momentum right from the start.</p>
<p>Knowing how to code is an invaluable skill for anyone on the job market, so it should be high on your list of skills to acquire. If you need to be convinced, we have an entire <strong><a href="https://human-jobs.com/2020/10/07/learn-to-code/">blogpost</a></strong> dedicated to coding for humanities people. Taking CS50 is a commitment, but you will not regret it. Free and paid versions are available from edX, so check it out <a href="https://www.edx.org/course/cs50s-introduction-to-computer-science"><strong>here.</strong></a></p>
<h4>6. Bonus Fun/Learning Resource: <a href="https://www.youtube.com/channel/UC9RM-iSvTu1uPJb8X5yp3EQ">Wendover Productions</a> on YouTube</h4>
<p>This isn’t a course, but rather a YouTube channel that offers super high-quality “mini-documentaries” on really interesting topics. Wendover’s videos are pithy and jam-packed with interesting insights. Ever wonder how overnight shipping works? Check out this <strong><a href="https://www.youtube.com/watch?v=y3qfeoqErtY">video</a></strong>. Curious about how humans conceptualize risk? Wendover has got you covered <strong><a href="https://www.youtube.com/watch?v=NtX-Ibi21tU">here</a>.&nbsp;</strong></p>
<p>I watch Wendover to understand how the world works, and I always come away with a new insight into the unseen forces that shape our lives. Highly recommended for some fun and educational time on YouTube. <a href="https://www.youtube.com/channel/UC9RM-iSvTu1uPJb8X5yp3EQ"><strong>Here</strong></a> is&nbsp;the channel link.</p>
<h3>Never stop learning – build job skills every day</h3>
<p>Learning new things and building skills is a major motivator in my life. I do it for fun, and I do it for the career opportunities that an expanded skillset affords. Tell me in the comments: what skills do you want to build? Do you have any amazing online resources that others should check out?</p>


			<p><a href="https://human-jobs.com/category/careers/" rel="category tag">Careers</a>, <a href="https://human-jobs.com/category/coding/" rel="category tag">coding</a>, <a href="https://human-jobs.com/category/entrepreneurship/" rel="category tag">entrepreneurship</a>, <a href="https://human-jobs.com/category/income-streams/" rel="category tag">income streams</a>, <a href="https://human-jobs.com/category/job-search/" rel="category tag">Job search</a>, <a href="https://human-jobs.com/category/lifelong-learning/" rel="category tag">Lifelong learning</a>, <a href="https://human-jobs.com/category/skills/" rel="category tag">skills</a>, <a href="https://human-jobs.com/category/uncategorized/" rel="category tag">Uncategorized</a></p>
			
					</div></div>]]>
            </description>
            <link>https://human-jobs.com/2020/10/28/5-favorite-online-courses-skill-buidling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24921941</guid>
            <pubDate>Wed, 28 Oct 2020 17:55:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Code Review of the Axios JavaScript package]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24921829">thread link</a>) | @timemachine
<br/>
October 28, 2020 | http://ctrl-c.club/~timemachine/2020/10/24/code-review-axios | <a href="https://web.archive.org/web/*/http://ctrl-c.club/~timemachine/2020/10/24/code-review-axios">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <blockquote>
<p>This article is in a series of code review articles that take a
deep look at a popular module and discuss its merits, flaws, and
overall fitness for a task.</p>
</blockquote>
<h2 id="Summary"><a href="#Summary" title="Summary"></a>Summary</h2><p><a target="_blank" rel="noopener" href="https://github.com/axios/axios">Axios</a> is a solid, battle-tested, replacement for the deprecated <code>require.js</code>. I
recommend it despite the imperfections that I have summarized in this article.</p>
<p>The logic in this package is well thought out and meets my standards. Some of
the more complex functions are arduous to read. This makes collaboration from
the development community difficult and undermines the overall effectiveness of
the project.</p>
<p>The interceptor system is a workable solution for extending the package
functions. Personally, I have wrapped request/response to extend error reporting
and the updates felt natural and a seamless transition.</p>
<p>There are two test runners in the project: Mocha (for node.js) and Jasmine/Karma
(for browser testing). This is unnecessary as both test packages can run both
platforms. A large number of the tests are written for jasmine and will not
run, without modification in the mocha test suite. This prevents me from
showing full code coverage without hacking on the tests (more on this later). </p>
<p>Running <code>npm test</code> takes many minutes and fails, by default, if the developer
does not have the Opera browser installed. I can understand that an exhaustive
integration run in a multi-target package is a long process. Fleshing out the
Mocha test suite to run on the command line in a second npm script would
encourage test-driven refactoring and make many of the improvements I outline
much simpler and safer. Iterative, refactoring tests must be fast, sane, and
meaningful. They need not be exhaustive. The exhaustive testing can be saved
for pre-release and proofing pull-requests.</p>
<p>The current version is <code>0.20.0</code>. There is no explicit roadmap for the project;
however, I do not see a reason for the delay in assigning version <code>1.0.0</code> to this
release.</p>
<h2 id="About-Reviewed-Version-amp-System"><a href="#About-Reviewed-Version-amp-System" title="About Reviewed Version &amp; System"></a>About Reviewed Version &amp; System</h2><ul>
<li>Repository: <a target="_blank" rel="noopener" href="https://github.com/axios/axios">https://github.com/axios/axios</a></li>
<li>Reviewed Commit Hash: <code>6d05b96dcae6c82e28b049fce3d4d44e6d15a9bc</code></li>
<li>Average weekly downloads: 12 million</li>
<li>Version: 0.20.0</li>
<li><code>du -sh dist</code>: 244K</li>
<li>Dependencies: 1<ul>
<li>follow-redirects</li>
</ul>
</li>
<li>Node: v14.10.1</li>
<li>npm: 4.16.8</li>
<li>uname -a<ul>
<li>Linux morlock 5.4.0-7642-generic #46~1598628707~20.04~040157c-Ubuntu x86_64 GNU/Linux</li>
</ul>
</li>
</ul>
<p>Axios is a promise-based HTTP client. It is available for use in the
browser (wrapping around XMLHttpRequest) or in node.js (wrapping the
built-in <code>http</code> module.</p>
<h2 id="Setup"><a href="#Setup" title="Setup"></a>Setup</h2><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br></pre></td><td><pre><span>✔ pilot@morlock ~/Projects/codereview % git clone https://github.com/axios/axios.git</span><br><span>Cloning into 'axios'...</span><br><span>...</span><br><span>... &lt;snip&gt;</span><br><span>...</span><br><span>✔ pilot@morlock ~/Projects/codereview % npm install</span><br><span></span><br><span>... &lt;snip&gt; npm WARN deprecated 18 messages</span><br><span>...</span><br><span></span><br><span>&gt; iltorb@2.4.5 install /home/pilot/Projects/codereview/axios/node_modules/iltorb</span><br><span>&gt; node ./scripts/install.js || node-gyp rebuild</span><br><span></span><br><span>...</span><br><span>... &lt;snip&gt; Complation messages for node_modules/iltorb</span><br><span>... &lt;snip&gt; package postinstall garbage</span><br><span>...</span><br><span></span><br><span>npm notice created a lockfile as package-lock.json. You should commit this file.</span><br><span>npm WARN notsup Unsupported engine for karma@1.7.1: wanted: {"node":"0.10 || 0.12 || 4 || 5 || 6 || 7 || 8"} (current: {"node":"14.10.1","npm":"6.14.8"})</span><br><span>npm WARN notsup Not compatible with your version of node/npm: karma@1.7.1</span><br><span>npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@^1.2.7 (node_modules/chokidar/node_modules/fsevents):</span><br><span>npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.13: wanted {"os":"darwin","arch":"any"} (current: {"os":"linux","arch":"x64"})</span><br><span>npm WARN ajv-keywords@2.1.1 requires a peer of ajv@^5.0.0 but none is installed. You must install peer dependencies yourself.</span><br><span></span><br><span>added 975 packages from 1871 contributors and audited 978 packages in 61.395s</span><br><span></span><br><span>11 packages are looking for funding</span><br><span>  run `npm fund` for details</span><br><span></span><br><span>found 33 vulnerabilities (22 low, 10 high, 1 critical)</span><br><span>  run `npm audit fix` to fix them, or `npm audit` for details</span><br></pre></td></tr></tbody></table></figure>

<p>Installed 975 packages. All but one are dev.</p>
<p><code>axios</code> installs <code>bundlesize@^0.17.0</code>, which is a drop-in
replacement for <code>du -sh</code> (if <code>du</code> required oAuth read/write access to your
github account). Bundlesize uses a hand full of compression modules, including
<code>iltorb</code>. <code>iltorb</code> is deprecated garbage. </p>
<h3 id="NPM-Audit-Review"><a href="#NPM-Audit-Review" title="NPM Audit Review"></a>NPM Audit Review</h3><figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>✔ pilot@morlock ~/Projects/codereview/axios % npm --no-color audit &gt; audit.txt</span><br></pre></td></tr></tbody></table></figure>

<p>I’m not going to detail all of the audit warnings, they are mostly from the
<a target="_blank" rel="noopener" href="https://github.com/visionmedia/debug/pull/504/files"><code>debug</code> package</a> and it’s
<a target="_blank" rel="noopener" href="https://npmjs.com/advisories/534">DDoS Regex</a>.</p>
<p>The first High level security threat is from installing the <code>karma</code> test runner:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></pre></td><td><pre><span>✘ pilot@morlock ~/Projects/codereview/axios % npm ls ws</span><br><span>axios@0.20.0 /home/pilot/Projects/codereview/axios</span><br><span>└─┬ karma@1.7.1</span><br><span>  └─┬ socket.io@1.7.3</span><br><span>    ├─┬ engine.io@1.8.3</span><br><span>    │ └── ws@1.1.2 </span><br><span>    └─┬ socket.io-client@1.7.3</span><br><span>      └─┬ engine.io-client@1.8.3</span><br><span>        └── ws@1.1.2  deduped</span><br></pre></td></tr></tbody></table></figure>

<p>That is an extremely old version of <code>ws</code>. <a target="_blank" rel="noopener" href="https://www.npmjs.com/advisories/550">It has been
fixed</a></p>
<p>I love <code>lodash</code> for the creativity of its codebase, the way the developers
step up to the challenge of being faster than native, but never user it. NPM
awards <code>lodash</code>‘s prototype pollution (actually polyfills) a <code>High</code> level alert.</p>
<p><code>karma</code> also depends on an old version of <code>chokidar</code>, but <a target="_blank" rel="noopener" href="https://paulmillr.com/posts/chokidar-3-save-32tb-of-traffic/">new chokidar is way
cooler</a>.</p>
<p>The <code>Critical</code> alert award goes to: <code>webpack-dev-server</code> … <a target="_blank" rel="noopener" href="https://npmjs.com/advisories/725">kind of a let
down</a></p>
<p><a target="_blank" rel="noopener" href="https://npmjs.com/advisories/528"><code>parsejson</code> is installed</a></p>
<p>I went into all the depth here because it is important to note that while all of
these dependencies are dev only, they are eliminated by just updating the
dependencies<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span aria-label="TODO: Update dependants; open PR.
">[1]</span></a></sup>. This is a bad code smell and indicator of lazy development cycles. </p>
<h2 id="Running-the-tests"><a href="#Running-the-tests" title="Running the tests"></a>Running the tests</h2><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br><span>51</span><br><span>52</span><br><span>53</span><br><span>54</span><br><span>55</span><br><span>56</span><br><span>57</span><br><span>58</span><br><span>59</span><br><span>60</span><br><span>61</span><br><span>62</span><br><span>63</span><br><span>64</span><br></pre></td><td><pre><span>✘ pilot@morlock ~/Projects/codereview/axios % npm test</span><br><span></span><br><span>&gt; axios@0.20.0 test /home/pilot/Projects/codereview/axios</span><br><span>&gt; grunt test &amp;&amp; bundlesize</span><br><span></span><br><span>Running "eslint:target" (eslint) task</span><br><span></span><br><span>Running "mochaTest:test" (mochaTest) task</span><br><span></span><br><span></span><br><span>...</span><br><span>... &lt;snip&gt; Test list</span><br><span>...</span><br><span></span><br><span>  29 passing (730ms)</span><br><span>  1 pending</span><br><span></span><br><span></span><br><span>Running "karma:single" (karma) task</span><br><span>Running locally since SAUCE_USERNAME and SAUCE_ACCESS_KEY environment variables are not set.</span><br><span>(node:26309) Warning: Accessing non-existent property 'VERSION' of module exports inside circular dependency</span><br><span>(Use `node --trace-warnings ...` to show where the warning was created)</span><br><span>Hash: f4683f5fa2953dc3a97c</span><br><span>Version: webpack 1.15.0</span><br><span>Time: 27ms</span><br><span>webpack: Compiled successfully.</span><br><span>webpack: Compiling...</span><br><span>webpack: wait until bundle finished: </span><br><span>&lt;snip&gt;</span><br><span>Hash: 17b067e2f01905fd51bf</span><br><span>    Version: webpack 1.15.0</span><br><span>Time: 844ms</span><br><span>&lt;snip&gt;</span><br><span></span><br><span>webpack: Compiled successfully.</span><br><span>07 10 2020 23:56:29.288:INFO [karma]: Karma v1.7.1 server started at http://0.0.0.0:9876/</span><br><span>07 10 2020 23:56:29.289:INFO [launcher]: Launching browsers Firefox, Chrome, Safari, Opera with unlimited concurrency</span><br><span>07 10 2020 23:56:29.294:INFO [launcher]: Starting browser Firefox</span><br><span>07 10 2020 23:56:29.311:INFO [launcher]: Starting browser Chrome</span><br><span>07 10 2020 23:56:29.328:INFO [launcher]: Starting browser Safari</span><br><span>07 10 2020 23:56:29.351:INFO [launcher]: Starting browser Opera</span><br><span>07 10 2020 23:56:29.388:ERROR [launcher]: No binary for Safari browser on your platform.</span><br><span>  Please, set "SAFARI_BIN" env variable.</span><br><span>07 10 2020 23:56:32.140:INFO [Chrome 85.0.4183 (Linux 0.0.0)]: Connected on socket OZh8d5JZl6lqIyL8AAAA with id 4718835</span><br><span>................................................................................</span><br><span>................................................................................</span><br><span>................................................................................</span><br><span>......</span><br><span>Chrome 85.0.4183 (Linux 0.0.0): Executed 246 of 246 SUCCESS (2.522 secs / 2.462 secs)</span><br><span>07 10 2020 23:56:35.007:INFO [Firefox 81.0.0 (Ubuntu 0.0.0)]: Connected on socket -qEkpSILYreupv-OAAAB with id 87695166</span><br><span>................................................................................</span><br><span>................................................................................</span><br><span>................................................................................</span><br><span>......</span><br><span>Firefox 81.0.0 (Ubuntu 0.0.0): Executed 246 of 246 SUCCESS (2.512 secs / 2.455 secs)</span><br><span></span><br><span>08 10 2020 00:00:29.394:WARN [launcher]: Opera have not captured in 240000 ms, killing.</span><br><span>08 10 2020 00:00:31.398:WARN [launcher]: Opera was not killed in 2000 ms, sending SIGKILL.</span><br><span>08 10 2020 00:00:33.400:WARN [launcher]: Opera was not killed by SIGKILL in 2000 ms, continuing.</span><br><span>TOTAL: 492 SUCCESS</span><br><span>Warning: Task "karma:single" failed. Use --force to continue.</span><br><span></span><br><span>Aborted due to warnings.</span><br><span>npm ERR! Test failed.  See above for more details.</span><br></pre></td></tr></tbody></table></figure>

<p>All tests passed… Except for the Opera tests; but I don’t have the opera
browser installed, nor does anyone else.</p>
<p>It is interesting to note that karma detected immediately that I do not have
Safari installed; but took over two minutes to not find Opera.  This is an old
version of karma so I can not criticise.</p>
<p>One of the mocha tests is skipped: <code>should support sockets</code>. Setting this test to
run passes<sup id="fnref:2"><a href="#fn:2" rel="footnote"><span aria-label="TODO: Pull request, re-adding the skipped test.
">[2]</span></a></sup>.</p>
<h2 id="Code-Coverage"><a href="#Code-Coverage" title="Code Coverage"></a>Code Coverage</h2><p>This was not as straightforward as I thought it would be. The <code>package.json</code>
has an entry for <code>coveralls</code> but the <code>lcov</code> file wasn’t generated by the test
run. Looking in <code>node_modules</code> I don’t see an entry for <code>blanket.js</code>. <em>Another
bad smell.</em> Checking the <code>travis-ci</code> runs for the project they all error on <code>npm run coveralls</code>. </p>
<p>Let’s live dangerously:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br></pre></td><td><pre><span>✘ pilot@morlock ~/Projects/codereview/axios % npx nyc@latest npm test</span><br><span>npx: installed 141 in 5.972s</span><br><span></span><br><span>&gt; axios@0.20.0 test /home/pilot/Projects/codereview/axios</span><br><span>&gt; grunt test &amp;&amp; bundlesize</span><br><span></span><br><span>Running "eslint:target" (eslint) task</span><br><span></span><br><span>Running "mochaTest:test" (mochaTest) task</span><br><span>...</span><br><span>... &lt;snip&gt; Test list</span><br><span>...</span><br><span></span><br><span></span><br><span>-------------------------|---------|----------|---------|---------|-----------------------------------</span><br><span>File                     | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s                 </span><br><span>-------------------------|---------|----------|---------|---------|-----------------------------------</span><br><span>All files                |   79.21 |    62.78 |   79.44 |   79.73 |                                   </span><br><span> axios                   |   33.33 |    11.36 |      40 |   34.69 |                                   </span><br><span>  …</span></pre></td></tr></tbody></table></figure></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://ctrl-c.club/~timemachine/2020/10/24/code-review-axios">http://ctrl-c.club/~timemachine/2020/10/24/code-review-axios</a></em></p>]]>
            </description>
            <link>http://ctrl-c.club/~timemachine/2020/10/24/code-review-axios</link>
            <guid isPermaLink="false">hacker-news-small-sites-24921829</guid>
            <pubDate>Wed, 28 Oct 2020 17:46:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pyston v2: Faster Python]]>
            </title>
            <description>
<![CDATA[
Score 260 | Comments 206 (<a href="https://news.ycombinator.com/item?id=24921790">thread link</a>) | @kmod
<br/>
October 28, 2020 | https://blog.pyston.org/2020/10/28/pyston-v2-20-faster-python/ | <a href="https://web.archive.org/web/*/https://blog.pyston.org/2020/10/28/pyston-v2-20-faster-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
			
		<div>
		<main id="main" role="main">

					<div>
				
<article id="post-895">
	<!-- .entry-header -->

	<div>
		
<p>We’re very excited to release Pyston v2, a faster and highly compatible implementation of the Python programming language.  Version 2 is 20% faster than stock Python 3.8 on our macrobenchmarks.  More importantly, it is likely to be faster on your code.  Pyston v2 can reduce server costs, reduce user latencies, and improve developer productivity.</p>



<p>Pyston v2 is easy to deploy, so if you’re looking for better Python performance, we encourage you to take five minutes and <a href="#availability">try Pyston</a>. Doing so is one of the easiest ways to speed up your project.</p>



<h2>Performance</h2>



<p>Pyston v2 provides a noticeable speedup on many workloads while having few drawbacks.  Our focus has been on web serving workloads, but Pyston v2 is also faster on other workloads and popular benchmarks.</p>



<p>Our team put together a new <a href="https://github.com/pyston/python-macrobenchmarks/">public Python macrobenchmark suite</a> that measures the performance of several commonly-used Python projects.  The benchmarks in this suite are larger than those found in other Python suites, making them more likely to be representative of real-world applications.  Even though this gives us a lower headline number than other projects, we believe it translates to better speedups for real use cases.  Pyston v2 still shows sped-up performance on microbenchmarks, being twice as fast as standard Python on tests like chaos.py and nbody.py.</p>



<p>Here are our performance results:</p>



<figure><table><tbody><tr><td></td><td>CPython 3.8.5</td><td>Pyston 2.0</td><td>PyPy 7.3.2</td></tr><tr><td>flaskblogging warmup time [1]</td><td>n/a</td><td>n/a</td><td>85s</td></tr><tr><td>flaskblogging mean latency</td><td>5.1ms</td><td>4.1ms</td><td>2.5ms</td></tr><tr><td>flaskblogging p99 latency</td><td>6.3ms</td><td>5.2ms</td><td>5.8ms</td></tr><tr><td>flaskblogging memory usage</td><td>47MB</td><td>54MB</td><td>228MB</td></tr><tr><td>djangocms warmup time [1]</td><td>n/a</td><td>n/a</td><td>105s</td></tr><tr><td>djangocms mean latency</td><td>14.1ms</td><td>11.8ms</td><td>15.9ms</td></tr><tr><td>djangocms p99 latency</td><td>15.0ms</td><td>12.8ms</td><td>179ms</td></tr><tr><td>djangocms memory usage</td><td>84MB</td><td>91MB</td><td>279MB</td></tr><tr><td>Pylint speedup</td><td>1x</td><td>1.16x</td><td>0.50x</td></tr><tr><td>mypy speedup</td><td>1x</td><td>1.07x [2]</td><td>unsupported</td></tr><tr><td>PyTorch speedup</td><td>1x</td><td>1.00x [2]</td><td>unsupported</td></tr><tr><td>PyPy benchmark suite [3]</td><td>1x</td><td>1.36x</td><td>2.48x</td></tr></tbody></table><figcaption>Results were collected on an m5.large EC2 instance running Ubuntu 20.04</figcaption></figure>



<p>[1] Warmup time is defined as time until the benchmark reached 95% of peak performance; if it was not distinguishable from noise it is marked “n/a”.  Only post-warmup behavior is considered for latency measurement.<br>[2] mypy and PyTorch don’t support automatically building their C extensions from source, so these Pyston numbers use our unsafe compatibility mode<br>[3] The PyPy benchmark suite was modified to only run the benchmarks that are compatible with Python 3.8</p>



<h2>Results analysis</h2>



<p>In our targeted benchmarks (djangocms + flaskblogging), Pyston v2 provides an average 1.22x speedup for mean latency and an 1.18x improvement for p99 latency while using a just few more megabytes per process.  We have not yet invested time in optimizing the other benchmarks.</p>



<p>“p99 latency” is the upper 99th percentile of the response-time distribution, and is a common metric used in web serving contexts since it can provide insight into user experience that is lost by taking an average.  PyPy’s high p99 latency on djangocms comes from periodic latency spikes, presumably from garbage collection pauses.  CPython and Pyston both exhibit periodic spikes, presumably from their cycle collectors, but they are both less frequent and much smaller in magnitude.</p>



<p>The mypy and PyTorch benchmarks show a natural boundary of Pyston v2. These benchmarks both do the bulk of their work in C extensions which are unaffected by our Python speedups.  We natively support the C API and do not have an emulation layer, so we are still able to provide a small boost to mypy performance and do not degrade pytorch or numpy performance.  Your benefit will depend on your mix of Python and C extension work.</p>



<h2>Technical approach</h2>



<p>We’re planning on going into more detail in future blog posts, but some of the techniques we use in Pyston v2 include:</p>



<ul><li>A very-low-overhead JIT using <a href="https://luajit.org/dynasm.html">DynASM</a></li><li><a href="https://bugs.python.org/issue14757">Quickening</a></li><li>General CPython optimizations</li><li>Build process improvements</li></ul>



<h2>Compatibility</h2>



<p>Since Pyston is a fork of CPython, we believe it is one of the most compatible alternative Python implementations available today.  It supports all the same features and C API that CPython does.</p>



<p>While Pyston is identically functional in theory, in practice there are some temporary compatibility hurdles for any new Python implementation.  Please see <a href="https://github.com/pyston/pyston/wiki">our wiki</a> for details.</p>



<h2 id="availability">Availability</h2>



<p>Pyston v2.0 is <a href="https://github.com/pyston/pyston/releases">immediately available</a> as a pre-built package.  Currently, we have packages for Ubuntu 18.04 and 20.04 x86_64.  If you would like support for a different OS, let us know by filing an issue in our <a href="https://github.com/pyston/pyston/issues">issue tracker</a>.</p>



<p>Trying out Pyston is as simple as installing our package, replacing <code>python3</code> with <code>pyston3</code>, and reinstalling your dependencies with <code>pip-pyston3 install</code> (though see our <a href="https://github.com/pyston/pyston/wiki">wiki</a> for a known issue about setuptools). If you already have an automated build set up, the change should be just a few lines.</p>



<p>Our plan is to open-source the code in the future, but since compiler projects are expensive and we no longer have benevolent corporate sponsorship, it is currently closed-source while we iron out our business model.</p>



<h2>Reaching us</h2>



<p>We are designing Pyston for developers and love to hear about your needs and experiences.  So, we’ve set up a <a href="https://discord.gg/S7gsqnb">Discord server</a> where you can chat with us.  If you’d like a commercially-supported version of Pyston, please <a href="mailto:business@pyston.org">send us an email</a>.</p>



<p>We’ve optimized Pyston for several use cases but are eager to hear about new ones so that we can make it even more beneficial.  If you run into any problems or instances where Pyston does not help as much as expected, please let us know!</p>



<h2>Background</h2>



<p>We designed Pyston v1 at Dropbox to speed up Python for its web serving workloads.  After the project ended, some of us from the team brainstormed how we would do it differently if we were to do it again.  In early 2020, enough pieces were in place for us to start a company and work on Pyston full-time.</p>



<p>Pyston v2 is inspired by but is technically unrelated to the original Pyston v1 effort.</p>



<h2>Moving forward</h2>



<p>We’re on a mission to make Python faster and have plenty of ideas to do so.  That means we’re actively looking for people to join the team.  <a href="https://discord.gg/S7gsqnb">Let us know</a> if you’d like to get involved.  Otherwise stay tuned for future releases and reach out if you have any questions!</p>
			</div><!-- .entry-content -->

	<!-- .entry-meta -->
</article><!-- #post-## -->
			</div>

				<nav role="navigation" id="nav-below">
		

	
				
	
	</nav><!-- #nav-below -->
	
			
<!-- #comments -->

		
		</main><!-- #main -->
	</div><!-- #primary -->

					<!-- #secondary -->
	
	</div></div>]]>
            </description>
            <link>https://blog.pyston.org/2020/10/28/pyston-v2-20-faster-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24921790</guid>
            <pubDate>Wed, 28 Oct 2020 17:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Justin Borgman, CEO of Starburst, the Company Behind the Presto Project]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24921725">thread link</a>) | @via_hacker
<br/>
October 28, 2020 | https://opensourceunderdogs.com/episode-54-starburst-justin-borgman/ | <a href="https://web.archive.org/web/*/https://opensourceunderdogs.com/episode-54-starburst-justin-borgman/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><strong>Mike:</strong>&nbsp;Hello, and welcome to Open Source Underdogs. I’m your host Mike Schwartz, and this is the episode 54, with Justin Borgman, Chairman, CEO, and Co-Founder of Starburst, the company behind the Presto Data Access Project.</p><p>Before we get started, I have a quick request – we all want to help open-source founders and startups. I make the podcast, but I need your&nbsp;<strong>help to get the word out</strong>, so tell your friends, post on LinkedIn, tweet out a link,&nbsp;<strong>post on Hacker News</strong>, or&nbsp;<a href="https://www.linkedin.com/in/nynymike">follow me</a>&nbsp;and share one of my posts on LinkedIn, whatever you think makes sense, go for it. </p><p>One of the themes of Machiavelli’s the Prince is <i>Virtu e Fortuna<i>—<i>virtu</i> meaning excellence in your domain, and <i>fortuna</i> meaning luck, whether good or bad. I really like how the story of Starburst exemplifies this 500-year-old insight.</i></i></p><p><i><i>



<p><br>Justin has a ton of domain <i>virtu</i>. He has deep technical knowledge, but he’s also on the lookout to harness fortuna. He’s one of the few podcast guests to acknowledge it. And Starburst earns its name because it’s one of the most stellar open-source business success stories I’ve heard in the last few years.<br>There’s so many great insights in this episode, a lot to think about. So, without further ado, let’s get on with the interview.</p>



<h3>What Is Presto?</h3>



<p><strong>Mike:</strong> Justin, thanks for
joining the podcast today.</p>



<p><strong>Justin:</strong> Hey, Mike, super glad
to be with you.</p>



<p><strong>Mike:</strong>&nbsp;Before we dive into the business stuff, I find it’s helpful
to talk a little bit about the technology. Can you start by giving a brief
history of the Presto project? What it’s good at, and how the community
coalesced around it?</p>



<div><p><strong>Justin:</strong> It was really back in 2012 for developers at Facebook, Martin, Dain, David, and Eric came together to create a new infrastructure project that would be a faster way of querying data at Facebook. Facebook, of course, collects massive amounts of data, hundreds of petabytes worth of data , and needed a faster alternative to a prior project that they also developed and they called Hive.</p><p> Hive was a SQL engine for Hadoop, and it just wasn’t fast enough. So, Presto was created to be a faster means of accessing that data. But it has one really important differentiation in addition to the speed, which is the ability to access data anywhere. So, it’s like a database without storage – that’s kind of one way to think about it. </p></div>



<p>So, it looks at storage in other systems, which could be Hadoop, it could be S3 and AWS, it could be a traditional database, like Oracle, or Teradata, or Snowflake. And regardless of where that data lives, Presto can reach it, query it, and deliver SQL-based analytics. </p>



<p>So, that’s kind of what makes it special, is the ability to access the data everywhere. And that’s gained particular momentum, I would say more recently, as many large enterprises have data silo problems, where they have data in a bunch of different databases, and are now perhaps moving to the Cloud in some fashion.</p>



<div><p><strong>Mike:</strong> And if I’m not mistaken, high concurrency is one of the areas that make sort of this data access plain different?</p><p> <strong>Justin:</strong>&nbsp;Yes, exactly, it’s very fast, and can support high concurrency. And in a lot of ways, this technology was sort of, I like to say built in reverse, in the sense that it was tested at ridiculous scale from day one. You know, very often, when you start something new, you don’t really know how it’ll work at scale until you get people using it. But because it was really born out of the internet companies, Facebook, and Uber, Airbnb, and Netflix were all early adopters to use the technology, it was really tested, and at scale, and as a result delivers great performance and concurrency.</p></div>



<h3>Origin Story</h3>



<div><p><strong>Mike:</strong>&nbsp;Starburst is not your first company, you are part of a team
at the company called Hadapt that’s sold to Teradata in about three and a half
years, I think.</p><p>

<strong>Justin: </strong>Yep.</p></div>



<p><strong>Mike:</strong> How did that experience lead you to Presto?</p>



<p><strong>Justin:</strong> In a lot of ways, this is really a continuation of that journey that began 10 years ago. So, that was 2010 that I started Hadapt. Hadapt was a spin-out actually from Yale University and the computer science department – there’s some research called HadoopDB, which was pretty pioneering research at the time, in terms of thinking about Hadoop as a data warehousing solution, and being able to deliver fast SQL analytics on top of Hadoop.</p>



<p>So, we spun that out, raised Venture Capital, built that business over nearly four years, as you mentioned, and then sold it to Teradata. We had ups and downs, definitely lessons learned through that experience. And I think, really, my discovery of Presto after arriving at Teradata in 2014 was kind of an exciting opportunity to reimagine the strategy that we had with Hadapt. </p>



<p>So, Hadapt was the SQL engine for Hadoop, Presto is a SQL engine for anything essentially, allows you to access data anywhere.it was an opportunity to basically take all the lessons learned from the first experience and start to apply them over again.</p>



<p>It was actually my team from Hadapt that ended up contributing a tremendous amount of software to Presto, and working with the guys at Facebook, who created it to really make it an enterprise-grade piece of technology. And I think, as we started to see Presto get more and more capable, and see more and more people use it, that was what created the idea in our head that maybe there was a business to be formed around this.</p>



<h3>Community Engagement</h3>



<p><strong>Mike:</strong>&nbsp;It’s a really interesting opportunity, and I can’t actually think of another example like it, but when I’m talking about open source, I sometimes talk about three types of open-source companies. One would be volunteer, where a bunch of guys or girls get together and write some piece of software that they love, but not necessarily for a business.</p>



<p>And then, I talk about corporate open source, where there’s some piece of software, where a company funds it, but it’s not their core business, but then, they realize that makes sense for them to collaborate like Kubernetes, let’s say ,and Google, and these pure-play, open-source companies, where the company behind it is developing it, and they’re the main contributors.</p>



<p><br>And so, lots of great open-source projects come out of this corporate open-source area, the podcast that is mostly focused on pure-play because they were trying to help entrepreneurs and founders start open source, use open source as part of their business model. But you’ve sort of, like, created a very interesting situation, where you have a mix of corporate and pure-play because you’re benefiting from, not just the community, but, really, Facebook is a big contributor to the project to — I heard almost 50/50. So, how’s that really evolved, and how do you continue to encourage this very symbiotic relationship?</p>



<p><br><strong>Justin:</strong> You’re right. Preston has a very interesting history to it, an interesting journey. It started as a small project at Facebook. When we got involved at Teradata, we were able to apply a few million dollars a year of R&amp;D budget into advancing that as well. And then, of course, you’ve got a few other companies contributing also along the way.</p>



<p>And, as a result, all of that kind of accelerates the development of the project. And I think that maybe what’s most unique here is not only that Facebook created great infrastructure software as a byproduct of their business – they’ve certainly done that before – but rather that there was kind of a commercial partner very early on, and myself, and my team at Teradata thinking about the commercial applications of this.</p>



<p>So, you know, back in 2014, Presto was still in its early days, Facebook wasn’t trying to monetize it obviously, that’s not their business, but we were already thinking about how this could be used by Fortune 500 customers, and what difference this could make to their business. And I think that led to its very enterprise-applicable evolution, and set us up really well to eventually commercialize this in 2017, when we left Teradata, the creators of Presto joined us from Facebook. And we went off on our way to build this business.</p>



<h3>Idea Incubation</h3>



<div><p><strong>Mike:</strong>&nbsp;So, you were working on Presto while you’re at Teradata. And did Teradata ask for any equity, or how did that work when you told Teradata, “We want to start this company basically working at Teradata? Like, what was that like?</p><p> <strong>Justin:</strong>&nbsp;Yeah, well, what was interesting about that – and I guess just to set the context, I think Teradata, from 2014, when they acquired my company through to probably today, has gone through various iterations of kind of rethinking their overall strategy, in terms of how they evolved into this next generation of sort of Big Data platforms. Because they had great success in the ‘80s, ‘90s, and early 2000s, as this kind of monolithic data warehouse, where you would ingest everything and store it in one place. </p></div>



<p>But obviously that became very expensive over time. And the appliance model, hardware and software combined, wasn’t necessarily set up for this future as people move to the cloud. So, they’ve gone through a lot of iterations. And it was really in that iterative process, where they weren’t really clear where they wanted to go, that they actually felt like Presto is maybe a distraction for them.</p>



<div><p>So, that actually created the opportunity, I think, for us, to say, well, we think it’s a little more than a distraction. And, you know, we’d be happy to sort of take that off your hands and work on this together.</p><p> So, it was a very amicable split – we remain partners, we’re still partners today, where we work together on some customer accounts, the technologies work together, we can access data in Teradata, for example, from Presto. So, that partnership remains. But it was one that I think for them, they viewed us as sort of taking Presto off their hands because there were maybe close to a dozen companies within their customer base that were using Presto. So, we were able to deliver really first-class support to …</p></div></i></i></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://opensourceunderdogs.com/episode-54-starburst-justin-borgman/">https://opensourceunderdogs.com/episode-54-starburst-justin-borgman/</a></em></p>]]>
            </description>
            <link>https://opensourceunderdogs.com/episode-54-starburst-justin-borgman/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24921725</guid>
            <pubDate>Wed, 28 Oct 2020 17:37:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby's Proposed STM]]>
            </title>
            <description>
<![CDATA[
Score 152 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24921657">thread link</a>) | @chrisseaton
<br/>
October 28, 2020 | https://chrisseaton.com/truffleruby/ruby-stm/ | <a href="https://web.archive.org/web/*/https://chrisseaton.com/truffleruby/ruby-stm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<header>

<h2><a href="https://chrisseaton.com/">Chris Seaton</a>, 28 October 2020</h2>


</header>

<p>There’s a proposal to add <em>Software Transactional Memory</em>, or <em>STM</em>, to the Ruby programming language. This is part of a wider effort to add better support for concurrency and parallelism in Ruby, and in particular the idea of <em>ractors</em>. A concept has been <a href="https://bugs.ruby-lang.org/issues/17261">proposed</a> and <a href="https://github.com/ruby/ruby/pull/3652">implemented</a> by Koichi Sasada.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/testBoard.gif" width="50%">
<figcaption>An animation of the algorithm we're going to use as an example of STM - we'll explain this later on</figcaption>
</figure>

<p>This article gives some context on what STM is, how you use it, and why you might want to use it. We’ll show an application which is well-suited to STM and we’ll use this to talk about the benefits, issues, and some open questions.</p>

<p>We’ll finish by setting a challenge for STM in Ruby.</p>

<p>I wrote the first half of my PhD on STM, and the second half on Ruby, so I’ve got quite a bit of experience with both and the idea of their combination is very interesting to me.</p>

<h2 id="why-might-we-want-an-stm">Why might we want an STM?</h2>

<p>Let’s say we’re a bank managing many bank accounts. Each account has a total. We get a never-ending stream of requests to move a sum of money <code>m</code> from an account <code>a</code> to account <code>b</code>.</p>

<div><div><pre><code><span>loop</span> <span>do</span>
  <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
  <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
  <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
<span>end</span>
</code></pre></div></div>

<p>Something not everyone may know about Ruby is that <code>x += y</code> is equivalent to writing <code>t = x; x = t + y</code>. We’ll write that out in full to make that clear to ourselves.</p>

<div><div><pre><code><span>loop</span> <span>do</span>
  <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
  <span>a_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
  <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>a_balance</span> <span>-</span> <span>m</span>
  <span>b_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>b</span><span>]</span>
  <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>=</span> <span>b_balance</span> <span>+</span> <span>m</span>
<span>end</span>
</code></pre></div></div>

<p>We’ve got a lot of transfers to run through, so we’ll have multiple threads processing these transfers.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>a_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
      <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>a_balance</span> <span>-</span> <span>m</span>
      <span>b_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>b</span><span>]</span>
      <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>=</span> <span>b_balance</span> <span>+</span> <span>m</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>We’ve got a few problems here now. With all these threads running at the same time, what happens if two threads are putting money into your account concurrently?</p>

<div><div><pre><code><span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>100</span>

<span># thread 1                        # thread 2</span>
<span>balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
  <span># balance = 100</span>
                                  <span>balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
                                    <span># balance = 100</span>
<span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>balance</span> <span>+</span> <span>10</span>
  <span># accounts[a] = 110</span>
                                  <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>balance</span> <span>+</span> <span>10</span>
                                    <span># accounts[a] = 110</span>
</code></pre></div></div>

<p>The two transfers have run, but your balance is 110. The other 10 has been lost - this is called a <em>lost update</em>, meaning it’s as if the update was never made.</p>

<p>Also consider what happens if the thread crashes after taking money from <code>a</code> but before putting it into <code>b</code>? The transfer would be applied partially and again we’d lose money.</p>

<p>We need to use some kind of <em>synchronization</em> on our accounts. Ruby has <em>mutual exclusion locks</em> or <em>mutexes</em>, so we can try using those.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>locks</span><span>[</span><span>a</span><span>].</span><span>synchronize</span> <span>do</span>
        <span>locks</span><span>[</span><span>b</span><span>].</span><span>synchronize</span> <span>do</span>
          <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
          <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Does this work? What if we process a transfer from account 1001 to account 1002 on one thread at the same time as processing a transfer from account 1002 to 1001, so the other way around, at the same time?</p>

<p>The first thread will try to lock 1001 and then 1002. The second thread will try to lock 1002 and then 1001. If the first thread gets as far as locking 1001, and the second as far as locking 1002, then both will be waiting for the opposite lock and will never release the lock they already have. We will be in <em>deadlock</em>.</p>

<p>If we always acquired locks in the same order, by collecting them up first and sorting them, we could fix this.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>x</span><span>,</span> <span>y</span> <span>=</span> <span>[</span><span>a</span><span>,</span> <span>b</span><span>].</span><span>sort</span>
      <span>locks</span><span>[</span><span>x</span><span>].</span><span>synchronize</span> <span>do</span>
        <span>locks</span><span>[</span><span>y</span><span>].</span><span>synchronize</span> <span>do</span>
          <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
          <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Now in both transfers account 1001 is locked first and 1002 is locked second. That will work.</p>

<p>We have to make up a somewhat artificial requirement to explain the next issue, but consider if for some good reason we wanted to transfer to one account if we had a lot of money, and a different account if we only had a little money. Maybe if we’re rich this month we donate to charity, otherwise we unfortunately need to save for ourselves.</p>

<div><div><pre><code>if account balance &gt; 1000
  transfer 10 to charity
else
  transfer 10 to savings
end
</code></pre></div></div>

<p>We’ll talk about accounts <code>a</code>, <code>b</code>, and <code>c</code>, now, and a threshold of money <code>t</code>.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>,</span> <span>t</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>x</span><span>,</span> <span>y</span><span>,</span> <span>z</span> <span>=</span> <span>[</span><span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>].</span><span>sort</span>
      <span>locks</span><span>[</span><span>x</span><span>].</span><span>synchronize</span> <span>do</span>
        <span>locks</span><span>[</span><span>y</span><span>].</span><span>synchronize</span> <span>do</span>
          <span>locks</span><span>[</span><span>z</span><span>].</span><span>synchronize</span> <span>do</span>
            <span>if</span> <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>&gt;</span> <span>t</span>
              <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
              <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
            <span>else</span>
              <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
              <span>accounts</span><span>[</span><span>c</span><span>]</span> <span>+=</span> <span>m</span>
            <span>end</span>
          <span>end</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>It’s starting to get very complicated. And this locks more than it needs to - it locks both <code>b</code> and <code>c</code> but then only uses one of them. If you use <code>b</code> in the end, ideally another thread could be serving a transfer to <code>c</code> at the same time, but you’ve locked it and it can’t. Imagine if instead of two potential accounts it was thousands and you had to lock them all. Imagine if you couldn’t work out at all which account you’d be transferring to until you started the transfer - then you’d never be able to process two transfers at the same time.</p>

<p>At this point as well we’re likely to start to make errors trying to do all this locking and ordering of locks and things.</p>

<p>Stepping back and taking it all in, we can draw up some requirements for what we need.</p>

<ul>
  <li><em>atomicity</em> - that all writes in the transfer are applied or none are applied</li>
  <li><em>consistency</em> - meaning that our data structures are always valid - the total sum of money never changes</li>
  <li><em>isolation</em> - meaning one transfer does not interfere with another</li>
  <li><em>durability</em> - meaning that when applied the transfer is available to all subsequent transactions</li>
</ul>

<p>Ideally a library or the language could do this all for us. We’d like to be able to write almost what we originally wrote, but with just an annotation to make the code inside a block atomic, consistent, isolated, and the result durable.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>atomically</span> <span>do</span>
        <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
        <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>This is what a <em>transactional</em> memory can let us do. It will automatically monitor what you read and write inside the <code>atomically</code> block, which is a <em>transaction</em>, and will make sure it is either applied fully or not, that the balance of the whole system is always consistent, that transactions do not see the result of each other partially applied, and that writes appear and stay.</p>

<p>It may be implemented using the code we eventually arrived at ourselves, or it could do something else instead. In practice how it is often implemented is that
reads and writes are stored in a log, then at the end the transaction works out if anyone else has written locations that you’ve read. If they have then the values you read are no longer valid, so your transaction <em>conflicts</em> with another, is <em>aborted</em> and retries, reading the locations again. When it eventually does not conflict with any other transactions it is <em>committed</em> and succeeds. This means you don’t need to lock everything up-front, which means you avoid the problem of what happens if you may potentially need every account. Locking everything up-front is called <em>pessimistic locking</em>. We’re moving to <em>optimistic locking</em></p>

<h2 id="the-proposed-stm">The proposed STM</h2>

<p>Koichi’s <a href="https://bugs.ruby-lang.org/issues/17261">proposed</a> STM for Ruby, in combination with his proposed <em>ractors</em> (similar to <em>actors</em>) would look like this.</p>

<div><div><pre><code><span>accounts</span> <span>=</span> <span>9999</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>Thread</span><span>::</span><span>TVar</span><span>.</span><span>new</span><span>(</span><span>100</span><span>)</span> <span>}</span>

<span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span> <span>*</span><span>accounts</span> <span>do</span> <span>|*</span><span>accounts</span><span>|</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>Thread</span><span>.</span><span>atomically</span> <span>do</span>
        <span>accounts</span><span>[</span><span>a</span><span>].</span><span>value</span> <span>-=</span> <span>m</span>
        <span>accounts</span><span>[</span><span>b</span><span>].</span><span>value</span> <span>+=</span> <span>m</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>He’s using a <code>Ractor</code> but you can think of it as a thread for the purposes of this article. Instead of an array of account balances, we now have an array of <code>TVar</code> objects that contain values. A <code>TVar</code> is a <em>transactional variable</em>. Only these variables are transactional - not any other Ruby value you read or write. His design requires that the <code>TVar</code> objects you’re going to use are passed into the <code>Ractor</code>, due to rules about sharing that aren’t relevant for this article.</p>

<p>This looks good, doesn’t it!</p>

<h2 id="a-more-complex-application">A more complex application</h2>

<p>Let’s consider a larger application, in order to illustrate further and to talk about some issues and open questions. The <a href="https://github.com/chrisseaton/ruby-stm-lee-demo">code is available on GitHub</a>.</p>

<p>Let’s say it’s our job to lay out the wires on a circuit board. We get a board with <em>pads</em> (connections to components mounted on the board) and a list of <em>routes</em> that we need to draw between these pads. There are a great many pads and routes, there isn’t much space on the tiny board, and another catch is that it’s very expensive to have wires crossing each other. Let’s say it’s exponentially more expensive for more deeply stacked wires.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/minimal.svg" width="25%">
<figcaption>A minimal board and a solution</figcaption>
</figure>

<p>In this minimal example we we can see two routes, and how they have to cross each other.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/mainboard.svg" width="50%">
<figcaption>A processor module board and a solution</figcaption>
</figure>

<p>This example is a processor module and shows what kind of scale we might want to be working at. This board has many longer routes which are more likely to conflict.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/memboard.svg" width="50%">
<figcaption>A memory module board and a solution</figcaption>
</figure>

<p>This example is a memory module. It has many shorter routes which we may expect to conflict less.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/testBoard.svg" width="50%">
<figcaption>The test board we'll use and a solution</figcaption>
</figure>

<p>We’ll use this test board, which is somewhere between all these extremes.</p>

<p>There’s an algorithm to lay each routes, and it actually produces an optimal solution for an individual route, but not for all routes. It’s called <em>Lee’s algorithm</em> and was published back in 1960. We’ll …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrisseaton.com/truffleruby/ruby-stm/">https://chrisseaton.com/truffleruby/ruby-stm/</a></em></p>]]>
            </description>
            <link>https://chrisseaton.com/truffleruby/ruby-stm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24921657</guid>
            <pubDate>Wed, 28 Oct 2020 17:32:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking Ideas Seriously Is Hard]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24921635">thread link</a>) | @neilkakkar
<br/>
October 28, 2020 | https://neilkakkar.com/taking-ideas-seriously.html | <a href="https://web.archive.org/web/*/https://neilkakkar.com/taking-ideas-seriously.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Most people don’t practice taking ideas seriously. I think it’s because most people don’t know how to. I didn’t either, until I stumbled upon an implication.</p>

<p>For example, what would it mean to take compounding seriously?</p>

<p>Ugh. I can feel your aversion. You’ve already heard so much about compounding, how it works, how it’s the eight wonder of the world, etc. etc.</p>

<p>But, familiarity is not the same as taking it seriously.</p>

<p>Say you start with $100, and every year, make 10% more. This compounds, since the extra money is a function of how much you already have. The more you have, the more you get. It’s a positive loop that keeps on increasing.</p>

<p>That’s the familiar interpretation. The earlier you start, the more money you’ll make.</p>

<p>To take this interpretation seriously would mean investing your earnings for a similar return. <a href="http://johnsalvatier.org/blog/2017/reality-has-a-surprising-amount-of-detail" target="_blank" rel="noopener">Reality has a surprising amount of detail</a>, and sometimes assumptions break. You don’t make 10% - which means you need to balance your investments somehow. That makes things complicated. However, this complication is not related to compounding.</p>

<p>Taking compounding seriously means taking it a step further. Your net worth is just one implication. What else compounds?</p>

<p>Your life experiences and knowledge. What would it mean to leverage compounding here?</p>

<p>If you’re taking compounding seriously, you’d learn the skills with the greatest return first. That means learning the broadest applicable skills you’d apply throughout your life first. That means learning how to think well - before learning the new fancy tech you want to learn.</p>

<p>Of course, sometimes you need a medium to learn the skill better. That makes sense: learn to think well via this new tech you wanted to learn. <a href="https://www.lesswrong.com/s/3HyeNiEpvbQQaqeoH" target="_blank" rel="noopener">Purposes are fragile</a> though, and it’s easy to get lost in the tool, instead of the overall goal.</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>

<p>What makes this example so good is that you’re probably very familiar with compounding. What else are you familiar with, but haven’t realised you’re not taking seriously?</p>

<p>A good way to practice this is to ask this question: What are the implications of (idea) in (field of interest)?</p>

<p>For example, asking myself What are the implications of compounding for my self-directed knowledge base led to the above insight of learning broader skills first.</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>

<p>You can reply to this post <a href="https://twitter.com/neilkakkar/status/1321126261775847424" target="_blank" rel="noopener">here</a>.</p><p>

    
      You can <a href="" onclick="return sendEmail(&quot;Taking Ideas Seriously is Hard&quot;, &quot;https://neilkakkar.com/taking-ideas-seriously.html&quot;)">send yourself an email</a> 
      with this post.
      

    
  </p></div></div>]]>
            </description>
            <link>https://neilkakkar.com/taking-ideas-seriously.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24921635</guid>
            <pubDate>Wed, 28 Oct 2020 17:30:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Hire the Right Blockcahin Developer for Your Project?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24921563">thread link</a>) | @4ire-natalie
<br/>
October 28, 2020 | https://4irelabs.com/blog/articles/how-to-hire-blockchain-developer/ | <a href="https://web.archive.org/web/*/https://4irelabs.com/blog/articles/how-to-hire-blockchain-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <!-- wp:paragraph -->
<p>The blockchain industry is one of the few where the demand exceeds the offer. A couple of years ago, the number of blockchain developers was 171 times smaller than the total number of software developers and the total worth of the blockchain market is expected to reach<a href="https://www.statista.com/statistics/647231/worldwide-blockchain-technology-market-size/"> $39.7 billion by 2025</a>. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>There is no doubt that the main demand is and will be coming from the financial sector, however, the<a href="https://igniteoutsourcing.com/blockchain/blockchain-use-cases-by-industry/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> diversified applications of the technology</a> in numerous markets (from retail to entertainment, from aviation to insurance) only inflames the need for qualitative blockchain experts in the world.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>The increased interest in the profession has spiked the salaries in the industry, so beware that a professional blockchain developer will have a 3-digit salary right from the start. When hiring a blockchain developer or a team, there are particular steps in the process that are distinct from the traditional recruitment of a software developer or engineer. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Below you can go through the table of contents with the tips and recommendations on hiring the right blockchain developer for your team. Click on the section, and begin learning the insights of the process.&nbsp;</p>
<!-- /wp:paragraph -->

<!-- wp:image {"align":"center","id":764,"sizeSlug":"large"} -->
<div><figure><img src="https://4irelabs.com/blog/wp-content/uploads/2020/10/hiring-blockchain-developers-1024x646.png" alt="blockchain experts"></figure></div>
<!-- /wp:image -->

<!-- wp:heading -->
<h2><strong>Is there a demand for blockchain developers</strong><strong>?</strong></h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>U.S. Bureau of Labor Statistics<a href="https://www.bls.gov/emp/tables/fastest-growing-occupations.htm" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> included developers</a> in the list of the fastest-growing occupations in 2019-2029. LinkedIn said that<a href="https://business.linkedin.com/talent-solutions/blog/trends-and-research/2020/most-in-demand-hard-and-soft-skills" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> blockchain is #1 needed hardskill</a> in 2020.<a href="https://hired.com/state-of-software-engineers#hottest-jobs" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> Hired</a> named blockchain engineers the “dark horses” of 2019 and confirmed the increasing demand for these specialists in 2020 as well. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Investors put more and more money into blockchain development, companies like Facebook, Amazon, Oracle, Toyota, Shell, Walt Disney, IBM, and many others have already turned to blockchain for their day-to-day operations in the financial sector. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>And if the<a href="https://www.forbes.com/sites/forbespr/2020/02/19/forbes-releases-2nd-annual-blockchain-50-list-of-companies-embracing-the-technology-underlying-cryptocurrencies/#1506ebcd17c5" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> top fortune companies</a> turn to this technology setting the trend for the rest of the world, then there is no doubt that the demand for blockchain developers exists, and it continues to rise every year.</p>
<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2><strong>Where can I find Blockchain developers</strong><strong>?</strong></h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>Blockchain developers are not ordinary programmers and you probably won’t find one on Facebook, LinkedIn, or any ordinary job-listing website. Their number is still not enough to satisfy the demand of the existing market so you should not expect an easy hiring process here. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Most likely, the search for the developer will look like renting an apartment in Germany: you come with your offer to the developers and they select the most interesting/well-paid/promising offer. And just like future tenants, you can only hope to be selected by the chosen blockchain developer.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>However, the situation in 2020 is not as bad as it might seem. To get the right blockchain programmers for a project, you simply need to look in the right places. Below is a list of potential places (online and offline) where good blockchain developers can be found:</p>
<!-- /wp:paragraph -->

<!-- wp:heading {"level":3} -->
<h3>Meeting places</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>Yes, all developers and tech people have their own meeting places in the context of a digital forum where like-minded programmers discuss blockchain-related topics. Most often they are similar to<a href="https://github.com/blockchain" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> GitHub</a>,<a href="https://www.reddit.com/r/CryptoTechnology/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> Reddit</a>, or<a href="https://www.ieee.org/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> IEEE Blockchain Community</a>. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>These are platforms, websites, and forums where developers share their ideas, discuss new trends, and test new possibilities. You can get to one of these places and ask a couple of members if they would be interested in your offer.</p>
<!-- /wp:paragraph -->

<!-- wp:image {"align":"center","id":765,"sizeSlug":"large"} -->
<div><figure><img src="https://4irelabs.com/blog/wp-content/uploads/2020/10/hiring-experts-1024x646.png" alt="hire experts"></figure></div>
<!-- /wp:image -->

<!-- wp:heading {"level":3} -->
<h3>Conferences</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>While due to COVID-19 conferences had to convert into the online format, they still happen. And the interested, progressive, and iconic blockchain developers do attend such events. So you can search for the upcoming events to participate and communicate with its participants. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>In-person hiring in this case would go smoother and much easier, yet even while talking online, you still stand a chance to get the right developer for your project or startup. Here is a couple of upcoming events for consideration:</p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul><li><a href="https://blockchainlive.com/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Blockchain Live 2020</a></li><li><a href="https://www.decentralized.com/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Decentralized</a></li><li><a href="https://www.maltablockchainsummit.com/events/general-info/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Annual Malta AI &amp; Blockchain Summit</a></li><li><a href="https://blockchain-expo.com/europe/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Blockchain Expo Europe</a></li></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p>You can also check the up-to-date schedule of the upcoming events in the crypto-world<a href="https://www.coindesk.com/bitcoin-events" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> here</a>.</p>
<!-- /wp:paragraph -->

<!-- wp:heading {"level":3} -->
<h3>Schools</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>Most<a href="https://www.bitrates.com/news/p/the-top-five-universities-offering-blockchain-courses" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> top schools</a> and universities turned to blockchain development because a lot of students in the technological departments wish to become a blockchain developer and earn a fortune,&nbsp; especially when the demand is only rising. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>This is a perfect place for large corporations and startups to find their next employee. Corporations can contact the school and offer to sponsor the best student; as a result, they can get the perfect young mind that will solemnly focus on their needs after graduation. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>For startups, schools are the perfect place to get a like-minded genius who will become a part of the young team and will work to get experience, knowledge, and real-life interaction based on the knowledge from school. Here are the best courses for cryptocurrency to get started:</p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul><li>Harvard’s<a href="https://online-learning.harvard.edu/course/introduction-blockchain-and-bitcoin?delta=0" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> Introduction to Blockchain and Bitcoin</a></li><li>Princeton’s&nbsp; <a href="https://online.princeton.edu/node/206" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Bitcoin and Cryptocurrency Technologies</a></li><li>IT University of Copenhagen’s<a href="https://en.itu.dk/news?tag=%7BD5792F5A-70B2-4D49-8236-AE6A81626943%7D" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> Blockchain</a></li><li>University of London’s <a href="https://requestinfo.onlinecourses.london.ac.uk/index-us.html?s=collegedegreesdtsulbusmgmt&amp;l=accountingdegreeorg&amp;send_id=3733&amp;c=management&amp;ef_id=222131343&amp;utm_content=management&amp;utm_source=collegedegreesdtsulbusmgmt&amp;email_id=null&amp;utm_campaign=accountingdegr" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">online courses</a></li><li>Berkley’s<a href="https://blockchain.berkeley.edu/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> Blockchain Research</a></li></ul>
<!-- /wp:list -->

<!-- wp:heading {"level":3} -->
<h3>Head-hunting websites for freelancers</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>At the beginning of this section, we said that usual listing websites are not the place for blockchain experts. Nonetheless, there are blockchain freelance platforms where an individual developer can easily be acquired. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>They include<a href="https://www.toptal.com/blockchain?dfh_uid=1" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> Toptal</a>,<a href="https://bountyone.io/?dfh_uid=1" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> BountyOne</a>,<a href="https://x-team.com/hire-blockchain-developers/?dfh_uid=1" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> X-Team</a>,<a href="https://www.stackoverflowbusiness.com/talent?dfh_uid=1" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> Stack Overflow</a>, or<a href="https://www.codementor.io/blockchain-developers?dfh_uid=1" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"> CodementorX</a>. These platforms<strong> </strong>can be of great help if you don’t know where to start your search and what conditions of cooperation to offer your potential developers. Here you can read what developers expect from their employers and so adjust your offer to the market.</p>
<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2><strong>Why is the developer in the industry?</strong></h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>Now that you know where to look for the blockchain developers, it is essential to understand why they are in business. Most broadly, these experts can be divided into two categories: <em>for the money</em> and <em>for the idea</em>. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Of course, it does not mean that developers interested in the idea of cryptocurrencies do not require payment; or that those who came into the industry to earn a living won’t have priceless ideas. The general division is important to ensure that you find your developer and that your goals and values match.</p>
<!-- /wp:paragraph -->

<!-- wp:heading {"level":3} -->
<h3>Developers for the Money</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>This “definition” is frequently applied to the 2<sup>nd</sup> and 3<sup>rd</sup> generation of blockchain developers. Those who understood that blockchain is the future and that the field of development is still undercovered in terms of resources. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Developers for the money do a quality job but will go into the project that pays more. So if you have a lucrative offer then you can be sure to get a good mind for the right money. This said, such developers will rarely look into the startup ideas unless they already have investors and lack just one element – a blockchain developer.</p>
<!-- /wp:paragraph -->

<!-- wp:image {"align":"center","id":766,"sizeSlug":"large"} -->
<div><figure><img src="https://4irelabs.com/blog/wp-content/uploads/2020/10/blockchain-developer-salary-1024x646.png" alt=""><figcaption><em>Source: https://hired.com/state-of-software-engineers</em> </figcaption></figure></div>
<!-- /wp:image -->

<!-- wp:heading {"level":3} -->
<h3>Developers for the Idea</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>Such a description is frequently applied to the first generation of blockchain developers, those who came into this field more than three-four years ago (before the world understood the true value of blockchain technologies). </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>These experts didn’t raise the questions on how to become a blockchain developer or what should I learn for blockchain developer; they were interested in the idea of developing something new, they were coding for the sake of coding. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Of course, most of these developers now have the top salaries in the industry. However, these people have still a fire in their eyes when they see a new idea. This means that developers for the idea can get into a not-well-paying project if the final product is great. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Moreover, there are also students of blockchain that also fall into this category; they will be willing to do the job almost for free only to get experience and understand how it works outside of the school walls.</p>
<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2><strong>What skills should the developer have?</strong></h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>Skillset for a programmer is the simple answer to the question “How can I be a Blockchain developer?” so frequently found on blockchain development for beginners. It is the particular set of skills and amount of knowledge that make a blockchain programmer stand out of the crowd.&nbsp;</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>In short, every blockchain developer must have a good understanding of blockchains concept, cryptography and cryptocurrencies, decentralized technologies, ledgers, the Ethereum network, ledgers, data security, and different programming languages. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Smart contracts are also considered to be the basic package in this field of development because even though these are related to the financial apps in most cases, understanding of this technology clarifies the general way crypto-world operates so helps with developing the right product.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Below we offer you a more complete answer with the details on every skill or tool a professional blockchain developer should have or know.</p>
<!-- /wp:paragraph -->

<!-- wp:heading {"level":3} -->
<h3>Basic programming concepts</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>A high-level understanding of JavaScript, Java, Node JS, C and C++, Python, Solidity, and Go is a must (depending on your project specification). Then search for an individual that:</p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul><li><strong>Worked with OOPS </strong>(Object-Oriented Programming Structure) because this structure allows for a quick program update whenever needed.</li><li><strong>Understands languages’ syntax </strong>since experience in working with a particular language and basic knowledge of one makes a difference when it comes to Dapps.</li><li><strong>Able to implement multi-threading</strong> in different types of applications.</li></ul>
<!-- /wp:list -->

<!-- wp:heading {"level":3} -->
<h3>Data structure</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>The data structure is the foundation of every app regardless of its connection to the blockchain. So choose a developer that knows and has worked with linked lists, hash tables, and acyclic graphs.</p>
<!-- /wp:paragraph -->

<!-- wp:heading {"level":3} -->
<h3>Encryption and security</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>Data security and encryption are among the top skill requirements for blockchain experts because every loss means leakage of information to the competition. In terms of security look for:</p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul><li><strong>SHA (Secure Hashing …</strong></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://4irelabs.com/blog/articles/how-to-hire-blockchain-developer/">https://4irelabs.com/blog/articles/how-to-hire-blockchain-developer/</a></em></p>]]>
            </description>
            <link>https://4irelabs.com/blog/articles/how-to-hire-blockchain-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24921563</guid>
            <pubDate>Wed, 28 Oct 2020 17:26:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HashiCorp Boundary: A Game Changing Infrastructure Access Solution]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24921481">thread link</a>) | @jsaundersdev
<br/>
October 28, 2020 | https://nextlinklabs.com/insights/hashicorp-releases-boundary-security-solution | <a href="https://web.archive.org/web/*/https://nextlinklabs.com/insights/hashicorp-releases-boundary-security-solution">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Last week, <a href="https://www.hashicorp.com/blog/hashicorp-boundary">HashiCorp announced the release of Boundary</a>, a game-changing infrastructure access solution aimed at helping developers, operators, and security teams maintain access controls for on-premises and cloud infrastructure.</p>
<p>Here at <a href="https://nextlinklabs.com/">NextLink Labs</a>, we couldn't be more excited about this security-minded offering. Being a company located at the heart between <a href="https://nextlinklabs.com/how-we-work">DevOps and Security</a>, we often encounter problems that, up until the release of  Boundary, required much more complicated tools and processes to solve. </p>
<p><a href="https://www.hashicorp.com/blog/why-we-built-hashicorp-boundary">Boundary is a tool built to make it simple to grant and maintain access to infrastructure</a>. In true HashiCorp fashion, Boundary accomplishes this in a way that can target any sort of infrastructure, including all the major cloud providers, Kubernetes, and on premise infrastructure. </p>
<p>Specifically, this tool enables access from a public user to many types of hosts and services located in a private network, and integrates with many existing Identity Providers such as Okta, Active Directory Federation Services, Active Directory, and more. </p>
<p><span>
      <a href="https://nextlinklabs.com/static/d9ed5cb6cd8462dd44d7058c00a10556/9569c/boundary1.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="HashiCorp Boundary Available Hosts and Services" title="HashiCorp Boundary Available Hosts and Services" src="https://nextlinklabs.com/static/d9ed5cb6cd8462dd44d7058c00a10556/c81eb/boundary1.png" srcset="https://nextlinklabs.com/static/d9ed5cb6cd8462dd44d7058c00a10556/a3406/boundary1.png 243w,
https://nextlinklabs.com/static/d9ed5cb6cd8462dd44d7058c00a10556/d5d05/boundary1.png 485w,
https://nextlinklabs.com/static/d9ed5cb6cd8462dd44d7058c00a10556/c81eb/boundary1.png 970w,
https://nextlinklabs.com/static/d9ed5cb6cd8462dd44d7058c00a10556/3100c/boundary1.png 1455w,
https://nextlinklabs.com/static/d9ed5cb6cd8462dd44d7058c00a10556/2b608/boundary1.png 1940w,
https://nextlinklabs.com/static/d9ed5cb6cd8462dd44d7058c00a10556/9569c/boundary1.png 2257w" sizes="(max-width: 970px) 100vw, 970px" loading="lazy">
  </a>
    </span></p>
<h3>The Challenge: Connecting Public Users to Private Resources Simply</h3>
<p>Most modern systems have resources located on a private network for which are going to need to be accessed by end users on a public network.  Examples are vast but a few simple ones are databases, web service hosts, kubernetes nodes, or something similar. </p>
<p>In order to grant users outside the network access to these resources, three things need to happen:</p>
<ul>
<li>A VPN or Bastion host needs set up as a gateway to bridge connections onto the resources</li>
<li>The connection must be restricted via firewall rules or similar so when you give a user access to the VPN or Bastion host they only have access to the resources they need and not the entire network</li>
<li>Individual credentials for each resource must be shared (DB credentials, ssh keys, etc)</li>
</ul>
<p>Doing things this way brings up a few issues with their own challenges that require solving: </p>
<p><strong>Issues with Onboarding and Offboarding Users</strong></p>
<p>Users must be granted a series of credentials and keys at different layers of the system. Not only is this difficult in and of itself, but when you throw in best practices around key rotations, static credentials, and how you handle dynamic infrastructure like auto scaling groups and kubernetes services, it can quickly become too much to handle.</p>
<p><strong>Problematic, Unclear Visibility into Connections</strong></p>
<p>We consider it a security best practice (and oftentimes a compliance requirement) to have visibility into what users and systems are connected where. This sort of access control record needs to be available in logs for security personnel to review.</p>
<p><strong>Difficult Integration and Tooling</strong></p>
<p>Users may need managed in multiple Identity Providers and other systems. Power users who are attempting to use command line tools or other tooling may find it difficult to work within the constraints of the VPN or bastion host setup</p>
<p>Boundary <strong>solves these issues</strong> by abstracting away much of the complexity and changing the way you think about access to system resources.</p>
<h3>How Boundary Makes it Work</h3>
<p>As mentioned previously, HashiCorp Boundary was built to make it easy to grant and maintain access to infrastructure. </p>
<p>So what does that look like in practice? </p>
<p>In initiating a boundary connection, 3 things happen:</p>
<ol>
<li><strong>Authentication:</strong> Boundary replaces individual Ssh keys and credentials with SSO via OpenID Connect. So the first step is to authenticate a user against an existing IDP (Identity Provider) such as Okta or ADFS.</li>
<li><strong>Authorization:</strong> Boundary checks its list of role based access controls to see if the authenticated user has access to the desired resource.</li>
<li><strong>Connection:</strong> Boundary initiates a connection to this resource. It does so via a client side agent that exposes this connection via localhost. Allowing a seamless experience with existing tools as you can work as if the connection is just a localhost connection. For many types of tools, this can also handle the credentials aspect of using a service so your end user never needs to be shared static credentials that may leak or be exposed.</li>
</ol>
<p><span>
      <a href="https://nextlinklabs.com/static/e8cf9bdaa409c30db3905af61f6e3ba1/f6036/boundary2.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="HashiCorp Boundary Authentication, Authorization, and Connection" title="HashiCorp Boundary Authentication, Authorization, and Connection" src="https://nextlinklabs.com/static/e8cf9bdaa409c30db3905af61f6e3ba1/c81eb/boundary2.png" srcset="https://nextlinklabs.com/static/e8cf9bdaa409c30db3905af61f6e3ba1/a3406/boundary2.png 243w,
https://nextlinklabs.com/static/e8cf9bdaa409c30db3905af61f6e3ba1/d5d05/boundary2.png 485w,
https://nextlinklabs.com/static/e8cf9bdaa409c30db3905af61f6e3ba1/c81eb/boundary2.png 970w,
https://nextlinklabs.com/static/e8cf9bdaa409c30db3905af61f6e3ba1/3100c/boundary2.png 1455w,
https://nextlinklabs.com/static/e8cf9bdaa409c30db3905af61f6e3ba1/2b608/boundary2.png 1940w,
https://nextlinklabs.com/static/e8cf9bdaa409c30db3905af61f6e3ba1/f6036/boundary2.png 2700w" sizes="(max-width: 970px) 100vw, 970px" loading="lazy">
  </a>
    </span></p>
<p>To the end user, they are able to use boundary in several different ways:</p>
<ul>
<li>CLI</li>
<li>SDK</li>
<li>REST API</li>
<li>User Interface</li>
<li>Desktop application <strong>(coming soon!)</strong></li>
</ul>
<p>With options for using Boundary that should appeal to both power users and less technical users, Boundary should provide a great user experience that will not only make your operations and security folks happy, but also provide tremendous value to end users.</p>
<p><span>
      <a href="https://nextlinklabs.com/static/ceedd6f6ef703adf7d0772952af7cbee/4d3a2/boundary3.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="HashiCorp Boundary Rules" title="HashiCorp Boundary Rules" src="https://nextlinklabs.com/static/ceedd6f6ef703adf7d0772952af7cbee/c81eb/boundary3.png" srcset="https://nextlinklabs.com/static/ceedd6f6ef703adf7d0772952af7cbee/a3406/boundary3.png 243w,
https://nextlinklabs.com/static/ceedd6f6ef703adf7d0772952af7cbee/d5d05/boundary3.png 485w,
https://nextlinklabs.com/static/ceedd6f6ef703adf7d0772952af7cbee/c81eb/boundary3.png 970w,
https://nextlinklabs.com/static/ceedd6f6ef703adf7d0772952af7cbee/3100c/boundary3.png 1455w,
https://nextlinklabs.com/static/ceedd6f6ef703adf7d0772952af7cbee/2b608/boundary3.png 1940w,
https://nextlinklabs.com/static/ceedd6f6ef703adf7d0772952af7cbee/4d3a2/boundary3.png 2858w" sizes="(max-width: 970px) 100vw, 970px" loading="lazy">
  </a>
    </span></p>
<h3>The Key Advantages to Boundary</h3>
<p>We think HashiCorp Boundary is a gamechanger for many organizations. </p>
<p>It is truly a tool set up for the future as it’s architecture supports modern cloud architectures. </p>
<p>HashiCorp says that in solving this common problem their users were experiencing (access to resources in a private network from a public network), they fundamentally changed how they think about solving the problem. </p>
<p>Boundary has many advantages over other ways of handling the issue:</p>
<ul>
<li><strong>Access rules</strong> can be setup and handled as code via their <strong>Terraform provider</strong> (provides all the other benefits of Infrastructure as Code)</li>
<li><strong>Policy</strong> is thought of as “which set of users needs access to which set of services” as opposed to IP based access control  - which is brittle, especially in today’s increasingly ephemeral environments</li>
<li><strong>Access to Session Visibility:</strong> Security Administrators are able to monitor and manage privileged sessions and export the session logs into analytics tooling</li>
<li>Promotes a <strong>zero-trust network security model</strong> as it does not trust the private network and does not give unnecessary access to the private network</li>
<li><strong>Makes onboarding and offboarding users a breeze</strong>. You only need to add or remove users to your Identity Provider. You don’t need to set up VPN or SSH access. You don’t need to grant individual user credentials</li>
</ul>
<p>Wrap up</p>
<p>In summary, we believe HashiCorp Boundary to be an excellent addition to many companies' toolchains. It does an excellent job of automating the setup and access of resources, identities, and access controls as code with Boundary’s Terraform Provider, REST API, CLI, and SDK. We think Boundary solves a common problem most organizations have in a way that enables simplicity for its users and operators while keeping security top of mind.</p>
<p>If you think your organization could benefit from a tool like HashiCorp Boundary, <a href="https://nextlinklabs.com/contact">please reach out to us here at NextLink Labs</a> and we are happy to help discuss how we can help.</p></div></div>]]>
            </description>
            <link>https://nextlinklabs.com/insights/hashicorp-releases-boundary-security-solution</link>
            <guid isPermaLink="false">hacker-news-small-sites-24921481</guid>
            <pubDate>Wed, 28 Oct 2020 17:21:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing pushdown to optimize joins in our open source Golang SQL engine]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24921460">thread link</a>) | @zachmu
<br/>
October 28, 2020 | https://www.dolthub.com/blog/2020-10-28-pushdown-filters/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-10-28-pushdown-filters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p><a href="https://doltdb.com/">Dolt</a> is Git for Data, a SQL database you can
branch, merge, clone, fork, sync, push and pull. Today we're excited
to announce the release of a new optimization in the query planner:
pushing down filters!</p>

<p>Pushdown is a query optimization that moves predicates in the
<code>WHERE</code> clause closer to the tables they refer to ("pushes them down
to the tables") in order to reduce the number of rows that need to be
examined. This is easiest to demonstrate with an example.</p>
<p>Let's say you have two tables that you want to join with a query,
along with some conditions. We'll use states and cities for these
examples.</p>
<div data-language="sql"><pre><code>pushdown<span>&gt;</span> <span>describe</span> states<span>;</span>
<span>+</span>
<span>|</span> Field      <span>|</span> <span>Type</span>        <span>|</span> <span>Null</span> <span>|</span> <span>Key</span> <span>|</span> <span>Default</span> <span>|</span> Extra <span>|</span>
<span>+</span>
<span>|</span> id         <span>|</span> <span>int</span>         <span>|</span> <span>NO</span>   <span>|</span> PRI <span>|</span>         <span>|</span>       <span>|</span>
<span>|</span> name       <span>|</span> <span>varchar</span><span>(</span><span>80</span><span>)</span> <span>|</span> YES  <span>|</span>     <span>|</span>         <span>|</span>       <span>|</span>
<span>|</span> code       <span>|</span> <span>varchar</span><span>(</span><span>2</span><span>)</span>  <span>|</span> YES  <span>|</span>     <span>|</span>         <span>|</span>       <span>|</span>
<span>|</span> population <span>|</span> <span>int</span>         <span>|</span> YES  <span>|</span>     <span>|</span>         <span>|</span>       <span>|</span>
<span>+</span>
pushdown<span>&gt;</span> <span>describe</span> cities<span>;</span>
<span>+</span>
<span>|</span> Field      <span>|</span> <span>Type</span>         <span>|</span> <span>Null</span> <span>|</span> <span>Key</span> <span>|</span> <span>Default</span> <span>|</span> Extra <span>|</span>
<span>+</span>
<span>|</span> id         <span>|</span> <span>int</span>          <span>|</span> <span>NO</span>   <span>|</span> PRI <span>|</span>         <span>|</span>       <span>|</span>
<span>|</span> name       <span>|</span> <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>|</span> YES  <span>|</span>     <span>|</span>         <span>|</span>       <span>|</span>
<span>|</span> state_id   <span>|</span> <span>int</span>          <span>|</span> YES  <span>|</span> MUL <span>|</span>         <span>|</span>       <span>|</span>
<span>|</span> population <span>|</span> <span>int</span>          <span>|</span> YES  <span>|</span>     <span>|</span>         <span>|</span>       <span>|</span>
<span>+</span></code></pre></div>
<p>For this example, we'll fill them with data from just a few states and
cities:</p>
<div data-language="sql"><pre><code>pushdown<span>&gt;</span> <span>SELECT</span> <span>*</span> <span>FROM</span> states<span>;</span>
<span>+</span>
<span>|</span> id <span>|</span> name       <span>|</span> code <span>|</span> population <span>|</span>
<span>+</span>
<span>|</span> <span>1</span>  <span>|</span> Alabama    <span>|</span> AL   <span>|</span> <span>4903000</span>    <span>|</span>
<span>|</span> <span>2</span>  <span>|</span> Alaska     <span>|</span> AK   <span>|</span> <span>731545</span>     <span>|</span>
<span>|</span> <span>3</span>  <span>|</span> Arizona    <span>|</span> AZ   <span>|</span> <span>7279000</span>    <span>|</span>
<span>|</span> <span>4</span>  <span>|</span> California <span>|</span> CA   <span>|</span> <span>39510000</span>   <span>|</span>
<span>|</span> <span>5</span>  <span>|</span> Colorado   <span>|</span> CO   <span>|</span> <span>5759000</span>    <span>|</span>
<span>+</span>
pushdown<span>&gt;</span> <span>SELECT</span> <span>*</span> <span>FROM</span> cities<span>;</span>
<span>+</span>
<span>|</span> id <span>|</span> name            <span>|</span> state_id <span>|</span> population <span>|</span>
<span>+</span>
<span>|</span> <span>1</span>  <span>|</span> Alabaster       <span>|</span> <span>1</span>        <span>|</span> <span>30352</span>      <span>|</span>
<span>|</span> <span>2</span>  <span>|</span> Auburn          <span>|</span> <span>1</span>        <span>|</span> <span>53380</span>      <span>|</span>
<span>|</span> <span>3</span>  <span>|</span> Birmingham      <span>|</span> <span>1</span>        <span>|</span> <span>212237</span>     <span>|</span>
<span>|</span> <span>4</span>  <span>|</span> Anchorage       <span>|</span> <span>2</span>        <span>|</span> <span>291826</span>     <span>|</span>
<span>|</span> <span>5</span>  <span>|</span> Akutan          <span>|</span> <span>2</span>        <span>|</span> <span>1027</span>       <span>|</span>
<span>|</span> <span>6</span>  <span>|</span> Bethel          <span>|</span> <span>2</span>        <span>|</span> <span>6080</span>       <span>|</span>
<span>|</span> <span>7</span>  <span>|</span> Avondale        <span>|</span> <span>3</span>        <span>|</span> <span>76238</span>      <span>|</span>
<span>|</span> <span>8</span>  <span>|</span> Apache Junction <span>|</span> <span>3</span>        <span>|</span> <span>35840</span>      <span>|</span>
<span>|</span> <span>9</span>  <span>|</span> Buckeye         <span>|</span> <span>3</span>        <span>|</span> <span>50876</span>      <span>|</span>
<span>|</span> <span>10</span> <span>|</span> Alturas         <span>|</span> <span>4</span>        <span>|</span> <span>2827</span>       <span>|</span>
<span>|</span> <span>11</span> <span>|</span> Anaheim         <span>|</span> <span>4</span>        <span>|</span> <span>336265</span>     <span>|</span>
<span>|</span> <span>12</span> <span>|</span> Bakersfield     <span>|</span> <span>4</span>        <span>|</span> <span>347483</span>     <span>|</span>
<span>|</span> <span>13</span> <span>|</span> Aurora          <span>|</span> <span>5</span>        <span>|</span> <span>353108</span>     <span>|</span>
<span>|</span> <span>14</span> <span>|</span> Aspen           <span>|</span> <span>5</span>        <span>|</span> <span>6805</span>       <span>|</span>
<span>|</span> <span>15</span> <span>|</span> Boulder         <span>|</span> <span>5</span>        <span>|</span> <span>105112</span>     <span>|</span>
<span>+</span></code></pre></div>
<p>Now let's say you want to join these two tables to find all the cities
that start with 'A' that are in states that start with 'A'. You would
write a query like this:</p>
<div data-language="sql"><pre><code><span>SELECT</span> c<span>.</span>name <span>AS</span> city_name<span>,</span> s<span>.</span>name <span>AS</span> state_name
    <span>FROM</span> cities c
    <span>JOIN</span> states s <span>ON</span> c<span>.</span>state_id <span>=</span> s<span>.</span>id
    <span>WHERE</span> c<span>.</span>name <span>LIKE</span> <span>'A%'</span> <span>AND</span> s<span>.</span>name <span>LIKE</span> <span>'A%'</span><span>;</span></code></pre></div>
<p>And you would get output like this:</p>
<div data-language="sql"><pre><code><span>+</span>
<span>|</span> city_name       <span>|</span> state_name <span>|</span>
<span>+</span>
<span>|</span> Alabaster       <span>|</span> Alabama    <span>|</span>
<span>|</span> Auburn          <span>|</span> Alabama    <span>|</span>
<span>|</span> Anchorage       <span>|</span> Alaska     <span>|</span>
<span>|</span> Akutan          <span>|</span> Alaska     <span>|</span>
<span>|</span> Avondale        <span>|</span> Arizona    <span>|</span>
<span>|</span> Apache Junction <span>|</span> Arizona    <span>|</span>
<span>+</span></code></pre></div>
<p>So far so good! But let's consider the number of rows that our query
has to examine to produce the answer. We can examine the query plan
the engine chose using the <code>EXPLAIN</code> keyword in front of the query. A
naive query planner will produce something like this:</p>
<div data-language="sql"><pre><code>pushdown<span>&gt;</span> <span>EXPLAIN</span> <span>SELECT</span> c<span>.</span>name <span>AS</span> city_name<span>,</span> s<span>.</span>name <span>AS</span> state_name
    <span>FROM</span> cities c
    <span>JOIN</span> states s <span>ON</span> c<span>.</span>state_id <span>=</span> s<span>.</span>id
    <span>WHERE</span> c<span>.</span>name <span>LIKE</span> <span>'A%'</span> <span>AND</span> s<span>.</span>name <span>LIKE</span> <span>'A%'</span><span>;</span>
<span>+</span>
<span>|</span> <span>plan</span>                                               <span>|</span>
<span>+</span>
<span>|</span> Project<span>(</span>c<span>.</span>name <span>as</span> city_name<span>,</span> s<span>.</span>name <span>as</span> state_name<span>)</span> <span>|</span>
<span>|</span>  └─ Filter<span>(</span>c<span>.</span>name <span>LIKE</span> <span>"A%"</span> <span>AND</span> s<span>.</span>name <span>LIKE</span> <span>"A%"</span><span>)</span>  <span>|</span>
<span>|</span>      └─ IndexedJoin<span>(</span>c<span>.</span>state_id <span>=</span> s<span>.</span>id<span>)</span>             <span>|</span>
<span>|</span>          ├─ TableAlias<span>(</span>c<span>)</span>                          <span>|</span>
<span>|</span>          │   └─ <span>Table</span><span>(</span>cities<span>)</span>                      <span>|</span>
<span>|</span>          └─ TableAlias<span>(</span>s<span>)</span>                          <span>|</span>
<span>|</span>              └─ <span>Table</span><span>(</span>states<span>)</span>                      <span>|</span>
<span>+</span></code></pre></div>
<p>So for this plan, we're examining every city in the <code>cities</code> table,
looking up its state (via an index, great!). Then we take this list,
the entire list of all the cities in the database joined to their
states, and filter it down to just those that start with the letter
A. There are about 20,000 cities and towns in the US, so this means
we'll be reading 20K rows and then doing another 20K index lookups
into the <code>states</code> table. That's not terrible, but we can do better.</p>
<p>Pushdown makes the filter happen before the join for each
table. Here's the same query with pushdown analysis enabled:</p>
<div data-language="sql"><pre><code><span>+</span>
<span>|</span> <span>plan</span>                                               <span>|</span>
<span>+</span>
<span>|</span> Project<span>(</span>c<span>.</span>name <span>as</span> city_name<span>,</span> s<span>.</span>name <span>as</span> state_name<span>)</span> <span>|</span>
<span>|</span>  └─ IndexedJoin<span>(</span>c<span>.</span>state_id <span>=</span> s<span>.</span>id<span>)</span>                 <span>|</span>
<span>|</span>      ├─ Filter<span>(</span>c<span>.</span>name <span>LIKE</span> <span>"A%"</span><span>)</span>                   <span>|</span>
<span>|</span>      │   └─ TableAlias<span>(</span>c<span>)</span>                          <span>|</span>
<span>|</span>      │       └─ <span>Table</span><span>(</span>cities<span>)</span>                      <span>|</span>
<span>|</span>      └─ Filter<span>(</span>s<span>.</span>name <span>LIKE</span> <span>"A%"</span><span>)</span>                   <span>|</span>
<span>|</span>          └─ TableAlias<span>(</span>s<span>)</span>                          <span>|</span>
<span>|</span>              └─ <span>Table</span><span>(</span>states<span>)</span>                      <span>|</span>
<span>+</span></code></pre></div>
<p>As you can see, the predicates in the filter node were pushed down
below the join node, to right above their respective tables. Since all
predicates were sucessfully pushed down, the entire wrapping filter
can be safely discarded.</p>
<p>This optimization has a number of desirable properties:</p>
<ol>
<li><strong>We do fewer lookups into the secondary table</strong> in the
join. Instead of doing a lookup for every city in the table, we
only do a lookup for the ones that start with 'A'.</li>
<li><strong>We don't assemble a join row result</strong> if the predicate on the
secondary table doesn't match. Without pushdown, we always assemble
a join row, comprising the concatenation of the rows from each of
the tables, for every row in the primary table. For the example
above, this means we never assemble the thousands of join rows for
cities that start with 'A' in states that start with another
letter. These join rows which will never appear in the final result
set is all memory that must be allocated and later collected, which
slows down the server.</li>
<li><strong>We can more efficiently execute in parallel</strong> on the two sides of
the join. It isn't shown in the above plan, but Dolt is capable of
running independent parts of the query in parallel to get faster
results. The further down the plan we push this parallelization,
the faster it makes the engine.</li>
</ol>
<p>So originally, we were examining about 40K rows (20K for the <code>cities</code>
table, then 20K index lookups into the <code>states</code> table). After
pushdown, we've reduced this by a lot, specifically by the number of
cities that don't begin with A. Let's make up a number: say that 10%
of cities start with A. In that case, we've reduced the number of
index lookups by 90%, but still have to scan all 20K <code>cities</code> rows. So
20K + 2K = 22K rows, a savings of 45%.</p>
<p>If we didn't have indexes to use for the join, we would get even
bigger savings. Without an index we're reduced to a cross join, which
means we're examining 20K * 50 rows, 1M rows total. Pushdown reduces
this to (20k + 50) + (2K * 4), so 28,050 rows total: a savings of
97.2%. (To truly do only 4 lookups on the secondary table we need to
load it entirely into memory during join analysis, which the engine
will do for a table this small).</p>
<p>That's a great start. Can we do better?</p>

<p>If we want this query to be faster, we'll need an index on it. So
let's create a new column for the first letter of the names of cities
and states, and populate it:</p>
<div data-language="sql"><pre><code>pushdown<span>&gt;</span> <span>alter</span> <span>table</span> cities <span>add</span> <span>column</span> first_letter <span>char</span><span>(</span><span>1</span><span>)</span><span>;</span>
pushdown<span>&gt;</span> <span>alter</span> <span>table</span> states <span>add</span> <span>column</span> first_letter <span>char</span><span>(</span><span>1</span><span>)</span><span>;</span>
pushdown<span>&gt;</span> <span>update</span> cities <span>set</span> first_letter <span>=</span> substr<span>(</span>name<span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span><span>;</span>
Query OK<span>,</span> <span>15</span> <span>rows</span> affected
<span>Rows</span> <span>matched</span>: <span>15</span>  Changed: <span>15</span>  <span>Warnings</span>: <span>0</span>
pushdown<span>&gt;</span> <span>select</span> <span>*</span> <span>from</span> cities<span>;</span>
<span>+</span>
<span>|</span> id <span>|</span> name            <span>|</span> state_id <span>|</span> population <span>|</span> first_letter <span>|</span>
<span>+</span>
<span>|</span> <span>1</span>  <span>|</span> Alabaster       <span>|</span> <span>1</span>        <span>|</span> <span>30352</span>      <span>|</span> A            <span>|</span>
<span>|</span> <span>2</span>  <span>|</span> Auburn          <span>|</span> <span>1</span>        <span>|</span> <span>53380</span>      <span>|</span> A            <span>|</span>
<span>|</span> <span>3</span>  <span>|</span> Birmingham      <span>|</span> <span>1</span>        <span>|</span> <span>212237</span>     <span>|</span> B            <span>|</span>
<span>|</span> <span>4</span>  <span>|</span> Anchorage       <span>|</span> <span>2</span>        <span>|</span> <span>291826</span>     <span>|</span> A            <span>|</span>
<span>|</span> <span>5</span>  <span>|</span> Akutan          <span>|</span> <span>2</span>        <span>|</span> <span>1027</span>       <span>|</span> A            <span>|</span>
<span>|</span> <span>6</span>  <span>|</span> Bethel          <span>|</span> <span>2</span>        <span>|</span> <span>6080</span>       <span>|</span> B            <span>|</span>
<span>|</span> <span>7</span>  <span>|</span> Avondale        <span>|</span> <span>3</span>        <span>|</span> <span>76238</span>      <span>|</span> A            <span>|</span>
<span>|</span> <span>8</span>  <span>|</span> Apache Junction <span>|</span> <span>3</span>        <span>|</span> <span>35840</span>      <span>|</span> A            <span>|</span>
<span>|</span> <span>9</span>  <span>|</span> Buckeye         <span>|</span> <span>3</span>        <span>|</span> <span>50876</span>      <span>|</span> B            <span>|</span>
<span>|</span> <span>10</span> <span>|</span> Alturas         <span>|</span> <span>4</span>        <span>|</span> <span>2827</span>       <span>|</span> A            <span>|</span>
<span>|</span> <span>11</span> <span>|</span> Anaheim         <span>|</span> <span>4</span>        <span>|</span> <span>336265</span>     <span>|</span> A            <span>|</span>
<span>|</span> <span>12</span> <span>|</span> Bakersfield     <span>|</span> <span>4</span>        <span>|</span> <span>347483</span>     <span>|</span> B            <span>|</span>
<span>|</span> <span>13</span> <span>|</span> Aurora          <span>|</span> <span>5</span>        <span>|</span> <span>353108</span>     <span>|</span> A            <span>|</span>
<span>|</span> <span>14</span> <span>|</span> Aspen           <span>|</span> <span>5</span>        <span>|</span> <span>6805</span>       <span>|</span> A            <span>|</span>
<span>|</span> <span>15</span> <span>|</span> Boulder         <span>|</span> <span>5</span>        <span>|</span> <span>105112</span>     <span>|</span> B            <span>|</span>
<span>+</span>
pushdown<span>&gt;</span> <span>update</span> states <span>set</span> first_letter <span>=</span> substr<span>(</span>name<span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span><span>;</span>
Query OK<span>,</span> <span>5</span> <span>rows</span> affected
<span>Rows</span> <span>matched</span>: <span>5</span>  Changed: <span>5</span>  <span>Warnings</span>: <span>0</span>
pushdown<span>&gt;</span> <span>select</span> <span>*</span> <span>from</span> states<span>;</span>
<span>+</span>
<span>|</span> id <span>|</span> name       <span>|</span> code <span>|</span> population <span>|</span> first_letter <span>|</span>
<span>+</span>
<span>|</span> <span>1</span>  <span>|</span> Alabama    <span>|</span> AL   <span>|</span> <span>4903000</span>    <span>|</span> A            <span>|</span>
<span>|</span> <span>2</span>  <span>|</span> Alaska     <span>|</span> AK   <span>|</span> <span>731545</span>     <span>|</span> A            <span>|</span>
<span>|</span> <span>3</span>  <span>|</span> Arizona    <span>|</span> AZ   <span>|</span> <span>7279000</span>    <span>|</span> A            <span>|</span>
<span>|</span> <span>4</span>  <span>|</span> California <span>|</span> CA   <span>|</span> <span>39510000</span>   <span>|</span> C            <span>|</span>
<span>|</span> <span>5</span>  <span>|</span> Colorado   <span>|</span> CO   <span>|</span> <span>5759000</span>    <span>|</span> C            <span>|</span>
<span>+</span>
pushdown<span>&gt;</span> <span>create</span> <span>index</span> cfl <span>on</span> cities <span>(</span>first_letter<span>)</span><span>;</span>
pushdown<span>&gt;</span> <span>create</span> <span>index</span> sfl <span>on</span> states <span>(</span>first_letter<span>)</span><span>;</span></code></pre></div>
<p>Now that we've indexed the main expression we care about, let's
<code>EXPLAIN</code> the query plan again.</p>
<div data-language="sql"><pre><code>pushdown<span>&gt;</span> <span>EXPLAIN</span> <span>SELECT</span> c<span>.</span>name <span>AS</span> city_name<span>,</span> s<span>.</span>name <span>AS</span> state_name
    <span>FROM</span> cities c
    <span>JOIN</span> states s <span>ON</span> c<span>.</span>state_id <span>=</span> s<span>.</span>id
    <span>WHERE</span> c<span>.</span>first_letter <span>=</span> <span>'A'</span> <span>AND</span> s<span>.</span>first_letter <span>=</span>  <span>'A'</span><span>;</span>
<span>+</span>
<span>|</span> <span>plan</span>                                                                <span>|</span>
<span>+</span>
<span>|</span> Project<span>(</span>c<span>.</span>name <span>AS</span> city_name<span>,</span> s<span>.</span>name <span>AS</span> state_name<span>)</span>                  <span>|</span>
<span>|</span>  └─ IndexedJoin<span>(</span>c<span>.</span>state_id <span>=</span> s<span>.</span>id<span>)</span>                                  <span>|</span>
<span>|</span>      ├─ Filter<span>(</span>c<span>.</span>first_letter <span>=</span> <span>"A"</span><span>)</span>                                <span>|</span>
<span>|</span>      │   └─ TableAlias<span>(</span>c<span>)</span>                                           <span>|</span>
<span>|</span>      │       └─ Indexed <span>table</span> access <span>on</span> <span>in…</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dolthub.com/blog/2020-10-28-pushdown-filters/">https://www.dolthub.com/blog/2020-10-28-pushdown-filters/</a></em></p>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-10-28-pushdown-filters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24921460</guid>
            <pubDate>Wed, 28 Oct 2020 17:19:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Enrich Your Snowflake Data Using External Functions]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24921452">thread link</a>) | @bradleybuda
<br/>
October 28, 2020 | https://blog.getcensus.com/data-enrichment-without-leaving-the-warehouse/ | <a href="https://web.archive.org/web/*/https://blog.getcensus.com/data-enrichment-without-leaving-the-warehouse/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                <div>
                    <p><a href="https://www.snowflake.com/data-warehousing-glossary/data-enrichment/">Data enrichment</a> is a powerful technique for adding valuable context to your customer data, and it’s simple in theory – given a bit of data about a record (e.g. a user's email or the IP of a web session), tell me more information about it so I can take effective action (e.g. map the email domain to a company or map the IP to a geolocation). In practice, however, it can be difficult to integrate a data enrichment process into an existing ELT pipeline, for a few reasons:</p><ul><li><strong>Maintaining Freshness: </strong>How recent are the results being correlated with my data? This may be a function of how often external datasets are loaded or how up-to-date your third-party data provider’s information is.</li><li><strong>Ensuring Consistency: </strong>Once data is enriched with new attributes, can I easily push those attributes to my warehouse and SaaS tools to maintain a synchronized data model?</li><li><strong>Limiting Resource Usage: </strong>Enrichment processes can be expensive in storage costs (to maintain huge third-party data sets), processing time, and API quota usage for paid enrichment services. And enrichment processes shouldn’t unnecessarily repeat the same work over and over again.</li></ul><p>In this post, I’ll share our recipe for enriching our own customer data at Census using the <a href="https://clearbit.com/" rel="noreferrer nofollow noopener">Clearbit</a> API, Snowflake External Functions, and <a href="https://www.getdbt.com/product/" rel="noreferrer nofollow noopener">dbt</a> to enrich data correctly and efficiently over large data sets.</p><p>One note before we begin, if you’re new to data enrichment: there’s a key difference between enriching using a dataset and enriching using an API. Some enrichment pipelines make use of third party datasets that can be purchased in their entirety – you can see many examples of these in the <a href="https://www.snowflake.com/data-marketplace/" rel="noreferrer nofollow noopener">Snowflake Data Marketplace</a>. This kind of data can be easier to work with because you can rely on your warehouse to efficiently <code>LEFT JOIN</code> to these datasets and materialize the result on a schedule. However, an enrichment API doesn’t give you the full dataset to work with; it replies to your queries (one at a time or in bulk) in a request-reply style to tell you if the API has additional data for the company or person in question. These are more challenging to work with in a data warehousing context, and we built this pipeline so that we can perform both types of enrichment without leaving the comfort of our warehouse SQL environment.</p><h3 id="snowflake-s-external-functions">Snowflake's External Functions</h3><p>External functions are a recentaddition in modern data warehouses. An external function is like a traditional <a href="https://docs.snowflake.com/en/sql-reference/user-defined-functions.html">user-defined function (UDF)</a>, but it allows you to break free of the database sandbox by calling an external handler to calculate results. For example, Redshift has basic support for <a href="https://docs.aws.amazon.com/redshift/latest/dg/r_CREATE_EXTERNAL_FUNCTION.html" rel="noreferrer nofollow noopener">external functions</a> that call Lambda functions to compute their results.</p><p>Snowflake's <a href="https://docs.snowflake.com/en/sql-reference/external-functions-introduction.html" rel="noreferrer nofollow noopener">external functions</a> call out to an <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/welcome.html" rel="noreferrer nofollow noopener">AWS API Gateway</a> endpoint to retrieve results, which allows us to connect many different handlers, including Lambda functions. Calls from SQL will be batched into JSON HTTP requests and proxied to the configured handler, which needs to unwrap the batch items, calculate appropriate values, and then return a batch of results as JSON. Setting up a gateway and handlers in AWS for the first time isn’t trivial, but the design allows a lot of flexibility. I won't go through that process in this post but you can read about it in Snowflake's <a href="https://docs.snowflake.com/en/sql-reference/external-functions-creating-aws.html" rel="noreferrer nofollow noopener">documentation</a>. We automate this using a <a href="https://www.terraform.io/" rel="noreferrer nofollow noopener">Terraform</a> module, which we hope to open source soon. Feel free to contact us if you’re curious!</p><figure><img src="https://blog.getcensus.com/content/images/2020/10/04r4gr_Q.png" alt="" srcset="https://blog.getcensus.com/content/images/size/w600/2020/10/04r4gr_Q.png 600w, https://blog.getcensus.com/content/images/size/w1000/2020/10/04r4gr_Q.png 1000w, https://blog.getcensus.com/content/images/2020/10/04r4gr_Q.png 1374w" sizes="(min-width: 720px) 720px"><figcaption>Architecture diagram of our external functions with backing resources</figcaption></figure><p>Once the remote gateway is set up, we need to set up an API integration in Snowflake and create one or more external functions that use the integration:</p><figure><pre><code>CREATE OR REPLACE API INTEGRATION clearbit_api_integration
  api_provider=aws_api_gateway
  -- This role is created during gateway setup and is the role that a Snowflake-managed user will assume
  api_aws_role_arn='arn:aws:iam::123456789012:role/gateway_access_role'
  api_allowed_prefixes=('https://&lt;gateway-id&gt;.execute-api.us-west-2.amazonaws.com/production')
  enabled=true;
           
CREATE OR REPLACE EXTERNAL FUNCTION clearbit_person(email_col VARCHAR)
  RETURNS VARIANT
  API_INTEGRATION = clearbit_api_integration
  AS 'https://&lt;gateway-id&gt;.execute-api.us-west-2.amazonaws.com/production/clearbit_person';
               
CREATE OR REPLACE EXTERNAL FUNCTION clearbit_company(domain_col VARCHAR)
  RETURNS VARIANT
  API_INTEGRATION = clearbit_api_integration
  AS 'https://&lt;gateway-id&gt;.execute-api.us-west-2.amazonaws.com/production/clearbit_company';</code></pre><figcaption>SQL code to create API integrations</figcaption></figure><p>Once the API Integration and external functions are created, assuming that the backing gateway is configured properly and our Lambda that forwards requests to Clearbit's API is implemented properly, we should be able to call them like any other SQL function:</p><!--kg-card-begin: html--><pre>&gt; SELECT CLEARBIT_PERSON('dave@getcensus.com');                                                                                     
+----------------------------------------------------------------------------------------------------------------------------------+
| CLEARBIT_PERSON('DAVE@GETCENSUS.COM')                                                                                            |
|----------------------------------------------------------------------------------------------------------------------------------|
| {                                                                                                                                |
|   "company": {                                                                                                                   |
|     "category": {                                                                                                                |
|       "industry": null,                                                                                                          |
|       "industryGroup": null,                                                                                                     |
|       "naicsCode": null,                                                                                                         |
|       "sector": null,                                                                                                            |
|       "sicCode": null,                                                                                                           |
|       "subIndustry": null                                                                                                        |
|     },                                                                                                                           |
|     "crunchbase": {                                                                                                              |
|       "handle": null                                                                                                             |
|     },                                                                                                                           |
|     "description": "Census is the easiest way to sync your data warehouse to the apps you use. No engineering favors required.", |
|     "domain": "getcensus.com",                                                                                                   |
|     "domainAliases": [                                                                                                           |
|       "sutrolabs.com"                                                                                                            |
|     ],                                                                                                                           |
|     "emailProvider": false,                                                                                                      |
|     ...                                                                                                                          |
|   },                                                                                                                             |
|   "person": {                                                                                                                    |
|     "avatar": null,                                                                                                              |
|     "bio": null,                                                                                                                 |
|     "email": "dave@getcensus.com",                                                                                               |
|     "emailProvider": false,                                                                                                      |
|     "employment": {                                                                                                              |
|       "domain": "getcensus.com",                                                                                                 |
|       "name": "Census",                                                                                                          |
|       "role": "engineering",                                                                                                     |
|       "seniority": null,                                                                                                         |
|       "subRole": "software_engineer",                                                                                            |
|       "title": "Software Engineer"                                                                                               |
|     },                                                                                                                           |
|     ...                                                                                                   …</pre></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.getcensus.com/data-enrichment-without-leaving-the-warehouse/">https://blog.getcensus.com/data-enrichment-without-leaving-the-warehouse/</a></em></p>]]>
            </description>
            <link>https://blog.getcensus.com/data-enrichment-without-leaving-the-warehouse/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24921452</guid>
            <pubDate>Wed, 28 Oct 2020 17:18:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Video Game Violence Isn’t Innocent]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24921421">thread link</a>) | @CrankyBear
<br/>
October 28, 2020 | https://aestheticsforbirds.com/2020/10/27/why-video-game-violence-isnt-innocent/ | <a href="https://web.archive.org/web/*/https://aestheticsforbirds.com/2020/10/27/why-video-game-violence-isnt-innocent/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

					
<p><em>What follows is a guest post by Christopher Bartel</em>, <em>Professor of Philosophy at Appalachian State University</em></p>



<p>Is it ever morally wrong to commit violent or immoral acts in a video game? Video games are just images, right? No matter what I do in a video game, I am just interacting with images, and harming an image doesn’t cause any real-world harm. So, all of my actions in games must be morally neutral. This is a perfectly reasonable (and common) line of thought. But I think it’s wrong. Here’s why.</p>



<p>Forget about video games for a moment. Let me ask you a different question: is it ever morally wrong to harm a photograph? Photographs are just glossy pieces of paper that share a visual resemblance to people, places, and things. Like video games, photographs are just images.</p>



<p>But it can be morally wrong to harm a photograph. Imagine that a white supremacist burns a photograph of Martin Luther King Jr. Or imagine someone burning a photo of the Pope, or of the Queen of England. Are these actions really morally neutral? I don’t think they are (which I’ve argued for&nbsp;<a href="https://rdcu.be/b7Yli">here</a>&nbsp;and&nbsp;<a href="https://doi.org/10.1093/aesthj/ayx031">here</a>). How we behave toward inanimate objects is not accidental. We have our reasons and our reasons can be morally problematic.&nbsp;</p>



<p>A photograph of my grandfather&nbsp;<em>is not</em>&nbsp;my grandfather. It has no feelings and cannot be hurt. It is merely a glossy piece of paper that visually resembles my grandfather. Now, imagine that I burn the photograph. Does my burning the photograph&nbsp;<em>mean</em>&nbsp;anything? In one sense, you might think not. There is nothing morally wrong with burning glossy pieces of paper. And I might have some understandable and morally innocent reason to burn the photograph. Suppose I decide to simplify my life, to get rid of all the stuff cluttering my house packed away in boxes that I never open. I am not a sentimental person after all. So, after binge-watching hours of Marie Kondo, I decide it’s time to get rid of my boxes of old photographs by burning them. It is a purely pragmatic decision to declutter my life. This seems fine because I am merely thinking of the photograph as an image—just another photo tucked away in a box.&nbsp;</p>



<p>However, if my reasons for burning the photograph are directed instead toward the subject of the photograph, then something more is going on. Suppose that I harbor some malicious and vindictive animosity toward my grandfather. In this case, my burning of his photograph is potent with meaning. I am not just burning any old photograph, rather it is&nbsp;<em>him</em>&nbsp;that I am fictionally burning. But,&nbsp;<em>why</em>&nbsp;do I want to burn his photograph? What are my reasons for defacing his image? Is my animosity toward my grandfather justified? Was he worthy of such animosity? Or am I being unreasonably malicious?&nbsp;</p>



<p>Think of my earlier examples—burning a photograph of Dr. King, or of the Pope, or of the Queen. If my reasons for burning these inanimate objects are directed toward the people depicted in them, then my reasons and my behaviors toward these objects&nbsp;<em>are</em>&nbsp;open to moral scrutiny. In these instances, the objects take on some symbolic meaning and my actions become symbolic too. My actions indicate something about my attitudes, values, and respect (or lack of respect) for the subject of the symbolic image. And we can morally criticize people for their attitudes and values just as much as we can criticize someone for their actions.</p>



<p>The important thing to notice here is that the object of moral condemnation in these cases is not the individual’s&nbsp;<em>actions</em>&nbsp;toward a glossy piece of paper. Rather, it is the individual’s&nbsp;<em>attitude</em>&nbsp;toward the person who’s in the photograph that is morally questionable. It is morally wrong to hold malicious attitudes toward other people even when we don’t act on those attitudes and the malicious things we do to photographs (or symbols more generally) reveal something about our attitudes toward those real-world subjects.&nbsp;</p>



<p>The same is true of video games. When we interact with a video game, we are merely interacting with images. But it is not the player’s actions toward those images that are morally interesting. It is their attitudes toward the image’s subject that matters morally. Consider a recent controversy over&nbsp;<em>Red Dead Redemption 2</em>. In one small town in the game, the player can interact with a suffragette who is campaigning for women’s right to vote. Many gamers have posted videos of themselves beating the suffragette unconscious, giving their videos titles like&nbsp;<a href="https://www.theguardian.com/games/2018/nov/07/red-dead-redemption-2-game-criticised-over-killing-of-suffragette">“Beating up annoying feminist”</a>. The player’s actions may be fictional, but their attitudes are non-fictional.</p>



<div><figure><img data-attachment-id="9367" data-permalink="https://aestheticsforbirds.com/red-dead-redemption-suffragette/" data-orig-file="https://aestheticsforbirds.files.wordpress.com/2020/10/red-dead-redemption-suffragette.jpg" data-orig-size="644,362" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="red-dead-redemption-suffragette" data-image-description="" data-medium-file="https://aestheticsforbirds.files.wordpress.com/2020/10/red-dead-redemption-suffragette.jpg?w=300" data-large-file="https://aestheticsforbirds.files.wordpress.com/2020/10/red-dead-redemption-suffragette.jpg?w=644" src="https://aestheticsforbirds.files.wordpress.com/2020/10/red-dead-redemption-suffragette.jpg?w=644" alt="" srcset="https://aestheticsforbirds.files.wordpress.com/2020/10/red-dead-redemption-suffragette.jpg 644w, https://aestheticsforbirds.files.wordpress.com/2020/10/red-dead-redemption-suffragette.jpg?w=150 150w, https://aestheticsforbirds.files.wordpress.com/2020/10/red-dead-redemption-suffragette.jpg?w=300 300w" sizes="(max-width: 644px) 100vw, 644px"></figure></div>



<p>Video games are works of fiction to be sure. What happens in a game is not real and cannot be held to the&nbsp;<em>same </em>moral scrutiny as our real-world actions. But that does not mean that our actions in video games can never be held to&nbsp;<em>any</em>&nbsp;moral scrutiny, as if they were entirely morally neutral. Video games often make use of the depiction of people, events, or scenarios that resonate with us; and by resonating with us, they invoke something of our real-world attitudes toward them.&nbsp;</p>



<p>Consider a few other examples.&nbsp;<em>Battle Raper</em>&nbsp;is a Japanese erotic game released in 2002 featuring hand-to-hand combat. When the player-character strikes a female opponent, her clothes fall off. After the female opponent is defeated, the player has the option to rape her.&nbsp;<em>Jesus Strikes Back: Judgment Day</em>&nbsp;is a third-person shooter. It was released in 2019. The player can choose to play as Hitler, “Tromp”, or Jesus Christ. The player’s mission is to kill a horde of immigrants, transgender people, and feminists. For the player who is drawn to these games, they are not “just games”. They are effigies. The player acts out symbolic violence on these effigies, which betrays the player’s attitudes toward their real-world counterparts. And attitudes themselves can be open to moral scrutiny.&nbsp;</p>



<div><figure><img loading="lazy" data-attachment-id="9368" data-permalink="https://aestheticsforbirds.com/5153949472_228cacefe5_b/" data-orig-file="https://aestheticsforbirds.files.wordpress.com/2020/10/5153949472_228cacefe5_b.jpg" data-orig-size="682,1023" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;William Warby&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5153949472_228cacefe5_b" data-image-description="" data-medium-file="https://aestheticsforbirds.files.wordpress.com/2020/10/5153949472_228cacefe5_b.jpg?w=200" data-large-file="https://aestheticsforbirds.files.wordpress.com/2020/10/5153949472_228cacefe5_b.jpg?w=682" src="https://aestheticsforbirds.files.wordpress.com/2020/10/5153949472_228cacefe5_b.jpg?w=682" alt="" width="390" height="582"><figcaption>Burning Guy Fawkes in effigy (Photo credit: <a href="https://search.creativecommons.org/photos/5599c80c-0b9a-42cd-ab44-ae2da5c2c096">wwarby</a>)</figcaption></figure></div>



<p>There are many reasons why players commit acts of violence in games, just like there are many reasons why someone might burn a photograph. Some of those reasons are morally innocent—because the violence offers a challenge, is novel, and is aesthetically rich. Indeed, many players engage in violent acts in video games for purely strategic reasons having to do with the competition—enacting violence is how you win. However, there are other reasons why players commit acts of violence in games that are not morally innocent. The moral relevance of our actions toward mere images is dependent on our attitudes and motivations.&nbsp;</p>



<p>Perhaps you—dear reader—are still not convinced. I ask you, then, to try this experiment at home. The experiment comes in two stages. Stage One: Take a photograph of someone you love and stab the eyes out. Are you hesitant to do it? Does it make you feel uneasy? Are you unwilling to stab out the eyes? Remember, it’s just a glossy piece of paper. If you can stab the eyes out, then you can move on to Stage Two: leave the maimed photograph in a place where your loved one will find it. When they find it, give them a lecture on the metaphysical status of images and why your actions didn’t mean anything because photographs lack moral status. Good luck!&nbsp;</p>



<p><span>Notes on the Contributor</span><br>Christopher Bartel is Professor of Philosophy at Appalachian State University. He is the author of&nbsp;<a href="https://www.bloomsbury.com/us/video-games-violence-and-the-ethics-of-fantasy-9781350121874/"><em>Video Games, Violence, and the Ethics of Fantasy: Killing Time</em></a>&nbsp;(you can read the first chapter for free&nbsp;<a href="https://bloomsburycp3.codemantra.com/viewer/5f61d28edc0e82000176fac7">here</a>). He plays a lot of fantasy RPGs, is embarrassingly bad at&nbsp;<em>Smash Bros.</em>, and can’t seem to get interested the&nbsp;<em>Assassin’s Creed</em>&nbsp;franchise. (I mean, it should tick a lot of boxes for him, but for some reason it’s just not.)&nbsp;</p>



<h6>Edited by <a href="https://objectionable.net/">C. Thi Nguyen</a></h6>
			
					
		<!-- end entry-meta -->

		
	</div></div>]]>
            </description>
            <link>https://aestheticsforbirds.com/2020/10/27/why-video-game-violence-isnt-innocent/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24921421</guid>
            <pubDate>Wed, 28 Oct 2020 17:16:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Use Slack for Web Development Workflows]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24921324">thread link</a>) | @jacksonpollock
<br/>
October 28, 2020 | https://cto.ai/blog/how-to-use-slack-for-web-development-workflows/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/how-to-use-slack-for-web-development-workflows/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>When it comes to development operations (aka DevOps) today, teams are collaborating remotely.</p><p>In fact, <a href="https://www.businessinsider.com/survey-over-two-thirds-of-companies-work-from-home-forever-2020-6">recent studies</a> highlight that this might be a more permanent setup for a majority of companies.</p><p>Even Stewart Butterfield, CEO of Slack, <a href="https://www.fastcompany.com/90558814/slacks-ceo-on-why-tech-companies-have-to-make-peace-with-permanent-remote-work">predicts</a> that Slack’s future workforce will be 20-30% remote with the majority of employees appearing at work 1-2 days per week for face time with their teams.</p><div><p>As a part of this major shift, you’ll have to familiarize yourself with the many remote developer tools available that you can use to make your remote workflows easier. And if your web development team or client’s central communication platform is Slack, then you’ll be glad to know that it's one of the best remote tools out there.</p><p>So, without further ado, here are 5 ways Slack can help you streamline your software development workflows.</p></div><h2 id="1-bug-trackers">1. Bug Trackers</h2><p>Developing a website doesn’t stop the moment it’s live. As newer software, integrations, and plugins are added to the equation, not to mention factoring in the kind of device(s) your users browse on, you’re bound to encounter bugs. Fortunately, <a href="https://thegeekpage.com/14-best-bug-tracking-software-for-2020/">various bug tracking software</a> is there to automate the monitoring and tracking of bugs. Slack can be integrated with many of these programs, like Usersnap, Jira, and Bugsnag. They ensure that you and your co-developers are automatically notified, allowing everybody to deal with bugs as soon as they appear.</p><h2 id="2-github">2. GitHub</h2><p>As the leading development platform, GitHub has around 50 million web developers reliant on it to get their projects done. <a href="https://slack.github.com/">Slack’s GitHub integration</a> allows you to get link previews for public repositories and create notifications with slash commands to stay on top of your workflow. Some activities you can subscribe to include but are not limited to: commit summaries, pull requests, and deployments.</p><h2 id="3-hubot">3. HuBot</h2><p><a href="https://ops-community.slack.com/apps/A0F7XDU93-hubot">HuBot</a> was developed by developers using CoffeeScript on Node.js — a runtime environment based on JavaScript. People often use a combination of <a href="https://www.altium.com/solution/prototype-board-layout-software">different prototype board layout software</a> to proof design ideas, utilizing circuit components on breadboards to ensure that the end product comes out functional. This helps reduce the guesswork that usually goes into designing. But with HuBot integration, you’ll have access to all the web development tools that you need. Whether you need to create/read files on the server or modify the data in your database, HuBot allows you to do all this and more on Slack.</p><h2 id="4-code-snippets">4. Code Snippets</h2><p>When developing code with the team, sometimes you have to share snippets of your progress, either for checking, reports, or coaching. Slack’s desktop app has a “create and share” <a href="https://slack.com/slack-tips/share-code-snippets">snippet feature</a> that you can use. To the left of the message box, click the lightning bolt icon to access the shortcuts menu. Under “Slack,” look for “Create code or text snippet” and click it. You can either type in your code or upload a file. Click “Create snippet” to post it on your chosen channel. There’s even a keyboard shortcut for it: Shift + Command (Mac) or Ctrl (Windows) + V.</p><h2 id="5-the-ops-platform">5. The Ops Platform</h2><div><p>Need one platform to rule them all for your dev team on Slack? <a href="https://cto.ai/platform">The Ops Platform</a> is a Slack-enabled serverless infrastructure designed for the needs of fast moving development teams who want to measure what the business cares about. The embedded Commands, Pipelines and Services provide all of the tools you need to easily integrate your GitOps and ChatOps workflows, so that you can workflow smarter, not harder.</p><p>In conclusion, Slack has a ton of neat features that make it the ideal collaboration platform for developers. Slack gives you the flexibility that you need to perform your tasks, whether that’s developer tool integration or sharing code.</p><p>Hungry for more? Here are another <a href="https://cto.ai/blog/slack-hacks-14-ideas-for-developer-devops-workflows-slack-aws-twilio-lyft/">14 developer Slack hacks for you to try</a>.</p></div><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p><em>Ria Jasper is a software developer and technical writer.</em></p>
			</div></div>]]>
            </description>
            <link>https://cto.ai/blog/how-to-use-slack-for-web-development-workflows/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24921324</guid>
            <pubDate>Wed, 28 Oct 2020 17:09:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Uncover how your funds spend money in politics]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24921199">thread link</a>) | @mushufasa
<br/>
October 28, 2020 | https://www.yourstake.org/politics/ | <a href="https://web.archive.org/web/*/https://www.yourstake.org/politics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<section>
  <p>
    <span>Are your Investments</span>
    <br>
    <span>Democrat or Republican?</span>
  </p>
  <p><img src="https://stake-assets.s3.amazonaws.com/static/sillyimages/Donkey-.svg">
    <img src="https://stake-assets.s3.amazonaws.com/static/sillyimages/Indian-elephant.svg">
  </p>
  <br>


  <!--
    to implement when we setup plaid
    <div class="tabs is-centered is-toggle">
    <ul>
      <li class="is-active">
        <a>
          <span>Select</span>
        </a>
      </li>
      <li>
        <a>
          <span>Sync</span>
        </a>
      </li>
    </ul>
  </div> -->
  
  <p>
    Lookup your Fund
  </p>
  <!-- field -->
<!-- myform-->

<p>
  <em>Find out how much money the companies in your mutual fund donate to Democratic and Republican candidates.</em>
</p>

<p><a href="https://www.yourstake.org/yourimpact/">
    <img src="https://stake-assets.s3.amazonaws.com/static/images/yourstakelogo.png" alt="Stake: Your Voice through Your Investments">
  </a>
</p>






</section></div>]]>
            </description>
            <link>https://www.yourstake.org/politics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24921199</guid>
            <pubDate>Wed, 28 Oct 2020 17:01:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An availability footprint of the Redpanda and Apache Kafka replication protocols]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24921163">thread link</a>) | @gbrown_
<br/>
October 28, 2020 | https://vectorized.io/kafka-redpanda-availability/ | <a href="https://web.archive.org/web/*/https://vectorized.io/kafka-redpanda-availability/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>We are building a streaming engine for modern applications. One that extends beyond the Kafka protocol, into inline WASM transforms and geo-replicated hierarchical storage. However, to build our house, we need a solid foundation. </p>
<p>In <a href="https://vectorized.io/validating-consistency" target="_self" rel="nofollow">my last post</a>, I talked at length about how our consistency and validation testing puts Redpanda through the paces, including unavailability windows. Fundamentally, we left a big question unanswered: does Raft make a difference? </p>
<p>As a quick recap, our previous consistency testing helped us fix an unavailability blip when a follower who was on a network partition rejoined the cluster. This disruption is common among Raft-based protocols. We hypothesize this is due to the fact that only Diego’s dissertation (not the Raft paper) mentions the anomaly below and a countermeasure. This got us thinking about walking through &amp; comparing our consensus protocol with upstream Apache Kafka with a fine tooth comb.</p>
<p><span>
      <a href="https://vectorized.io/static/fc0aaacff1ab66f051ab54d48d122edc/2e661/pre-vote.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="prevote" title="prevote" src="https://vectorized.io/static/fc0aaacff1ab66f051ab54d48d122edc/2f950/pre-vote.png" srcset="https://vectorized.io/static/fc0aaacff1ab66f051ab54d48d122edc/c7805/pre-vote.png 400w,
https://vectorized.io/static/fc0aaacff1ab66f051ab54d48d122edc/8ff1e/pre-vote.png 800w,
https://vectorized.io/static/fc0aaacff1ab66f051ab54d48d122edc/2f950/pre-vote.png 1600w,
https://vectorized.io/static/fc0aaacff1ab66f051ab54d48d122edc/2e661/pre-vote.png 2034w" sizes="(max-width: 1600px) 100vw, 1600px" loading="lazy">
  </a>
    </span></p>
<p>Redpanda uses the Raft replication protocol which tolerates <code>F</code> failures given <code>2F+1</code> nodes.</p>
<p>Apache Kafka uses synchronous replication and relies on Apache ZooKeeper for the cluster view management.</p>
<p>In the terms of the CAP theorem, it may be configured to work as an AP system (tolerates <code>N-1</code> failures out of <code>N</code> brokers, <a href="https://aphyr.com/posts/293-jepsen-kafka" target="_self" rel="nofollow">possibility</a> of a data loss) or as a CP system (via “acks=all”, setting “min.insync.replicas” of a quorum and flushing on every message via “log.flush.interval.messages=1” on all brokers).</p>
<p>In the latter case, the level of resiliency is the same as Raft’s (up to F failed nodes), so the question is if there is any difference between the protocols at all?</p>
<p>To answer that question we test a topic with a single partition and a replication factor of three. We configured Kafka 2.6.0 to work as a CP system and with Redpanda we used “acks=-1” (strongest) settings.</p>
<h2 id="Similarities">Similarities<a href="#Similarities" aria-label="Similarities permalink"></a></h2>
<p>Both protocols have a notion of a stable leader so any fault injection affecting a leader also affects the end-to-end experience.</p>
<h3 id="Termination-of-a-leader">Termination of a leader<a href="#Termination-of-a-leader" aria-label="Termination of a leader permalink"></a></h3>
<p>When a process is terminated with <code>kill -9</code> and restarted after a minute it affects Kafka (left) and Redpanda (right).</p>
<p><span>
      <a href="https://vectorized.io/static/a776cad75ee6e93504207534e80cc7af/55138/kill.leader.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="termination.leader" title="termination.leader" src="https://vectorized.io/static/a776cad75ee6e93504207534e80cc7af/2f950/kill.leader.png" srcset="https://vectorized.io/static/a776cad75ee6e93504207534e80cc7af/c7805/kill.leader.png 400w,
https://vectorized.io/static/a776cad75ee6e93504207534e80cc7af/8ff1e/kill.leader.png 800w,
https://vectorized.io/static/a776cad75ee6e93504207534e80cc7af/2f950/kill.leader.png 1600w,
https://vectorized.io/static/a776cad75ee6e93504207534e80cc7af/2fb56/kill.leader.png 2400w,
https://vectorized.io/static/a776cad75ee6e93504207534e80cc7af/55138/kill.leader.png 3200w" sizes="(max-width: 1600px) 100vw, 1600px" loading="lazy">
  </a>
    </span></p>
<h4 id="How-to-read-the-charts">How to read the charts<a href="#How-to-read-the-charts" aria-label="How to read the charts permalink"></a></h4>
<p>The first section of the chart is a number of successfully executed operations per second. It isn’t a stress test so we maintain a pretty low steady load (100 ops/s). But each logical operation consists of a write and a read so in reality the load is twice higher. This section is useful to detect when a system experiences availability issues.</p>
<p>The next two sections are about latency. Each dot represents the duration of an operation ended at this moment.The first part is a complete overview and the second part is zoom-in on the fastest operations. The x axis is in seconds and the y axis is in microseconds. Black dots are successful operations, blue is timed out (outcome is unknown) and red dots are rejections (an operation isn’t applied).</p>
<h3 id="10ms-disk-latency-increase-on-a-leader">10ms disk latency increase on a leader<a href="#10ms-disk-latency-increase-on-a-leader" aria-label="10ms disk latency increase on a leader permalink"></a></h3>
<p>We simulate disk latency spikes by adding artificial 10ms latency via FUSE to every disk IO operation on a leader for a minute. It sends Kafka’s average latency to 980ms (p99 is 1256ms) and Redpanda’s to 50ms (p99 is 94ms).</p>
<p><span>
      <a href="https://vectorized.io/static/723740a0200c19580fee6e72e7a91146/55138/disk.leader.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="10ms.leader" title="10ms.leader" src="https://vectorized.io/static/723740a0200c19580fee6e72e7a91146/2f950/disk.leader.png" srcset="https://vectorized.io/static/723740a0200c19580fee6e72e7a91146/c7805/disk.leader.png 400w,
https://vectorized.io/static/723740a0200c19580fee6e72e7a91146/8ff1e/disk.leader.png 800w,
https://vectorized.io/static/723740a0200c19580fee6e72e7a91146/2f950/disk.leader.png 1600w,
https://vectorized.io/static/723740a0200c19580fee6e72e7a91146/2fb56/disk.leader.png 2400w,
https://vectorized.io/static/723740a0200c19580fee6e72e7a91146/55138/disk.leader.png 3200w" sizes="(max-width: 1600px) 100vw, 1600px" loading="lazy">
  </a>
    </span></p>
<h2 id="Distinctions">Distinctions<a href="#Distinctions" aria-label="Distinctions permalink"></a></h2>
<p>Kafka uses sync replication, so any disturbance of a follower affects user end-to-end experience until the disturbance is gone or until a faulty follower is excluded from the ISR (a list of active followers).</p>
<p>Redpanda uses quorum replication (Raft) so as long as a majority of the nodes including a leader is stable it can tolerate any disturbances.</p>
<p>As a result, Raft is less sensitive to the fault injections.</p>
<h3 id="Termination-of-a-follower">Termination of a follower<a href="#Termination-of-a-follower" aria-label="Termination of a follower permalink"></a></h3>
<p>A process is terminated with <code>kill -9</code> and restarted after a minute. Redpanda doesn’t experience any disturbances.</p>
<p><span>
      <a href="https://vectorized.io/static/08b9cbb7e5f2cfff5373c6d6aa637d75/55138/kill.follower.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="termination.follower" title="termination.follower" src="https://vectorized.io/static/08b9cbb7e5f2cfff5373c6d6aa637d75/2f950/kill.follower.png" srcset="https://vectorized.io/static/08b9cbb7e5f2cfff5373c6d6aa637d75/c7805/kill.follower.png 400w,
https://vectorized.io/static/08b9cbb7e5f2cfff5373c6d6aa637d75/8ff1e/kill.follower.png 800w,
https://vectorized.io/static/08b9cbb7e5f2cfff5373c6d6aa637d75/2f950/kill.follower.png 1600w,
https://vectorized.io/static/08b9cbb7e5f2cfff5373c6d6aa637d75/2fb56/kill.follower.png 2400w,
https://vectorized.io/static/08b9cbb7e5f2cfff5373c6d6aa637d75/55138/kill.follower.png 3200w" sizes="(max-width: 1600px) 100vw, 1600px" loading="lazy">
  </a>
    </span></p>
<h3 id="10ms-disk-latency-increase-on-a-follower">10ms disk latency increase on a follower<a href="#10ms-disk-latency-increase-on-a-follower" aria-label="10ms disk latency increase on a follower permalink"></a></h3>
<p>10ms latency is added to every disk IO operation on a follower for a minute. Redpanda doesn’t experience any disturbances.</p>
<p><span>
      <a href="https://vectorized.io/static/97764122e655a5179a09f9e725ef430e/55138/disk.follower.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="10ms.follower" title="10ms.follower" src="https://vectorized.io/static/97764122e655a5179a09f9e725ef430e/2f950/disk.follower.png" srcset="https://vectorized.io/static/97764122e655a5179a09f9e725ef430e/c7805/disk.follower.png 400w,
https://vectorized.io/static/97764122e655a5179a09f9e725ef430e/8ff1e/disk.follower.png 800w,
https://vectorized.io/static/97764122e655a5179a09f9e725ef430e/2f950/disk.follower.png 1600w,
https://vectorized.io/static/97764122e655a5179a09f9e725ef430e/2fb56/disk.follower.png 2400w,
https://vectorized.io/static/97764122e655a5179a09f9e725ef430e/55138/disk.follower.png 3200w" sizes="(max-width: 1600px) 100vw, 1600px" loading="lazy">
  </a>
    </span></p>
<h2 id="Recap">Recap<a href="#Recap" aria-label="Recap permalink"></a></h2>
<p>Besides a termination and introducing a disk delay to a leader and a follower, we have tested the following fault injections.</p>
<ul>
<li>suspension of a follower / leader</li>
<li>isolation of a follower / leader</li>
<li>failing every disk operation on a follower / leader</li>
</ul>
<p>And the results were the same. When a fault injection affects a leader both Redpanda and Kafka experience an availability loss, when a fault affects a follower only Kafka experiences disturbance.</p>
<p>The results fit the theory. Raft’s (and Redpanda’s) performance is proportional to the best of the majority of nodes, while sync replication (Kafka) works only as well as its worst-performing node. </p>
<h2 id="Can-we-do-better">Can we do better?<a href="#Can-we-do-better" aria-label="Can we do better permalink"></a></h2>
<p>A recipe for the performance / availability improvements is simple:</p>
<ol>
<li>come up with a good mental model</li>
<li>measure how far the actual performance model is from the mental one</li>
<li>find a bottleneck</li>
<li>fix the bottleneck or adjust the model</li>
<li>pick a new algorithm / mental model and start again</li>
</ol>
<p>Our experiments demonstrated that an availability footprint of Redpanda (actual model) matches the theoretical limit of Raft (mental model), so the only thing left to do is take a step back from Raft.</p>
<p>Heidi Howard and Richard Mortier wrote an <a href="https://arxiv.org/abs/2004.05074" target="_self" rel="nofollow">excellent paper</a> on comparing Raft and Paxos replication protocols. Most relevantly:</p>
<blockquote>
<p>We must first answer the question of how exactly the two algorithms differ in their approach to consensus? Not only will this help in evaluating these algorithms, it may also allow Raft to benefit from the decades of research optimising Paxos’ performance and vice versa.</p>
<p>By describing a simplified Paxos algorithm using the same approach as Raft, we find that the two algorithms differ only in their approach to leader election</p>
</blockquote>
<p>The exciting conclusion here is that we can bring in decades of research and optimizations for Paxos based systems to Redpanda and our Raft-based consensus and data replication protocol. The depth and breadth of these optimizations cover amortizing disk latency spikes that affect a minority of nodes including the leader, as well as figuring out a way to have natural hierarchy and WAN-based optimizations. We can’t wait to see how far we can push the system, break it and start again :)</p></section></div>]]>
            </description>
            <link>https://vectorized.io/kafka-redpanda-availability/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24921163</guid>
            <pubDate>Wed, 28 Oct 2020 16:59:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Translating lost languages using machine learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24921013">thread link</a>) | @kylebgorman
<br/>
October 28, 2020 | https://www.wellformedness.com/blog/translating-lost-languages-machine-learning/ | <a href="https://web.archive.org/web/*/https://www.wellformedness.com/blog/translating-lost-languages-machine-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><strong>[The following is a guest post from my colleague <a href="https://rws.xoba.com/">Richard Sproat</a>. This should go without saying, but: this post does not represent the opinions of&nbsp;<em>anyone’s</em> employer.]</strong></p>
<p><span>In 2009 a </span><a href="https://science.sciencemag.org/content/324/5931/1165/tab-figures-data"><span>paper</span></a><span> appeared in </span><i><span>Science </span></i><span>by Rajesh Rao and colleagues that claimed to show using “entropic evidence” that the thus far undeciphered Indus Valley symbol system was true writing not, as colleagues and I had </span><a href="https://crossasia-journals.ub.uni-heidelberg.de/index.php/ejvs/article/view/620"><span>argued</span></a><span>, a non-linguistic symbol system. Some other papers from Rao and colleagues followed, and there was also a </span><a href="https://royalsocietypublishing.org/doi/full/10.1098/rspa.2010.0041"><span>paper</span></a><span> in the </span><i><span>Proceedings of the Royal Society </span></i><span>by Rob Lee and colleagues that used a different “entropic” method to argue that symbols carved on stones by the Picts of Iron Age Scotland also represented language.&nbsp;</span></p>
<p><span>I, and others, were deeply skeptical (see e.g. </span><a href="https://languagelog.ldc.upenn.edu/nll/?p=2227"><span>here</span></a><span>) that such methods could distinguish between true writing and symbol systems that, while having structure, encoded some sort of non-linguistic information. This skepticism was fed in part by our observation that completely random meaningless “symbol systems” could be shown to fall into the “linguistic” bin according to those measures. What if anything were such methods telling us about the difference between natural language and other systems that convey meaning? My skepticism led to a sequence of presentations and papers, culminating in this </span><a href="https://www.linguisticsociety.org/sites/default/files/archived-documents/Sproat_Lg_90_2.pdf"><span>paper</span></a><span> in </span><i><span>Language</span></i><span>, where I tried a variety of statistical methods, including those of the Rao and Lee teams, in an attempt to distinguish between samples of systems that were known to be true writing, and systems known to be non-linguistic. None of these methods really worked and I concluded that simple extrinsic measures based on the distribution of symbols without knowing </span><i><span>what </span></i><span>the symbols denote, were unlikely to be of much use.</span></p>
<p><span>The upshot of this attempt at debunking Rao’s and Lee’s widely publicized work was that I convinced people who were already convinced and failed to convince those who were not. As icing on the cake, I was accused by Rao and Lee and colleagues of totally misrepresenting their work, which I most certainly had not done: indeed I was careful to consider all possible interpretations of their arguments, the problem being that their own interpretations of what they had done seemed to be rather fluid, changing as the criticisms changed; on the latter point see </span><a href="https://www.linguisticsociety.org/sites/default/files/14e_91.4Sproat.pdf"><span>my reply</span></a><span>, also in </span><i><span>Language</span></i><span>. This experience led me to pretty much give up the debunking business entirely, since people usually end up believing what they want to believe, and it is rare for people to admit they were wrong.</span></p>
<p><span>Still, there are times when one feels inclined to try to set the record straight, and one such instance is this </span><a href="https://news.mit.edu/2020/translating-lost-languages-using-machine-learning-1021"><span>recent announcement</span></a><span> from MIT about work from Regina Barzilay and colleagues that purports to provide a machine-learning based system that “aims to help linguists decipher languages that have been lost to history.” The </span><a href="https://arxiv.org/abs/2010.11054"><span>paper</span></a><span> this press release is based on (to appear in the </span><em><a href="https://transacl.org/index.php/tacl"><span>Transactions of the Association for Computational Linguistics</span></a></em><span>) is of course more reserved than what the MIT public relations people produced, but is still misleading in a number of ways.</span></p>
<p><span>Before I get into that though, let me state at the outset that as with the work by Rao et al. and Lee et al. that I had critiqued previously, the issue here is not that Barzilay and colleagues do not have results, but rather what one concludes from their results. And to be fair, this new work is a couple of orders of magnitude more sophisticated than what Rao and his colleagues did.</span></p>
<p><span>In brief summary, Barzilay et al’s approach is to take a text in an unknown ancient script, which may be </span><i><span>unsegmented</span></i><span> into words, along with phonetic transcriptions of a known language. In general the phonetic values of the unknown script are, well, not known, so candidate mappings are generated. (The authors also consider cases where some of the values are known, or can be guessed at, e.g. because the glyphs look like glyphs in known scripts.) The weights on the various mappings are learnable parameters, and the learning is also guided by phonological constraints such as assumed regularity of sound changes and rough preservation of the size of the phonemic inventory as languages change. (Of course, phoneme inventories can change a lot in size and details over a long history: Modern English has quite a different inventory from Proto-Indo-European. Still, since one’s best hope of a decipherment is to find languages that are reasonably closely related to the target, the authors’ assumption here may not be unreasonable.) The objective function for the learning aims to cover as much of the unknown text as possible while optimizing the quality of the extracted cognates. Their training is summarized in the following pseudocode from page 6 of their paper:</span></p>
<p><img loading="lazy" src="http://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0.png" alt="" width="2296" height="632" srcset="https://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0.png 2296w, https://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0-300x83.png 300w, https://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0-1024x282.png 1024w, https://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0-768x211.png 768w, https://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0-1536x423.png 1536w, https://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0-2048x564.png 2048w, https://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0-500x138.png 500w" sizes="(max-width: 2296px) 100vw, 2296px"></p>
<p><span>One can then compare the results of the algorithm when run with the unknown text, and a </span><i><span>set</span></i><span> of known languages, to see which of the known languages is the best model. The work is thus in many ways similar to earlier </span><a href="https://www.isi.edu/natural-language/mt/decipher06.pdf"><span>work</span></a><span> by Kevin Knight and colleagues, which the present paper also cites.</span></p>
<p><span>In the experiments the authors used three ancient scripts: </span><a href="https://en.wikipedia.org/wiki/Ugaritic"><span>Ugaritic</span></a><span> (12th century BCE), a close relative of Hebrew; Gothic, a 4th century CE East Germanic language that is also the earliest preserved Germanic tongue; and Iberian, a heretofore undeciphered script — or more accurately a collection of scripts — of the late pre-Common Era from the Iberian peninsula. (It is worth noting that Iberian was very likely to have been a mixed </span><a href="https://en.wikipedia.org/wiki/Iberian_scripts"><span>alphabetic-syllabic</span></a><span> script, not a purely alphabetic one, which means that one is giving oneself a bit of a leg up if one bases one’s work on a transliteration of those texts into a purely alphabetic form.) The comparison known languages were Proto-Germanic, Old Norse, Old English, Latin, Spanish, Hungarian, Turkish, Basque, Arabic and Hebrew. (I note in passing that Latin and Spanish seem to be assigned by the authors to different language families!)</span></p>
<p><span>For Ugaritic, Hebrew came out as dramatically closer than other languages, and for Gothic, Proto-Germanic. For Iberian, no language was a dramatically better match, though Basque did seem to be somewhat closer. As they argue (p. 9):</span></p>
<blockquote><p><span>The picture is quite different for Iberian. No language seems to have a pronounced advantage over others. This seems to accord with the current scholarly understanding that Iberian is a language isolate, with no established kinship with others.</span></p></blockquote>
<p><span>“Scholarly understanding” may be an overstatement since the most one can say at this point is that there is </span><i><span>scholarly disagreement </span></i><span>on the relationships between the Iberian language(s) and known languages.</span></p>
<p><span>But, in any case, one problem is that since they only perform this experiment for three ancient scripts, two of which they are able to find clear relationships for, and the third not so clearly, it is not obvious what if anything one can conclude from this. The statistical sample is not such as to be overwhelming in its significance. Furthermore, in at least one case there is a serious danger of circularity: the closest match they find for Gothic is with Proto-Germanic, which shows a much better match than the other Germanic languages, Old Norse or Old English. But that is hardly surprising: Proto Germanic reconstructions are heavily informed by Gothic, the earliest recorded example of a Germanic language. Indeed, if Gothic were truly an unknown language, and assuming that we had no access to a reconstructed protolanguage that depends in part on Gothic for its reconstruction, then we would be left with the two known Germanic languages in their set, Old English and Old Norse. This of course would be a more reasonable model in any case for the situation a real decipherer would encounter. But then the situation for Gothic becomes much less clear. Below is their Figure 4, which plots various settings of their coverage threshold hyperparameter </span><i><span>r</span></i><i><span>cov</span></i> <span>against the obtained coverage. The more separated the curve for the language is above the rest, the better the method is able to distinguish the closest matched language from everything else. With this in mind, Hebrew is clearly a lot closer to Ugaritic than anything else. Iberian, as we noted, does not have a language that is obviously closest, though Basque is a contender. For Gothic, Proto-Germanic (PG) is a clear winner, but if one removed that the closest two are now Old English (OE) and Old Norse (ON). Not bad, of course, but just eyeballing the plots, the situation is no longer as dramatic, and not clearly more dramatic than the situation for Iberian.</span></p>
<p><img loading="lazy" src="http://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0-1.png" alt="" width="2166" height="1782" srcset="https://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0-1.png 2166w, https://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0-1-300x247.png 300w, https://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0-1-1024x842.png 1024w, https://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0-1-768x632.png 768w, https://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0-1-1536x1264.png 1536w, https://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0-1-2048x1685.png 2048w, https://www.wellformedness.com/blog/wp-content/uploads/2020/10/pasted-image-0-1-365x300.png 365w" sizes="(max-width: 2166px) 100vw, 2166px"></p>
<p><span>And as for Iberian, again, they note (p. 9) that “Basque somewhat stands out from the rest, which might be attributed to its similar phonological system with Iberian”. But what are they comparing against? Modern Basque is certainly different from its form 2000+ years ago, and indeed if one buys into </span><a href="https://julietteblevins.ws.gc.cuny.edu/proto-basque/"><span>recent work by Juliette Blevins</span></a><span>, then Ancient Basque was phonologically quite a bit different from the modern language. Which in turn leaves one wondering what these results are telling us.</span></p>
<p><span>The abstract of the paper opens with the statement that:</span></p>
<blockquote><p><span>Most undeciphered lost languages exhibit two characteristics that pose significant decipherment challenges: (1) the scripts are not fully segmented into words; (2) the closest known language is not determined.</span></p></blockquote>
<p><span>Of course this is all perfectly true, but it rather understates the case when it comes to the real challenges faced in most cases of decipherment.&nbsp;</span></p>
<p><span>To wit:</span></p>
<p><span>Not only is the “closest … language” not usually known, but there may not even</span><i><span> be</span></i><span> a closest language. This appears to be the situation for Linear A where, even though there is a substantial amount of Linear A text, and the syllabary is very similar in appearance and was almost certainly the precursor to the deciphered Linear B, decipherment has remained elusive for 100 years in large measure because we simply do not know anything about the Eteocretan Language. It is also the situation for Etruscan. The authors of course …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.wellformedness.com/blog/translating-lost-languages-machine-learning/">https://www.wellformedness.com/blog/translating-lost-languages-machine-learning/</a></em></p>]]>
            </description>
            <link>https://www.wellformedness.com/blog/translating-lost-languages-machine-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24921013</guid>
            <pubDate>Wed, 28 Oct 2020 16:48:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chess Captcha]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24920945">thread link</a>) | @chadash
<br/>
October 28, 2020 | https://elioair.github.io/chesscaptcha/ | <a href="https://web.archive.org/web/*/https://elioair.github.io/chesscaptcha/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="main_content">
          <h3>
ChessCaptcha.</h3>

<p>This is a captcha system where the user either recreates the position of the pieces on the board - <em>non chess savvy users</em> - or she solves a mate-in-one puzzle by putting the piece on the square where it gives the checkmate - <em>chess savvy users only</em>. There is also a no-js fallback that exists mostly as a placeholder for future iterations; don't use it.</p>
        </section><section id="usage">
          <h3>
Usage.</h3>

<h4>Copy the position mode. - Default</h4>
<p>
  In this mode which happens to be the one where the user needs no chess knowledge at all to use, he simply drags the pieces
  into the board trying to replicate the position shown in the image.
</p>
<p>
  <img src="https://elioair.github.io/chesscaptcha/images/chesscaptchausage.gif">
</p>
<h4>Mate in One mode</h4>
<p>
  Here the user is given a position and where he has to move a piece to create a mating position on the board.
  Only chess players -and maybe computer engines. cough..!- will be able to solve this. It can be used for example in chess sites
  to determine if the user is really a chess player or a simple spammer.
</p>
<p>
  <img src="https://elioair.github.io/chesscaptcha/images/chesscaptchamatemode.gif">
</p>
<h4>Color Tolerance</h4>
<p>
  If needed you can turn on color tolerance. In this case the validation will be color agnostic and for example the white king will be 
  considered equal to the black king.
</p>
<p>
  <img src="https://elioair.github.io/chesscaptcha/images/chesscaptchacolortolerance.gif">
</p>
        </section></div>]]>
            </description>
            <link>https://elioair.github.io/chesscaptcha/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24920945</guid>
            <pubDate>Wed, 28 Oct 2020 16:44:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an Alliance Sacrée: An Abrahamic Framework for a Just Political Economy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24920731">thread link</a>) | @bmdavis
<br/>
October 28, 2020 | https://www.athwart.org/building-an-alliance-sacree/ | <a href="https://web.archive.org/web/*/https://www.athwart.org/building-an-alliance-sacree/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!--kg-card-begin: markdown-->
<p>This essay is a contribution from our symposium <em>Toward a Just Political Economy</em>. To receive a print copy and read the other essays, <a href="https://www.athwart.org/building-an-alliance-sacree/athwart.org/symposium">order here</a>.</p>
<hr>
<!--kg-card-end: markdown--><h2 id="the-collapse-of-political-economy">The Collapse of Political Economy</h2><p><strong>The invention of</strong> the individual is a relatively recent phenomenon. As the modern state’s development accelerated across the 19<sup>th</sup> century due to new technologies of transport and communications, complex social relations in both urban and rural areas collapsed. The response of ideological actors within the state, market, and civil society, was to encourage the creation of the worldview of progressive individualism. This doctrine was a way to socially engineer society for new purposes, namely, transhumanism and man’s escape from the restrictions of biology and nature. In this worldview, only the individual and state were meant to exist and, in a capitalist society, the market would mediate between the two. Because human beings are predisposed to form group feelings with each other this effort was destined to fail. The 14<sup>th</sup> century sociologist Ibn Khaldun termed this sentiment <em>asabiya</em>, meaning group solidarity or tribal feeling.<sup>1</sup> When possessing <em>asabiya</em>, members of an in-group are inclined to subsume any sense of “self-interest” entirely into the interest of the whole. As complex social relations and networks melted away, “society” was meant to substitute the subconscious yearning of the individual to find group feeling in an abstract blob of people.</p><p>The rise of economics, financialization of the economy, collapse of complex social relations, and homogenization of society into a mass of individual consumers combined to bring disaster. America, hoodwinked for decades by an ideology that asserted free trade would bring freedom worldwide, finds itself on the back foot against a calculating actor, China, that eschews economics as an ideology, seeing it merely as a toolkit to advance other, primarily political, interests. In America, society is collapsing. Americans are killing themselves at record rates; drug abuse is at a record high; and ever more young girls find themselves on the Tiktok-to-OnlyFans exploitation conveyor belt. Marriage and fertility rates are collapsing—although divorce isn’t doing too poorly. The coronavirus has brought all of this to a head and revealed just how rotten America’s social base has become. Still, the worst has yet to come. The November election threatens a new wave of social unrest and political polarization. Coronavirus lockdowns have revealed that most of the economy is quite simply fake and non-existent, with millions of people working fake jobs with accreditation rendered increasingly worthless due to inflation.</p><p>This political-economic experiment has failed. Our world has not seen greater justice and equality as a result of the triumph of the individual-market-state nexus. More importantly, the liberal institutions that underpin this nexus have proven unable to update themselves in the face of a rising techno-surveillance society. Liberalism has failed to meet the technology challenge, and it is being dragged into the void left behind by its “creative destruction” of faith and family. Any “new deal” that looks to rebuild communities has to take into account that liberalism is now living on the exhausted fumes of its inheritance. There needs to be a willingness to look at post-liberal solutions. Note that post-liberalism is not a repudiation of liberalism but its evolution, continuing with the good and surgically eliminating the bad—much of which has contributed to the destruction of faith and community, ultimately threatening the existence of the Republic.</p><p>My contribution to this emerging post-liberal framework is to borrow and synthesize it with elements from foreign civilizational frameworks to build a more just political economy. It isn’t good enough to handwave about the common good. We need real creativity and reorganization of communities; we must consider the way political structures interact with and sustain the health of these vital building blocks of civilization. Faiths are the last real nationwide communities left in America’s social hellscape. In particular, the three Abrahamic faiths—Judaism, Christianity, and Islam—possess the social technologies necessary to subsist for long periods of time, through rise and decline, prosperity and famine. They are anchors for civilizations in turmoil. It is incumbent we look at how exactly these faiths have survived around the world for such a long time so that we can adopt their traditions, methods, and norms to rebuild the foundations of today’s society.</p><p>I want especially to look at Islamic civilization’s heritage in matters of governance, political economy, and law. This legacy of thought is extensive and has existed in a symbiotic relationship with correspondent European traditions for over a millennium. It is not as alien as it may first appear, even if some wish it to be so. One of the modern state’s main problems, not just in America but worldwide, is that it opposes all forms of territorial autonomy not granted by the state itself. At best, this is bound within some sort of federalist structure. However, most of the thinking done by scholars and activists on autonomy and decentralization has focused on territorial autonomy. The Islamic millet system was a non-territorial form of autonomy that did not threaten the state’s control over its territory. Out-sourcing key functions of governance to communities, it devolved such duties as judiciary, education, and security. The millet system shares many principles with the American federalist system and can be adapted to the American tradition to help rebuild family and community, develop a healthy relationship with the state, and create a more just political economy.</p><p>Milletism is not integralism. Integralism, a political theory that has been in vogue among the Catholic right, entails the subordination of state to church to achieve a moral, common good. Integralism is only made possible by the existence of a centralized institution like the Catholic Church. Unlike the development of state-church relations in Europe, there has never been a centralized religious institution in Islamic civilization. The forefathers of America fled Europe to escape the tyranny and conflict arising between centralized religious and secular power. In doing so, they created a political and social system that at once prevented religious conflict from taking over at the top and ensured a level of decentralization that enabled various faith groups to live in peace. As such, there could be no a priori consideration of a division between the temporal and the divine, as these were not embodied in distinct institutions like the state and church, respectively. The boundaries between the secular (<em>qanun</em>, derived from the Latin “canon”) and the revelation (<em>shar’i</em>) have always been fluid. More importantly, this means the millet model followed a path dependency of development that provided both greater community autonomy alongside the state. It did not threaten political power and incentivized rulers to respect local autonomy. The millet system offers incentives to actors across social strata—except, of course, those whose interests it is to continually atomize and destroy social bonds for the sake of economic rent-seeking or radical political centralization, the road to tyranny.</p><h2 id="the-basis-of-an-alliance-sacr-e-in-the-21st-century"><em>The Basis of an Alliance Sacrée </em>in the 21st Century</h2><p><strong>In introducing Islamicate</strong> ideas of social, political, and economic organization to a western audience who may react with bewilderment if not hostility, it is important to establish a basis of cooperation and dialogue. Especially in times where we see the rise of pedophilia in music and film to the aggressive silencing of our beliefs and traditions, the Abrahamic faiths now need each other more than they oppose each other. Times have changed, and while some still meme about crusades to conquer Jerusalem or jihads to conquer Rome, faith communities are besieged by an incredibly aggressive and totalizing ideology that renders these issues irrelevant.</p><p>In Genesis, God promised Abraham:</p><p><em>And I will make thy seed to multiply as the stars of heaven and will give unto thy seed all these countries; and in thy seed shall all the nations of the earth be blessed.</em><sup>2</sup></p><p>Over half of the world’s population belongs to one of the three Abrahamic faiths. Outside of East Asia and India, the Abrahamic faiths predominate. God’s promise to Abraham was fulfilled. The shared blood and history of the children of Isaac and Ismael mean that there are primordial values, applicable across space-time, that characterize the core essence of the Abrahamic worldview. This shared experience distinguishes us, on a planetary scale, from any other group of beliefs, be they Sinic, Indic, or otherwise. These values should operate as the basis of collaboration against the encroaching power of the state and aggressive ideologies. As the beleaguered bearers of a worldview still imbued with the presence of the divine, the Abrahamic faiths’ response to the challenges of modernity has so far been haphazard and poor. Organized collaboration based on shared interests is almost non-existent beyond interfaith conferences and flaccid statements about tolerance and coexistence.</p><p>The English polymath and Islamic scholar Abdul Hakim Murad has repeatedly called for an “<em>alliance sacrée</em>” between the Abrahamic faiths to resist encroaching secularization and its deleterious effects: family breakdown, social atomization, and the rise of ersatz religions turning into bloody revolutions and cults.<sup>3</sup> If the imperative for Abrahamic collaboration is clear, then what are the fundamental principles that would underlie this collaboration? Ismail Royer offers a useful syllogism from the Muslim perspective:<sup>4</sup></p><p><strong>1.</strong> Islam, Christianity, and Judaism are all true in the things they agree on.</p><p><strong>2.</strong> Christianity &amp; Judaism are false in the things they disagree on with Islam.</p><p>Point 1 is the basis of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.athwart.org/building-an-alliance-sacree/">https://www.athwart.org/building-an-alliance-sacree/</a></em></p>]]>
            </description>
            <link>https://www.athwart.org/building-an-alliance-sacree/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24920731</guid>
            <pubDate>Wed, 28 Oct 2020 16:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Soil microbial fuel cells creating energy to filter daily drinking water]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24920724">thread link</a>) | @finphil
<br/>
October 28, 2020 | https://nuadox.com/post/633237102683947008/soil-microbial-fuel-cells-drinking-water | <a href="https://web.archive.org/web/*/https://nuadox.com/post/633237102683947008/soil-microbial-fuel-cells-drinking-water">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="633237102683947008">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/633237102683947008/soil-microbial-fuel-cells-drinking-water"><h2>Soil microbial fuel cells creating energy to filter a person’s daily drinking water</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1279"><img src="https://64.media.tumblr.com/d49c684e127dc7710aba2d09ce5f843a/cb41f8fb3a1fa627-7e/s1280x1920/833c368cae1170595309f9a6d5a9dbe941833de3.jpg" alt="image" data-orig-width="1920" data-orig-height="1279" width="1280" height="853"></figure><p><b>- By&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.bath.ac.uk%2F&amp;t=NzY1MmEyZTgzN2YzY2NmMjkxOWM3MGYzZjMwMjJjZGY0YWY1MWU5NSxqN2NuN3R6cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F633237102683947008%2Fsoil-microbial-fuel-cells-drinking-water&amp;m=0&amp;ts=1604175440">University of Bath</a> -</b></p><p>Soil microbial fuel cells have proved to be capable of creating energy to filter a person’s daily drinking water in a Brazil test.</p><ul><li>Fuel cells that create energy using chemical reactions in soil-based organisms in successful field test in North-East Brazil</li><li>They can be used to produce energy to filter enough water for a person’s daily needs, with potential to increase scale</li><li>“This project shows that SMFCs have true potential as a sustainable, low-energy source”, says project lead Dr Mirella Di Lorenzo</li></ul><p>Engineers at the University of Bath (in the UK) have shown that it’s possible to capture and use energy created by the natural reactions occurring in microorganisms within soil.</p><p>A team of chemical and electrical engineers has demonstrated the potential of cheap, simple ‘soil microbial fuel cells’ (SMFCs), buried in the earth to power an electrochemical reactor that purifies water.</p><p>The proof-of-concept design was demonstrated during field testing in North-East Brazil that took place in 2019 and showed that SMFCs can purify about three litres of water per day- enough to cover a person’s daily water needs.</p><figure data-orig-width="1440" data-orig-height="960"><img src="https://64.media.tumblr.com/62df5f3f41e6ea1fd2e9c9f77bbd83c3/cb41f8fb3a1fa627-09/s1280x1920/1dfe540a44f26bcc97389fd7c892785e71f9b57f.jpg" alt="image" data-orig-width="1440" data-orig-height="960" width="1280" height="853"></figure><p><i>Image:&nbsp;Soil microbial fuel cells as designed by researchers at the University of Bath. Credit:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.eurekalert.org%2Fmultimedia%2Fpub%2F247083.php&amp;t=MTZkOWZjNTUyNjc5MDJmNWI5NWVmNmIwNTBhYjhhYjQ3YWIzMDEyZixqN2NuN3R6cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F633237102683947008%2Fsoil-microbial-fuel-cells-drinking-water&amp;m=0&amp;ts=1604175440">University of Bath</a>.</i></p><p>The project is a collaboration with a team of geographers from <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwww.ufc.br%2F&amp;t=M2ZlOTdiNWFmZDY4ZGU3M2QyNDQzNWEwYTk2ZGQ3OTdjZjUwYThhOCxqN2NuN3R6cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F633237102683947008%2Fsoil-microbial-fuel-cells-drinking-water&amp;m=0&amp;ts=1604175440">Universidade Federal do Ceará</a> and a team of chemists from <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.ufrn.br%2F&amp;t=ZjBmY2ZiYTc0ODYxNWVlYWEwNTcyMTY2YWIzN2RlN2E0NGExZWJlMCxqN2NuN3R6cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F633237102683947008%2Fsoil-microbial-fuel-cells-drinking-water&amp;m=0&amp;ts=1604175440">Universidade Federal do Rio Grande do Norte</a>.</p><p>Testing took place in Icapuí, a fishing village located in a remote semi-arid location where the main source of drinking water is rainwater and access to a reliable power network is scarce.</p><p>Rainwater must be chlorinated to be drinkable, and in addition to causing bad taste and odour, uncontrolled chlorination is dangerous to human health - so safe methods to treat water are essential.</p><h2><b>Soil microbial fuel cells shown to work in the field</b></h2><p>SMFCs generate energy from the metabolic activity of specific microorganisms (electrigens) naturally present in soil, which are able to transfer electrons outside their cells.</p><p>The system, developed by staff from Bath’s <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.bath.ac.uk%2Fdepartments%2Fdepartment-of-chemical-engineering%2F&amp;t=MGE3ZjJiZTYzYzBmOTk3MTZmODc2N2ZhYTViNzQ3OGY5Mzc5ZjdjNyxqN2NuN3R6cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F633237102683947008%2Fsoil-microbial-fuel-cells-drinking-water&amp;m=0&amp;ts=1604175440">Department of Chemical Engineering</a> and <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.bath.ac.uk%2Fdepartments%2Fdepartment-of-electronic-electrical-engineering%2F&amp;t=ODM2MDk4OTVmN2I2YTc3ZDNjODdiMGVlZTYzNGNkMjhjODExM2Y5MCxqN2NuN3R6cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F633237102683947008%2Fsoil-microbial-fuel-cells-drinking-water&amp;m=0&amp;ts=1604175440">Department of Electronic &amp; Electrical Engineering</a>, consists of two carbon-based electrodes positioned at a fixed distance apart (4cm) and connected to an external circuit. One electrode, the anode, is buried inside the soil, while the other, the cathode, is exposed to air on the soil surface.</p><p>Electrigens populate the surface of the anode and as they ‘consume’ the organic compounds present in soil, they generate electrons. These electrons are transferred to the anode and travel to the cathode via the external circuit, generating electricity.</p><p>By building a stack of several SMFCs, and by connecting this to a battery it is possible to harvest and store this energy, and use it to power an electrochemical reactor for water treatment.</p><p>A single SMFC unit costs just a few pounds, which could be further reduced with mass production and with the use of local resources for the electrode fabrication.</p><h2><b>Cheap and sustainable solution for a chlorination problem</b></h2><p>The need for sustainable water purification in the area stems from the fact that the main supply of water is from precipitation, which needs to be chlorinated to be drinkable.</p><p>The technology, installed at the EEF Professora Mizinha of Icapuí primary school, creates a small amount of power, which can be used to purify up to three litres of water in about a day. Further research is needed to scale-up its capacity.</p><p>The team is aiming to refine the design of the equipment and its efficiency to allow one piece of equipment to purify the water needed by a family in a day. This presents three challenges: generating enough energy; collecting and storing that energy effectively; and treating the water efficiently to ensure quality and drinkability.</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fresearchportal.bath.ac.uk%2Fen%2Fpersons%2Fmirella-di-lorenzo&amp;t=OWEyNWZjODVlYjQyZDJkYjA1MjZlN2M4MjQ0ZjM1NzY1N2I4NGViYSxqN2NuN3R6cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F633237102683947008%2Fsoil-microbial-fuel-cells-drinking-water&amp;m=0&amp;ts=1604175440">Dr Mirella Di Lorenzo</a>, who led the project said: “Using soil microbial fuel cell technology to treat a family’s daily water needs is already achievable in laboratory conditions, but doing so outdoors and with a system that requires minimal maintenance is much trickier, and this has previously proven a barrier to microbial fuel cells being considered effective. This project shows that SMFCs have true potential as a sustainable, low-energy source.”</p><figure data-orig-width="1440" data-orig-height="960"><img src="https://64.media.tumblr.com/c81b6c2124ad93ef4c46cfb68d9533dd/cb41f8fb3a1fa627-3a/s1280x1920/fca5f3fa5884d20659d17d182cdacea29dd5c805.jpg" alt="image" data-orig-width="1440" data-orig-height="960" width="1280" height="853"></figure><p><i>Image:&nbsp;Jakub Dzieglowski, Dr Jannis Wenk and Dr Mirella Di Lorenzo from the University of Bath testing soil microbial fuel cells in Icapui, Brazil. Credit:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.eurekalert.org%2Fmultimedia%2Fpub%2F247084.php&amp;t=MzJkMjVmYjdkOTdkMWQ4OTVkNDI3MWMxMjEyYzhkOTQ4NjA3MTMwNCxqN2NuN3R6cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F633237102683947008%2Fsoil-microbial-fuel-cells-drinking-water&amp;m=0&amp;ts=1604175440">University of Bath</a>.</i></p><p>She added: “We’re addressing the issue of water scarcity and energy security in North-East Brazil, which is a semi-arid area. We sought a sustainable way to treat water effectively and make it drinkable. Rainwater is the main source of drinking water in the area, but this is not sterile - our approach in this work points to a way we could solve the issue.</p><p>“Another important element of our project is education around sustainable technologies. The field work was performed together with primary school pupils and their teachers. They were trained on the system’s working principles, installation and maintenance.”</p><p>During the fieldwork, which took place in 2019, a system was installed at the primary school, where it was tested to ensure it could replicate results previously seen in the lab.</p><p>The Brazilian leader of the project, Dr. Adryane Gorayeb, from Federal University of Ceará (UFC), said: “The application of the technology, as well as the educational element of the project, provided a transformative experience to the pupils, that have broadened their world view.</p><p>“The pupils helped with the soil microbial fuel cells fabrication and have learned how to handle the technology. They also participated in a dedicated workshop to raise environmental awareness, based on the United Nations Sustainable Development Goals.”</p><figure data-orig-width="1440" data-orig-height="960"><img src="https://64.media.tumblr.com/318af471e0f34f76c34657de1695b508/cb41f8fb3a1fa627-a5/s1280x1920/73b6f85f8dc93b316b60cf661364741d4e4e2248.jpg" alt="image" data-orig-width="1440" data-orig-height="960" width="1280" height="853"></figure><p><i>Image:&nbsp;Students from EEF Professora Mizinha of Icapuí primary school, Brazil, learn about soil microbial fuel cells. Credit: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.eurekalert.org%2Fmultimedia%2Fpub%2F247085.php&amp;t=ZDY3ZWJhMTRhMjE0NmRmZmRjODNmMGQ1Y2YxNTI4M2I3NWQ3YzM1NCxqN2NuN3R6cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F633237102683947008%2Fsoil-microbial-fuel-cells-drinking-water&amp;m=0&amp;ts=1604175440">University of Bath</a>.</i></p><p>The project, which is funded by Research England under the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.ukri.org%2Fresearch%2Fglobal-challenges-research-fund%2F&amp;t=ODUzMDc0NzBmZGJhMzZkMGZlZWJiZGJhNWI0ZjYwOTU4MzkwYTM3MixqN2NuN3R6cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F633237102683947008%2Fsoil-microbial-fuel-cells-drinking-water&amp;m=0&amp;ts=1604175440">Global Challenges Research Fund</a> (GCRF) frame and by The Brazilian National Council for Scientific and Technological Development, has now been granted further funds to continue its work and improve the design and efficiency of the fuel cells.</p><p>–</p><p><b>Source: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.bath.ac.uk%2Fannouncements%2Fsoil-powered-fuel-cell-promises-cheap-sustainable-water-purification%2F&amp;t=Y2IxMmY4NjE1NmYyMmE0YzdkYjM2MTE3NzM3MjA1YmY2ZmExNDMxNCxqN2NuN3R6cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F633237102683947008%2Fsoil-microbial-fuel-cells-drinking-water&amp;m=0&amp;ts=1604175440">University of Bath</a></b></p><p><b>Full study:</b>&nbsp;“Development of a functional stack of soil microbial fuel cells to power a water treatment reactor: From the lab to field trials in North East Brazil”,&nbsp;<i>Applied Energy</i>.</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fdoi.org%2F10.1016%2Fj.apenergy.2020.115680&amp;t=ZWJkMWZjMGRmMTI5ZmZiNzZkMTQ2ZDJhNTVhYmQ0NDYzN2Y1MTE0ZCxqN2NuN3R6cw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F633237102683947008%2Fsoil-microbial-fuel-cells-drinking-water&amp;m=0&amp;ts=1604175440">https://doi.org/10.1016/j.apenergy.2020.115680</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/183742644057/smartphone-biosensor-arsenic-detection">Smartphone biosensor uses bacteria to detect unsafe arsenic levels</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/water">water</a>
                                    
                                        <a href="https://nuadox.com/tagged/soil">soil</a>
                                    
                                        <a href="https://nuadox.com/tagged/energy">energy</a>
                                    
                                        <a href="https://nuadox.com/tagged/water-purifier">water purifier</a>
                                    
                                        <a href="https://nuadox.com/tagged/hydrology">hydrology</a>
                                    
                                        <a href="https://nuadox.com/tagged/chemistry">chemistry</a>
                                    
                                        <a href="https://nuadox.com/tagged/physics">physics</a>
                                    
                                        <a href="https://nuadox.com/tagged/water-filter">water filter</a>
                                    
                                    </p>
                                </span></p>
                                
<ol><!-- START NOTES --><!-- END NOTES --></ol></div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/633237102683947008/soil-microbial-fuel-cells-drinking-water</link>
            <guid isPermaLink="false">hacker-news-small-sites-24920724</guid>
            <pubDate>Wed, 28 Oct 2020 16:28:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If Not SPAs, What?]]>
            </title>
            <description>
<![CDATA[
Score 341 | Comments 426 (<a href="https://news.ycombinator.com/item?id=24920702">thread link</a>) | @todsacerdoti
<br/>
October 28, 2020 | https://macwright.com/2020/10/28/if-not-spas.html | <a href="https://web.archive.org/web/*/https://macwright.com/2020/10/28/if-not-spas.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A few months ago, I <a href="https://macwright.com/2020/05/10/spa-fatigue.html">wrote an article about how the SPA pattern has failed to simplify web development</a>. The <em>SPA pattern</em> (Single-Page Apps), I tried to define, was about the React model, which also covers, to a large extent, the model of Vue, Angular, and other frontend frameworks.</p><p>Like any critique, it begs for a prescription and I didn’t give one, other than gesturing toward server-side frameworks like Rails and Django. But I think there are some trends starting to form. I had queued up some time to <em>really dive into the frameworks</em>, but things like <a href="https://macwright.com/2020/10/12/holly-park.html">walking in parks</a> have taken priority, so here’s just a grand tour.</p><h3 id="opinionated-full-stack-javascript-frameworks">Opinionated full-stack JavaScript frameworks</h3><p>Primarily I’m talking about <a href="https://remix.run/features">Remix</a>, <a href="https://redwoodjs.com/">RedwoodJS</a>, and <a href="https://blitzjs.com/">Blitz.js</a>, though I’m sure there are similar efforts in the non-React world that are relevant. <a href="https://nextjs.org/">Next.js</a> <em>almost</em> falls into this category, but as far as I can tell, it’s still unopinionated about the data layer and most sites that use Next.js are still going to use a separate API stack. But that’s subject to change, because all of these are moving fast.</p><p>It’s interesting to note that Remix, Redwood, and Next are all backed by companies or foundations, and that Blitz is aiming early on to be a <a href="https://github.com/sponsors/blitz-js">sponsor-funded project</a>. These projects, I think, are trying to sidestep the “tragedy of the commons” failures of earlier open source, wherein overworked and unpaid maintainers service a large userbase and eventually burn out and abandon the project.</p><p>To take Remix as an example, it re-ties data loading with routes, and then gives the pretty amazing promise of <em>no client side data fetching by default</em>. These frameworks are also <em>opinionated about status codes and caching strategies</em>. RedwoodJS automatically creates an <a href="https://redwoodjs.com/tutorial/side-quest-how-redwood-works-with-data">ORM-like interface using GraphQL and Prisma</a>.</p><p>As context, Remix is backed by the folks from <a href="https://reacttraining.com/">React Training</a>, who are also the folks from <a href="https://reactrouter.com/">React Router</a>, which is as much React pedigree as you can get without joining the team at Facebook. Redwood is run by <a href="https://prestonwernerventures.com/">Preston-Werner Ventures</a>, of <a href="https://en.wikipedia.org/wiki/Tom_Preston-Werner">Tom Preston-Werner</a>, a GitHub founder. Next.js is sponsored and heavily promoted by <a href="https://vercel.com/">Vercel</a>, née Zeit.</p><h3 id="turbolinks">Turbolinks</h3><p>It’s worthwhile to just mention <a href="https://github.com/turbolinks/turbolinks">Turbolinks</a>. I didn’t use it until this year, and apparently there were issues with it before, but the pitch for Turbolinks 5 is: <em>what is the bare minimum you need to do to get the SPA experience without any cooperation from your application?</em></p><p>So it’s a tiny JavaScript library that sits on top of an existing server-rendered application and replaces full pageloads with SPA-like partial pageloads. Instead of loading a page from scratch, pages are loaded with AJAX, page contents are replaced, and client-side navigation updates your URLs. Basically, it prevents the ‘blink’ of real page transitions and saves on all othe sorts of costs of fully loading a new page. Turbolinks was spawned from the <a href="https://rubyonrails.org/">Ruby on Rails</a> project, and works great with Rails but doesn’t require it.</p><p>In terms of power-to-weight for user experience improvements, Turbolinks is a standout: it adds very little complexity and a tiny size impact for a big user experience improvement.</p><h3 id="server-side-state-frameworks">Server-side-state frameworks</h3><p>These are the spiciest new solution. The main contenders are <a href="https://laravel-livewire.com/">Laravel Livewire</a> (in PHP), <a href="https://docs.stimulusreflex.com/">Stimulus Reflex</a> (for Ruby on Rails), and <a href="https://github.com/phoenixframework/phoenix_live_view">Phoenix LiveView</a> (on Phoenix, in Elixir).</p><p>The pitch here is: <em>what if you didn’t have to write any JavaScript?</em> It sort of hearkens back to the critique of JavaScript in <a href="https://vimeo.com/5047563">_why’s ART &amp;&amp; CODE talk</a>, that web development is the only kind where you normally have to write in three (or more) languages. These languages also most remnants of “client-side” logic, putting it all on the server side.</p><p>How do they do this? Well, a lot of WebSockets, in the case of Reflex and LiveView, as well as very tightly coupled server interactions. As you can see in the <a href="https://www.phoenixframework.org/blog/build-a-real-time-twitter-clone-in-15-minutes-with-live-view-and-phoenix-1-5">LiveView demo</a>, which I highly recommend, these frameworks tend to operate sort of like reactive DOM libraries on the front end – in which the framework figures out minimal steps to transform from one state to another - except those steps are computed on the server side and then generically applied on the client side. They also do a lot more data storage &amp; state management on the server-side, because a lot of those interactions which wouldn’t be persisted to the server are now at least communicated to the server.</p><p>These frameworks are exciting, and also extremely contrarian, because they are the polar opposite of the “frontend plus agnostic API layer” pattern, and they also wholeheartedly embrace the thing everyone tries to avoid: mutable state on the server.</p><h3 id="modest-progressive-enhancement-javascript-frameworks">Modest progressive-enhancement JavaScript frameworks</h3><p>These are typically used “in addition” to the above, but they certainly deserve a shout-out because I think a wide swath of frontend-programming concerns actually only need a tiny hint of JavaScript. But the main caveat is that <em>they assume that you know JavaScript and the DOM</em>, which are not necessarily universal skills anymore. A lot of developers growing up on React have acquired a real blind spot for native browser APIs.</p><p>The main ones I’ve looked at are <a href="https://stimulusjs.org/">Stimulus</a> (out of the Ruby on Rails camp), <a href="https://github.com/alpinejs/alpine/">Alpine</a>, and <a href="https://htmx.org/">htmlx</a>. They’re all tiny, and work great in <em>existing pages</em>. I think – and here come the flames – <a href="https://developer.mozilla.org/en-US/docs/Web/Web_Components">Web Components</a> also fit into this sphere of progressive enhancement! If you just use good web components - <a href="https://github.com/search?q=topic%3Aweb-components+org%3Agithub&amp;type=Repositories">only ones that GitHub writes is a good rule of thumb</a> - then they can fit the role of just improving an existing static UI. It’s where you start to use Web Components as an apples-to-apples replacement for full-fledged frontend frameworks is where things seem to get dicey.</p><p>These frameworks have the luxury of operating on a deeply improved web stack, one with fundamental components like <a href="https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API">fetch()</a> and <a href="https://developer.mozilla.org/en-US/docs/Web/API/MutationObserver">MutationObserver</a>. These things were previously at the core of the utility of progressive enhancement frameworks, and now they can just be the utilities that those frameworks build on.</p><hr><p>I’m sure that there are additional patterns out there! But these currents all seem strong right now, and it’s fascinating to see some really divergent and adventurous – and common-sense – approaches start to crop up.</p></div></div>]]>
            </description>
            <link>https://macwright.com/2020/10/28/if-not-spas.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24920702</guid>
            <pubDate>Wed, 28 Oct 2020 16:27:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Svelte for Sites, React for Apps]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24920412">thread link</a>) | @himynameisdave
<br/>
October 28, 2020 | https://www.swyx.io/svelte-sites-react-apps/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/svelte-sites-react-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In 2020, my personal recommendation to web developers is to use <strong>Svelte for Sites, and React for Apps</strong>. This is, remarkably, a nuanced enough opinion that it pisses off fans of <em>either</em> of them.</p>
<p>I mentioned this in my <a href="https://shoptalkshow.com/432/">Shoptalk Show interview</a> and Chris Coyier encouraged me to blog about it. Let me try to explain.</p>
<section>
  <h2 id="sites-vs-apps"><a href="#sites-vs-apps">Sites vs Apps</a></h2>
  <p>First, I have to make a distinction between (Web) Sites and (Web) Apps. There are serious, intelligent people who insist that there isn't one. They want to build everything on the web with the same tech. Respectfully, <a href="https://macwright.com/2020/08/22/clean-starts-for-the-web.html">they are wrong</a>.</p>
  <p><strong>Web Sites</strong> primarily display content, while interaction is limited. First-load times are paramount since users may bounce and/or their limited data/power/CPU may deprive them of important information (see <a href="https://infrequently.org/2017/10/can-you-afford-it-real-world-web-performance-budgets/">Alex Russell for math on a reasonable baseline</a> but let's say you definitely want &lt;200kb in the critical path). This was the web's original usecase - displaying information - and it is what HTML/CSS/Browsers are great at.</p>
  <p><strong>Web Apps</strong> primarily exist for interaction. CRUD apps, livestream apps, games, whatever. These apps tend to be heavier, which is unfortunate because that affects their performance. But even a 2MB JS app doesn't sound so bad when it is literally competing with a 200MB mobile app, and (let's say) you're developing a B2B app where everyone is on high power and high bandwidth devices anyway. You're typically also keeping apps open longer, so the first-load issue doesn't matter as much (and can be mitigated with service workers). The challenge is even higher once you account for the fact that the Web App must ship with it all the UI components and behaviors for it to work, whereas a typical native app will usually heavily lean on platform-provided components. The web platform still lacks a lot of standard components/APIs and developer experience needed to make writing great Web Apps easy - hence the gap is filled by frameworks.</p>
  <p>I view Sites vs Apps as a spectrum. Of course, if your sites dont need ANY interaction at all, don't use any JS. But most sites have app-like features (login, reactions, comments), and many apps need to perform under site-like constraints.</p>
  <p>You'll notice that most businesses already recognize this - <code>www.mysaas.com</code> is the marketing site, <code>app.mysaas.com</code> is the app. They may start out the same codebase, but due to the vastly different requirements, they eventually split into different codebases and then different teams handling them. It's usually the idealist enthusiasts that try to make the same tech work for these clearly different purposes.</p>
</section>
<section>
  <h2 id="react-for-apps"><a href="#react-for-apps">React for Apps</a></h2>
  <p>React has been open sourced for 7 years now. It is used in production at the biggest companies and sites in the world from Apple to Twitter to Amazon to Airbnb to Uber. It has been the most cited technology in Hacker News job postings for <a href="https://www.hntrends.com/2020/may-big-drop-developer-job-postings.html">at least 36 straight months</a>. There are <a href="https://twitter.com/swyx/status/1190088019707154432?s=20">between 3-9m React developers</a>, growing <a href="https://twitter.com/swyx/status/1024974678337703937?s=20">at least &gt;50% annually</a>. The <a href="https://youtu.be/Qox56z4xH6o">third party ecosystem is vast</a> and attracting instructors, developers, companies and hundreds of millions in corporate and venture funding.</p>
  <p>Based on that <em>alone</em> it is a good tech choice to base your app on already. But these are contingent facts that don't really have anything fundamental to do with React's merits. This is offensive to <a href="https://www.swyx.io/first-principles-approach/">first principles thinkers</a>. So let me offer some <em>core</em> reasons why React is a great choice for apps:</p>
  <ul>
    <li>React Native looked troubled in 2018, but <a href="https://www.reactiflux.com/transcripts/react-native-team-2">the current team</a> seems to be executing well (as far as an outsider like me can tell). <a href="https://twitter.com/swyx/status/1301103950066671616?s=20">Flutter may yet give it a run for its money</a> someday, but has the Dart and Google hurdles to overcome. <strong>React Native is the best cross platform (mobile+web+desktop) "Write mostly once, run mostly anywhere" solution</strong> in tech today. If you have the resources to hire platform specialists, <a href="https://medium.com/airbnb-engineering/sunsetting-react-native-1868ba28e30a">you won't find this useful</a>. However, if, like the vast majority of companies, you can't afford a dedicated team of specialists per platform, React Native is your best bet.</li>
    <li>React has by far the most experience in abstraction design. <strong>Where React leads, other frameworks follow</strong> (Both Vue's <a href="https://composition-api.vuejs.org/">Composition API</a> and <a href="https://www.youtube.com/watch?v=AdNJ3fydeao">Svelte 3's $: API</a> directly credit React for inspiration, as do Swift UI and Jetpack Compose). This isn't to say they always get it right (<em>pop quiz: how many Context APIs are there in React?</em>) but when <a href="https://reactjs.org/docs/concurrent-mode-intro.html">Concurrent Mode</a> and <a href="https://twitter.com/brian_d_vaughn/status/1308438105616191496?s=20">React Flight</a> are released, I expect it to be deeply informed by production usage at the biggest websites in the world. Suspense for Data Fetching, still not yet released, has <a href="https://engineering.fb.com/web/facebook-redesign/">been in production at Facebook</a> for over a year. I want to stress how unusual this is - typically in open source, you release something and then hope it gets picked up by a BigCo and tested at scale. With React, Facebook <strong>dogfoods it at scale</strong> before releasing to the general developer community, with <a href="https://github.com/facebook/react/issues/15257">many</a> <a href="https://github.com/facebook/prepack/wiki/react-compiler">ideas</a> <a href="https://cdb.reacttraining.com/react-call-return-what-and-why-7e7761f81843">killed</a> before they are publicly blessed, because flaws were found. Judge React as much on what it doesn't ship as you do on what it does ship.</li>
    <li>That brings me to governance. It's not perfect (many people have issues with Facebook, for one thing), but I think <strong>React is one of the best run open source projects in the world</strong>. Normally mundane things like <a href="https://reactjs.org/docs/faq-versioning.html">versioning policy</a> to <a href="https://reactjs.org/docs/error-decoder.html/">error messages</a> to <a href="https://reactjs.org/blog/2019/10/22/react-release-channels.html">release channels</a> to <a href="https://reactjs.org/blog/2020/10/20/react-v17.html#gradual-upgrades">gradual upgrades</a> matter at the scale of React. The team also does a lot of informal collaboration with key ecosystem partners like Gatsby, Apollo and Next.js, including at the browser level with Chrome and the language level with TC39. The team not only deeply cares about technical governance, but also fostering an inclusive and diverse community.</li>
    <li>I hesitated to mention this last point because it technically has to do with adoption, but I cannot separate it from React's merits: it seems to have <strong>the best thinkers on accessibility and interaction design</strong> right now. No other ecosystem has projects like Adobe and Devon Govett's <a href="https://react-spectrum.adobe.com/react-aria/index.html">React Aria</a> that has extensively thought through and tested for WAI-ARIA so you don't have to. Ditto <a href="https://www.smashingmagazine.com/2020/07/accessible-front-end-application-chakra-ui-nuxtjs/">Segun Adebayo's Chakra UI</a>. Or listen to <a href="https://www.youtube.com/watch?v=LhKglxQT4sU">Rick Hanlon on the Touchable Web</a> and realize how much web apps need to improve for the open web to reverse <a href="https://vimeo.com/364402896">its alarming decline vs. mobile walled gardens</a>.
      <ul>
        <li>Let me be clear - is the React community ACTUALLY good at these things today? Hell to the no. Most of them are still debating whether or not to learn hooks vs class components. BUT React has the best shot because it has the best abstractions that enable the best thinkers to create the web application standard library we all want.</li>
      </ul>
    </li>
    <li><a href="https://github.com/facebook/react/pull/17004">Selective</a> and <a href="https://twitter.com/dan_abramov/status/1200111677833973760?s=20">Progressive Hydration</a> are particularly interesting results of the Fiber rewrite. Together with a "full stack" future of React that lets the developer <a href="https://twitter.com/dan_abramov/status/1259615888438935556?s=20">easily move code and execution between client and server</a>, the hope for making apps that feel fast without compromising on developer or user experience is extremely strong.</li>
  </ul>
  <p>You can, of course, use React to make sites. Gatsby and Next.js (and the upcoming <a href="https://remix.run/">Remix</a>) are great static and serverless rendering options (The "greatness" of Gatsby <a href="https://dev.to/richharris/in-defense-of-the-modern-web-2nia">is disputed</a>). <a href="https://docusaurus.io/">Docusaurus</a> is great for docs sites. If you are making sites and are worried about JS weight, you can usually <a href="https://twitter.com/swyx/status/1316540904761520129?s=20">swap Preact for React in a few lines of code</a> because you will usually not be running into any of <a href="https://preactjs.com/guide/v8/differences-to-react/">Preact's compromises</a> if you are just making a site.</p>
  <p>So why do I advocate using a different framework for sites?</p>
</section>
<section>
  <h2 id="svelte-for-sites"><a href="#svelte-for-sites">Svelte for Sites</a></h2>
  <blockquote>
    <p>Specifically, Svelte for <em>Interactive</em> Sites</p>
  </blockquote>
  <p>
    Svelte is <a href="https://twitter.com/SvelteSociety/status/1260209026563858432?s=20">used in production</a>
    from the NY Times (of course) to Square Enix to Apple to Spotify to Google Arts to Alaska Airlines and <a href="https://github.com/sveltejs/community/tree/master/who's-using-svelte">hundreds more</a>, with other big dev platforms like Amazon and Microsoft also increasingly featuring it in their content. It has a lively community with the first podcasts, YouTube channels, schools, conferences and newsletters emerging. Svelte 3 has been wildly successful and yet it is still early days.
  </p>
  <p>I'm going to let you in on a little secret: <a href="https://twitter.com/buildsghost/status/1255936971265826816?s=20">Svelte and React aren't that different</a>. Take a look <a href="https://lihautan.com/compile-svelte-in-your-head-part-1/#compile-svelte-in-your-head">under the hood of Svelte compiled output</a>:</p>
  <pre><code><span>function</span><span> </span><span>create_fragment</span><span>(</span><span>ctx</span><span>)</span><span> </span><span>{</span>
<span>  </span><span>// redacted</span>
<span>}</span>

<span>export</span><span> </span><span>default</span><span> </span><span>class</span><span> </span><span>App</span><span> </span><span>extends</span><span> </span><span>SvelteComponent</span><span> </span><span>{</span>
<span>  </span><span>constructor</span><span>(</span><span>options</span><span>)</span><span> </span><span>{</span>
<span>    </span><span>super</span><span>()</span><span>;</span>
<span>    </span><span>init</span><span>(</span><span>this,</span><span> </span><span>options</span><span>,</span><span> </span><span>null,</span><span> </span><span>create_fragment</span><span>,</span><span> </span><span>safe_not_equal</span><span>,</span><span> </span><span>{}</span><span>)</span><span>;</span>
<span>  </span><span>}</span>
<span>}</span>
</code></pre>
  <p>Wtf? <code>class App extends SvelteComponent</code>?? That looks like React??</p>
  <p>Yes. Wait til you realize that <a href="https://lihautan.com/compile-svelte-in-your-head-part-1/#updating-data"><code>=</code> basically compiles to <code>setState</code></a>, or that yes, it does actually <a href="https://github.com/sveltejs/svelte/tree/master/src/runtime">ship a runtime</a>, or that yes, it actually has <a href="https://github.com/sveltejs/svelte/blob/ec0f79c5af3113bedf0a5e9ae1f5f521328fcd30/src/runtime/internal/scheduler.ts">a scheduler</a> too. Like I said, where React leads, other frameworks follow. React proved Components are the right way to go.</p>
  <p>This also means that <a href="https://youtu.be/xgER1OutVvU">most React developers can learn Svelte in <em>hours</em></a> so the switching cost is low.</p>
  <p>The differences are large enough, though, in everything else:</p>
  <ul>
    <li><strong>JS Weight</strong>. Your site might get green Lighthouse scores, but hopefully you agree that you ideally only ship JS that you use, for your users' sake. Svelte sites are often single digit kilobytes. React+React DOM is ~120kb uncompressed. You can of course slash this severely if you can switch to Preact. But Svelte offers <a href="https://twitter.com/SvelteSociety/status/1314255119555338241">the smallest measured runtime footprint</a>. We used to worry about the compiler output overhead exceeding the size of React components (smaller runtime = more boilerplate), but <a href="https://twitter.com/SvelteSociety/status/1297548737091264518?s=20">recent studies have debunked this concern completely</a>.
      <ul>
        <li>But my consideration of JS weight extends beyond just the framework. Anecdotally, the kind of people that are drawn to Svelte seem to be more performance-minded than those in React (see everything that <a href="https://github.com/lukeed/">lukeed</a> makes). This comes from the top - where React devs often import heavy dependencies as long as they kinda fit the usecase, Rich Harris is the kind of stubborn developer that makes his own version of everything because he just needs it to do a smaller job. But also, Svelte is most people's <em>second</em> framework, so they come to it with more of a performance mindset. Collectively, the dependency choices encouraged by the framework's culture also impact the end result of JS weight.</li>
        <li>I am even encouraged by the emerging JAMstack culture in …</li></ul></li></ul></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.swyx.io/svelte-sites-react-apps/">https://www.swyx.io/svelte-sites-react-apps/</a></em></p>]]>
            </description>
            <link>https://www.swyx.io/svelte-sites-react-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24920412</guid>
            <pubDate>Wed, 28 Oct 2020 16:06:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding GAN Loss Functions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24920406">thread link</a>) | @patrycjaneptune
<br/>
October 28, 2020 | https://neptune.ai/blog/gan-loss-functions | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/gan-loss-functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p>Ian Goodfellow introduced Generative Adversarial Networks (GAN) in 2014. It was one of the most beautiful, yet straightforward implementations of Neural Networks, and it involved two Neural Networks competing against each other. <em>Yann LeCun, </em>the founding father of Convolutional Neural Networks (CNNs), described GANs as “<strong>the most interesting idea in the last ten years in Machine Learning</strong>“.</p>



<p>In simple words, the idea behind GANs can be summarized like this:</p>



<ul><li>Two Neural Networks are involved.</li><li>One of the networks, the Generator, starts off with a random data distribution and tries to replicate a particular type of distribution.</li><li>The other network, the Discriminator, through subsequent training, gets better at classifying a forged distribution from a real one.</li><li>Both of these networks play a min-max game where one is trying to outsmart the other.</li></ul>



<p>Easy peasy lemon squeezy… but when you actually try to implement them, they often don’t learn the way you expect them to. One common reason is the overly simplistic<a href="https://developers.google.com/machine-learning/gan/loss" target="_blank" rel="noreferrer noopener nofollow"> loss function</a>.&nbsp;</p>



<p>In this blog post, we will take a closer look at GANs and <a href="https://towardsdatascience.com/gan-objective-functions-gans-and-their-variations-ad77340bce3c" target="_blank" rel="noreferrer noopener nofollow">the different variations to their loss functions</a>, so that we can get a better insight into how the GAN works while addressing the unexpected performance issues.&nbsp;</p>






<h2>Standard GAN loss function (min-max GAN loss)</h2>



<p>The standard GAN loss function, also known as the <strong>min-max loss, </strong>was first described in a 2014 paper by Ian Goodfellow et al., titled “<a href="https://arxiv.org/abs/1406.2661" target="_blank" rel="noreferrer noopener nofollow">Generative Adversarial Networks</a>“.</p>



<div><figure><img src="https://lh6.googleusercontent.com/bNCS4HQXVJHa7mAv7CqQWbyJn076w5d5liTpVOV8meRz2tYtjtR-p92opSH9zAb4Yv2qhF0hMAyWvQef3a2EqR4J_dLq3-ZjsJufN38r-FBbSB1cRUjMyd5JrExyUh9JYfOdSQ2e" alt=""></figure></div>



<p>The generator tries to minimize this function while the discriminator tries to maximize it. Looking at it as a min-max game, this formulation of the loss seemed effective.&nbsp;</p>



<p>In practice, it saturates for the generator, meaning that the generator quite frequently stops training if it doesn’t catch up with the discriminator.</p>



<p>The Standard GAN loss function can further be categorized into two parts: <strong>Discriminator loss</strong> and <strong>Generator loss</strong>.</p>



<h3><strong>Discriminator loss</strong></h3>



<p>While the discriminator is trained, it classifies both the real data and the fake data from the generator.</p>



<p>It penalizes itself for misclassifying a real instance as fake, or a fake instance (created by the&nbsp; generator) as real, by maximizing the below function.</p>



<div><figure><img loading="lazy" src="https://lh4.googleusercontent.com/yAT4vN1GFT8D0QUDMAReZS0BLD_vi7KZc-AE02RFWI9ZVSQHLqKTTthtgx_BK-DlKOeFDgtkA3byl9VMHPEI0r5ZTn1nKYLbeEflJuspuykXcNMOmEmXomWZzMwdzUBbxf-BlkjJ" alt="" width="566" height="100"></figure></div>



<ul><li><strong>log(D(x)) </strong>refers to the probability that the generator is rightly classifying the real image,</li><li>maximizing <strong>log(1-D(G(z))) </strong>would help it to correctly label the fake image that comes from the generator.</li></ul>



<h3><strong>Generator loss</strong></h3>



<p>While the generator is trained, it samples random noise and produces an output from that noise. The output then goes through the discriminator and gets classified as either “Real” or “Fake” based on the ability of the discriminator to tell one from the other.</p>



<p>The generator loss is then calculated from the discriminator’s classification – it gets rewarded if it successfully fools the discriminator, and gets penalized otherwise.&nbsp;</p>



<p>The following equation is minimized to training the generator:</p>



<div><figure><img src="https://lh6.googleusercontent.com/HELs4L-7j4GKYHus3PNWUuWxd5MhoOiY1Gp0MDB71QHi4_2WueJZYApJE2Emsk6SHEdgSTjd0f_ey9OcYAOY2mfMsQb5m37zHrypxml46_6i510NPKVPxUyfEAdRHuCatnfmeNe_" alt=""></figure></div>






<h2>Non-Saturating GAN Loss</h2>



<p>A subtle variation of the standard loss function is used where the generator maximizes the log of the discriminator probabilities – <strong>log(D(G(z))).&nbsp;</strong></p>



<p>This change is inspired by framing the problem from a different perspective, where the generator seeks to maximize the probability of images being real, instead of minimizing the probability of an image being fake.&nbsp;</p>



<p>This avoids generator saturation through a more stable weight update mechanism. In his <a href="https://danieltakeshi.github.io/2017/03/05/understanding-generative-adversarial-networks/" target="_blank" rel="noreferrer noopener nofollow">blog</a>, Daniel Takeshi compares the Non-Saturating GAN Loss along with some other variations.</p>






<h2>Challenges with GAN loss functions</h2>



<p>More often than not, <strong>GANs tend to show some inconsistencies in performance.&nbsp;</strong></p>



<p>Most of these problems <a href="https://machinelearningmastery.com/how-to-code-the-generative-adversarial-network-training-algorithm-and-loss-functions/" target="_blank" rel="noreferrer noopener nofollow">are associated with their training</a> and are an active area of research.&nbsp;</p>



<p>Let’s look at some of them in detail:</p>



<h3><strong>Mode Collapse</strong></h3>



<p>This issue is on the unpredictable side of things. It wasn’t foreseen until someone noticed that the generator model could only generate one or a small subset of different outcomes or modes.&nbsp;</p>



<p><strong>Usually, we would want our GAN to produce a range of outputs</strong>. We would expect, for example, another face for every random input to the face generator that we design.&nbsp;</p>



<p>Instead, through subsequent training, the network learns to model a particular distribution of data, which gives us a <strong>monotonous output</strong> which is illustrated below.&nbsp;</p>



<div><figure><img loading="lazy" width="284" height="287" src="https://i2.wp.com/neptune.ai/wp-content/uploads/GAN-face-generator.png?resize=284%2C287&amp;ssl=1" alt="" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/GAN-face-generator.png?w=284&amp;ssl=1 284w, https://i2.wp.com/neptune.ai/wp-content/uploads/GAN-face-generator.png?resize=80%2C80&amp;ssl=1 80w" sizes="(max-width: 284px) 100vw, 284px" data-recalc-dims="1"></figure></div>



<p>In the process of training, the <strong>generator is always trying to find the one output</strong> that seems most plausible to the discriminator.</p>



<p>Because of that, the <strong>discriminator’s best strategy is always to reject the output </strong>of the generator.&nbsp;</p>



<p>But if the next generation of discriminator gets stuck in a local minimum and doesn’t find its way out by getting its weights even more optimized, it’d get easy for the next generator iteration to find the most plausible output for the current discriminator.&nbsp;</p>



<p>This way, it will keep on repeating the same output and refrain from any further training.</p>



<h3><strong>Vanishing Gradients</strong></h3>



<p>This phenomenon happens when the discriminator performs significantly better than the generator. Either the updates to the discriminator are inaccurate, or they disappear.&nbsp;</p>



<p>One of the proposed reasons for this is that the generator gets heavily penalized, which leads to saturation in the value post-activation function, and the eventual gradient vanishing.</p>



<h3><strong>Convergence</strong></h3>



<p>Since there are two networks being trained at the same time, the problem of GAN convergence was one of the earliest, and quite possibly one of the most challenging problems since it was created.&nbsp;</p>



<p>The utopian<strong> situation where both networks stabilize and produce a consistent result is hard to achieve in most cases.</strong> One explanation for this problem is that as the generator gets better with next epochs, the discriminator performs worse because the discriminator can’t easily tell the difference between a real and a fake one.&nbsp;</p>



<p>If the generator succeeds all the time, the discriminator has a 50% accuracy, similar to that of flipping a coin. This poses a threat to the convergence of the GAN as a whole.&nbsp;</p>



<p>This image below shows this problem in particular:</p>



<div><figure><img loading="lazy" width="622" height="459" src="https://i0.wp.com/neptune.ai/wp-content/uploads/GAN-accuracy.png?resize=622%2C459&amp;ssl=1" alt="" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/GAN-accuracy.png?w=622&amp;ssl=1 622w, https://i0.wp.com/neptune.ai/wp-content/uploads/GAN-accuracy.png?resize=300%2C221&amp;ssl=1 300w" sizes="(max-width: 622px) 100vw, 622px" data-recalc-dims="1"></figure></div>



<p>As the discriminator’s feedback loses its meaning over subsequent epochs by giving outputs with equal probability, the generator may deteriorate its own quality if it continues to train on these junk training signals.</p>



<p><a href="https://medium.com/@jonathan_hui/gan-why-it-is-so-hard-to-train-generative-advisory-networks-819a86b3750b" target="_blank" rel="noreferrer noopener nofollow">This </a>medium article by Jonathan Hui takes a comprehensive look at all the aforementioned problems from a mathematical perspective.</p>






<h2>Alternate GAN loss functions</h2>



<p>Several different variations to the original GAN loss have been proposed since its inception. To a certain extent, they addressed the challenges we discussed earlier.&nbsp;</p>



<p>We will discuss some of the most popular ones which alleviated the issues, or are employed for a specific problem statement:</p>



<h3><strong>Wasserstein Generative Adversarial Network (WGAN)</strong></h3>



<p>This is one of the most powerful alternatives to the original GAN loss. It <strong>tackles the problem of </strong><strong>Mode Collapse</strong><strong> and </strong><strong>Vanishing Gradient</strong><strong>.&nbsp;</strong></p>



<p>In this implementation, the <strong>activation of the output layer of the discriminator is changed from sigmoid to a linear one</strong>. This simple&nbsp; change influences the discriminator to give out a score instead of a probability associated with data distribution, so the output does not have to be in the range of 0 to 1.&nbsp;</p>



<p>Here, the discriminator is called critique instead, because it doesn’t actually classify the data strictly as real or fake, it simply gives them a rating.&nbsp;</p>



<p>Following loss functions are used to <strong>train the critique and the discriminator</strong>, respectively.&nbsp;</p>



<p>The output of the critique and the generator is not in probabilistic terms (between 0 and 1), so the absolute difference between critique and generator outputs is maximized while training the critique network.&nbsp;</p>



<p>Similarly, the absolute value of the generator function is maximized while training the generator network.&nbsp;</p>



<p>The original paper used RMSprop followed by clipping to prevent the weights values to explode:</p>



<div><figure><img src="https://lh4.googleusercontent.com/2hcD7a2_DBJpiUs9vG6XsmGB35fvtHT-yAEavn1btSmPmMmKtzv7I9tIZ5KbXA3wlt27CqdIIYohdKV9gZEjT1JIj89SmzN4IYxFZ0f_vXgBC9j0RqwxdxGscekiL6s7EX-c7vE1" alt=""></figure></div>



<div><figure><img src="https://lh5.googleusercontent.com/aoigHuhR13wGzC5tkVMsmvS5ewsQvgWAruu8Il0bPQ10Fj8R2A8Dka8z6twI1FUr25CnLewr-r3c1v-fkzPS0Ov4OwufVrmhNcd-fxl_mBZSy702_lf-zRx-XVirVP3v56J-LwX_" alt=""></figure></div>



<h3><strong>Conditional Generative Adversarial Network (CGAN)</strong></h3>



<p>This version of GAN is used to learn a multimodal model. It basically <strong>generates descriptive labels which are the attributes associated with the particular image that was not part of the original training data.</strong>&nbsp;</p>



<p>CGANs are mainly employed in image labelling, where both the generator and the discriminator are fed with some extra information <strong>y</strong> which works as an auxiliary information, such as class labels from or data associated with different modalities.&nbsp;</p>



<p>The conditioning is usually done by feeding the information <strong>y</strong> into both the discriminator and the generator, as an additional input layer to it.&nbsp;</p>



<p>The following modified loss function plays the same min-max game as in the Standard GAN Loss function. The only difference between them is that a conditional probability is used for both the generator and the discriminator, instead of the regular one.&nbsp;</p>



<div><figure><img loading="lazy" src="https://i2.wp.com/neptune.ai/wp-content/uploads/image-2.png?resize=552%2C78&amp;ssl=1" alt="" width="552" height="78" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/image-2.png?w=736&amp;ssl=1 736w, https://i2.wp.com/neptune.ai/wp-content/uploads/image-2.png?resize=300%2C42&amp;ssl=1 300w" sizes="(max-width: 552px) 100vw, 552px" data-recalc-dims="1"></figure></div>



<p><strong>Why conditional probability?</strong> Because we are feeding in some auxiliary information(the green points), which helps in making it a multimodal model, as shown in the diagram below:</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/neptune.ai/wp-content/uploads/conditional-adversarial-net-1.png?resize=512%2C444&amp;ssl=1" alt="" width="512" height="444" srcset="https://i1.wp.com/neptune.ai/wp-content/uploads/conditional-adversarial-net-1.png?resize=1024%2C887&amp;ssl=1 1024w, https://i1.wp.com/neptune.ai/wp-content/uploads/conditional-adversarial-net-1.png?resize=300%2C260&amp;ssl=1 300w, https://i1.wp.com/neptune.ai/wp-content/uploads/conditional-adversarial-net-1.png?resize=768%2C665&amp;ssl=1 768w, https://i1.wp.com/neptune.ai/wp-content/uploads/conditional-adversarial-net-1.png?w=1198&amp;ssl=1 1198w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1"></figure></div>



<p><em>Figure 1: Conditional adversarial net</em></p>



<p><a href="https://medium.com/@jonathan_hui/gan-cgan-infogan-using-labels-to-improve-gan-8ba4de5f9c3d" target="_blank" rel="noreferrer noopener nofollow">This </a>medium article by Jonathan Hui delves deeper into CGANs and discusses the mathematics behind it.</p>






<h2>Summary</h2>



<p>In this blog, we discussed:</p>



<ul><li>The original Generative Adversarial Networks loss functions along with the modified ones.</li><li>Different challenges of employing them in real-life scenarios.</li><li>Alternatives loss functions like WGAN and C-GAN.</li></ul>



<p>The main goal of this article was to provide an overall intuition behind the development of the Generative Adversarial Networks. Hopefully, it gave you a better feel for GANs, along with a few helpful insights. Thanks for reading!</p>



<p><a href="https://neptune.ai/blog/experiment-management" target="_blank"><img width="684" height="1083" src="https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?fit=684%2C1083&amp;ssl=1&amp;is-pending-load=1" alt="" loading="lazy" data-attachment-id="21371" data-permalink="https://neptune.ai/blog/this-week-in-machine-learning-ai-graphic-designer-computational-limits-and-ai-need-for-people/cta-experiment-tracking-mobile" data-orig-file="https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?fit=684%2C1083&amp;ssl=1" data-orig-size="684,1083" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="CTA experiment tracking mobile" data-image-description="" data-medium-file="https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?fit=189%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?fit=647%2C1024&amp;ssl=1" data-lazy-srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?w=684&amp;ssl=1 684w, https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?resize=189%2C300&amp;ssl=1 189w, https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?resize=647%2C1024&amp;ssl=1 647w" data-lazy-sizes="(max-width: 684px) 100vw, 684px" data-lazy-src="https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?fit=684%2C1083&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><img width="1366" height="730" src="https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?fit=1366%2C730&amp;ssl=1&amp;is-pending-load=1" alt="" loading="lazy" data-attachment-id="21372" data-permalink="https://neptune.ai/blog/this-week-in-machine-learning-ai-graphic-designer-computational-limits-and-ai-need-for-people/cta-experiment-tracking" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?fit=1366%2C730&amp;ssl=1" data-orig-size="1366,730" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="CTA experiment tracking" data-image-description="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?fit=300%2C160&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?fit=1024%2C547&amp;ssl=1" data-lazy-srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?w=1366&amp;ssl=1 1366w, https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?resize=300%2C160&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?resize=1024%2C547&amp;ssl=1 1024w, https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?resize=768%2C410&amp;ssl=1 768w, https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?resize=1200%2C641&amp;ssl=1 1200w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?fit=1366%2C730&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>










<div>
    <h3>Get notified of new articles</h3>
    
    <p>By submitting the form you give concent to store the information provided and to contact you.<br>Please review our <a href="https://neptune.ai/wp-content/uploads/privacy-policy.pdf">Privacy Policy</a> for further information.</p>
</div>


</article>
            …</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/gan-loss-functions">https://neptune.ai/blog/gan-loss-functions</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/gan-loss-functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-24920406</guid>
            <pubDate>Wed, 28 Oct 2020 16:05:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bizarre Design Choices in Zoom's End-to-End Encryption]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24920125">thread link</a>) | @some_furry
<br/>
October 28, 2020 | https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Zoom recently announced that they were going to make end-to-end encryption available to all of their users–not just customers.</p>



<figure><div>

</div></figure>



<p>This is a good move, especially for people living in countries with <a href="https://soatok.blog/2020/07/02/how-and-why-america-was-hit-so-hard-by-covid-19/">inept leadership that failed to address the COVID-19 pandemic</a> and therefore need to conduct their work and schooling remotely through software like Zoom. I enthusiastically applaud them for making this change.</p>



<div><figure><img data-attachment-id="1333" data-permalink="https://soatok.blog/soatoktelegrams2020-08/" data-orig-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-08" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=512" src="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png 512w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=150 150w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>End-to-end encryption, on by default, is a huge win for everyone who uses Zoom. (Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<p>The end-to-end encryption capability arrives on the heels of their acquisition of <a href="https://keybase.io/">Keybase</a> in earlier this year. Hiring a team of security experts and cryptography engineers seems like a good move overall.</p>



<p>Upon hearing this news, I decided to be a good neighbor and take a look at their source code, with the reasoning, “If so many people’s privacy is going to be dependent on Zoom’s security, I might as well make sure they’re not doing something ridiculously bad.”</p>



<p>Except I couldn’t find their source code anywhere online. But they did publish <a href="https://github.com/zoom/zoom-e2e-whitepaper">a white paper on Github</a>…</p>







<h2>Disclaimers</h2>



<p>What follows is the opinion of some guy on the Internet with a fursona–so whether or not you choose to take it seriously should be informed by this context. It is not the opinion of anyone’s employer, nor is it endorsed by Zoom, etc. Tell your lawyers to calm their nips.</p>



<p>More importantly, I’m not here to hate on Zoom for doing a good thing, nor on the security experts that worked hard on making Zoom better for their users. The responsibility of security professionals is to the users, after all.</p>



<p>Also, these aren’t zero-days, so don’t try to lecture me about “responsible” disclosure. (That term is also <a href="https://adamcaudill.com/2015/11/19/responsible-disclosure-is-wrong/">problematic</a>, by the way.)</p>



<p>Got it? Good. Let’s move on.</p>







<h2>Bizarre Design Choices in Version 2.3 of Zoom’s E2E White Paper</h2>



<p>Note: I’ve altered the screenshots to be white text on a black background, since my blog’s color scheme is darker than a typical academic PDF. You can find the source <a href="https://github.com/zoom/zoom-e2e-whitepaper/blob/d3be2a5a3e16be04f1199b92630f180ba79cb51c/zoom_e2e.pdf">here</a>.</p>



<h3>Cryptographic Algorithms</h3>



<div><figure><img data-attachment-id="1744" data-permalink="https://soatok.blog/zoom-e2e-02/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png" data-orig-size="784,652" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-02" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png" alt=""></figure></div>



<p>It’s a little weird that they’re calculating a signature over SHA256(Context) || SHA256(M), considering Ed25519 uses SHA512 internally.</p>



<p>It would make just as much sense to sign Context || M directly–or, if pre-hashing large streams is needed, SHA512(Context || M).</p>



<div><figure><img data-attachment-id="1740" data-permalink="https://soatok.blog/zoom-e2e-01/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png" data-orig-size="1039,788" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-01" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png" alt=""></figure></div>



<p>At the top of this section, it says it uses libsodium’s <code>crypto_box</code> interface. But then they go onto… not actually use it.</p>



<p>Instead, they wrote their own protocol using HKDF, two SHA256 hashes, and XChaCha20-Poly1305.</p>



<p>While secure, this isn’t <em>really</em> using the crypto_box interface.</p>



<p>The only part of the libsodium interface that’s being used is <code><a href="https://github.com/jedisct1/libsodium/blob/927dfe8e2eaa86160d3ba12a7e3258fbc322909c/src/libsodium/crypto_box/curve25519xsalsa20poly1305/box_curve25519xsalsa20poly1305.c#L35-L46">crypto_box_beforenm()</a></code>, which could easily have been a call to <code>crypto_scalarmult()</code>instead (since they’re passing the output of the scalar multiplication to HKDF anyway).</p>







<p>Also, the SHA256(a) || SHA256(b) pattern returns. Zoom’s engineers must love SHA256 for some reason.</p>



<p>This time, it’s in the additional associated data for the XChaCha20-Poly1305. </p>



<p>Binding the ciphertext and the signature to the same context string is a sensible thing to do, it’s just the concatenation of SHA256 hashes is a bit weird when SHA512 exists.</p>



<h3>Meeting Leader Security Code</h3>



<div><figure><img data-attachment-id="1746" data-permalink="https://soatok.blog/zoom-e2e-03/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png" data-orig-size="760,733" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-03" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png" alt=""></figure></div>



<p>Here we see Zoom using the a SHA256 of a constant string (“<code>Zoombase-1-ClientOnly-MAC-SecurityCode</code>“) in a construction that tries but fails to be HMAC.</p>



<p>And then they concatenate it with the SHA256 hash of the public key (which is already a 256-bit value), and then they hash the whole thing again.</p>



<p>It’s redundant SHA256 all the way down. The redundancy of “MAC” and “SecurityCode” in their constant string is, at least, consistent with the rest of their design philosophy.</p>



<p>It would be a real shame if double-hashing carried the risk of <a href="https://eprint.iacr.org/2013/382">invalidating security proofs</a>, or if <a href="https://cseweb.ucsd.edu/~mihir/papers/kmd5.pdf">the security proof for HMAC</a> required a high Hamming distance of padding constants and this design decision also later <a href="https://eprint.iacr.org/2012/684.pdf">saved HMAC from related-key attacks</a>.</p>



<h3>Hiding Personal Details</h3>



<figure><img data-attachment-id="1750" data-permalink="https://soatok.blog/zoom-e2e-04/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png" data-orig-size="739,603" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-04" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=739" alt="" srcset="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png 739w, https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=150 150w, https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=300 300w" sizes="(max-width: 739px) 100vw, 739px"></figure>



<p>Wait, you’re telling me Zoom was aware of HMAC’s existence this whole time?</p>



<div><figure><img data-attachment-id="1202" data-permalink="https://soatok.blog/soatoktelegrams2020-02/" data-orig-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-02" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=512" src="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png 512w, https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=150 150w, https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>I give up!</figcaption></figure></div>



<h2>Enough Pointless Dunking, What’s the Takeaway?</h2>



<p>None of the design decisions Zoom made that I’ve criticized here are security vulnerabilities, but they do demonstrate an early lack of cryptography expertise in their product design.</p>



<p>After all, the weirdness is almost entirely contained in section 3 of their white paper, which describes the “Phase I” of their rollout. So what I’ve pointed out here appears to be mostly legacy cruft that wasn’t risky enough to bother changing in their final design.</p>



<p>The rest of their paper is pretty straightforward and pleasant to read. Their design makes sense in general, and each phase includes an “Areas to Improve” section.</p>



<p>All in all, if you’re worried about the security of Zoom’s E2EE feature, the only thing they can really do better is to publish the source code (and link to it from the whitepaper repository for ease-of-discovery) for this feature so independent experts can publicly review it.</p>



<p>However, they seem to be getting a lot of mileage out of the experts on their payroll, so I wouldn’t count on that happening.</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24920125</guid>
            <pubDate>Wed, 28 Oct 2020 15:45:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Meetsy – an ephemeral social space for you friends]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24919934">thread link</a>) | @oscare
<br/>
October 28, 2020 | https://www.meetsy.me/events/9f5b9c78-7d66-414c-9124-5910923172da?ref=producthunt | <a href="https://web.archive.org/web/*/https://www.meetsy.me/events/9f5b9c78-7d66-414c-9124-5910923172da?ref=producthunt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  <div>
    <h5>Storytime</h5>
    
    <p>ðŸ‘‹ Hey party people,

Thanks for checking out Meetsy! ðŸŽ‰

You can organise your own event, just like this one, by clicking the '+' icon on top. Then you can invite your friends and family and update them as time goes by. After the event is over, everybody will be asked to upload a couple of there best photos. Once that is done, everybody can download the complete photo album to their private library.

And most important: 15 days after the scheduled date, the event and all uploaded data is completely deleted!

For more information, see the 'How It Works' page on the bottom.

Try it out and let me know what you think! ðŸ™Œ</p>
    <p><img src="https://res.cloudinary.com/dhrr755kq/image/upload/c_fill/gipfmy49bsa83l2l0m39ibwo7tba" alt="Organiser-image">
      @edeloscar
    </p>
  </div>

  <div>

    <div>
      

      <div>
        <h5>Share</h5>
        

        <p><small>Pro-tip: <i></i> Add to your homescreen.</small></p>
      </div>
    </div>

  </div>
</div></div>]]>
            </description>
            <link>https://www.meetsy.me/events/9f5b9c78-7d66-414c-9124-5910923172da?ref=producthunt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24919934</guid>
            <pubDate>Wed, 28 Oct 2020 15:32:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tools and Trends: Security Testing for Risky Functionalities]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24919844">thread link</a>) | @_Tata_
<br/>
October 28, 2020 | https://www.ego-cms.com/post/how-ego-performs-security-testing-for-risky-functionalities | <a href="https://web.archive.org/web/*/https://www.ego-cms.com/post/how-ego-performs-security-testing-for-risky-functionalities">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><a href="https://www.ego-cms.com/tags/security"><p>Security</p></a><h2>How EGO Performs Security Testing for Risky Functionalities</h2><p>No software can be 100% protected. Yet the harm it might bring can be minimized with a proper approach to app development and testing.</p></div></div><article><div target="_blank"><p>Security breaches are reported almost every day. Data gets stolen so often there are already services like<a href="https://haveibeenpwned.com/"> https://haveibeenpwned.com/</a> that monitor those attacks and inform if your credentials have been compromised.</p><p>And while you might have only been reading those reports on the Internet, for us as an app building company it's an everyday threat since we're working in probably the most data-sensitive industries: healthcare and fintech. Compromising such data may lead to everything from digital identity theft to life-threatening situations.</p><p>For instance, just recently, a woman<a href="https://www.nytimes.com/2020/09/18/world/europe/cyber-attack-germany-ransomeware-death.html"> had died</a> due to a software failure in a German hospital. That failure was caused by a cyber attack and forced doctors to move the patient to another facility, but she died on her way to it.<br></p><h2>Security Testing as an Answer</h2><p>So what's our way to minimize the possibility of such outcomes? (We can only imagine the feelings of those QA guys who – although most probably unintentionally – overlooked that threat in the software and made this attack possible).&nbsp;</p><p>There's a number of techniques that all can be united by one broad term "security testing". Its scope varies from project to project and may include or combine such activities as finding and removing system vulnerabilities and weaknesses, penetration testing, line-by-line code inspection, and others.</p><p>Instead of diving into technical aspects of our work, we'd like to dedicate a few sentences to its importance.</p><p>Often companies tend to save money on or postpone security testing, mainly due to three reasons:</p><ol role="list"><li>Their business is too small/unimportant to be targeted by hackers</li><li>There is no return on investment</li><li>The software can never be perfectly secure OR it's much easier to install some third-party tool for data protection.</li></ol><p>However, that attitude is exactly the reason data breaches happen so often. Yes, databases leak every day, and a single database might be of no significant value. But when they are combined, such new big data provides an enormous amount of information about people, starting with the time they usually come home from work and their most often ordered pizza to the passwords of their email accounts and CVV codes of their credit cards.</p><p>Now, it might seem that security testing is something very vague for a non-technical person. How can you know that your development team is actually working on your product's security?</p><p>Answering this question, any app building company would say something like:</p><blockquote>“– Our QA team finds a unique testing approach for every project, and to do that, they apply experience from the decade of work in this area.”</blockquote><p>Yet in real life, it is only during your interaction with the most reliable teams you'll be getting an answer to that question.&nbsp;</p><p>Most often, you’ll get detailed reports on what vulnerabilities and breaches were found and fixed. But that's not all. Security testing also reveals additional ways to protect user data.<br></p><p>For instance, here is only a couple of things we suggested and developed in our latest projects:&nbsp;</p><ol role="list"><li>In one of the healthcare projects, a user was able to download medical files to their device through the app. We programmed the app to automatically delete those files after some time. Not only it is done because a copy may become outdated. We noticed that files are downloaded for a one-time interaction (or importing into another app for further processing).</li><li>In another project, our software was communicating with the client's proprietary scanners. Initially, we intended to work with those scanners remotely. But we decided to have them delivered to our office to check if the hardware might be tampered with to alter its behavior and how our code can prohibit that.</li><li>When we were making an app for the bank, security testing requires having quite an amount of client data, and resources were invested to fake them. It is OK to suppose we might have a breach possibility on our side too.</li></ol><p>You might also know that all healthcare applications in the US must follow the HIPAA Security Standards. Those include solid requirements for data encryption, user identification, emergency access, and other aspects of such software. To follow them, we implement features like password hashing, biometric identification, automatic logoff, file change logging, and others.</p><p>Sometimes we might go as far as to sending our clients <a href="https://sdn.ego-cms.com/s/52Cdd5djCdsTD4s">cheat sheets like this</a> to implement healthcare security practices all over their organization.</p><h2>How Can You See EGO Pays Attention to Security?</h2><p>Now, the main outcome of the successful security testing might seem to be hardly visible. Your app works as intended, and hacks are either unsuccessful or absent at all.<br></p><p>So here are a few security practices we often turn to when working on software projects having risky functionalities (mainly, those include payment features, file uploading, and personal data processing). Seeing them when interacting with your development team, you may be sure the security aspect is treated seriously on your project.&nbsp;&nbsp;</p><h3>Different environments</h3><p>&nbsp;Most of the applications we maintain or improve already have a real-world userbase.</p><p>To make sure we won't affect their user experience, we create different environments:</p><ul role="list"><li>a demo environment to show new or updated functionality to the client</li><li>A staging environment for smoke testing purposes</li><li>A few QA environments for our internal needs (mostly for testing new features separately from each other)</li></ul><p>Additionally, as in the example earlier, we create fake or seed data for testing purposes.</p><h3>Project Permissions</h3><p>It's very common to build MVPs without paying special attention to the user roles and permissions. However, if the project works with data sensitive enough to have its security taken care of, this is a critical issue to address.</p><p>Who can access the code and user data?</p><p>Who can edit it?</p><p>Who can dump it?</p><p>In teams with people combining various roles and responsibilities, those are questions not obvious at all. And the better is the security policy, the less are the chances of internal data theft, a social engineering attack, or a banal mistake.</p><p>As an example, we get our hands on projects that initially allow us to access user data. Many mobile apps let users sign up, and the APIs implementing this functionality provide the developers with the ability to access, dump, or alter the database of users and their passwords.&nbsp;</p><p>In such cases, we change the app logic and permissions to make such data invisible and inaccessible for developers (at least, by default).&nbsp;</p><h3>Payment testing</h3><p>However appealing might be the software product, if the payment procedure is unclear, or, even worse, goes wrong, that might cause a user not only to refuse using your app but leave a negative review and tell about their experience on social networks.</p><p>To make sure the payment procedure works flawlessly, quality assurance engineers from the EGO app development agency create a sandbox and test credentials (a card number, date, random name, etc. for testing purposes.</p><h2>Where's a fly in the ointment?</h2><p>Although we dropped many more boring technical details – like how we perform penetration testing and security auditing – there will still be a question hanging in the air:</p><p><em>Can EGO guarantee your product's security?</em></p><p>The answer is "No", but also "No, and nobody can".</p><p>In September 2020, another zero-day vulnerability was<a href="https://www.bleepingcomputer.com/news/security/windows-10-sandbox-activation-enables-zero-day-vulnerability/"> discovered</a> in Windows 10. A zero-day vulnerability means there’s a chance it was found earlier by a trespasser and used for an unknown number of times for an unknown purpose.<br></p><p>Who knows how many more of such vulnerabilities are in the operating system most of our clients use. Clients, who may have access to the code base or the user database of their product. And this is only one of many attack vectors we cannot do anything about.</p><p>And then there are new security testing tools coming out on the market. And new testing approaches. And new people joining our team.&nbsp;</p><p>The growth strategy that our QA team has come up with over the years of their work is finding ways to make better-informed decisions. Decisions on the optimal testing approach for every project, on testing plans and estimates, on testing tools and reports.</p><p>And then, following our decisions, we should never stop paying attention to details. Because if there would be an idiom that would describe the essence of quality assurance, it would be “God is in the detail”.</p><figure><a href="https://www.ego-cms.com/contact-us" target="_blank"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5f6cbccfbb5afc0b752a1448_5d30419c6c4ba507b52124bd_App%20Development.png" loading="lazy" alt=""></p></a></figure></div></article><section><div><div><p>LIKE THIS ARTICLE? Help us SPREAD THE WORD.</p></div></div></section></div>]]>
            </description>
            <link>https://www.ego-cms.com/post/how-ego-performs-security-testing-for-risky-functionalities</link>
            <guid isPermaLink="false">hacker-news-small-sites-24919844</guid>
            <pubDate>Wed, 28 Oct 2020 15:26:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linear's Superb User Experience]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24919690">thread link</a>) | @stevenaanen
<br/>
October 28, 2020 | https://www.buildwithusers.com/p/superb-user-experience-with-linear | <a href="https://web.archive.org/web/*/https://www.buildwithusers.com/p/superb-user-experience-with-linear">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3ab90fc7-0378-46d8-a5f4-1b35100abc28_1254x841.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3ab90fc7-0378-46d8-a5f4-1b35100abc28_1254x841.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/3ab90fc7-0378-46d8-a5f4-1b35100abc28_1254x841.jpeg&quot;,&quot;height&quot;:841,&quot;width&quot;:1254,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:852250,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>Welcome once again! 👋 Today we have a very special interview for you with Tuomas from one of the hottest startups in SaaS: <strong>Linear</strong>.</p><p><strong>Tuomas explains how they’ve built a continuous feedback loop, how they prioritize and design new features, and he has an important tip for product builders that think about starting their own community. 💡</strong></p><p>Enjoy, and don’t forget to hit the subscribe button (if you haven’t) to follow along on the next issues! 👇</p><h2>About Linear and Tuomas</h2><p>Linear is a popular new tool to streamline software project management and is built with remarkable attention to detail in terms of usability. The team consists of ex-employees of Uber, Airbnb, Slack, Coinbase, and Microsoft, and collaborates with their Slack community of 900+ members.</p><p>Tuomas is co-founder of Linear, an engineer and experienced entrepreneur with a strong passion for UX. He previously worked at Uber and helped scale mobile engineering from 15 to 400 engineers. Today, Tuomas explains why the team chooses to build community-first.</p><h2>At what stage of the company did you start an online community and why?</h2><p>We started our online community very early, right about when we launched a private alpha. <strong>We don’t want to build our product in isolation</strong> but want to make sure that we’re as close and aligned with our users as possible. Our belief is that <strong>everyone in our team should be exposed to feedback from our users</strong>. Therefore it was critical to have as many channels of communication as possible to ensure this.</p><blockquote><p>Without a continuous feedback channel like the Slack community, we would probably build the wrong things.</p></blockquote><p>Without a continuous feedback channel like the Slack community, we would probably build the wrong things. <strong>Most of the direction comes from our customers</strong> and the chats that we have with them. If we wouldn’t have the community, we’d still go through a customer list and have daily calls with them to get an idea of what they need and what they're after. But it would certainly be slower, and you wouldn't be able to get a quick overview of what people want. </p><p>I think that <strong>the Slack community is a very fast</strong>-<strong>paced feedback mechanism</strong> for the entire team to get a grasp on what's going on, what's working, and what’s not.</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fab27779f-a23c-46aa-9109-aaa453f9aa77_972x485.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fab27779f-a23c-46aa-9109-aaa453f9aa77_972x485.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ab27779f-a23c-46aa-9109-aaa453f9aa77_972x485.jpeg&quot;,&quot;height&quot;:485,&quot;width&quot;:972,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:308918,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><h2>What platform do you use to run your online community?</h2><p>We used to run our community on Telegram but quickly switched to Slack. Additionally, a lot of feedback comes from forms within the application and from emails from users, which we manage with Front.&nbsp;</p><p>Slack is a great mechanism for fast-paced feedback and discussions. We also get bug reports and user questions in this way. Glancing over it gives everyone <strong>a good grasp on how our users are using Linear</strong> and what areas we still need to improve on.</p><p>The <strong>real-time and casual feel</strong> of Slack makes it great for the job. Using a forum for instance would probably increase the barrier to connect easily. We do get a lot of repeat questions through our channels, which takes time to answer, but that also tells us that we could do a better job at documenting our functionality.</p><h2>How do people find out about the community?</h2><p>The Slack community is <strong>open for all</strong>, but we don’t really promote it anywhere, except for a mention in our welcome email. We do have a prominent entry point in the main menu inside our application, but we probably should do a bit more to guide users to the community.</p><h2>How do you keep your community lively and positive?</h2><p>Not too long ago, we started with channels where people can <strong>introduce themselves</strong>, <strong>share stories</strong> about how they started using Linear, or learn about <strong>how other companies are using Linear</strong> to drive their software development. Most other channels are about providing feedback and feature requests or asking questions about particular functionality. <strong>Our whole team is active in those channels and we try to respond to each discussion.</strong></p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5ef2146b-918e-435e-beff-7d37f00f6bb4_1080x720.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5ef2146b-918e-435e-beff-7d37f00f6bb4_1080x720.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/5ef2146b-918e-435e-beff-7d37f00f6bb4_1080x720.jpeg&quot;,&quot;height&quot;:720,&quot;width&quot;:1080,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:650777,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>So far, the discussion has always remained positive and courteous. If discussions were ever to change to be rude, we would have to think about publishing community guidelines and enforcing them. I do believe that the positivity in the community is tightly coupled with how people experience Linear. If that were to change we would first have to <strong>look at our product and see where we’ve messed up</strong> the user experience.</p><blockquote><p>Any question is literally our problem. If people have to ask how things work, then we haven't done a good job in the product to explain it.</p></blockquote><p>The time it takes to reply to everything is really <strong>the only downside</strong>. Then again, you want to spend time with your customers so I don’t see it as something annoying. Any question is literally our problem. If people have to ask how things work, then we haven't done a good job in the product to explain it.</p><h2>How did engagement change when you grew from the first 50 members to a few hundred members?</h2><p>Nothing much has changed really as we’ve grown. Except for the volume of feedback and questions. As mentioned before, it’s our belief that everybody on the team should be exposed to feedback from our customers. So everybody was just active on the channels and responding to questions. But at some point, we realized that <strong>the team could no longer keep up</strong> with the amount of feedback and that this unstructured approach would not scale much further.</p><p>We did want to continue to provide awesome support, so we started building out a <strong>customer experience function</strong> at Linear. This ensures that all questions get answered quickly. Either directly by our customer experience lead or by someone else on the team who gets looped into the conversation. This helps us to continue learning from our users in a more efficient and controlled manner.</p><h2>How do you involve your community in improving your product?</h2><p>We use the feedback from our community as <strong>signals that help us prioritize</strong> what we’re working on. Receiving a lot of feedback of a certain type will make us re-prioritize our work and look into that particular problem field.</p><p>Often we do get feedback on existing functionality that we feel is just a good improvement (or a straight-up bug report). This kind of feedback we <strong>try to address immediately</strong>, in order to constantly ship smaller improvements to our users.</p><blockquote><p>We try to surprise and delight our users every now and then with a more elegant solution than they could have imagined.</p></blockquote><p>For all the other feedback, it's important to <strong>understand the underlying problem</strong>. It is therefore <strong>necessary to dive deeper</strong> instead of literally building what our users ask. A particular feature request might be an indication of a deeper reaching problem or limitation of our application. Coming up with a solution to that underlying problem might have <strong>further-reaching effects</strong> than implementing individual asks. This way we try to surprise and delight our users every now and then with a more elegant solution than they could have imagined.</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb19929c3-8a7c-40d8-9907-fb9147cf468f_2045x1088.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb19929c3-8a7c-40d8-9907-fb9147cf468f_2045x1088.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/b19929c3-8a7c-40d8-9907-fb9147cf468f_2045x1088.jpeg&quot;,&quot;height&quot;:775,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:476511,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>We usually do quarterly planning on these kinds of high-level directions for the application. The planning makes sure that we’re addressing the needs of our customers with more complicated <strong>long-term projects</strong> as well.</p><p>For substantial additions, we <strong>select a few customers</strong> and invite them to a private Slack channel. We let them try it out and provide feedback before we ship it to the rest of our users. Sometimes we involve our customers very early on to provide feedback already in the design phase. This is all to make sure that we’re <strong>building something that our users want</strong>.</p><h2>One piece of advice you would give to anyone that is building out an early community around a software startup</h2><blockquote><p>You’re building something for your users and not for yourself.</p></blockquote><p><strong>Invest the time as soon as possible</strong>. You will be in a place where you’re rapidly iterating on the product and working very hard. At that point, spending a lot of time to build up and engaging with a community might feel like a distraction, but <strong>it’s well worth it</strong>. After all, you’re building something for your users and not yourself.</p><h2>What are your plans for the future, as a company in general and with your community?</h2><p>We’re focused on building out <strong>the best application for managing software product development</strong>. We’ve started small and are continuously increasing the footprint of what Linear can do and what kind of companies it can support. Our biggest user segment consists of other startup-ups and our plan is to <strong>grow with them</strong>, supporting them with new functionality as they grow. This will require <strong>continuous communications and the building of our community</strong>. It remains to be seen when we’ll outgrow our current community tools and what we’d switch to when that happens.</p><h2>How can we find out more about you and Linear?</h2><p>If you haven’t done so yet, give us a try at <a href="https://linear.app/">https://linear.app</a>. We’d love to hear from you in our Slack community! You can find me on <a href="https://twitter.com/artman">Twitter</a>.</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0bed88df-f6fe-4779-8d16-9c430f97f024_880x440.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0bed88df-f6fe-4779-8d16-9c430f97f024_880x440.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/0bed88df-f6fe-4779-8d16-9c430f97f024_880x440.jpeg&quot;,&quot;height&quot;:440,&quot;width&quot;:880,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:108994,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><h2><strong>The Jam</strong></h2><p><strong>Have you heard about our Build With Users Jam yet? </strong>This is a cozy, weekly online meetup where we chat about product &amp; community building with anyone interested.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.buildwithusers.com/p/build-with-users-jams-&quot;,&quot;text&quot;:&quot;More about the Jam&quot;,&quot;class&quot;:null}"><a href="https://www.buildwithusers.com/p/build-with-users-jams-"><span>More about the Jam</span></a></p><p>Thanks for reading this issue 🙏</p><p>Next week we plan to have another cool interview for you 💪, stay tuned, and <a href="https://buildwithusers.substack.com/">subscribe</a> if you didn’t yet.</p><p>✌️ Cheers,</p><p><a href="https://twitter.com/stevenaanen">Steven</a>, Lennart, <a href="https://twitter.com/GinoNL">Gino</a>, <a href="https://twitter.com/franklagendijk">Frank</a></p></div></div>]]>
            </description>
            <link>https://www.buildwithusers.com/p/superb-user-experience-with-linear</link>
            <guid isPermaLink="false">hacker-news-small-sites-24919690</guid>
            <pubDate>Wed, 28 Oct 2020 15:15:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alternative Investments: why the “new rich” aren't sticking to stocks and bonds]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24919670">thread link</a>) | @KaiserSanchez
<br/>
October 28, 2020 | https://www.kubera.com/blog/alternative-investments | <a href="https://web.archive.org/web/*/https://www.kubera.com/blog/alternative-investments">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>You didn’t have to be an investor, you just had to be <em>alive</em> over the last few decades to know that the stock market is far from a predictable or even stable thing.&nbsp;<br></p><p><a href="https://www.investopedia.com/terms/d/dotcom-bubble.asp#:~:text=During%20the%20dotcom%20bubble%2C%20the,the%20years%201995%20and%202000.&amp;text=Even%20the%20share%20prices%20of,than%2080%25%20of%20their%20value." target="_blank">The bursting of the “Dotcom Bubble”</a> saw the Nasdaq index peak and then fall more than 76% from March 2000 to October 2002 thanks to speculative investment in seemingly miraculous new “internet companies” that couldn’t deliver on outlandish expectations.&nbsp;<br></p><p>Hot on the heels of that meltdown came another — <a href="https://www.investopedia.com/terms/g/great-recession.asp" target="_blank">the Great Recession of 2008</a>, triggered by a general lack of regulation in several corners of the financial industry.<br></p><p>Which brings us to today and the most unique crisis that most of us will ever experience — COVID-19. Now considered the herald of the COVID-19 recession, the <a href="https://en.wikipedia.org/wiki/2020_stock_market_crash" target="_blank">2020 stock market crash, or “Coronavirus Crash,”</a> was a global stock market crash that ran from February 20, 2020, to April 7, 2020, and was the most damaging since the Wall Street Crash of 1929 that kicked off the Great Depression.<br></p><p>If that brief history of economic instability freaked you out a bit, we can’t blame you. But what we <em>can</em> do is help you improve upon one of the few elements of wealth management that you can control — how you choose to allocate your assets to ward off loss through inevitable market fluctuations.&nbsp;<br></p><p>So let’s get started by diving a little deeper into the ins and outs of that term “diversification” that we hear so much about and then explore the alternative investments today’s current or aspiring high-net-worth individuals (HNWIs) can turn to in order to protect their portfolios.&nbsp;<br></p><h2>Why Modern Investors Are Diversifying Into Alternative Investments</h2><p>If the past 20 years have taught us anything about wealth management, it’s that absolutely no single asset class is immune to failing. That’s exactly why modern investors are looking to alternative investment sources to diversify their investment portfolios beyond simple stocks and bonds.<br></p><p>But what exactly does that mean, “diversify”?&nbsp;<br></p><p>When it comes to wealth management, <a href="https://www.kubera.com/blog/digital-asset-investment">diversification is the process of investing in different types of assets</a> to shield your portfolio from the losses that come with inevitable ups and downs in the stock market. <br></p><p>Diversification actually works <em>because of</em> these natural fluctuations. While every market will flex, it’s extremely unlikely they’ll all flex the same way at the same time — which puts you at less risk of experiencing dramatic losses and in a good position to catch the gains.<br></p><p>Which leads us to our next point: Effective diversification is done with purpose, not by throwing a dart and picking the first asset you hit.<br></p><div><p>A well-diversified portfolio will contain your own unique selection of assets that align with your risk tolerance which still meeting your goals for growth. If you aren’t sure where you stand with your risk tolerance, <a href="https://personal.vanguard.com/us/FundsInvQuestionnaire" target="_blank">try this quiz from Vanguard to help you decide</a>.</p><p>Ultimately, investors who build long-term, carefully-diversified portfolios have a <em>much</em> easier time generating returns and riding out the losses than the high-stakes gamblers who bet all their money on a single asset and often lose big in the stock market.</p></div><p>Next up: Today’s strongest alternative investment types to look for when building your balanced portfolio.&nbsp;<br></p><h2>Alternative Investments Worth Considering in a Digital-First World</h2><p>Between technological developments and a growing population of <a href="https://www.mx.com/thought-leadership/the-changing-face-of-wealth" target="_blank">adults who are more financially savvy than their predecessors</a>, actively seeking unconventional sources of income, and excited to manage their wealth digitally; we’re witnessing the birth of a new asset class that is changing the investment world.<br></p><p><a href="https://www.kubera.com/blog/digital-asset-investment"><strong>Digital assets are the alternative investment class of the future</strong></a><strong>.</strong>&nbsp;<br></p><p>While the term “digital asset” can be used to describe digital tokens that represent traditional and even physical assets, in this case we’re talking about assets that exist only in the digital realm.&nbsp;<br></p><p>While digital assets are still a new idea for many investors, they’re just as powerful as any traditional investment asset. Just ask the Winklevoss twins — <a href="https://www.investopedia.com/articles/people/083016/who-are-top-5-bitcoin-millionaires.asp" target="_blank">the world’s first Bitcoin billionaires</a>.&nbsp;<br></p><p>And according to a recent survey of almost 800 financial professionals across the U.S. and Europe, <a href="https://www.businesswire.com/news/home/20200609005138/en/Growing-Number-Institutional-Investors-Digital-Assets-Part" target="_blank">institutional investors are very interested in digital assets</a>.<br></p><figure id="w-node-931cd4d59614-ac468d02"><p><img src="https://uploads-ssl.webflow.com/5ded36b5e942e74b13468d23/5f91241956ac2a548b0f0a9e_01-Image%402x.png" loading="lazy" alt=""></p></figure><p>The most popular digital asset among these investors? Bitcoin — a type of cryptocurrency.&nbsp;<br></p><p>With that in mind, let’s talk more about cryptocurrency as well as some other popular digital assets you can use to round out your modern investment portfolio.&nbsp;<br></p><h3>Cryptocurrencies</h3><p><a href="https://www.investopedia.com/terms/c/cryptocurrency.asp" target="_blank">Cryptocurrency is digital currency</a> that is secured using cryptography and “backed” by a distributed network of computers. Its decentralized nature means it exists outside the control of any central authority, which increases its transparency but also its general instability (for now).</p><p>Cryptocurrency — often shorted to “crypto” — exists solely in the digital sphere, and it’s leading the way as far as introducing the masses to digital assets.&nbsp;<br></p><p>Fidelity has launched a <a href="http://crypto.marketswiki.com/index.php?title=Fidelity_Digital_Assets" target="_blank">digital assets subsidiary</a>, <a href="https://www.investopedia.com/articles/people/083016/who-are-top-5-bitcoin-millionaires.asp" target="_blank">the crypto-focused investment firm</a> Pantera Capital has delivered a 24,000% return to investors, and investment advisory firm <a href="https://medium.com/@HuttCapital/reflecting-on-cambridge-associates-blockchain-investment-research-piece-d06bc3af0469" target="_blank">Cambridge Associates encouraged investors to try digital assets</a> in their report “Cryptoassets: Venture into the Unknown.”<br></p><p>To get started with crypto, do your research and sign up with a credible exchange that enables you to create a crypto “wallet” and start buying and selling coins. But remember, as easy as it is to dive into crypto, it’s also as easy to mess it up. Learn the lingo and get a running start with this overview from Hacker Noon: “<a href="https://hackernoon.com/a-beginners-guide-to-getting-started-with-cryptocurrencies-76027bebb1b1" target="_blank">A beginner’s guide to getting started with cryptocurrencies</a>.”<br></p><h3>Websites&nbsp;</h3><p>There are <em>billions</em> of websites online — which makes websites a <em>huge</em> asset class when you think about them as an alternative investment resource for your portfolio.&nbsp;<br></p><p>If you want to invest in websites without making website management your full-time job, the best approach for you is probably buying, improving (or just holding), and “flipping” — to use real estate lingo — any type of website that generates income. Often, these include blogs, digital publications, and ecommerce stores.&nbsp;<br></p><p>To find established (and, ideally, money-making) websites that are for sale, you’ll want to look at online website marketplaces. <a href="https://flippa.com/websites" target="_blank">Flippa is quite common</a> and a good place to start.&nbsp;<br></p><h3>Domain Names&nbsp;</h3><p>A little more specific than websites are the domain names upon which they exist.&nbsp;<br></p><p>A domain name is a unique address people use to access a website. For example, the domain name of the website you’re reading this on is “kubera.com.”<br></p><p>To revisit the real estate metaphor, domain names are kind of like land in the fast-growing city that is the internet. As more people want their own space on the internet, the more valuable domain names become.&nbsp;<br></p><p>For investor Igal Lichtman, for example, <a href="https://www.kubera.com/blog/what-happens-to-your-domains-when-you-die">the value of his domain names would have amounted to almost $75,000</a> for just a handful of some of his smartest investments — <em>if</em> he had properly prepared his beneficiaries to take ownership of his domains (more on that in the next section!).<br></p><p>While there are several ways to generate income from purchasing domain names — developing a website, displaying ads, etc. — the strategy that makes the most sense for someone who’s interested from an investment standpoint is again a buy/hold/sell approach.&nbsp;<br></p><p>GoDaddy, a recognized domain registrar where you can search for and purchase domain names, has a simple guide that will help you start wrapping your head around <a href="https://www.godaddy.com/garage/5-tried-and-true-tips-for-buying-and-selling-domain-names-for-profit/" target="_blank">the process of buying and selling domain names for profit</a>.&nbsp;<br></p><figure id="w-node-52e775ab4ef0-ac468d02"><p><img src="https://uploads-ssl.webflow.com/5ded36b5e942e74b13468d23/5f9124f817272fdbe88f5353_02-Image%402x.png" loading="lazy" alt="HNWI interest in digital assets"></p></figure><p>Remember that these are just some of the most popular digital assets for investors who are just diving into the alternative realm. There are plenty of other options, including trademarks, SaaS platforms, revenue-generating social media accounts, and tons more. In fact, KPMG estimates that <a href="https://www.fintechfutures.com/2019/03/wealth-managers-can-adapt-to-digital-assets-and-thrive/" target="_blank">there are more than 2,000 digital assets</a> on the market. So if you didn’t click with any of the digital assets we discussed today, stay tuned as we cover more digital assets on our blog in the future — you’re bound to find a good fit for your portfolio.&nbsp;<br></p><h2>How to Manage All of Your Alternative Investments</h2><p>While you might be ready for alternative investments, chances are the traditional portfolio management tools you’re used to aren’t up for the challenge.&nbsp;<br></p><p>When you’re ready for a portfolio manager that’s <em>made</em> for the digital world in which we live, turn to Kubera.&nbsp;<br></p><p>At Kubera, we brought together the <a href="https://www.kubera.com/portfolio-tracker">ease of a spreadsheet with the power of high-tech integrations</a> to enable you to manage and optimize every single one of your assets — from traditional investments like stocks and bonds (<a href="https://www.kubera.com/financial-tracking-app">in any currency!</a>) to <a href="https://www.kubera.com/crypto-tracker">alternative assets like crypto, domain names, websites, and more</a>.&nbsp;<br></p><p>And not only that, but <a href="https://www.kubera.com/beneficiary-management">Kubera’s beneficiary management feature also empowers investors</a> to create a secure and streamlined path for passing their investment portfolio down to a pre-determined heir when the time comes. No more lost domain names or crypto wallets here!<br></p><figure id="w-node-807e0038b565-ac468d02"><p><img src="https://uploads-ssl.webflow.com/5ded36b5e942e74b13468d23/5f912518b04741c3096c4fa3_03-%20Kubera-New-Logo.png" loading="lazy" alt="How to Manage All of Your Alternative Investments"></p></figure><p>Kubera is the only portfolio management solution that can keep up with the alternative, digital investments current and soon-to-be HNWIs are making in the modern world.&nbsp;<br></p><p>Join the club and <a href="https://app.kubera.com/signup">sign up for your free trial of Kubera today</a>.<br></p></div></div>]]>
            </description>
            <link>https://www.kubera.com/blog/alternative-investments</link>
            <guid isPermaLink="false">hacker-news-small-sites-24919670</guid>
            <pubDate>Wed, 28 Oct 2020 15:13:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why We Memo All the Things]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24919640">thread link</a>) | @steadicat
<br/>
October 28, 2020 | https://attardi.org/why-we-memo-all-the-things/ | <a href="https://web.archive.org/web/*/https://attardi.org/why-we-memo-all-the-things/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-css-e5dvzf=""><p>On my team at Coinbase, we ask everyone to use the React performance trinity – <code>memo</code>, <code>useMemo</code>, and <code>useCallback</code> – all the time. For some reason, this is controversial. I’m guessing this has something to do with Twitter. This article explains why we do it anyway.</p>
<h3 id="why-we-reactmemo-all-components"><a href="#why-we-reactmemo-all-components" aria-label="why we reactmemo all components permalink"></a>Why We React.memo All Components</h3>
<p>Let’s start with what we can all agree on: in most apps, some components can benefit from being wrapped in <code>React.memo</code>. Maybe because they are expensive to rerender, or maybe they are children of a component that renders much more frequently. Maybe both.</p>
<p>So not using <code>memo</code> at all is not an option. We are left with two options:</p>
<ul>
<li>Use <code>memo</code> some of the time</li>
<li>Use <code>memo</code> all the time</li>
</ul>
<p>The first option sounds like the most appealing, doesn’t it? Figure out when we can benefit from <code>React.memo</code>, and use it then, and only then. However, before we go that far, we have to remind ourselves that we work on a large team. No matter how diligent we are with education, code review, and profiling, <strong>we are not going to get it right 100% of the time</strong>. So we have to ask ourselves:</p>
<blockquote>What is the cost of getting it wrong?</blockquote>
<p>If we <code>memo</code> a component that doesn’t need to be, all we’re doing is a shallow equality check on the props of that component, on each potential render.</p>
<p>If we don’t <code>memo</code> a component that should be, we are:</p>
<ol>
<li>Running a render function</li>
<li>Allocating all callbacks anew</li>
<li>Allocating all <code>useMemo</code> functions anew</li>
<li>Allocating a bunch of new <span>JSX</span> elements</li>
<li>Repeating 1–4 recursively for all the children</li>
<li>Causing the React reconciler to compare the old tree with the new tree</li>
</ol>
<p>If you’ve ever profiled a React app – even in production mode – you know there is a non-negligible performance impact to every component that renders. By contrast, the props comparison in <code>memo</code> itself hardly ever shows up in profiles.</p>
<p>Wastefully rerendering a component is more expensive than wastefully testing whether props changed. So we want to err on the side of avoiding unnecessary rerenders. Since we are fallible, the only foolproof way to achieve that is <code>memo</code>ing everything by default.</p>
<h3 id="sane-defaults"><a href="#sane-defaults" aria-label="sane defaults permalink"></a>Sane Defaults</h3>
<p>On top of that, leaving the responsibility of deciding when to use <code>memo</code> and when not to places an unnecessary burden on all our engineers. Do we expect everybody to be intimately familiar with the tradeoffs? To profile each component to make the decision? What is the cost in terms of extra mental effort and time to try to get this right? Is it worth it? Why not provide a <em>sane</em> default, and diverge when necessary?</p>
<h3 id="cpu-cost-of-reactmemo"><a href="#cpu-cost-of-reactmemo" aria-label="cpu cost of reactmemo permalink"></a><span>CPU</span> Cost of React.memo</h3>
<p>But, you may be thinking, what if the vast majority of my components are cheap to rerender? Won’t the cost of all these unnecessary <code>memo</code>s add up to more than the possible cost of a wasted expensive rerender?</p>
<p>In my experience, the answer is no. I have never seen <code>memo</code> itself show up in a profile, whereas it’s pretty common to see expensive renders take mega amounts of <span>CPU</span> time. If you see something different, you probably have a bigger problem, like having way too many components mounted.</p>
<blockquote>
<p>If you have a legit use case where <code>memo</code> introduces a measurable performance hit, ping me. I’ll be happy to update this post based on new information!</p>
</blockquote>
<h3 id="memory-cost-of-reactmemo"><a href="#memory-cost-of-reactmemo" aria-label="memory cost of reactmemo permalink"></a>Memory Cost of React.memo</h3>
<p>There is a <code>memo</code> meme that’s going around: they say that <code>React.memo</code> has a memory cost, because – like other memoizations – you have to keep around the old values in case you need them again later. Makes sense? Unfortunately, that’s not quite right. Because of how React works, the result of previous renders needs to be kept around anyway – to diff it against subsequent renders. That’s the basis of React’s reconciliation algorithm. It can’t work without it.</p>
<p>Don’t take my word for it. Here’s <a href="https://twitter.com/Vjeux/status/1083902075946205189">Christopher Chedeau on Twitter</a>, responding to one Dan Abramov:</p>
<blockquote>I don’t think that it’s a great analogy. Doing memoize() on every function would be horrible because you’d have to store the state of the input/output for all the calls. In the React case, React already does that for everything, so it’s “free”.</blockquote>
<blockquote>
<p>In case you don’t know him, Christopher Chedeau has been on the React Core team at Facebook since 2012, i.e. the very beginning<!--, i.e. much longer than Dan Abramov-->. He created React Native, Prettier, <span>CSS</span>-in-<span>JS</span>, Excalidraw, and Yoga. <!--Dan Abramov, on the other hand, created Redux.--></p>
</blockquote>
<h3 id="isnt-it-premature-optimization"><a href="#isnt-it-premature-optimization" aria-label="isnt it premature optimization permalink"></a>Isn’t it Premature Optimization?</h3>
<p>Premature optimization is spending time optimizing your code for performance before you know which code needs to be made faster. By asking engineers to make the memo-no-memo choice on every component, we are forcing them to spend more time thinking about performance because we are concerned about the <em>potential</em> performance cost of a <code>memo</code> call. That, in my mind, is premature optimization. Not the other way round.</p>
<h3 id="why-we-reactusecallback-all-callbacks"><a href="#why-we-reactusecallback-all-callbacks" aria-label="why we reactusecallback all callbacks permalink"></a>Why we React.useCallback All Callbacks</h3>
<p>Are we on the same page about <code>React.memo</code>? Good, then this one is going to be easy. In the majority of the cases, callbacks get passed as props to other components. If you don’t wrap them in <code>useCallback</code>, you’re gonna break <code>memo</code>. It’s that simple. Wrap your callbacks in <code>useCallback</code> to make <code>memo</code> work.</p>
<p>What about callbacks that get passed to primitive components? Isn’t <code>useCallback</code> useless in those cases? Yes. But. When the next intern wraps your primitive in another component, are they gonna know to go back and change all the passed in callbacks to wrap them in <code>useCallback</code>? Probably not.</p>
<p>Plus, the arguments above about having sane defaults and not creating an extra burden on our engineers still apply. The <span>CPU</span> and memory cost of <code>useCallback</code> is negligible. Yes, callbacks need to stick around in memory regardless. After all, they may need to be called!</p>
<p>Keep it simple. <code>useCallback</code> all the fns.</p>
<h3 id="why-we-reactusememo-all-the-props--deps"><a href="#why-we-reactusememo-all-the-props--deps" aria-label="why we reactusememo all the props  deps permalink"></a>Why we React.useMemo All the Props &amp; Deps</h3>
<p>The same thing goes for any time we are creating a new object or array. We have to wrap it in <code>useMemo</code> or it’s going to break any component that receives those values as props.</p>
<p>Any data structure that gets recreated on every render can also break downstream <code>useCallback</code>s and <code>useMemo</code>s, by showing up in their list of dependencies. Such ever-changing values are then referenced in other callbacks and derived values, so the breakage spreads – like a coronavirus in a town where only half the people wear masks. If things aren’t <code>memo</code>ed by default, debugging performance issues as they come up is going to involve a long game of whack-a-mole, as you walk back up the chain of dependencies all the way to add memoization at every step.</p>
<h3 id="will-someone-please-think-of-the-children"><a href="#will-someone-please-think-of-the-children" aria-label="will someone please think of the children permalink"></a>Will Someone Please Think of the Children?</h3>
<p>Many people aren’t aware of this: <code>children</code> is a sneaky prop that breaks <code>memo</code>. <span>JSX</span> creates a new data structure on every render. Any time a component rerenders and passes <span>JSX</span> to another component, it’s gonna break the child component’s <code>memo</code>.</p>
<p>How do we deal with this? The same way we deal with all other complex data structures created during render: we <code>useMemo</code> it.</p>
<p>I know what you’re thinking: nobody wraps children in <code>useMemo</code>, and you’re right. I’ll admit that we also don’t often do this in our codebase. It’s just not idiomatic React, and doing this everywhere might be too much to ask. So we live with this compromise. This means we have to be vigilant, and continuously monitor our app for performance issues. The good news is, when we identify one, wrapping a <code>useMemo</code> around a children prop is a lot more straightforward than adding all sorts of optimizations to a complex web of hooks and components that started off with zero optimizations to begin with.</p>
<h3 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h3>
<p>Using <code>memo</code> and its cousins everywhere is a sane default. It’s like a mask mandate during a coronavirus pandemic. Sure, we could have everybody tested every day and only ask people who are actively contagious to wear a mask. But it’s far cheaper, simpler, and ultimately more effective to ask everybody to wear a mask by default.</p></div></div>]]>
            </description>
            <link>https://attardi.org/why-we-memo-all-the-things/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24919640</guid>
            <pubDate>Wed, 28 Oct 2020 15:10:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[About the Zcoin Project]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24919606">thread link</a>) | @GetBlock
<br/>
October 28, 2020 | https://getblock.io/blog/about-the-zcoin-project | <a href="https://web.archive.org/web/*/https://getblock.io/blog/about-the-zcoin-project">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://getblock.io/nodes/xzc">Zcoin</a> crypto project implements a zero-knowledge proof technology to maintain anonymity when conducting exchange transactions with cryptocurrencies. Zcoin concept is that there is no direct crypto coins transfer. The anonymity preservation algorithm is RSA-storage.</p>
<h3 id="about-the-coin">About the coin</h3>
<p>The Zcoin crypto coin implements the Zerocoin protocol and it appeared on October 28, 2016. The protocol turned out to be imperfect. It was hacked in February 2017 and as a result, 370,000 fake tokens were created. The developers did not destroy the coins, as the second-largest cryptocurrency platform, Ethereum did after the DAO smart contract software was hacked.</p>
<p>In 2018, a cryptographic error was discovered in the Zerocoin protocol. This error allowed us to create and destroy new Zcoins. The developers highlighted the attacks' high complexity and the low probability for the cybercriminals.</p>
<p>To address the vulnerability of the protocol, the Dandelion protocol was introduced in September 2018, hiding the source IP address without using a Tor router or VPN.</p>
<p>In 2018, Zcoin was successfully tested during the elections in Thailand. In December 2018, Zcoin implemented a mining algorithm with a containment mechanism for ASICs.</p>
<p>A crypto wallet supported by the Binance exchange was added in February 2019.</p>
<p>On July 30, 2019, the Sigma protocol with zero-knowledge proof was adopted instead of Zerocoin. It solved the problem of confidentiality and eliminated the possibility of issuing counterfeit coins.<br>Since August 2019, Zcoin has been added to the OVEX African cryptocurrency exchange. In December 2019, Zcoin introduced a decentralized crowdfunding system.</p>
<h3 id="features-of-the-zcoin-xzc-project">Features of the <a href="https://getblock.io/nodes/xzc">Zcoin (XZC)</a> project.</h3>
<ol>
<li>Wallet Multiple Billing Code [BIP47] RAP. Users share their permanent RAP address publicly while keeping their privacy.</li>
<li>No direct transfer of Zcoin tokens. Tokens are removed from the sender’s wallet and appear in the recipient's wallet, thus, Zcoin digital coins have no history.</li>
<li>Transaction information is hidden:</li>
</ol>
<ul>
<li>anonymous sender and recipient</li>
<li>the transfer amount is disclosed;<br>Zcoin takes up to three seconds.</li>
</ul>
<h3 id="mining-with-zcoin">Mining with ZCoin</h3>
<p>Zcoin uses the Proof of Work (PoW) protocol using the network computer's power.<br>The creators plan to switch to the MTP algorithm (instead of Lyra2z), which will allow Zcoin to position itself as a secure token, and reduce the time it takes to verify the crypto wallet during transactions.</p>
<p>The MTP algorithm maintains the same prices for one computing unit on all platforms, i.e. the possibility of gaining advantages over other users is eliminated. Attacks by cybercriminals are becoming economically unprofitable.</p>
<p>Zcoin founder rewards have been discontinued since May 2020. Remuneration for the formation of new blocks is 15%. 35% is the block reward for master nodes.<br>The Zcoin reserve fund is $ 100,000.<br>21 million crypto coins are planned for production. The remuneration principle is similar to BTC: the award is halved every 4 years.</p>
<h3 id="halving">Halving</h3>
<p><a href="https://getblock.io/nodes/xzc">Zcoin</a> follows a reward cut schedule every four years. The first halving happened in September-October of 2020.<br>Block rewards will drop from 25 XZC to 12.5 XZC per block. Zcoin's inflation rate is expected to drop from ~ 25% annually to ~ 12%. It will be the largest drop in inflation in the history of Zcoin after the first cut.<br>The next generation Lelantus privacy protocol will be launched in a few weeks.</p>
</div></div>]]>
            </description>
            <link>https://getblock.io/blog/about-the-zcoin-project</link>
            <guid isPermaLink="false">hacker-news-small-sites-24919606</guid>
            <pubDate>Wed, 28 Oct 2020 15:08:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Local Development Clusters]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24919575">thread link</a>) | @nicksantos
<br/>
October 28, 2020 | https://www.dex.dev/dex-videos/development-clusters | <a href="https://web.archive.org/web/*/https://www.dex.dev/dex-videos/development-clusters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Why Local Clusters? A local cluster is a great way to get started with Kubernetes. You’ll be able to experiment and make all the mistakes&nbsp;you want. But when you're looking around for local clusters, there's tons of options! Too many! Luckily, we’re here to help.</p><div><p>Why Local Clusters? <strong>A local cluster is a great way to get started with Kubernetes.</strong></p><p>You’ll be able to experiment and make all the mistakes&nbsp;you want. And afterwards it’s very easy to just reset the cluster and start anew. So it’s a great way for learning and trying new things.</p><figure id="w-node-1bc3a5362e69-9e408582"><p><img src="https://uploads-ssl.webflow.com/5f243bc3e9d7326bfac6867d/5f8f05ee73769925fa7ad8dd_alltheclusters.png" loading="lazy" alt=""></p></figure><p>But when you're looking around for local clusters, there's tons of options! Too many! There's <a href="https://kind.sigs.k8s.io/">Kind</a>, there's <a href="https://microk8s.io/">Microk8s</a>, there's <a href="https://k3s.io/">K3s</a>, <a href="https://github.com/kubernetes/minikube">Minikube</a>, <a href="https://www.docker.com/products/docker-desktop">Docker for Desktop</a>...? They all kind of copy each other, and there's tons of configurations for each.</p><p><strong>So how do you choose? Are they all the same? Are there any differences?</strong> Does it really matter?!</p><p>Luckily, we’re here to help.</p><p>‍</p><h2>How do I tell them apart?</h2><p>Every cluster needs to solve 3 problems:</p><ul role="list"><li>How do I <strong>build</strong> my app? (builders)</li><li>How do I <strong>store</strong> my app? (registries)</li><li>How do I <strong>run</strong> my app? (runtimes</li></ul><p>Docker for Desktop is one big component that solves all 3 problems. The others let you mix and match.</p><p>The advantage of being a single component is that it’s easier to set up. But it comes with limitations, and when it breaks, the whole things breaks.</p><p>For the others, you can mix and match components, and optimize the different parts to your workflow—this way they can be <strong>more powerful, but it's also more complicated</strong>.</p><p>So what are the components? What you should pay attention to? What are the parts, and can you replace &amp; optimize them?</p><p>‍</p><h2>What should I pay attention to?</h2><h3>Builder </h3><p>This is stuff like <a href="https://github.com/moby/buildkit">buildkit</a>, <a href="https://github.com/GoogleContainerTools/kaniko">kaniko</a>, <a href="https://github.com/genuinetools/img">img</a>, and so on. What matters here? For example: When building, you don’t wanna build everything from scratch. So how good is the caching in the builder that you're using?</p><p>Something else to consider is that builders are getting better all the time, getting new features and functionality. In your cluster of choice, <strong>will you be stuck with the default builder, or can you try new ones as you please?</strong></p><h3>Registry</h3><p>When developing locally, you shouldn't have to push your container images to DockerHub every single time. Ideally you'll be able to keep them locally, in a local registry. </p><p>But here's the thing: <strong>When using a local cluster, will resetting it</strong> (e.g. when it gets wedged) <strong>going to delete all your storage and all the cached container images</strong> you've already built?</p><h3>Runtime</h3><p>Trust me, you don’t want to have to debug virtual machine drivers, or decide by youself which VM is the <em>mostest optimalest</em> for the hardware you're using.</p><p>But what VM your cluster chooses, and <strong>how lightweight the container runner in that VM is, can have a big impact on the speed and stability of your app.</strong> </p><p>For reference, commonly used container runtimes are <a href="https://www.docker.com/products/container-runtime">Docker</a>, <a href="https://containerd.io/">containerd</a>, and <a href="https://cri-o.io/">CRI-O</a>.</p><p>‍</p><h2>What are the choices?</h2><p>To help us make sense of all the options we have, let’s classify them into three categories: all integrated, customizable, and “kitchen sink.”</p><p>‍</p><figure id="w-node-b7a3e7b107ba-9e408582"><p><img src="https://uploads-ssl.webflow.com/5f243bc3e9d7326bfac6867d/5f8f0b004debb4661f25e4f0_categorized.png" loading="lazy" alt=""></p></figure><h3>Docker for Desktop</h3><p><strong>Everything is one component.</strong> It has an amazing virtual machine experience—you often don’t even know you’re running a VM. Even the other clusters below often use Docker to manage the VM part. On the other extreme, we have...</p><h3>Minikube</h3><p><strong>Minikube can be anything you want it to be!</strong> There’s a way to run it like Docker for Desktop, where the builder, registry, and runtime are all a single component. </p><p>And there’s a way to do the absolute opposite, and customize it to your hearts content—beware though that not all the options really make sense, which can make things quite complicated.</p><h3>Kind</h3><p>The name stands for Kubernetes in Docker. It uses Docker to run the virtual machine, and for runtime it uses the generally more stable containerd. </p><p>You can run a separate registry that persists even after you reset the cluster. You can also use whatever builder you want. And <strong>Kind is very stable</strong>, because the Kubernetes project uses Kind to test Kubernetes itself.</p><h3>K3d</h3><p>The name stands for K3s in Docker. It's conceptually similar to Kind, but with <strong>K3s instead of the regular Kubernetes</strong>. K3s is a lighter Kubernetes distribution designed for lightweight, resource-constrained environments.</p><h3>Microk8s</h3><p>Microk8s is Kubernetes in a Snap. Snaps are a sandbox technology that <strong>works really well on Ubuntu</strong> but not necessarily as seamlessly on other distributions and operating systems. It has a registry in the cluster that resets with the cluster, unfortunately. And you can use whatever builder you want.</p><p>‍</p><h2>Recommendations</h2><p>Okay, that was a lot of options, and a whole lot of information. To navigate that, here are some opinions that might help you in making a choice:</p><p><strong>For getting started, Docker for Desktop is really easy and really convenient</strong>—it even has a GUI! </p><p>The problem is that it gets bricked from time to time, and needs to be reset. When that happens, your registry goes out the window, which means you have to rebuild everything again. That's annoying, but it's not a dealbreaker.</p><p>Once your whole team is using Kubernetes, <strong>we recommend you invest in setting up Kind</strong>. It has a solid, well-tested happy path and it makes good technical choices. </p><p>You can swap out components, but you don’t have to worry that some developer accidentally turned on an obscure VM driver—hello minikube!—and lost a whole day's work. And you can run Kind in CI too, which is a nice bonus.</p><p>Does that mean you’re never gonna use the other options? </p><p>No! <strong>There are good reasons to use all of them!</strong></p><ul role="list"><li>Minikube lets you test with lots of different Kubernetes configurations.</li><li>Microk8s offers really good integration with Ubuntu, so if you're using Ubuntu all day, it might be a really good option for you.</li><li>And K3d uses K3s, so for example it uses much less CPU at rest, so if that's what you're looking for, definitely check it out.</li></ul><p>And that’s it. </p><p>To summarize: </p><ul role="list"><li><a href="https://www.docker.com/products/docker-desktop">Docker for Desktop</a>: if you're just getting started.</li><li><a href="https://kind.sigs.k8s.io/">Kind</a>: for general usage.</li><li><a href="https://github.com/kubernetes/minikube">Minikube</a>, <a href="https://k3s.io/">K3s</a>, <a href="https://microk8s.io/">Microk8s</a>: for specific use-cases.</li></ul><p>Have fun folks! Just wait until you start having to mix-and-match local and remote resources... But that's a discussion for some other time.</p><p>For more content like this, please subscribe to our newsletter!</p><p>▋</p></div></div>]]>
            </description>
            <link>https://www.dex.dev/dex-videos/development-clusters</link>
            <guid isPermaLink="false">hacker-news-small-sites-24919575</guid>
            <pubDate>Wed, 28 Oct 2020 15:05:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Axios vs. Fetch: Which Should You Use?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24919558">thread link</a>) | @code_barbarian
<br/>
October 28, 2020 | https://masteringjs.io/tutorials/axios/vs-fetch | <a href="https://web.archive.org/web/*/https://masteringjs.io/tutorials/axios/vs-fetch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  
  
  <p>
    Oct 28, 2020
  </p>
  
  
  <p><a href="https://www.getrevue.co/profile/masteringjs/issues/should-you-use-axios-or-fetch-237049">Axios is Mastering JS' offically recommended HTTP client</a>. We occasionally use <a href="http://npmjs.com/package/superagent">superagent</a>, but we almost never use the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API/Using_Fetch"><code>fetch()</code> function</a>. The reason is that Axios drastically reduces the amount of boilerplate you need for your average API request. Here's some reasons why:</p>
<h3 id="axios-is-isomorphic-fetch-is-not">Axios is <a href="https://www.npmjs.com/package/axios#features">isomorphic</a>, fetch is not</h3>
<p>The syntax for most basic Axios requests is the same in both Node.js and the browser. Since Node.js does not
have a built-in <code>fetch()</code> function, you need to use a polyfill like <a href="http://npmjs.com/package/node-fetch">node-fetch</a>. And there are several <a href="https://github.com/node-fetch/node-fetch/blob/master/docs/v3-LIMITS.md">known differences between node-fetch and browser <code>fetch()</code></a>.</p>
<h3 id="axios-throws-an-error-when-a-request-fails">Axios throws an error when a request fails</h3>
<p>One of the most annoying issues with <code>fetch()</code> is that it <a href="https://medium.com/frontend-digest/axios-vs-fetch-which-to-use-in-2019-6678c083c5c">does not throw an error when the server responds with an HTTP error status, like 404 or 500</a>.</p>
<pre><code>fetch(<span>'https://httpbin.org/post'</span>).catch(<span><span>err</span> =&gt;</span> {
  
});

axios.get(<span>'https://httpbin.org/post'</span>).catch(<span><span>err</span> =&gt;</span> {
  err.response.status; 
});</code></pre>
<p>However, <code>fetch()</code> <strong>does</strong> throw an error if it can't reach the server, so you always need two distinct error handling
paths with <code>fetch()</code>. The situation is even worse with <a href="http://thecodebarbarian.com/async-await-error-handling-in-javascript.html">async/await</a>: every <code>fetch()</code> needs an extra <a href="https://masteringjs.io/tutorials/fundamentals/then"><code>then()</code></a> to bubble up errors.</p>
<p><a href="https://masteringjs.io/tutorials/axios/catch">Axios error handling</a> is much easier: just use <code>catch()</code>.</p>
<h3 id="automatic-json-and-form-encoded-serialization-and-parsing">Automatic JSON and Form-Encoded Serialization and Parsing</h3>
<p>Most modern APIs use JSON or <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/POST">form encoding</a> for request bodies. Axios handles JSON and form encoding automatically, as well as automatically <a href="https://masteringjs.io/tutorials/axios/get-query-params">serializing query strings</a>.</p>
<pre><code>
body = <span>JSON</span>.stringify(body);
query = <span>new</span> URLSearchParams(query).toString();

<span>const</span> res = <span>await</span> fetch(<span>'/myendpoint?'</span> + query, {
  <span>method</span>: <span>'POST'</span>,
  <span>headers</span>: {
    <span>'Content-Type'</span>: <span>'application/json'</span>
  },
  body
});


<span>await</span> axios.post(<span>'/myendpoint'</span>, { <span>params</span>: query, body });</code></pre>
<h3 id="framework-features-interceptors-and-instances">Framework Features: <a href="https://masteringjs.io/tutorials/axios/interceptors">Interceptors</a> and <a href="https://masteringjs.io/tutorials/axios/create">Instances</a></h3>
<p>With all these limitations, the unfortunate reality is that <a href="https://kentcdodds.com/blog/replace-axios-with-a-simple-custom-fetch-wrapper/">everybody who uses <code>fetch()</code> writes their own wrapper around <code>fetch()</code></a>. It is extremely difficult to build an app using <code>fetch()</code> directly.</p>
<p>Axios lets you go further by providing some framework-like features. You can use interceptors and instances to
<a href="https://www.getrevue.co/profile/masteringjs/issues/building-an-api-client-library-with-axios-254566">create your own API wrappers using Axios</a>. For example, here's how you can build a Trello API client using
instances and interceptors:</p>
<p><img src="https://s3.amazonaws.com/revue/items/images/006/139/960/mail/48496b778150aefaa29789612cff0777.png"></p><p>So Axios not only eliminates a lot of the boilerplate and rough edges of <code>fetch()</code>, and also makes it easier to
build specific wrappers for different APIs.</p>

  
  <hr>
  
    <h2>More Axios Tutorials</h2>
    <ul>
    
    <li><a href="https://masteringjs.io/tutorials/axios/proxy">Using Axios' Proxy Option</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/axios/delete">Axios DELETE Requests</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/axios/options">Axios Options</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/axios/get-with-data">Axios GET with Data</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/axios/get-query-params">GET Request Query Params with Axios</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/axios/response-body">Get the HTTP Response Body with Axios</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/axios/get">GET Requests with Axios</a></li>
  
    </ul>
  

      </div></div>]]>
            </description>
            <link>https://masteringjs.io/tutorials/axios/vs-fetch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24919558</guid>
            <pubDate>Wed, 28 Oct 2020 15:04:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Makes Netflix One of Media's Best Apps?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24919422">thread link</a>) | @Alvinthj
<br/>
October 28, 2020 | https://blog.snappymob.com/what-makes-netflix-one-of-medias-best-apps | <a href="https://web.archive.org/web/*/https://blog.snappymob.com/what-makes-netflix-one-of-medias-best-apps">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>In Southeast Asia alone, Netflix has over 14.5 million subscribers by the year of 2020. Can you imagine how much bigger the number is when we take into account their total subscribers worldwide?&nbsp;</p>
<!--more--><p>How does Netflix maintain the quality of their service by providing high quality videos at minimal buffer time? How do they maintain consistency in giving their users the best user experience regardless of their geographic coordinates?&nbsp;</p>
<p>Let’s put it under a microscope.</p>
<h2><strong>Data Analytics: Netflix’s Recommendation System</strong></h2>
<h3><strong>Viewing History</strong></h3>
<p>First things first, as you may or may not have noticed already, Netflix doesn't rely on one-size-fits-all ratings from IMDb or Rotten Tomatoes. Instead, they focus on personalization for users.&nbsp;</p>
<p>To provide the best user experience, it is essential to understand that every user is different. Netflix builds its algorithm around your viewing history and ratings. To suit your preferences, It detects patterns in your activity and makes recommendations accordingly.</p>
<p><img src="https://blog.snappymob.com/hs-fs/hubfs/recommendation%20system.png?width=600&amp;name=recommendation%20system.png" alt="recommendation system" width="600" srcset="https://blog.snappymob.com/hs-fs/hubfs/recommendation%20system.png?width=300&amp;name=recommendation%20system.png 300w, https://blog.snappymob.com/hs-fs/hubfs/recommendation%20system.png?width=600&amp;name=recommendation%20system.png 600w, https://blog.snappymob.com/hs-fs/hubfs/recommendation%20system.png?width=900&amp;name=recommendation%20system.png 900w, https://blog.snappymob.com/hs-fs/hubfs/recommendation%20system.png?width=1200&amp;name=recommendation%20system.png 1200w, https://blog.snappymob.com/hs-fs/hubfs/recommendation%20system.png?width=1500&amp;name=recommendation%20system.png 1500w, https://blog.snappymob.com/hs-fs/hubfs/recommendation%20system.png?width=1800&amp;name=recommendation%20system.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></p>
<h3><strong>Collaborative Filtering (CF)</strong></h3>
<p>Netflix connects your preferences with other Netflix users. Collaborative filtering functions with the assumption that if two users have similar ratings on a number of shows and movies, they behave similarly.</p>
<p>How does this play out on the app? When you rate a movie highly, Netflix recommends that movie to other users who share similar preferences with you.</p>
<h3><strong>Content Based Filtering (CB)</strong></h3>
<p>Unlike CF, Content Based Filtering (CB) isn’t based on data from other users, but the type of content users have shown interest in. The algorithm captures a user’s specific interests by detecting keywords used to describe the content they interact with.&nbsp;</p>
<p>For example, if a user completes a season of a spanish telenovela, Netflix will recommend other available spanish series. Or, if a user watches a horror film, Netflix will (you guessed it) recommend more of that genre.</p>
<h3><strong>User Profiling</strong></h3>
<p>User profiling is the process of collecting relevant data about the user <span>—</span> from a user’s geographical location and interests to behavioural statistical data like their active time on the app, time spent watching a movie, device, etc.&nbsp;</p>
<p>Taking the user’s information into account, Netflix suggests content that is compatible with the user profile.</p>
<h3><strong>Personalized Header Images</strong></h3>
<p>More about personalization <span>—</span> not sure if you’ve noticed before, but there’s a high chance that the headers you see on your account differs from another person’s.&nbsp;</p>
<p><img src="https://blog.snappymob.com/hs-fs/hubfs/gone%20girl%201.png?width=518&amp;name=gone%20girl%201.png" alt="gone girl 1" width="518" srcset="https://blog.snappymob.com/hs-fs/hubfs/gone%20girl%201.png?width=259&amp;name=gone%20girl%201.png 259w, https://blog.snappymob.com/hs-fs/hubfs/gone%20girl%201.png?width=518&amp;name=gone%20girl%201.png 518w, https://blog.snappymob.com/hs-fs/hubfs/gone%20girl%201.png?width=777&amp;name=gone%20girl%201.png 777w, https://blog.snappymob.com/hs-fs/hubfs/gone%20girl%201.png?width=1036&amp;name=gone%20girl%201.png 1036w, https://blog.snappymob.com/hs-fs/hubfs/gone%20girl%201.png?width=1295&amp;name=gone%20girl%201.png 1295w, https://blog.snappymob.com/hs-fs/hubfs/gone%20girl%201.png?width=1554&amp;name=gone%20girl%201.png 1554w" sizes="(max-width: 518px) 100vw, 518px"></p>
<p><img src="https://blog.snappymob.com/hs-fs/hubfs/gone%20girl%202.jpg?width=332&amp;name=gone%20girl%202.jpg" alt="gone girl 2" width="332" srcset="https://blog.snappymob.com/hs-fs/hubfs/gone%20girl%202.jpg?width=166&amp;name=gone%20girl%202.jpg 166w, https://blog.snappymob.com/hs-fs/hubfs/gone%20girl%202.jpg?width=332&amp;name=gone%20girl%202.jpg 332w, https://blog.snappymob.com/hs-fs/hubfs/gone%20girl%202.jpg?width=498&amp;name=gone%20girl%202.jpg 498w, https://blog.snappymob.com/hs-fs/hubfs/gone%20girl%202.jpg?width=664&amp;name=gone%20girl%202.jpg 664w, https://blog.snappymob.com/hs-fs/hubfs/gone%20girl%202.jpg?width=830&amp;name=gone%20girl%202.jpg 830w, https://blog.snappymob.com/hs-fs/hubfs/gone%20girl%202.jpg?width=996&amp;name=gone%20girl%202.jpg 996w" sizes="(max-width: 332px) 100vw, 332px"></p>
<p>Netflix shows you cover images that would most likely catch your interest. As mentioned before, there are many factors that go into this algorithm. If your activity shows that you’ve frequented action movies, chances are, Netflix is going to show you cover images of high-action blockbusters.</p>
<h2>Direct Content Acquisition</h2>
<p>If you’re subscribed, you probably know about Netflix Originals. It’s a no-brainer that Netflix would have full rights over Netflix Originals, but what about TV shows and movies that aren’t produced by Netflix?</p>
<p>To obtain broadcast rights for content from across the world, there are a few steps Netflix needs to take. First, Netflix would need to source the companies responsible for handling the distribution of a particular content. Oftentimes, a company might have signed a deal with different video services or TV channels at a specific location. When this happens, it’s one of two things <span>— </span>either Netflix won’t be able to obtain rights for the show, or they could, but on a different date.&nbsp;</p>
<p>Production houses and studios provide Netflix with high-quality cinema videos, which need to be processed before being made available to viewers on different devices. Considering that Netflix supports up to 2200 devices to this date, they need to take into account the varying video formats each device needs. How is this done?</p>
<h3><strong>Transcoding</strong></h3>
<p>This is where the magic of AWS servers come into play, by converting the original video into numbers of different formats and resolutions to support different screen sizes and devices.&nbsp;</p>
<p>Transcoding is a process by which Netflix breaks down the video into blocks, which with the help of AWS servers, will be converted into different formats across different resolutions like 4k, 1080p and etc. All these copies are then stored on Amazon S3. At the end of the day, one file will work exclusively on an iPhone, one on a Sony TV with Dolby sound, one on an Android tablet, and so on.&nbsp;</p>
<p>Interestingly, these files are also made with varying video qualities to suit different qualities of network connection. Netflix analyzes the quality and stability of a user’s internet connection and serves content accordingly, to ensure a smooth buffer regardless of network strength.</p>
<h3><strong>Digital Rights Management (DRM)</strong></h3>
<p>To prevent any piracy issues, a technological measure known as digital rights management is implemented, whereby a special code is added into these files to lock them from any possibilities of piracy. That’s why when you try to screenshot a movie you’re watching, you get an image of a black screen.</p>
<h2><strong>Running Microservices for Efficiency</strong></h2>
<h2><strong>Monolithic Architecture vs Microservices Architecture</strong></h2>
<p>Monolithic architecture is a model by which all codes and services are run by one application. Using this architecture runs the risk of having to rewrite every other part of the application’s code if one part of it is changed, shutting the entire app down. This could destroy the experience for Netflix’s users.</p>
<p>To change the game, Netflix built a revolutionary architecture known as microservices. In contrast to monolithic, this architecture structures the application as a collection of services. This means that each application or microservices’ code and resources are its very own.&nbsp;</p>
<p>By part of which two applications need to interact with each other, they will use an <strong>Application Programming Interface (API)</strong> <span>—</span> a software intermediary that allows two applications to “talk” to each other. This way, developers can make changes to the application with ease.</p>
<p>There are an estimated amount of 700 microservices used by Netflix <span>—</span> one for storing the content you watch, one for deducting monthly fees from credit cards, and other miscellaneous services.&nbsp;</p>
<p>To conclude, microservices architecture is built around business logic and enables flexibility for different needs. If one learns that a system is facing a bottleneck, it can efficiently be altered for scaling and optimization without changing the resources configuration for other services.</p>
<h3><strong>Amazon Web Services (AWS): Cloud-based Choice</strong></h3>
<p>With this huge number of microservices that stores hundreds and thousands of videos, Netflix needs reliable and scalable cloud networks and servers that would let them handle everything to their leverage. With the help of AWS EC2 and S3, Netflix can rapidly improve their services and keep the site stable.&nbsp;</p>
<h2><strong>Journey to Zero Buffer Time: Custom Content Delivery Network (CDN)</strong></h2>
<p>First, let’s try to understand how the internet works.&nbsp;</p>
<p>When you visit a site that requires net access, a request is sent to your internet service provider, which is also known as ISP. This ISP will then forward the request to the dedicated servers that handle the particular website that you’re trying to access. Upon receiving the request, the server provides a response which is navigated back to your computer, enabling your access to the site.&nbsp;</p>
<p>For a high-volume site like Netflix, a much larger network of servers is needed to maintain its performance. This is made possible with Content Delivery Network (CDN).</p>
<h3><strong>What is Content Delivery Network (CDN)?</strong></h3>
<p>Content Delivery Network is mostly used by giant media websites, like Facebook and Youtube. With CDN, the idea is to place servers as close as possible to users and optimize the network for speed and reliability.</p>
<p>For Netflix, CDN takes the original website and its content, and copies it across hundreds of servers all around the world. This increases speed as it reduces the gap between a request and a response, making loading content really fast regardless of where you are in the world.</p>
<h3><strong>Open Connect: Reaching Out to the Locals</strong></h3>
<p>With a rapidly growing user base, Netflix needed an alternative that will help in reducing cost while increasing quality and scalability. So they made a custom CDN, Open Connect, which is like a fast server assembled from numbers of hard disks and flash drives for storing videos.</p>
<p>Netflix places their open connect boxes with the data centres of ISPs all around the world. They struck a deal with these ISPs and in turn, provided them the fast server at no cost. It’s a win-win situation. ISPs get to install these along with their servers where they can download all of Netflix libraries for their region from the main servers in the United States.&nbsp;</p>
<p>In literal terms, they are like hard drives located around the world that store videos from Netflix. This way, Netflix gets all the benefits of a data centre without having the need to manage them. This strategy is (among other factors) what enables Netflix users to load content fast, as ISPs are located close to them.&nbsp;</p>
<p>ISPs can submit a request to improve their customer’s experience on Netflix through localizing Netflix traffic, by joining <a href="https://openconnect.netflix.com/"><span>The Netflix Open Connect Program</span></a>.</p>
<h2><strong>Next Step for Media Companies</strong></h2>
<p>For media companies, consistent and constant improvement in media strategy is essential. Be it scaling up, digitalization, or automation, Snappymob has experience lifting up companies like 988 FM, BFM Radio, Suria FM in the media industry.</p>
<p>Let us take you higher in the digital atmosphere. Contact us <a href="http://www.snappymob.com/contact"><span>here</span></a> to discuss your company’s growth opportunities, or read our case studies on media apps <a href="http://www.snappymob.com/work"><span>here</span></a>.</p></span></p><p><label>app insights</label></p>
        
      </div></div>]]>
            </description>
            <link>https://blog.snappymob.com/what-makes-netflix-one-of-medias-best-apps</link>
            <guid isPermaLink="false">hacker-news-small-sites-24919422</guid>
            <pubDate>Wed, 28 Oct 2020 14:54:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Various Outlets Are Saying About Section 230 of Communications Decency Act]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24918967">thread link</a>) | @pspct
<br/>
October 28, 2020 | https://www.alephpost.com/event/2020-10-27/internet-jack-dorsey-mark-zuckerberg-section-230-of-the-communications-decency-act | <a href="https://web.archive.org/web/*/https://www.alephpost.com/event/2020-10-27/internet-jack-dorsey-mark-zuckerberg-section-230-of-the-communications-decency-act">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.alephpost.com/event/2020-10-27/internet-jack-dorsey-mark-zuckerberg-section-230-of-the-communications-decency-act</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918967</guid>
            <pubDate>Wed, 28 Oct 2020 14:18:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The all-powerful bad apple]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24918939">thread link</a>) | @mcrittenden
<br/>
October 28, 2020 | https://critter.blog/2020/10/28/the-all-powerful-bad-apple/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/10/28/the-all-powerful-bad-apple/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-2629">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>The book <a href="https://www.goodreads.com/book/show/33517721-the-culture-code">The Culture Code</a> by Daniel Coyle starts out with a fascinating example of a bad apple. Here’s a big quote, but I promise it’s worth it.</p>



<blockquote><p>Meet Nick, a handsome, dark-haired man in his twenties seated comfortably in a wood-paneled conference room in Seattle with three other people. To outward appearances, he is an ordinary participant in an ordinary meeting. This appearance, however, is deceiving. The other people in the room do not know it, but his mission is to sabotage the group’s performance.</p><p>Nick is the key element of an experiment being run by Will Felps, who studies organizational behavior at the University of South Wales in Australia. Felps has brought in Nick to portray three negative archetypes: the Jerk (an aggressive, defiant deviant), the Slacker (a withholder of effort), and the Downer (a depressive Eeyore type). Nick plays these roles inside forty four-person groups tasked with constructing a marketing plan for a start-up. In effect, Felps injects him into the various groups the way a biologist might inject a virus into a body: to see how the system responds. Felps calls it the bad apple experiment.</p><p>Nick is really good at being bad. In almost every group, his behavior reduces the quality of the group’s performance by 30 to 40 percent. The drop-off is consistent whether he plays the Jerk, the Slacker, or the Downer.</p><p>“When Nick is the Downer, everybody comes into the meeting really energized. He acts quiet and tired and at some point puts his head down on his desk,” Felps says. “And then as the time goes by, they all start to behave that way, tired and quiet and low energy. By the end, there are three others with their heads down on their desks like him, all with their arms folded.”</p><p>When Nick plays the Slacker, a similar pattern occurs. “The group quickly picks up on his vibe,” Felps says. “They get done with the project very quickly, and they do a half-assed job. What’s interesting, though, is that when you ask them about it afterward, they’re very positive on the surface. They say, ‘We did a good job, we enjoyed it.’ But it isn’t true. They’d picked up on the attitude that this project really didn’t matter, that it wasn’t worth their time or energy. I’d gone in expecting that someone in the group would get upset with the Slacker or the Downer. But nobody did. They were like, ‘Okay, if that’s how it is, then we’ll be Slackers and Downers too.’ ”</p><cite>Daniel Coyle, <a href="https://www.goodreads.com/book/show/33517721-the-culture-code">The Culture Code</a></cite></blockquote>



<p>This was a lightbulb moment for me because I see it all the time but I’ve never realized it. </p>



<p>I’ve been in upbeat meetings that were cruising until a downer joined. And I’ve seen miserable Eeyore meetings turn around when an excited person hopped on. </p>



<p>It only takes one Nick. One downer, or one jerk, or one slacker (which often manifests by <em>multitasking</em>). I don’t want to be the Nick. I can’t be the person that brings the group down. </p>



<p>The book goes on to describe an outlier group. Nick couldn’t bog this group down, because it had Jonathan. Jonathan was so good at encouraging and jelling the team that Nick didn’t have an effect. Nick even found himself being helpful almost against his will.</p>



<p>My resolution is to either be the Jonathan, or leave the meeting. If I can’t help but be the Nick, then I shouldn’t be there. They’re better off without me. Jonathan or bust!</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/10/28/the-all-powerful-bad-apple/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918939</guid>
            <pubDate>Wed, 28 Oct 2020 14:15:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handling of Uncaught Exceptions in Haskell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24918897">thread link</a>) | @NaeosPsy
<br/>
October 28, 2020 | https://serokell.io/blog/uncaught-exception-handling | <a href="https://web.archive.org/web/*/https://serokell.io/blog/uncaught-exception-handling">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When your Haskell application’s thread throws an exception that does not get caught, the Haskell runtime system will handle it and print it based on the <code>Show</code> instance.
This is the default behavior that can be customized using the <a href="https://hackage.haskell.org/package/base-4.14.0.0/docs/GHC-Conc-Sync.html#v:setUncaughtExceptionHandler"><code>setUncaughtExceptionHandler</code></a> function.</p><p>Personally, I was quite surprised when I noticed that the <code>Show</code> type class is used for rendering.
At the early days of my Haskell development experience, I noticed that the <code>Exception</code> type class had the <code>displayException</code> method and assumed that it’s used for printing of uncaught exceptions.
A few years later, I realized that my assumption was wrong and was quite surprised.
The default uncaught exception handler uses <code>showsPrec</code> from the <code>Show</code> type class, not <code>displayException</code>.
When I shared this information with my colleagues, some of them were surprised as well.
I was inclined to think that <code>displayException</code> is a better default, and it turned out that I was not the only one thinking this way.
Since people were supporting this idea, I decided to do two things:</p><ol>
<li>Raise this topic in the GHC issue tracker.</li>
<li>Create a small library with a function that would carefully modify uncaught exception handling to use <code>displayException</code>.
We already had such a helper in our code base and wanted to extract it into a library.
This function is not entirely trivial because, for example, the <code>ExitCode</code> exception should be handled specially (the program should exit with the appropriate exit code in this case).</li>
</ol><p>I started with researching this topic and discovered that it already had been discussed back in 2014.</p><h2 id="history">History</h2><p>The relevant GHC issue is <a href="https://gitlab.haskell.org/ghc/ghc/-/issues/9822">#9822</a>.
It refers to the <a href="https://mail.haskell.org/pipermail/libraries/2014-November/024176.html">e-mail thread</a> where two things were proposed:</p><ol>
<li>The addition of <code>displayException</code> to <code>Exception</code>.</li>
<li>The modification of the default uncaught exception handler to use <code>displayException</code>.</li>
</ol><p>The first thing was accepted and implemented, and the <code>displayException</code> is a part of <code>Exception</code> for many years already.
The second thing, however, appeared to be debatable and there was no consensus regarding it.
You can read the whole thread for details since it’s not so big.
Two essential points from it are:</p><ol>
<li>There is a good reason to use <code>show</code> for uncaught exceptions.
Uncaught exceptions are usually encountered by programmers, so it’s better to format them in “programmer-friendly” way, i. e. using <code>show</code>.
So that should be the default.
However, sometimes one may prefer <code>displayException</code>, so it should be easy to use it instead.</li>
<li>Even though there is <a href="https://hackage.haskell.org/package/base-4.14.0.0/docs/GHC-Conc-Sync.html#v:setUncaughtExceptionHandler"><code>setUncaughtExceptionHandler</code></a>, modifying the uncaught exception handler to use <code>displayException</code> is not easy because:</li>
</ol><ul>
<li>stdout has to be flushed, ignoring any exceptions while doing so;</li>
<li>output has to go to stderr, not stdout;</li>
<li>the <code>ExitCode</code> exception should be handled correctly, and the program should exit with correct exit code.</li>
</ul><p>After that, there was a discussion about adding <code>useDisplayExceptionHandler</code> or <code>displayExceptionHandler</code> that would do “the right thing”, but this discussion quickly moved into another direction and no such function was added.
In 2020, I couldn’t find a function that does “the right thing” on Hackage.</p><p>When I first implemented this helper (before reading this thread), I didn’t take <code>ExitCode</code> into account and had a subtle minor bug.
My program was exiting with non-zero code when launched with <code>--help</code> because <code>optparse-applicative</code> library throws (probably indirectly) <code>ExitSuccess</code> in this case, but I didn’t consider that.</p><h2 id="why-displayexception%3F">Why <code>displayException</code>?</h2><p>The intended difference between <code>displayException</code> and <code>show</code> is that the former should return a “human-friendly” string, while the latter does not say anything about “human-friendliness” and is usually auto-generated to produce “programmer-friendly” strings that reflect the internal structure of the Haskell type.
A good analogy from the aforementioned e-mail thread is <code>str()</code> and <code>repr()</code> functions in Python.</p><p>Based on my experience, I admit that <code>displayException</code> is usually implemented as <code>show</code>, which is the default implementation.
I think there are 3 possible reasons for that:</p><ol>
<li><code>Show</code> is auto-generated and the string produced by it sufficiently human-friendly and custom formatting is not needed.
I believe it’s a rare case because auto-generated <code>show</code> usually looks quite verbose.</li>
<li>A programmer just didn’t bother implementing <code>displayException</code>.
Maybe they forgot to do it (the compiler doesn’t check it), maybe they were lazy, maybe they didn’t even know about this method.</li>
<li>There is a custom <code>Show</code> instance with human-readable pretty formatting.
I think it’s a bad idea because then there is no way to render an exception in “programmer-friendly” way.
“Programmer-friendly” way usually contains Haskell identifiers, so that you can quickly find documentation for the relevant data type.
Also, you should be able to see all values that constitute the exception.
“Human-friendly” way may return a string where some fields are omitted and figuring out which type of exception was thrown can be complicated.</li>
</ol><p>So currently, in many cases it does not really matter which function is called to print an uncaught exception because <code>displayException</code> is often implemented as <code>show</code>.
However, I think that in the ideal world, most of the types with <code>Exception</code> instance should provide a custom definition for <code>displayException</code>, and the topic brought up in this article will matter.</p><p>It’s indeed debatable which function is more appropriate. I think there is no clear winner, so it should be easy to use either of them for uncaught exceptions.
One thought that I have is that <code>displayException</code> is more appropriate for console apps because uncaught exceptions are visible to end users, while <code>show</code> is more appropriate for UI apps because errors in UI apps are hidden from end users.
Anyway, it’s just one thought, and I don’t intend to recommend using <code>displayException</code> for uncaught exceptions, I just want to make it easy to do so if someone wants that.</p><h2 id="uncaught-exception">uncaught-exception</h2><p>Since there was a discussion about providing a function that would change uncaught exception handling to use <code>displayException</code> but no actions were taken, I went ahead and implemented a tiny library for this use case.
The library is called <a href="https://hackage.haskell.org/package/uncaught-exception">uncaught-exception</a>.
You can view its source code on <a href="https://github.com/serokell/uncaught-exception">GitHub</a>.</p><p>The default exception handler is implemented in GHC <a href="https://hackage.haskell.org/package/base-4.14.0.0/docs/src/GHC.Conc.Sync.html#uncaughtExceptionHandler">as follows</a>:</p><pre><code><span>defaultHandler</span> :: <span>SomeException</span> -&gt; <span>IO</span> ()
<span>defaultHandler</span> se@(<span>SomeException</span> ex) = <span>do</span>
   (hFlush stdout) `catchAny` (\ _ -&gt; return ())
   <span>let</span> msg = <span>case</span> cast ex <span>of</span>
         <span>Just</span> <span>Deadlock</span> -&gt; <span>"no threads to run:  infinite loop or deadlock?"</span>
         _                  -&gt; showsPrec <span>0</span> se <span>""</span>
   withCString <span>"%s"</span> $ \cfmt -&gt;
    withCString msg $ \cmsg -&gt;
      errorBelch cfmt cmsg



<span>foreign</span> <span>import</span> <span>ccall</span> <span>unsafe</span> <span>"HsBase.h errorBelch2"</span>
   errorBelch :: <span>CString</span> -&gt; <span>CString</span> -&gt; <span>IO</span> ()
</code></pre><p>I could have implemented a similar handler myself, but decided not to do it because I don’t entirely understand this definition.
Specifically:</p><ol>
<li>How is <code>ExitCode</code> handled and how does a Haskell program determine which code it should exit with?
Is it handled by <code>errorBelch</code>? Probably no because <code>errorBelch</code> only takes two strings.
So perhaps it’s handled outside of this helper.</li>
<li>What does <code>errorBelch</code> do, and why is it implemented in a foreign language (most likely C/C++)?
Can’t it be implemented in Haskell?
Should I use FFI in my handler as well?</li>
</ol><p>I guess I could find out answers to these questions, but I picked a simpler way, actually two ways.
If this default handler is ever updated in GHC, I will not have to do anything in my library.
I define the following wrapper:</p><pre><code>



<span><span>newtype</span> <span>DisplayExceptionInShow</span> = <span>DisplayExceptionInShow</span> <span>SomeException</span></span>
<span>
<span>instance</span> <span>Show</span> <span>DisplayExceptionInShow</span> <span>where</span></span>
  show (<span>DisplayExceptionInShow</span> se) = displayException se
<span>
<span>instance</span> <span>Exception</span> <span>DisplayExceptionInShow</span>
</span></code></pre><p>along with the <code>wrapException :: SomeException -&gt; SomeException</code> function that wraps exceptions into this wrapper.
And define two functions:</p><pre><code><span>displayUncaughtException</span> :: <span>IO</span> a -&gt; <span>IO</span> a
<span>displayUncaughtException</span> = handle (throwIO . wrapException)

<span>withDisplayExceptionHandler</span> :: <span>IO</span> a -&gt; <span>IO</span> a
<span>withDisplayExceptionHandler</span> action = <span>do</span>
  handler &lt;- getUncaughtExceptionHandler
  setUncaughtExceptionHandler (handler . wrapException)
  action &lt;* setUncaughtExceptionHandler handler
</code></pre><p>They serve the same purpose, but I am not sure which one is better, hence I provide both.
If you have a good argument in favor of one of these functions, please let me know.</p><p>In the first version, we don’t touch the default handler at all.
In the second version, we only update it to wrap its argument into <code>DisplayExceptionInShow</code> and then apply as is.
Also, there is <code>setDisplayExceptionHandler</code>, which updates the handler the same way as <code>withDisplayExceptionHandler</code> but doesn’t restore it in the end.
In all cases, all concerns should be handled.</p><p>All but one: if we wrap <code>ExitCode</code> into <code>DisplayExceptionInShow</code>, we will break functions like <code>exitSuccess</code> because they work by throwing an <code>ExitCode</code> exception and we change its type.
So we implement <code>wrapException</code> carefully to ignore <code>ExitCode</code>:</p><pre><code><span>wrapException</span> :: <span>SomeException</span> -&gt; <span>SomeException</span>
<span>wrapException</span> e
  | isSyncException e
  , <span>Nothing</span> &lt;- fromException @<span>Deadlock</span> e
  , <span>Nothing</span> &lt;- fromException @<span>ExitCode</span> e =
      toException $ <span>DisplayExceptionInShow</span> e
  | otherwise = e
  <span>where</span>
    isSyncException :: <span>SomeException</span> -&gt; <span>Bool</span>
    isSyncException = isNothing . fromException @<span>SomeAsyncException</span>
</code></pre><p>Notice that we also ignore exceptions that can be cast to <code>SomeAsyncException</code>.
The reason is twofold:</p><ol>
<li>There are not many such exceptions, and their <code>show</code> representation should be more or less human-friendly.</li>
<li>I am afraid that by wrapping them into <code>DisplayExceptionInShow</code>, we may break something the same way as we break when we wrap <code>ExitCode</code>.</li>
</ol><p>We also ignore <code>Deadlock</code> because it’s specifically handled by <code>defaultHandler</code>.</p><p>Notice that there is an essential difference in case an uncaught exception occurs in a thread other than the one where one of these functions was used.
<code>displayUncaughtException</code> only affects the thread where it’s called, all other threads are unaffected (and use <code>Show</code> for printing by default).
<code>withDisplayExceptionHandler</code> updates …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serokell.io/blog/uncaught-exception-handling">https://serokell.io/blog/uncaught-exception-handling</a></em></p>]]>
            </description>
            <link>https://serokell.io/blog/uncaught-exception-handling</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918897</guid>
            <pubDate>Wed, 28 Oct 2020 14:11:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Higher Kinded Types in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24918857">thread link</a>) | @jerodsanto
<br/>
October 28, 2020 | https://sobolevn.me/2020/10/higher-kinded-types-in-python | <a href="https://web.archive.org/web/*/https://sobolevn.me/2020/10/higher-kinded-types-in-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p><img src="https://dev-to-uploads.s3.amazonaws.com/i/73uvh47fvxfveqpz2xgi.png" alt="Cover image"></p>

<p><code>dry-python/returns@0.15</code> is <a href="https://github.com/dry-python/returns/releases/tag/0.15.0">released</a>! And it means that now anyone can use our Higher Kinded Types emulation in their projects.</p>

<p>In this post I will explain:</p>
<ul>
  <li>What Higher Kinded Types (HKTs) are and why they are useful</li>
  <li>How they are implemented and what limitations there are</li>
  <li>How can you use them in your own projects</li>
</ul>

<p>Without further ado, let’s talk about typing!</p>


      <h2 id="simple-types">
        
        <a href="#simple-types">Simple types</a>
        
      </h2>

<p>Typing is layered. Like a good cake. There are at least three layers that we are going to cover.</p>

<p>Simple (or flat) typing, like <code>x: int = 1</code>. This allows us to express simple types and their transformations. Like <code>int -&gt; str</code>:</p>

<div><div><pre><code><span>def</span> <span>stringify</span><span>(</span><span>arg</span><span>:</span> <span>int</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>return</span> <span>str</span><span>(</span><span>arg</span><span>)</span>
</code></pre></div></div>

<p>A lot of languages like <code>go</code> and <code>php</code> do not go beyond this line. And they still work pretty well! These types are also sometimes called <code>*</code>-kinded. It can be understood as “a place for just a single type argument”.</p>


    
      <h2 id="generic">
        
        <a href="#generic">Generic</a>
        
      </h2>

<p>Generic level is required to express “nested” types. For example, you have a list of integers. In Python we annotate it as <code>List[int]</code> or <a href="https://www.python.org/dev/peps/pep-0585/"><code>list[int]</code></a> in Python <code>3.9</code>. This allows us to have types with other types as arguments. <code>List</code> can receive <code>int</code> or <code>str</code> or even another <code>List</code> as the type argument. This way we can nest type and types start to have their own structure.</p>

<p>Generics are much more interesting than simple types. And they can have multiple type arguments:</p>
<ul>
  <li>List has one: for values, so it has a kind of <code>* -&gt; *</code>. It can be understood as a type transformation <code>List -&gt; T = List[T]</code></li>
  <li>Dict has two: for keys and values, so it has a kind of <code>* -&gt; * -&gt; *</code>. It can be understood as a type transformation <code>Dict -&gt; K -&gt; V = Dict[K, V]</code></li>
  <li>And so on!</li>
</ul>

<p>This would be very helpful for us in the future, I promise.</p>

<p>We can also write transformations for generic types:</p>

<div><div><pre><code><span>def</span> <span>stringify_list_items</span><span>(</span><span>arg</span><span>:</span> <span>List</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>List</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>[</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>]</span>
</code></pre></div></div>

<p>But, that is where things begin to be quite complicated.</p>

<p>How can this function work with other iterables like <code>set</code>, <code>frozenset</code>, <code>tuple</code>?
We can express this in Python as easy as:</p>

<div><div><pre><code><span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>):</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>But the typing part would be quite challenging. Let’s try several things.</p>


    
      <h3 id="common-interface">
        
        <a href="#common-interface">Common interface</a>
        
      </h3>

<p>The first obvious thing to try is <code>Iterable</code> protocol. It is builtin into Python and does what we need.</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Iterable</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>Iterable</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>Iterable</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>Let’s try it out:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>]))</span>
<span># Revealed type is 'typing.Iterable[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>}))</span>
<span>#  Revealed type is 'typing.Iterable[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>((</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>)))</span>
<span>#  Revealed type is 'typing.Iterable[builtins.str]'
</span></code></pre></div></div>

<p>You can see that a part of our typing information is lost. We pass <code>List</code> or <code>Set</code> or <code>Tuple</code> and always get the <code>Iterable</code> back.</p>

<p>Sometimes - this is ok. But, in some cases, this is not enough. Let’s try some other technique!</p>


    
      <h3 id="methods">
        
        <a href="#methods">Methods</a>
        
      </h3>

<p>One can say: we are all using Object-Oriented Programming! Why cannot we just create a new method for each type we need? And specify the exact return type there!</p>

<p>Well, it is a possible solution. But, there are some reasonable problems:</p>

<ul>
  <li>You cannot add methods to existing types and extend them with this approach. Only create new ones, probably via subtyping, and add new methods there. In our example you would have to create your own versions of <code>List</code>, <code>Set</code>, and <code>Tuple</code>. Which is not desirable in most situations</li>
  <li>It really starts to be messy if you have a lot of methods to add. A type with more than <code>X</code> (choose the number yourself) methods starts to be really complex to read, understand, and use. Instead, using separate functions is much easier, because we don’t have to put everything into a single namespace</li>
</ul>

<p>Let’s try something else.</p>


    
      <h3 id="overloads">
        
        <a href="#overloads">overloads</a>
        
      </h3>

<p>Another solution that might solve our problem is using the <code>@overload</code> decorator with proper types for each required case.</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>List</span><span>,</span> <span>Set</span><span>,</span> <span>overload</span>

<span>@</span><span>overload</span>
<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>List</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>List</span><span>[</span><span>str</span><span>]:</span>
    <span>...</span>

<span>@</span><span>overload</span>
<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>Set</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>Set</span><span>[</span><span>str</span><span>]:</span>
    <span>...</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>):</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>Let’s test it:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>]))</span>
<span># Revealed type is 'builtins.list[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>}))</span>
<span># Revealed type is 'builtins.set[builtins.str]'
</span></code></pre></div></div>

<p>Awesome! Looks like we’ve achieved our goal, haven’t we? But, there’s a new problem. We have to manually list all possible cases in a function’s signature. This works for cases when all possible arguments and outcomes are known in advance. But, not in this case. In Python <code>Iterable</code> is a protocol. We can use this function with any type with <code>__iter__</code> method defined: with both builtin and custom types. So, the number of possible arguments and outcomes is endless.</p>

<p>To illusrate the problem, let’s see what happens for <code>Tuple</code> which is not listed in the function’s overloads:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>((</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>)))</span>
<span># error: No overload variant of "stringify_iterable_items" matches argument type "Tuple[int, int, int]"
</span></code></pre></div></div>

<p>We, in <code>dry-python</code> <a href="https://github.com/dry-python/returns/blob/0.14.0/returns/_generated/converters/flatten.pyi">used this technique</a> with <code>@overload</code> decorator for our previous versions. This allowed us to write correct definitions of functions working with generic types. But, they were limited to the pre-defined set of our own types. And we wanted to allow our users to create their custom types based on our interfaces. With the full existing code reuse.</p>


    
      <h2 id="higher-kinded-types">
        
        <a href="#higher-kinded-types">Higher Kinded Types</a>
        
      </h2>

<p>That’s where the idea of Higher Kinded Types becomes useful. We need HKTs when we want to change the inner structure of generics with full type information preserving and openness to the extension. In theory, you can write something like:</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Iterable</span>

<span>T</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'T'</span><span>,</span> <span>bound</span><span>=</span><span>Iterable</span><span>)</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>T</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>T</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>And this would solve our problem! What happens here is that we abstract away the <code>Iterable</code> type itself. And then ask <code>mypy</code> to figure this out for us.</p>

<p>This way we can potentially have <code>stringify_iterable_items</code> working for any <code>Iterable</code> type, but with the exact same type returned back without any information lost. And it would work for all types.</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>]))</span>
<span># Revealed type is 'builtins.list[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>}))</span>
<span># Revealed type is 'builtins.set[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>(</span><span>MyCustomIterable</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)))</span>
<span># Revealed type is 'my_module.MyCustomIterable[builtins.str]'
</span></code></pre></div></div>

<p>Unfortunately, <a href="https://github.com/python/typing/issues/548">it is not supported</a> at the moment.</p>


    
      <h3 id="emulation">
        
        <a href="#emulation">Emulation</a>
        
      </h3>

<p>Turns out we are not alone in this situation. There are multiple languages where Higher Kinded Types are not natively supported yet. But, they can be emulated:</p>

<ul>
  <li><a href="https://github.com/gcanti/fp-ts/blob/master/docs/guides/HKT.md">TypeScript</a></li>
  <li><a href="https://bow-swift.io/docs/fp-concepts/higher-kinded-types/">Swift</a></li>
  <li><a href="https://arrow-kt.io/docs/0.10/patterns/glossary/#higher-kinds">Kotlin</a></li>
</ul>

<p>And now with <a href="https://returns.readthedocs.io/en/latest/pages/hkt.html">Python</a> too!</p>

<p>There’s also <a href="https://www.cl.cam.ac.uk/~jdy22/papers/lightweight-higher-kinded-polymorphism.pdf">an original whitepaper</a> for ones who are interested.</p>

<p>The core idea of HKT emulation is that we can write types the other way around: not like <code>T[int]</code>, but rather like <code>Kind[T, int]</code> (which is absolutely the same thing).</p>

<p>This way we can transform the inner structure of generics, but maintain the simple context without reinventing <code>TypeVar</code> with type arguments. And our function’s type signature will look like: <code>Kind[T, int] -&gt; Kind[T, str]</code>.</p>

<p>Let’s see the implementation.</p>


    
      <h2 id="implementation">
        
        <a href="#implementation">Implementation</a>
        
      </h2>

<p><strong>TLDR</strong>: here’s <a href="https://gist.github.com/sobolevn/7f8ffd885aec70e55dd47928a1fb3e61">the final working code</a> with all the logic, all the hacks, and everything. In this article, we going to write and explain it step by step.</p>

<p>We would need a better example to test our implementation. Let’s build two types: a <code>Box</code> and a <code>Bag</code>. <code>Box</code> is defined by its size, while a <code>Bag</code> is an item of fashion: it has a brand name and a model name (I have a wife, I know this stuff!).</p>

<div><div><pre><code><span>from</span> <span>dataclasses</span> <span>import</span> <span>dataclass</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Callable</span><span>,</span> <span>Generic</span><span>,</span> <span>TypeVar</span>

<span>_ValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_ValueType'</span><span>)</span>
<span>_NewValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_NewValueType'</span><span>)</span>

<span>@</span><span>dataclass</span>
<span>class</span> <span>Box</span><span>(</span><span>Generic</span><span>[</span><span>_ValueType</span><span>]):</span>
    <span>value</span><span>:</span> <span>_ValueType</span>
    <span>length</span><span>:</span> <span>int</span>
    <span>width</span><span>:</span> <span>int</span>
    <span>height</span><span>:</span> <span>int</span>

<span>@</span><span>dataclass</span>
<span>class</span> <span>Bag</span><span>(</span><span>Generic</span><span>[</span><span>_ValueType</span><span>]):</span>
    <span>value</span><span>:</span> <span>_ValueType</span>
    <span>brand</span><span>:</span> <span>str</span>
    <span>model</span><span>:</span> <span>str</span>
</code></pre></div></div>

<p>And we can create <code>Box</code>es and <code>Bag</code>s of different types, because we can put different things inside them:</p>

<div><div><pre><code><span>box</span> <span>=</span> <span>Box</span><span>(</span><span>value</span><span>=</span><span>10</span><span>,</span> <span>length</span><span>=</span><span>1</span><span>,</span> <span>width</span><span>=</span><span>2</span><span>,</span> <span>height</span><span>=</span><span>3</span><span>)</span>  <span># Box[int]
</span><span>bag</span> <span>=</span> <span>Bag</span><span>(</span><span>value</span><span>=</span><span>5</span><span>,</span> <span>brand</span><span>=</span><span>'Fancy'</span><span>,</span> <span>model</span><span>=</span><span>'Baggy'</span><span>)</span>  <span># Bag[int]
</span></code></pre></div></div>

<p>Now, we need a function with a type transformation. Let’s say we want to apply a function to the value inside boxes and bags. Let’s use fake <code>BoxOrBag</code> type for now to illustrate our intent:</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Callable</span>

<span>_NewValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_NewValueType'</span><span>)</span>

<span>def</span> <span>apply_function</span><span>(</span>
    <span>instance</span><span>:</span> <span>BoxOrBag</span><span>[</span><span>_ValueType</span><span>],</span>  <span># fake type for now
</span>    <span>callback</span><span>:</span> <span>Callable</span><span>[[</span><span>_ValueType</span><span>],</span> <span>_NewValueType</span><span>],</span>
<span>)</span> <span>-&gt;</span> <span>BoxOrBag</span><span>[</span><span>_NewValueType</span><span>]:</span>  <span># fake type for now
</span>    <span>...</span>
</code></pre></div></div>

<p>It is going to work like so:</p>

<div><div><pre><code><span>assert</span> <span>apply_function</span><span>(</span><span>box</span><span>,</span> <span>str</span><span>)</span> <span>==</span> <span>Box</span><span>(</span><span>value</span><span>=</span><span>'10'</span><span>,</span> <span>length</span><span>=</span><span>1</span><span>,</span> <span>width</span><span>=</span><span>2</span><span>,</span> <span>height</span><span>=</span><span>3</span><span>)</span>
<span>assert</span> <span>apply_function</span><span>(</span><span>bag</span><span>,</span> <span>bool</span><span>)</span> <span>==</span> <span>Bag</span><span>(</span><span>value</span><span>=</span><span>True</span><span>,</span> <span>brand</span><span>=</span><span>'Fancy'</span><span>,</span> <span>model</span><span>=</span><span>'Baggy'</span><span>)</span>
</code></pre></div></div>

<p>We only need to change current fake <code>BoxOrBag</code> type to a real HKT. We would need to define a new <code>Kind</code> type to make the emulation:</p>

<div><div><pre><code><span>_InstanceType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_InstanceType'</span><span>,</span> <span>covariant</span><span>=</span><span>True</span><span>)</span>
<span>_FirstTypeArgType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_FirstTypeArgType'</span><span>,</span> <span>covariant</span><span>=</span><span>True</span><span>)</span>

<span>class</span> <span>Kind</span><span>(</span><span>Generic</span><span>[</span><span>_InstanceType</span><span>,</span> <span>_FirstTypeArgType</span><span>]):</span>
    <span>"""Used for HKT emulation."""</span>
</code></pre></div></div>

<p>One pro-tip about <code>Kind</code>: it won’t not exist during runtime. Only during type-checking.</p>

<p>Now, let’s change <code>apply_function</code> to use <code>Kind</code>:</p>

<div><div><pre><code><span>_InstanceKind</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_InstanceKind'</span><span>)</span>

<span>def</span> <span>apply_function</span><span>(</span>
    <span>instance</span><span>:</span> <span>Kind</span><span>[</span><span>_InstanceKind</span><span>,</span> <span>_ValueType</span><span>],</span>
    <span>callback</span><span>:</span> <span>Callable</span>…</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sobolevn.me/2020/10/higher-kinded-types-in-python">https://sobolevn.me/2020/10/higher-kinded-types-in-python</a></em></p>]]>
            </description>
            <link>https://sobolevn.me/2020/10/higher-kinded-types-in-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918857</guid>
            <pubDate>Wed, 28 Oct 2020 14:07:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Overkill WorkBench for Home Office Series Part 5 – Workbench Completed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24918693">thread link</a>) | @gcds
<br/>
October 28, 2020 | https://www.techprowd.com/home-office-project-overkill-workbench-series-part-5-workbench-completed/ | <a href="https://web.archive.org/web/*/https://www.techprowd.com/home-office-project-overkill-workbench-series-part-5-workbench-completed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>After a long break (I couldn't reach my computers from all the mess I had been working on to write some update posts 😅) from part 4, now we continue the adventure with building this overkill workbench.</p><figure><a href="https://www.techprowd.com/home-office-project-overkill-workbench-series-part-4-frame-completed/"><div><p>Home Office Project: Overkill Workbench Series Part 4 Frame Completed</p><p>Continuing from part 3, now it’s time for part 4! Home Office Project: Overkill Workbench Series Part 3 Delivery of Materials anda few buildsToday is finally the day the materials were delivered to my home.Unloading was pretty quick as it was 3 (including me) unloading it nearthestaircases to my…</p><p><img src="https://www.techprowd.com/content/images/2020/09/logo.png"><span>techprowd</span></p></div><p><img src="https://www.techprowd.com/content/images/2020/10/3912BBF5-2021-467E-96BB-D84F6CDBA199_1_105_c.jpeg"></p></a></figure><p><strong>(sorry updates are not sequential as many things were happening at the same time, so I am trying to group them to not have a big mess around)</strong></p><p>After waiting for color MDF panels to be in stock, I finally got them delivered to my place, and I could continue working on this project.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-22.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-22.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-22.png 1000w, https://www.techprowd.com/content/images/2020/10/image-22.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>The 1 x red MDF panel will be used for under shelf face, 1 x black MDF panel for covering sides and other pieces, and 4 x black MDF with 6mm diameter hole 30mm grid for hanging stuff and similar things.</p><p>Testing fit of the panel before cutting to size:</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-23.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-23.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-23.png 1000w, https://www.techprowd.com/content/images/2020/10/image-23.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>Sadly red MDF is not as bright as I was expecting, but it will do:</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-24.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-24.png 600w, https://www.techprowd.com/content/images/2020/10/image-24.png 768w" sizes="(min-width: 720px) 720px"></figure><p>At the same time Panasonic power sockets and wall plates arrived.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-25.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-25.png 600w, https://www.techprowd.com/content/images/2020/10/image-25.png 768w" sizes="(min-width: 720px) 720px"></figure><p>Testing pieces on MDF to see if it looks okay together.</p><figure><div><div><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3546.jpeg" width="960" height="1280" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3546.jpeg 600w, https://www.techprowd.com/content/images/2020/10/IMG_3546.jpeg 960w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3549.jpeg" width="960" height="1280" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3549.jpeg 600w, https://www.techprowd.com/content/images/2020/10/IMG_3549.jpeg 960w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>I will try to use varnish on MDF panels, too; maybe it will bring out contrast in color.</p><p>As it was weekend and I hadn't yet received required tools, I decided it's also time to purchase the wood for the cabinets hanging over the table.</p><p>Visiting the same Super Viva Home, I purchased some 15mm plywood panels and few extra 15mm MDF panels for future projects.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-27.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-27.png 600w, https://www.techprowd.com/content/images/2020/10/image-27.png 768w" sizes="(min-width: 720px) 720px"></figure><h2 id="making-red-mdf-under-shelf-faces">Making red MDF under-shelf faces</h2><p>After receiving tools required for the job, I started cutting the red MDF panels for under-shelf. I am cutting them a bit longer to trim them with the router to the exact height as the heights are not as uniform as I would want it.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-28.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-28.png 600w, https://www.techprowd.com/content/images/2020/10/image-28.png 768w" sizes="(min-width: 720px) 720px"></figure><p>MDF dust is so annoying...</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-29.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-29.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-29.png 1000w, https://www.techprowd.com/content/images/2020/10/image-29.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>After cutting all required pieces it was almost done:</p><figure><div><div><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3581.jpeg" width="1280" height="960" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3581.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/IMG_3581.jpeg 1000w, https://www.techprowd.com/content/images/2020/10/IMG_3581.jpeg 1280w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3582.jpeg" width="1280" height="960" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3582.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/IMG_3582.jpeg 1000w, https://www.techprowd.com/content/images/2020/10/IMG_3582.jpeg 1280w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>Now it's time to get them attached to the framing. For this, I am using M5 size wood nut inserts so I can remove them when needed to access to the "backend".</p><figure><div><div><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3591.jpeg" width="960" height="1280" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3591.jpeg 600w, https://www.techprowd.com/content/images/2020/10/IMG_3591.jpeg 960w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3592.jpeg" width="1280" height="960" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3592.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/IMG_3592.jpeg 1000w, https://www.techprowd.com/content/images/2020/10/IMG_3592.jpeg 1280w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>I had ordered the black bolts, but they there too short, so I had to use silver ones until the black ones arrived. You can see in comparison how black looks much better than silver ones.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-30.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-30.png 600w, https://www.techprowd.com/content/images/2020/10/image-30.png 768w" sizes="(min-width: 720px) 720px"></figure><h2 id="mounting-back-panels">Mounting back panels</h2><p>Now it is time to mount the black/gray grid panels to the back, but I discovered an issue. Notice how the white wood is pretty visible through the holes. I decided to paint with some wood paint/stain so it's not visible.</p><p>A short visit to the local home improvement store and I picked up required stuff.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-31.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-31.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-31.png 1000w, https://www.techprowd.com/content/images/2020/10/image-31.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>After spending a few hours trying to paint all visible wood, it was finally finished:</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-32.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-32.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-32.png 1000w, https://www.techprowd.com/content/images/2020/10/image-32.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>I left all windows opened and sealed the doors for the night. This stuff did not smell pleasant!</p><h2 id="trimming-red-mdf-panels">Trimming red MDF panels</h2><p>The next day I decided to trim red MDF panels to the correct size to install the shelves and get the back panels installed as those stand on the shelftops.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-33.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-33.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-33.png 1000w, https://www.techprowd.com/content/images/2020/10/image-33.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>Sadly Router-kun could not reach the corners.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-34.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-34.png 600w, https://www.techprowd.com/content/images/2020/10/image-34.png 768w" sizes="(min-width: 720px) 720px"></figure><p>After finishing the work with red panels, it was finally time for the back panels.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-35.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-35.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-35.png 1000w, https://www.techprowd.com/content/images/2020/10/image-35.png 1024w" sizes="(min-width: 720px) 720px"></figure><h2 id="back-panel-installation">Back panel installation</h2><p>Now that the back panel installation requirements are finished, it's time to cut to size and install back panels.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-36.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-36.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-36.png 1000w, https://www.techprowd.com/content/images/2020/10/image-36.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>Looks pretty good! (Ignore the shelvetops – I haven't tightened them down)</p><p>You can see a big difference between stained wood and raw one.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-37.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-37.png 600w, https://www.techprowd.com/content/images/2020/10/image-37.png 768w" sizes="(min-width: 720px) 720px"></figure><p>Finishing the work with the left side, I will move to installing the right side. It would be a bit more problematic as it is tall and in the corner.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-38.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-38.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-38.png 1000w, https://www.techprowd.com/content/images/2020/10/image-38.png 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-40.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-40.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-40.png 1000w, https://www.techprowd.com/content/images/2020/10/image-40.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>It already looks pretty good. Reinstalled the monitor mounts, and drilled a holes and routed HDMI cables for the monitors.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-41.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-41.png 600w, https://www.techprowd.com/content/images/2020/10/image-41.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-42.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-42.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-42.png 1000w, https://www.techprowd.com/content/images/2020/10/image-42.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>That was all the work I could finish for that day as I am trying to work on this project on during appropriate hours as I have downstairs neighbors, and I don't want to annoy them too much!</p><p>In the evening, the IKEA drawer units arrived. Sadly in Japan, there is no dark gray version of Alex drawers for some reason. So I went with the closest matching color: dark blue.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-43.png" alt=""></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-44.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-44.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-44.png 1000w, https://www.techprowd.com/content/images/2020/10/image-44.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>The funniest thing is how this drawer unit fits under the table with a few millimeters of space.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-45.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-45.png 600w, https://www.techprowd.com/content/images/2020/10/image-45.png 768w" sizes="(min-width: 720px) 720px"></figure><p>It has enough space to push deep inside and not bother my legs when sitting in front of it.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-46.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-46.png 600w, https://www.techprowd.com/content/images/2020/10/image-46.png 768w" sizes="(min-width: 720px) 720px"></figure><h2 id="working-on-the-tabletop">Working on the tabletop</h2><p>The next day I used Router-kun to round the tabletop edges to look and feel better.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-47.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-47.png 600w, https://www.techprowd.com/content/images/2020/10/image-47.png 768w" sizes="(min-width: 720px) 720px"></figure><p>After finishing work in daytime &nbsp;I wanted to use the evening to do noiseless work, I started applying varnish to the tabletop. I decided to use water-based polyurethane varnish for tabletop and shelf tops.</p><p>Before varnish, it looked like this:</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-48.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-48.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-48.png 1000w, https://www.techprowd.com/content/images/2020/10/image-48.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>After the first layer, it looked like this. Finally, it starts to take shape.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-49.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-49.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-49.png 1000w, https://www.techprowd.com/content/images/2020/10/image-49.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>With extra varnish left after the first layer, I decided to varnish the MDF panels, too.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-50.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-50.png 600w, https://www.techprowd.com/content/images/2020/10/image-50.png 768w" sizes="(min-width: 720px) 720px"></figure><p>Applying the second layer, it started to take even better shape.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-51.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-51.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-51.png 1000w, https://www.techprowd.com/content/images/2020/10/image-51.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>After applying the third layer, it was looking good – can't wait to finish it!</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-52.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-52.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-52.png 1000w, https://www.techprowd.com/content/images/2020/10/image-52.png 1024w" sizes="(min-width: 720px) 720px"></figure><h2 id="working-on-red-mdf-panels">Working on red MDF panels</h2><p>After finishing the routing of the tabletop edge, I went on with making holes for wall sockets. I have tried to make a few templates, but the first tries failed, and only on the 3rd try di I manage to create one.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-53.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-53.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-53.png 1000w, https://www.techprowd.com/content/images/2020/10/image-53.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>Using a template with a custom router bit to cut – it was not perfect hole shape, but it will do as it's not visible. After a few hours, I managed to cut out all 32 of them.</p><figure><div><div><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3647.jpeg" width="1280" height="960" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3647.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/IMG_3647.jpeg 1000w, https://www.techprowd.com/content/images/2020/10/IMG_3647.jpeg 1280w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3646.jpeg" width="1280" height="960" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3646.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/IMG_3646.jpeg 1000w, https://www.techprowd.com/content/images/2020/10/IMG_3646.jpeg 1280w" sizes="(min-width: 720px) 720px"></p></div></div></figure><h2 id="building-cabinets">Building cabinets</h2><p>The next day, the pre-cut plywood panels for the cabinets arrived.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-54.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-54.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-54.png 1000w, https://www.techprowd.com/content/images/2020/10/image-54.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>I spent the whole evening pre-drilling all 400 holes for the shelf mounting pins.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-55.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-55.png 600w, https://www.techprowd.com/content/images/2020/10/image-55.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-56.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-56.png 600w, https://www.techprowd.com/content/images/2020/10/image-56.png 768w" sizes="(min-width: 720px) 720px"></figure><p>For the hole template, I used the same back panel leftovers to cut perfectly spaced holes. </p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-57.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-57.png 600w, https://www.techprowd.com/content/images/2020/10/image-57.png 768w" sizes="(min-width: 720px) 720px"></figure><p>I spent the next day assembling cabinets and mounting them to the wall</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-58.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-58.png 600w, https://www.techprowd.com/content/images/2020/10/image-58.png 768w" sizes="(min-width: 720px) 720px"></figure><p>The design is pretty simple: join panels into a box and use one panel to keep the other panels in place. Using extra-long screws, I don't think this cabinet is going to be falling apart any time soon!</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-59.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-59.png 600w, https://www.techprowd.com/content/images/2020/10/image-59.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-60.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-60.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-60.png 1000w, https://www.techprowd.com/content/images/2020/10/image-60.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>It was pretty easy and quick to build them. As it was my first time building cabinets, I feel it could be even faster if had independent tools for things like pre-drilling hole, countersunk the hole for screw head, and impact driver for driving the screw in.</p><p>Anyway, it was much easier than I anticipated. Now, for mounting, it was a bit difficult as I am a single person and mounting them to the frame was a bit of a challenge for myself. I needed to hold it in place and also screw it into the frame. I used 6x30 wood screws; They won't be falling off the frame any time soon, either!</p><figure><div><div><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3712.jpeg" width="960" height="1280" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3712.jpeg 600w, https://www.techprowd.com/content/images/2020/10/IMG_3712.jpeg 960w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3713.jpeg" width="960" height="1280" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3713.jpeg 600w, https://www.techprowd.com/content/images/2020/10/IMG_3713.jpeg 960w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>Now repeat mounting all the other three and try to keep them aligned.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-61.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-61.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-61.png 1000w, https://www.techprowd.com/content/images/2020/10/image-61.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>I have left some space for the air conditioner.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-62.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-62.png 600w, https://www.techprowd.com/content/images/2020/10/image-62.png 768w" sizes="(min-width: 720px) 720px"></figure><p>Sadly, the cabinets and tabletops are not parallel because of warped wood, but it is only visible if you are looking at it sideways.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-63.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-63.png 600w, https://www.techprowd.com/content/images/2020/10/image-63.png 768w" sizes="(min-width: 720px) 720px"></figure><p>But, it's pretty much satisfactory to me.</p><h2 id="installing-the-front-lip-under-cabinets-and-lights-">Installing the front lip under cabinets and lights.</h2><p>Early in the project, I decided to use the IKEA STRÖMLINJE worktop lights for this project, but I did not want to see them while sitting in front of the table, so I decided to use some of the 15mm MDF I got as a lip.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-64.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-64.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-64.png 1000w, https://www.techprowd.com/content/images/2020/10/image-64.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>For powering these lights, I decided to use the MEAN WELL HLG-40H-24B LED driver power supply instead of IKEA one as it was a lot cheaper and supports dimming using a 0-10VDC signal.</p><p>While making the lip, I decided to cover all front-facing surfaces of the cabinet using the same black MDF panel for a better look.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-65.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-65.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-65.png 1000w, https://www.techprowd.com/content/images/2020/10/image-65.png 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-66.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-66.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-66.png 1000w, https://www.techprowd.com/content/images/2020/10/image-66.png 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-67.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-67.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-67.png 1000w, https://www.techprowd.com/content/images/2020/10/image-67.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>After waiting overnight for wood glue to dry the next day, I trimmed all piece.s</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-72.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-72.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-72.png 1000w, https://www.techprowd.com/content/images/2020/10/image-72.png 1024w" sizes="(min-width: 720px) 720px"></figure><h2 id="installing-end-covers">Installing end covers</h2><p>As woodwork tasks has neared the end, I decided it's time to finish all the ends with covers made from the same black MDF panel</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-78.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-78.png 600w, https://www.techprowd.com/content/images/2020/10/image-78.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-76.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-76.png 600w, https://www.techprowd.com/content/images/2020/10/image-76.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-77.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-77.png 600w, https://www.techprowd.com/content/images/2020/10/image-77.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-75.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-75.png 600w, https://www.techprowd.com/content/images/2020/10/image-75.png 768w" sizes="(min-width: 720px) 720px"></figure><h2 id="installing-cable-channels-ground-bus-bars-and-other-bits-and-pieces">Installing cable channels, ground bus bars and other bits and pieces</h2><figure><img src="https://www.techprowd.com/content/images/2020/10/image-79.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-79.png 600w, https://www.techprowd.com/content/images/2020/10/image-79.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-80.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-80.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-80.png 1000w, https://www.techprowd.com/content/images/2020/10/image-80.png 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-81.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-81.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-81.png 1000w, https://www.techprowd.com/content/images/2020/10/image-81.png 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-82.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-82.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-82.png 1000w, https://www.techprowd.com/content/images/2020/10/image-82.png 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-83.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-83.png 600w, https://www.techprowd.com/content/images/2020/10/image-83.png 768w" sizes="(min-width: 720px) 720px"><figcaption>Grounding wire for all the sockets and other things</figcaption></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-85.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-85.png 600w, https://www.techprowd.com/content/images/2020/10/image-85.png 768w" sizes="(min-width: 720px) 720px"></figure><p>Suppose someone may asks why such big cable trunks/channels. To answer this question I have finished routing all individual power cables for each socket; this is the end place where all automation and electricity stuff will be mounted.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-86.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-86.png 600w, https://www.techprowd.com/content/images/2020/10/image-86.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-87.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-87.png 600w, https://www.techprowd.com/content/images/2020/10/image-87.png 768w" sizes="(min-width: 720px) 720px"></figure><p>Now that all power cables are routed, I could try to wire up some sockets before sitting down and doing all of it.</p><p>I used crimp termination plugs as my cables are multi-stranded, and Panasonic uses push-in contacts for solid copper conductors.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-88.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-88.png 600w, https://www.techprowd.com/content/images/2020/10/image-88.png 768w" sizes="(min-width: 720px) 720px"></figure><p>But with proper tool, those are pretty easy to work with</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-89.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-89.png 600w, https://www.techprowd.com/content/images/2020/10/image-89.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-90.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-90.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-90.png 1000w, https://www.techprowd.com/content/images/2020/10/image-90.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>Right now, I am just using blank plates for top level, as I still haven't started working on making USB3.1 ports, headphones, and other custom plates.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-91.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-91.png 600w, https://www.techprowd.com/content/images/2020/10/image-91.png 768w" sizes="(min-width: 720px) 720px"></figure><h2 id="rgb-all-the-things-">RGB all the things!</h2><figure><img src="https://www.techprowd.com/content/images/2020/10/image-68.png" alt=""></figure><p>How could this project just skip RGB part?! Next to IKEA lights, I also installed strips of WS2815B 12V addressable RGB strips</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-69.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-69.png 600w, https://www.techprowd.com/content/images/2020/10/image-69.png 768w" sizes="(min-width: 720px) 720px"></figure><p>Also in the shelftops which routed out channel for them</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-71.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-71.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-71.png 1000w, https://www.techprowd.com/content/images/2020/10/image-71.png 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-70.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-70.png 600w, https://www.techprowd.com/content/images/2020/10/image-70.png 768w" sizes="(min-width: 720px) 720px"></figure><p>I am using <a href="https://twitter.com/scanlime">@scanlime</a> <a href="https://github.com/scanlime/fadecandy">FadeCandy</a> controller boards for controlling all RGB WS2815B strips; the only negative thing &nbsp;is about this controller is limitation of 8 x 64-pixel channels, so I had to cut and join length of strips on shelftops to achieve 64 pixels per channel</p><p>After spending some time to solder some demo cables, I managed to get all RGB strips working.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-73.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-73.png 600w, https://www.techprowd.com/content/images/2020/10/image-73.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-74.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-74.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-74.png 1000w, https://www.techprowd.com/content/images/2020/10/image-74.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>After finishing most of the woodwork, I finally finalized RGB installation with routing correct length cables, installing extensions, and other things.</p><figure><div><div><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3800.jpeg" width="960" height="1280" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3800.jpeg 600w, https://www.techprowd.com/content/images/2020/10/IMG_3800.jpeg 960w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3794.jpeg" width="960" height="1280" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3794.jpeg 600w, https://www.techprowd.com/content/images/2020/10/IMG_3794.jpeg 960w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3791.jpeg" width="1280" height="960" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3791.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/IMG_3791.jpeg 1000w, https://www.techprowd.com/content/images/2020/10/IMG_3791.jpeg 1280w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3793.jpeg" width="960" height="1280" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3793.jpeg 600w, https://www.techprowd.com/content/images/2020/10/IMG_3793.jpeg 960w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3797.jpeg" width="960" height="1280" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3797.jpeg 600w, https://www.techprowd.com/content/images/2020/10/IMG_3797.jpeg 960w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3798.jpeg" width="960" height="1280" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3798.jpeg 600w, https://www.techprowd.com/content/images/2020/10/IMG_3798.jpeg 960w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/10/IMG_3799.jpeg" width="960" height="1280" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3799.jpeg 600w, https://www.techprowd.com/content/images/2020/10/IMG_3799.jpeg 960w" sizes="(min-width: 720px) 720px"></p></div></div></figure><h2 id="finalization-of-woodworks-for-this-project">Finalization of woodworks for this project</h2><p>Finally, I have reached the first milestone of this project to have completed workbench wood/structure parts. After this, I will be waiting for parts from Aliexpress and other places to arrive to start working on Automation, and other things for this project, so subscribe to get the latest updates regarding this project series.</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-94.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-94.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-94.png 1000w, https://www.techprowd.com/content/images/2020/10/image-94.png 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-95.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-95.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-95.png 1000w, https://www.techprowd.com/content/images/2020/10/image-95.png 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-96.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-96.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-96.png 1000w, https://www.techprowd.com/content/images/2020/10/image-96.png 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/IMG_3810.jpeg" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/IMG_3810.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/IMG_3810.jpeg 1000w, https://www.techprowd.com/content/images/2020/10/IMG_3810.jpeg 1280w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/9928F852-16CE-4C2C-B07E-0B1585560A88_1_105_c.jpeg" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/9928F852-16CE-4C2C-B07E-0B1585560A88_1_105_c.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/9928F852-16CE-4C2C-B07E-0B1585560A88_1_105_c.jpeg 1000w, https://www.techprowd.com/content/images/2020/10/9928F852-16CE-4C2C-B07E-0B1585560A88_1_105_c.jpeg 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/3614746C-5B2D-4BF0-A8AD-6E48877DE004_1_105_c.jpeg" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/3614746C-5B2D-4BF0-A8AD-6E48877DE004_1_105_c.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/3614746C-5B2D-4BF0-A8AD-6E48877DE004_1_105_c.jpeg 1000w, https://www.techprowd.com/content/images/2020/10/3614746C-5B2D-4BF0-A8AD-6E48877DE004_1_105_c.jpeg 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/D9D3E437-3127-45E8-A8A6-514317B9885F_1_105_c.jpeg" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/D9D3E437-3127-45E8-A8A6-514317B9885F_1_105_c.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/D9D3E437-3127-45E8-A8A6-514317B9885F_1_105_c.jpeg 1000w, https://www.techprowd.com/content/images/2020/10/D9D3E437-3127-45E8-A8A6-514317B9885F_1_105_c.jpeg 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/5EC51CA6-3F77-473B-95DF-4343EC4CFE61_1_105_c.jpeg" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/5EC51CA6-3F77-473B-95DF-4343EC4CFE61_1_105_c.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/5EC51CA6-3F77-473B-95DF-4343EC4CFE61_1_105_c.jpeg 1000w, https://www.techprowd.com/content/images/2020/10/5EC51CA6-3F77-473B-95DF-4343EC4CFE61_1_105_c.jpeg 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-97.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-97.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-97.png 1000w, https://www.techprowd.com/content/images/2020/10/image-97.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>Now with RGB strip at 50% white</p><figure><img src="https://www.techprowd.com/content/images/2020/10/image-98.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-98.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-98.png 1000w, https://www.techprowd.com/content/images/2020/10/image-98.png 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/10/image-99.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/10/image-99.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/10/image-99.png 1000w, https://www.techprowd.com/content/images/2020/10/image-99.png 1024w" sizes="(min-width: 720px) 720px"></figure><h2 id="future-plans">Future Plans</h2><p>This is just a first milestone of several milestones I have for this project. Tomorrow unexpectedly, all other missing sockets arrive, so I will wire those in, assembly another IKEA drawer unit, and then wait for other parts like MCB, etc. for automation.</p><p>Don't forget to subscribe to the newsletters down bellow. Every new article …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.techprowd.com/home-office-project-overkill-workbench-series-part-5-workbench-completed/">https://www.techprowd.com/home-office-project-overkill-workbench-series-part-5-workbench-completed/</a></em></p>]]>
            </description>
            <link>https://www.techprowd.com/home-office-project-overkill-workbench-series-part-5-workbench-completed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918693</guid>
            <pubDate>Wed, 28 Oct 2020 13:49:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brier Score: Understanding Model Calibration]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24918570">thread link</a>) | @patrycjaneptune
<br/>
October 28, 2020 | https://neptune.ai/blog/brier-score-and-model-calibration | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/brier-score-and-model-calibration">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p>Do you ever encounter a storm when the probability of rain in your weather app is below 10%? Well, this shows perfectly how your plans can be destroyed with a not <a href="https://stats.stackexchange.com/questions/270508/meaning-of-model-calibration" target="_blank" rel="noreferrer noopener nofollow">well-calibrated model</a> (also known as an ill-calibrated model, or a model with a very high Brier score).</p>



<p>When building a prediction model, you take into account its predictive power by calculating <a href="https://neptune.ai/blog/evaluation-metrics-binary-classification" target="_blank" rel="noreferrer noopener nofollow">different evaluation metrics</a>. Some of them are common, like accuracy and precision. But others, like the Brier score in the weather forecasting model above, are often neglected.</p>



<p>In this tutorial you’ll get a simple, introductory explanation of <strong>Brier Score and calibration – one of the most important concepts used to evaluate prediction performance in statistics.</strong></p>






<h2>What is the Brier Score?</h2>



<p>Brier Score evaluates the accuracy of <a href="https://en.wikipedia.org/wiki/Brier_score" target="_blank" rel="noreferrer noopener nofollow">probabilistic predictions</a>.&nbsp;</p>



<p>Say we have two models that correctly predicted the sunny weather. One with the probability of 0.51 and the other with 0.93. They are both correct and have the same accuracy (assuming 0.5 threshold) but the second model feels better right? That is where Brier score comes in.</p>



<p>It is particularly useful when we are working with variables that can only take a finite number of values (we can call them categories or labels too).&nbsp;</p>



<p>For example, level of emergency (which takes four values: green, yellow, orange, and red), or whether tomorrow will be a rainy, cloudy or sunny day, or whether a threshold will be exceeded.</p>



<p><strong>The Brier Score is more like a cost function.</strong> A lower value implies accurate predictions and vice versa. The primary goal of dealing with this concept is to decrease it.</p>



<p>The mathematical formulation of the Brier Score depends on the type of predicted variable. If we are developing a binary prediction, the score is given by:</p>



<div><figure><img loading="lazy" src="https://lh6.googleusercontent.com/Q4p2F5bge5_hnyvs0JG_YUp7392F2FgSdWTYsI51aRrTbYIuqAV33KKzmEka4tU8pK0tQgLpVzAkVNNcS4Y-XWVdiOp2Z_lppmv9Po3ZuWHPMfaIv-U7QkB58ND1NGOt8E8X2AN6" alt="equation" width="238" height="73"></figure></div>



<p>Where p is the prediction probability of occurrence of the event, and the term oi is equal to 1 if the event occurred and 0 if not.</p>



<div>
<div>
<figure><img loading="lazy" width="1024" height="768" src="https://i2.wp.com/neptune.ai/wp-content/uploads/sun.jpg?resize=1024%2C768&amp;ssl=1" alt="sun" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/sun.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i2.wp.com/neptune.ai/wp-content/uploads/sun.jpg?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/neptune.ai/wp-content/uploads/sun.jpg?resize=768%2C576&amp;ssl=1 768w, https://i2.wp.com/neptune.ai/wp-content/uploads/sun.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>
</div>



<div>
<p>Let’s take a very quick example to assimilate this concept. Let’s consider the event <strong>A=”Tomorrow is a sunny day”</strong>.&nbsp;</p>



<p>If you predict that the event A will occur with a probability of 100%, and the event occurs (the next is sunny which means o=1), the Brier score is equal to:</p>



<div><figure><img loading="lazy" src="https://lh6.googleusercontent.com/ac266s-ucUPAcK6S2azMNSR6Gi7uvRShCgyZ3ZAjjXtcucryr5iZyiWFXUO85uHYbB_MuBN2NAvsgcN3QhDVO3-4Grm9p9_E5ro7bhbSAip9z4QOTWT-L-98oLhcdRQAGL-YyGJ7" alt="(1-1)^2=0" width="142" height="33"></figure></div>
</div>
</div>



<p>This is the lowest value possible. In other words: the best case we can achieve.</p>



<p>If we predicted the same event with the same probability, but the event doesn’t occur, the Brier score in this case is:</p>



<div><figure><img loading="lazy" src="https://lh5.googleusercontent.com/nEZ-Uzx_T2Tf-ugHrqGouKkodSNQba7B1_Nd9W39TshxDdGJ6P8pp_2k2OfH0pVJpI7wcjZ_uiaAnN33qArqYNxMfFus0HwSItr4iAwZyKAD8jNzyLLppGlW8f_kvjxG-pqGoxJy" alt="equation" width="142" height="33"></figure></div>



<p>Say you predicted that the event A will occur with another probability, let’s say 60%. In case the event doesn’t occur in reality, the Brier Score will be:</p>



<div><figure><img loading="lazy" src="https://lh3.googleusercontent.com/JPUF_ydWbPK01Rp4Ja-uHZeJ9TwQ3E6eo7k89N1ebVGHu0ayxtfifuuYSt2xAudQ_KavEfWzKBjoVAMYEKNDnolZkDN-NyCwomNrcltQognR3R-ZQf18_oXlFL7XRUXQ-C48IwfC" alt="equation" width="198" height="33"></figure></div>



<p>As you may have noticed, the Brier score is a distance in the probability domain. Which means: <strong>the lower the value of this score, the better the prediction.</strong>&nbsp;</p>



<p>A perfect prediction will get a score of 0. The worst score is 1. It’s a synthetic criterion that provides combined information on the accuracy, robustness, and interpretability of the prediction model.</p>



<figure><img loading="lazy" src="https://i1.wp.com/neptune.ai/wp-content/uploads/Brier-score.jpg?resize=768%2C431&amp;ssl=1" alt="brier score prediction" width="768" height="431" srcset="https://i1.wp.com/neptune.ai/wp-content/uploads/Brier-score.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/neptune.ai/wp-content/uploads/Brier-score.jpg?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/neptune.ai/wp-content/uploads/Brier-score.jpg?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/neptune.ai/wp-content/uploads/Brier-score.jpg?w=1366&amp;ssl=1 1366w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1"></figure>



<p><strong>Dotted lines represent the worst cases</strong> (if the event occurs, the circle is equal to 1).</p>






<h2>What is probability calibration?</h2>



<p>Probability calibration is the post-processing of a model to improve its <a href="https://www.webpages.uidaho.edu/niatt_labmanual/Chapters/traveldemandforecasting/professionalpractice/ModelCalibrationAndValidation.htm" target="_blank" rel="noreferrer noopener nofollow">probability estimate</a>. It helps us compare two models that have the same accuracy or other standard evaluation metrics.</p>



<p><strong>We say that a model is well calibrated when a prediction of a class with confidence p is correct 100p % of the time. </strong>To illustrate this calibration effect, let’s consider that you have a model that predicts cancer with a score of 70% for each patient out of 100. If your model is well calibrated, we would have 70 patients with cancer, if it is ill-calibrated, we will have more (or less).<strong> </strong>Therefore, the difference between these two models:&nbsp;</p>



<ul><li>A model has an accuracy of 70% with 0.7 confidence in each prediction = well calibrated.</li><li>A model who has an accuracy of 70% with 0.9 confidence in each prediction = ill-calibrated.</li></ul>



<p>For a perfect calibration, the relationship between the predicted probability and the fraction of positives follows the given:</p>



<div><figure><img loading="lazy" width="386" height="278" src="https://i0.wp.com/neptune.ai/wp-content/uploads/perfect-calibration.png?resize=386%2C278&amp;ssl=1" alt="perfect calibration" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/perfect-calibration.png?w=386&amp;ssl=1 386w, https://i0.wp.com/neptune.ai/wp-content/uploads/perfect-calibration.png?resize=300%2C216&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/perfect-calibration.png?resize=370%2C265&amp;ssl=1 370w" sizes="(max-width: 386px) 100vw, 386px" data-recalc-dims="1"></figure></div>



<p>The expression of this relationship is given by:</p>



<div><figure><img loading="lazy" src="https://lh6.googleusercontent.com/Q2F0Woa7z9QD1HHWY6UCfCcn98CrT-weUWQiebvxHjGle3D1dfoZQtLnVW1KznaLUAN2zhuwLfNfoW3zzZfYbG-tcuCoy9qwncDJ3mlZ0vJiAkmhjjLz4vceil-01z-yYPefK9wZ" alt="equation" width="275" height="36"></figure></div>



<p>The figure above represents the <strong>reliability diagram of a model</strong>. We can plot it using scikit-learn as below:</p>



<pre><span>import</span> sklearn 
<span>from</span> sklearn.calibration <span>import</span> calibration_curve
<span>import</span> matplotlib.lines <span>as</span> line
<span>import</span> matplotlib.pyplot <span>as</span> plt 

x, y=calibration_curve(y_true, y_prob)

plt.plot(x,y)
ref = line.Line2D([<span>0</span>, <span>1</span>], [<span>0</span>, <span>1</span>], color=<span>'black'</span>)
transform = ax.transAxes
line.set_transform(transform)
ax.add_line(line)
fig.suptitle(<span>'Calibration – Neptune.ai'</span>)
ax.set_xlabel(<span>'Predicted probability'</span>)
ax.set_ylabel(<span>'Fraction of positive'</span>)
plt.legend()
plt.show()
</pre>



<p><strong>Plotting the reliability curve for multiple models allows us to choose the best model not only based on its accuracy, but on its calibration too</strong>.&nbsp;</p>



<p>In the figure below, we can eliminate the SVC (0.163) model because it is far from being well calibrated.</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/neptune.ai/wp-content/uploads/calibration-plots.png?resize=768%2C494&amp;ssl=1" alt="calibration plots" width="768" height="494" srcset="https://i1.wp.com/neptune.ai/wp-content/uploads/calibration-plots.png?resize=1024%2C659&amp;ssl=1 1024w, https://i1.wp.com/neptune.ai/wp-content/uploads/calibration-plots.png?resize=300%2C193&amp;ssl=1 300w, https://i1.wp.com/neptune.ai/wp-content/uploads/calibration-plots.png?resize=768%2C494&amp;ssl=1 768w, https://i1.wp.com/neptune.ai/wp-content/uploads/calibration-plots.png?w=1212&amp;ssl=1 1212w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1"></figure></div>



<p><em>Figure taken from<a href="https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html#sphx-glr-auto-examples-calibration-plot-calibration-curve-py" target="_blank" rel="noreferrer noopener nofollow"> sklearn documentation</a> </em></p>



<p>If we want a numeric value to check the calibration of our models, we can use the calibration error given theoretically by:</p>



<div><figure><img loading="lazy" src="https://lh5.googleusercontent.com/4l2TYtb5DJJh03TIJrENrxsyx2OJr58kZtQJ9FWa-kDDXDgWZfSYCIHlDaPqNpmliLgicPwZ6lwqDwAtJBxmKRfAdE3oyP_UBEkFyMBIvq5HtY9y9FXCD0pkaDyqM9JkFrxZOT-J" alt="equation" width="307" height="50"></figure></div>






<h2>When should you use the Brier score?</h2>



<p>Evaluating the performance of a machine learning model is important, but it’s not enough to evaluate the <a href="https://timvangelder.com/2015/05/18/brier-score-composition-a-mini-tutorial/" target="_blank" rel="noreferrer noopener nofollow">real-world application</a> predictions.&nbsp;</p>



<p>We often worry about:</p>



<ul><li>the model’s confidence in its predictions,&nbsp;</li><li>its error distribution,&nbsp;</li><li>and how probability estimates are made.&nbsp;</li></ul>



<p>In such cases, we need to use other performance factors. Brier score is an example.</p>



<p>This type of performance score is <strong>specifically used in high-risk applications</strong>. This score allows us to not treat the model results as real probabilities, but instead go beyond the raw results and check the model calibration, which is important for avoiding bad decision making or false interpretation.&nbsp;</p>



<h3><strong>Example of needing well-calibrated probabilities/model calibration</strong></h3>



<p>Let’s consider that you want to build a model that shows news pages to users by the chance of clicking on them. If the chance of the user clicking on a suggested item is high, the item is shown on the main page. Else, we show another item with a higher chance.&nbsp;</p>



<p>In this kind of problem, we don’t really care about how much the exact chance of clicking is, but only which item has the highest chance between all of the existing items. <strong>The model calibration is not really crucial here</strong>. What matters is which one of them has the highest probability (chance) of being clicked.</p>



<p>On the other hand, consider a problem in which we build a model that predicts the probability of contracting a specific disease based on the output of some analysis. The exact value of the probability is crucial here because it affects the decision of the doctor and the health of the patient.&nbsp;</p>



<p>Generally, calibration is used to improve a model when the results show that it has mistakes with high probabilities (or prediction score when the model doesn’t output the probability estimate e.g. random forest).</p>



<p>Of course, you can also look at other metrics that take prediction scores as input, like <a href="https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc" target="_blank" rel="noreferrer noopener nofollow">ROC AUC score</a>, but they usually don’t focus on correctly calibrated probabilities. For example, ROC AUC focuses on ranking predictions.&nbsp;</p>



<p>Ok, now we can tell when the model is not well calibrated, but what can we do about it? How can we calibrate it?</p>






<h2>Probability calibration methods</h2>



<p>People use a lot of <a href="https://medium.com/@kingsubham27/calibration-techniques-and-its-importance-in-machine-learning-71bec997b661" target="_blank" rel="noreferrer noopener nofollow">calibration methods</a>. We will focus on the two most popular approaches:&nbsp;</p>



<h3><strong>Platt Scaling</strong></h3>



<p>Platt Scaling is often used to calibrate a model that we have already built. The principle of this method is based on the transformation of the outputs of our classification model into probability distribution.&nbsp;</p>



<p><strong>Our model will not only give a categorical result (label or class), but also a degree of certainty about the result itself</strong>.&nbsp;</p>



<p>Instead of returning the class 1 as a result, it will return the probability of the correctness of this class prediction. Unfortunately, some classification models (like SVM) do not return probability values, or give poor probability estimates.&nbsp;</p>



<p>That’s why we use specific transformations to calibrate our model and convert the results into probability.</p>



<figure><img loading="lazy" width="1024" height="321" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Brier-score-2-1.jpg?resize=1024%2C321&amp;ssl=1" alt="plat scalling" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/Brier-score-2-1.jpg?resize=1024%2C321&amp;ssl=1 1024w, https://i0.wp.com/neptune.ai/wp-content/uploads/Brier-score-2-1.jpg?resize=300%2C94&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/Brier-score-2-1.jpg?resize=768%2C241&amp;ssl=1 768w, https://i0.wp.com/neptune.ai/wp-content/uploads/Brier-score-2-1.jpg?w=1366&amp;ssl=1 1366w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>



<p><strong>To use the Platt scaling method</strong>, we train our model normally, and then train the parameters of an additional sigmoid function to map the model outputs into probabilities.&nbsp;</p>



<p>You can do it using Logistic Regression fitted on the output of the model.&nbsp;</p>



<pre><span>from</span> sklearn.linear_model <span>import</span> LinearRegression

model=LinearRegression()
model.fit(p_out, y_out)
calib_p=model.predict(p_test)[:,<span>1</span>]
</pre>



<h3><strong>Isotonic Regression</strong></h3>



<p>Isotonic Regression does the same thing as Platt Scaling – they both transform model output into probability, and therefore calibrate it.&nbsp;</p>



<p>What’s the difference?</p>



<p><strong>Platt Scaling uses a sigmoid shape to calibrate the model</strong>, which implies a sigmoid-shaped distortion in our probability distribution.&nbsp;</p>



<p><strong>Isotonic Regression</strong> is a more powerful calibration method that can correct any monotonic distortion. It <strong>projects a non parametric function into a set of increasing functions</strong> (monotonic).&nbsp;</p>



<p><strong>It is not recommended to use the isotonic regression if you have a small dataset,</strong> because it can easily&nbsp;overfit.</p>



<p>To implement this approach, we will again use sklearn (we assume you have already built and trained your “uncalibrated model”):</p>



<pre><span>from</span> sklearn.linear_model <span>import</span> IsotonicRegression

model=IsotonicRegression()
model.fit(p_out, y_out)
calib_p=model.transform(p_test)
</pre>






<h2>Using model calibration on a real example</h2>



<p>Let’s get some practice!</p>



<p>In order to keep it unique, we will generate two classes using <code>make_classification</code> from sklearn.&nbsp;</p>



<p>After that, we will train and fit an SVM classifier on the dataset.</p>



<pre><span>from</span> sklearn.datasets <span>import</span> make_classification
<span>from</span> sklearn.model_selection <span>import</span> train_test_split
<span>from</span> sklearn.svm <span>import</span> SVC

X, y = make_classification(n_samples=<span>2500</span>, n_classes=<span>2</span>)
X_train, X_test, …</pre></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/brier-score-and-model-calibration">https://neptune.ai/blog/brier-score-and-model-calibration</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/brier-score-and-model-calibration</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918570</guid>
            <pubDate>Wed, 28 Oct 2020 13:36:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Law of Demeter: Always Encapsulate]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24918455">thread link</a>) | @camnora
<br/>
October 28, 2020 | https://www.jakerobers.com/law-of-demeter-always-encapsulate | <a href="https://web.archive.org/web/*/https://www.jakerobers.com/law-of-demeter-always-encapsulate">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Exposing internal data structures are bound to lead to a messy situation.
When a method caller knows too much about an underlying system, there is a nasty kind of coupling.
This dependency issue is also known as the <a href="https://en.wikipedia.org/wiki/Law_of_Demeter">Law of Demeter</a>.
Some people call it â€œtoo many dots syndromeâ€� because it leads to <code>code.accessing.attributes.very.deeply</code>.
The whole point is that the caller should not have knowledge of the deep attribute.</p>

<p>I recently worked on a project that dealt with parsing numbers.
Lots of projects do this, right?
Another common use-case is to provide some error messages based on the type of incorrect input.
Unfortunately, as the business requirements grew, our code lagged behind.
This technical debt slowed future velocity and introduced some errors.
Eww.</p>

<p>The data structure began something like this:</p>



<p>The above structure represents what a user might have in their shopping cart for checkout.
It does feel like <code>quantity</code> isnâ€™t actually part of a product and that it should be normalized somehow.
Regardless, this was the structure that the team came to a consensus on.</p>

<p>As it turns out, the quantity attribute needs to be a little more complicated.
You see, a user might want to input a quantity in a text box.
So at this point you might be saying: â€œWell just make quantity a stringâ€�.
Sounds good, right?
Letâ€™s go ahead and roll with it.</p>



<p>Now the user is able to edit the quantity.
However, changing the type from a number to a string leads to an issue.
Now we cannot calculate the total as easily anymore.
So at this point you might be saying: â€œJust parse the numberâ€�.
<em>Hmmâ€¦ thereâ€™s a little voice in the back of my head warning me</em>.
Eh, whatever.
Letâ€™s go ahead and throw this change in too.</p>



<p>Youâ€™ll also notice that we are adding some scope in.
We are fetching the total by parsing the quantity and multiplying by the price.
I think now the little voice is speaking up:</p>
<blockquote>
  <p>â€œShould it be the job of the caller to calculate the price?â€�</p>
</blockquote>

<p>If two product attributes are being exclusively accessed, maybe we should have a separate module to encapsulate this logic.
The module could be named <code>Product</code>, and it could hold a function called <code>getTotal()</code>.</p>

<p>In the favor of moving fast, we ended up <em>not</em> creating a module dedicated to product operations.
I would say that this was the first substantial warning sign that went unnoticed.</p>

<p>Alright, so now what happens when the user inputs garbage like â€œasdfâ€� into the text box?</p>



<p>Itâ€™s not the best UX to be displaying NaN as a product total.
Itâ€™s probably a good call to add a little more safety around quantity.
This will allow us to report to the user that theyâ€™ve made a mistake.</p>



<p>The <code>const total</code> assignment is getting larger.
This doesnâ€™t look too good.</p>

<p>At this point, the total calculation was abstracted away into a function, but it still was not apart of a module specific to a product.
This lead to several places in the codebase with similar quantity parsing.
As a result, we still <em>did not have a single source of truth</em>.</p>

<p>In the meantime, thereâ€™s an edge case that we didnâ€™t cover yet.
Can you find it?
Itâ€™s not quite possible to purchase negative vacuum cleaners.
Additionally, there are only so many vacuum cleaners in stock.
Therefore, there needs to be some kind of minimum/maximum validation.
As a result, we added a validation object to quantity.</p>



<p>I am omitting the actual validation logic, but we can pretend that the <code>errMessage</code> will be populated with the expected value.
As we can see, our data structure is nowhere near as simple as it once was.</p>

<p>This is where things started breaking.
The attribute <code>product.quantity.isValid</code> has now moved to <code>product.quantity.validation.isValid</code>.
I believe we had about 10-15 callers trusting the integrity of the product data structure.
This is where the lesson is learned.</p>

<p><strong>Never trust the integrity of a data structure.</strong></p>

<p>This Law of Demeter violation could be pretty easily patched with a module dedicated to the product.
By having a module along side the complex data structure, we can derive a productâ€™s attributes without requiring knowledge of the underlying implementation.</p>

<p>Furthermore, by following the Single Responsibility Principle, a product can be further split into a couple of concepts:</p>
<ul>
  <li>Product (as before)</li>
  <li>Quantity</li>
  <li>Validator</li>
</ul>

<p>The first step would be to define some interfaces representing these concepts.
The interface ought to be unchanging â€“ serving as a contract.
This will ensure stability for the 10-15 areas which utilize this code.</p>



<p>Take a peek and notice <code>Quantity.isValid()</code>.
From an implementation standpoint, Quantity would just defer to <code>validation.isValid()</code>.
In the case that business requirements become more difficult, additional logic can be added as necessary.</p>

<p>As a result, the 10-15 function calls can let out a sigh of relief.
They no longer need to know how exactly a quantity is being validated.
All the need to know is <code>product.getQuantity().isValid()</code>.
Easy right?</p>

<p>One other thing worth noting, we now have a <code>getTotal()</code> on Product!
Now there is a single source of truth for computing a price. :D</p>

<p>Why is encapsulation so powerful?
It is adaptive to change.</p>
<ul>
  <li>The Product might one day substitute the <code>name</code> attribute for an <code>InternationalizedString</code> object. This would add support for different languages.</li>
  <li>The Product might one day change <code>price</code> to a <code>CurrencyAmount</code>. This would add support for formatting price strings in different currencies.</li>
</ul>

<p>All the while, each of the 10-15 callers would be none-the-wiser on how these attributes are computed!
The interface remains a steadfast contract!</p>

<p>So next time you see <code>code.accessing.attributes.very.deeply</code>, letâ€™s stop for a moment to refactor.
Encapsulation is a quick win.
Yes it might be a little more verbose, but you will thank yourself down the road.</p>


      </div></div>]]>
            </description>
            <link>https://www.jakerobers.com/law-of-demeter-always-encapsulate</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918455</guid>
            <pubDate>Wed, 28 Oct 2020 13:26:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn programming: tips to improve your journey]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24918415">thread link</a>) | @pixo
<br/>
October 28, 2020 | https://pixo.sh/learn-programming-3-tips-to-improve-your-journey/ | <a href="https://web.archive.org/web/*/https://pixo.sh/learn-programming-3-tips-to-improve-your-journey/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure><img loading="lazy" width="640" height="428" src="https://pixo.sh/wp-content/uploads/frustration.jpg" alt="Guy wanting to kill herself while he learn programming" srcset="https://pixo.sh/wp-content/uploads/frustration.jpg 640w, https://pixo.sh/wp-content/uploads/frustration-300x201.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"><figcaption> <a aria-label="Picture by Tim Gouw on Unsplash (opens in a new tab)" href="http://Picture by Tim Gouw on Unsplash" target="_blank" rel="noreferrer noopener">Picture by Tim Gouw on Unsplash</a></figcaption></figure>
<p>At first, learn programming can be scary as fuck, you can think about maths and complex operations, but actually, programming is as simple as talking with a computer, is like learning English or French, but you use programming languages to communicate with the machines.</p>
<p>When you start learning programming, you will feel overwhelmed by the number of resources you will find. I won’t cover where to find resources in this post (TODO: write a post about that), but you can find some interesting things in <a href="https://pixo.sh/starting-in-programming-as-a-self-taught-developer/" target="_blank" aria-label="this article (opens in a new tab)" rel="noreferrer noopener">this article</a>, instead, I will share some tips I used (and I still use), and how they helped me to improve my learning curve</p>

<h2>Tip 1: Consistency is key</h2>
<p>I’m a genious right? nobody though about this. Actually this is very important, and is the base of every habit you will try to build by yourself</p>
<p>When you learn something new, your brain will be trained based on two things: frequency and recency</p>
<p>Consistency here means that you should try to learn on a regular basis, try to stablish a time during your day where you can stick your ass in a chair with a relaxing mood and without being disturbed.</p>

<h2>Tip 2: Write a glossary</h2>
<p>You will find A LOT of things that you don’t understand, write them in a glossary and explain them in a way you can understand, this is for you, use whatever technique you want to explain the concepts, frogs? frogs then, amount of apples in a basked? amount of apples in a basket.</p>
<p>When I learn new things I use this technique: Scan – Learn – Read</p>
<ol><li>I scan the information and identify concepts that I don’t understand, I write them in a simple .txt file in my editor</li><li>I learn every concept, I tend to use practical examples, they allow me to assimilate knowledge easily</li><li>Now I can understand everything I read, so I can read everything in a fluent way without stopping because I don’t understand something</li></ol>
<h2>Tip 3: Learn to deal with the frustration</h2>
<p>Frustration will come, and that’s something every one of us should learn to deal with.</p>
<p>Sometimes you will feel frustrated because you don’t understand <a aria-label="what's a thread (opens in a new tab)" href="https://en.wikipedia.org/wiki/Thread_(computing)" target="_blank" rel="noreferrer noopener">what’s a thread</a> (this took me some time to understand), or a determinated concept, but you know what, THAT’S TOTALLY OK, you don’t need to understand everything at first. It can demotivate you, make you want to give up, but the truth is that is only a stone in your path.</p>
<p>People has several ways to deal with frustration, but my main advice is to step away from your source of frustration for a while, and try to think in other things, when you arrive to the problem next time, you will see it with other eyes</p>
<p>What to do vs what not to do when you are frustrated while you are learning programming:</p>
<h3>DON’T</h3>
<ul><li>Don’t keep trying to solve the problem, it will frustrate you even more</li><li>Don’t try to learn other programming things immediately, you will keep thinking about that thing that is frustrating you</li><li>Don’t rush things, even if you solve this problem, you will face more in the future, improve the way you deal with them</li></ul>
<h3>DO</h3>
<ul><li>Do things not related to programming, cooking, videogames, do some exercises, for example, I like to watch youtube videos about restorations, I recommend you <a aria-label="this channel (opens in a new tab)" href="https://www.youtube.com/channel/UCsCCifMby57qV_UmrYGladQ" target="_blank" rel="noreferrer noopener">this channel</a> if you want to try, they are really satisfying and relaxing</li><li>Ask for help, there are a lot of people on the internet who probably stepped into the same problem before and are more than happy to help you, but remember, their time is valuable, be polite and respectful.</li></ul>

<p>I hope this post helps people in their programming journey, is directly extracted from my professional journey and these are some of the things that worked for me</p>
<p><span>Pixo</span>
</p></div></div>]]>
            </description>
            <link>https://pixo.sh/learn-programming-3-tips-to-improve-your-journey/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918415</guid>
            <pubDate>Wed, 28 Oct 2020 13:23:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Fast HTTP Parser [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24918354">thread link</a>) | @todsacerdoti
<br/>
October 28, 2020 | https://httpwork.shop/workshop2015/presentations/oku-picohttpparser.pdf | <a href="https://web.archive.org/web/*/https://httpwork.shop/workshop2015/presentations/oku-picohttpparser.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://httpwork.shop/workshop2015/presentations/oku-picohttpparser.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918354</guid>
            <pubDate>Wed, 28 Oct 2020 13:17:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The On-Demand Communication Fallacy]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24918319">thread link</a>) | @ahmed_sulajman
<br/>
October 28, 2020 | https://curvedlayer.com/2020/10/20/internal-communication.html | <a href="https://web.archive.org/web/*/https://curvedlayer.com/2020/10/20/internal-communication.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Well established communication is the most critical factor for the team to work. Without sharing information, we can’t get anything done.</p>

<p>Poorly designed communication brings more harm than any other inefficient process. Let’s take Slack as an example. Slack made it effortless to ask anyone in the team at your convenience. You don’t know the date of the next release? You’re one question away from knowing it.</p>

<p>Although this is a powerful concept, there are numerous downsides to it. Instead of surfacing relevant information, we “actively query” knowledge from humans on-demand.</p>

<h3 id="problems-with-on-demand-communication">Problems with on-demand communication</h3>
<p>Active Information Seeking is commonly used in social media. With algorithms forming the feed, new and engaging content is always there for you. No matter when you open the app.</p>

<p>Real-time chat apps are using a similar model. Except in the team environment, you don’t need “engaging” content. All you need is painless access to your colleagues.</p>

<h4 id="1--remote-teams">#1 – Remote Teams</h4>
<p>Having the team spread around the world immediately breaks an on-demand information querying model. You can’t rely on people being available whenever you are. You no longer have the luxury to ask people anytime.</p>

<p>A lot of US companies embraced Remote work but only within the US. <span>Limiting communication to a time zone doesn’t solve the fundamental problem. It just removes some symptoms.</span></p>

<p>In the remote environment, communication flow should not depend on individuals. It decreases the overall resilience of the team and slows everyone down.</p>

<h4 id="2--idle-time">#2 – Idle Time</h4>
<p>The time you spend asking people is the time that could be invested better. The time you wait for their response is even more precious. If you value time and speed, on-demand communication should not even be the option.</p>

<p>I’m not even talking about the effects of this model on other people in the team. Every message (information query) sent could break someone else’s flow. And coming back to the flow state would require additional effort + time.</p>

<h4 id="3--pressure--anxiety">#3 – Pressure &amp; Anxiety</h4>
<p>Heavy reliance on real-time communication brings additional emotional pressure. It is especially true for remote teams. There’s no way to know what the person on the other end feels. What might seem like a “friendly question” could be a distraction for others.</p>

<h3 id="passive-consumption--active-seeking">Passive Consumption &gt; Active Seeking</h3>
<p>The opposite of active on-demand communication is passive information consumption. With heavy reliance on systems, passive consumption guarantees relevant information is distributed to the right people at the right time. Setting up passive consumption for a team requires you to look at overall operations on the meta-level. Define who needs what and when.</p>

<p>The marketing team might need to know about the new feature release at least three weeks in advance. Or support engineers might need to know about bug fix deployment right away.</p>

<p>This way, you can set up processes to let relevant information come to people. Instead of people searching for relevant information themselves.</p>

<p>There are a few tools based on this model. For example, <a href="https://mailbrew.com/">Mailbrew</a> and <a href="http://mailmanhq.com/">Mailman</a> allow choosing the terms for receiving relevant information. No matter when this information became available.</p>

<h3 id="fundamentals-of-information-logistics">Fundamentals of Information Logistics</h3>
<p>The idea of passive information consumption is based on information distribution rules. There are five core principles for information logistics. Each piece of circulating information needs to be examined against them.</p>

<p>It’s important to mention these concepts below aren’t isolated from each other. That means each of them defines the others.</p>

<h4 id="what-kind-of-information">What kind of Information?</h4>
<p>First, it’s important to define the actual knowledge you want to distribute. It can be the date of the upcoming release or feedback from customers, bug reports, etc. Not everything has to be delivered passively.</p>

<h4 id="who-needs-the-information">Who needs the Information?</h4>
<p>When the type of information is defined, it’s time to understand who needs to get it. How to select those people? A good approximation would be answering those questions:</p>
<ul>
  <li>How motivated are they to get the information?</li>
  <li>How much their duty depends on the information?</li>
  <li>What difference would it make if they won’t get the information?</li>
</ul>

<p>For passive consumption to work, you have to clearly define recipients. But it’s also important not to make the information fully exclusive. There might be other motivated people in the team that you didn’t include.</p>

<h4 id="when-information-is-needed">When Information is needed?</h4>
<p>You have “what” and “who” the next piece is “when”. Different kinds of information should be delivered at different times, depending on the recipient. For example, deploy of the critical bug fix could be delivered instantly. While information about upcoming releases can be delivered in weekly batches.</p>

<p>Determining the right time ensures that the recipient will consume the information. One of the reasons on-demand communication doesn’t work is because the time when the question is asked isn’t comfortable for the person answering.</p>

<h4 id="whats-the-right-form-of-information">What’s the right form of Information?</h4>
<p>The form in which you deliver information plays an important role too. Some people prefer information presented visually, while others like long text messages. The same information can be presented as a presentation, visual diagram, text message, charts, etc. It’s another step to ensure the content you share is consumed.</p>

<p>Because sending the long document hoping people read it doesn’t guaranty anything. You can have all the information in the world in one Google Doc, but it would be impossible to read.</p>

<h4 id="what-delivery-channel-to-use">What delivery channel to use?</h4>
<p>Just like the form of information ensures readability, the channel you use to deliver knowledge ensures receivability. Some people prefer Slack messages, emails, or even Issues on GitHub as information delivery channels. It’s up to the recipient to determine which channel would work best for them.</p>

<h3 id="how-to-setup-passive-consumption">How to setup Passive Consumption?</h3>
<p>You can automate pretty much everything with tools like <a href="https://zapier.com/">Zapier</a> and recently launched <a href="https://www.ahoyteam.com/">AhoyTeam</a>. Including information distribution at the right time and through comfortable channels.</p>

<p>Actual technical implementation depends a lot on the tools your team uses. For example, do you host your code on GitHub, Bitbucket, or GitLab? Are you using Slack, Twist, or Microsoft Teams? What do you use for Task Management?</p>

<h3 id="conclusions">Conclusions</h3>
<p>Passive information consumption has many upsides compared to on-demand communication. If you noticed, with the on-demand communication model, there is little or no consideration of other people’s preferences. While in passive consumption, other people’s preference is the only thing that makes the system work.</p>

<p>It takes time to set up, analyze the information flow, define interested people, etc. But the gain is a calmer, more efficient workplace where people do not bother each other for no reason.</p>

</div><p>If you enjoyed the article, have some thoughts or things you disagree with – I'd love to hear from you. Please feel free to share the article or <a href="https://twitter.com/ahmed_sulajman" target="_blank">DM me on Twitter</a> to start a discussion.</p></div>]]>
            </description>
            <link>https://curvedlayer.com/2020/10/20/internal-communication.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918319</guid>
            <pubDate>Wed, 28 Oct 2020 13:13:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's OKAY to not know everything]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24918302">thread link</a>) | @phongduong
<br/>
October 28, 2020 | https://phongduong.dev/blog/it-s-okay-to-not-know-everything/ | <a href="https://web.archive.org/web/*/https://phongduong.dev/blog/it-s-okay-to-not-know-everything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>There are many fields in programming. Each field contains many topics. We can't learn and know all of them. </p>
<p>As a developer, I want to learn new frameworks and libraries. But there are many frameworks and libraries created every day. Learning all of them is impossible.</p>
<p>When I started learning web development, I wanted to learn all tools that I was suggested, from programming languages to libraries. Because I thought I would become a professional developer. This made me feel nervous because I can't keep up with the releasing pace. </p>
<p>After I joined a tech company as an intern, I was assigned to a PHP project. Although I worked with PHP, I also wanted to learn other programming languages and tools my company was using. I thought I could be fired if I couldn't use them. </p>
<p>Fortunately, I got the developer job and continued working on this project for almost 1 year. I was also assigned to some PHP projects. Some of them had been written 3 - 4 years ago. I only maintained and updated some minor features. It made me realize that although the technology changed rapidly, the projects did not. Companies didn't want to upgrade to the latest versions of technologies. If the project was working well, there is no reason to change.</p>
<p>At that time, I also knew about Node.js. It was really interesting. You can write Javascript on both front-end and back-end. I decided I would stick with it and be a full-stack Javascript developer. Because I was tired and lazy. I was tired because I try to learn so many things but not use them much. I was lazy because the time was not enough for me. So I wanted to focus on only one thing. This was better.</p>
<p>Now I don't rush to learn new technologies as I did. I am not afraid of being obsolete. I learn new technologies due to being curious. If I want to create something, I will learn a library. I only learn the fundamental and non-technical topics. I love it.</p>
<p>If you just start learning web development or being a professional developer, you don't need to learn all of the latest technologies. Just learn the fundamentals and master them. You should also learn soft-skill. It is important. Although technologies change every day, companies don't change that much. I hear that some projects were written over the decades but still using old technologies.</p>
<p>You don't become a professional developer if you learn all technologies. You also don't become obsolete if you don't learn new technologies. Pick something you want to learn and stick with it. As long as you know the fundamentals, there are many opportunities for you. </p>
<p>It's OKAY to not know everything. Be patient and enjoy learning.</p>
</div></div>]]>
            </description>
            <link>https://phongduong.dev/blog/it-s-okay-to-not-know-everything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918302</guid>
            <pubDate>Wed, 28 Oct 2020 13:11:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neuroplasticity Is a Pretty Useless Idea for Practice]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24918290">thread link</a>) | @durmonski
<br/>
October 28, 2020 | https://commoncog.com/blog/neuroplasticity-is-a-pretty-useless-idea-for-practice/ | <a href="https://web.archive.org/web/*/https://commoncog.com/blog/neuroplasticity-is-a-pretty-useless-idea-for-practice/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <p>One of the more interesting things that I've learnt from <a href="https://commoncog.com/blog/doing-personal-experiments/">personal experimentation</a> — but that I have long struggled to express — is some notion of ‘don’t think at the wrong level of abstraction’. </p><p>For a number of years now, I’ve noticed that certain ideas that are true and right when applied to higher levels of abstractions <em>don’t</em> apply to lower ones. Conversely, ideas that might apply to lower levels of abstractions don’t apply cleanly to the higher levels.</p><p>This all seems a little abstract and weird, so here's a trivial example: the rules governing neural networks in the human brain do not apply to human psychology, even though human psychology rests on top of the complex interplay between neurons. Similarly — but from the opposite end — the rules that govern a market economy do not apply to the businesses that <em>make up</em> that market economy, in much the same way that the rules that govern an ecosystem do not apply to the social interactions within a particular species.</p><p>I think this idea is broadly generalisable. For this post, however, I want to talk about a very specific instance of the principle: when attempting to get good at some skill, it is not as useful to think about or even talk about neuroplasticity.</p><p>First: neuroplasticity is a <a href="https://en.wikipedia.org/wiki/Neuroplasticity">real thing</a> — it is the observation that the human brain is able to reorganise synaptic functions and neural connections in order to adapt to learning, practice, or even brain trauma.</p><p>Neuroplasticity is a nice concept to know, if you’re curious about the brain. The idea very often shows up in books or blog posts about expertise and expert performance. K. Anders Ericsson, for example, dedicates an entire chapter to plasticity in his popular science book <a href="https://commoncog.com/blog/peak-book-summary/"><em>Peak</em></a>; he uses it to argue that ‘hey, when you learn, your brain changes in response to it!’</p><p>So far so good. But as an idea, neuroplasticity is not particularly useful when you’re attempting to improve in some skill. It is patently ridiculous to say “Oh, I went on a neuroplasticity binge over the weekend, I worked with my coach to improve my chess openings” — you’re essentially saying “I practiced with a coach in order to change my brain.” Good on you!</p><p>What’s the point?</p><p>Neuroplasticity simply tells us that the brain changes in response to learning. It doesn’t tell us <em>how</em> to learn better, or what pedagogical techniques work best for effective learning. And the research around neuroplasticity — that the brain can adapt to trauma, that physical therapy after a stroke works because it depends on the brain’s ability to reconfigure neural connections — isn’t as useful for practice as you might think; it doesn’t tell you anything <em>instrumentally actionable</em> that you may incorporate into your practice.</p><p>In other words, neuroplasticity operates at the <em>wrong level of abstraction for learning</em>. It describes what happens to your neural connections when you’re engaged in practice, but neuroscience isn’t the right level to mine for pedagogical insight. For that, you’ll have to go one level up — to the realm of cognitive science, or psychology. You’ll want to know things like:</p><ul><li>You have two kinds of memory: working memory and long-term memory. How your brain implements these two types of memories is of little concern to you; you merely need to know how to facilitate the transfer of information from working memory to long-term memory, and to improve your ability to recall that information.</li><li>Your brain processes visual and linguistic information using two different subsystems. You don’t need to know where those two subsystems live in your brain; you merely need to understand that presenting complementary visual and linguistic information together (e.g. pictures accompanied by words) strengthens recall of that information.</li><li>And of course, once you begin to learn these ideas, you’ll quickly realise that you should focus on cognitive <em>systems</em>, not neurological facts; this should lead you to the <a href="https://www.learningscientists.org/downloadable-materials">Six Strategies of Effective Learning</a> (<a href="https://teachtogether.tech/en/index.html#s:individual-strategies">longer explanation</a>) and also to things like the <a href="https://commoncog.com/blog/everything-you-need-to-know-about-human-learning-and-memory-retention/#-recall-short-term-memory-overload">7±2 rule</a>.</li></ul><p>This seems like a specific principle: if you’re a practitioner looking for better cognitive techniques, do not reach for neuroscience to explain what might be adequately handled by psychology, or cognitive science.</p><p>In other words, look for things at the right level of abstraction.</p>
      </section></div>]]>
            </description>
            <link>https://commoncog.com/blog/neuroplasticity-is-a-pretty-useless-idea-for-practice/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918290</guid>
            <pubDate>Wed, 28 Oct 2020 13:10:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Awkward translation fails on Amazon's new Swedish site]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24918176">thread link</a>) | @draugadrotten
<br/>
October 28, 2020 | https://www.thelocal.se/20201028/translation-fails-on-amazons-new-swedish-site | <a href="https://web.archive.org/web/*/https://www.thelocal.se/20201028/translation-fails-on-amazons-new-swedish-site">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://storage.googleapis.com/ddos-shield.appspot.com/shield-logo-mono-darktext.svg" width="250px" height="50px" alt="Project Shield Logo"></p><p>You will be connected to <b>www.thelocal.se</b> in just a moment...</p><p><a href="https://g.co/shield">Learn about Project Shield</a></p></div></div>]]>
            </description>
            <link>https://www.thelocal.se/20201028/translation-fails-on-amazons-new-swedish-site</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918176</guid>
            <pubDate>Wed, 28 Oct 2020 12:58:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OKRs vs. KPIs: explanation with examples for Engineering Teams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24918125">thread link</a>) | @bmgoss
<br/>
October 28, 2020 | https://sourcelevel.io/blog/okrs-vs-kpis-explanation-with-examples-for-engineering-teams | <a href="https://web.archive.org/web/*/https://sourcelevel.io/blog/okrs-vs-kpis-explanation-with-examples-for-engineering-teams">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-url="https://sourcelevel.io/blog/okrs-vs-kpis-explanation-with-examples-for-engineering-teams" data-title="OKRs vs. KPIs: explanation with examples for Engineering Teams.">
<p><em>OKRs vs. KPIs, what are the differences?</em> That’s a common question I hear from managers of Engineering Teams. KPIs are more straightforward to explain than <a href="https://en.wikipedia.org/wiki/OKR">OKRs</a>, which can be tricky and more complex. They don’t mean the same, although they are connected.</p>



<h2>What are KPIs?</h2>



<p><strong>KPI stands for Key Performance Indicators.</strong> In other words, KPIs are a set of metrics that should give you an overview of the area or team’s performance. They need to be measurable and comparable.</p>



<p>If you look at many KPIs, they’re not fulfilling their purpose. Organizations should select as few as possible so that tracking the progress is possible. Besides, all the significant changes in process and company goals should impact the numbers.</p>



<p>Then, managing an area or a team becomes more tangible: when the KPIs show poor performance, it’s time to act. The actions taken should reflect better numbers; otherwise, managers need to find another strategy and act differently.</p>



<h2>What are OKRs?</h2>



<p><strong>OKRs stands for Objective Key Results</strong>. It’s a managing methodology that is popular in Silicon Valey. It’s been widely adopted by companies and startups at scale. It’s also seen as an alternative or complement for strategic planning.</p>



<p>OKRs’ primary purpose is to define Objectives that must align with the business and a set of Key Results. Each Key Result needs to have a measurable number as the goal and a limit date. The limit date means that the goal should be achieved within that time frame.</p>



<h2>What’s the difference between KPIs and OKRs?</h2>



<p><strong>KPIs provide an overview of the area or team for managers, whereas OKRs must focus on its future.</strong> That said, it becomes clear that KPIs are a controlling tool, and OKRs intend to change an organization’s status quo and keep track of its progress by periodic assessment meetings.</p>



<p>It’s crucial to have that in mind when choosing the KPIs and the OKRs. Otherwise, they become useless and can even play against business goals. Let’s see some examples of them</p>



<h2>Examples of OKRs and KPIs for Engineering Teams</h2>



<p>Below there is a list of KPIs examples. However, you can find more examples in my article&nbsp;<a href="https://sourcelevel.io/blog/software-engineering-kpis-how-to-choose-the-best-fitting-metrics">Software Engineering KPIs: how to choose the best fitting metrics</a>.</p>



<ul><li><strong>Deploy Frequency</strong>: it’s a sum of the <a href="https://thenewstack.io/measuring-engineering-velocity-deploy-frequency-as-a-vital-sign-of-devops-health/">number of deploys made by day</a>, week, or month, depending on the organization’s need.&nbsp;<em>It shows how frequently the team — or area — delivers value to the final user</em>.</li><li><strong>Time to Merge</strong>: it measures the number of days a Pull Request remains open or under review. You can find an average or, as I prefer, see the 75th percentile of all pull requests closed in a given period.&nbsp;<em>It shows how performant is the team</em>.</li><li><strong>Time to Recover</strong>: how much time does the application is inaccessible after an error?&nbsp;<em>This metric tells a lot about how engineering teams respond to failures.</em></li></ul>



<p>When thinking of OKRs, Engineering Teams may consider Objectives such as:</p>



<ul><li><strong>Improving the Time to Market of new features</strong></li><li><strong>Lessen the Churn rate of the product</strong></li></ul>



<p>Here are some possible Key Results for&nbsp;<strong>Improving the Time to Market of new features</strong>:</p>



<ul><li><strong>Increase the Deploy Frequency to 37/week until &lt;insert the date&gt;</strong>. Assuming you deploy less than 37 times a week currently, increasing the frequency means you’re delivering more. Delivering more is crucial to achieving a more competitive Time to Market.</li><li><strong>Reduce the 75th percentile of Time to Merge to 3 days until &lt;insert the date&gt;</strong>. Instead of the Median or Average, I prefer using the 75th percentile for Key Results. In other words, it means that 75% of the Pull Requests must be merged up to 3 days after they were opened. The team can achieve it by opening lighter pull requests or engaging in collaborators’ pull requests instead of working on a new work item.</li></ul>



<p>For the second object,&nbsp;<strong>Lessen the Churn rate of the product</strong>, let’s assume you know the primary source of churn comes due to a high number of errors in the application. Then, the Key Results could include:</p>



<ul><li><strong>Reduce the number of Technical Debts to 15 until &lt;insert the date&gt;</strong>. Let’s say you have 30 Technical Debts currently. It’s a 50% improvement. There are many chances that improving the codebase will positively affect the churn rate and help in the KR of the previous Objective. The cleaner the code, the better it embraces the changes. It means you can reduce the churn and also achieve better Time to Market by gardening your codebase.</li><li><strong>Reduce the Mean Time to Recover to Recover (MTTR) to 3 minutes until &lt;insert the date&gt;</strong>. The team needs to monitor application outages, connectivity problems, 503 errors, and other failures to ensure end-users’ experience is not impacted with more than 3 minutes of instability.</li></ul>



<h2>In short,</h2>



<p>KPIs and OKRs are not the same. They have different purposes. KPIs aim to give managers an overview of how the team or area is working, whereas OKRs focus on providing the team a direction and then tracking its progress.</p>



<p>I presented some examples of KPIs and OKRs for Engineering Teams to illustrate the difference. SourceLevel provides lots of metrics, which may include your KPIs. Check out our&nbsp;<a href="https://sourcelevel.io/engineering-metrics">Analytics feature</a>, or&nbsp;<a href="https://sourcelevel.io/schedule-your-demo">schedule a demo with me</a>.</p>



<p>If you need to define KPIs for your team, I am giving away a&nbsp;<a href="https://sourcelevel.io/software-engineering-kpi-consultation">30-min consultation meeting</a>. Schedule a demo so that we can discuss your specific needs.</p>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img alt="" src="https://secure.gravatar.com/avatar/eada2a1e2181b03b4f1a76359e3f8b5b?s=100&amp;d=blank&amp;r=r" srcset="https://secure.gravatar.com/avatar/eada2a1e2181b03b4f1a76359e3f8b5b?s=200&amp;d=blank&amp;r=r 2x" height="100" width="100" itemprop="image" loading="lazy"></p></div></div></div>]]>
            </description>
            <link>https://sourcelevel.io/blog/okrs-vs-kpis-explanation-with-examples-for-engineering-teams</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918125</guid>
            <pubDate>Wed, 28 Oct 2020 12:52:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Six-page narratives tackling our biggest challenges]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24918041">thread link</a>) | @scotthtaylor
<br/>
October 28, 2020 | https://st.im/six-page-narratives-tackling-worlds-biggest-challenges/ | <a href="https://web.archive.org/web/*/https://st.im/six-page-narratives-tackling-worlds-biggest-challenges/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<div>
  <main>
      <article>
  
  <div>
        <p>For the past few months I’ve been thinking about how to persuade some of the top philanthropists, investors and thinkers to work on an idea alongside me.</p><p>These ideas aren’t focused on problems that I’ve typically tried to tackle in the past. They’re focused on some of the most significant problems facing the world today: carbon removal, longevity, artificial intelligence, biotech, battery technology... to name a few.</p><h2 id="why-these-challenges">Why these challenges?</h2><p>Now in my early thirties, I want to focus on what I believe are some of the biggest challenges facing the world today. Using everything that I’ve learned over the past decade of launching startups, building machine learning algorithms, and connecting with people that are much smarter than me.</p><p>Seeing initiatives such as the <a href="https://earthshotprize.org/">Earthshot Prize</a>, <a href="https://schmidtfutures.com/">Schmidt Futures</a>, and <a href="https://twitter.com/chamath/status/1284531841651752960?s=21">Chamath’s ‘climate action’ call</a>, I feel there’s never been a better time to focus on the biggest challenges we face as humanity.</p><p>Over the next few months I’ve set myself the challenge of scoping out a solution to these challenges that is worth exploring, then to partner with a domain expert, and start to raise funding.</p><p>So how should I go about building a compelling case?</p><h2 id="creating-good-ideas-clear-thinking-is-clear-writing">Creating good ideas: clear thinking is clear writing</h2><p>You might have seen my <a href="https://st.im/what-i-learned-reading-every-amazon-shareholder-letter/">recent post</a> on how I read every one of Amazon's shareholder letters.</p><p>I chose Amazon for a reason.</p><p>Founder &amp; CEO, Jeff Bezos, is an excellent storyteller. His writing is concise, articulate and authentic. It's rare to find someone who can convey their thinking, mission and vision as articulately as Bezos can. And he places a high level of importance on the skill at Amazon.</p><p>Bezos has been able to instil, defend and evolve his company's thinking and behaviour for two decades, ever since its founding. The only ideas that can survive for that long are the ones that are packaged memorably enough -- and memorably packaging ideas in just a few choice words has long been one of Bezos' strengths.</p><p>One of the most important takeaways I found whilst reading through his shareholder letters was Amazon's use of 'six-page narratives', alongside their 'no PowerPoint' rule.</p><blockquote><em>We don’t do PowerPoint (or any other slide-oriented) presentations at Amazon. Instead, we write narratively structured six-page memos. We silently read one at the beginning of each meeting in a kind of “study hall.” Not surprisingly, the quality of these memos varies widely. Some have the clarity of angels singing. They are brilliant and thoughtful and set up the meeting for high-quality discussion. Sometimes they come in at the other end of the spectrum.</em></blockquote><p>Bezos goes onto explain what makes a good memo:</p><blockquote>Here’s what we’ve figured out. Often, when a memo isn’t great, it’s not the writer’s inability to recognize the high standard, but instead a wrong expectation on scope: they mistakenly believe a high-standards, six-page memo can be written in one or two days or even a few hours, when really it might take a week or more! They’re trying to perfect a handstand in just two weeks, and we’re not coaching them right. The great memos are written and re-written, shared with colleagues who are asked to improve the work, set aside for a couple of days, and then edited again with a fresh mind. They simply can’t be done in a day or two. The key point here is that you can improve results through the simple act of teaching scope – that a great memo probably should take a week or more.</blockquote><p>Writing these narratives, or stories, forces those at Amazon to think through their ideas in high-resolution detail. Instead of wasting time with impromptu brainstorming sessions, writing memos ensures that group discussion is based on the critical review of the relevant ideas, not on hypotheticals.</p><p>Most importantly, it makes it impossible to hide any logical inconsistencies in the ideas that people put out there. By imposing a rigorous, standardised template on the process of idea generation at Amazon, Jeff Bezos raises the bar and raises the quality of his team's thinking.</p><h2 id="stories-have-long-been-fundamental-to-the-human-experience">Stories have long been fundamental to the human experience</h2><p>Stories are vivid, coherent and memorable – and are crucial to how we interact with the world. Although the term ‘story’ conjures images of fairy tales and myths, there is little that occurs in our lives around which we do not attempt to weave a narrative. Stories cater to our need for sense-making and our desire to observe causality. In one form or another, they underpin most human decisions.</p><p>One particular model of decision-making – explanation-based theory – emphasises that in certain conditions, individuals start their decision process by developing a causal model to explain the available evidence. To rationalise it, in other words, and put otherwise potentially abstract data into context. In this model, the story that has been created informs the ultimate decision as much as the standalone evidence.</p><p>Trial jurors are more likely to be persuaded by evidence if it is presented in the order of a logical story than if the same evidence is shown in random order. What’s more, the story each individual develops around the evidence will be unique and dependent on their own characteristics, beliefs and experience.</p><p>The juror example is useful when considering the role of narratives in investment decision making. Explanation-based theory is particularly applicable when decisions are large and complex, as investment decisions often tend to be. In fact, investment decision-making is a domain in which stories assume a particular importance in driving, informing and justifying conclusions.</p><p>There are two key reasons for this:</p><p>Complexity: narratives aid our comprehension There is intricacy and complication even in the simplest of investments, and if we start to consider the innovation and product proliferation that have come to define the industry, many investments can be fairly considered unfathomable. Stories are important in allowing investors to both simplify and justify decisions. </p><p>Uncertainty: startups, by definition, are risky. There are many things founders simply can’t plan for. Our surest means of coping with the discomfort is to manufacture meaning by forging a relationship between the data and an explanation – a story, in other words – of why the data is what it is and how it got that way.</p><p>Most investors won’t make a decision without it being supported by some form of story, and that’s understandable; stories are effective and can be very valuable. Now with the pandemic meaning in-person meetings are on hold, crafting a narrative -- with clear supporting evidence -- seems to be the best way for me to forge a connection with any potential investor.</p><p>Using Amazon’s narrative format, I'm sharing some ‘six-pagers’ that will hopefully start to lay the foundations for the next chapter of my life.</p><p>If you’ve read this blog before, you’ll know I'm a fan of networked thought, using <a href="https://obsidian.md/">Obsidian</a> on a daily basis.</p><p>They've just rolled out a new feature, Obsidian Publish; which, in essence, is a public notebook. I thought it would probably make most sense to share my own <a href="http://publish.obsidian.md/stim">six-page narratives</a> on there.</p><p>I'm still working on them as we speak, so you're getting a pretty raw insight into my thinking, as well as how I formulate or tackle problems.</p><p>I hope you’ll follow me as I start out on this new journey.</p>
              <section>
                <h2>Enjoying these posts? Join for more</h2>
                <a href="https://st.im/join/">Join now</a>
                <br>
                <a href="https://st.im/signin/">Already have an account? Sign in</a>
              </section>
  </div>
    
</article>          
          


  </main>
</div>
      </div><p>
  You've successfully subscribed to Scott Taylor.
  
</p><p>
  Great! Next, complete checkout for full access to Scott Taylor.
  
</p><p>
  Welcome back! You've successfully signed in.
  
</p><p>
  Success! Your account is fully activated, you now have access to all content.
  
</p><p>
  Success! Your billing info is updated.
  
</p></div>]]>
            </description>
            <link>https://st.im/six-page-narratives-tackling-worlds-biggest-challenges/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918041</guid>
            <pubDate>Wed, 28 Oct 2020 12:43:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facts worth knowing: Starting a career in tech]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24918039">thread link</a>) | @omotola28
<br/>
October 28, 2020 | https://blog.oshogunle.com/5-facts-worth-knowing-starting-a-career-in-tech-ckgscogcy04z506s16pbe5vua | <a href="https://web.archive.org/web/*/https://blog.oshogunle.com/5-facts-worth-knowing-starting-a-career-in-tech-ckgscogcy04z506s16pbe5vua">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1603826118326/xmu8PEoSf.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>I just recently started my graduate role 🥳 at  <a target="_blank" href="https://ampersandcommerce.com/">Ampersand UK</a> and it's been amazing, (PS. That is why I have been MIA from blogging) however, prior to that I was involved in a few extracurricular activities before starting my job. Today I want to talk about a few facts I appreciate knowing before starting my tech career. </p>
<blockquote>
<p> <a target="_blank" href="https://youtu.be/ox8sJtZb5lw">Listen to me</a>  read the post to you</p>
</blockquote>

<p><strong>Fact number 1</strong>, there is a tech community, that is generous, willing and happy to help, or share their ideas and expertise in a wide variety of non-technical and technical topics. If you are like me and have been under a rock, doing things by yourself and not quite finding a community to encourage you in your journey. This would be particularly relieving to know, because, I don't know what it is about seeing people in positions I aspire to be? But for me, it gives me a sense of hope that I can achieve what I set out to do. It's great to know that I am not in this alone! In irony, I was never 😃, I just decided to stick my head out a little and it's paid off tremendously. </p>

<p><strong>Fact number 2</strong>, Mentors are important! For the most part of my journey, I have had what I would refer to as <em>online mentors</em>. People who I haven't met, but I have spent time with their work. Engaging with it and taking away little gems that have helped me one way or the other. But do you know what would have even been more helpful? Having a physical mentor, that I could have both formal and informal conversations with. Someone who is a friend and mentor, who has way more life and work experience than I have. I really do believe having this sort of relationship in your life is mutually beneficial to both mentor and mentee. If you have one atm you are very lucky!</p>

<p><strong>Okay fact number 3</strong> I did mention at the start that I was involved in some extracurricular activities before I started my job. These included</p>
<ul>
<li>Volunteering to teach kids how to code</li>
<li>Contributing to open source projects </li>
<li>Starting a  <a target="_blank" href="https://www.instagram.com/mycodinghabits/">technical page</a>  on Instagram </li>
<li>Mentoring and</li>
<li>Technical writing as seen on this blog etc.</li>
</ul>
<p>I actually enjoyed doing all of these extracurricular activities, because It was fulfilling. I was spreading knowledge that was extremely helpful to people that needed the help, support, general information or source of inspiration. It felt purposeful, knowing I was serving others in a way that added value.</p>

<p><strong>Fact number 4</strong> is a bit of a debatable fact! Some say to prove yourself in the workplace you have to go <em> <strong>'Above and beyond'</strong></em>  to impress both your colleagues and employer. Others say it's a <strong><em>9-5 no more no less</em></strong>, I am sure you have also heard <strong><em>work smart not hard</em></strong>, and the debate goes on. I was still on the fence on this one until I read an article by <a href="https://hashnode.com/@victoria">Victoria Lo</a> on <a target="_blank" href="https://lo-victoria.com/become-a-better-developer-with-self-care">self-care tips</a>  for developers. And I had an <em>Aha moment</em> 🤓, it made sense. The keyword with the whole idea of work-life balance is the word <strong><em>BALANCE</em></strong>. I believe there are grey areas with this concept and it can't be a sharp contrast between managing both your life and work because sometimes one might require more attention than the other. And as professionals we have to adhere to the different demands accordingly, but in this case do it acknowledging the human also needs to be taken care of in order to perform at their most optimal level.</p>

<p><strong> Finally the money fact </strong> I bet a good number of us did not negotiate the salary offer for your first job? 🙋🏾‍♀️ I didn't as well, not necessarily a bad thing, I bet given better knowledge, circumstance, experience or understanding you could have. But what's great about this fact is I can start doing specific things that would help my chances of getting a raise on the job or better feedback. Someone once said if you don't document it, it never happened, and if it never happened there would not be any strong basis for negotiation or solid feedback that is essential for my growth. So a few things I now know to implement towards this fact is</p>
<ul>
<li>To document my progress on the job and how my work might be improving the business or even helping my team in general.</li>
<li>By doing this, scheduled 1:1s with my team lead would be more practical and intentional. This way, asking for feedback or opportunity for growth would be easier.</li>
</ul>
<p>One of the reasons I love where I work is that, this practice of documenting and organizing 1:1s is done using a platform called  <a target="_blank" href="https://lattice.com/">Lattice</a>. With a tool like this, there is a lot of transparency, and its good practice not only for negotiating your salary, but for adding to your career growth, and also appreciating other peoples work in and outside your team.</p>
<p>Is there any other <strong>fact/advise you would like to share with me?</strong> Please write them in the comment section. </p>
<ul>
<li><strong> Engage with my post </strong> ==&gt; I promise you it cost nothing</li>
<li><strong> Comment below your thoughts </strong> ==&gt; I would really like to hear them</li>
<li><strong> Share with others </strong> ==&gt; lol don't be stingy!</li>
</ul>
<p>Thank you!</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.oshogunle.com/5-facts-worth-knowing-starting-a-career-in-tech-ckgscogcy04z506s16pbe5vua</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918039</guid>
            <pubDate>Wed, 28 Oct 2020 12:43:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coming to Elixir from TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24918035">thread link</a>) | @1_player
<br/>
October 28, 2020 | https://papercups.io/blog/elixir-noob | <a href="https://web.archive.org/web/*/https://papercups.io/blog/elixir-noob">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://papercups.io/blog/elixir-noob</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918035</guid>
            <pubDate>Wed, 28 Oct 2020 12:42:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[20 Predictions for Community in the 2020s]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24918006">thread link</a>) | @teaguns
<br/>
October 28, 2020 | https://the.community.club/mac/20-predictions-for-community-in-the-2020s-2ec3 | <a href="https://web.archive.org/web/*/https://the.community.club/mac/20-predictions-for-community-in-the-2020s-2ec3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-title">
            <p><img src="https://the.community.club/images/PcDObvAWNr8SuZtdzYc-K9JFgEm2j9yanWgap0z1z4Q/s:1000:420/aHR0cHM6Ly90aGUu/Y29tbXVuaXR5LmNs/dWIvcmVtb3RlaW1h/Z2VzL2kvY3h5aGJj/OHF3ZmQzc2p1NGww/MDYucG5n" width="1000" height="420" alt="Cover image for 20 Predictions for Community in the 2020s">
            </p>

          
        </div><div>

          <div data-article-id="38" id="article-body">
            <p>Software is eating the world, and community is eating software</p>

<p>In no particular order, a few predictions for community in the 2020s.</p>

<p>💪 <strong>Community will continue to be a broad term</strong>, but finally people and companies will fully grasp that an audience does not mean the same thing as a community.</p>

<p>🪑 <strong>Community will finally get a seat at the table</strong>, following in the footsteps of customer success from a decade ago. Community will become its own department within orgs, leading to more Heads of Community, Chief Community Officers, and other community leadership roles.</p>

<p>✨ <strong>Continued specialization of roles in community.</strong> Community Manager will turn into Community Engagement, Community Marketing, Community Support, Community Success, etc.</p>

<p>🙋 <strong>And then we’ll see other roles start to merge under community.</strong> Community, customer support, and customer success will overlap and start to blend together. Traditional CS roles will still exist, but more ‘low-level’ support will be offloaded to communities and community teams.</p>

<p>📈 <strong>More and more companies will invest in community early</strong>, hiring their first community roles in their first 10 or 20 employees. Community will be standard for startups started in the 2020s.</p>

<p>💼 <strong>The unbundling of LinkedIn.</strong> What Dribbble is to designers, we’ll see for nurses, marketers, community managers, and every other career vertical, providing community, ‘portfolios’, and better job hunting experiences tailored to the specific type.</p>

<p>🎁 <strong>The unbundling of Reddit.</strong> Every subreddit will get its own dedicated community app, built specifically to serve the unique needs of that vertical. Vertical specificity will win out over general community platforms.</p>

<p>🚗 <strong>Community-driven versions of existing products</strong> and services will continue to be built, eventually taking over those who built without community. See Public vs Robinhood.</p>

<p>📣 <strong>Interactive audio and audio communities</strong> will continue to grow. Spotify will enter the market with their own offering, or acquire an existing player similarly to when they initially entered podcasting.</p>

<p>🕺 <strong>We’ll see innovation in the community platform space.</strong> Everything right now looks like some form of forum or ‘Slack for community’. We’ll see platforms that rethink the idea of community from the ground up, in less structured ways than ‘forums’.</p>

<p>🌍 The explosion of remote work will continue to drive <strong>a greater need for community at every level, online and offline</strong>, locally and globally. Expect more companies to build verticals in Nextdoor’s space.</p>

<p>🤑 <strong>Companies will continue to acquire communities</strong> as starting points for their own. See Outreach + Saleshacker, Stripe + Indiehackers, and DigitalOcean + Scotch.</p>

<p>💡 <strong>More and more companies will build communities of interest</strong>, rather than just customer &amp; support communities. This will enable their communities to reach a wider audience, and ultimately be seen as revenue generators rather than cost centers.</p>

<p>💬 <strong>A number of independent communities will turn into full-fledged businesses</strong> and media ‘empires’ as they grow beyond the community they started with.</p>

<p>🛠 <strong>Consolidation of tools.</strong> We’re currently in a golden age of community, engagement and event tools, but over the next decade we’ll see major players start to lead, acquire competitors, and ultimately ‘win’. We’ll also see existing companies (Salesforce, Slack, etc) invest more in community by acquiring companies that are being built right now.</p>

<p>🙊 <strong>Increased innovation will occur in the moderation space.</strong> As community gets elevated in organizations, companies will finally want to invest in tools to help make moderation easier and less dependent on pure manpower.</p>

<p>🏢 <strong>Companies will treat their internal teams more like communities</strong>, and there will be an expansion of internal community teams, especially at cos with 1,000+ employees. Remote-first companies will set this trend, needing to be more intentional about fostering internal community.</p>

<p>👋 <strong>Continued normalization of internet friends</strong>, people that you met in online communities rather than in-person. This has been normal for a decade or more in the gaming world, but it will bleed over to professional friends and relationships.</p>

<p>🏃‍♀️ <strong>In-person events will come back quickly post-Covid</strong>, but they will be smaller and more intimate, focusing on genuine connection. It will be a while before we see large 500+ person events and conferences again.</p>

<p>📆 <strong>Companies will continue to invest in online events</strong> and engagement as they realize how much larger of a reach they can achieve for lower cost and overhead. In-person conferences will adopt hybrid models, offering virtual access in addition to their physical locations.</p>


<hr>

<p>Have any predictions of your own for how community (especially within organizations) will evolve over the next decade? Share them in the thread below! 👇</p>


          </div>

        </div></div>]]>
            </description>
            <link>https://the.community.club/mac/20-predictions-for-community-in-the-2020s-2ec3</link>
            <guid isPermaLink="false">hacker-news-small-sites-24918006</guid>
            <pubDate>Wed, 28 Oct 2020 12:39:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dutch flying car gets permission to drive on European roads]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 106 (<a href="https://news.ycombinator.com/item?id=24917841">thread link</a>) | @Bologo
<br/>
October 28, 2020 | https://www.psychnewsdaily.com/dutch-flying-car-pal-v-gets-permission-to-drive-on-european-roads/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/dutch-flying-car-pal-v-gets-permission-to-drive-on-european-roads/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4802" role="main"><div><div><div><p>The Dutch company <a rel="noreferrer noopener" href="https://www.pal-v.com/en/" target="_blank">PAL-V</a> today announced that its Liberty flying car <a href="https://www.pal-v.com/en/press/worlds-first-flying-car-hits-the-road" target="_blank" rel="noreferrer noopener">has received permission</a> from the <a rel="noreferrer noopener" href="https://www.rdw.nl/over-rdw/information-in-english" target="_blank">Netherlands Vehicle Authority</a>&nbsp;to drive on public roads.<span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p>The PAL-V Liberty, the flying car’s full name, is a gyro-copter.&nbsp;The rotor can be folded so that the vehicle can also drive on the road like a regular car.&nbsp;</p><p>It needs a runway of between 180 – 330 meters for takeoff, but only 30 meters for landings.&nbsp;Both in the air and on the road, its maximum speed is 180 km/hour (112 mph). Converting from road to air mode (or vice versa) takes between five and ten minutes.</p><p>The Liberty runs on normal gasoline, and has a range of 1315 km (817 miles) on the road. In the air, it can fly 400 – 500 km (250 – 310 milles), and can remain airborne for 4.3 hours.</p><p>The PAL-V Liberty weighs 664 kg (1464 lbs) when empty. Its fuel tank holds 100 liters. The tank of a Honda Accord, just by way of comparison, holds about 53 liters.<span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><h2>Already 30 orders for this Dutch flying car</h2><p>According to the company, about thirty Dutch residents have already ordered and paid for the Liberty. The list price is just under €500,000 ($587,000).</p><p>At the moment, the granted permission is only for a single vehicle. That means PAL-V cannot yet put their car into full production.&nbsp;The Netherlands Vehicle Authority first needs to ensure that the company can produce every vehicle according to the same quality standards.</p><p>PAL-V has been working on the Liberty since 2007. The European Aviation Safety Agency is still examining the company’s request to have the vehicles certified to fly. The company expects this permission to arrive in 2022.</p><p>The US state of New Hampshire <a href="https://www.timesnownews.com/auto/features/article/this-is-the-first-state-in-us-to-allow-flying-cars-on-public-roads/634621" target="_blank" rel="noreferrer noopener">made it legal to drive flying cars on public roads</a> in August of this year.<span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>See a video of the PAL-V Liberty driving <a rel="noreferrer noopener" href="https://youtu.be/yIjSaEeO2l0" target="_blank">here</a>, and flying (briefly) <a rel="noreferrer noopener" href="https://youtu.be/fFW_0C7yFCI" target="_blank">here</a>.</p><figure><img loading="lazy" width="1024" height="512" src="https://www.psychnewsdaily.com/wp-content/uploads/2020/10/Flying-Car-PAL-V-Liberty-1024x512.jpg" alt="" srcset="https://www.psychnewsdaily.com/wp-content/uploads/2020/10/Flying-Car-PAL-V-Liberty-1024x512.jpg 1024w, https://www.psychnewsdaily.com/wp-content/uploads/2020/10/Flying-Car-PAL-V-Liberty-300x150.jpg 300w, https://www.psychnewsdaily.com/wp-content/uploads/2020/10/Flying-Car-PAL-V-Liberty-768x384.jpg 768w, https://www.psychnewsdaily.com/wp-content/uploads/2020/10/Flying-Car-PAL-V-Liberty-1536x768.jpg 1536w, https://www.psychnewsdaily.com/wp-content/uploads/2020/10/Flying-Car-PAL-V-Liberty-360x180.jpg 360w, https://www.psychnewsdaily.com/wp-content/uploads/2020/10/Flying-Car-PAL-V-Liberty-1320x660.jpg 1320w, https://www.psychnewsdaily.com/wp-content/uploads/2020/10/Flying-Car-PAL-V-Liberty.jpg 1560w" sizes="(max-width: 1024px) 100vw, 1024px"></figure><figure><img loading="lazy" width="1024" height="537" src="https://www.psychnewsdaily.com/wp-content/uploads/2020/10/pal-v-liberty-flying-car-1024x537.jpg" alt="" srcset="https://www.psychnewsdaily.com/wp-content/uploads/2020/10/pal-v-liberty-flying-car-1024x537.jpg 1024w, https://www.psychnewsdaily.com/wp-content/uploads/2020/10/pal-v-liberty-flying-car-300x157.jpg 300w, https://www.psychnewsdaily.com/wp-content/uploads/2020/10/pal-v-liberty-flying-car-768x403.jpg 768w, https://www.psychnewsdaily.com/wp-content/uploads/2020/10/pal-v-liberty-flying-car-360x189.jpg 360w, https://www.psychnewsdaily.com/wp-content/uploads/2020/10/pal-v-liberty-flying-car-1320x693.jpg 1320w, https://www.psychnewsdaily.com/wp-content/uploads/2020/10/pal-v-liberty-flying-car.jpg 1408w" sizes="(max-width: 1024px) 100vw, 1024px"></figure><figure><img loading="lazy" width="1024" height="538" src="https://www.psychnewsdaily.com/wp-content/uploads/2020/10/pal-v-liberty-fying-car-interior-1-1024x538.jpg" alt="" srcset="https://www.psychnewsdaily.com/wp-content/uploads/2020/10/pal-v-liberty-fying-car-interior-1-1024x538.jpg 1024w, https://www.psychnewsdaily.com/wp-content/uploads/2020/10/pal-v-liberty-fying-car-interior-1-300x158.jpg 300w, https://www.psychnewsdaily.com/wp-content/uploads/2020/10/pal-v-liberty-fying-car-interior-1-768x403.jpg 768w, https://www.psychnewsdaily.com/wp-content/uploads/2020/10/pal-v-liberty-fying-car-interior-1-360x189.jpg 360w, https://www.psychnewsdaily.com/wp-content/uploads/2020/10/pal-v-liberty-fying-car-interior-1.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/dutch-flying-car-pal-v-gets-permission-to-drive-on-european-roads/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917841</guid>
            <pubDate>Wed, 28 Oct 2020 12:17:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thinking about Climate Change]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24917809">thread link</a>) | @scotthtaylor
<br/>
October 28, 2020 | https://st.im/thinking-about-climate-change/ | <a href="https://web.archive.org/web/*/https://st.im/thinking-about-climate-change/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Global warming is quite possibly the greatest challenge we have ever faced.</p><p>A solution involves not only understanding most branches of science, but economics, politics and, more generally, human behaviour. </p><p>To date, even with our advanced technologies, planet earth's climate seems to remain beyond our control.</p><p><a href="https://st.im/six-page-narratives-tackling-worlds-biggest-challenges/">Last week I wrote</a> about the fact that I’ve started to spend a lot of time thinking about some of the biggest challenges we face as humanity. My goal being to narrow these challenges and dedicate the next decade of my life toward realising some of the potential solutions. </p><p>To help me kickstart, I’m publicly writing a series of Amazon-style <a href="https://publish.obsidian.md/stim/Public+Obsidian/Six-pagers">six-page memos</a> that I will send to investors, philanthropists and potential co-founders with the ultimate goal of seeing if they’d like to partner, and tackle one of these challenges alongside me.</p><p>So how do I go about it? It won’t be easy, especially in fields where I have limited ‘applied’ or academic experience. I’m using these memos as a stepping stone toward real world experiments, hopefully validating some of my hypotheses.</p><p>Today, there’s an abundance of free information. What remains scarce is insight. Choose any non-trivial topic X, and a cursory Google search will give you evidence for both X and NOT (X). </p><p>So how do you find out what’s really true in the world of climate change? </p><p>That’s where <a href="https://fs.blog/2018/04/first-principles/">thinking from first principles</a> comes in. The basic idea behind this is to break down complicated problems into basic elements and then reassemble them from the ground up. I’ve found it to be one of the best ways to learn to think for myself, unlock creative potential, and move from linear to non-linear results.</p><p>Over the years there’s been so much fake news from vested interests, and well-meaning but conflicting reports about climate change. Couple this with the fact that attempting to solve it is hugely complex, with many interdependencies. Crafting a meaningful solution will mean not only exploring and understanding most branches of science, but economics, politics and, more generally, human behaviour. </p><p>By breaking each of these down to their basic elements it should help me understand them more thoroughly. Allowing me to build my own ground truths, and focus on the right stuff.</p><p>Why have I <a href="https://publish.obsidian.md/stim/Public+Obsidian/Climate+Change">started</a> with climate change? </p><p>Simple: time, and the lack of it. </p><p>Scientists are telling us that on current trends by the middle of this century, vast swathes of the world will be experiencing uninhabitable temperatures for weeks on end. In essence, making them no-go zones. &nbsp;This means the next decade is make or break. </p><p>Thankfully, climate change is starting to gain some real attention. </p><p>People are increasingly paying attention to the fact that:</p><ol><li>We’re experiencing unprecedented lethal <a href="https://www.who.int/health-topics/heatwaves#tab=tab_1">heat waves</a>. It’s simply getting too hot and too humid for humans to be able to survive in many places.</li><li>Our largest physical structures; ice caps, coral reefs, and rainforests are disappearing before our eyes. Sea levels are rising, literally making the habitable world smaller.</li><li>There will be an <a href="https://www.climateforesight.eu/migrations-inequalities/environmental-migrants-up-to-1-billion-by-2050/">estimated 200 million - 1 billion</a> climate refugees in this century alone. This number of people on the move will be hugely destabilising.</li><li>When you factor in the cost of the environmental damage caused by our continued use of fossil fuels, &nbsp;it makes no economic sense to generate power in the way we have historically. The price of a solar panel, for example, has fallen 90 percent.</li></ol><p>The climate sector has also grown dramatically over the last few years. </p><p><a href="https://lowercarboncapital.com/">LowerCarbon Capital</a>, <a href="https://www.primeimpactfund.com/">Prime Impact</a> &amp; <a href="https://www.palebluedotventures.com/">PaleBlueDot</a> all launched. And several corporates have also announced their corporate venture funds tackling decarbonisation. Many more made net zero commitments.</p><p>Initiatives such as the <a href="https://earthshotprize.org/">Earthshot Prize</a> are attracting some of the world’s smartest thinkers. Chamath Palihapitiya also <a href="https://twitter.com/chamath/status/1284531841651752960?s=21">announced</a> the allocation of a “few billion” to solve the problem. He <a href="https://fs.blog/knowledge-project/chamath-palihapitiya/">said recently</a> that he believes the world’s first trillionaire will be someone involved in developing technologies to combat climate change.</p><p>When it comes to philanthropy, there is no one better versed than Bill Gates in understanding how to prioritise dollar impact to maximise lives improved or saved. He’s <a href="https://www.gatesnotes.com/How-to-Avoid-a-Climate-Disaster">just announced</a> a new book ‘<em>How to Avoid a Climate Disaster: The Solutions We Have and the Breakthroughs We Need’</em>. </p><p>So the foundation of a meaningful climate change ecosystem is already here.</p><p>This enables the “crazy ones”, or “the ones who see things different” to innovate, to think outside of the box, and to find the support and freedom to dedicate themselves to discovering solutions. </p><p>There’s going to be quite a few footnotes in this post. A lot of people who are much smarter than me have spent a lot of time figuring stuff out. I’m hoping that I’ll be able to stand on the shoulders of these giants. With a set of fresh eyes, and the ignorance that only someone new to the space can have. </p><p>Let’s see if I can connect some dots, and pull together a plan. </p><p>In the remainder of this post, I’m going to cover the basics of climate change, as well as how I’m thinking of approaching it — with scenario planning and probabilistic forecasting. Finally we’ll look at the most promising areas of research in 2020. </p><p>If you're interested, I'd recommend bookmarking the <a href="https://publish.obsidian.md/stim/Public+Obsidian/Climate+Change">climate change six-pager</a> —over the next couple of weeks I'll be working on it. With the goal of sending it as soon as possible. </p><h2 id="what-factors-determine-earth-s-climate">What factors determine Earth’s climate?</h2><p>The Royal Society has done a <a href="https://royalsociety.org/topics-policy/projects/climate-change-evidence-causes/basics-of-climate-change/">great job</a> of introducing the topic, and much of what is written below is learned from their resources.</p><p>The Sun is the primary energy source for Earth’s climate. </p><p>Some of this sunlight is reflected back into space, predominantly by bright surfaces (e.g. ice and clouds) the rest is absorbed by the surface and the atmosphere. </p><p>Much of this absorbed solar energy is re-emitted as heat. The atmosphere in turn absorbs and re-radiates heat, some of which escapes to space. Any disturbance to this balance of incoming and outgoing energy affects the climate. Small changes in the output of energy from the Sun will change this balance.</p><p>If all the heat energy emitted from the surface passed through the atmosphere directly into space, Earth’s average surface temperature would be significantly colder than today. </p><p>Greenhouse gases in the atmosphere, including water vapour, carbon dioxide, methane, and nitrous oxide, act to make the surface much warmer than this because they absorb and emit heat energy in all directions, keeping Earth’s surface and lower atmosphere warm. </p><p>Without this greenhouse effect, life as we know it could not have evolved on our planet. Adding more greenhouse gases to the atmosphere makes it even more effective at preventing heat from escaping into space. When the energy leaving is less than the energy entering, Earth warms until a new balance is established.</p><p>Greenhouse gases emitted by human activities alter Earth’s energy balance and thus its climate. We affect climate by changing the nature of the land surfaces; for example, by clearing forests for farming. The emission of pollutants also affect the amount and type of particles in the atmosphere.</p><p>Scientists have determined that, when all human and natural factors are considered, Earth’s climate balance has been altered towards warming, with the biggest contributor being increases in CO2.</p><h2 id="human-activities-have-added-greenhouse-gases-to-the-atmosphere">Human activities have added greenhouse gases to the atmosphere</h2><!--kg-card-begin: html--><!--kg-card-end: html--><p>The atmospheric concentrations of carbon dioxide, methane, and nitrous oxide have increased significantly since the Industrial Revolution began. </p><p>In the case of carbon dioxide, the average concentration measured at the Mauna Loa Observatory in Hawaii has risen from 316 parts per million (ppm) in 1959 (the first full year of data available) to more than 411 ppm in 2019. </p><!--kg-card-begin: html--><!--kg-card-end: html--><p>The same rates of increase have since been recorded at numerous other stations worldwide. Since preindustrial times, the atmospheric concentration of CO2 has increased by over 40%, methane has increased by more than 150%, and nitrous oxide has increased by roughly 20%.</p><p>More than half of the increase in CO2 has occurred since 1970. Increases in all three gases contribute to warming of Earth, with the increase in CO2 playing the largest role. </p><p>Scientists have examined greenhouse gases from the past — by examining air trapped inside ice in Antarctica, we now know that the CO2 concentration began to increase significantly in the 19th century. This is after it had stayed in the range of 260 - 280 ppm for the previous 10,000 years. Ice core records extending back 800,000 years show that during that time, CO2 concentrations remained within the range of 170 to 300 ppm throughout many “ice age” cycles - and no concentration above 300 ppm is seen in ice core records until the past 200 years.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>This should already be setting off alarm bells. The change in the last 200 years compared to the past 800,000 years. And the impact from humans. Crazy. </p><p>Measurements of the forms of carbon in the modern atmosphere show a clear fingerprint of the addition of “old” carbon coming from the combustion of fossil fuels, as opposed to “newer” carbon coming from living systems. </p><p>Furthermore, it is known that human activities, excluding land use change, currently emit an estimated 10 billion tonnes of carbon each year, mostly by burning fossil fuels, which is more than enough to explain the observed increase in concentration. </p><p><strong>These and other lines of evidence point conclusively to the fact that the elevated CO2 concentration in our atmosphere is the result of human activities.</strong></p><h2 id="climate-records-show-a-warming-trend">Climate records show a warming trend</h2><p>Estimating global average surface air temperature increase requires careful analysis of millions of measurements from around the world, including from land stations, ships, and satellites. </p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Despite the difficulty in collating the data, quite a few independent teams concluded separately (and unanimously) that global average surface air temperature has risen by about 1 degree celsius since 1900. </p><p>Although the record shows several pauses and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://st.im/thinking-about-climate-change/">https://st.im/thinking-about-climate-change/</a></em></p>]]>
            </description>
            <link>https://st.im/thinking-about-climate-change/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917809</guid>
            <pubDate>Wed, 28 Oct 2020 12:10:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Make a Calendar in LibreOffice]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24917801">thread link</a>) | @roosgit
<br/>
October 28, 2020 | https://calendartricks.com/how-to-make-a-calendar-in-libreoffice/ | <a href="https://web.archive.org/web/*/https://calendartricks.com/how-to-make-a-calendar-in-libreoffice/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>How to create a calendar template in LibreOffice Calc that can be updated dynamically with any year or month. The tutorial includes a calendar template(.ods).</p>
<p>In this post I will show you how to make an editable calendar template for LibreOffice Calc in which you can simply change the month or the year and the entire calendar gets updated.<span id="more-4"></span></p>
<p>To those who are only looking for a <a href="https://www.libreoffice.org/">LibreOffice</a> calendar template that they wish to print, simply download one of the .ods files below:</p>
<ul>
<li><a href="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-calendar-template-US-letter.ods">LibreOffice Calendar Template US Letter</a></li>
<li><a href="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-calendar-template-A4.ods">LibreOffice Calendar Template A4</a></li>
</ul>
<p>For more styles and designs check out these <a href="https://calendaroptions.com/">printable calendars (PDF)</a>.</p>
<p>Before we begin, allow me to show you the end result:</p>
<p><a title="Calendar template US letter" href="https://calendartricks.com/wp-content/uploads/2020/calendar-template.png"><img src="https://calendartricks.com/wp-content/uploads/2020/calendar-template.png" alt="Calendar template US letter"></a></p>
<p>Let’s start by making a new spreadsheet. From the menu select <strong>File</strong> -&gt; <strong>New</strong> -&gt; <strong>Spreadsheet</strong>.</p>
<p>Because we intend to make this template be printable we have to setup the printable area. In the menu go to <strong>Format</strong> -&gt; <strong>Page…</strong></p>
<p>In the “Page” tab choose the format of the paper. I went for US Letter, but you can choose another one, A4, for example, depending on which format is the most popular where you live. Next, select “Landscape” for orientation.</p>
<p>A little bit lower, you can set the margins. You can leave the default values but I opted for some more rounded values. See the following image:</p>
<p><a title="LibreOffice page settings" href="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-page-settings.png"><img src="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-page-settings.png" alt="LibreOffice page settings"></a></p>
<p>Once you click OK you should see some dashed lines in your spreadsheet. Those define the print area. We’ll come back to this later when we need to style the calendar.</p>
<p>Now let’s rename the existing sheet in our spreadsheet to “Month Calendar”. You can do that by double clicking on the tab “Sheet1”. Additionally, create a new sheet called “Settings”, similarly to what you see in the image below.</p>
<p><a title="Rename new sheet in LibreOffice Calc" href="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-rename-new-sheet.png"><img src="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-rename-new-sheet.png" alt="Rename new sheet in LibreOffice Calc"></a></p>
<p>Considering this is a dynamic template, and to avoid typos, we should define the month names. LibreOffice doesn’t have a list of month names, so we’ll need to make our own. This also means you can have the month names in another language. I’ll use English, but you can experiment with something else.</p>
<p>If you’re not in the “Settings” sheet, switch to it. In the first column start writing the month names, one below the other.</p>
<p><a title="Sheet with month names" href="https://calendartricks.com/wp-content/uploads/2020/month-names-sheet.png"><img src="https://calendartricks.com/wp-content/uploads/2020/month-names-sheet.png" alt="Sheet with month names"></a></p>
<p>Next, we’ll use this list as a drop-down. For this, select the first cell(A1) in the “Month Calendar” sheet. Then from the menu choose <strong>Data</strong> -&gt; <strong>Validity…</strong></p>
<p>In the “Validity” panel, under the “Criteria” tab, select “Cell Range” from the options for the “Allow” section. Then in the “Source” field we are going to define the range. This will be <code><strong>$Settings.$A$1:$A$12</strong></code>. Simple translation: get the cell range starting from A1 to A12 in the “Settings” sheet.</p>
<p><a title="Validity cell range in LibreOffice Calc" href="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-validity-cell-range.png"><img src="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-validity-cell-range.png" alt="Validity cell range in LibreOffice Calc"></a></p>
<p>After clicking OK you should see a button with an arrow pointing down next to the first cell. Clicking on that button should reveal the drop-down list with all the months, like in the image below.</p>
<p><a title="LibreOffice drop-down list" href="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-drop-down-list.png"><img src="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-drop-down-list.png" alt="LibreOffice drop-down list" loading="lazy"></a></p>
<p>Although it complicates things, we’ll have to start styling things. First, the month has to be larger. Choose a font you like and a size. I went with the default font, size 40. I also merged the top 3 cells to give the month more space.</p>
<p><a title="Merge cells in LibreOffice" href="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-merge-cells.png"><img src="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-merge-cells.png" alt="Merge cells in LibreOffice" loading="lazy"></a></p>
<p>Now, it’s time for a bit of math. We need to calculate the width of a day, in our case, the width of a column. So given that there are 7 days in a week we’ll use 7 columns for our calendar. This means we’ll have to divide the width of our page to 7. Let’s have a look back at our page settings. From the menu choose <strong>Format</strong> -&gt; <strong>Page…</strong></p>
<p><a title="LibreOffice page settings" href="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-page-settings.png"><img src="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-page-settings.png" alt="LibreOffice page settings" loading="lazy"></a></p>
<p>Open your calculator application. For me it’s <code><strong>(11-2*0.75)/7=1.3571</strong></code>. Note: only use the first 2 decimals, LibreOffice will round the number anyway.</p>
<p>In order to resize the columns select the first 7, and right click on the header choosing “Column Width…”. Put in the result you have from the earlier calculation (for me it was 1.35″) and hit OK.</p>
<p>Ideally, after this you should see the dashed line (print are side) after column G. To check how the document looks to the printer, you can preview it by choosing <strong>File</strong> -&gt; <strong>Print Preview</strong> from the menu.</p>
<p>Tip: click on the “Margins” item in the toolbar to see the margins of the page.</p>
<p><a title="Print preview LibreOffice" href="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-print-preview.png"><img src="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-print-preview.png" alt="Print preview LibreOffice" loading="lazy"></a></p>
<p>You might notice there is some text at the top and bottom of the page. The header and footer of the document. To remove them first exit the “Print Preview” window by pressing the Escape key or click on “Close Preview” in the toolbar. Once you are back in the spreadsheet window, go to <strong>Format</strong> -&gt; <strong>Page</strong> and then in the “Header” tab uncheck “Header on”. Do the same for the Footer.</p>
<p><a title="Hide the header in LibreOffice" href="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-disable-header.png"><img src="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-disable-header.png" alt="Hide the header in LibreOffice" loading="lazy"></a></p>
<p>According to the design of the calendar, the year is placed on the right side, at the top. So in the G1 cell write the year you want, or if you want to have the current year dynamically use this formula instead: <code><strong>=YEAR(TODAY())</strong></code>. Don’t forget to use the same font and size for the year as you did for the month.</p>
<p><a title="Current year formula in LibreOffice" href="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-current-year-formula.png"><img src="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-current-year-formula.png" alt="Current year formula in LibreOffice" loading="lazy"></a></p>
<p>We continue by writing the days of the week in the row below the month and year. In my case, the week starts on Sunday. For an example with the week starting on Monday have a look at the A4 calendar template.</p>
<p><a title="Days of the week" href="https://calendartricks.com/wp-content/uploads/2020/days-of-the-week.png"><img src="https://calendartricks.com/wp-content/uploads/2020/days-of-the-week.png" alt="Days of the week" loading="lazy"></a></p>
<p>Now that we have the top part ready, let’s get on with the rest. For that, we need to know what is the first date in our calendar. It’s not the 1st of the current month, most of the time, but one of the last days in the previous month. Once we establish that date, we simply add 1(day) to that value until we have six rows. I’ll explain why 6 rows, a bit later.</p>
<p>Let’s get back to how we’re going to get that first date. In the A3 cell we’ll start by getting the first day of the month. This is the formula I used <code><strong>=DATE(G1,MATCH(A1,$Settings.A1:A12,0),1)</strong></code>.</p>
<p>The <code><a href="https://help.libreoffice.org/7.0/en-US/text/scalc/01/func_date.html?DbPAR=CALC#bm_id3155511"><strong>DATE</strong></a></code> function has 3 parameters: year, month and day. The year we can get from G1. The month has to be a number, but all we have is January, February and so on which LibreOffice does not understand. The trick is to try and find the position of the word “January” in the month list in the “Settings” sheet. Luckily, there’s a function for that, <code><a href="https://help.libreoffice.org/7.0/en-US/text/scalc/01/04060109.html?DbPAR=CALC#bm_id3158407"><strong>MATCH</strong></a></code>, which needs the value you’re looking for(A1 in my case) and the cell range where to look for it(A1:A12 in Settings). The last parameter needs to be “0” in order to only match exact values, using “1” will give you strange results for certain months.</p>
<p><a title="First day of the month spreadsheet formula" href="https://calendartricks.com/wp-content/uploads/2020/first-day-of-the-month-formula.png"><img src="https://calendartricks.com/wp-content/uploads/2020/first-day-of-the-month-formula.png" alt="First day of the month spreadsheet formula" loading="lazy"></a></p>
<p>But putting the first day of the month in the first cell is not correct, as most months do not start on a Sunday. But it makes a good starting point.</p>
<p>By knowing the first day of the month we can get the day of the week. In my example it’s a Wednesday. The function that returns the day of week from a date is <code><a href="https://help.libreoffice.org/7.0/en-US/text/scalc/01/func_weekday.html?DbPAR=CALC#bm_id3154925"><strong>WEEKDAY</strong></a></code>. The formula is <code><strong>=WEEKDAY(DATE(G1,MATCH(A1,$Settings.A1:A12,0),1))</strong></code>. You should get a number from 1 to 7. If you don’t change the “Number Format” from “Date” to “General”.</p>
<p><a title="Day of the week spreadsheet formula" href="https://calendartricks.com/wp-content/uploads/2020/day-of-the-week-formula.png"><img src="https://calendartricks.com/wp-content/uploads/2020/day-of-the-week-formula.png" alt="Day of the week spreadsheet formula" loading="lazy"></a></p>
<p>But why do we need the weekday? The easiest way to explain it is by using a real example. In my case the first day of the month is a Wednesday. The week in my example starts on Sunday, making Wednesday the 4th day of the week. So if January 1st is a Wednesday(the 4th day), Sunday would be 3 days before(the 29th of December). Eventually, we just need to subtract 3 days from the date which is the 1st of the month. This way the formula becomes: <code><strong>=DATE(G1,MATCH(A1,$Settings.A1:A12,0),1) - (WEEKDAY(DATE(G1,MATCH(A1,$Settings.A1:A12,0),1)) - 1)</strong></code>. In practical numbers my example is 01/01 – (4 – 1).</p>
<p><a title="First day of the week spreadsheet formula" href="https://calendartricks.com/wp-content/uploads/2020/first-day-of-the-week-formula.png"><img src="https://calendartricks.com/wp-content/uploads/2020/first-day-of-the-week-formula.png" alt="First day of the week spreadsheet formula" loading="lazy"></a></p>
<p>Like mentioned earlier now we only need to add one to the previous row cell. So B3 becomes <code><strong>=A3+1</strong></code>, C3 becomes <code><strong>=B3+1</strong></code> and so on until the end of the week.</p>
<p><a title="First week" href="https://calendartricks.com/wp-content/uploads/2020/first-week.png"><img src="https://calendartricks.com/wp-content/uploads/2020/first-week.png" alt="First week" loading="lazy"></a></p>
<p>Next, we skip the 4th row. If you look at the final design, we’ll need the rows in between to leave as editable spaces. So the next cell will be A5 and we simply need to add 7 days to A3, resulting in <code><strong>=A3+7</strong></code>, <code><strong>=B3+7</strong></code> and so on until the end of the second week. Continuing with that logic, we skip the 6th, 8th, 10th and 12th rows. Also A7 will be <code><strong>=A5+7</strong></code>, B7 <code><strong>=B5+7</strong></code>… A13 <code><strong>=A11+7</strong></code>… you get it.</p>
<p>Tip: if you copy the 5th row and paste it onto the 7th row, LibreOffice will do all the work and you won’t have to type as much.</p>
<p><a title="Full month" href="https://calendartricks.com/wp-content/uploads/2020/full-month.png"><img src="https://calendartricks.com/wp-content/uploads/2020/full-month.png" alt="Full month" loading="lazy"></a></p>
<p>Things are starting to look better, but we don’t want the full date for each day. So select all the date cells and right-click on one of them. From the context menu(right-click menu) choose “<strong>Format Cells…</strong>”.</p>
<p><a title="Formatting cells in LibreOffice" href="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-format-cells.png"><img src="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-format-cells.png" alt="Formatting cells in LibreOffice" loading="lazy"></a></p>
<p>In the “Format Cells” panel, make sure the Date category is selected, it normally should be, automatically. Then in the “Format Code” text field replace the default code(MM/DD/YY) with the letter “D”(it stands for “day”). Click on the green check mark and then on OK.</p>
<p><a title="Add new format in LibreOffice" href="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-add-format.png"><img src="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-add-format.png" alt="Add new format in LibreOffice" loading="lazy"></a></p>
<p>The next step in styling requires a bit of basic math again. Just the way we had to make sure the 7 columns fit in the print area horizontally, we also need to space the rows to fit in the page vertically.</p>
<p>But before that let’s increase the font size of the days. I bumped it up to 12 and made it bold.</p>
<p>Back to the row height issue, let’s find out how tall is each row that’s not empty. To see the actual height of a row, right-click on the left header where the number is. From the context menu select “<code><strong>Row Height...</strong></code>”.</p>
<p><a title="Set row height LibreOffice" href="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-row-height.png"><img src="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-row-height.png" alt="Set row height LibreOffice" loading="lazy"></a></p>
<p>Get the height values of each row that’s not empty and add them up. For me it’s 2,28″. The page height is 8.5″. And the top and bottom margins are 0.75″ each, so 1.5″. So 8.5 – 1.5 – 2.28 = 4.72.</p>
<p>Why do we care about this number? If you take a look at the final calendar design, you’ll notice that each day number has a space below it where events can be added. So we need to calculate how tall those cells can be. We have 6 rows for the days which means we’ll have 6 rows for the events. Dividing 4.72 to 6 gives me 0.786. Given that LibreOffice only uses the first two decimals, I will settle for 0.78″ for the height of the event rows.</p>
<p><a title="Calendar without borders" href="https://calendartricks.com/wp-content/uploads/2020/calendar-no-borders.png"><img src="https://calendartricks.com/wp-content/uploads/2020/calendar-no-borders.png" alt="Calendar without borders" loading="lazy"></a></p>
<p>Things are looking much better, but we still need some borders. Select the cells like you see in the image below:</p>
<p><a title="Selected cells" href="https://calendartricks.com/wp-content/uploads/2020/selected-cells.png"><img src="https://calendartricks.com/wp-content/uploads/2020/selected-cells.png" alt="Selected cells" loading="lazy"></a></p>
<p>Then for applying a border to these cells, right-click the selection and choose “<strong>Format Cells…</strong>” from the context menu. A panel should open where the “Borders” tab is active. Pick the settings in the following screenshot:</p>
<p><a title="Setting borders in LibreOffice" href="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-set-borders.png"><img src="https://calendartricks.com/wp-content/uploads/2020/LibreOffice-set-borders.png" alt="Setting borders in LibreOffice" loading="lazy"></a></p>
<p>The “Print Preview” result looks like this:</p>
<p><a title="Calendar Print Preview" href="https://calendartricks.com/wp-content/uploads/2020/calendar-print-preview.png"><img src="https://calendartricks.com/wp-content/uploads/2020/calendar-print-preview.png" alt="Calendar Print Preview" loading="lazy"></a></p>
<p>You can leave it like this if it’s good for you, but by setting the bottom border to “none” for the days and the same for the top border for events you get a more accurate …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://calendartricks.com/how-to-make-a-calendar-in-libreoffice/">https://calendartricks.com/how-to-make-a-calendar-in-libreoffice/</a></em></p>]]>
            </description>
            <link>https://calendartricks.com/how-to-make-a-calendar-in-libreoffice/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917801</guid>
            <pubDate>Wed, 28 Oct 2020 12:09:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are we losing our ability to remember?]]>
            </title>
            <description>
<![CDATA[
Score 238 | Comments 157 (<a href="https://news.ycombinator.com/item?id=24917721">thread link</a>) | @scotthtaylor
<br/>
October 28, 2020 | https://st.im/are-we-losing-our-ability-to-remember/ | <a href="https://web.archive.org/web/*/https://st.im/are-we-losing-our-ability-to-remember/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>The other day I had a bit of a crisis, I was worried that I was starting to have trouble with my memory. Something had to be wrong! I started to notice (increasingly!) my inability to recall trivial things; for example, the action points from a Zoom call, or a quote from a book that I had read a couple of months ago. Surely this can’t be normal?</p><p>Before calling the doctor’s office I did what any decent hypochondriac would do, and started googling. After clicking through a few pages, I began to feel a bit better. It was normal. Short term (or working) memory <em>is</em> inefficient, and unless I revisit the thing I’m trying to remember a few times, I’m most likely going to forget it. And no, it’s not a side effect of turning thirty. Phew.</p><p>It’s a “feature, not a bug” of how our memory systems are designed. </p><p>Our memory is made up of not one, nor two, but three components: 1) a sensory register, 2) working memory, and 3) long-term memory.</p><p>When I look back at my childhood or I remember some basic words from French, I'm drawing on portions of my brain involved in long-term memory. But when I'm trying to hold a few ideas in mind to connect them together so I can understand a concept or solve a problem, I'm using my working memory.</p><p>With my health crisis averted, I got thinking about technology and its impact (positive and negative) on the way the brain, and memory, function. With all the knowledge I could ever need at my fingertips, alongside note taking apps and the smartphones that are now an extension of our physical being -- am I being lazy or efficient, or a mixture of the two? Much like our overactive fight-or-flight response, has evolution not had a chance to adapt or catch-up with the mind of today versus our ancestors’? </p><h3 id="four-chunks-of-information">Four chunks of information</h3><p>We ‘can’t remember’ things because there is a limit to what we can hold in our working memory. Researchers used to think that it could hold around seven items or chunks, but now it’s widely believed that the working memory only holds about four chunks of information.</p><p>If you’re anything like me you’ll have to repeat something to yourself until you have a chance to write it down. Repetitions are needed so that natural dissipating processes don’t suck the memories away. How many times have you found yourself shutting your eyes to keep other things from intruding into the limited slots of your working memory as you concentrate?</p><p>I believe that we need to offload from our working memory as soon as possible.</p><p>With the goal historically being, before computers, to move it to long-term memory. If this didn’t happen -- you’d essentially be waving goodbye to that memory. </p><p>Moving a memory from ‘working’ to ‘long-term’ takes time and practice. </p><p>There’s a steep drop in what you remember, anyway. The ‘forgetting curve’, as it’s called, is steepest during the first twenty-four hours after you learn something. Exactly how much you forget, percentage-wise, varies, but unless you review the material, much of it slips down the drain. What you remember after day one has a good chance of still being retained after thirty. </p><h3 id="spaced-repetition">Spaced repetition</h3><p>To improve retention, spaced repetition is typically used. This technique involves repeating what you're trying to retain, ensuring to space the repetition out. Repeating a new vocabulary word or a problem solving technique for example over a number of days.</p><p>The good news is, our long-term memory has room for billions of items. In fact there can be so many items they can bury each other. It can be difficult for you to find the information you need unless you practice and repeat at least a few times. This allows the synoptic connections in the brain to form and strengthen into a lasting structure.</p><p>Long-term memory is important because it's where you store fundamental concepts and techniques that are often involved in whatever you're learning about.</p><p>Having strong foundations in your long-term memory also makes the working memory more efficient, and able to connect dots from wider, more abstract, fields. It gives our thinking ‘richness’ and ‘associative access’. </p><p>Richness refers to the theory that a large number of things we have apparently forgotten all about are still there, somewhere, and add depth to our thinking. Associative access means that your thoughts can be accessed in a number of different ways by semantic or perceptual associations  — memories can be triggered by related words, by category names, by a smell, an old song or photograph, or even seemingly random neural firings that bring them up to consciousness.</p><h3 id="offloading-memory">Offloading memory</h3><p>But now, of course, we don’t bother to do all of the hard work of committing many things to our long-term memory. We have devices -- and the internet -- to remember stuff for us.</p><p>When I think back to when I started journaling on my iPad and laptop, as well as using apps like <a href="https://obsidian.md/">Obsidian</a> that are focused on ‘<a href="https://st.im/ive-become-obsessed-with-networked-thought/">networked thought</a>’, it is interesting<strong> </strong>to hypothesise how they have potentially impacted the fundamental chemistry or feedback loops in my brain. </p><p>For me, they have helped reduce my cognitive load by letting me off-load much of what goes on in my brain to an external entity. In this day and age, this recall memory has become less necessary. Recognition memory is more important (i.e. the ability to judge that a currently present object, person, place, or event, has previously been encountered or experienced).</p><p>Research has shown that the internet functions as a sort of externalised memory. “When people expect to have future access to information, they have lower rates of recall of the information itself,” <a href="https://www.ncbi.nlm.nih.gov/pubmed/21764755">as one study puts it</a>. </p><p>If you know that you ‘know’ something, and you know how to retrieve it (thank you Google) that performs pretty much the same function as having a brain stuffed with lots of long-term memories. And the new ‘networked thought’ apps allow us to make interesting connections between these various bits of stored knowledge in much the same way that a well-stocked memory does.</p><h3 id="using-our-second-brain">Using our second brain </h3><p>So I wouldn’t say we are losing our ability to remember, as I posed at the start of this post. I think people (me included) just don’t do enough work to move stuff from our working memory into our long-term memory. </p><p>Our decreased reliance on recall memory and our &nbsp;ever-decreasing attention spans may not be the disaster that I first feared.</p><p>I think that the internet and apps focused on network thinking do assist us. They do act as a second brain. And I think that &nbsp;makes us more efficient.</p><hr><p>Cover photo by <a href="https://unsplash.com/@sarandywestfall_photo?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Sarandy Westfall</a> on <a href="https://unsplash.com/s/photos/memory?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a><br>Thanks to <a href="https://jonathangifford.com/">Jonathan</a> for reading through early drafts of this post.<br>For discussion, check out this post on <a href="https://news.ycombinator.com/item?id=24917721">Hacker News</a>. &nbsp;</p>
              <section>
                <h2>Enjoying these posts? Join for more</h2>
                <a href="https://st.im/join/">Join now</a>
                <br>
                <a href="https://st.im/signin/">Already have an account? Sign in</a>
              </section>
  </div></div>]]>
            </description>
            <link>https://st.im/are-we-losing-our-ability-to-remember/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917721</guid>
            <pubDate>Wed, 28 Oct 2020 11:58:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Colour are your bits? (2004)]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24917679">thread link</a>) | @dredmorbius
<br/>
October 28, 2020 | https://ansuz.sooke.bc.ca/entry/23 | <a href="https://web.archive.org/web/*/https://ansuz.sooke.bc.ca/entry/23">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentsidewrap">
    <div id="content">
      <p>
        « <a href="https://ansuz.sooke.bc.ca/entry/22">Yon and Tinu</a> | <a href="https://ansuz.sooke.bc.ca/">Home</a> | <a href="https://ansuz.sooke.bc.ca/entry/24">Colour, social beings, and und...</a> »
      </p>    

      <h2><a href="https://ansuz.sooke.bc.ca/entry/23">What Colour are your bits?</a></h2>

      <p><span>
        Thu 10 Jun 2004 by <a href="mailto:mskala@ansuz.sooke.bc.ca" title="">mskala</a>
        Tags used:  <a rel="tag" href="https://ansuz.sooke.bc.ca/tag/colour" title="Tag: colour">colour</a>, <a rel="tag" href="https://ansuz.sooke.bc.ca/tag/copyright" title="Tag: copyright">copyright</a>, <a rel="tag" href="https://ansuz.sooke.bc.ca/tag/philosophy" title="Tag: philosophy">philosophy</a>
      </span></p><p>There's a classic adventure game called <a href="http://www.paranoia-rpg.com/players/intro.php">Paranoia</a> which is
set in an extremely <s>repressive</s> Utopian futuristic world
run by The Computer, who
is Your Friend.&nbsp; Looking at a recent <a href="http://research.yale.edu/lawmeme/modules.php?name=News&amp;file=article&amp;sid=1487">LawMeme
posting</a> and related discussion, it occurred to me that the concept of
colour-coded security clearances in Paranoia provides a good metaphor for
a lot of copyright and intellectual freedom issues, and it may illuminate
why we sometimes have difficulty communicating and understanding the
ideologies in these areas.</p>

<p><i>An article based on this one and its follow-ups, by me, Brett Bonfield,
and Mary Fran Torpey, appeared in the 15 February 2008 issue of
<a href="http://www.libraryjournal.com/article/CA6529387.html">LJ, Library
Journal</a>.</i></p>

<p>In Paranoia, everything has a colour-coded security level (from Infrared
up to Ultraviolet) and everybody has a clearance on the same scale.&nbsp; You
are not allowed to touch, or have any dealings with, anything that exceeds
your clearance.&nbsp; If you're a Red Troubleshooter, you're not allowed to
walk through an Orange door.&nbsp; Formally, you're not really supposed to even
know about the existence of anything above your clearance.&nbsp; Anyone who
breaks the rules is a Commie Mutant Traitor, subject to the death penalty.</p>

<p>Much of the game revolves around the consequences of the security levels.&nbsp;
For instance, Friend Computer might assign a team of Red Troubleshooters
to re-paint a hallway that ought to be Orange but was painted Yellow by
<s>mistake</s> the Commie Mutant Traitors.&nbsp; It's quite likely in
such a case that the Troubleshooters will all end up shooting each other
for treason against Friend Computer, since none of them are allowed to
touch the paint, go near the hallway, or talk about their mission, and
they're all charged with enforcing the rules on one another.</p>

<p>In intellectual property and some other fields we're very interested in
information, data, artistic works, a whole lot of things that I'll
summarize with the term "bits".&nbsp; Bits are all the things you can (at
least in principle) represent with binary ones and zeroes.&nbsp; And very much
of intellectual property law comes down to rules regarding intangible
attributes of bits - Who created the bits?&nbsp; Where did they come from?&nbsp;

Where are they going?&nbsp; Are they copies of other bits?&nbsp; Those questions are
perhaps answerable by "metadata", but metadata suggests to me additional
bits attached to the bits in question, and I'd like to emphasize that I'm
talking here about something that is not properly captured by bits at all
and actually cannot be, ever.&nbsp; Let's call it "Colour", because it turns
out to behave a lot like the colour-coded security clearances of the
Paranoia universe.</p>

<p>Bits do not naturally have Colour.&nbsp; Colour, in this sense, is not part of
the natural universe.&nbsp; Most importantly, you cannot look at bits and
observe what Colour they are.&nbsp; I encountered an amusing example of bit
Colour recently:&nbsp; one of my friends was talking about how he'd
performed John Cage's famous silent musical composition <i>4'33"</i> for
MP3.&nbsp; Okay, we said, (paraphrasing the conversation here) so you took an
appropriate-sized file of zeroes out of /dev/zero and compressed that with
an MP3 compressor?&nbsp; No, no, he said.&nbsp; If I did that, it wouldn't really be

<i>4'33"</i> because to perform the composition, you have to make the
silence in a certain way, according to the rules laid down by the
composer.&nbsp; It's not just four minutes and thirty-three seconds of any old
silence.</p>

<p>My friend had gone through an elaborate process that basically amounted to
performing some other piece of music four minutes and thirty-three seconds
long, with a software synthesizer and the volume set to zero.&nbsp; The result
was an appropriate-sized file of zeroes - which he compressed with an MP3
compressor.&nbsp; The MP3 file was bit-for-bit identical to one that would have
been produced by compressing /dev/zero...&nbsp; but this file was (he claimed)
legitimately a recording of <i>4'33"</i> and the other one wouldn't have
been.&nbsp; The difference was the Colour of the bits.&nbsp; He was asserting
that the bits in his copy of 433.mp3 had a different Colour from those
in a copy of 433.mp3 I might make by means of the /dev/zero procedure,
even though the two files would contain exactly the same bits.</p>

<p>Now, the preceding paragraph is basically nonsense to computer scientists
or anyone with a mathematical background.&nbsp; (My friend is one; he'd done
this as a sort of elaborate joke.)  Numbers are numbers, right?&nbsp;
If I add 39 plus 3 and get 42, and you do the same thing, there is no way
that "my" 42 can be said to be different from "your" 42.&nbsp; Given two
bit-for-bit identical MP3 files, there is no meaningful (to a computer
scientist) way to say that one is a recording of the Cage composition and
the other one isn't.&nbsp; There would be no way to test one of the files and
see which one it was, because they are actually the same file.&nbsp; Having
identical bits means by definition that there can be no difference.&nbsp; Bits
don't have Colour; computer scientists, like computers, are Colour-blind.&nbsp;
That is not a mistake or deficiency on our part:&nbsp; rather, we have worked
hard to become so.&nbsp; Colour-blindness on the part of computer scientists
helps us understand the fact that computers are also Colour-blind, and we
need to be intimately familiar with that fact in order to do our jobs.</p>

<p>The trouble is, human beings are not in general Colour-blind.&nbsp; The law is
not Colour-blind.&nbsp; It makes a difference not only what bits you have, but
where they came from.&nbsp; There's a very interesting Web page illustrating
the Coloured nature of bits in law <a href="http://aa.usno.navy.mil/faq/docs/lawyers.html">on the US Naval
Observatory Web site</a>.&nbsp; They provide information on that site about
when the Sun rises and sets and so on...&nbsp; but they also provide it under a
disclaimer saying that this information is not suitable for use in court.&nbsp;
If you need to know when the Sun rose or set for use in a court case, then
you need an expert witness - because you don't actually just need the bits
that say when the Sun rose.&nbsp; You need those bits to be Coloured with the
Colour that allows them to be admissible in court, and the USNO doesn't
provide that.&nbsp; It's not just a question of accuracy - we all know
perfectly well that the USNO's numbers are good.&nbsp; It's a question of where
the numbers came from.&nbsp; It makes perfect sense to a lawyer that where the
information came from is important, in fact maybe more important than the
information itself.&nbsp; The law sees Colour.</p>

<p>Suppose you publish an article that happens to contain a sentence
identical to one from this article, like "The law sees Colour."  That's
just four words, all of them common, and it might well occur by random
chance.&nbsp; Maybe you were thinking about similar ideas to mine and happened
to put the words together in a similar way.&nbsp; If so, fine.&nbsp; But maybe you
wrote "your" article by cutting and pasting from "mine" - in that case,
the words have the Colour that obligates you to follow quotation
procedures and worry about "derivative work" status under copyright law
and so on.&nbsp; Exactly the same words - represented on a computer by the same
bits - can vary in Colour and have differing consequences.&nbsp; When you
use those words without quotation marks, either you're an author or a
plagiarist depending on where you got them, even though they are the
same words.&nbsp; It matters where the bits came from.</p>

<p>I think Colour is what the designers of <a href="http://monolith.sourceforge.net/">Monolith</a> are trying to
challenge, although I'm afraid I think their understanding of the
issues is superficial on both the legal and computer-science sides.&nbsp; The
idea of Monolith is that it will mathematically combine two files with the
exclusive-or operation.&nbsp; You take a file to which someone claims
copyright, mix it up with a public file, and then the result, which is
mixed-up garbage supposedly containing no information, is supposedly free
of copyright claims even though someone else can later undo the mixing
operation and produce a copy of the copyright-encumbered file you started
with.&nbsp; Oh, happy day!&nbsp; The lawyers will just have to all go away now,
because we've demonstrated the absurdity of intellectual property!</p>

<p>The fallacy of Monolith is that it's playing fast and loose with Colour,
attempting to use legal rules one moment and math rules another moment as
convenient.&nbsp; When you have a copyrighted file at the start, that file
clearly has the "covered by copyright" Colour, and you're not cleared for
it, Citizen.&nbsp; When it's scrambled by Monolith, the claim is that the
resulting file has no Colour - how could it have the copyright Colour?&nbsp;
It's just random bits!&nbsp; Then when it's descrambled, it still can't have
the copyright Colour because it came from public inputs.&nbsp; The problem is
that there are two conflicting sets of rules there.&nbsp; Under the lawyer's
rules, Colour is not a mathematical function of the bits that you can
determine by examining the bits.&nbsp; <i>It matters where the bits came
from.</i> The scrambled file still has the copyright Colour because it
came from the copyrighted input file.&nbsp; It doesn't matter that it looks
like, or maybe even is bit-for-bit identical with, some other file that
you could get from a random number generator.&nbsp; It happens that you didn't
get it from a random number generator.&nbsp; You got it from copyrighted
material; it is copyrighted.&nbsp; The randomly-generated file, even if
bit-for-bit identical, would have a different Colour.&nbsp; The Colour inherits
through all scrambling and descrambling operations and you're distributing
a copyrighted work, you Commie Mutant Traitor.</p>

<p>To a computer scientist, on the other hand, bits are bits are bits and it
is absolutely fundamental that two identical chunks of bits cannot be
distinguished.&nbsp; Colour does not exist.&nbsp; I've seen computer people claim
(indeed, one did this to me just today in the very discussion that
inspired this posting) that copyright law …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ansuz.sooke.bc.ca/entry/23">https://ansuz.sooke.bc.ca/entry/23</a></em></p>]]>
            </description>
            <link>https://ansuz.sooke.bc.ca/entry/23</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917679</guid>
            <pubDate>Wed, 28 Oct 2020 11:53:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Bad Parts]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24917651">thread link</a>) | @elorm
<br/>
October 28, 2020 | https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1 | <a href="https://web.archive.org/web/*/https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><i>See a typo? Have a suggestion?
<a target="_blank" rel="nofollow" href="https://github.com/snoyberg/snoyman.com/edit/master/content/posts/haskell-bad-parts-1.md">Edit this page on Github</a>
</i>
</p>
<p>There’s a popular book called “JavaScript: The Good Parts.” And there’s a common meme around the relative size of that book versus “JavaScript: The Definitive Guide.”</p>
<p><img src="https://i.imgur.com/wIf3EJh.jpg"></p><p>Haskell is in my opinion a far more well designed and coherent language than JavaScript. However, it’s also an old language with some historical baggage. And in many ways it’s a bleeding edge research language that sometimes includes… half-baked features. And due to an inconsistent set of rules around backwards compatibility, it sometimes will break code every six months, and sometimes keep strange decisions around for decades.</p>
<blockquote><div lang="en" dir="ltr"><p>True mastery of Haskell comes down to knowing which things in core libraries should be avoided like the plague.</p><p>* foldl<br>* sum/product<br>* Data.Text.IO<br>* Control.Exception.bracket (use unliftio instead, handles interruptible correctly)</p><p>Just as some examples</p></div>— Michael Snoyman (@snoyberg) <a href="https://twitter.com/snoyberg/status/1321049221697544193?ref_src=twsrc%5Etfw">October 27, 2020</a></blockquote> 
<p>After a request and some tongue-in-cheek comments in that thread, I decided a longer form blog post was in order. I’m going to start off by expanding on the four examples I gave in that tweet. But there are many, many more examples out there. If there’s more interest in seeing a continuation of this series, please let me know. And if you have pet peeves you’d like me to address, input will be very welcome.</p>
<h2>What is a “bad part”</h2>
<p>Very rarely is there such a thing as a language feature, function, type, or library that is so egregiously bad that it should never, ever be used. Null is of course the billion dollar mistake, but it’s still incredibly useful in some cases. So when I say that something is a “bad part” of Haskell, I mean something along these lines:</p>
<ul>
<li>A rarely-useful feature has been promoted to a position of prominence</li>
<li>A function has major downsides that are not documented</li>
<li>There’s an unexpected performance implication</li>
</ul>
<p>There’s a large tendency in the Haskell community to be overly literal in responding to blog posts. Feel free to do that to your heart’s content. But this caveat serves as a word of warning: I’m not going to caveat each one of these with an explanation of “yes, but there’s this one corner case where it’s actually useful.”</p>
<h2>Why attack Haskell?</h2>
<p>Since I’m a Haskeller and advocate of the language, you may be wondering: why am I attacking Haskell? I don’t see this as an attack. I <em>do</em> wish we could fix these issues, and I think it’s a fair thing to say that the problems I’m listing are warts on the language. But every language has warts. I’m writing this because I’ve seen these kinds of things break real world projects. I’ve seen these failures manifest at runtime, defeating yet again the false claim that “if it compiles it works.” I’ve seen these become nefarious time bombs that disincentivize people from ever working with Haskell in the future.</p>
<p>I hope by calling these out publicly, I can help raise awareness of these problems. And then, either we can fix the problems at their source or, more likely, get more widespread awareness of the issue.</p>
<p>Also, because it feels appropriate, I’m going to take a more jovial tone below. I personally find it easier to beat up on a language I love like that.</p>
<h2>foldl</h2>
<p>Duncan Coutts <a href="https://www.well-typed.com/blog/2014/04/fixing-foldl/">already did this one</a>. <code>foldl</code> is broken. It’s a bad function. Left folds are supposed to be strict, not lazy. End of story. Goodbye. Too many space leaks have been caused by this function. We should gut it out entirely.</p>
<p>But wait! A lazy left fold makes perfect sense for a <code>Vector</code>! Yeah, no one ever meant that. And the problem isn’t the fact that this function exists. It’s the <strong>name</strong>. It has taken the hallowed spot of the One True Left Fold. I’m sorry, the One True Left Fold is strict.</p>
<p>Also, side note: we can’t raise linked lists to a position of supreme power within our ecosystem and then pretend like we actually care about vectors. We don’t, we just pay lip service to them. Until we fix the wart which is overuse of lists, <code>foldl</code> is only ever used on lists.</p>
<p>OK, back to this bad left fold. This is all made worse by the fact that the true left fold, <code>foldl'</code>, is not even exported by the <code>Prelude</code>. We Haskellers are a lazy bunch. And if you make me type in <code>import Data.List (foldl')</code>, I just won’t. I’d rather have a space leak than waste precious time typing in those characters.</p>
<p>Alright, so what should you do? Use an alternative prelude that doesn’t export a bad function, and does export a good function. If you really, really want a lazy left fold: add a comment, or use a function named <code>foldlButLazyIReallyMeanIt</code>. Otherwise I’m going to fix your code during my code review.</p>
<h2>sum/product</h2>
<p>The <code>sum</code> and <code>product</code> functions are implemented in terms of <code>foldr</code>. Well, actually <code>foldMap</code>, but list’s <code>foldMap</code> is implemented in terms of <code>foldr</code>, and lists are the only data structure that exist in Haskell. “Oh, but <code>foldr</code> is the good function, right?” Only if you’re folding a function which is lazy in its second argument. <code>+</code> and <code>*</code> are both strict in both of their arguments.</p>
<p>If you’re not aware of that terminology: “strict in both arguments” means “in order to evaluate the result of this function/operator, I need to evaluate both of its arguments.” I can’t evaluate <code>x + y</code> without knowing what <code>x</code> and <code>y</code> are. On the other hand, <code>:</code> (list cons) is lazy in its second argument. Evaluating <code>x : y</code> doesn’t require evaluating <code>y</code> (or, for that matter, <code>x</code>). (For more information, see <a href="https://www.fpcomplete.com/haskell/tutorial/all-about-strictness/">all about strictness</a>.)</p>
<p>“But wait!” you say. “What if I have a custom data type with a custom typeclass instance of <code>Num</code> that has a custom <code>+</code> and/or <code>*</code> that is in fact lazy in the second argument! Then <code>sum</code> and <code>product</code> are perfect as they are!”</p>
<p>That’s true. Now go off and write your own <code>lazySum</code> and <code>lazyProduct</code>. 99 times out of 100, or more likely 999,999 times out of 1,000,000, we want the fully strict version.</p>
<p>“But it doesn’t matter, GHC will optimize this away.” Maybe. Maybe not. Stop relying on GHC’s optimizer to convert horribly inefficient code into not efficient code. (But I digress, we’ll talk about why the <code>vector</code> package is bad another time.)</p>
<h2>Data.Text.IO</h2>
<p>I’ve already covered this one once before when I told everyone to <a href="https://www.snoyman.com/blog/2016/12/beware-of-readfile">beware of <code>readFile</code></a>. In that blog post, I talk about a bunch of <code>String</code> based I/O functions, especially the titular <code>readFile</code>, which is obnoxiously exported by <code>Prelude</code>. Those are bad, and I’ll reiterate why in a second. But <code>Data.Text.IO</code> is arguably far worse. The reason is that there’s pretty good awareness in the community that <code>String</code>-based I/O is bad. Even though the <code>String</code> part is the least of our worries, it does a good job of scaring away the uninitiated.</p>
<p>But <code>Data.Text.IO</code> is a wolf in sheep’s clothing. We’re all told by people who think they can tell people how to write their Haskell code (<em>cough</em> me <em>cough</em>) that we should exorcise <code>String</code> from our codebases and replace it in all cases with <code>Text</code>. Attacking the <code>Text</code> type is a topic for another time. But the problem is that by cloaking itself in the warm embrace of <code>Text</code>, this module claims more legitimacy than it deserves.</p>
<p>The only module worse in this regard is <code>Data.Text.Lazy.IO</code>, which should be buried even deeper.</p>
<p>OK, what exactly am I on about? Locale sensitive file decoding. It’s possible that this has been the number one example of a Haskell bug in the wild I’ve encountered in my entire career. Not the spooky memory leak. Partial functions like <code>head</code> randomly throwing exceptions are up there, but don’t quite rise to prominence.</p>
<p>You see, when you are dealing with file formats, there is typically an actual, defined format. YAML, XML, JSON, and many others give a lot of information about how to serialize data, including character data, into raw bytes. We want to be consistent. We want to write a file in one run of the program, and have it read in a separate run. We want to write the file on a Windows machine and read it on a Linux machine. Or we want to interact with programs in other languages that read or write data in a consistent format.</p>
<p>Locale sensitive file encoding and decoding laughs in our face. When you use <code>Data.Text.IO.readFile</code>, it plays a mind reading game of trying to deduce from clues you don’t care about which character encoding to use. These days, on the vast majority of systems used by native English speakers, this turns out to be UTF-8. So using <code>readFile</code> and <code>writeFile</code> typically “just works.” Using functions from <code>Data.Text.IO</code> looks safe, and can easily get hidden in a large PR or a library dependency.</p>
<p>That’s when all hell breaks loose. You ship this code. You run it in a Docker container. “Oops, you forgot to set the <code>LANG</code> env var, Imma crash.” But it’s worse than that. Typically things will work well for weeks or months, because it can often be a long time before someone tries to encode a non-ASCII character.</p>
<p>The same kind of thing happens regularly to Stack. Someone adds a new feature that writes and reads a file. The code passes all integration tests. And then someone in Russia with a weird Windows code page set and a Cyrillic character in their name files a bug report 2 years later about how they can’t build anything, and we sheepishly tell them to run <code>chcp 65001</code> or build in <code>c:\</code>.</p>
<p>Friends don’t let friends use <code>Data.Text.IO</code>.</p>
<p>“Oh, but <code>putStrLn</code> is fine!” Yeah, maybe. It’s also potentially slow. And it will throw a runtime exception due to character encoding mismatches. Just use a good logging library. That’s why we have one in <code>rio</code>.</p>
<p><strong>EDIT</strong> Since so many people have asked: instead of <code>readFile</code>, I recommend using <a href="https://www.stackage.org/haddock/lts-16.20/rio-0.1.19.0/RIO.html#v:readFileUtf8"><code>readFileUtf8</code></a>, which is available from <a href="https://github.com/commercialhaskell/rio"><code>rio</code></a>.</p>
<h2>Control.Exception.bracket</h2>
<p>This is by far the least objectionable of the bad things in this list. I included it because the entire original tweet was inspired by a coworker telling me about a bug he ran into because of this function.</p>
<p>Async exceptions are subtle. Very, very subtle. Like, super duper subtle. I’ve devoted a large percentage to my Haskell teaching career towards them. Async exceptions are a concept that don’t truly exist in most other languages. They require rewiring the way your brain works for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1">https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1</a></em></p>]]>
            </description>
            <link>https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917651</guid>
            <pubDate>Wed, 28 Oct 2020 11:48:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Limits of Correctness in Computers (1985) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24917644">thread link</a>) | @vestingz
<br/>
October 28, 2020 | https://student.cs.uwaterloo.ca/~cs492/11public_html/p18-smith.pdf | <a href="https://web.archive.org/web/*/https://student.cs.uwaterloo.ca/~cs492/11public_html/p18-smith.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://student.cs.uwaterloo.ca/~cs492/11public_html/p18-smith.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917644</guid>
            <pubDate>Wed, 28 Oct 2020 11:47:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Useful Shell Prompt]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24917583">thread link</a>) | @todsacerdoti
<br/>
October 28, 2020 | https://solovyov.net/blog/2020/useful-shell-prompt/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/useful-shell-prompt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>There are only a few apps I use every day and shell — ZSH — is one of the most used. It’s been that way since the beginning of the ’00s and back then I spent a lot of time configuring my prompt to be a good balance between compact/readable and useful. I found that I dislike fancy two-line prompts, information on a right-hand side (because of its awkward behavior), and stuff like that. So the result looks like that:</p>
<pre><code>piranha@rigel ~&gt; █
</code></pre>
<p>where <code>█</code> is a cursor. It shows username, <code>@</code> to separate it from hostname - or <span><code>#</code></span> if this is uid 0 shell, then hostname, and a home-abbreviated path. One of the fancy things is that space before the cursor is Unicode glyph <code>\u00A0</code> - non-breaking space - which is bound in ZLE to delete everything to the beginning of a line. Unfortunately, this does not work with Terminal.app, so it just sits there waiting for a better time. This setup along with colors had no changes for over a decade.</p>
<p>But a week ago a saw a <a href="https://twitter.com/thingskatedid/status/1316081732467081217">tweet</a> with an idea to change prompt’s prompt (the <code>&gt;</code> thingie) to a red color when previous command exited with an error status. This motivated me to cleanup and update my prompt to a newer conventions. This is a result:</p>
<p><img alt="prompt screenshot" src="https://solovyov.net/media/prompt.jpg" height="60px" width="127px"></p>
<p>You can see I removed my username since it really gives me no information, no reason to spend space on that. I also really like white background, but if you don’t, changing colors is easy — I’ll explain how everything works.</p>
<p>Let’s break down it bit by bit. The prompt syntax is a little hard on the eyes - in case if you have ideas on how to write this so next time I won’t have to dig deep into ZSH documentation, I’ll be glad to listen.</p>
<pre><code>p_at='%(!.%F{red}%B#%b%f.@)'
</code></pre>
<p>In this case, few things are interesting:</p>
<ul>
<li><code>%(x.if-true.if-false)</code> construct (documented <a href="http://zsh.sourceforge.net/Doc/Release/Prompt-Expansion.html#Conditional-Substrings-in-Prompts">here</a>) shows either <code>@</code> if I’m a normal user or a red <span><code>#</code></span> if I’m a root.</li>
<li><code>!</code> there means “True if the shell is running with privileges”.</li>
<li>You can clearly see <code>@</code> after the second dot, but what does <code>%F{red}%B#%b%f</code> mean? <code>%B</code> means “start bold”, <code>%b</code> means “end bold”.</li>
<li><code>%F</code>/<code>%f</code> duo is “start/stop color” - it can either accept old-style color numbers (where 1 is red) or color names, which is easier to understand.</li>
</ul>
<pre><code>p_host='%F{blue}%m%f'
p_path='%F{blue}%~%f'
</code></pre>
<p>Those are easy to understand, just refer to <a href="http://zsh.sourceforge.net/Doc/Release/Prompt-Expansion.html">documentation</a> — <code>%m</code> is a hostname before the first dot, <code>%~</code> is a path where <code>$HOME</code> is abbreviated to <code>~</code>.</p>
<pre><code>p_pr='%(?.%F{blue}.%F{red})&gt;%f'
</code></pre>
<p>This is a new part. <code>?</code> means “True if exit status of the last command was 0”. So if a command exited nicely (with a status code 0), then it’s going to be blue <span><code>&gt;</code></span>, in other case it’s going to be red <span><code>&gt;</code></span>. Voila! :-)</p>
<p>End result looks like this:</p>
<pre><code>p_at='%(!.%F{red}%B#%b%f.@)'
p_host='%F{blue}%m%f'
p_path='%F{blue}%~%f'
p_pr='%(?.%F{blue}.%F{red})&gt;%f'

PS1="$p_at$p_host $p_path$p_pr "
unset p_at p_host p_path p_pr
</code></pre>
<p>You can see I’m unsetting color in every variable and unset those variables — cleaning up after yourself is a valuable habit, especially with a shell. :-)</p>
<p>I’m pretty sure the same could be done for bash (or tclsh, or whatever), but I’m not using it so… If anybody wants to contribute a similar configuration for other shells, I’ll gladly link to a post or add it here.</p>
</div></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/useful-shell-prompt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917583</guid>
            <pubDate>Wed, 28 Oct 2020 11:37:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ADS1115: Analog-to-Digital Converter for Arduino]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24917550">thread link</a>) | @Gedxx
<br/>
October 28, 2020 | https://www.oshardware.net/ads1115/ | <a href="https://web.archive.org/web/*/https://www.oshardware.net/ads1115/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			<p><img src="https://www.oshardware.net/wp-content/uploads/2020/06/ads1115.jpg" alt="ADS1115" width="1200" height="600" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%20600'%3E%3C/svg%3E" data-lazy-src="https://www.oshardware.net/wp-content/uploads/2020/06/ads1115.jpg"></p>
<p>For those projects where a conversion from analog to digital signal is needed, and the microcontroller used does not have this capability, it is interesting to have this type of <strong> module ADS1115</strong>, which provides this ADC conversion capability with 16-bit accuracy.</p>
<p>Furthermore, this electronic component may also be interesting to extend the <strong> conversion capabilities</strong>, even if the microcontroller you are using for your project has such capability but you need something else.</p>

<h2><span id="AD_and_DA_converters"><span id="more-680"></span><br>
A/D and D/A converters</span></h2>
<p>There are two types of fundamental signal converters, but there are also other chips capable of doing both types of conversion at the same time. These are:</p>
<ul>
<li><strong>CAD (Analog to Digital Converter) or ADC (Analog to Digital Converter):</strong> is a type of device that converts the analog signal into a digital signal. To do this, you can use a binary code that encodes the analog signal. For example, associating a binary value to a specific voltage or current value. For example, with 4-bit resolution can go from 0000 to 1111, and could correspond to 0v and 12v respectively. Although if you use a sign bit you can measure negative and positive values.</li>
<li><strong>CDA (Digital-to-Analog Converter) or DAC (Digital-to-Analog Converter):</strong> it is a device that does the opposite to the above, that is, it transforms binary data into an analog current or voltage signal.</li>
</ul>
<p><img src="https://www.oshardware.net/wp-content/uploads/2020/06/conversor-analogico-digital.jpg" alt="" width="1200" height="600" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%20600'%3E%3C/svg%3E" data-lazy-src="https://www.oshardware.net/wp-content/uploads/2020/06/conversor-analogico-digital.jpg"></p>
<p>With these converters it is possible to pass from one type of signal to another, as you will see in the case of the <strong>ADS1115</strong>, which would correspond to the first case.</p>
<h2><span id="About_the_ADS1115">About the ADS1115</span></h2>
<p><img src="https://www.oshardware.net/wp-content/uploads/2020/06/pinout-ads1115.jpg" alt="pinout ADS1115" width="1200" height="664" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%20664'%3E%3C/svg%3E" data-lazy-src="https://www.oshardware.net/wp-content/uploads/2020/06/pinout-ads1115.jpg"></p>
<p>The ADS1115 is a signal converter module. What it does is <strong>convert from analogue to digital</strong>. You may think that the <a href="https://www.oshardware.net/arduino/">Arduino development</a> board itself already includes internal ADCs to be able to do this task when using the analog inputs and that they can be compatible with the microcontroller signals.</p>
<p>Yes, that’s right, they have 6 10-bit resolution ADCs in the UNO, Mini and <a href="https://www.oshardware.net/arduino-nano/">Nano</a>. But with the ADS1115 you add another one with a 16-bit resolution, higher than the Arduino one, plus you can free the Arduino shell. Fifteen of them are for the measurement and one last bit for the sign of the analog signal, because as you know, the analog signal can be negative or positive.</p>
<p>In addition, this module provides everything you need to make it very simple to use. To connect it to your Arduino you can <a href="https://www.oshardware.net/arduino-i2c-bus/">use the I2C</a><a>, so <strong> is really simple</strong>. It even includes a pin marked ADDR with which you can select one of the 4 addresses available for this component.</a></p>
<p>On the other hand, you have to understand that the ADS1115 has two measurement modes, one is <strong>the differential and the other the single ended:</strong></p>
<ul>
<li><strong>Differential:</strong> it uses two ADCs for each measurement, reducing the number of channels to 2, but it brings a clear advantage, which is that it can measure negative voltages and is not as vulnerable to noise.</li>
<li><strong>Single ended:</strong> it has four channels as it does not use both as in the previous case. Each of the channels is 15-bit.</li>
</ul>
<p>Besides those modes, it includes a comparator mode in which an alert is generated through the<strong> ALRT</strong> pin when any of the channels exceeds a threshold value that can be configured in the source code of the sketch.</p>
<p>If you want to make <strong> measurements below 5v</strong>, but with higher accuracies, you should know that the ADS1115 has a PGA that can adjust the voltage gain from 6.144v to 0.256v. Always keeping in mind that the maximum voltage that can be measured in any case will be the supply voltage used (5v).</p>
<h3><span id="Pinout_and_datasheet">Pinout and datasheet</span></h3>
<p>If you want to see all the technical details of the ADS1115 to know its limits at the electronic level or the conditions under which it can work according to the manufacturer’s recommendations, you can use the datasheets that you can find on the network. For example, you can download this from <a href="https://cdn-shop.adafruit.com/datasheets/ads1115.pdf">TI (Texas Instruments)</a></p>
<p>For <strong> the pinout</strong> and connection, previously I have already commented something about the ALRT signal that includes also about ADDR. But it has other pins that you must also know for a correct integration with your Arduino board or for any other case. The pins available in the ADS1115 module are:VDD: 2v to 5.5v power supply. You can power it by connecting it to 5v from your Arduino board.</p>
<ul>
<li>GND: ground that you can connect to GND of your Arduino board.</li>
<li>SCL and SDA: communication pins for the I2C. In this case they should go to the appropriate pins according to your Arduino model.</li>
<li>ADDR: steering pin. By default it is connected to GND, which results in the address 0x48, but you can choose other addresses:
<ul>
<li>Connected to GND = 0x48</li>
<li>Connected to VDD = 0x49</li>
<li>Connected to SDA = 0x4A</li>
<li>Connected to SCL = 0x4B</li>
</ul>
</li>
<li>ALRT: alert pin</li>
<li>A0 to A3: analog pins</li>
</ul>

<p>If you want to use <strong>single end</strong> you can connect the analog current or voltage you want to measure between GND and one of the 4 analog pins available.<br>
<img src="https://www.oshardware.net/wp-content/uploads/2020/06/arduino-uno-ads1115.jpg" alt="Arduino diagram ADS1115" width="1200" height="600" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%20600'%3E%3C/svg%3E" data-lazy-src="https://www.oshardware.net/wp-content/uploads/2020/06/arduino-uno-ads1115.jpg"></p>
<p>As an example of connection in the case of <strong>a differential reading mode</strong>, you can see the previous image. In it, batteries of 1.5 are used in series, adding 3v that are connected between A0 and A1 in this case so that the Arduino board can measure through the <a href="https://www.oshardware.net/arduino-i2c-bus/">I2C the values</a> obtained of voltage in each moment. Obviously, you can use any other signal to measure, in this case it is a battery, but it can be whatever you want…</p>
<h3><span id="Where_to_buy_the_ADS1115">Where to buy the ADS1115?</span></h3>
<p><img src="https://www.oshardware.net/wp-content/uploads/2020/06/ads1115-modulo.jpg" alt="ADS1115 módulo" width="1200" height="600" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%20600'%3E%3C/svg%3E" data-lazy-src="https://www.oshardware.net/wp-content/uploads/2020/06/ads1115-modulo.jpg"></p>
<p>If you want to buy the ADS1115, you should know that you have modules ready to integrate with Arduino for quite cheap prices. You can find them in many electronics stores, as well as on eBay, Aliexpress and Amazon. For example:</p>
<ul>
<li><a href="https://www.amazon.com/dp/B07DFX9Q4G?tag=oshardaware-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Pack of 2 modules ADS1116" target="_blank" rel="nofollow" data-aawp-product-id="B07DFX9Q4G" data-aawp-product-title="JZK 2 x CJMCU-ADS1115 Mini 16 Byte Precision Analog-to-Digital Converter ADC Development Board Module">Pack of 2 modules ADS1116</a></li>
<li></li>
</ul>
<h2 id="pac-technical-details"><span id="Integration_with_Arduino">Integration with Arduino</span></h2>
<p><img src="https://www.oshardware.net/wp-content/uploads/2018/04/IDE-Arduino.png" alt="Screenshot of Arduino IDE" width="830" height="466" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20830%20466'%3E%3C/svg%3E" data-lazy-src="https://www.oshardware.net/wp-content/uploads/2018/04/IDE-Arduino.png"></p>
<p>To start, first install the corresponding library in your Arduino IDE. To do this, you can use the most famous one, <a href="https://github.com/adafruit/Adafruit_ADS1X15" target="_blank" rel="noopener noreferrer">Adafruit</a>. To do this, you can follow these steps:</p>
<ol>
<li>Open Arduino IDE</li>
<li>Go to the Sketch menu</li>
<li>Then to Include Library</li>
<li>Manage libraries</li>
<li>In the search engine you can search Adafruit ADS1X15</li>
<li>Click on Install</li>
</ol>
<p>Now you are ready to start, you can access the code of the installed library or the examples available at</p>
<ol>
<li>Open Arduino IDE</li>
<li>Go to Archive</li>
<li>Examples</li>
<li>And in the list look for those of this library…</li>
</ol>
<p>Among the examples you will see both for the <strong>comparator mode, differential mode and single end</strong> mode. You can see the examples to start using them and modify them according to your needs or write more complex code. For more information, I recommend our free introduction course in PDF.</p>
		</div></div>]]>
            </description>
            <link>https://www.oshardware.net/ads1115/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917550</guid>
            <pubDate>Wed, 28 Oct 2020 11:30:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neon – a lightweight component library for VueJs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24917464">thread link</a>) | @aotearoan
<br/>
October 28, 2020 | https://aotearoan.github.io/neon/ | <a href="https://web.archive.org/web/*/https://aotearoan.github.io/neon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://aotearoan.github.io/neon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917464</guid>
            <pubDate>Wed, 28 Oct 2020 11:15:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bulgaria accepts controvertial carpooling law]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24917439">thread link</a>) | @xswordsx
<br/>
October 28, 2020 | https://www.24chasa.bg/novini/article/9163984 | <a href="https://web.archive.org/web/*/https://www.24chasa.bg/novini/article/9163984">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text">
                <div>
                    <div>
                        <div>
                                    <a itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject" href="https://cache2.24chasa.bg/Images/Cache/996/Image_9163996_126.jpg" onclick="fnArticleGalleryLoad(9163996);return false;">
                                        <img itemprop="url" content="https://cache1.24chasa.bg/Images/Cache/996/Image_9163996_1226.jpg" src="https://cache2.24chasa.bg/Images/Cache/996/Image_9163996_126.jpg" width="400" height="267" alt="Депутатите в зала СНИМКА: Архив">
                                        <meta itemprop="width" content="650">
                                        <meta itemprop="height" content="433">
                                    </a>
                        </div>
                        <ul id="galery-list">
                        </ul>
                    </div>
                    <p>Депутатите в зала СНИМКА: Архив</p>
                </div>
            <p><span itemprop="articleBody">


<p>До 10 години затвор за нелегален обществен превоз на пътници. Това решиха депутатите след като приеха на второ четене промени в Назакателния кодекс, който бяха записани в заключителните разпоредби на Кодекса на търговското корабоплаване.</p><p>За обществен превоз на пътници без разрешение, регистрация или лиценз, законът предвижда затвор от 2 до 5 години, а моторното превозно средство се отнема в полза на държавата.</p>


<p>Когато нелегално се превозват две или повече лица, тогава наказанието е лишаване от свобода от 5 до 10 години и глоба от 5 до 15 хил.лв., като съдът може да постанови и конфискация до една втора от имуществото на виновния, записаха още депутатите.</p><p>Промените породиха дебат в зала дали с така записаните поправки ще се постигне ограничаване на нелегалните обществени превози, както и дали е правилно чрез заключителни разпоредби на друг закон да се променя Наказателния кодекс, без промените да са минали през правна комисия. В крайна сметка обаче бяха приети.</p>            </span></p>
                
                
                
            


            
        </div></div>]]>
            </description>
            <link>https://www.24chasa.bg/novini/article/9163984</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917439</guid>
            <pubDate>Wed, 28 Oct 2020 11:12:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Design a DI-Friendly Framework]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24917398">thread link</a>) | @fagnerbrack
<br/>
October 28, 2020 | https://blog.ploeh.dk/2014/05/19/di-friendly-framework/ | <a href="https://web.archive.org/web/*/https://blog.ploeh.dk/2014/05/19/di-friendly-framework/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
  <p>
    <em>How to create a Dependency Injection-friendly software framework.</em>
  </p>
  <p>
    It seems to me that every time a development organisation wants to add 'Dependency Injection support' to a framework, all too often, the result is a <a href="https://blog.ploeh.dk/2014/05/19/conforming-container">Conforming Container</a>. In this article I wish to describe good alternatives to this anti-pattern.
  </p>
  <p>
    In a previous article I covered <a href="https://blog.ploeh.dk/2014/05/19/di-friendly-library">how to design a Dependency Injection-friendly library</a>; in this article, I will deal with frameworks. The <a href="http://stackoverflow.com/a/2190658/126014">distinction I usually make</a> is:
    </p><ul>
      <li>A <strong>Library</strong> is a reusable set of types or functions you can use from a wide variety of applications. The application code initiates communication with the library and invokes it.</li>
      <li>A <strong>Framework</strong> consists of one or more libraries, but the difference is that <a href="http://stackoverflow.com/a/3227404/126014">Inversion of Control</a> applies. The application registers with the framework (often by implementing one or more interfaces), and the framework calls into the application, which may call back into the framework. A framework often exists to address a particular general-purpose Domain (such as web applications, mobile apps, workflows, etc.).</li>
    </ul><p>
    In my article about the <a href="https://blog.ploeh.dk/2014/05/19/conforming-container">Conforming Container anti-pattern</a>, I already covered some general reason why attempting to create an abstraction over DI Containers is a bad idea, but when it comes to frameworks, some extra concerns arise.
  </p>
  <h3 id="15b8d9b2820a4ad698061c92d42f0ddd">
    The composition challenge <a href="#15b8d9b2820a4ad698061c92d42f0ddd" title="permalink">#</a>
  </h3>
  <p>
    One of the most challenging aspects of writing a framework is that the framework designers can't predict what users will want to do. Often, a framework defines a way for you to interact with it:
    </p><ul>
      <li>Implement an interface</li>
      <li>Derive from a base class</li>
      <li>Adorn your classes or methods with a particular attribute</li>
      <li>Name your classes according to some naming convention</li>
    </ul><p>
    Common for all these approaches is, however, that the user of the framework develops some classes, and the framework then has to create instances of those classes. Obviously, the framework doesn't know anything about custom user classes, so it'll need some way of creating those instances.
  </p>
  <p>
    <img src="https://blog.ploeh.dk/content/binary/framework-sequence-diagram.png" alt="Framework sequence diagram">
  </p>
  <p>
    Once the framework has an instance of the custom user class, it can easily start using it by invoking methods defined by the interface the class implements, etc. The difficult part is creating the instance. By default, most frameworks require that a custom class has a default (parameterless) constructor, but <a href="https://blog.ploeh.dk/2011/05/30/DesignSmellDefaultConstructor">that may be a design smell</a>, and doesn't fit with the Constructor Injection pattern. Such a requirement is a sensible default, but isn't Dependency Injection-friendly; in fact, it's an example of the Constrained Construction anti-pattern, which you can read about in <a href="http://amzn.to/12p90MG">my book</a>.
  </p>
  <p>
    Most framework designers realize this and resolve to add Dependency Injection support to the framework. Often, in the first few iterations, they get it right!
  </p>
  <h3 id="e7496d9d45cd4140a8fd60729068cef4">
    Abstractions and ownership <a href="#e7496d9d45cd4140a8fd60729068cef4" title="permalink">#</a>
  </h3>
  <p>
    If you examine the sequence diagram above, you should realize one thing: the framework is the <em>client</em> of the custom user code; the custom user code provides the services for the framework. In most cases, the custom user code exposes itself as a service to the framework. Some examples may be in order:
    </p><ul>
      <li>In ASP.NET MVC, user code implements the <a href="http://msdn.microsoft.com/en-us/library/system.web.mvc.icontroller.aspx">IController</a> interface, although this is most commonly done by deriving from the abstract <a href="http://msdn.microsoft.com/en-us/library/system.web.mvc.controller.aspx">Controller</a> base class.</li>
      <li>In ASP.NET Web API, user code implements the <a href="http://msdn.microsoft.com/en-us/library/system.web.http.controllers.ihttpcontroller.aspx">IHttpController</a> interface, although this is most commonly done by deriving from the abstract <a href="http://msdn.microsoft.com/en-us/library/system.web.http.apicontroller.aspx">ApiController</a> class.</li>
      <li>In Windows Presentation Foundation, user code derives from the <a href="http://msdn.microsoft.com/en-us//library/System.Windows.Window.aspx">Window</a> class.</li>
    </ul><p>
    The framework code doesn't know anything about custom user classes, but when they implement the appropriate interface, the framework talks to those interfaces.
  </p>
  <p>
    There's an extremely important point hidden here: although it looks like a framework has to deal with the unknown, all the <em>requirements</em> of the framework are known:
    </p><ul>
      <li>The <em>framework</em> defines the interface or base class</li>
      <li>The <em>framework</em> creates instances of the custom user classes</li>
      <li>The <em>framework</em> invokes methods on the custom user objects</li>
    </ul><p>
    The <em>framework</em> is the client, and the framework defines the interface. That's exactly how it should be. In <a href="http://amzn.to/19W4JHk">Agile Principles, Patterns, and Practices</a>, Robert C. Martin defines interface ownership as
    </p><blockquote>
      "clients [...] own the abstract interfaces"
    </blockquote><p>
    This is a quote from chapter 11, which is about the <a href="http://en.wikipedia.org/wiki/Dependency_inversion_principle">Dependency Inversion Principle</a>, so it all fits.
  </p>
  <p>
    Notice what the framework <em>does</em> in the list above. Not only does it <em>use</em> the custom user objects, it also <em>creates</em> instances of the custom user classes. This is the tricky part, where many framework designers have a hard time seeing past the fact that the custom user code is unknown. However, from the perspective of the framework, the concrete type of a custom user class is irrelevant; it just needs to create an instance of it, but treat it as the well-known interface it implements.
    </p><ul>
      <li>The client owns the interface</li>
      <li>The <em>framework</em> is the client</li>
      <li>The framework knows what <em>it</em> needs, not what user code needs</li>
      <li>Thus, framework interfaces should be defined by what the framework needs, not as a general-purpose interface to deal with user code</li>
      <li>Users know much better what user code needs than the framework can ever hope to do</li>
    </ul><p>
    The framework owns the interface for creating those objects, and it shouldn't be complicated; in essence, it should look like this:
  </p>
  <pre><span>public</span>&nbsp;<span>interface</span>&nbsp;<span>IFrameworkControllerFactory</span>
{
&nbsp;&nbsp;&nbsp;&nbsp;<span>IFrameworkController</span>&nbsp;Create(<span>Type</span>&nbsp;controllerType);
}</pre>
  
  <p>
    assuming that the interface that the user code must implement is called IFrameworkController.
  </p>
  <p>
    The custom user class may contain one or more disposable objects, so in order to prevent resource leaks, the framework must also provide a hook for decommissioning:
  </p>
  <pre><span>public</span>&nbsp;<span>interface</span>&nbsp;<span>IFrameworkControllerFactory</span>
{
&nbsp;&nbsp;&nbsp;&nbsp;<span>IFrameworkController</span>&nbsp;Create(<span>Type</span>&nbsp;controllerType);
 
&nbsp;&nbsp;&nbsp;&nbsp;<span>void</span>&nbsp;Release(<span>IFrameworkController</span>&nbsp;controller);
}</pre>
  
  <p>
    In this expanded iteration of the Abstract Factory, the contract is that the framework will invoke the Release method when it's finished with a particular IFrameworkController instance.
  </p>
  <p>
    <img src="https://blog.ploeh.dk/content/binary/framework-sequence-diagram-with-release-hook.png" alt="Framework sequence diagram with release hook">
  </p>
  <p>
    Some framework designers attempt to introduce a 'more sophisticated' lifetime model, but there's no reason for that. This Create/Release design is simple, easy to understand, works very well, and fits perfectly into the <a href="https://blog.ploeh.dk/2010/09/29/TheRegisterResolveReleasepattern">Register Resolve Release</a> pattern, since it provides hooks for the Resolve and Release phases.
  </p>
  <p>
    ASP.NET MVC 1 and 2 provided <em>flawless</em> examples of such Abstract Factories in the form of the <a href="http://msdn.microsoft.com/en-us/library/system.web.mvc.icontrollerfactory(v=vs.100).aspx">IControllerFactory</a> interface:
  </p>
  <pre><span>public</span>&nbsp;<span>interface</span>&nbsp;<span>IControllerFactory</span>
{
&nbsp;&nbsp;&nbsp;&nbsp;<span>IController</span>&nbsp;CreateController(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>RequestContext</span>&nbsp;requestContext,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>string</span>&nbsp;controllerName);
 
&nbsp;&nbsp;&nbsp;&nbsp;<span>void</span>&nbsp;ReleaseController(<span>IController</span>&nbsp;controller);
}</pre>
  
  <p>
    Unfortunately, in ASP.NET MVC 3, a completely unrelated third method was added to that interface; it's still useful, but not as clean as before.
  </p>
  <p>
    Framework designers ought to stop here. With such an Abstract Factory, they have <em>perfect</em> Dependency Injection support. If a user wants to hand-code the composition, he or she can implement the Abstract Factory interface. Here's an ASP.NET 1 example:
  </p>
  <pre><span>public</span>&nbsp;<span>class</span>&nbsp;<span>PoorMansCompositionRoot</span>&nbsp;:&nbsp;<span>DefaultControllerFactory</span>
{
&nbsp;&nbsp;&nbsp;&nbsp;<span>private</span>&nbsp;<span>readonly</span>&nbsp;<span>Dictionary</span>&lt;<span>IController</span>,&nbsp;<span>IEnumerable</span>&lt;<span>IDisposable</span>&gt;&gt;&nbsp;disposables;
&nbsp;&nbsp;&nbsp;&nbsp;<span>private</span>&nbsp;<span>readonly</span>&nbsp;<span>object</span>&nbsp;syncRoot;
 
&nbsp;&nbsp;&nbsp;&nbsp;<span>public</span>&nbsp;PoorMansCompositionRoot()
&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>this</span>.syncRoot&nbsp;=&nbsp;<span>new</span>&nbsp;<span>object</span>();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>this</span>.disposables&nbsp;=&nbsp;<span>new</span>&nbsp;<span>Dictionary</span>&lt;<span>IController</span>,&nbsp;<span>IEnumerable</span>&lt;<span>IDisposable</span>&gt;&gt;();
&nbsp;&nbsp;&nbsp;&nbsp;}
 
&nbsp;&nbsp;&nbsp;&nbsp;<span>protected</span>&nbsp;<span>override</span>&nbsp;<span>IController</span>&nbsp;GetControllerInstance(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>RequestContext</span>&nbsp;requestContext,&nbsp;<span>Type</span>&nbsp;controllerType)
&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>if</span>&nbsp;(controllerType&nbsp;==&nbsp;<span>typeof</span>(<span>HomeController</span>))
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>var</span>&nbsp;connStr&nbsp;=&nbsp;<span>ConfigurationManager</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.ConnectionStrings[<span>"postings"</span>].ConnectionString;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>var</span>&nbsp;ctx&nbsp;=&nbsp;<span>new</span>&nbsp;<span>PostingContext</span>(connStr);
 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>var</span>&nbsp;sqlChannel&nbsp;=&nbsp;<span>new</span>&nbsp;<span>SqlPostingChannel</span>(ctx);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>var</span>&nbsp;sqlReader&nbsp;=&nbsp;<span>new</span>&nbsp;<span>SqlPostingReader</span>(ctx);
 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>var</span>&nbsp;validator&nbsp;=&nbsp;<span>new</span>&nbsp;<span>DefaultPostingValidator</span>();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>var</span>&nbsp;validatingChannel&nbsp;=&nbsp;<span>new</span>&nbsp;<span>ValidatingPostingChannel</span>(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;validator,&nbsp;sqlChannel);
 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>var</span>&nbsp;controller&nbsp;=&nbsp;<span>new</span>&nbsp;<span>HomeController</span>(sqlReader,&nbsp;validatingChannel);
 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>lock</span>&nbsp;(<span>this</span>.syncRoot)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>this</span>.disposables.Add(controller,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>new</span>&nbsp;<span>IDisposable</span>[]&nbsp;{&nbsp;sqlChannel,&nbsp;sqlReader&nbsp;});
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>return</span>&nbsp;controller;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>return</span>&nbsp;<span>base</span>.GetControllerInstance(requestContext,&nbsp;controllerType);
&nbsp;&nbsp;&nbsp;&nbsp;}
 
&nbsp;&nbsp;&nbsp;&nbsp;<span>public</span>&nbsp;<span>override</span>&nbsp;<span>void</span>&nbsp;ReleaseController(<span>IController</span>&nbsp;controller)
&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>lock</span>&nbsp;(<span>this</span>.syncRoot)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>foreach</span>&nbsp;(<span>var</span>&nbsp;d&nbsp;<span>in</span>&nbsp;<span>this</span>.disposables[controller])
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d.Dispose();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;}
}</pre>
  
  <p>
    In this example, I derive from <a href="http://msdn.microsoft.com/en-us/library/system.web.mvc.defaultcontrollerfactory(v=vs.100).aspx">DefaultControllerFactory</a>, which implements the IControllerFactory interface - it's a little bit easier than implementing the interface directly.
  </p>
  <p>
    In this example, the Composition Root only handles a single user Controller type (HomeController), but I'm sure you can extrapolate from the example.
  </p>
  <p>
    If a developer rather prefers using a DI Container, that's also perfectly possible with the Abstract Factory approach. Here's another ASP.NET 1 example, this time with Castle Windsor:
  </p>
  <pre><span>public</span>&nbsp;<span>class</span>&nbsp;<span>WindsorCompositionRoot</span>&nbsp;:&nbsp;<span>DefaultControllerFactory</span>
{
&nbsp;&nbsp;&nbsp;&nbsp;<span>private</span>&nbsp;<span>readonly</span>&nbsp;<span>IWindsorContainer</span>&nbsp;container;
 
&nbsp;&nbsp;&nbsp;&nbsp;<span>public</span>&nbsp;WindsorCompositionRoot(<span>IWindsorContainer</span>&nbsp;container)
&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>if</span>&nbsp;(container&nbsp;==&nbsp;<span>null</span>)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>throw</span>&nbsp;<span>new</span>&nbsp;<span>ArgumentNullException</span>(<span>"container"</span>);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>this</span>.container&nbsp;=&nbsp;container;
&nbsp;&nbsp;&nbsp;&nbsp;}
 
&nbsp;&nbsp;&nbsp;&nbsp;<span>protected</span>&nbsp;<span>override</span>&nbsp;<span>IController</span>&nbsp;GetControllerInstance(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>RequestContext</span>&nbsp;requestContext,&nbsp;<span>Type</span>&nbsp;controllerType)
&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>return</span>&nbsp;(<span>IController</span>)<span>this</span>.container.Resolve(controllerType);
&nbsp;&nbsp;&nbsp;&nbsp;}
 
&nbsp;&nbsp;&nbsp;&nbsp;<span>public</span>&nbsp;<span>override</span>&nbsp;<span>void</span>&nbsp;ReleaseController(<span>IController</span>&nbsp;contro…</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ploeh.dk/2014/05/19/di-friendly-framework/">https://blog.ploeh.dk/2014/05/19/di-friendly-framework/</a></em></p>]]>
            </description>
            <link>https://blog.ploeh.dk/2014/05/19/di-friendly-framework/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917398</guid>
            <pubDate>Wed, 28 Oct 2020 11:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Multi user Wine apps with OverlayFS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24917353">thread link</a>) | @eniac111
<br/>
October 28, 2020 | https://petrovs.info/post/2020-10-11-running-wine-apps-in-multi-user-env/ | <a href="https://web.archive.org/web/*/https://petrovs.info/post/2020-10-11-running-wine-apps-in-multi-user-env/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">



<div>
    
    
    <p><img src="https://petrovs.info/post/2020-10-11-running-wine-apps-in-multi-user-env/img/wine.gif" alt="wine"> For the project I mentioned in the <a href="https://petrovs.info/post/2020-10-08-revival-of_the-bulgarian-villages/">last post</a>
there was a requirement for running some Windows games on the computers. Despite the challenge to maintain 20 years old Windows software in Linux,
the main challenge was to make it working in multi user environment with LDAP.</p>
<p><a href="https://winehq.org/">Wine</a> is a per-user app. Every user has their own Wine prefix with the apps directory and the emulated Windows root drive.</p>
<p>There were some solutions from internet but none was working and convenient for the case.</p>
<p>First I tried with the <a href="https://www.winepak.org/">Winepak</a> project but it wasn’t working. The project seems to be unmaintained on this date. They were providing libraries for “Flatpak-ing” Wine applications.</p>
<p>Other users tried with separate user for Wine and sudo-ing but it’s also doesn’t look stable enough for remote setup in different villages across the country.</p>
<p>Skel is a simple and working variant but the Wine directory is several gigabytes. If the library contains more than 30 users, the local disk wouldbe filled with skel copies of the Wine directory. It will also delay the first login with minutes. Symlinks won’t work because the applications are using files and the Wine directory should have <code>Write</code> access.</p>
<h2 id="the-variant-that-came-to-my-mind-was-mounting-the-wine-directory-with-overlayfs">The variant that came to my mind was mounting the Wine directory with OverlayFS.</h2>
<p>OverlayFS is a union mount file system which is a part of the Linux kernel since Linux 3.18. It combines upper and lower directory trees with files and subdirectories into one that combines their contents. It’s used in Live CDs and mostly in Docker for the layering functionality of the images.</p>
<p>The upper and lower directory trees can be from different filesystems. In a case of a file that contains the same name in the lower overlay directories, it’s version from the lower directory is hidden. In case of directories with the same name, their contents are merged.</p>
<p>The lower directory could be read only which is our case. It can also be overlay mount itself as in Docker layers and other container engines.</p>
<p>The file changes are commited to the upper directory and it should be writable in the case.</p>
<p>Work directory is required for temporary storing the files on atomic file operations. It must be on the same file system as the work directory.</p>
<p>Here is an example of using it:</p>
<p><a href="https://asciinema.org/a/HMynwKfkUcGmMQErXzwLIWiW8"><img src="https://asciinema.org/a/HMynwKfkUcGmMQErXzwLIWiW8.svg" alt="asciicast"></a></p>
<p>In the current case, the <code>upper</code> and <code>workdir</code> will be created by Skel in the home directories of the users and the lower dir will be in <code>/opt</code>:</p>
<div><pre><code data-lang="bash">/opt/winedir <span># Lower</span>
/home/$USER/.wine-upper
/home/$USER/.wine-workdir <span>#The workdir must be empty directory!</span>
</code></pre></div><p>Pam-mount module will mount the overlayfs when the user logs-in. It’s not installed by default. For Debian/Ubuntu:</p>
<div><pre><code data-lang="bash">apt-get install libpam-mount
</code></pre></div><p>pam-mount’s configuration is in <code>/etc/security/pam_mount.conf.xml</code>. The code must be put after <code>&lt;!-- Volume definitions --&gt;</code>:</p>
<div><pre><code data-lang="xml">          <span>&lt;volume</span>
            <span>fstype=</span><span>"overlay"</span>
            <span>path=</span><span>"/home/%(USER)/.wine"</span>
            <span>mountpoint=</span><span>"~/.wine"</span>
            <span>options=</span><span>"lowerdir=/opt/winedir,upperdir=/home/%(USER)/.wine-upper,workdir=/opt/workdir"</span>
            <span>/&gt;</span>
</code></pre></div><p>In this way, the <code>~/.wine</code> directory will be unique and it will contain only the file deltas.</p>
<p>Pam interactive login must also be disabled. Otherwise it will ask twice for password at login. It’s used for mounting SSH, CIFS and other file systems with pam-mount. in <code>/etc/pam.d/common-auth</code> append `disable_interactive :</p>
<pre><code data-lang="csv"># and here are more per-package modules (the "Additional" block)
auth    optional        pam_mount.so  disable_interactive
</code></pre><p>The Ansible role for project “Za Selata” is <a href="https://gitlab.com/zaselata/computer-cabinets/zsl-win-games/-/tree/master">here</a>. It can be used for a reference.</p>

    <p><a onclick="openComments()">Comments</a></p>
    
    <h4><a href="https://petrovs.info/">Back to Home</a></h4>
</div>


        </div></div>]]>
            </description>
            <link>https://petrovs.info/post/2020-10-11-running-wine-apps-in-multi-user-env/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917353</guid>
            <pubDate>Wed, 28 Oct 2020 10:58:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Massively-Parallel Vector Graphics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24917164">thread link</a>) | @vg_head
<br/>
October 28, 2020 | http://w3.impa.br/~diego/projects/GanEtAl14/ | <a href="https://web.archive.org/web/*/http://w3.impa.br/~diego/projects/GanEtAl14/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">





<h2>
IMPA
</h2>

<h3>
ACM Transactions on Graphics (Proceedinds of ACM SIGGRAPH
Asia 2014), 36(6):229
</h3>


<p>
<b>Abstract:</b>
We present a massively parallel vector graphics rendering
pipeline that is divided into two components. The
preprocessing component builds a novel adaptive acceleration
data structure, the <em>shortcut tree</em>. Tree construction
is efficient and parallel at the segment level, enabling
dynamic vector graphics. The tree allows efficient random
access to the color of individual samples, so the graphics
can be warped for special effects. The rendering component
processes all samples and pixels in parallel. It was
optimized for wide antialiasing filters and a large number
of samples per pixel to generate sharp, noise-free images.
Our <em>sample scheduler</em> allows pixels with overlapping
antialiasing filters to share samples. It groups together
samples that can be computed with the same vector operations
using little memory or bandwidth.  The pipeline is
feature-rich,
supporting multiple layers of filled paths, each defined by
curved outlines (with linear, rational quadratic, and
integral cubic Bézier segments), clipped against other
paths, and painted with semi-transparent colors, gradients,
or textures.  We demonstrate renderings of complex vector
graphics in state-of-the-art quality and performance.
Finally, we provide full source-code for our implementation
as well as the input data used in the paper.
</p>



<div>
<p><img src="http://w3.impa.br/~diego/projects/GanEtAl14/hawaii.png"></p><p>
<b>Figure 1:</b> Sample vector graphics rendered with our pipeline under a
perspective warp.
</p>
</div>

<br>






</div>]]>
            </description>
            <link>http://w3.impa.br/~diego/projects/GanEtAl14/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917164</guid>
            <pubDate>Wed, 28 Oct 2020 10:24:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiten Shah on choosing the right value proposition]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24917128">thread link</a>) | @gresquare
<br/>
October 28, 2020 | https://www.everyonehatesmarketers.com/hiten-shah-on-choosing-the-right-value-proposition/ | <a href="https://web.archive.org/web/*/https://www.everyonehatesmarketers.com/hiten-shah-on-choosing-the-right-value-proposition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><b>Louis:</b><span> Bonjour, bonjour and welcome to another episode of Everyone Hates Marketers.com. The no fluff, actionable marketing podcast, for people sick of shady, aggressive marketing.</span></p>
<p><span>I’m your host, Louis Grenier. In today’s episode, you learn how to test different value propositions for whatever you’re offering your product or service, and pick which one you’d like to resonate the most with your audience.</span></p>
<p><span>My guest today you probably know him. He’s the co-founder and the CEO of FYI, a solution to have all of your documents in one place, and is the co-owner of Crazy Egg as well. He’s a serial entrepreneur, founded multiple software companies over the last 20 years or so. And I’m super happy to have him on board because.. obviously I believe that customer feedback and truly understanding your customer is the first step towards success, towards building something that people would care about. So that’s why I’m super happy to have you Hitan Shah onboard. Welcome.</span></p>
<p><b>Hiten:</b><span>Thanks for having me</span></p>
<p><b>Louis:</b><span> Let’s get started straight away. How do you define what a value proposition is, you have extensive experience launching products, dating them side projects, et cetera. But how do you define what a value proposition is?</span></p>
<p><b>Hiten:</b><span> Yeah. In short, I think it’s what, one sort of entity, if you want to call it, that can do for another.</span></p>
<p><span>And that it’s very simple. and the reason I would put it that way is because a value proposition can exist between any, basically two entities. So it could be an individual and an organization. It could be an organization or an organization. It could be an individual and an individual.</span></p>
<p><span>And it’s basically the value that one entity delivers to another. And the value proposition is how that sort of quantified, communicated, realized, et cetera. And the typical way people think about this is your business has a value proposition for its customers. The way I think about it is that.</span></p>
<p><span>Your value proposition for a business, a service, one human to another is what they’re getting from you, that is of value to them. And when you think about it that way, I think it really defines, it defines what this means and what it means is that it’s not up to you. Who’s giving the value, whether it’s an organization or individual to the other person to be like, Oh, here’s my value proposition for you.</span></p>
<p><span>It actually more works the other way around where that person or that company organization, group of individuals is like, this is what that other entity, organization, person does for me. And this is why it’s valuable. And I think that’s the basis of the value proposition is this idea that it’s in someone else’s mind. It’s not in your mind. The one who’s delivering the value. It’s the other party’s mind.</span></p>
<p><span>So it’s generous, it’s a way to think about it. Generously thinking about your people first, what do they want? And you provide that to them. You don’t start with your, with you being self centered and then think of your product.</span></p>
<p><b>Louis:</b><span> And now, what is our value proposition? Then let’s find people who would care about it. It’s really the opposite. You think of those people first, what they care about because it’s, that’s what they care about is themselves, right?</span></p>
<p><b>Hiten:</b><span> Yeah. if you don’t do that, then whatever value proposition you come up with, you’re throwing darts against the wall and hoping something just sticks and it’s probably not going to hit the bullseye for sure.</span></p>
<p><span>So you, you think of it the other way, and you think about these people and what their needs are and, I don’t know, I’ve seen that in every single, basically business I’ve started or business I’ve talked to somebody about it. It doesn’t even matter what it is. It’s that there’s this sort of effect where no matter what I say I’m doing for you, if you don’t agree, I don’t get to have your business.</span></p>
<p><span>I don’t get to be in that relationship with you. And you could go all the way to dating. You could go to marriage, you could go to any type of business. This will work. Because the value, the whole idea of a value proposition is it’s for somebody else. It’s not for the person who’s delivering the value.</span></p>
<p><span>And what I mean by that is like my understanding of it as a person, delivering value is only valuable if it relates to how I’m delivering value to somebody else. Or some other organization or whatever, and this is why this method works. No matter what industry you’re in. Like I said, it boils down to even relationships.</span></p>
<p><span>I think relationships are a set of value propositions to each other, And like when they fall apart, it’s usually because value is not met. Some expectation of that value is not delivered on and that’s it.</span></p>
<p><b>Louis:</b><span> Yeah. That’s when you’re diving very deep into a topic when you see it everywhere, when you go back to first principles, fundamental truth. Which is the way I like to think. So it’s great to hear. So before we actually go through a step by step on how to actually test value propositions, if you have a few in mind and how maybe how to come up with them in the first place. Based on your experience, you said you have funded multiple, very successful companies, you’ve probably advised a lot as well, being in touch with a lot of people. What do you think are the top two other mistakes folks are doing when it comes to value proposition? Besides the main one you described there?</span></p>
<p><b>Hiten:</b><span> Yeah. Let me even give you an example from right now, if I may. So you said, I said, certain things about the businesses I started. In reality, you said it, I didn’t say it. So in a way, it’s really like what people get wrong is they don’t pay attention to basically this idea that, look you said it, not me. And if you said it’s in your mind. So for example, you said that the businesses I’ve started have been successful.</span></p>
<p><span>I didn’t say that. You didn’t even ask me if they have been, right? Because if you would’ve asked me, I would have said successful? I don’t really know what that means. I think I tried my best, the teams did, and we got where we got, and here we are. Like whether that big thing is over or the thing is still going, that eye of the beholder is not me. The eye of the beholder is you, so thank you for saying that. I think there’s some level of credibility, maybe I have as a result of what’s in other people’s minds, but in my mind, I don’t know. Cause it doesn’t matter. So I think what people get wrong is they try to make up the value propositions, in their own heads about what they’re doing.</span></p>
<p><span>Oftentimes, because what they’re doing is something that they want to see exist in the world. And they haven’t really thought about whether it should exist to other people. I know this might sound like what I just said, you know what we’ve been talking about, but it is a second point. The second point is it doesn’t matter what you think.</span></p>
<p><span>Like it just doesn’t. so a lot of times people will come up with things and it’s just wrong because their whole idea of a value proposition is based on what they think about it. So if you asked me about my businesses, I would go into a lot of detail, about them and what happened, but I would never use the word successful, but you did.</span></p>
<p><span>So that means that I’m not saying I should, but it’s just information for me, regardless of what I think. And I think that there’s a resistance oftentimes to what other people think about something of yours and that resistance. Yeah.</span></p>
<p><b>Louis:</b><span> Let’s, sorry to cut through there, but I think you’re about to touch on it.</span></p>
<p><span>Let’s talk about this resistance. Where do you think it’s mainly coming from?</span></p>
<p><b>Hiten:</b><span> A lot of places. I think it usually comes from some form of a reaction that you have to what you just heard and whether that reaction is positive or negative. That’s really what sort of shapes your own ability to deal with what you’re hearing, this is one of the biggest problems with value propositions, which is when you don’t personally agree with what you’re hearing.</span></p>
<p><span>And then you bias yourself towards what you actually want something to be when it won’t be that, because nobody’s saying it. So I don’t think if I said my businesses have been successful, that would be as powerful or accurate as someone else saying it, because my definition of it, because it’s mine is going to be different than yours.</span></p>
<p><span>But what I really care about is your definition of it, not mine. And I think there’s a lot of aversion there to being able to see the truth about yourself or the truth about what you’re doing. And the main reason is you get invested in it. So the reason this happens is usually a really strong, emotional investment in what you’re doing and what you want it to be versus the ability to I like to call it, you go where the wind blows.</span></p>
<p><span>So the wind is blowing a certain way, you go there. So a good example of this is like a lawyer who’s really good at, let’s say like trademark law, and yet they want to do, I don’t know, some kind of M&amp;A, yeah. They want to be an M&amp;A lawyer. That’s very different from trademarks, but they happen to be really good at trademarks.</span></p>
<p><span>And everybody knows them as a lawyer. That’s all about trademarks. But they want to do M&amp;A. So think about how much effort they’re going to have to put in to become known and good at being an M&amp;A lawyer and known for it compared to the thing that’s the path of least resistance where the wind is already blowing, which is other people consider them a great trademark lawyer.</span></p>
<p><span>And it’s not to say that they shouldn’t be an M&amp;A lawyer or anything like that. It’s just to say that, like you have a position in people’s minds. And I don’t think you can talk about value propositions without thinking about positioning and positioning to me, is really like when a good service person, human being, whatever has carved out a place in your brain, and that positioning is what I’m really trying to figure out constantly what, when I’m presented with a problem where we need to like, figure out the value proposition.</span></p>
<p><b>Louis:</b><span> They are always though too, when you have 10, like tens of …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.everyonehatesmarketers.com/hiten-shah-on-choosing-the-right-value-proposition/">https://www.everyonehatesmarketers.com/hiten-shah-on-choosing-the-right-value-proposition/</a></em></p>]]>
            </description>
            <link>https://www.everyonehatesmarketers.com/hiten-shah-on-choosing-the-right-value-proposition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917128</guid>
            <pubDate>Wed, 28 Oct 2020 10:17:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What SOFIA’s discovery of water on the Moon is, and isn’t]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24917107">thread link</a>) | @uncertainquark
<br/>
October 28, 2020 | https://jatan.space/on-sofias-discovery-of-water-on-the-moon/ | <a href="https://web.archive.org/web/*/https://jatan.space/on-sofias-discovery-of-water-on-the-moon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		
	<main id="content" role="main">

	<div>
		<div>
						<article id="post-5589">
				<div>
<p>NASA and the Germany space agency’s airborne SOFIA telescope has&nbsp;<a href="https://www.nasa.gov/press-release/nasa-s-sofia-discovers-water-on-sunlit-surface-of-moon/">detected water</a>&nbsp;on the Moon’s surface. There are many misconceptions floating around this discovery so I’d like to clarify the nature of the findings and what it means for lunar science and exploration.</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/10/nasa-sofia-water-cover.jpg?resize=819%2C819&amp;ssl=1" alt="" width="819" height="819" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/10/nasa-sofia-water-cover.jpg?w=985&amp;ssl=1 985w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/10/nasa-sofia-water-cover.jpg?resize=200%2C200&amp;ssl=1 200w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/10/nasa-sofia-water-cover.jpg?resize=768%2C768&amp;ssl=1 768w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/10/nasa-sofia-water-cover.jpg?resize=800%2C800&amp;ssl=1 800w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/10/nasa-sofia-water-cover.jpg?resize=400%2C400&amp;ssl=1 400w" sizes="(max-width: 819px) 100vw, 819px" data-recalc-dims="1"><figcaption>This illustration highlights the Moon’s Clavius crater with an illustration depicting water trapped in its lunar soil, along with an image of NASA’s airborne SOFIA telescope that found such water. <a href="https://www.nasa.gov/press-release/nasa-s-sofia-discovers-water-on-sunlit-surface-of-moon/">Credits: NASA/Daniel Rutter</a></figcaption></figure></div>



<h2>Different from Chandrayaan 1</h2>



<p>SOFIA detected water on the Moon’s non-polar regions, and in areas of sunlight, making it different from ISRO Chandrayaan 1’s&nbsp;<a href="https://jatan.space/how-nasa-and-chandrayaan-discovered-water-on-the-moon/">discovery of water ice</a>&nbsp;inside dark, cold craters on the lunar poles.</p>



<p>The water SOFIA found is locked in the lunar soil and rocks. Interestingly, NASA’s M3 instrument on Chandrayaan 1 had&nbsp;<a href="https://web.archive.org/web/20120929095219/http://lunarscience.nasa.gov/wp-content/uploads/2012/08/38_Klima_NLSI_2012.pdf">seen hints</a>&nbsp;of such trapped water in non-polar regions, <a href="https://www.nasa.gov/topics/moonmars/features/clark1.html">as did Cassini</a>. But unlike SOFIA, those missions couldn’t tell if what they had detected was water or just hydroxyl groups (H2O vs OH).</p>



<p>Chandrayaan 1 dropped an impact probe on the Moon 12 years ago and did&nbsp;<a href="http://www.planetary.org/blogs/emily-lakdawalla/2010/2430.html">find water</a>, as in H2O. But it too is different from SOFIA’s findings because the probe detected water in the Moon’s thin atmosphere, not on the surface.</p>



<h2>Scientific not exploratory importance</h2>



<p>NASA PR spinned the announcement as the water being a promising source for future missions in creating sustainable habitats. But that’s not the case since this trapped water is in trace amounts, less than even the driest deserts on Earth. However, finding out where this water comes from or how it’s created has implications for understanding&nbsp;<a href="https://jatan.space/apollo-moon-origin/">the Moon’s origin</a>, which itself is tied to Earth’s.</p>



<p>The one area where the results have some exploratory relevance is understanding how water is transported on the Moon, so as to get a better handle on where on the Moon such resources are deposited. But the substantially more water ice present on the lunar poles continue to be the prime target for enabling sustainable human presence on the Moon.</p>



<div><figure><img loading="lazy" width="1200" height="675" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/01/3cc0f-water-ice-moon-map-m3.jpg?resize=1200%2C675&amp;ssl=1" alt="" data-recalc-dims="1"><figcaption>Illustration showing water ice in eternally dark craters on the Moon’s south pole (left) and north pole (right) as discovered by ISRO’s Chandrayaan 1 spacecraft.&nbsp;<a href="https://www.jpl.nasa.gov/news/news.php?feature=7218">Credit: NASA</a></figcaption></figure></div>



<p>Alongside the SOFIA findings, NASA mentioned&nbsp;<a href="https://www.nature.com/articles/s41550-020-1198-9#_blank">another result</a>&nbsp;that does have exploratory significance. Researchers using data from NASA’s Lunar Reconnaissance Orbiter have identified several craters smaller than a kilometer which are eternally dark polar and can thus host water ice. The sheer number of such small craters increases the expected amount of water ice on the Moon.</p>



<p>As per previous observations by the Chandrayaan 1 orbiter and the Lunar Reconnaissance Orbiter, scientists estimated the Moon’s poles to host&nbsp;<a href="https://www.nasa.gov/mission_pages/Mini-RF/multimedia/feature_ice_like_deposits.html">more than 600 billion kg</a>&nbsp;of water ice, enough to fill at least 240,000 Olympic-sized swimming pools. As the next logical step, Chandrayaan 2 orbiter is&nbsp;<a href="https://jatan.space/chandrayaan-2-is-creating-the-highest-resolution-map-of-the-moon/">quantifying the amount of water ice</a>&nbsp;on the lunar poles and mapping it as we speak, and its findings should include these smaller craters.</p>



<p>Once we have such data, these smaller, dark craters will likely be better targets for future missions as they’d be easier to explore and extract water from than large craters like Shackleton.</p>



<p><strong>Like my work?</strong><br>I could write this article thanks to my readers. To keep me going, <a href="https://jatan.space/support">support me</a> and get exclusive benefits in return.&nbsp;🚀</p>

</div>

			</article>
					</div>
	</div>
</main><!--/.neve-main-->




</div></div>]]>
            </description>
            <link>https://jatan.space/on-sofias-discovery-of-water-on-the-moon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917107</guid>
            <pubDate>Wed, 28 Oct 2020 10:12:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Markov Chain Monte Carlo (MCMC) Sampling, Part 1: The Basics (2019)]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24917011">thread link</a>) | @vonadz
<br/>
October 28, 2020 | https://www.tweag.io/blog/2019-10-25-mcmc-intro1/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2019-10-25-mcmc-intro1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>This is part 1 of a series of blog posts about MCMC techniques:</p>
<ul>
<li><a href="https://www.tweag.io/posts/2020-01-09-mcmc-intro2.html">Part II: Gibbs sampling</a></li>
<li><a href="https://www.tweag.io/blog/2020-08-06-mcmc-intro3/">Part III: Hamiltonian Monte Carlo</a></li>
<li><a href="https://www.tweag.io/blog/2020-10-28-mcmc-intro-4/">Part IV: Replica Exchange</a></li>
</ul>
<p><a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">Markov chain Monte Carlo</a> (MCMC) is a powerful class of methods to sample from probability distributions known only up to an (unknown) normalization constant. But before we dive into MCMC, let’s consider why you might want to do sampling in the first place.</p>
<p>The answer to that is: whenever you’re either interested in the samples themselves (for example, inferring unknown parameters in Bayesian inference) or you need them to approximate expected values of functions w.r.t. to a probability distribution (for example, calculating thermodynamic quantities from the distribution of microstates in statistical physics).
Sometimes, only the mode of a probability distribution is of primary interest. In this case, it’s obtained by numerical optimization so full sampling is not necessary.</p>
<p>It turns out that sampling from any but the most basic probability distributions is a difficult task.
<a href="https://en.wikipedia.org/wiki/Inverse_transform_sampling">Inverse transform sampling</a> is an elementary method to sample from probability distributions, but requires the cumulative distribution function, which in turn requires knowledge of the, generally unknown, normalization constant.
Now in principle, you could just obtain the normalization constant by numerical integration, but this quickly gets infeasible with an increasing number of dimensions.
<a href="https://en.wikipedia.org/wiki/Rejection_sampling">Rejection sampling</a> does not require a normalized distribution, but efficiently implementing it requires a good deal of knowledge about the distribution of interest, and it suffers strongly from the curse of dimension, meaning that its efficiency decreases rapidly with an increasing number of variables.
That’s when you need a smart way to obtain representative samples from your distribution which doesn’t require knowledge of the normalization constant.</p>
<p>MCMC algorithms are a class of methods which do exactly that.
These methods date back to a <a href="https://pdfs.semanticscholar.org/7b3d/c9438227f747e770a6fb6d7d7c01d98725d6.pdf">seminal paper by Metropolis et al.</a>, who developed the first MCMC algorithm, correspondingly called <a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm">Metropolis algorithm</a>, to calculate the equation of state of a two-dimensional system of hard spheres. In reality, they were looking for a general method to calculate expected values occurring in statistical physics.</p>
<p>In this blog post, I introduce the basics of MCMC sampling; in subsequent posts I’ll cover several important, increasingly complex and powerful MCMC algorithms, which all address different difficulties one frequently faces when using the Metropolis-Hastings algorithm. Along the way, you will gain a solid understanding of these challenges and how to address them.
Also, this serves as a reference for MCMC methods in the context of the <a href="https://www.tweag.io/posts/2019-09-20-monad-bayes-1.html">monad-bayes</a> series.
Furthermore, I hope the provided notebooks will not only spark your interest in exploring the behavior of MCMC algorithms for various parameters/probability distributions, but also serve as a basis for implementing and understanding useful extensions of the basic versions of the algorithms I present.</p>
<h2>Markov chains</h2>
<p>Now that we know why we want to sample, let’s get to the heart of MCMC: Markov chains.
What is a Markov chain? Without all the technical details, a Markov chain is a random sequence of states in some state space in which the probability of picking a certain state next depends only on the current state in the chain and not on the previous history: it is memory-less.
Under certain conditions, a Markov chain has a unique stationary distribution of states to which it converges after a certain number of states. From that number on, states in the Markov chain are distributed according to the invariant distribution.</p>
<p>In order to sample from a distribution <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi(x)</annotation></semantics></math></span></span>, a MCMC algorithm constructs and simulates a Markov chain whose stationary distribution is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi(x)</annotation></semantics></math></span></span>, meaning that, after an initial “burn-in” phase, the states of that Markov chain are distributed according to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi(x)</annotation></semantics></math></span></span>.
We thus just have to store the states to obtain samples from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi(x)</annotation></semantics></math></span></span>.</p>
<p>For didactic purposes, let’s for now consider both a discrete state space and discrete “time”.
The key quantity characterizing a Markov chain is the transition operator <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">T(x_{i+1}|x_i)</annotation></semantics></math></span></span> which gives you the probability of being in state <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_{i+1}</annotation></semantics></math></span></span> at time <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">i+1</annotation></semantics></math></span></span> given that the chain is in state <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span></span> at time <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span></span>.</p>
<p>Now just for fun (and for illustration), let’s quickly whip up a Markov chain which has a unique stationary distribution.
We’ll start with some imports and settings for the plots:</p>
<div data-language="python"><pre><code><span>%</span>matplotlib notebook
<span>%</span>matplotlib inline
<span>import</span> numpy <span>as</span> np
<span>import</span> matplotlib<span>.</span>pyplot <span>as</span> plt
plt<span>.</span>rcParams<span>[</span><span>'figure.figsize'</span><span>]</span> <span>=</span> <span>[</span><span>10</span><span>,</span> <span>6</span><span>]</span>
np<span>.</span>random<span>.</span>seed<span>(</span><span>42</span><span>)</span></code></pre></div>
<p>The Markov chain will hop around on a discrete state space which is made up from three weather states:</p>
<div data-language="python"><pre><code>state_space <span>=</span> <span>(</span><span>"sunny"</span><span>,</span> <span>"cloudy"</span><span>,</span> <span>"rainy"</span><span>)</span></code></pre></div>
<p>In a discrete state space, the transition operator is just a matrix.
Columns and rows correspond, in our case, to sunny, cloudy, and rainy weather.
We pick more or less sensible values for all transition probabilities:</p>
<div data-language="python"><pre><code>transition_matrix <span>=</span> np<span>.</span>array<span>(</span><span>(</span><span>(</span><span>0.6</span><span>,</span> <span>0.3</span><span>,</span> <span>0.1</span><span>)</span><span>,</span>
                              <span>(</span><span>0.3</span><span>,</span> <span>0.4</span><span>,</span> <span>0.3</span><span>)</span><span>,</span>
                              <span>(</span><span>0.2</span><span>,</span> <span>0.3</span><span>,</span> <span>0.5</span><span>)</span><span>)</span><span>)</span></code></pre></div>
<p>The rows indicate the states the chain might currently be in and the columns the states the chains might transition to.
If we take one “time” step of the Markov chain as one hour, then, if it’s sunny, there’s a 60% chance it stays sunny in the next hour, a 30% chance that in the next hour we will have cloudy weather, and only a 10% chance of rain immediately after it had been sunny before.
This also means that each row has to sum up to one.</p>
<p>Let’s run our Markov chain for a while:</p>
<div data-language="python"><pre><code>n_steps <span>=</span> <span>20000</span>
states <span>=</span> <span>[</span><span>0</span><span>]</span>
<span>for</span> i <span>in</span> <span>range</span><span>(</span>n_steps<span>)</span><span>:</span>
    states<span>.</span>append<span>(</span>np<span>.</span>random<span>.</span>choice<span>(</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>2</span><span>)</span><span>,</span> p<span>=</span>transition_matrix<span>[</span>states<span>[</span><span>-</span><span>1</span><span>]</span><span>]</span><span>)</span><span>)</span>
states <span>=</span> np<span>.</span>array<span>(</span>states<span>)</span></code></pre></div>
<p>We can monitor the convergence of our Markov chain to its stationary distribution by calculating the empirical probability for each of the states as a function of chain length:</p>
<div data-language="python"><pre><code><span>def</span> <span>despine</span><span>(</span>ax<span>,</span> spines<span>=</span><span>(</span><span>'top'</span><span>,</span> <span>'left'</span><span>,</span> <span>'right'</span><span>)</span><span>)</span><span>:</span>
    <span>for</span> spine <span>in</span> spines<span>:</span>
        ax<span>.</span>spines<span>[</span>spine<span>]</span><span>.</span>set_visible<span>(</span><span>False</span><span>)</span>

fig<span>,</span> ax <span>=</span> plt<span>.</span>subplots<span>(</span><span>)</span>
width <span>=</span> <span>1000</span>
offsets <span>=</span> <span>range</span><span>(</span><span>1</span><span>,</span> n_steps<span>,</span> <span>5</span><span>)</span>
<span>for</span> i<span>,</span> label <span>in</span> <span>enumerate</span><span>(</span>state_space<span>)</span><span>:</span>
    ax<span>.</span>plot<span>(</span>offsets<span>,</span> <span>[</span>np<span>.</span><span>sum</span><span>(</span>states<span>[</span><span>:</span>offset<span>]</span> <span>==</span> i<span>)</span> <span>/</span> offset
            <span>for</span> offset <span>in</span> offsets<span>]</span><span>,</span> label<span>=</span>label<span>)</span>
ax<span>.</span>set_xlabel<span>(</span><span>"number of steps"</span><span>)</span>
ax<span>.</span>set_ylabel<span>(</span><span>"likelihood"</span><span>)</span>
ax<span>.</span>legend<span>(</span>frameon<span>=</span><span>False</span><span>)</span>
despine<span>(</span>ax<span>,</span> <span>(</span><span>'top'</span><span>,</span> <span>'right'</span><span>)</span><span>)</span>
plt<span>.</span>show<span>(</span><span>)</span></code></pre></div>
<p><span>
      <a href="https://www.tweag.io/static/970ffb50b65a63406121b8ed07f5e4b1/d0d8c/mcmc-intro1-weatherchain.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="png" title="png" src="https://www.tweag.io/static/970ffb50b65a63406121b8ed07f5e4b1/fcda8/mcmc-intro1-weatherchain.png" srcset="https://www.tweag.io/static/970ffb50b65a63406121b8ed07f5e4b1/12f09/mcmc-intro1-weatherchain.png 148w,
https://www.tweag.io/static/970ffb50b65a63406121b8ed07f5e4b1/e4a3f/mcmc-intro1-weatherchain.png 295w,
https://www.tweag.io/static/970ffb50b65a63406121b8ed07f5e4b1/fcda8/mcmc-intro1-weatherchain.png 590w,
https://www.tweag.io/static/970ffb50b65a63406121b8ed07f5e4b1/d0d8c/mcmc-intro1-weatherchain.png 609w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>The mother of all MCMC algorithms: Metropolis-Hastings</h2>
<p>So that’s lots of fun, but back to sampling an arbitrary probability distribution <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span></span>.
It could either be discrete, in which case we would keep talking about a transition matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span></span>, or be continuous, in which case <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span></span> would be a transition <em>kernel</em>.
From now on, we’re considering continuous distributions, but all concepts presented here transfer to the discrete case.</p>
<p>If we could design the transition kernel in such a way that the next state is already drawn from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span></span>, we would be done, as our Markov chain would… well… immediately sample from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span></span>.
Unfortunately, to do this, we need to be able to sample from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span></span>, which we can’t.
Otherwise you wouldn’t be reading this, right?</p>
<p>A way around this is to split the transition kernel <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">T(x_{i+1}|x_i)</annotation></semantics></math></span></span> into two parts:
a proposal step and an acceptance/rejection step.
The proposal step features a proposal distribution <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q(x_{i+1}|x_i)</annotation></semantics></math></span></span>, from which we can sample possible next states of the chain.
In addition to being able to sample from it, we can choose this distribution arbitrarily. But, one should strive to design it such that samples from it are both as little correlated with the current state as possible and have a good chance of being accepted in the acceptance step.
Said acceptance/rejection step is the second part of the transition kernel and corrects for the error introduced by proposal states drawn from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo mathvariant="normal">≠</mo><mi>π</mi></mrow><annotation encoding="application/x-tex">q \neq \pi</annotation></semantics></math></span></span>.
It involves calculating an acceptance probability <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_\mathrm{acc}(x_{i+1}|x_i)</annotation></semantics></math></span></span> and accepting the proposal <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_{i+1}</annotation></semantics></math></span></span> with that probability as the next state in the chain.
Drawing the next state <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_{i+1}</annotation></semantics></math></span></span> from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">T(x_{i+1}|x_i)</annotation></semantics></math></span></span> is then done as follows:
first, a proposal state <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_{i+1}</annotation></semantics></math></span></span> is drawn from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q(x_{i+1}|x_i)</annotation></semantics></math></span></span>.
It is then accepted as the next state with probability <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_\mathrm{acc}(x_{i+1}|x_i)</annotation></semantics></math></span></span> or rejected with probability <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mi mathvariant="normal">_</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">1-p_\mathrm{acc}(x\_{i+1}|x_i)</annotation></semantics></math></span></span>, in which case the current state is copied as the next state.</p>
<p>We thus have</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>×</mo><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mtext>&nbsp;.</mtext></mrow><annotation encoding="application/x-tex">T(x_{i+1}|x_i)=q(x_{i+1} | x_i) \times p_\mathrm{acc}(x_{i+1}|x_i) \ \text .</annotation></semantics></math></span></span></span></p><p>A sufficient condition for a Markov chain to have <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span></span> as its stationary distribution is the transition kernel obeying <em>detailed balance</em> or, in the physics literature, <em>microscopic reversibility</em>:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mi>T</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>π</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mi>T</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi(x_i) T(x_{i+1}|x_i) = \pi(x_{i+1}) T(x_i|x_{i+1})</annotation></semantics></math></span></span></span></p><p>This means that the probability of being in a state <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span></span> and transitioning to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_{i+1}</annotation></semantics></math></span></span> must be equal to the probability of the reverse process, namely, being in state <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mi mathvariant="normal">_</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></mrow><annotation encoding="application/x-tex">x\_{i+1}</annotation></semantics></math></span></span> and transitioning to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span></span>.
Transition kernels of most MCMC algorithms satisfy this condition.</p>
<p>For the two-part transition kernel to obey detailed balance, we need to choose <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">p_\mathrm{acc}</annotation></semantics></math></span></span> correctly, meaning that is has to correct for any asymmetries in probability flow from / to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_{i+1}</annotation></semantics></math></span></span> or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span></span>.
Metropolis-Hastings uses the Metropolis acceptance criterion:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow><mrow><mo fence="true">{</mo><mn>1</mn><mo separator="true">,</mo><mfrac><mrow><mi>π</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>×</mo><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>π</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>×</mo><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">}</mo></mrow><mtext>&nbsp;.</mtext></mrow><annotation encoding="application/x-tex">p_\mathrm{acc}(x_{i+1}|x_i) = \mathrm{min} \left\{1, \frac{\pi(x_{i+1}) \times q(x_i|x_{i+1})}{\pi(x_i) \times q(x_{i+1}|x_i)} \right\} \ \text .</annotation></semantics></math></span></span></span></p><p>Now here’s where the magic happens:
we know <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span></span> only up to a constant, but it doesn’t matter, because that unknown constant cancels out in the expression for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">p_\mathrm{acc}</annotation></semantics></math></span></span>!
It is this property of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">p_\mathrm{acc}</annotation></semantics></math></span></span> which makes algorithms based on Metropolis-Hastings work for unnormalized distributions.
Often, symmetric proposal distributions with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mi>q</mi><mo stretchy="false">(</mo><mi>x</mi><mi mathvariant="normal">_</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q(x_i|x_{i+1})=q(x\_{i+1}|x_i)</annotation></semantics></math></span></span> are used, in which case the Metropolis-Hastings algorithm reduces to the original, but less general Metropolis algorithm developed in 1953 and for which</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow><mrow><mo fence="true">{</mo><mn>1</mn><mo separator="true">,</mo><mfrac><mrow><mi>π</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>π</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">}</mo></mrow><mtext>&nbsp;.</mtext></mrow><annotation encoding="application/x-tex">p_\mathrm{acc}(x_{i+1}|x_i) = \mathrm{min} \left\{1, \frac{\pi(x_{i+1})}{\pi(x_i)} \right\} \ \text .</annotation></semantics></math></span></span></span></p><p>We can then write the complete Metropolis-Hastings transition kernel as</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>×</mo><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>:</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo mathvariant="normal">≠</mo><msub><mi>x</mi><mi>i</mi></msub><mtext>;</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn><mo>−</mo><mo>∫</mo><mi mathvariant="normal">d</mi><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mtext>&nbsp;</mtext><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>×</mo><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>:</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mtext>.</mtext></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">T(x_{i+1}|x_i) = \begin{cases}
                   q(x_{i+1}|x_i) \times p_\mathrm{acc}(x_{i+1}|x_i) &amp;: x_{i+1} \neq x_i \text ; \\\\
                   1 - \int \mathrm{d}x_{i+1} \ q(x_{i+1}|x_i) \times p_\mathrm{acc}(x_{i+1}|x_i) &amp;: x_{i+1} = x_i\text .
                 \end{cases}</annotation></semantics></math></span></span></span></p><h2>Implementing the Metropolis-Hastings algorithm in Python</h2>
<p>All right, now that we know how Metropolis-Hastings works, let’s go ahead and implement it.
First, we set the log-probability of the distribution we want to sample from—without normalization constants, as we pretend we don’t know them. Let’s work for now with a standard normal distribution:</p>
<div data-language="python"><pre><code><span>def</span> <span>log_prob</span><span>(</span>x<span>)</span><span>:</span>
     <span>return</span> <span>-</span><span>0.5</span> <span>*</span> np<span>.</span><span>sum</span><span>(</span>x <span>**</span> <span>2</span><span>)</span></code></pre></div>
<p>Next, we choose a symmetric proposal distribution. Generally, including information you have about the distribution …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tweag.io/blog/2019-10-25-mcmc-intro1/">https://www.tweag.io/blog/2019-10-25-mcmc-intro1/</a></em></p>]]>
            </description>
            <link>https://www.tweag.io/blog/2019-10-25-mcmc-intro1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917011</guid>
            <pubDate>Wed, 28 Oct 2020 09:55:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Malcontents]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24916924">thread link</a>) | @bschne
<br/>
October 28, 2020 | https://boz.com/articles/malcontents | <a href="https://web.archive.org/web/*/https://boz.com/articles/malcontents">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>There is an important, under appreciated group at every company who are never content no matter how much success they or the company has had. There is a set of people who care so deeply about the company and its products that they take any shortcomings personally. They are offended by bad products and angered by cultural deficiencies. They write passionate notes that nobody asked for and rally people on comment threads in groups they aren’t required to be a part of. They speak truth to power because they are righteous and speak for those who might otherwise have no voice. They aren’t afraid to rock the boat no matter how much the people around them value stability and they can’t be bothered to do it politely. Adam Grant calls these people “<a href="https://www.ted.com/talks/adam_grant_are_you_a_giver_or_a_taker#t-113064">Disagreeable Givers</a>.” I call these people malcontents. And I am one of them.</p>
<p>We malcontents are often confused with <a href="http://boz.com/articles/ownership-and-entitlement.html">entitled whiners</a> but that’s a mistake. Whiners and Malcontents may share the same disagreeable tactics when it comes to complaining, but whiners have poor motivation whereas we malcontents have the best intentions. Whiners want to change the establishment for their own benefit. We malcontents want the establishment to change for its own benefit. Unlike whiners, we malcontents often make personal sacrifices to effect positive change (even if we would rather not be forced to). We often do valuable, unsexy, and sometimes underappreciated work like fixing bugs, improving tools or processes, and helping others. When you see large shifts in culture, organizations, or technology not driven by extrinsic or top down forces there is usually a malcontent behind the scenes or leading the charge.</p>
<p>The fate of malcontents is proof that good intentions and good work simply aren’t enough. Evaluating them exclusively on the impact of their work they are invariably promoted more slowly than their more polite peers. They get feedback constantly that they are doing good work but need to figure out how to do it without frustrating so many people. They are told they need to learn how to influence more effectively. To them it just feels like oppressive politics slowing them and the whole company down. I watched at Facebook as my peer group was consistently promoted a year or two ahead of me. I recall telling my manager at one point after a disappointing review that “this company is going to nice itself to death.” But niceness wasn’t hurting the company. I was. For every person who made me feel good about myself by clicking like on something inflammatory that I wrote there were ten people who quietly wrote me off. Not only did that erode my <a href="http://boz.com/articles/influence-over-authority.html">influence</a> over time it also didn’t help me advance my agenda on whatever issue I was raising.</p>
<p>For the malcontents out there: my advice is to stop and listen to the feedback you are getting. Your team needs you to highlight the opportunities around them and I don’t want you to stop advocating for change but I can tell you from personal experience that your impact is being diluted by your approach. You’re loudly trying to make a change but the tactics you use are costly and only marginally effective. If people think are you are emotional or biased, they will dismiss you. If they think your mind is closed, they will close their own. If they think you are attacking them, they will defend. If you take too much of their time or energy relative to the size of the issue, they will avoid you in the future. Do not fall for the Golden Rule — “Treat others as you wish to be treated” — because nobody else wants to be treated as bluntly as you do. If you do that, you will end up frustrated and marginalized. Instead go for the Platinum Rule: <em>Treat others as they wish to be treated</em>. It is only in expressing your passion through openness, empathy, and relationship building that you can really start to create change at scale.</p>
<p>Instead of just fighting the establishment, you must co-opt it. Find things the people involved care about and frame your concerns in those terms. You can change what the organization cares about by degrees over time, not dramatically overnight. As Richard Hamming said : “By realizing you have to use the system and studying how to get the system to do your work, you learn how to adapt the system to your desires. Or you can fight it steadily, as a small undeclared war, for the whole of your life.”</p>
<p>For those interacting with malcontents: embrace them. Nobody will care more or work harder on behalf of the people who use your product. Make space for them to raise all the concerns they have in an environment where it can be productive and recognize them for the value they bring in doing so when others are too polite to ask hard questions. And when necessary, try to make the cost of their clumsy communication as tangible a possible. Remind them of what their goal is in communicating and then show them how their approach was ineffective and coach them on a more effective approach.</p>
<p>I’m no less personally offended today by bad products or bad practices as I was years ago, but I’m much more effective at turning those emotions into impact. I’m not perfect at it and it isn’t hard to find examples where I’ve missed the mark, but now that I see how effective it can be to communicate more respectfully I find it much easier to do most of the time. I will always be grateful to Facebook for all the critical feedback and patience that got me to where I am. So today I try to pay it forward by identifying malcontents and giving them a little extra space and a lot of extra help.</p></section></div></div>]]>
            </description>
            <link>https://boz.com/articles/malcontents</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916924</guid>
            <pubDate>Wed, 28 Oct 2020 09:41:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Defining Data Intuition]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24916868">thread link</a>) | @headalgorithm
<br/>
October 28, 2020 | https://blog.harterrt.com/data_intuition.html | <a href="https://web.archive.org/web/*/https://blog.harterrt.com/data_intuition.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Last week, one of my peers asked me to explain what I meant by "Data Intuition",
and I realized I really didn't have a good definition.
That's a problem! I refer to data intuition all the time!</p>
<p>Data intuition is one of the three skills I interview new data scientists for
(along with statistics and technical skills).
In fact, I just spent the first nine months of 2020
building Mozilla's data intuition.
I'm really surprised to realize I can't point to
a good explanation of what I'm trying to cultivate.</p>
<p>So - I'll make one up. I propose the following definition for Data Intuition:</p>
<blockquote>
<p><strong>Data Intuition is a resilience to misleading data and analyses.</strong></p>
</blockquote>
<p>In other words, it's harder to mislead someone with data
if they have strong data intuition.
Think of this as <strong>a defense against the dark data arts</strong>.</p>
<p>So what does that look like in practice?</p>
<h2>Data Stink</h2>
<p>Someone with strong data intuition can quickly spot "data-stink"
(a close cousin to "<a href="https://en.wikipedia.org/wiki/Code_smell">code smell</a>").
These are data issues that don't necessarily invalidate an analysis,
but certainly draw suspicion on the results.
For example:</p>
<ul>
<li>An analysis prominently reports a seemingly <strong>arbitrary metric</strong> -
  4-day retention increased by 0.5%!
  Where did 4-day retention come from? Don't we usually track 7-day retention?
  This needs more attention before I trust the results.</li>
<li>An analysis reports <strong>extraordinary results</strong> where nominal results are expected -
  this feature increased retention by 10%!
  But, past efforts were trying to increase retention by 0.5% - 
  and isn't retention already 90%? How'd we get and increase of 10%?</li>
</ul>
<p>These are extreme examples. 
Usually the problems are more subtle
and result in a general sense of uneasiness with the results
(that's why it's called "intuition").</p>
<p>It's clear to me that data intuition is <em>related</em> to product intuition,
though these <em>are</em> different skills.
Product intuition can contextualize our results
and make it easier to identify extraordinary claims in analyses.
To know a 10% gain in retention is ridiculous
we need to know that users retain pretty well already.</p>
<h2>Methods issues</h2>
<p>Strong data intuition can also help you 
spot issues with how the analysis was designed.
Things like: how did the author collect data? Is it a representative sample?
Do they need to have an experiment to establish causation?</p>
<p>Here's an example -
say an analysis reports that Firefox users who create a Firefox account
retain 10% higher than users who don't.
By default, a lot of folks interpret this to mean that
if we invest some time in helping users open accounts
we'll see an increase in retention.
Folks with stronger data intuition will instead 
recognize these results are just correlational (not causational).</p>
<p>Users who use the product a lot tend to stick around longer.
Users who open an account are more active users, thus they retain better.
Users who <em>crash</em> Firefox are more active users, and also retain <em>better</em>.</p>
<p>I think this intuition is more than just understanding statistics well.
A strong stats background can help me identify issues
when reading the <em>methods section of a white paper</em>.
Strong data intuition helps me determine how much I trust
results I hear about in a <em>news headline</em>.
Data intuition helps me establish whether results are
<a href="https://blog.harterrt.com/pub-true.html">true-enough</a>.</p>
<h2>More than Skepticism</h2>
<p>I almost defined data intuition as a type of skepticism,
but I think this is a bad characterization.
Skepticism over-focuses on disregarding results.</p>
<p>Intuition is more than being skeptical.
It's <strong>incorporating new data as part of a body of existing knowledge</strong>.
A lot of times, that means deciding new incoming data are inconsistent
and need more investigating before we can trust them.
But other times, it means changing our opinions in the face of new data
that are more authoritative than our existing body of knowledge.</p>
<h2>What do you think?</h2>
<p>I want to hear your thoughts on this.
I'm posting this definition publicly in part because I want to invoke
<a href="https://meta.wikimedia.org/wiki/Cunningham%27s_Law">Cunningham's Law</a>.
The best way to get to the right answer is to post the wrong answer!</p>
<p>Does this definition for data intuition resonate with you?
Am I missing something important? Let me know! 
My email is at the bottom of this page.</p>
<p>I'm spending the next few month building some self-service trainings
to help non-data people at Mozilla build data intuition.
I'd rather be wrong now than next year!</p>
  </div><p>
        Feel free to share any feedback via email!
        You can reach me at <code>harterrt</code> on gmail.
        Look forward to hearing from you!
    </p></div>]]>
            </description>
            <link>https://blog.harterrt.com/data_intuition.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916868</guid>
            <pubDate>Wed, 28 Oct 2020 09:33:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MongoDB Online Playground]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24916831">thread link</a>) | @kamagatos
<br/>
October 28, 2020 | https://www.humongous.io/app/playground | <a href="https://web.archive.org/web/*/https://www.humongous.io/app/playground">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.humongous.io/app/playground</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916831</guid>
            <pubDate>Wed, 28 Oct 2020 09:25:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ripcord – A cross-platform/native Slack/Discord client]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24916762">thread link</a>) | @tuananh
<br/>
October 28, 2020 | https://cancel.fm/ripcord/ | <a href="https://web.archive.org/web/*/https://cancel.fm/ripcord/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section id="description" aria-label="Description"><p>Ripcord is a desktop chat client for group-centric services like Slack and Discord. It provides a traditional compact desktop interface designed for power users. It's not built on top of web browser technology: it has a small resource footprint, responds quickly to input, and gets out of your way. Shareware is coming back, baby.</p></section><section id="features"><h2>Features</h2><ul><li>Not made from a web browser</li><li>Tabs</li><li>Multiple windows</li><li>Multiple accounts</li><li>Voice chat <small>(Discord OK, Slack WIP)</small></li><li>Graphical emoji and custom emoji</li><li>Tab completion for user names and emoji</li><li>Customizable fonts, colors, and sizes</li><li>Custom bookmark lists for easily accessing only the channels you actually use</li><li>Variable DPI and multi-monitor support</li><li>Low CPU and memory usage</li><li>Zero GPU usage</li><li>No tracking or analytics</li><li>No installer or forced updates</li></ul></section><section id="screenshots"><h2>Screenshots</h2></section><section id="download"><h2>Download</h2><article><h3>Windows</h3><a href="https://cancel.fm/dl/Ripcord_Win_0.4.26.zip">Ripcord Windows 0.4.26 (.zip)</a><ul><li><time>Updated 2020-06-21 04:06 UTC</time></li><li>Compatible with 64-bit Windows 7, 8, 8.1, and 10.</li></ul></article><article><h3>Mac</h3><a href="https://cancel.fm/dl/Ripcord_Mac_0.4.26.zip">Ripcord Mac 0.4.26 (.zip)</a><ul><li><time>Updated 2020-06-21 04:24 UTC</time></li><li>Compatible with macOS 10.12 Sierra and later.</li></ul></article><article><h3>Linux</h3><a href="https://cancel.fm/dl/Ripcord-0.4.26-x86_64.AppImage">Ripcord Linux 0.4.26 (AppImage)</a><ul><li><time>Updated 2020-06-21 04:11 UTC</time></li><li><a href="https://cancel.fm/dl/Ripcord-0.4.26-x86_64.AppImage.asc">PGP signature</a> (and <a href="https://keybase.io/cancel">public key on Keybase</a>)</li><li>x86-64. Requires glibc 2.19 or newer.</li><li>To run, <code>chmod +x</code> the AppImage file and execute it.</li></ul></article><details><summary>SHA256</summary><dl><dt>Windows</dt><dd>eaa6e9ef1ad1204f9a978d8653088e49a6b83c134cbe18d7cc6512510baa9c61</dd><dt>Mac</dt><dd>6d76e1ef7589df8d4b3816c8ee77701e03460f7edaa47717abb8ecb84999b6c8</dd><dt>Linux</dt><dd>784602ca1d8f86f7e8bb01603bc31682ad8d2c8be6e26fa33a423dec5f103445</dd></dl></details></section><section id="more-information" aria-label="More information"><ul><li><p><a href="https://dev.cancel.fm/changelog">Changelog and update notes</a></p></li><li><p><a href="https://dev.cancel.fm/issues">Bug reports and feature requests</a></p></li><li><p><a href="https://dev.cancel.fm/service_features">Status table of feature support in Slack and Discord</a></p></li><li><p>Join the <a href="https://discord.gg/XWbKGGv">Ripcord Discord server</a> or the <a href="https://join.slack.com/t/ripdev/shared_invite/enQtMzY1NjkxMDUxNzAxLTA1NTlmNWQzYzA5NzBmZDEzNDBlOTlkODIyZDk5ZmFkYzA5MmFjOTZjZDg4NTk5NDEyOGJjNDAwMTc5Njc5MjA">Ripcord Slack team</a> to get help, ask questions, or give feedback.</p></li></ul></section><section id="buy"><h2>Shareware</h2><p>Ripcord is shareware. You can try it without paying, but if you use the Slack features, you'll eventually need to pay up.</p><article><a href="https://ripcordchat.onfastspring.com/ripcord"><div><h3>Buy Ripcord License</h3><p><span>$20</span>
<span>USD</span>
<span>via FastSpring</span></p></div></a><ul><li>Not a subscription—never expires</li><li>Includes 1 year of free version upgrades</li><li>Windows, Mac, and Linux all in a single license</li><li>Use on as many personal computers as you want<br><small>(as long as you're the only person using it)</small></li></ul></article><p>Ripcord is developed by one person. Every license purchase goes a long way.</p><p>If you don't use Ripcord's Slack features, buying a license is optional.</p><p>The alpha/beta development preview phase does not count against the year of free upgrades that comes with a new license. If you a buy license now, the year of free upgrades is extended by the remaining length of the alpha/beta preview phase.</p><p>For enterprise or floating site licenses, <a href="mailto:cancel@cancel.fm">send me an email</a>. Enterprise licenses come with full source code access and high-priority feature requests. If you just need to buy a few licenses for use in an office, the FastSpring link above allows you to specify a quantity during checkout.</p><p>For help with orders and license keys (error during ordering, no license key delivered, mistaken order, lost license key, refund, etc.), or if you need some other type of support for Ripcord, you can send an email to my LLC's official support email address, <a href="mailto:support@acyclic.jp">support@acyclic.jp</a>, or to my personal email address, <a href="mailto:cancel@cancel.fm">cancel@cancel.fm</a>.</p><p>You can redistribute and share Ripcord with other people, including through package managers, as long as you follow these <a href="https://cancel.fm/ripcord/shareware-redistribution/">shareware redistribution rules</a>.</p></section><section id="qna"><h2>What the</h2><dl><dt>How do I prevent Ripcord from checking for updates before I'm able to open the preferences window to disable it?</dt><dd>Set the environment variable <code>RIPCORD_ALLOW_UPDATES=0</code></dd><dt>Where can I view the license information for the third-party components used in Ripcord?</dt><dd><a href="https://cancel.fm/ripcord/static/app_misc/additional_license_information.txt">License information for the third-party libraries used in Ripcord.</a> My thanks to the authors of these libraries for providing them.</dd><dt>Can I add Ripcord to a package manager?</dt><dd>Sure. Just make sure you follow <a href="https://cancel.fm/ripcord/shareware-redistribution/">these rules</a>.</dd></dl></section></div></div>]]>
            </description>
            <link>https://cancel.fm/ripcord/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916762</guid>
            <pubDate>Wed, 28 Oct 2020 09:12:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: FsKube-A full stack Kubernetes enabler now available for Django]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24916734">thread link</a>) | @rebataur
<br/>
October 28, 2020 | https://www.rebataur.com/tools/fskube#fskube | <a href="https://web.archive.org/web/*/https://www.rebataur.com/tools/fskube#fskube">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<section>
		<div>
			<p id="plan-switch">
				
				
			<h3>fsKube Pricing - Billed Annually</h3>
				
			</p>
			<div id="plan-items">
				<div>
					<div>
						<!--//plan-header-->
						
						<div>
							<p>Full Stack Django framework on Kubernetes on AWS</p>
							<ul>
								<li>Full AWS Cost breakdown dashboard</li>
								<li>Easily setup Kubernetes cluster in AWS</li>
								<li>Easily manage Kubernetes cluster in AWS</li>
								<li>Easily setup Kubernetes Components in AWS</li>
								<li>Easily setup Github project with kubernetes enabled Django template</li>
								<li>Automatically create Git branch strategy</li>
								<li>Automatically create Github actions for container registration</li>
								<li>Easy DevSecOps configuration for Dev, Quality and Production</li>
								<li>Fully integrated release management strategy with Github , Kubernetes and AWS</li>
								<li>Easily scale up or down Kubernetes cluster with Operations</li>
								<li>Single Screen health monitoring for all your Kubernetes Nodes and Pods</li>
								
								
								

							</ul>
						</div><!--//plan-content-->
					</div><!--//item-->
				</div><!--//col-->
			

				<div>
					<div>
						<!--//plan-header-->
						<p>Full Stack SpringBoot framework on Kubernetes on AWS</p>
						<ul>
							<li>Full AWS Cost breakdown dashboard</li>
							<li>Easily setup Kubernetes cluster in AWS</li>
							<li>Easily manage Kubernetes cluster in AWS</li>
							<li>Easily setup Kubernetes Components in AWS</li>
							<li>Easily setup Github project with kubernetes enabled Django template</li>
							<li>Automatically create Git branch strategy</li>
							<li>Automatically create Github actions for container registration</li>
							<li>Easy DevSecOps configuration for Dev, Quality and Production</li>
							<li>Fully integrated release management strategy with Github , Kubernetes and AWS</li>
							<li>Easily scale up or down Kubernetes cluster with Operations</li>
							<li>Single Screen health monitoring for all your Kubernetes Nodes and Pods</li>
							
							
							

						</ul>
					</div><!--//item-->
				</div><!--//col-->


				<div>
					<div>
						<!--//plan-header-->
						<p>Full Stack Ruby on Rails framework on Kubernetes on AWS</p>
						<ul>
							<li>Full AWS Cost breakdown dashboard</li>
							<li>Easily setup Kubernetes cluster in AWS</li>
							<li>Easily manage Kubernetes cluster in AWS</li>
							<li>Easily setup Kubernetes Components in AWS</li>
							<li>Easily setup Github project with kubernetes enabled Django template</li>
							<li>Automatically create Git branch strategy</li>
							<li>Automatically create Github actions for container registration</li>
							<li>Easy DevSecOps configuration for Dev, Quality and Production</li>
							<li>Fully integrated release management strategy with Github , Kubernetes and AWS</li>
							<li>Easily scale up or down Kubernetes cluster with Operations</li>
							<li>Single Screen health monitoring for all your Kubernetes Nodes and Pods</li>
							
							
							

						</ul>
					</div><!--//item-->
				</div><!--//col-->
					

		
			</div><!--//row-->

			
		</div><!--//container-fluid-->
	</section><!--//plans-section-->




</div><section>
		
		
		<div>
			<h3>Get Started in No Time with Kubernetes, DevSecOps and Full Stack Development</h3>
			<p>Rebataur makes it super easy to get your
				Kubernetes cluster up and working with all the necessary tools and technology and a fully functioning DevSecOps pipeline.
				All under your control.
			</p>
			
		</div>
	</section></div>]]>
            </description>
            <link>https://www.rebataur.com/tools/fskube#fskube</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916734</guid>
            <pubDate>Wed, 28 Oct 2020 09:06:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Draw on a PDF Online]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24916721">thread link</a>) | @perrys
<br/>
October 28, 2020 | https://www.goodannotations.com/tools/draw-on-pdf | <a href="https://web.archive.org/web/*/https://www.goodannotations.com/tools/draw-on-pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><h2>Replace pen and paper by drawing on PDF online</h2><p>Pen and papers are slow and inefficient. Leave the slow school tools in the past, quickly jot down, circle, and draw pointers on PDF documents. Draw your thoughts and markups on the screen as fast as they come to mind. The free pdf editor lets you use any stylus to draw on PDF online better and more effectively. Simply pick the right tool and the right color and draw online. </p><h2>Avoid friction and draw directly on your PDF document</h2><p>Less friction means more accomplishment. Taking your PDFs online and drawing with the right tools is fast, convenient, and easy to use. Don’t waste time with bulky software and confusing tool manuals. Focus on the message, not the technicals, and draw on PDF like a professional. </p><h2>Draw with a better markup and annotation PDF editor </h2><p>Take the lead on your project and stay in charge. Indicate and suggest what should be changed, improved, and deleted from any PDF document. Circle the problematic text, draw a pointer, and explain why that part of the PDF document should get more attention than the rest. Your team members will appreciate better digital communication.</p><h2>Deliver product guides and how-to material in PDF</h2><p>Create product guides that look and feel professional and trustworthy. Nothing says we’re a serious project better than a nicely done PDF catalog of how-to product guides. Take screenshots of your digital product, and draw on PDF online. Simply choose the PDF option when you download the file or share it with a link.</p><h2>Most PDF tools don’t let you draw in PDF documents </h2><p>Regular PDF software lets you only open and read the file. And even when you find an inexpensive and reasonably understandable pdf editor, you probably can’t add pointers, circles, squares, and other elements. Avoid the trouble, and upload your PDF to the best online PDF editor and simply jot the details down on PDF.</p><h2>Delete, change or reverse any PDF drawing online</h2><p>Never lose track of your work by having to start all over again after a careless mistake. Click on the bent arrow to undo any drawings on your document, and try again without damaging your design. Backspace and the trash bin icon will help you delete a specific element. Use the pointer to select a troublesome drawing and remove it with one click on the trash bin icon.</p><h2>Draw on PDF from any internet devices and gadget</h2><p>Tablets, mobile phones, and MacBooks are all fantastic devices to draw on PDF online. As long as you have an internet connection, you can draw your stylus, fingers, trackpad, and mouse on any PDF file. Jot down your ideas on the move, and share them digitally from anywhere and at any time. </p><h2>Draw for free with no trial accounts and data retention</h2><div><p>Don’t start a free month because you don’t need to pay to edit PDF documents. Enjoy smooth and frictionless PDF drawings wholly free and online. You can transform your PDF files into professional-looking project guides and give classy feedback to other project members with Good Annotations.</p><p>We’re thinking about premium features for different tools. Come back soon to discover optimized teamwork, collaborative editing, and organized file libraries. </p></div></div></div></div></div>]]>
            </description>
            <link>https://www.goodannotations.com/tools/draw-on-pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916721</guid>
            <pubDate>Wed, 28 Oct 2020 09:04:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emerging JavaScript pattern: multiple return values]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24916683">thread link</a>) | @loige
<br/>
October 28, 2020 | https://loige.co/emerging-javascript-pattern-multiple-return-values | <a href="https://web.archive.org/web/*/https://loige.co/emerging-javascript-pattern-multiple-return-values">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>In this article, I want to explore an interesting pattern that I am seeing more and more in JavaScript code which allows you to return multiple values from a function.</p>
<p>You probably know already that JavaScript does not support multiple return values natively, so this article will actually explore some ways to “simulate” this behavior.</p>
<p>One of the most famous usages of this pattern I have seen recently is within <a href="https://reactjs.org/docs/hooks-overview.html">React Hooks</a>, but before delving into that, let’s see what I mean with “multiple return values” by exploring this concept in other languages.</p>
<h2 id="multiple-return-values-in-other-languages"><a href="#multiple-return-values-in-other-languages" aria-label="multiple return values in other languages permalink"></a>Multiple return values in other languages</h2>
<p>Two languages that come to my mind which natively support multiple return values are Lua and Go. Let’s implement a simple <em>integer division</em> function that returns both the <em>quotient</em> and the <em>remainder</em>.</p>
<h3 id="lua"><a href="#lua" aria-label="lua permalink"></a>Lua</h3>
<p>Let’s start with a simple implementation in Lua. It’s definitely worth mentioning that <a href="https://www.lua.org/pil/5.1.html">Lua’s official documentation</a> defines multiple return values as <em>“An unconventional, but quite convenient feature”</em>:</p>
<div data-language="lua"><pre><code><span>function</span> <span>intDiv</span> <span>(</span>dividend<span>,</span> divisor<span>)</span>
  <span>local</span> quotient <span>=</span> math<span>.</span><span>floor</span><span>(</span>dividend <span>/</span> divisor<span>)</span>
  <span>local</span> remainder <span>=</span> dividend <span>%</span> divisor
  <span>return</span> quotient<span>,</span> remainder
<span>end</span>

<span>print</span><span>(</span><span>intDiv</span><span>(</span><span>10</span><span>,</span><span>3</span><span>)</span><span>)</span> </code></pre></div>
<h3 id="go"><a href="#go" aria-label="go permalink"></a>Go</h3>
<p>Here’s some equivalent code in Go:</p>
<div data-language="go"><pre><code><span>package</span> main

<span>import</span> <span>"fmt"</span>

<span>func</span> <span>intDiv</span><span>(</span>dividend<span>,</span> divisor <span>int</span><span>)</span> <span>(</span><span>int</span><span>,</span> <span>int</span><span>)</span> <span>{</span>
  quotient <span>:=</span> dividend <span>/</span> divisor
  remainder <span>:=</span> dividend <span>%</span> divisor
  <span>return</span> quotient<span>,</span> remainder
<span>}</span>

<span>func</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  fmt<span>.</span><span>Println</span><span>(</span><span>intDiv</span><span>(</span><span>10</span><span>,</span><span>3</span><span>)</span><span>)</span> 
<span>}</span></code></pre></div>
<p>As you can see in these 2 code snippets, functions can return more than 1 value and this can be very convenient in cases where you logically have produce multiple outputs in a computation.</p>
<p><strong>Note</strong>: a more realistic implementation in Go, would take into account errors (e.g. division by 0) and add an extra return value to propagate potential errors. We shouldn’t worry too much about this for the sake of this article, but it is definitely worth mentioning that multiple return values in Go shine when it comes to error propagation and error handling. We will touch a bit more on this later in this article to see how this idea can be applied to JavaScript as well, especially in the context of Async/Await.</p>
<h2 id="simulating-multiple-return-values-in-javascript"><a href="#simulating-multiple-return-values-in-javascript" aria-label="simulating multiple return values in javascript permalink"></a>Simulating multiple return values in JavaScript</h2>
<p>So, as we said early on, JavaScript does not natively support a syntax to return more than one value from a function. We can workaround this limitation by using <em>composite values</em> like arrays or objects.</p>
<h3 id="multiple-return-values-with-arrays"><a href="#multiple-return-values-with-arrays" aria-label="multiple return values with arrays permalink"></a>Multiple return values with arrays</h3>
<p>Let’s implement our <code>intDiv</code> in JavaScript by using arrays as return types:</p>
<div data-language="javascript"><pre><code><span>intDiv</span> <span>=</span> <span>(</span><span>dividend<span>,</span> divisor</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> quotient <span>=</span> Math<span>.</span><span>floor</span><span>(</span>dividend <span>/</span> divisor<span>)</span>
  <span>const</span> remainder <span>=</span> dividend <span>%</span> divisor
  <span>return</span> <span>[</span>quotient<span>,</span> remainder<span>]</span>
<span>}</span>

console<span>.</span><span>log</span><span>(</span><span>intDiv</span><span>(</span><span>10</span><span>,</span> <span>3</span><span>)</span><span>)</span> </code></pre></div>
<p>Here we are just printing the result of a division, but let’s assume we want to handle the two return values individually, how do we <em>reference</em> those?</p>
<p>Well, the return value is an array so we can simply access the two elements in the array using the indices <code>0</code> and <code>1</code>:</p>
<div data-language="javascript"><pre><code><span>const</span> result <span>=</span> <span>intDiv</span><span>(</span><span>10</span><span>,</span> <span>3</span><span>)</span>
<span>const</span> quotient <span>=</span> result<span>[</span><span>0</span><span>]</span>
<span>const</span> remainder <span>=</span> result<span>[</span><span>1</span><span>]</span>
console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Quotient = </span><span><span>${</span>quotient<span>}</span></span><span>`</span></span><span>)</span> 
console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Remainder = </span><span><span>${</span>remainder<span>}</span></span><span>`</span></span><span>)</span> </code></pre></div>
<p>This syntax is arguably verbose and definitely not very elegant. Thankfully, <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment">ES2015 array destructuring assignment</a> can help us here:</p>
<div data-language="javascript"><pre><code><span>const</span> <span>[</span>quotient<span>,</span> remainder<span>]</span> <span>=</span> <span>intDiv</span><span>(</span><span>10</span><span>,</span> <span>3</span><span>)</span>
console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Quotient = </span><span><span>${</span>quotient<span>}</span></span><span>`</span></span><span>)</span> 
console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Remainder = </span><span><span>${</span>remainder<span>}</span></span><span>`</span></span><span>)</span> </code></pre></div>
<p>This is much nicer to read and we also trimmed away 2 out 3 lines of code, big win!</p>
<p>As nice as it is, this implementation has an important shortcoming: return values are positional, so you need to be careful and respect the order while destructuring.</p>
<h3 id="multiple-return-values-with-objects"><a href="#multiple-return-values-with-objects" aria-label="multiple return values with objects permalink"></a>Multiple return values with objects</h3>
<p>An alternative implementation could use objects as return value, let’s see how:</p>
<div data-language="javascript"><pre><code><span>intDiv</span> <span>=</span> <span>(</span><span>dividend<span>,</span> divisor</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> quotient <span>=</span> Math<span>.</span><span>floor</span><span>(</span>dividend <span>/</span> divisor<span>)</span>
  <span>const</span> remainder <span>=</span> dividend <span>%</span> divisor
  <span>return</span> <span>{</span> quotient<span>,</span> remainder <span>}</span>
<span>}</span></code></pre></div>
<p>Note that here we are using another syntactic sugar from ES2015 (Enhanced object literal syntax) that allows us to define objects very concisely. Prior to ES2015, we would have defined the return statement as <code>{quotient: quotient, remainder: remainder}</code>.</p>
<p>With this approach we will be able to use our <code>intDiv</code> function as follows:</p>
<div data-language="javascript"><pre><code><span>const</span> result <span>=</span> <span>intDiv</span><span>(</span><span>10</span><span>,</span> <span>3</span><span>)</span>
<span>const</span> quotient <span>=</span> result<span>.</span>quotient
<span>const</span> remainder <span>=</span> result<span>.</span>remainder
console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Quotient = </span><span><span>${</span>quotient<span>}</span></span><span>`</span></span><span>)</span> 
console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Remainder = </span><span><span>${</span>remainder<span>}</span></span><span>`</span></span><span>)</span> </code></pre></div>
<p>Again, this is a bit too verbose and ES2015 has another fantastic syntactic sugar to make this nicer:</p>
<div data-language="javascript"><pre><code><span>const</span> <span>{</span> quotient<span>,</span> remainder <span>}</span> <span>=</span> <span>intDiv</span><span>(</span><span>10</span><span>,</span> <span>3</span><span>)</span>
console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Quotient = </span><span><span>${</span>quotient<span>}</span></span><span>`</span></span><span>)</span> 
console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Remainder = </span><span><span>${</span>remainder<span>}</span></span><span>`</span></span><span>)</span> </code></pre></div>
<p>This syntactic sugar is called <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment#Object_destructuring">Object Destructuring Assignment</a>. With this approach we are now independent from the position of return values (we can swap the position of <code>quotient</code> and <code>remainder</code> without side effects). This syntax also lets you rename the destructured variables, which can very useful to avoid name collisions with other local variables, or just to make variable names shorter or more descriptive as we please. Let’s see how this works:</p>
<div data-language="javascript"><pre><code><span>const</span> <span>{</span> remainder<span>:</span> r<span>,</span> quotient<span>:</span> q <span>}</span> <span>=</span> <span>intDiv</span><span>(</span><span>10</span><span>,</span> <span>3</span><span>)</span>
console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Quotient = </span><span><span>${</span>q<span>}</span></span><span>`</span></span><span>)</span> 
console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Remainder = </span><span><span>${</span>r<span>}</span></span><span>`</span></span><span>)</span> </code></pre></div>
<p>Here we are not dependent by values position, but by their names in the returned object. If you are designing an API with multiple return values, it’s up to you to figure out which trade off will be the best to guarantee a proper developer experience.</p>
<p>Ok, now you should have a good idea on how to simulate multiple return values in JavaScript. In the next section we will see some more realistic examples that take advantage of this pattern.</p>
<h2 id="some-more-realistic-use-cases"><a href="#some-more-realistic-use-cases" aria-label="some more realistic use cases permalink"></a>Some more realistic use cases</h2>
<p>As mentioned early on, this technique has been recently popularized by React hooks, so we are gonna explore this use case first. Later we will see other two cases related to Async/Await.</p>
<h3 id="react-hooks"><a href="#react-hooks" aria-label="react hooks permalink"></a>React Hooks</h3>
<p>React hooks are a <a href="https://reactjs.org/docs/hooks-overview.html">new feature proposal</a> available from <em>React v16.7.0-alpha</em> that lets you use state and other React features without having to write a class.</p>
<p>The first and most famous React hook present is called <strong>State Hook</strong>.</p>
<p>Let’s see how it works with an example, let’s build a CSS color viewer component.</p>
<p>Here’s how our component is going to look like:</p>
<p><img src="https://loige.co/content/4c8fe2a31135971902611822ca2f3df2/css-color-viewer-demo.gif" alt="CssColorViewer React component demo"></p>
<p>And here’s the code used to implement this:</p>
<div data-language="javascript"><pre><code><span>import</span> <span>{</span> useState <span>}</span> <span>from</span> <span>'react'</span>

<span>function</span> <span>CssColorViewer</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>cssColor<span>,</span> setCssColor<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>'Blue'</span><span>)</span>
  

  <span>const</span> <span>onCssColorChange</span> <span>=</span> <span>e</span> <span>=&gt;</span> <span>{</span>
    <span>setCssColor</span><span>(</span>e<span>.</span>target<span>.</span>value<span>)</span>
  <span>}</span>

  <span>return</span> <span>(</span>
    <span>&lt;</span>div<span>&gt;</span>
      <span>&lt;</span>input value<span>=</span><span>{</span>cssColor<span>}</span> onChange<span>=</span><span>{</span>onCssColorChange<span>}</span> <span>/</span><span>&gt;</span>
      <span>&lt;</span>div
        style<span>=</span><span>{</span><span>{</span>
          width<span>:</span> <span>100</span><span>,</span>
          height<span>:</span> <span>100</span><span>,</span>
          background<span>:</span> cssColor<span>,</span>
        <span>}</span><span>}</span>
      <span>/</span><span>&gt;</span>
    <span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>)</span>
<span>}</span></code></pre></div>
<p>You can see this component in action and play with the code on <a href="https://codesandbox.io/s/9lzyov54lr">CodeSandbox</a>.</p>
<p>For the sake of this article, we are going to focus only on the <code>useState</code> call, but if you are curious to understand better how the hook itself works internally I really recommend you read the <a href="https://reactjs.org/docs/hooks-state.html">official State Hook documentation</a>. I was personally curious to understand how multiple <code>useState</code> calls could maintain the relationship with the specific state attribute (since there’s no explicit labelling or reference). If you are curious about that too, well you should read the <a href="https://reactjs.org/docs/hooks-faq.html#how-does-react-associate-hook-calls-with-components">Hooks FAQ</a> and <a href="https://medium.com/@dan_abramov/making-sense-of-react-hooks-fdbde8803889">Dan Abramov’s recent article about Hooks</a>.</p>
<p>Back to the <code>useState</code> call in our example, now!</p>
<p>The <code>useState</code> hook acts like a factory: given a default value for the state property (<code>'Blue'</code> in our case), it will need to instantiate for you 2 things:</p>
<ul>
<li>the current value for the specific state property (<code>cssColor</code> in our case)</li>
<li>a function that allows you to alter the specific property (<code>setCssColor</code> in our case)</li>
</ul>
<p>React developers decided to handle this requirement by simulating multiple return values with an array.</p>
<p>Combining this with array destructuring and proper variable naming, the result is an API that is very nice to read and to use.</p>
<p>This React feature is still very experimental and subject to change at the time of writing, but it already sounds like a big deal for the React community to make the code more expressive and reduce the barrier to entry to start adopting React.</p>
<p>The point I want to make is that, in this specific case, the multiple return values pattern plays a big role towards this goal.</p>
<h3 id="converting-callbacks-api-to-asyncawait"><a href="#converting-callbacks-api-to-asyncawait" aria-label="converting callbacks api to asyncawait permalink"></a>Converting callbacks API to Async/Await</h3>
<p>Recently I found another great use case for the multiple return values pattern while trying to convert a callback oriented API into an equivalent Async/Await API.</p>
<p>To make this part clear, I am going to explain very quickly an approach I use to convert callback based APIs into functions that I can use with Async/Await.</p>
<p>Let’s take this generic example:</p>
<div data-language="javascript"><pre><code><span>function</span> <span>doSomething</span><span>(</span><span>input<span>,</span> callback</span><span>)</span> <span>{</span>
  
  
  
  <span>callback</span><span>(</span>error<span>,</span> response<span>)</span>
<span>}</span></code></pre></div>
<p>To convert this function into something that can be used with Async/Await we have to essentially <a href="https://loige.co/to-promise-or-to-callback-that-is-the-question/"><em>promisify</em></a> it. There are libraries to do it and, if you are using Node.js you can even use the builtin <a href="https://nodejs.org/api/util.html#util_util_promisify_original"><code>util.promisify</code></a>, but that’s something we can do ourselves by just creating a <em>wrapper</em> function like the following one:</p>
<div data-language="javascript"><pre><code><span>const</span> <span>doSomethingPromise</span> <span>=</span> <span>(</span><span>input</span><span>)</span> <span>=&gt;</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve<span>,</span> reject</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>doSomething</span><span>(</span>input<span>,</span> <span>(</span><span>error response</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span>error<span>)</span> <span>{</span>
      <span>return</span> <span>reject</span><span>(</span>error<span>)</span>
    <span>}</span>

    <span>return</span> <span>resolve</span><span>(</span>response<span>)</span>
  <span>}</span><span>)</span>
<span>}</span><span>)</span></code></pre></div>
<p>In short, our wrapper function <code>doSomethingPromise</code> is immediately returning a <code>Promise</code>. Inside the body of the promise we are invoking the original <code>doSomething</code> function with a callback that will be resolving or rejecting the promise based on whether there’s an <code>error</code> or not.</p>
<p>Now we can finally take advantage of Async/Await:</p>
<div data-language="javascript"><pre><code>
<span>const</span> response <span>=</span> <span>await</span> <span>doSomethingPromise</span><span>(</span>input<span>)</span></code></pre></div>
<p><strong>Note</strong>: this will throw in case of error, so make sure you have it in a <code>try/catch</code> block to handle the error correctly.</p>
<blockquote>
<p>If you are curious about <em>promisifying</em> callback-based functions, I have <a href="https://loige.co/to-promise-or-to-callback-that-is-the-question/">an entire article</a> dedicated to this topic.</p>
</blockquote>
<p>In my specific use case, I was using a <a href="https://www.npmjs.com/package/twitter">twitter client</a> library that follows this conventions:</p>
<div data-language="javascript"><pre><code>
client<span>.</span><span>get</span><span>(</span><span>'statuses/user_timeline'</span><span>,</span> params<span>,</span> <span>function</span> <span>callback</span>…</code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://loige.co/emerging-javascript-pattern-multiple-return-values">https://loige.co/emerging-javascript-pattern-multiple-return-values</a></em></p>]]>
            </description>
            <link>https://loige.co/emerging-javascript-pattern-multiple-return-values</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916683</guid>
            <pubDate>Wed, 28 Oct 2020 08:56:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Was Remote YC Like?]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24916629">thread link</a>) | @crowdhailer
<br/>
October 28, 2020 | https://www.richardesigns.co.uk/2020/10/27/what-was-remote-yc-like.html | <a href="https://web.archive.org/web/*/https://www.richardesigns.co.uk/2020/10/27/what-was-remote-yc-like.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <nav>
    <a href="https://www.richardesigns.co.uk/">Home</a>
  </nav>
  
  <p>Summer 2020 saw the first completely remote YC batch in history.  My co-founder Peter and I were fortunate enough to participate with our company <a href="https://plummail.co/">Plum Mail</a> and we did so entirely remotely from our homes in South West England.</p>

<p>What was it like you ask?  Essentially, it was like taking an e-learning course. This had a number of benefits for us as a team, which are totally valid, but a number of disadvantages surface as you progress through the process.</p>

<p>The whole YC team did a genuinely amazing job of making the experience hugely valuable, exciting and accessible.  As a founder, your challenge is to step up to the plate and embrace the process if you want to get the most out of it.  Being aware of the disadvantages of the remote batch means you can come up with creative ways to get around them.</p>

<p>Hopefully, this blog will help you feel ready to embrace a remote YC batch, so here’s what doing a remote YC batch is really like.</p>

<h2 id="1-the-interview">1. The Interview</h2>

<p>This is your first remote YC experience.  It’s on a Zoom call that will last around fifteen minutes.  You’re probably feeling nervous and it may be a very weird time of day depending on your time zone.  For us, the interview was at 5pm BST / 9am PST so I had all day to get worked up about it!</p>

<p>For some of our batchmates, calls were at even less convenient times (try midnight) although YC are sensitive to this and will try to accommodate speaking to you at a time that suits everyone on the call.</p>

<p>This combination of timezone conflict and the usual pre-interview nerves are kinda toxic on a video call. You have to work hard to come across as calm, confident and competent.</p>

<p>It felt like sitting in a TV studio waiting to go on air. There is no time for pleasantries as you might expect in person. There is no time for technical errors either. In fact, my internet dropped out at the very end of the call but I only missed a few seconds of the conversation.</p>

<p>I wish deeply that I had gotten used to doing video calls before the interview. Weird as that sounds mid-pandemic, before Covid I had barely done 10 video calls my entire life and now I was doing arguably the most valuable Zoom call I might ever do.</p>

<p>All in all it was quite a stressful experience that I could have aced with some simple steps. Having said that, we were accepted into the batch so it can’t have been that bad.</p>

<h3 id="yc-interview-takeaways">YC Interview Takeaways</h3>

<ol>
  <li>
    <p>Get comfortable on video calls.  Take a moment to figure out where best for a clean background.  Sit or stand facing a window or other source of light so you don’t look like a shawdow puppet.  Aim for getting your whole head, shoulders and upper body into the shot roughly square on.</p>
  </li>
  <li>
    <p>Chill before the call.  The interviewer just wants to have a chat with you about you and your product.  Nervous people tend to ramble.  If you can come across as calm and confident you’ll have a more natural, authentic conversation.</p>
  </li>
  <li>
    <p>Smile. Be yourself.</p>
  </li>
  <li>
    <p>If the interview slot is at 2am local time ask them to consider re-arranging it.  No one is their best at 2am, unless you are your best at 2am in which case, I guess 2am is fine. Don’t be afraid to ask nicely if the interview time is massively inconvenient for you.</p>
  </li>
  <li>
    <p>Jazz up your internet connection.  You’ll be doing a lot of video calls if you get into the batch and at remote demo day, a sturdy, fast internet connection is essential so why not start now and have a decent connection for the interview too.</p>
  </li>
</ol>

<h2 id="2-your-remote-working-arrangements">2. Your remote working arrangements</h2>

<p>Peter and I are used to working remote with meetings every so often. However, local restrictions meant we couldn’t always meet up when we needed to.  This definitely created issues for us in terms of communication.  We would try to use instant messenger but found this quickly descended into hours of wasted typing when a phone call or meeting would have been much faster.</p>

<p>Working remote for me also equalled working alone most of the day.  I started out with great focus but would often go astray as my thoughts outpaced my ability to deliver.</p>

<p>This process was compounded during the batch because of the pressure to deliver impressive progress. During the batch you are expected to pull out all the stops to get progress made and I think this is reasonable and exciting.  YC is a once (sometimes twice, rarely three times) in a lifetime opportunity.</p>

<p>Overtime, we got good at working remotely in an efficient and productive way but it took a couple of tries to get it right.</p>

<p>What works for us is a daily catch up call at the same time every day. There is always plenty to talk about and it’s something to hold onto if you’re feeling adrift.  Every Friday we travel and get together (assuming local restrictions allow it) for a strategy day.</p>

<p>Time-boxing strategy talk to Fridays is a very efficient way to timebox ‘big chat’ so that the other four days a week your focus is on actions.</p>

<p>This aspect of the batch experience is probably the most different to an in-person batch where you’re living in a flat with your founders and you eat, sleep, breathe your company.</p>

<p>I’d say it’s totally worth optimising your remote working arrangements so you can make the most of the productive time you have during the batch. The more progress you make, the more you’ll be able to leverage out of the process as the weeks go by.</p>

<h2 id="3-bootcamp">3. Bootcamp</h2>

<p>The first two weeks of remote YC are intense.  Somehow it seemed more intense from the comfort of my own home.  Bootcamp introduces you to an almost overwhelming number of talks and presentations that cover pretty much every aspect of running a startup.</p>

<p>It’s really exciting!  It’s also all on-screen.  Pretty much everything is on video call from here on in.</p>

<p>Each day of bootcamp typically starts with a rousing introduction by a YC partner followed by a series of talks by YC Alum, well-known entrepreneurs or investors and after all of that you are thrust into a video call with a random selection of batchmates to discuss what you just heard.</p>

<p>It all takes around three hours.</p>

<p>The content was all hugely valuable.  Somehow it felt harder to access the value remotely. When you’re watching someone speak live it’s somehow more immersive, over video call I felt disconnected and at times distracted.</p>

<p>However, it is much easier to make notes if you’re sat at a desk listening to the talk rather than trying to jot onto a notepad perched on your knee in a lecture theatre.</p>

<p>And that’s what made the remote bootcamp awesome for me.  I started each talk with a plan to make notes throughout.  This gave me a task to do to keep me interested and the output remains a valuable resource on which to draw.</p>

<p>Some of the insights you pick up might not seem relevant at the time but six months in they suddenly make perfect sense.</p>

<p>If you’re in a non Pacific time zone, like I was, be kind to yourself and take a little time off-screen before the video calls kick in.  Bootcamp will be much easier if you’re feeling fresh and don’t have eye-strain already from an 8 hour day coding.</p>

<p>For me, bootcamp started at 5pm BST so I typically took an hour or so from 4pm away from the computer to get some air, a little food and exercise before the talks began.  A few times I worked through and hopped into bootcamp last minute.  That’s when I felt least engaged largely because I was through with working for the day before the bootcamp had even started.</p>

<h2 id="4-serendipity">4. Serendipity</h2>

<p>It’s not what you know, it’s who you know.  This is true as far as I’m concerned and to be candid, a remote YC batch does not lend itself to chance-encounters and lunch-queue friendships.</p>

<p>Those ‘water cooler moments’ obviously don’t happen so, YC tried to create virtual equivalents of this magic sauce.  This is so important because your batchmates are potential customers, employees, introducers, a shoulder to cry on and someone to celebrate with.</p>

<p>After bootcamp and dinner talks, YC hosts video calls with up to seven participants in each one and you’re dropped randomly into one.  What you get are seven people who don’t know each other but have two things in common: 1, they are a company founder in your batch and 2, they just watched the same talk as you.</p>

<p>At times these were extremely awkward with no one speaking or maybe one person dominating the conversation completely.  However, some of the calls were really engaging and it’s a good chance to get to know a few folks.   Soon enough you make friends and you’ll be setting up video calls for virtual coffee before you can say pumpkin latte.</p>

<p>YC also invited us to participate in random founder pairings in which two founders were randomly introduced to each other and invited to have a 30 minute call.  This resulted in some awesome friendships that continue to add value on a personal and professional level.</p>

<p>These moments of serendipity aren’t really serendipitous at all, they are forced, however, they do a good job of replacing the serendipity where it just isn’t practical to have 400 people in the same room at the moment.</p>

<p>So, embrace it.  Yes it’s slightly forced but approach it with an open mind and an open heart and you’ll be pleasantly surprised.</p>

<h2 id="5-office-hours">5. Office Hours</h2>

<p>Every two weeks we were invited to participate in a video call always with the same group of people for what YC call Group Office Hours.  It’s like group therapy.  You get to know the folks in your group probably more intimately than any of your other batchmates.</p>

<p>Since you’ll be spending a lot of time with these guys on video calls, I would definitely reach out to them outside of office hours to say hello and to allow yourself time to get to know each other.</p>

<p>This really helped me get more out of the office hours.  We’re all probably a little shy around new people but if you get to know everyone better, you’ll be able to access more value from the process faster.  It just requires more effort remotely because you can’t read people so easily.</p>

<h2 id="6-success-and-failure">6. Success and Failure</h2>

<p>Any startup journey is a rollercoaster.  When we enjoyed success …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.richardesigns.co.uk/2020/10/27/what-was-remote-yc-like.html">https://www.richardesigns.co.uk/2020/10/27/what-was-remote-yc-like.html</a></em></p>]]>
            </description>
            <link>https://www.richardesigns.co.uk/2020/10/27/what-was-remote-yc-like.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916629</guid>
            <pubDate>Wed, 28 Oct 2020 08:47:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sudden Changes in UI: Why It's a Bad Move]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24916574">thread link</a>) | @yllow
<br/>
October 28, 2020 | https://blog.snappymob.com/sudden-changes-in-ui-why-its-a-bad-move | <a href="https://web.archive.org/web/*/https://blog.snappymob.com/sudden-changes-in-ui-why-its-a-bad-move">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>There’s a reason why change aversion in users is so often spoken about in the world of digital consumerism <span>— </span>human beings love their comfort zones. In the grand scheme of things, we seek out what is familiar to us for a sense of security.</p>
<!--more-->
<p>Keeping your software product updated is important, but it’s also important to make sure the perfective changes you make are within the bounds of what your users are familiar and comfortable with.</p>
<p>Now, what kinds of changes might we be referring to?&nbsp;</p>
<p>The types of changes that can be introduced in a software product are changes in infrastructure, functionality, and interface. Among them, interface changes incite the biggest reactions from users. That’s because it’s the most forefront part of a product that they see and interact with <span>— layout, tabs, fonts, colors, buttons, animation, etc</span>.</p>
<p><span>When introducing changes in this aspect of your product, both psychology and history say you should take it slow.</span></p>
<h2><strong>What Psychology Tells Us&nbsp;</strong></h2>
<p>To discuss why sudden and major UI changes backfire from a psychological point of view, we have to address change aversion.&nbsp;</p>
<p>There have been many cases where consumers refused to adapt to a new product, even if it was objectively “better”. One good example would be the introduction of the <a href="https://www.dvorak-keyboard.com/"><span>Dvorak keyboard</span></a> in the 1930s.</p>
<p>Even&nbsp;though the Dvorak keyboard promoted objectively better physical ergonomics, people refused to move from the QWERTY keyboard <span>—</span> simply because they were used to it.&nbsp;</p>
<p>Why is that?</p>
<h3><strong>Users Want to Feel Smart</strong></h3>
<p>It’s widely taught by UIUX experts like Rohan Puri and Robert Youmans, that users are aversive to change because “change makes them feel dumb”. When using your product, users want to feel in control, like they know what they’re doing.&nbsp;</p>
<p>Especially for neurodivergent users, big and sudden changes in UI can be disorienting. When you change things around all at once, you’re also making your users relearn what they’d previously mastered before <span>— and that takes time and energy. In other words, you’re giving them work to do.</span></p>
<p>If you’re an app or web developer, always remember that your users aren’t sitting next to you, watching you iterate and develop from scratch. Your interface may seem simple to you because you’ve familiarized with it as you worked on it, but that’s not the case for them.</p>
<h3><strong>Value is Invisible</strong></h3>
<p>Confirming many real-life cases, a study by Rosman et al on <a href="https://www.researchgate.net/publication/262411663_On_user_behaviour_adaptation_under_interface_change"><span>user behaviour adaptation under interface change</span></a> found that it takes many tries for a user to feel comfortable enough with an interface that was initially unfamiliar to them, before they “conﬁdently choose it and realise the potential beneﬁts”.</p>
<p>Because the bulk of your revamp’s value is neither visible nor instantly detectable, more impatient users might poorly estimate the efﬁciency of your improved UI and “prematurely abandon it” in that particular time frame.</p>
<p>After all, if they don’t see an increase in value, why would they like that you changed what was already working for them?</p>
<h2><strong>What History Tells Us</strong></h2>
<p>Negative feedback from a large number of users can spread like wildfire on social media. Needless to say, that can be really detrimental to your brand and product.</p>
<p>If you’re a startup just starting out with a small user base, you have more leeway for major UI redesigns while you figure out your brand and voice. As your product grows, however, so does the need to prioritize your users’ preferences.&nbsp;</p>
<p>Some companies with really big user bases learned the hard way so we don’t have to.&nbsp;</p>
<h3><strong>What Happened with Digg</strong></h3>
<p>In 2010, Digg, a news aggregate site very much like reddit, launched a redesign that caused them to lose 35% of their users nearly instantly.</p>
<p>In the Digg v4 update, the site was heavily revamped visually and functionally. Among many of the sudden changes, the downvote button was removed, users could no longer save posts to favorites or posts videos,&nbsp; their Upcoming page was gone, and the overall focus was shifted from user-submitted content to publisher-submitted content.&nbsp;</p>
<p>This major change didn’t just disorient their users. It took control away from them. With the new system, posts by publishers and sponsors flooded the front page, while posts by regular users were practically invisible.&nbsp;</p>
<p>The result of this? A mass exodus. Users either flooded the site with protest links (many of which were links to Reddit, their biggest competitor) or immediately migrated to Reddit.&nbsp;</p>
<h3><strong>What Happened with eBay</strong></h3>
<p>Once, eBay decided to change the background color of many of their site’s pages from bright yellow to white. Even though this change may seem like an obvious aesthetic choice today, it caused a ruckus on the internet (and in the team’s mailbox) when it first happened, forcing them to revert to yellow.</p>
<p>eBay didn’t give up on their vision, though. They came up with a strategy to go subtle, and designed an algorithm that faded the background from yellow to white, one shade at a time, over a few months. This time, the internet was still. The change was taking place so gradually that their users didn’t notice it was happening.</p>
<h2><strong>How Do You Safely Revamp?</strong></h2>
<p>Now that storytime is over, let’s talk about what we can learn from them. How can you revamp your product while being wary of change aversion?&nbsp;</p>
<p>Obviously, getting complaints from users doesn’t mean you should stop updating your app or website. <span>M</span>aintenance is necessary for your product to thrive and continue thriving.<span> The secret lies in </span><em><span>how</span></em><span> you execute it.</span></p>
<h3><strong>Change Little and Often</strong></h3>
<p>Instead of giving your users a whole new interface to relearn at one go, introduce a little change at a time. Habits take time to unlearn. Giving users one small redirection at a time is a lot less disorienting and burdensome for them.</p>
<h3><strong>Give Users a Heads-up&nbsp;</strong></h3>
<p>Before you launch your redesign, give users time to prepare for it. This will dampen the impact of the launch and reduce the risk of shocking them into frustration with your product.&nbsp;</p>
<h3><strong>Spell Out the Values</strong></h3>
<p>As mentioned before, values are invisible. Users don’t always immediately see the benefits of your new interface when they first try it. Instead of waiting for them to figure the maze out on their own, give them the lowdown on how the changes you’ve implemented are designed to solve the problems they face.</p>
<h3><strong>Provide Guidance</strong></h3>
<p>Part of spelling out the values of your redesign is by easing your users’ transition to your new interface. When you provide tutorials and demonstratives, you’re also teaching them how the new design improves their experience on your app or website.</p>
<h3><strong>Provide Options</strong></h3>
<p>It’s always good to give your users the option to switch back to the old interface. Provide them a toggle switch or button to revert to the old version, and place it somewhere easily accessible.</p>
<h3><strong>Welcome Feedback</strong></h3>
<p>Give your users an outlet or channel through which they can directly communicate with your team. Whether it’s a form on your website, or simply an email address they can write to specifically for complaints and feedback, it’s always good to let your users know that you’re listening.</p>
<h2><strong>We’re Here to Help</strong></h2>
<p>Snappymob is equipped with software developers and designers who understand user behavior. Our team has helped clients from startups to large corporations, within and beyond Malaysia, launch successful revamps and redesigns.</p>
<p>With our help, you can rest assured that your redesigns launch safely. Click <a href="https://www.snappymob.com/contact"><span>here</span></a> to reach out to us!</p>
</span></p><p><label>app design</label></p>
        
      </div></div>]]>
            </description>
            <link>https://blog.snappymob.com/sudden-changes-in-ui-why-its-a-bad-move</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916574</guid>
            <pubDate>Wed, 28 Oct 2020 08:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Refining the Linux Tablet Experience – Debian on Surface Go 2 with LTE]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24916439">thread link</a>) | @willemlaurentz
<br/>
October 28, 2020 | https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/ | <a href="https://web.archive.org/web/*/https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="content">
	
	
	
	<p>Earlier this year I tried to create my own tablet operating system by installing Debian GNU/Linux on a Microsoft Surface Go tablet. I learned a great deal about what I like about tablets. But I still preferred my iPad Pro, mainly because of its polished user experience. This time I set out to refine my tablet software to replace my iPad.</p>

	<a name="continue" id="continue"></a>
	<h3>Linux on (Surface) tablets</h3><p>If you’re thinking about installing Linux on a tablet: you’re not alone. My earlier post on <a href="https://willem.com/blog/2020-03-09_making-my-own-tablet-os/" title="installing Debian GNU/Linux on Surface GO" target="_blank">installing Debian GNU/Linux on Surface GO</a> received a ton of attention. Apparently, many of you are looking for an alternative for the locked down operating systems that are usually installed on tablets (like iPadOS, Android or Windows 10S). </p><h4>Microsoft Surface hardware and Linux</h4><p>As history is full of sweet irony, it’s Microsoft that actually makes some pretty handsome hardware that works well with Linux. Their Surface line-up includes different laptops and tablets. The <a href="https://www.reddit.com/r/SurfaceLinux/" title="“SurfaceLinux”" target="_blank">“SurfaceLinux”</a> reddit page is is full of interesting user stories worth checking out. People are doing this and you could do it yourself, too.</p><a name="Microsoft Surface hardware is popular because it’s genuinely nice" title="Microsoft Surface hardware is popular because it’s genuinely nice" href="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_00_Microsoft-Surface-hardware-is-popular-because-it-s-genuinely-nice_3000px.jpg"><figure><img alt="Microsoft Surface hardware is popular because it’s genuinely nice" src="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_00_Microsoft-Surface-hardware-is-popular-because-it-s-genuinely-nice_500px.jpg" srcset="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_00_Microsoft-Surface-hardware-is-popular-because-it-s-genuinely-nice_500px.jpg 500w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_00_Microsoft-Surface-hardware-is-popular-because-it-s-genuinely-nice_640px.jpg 640w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_00_Microsoft-Surface-hardware-is-popular-because-it-s-genuinely-nice_720px.jpg 720w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_00_Microsoft-Surface-hardware-is-popular-because-it-s-genuinely-nice_750px.jpg 750w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_00_Microsoft-Surface-hardware-is-popular-because-it-s-genuinely-nice_960px.jpg 960w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_00_Microsoft-Surface-hardware-is-popular-because-it-s-genuinely-nice_1000px.jpg 1000w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_00_Microsoft-Surface-hardware-is-popular-because-it-s-genuinely-nice_1080px.jpg 1080w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_00_Microsoft-Surface-hardware-is-popular-because-it-s-genuinely-nice_1125px.jpg 1125w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_00_Microsoft-Surface-hardware-is-popular-because-it-s-genuinely-nice_1440px.jpg 1440w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_00_Microsoft-Surface-hardware-is-popular-because-it-s-genuinely-nice_1536px.jpg 1536w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_00_Microsoft-Surface-hardware-is-popular-because-it-s-genuinely-nice_1920px.jpg 1920w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_00_Microsoft-Surface-hardware-is-popular-because-it-s-genuinely-nice_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Microsoft Surface hardware is popular because it’s genuinely nice</figcaption></figure></a><h3>First attempt: Surface Go (versus iPad Pro)</h3><p>After <a href="https://willem.com/blog/2020-03-09_making-my-own-tablet-os/" title="installing and modifying Debian GNU/Linux on Surface Go" target="_blank">installing and modifying Debian GNU/Linux on Surface Go</a>, dubbed “Willem OS”, I tried to make it my main computer. If you’re a frequent visitor of my blog, you’ll know that <a href="https://willem.com/blog/tablet/" title="I have been using iPads and tablets for years as main computer" target="_blank">I have been using iPads and tablets for years as main computer</a>. Ultimately I deemed my first version of “WillemOS” not good enough: iPad Pro was light-years ahead when it came to a polished user experience.</p><p>From this first attempt I <a href="https://willem.com/blog/2020-04-14_talking-tablets-what-makes-a-great-tablet/" title="learned" target="_blank">learned</a> a great deal, it led to a better understanding of what I seek in a tablet experience. <b>I am looking for simple, yet versatile software to run on my tablet.</b></p><p>But “simple” is actually very hard to achieve. In order to make things<i> really</i> simple, you need to seamlessly integrate hardware and software. Apple does this well, iPad Pro provides a great user experience because:</p><ul><li><b>continue where you’ve left</b>: it saves everything when you put it in a <a href="https://willem.com/blog/2018-12-22_business-in-a-bag/" title="bag" target="_blank">bag</a>, being (instantly) ready to continue when you take it out. No manual saving or (re)booting required.</li><li><b>internet everywhere</b>: it automatically switches between <a href="https://willem.com/blog/2017-07-31_the-day-i-killed-my-lan/" title="WiFi and 4G/LTE networks" target="_blank">WiFi and 4G/LTE networks</a>, you don’t need to do anything this ‘just works’</li><li><b>any orientation and position:</b> iPad functions great without an external <a href="https://willem.com/blog/2020-08-11_the-best-keyboard-for-ipad/" title="keyboard" target="_blank">keyboard</a> or mouse, allowing you to use it in many different scenarios (the display automatically adjusts its brightness and white balance to match your surroundings, too!)</li></ul><p>It turns out that getting these things working seamlessly with Debian GNU/Linux on Surface is hard. My first tablet OS required a lot of manual interaction and was therefore cumbersome in comparison to iPad Pro. </p><h3>Second attempt: Surface Go 2</h3><p>Microsoft released a new Surface Go tablet this year, the Surface Go 2. It has a faster processor (up to 64%!), thinner bezels and an improved screen. It is a very descent upgrade that puts the Surface Go 2 much more on par with the 11-inch iPad Pro in hardware terms. For my second attempt to create the ultimate tablet experience, I decided to use the top model Surface Go 2:</p><ul><li>10.5” touch screen (1920x1250, 220PPI), 3:2 aspect ratio, Corning® Gorilla® Glass 3</li><li>Intel Core m3 processor (8th gen)</li><li>8GB RAM</li><li>Wifi 802.11a/b/g/n/ac/ax</li><li>LTE Advanced (Qualcomm® Snapdragon™ X16 LTE Modem)</li><li>Bluetooth 5.0</li><li>Intel UHD Graphics 615</li><li>Dimensions: 245 mm x 175 mm x 8.3 mm</li><li>256GB SSD</li><li>512GB MicroSDXC card</li><li>1x USB-C and 1x Surface Connect port</li></ul><a name="Microsoft Surface Go 2 with black type cover and Surface Pen - a nice piece of hardware!" title="Microsoft Surface Go 2 with black type cover and Surface Pen - a nice piece of hardware!" href="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_01_Microsoft-Surface-Go-2-with-black-type-cover-and-Surface-Pen-a-nice-piece-of-hardware_3000px.jpg"><figure><img alt="Microsoft Surface Go 2 with black type cover and Surface Pen - a nice piece of hardware!" src="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_01_Microsoft-Surface-Go-2-with-black-type-cover-and-Surface-Pen-a-nice-piece-of-hardware_500px.jpg" srcset="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_01_Microsoft-Surface-Go-2-with-black-type-cover-and-Surface-Pen-a-nice-piece-of-hardware_500px.jpg 500w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_01_Microsoft-Surface-Go-2-with-black-type-cover-and-Surface-Pen-a-nice-piece-of-hardware_640px.jpg 640w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_01_Microsoft-Surface-Go-2-with-black-type-cover-and-Surface-Pen-a-nice-piece-of-hardware_720px.jpg 720w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_01_Microsoft-Surface-Go-2-with-black-type-cover-and-Surface-Pen-a-nice-piece-of-hardware_750px.jpg 750w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_01_Microsoft-Surface-Go-2-with-black-type-cover-and-Surface-Pen-a-nice-piece-of-hardware_960px.jpg 960w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_01_Microsoft-Surface-Go-2-with-black-type-cover-and-Surface-Pen-a-nice-piece-of-hardware_1000px.jpg 1000w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_01_Microsoft-Surface-Go-2-with-black-type-cover-and-Surface-Pen-a-nice-piece-of-hardware_1080px.jpg 1080w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_01_Microsoft-Surface-Go-2-with-black-type-cover-and-Surface-Pen-a-nice-piece-of-hardware_1125px.jpg 1125w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_01_Microsoft-Surface-Go-2-with-black-type-cover-and-Surface-Pen-a-nice-piece-of-hardware_1440px.jpg 1440w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_01_Microsoft-Surface-Go-2-with-black-type-cover-and-Surface-Pen-a-nice-piece-of-hardware_1536px.jpg 1536w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_01_Microsoft-Surface-Go-2-with-black-type-cover-and-Surface-Pen-a-nice-piece-of-hardware_1920px.jpg 1920w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_01_Microsoft-Surface-Go-2-with-black-type-cover-and-Surface-Pen-a-nice-piece-of-hardware_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Microsoft Surface Go 2 with black type cover and Surface Pen - a nice piece of hardware!</figcaption></figure></a><h4>Installing Debian GNU/Linux on Surface Go 2 </h4><p>The Surface Go 2 is very similar to its predecessor when it comes to installing a base installation of your favourite GNU/Linux distribution. I followed my own steps from the original Surface Go installation <a href="https://willem.com/blog/2020-03-09_making-my-own-tablet-os/" title="here" target="_blank">here</a>. </p><a name="Installing Debian GNU/Linux on Surface Go 2 is very similar to the original Surface Go" title="Installing Debian GNU/Linux on Surface Go 2 is very similar to the original Surface Go" href="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_02_Installing-Debian-GNU-Linux-on-Surface-Go-2-is-very-similar-to-the-original-Surface-Go_3000px.jpg"><figure><img alt="Installing Debian GNU/Linux on Surface Go 2 is very similar to the original Surface Go" src="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_02_Installing-Debian-GNU-Linux-on-Surface-Go-2-is-very-similar-to-the-original-Surface-Go_500px.jpg" srcset="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_02_Installing-Debian-GNU-Linux-on-Surface-Go-2-is-very-similar-to-the-original-Surface-Go_500px.jpg 500w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_02_Installing-Debian-GNU-Linux-on-Surface-Go-2-is-very-similar-to-the-original-Surface-Go_640px.jpg 640w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_02_Installing-Debian-GNU-Linux-on-Surface-Go-2-is-very-similar-to-the-original-Surface-Go_720px.jpg 720w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_02_Installing-Debian-GNU-Linux-on-Surface-Go-2-is-very-similar-to-the-original-Surface-Go_750px.jpg 750w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_02_Installing-Debian-GNU-Linux-on-Surface-Go-2-is-very-similar-to-the-original-Surface-Go_960px.jpg 960w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_02_Installing-Debian-GNU-Linux-on-Surface-Go-2-is-very-similar-to-the-original-Surface-Go_1000px.jpg 1000w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_02_Installing-Debian-GNU-Linux-on-Surface-Go-2-is-very-similar-to-the-original-Surface-Go_1080px.jpg 1080w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_02_Installing-Debian-GNU-Linux-on-Surface-Go-2-is-very-similar-to-the-original-Surface-Go_1125px.jpg 1125w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_02_Installing-Debian-GNU-Linux-on-Surface-Go-2-is-very-similar-to-the-original-Surface-Go_1440px.jpg 1440w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_02_Installing-Debian-GNU-Linux-on-Surface-Go-2-is-very-similar-to-the-original-Surface-Go_1536px.jpg 1536w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_02_Installing-Debian-GNU-Linux-on-Surface-Go-2-is-very-similar-to-the-original-Surface-Go_1920px.jpg 1920w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_02_Installing-Debian-GNU-Linux-on-Surface-Go-2-is-very-similar-to-the-original-Surface-Go_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Installing Debian GNU/Linux on Surface Go 2 is very similar to the original Surface Go</figcaption></figure></a><p>In short, you must take the following steps when installing Linux on your Surface:</p><ul><li>1) Update Windows 10 and install all the firmware patches/updates</li><li>2) Create a bootable installation medium containing your favourite GNU/Linux distribution</li><li>3) (Optional) connect a wired ethernet connection</li><li>4) Boot the Surface from the USB drive</li><li>5) Install the operating system using the installer</li><li>6) Finetune and optimise the software experience</li></ul><a name="Debian GNU/Linux with i3wm (“aka WillemOS”) running on Surface Go 2" title="Debian GNU/Linux with i3wm (“aka WillemOS”) running on Surface Go 2" href="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_03_Debian-GNU-Linux-with-i3wm-aka-WillemOS-running-on-Surface-Go-2_3000px.jpg"><figure><img alt="Debian GNU/Linux with i3wm (“aka WillemOS”) running on Surface Go 2" src="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_03_Debian-GNU-Linux-with-i3wm-aka-WillemOS-running-on-Surface-Go-2_500px.jpg" srcset="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_03_Debian-GNU-Linux-with-i3wm-aka-WillemOS-running-on-Surface-Go-2_500px.jpg 500w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_03_Debian-GNU-Linux-with-i3wm-aka-WillemOS-running-on-Surface-Go-2_640px.jpg 640w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_03_Debian-GNU-Linux-with-i3wm-aka-WillemOS-running-on-Surface-Go-2_720px.jpg 720w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_03_Debian-GNU-Linux-with-i3wm-aka-WillemOS-running-on-Surface-Go-2_750px.jpg 750w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_03_Debian-GNU-Linux-with-i3wm-aka-WillemOS-running-on-Surface-Go-2_960px.jpg 960w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_03_Debian-GNU-Linux-with-i3wm-aka-WillemOS-running-on-Surface-Go-2_1000px.jpg 1000w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_03_Debian-GNU-Linux-with-i3wm-aka-WillemOS-running-on-Surface-Go-2_1080px.jpg 1080w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_03_Debian-GNU-Linux-with-i3wm-aka-WillemOS-running-on-Surface-Go-2_1125px.jpg 1125w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_03_Debian-GNU-Linux-with-i3wm-aka-WillemOS-running-on-Surface-Go-2_1440px.jpg 1440w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_03_Debian-GNU-Linux-with-i3wm-aka-WillemOS-running-on-Surface-Go-2_1536px.jpg 1536w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_03_Debian-GNU-Linux-with-i3wm-aka-WillemOS-running-on-Surface-Go-2_1920px.jpg 1920w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_03_Debian-GNU-Linux-with-i3wm-aka-WillemOS-running-on-Surface-Go-2_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Debian GNU/Linux with i3wm (“aka WillemOS”) running on Surface Go 2</figcaption></figure></a><h3>Refining the experience</h3><p>The last step of the installation is where you can make the difference between a fantastic and lousy user experience. To<i> “encourage”</i> myself to stick to this experiment I decided to sell my iPad Pro: burning the ships (as there would be no way back)!</p><a name="Selling your iPad Pro is easy if you keep the original boxes - I sold mine in just a few days: enforcing myself to make the new tablet work!" title="Selling your iPad Pro is easy if you keep the original boxes - I sold mine in just a few days: enforcing myself to make the new tablet work!" href="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_04_Selling-your-iPad-Pro-is-easy-if-you-keep-the-original-boxes-I-sold-mine-in-just-a-few-days-enforcing-myself-to-make-the-new-tablet-work_3000px.jpg"><figure><img alt="Selling your iPad Pro is easy if you keep the original boxes - I sold mine in just a few days: enforcing myself to make the new tablet work!" src="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_04_Selling-your-iPad-Pro-is-easy-if-you-keep-the-original-boxes-I-sold-mine-in-just-a-few-days-enforcing-myself-to-make-the-new-tablet-work_500px.jpg" srcset="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_04_Selling-your-iPad-Pro-is-easy-if-you-keep-the-original-boxes-I-sold-mine-in-just-a-few-days-enforcing-myself-to-make-the-new-tablet-work_500px.jpg 500w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_04_Selling-your-iPad-Pro-is-easy-if-you-keep-the-original-boxes-I-sold-mine-in-just-a-few-days-enforcing-myself-to-make-the-new-tablet-work_640px.jpg 640w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_04_Selling-your-iPad-Pro-is-easy-if-you-keep-the-original-boxes-I-sold-mine-in-just-a-few-days-enforcing-myself-to-make-the-new-tablet-work_720px.jpg 720w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_04_Selling-your-iPad-Pro-is-easy-if-you-keep-the-original-boxes-I-sold-mine-in-just-a-few-days-enforcing-myself-to-make-the-new-tablet-work_750px.jpg 750w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_04_Selling-your-iPad-Pro-is-easy-if-you-keep-the-original-boxes-I-sold-mine-in-just-a-few-days-enforcing-myself-to-make-the-new-tablet-work_960px.jpg 960w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_04_Selling-your-iPad-Pro-is-easy-if-you-keep-the-original-boxes-I-sold-mine-in-just-a-few-days-enforcing-myself-to-make-the-new-tablet-work_1000px.jpg 1000w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_04_Selling-your-iPad-Pro-is-easy-if-you-keep-the-original-boxes-I-sold-mine-in-just-a-few-days-enforcing-myself-to-make-the-new-tablet-work_1080px.jpg 1080w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_04_Selling-your-iPad-Pro-is-easy-if-you-keep-the-original-boxes-I-sold-mine-in-just-a-few-days-enforcing-myself-to-make-the-new-tablet-work_1125px.jpg 1125w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_04_Selling-your-iPad-Pro-is-easy-if-you-keep-the-original-boxes-I-sold-mine-in-just-a-few-days-enforcing-myself-to-make-the-new-tablet-work_1440px.jpg 1440w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_04_Selling-your-iPad-Pro-is-easy-if-you-keep-the-original-boxes-I-sold-mine-in-just-a-few-days-enforcing-myself-to-make-the-new-tablet-work_1536px.jpg 1536w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_04_Selling-your-iPad-Pro-is-easy-if-you-keep-the-original-boxes-I-sold-mine-in-just-a-few-days-enforcing-myself-to-make-the-new-tablet-work_1920px.jpg 1920w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_04_Selling-your-iPad-Pro-is-easy-if-you-keep-the-original-boxes-I-sold-mine-in-just-a-few-days-enforcing-myself-to-make-the-new-tablet-work_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Selling your iPad Pro is easy if you keep the original boxes - I sold mine in just a few days: enforcing myself to make the new tablet work!</figcaption></figure></a><p>On a small display, running apps full screen makes perfect sense. I know that the conventional PC concept of managing distinct application Windows doesn’t provide the best user experience on a small tablet computer. Therefore I decided to try a tiling window manager: <a href="https://i3wm.org/" title="i3wm" target="_blank">i3wm</a>.</p><h4>Tiling window manager</h4><p>The principle of a tiling window manager is simple: apps take up as much space as there is available. This means that if you run just one app, it will be full screen. Two apps run split screen, etc, etc. You can define rules that automate the arrangement of apps. Using keyboard shortcuts you can quickly switch between apps. You may need some time to figure out what works best for<i> you</i> when you use a tiling window manager, but in the end it can save you a lot of time!</p><a name="Running Firefox (left) and a MOSH/tmux terminal window (right) in splitscreen using the i3wm tiling window manager" title="Running Firefox (left) and a MOSH/tmux terminal window (right) in splitscreen using the i3wm tiling window manager" href="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_05_Running-Firefox-left-and-a-MOSH-tmux-terminal-window-right-in-splitscreen-using-the-i3wm-tiling-window-manager_3000px.jpg"><figure><img alt="Running Firefox (left) and a MOSH/tmux terminal window (right) in splitscreen using the i3wm tiling window manager" src="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_05_Running-Firefox-left-and-a-MOSH-tmux-terminal-window-right-in-splitscreen-using-the-i3wm-tiling-window-manager_500px.jpg" srcset="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_05_Running-Firefox-left-and-a-MOSH-tmux-terminal-window-right-in-splitscreen-using-the-i3wm-tiling-window-manager_500px.jpg 500w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_05_Running-Firefox-left-and-a-MOSH-tmux-terminal-window-right-in-splitscreen-using-the-i3wm-tiling-window-manager_640px.jpg 640w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_05_Running-Firefox-left-and-a-MOSH-tmux-terminal-window-right-in-splitscreen-using-the-i3wm-tiling-window-manager_720px.jpg 720w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_05_Running-Firefox-left-and-a-MOSH-tmux-terminal-window-right-in-splitscreen-using-the-i3wm-tiling-window-manager_750px.jpg 750w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_05_Running-Firefox-left-and-a-MOSH-tmux-terminal-window-right-in-splitscreen-using-the-i3wm-tiling-window-manager_960px.jpg 960w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_05_Running-Firefox-left-and-a-MOSH-tmux-terminal-window-right-in-splitscreen-using-the-i3wm-tiling-window-manager_1000px.jpg 1000w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_05_Running-Firefox-left-and-a-MOSH-tmux-terminal-window-right-in-splitscreen-using-the-i3wm-tiling-window-manager_1080px.jpg 1080w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_05_Running-Firefox-left-and-a-MOSH-tmux-terminal-window-right-in-splitscreen-using-the-i3wm-tiling-window-manager_1125px.jpg 1125w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_05_Running-Firefox-left-and-a-MOSH-tmux-terminal-window-right-in-splitscreen-using-the-i3wm-tiling-window-manager_1440px.jpg 1440w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_05_Running-Firefox-left-and-a-MOSH-tmux-terminal-window-right-in-splitscreen-using-the-i3wm-tiling-window-manager_1536px.jpg 1536w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_05_Running-Firefox-left-and-a-MOSH-tmux-terminal-window-right-in-splitscreen-using-the-i3wm-tiling-window-manager_1920px.jpg 1920w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_05_Running-Firefox-left-and-a-MOSH-tmux-terminal-window-right-in-splitscreen-using-the-i3wm-tiling-window-manager_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Running Firefox (left) and a MOSH/tmux terminal window (right) in splitscreen using the i3wm tiling window manager</figcaption></figure></a><h4>Workspaces</h4><p>Another powerful feature of i3wm is that you can have different <a href="https://i3wm.org/docs/userguide.html#_using_workspaces" title="‘workspaces’" target="_blank">‘workspaces’</a>. They are an easy way to organise groups of apps running together. I use different workspaces for different things that I do. A common approach is to put the web browser on one workspace, mail applications  on another one, and the ones with which you work, on the third one. </p><a name="Multiple workspaces are very powerful: it’s like switching TV channels" title="Multiple workspaces are very powerful: it’s like switching TV channels" href="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_06_Multiple-workspaces-are-very-powerful-it-s-like-switching-TV-channels_3000px.jpg"><figure><img alt="Multiple workspaces are very powerful: it’s like switching TV channels" src="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_06_Multiple-workspaces-are-very-powerful-it-s-like-switching-TV-channels_500px.jpg" srcset="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_06_Multiple-workspaces-are-very-powerful-it-s-like-switching-TV-channels_500px.jpg 500w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_06_Multiple-workspaces-are-very-powerful-it-s-like-switching-TV-channels_640px.jpg 640w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_06_Multiple-workspaces-are-very-powerful-it-s-like-switching-TV-channels_720px.jpg 720w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_06_Multiple-workspaces-are-very-powerful-it-s-like-switching-TV-channels_750px.jpg 750w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_06_Multiple-workspaces-are-very-powerful-it-s-like-switching-TV-channels_960px.jpg 960w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_06_Multiple-workspaces-are-very-powerful-it-s-like-switching-TV-channels_1000px.jpg 1000w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_06_Multiple-workspaces-are-very-powerful-it-s-like-switching-TV-channels_1080px.jpg 1080w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_06_Multiple-workspaces-are-very-powerful-it-s-like-switching-TV-channels_1125px.jpg 1125w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_06_Multiple-workspaces-are-very-powerful-it-s-like-switching-TV-channels_1440px.jpg 1440w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_06_Multiple-workspaces-are-very-powerful-it-s-like-switching-TV-channels_1536px.jpg 1536w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_06_Multiple-workspaces-are-very-powerful-it-s-like-switching-TV-channels_1920px.jpg 1920w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_06_Multiple-workspaces-are-very-powerful-it-s-like-switching-TV-channels_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Multiple workspaces are very powerful: it’s like switching TV channels</figcaption></figure></a><p>The great thing about multiple workspaces is that one app (e.g. your browser) can run multiple instances on different workspaces. This enables many different combinations of apps. This is really where the i3wm window manager is<i> much</i> better than iPadOS’s take on multi tasking. </p><p>The i3wm window manager supports external monitors very well, using the same concept of a workspace. You simply designate one or multiple workspaces to be shown on the extra/external screen. This works well with the Surface Dock and USB-C-to-HDMI accessories for Surface. Multi monitor support is really great. </p><a name="Three finger swipe to switch workspaces - a trick from macOS - using fusuma you can use multi touch gestures in i3wm" title="Three finger swipe to switch workspaces - a trick from macOS - using fusuma you can use multi touch gestures in i3wm" href="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_07_Three-finger-swipe-to-switch-workspaces-a-trick-from-macOS-using-fusuma-you-can-use-multi-touch-gestures-in-i3wm_3000px.jpg"><figure><img alt="Three finger swipe to switch workspaces - a trick from macOS - using fusuma you can use multi touch gestures in i3wm" src="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_07_Three-finger-swipe-to-switch-workspaces-a-trick-from-macOS-using-fusuma-you-can-use-multi-touch-gestures-in-i3wm_500px.jpg" srcset="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_07_Three-finger-swipe-to-switch-workspaces-a-trick-from-macOS-using-fusuma-you-can-use-multi-touch-gestures-in-i3wm_500px.jpg 500w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_07_Three-finger-swipe-to-switch-workspaces-a-trick-from-macOS-using-fusuma-you-can-use-multi-touch-gestures-in-i3wm_640px.jpg 640w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_07_Three-finger-swipe-to-switch-workspaces-a-trick-from-macOS-using-fusuma-you-can-use-multi-touch-gestures-in-i3wm_720px.jpg 720w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_07_Three-finger-swipe-to-switch-workspaces-a-trick-from-macOS-using-fusuma-you-can-use-multi-touch-gestures-in-i3wm_750px.jpg 750w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_07_Three-finger-swipe-to-switch-workspaces-a-trick-from-macOS-using-fusuma-you-can-use-multi-touch-gestures-in-i3wm_960px.jpg 960w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_07_Three-finger-swipe-to-switch-workspaces-a-trick-from-macOS-using-fusuma-you-can-use-multi-touch-gestures-in-i3wm_1000px.jpg 1000w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_07_Three-finger-swipe-to-switch-workspaces-a-trick-from-macOS-using-fusuma-you-can-use-multi-touch-gestures-in-i3wm_1080px.jpg 1080w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_07_Three-finger-swipe-to-switch-workspaces-a-trick-from-macOS-using-fusuma-you-can-use-multi-touch-gestures-in-i3wm_1125px.jpg 1125w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_07_Three-finger-swipe-to-switch-workspaces-a-trick-from-macOS-using-fusuma-you-can-use-multi-touch-gestures-in-i3wm_1440px.jpg 1440w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_07_Three-finger-swipe-to-switch-workspaces-a-trick-from-macOS-using-fusuma-you-can-use-multi-touch-gestures-in-i3wm_1536px.jpg 1536w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_07_Three-finger-swipe-to-switch-workspaces-a-trick-from-macOS-using-fusuma-you-can-use-multi-touch-gestures-in-i3wm_1920px.jpg 1920w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_07_Three-finger-swipe-to-switch-workspaces-a-trick-from-macOS-using-fusuma-you-can-use-multi-touch-gestures-in-i3wm_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Three finger swipe to switch workspaces - a trick from macOS - using fusuma you can use multi touch gestures in i3wm</figcaption></figure></a><p>One thing that you should try is to use <a href="https://github.com/iberianpig/fusuma" title="fusuma" target="_blank">fusuma</a> to enable three finger gestures on the trackpad. If you have ever worked on a MacBook you’ll know that the multi touch trackpads enable useful gestures to switch desktops (or workspaces in i3wm). It works really well!</p><h4>Storage</h4><p>For <a href="https://willem.com/blog/2020-08-31_free-from-the-icloud-escaping-apple-photos/" title="managing my photos using Shotwell" target="_blank">managing my photos using Shotwell</a> I wanted some serious storage on my tablet. Altough I have the top model Surface Go 2 with the 256GB SSD drive, I used the MicroSD card slot to extend my storage capacity by another 512GB. The MicroSD card is slower than the integrated SSD, but for files that you don’t read every day/hour/minute it is fast enough. </p><a name="Extending storage on a Surface Go 2 is possible using a MicroSD card" title="Extending storage on a Surface Go 2 is possible using a MicroSD card" href="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_08_Extending-storage-on-a-Surface-Go-2-is-possible-using-a-MicroSD-card_3000px.jpg"><figure><img alt="Extending storage on a Surface Go 2 is possible using a MicroSD card" src="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_08_Extending-storage-on-a-Surface-Go-2-is-possible-using-a-MicroSD-card_500px.jpg" srcset="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_08_Extending-storage-on-a-Surface-Go-2-is-possible-using-a-MicroSD-card_500px.jpg 500w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_08_Extending-storage-on-a-Surface-Go-2-is-possible-using-a-MicroSD-card_640px.jpg 640w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_08_Extending-storage-on-a-Surface-Go-2-is-possible-using-a-MicroSD-card_720px.jpg 720w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_08_Extending-storage-on-a-Surface-Go-2-is-possible-using-a-MicroSD-card_750px.jpg 750w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_08_Extending-storage-on-a-Surface-Go-2-is-possible-using-a-MicroSD-card_960px.jpg 960w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_08_Extending-storage-on-a-Surface-Go-2-is-possible-using-a-MicroSD-card_1000px.jpg 1000w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_08_Extending-storage-on-a-Surface-Go-2-is-possible-using-a-MicroSD-card_1080px.jpg 1080w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_08_Extending-storage-on-a-Surface-Go-2-is-possible-using-a-MicroSD-card_1125px.jpg 1125w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_08_Extending-storage-on-a-Surface-Go-2-is-possible-using-a-MicroSD-card_1440px.jpg 1440w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_08_Extending-storage-on-a-Surface-Go-2-is-possible-using-a-MicroSD-card_1536px.jpg 1536w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_08_Extending-storage-on-a-Surface-Go-2-is-possible-using-a-MicroSD-card_1920px.jpg 1920w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_08_Extending-storage-on-a-Surface-Go-2-is-possible-using-a-MicroSD-card_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Extending storage on a Surface Go 2 is possible using a MicroSD card</figcaption></figure></a><p>My Debian GNU/Linux installation had no trouble recognising the MicroSD card. I encrypted the entire MicroSD card to prevent my photos from leaking if I would ever lose my card. You should (always) consider this, take appropriate measures to protect and backup your data!</p><h4>Connectivity WiFi/4G/LTE</h4><p>After installing the ‘non-free’ wireless firmware in Debian the WiFi works well on Surface Go 2. Getting the LTE/4G to work was a lot harder! For some reason the WWAN connection did not start, even though I inserted a working SIM-card in the Surface Go. For some mysterious reason the modem did not start correctly, 4G/LTE did not work!</p><a name="Installing the SIM in the Surface Go 2 tablet" title="Installing the SIM in the Surface Go 2 tablet" href="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_09_Installing-the-SIM-in-the-Surface-Go-2-tablet_3000px.jpg"><figure><img alt="Installing the SIM in the Surface Go 2 tablet" src="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_09_Installing-the-SIM-in-the-Surface-Go-2-tablet_500px.jpg" srcset="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_09_Installing-the-SIM-in-the-Surface-Go-2-tablet_500px.jpg 500w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_09_Installing-the-SIM-in-the-Surface-Go-2-tablet_640px.jpg 640w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_09_Installing-the-SIM-in-the-Surface-Go-2-tablet_720px.jpg 720w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_09_Installing-the-SIM-in-the-Surface-Go-2-tablet_750px.jpg 750w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_09_Installing-the-SIM-in-the-Surface-Go-2-tablet_960px.jpg 960w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_09_Installing-the-SIM-in-the-Surface-Go-2-tablet_1000px.jpg 1000w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_09_Installing-the-SIM-in-the-Surface-Go-2-tablet_1080px.jpg 1080w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_09_Installing-the-SIM-in-the-Surface-Go-2-tablet_1125px.jpg 1125w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_09_Installing-the-SIM-in-the-Surface-Go-2-tablet_1440px.jpg 1440w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_09_Installing-the-SIM-in-the-Surface-Go-2-tablet_1536px.jpg 1536w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_09_Installing-the-SIM-in-the-Surface-Go-2-tablet_1920px.jpg 1920w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_09_Installing-the-SIM-in-the-Surface-Go-2-tablet_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Installing the SIM in the Surface Go 2 tablet</figcaption></figure></a><p>One of the great things of iPad is that it shares the connectivity logic from iPhone. It automatically manages different wireless networks and mobile broadband connections. I wanted this to work on my Linux tablet, too! </p><p>When I looking for a clue to get 4G/LTE to work, I looked into reports on Surface Pro. The Surface Go 2 is technically very similar to the larger Pro. I figured that I could learn from peoples efforts with mobile broadband on the Surface Pro. After many hours of searching and trying different things, I found <a href="https://github.com/jakeday/linux-surface/issues/306#issuecomment-518898603" title="this solution to get 4G to work on Surface" target="_blank">this solution to get 4G to work on Surface</a>:</p><a name="Resetting the buffers of the Surface broadband modem allowed it to work with Debian GNU/Linux!" title="Resetting the buffers of the Surface broadband modem allowed it to work with Debian GNU/Linux!" href="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_10_Resetting-the-buffers-of-the-Surface-broadband-modem-allowed-it-to-work-with-Debian-GNU-Linux_3000px.png"><figure><img alt="Resetting the buffers of the Surface broadband modem allowed it to work with Debian GNU/Linux!" src="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_10_Resetting-the-buffers-of-the-Surface-broadband-modem-allowed-it-to-work-with-Debian-GNU-Linux_500px.png" srcset="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_10_Resetting-the-buffers-of-the-Surface-broadband-modem-allowed-it-to-work-with-Debian-GNU-Linux_500px.png 500w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_10_Resetting-the-buffers-of-the-Surface-broadband-modem-allowed-it-to-work-with-Debian-GNU-Linux_640px.png 640w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_10_Resetting-the-buffers-of-the-Surface-broadband-modem-allowed-it-to-work-with-Debian-GNU-Linux_720px.png 720w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_10_Resetting-the-buffers-of-the-Surface-broadband-modem-allowed-it-to-work-with-Debian-GNU-Linux_750px.png 750w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_10_Resetting-the-buffers-of-the-Surface-broadband-modem-allowed-it-to-work-with-Debian-GNU-Linux_960px.png 960w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_10_Resetting-the-buffers-of-the-Surface-broadband-modem-allowed-it-to-work-with-Debian-GNU-Linux_1000px.png 1000w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_10_Resetting-the-buffers-of-the-Surface-broadband-modem-allowed-it-to-work-with-Debian-GNU-Linux_1080px.png 1080w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_10_Resetting-the-buffers-of-the-Surface-broadband-modem-allowed-it-to-work-with-Debian-GNU-Linux_1125px.png 1125w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_10_Resetting-the-buffers-of-the-Surface-broadband-modem-allowed-it-to-work-with-Debian-GNU-Linux_1440px.png 1440w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_10_Resetting-the-buffers-of-the-Surface-broadband-modem-allowed-it-to-work-with-Debian-GNU-Linux_1536px.png 1536w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_10_Resetting-the-buffers-of-the-Surface-broadband-modem-allowed-it-to-work-with-Debian-GNU-Linux_1920px.png 1920w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_10_Resetting-the-buffers-of-the-Surface-broadband-modem-allowed-it-to-work-with-Debian-GNU-Linux_3000px.png 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Resetting the buffers of the Surface broadband modem allowed it to work with Debian GNU/Linux!</figcaption></figure></a><p>You can use the Network Manager (and Modem Manager) to automate connectivity management under Linux. By default it will prefer WiFi connections over mobile broadband. You can have it automatically connect over 4G/LTE if there is no WiFi available. It now works very well in combination with the Surface Go 2 hardware!</p><a name="Network Manager (nm-applet) automatically switches between WiFi and mobile broadband connections" title="Network Manager (nm-applet) automatically switches between WiFi and mobile broadband connections" href="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_11_Network-Manager-nm-applet-automatically-switches-between-WiFi-and-mobile-broadband-connections_3000px.jpg"><figure><img alt="Network Manager (nm-applet) automatically switches between WiFi and mobile broadband connections" src="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_11_Network-Manager-nm-applet-automatically-switches-between-WiFi-and-mobile-broadband-connections_500px.jpg" srcset="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_11_Network-Manager-nm-applet-automatically-switches-between-WiFi-and-mobile-broadband-connections_500px.jpg 500w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_11_Network-Manager-nm-applet-automatically-switches-between-WiFi-and-mobile-broadband-connections_640px.jpg 640w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_11_Network-Manager-nm-applet-automatically-switches-between-WiFi-and-mobile-broadband-connections_720px.jpg 720w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_11_Network-Manager-nm-applet-automatically-switches-between-WiFi-and-mobile-broadband-connections_750px.jpg 750w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_11_Network-Manager-nm-applet-automatically-switches-between-WiFi-and-mobile-broadband-connections_960px.jpg 960w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_11_Network-Manager-nm-applet-automatically-switches-between-WiFi-and-mobile-broadband-connections_1000px.jpg 1000w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_11_Network-Manager-nm-applet-automatically-switches-between-WiFi-and-mobile-broadband-connections_1080px.jpg 1080w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_11_Network-Manager-nm-applet-automatically-switches-between-WiFi-and-mobile-broadband-connections_1125px.jpg 1125w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_11_Network-Manager-nm-applet-automatically-switches-between-WiFi-and-mobile-broadband-connections_1440px.jpg 1440w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_11_Network-Manager-nm-applet-automatically-switches-between-WiFi-and-mobile-broadband-connections_1536px.jpg 1536w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_11_Network-Manager-nm-applet-automatically-switches-between-WiFi-and-mobile-broadband-connections_1920px.jpg 1920w,
		https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/images/i_11_Network-Manager-nm-applet-automatically-switches-between-WiFi-and-mobile-broadband-connections_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Network Manager (nm-applet) automatically switches between WiFi and mobile broadband connections</figcaption></figure></a><h4>Suspend/Hibernate/Resume</h4><p>Another thing no iPad user ever thinks of, is how great Apple got things right when it comes to suspend and resume. When you have an iPad you can have it in standby mode for many days, yet it is always very quick to continue where you have left once you pick it up again.</p><p>To make my Surface with GNU/Linux do the same I needed a way to quickly suspend and resume. In Linux / PC world there are basically four power modes:</p><ul><li><b>on:</b> apps are running. System is fully powered on, consumes a lot of power </li><li><b>suspend (to RAM):</b> app states are preserved in RAM memory. System is still powered on, but every component is turned down as much as possible, still consumes power (+/- 10% battery drain per …</li></ul></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/">https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/</a></em></p>]]>
            </description>
            <link>https://willem.com/blog/2020-09-28_refining-my-tablet-os-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916439</guid>
            <pubDate>Wed, 28 Oct 2020 08:14:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon Launches in Sweden]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24916410">thread link</a>) | @kouzant
<br/>
October 28, 2020 | https://www.aboutamazon.eu/press-release/amazon-se-launches-in-sweden | <a href="https://web.archive.org/web/*/https://www.aboutamazon.eu/press-release/amazon-se-launches-in-sweden">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
    
        <div><p><b>Stockholm - October 28, 2020</b> – Starting today, customers across Sweden can visit Amazon.se to shop from a selection of over 150m products, with the benefit of everyday low prices and reliable free delivery for eligible orders above SEK 229. Amazon.se features a vast selection of products across more than 30 categories, such as Books, Consumer Electronics, Sports and Outdoor, Tools and Home Improvement, Toys and Baby, including products from thousands of European and local Swedish businesses.</p><p>“We are thrilled to launch Amazon.se and to be able to offer Swedish customers a selection of more than 150 million products, including tens of thousands of products from local Swedish businesses,” said Alex Ootes, Vice President, European Expansion for Amazon. “Today is only the start of Amazon.se. We will continue to work hard to earn the trust of Swedish customers by growing our product range, ensuring low prices, and providing a convenient and trusted shopping experience.”</p><p>Swedish customers can conveniently shop from anywhere, any time with no-hassle returns and Swedish customer service through the Amazon Shopping app and desktop and mobile browsers. All customers shopping on Amazon.se enjoy free delivery for millions of items on eligible orders over SEK 229. Customers can easily browse the growing selection, read customer reviews, view personalized recommendations, create wish lists and track their orders.</p><p>Amazon is offering a wide variety of products from local Swedish brands, as well as big brand favorites. Customers can find great prices on products offered by Swedish brands like Electrolux, Lagerhaus, OBH Nordica, Ellos, BRIO, Bonnierförlagen and Ifö, as well as international brands like ASUS, Mattel, Hasbro, LEGO and Bosch.</p><p><b><em>Amazon.se offers growth opportunities for Swedish businesses – big and small</em></b><br>With the launch of Amazon.se, it will be easier for Swedish businesses to sell their products on Amazon, reach more customers and expand. Amazon has invested billions of dollars in infrastructure and technical services that help small and medium-sized businesses reach new customers across Sweden and around the world, including simple listing tools that support all seven European Amazon stores, enabling easy expansion within Europe, as well as 24/7 online Selling Partner support, open and transparent selling conditions and pricing, and reports and analytics tools to help them grow. As a result of this investment there are now 1.7 million small and medium-sized businesses around the world selling in Amazon’s stores, with more than 200,000 entrepreneurs worldwide who surpassed $100,000 in sales on Amazon in 2019.</p><p>“Today, thousands of European and local selling partners are offering their products on Amazon.se and on our other Amazon stores across the EU as well as in the US. We are excited for our international customers to experience and enjoy this Swedish selection and help grow these businesses with every purchase they make”, says Alex Ootes. “Small and medium sized companies selling in Amazon stores created an estimate 1.6 million jobs worldwide and we hope to see Swedish companies prosper in the same way.”</p><p>Pierre Magnusson, Head of E-commerce at N!CK’S, the Swedish healthy snack business, said: “The opportunities on Amazon are enormous. Amazon has grown to become our most important channel for exports, and within the first months of working with Amazon we were cash flow positive. N!CK'S continues to grow and has become one of the best-selling brands within our category, and we are still seeing 50% year-on-year growth in the EU Amazon stores alone. I would definitely recommend more Swedish companies start selling on Amazon.”</p><p>Elisabet Sandström, CEO of Miss Mary of Sweden AB, a manufacturer of high quality lingerie, said: “Amazon is an important channel for our expansion in Europe and the US, and we now look forward to selling through the Swedish Store when Amazon opens in our home country. Our sales on Amazon have increased steadily by over 50% per year, and Amazon is our fastest growing channel. Germany is currently Miss Mary’s largest customer base, and when we entered Amazon.de we noticed an immediate sales increase. We now appreciate the opportunity to reach new Swedish customers and make them happy.”</p><p><b><em>Investment in Sweden for a Sustainable Future</em></b><br>The launch of Amazon.se comes weeks after Amazon announced its largest investment in renewable energy outside of the US, with the launch (10/15) of the 91-megawatt Bäckhammar project in Western Sweden. It will support Amazon Web Services (AWS) data centers in the country, as well as the expanding Amazon retail business, and is expected to deliver 280,000-megawatt hours of clean energy annually into the Swedish grid - the equivalent of powering 29,000 average homes in Sweden. The Bäckhammar project is<em> </em>the first of two Amazon renewable energy projects to come online in Sweden. The second, a 122-megawatt onshore windfarm in Västernorrland, currently in construction, is expected to commence operations in 2022. In total, these projects will add 213 megawatts of new clean energy to the Swedish grid.</p><p>These launches takes Amazon one step closer to meeting its <span><span><a href="https://sustainability.aboutamazon.com/about/the-climate-pledge#section-nav-id-1" target="_blank" data-cms-ai="0">Climate Pledge commitments</a></span></span> of achieving net zero carbon emissions by 2040, ten years ahead of the Paris Agreement. This will be achieved through powering its operations with 100% renewable energy by 2025, making all Amazon shipments net zero carbon through Shipment Zero, with 50% of all shipments net zero carbon by 2030; ordering over 100,000 electric delivery vehicles; and investing $2 billion to support the development of technologies and services that reduce carbon emissions and help preserve the natural world.</p><p><b><em>About Amazon</em></b><br>Amazon is guided by four principles: customer obsession rather than competitor focus, passion for invention, commitment to operational excellence, and long-term thinking. Customer reviews, 1-Click shopping, personalized recommendations, Prime, Fulfillment by Amazon, AWS, Kindle Direct Publishing, Kindle, Fire tablets, Fire TV, Amazon Echo, and Alexa are some of the products and services pioneered by Amazon. For more information, visit <span><span><a href="https://www.aboutamazon.eu/" data-amzn-id="00000162-a79c-d62f-ab6e-ef9d38f30000" data-cms-ai="0">aboutamazon.eu</a></span></span> and follow <span><span><a href="https://twitter.com/AmazonNewsEU" target="_blank" data-cms-ai="0">@AmazonNewsEU</a></span></span>.<br></p></div>
    
</div></div></div>]]>
            </description>
            <link>https://www.aboutamazon.eu/press-release/amazon-se-launches-in-sweden</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916410</guid>
            <pubDate>Wed, 28 Oct 2020 08:09:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Qt 6 will provide additional libraries via Conan package manager]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 35 (<a href="https://news.ycombinator.com/item?id=24916321">thread link</a>) | @alaenix
<br/>
October 28, 2020 | https://www.qt.io/blog/qt-6-additional-libraries-via-package-manager | <a href="https://web.archive.org/web/*/https://www.qt.io/blog/qt-6-additional-libraries-via-package-manager">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            

                            <p>
                                Tuesday October 27, 2020 by <a href="https://www.qt.io/blog/author/iikka-eklund">Iikka Eklund</a> | <a href="#commento">Comments</a>
                            </p>
                            
                            <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><span data-contrast="auto">With Qt 6 we want to provide more flexibility via </span><span data-contrast="auto">leveraging</span><span data-contrast="auto"> a package manager in addition to Qt </span><span data-contrast="auto">Online </span><span data-contrast="auto">Installer. The new package manager functionality, based on conan.io (</span><a href="https://conan.io/"><span data-contrast="none">https://conan.io</span></a><span data-contrast="auto">), allows provi</span><span data-contrast="auto">ding more </span><span data-contrast="auto">packages </span><span data-contrast="auto">to the users without increasing the complexity of the baseline Qt. In addition to the </span><span data-contrast="auto">packages </span><span data-contrast="auto">provided by Qt, the package manager can be used for getting content from other sources.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<!--more-->
<p><span data-contrast="auto">Initially</span><span>,</span><span data-contrast="auto"> we have three </span><span data-contrast="auto">Additional Li</span><span data-contrast="auto">b</span><span data-contrast="auto">raries </span><span data-contrast="auto">provided via the package manager: Qt Network Authorization, Qt Image Formats</span><span>,</span><span data-contrast="auto"> and Qt 3D. More </span><span data-contrast="auto">Additional Libraries </span><span data-contrast="auto">will be available </span><span data-contrast="auto">in forthcoming</span><span data-contrast="auto"> Qt 6 releases. We are currently leveraging the exis</span><span data-contrast="auto">ting Qt delivery system as</span><span data-contrast="auto"> the</span> <span data-contrast="auto">backend for the </span><span data-contrast="auto">Additional Libraries</span><span data-contrast="auto"> available via the package manager.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><strong>How the packages are managed?&nbsp;</strong></p>
<p><span data-contrast="auto">The required </span><span data-contrast="auto">tools, Conan, </span><span data-contrast="auto">CMake</span><span>,</span><span data-contrast="auto"> and Ninja, can be easily installed u</span><span data-contrast="auto">sing</span><span data-contrast="auto"> the</span> <span><strong>Qt </strong></span><strong><span data-contrast="auto">O</span></strong><strong><span data-contrast="auto">nline installer </span></strong><strong><span data-contrast="auto">4.0</span></strong><span data-contrast="auto">, which is going to be released </span><span data-contrast="auto">soon.</span> <span data-contrast="auto">The</span><span data-contrast="auto"> Conan</span><span data-contrast="auto"> build </span><span data-contrast="auto">recipes</span> <span data-contrast="auto">for </span><span data-contrast="auto">Additional Libraries</span><span data-contrast="auto"> require </span><span data-contrast="auto">CMake</span><span data-contrast="auto"> and Ninja to build the module</span><span data-contrast="auto">.</span> <span data-contrast="auto">The project linking to the module</span> <span data-contrast="auto">can be </span><span data-contrast="auto">qmake</span><span data-contrast="auto">-</span><span data-contrast="auto">based as well.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Once installed</span><span data-contrast="auto">, </span><span data-contrast="auto">the selected </span><span data-contrast="auto">Add</span><span data-contrast="auto">itional Libraries</span> <span data-contrast="auto">can be built </span><span data-contrast="auto">once </span><span data-contrast="auto">by </span><span data-contrast="auto">using</span><span data-contrast="auto"> Conan</span><span data-contrast="auto"> per selected target configuration</span><span data-contrast="auto">. After the build</span><span data-contrast="auto">,</span><span data-contrast="auto"> the binary package is available in </span><span data-contrast="auto">user’s</span><span data-contrast="auto"> local</span><span data-contrast="auto"> Conan</span><span data-contrast="auto"> cache</span><span data-contrast="auto">, and can be </span><span data-contrast="auto">linked to any other project</span><span data-contrast="auto">.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;<br></span><span></span></p>
<p><span><strong>How to get and build the packages?&nbsp;</strong><br></span><span data-contrast="auto"></span></p>
<p><span data-contrast="auto">An example build call</span> <span data-contrast="auto">look</span><span data-contrast="auto">s</span><span data-contrast="auto"> like this:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<pre>$conan.exe install qtnetworkauth/6.0.0@qt/beta --build=missing <br>--profile=&lt;QtSdk&gt;/Tools/Conan/profiles/qt-6.0.0-msvc2019_64 -s <br>build_type=Release -g cmake_paths -g=cmake -g deploy&nbsp;</pre>

<p><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">Now, let's look what that contains:</span></p>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="auto">qtnetworkauth</span><span data-contrast="auto">/6.0.0@qt/beta</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="auto">This is the</span><span data-contrast="auto"> Conan</span><span data-contrast="auto"> reference for the package</span></li>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="auto">You can search available packages in your </span><span data-contrast="auto">C</span><span data-contrast="auto">onan cache by:</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;&nbsp;</span><span data-contrast="auto">$conan</span><span data-contrast="auto">.exe </span><span data-contrast="auto">search</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></li>
</ul>
</li>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">--profile</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">This file is installed by the Qt installer. Each </span><span data-contrast="none">Qt 6 E</span><span data-contrast="none">ssential package installed by the Qt </span><span data-contrast="none">I</span><span data-contrast="none">nstaller</span><span data-contrast="none"> installs also a matching profile file. This tells</span><span data-contrast="none"> Conan</span><span data-contrast="none"> the target build configuration.</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></li>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">The user needs to select</span><span data-contrast="none"> a </span><span data-contrast="none">suitable profile</span><span data-contrast="none">, that is </span><span data-contrast="none">the target build configuration.</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></li>
</ul>
</li>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">-g</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">If your consuming project is a </span><span data-contrast="none">CMake</span> <span data-contrast="none">project</span><span data-contrast="none"> the</span><span data-contrast="none">n</span><span data-contrast="none"> use the</span> <span data-contrast="none">CMake</span><span data-contrast="none"> generators</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></li>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">If your consuming project is</span><span data-contrast="none"> a</span> <span data-contrast="none">qmake</span> <span data-contrast="none">project</span><span data-contrast="none"> then you can pass: -g </span><span data-contrast="none">qmake</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></li>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">The “deploy” generator deploys the buil</span><span data-contrast="none">t</span><span data-contrast="none"> A</span><span data-contrast="none">dditional Library</span><span data-contrast="none"> from </span><span data-contrast="none">the</span><span data-contrast="none"> Conan</span><span data-contrast="none"> cache to your working environment</span><span data-contrast="none">. This is useful if you </span><span data-contrast="none">want to bundle your application files together.</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></li>
</ul>
</li>
</ul>
<p><span data-contrast="none">For detailed steps see the <a data-insert="true" href="https://wiki.qt.io/Qt6_Add-on_src_package_build_using_Conan_package_manager" rel="noopener">instructions</a>.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="none">Currently</span><span data-contrast="none">,</span><span data-contrast="none"> Qt </span><span data-contrast="none">Online </span><span data-contrast="none">Installer exports the A</span><span data-contrast="none">dditional Library packages (sources and build recipes)</span><span data-contrast="none"> into the</span><span data-contrast="none"> Conan</span><span data-contrast="none"> cache. There is no </span><span data-contrast="none">C</span><span data-contrast="none">onan remote that hosts the Add</span><span data-contrast="none">itional Library</span> <span data-contrast="none">C</span><span data-contrast="none">onan packages</span><span data-contrast="none">.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p aria-level="2"><strong>Next steps&nbsp;</strong></p>
<p><span data-contrast="none">Like Qt 6.0, the current work is still in beta phase and </span><span data-contrast="none">all </span><span data-contrast="none">feedback is welcome</span><span data-contrast="none">.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;Note that currently the Conan profile files and build recipies for&nbsp;</span><span data-contrast="none">Android and iOS targets are being worked on</span><span data-contrast="none">.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;Also, t</span><span data-contrast="none">he build recipes of the </span><span data-contrast="none">Additional Libraries</span><span data-contrast="none"> are not part of the repositories yet. </span><span>&nbsp;</span><span data-contrast="none">Once the build recipes</span><span data-contrast="none"> are mature</span><span data-contrast="none"> the plan is to move those into module repositories.</span><span>&nbsp;</span></p>
<p><span></span><span data-contrast="none">If you want to have a look already now</span><span data-contrast="none">,</span><span data-contrast="none"> how</span><span data-contrast="none"> the conanfile.py recipes </span><span data-contrast="none">look like</span><span data-contrast="none">,</span> <span data-contrast="none">those </span><span data-contrast="none">can be found </span><span data-contrast="none">in</span> <span data-contrast="none">the </span><span data-contrast="none">Qt installation, under each module in “</span><span data-contrast="none">AdditionalLibraries</span><span data-contrast="none">/Qt</span><span data-contrast="none">/”</span><span data-contrast="none">.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
&nbsp;</span></p>
                            
                            
                                <hr>
                          
                                <h6>Blog Topics:</h6>        
                                
                            


                        </div></div>]]>
            </description>
            <link>https://www.qt.io/blog/qt-6-additional-libraries-via-package-manager</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916321</guid>
            <pubDate>Wed, 28 Oct 2020 07:55:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Sjgar Stack]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24916319">thread link</a>) | @vijairamcharan
<br/>
October 28, 2020 | https://sjgarstack.org/blog/20201028/introducing-the-sjgar-stack | <a href="https://web.archive.org/web/*/https://sjgarstack.org/blog/20201028/introducing-the-sjgar-stack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<p><em>Published October 28th, 2020 – 20 min read</em></p>
<p><strong>In this article I will introduce you to a new software stack that can be thought of as a spiritual successor to the MEAN or MERN stack. The technologies in the SJGAR stack were carefully combined to create something where the whole is greater than the sum of its parts. Focus on your customers, on business value and the developer experience. Do more, and keep things simple.</strong></p>
<p><strong>If you want to find out why the mix of Serverless, JavaScript, GraphQL, AWS and React could be interesting to you please read on.</strong></p>
<p><em>Disclaimer: This is <strong>not</strong> a sponsored post. All views expressed in this article are mine and may or may not be shared by my employer.</em></p>
<p><span>
      <a target="_blank" rel="noopener" href="https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/857b3/pexels-archie-binamira-672358.jpg">
    <span></span>
  <img alt="Climb the mountain. Keep it simple. Photo by Archie Binamira from Pexels" title="Climb the mountain. Keep it simple. Photo by Archie Binamira from Pexels" src="https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/de5ef/pexels-archie-binamira-672358.jpg" srcset="https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/e6c22/pexels-archie-binamira-672358.jpg 205w, https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/0d3fb/pexels-archie-binamira-672358.jpg 410w, https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/de5ef/pexels-archie-binamira-672358.jpg 820w, https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/4f4d6/pexels-archie-binamira-672358.jpg 1230w, https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/b68c0/pexels-archie-binamira-672358.jpg 1640w, https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/857b3/pexels-archie-binamira-672358.jpg 6000w" sizes="(max-width: 820px) 100vw, 820px" loading="lazy">
  </a>
    </span></p>

<p>I remember writing software in the period roughly between 2005 and 2015 where sometimes it could feel like every week something new was thrown at us. We were transitioning from desktop to the web and then cloud and mobile. We were just getting good at Object-oriented programming when a shift towards Functional Programming required us to rethink our mental models around our code. Cloud scale computing brought us from solely using SQL databases to study and use NoSQL databases. We went from embracing XML and SOAP to transitioning to JSON.</p>
<div><p><h3>Focus on your customers, on business value and the developer experience. Do more, and keep things simple.</h3></p></div>

<p>Looking at JavaScript alone there was also a lot of turmoil. The language started almost as a toy language to glue together simple elements on a web page. Then it slowly but steadily grew into becoming the most widely used programming language on the web. It even moved on beyond the browser and started to conquer the server with Node.js. A realm where Java and .NET were dominant before, now had to create some room for people starting to use JavaScript on the server.</p>
<p>On the web, framework after framework was becoming popular. Much to the point where they are still being refactored away ten years later. I remember moving from jQuery to Backbone or Knockout. I used Ember a bit and then also Angular. All of these seemed to offer some improvements over what was previously there. There were still enough rough edges however. It was clear we were not there yet.</p>
<div id="enter-the-calm-and-how-we-used-the-sjgar-stack-for-the-first-time"><h3><a href="#enter-the-calm-and-how-we-used-the-sjgar-stack-for-the-first-time" target="_blank" rel="noopener noreferrer" aria-label="enter the calm and how we used the sjgar stack for the first time permalink"></a>Enter the Calm and how we used the SJGAR stack for the first time.</h3></div>
<p>In 2015, I got the chance to work on a corporate startup project that was completely greenfield. We set out to create a platform with web and mobile apps with state-of-the-art user experience, and we wanted to fail or succeed fast. This meant we had to ensure a short time to market. We had to focus on developer experience and productivity. After having tried some pieces of technology on smaller projects, this was the perfect chance to put them together and figure out if they would play nicely together. In theory, it should all work, but previous experience had shown that you really need to start using them for a decent amount of time to figure out if the new advantages will really outweigh the drawbacks.</p>
<div><p><h3>It worked. It really worked.</h3></p></div>
<p>We built a web application using React and an accompanying mobile app using React Native. The backend was built using AWS Serverless technologies. We used DynamoDB as the single source of truth for data. The built-in event triggering system was used to run some Node.js code in a Lambda to stream this data to a managed Elasticsearch cluster, so we could support the search and query capabilities we needed. We created a GraphQL API using the reference server implementation graphql-js (Apollo Server and Client weren't a thing back then). Again this was run in Lambda. To make sure the web application was performant enough for our end users we used a Lambda to implement Server Side Rendering (Gatsby and Next.js also weren't a thing back then). We also used the Serverless framework, a bit shaky at that time, to write our infra as code.</p>
<p>With a handful of full stack engineers we were able to deliver this project successfully to production. We could deliver new versions of our microservices independently, and we would do this multiple times a day.</p>
<p>It worked. It really worked.</p>
<p>We started with almost zero costs for infrastructure. The most expensive service was the Elasticsearch service. The other services would easily service our first customers on the free tier. I think we never spent over 100 euros a month. Without Elasticsearch it would probably not have been higher than 10 euros a month. We launched and started running ad campaigns to lure customers to our new offering. For these ad campaigns we were spending over a thousand euros per month. It was clear that we now could go to the business and tell them we could do innovation projects with IT running costs of close to zero.</p>
<p>I remember we were able to move some logic from the web app to the authentication provider (we used Auth0 back then since Cognito was still a bit too new) by just copying some JavaScript code. Similarly, we were able to move code from frontend to backend. More generally we were able to take what we learned in a certain context, and apply it to a different one. JavaScript allowed us to learn a single programming language and write code for the Web, Mobile and Cloud. React allowed us to use a single framework to structure applications and do the state management for both Web and Mobile. Using Flexbox we could even apply the same UI layout system in these apps. With the complex and time-consuming nature of layout work, it was great that we were able to reuse our knowledge and tools to enjoy a great productivity boost.</p>
<p>Going Serverless meant we did not have to spend time on managing servers. The code and the system would just work. No disks filling up, no security patches to be applied, no certificates to be updated. AWS had given us a platform with great performance and stability. Everything would just run.</p>
<p>After running this project in 2015 and 2016, in the end it was shuttered because it did not align with our business goals. Only later I came to realize this set of technologies would stand the test of time, and would do so pretty well.</p>
<div id="okay-this-thing-needs-a-name"><h3><a href="#okay-this-thing-needs-a-name" target="_blank" rel="noopener noreferrer" aria-label="okay this thing needs a name permalink"></a>Okay. This Thing Needs A Name.</h3></div>
<p>Fast-forward a bit to when I joined my current team and company early 2019. We formed a new innovation department and dreamed of a future where we helped turn our 175-year-old financial company into a fintech. Teaming up with the department that was our business counterpart, in the first year we built and delivered a total of fourteen projects with a relatively common two pizza team. In the previous nineteen years of my career I had never witnessed anything like this. We built smaller projects like landing pages, but also large ones like a new platform to sell houses using data and AI. We also built a fairly complex API to serve as the backend for an IoT driven car insurance. We even managed to surprise ourselves and win a hackathon in our first year with a mobile app for planting trees.</p>
<div><p><h3>Five years after having first used this set of technologies it was clear that they still were around. Not only were they still around, they had become even stronger with a bigger community supporting them.</h3></p></div>
<p>Many things fell into place to make this a success. For one, it were the amazing people we joined. I consider myself lucky to this day that we met them and were able to make all of these things happen. It was almost as if we started in a performing phase as a team, skipping the forming, norming and storming phases altogether.</p>
<p>Besides the people the technology played an important role here. Five years after having first used this set of technologies it was clear that they still were around. Not only were they still around, they had become even stronger with a bigger community supporting them.</p>
<p>What was really cool was that we were able to deliver all these different types of applications using basically the same architecture. For the IoT insurance, the API we delivered we implemented a lightweight event sourced system using mainly DynamoDB and Lambda. We later added a future event system where we combined DynamoTTL and Step Functions to combine high and low resolution timers, all of which were inspired by a set of blog posts and a tweet we found on the web.</p>
<p>For the housing platform we combined Cognito, Azure AD, DynamoDB, Lambda, AppSync, S3 and CloudFront to deliver a platform that was highly performant. Gatsby helped us leverage React’s power to build statically rendered, SEO-friendly pages, hosted on S3 and made available to the wide internet using CloudFront and Route53. On the backend we created a GraphQL API to, on the one hand, power the build-time data requirements. On the other hand it also powered the real-time admin panel we needed for providing customers support.</p>
<p>There were many more projects that used very similar architectures. Five years after first having used these technologies we were still able to use them to build modern applications. In our hiring process I remember seeing the smiles on the faces of the engineers when we would mention our tech stack.</p>
<div><p><h3>Which parts are going to be successful for at least the next five years?</h3></p></div>
<p>There was this one thing I noticed though. Whenever I wanted to explain our technology stack, I was summing up this combination of technologies one by one. Time after time saying things like “Our stack is JavaScript based, uses the React ecosystem and runs on AWS Serverless... And oh yeah we use GraphQL as a BFF for our apps.” A couple of days later I would say something like “We build apps using React and use JavaScript/TypeScript. Our APIs are running on AWS Lambda using NodeJS.”. And then many more variations of these sentences.</p>
<p>Okay. This thing needs a name.</p>
<p>Back in the days we had the LAMP stack, and some time after that there was the MEAN stack. Acronyms that became part of our vocabulary to help explain the stack we were using, or even inspired greenfield projects to combine these technologies. People would think, hey, I recently have been hearing a lot of buzz around the MEAN …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sjgarstack.org/blog/20201028/introducing-the-sjgar-stack">https://sjgarstack.org/blog/20201028/introducing-the-sjgar-stack</a></em></p>]]>
            </description>
            <link>https://sjgarstack.org/blog/20201028/introducing-the-sjgar-stack</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916319</guid>
            <pubDate>Wed, 28 Oct 2020 07:55:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using an AWS ECR Image as a GitHub Action Container]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24916221">thread link</a>) | @mbitard
<br/>
October 28, 2020 | https://agileek.github.io/software/aws/2020/10/28/using-an-ecr-image-in-github-actions/ | <a href="https://web.archive.org/web/*/https://agileek.github.io/software/aws/2020/10/28/using-an-ecr-image-in-github-actions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <h2 id="moving-from-docker-hub-to-ecr">Moving from Docker Hub to ECR</h2>

<p><a href="https://pubstack.io/">Pubstack</a>, my current client decided to migrate all its docker images to <a href="https://aws.amazon.com/ecr/">ECR</a>.</p>

<p>With the recent <a href="https://www.docker.com/pricing/resource-consumption-updates">announcement</a> about rate limiting on Docker Hub, maybe we will not be the only ones moving away.</p>

<p>For our <strong>CI/CD</strong> pipelines we use both <a href="https://circleci.com/">CircleCI</a> and <a href="https://github.com/features/actions">GitHub Actions</a>.</p>

<p>Using an <strong>ECR</strong> image is a really simple task in <strong>CircleCI</strong>, it consists of adding the <code>aws_auth</code> to the image configuration.</p>

<div><div><pre><code>  <span>docker</span><span>:</span>
    <span>-</span> <span>image</span><span>:</span> <span>ACCOUNT.dkr.ecr.REGION.amazonaws.com/IMAGE:VERSION</span>
      <span>aws_auth</span><span>:</span>
        <span>aws_access_key_id</span><span>:</span> <span>$AWS_ACCESS_KEY_ID</span>
        <span>aws_secret_access_key</span><span>:</span> <span>$AWS_SECRET_ACCESS_KEY</span>
</code></pre></div></div>

<p>On the other hand, using <strong>ECR</strong> images in <strong>GitHub Actions</strong> was a bit more tricky.</p>

<p>The problem is, you could only use images from private registries in job and service containers since <a href="https://github.blog/changelog/2020-09-24-github-actions-private-registry-support-for-job-and-service-containers/">late september</a>, and they only did the “credentials” implementation.
It means something like this is expected:</p>

<div><div><pre><code><span>jobs</span><span>:</span>
  <span>test</span><span>:</span>
    <span>runs-on</span><span>:</span> <span>ubuntu-latest</span>
    <span>container</span><span>:</span>
      <span>image</span><span>:</span> <span>ACCOUNT.dkr.ecr.REGION.amazonaws.com/IMAGE:VERSION</span>
      <span>credentials</span><span>:</span>
        <span>username</span><span>:</span> <span>AWS</span>
        <span>password</span><span>:</span> <span>${{ secrets.ECR_PASSWORD }}</span>
    <span>steps</span><span>:</span>
      <span>-</span> <span>run</span><span>:</span> <span>echo "inside an ecr container"</span>
</code></pre></div></div>

<p>With aws, you can get a password with <code>aws ecr get-login-password</code>, and it is valid 12 hours.</p>

<p>You can manually set the GitGub secret “ECR_PASSWORD” every 12 hours, but that’s not really convenient.</p>

<p>After a little digging, I found an <a href="https://github.community/t/github-actions-new-pulling-from-private-docker-repositories/16089/28">answer</a> on a GitHub community thread explaining what seems like a good solution.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>

<p>Basically what we will do is:</p>

<ol>
  <li>Retrieve <strong>ECR</strong> password from aws</li>
  <li>Store it as a <strong>GitHub</strong> secret name <code>ECR_PASSWORD</code></li>
</ol>

<p>All that inside a <strong>GitHub</strong> action scheduled to run every 6 hours.</p>

<p>It was not really as simple as I first thought, so here is all I had to do.
I hope it can help you.</p>

<p>First, I created some aws credentials (ie. a couple <code>aws_access_key_id</code> and <code>aws_secret_access_key</code> with enough right to pull from ECR)
I put them as secrets inside the <strong>GitHub</strong> project, let’s call them <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code>.
Then I generated a personal access token (the “provided by default” <code>GITHUB_TOKEN</code> doest not have sufficient rights), let’s call it <code>GH_API_ACCESS_TOKEN</code>.</p>

<p>The complete <strong>GitHub</strong> workflow:</p>

<div><div><pre><code><span>name</span><span>:</span> <span>ecr-login</span>
<span>on</span><span>:</span>
  <span># Every 6 hours, the password validity is 12 hours</span>
  <span>schedule</span><span>:</span>
    <span>-</span> <span>cron</span><span>:</span>  <span>'</span><span>0</span><span> </span><span>*/6</span><span> </span><span>*</span><span> </span><span>*</span><span> </span><span>*'</span>
<span>jobs</span><span>:</span>
  <span>login</span><span>:</span>
    <span>runs-on</span><span>:</span> <span>ubuntu-latest</span>
    <span>steps</span><span>:</span>
      <span>-</span> <span>name</span><span>:</span> <span>Checkout</span>
        <span>uses</span><span>:</span> <span>actions/checkout@v2</span>
      <span>-</span> <span>name</span><span>:</span> <span>AWS cli install action</span>
        <span>uses</span><span>:</span> <span>chrislennon/action-aws-cli@1.1</span>
      <span>-</span> <span>name</span><span>:</span> <span>retrieve ecr password and store as secret</span>
        <span>run</span><span>:</span> <span>|</span>
          <span>pip3 install -r .github/requirements.txt</span>
          <span>python3 .github/ecr_password_updater.py</span>
        <span>env</span><span>:</span>
          <span>AWS_ACCESS_KEY_ID</span><span>:</span> <span>${{ secrets.AWS_ACCESS_KEY_ID }}</span>
          <span>AWS_SECRET_ACCESS_KEY</span><span>:</span> <span>${{ secrets.AWS_SECRET_ACCESS_KEY }}</span>
          <span>AWS_DEFAULT_REGION</span><span>:</span> <span>AWS_REGION</span>
          <span>GH_API_ACCESS_TOKEN</span><span>:</span> <span>${{ secrets.GH_API_ACCESS_TOKEN }}</span>
  <span># This 'test' job is usefull for fast debugging</span>
  <span>test</span><span>:</span>
    <span>needs</span><span>:</span> <span>login</span>
    <span>runs-on</span><span>:</span> <span>ubuntu-latest</span>
    <span>container</span><span>:</span>
      <span>image</span><span>:</span> <span>ACCOUNT.dkr.ecr.REGION.amazonaws.com/IMAGE:VERSION</span>
      <span>credentials</span><span>:</span>
        <span>username</span><span>:</span> <span>AWS</span>
        <span># Here is the password retrieved as a secret that is set by the `login` job</span>
        <span>password</span><span>:</span> <span>${{ secrets.ECR_PASSWORD }}</span>
    <span>steps</span><span>:</span>
      <span>-</span> <span>run</span><span>:</span> <span>echo "Inside a container pulled from ECR \o/"</span>
</code></pre></div></div>

<p>The python file <code>ecr_password_updater.py</code>:</p>

<div><div><pre><code><span>from</span> <span>base64</span> <span>import</span> <span>b64encode</span>
<span>from</span> <span>nacl</span> <span>import</span> <span>encoding</span><span>,</span> <span>public</span>
<span>import</span> <span>requests</span>
<span>import</span> <span>os</span>
<span>import</span> <span>subprocess</span>
<span>import</span> <span>json</span>


<span>def</span> <span>encrypt</span><span>(</span><span>raw_public_key</span><span>:</span> <span>str</span><span>,</span> <span>secret_value</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>"""Encrypt a Unicode string using the public key."""</span>
    <span>public_key</span> <span>=</span> <span>public</span><span>.</span><span>PublicKey</span><span>(</span><span>raw_public_key</span><span>.</span><span>encode</span><span>(</span><span>"utf-8"</span><span>),</span> <span>encoding</span><span>.</span><span>Base64Encoder</span><span>())</span>
    <span>sealed_box</span> <span>=</span> <span>public</span><span>.</span><span>SealedBox</span><span>(</span><span>public_key</span><span>)</span>
    <span>encrypted</span> <span>=</span> <span>sealed_box</span><span>.</span><span>encrypt</span><span>(</span><span>secret_value</span><span>.</span><span>encode</span><span>(</span><span>"utf-8"</span><span>))</span>
    <span>return</span> <span>b64encode</span><span>(</span><span>encrypted</span><span>).</span><span>decode</span><span>(</span><span>"utf-8"</span><span>)</span>


<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span>

    <span>get_public_key</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>f'https://api.github.com/repos/ORG/REPOSITORY/actions/secrets/public-key'</span><span>,</span>
                                  <span>headers</span><span>=</span><span>{</span><span>'Accept'</span><span>:</span> <span>'application/vnd.github.v3+json'</span><span>,</span>
                                           <span>'Authorization'</span><span>:</span> <span>'token '</span> <span>+</span> <span>os</span><span>.</span><span>environ</span><span>[</span><span>'GH_API_ACCESS_TOKEN'</span><span>]})</span>
    <span>if</span> <span>get_public_key</span><span>.</span><span>ok</span> <span>is</span> <span>False</span><span>:</span>
        <span>print</span><span>(</span><span>'could not retrieve public key'</span><span>)</span>
        <span>print</span><span>(</span><span>get_public_key</span><span>.</span><span>text</span><span>)</span>
        <span>exit</span><span>(</span><span>1</span><span>)</span>
    <span>get_public_key_response</span> <span>=</span> <span>get_public_key</span><span>.</span><span>json</span><span>()</span>
    <span>public_key_value</span> <span>=</span> <span>get_public_key_response</span><span>[</span><span>'key'</span><span>]</span>
    <span>public_key_id</span> <span>=</span> <span>get_public_key_response</span><span>[</span><span>'key_id'</span><span>]</span>

    <span>password</span> <span>=</span> <span>subprocess</span><span>.</span><span>run</span><span>([</span><span>'aws'</span><span>,</span> <span>'ecr'</span><span>,</span> <span>'get-login-password'</span><span>],</span> <span>stdout</span><span>=</span><span>subprocess</span><span>.</span><span>PIPE</span><span>).</span><span>stdout</span><span>.</span><span>decode</span><span>(</span><span>'utf-8'</span><span>)</span>
    <span>encrypted_password</span> <span>=</span> <span>encrypt</span><span>(</span><span>public_key_value</span><span>,</span> <span>password</span><span>)</span>
    <span>update_password</span> <span>=</span> <span>requests</span><span>.</span><span>put</span><span>(</span><span>'https://api.github.com/repos/ORG/REPOSITORY/actions/secrets/ECR_PASSWORD'</span><span>,</span>
                                   <span>headers</span><span>=</span><span>{</span><span>'Accept'</span><span>:</span> <span>'application/vnd.github.v3+json'</span><span>,</span>
                                            <span>'Authorization'</span><span>:</span> <span>'token '</span> <span>+</span> <span>os</span><span>.</span><span>environ</span><span>[</span><span>'GH_API_ACCESS_TOKEN'</span><span>]},</span>
                                   <span>data</span><span>=</span><span>json</span><span>.</span><span>dumps</span><span>({</span><span>'encrypted_value'</span><span>:</span> <span>encrypted_password</span><span>,</span> <span>'key_id'</span><span>:</span> <span>public_key_id</span><span>}))</span>
    <span>if</span> <span>update_password</span><span>.</span><span>ok</span> <span>is</span> <span>False</span><span>:</span>
        <span>print</span><span>(</span><span>'could not update password'</span><span>)</span>
        <span>print</span><span>(</span><span>update_password</span><span>.</span><span>text</span><span>)</span>
        <span>exit</span><span>(</span><span>1</span><span>)</span>

</code></pre></div></div>

<p>The dependencies used by the python code:</p>
<div><div><pre><code>pynacl==1.4.0
requests==2.24.0
</code></pre></div></div>

<p>I first started with a simple bash script, but it became quite complex<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>, so I switched to python.</p>

<p>Enjoy!</p>



    </div></div>]]>
            </description>
            <link>https://agileek.github.io/software/aws/2020/10/28/using-an-ecr-image-in-github-actions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916221</guid>
            <pubDate>Wed, 28 Oct 2020 07:37:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracing Kernel Functions: FBT stack() and arg]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24915942">thread link</a>) | @moks
<br/>
October 27, 2020 | https://zinascii.com/2020/fbt-args-and-stack.html | <a href="https://web.archive.org/web/*/https://zinascii.com/2020/fbt-args-and-stack.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      
      <p>Oct 27, 2020</p>

      <p>
	In my <a href="https://zinascii.com/2020/the-amd64-fbt-handler.html">previous
	post</a> I described how FBT intercepts function calls and
	vectors them into the DTrace framework. That laid the
	foundation for what I want to dicuss in this post: the
	implementation of the <code>stack()</code> action and
	built-in <code>arg</code> variables. These features rely on
	the precise layout of the stack, the details of which I
	touched on previously. In this post I hope to illuminate those
	details a bit more with the help of some visuals, and then
	guide you through the implentation of these two DTrace
	features as they relate to the FBT provider.
      </p>

      <h2>A Correction</h2>

      <p>
	But first I must make a correction to my last post. It turns
	out the FBT handler <b>does not</b> execute on the IST stack.
	It runs on either the thread’s stack or the CPU’s high-level
	interrupt stack depending on the context of the kernel
	function call, but never on the IST.
	Rather, <a href="https://en.wikipedia.org/wiki/Kernel_page-table_isolation">KPTI</a>
	uses the IST stack as a scratch space to perform its
	trampoline into the real handler. This little detail is
	important. Functions like <code>dtrace_getpcstack()</code>
	have zero chance of working if run with the IST stack, for
	reasons which become obvious later. This also explains why the
	AMD64 handler pulls down the stack
	during <code>pushq&nbsp;%RBP</code> emulation: if it’s working
	on the same stack as the thread/interrupt, then it must make
	room for <code>RBP</code>. I can explain better with a visual.
	First, the diagram from the last post.
      </p>

      <figure>
	  
	  <figcaption><a name="fig1-int3-pre-handler">Figure 1. INT3 thread/interrupt state pre-handler</a></figcaption>
      </figure>

      <p>
	On the left we have a kernel thread, interrupt thread, or
	high-level interrupt running on CPU. On the right we have the
	“interrupt context” of the breakpoint exception, using the
	IST. The image is correct in that there are two different
	stacks in play, but what’s running on the right-hand side is
	not the <code>brktrap</code> handler. The right-hand side is
	running the KPTI trampoline, ensuring a CR3 switch when moving
	between the user/kernel boundary. The trampoline also provides
	a facsimile of the processor frame to the interrupted thread’s
	stack, making it none the wiser that KPTI was ever on the
	scene. So all the action happens on the left side, but what
	does the stack look like as we transition through the #BP
	handler on our way to <code>dtrace_invop()</code>?
      </p>

      <figure>
	  
	  <figcaption><a name="fig2-pre-fbt-stack">Figure 2. stack state from #BP to pre dtrace_invop()</a></figcaption>
      </figure>

      <p>
	In phase ① <code>mac_provider_tx()</code> is
	calling <code>mac_ring_tx()</code> while it is under FBT entry
	instrumentation. The last thing on the thread’s stack is the
	return address, and the CPU is about to execute
	the <code>int3</code> instruction.
      </p>

      <p>
	Phase ② is immediately after the CPU has finished execution of
	the <code>int3</code> instruction. The processor (via the
	spectre of the KPTI trampoline) has pushed a 16-byte aligned
	processor frame on the stack and has vectored into
	the <code>brktrap()</code> handler.
      </p>

      <p>
	Phase ③ is after some amount of execution of
	the <code>brktrp()</code> and <code>invoptrap()</code>
	handlers—remember, the #BP handler for DTrace mimics a #UD.
	This last phase shows the state just before the call
	to <code>dtrace_invop()</code>. At this point we’ve grown an
	entire <code>regs</code> structure on the stack and stashed a
	copy of the return address on top of this. The later used to
	populate <code>cpu_dtrace_caller</code>, a variable which
	becomes important later.
      </p>

      <h2>The stack() Action</h2>

      <p>
	The separation of probes and actions is a vital aspect of
	DTrace’s architecture. A firm boundary between these two makes
	DTrace more powerful than it ever could be if they were
	tightly coupled. Think about it, I can ask for the call stack
	in any probe, not just the probes that deem that information
	useful. The probes give you access to a context, and the
	actions give you access to data in that context. To limit the
	execution of actions to specific probes would limit the
	questions you can ask about the system. With this design the
	number of questions you can ask is virtually endless. And it
	turns out one of the more useful questions to ask is: “what
	the hell is running on my CPU”?
      </p>

      <p>
	The <code>stack()</code> action allows you to record the call
	stack that lead to the probe site. In the context of FBT this
	will record the call stack of the kernel thread or interrupt
	executing an entry or return from this kernel function. You
	can also access the userland stack of a thread
	via <code>ustack()</code>, but I don’t cover that here.
      </p>

      <p>
	The <code>stack()</code> action is implemented by
	the <code>dtrace_getpcstack()</code> function. To get there
	from <code>dtrace_invop()</code> requires a couple of more
	calls in the DTrace framework. Ultimately, the call stack to
	get there looks like this.
      </p>

      <figure>
	<div>
	  <pre><code>dtrace_getpcstack()
dtrace_probe()
fbt_invop()
dtrace_invop()
dtrace_invop_callsite() &lt;aka invoptrap&gt;
&lt;rest of call stack that lead here&gt;</code></pre>
	</div>
	<figcaption>call stack between dtrace_getpcstack() and dtrace_invop()</figcaption>
      </figure>

      <p>
	The implementation of <code>stack()</code> really starts
	with <code>DTRACEACT_STACK</code> inside
	of <code>dtrace_probe()</code>.
      </p>

      <figure>
	<figcaption><a href="https://github.com/illumos/illumos-gate/blob/007ca33219ffdc49281657f5f8a9ee1bbfc367ab/usr/src/uts/common/dtrace/dtrace.c#L7184-L7191">usr/src/uts/common/dtrace/dtrace.c</a></figcaption>
	<figure>
	  <div>
<pre><span><span></span><code>			case DTRACEACT_STACK:</code></span>
<span><span></span><code>				if (!dtrace_priv_kernel(state))</code></span>
<span><span></span><code>					continue;</code></span>
<span><span></span><code></code></span>
<span><span></span><code>				dtrace_getpcstack((pc_t *)(tomax + valoffs),</code></span>
<span><span></span><code>				    size / sizeof (pc_t), probe-&gt;dtpr_aframes,</code></span>
<span><span></span><code>				    DTRACE_ANCHORED(probe) ? NULL :</code></span>
<span><span></span><code>				    (uint32_t *)arg0);</code></span></pre>
	  </div>
	  <figcaption>stack() action implementation found in dtrace_probe()</figcaption>
	</figure>
      </figure>

      <p>
	The first argument is the address of the array used to store
	program counter values (aka function pointers). This array
	starts at some offset into the current DTrace buffer. The
	second argument if the size of that array. The third argument
	is the number of “artificial frames” on the stack, more on
	this later. The fourth argument is used to determine if the
	first (topmost) program counter in the call stack is the value
	passed in <code>arg0</code> to <code>dtrace_probe()</code>. An
	“anchored” probe is one that has a function name specified
	when calling <code>dtrace_probe_create()</code>. For example,
	the FBT provider uses the name of the kernel function as the
	probe’s function name, thus it is anchored on the kernel
	function. The profile provider, however, specifies no probe
	function name; it is not anchored and is a bit of a special
	case. I address this at the end of the post.
      </p>

      <p>
	This brings us to the <code>dtrace_getpcstack()</code>
	function. But first I’ll expand
	on <a href="#fig2-pre-fbt-stack">figure 2</a> to show our
	stack state as of source line 60 of the function.
      </p>

      <figure>
	
	<figcaption>
	  <a name="fig3-start-of-dtrace_getpcstack">Figure 3. start of dtrace_getpcstack()</a>
	</figcaption>
      </figure>

      <figure>
	<figcaption><a href="https://github.com/illumos/illumos-gate/blob/007ca33219ffdc49281657f5f8a9ee1bbfc367ab/usr/src/uts/intel/dtrace/dtrace_isa.c#L43-L60">usr/src/uts/intel/dtrace/dtrace_isa.c</a></figcaption>
	<figure>
	  <div>
<pre><span><span></span><code>void</code></span>
<span><span></span><code>dtrace_getpcstack(pc_t *pcstack, int pcstack_limit, int aframes,</code></span>
<span><span></span><code>    uint32_t *intrpc)</code></span>
<span><span></span><code>{</code></span>
<span><span></span><code>	struct frame *fp = (struct frame *)dtrace_getfp();</code></span>
<span><span></span><code>	struct frame *nextfp, *minfp, *stacktop;</code></span>
<span><span></span><code>	int depth = 0;</code></span>
<span><span></span><code>	int on_intr, last = 0;</code></span>
<span><span></span><code>	uintptr_t pc;</code></span>
<span><span></span><code>	uintptr_t caller = CPU-&gt;cpu_dtrace_caller;</code></span>
<span><span></span><code></code></span>
<span><span></span><code>	if ((on_intr = CPU_ON_INTR(CPU)) != 0)</code></span>
<span><span></span><code>		stacktop = (struct frame *)(CPU-&gt;cpu_intr_stack + SA(MINFRAME));</code></span>
<span><span></span><code>	else</code></span>
<span><span></span><code>		stacktop = (struct frame *)curthread-&gt;t_stk;</code></span>
<span><span></span><code>	minfp = fp;</code></span>
<span><span></span><code></code></span>
<span><span></span><code>	aframes++;</code></span></pre>
	  </div>
	  <figcaption>dtrace_getpcstack()</figcaption>
	</figure>
      </figure>

      <p>
	To build the call stack we first need to be able to walk the
	stack. Luckily, illumos keeps frame pointers in the kernel,
	making this easy. But in this particular situation there is
	more to consider. First, we might have two stacks in play: the
	high-level interrupt’s stack as well as the stack of the
	thread it interrupted. Second, the DTrace framework and FBT
	provider have put their own frames between this code and the
	function that tripped this probe; we must exclude these
	“artificial” frames from the result. Finally, we need to make
	sure not to walk off the stack and into space, both for
	correctness and safety. Speaking of the stack,
	the <code>stacktop</code> variable is pointing to the “top” of
	the stack in terms of memory (on x86 stacks grow downwards).
	Logically speaking, <code>stacktop</code> is the bottom of the
	stack and the <code>dtrace_getpcstack()</code> frame is the
	top.
      </p>

      <figure>
	<figcaption><a href="https://github.com/illumos/illumos-gate/blob/007ca33219ffdc49281657f5f8a9ee1bbfc367ab/usr/src/uts/intel/dtrace/dtrace_isa.c#L62-L63">usr/src/uts/intel/dtrace/dtrace_isa.c</a></figcaption>
	<figure>
	  <div>
<pre><span><span></span><code>	if (intrpc != NULL &amp;&amp; depth &lt; pcstack_limit)</code></span>
<span><span></span><code>		pcstack[depth++] = (pc_t)intrpc;</code></span></pre>
	  </div>
	  <figcaption>dtrace_getpcstack()</figcaption>
	</figure>
      </figure>

      <p>
	If <code>intrpc</code> is set, then that’s our first program counter.
      </p>

      <figure>
	<figcaption><a href="https://github.com/illumos/illumos-gate/blob/007ca33219ffdc49281657f5f8a9ee1bbfc367ab/usr/src/uts/intel/dtrace/dtrace_isa.c#L65-L85">usr/src/uts/intel/dtrace/dtrace_isa.c</a></figcaption>
	<figure>
	  <div>
<pre><span><span></span><code>	while (depth &lt; pcstack_limit) {</code></span>
<span><span></span><code>		nextfp = (struct frame *)fp-&gt;fr_savfp;</code></span>
<span><span></span><code>		pc = fp-&gt;fr_savpc;</code></span>
<span><span></span><code></code></span>
<span><span></span><code>		if (nextfp &lt;= minfp || nextfp &gt;= stacktop) {</code></span>
<span><span></span><code>			if (on_intr) {</code></span>
<span><span></span><code>				/*</code></span>
<span><span></span><code>				 * Hop from interrupt stack to thread stack.</code></span>
<span><span></span><code>				 */</code></span>
<span><span></span><code>				stacktop = (struct frame *)curthread-&gt;t_stk;</code></span>
<span><span></span><code>				minfp = (struct frame *)curthread-&gt;t_stkbase;</code></span>
<span><span></span><code>				on_intr = 0;</code></span>
<span><span></span><code>				continue;</code></span>
<span><span></span><code>			}</code></span>
<span><span></span><code></code></span>
<span><span></span><code>			/*</code></span>
<span><span></span><code>			 * This is the last frame we can process; indicate</code></span>
<span><span></span><code>			 * that we should return after processing this frame.</code></span>
<span><span></span><code>			 */</code></span>
<span><span></span><code>			last = 1;</code></span>
<span><span></span><code>		}</code></span></pre>

	  </div>
	  <figcaption>dtrace_getpcstack()</figcaption>
	</figure>
      </figure>

      <p>
	The main loop walks the call stack and fills in program
	counters as long as there are slots remaining in
	<code>pcstack</code>. If we were in the context of a
	high-level interrupt and we’ve walked off its stack, then hop
	to the thread stack. Otherwise, we’ve walked off the thread
	stack, leaving just this last frame to record.
      </p>

      <figure>
	<figcaption><a href="https://github.com/illumos/illumos-gate/blob/007ca33219ffdc49281657f5f8a9ee1bbfc367ab/usr/src/uts/intel/dtrace/dtrace_isa.c#L87-L98">usr/src/uts/intel/dtrace/dtrace_isa.c</a></figcaption>
	<figure>
	  <div>
<pre><span><span></span><code>		if (aframes &gt; 0) {</code></span>
<span><span></span><code>			if (--aframes == 0 &amp;&amp; caller != 0) {</code></span>
<span><span></span><code>				/*</code></span>
<span><span></span><code>				 * We've just run out of artificial frames,</code></span>
<span><span></span><code>				 * and we have a valid caller -- fill it in</code></span>
<span><span></span><code>				 * now.</code></span>
<span><span></span><code>				 */</code></span>
<span><span></span><code>				ASSERT(depth &lt; pcstack_limit);</code></span>
<span><span></span><code>				pcstack[depth++] = (pc_t)caller;</code></span>
<span><span></span><code>				caller = 0;</code></span>
<span><span></span><code>			}</code></span>
<span><span></span><code>		} else {</code></span></pre>
	  </div>
	  <figcaption>dtrace_getpcstack()</figcaption>
	</figure>
      </figure>

      <p>
	Make sure to skip over any artificial frames.
	The <code>aframes</code> value is based on information given
	by the provider at probe creation time
	(<code>dtrace_probe_create()</code>/<code>dtpr_aframes</code>)
	as well as knowledge inherent to the DTrace framework. These
	two know how many frames they have each injected between
	the <code>stack()</code> action and the first real frame; we
	sum the values to know how many total frames to skip.
      </p>

      <p>
	The <code>caller</code> variable is a bit more subtle; and
	this is another thing I got wrong in
	my <a href="https://zinascii.com/2020/the-amd64-fbt-handler.html">last post</a> while
	discussing the return probe. The <code>caller</code> value
	…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zinascii.com/2020/fbt-args-and-stack.html">https://zinascii.com/2020/fbt-args-and-stack.html</a></em></p>]]>
            </description>
            <link>https://zinascii.com/2020/fbt-args-and-stack.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915942</guid>
            <pubDate>Wed, 28 Oct 2020 06:39:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub should stand up to the RIAA over YouTube-dl]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24915885">thread link</a>) | @pabs3
<br/>
October 27, 2020 | https://funnelfiasco.com/blog/2020/10/25/youtube-dl-github-riaa/ | <a href="https://web.archive.org/web/*/https://funnelfiasco.com/blog/2020/10/25/youtube-dl-github-riaa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Earlier this week, <a href="https://www.zdnet.com/article/riaa-blitz-takes-down-18-github-projects-used-for-downloading-youtube-videos/">GitHub took down the repository</a> for the youtube-dl project. This came in response to a request from the RIAA—the recording industry’s lobbying and harassment body. youtube-dl is a tool for downloading videos. The RIAA argued that this violates the anticircumvention protections of the Digital Millennium Copyright Act (DMCA). While GitHub taking down the repository and its forks is true to the principle of minimizing corporate risk, it’s the wrong choice.</p>



<p> Microsoft—currently the world’s second-most valuable company with a market capitalization of $1.64 trillion—owns GitHub. If anyone is in a position to fight back on this, it’s Microsoft. Microsoft’s lawyers should have a one word answer to the RIAA’s request: “no”. <em>(full disclosure: I own a small number of shares of Microsoft)</em></p>



<h2>The procedural argument</h2>



<p>The first reason to tell the RIAA where to stick it is procedural. The RIAA isn’t arguing that youtube-dl is infringing its copyrights or circumventing its protections. It is arguing that youtube-dl infringes YouTube’s protections. So even if it is, that’s YouTube’s problem, not the RIAA’s.</p>



<h2>The factual argument</h2>



<p>I have some sympathy for the anticircumvention argument. I’m not familiar with the specifics of how youtube-dl works, but it’s at least possible that youtube-dl circumvents YouTube’s copy protection. This would be a reasonable basis for YouTube to take action. Again, YouTube, not the RIAA.</p>



<p>I have less sympathy for the infringement argument. youtube-dl doesn’t induce infringement more than a web browser or screen recorder does. There are a variety of uses for youtube-dl that are not infringing. Foremost is the fact that some YouTube videos are under a license that explicitly allows sharing and remixing. Archivers use it to archive content. Some people who have time-variable Internet billing use it to download videos overnight.</p>



<p>So, yes, youtube-dl can be used to infringe the RIAA’s copyrights. It can also be used for non-infringing purposes. The code itself does not infringe. There’s nothing about it that gives the RIAA a justification to take it down.</p>



<h2>youtube-dl isn’t the whole story</h2>



<p>youtube-dl provides a focal point, but there’s more to it. Copyright law is now used to suppress instead of promote creative works. The DMCA, in particular, favors the large rightsholders over smaller developers and creators. It essentially forces sites to act on a “guilty until proven innocent” model. Companies in a position to push back have an obligation to do so. Microsoft has become a supporter of open source, now it’s time to show they mean it.</p>



<p>We should also consider the risks of consolidation. git is a decentralized system. GitHub has essentially centralized it. Sure, many competitors exist, but GitHub has become the default place to host open source code projects. The fact that GitHub’s code is proprietary is immaterial to this point. A FOSS service would pose the same risk if it became the centralized service.</p>



<p>I saw a quote on this discussion (which I can’t find now) that said “code is free, infrastructure is not.” And while projects self-hosting their code repository, issue tracker, etc may be philosophically appealing, that’s not realistic. Software-as-a-Service has lowered the barrier for starting projects, which is a good thing. But it doesn’t come without risk, which we are now seeing.</p>



<p>I don’t know what the right answer is for this. I know the answer won’t be easy. But both this specific case and the general issues they highlight are important for us to think about.</p>
			</div></div>]]>
            </description>
            <link>https://funnelfiasco.com/blog/2020/10/25/youtube-dl-github-riaa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915885</guid>
            <pubDate>Wed, 28 Oct 2020 06:29:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fraudster Startup]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24915876">thread link</a>) | @ninja-z
<br/>
October 27, 2020 | https://www.eloquicity.com/2020/10/28/the-fraudster-startup/ | <a href="https://web.archive.org/web/*/https://www.eloquicity.com/2020/10/28/the-fraudster-startup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.eloquicity.com/2020/10/28/the-fraudster-startup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915876</guid>
            <pubDate>Wed, 28 Oct 2020 06:27:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pants v2]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24915737">thread link</a>) | @gilad
<br/>
October 27, 2020 | https://blog.pantsbuild.org/introducing-pants-v2/ | <a href="https://web.archive.org/web/*/https://blog.pantsbuild.org/introducing-pants-v2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<h3 id="pants-2-0-0-the-first-stable-release-of-the-pants-v2-open-source-build-system-is-out-now-">Pants 2.0.0, the first stable release of the Pants v2 open-source build system, is out now!</h3><p>There are so many tools in the Python development ecosystem. You might use <a href="https://pip.pypa.io/en/stable/">pip</a> to resolve dependencies, <a href="https://docs.pytest.org/en/stable/">pytest</a> to run tests, <a href="https://flake8.pycqa.org/en/latest/">flake8</a> and <a href="https://www.pylint.org/">pylint</a> for lint checks, <a href="https://black.readthedocs.io/en/stable/">black</a> and <a href="https://pycqa.github.io/isort/">isort</a> for auto-formatting, <a href="http://mypy-lang.org/">mypy</a> for type checking, <a href="https://ipython.org/">IPython</a> or <a href="https://jupyter.org/">Jupyter</a> for interactive sessions, <a href="https://setuptools.readthedocs.io/en/latest/">setuptools</a>, <a href="https://pex.readthedocs.io/en/latest/">pex</a> or <a href="https://www.docker.com/">docker</a> for packaging, <a href="https://developers.google.com/protocol-buffers">protocol buffers</a> for code generation, and many more. Not to mention any custom tooling you've built for your repo. </p><p>Installing, configuring and orchestrating the invocation of these tools<strong>—</strong>all while not re-executing work unnecessarily<strong>—</strong>is a hard problem, especially as your codebase grows. The lack of a robust, scalable build system for Python has been a problem for a long time, and this has become even more acute in recent years, with Python codebases increasing in size and complexity. </p><p>Fortunately, there is now a tailor-made (pun intended) solution: <strong>Pants v2</strong>!</p><p><a href="https://www.pantsbuild.org/">Pants v2</a> is designed from the ground-up for fast, consistent builds. Some noteworthy features include:</p><ul><li>Minimal metadata and boilerplate</li><li>Fine-grained workflow</li><li>Shared result caching</li><li>Concurrent execution</li><li>A responsive, scalable UI</li><li>Unified interface for multiple tools and languages</li><li>Extensibility and customizability via a plugin API</li></ul><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/render1603750306032.gif" alt=""><figcaption>Pants running multiple linters in parallel</figcaption></figure><p>Read on to learn more about Pants v2, and what it means for your Python codebase.</p><hr><h2 id="a-little-history">A little history</h2><p>We started the original open-source Pants project back in 2011. At the time, we were frustrated by slow, flaky Scala builds. The leading strategy for scaling was to hand each developer a RAM stick and a screwdriver... Surely this was a problem we could tackle with software! Thus Pants v1 was born. </p><p>Pants v1 was quite successful, and was adopted at cutting-edge tech companies such as Twitter, Foursquare, Square and others. But we still weren't satisfied: The APIs were clunkier than we would have liked, the UI was overly chatty, caching was hard to get right, and concurrent execution had to be special-cased. We knew there were plenty of performance and stability improvements to be had, if we could only unlock them. </p><p>We learned a lot from our years of work on Pants v1, and knew that we could design something new and better, leaning on our experience with v1 while addressing the drawbacks of that system. Luckily, at the same time as we began thinking about this hypothetical next system, a new motivating problem emerged: Python builds.</p><h2 id="python-builds-today">Python builds today</h2><p>As you probably know, Python has skyrocketed in popularity in recent years. Not only is it used to build a wide variety of server applications, via frameworks such as <a href="https://www.djangoproject.com/">Django</a> and <a href="https://flask.palletsprojects.com/en/1.1.x/">Flask</a>, but it's also the language of choice for data scientists, thanks to powerful libraries and tools such as <a href="https://numpy.org/">NumPy</a>, <a href="https://www.scipy.org/">SciPy</a>, <a href="https://pandas.pydata.org/">Pandas</a> and <a href="https://jupyter.org/">Jupyter</a>. </p><p>Python hits a sweet spot of simplicity and power, but there is a big problem - there is no truly great scalable build tool for Python, and this is becoming a real pain point as Python repos grow like never before. &nbsp;</p><p>Python builds today involve manually invoking a wide variety of tools. Each tool has to be installed, configured and invoked in just the right way, often while sequencing the output of one tool into input of another. Knowing how to use each tool in a given scenario is complicated and burdensome. </p><p>Sure, you can hack around the problem for a while with some combination of shell scripts, <a href="https://www.gnu.org/software/make/manual/make.html">Makefiles</a>, <a href="https://tox.readthedocs.io/en/latest/">tox</a>, and <a href="https://python-poetry.org/">poetry</a>. But even a small code change might require you to run a huge amount of sequential build work. Re-executing the same processes with the same inputs over and over again is a frustrating waste of time and resources. &nbsp;And these solutions start to break down as your codebase grows.</p><p>Perhaps you experimented with more complex build systems, such as <a href="https://bazel.build/">Bazel</a> or <a href="https://v1.pantsbuild.org/">Pants v1</a>. &nbsp;But it's laborious to maintain all that BUILD metadata, all for a sub-par experience not optimized for Python. Not to mention the difficulty of implementing your own custom build logic. </p><p>Alternatively, maybe you've been tempted to split up your codebase into multiple interdependent repos, each with their own "smaller" builds. But that creates an even thornier problem, namely how to manage those interdependencies. Having to propagate changes across codebase boundaries can slow development down to a crawl, and leave you with the worst of both worlds - slower processes and a fragmented, unmanageable codebase.</p><p>A great build system for repos - of all sizes - that include Python code would support fine-grained invalidation and caching, so that it only executes the build work actually affected by a change. It would support concurrent local and even remote execution, to greatly speed up work by using all available CPU. It would be easy to adopt in a small repo, but would scale up as your codebase grows. It wouldn't require huge amounts of boilerplate metadata, and it would be easy to extend with custom build logic. </p><p>Well, Pants v2 is that system! </p><h2 id="introducing-pants-v2">Introducing Pants v2</h2><p><a href="https://www.pantsbuild.org/">Pants v2</a> is a completely new open-source build system, inspired by our work on Pants v1. &nbsp;We've been developing and testing it for the last couple of years, and it's finally ready for prime time!</p><p>A key factor in the design of Pants v2 was a set of lessons we learned from Pants v1 and other existing systems, such as Bazel. Among them: that ease of use and performance matter, boilerplate is annoying, concurrency and caching require hard design work, and most people will need custom logic at some point.</p><h3 id="lesson-1-ease-of-use-and-performance-both-matter">Lesson #1: Ease of use and performance both matter</h3><p>When designing software you often find yourself making tradeoffs between ease of use and performance. But in a build system, both are vital. The Pants v2 execution engine - which is the performance-critical heart of the system - is written in <a href="https://www.rust-lang.org/">Rust</a>, for raw speed. And the domain-specific build logic is written in familiar, easy to work with, type-annotated Python 3. This helps make Pants v2 easy to extend, without compromising performance. </p><p>Pants v2 also runs a daemon that memoizes fine-grained build state in memory, for even faster performance. This daemon watches for changes to your source files and precisely invalidates its state on the fly to ensure that the minimum amount of work happens the next time you build.</p><h3 id="lesson-2-writing-build-metadata-is-a-real-drag">Lesson #2: Writing build metadata is a real drag</h3><p>Some build tools are slow because they don't have enough information about the structure of your code to intelligently perform incremental work. Others have gone too far in the other direction, requiring a huge amount of metadata and boilerplate in BUILD files, especially relating to your code's dependencies. </p><p>Pants v2 offers the best of both worlds - intelligent, fine-grained incremental work, without the boilerplate. It does so by assuming sensible, magic-free defaults, inferring dependencies from the import statements in your code, and supporting plugins for custom inference logic. Stay tuned for an upcoming post on exactly how Pants achieves this!</p><h3 id="lesson-3-design-for-caching-concurrency-and-remoting">Lesson #3: Design for caching, concurrency and remoting </h3><p>Writing build logic that can be cached and executed concurrently and remotely is very hard. You have to be very careful about not producing or consuming side-effects, and it's extremely difficult to tack that on later. And unless you design your APIs with care, supporting these kinds of features often places severe restrictions on what your build logic may safely do. </p><p>In Pants v2, build logic is composed of <a href="https://en.wikipedia.org/wiki/Pure_function">pure</a> Python 3 <a href="https://docs.python.org/3/library/asyncio-task.html">async coroutines</a>. So a build rule can depend not only on its inputs, but can also await on new data at runtime - all of which is precisely tracked for invalidation and caching. This gives us the best of both worlds: logic that is properly isolated from side-effects, and is therefore amenable to caching, concurrent execution and remoting, while still allowing the use of natural control flow.</p><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/caching.gif" alt=""><figcaption>We run both tests, then add a syntax error to one test and rerun; the unmodified test uses the cache and is isolated from the syntax error.</figcaption></figure><h3 id="lesson-4-almost-everyone-needs-to-customize-their-builds">Lesson #4: Almost everyone needs to customize their builds</h3><p>Most teams have custom build steps, so extensibility is a key feature in any build system. Pants v2 is built around a <a href="https://www.pantsbuild.org/docs/plugins-overview">plugin architecture</a>. You can write your own rules using the same API as the built-in functionality. So your custom build logic will enjoy the same fine-grained invalidation, caching, concurrency and remote execution abilities as the core Pants code.</p><h2 id="pants-2-0-0-is-out-now-">Pants 2.0.0 is out now!</h2><p>All this leads me to the happy announcement that <a href="https://pypi.org/project/pantsbuild.pants/2.0.0/">Pants 2.0.0</a>, the first stable release of Pants v2, is out now! 2.0.0 is the culmination of years of design and development work, and many months of beta testing at several organizations. So we're really happy, proud (and relieved…) to finally have it ready for general use. </p><p>You can see what Python tools Pants currently supports <a href="https://www.pantsbuild.org/docs/python">here</a>. There are also commands for querying and understanding your dependency graph, and a robust help system. &nbsp;We're adding support for additional tools and features all the time, and it's straightforward to implement your own. Beta users have already written their own logic for Cython and docker, for example. </p><p>Now is a great time to adopt Pants 2.0.0! The team that developed Pants v2 is <a href="https://www.pantsbuild.org/docs/community">ready to help you</a> onboard, answer any questions, and even pair with you to help you write any custom build logic. We're also eager to get feedback, bug reports and suggestions for what features we should focus on in the next weeks and months of development.</p><p>Pants v2 is developed by a helpful open source community, is funded by a 501(c)6 non-profit, and has excellent support available. If you have a growing Python codebase, and want to take Pants 2.0.0 for a spin, <a href="https://www.pantsbuild.org/docs/community">let us know</a>. We'd love to fit you with some new Pants today!</p>
			</section></div>]]>
            </description>
            <link>https://blog.pantsbuild.org/introducing-pants-v2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915737</guid>
            <pubDate>Wed, 28 Oct 2020 06:03:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Paradigms of Personal Computing]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24915683">thread link</a>) | @riverlong
<br/>
October 27, 2020 | https://jayriverlong.github.io/2020/10/27/machines.html | <a href="https://web.archive.org/web/*/https://jayriverlong.github.io/2020/10/27/machines.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"> <article role="article">  <p>A frequently recurring staple of Hacker News is the <em>personal computing rant</em>: modern computers are black boxes, far too locked down.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> We long for our desktop computers, the early-2000s computing paradigm, and we want to take back control of our data.</p> <p>I sympathize greatly with this view. For the past five years, I have exclusively run Arch Linux. I love the early-2000s style of personal computing: text-heavy interfaces, words rather than icons, uniform keyboard shortcuts everywhere. I do nearly all my computing in emacs. It is feature rich, and no product manager is ever going to change the experience, interface, or shortcuts. My workspace allows me to be <em>fast</em>. Contrary to much modern software, emacs responds instantaneously to my keystrokes. Every action has an immediate effect, clear on the page, with no background process ambiguity. This is enormously satisfying. I would characterize this computing environment as a spiritual descendant of the typewriter: on its own, it is a dumb machine, but when you command it, it becomes a powerful extension of you. The user experience is given by speed, smoothness, reliability, and nothing else.</p> <p>On the other hand, you’ve got iPhones and iPads. These are not machines that you command – on the contrary, you might argue that all their notifications command you. With touch interfaces, facial recognition, and voice control, these are machines that are meant to merge with you. Instead of becoming an <em>extension</em> of you, it becomes <em>part</em> of you. Instead of you commanding it, it is meant to anticipate your commands. Where is the data? How does it work? Who knows. They’re total black boxes, effectively indistinguishable from magic, whereas your Linux Desktop is a DIYable simple machine.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p> <p>Many contemporary writers think of personal computing as one paradigm that is gradually evolving. I disagree: I think there are two, deeply different paradigms of personal computing, reflecting deeply different desires.</p> <ul> <li>Machine as extension of the self (your Windows XP Desktop).</li> <li>Machine as part of the self (your iPhone).</li> </ul> <p>Plenty of devices exist in the space in-between. Android phones try to give you some control back over your device, by which they necessarily preclude themselves from truly being <em>part</em> of you. Modern versions of OS X, with the touchbar, Siri, and integrations into all your other Apple devices, are starting to make the leap from extending the self to being part of the self.</p> <p>As a genre, the personal computing rant comes out of the correct view that these are all forms of personal computing, but it fails to recognize that within this broad umbrella, we’ve seen paradigms arise that differ in both intent and the human desire they’re meant to meet. It’s not that one class of devices is replacing the other. They are fundamentally different, and one paradigm succeeds where the other falls short of meeting the consumers’ needs. The terminal never met the needs of those who want Amazon Alexa, and vice-versa.</p> <p>I live in the in-between. I happily imagine a world where my Apple Watch monitors my glucose and blood oxygen, my Eight Sleep quantifies my rest, I mark up documents on giant touchscreens, but I sit on a clacky IBM keyboard to write code and blog posts in a terminal that hasn’t changed in twenty years. While your iPhone might meld with your mind by quantifying and anticipating your every need, my terminal melds with my mind by being fast, constant, and <em>always</em> correct. Each has its place, and I would never trade one for the other.</p>  <hr>  <br> </article> </div></div>]]>
            </description>
            <link>https://jayriverlong.github.io/2020/10/27/machines.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915683</guid>
            <pubDate>Wed, 28 Oct 2020 05:53:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Firearms by the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24915677">thread link</a>) | @lettergram
<br/>
October 27, 2020 | https://austingwalters.com/firearms-by-the-numbers/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/firearms-by-the-numbers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3517">

<div>
<p>Firearms (guns) are one of the hot button issues in the United States and globally. I’m sure it is understandable why — pull the trigger and something dies. Killing is the primary purpose of a firearm. Naturally, this leads many to be fearful of firearms, but should people be fearful?</p>
<p>When I started writing this, I wanted to answer:</p>
<blockquote><p>Are firearms inherently unsafe?</p>
<p>Should firearms be banned, as many believe?</p></blockquote>
<p>It’s quite ambitious. One may believe you can just find an answer on a website / paper somewhere or is obvious. Unfortunately, the reality is far more complicated and has turned this into my longest article to date.</p>
<p>It’s been said,</p>
<blockquote><p>Guns don’t kill people, people kill people. <em>– unknown</em></p></blockquote>
<p>Many agree and many others strongly disagree. That divisiveness has made firearms a political issue, leading to a plethora of bias studies, inaccurate analysis, and more. Thus, to answer these questions I had to go through the data myself; I pulled <a href="#Data_Tooling">data from the CDC, FBI, RAND, Census and others</a> and completed my own analysis.</p>
<h4>Introduction</h4>
<p>Due to the nature of this analysis, it is important to highlight some items upfront.</p>
<p>1. The United States is often the focus throughout the analysis. This is because the United States has an abundance of firearms, a relatively uniform society and the most available &amp; accurate records.</p>
<p>2. This analysis focuses on general trends. Specific situations vary wildly, even in the same region: country, state, county, city, and neighborhood situations vary. As such, I caution making detailed / specific inference, beyond what the data explicitly shows (in the general case).</p>
<p>3. Some important data is lacking, such as socioeconomic status associated with crimes. This makes it very difficult to isolate confounding factors and leads to confusion / lack of definitive answer(s).</p>
<p>The goal of this analysis was to analyze available (and unbiased) data as in-depth as enabled, with no particular outcome in mind. <em>If new data comes in that materially changes what can be inferred, I’ll attempt to update the analysis.</em> With that in mind, I want to highlight that I dive into demographic information and I found some surprises. Politics seems to stifle this topic and in fact the truth. Instead I went to the data, I hope you can find it as interesting as I do.</p>
<blockquote><p>The truth is not for all men, but only for those who seek it.<br>
– Ayn Rand</p></blockquote>
<p>If anything in this analysis was missed,<strong> please feel free to reach out or leave comments.</strong></p>


<p>Globally, firearms are highly controlled, particularly in the Europe and Asia. In contrast, the United States has more firearms held by it’s citizens than the rest of the world combined.<a href="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png" alt="" width="1107" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-768x477.png 768w" sizes="(max-width: 1107px) 100vw, 1107px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-768x477.png 768w"></a>The real question — do the number of firearms really matter? From the graph above, it’s clear China, Russia and Iran have a high number of military firearms when compared civilian held firearms (and I suspect most civilian held firearms are former military, in countries such as China, Russia ,Iran, India, etc). In contrast, the “<a href="https://en.wikipedia.org/wiki/Free_World" target="_blank" rel="noopener noreferrer">free world</a>” has an order of magnitude more civilian firearms, when compared to military firearms.</p>
<p>Clearly, what matters to “<a href="https://en.wikipedia.org/wiki/Second_World" target="_blank" rel="noopener noreferrer">second world</a>” is having a large military arsenal, when compared to civilian held firearms.</p>
<p>It can be argued an unarmed society allows the military to impose their will, allowing countries to maintain the status quo and avoiding violent revolutions overthrowing the government.</p>
<h2><span id="Homicides_Firearms_Globally"></span>Homicides &amp; Firearms Globally<span></span></h2>
<p>In the “free world,” the main concern surrounding firearms are homicides &amp; suicides, with homicides being the most concerning. Below is a comparison of homicides by firearm deaths per 100,000 people across the globe.</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png" alt="" width="1228" height="677" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png 1228w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-300x165.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-1024x565.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-768x423.png 768w" sizes="(max-width: 1228px) 100vw, 1228px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png 1228w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-300x165.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-1024x565.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-768x423.png 768w"></a>When we compare the world, a few things become clear:</p>
<ol>
<li>The America’s, Caribbean and Africa have a much higher firearm homicide rate</li>
<li>The United States has the highest firearm homicide rate of a “<a href="https://en.wikipedia.org/wiki/First_World" target="_blank" rel="noopener noreferrer">first world</a>” country</li>
<li>Europe has the lowest firearm homicide rate globally</li>
</ol>
<p>What’s not clear, is whether or not firearms are really leading the increased firearm homicide rate.</p>
<p>Are homicides just naturally higher in these regions?</p>
<h2><span id="Firearm_Death_Rate_per_Firearm"></span>Firearm Death Rate per Firearm<span></span></h2>
<p>Below is an argument from the Amnesty International’s website:</p>
<blockquote><p>governments [with] poor regulation of the possession and use of <strong>guns lead to violence</strong> and that they must tackle this now through strict controls on guns and effective interventions in communities suffering high levels of gun violence.</p>
<p>– <a href="https://www.amnesty.org/en/what-we-do/arms-control/gun-violence/" target="_blank" rel="noopener noreferrer">Amnesty International</a></p></blockquote>
<p>The key statement is:</p>
<blockquote><p>Guns lead to violence</p></blockquote>
<p>The statement above implies a couple of things:</p>
<ol>
<li>Gun volume and violence are correlated</li>
<li>As the number of guns increase, violence increases</li>
</ol>
<p>There are a few ways to invalidate / validate this statement. The clearest method is to simply compare firearm deaths per firearm. If firearms lead to more violence, we should see the ratio of firearm deaths to firearms (firearm deaths / firearms) staying constant (or growing at a constant rate). This ratio should stay or grow at a constant rate because as the firearm count increases, the firearm homicides should increase (keeping the ratio constant). We could also assume a direct correlation if “guns lead to violence” as it would probably occur at some constant rate.</p>
<p>Below you can see the comparison between firearm deaths and firearms:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png" alt="" width="1313" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png 1313w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-300x157.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-1024x536.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-768x402.png 768w" sizes="(max-width: 1313px) 100vw, 1313px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png 1313w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-300x157.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-1024x536.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-768x402.png 768w"></a>As seen in the chart, the Caribbean, South America, Africa have a high number of firearm deaths per firearm, Columbia having one death per five hundred firearms. In contrast, “First World” (Europe and the United States) has a much lower number of fatalities per firearm, the United States having only one death per ten thousand firearms.</p>
<h3><span id="Firearms_vs_Homicide_Rate"></span>Firearms vs Homicide Rate<span></span></h3>
<p>For further evidence firearms aren’t correlated with violence, it’s possible to directly compare the number of firearms vs homicides:<a href="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png" alt="" width="1107" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-768x477.png 768w" sizes="(max-width: 1107px) 100vw, 1107px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-768x477.png 768w"></a>Across the bottom of the chart you can see all the countries with high homicide rates. The United States stands out clearly, if firearms were correlated with homicides we’d expect the U.S. to have many more homicides than it currently does. It does not appear more firearms are correlated with more homicides, in fact the trend line shows the opposite to be true (more firearms are correlated to less homicides).</p>
<p>For a final validation, we can compare firearms against homicides and firearm homicides against total homicides. Both should have a similar growth rate, if there was a correlation.</p>
<figure id="attachment_3617" aria-describedby="caption-attachment-3617"><a href="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png" alt="" width="1107" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-768x477.png 768w" sizes="(max-width: 1107px) 100vw, 1107px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-768x477.png 768w"></a><figcaption id="caption-attachment-3617">* United States represented by a Star</figcaption></figure>
<p>It’s important to note the graph is a logarithmic comparison for homicides and homicides by firearm (firearms per 100k Inhabitants are not logarithmic). The trend line comparison of Total Homicides and Homicides by Firearm is linear, but because the comparison is logarithmic, it appears exponential on the chart.</p>
<p>It is clear as homicides increase, homicides by firearm increase (blue data points). In contrast, when there are more firearms, homicides by firearm remain flat (purple data points), implying more firearms do not cause increase the number of homicides involving a firearm.</p>
<p>Further, you can see the blue star representing the United States homicide rate to homicide firearm deaths is right where it is expected. However, the purple star, representing the United States homicide rate to firearms per 100k inhabitants, is way outside the norm.</p>
<p>To summarize,</p>
<blockquote><p>Globally, as the firearm homicide rate increases, the total homicide rate increases; as the prevalence of firearms increase, the homicide rate <span>does not increase</span>.</p></blockquote>

<p>The United States is clearly the largest holder of firearms in the world, most states have more firearms than entire countries. Fun fact:</p>
<blockquote><p>Texans and the Chinese military have the same number of firearms.</p></blockquote>
<p>Clearly, there’s a culture of gun ownership in the United States. When the United States was formed it had just fought a war of independence and regularly combated Native Americans, settling North America by force. Even today, the <a href="https://en.wikipedia.org/wiki/United_States_National_Guard" target="_blank" rel="noopener noreferrer">United States National Guard</a> is one of the largest militias in the world.</p>
<blockquote><p>A well regulated Militia, being necessary to the security of a free State, the right of the people to keep and bear Arms, shall not be infringed.<br>
–<a href="https://constitution.congress.gov/constitution/amendment-2/"> Constitution of the United States</a></p></blockquote>
<p>Without diving into politics, the constitution &amp; culture has enabled the United States to be relatively unique. Firearms are regulated, but just barely. Generally, citizens can do everything from carrying a firearms in public to purchasing assault rifles, flamethrowers, <a href="https://en.wikipedia.org/wiki/Minigun" target="_blank" rel="noopener noreferrer">miniguns</a>, rocket launcher(s), etc. Often the only requirement is obtaining permit to own weapons, after that you can regularly purchase as many firearms as you’d like.</p>
<p>As seen in the previous section, the United States does have a higher (on average) number of firearm deaths. However, this doesn’t necessarily tell the whole story. In the prior section, we focused on the homicide rate. In the following sections, the focus will expand as uniform data collection, similar social norms and a widespread framework for law makes comparisons much easier.</p>
<p>Some topics we will explore here are:</p>
<ul>
<li>Suicide vs homicide vs accidental rates</li>
<li>The type of weapons used in homicides</li>
<li>How demographics impact firearm fatalities</li>
<li>How firearm fatalities compare to other fatalities</li>
</ul>
<h2><span id="Suicides_Homicides_in_the_United_States"></span>Suicides &amp; Homicides in the United States<span></span></h2>
<p>First, it is also important to highlight just how small the number of firearm related homicides really are, when compared to all deaths. On average, the total (suicide, homicide &amp; accidental) number of firearm related fatalities account for about 1.33% of all deaths in the United States (firearm related homicides account for ~0.44% of all deaths) and it varies wildly between states.</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png" alt="" width="736" height="855" srcset="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png 736w, https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal-258x300.png 258w" sizes="(max-width: 736px) 100vw, 736px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png 736w, https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal-258x300.png 258w"></a></p>
<p>Perhaps the most important item to discuss is that this is the “<em>firearm fatality rate</em>“, often conflated with the “<em>firearm homicide rate</em>” by political pundits. While all fatalities are unfortunate, most American’s would argue there is a different between <em>suicides</em> and <em>homicides</em>. Some states, such as Washington, support medically assisted suicides (for the terminally ill).</p>
<p>Below is a comparison between accidents, suicides and homicides by firearms in the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://austingwalters.com/firearms-by-the-numbers/">https://austingwalters.com/firearms-by-the-numbers/</a></em></p>]]>
            </description>
            <link>https://austingwalters.com/firearms-by-the-numbers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915677</guid>
            <pubDate>Wed, 28 Oct 2020 05:52:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Bayesian Perspective on Q-Learning]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24915662">thread link</a>) | @jonbaer
<br/>
October 27, 2020 | https://brandinho.github.io/bayesian-perspective-q-learning/ | <a href="https://web.archive.org/web/*/https://brandinho.github.io/bayesian-perspective-q-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <d-contents>
    <nav>
      <h3>Contents</h3>
      
      
      
      
      
      
    </nav>
  </d-contents>

  <p>
    Recent work by Dabney et al. suggests that the brain represents reward predictions as probability distributions
    <d-footnote>
      Experiments were conducted on mice using single-unit recordings from the ventral tegmental area.
    </d-footnote><d-cite key="dabney2020distribtionmice"></d-cite>.
    This contrasts against the widely adopted approach in reinforcement learning (RL) of modelling single scalar
    quantities (expected values).
    In fact, by using distributions we are able to quantify uncertainty in the decision-making process.
    Uncertainty is especially important in domains where making a mistake can result in the inability to recover
    <d-footnote>
      Examples of such domains include autonomous vehicles, healthcare, and the financial markets.
    </d-footnote>. Research in risk-aware reinforcement learning has emerged to address such problems
    <d-cite key="morimura2010risksensitive,chow2018riskconstrainedrl"></d-cite>.
    However, another important application of uncertainty, which we focus on in this article, is efficient exploration
    of the state-action space.
  </p>

  <h2>Introduction</h2>

  <p>
    The purpose of this article is to clearly explain Q-Learning from the perspective of a Bayesian.
    As such, we use a small grid world and a simple extension of tabular Q-Learning to illustrate the fundamentals.
    Specifically, we show how to extend the deterministic Q-Learning algorithm to model
    the variance of Q-values with Bayes' rule. We focus on a sub-class of problems where it is reasonable to assume that Q-values
    are normally distributed
    and derive insights when this assumption holds true. Lastly, we demonstrate that applying Bayes' rule to update
    Q-values comes with a challenge: it is vulnerable to early exploitation of suboptimal policies.
  </p>

  <p>
    This article is largely based on the seminal work from Dearden et al. <d-cite key="dearden1998bayesianqlearning"></d-cite>.
    Specifically, we expand on the assumption that Q-values are normally distributed and evaluate various Bayesian exploration
    policies. One key distinction is that we model $$\mu$$ and $$\sigma^2$$, while the
    authors of the original Bayesian Q-Learning paper model a distribution over these parameters. This allows them to quantify
    uncertainty in their parameters as well as the expected return - we only focus on the latter.
  </p>

  <div><h4>Epistemic vs Aleatoric Uncertainty</h4></div>
  <div><p>
    Since Dearden et al. model a distribution over the parameters, they can sample from this distribution and the resulting
    dispersion in Q-values is known as <b>epistemic</b> uncertainty. Essentially, this uncertainty is representative of the
    "knowledge gap" that results from limited data (i.e. limited observations). If we close this gap, then we are left with
    irreducible uncertainty (i.e. inherent randomness in the environment), which is known as <b>aleatoric</b> uncertainty
    </p><d-cite key="kiureghian2007aleatoric"></d-cite><p>.

    </p><p>
    One can argue that the line between epistemic and aleatoric uncertainty is rather blurry. The information that
    you feed into your model will determine how much uncertainty can be reduced. The more information you incorporate about
    the underlying mechanics of how the environment operates (i.e. more features), the less aleatoric uncertainty there will be.

    </p><p>

    It is important to note that inductive bias also plays an important role in determining what is categorized as
    epistemic vs aleatoric uncertainty for your model.
    </p><p>

    <b>Important Note about Our Simplified Approach:</b></p><p>

    Since we only use $$\sigma^2$$ to represent uncertainty, our approach does not distinguish between epistemic and aleatoric uncertainty.

    Given enough interactions, the agent will close the knowledge gap and $$\sigma^2$$ will only represent aleatoric uncertainty. However, the agent still
    uses this uncertainty to explore.

    This is problematic because the whole point of exploration is to gain
    knowledge, which indicates that we should only explore using epistemic uncertainty.
    </p></div>


  

  <p>
    Since we are modelling $$\mu$$ and $$\sigma^2$$, we begin by evaluating the conditions under which it is appropriate
    to assume Q-values are normally distributed.
  </p>

  <a href="#section-1" id="section-1"></a>
  <h2>When Are Q-Values Normally Distributed?</h2>

  <p>
    The readers who are familiar with Q-Learning can skip over the collapsible box below.
  </p>

  <div><h4>Temporal Difference Learning</h4></div>
  <div>
    <p>
      Temporal Difference (TD) learning is the dominant paradigm used to learn value functions in reinforcement learning
      <d-cite key="sutton1988tempdiff"></d-cite>.
      Below we will quickly summarize a TD learning algorithm for Q-values,
      which is called Q-Learning. First, we will write Q-values as follows <d-cite key="Sutton2017ReinforcementIntroduction"></d-cite>:
    </p>

    <d-math block="">
      \overbrace{Q_\pi(s,a)}^\text{current Q-value} =
      \overbrace{R_s^a}^\text{expected reward for (s,a)} +
      \overbrace{\gamma Q_\pi(s^{\prime},a^{\prime})}^\text{discounted Q-value at next timestep}
    </d-math>

    <p>
      We will precisely define Q-value as the expected value of the total return from taking action $$a$$ in state $$s$$ and following
      policy $$\pi$$ thereafter. The part about $$\pi$$ is important because the agent's view on how good an action is
      depends on the actions it will take in subsequent states. We will discuss this further when analyzing our agent in
      the game environment.
    </p>

    <p>
      For the Q-Learning algorithm, we sample a reward $$r$$ from the environment, and estimate the Q-value for the current
      state-action pair $$q(s,a)$$ and the next state-action pair $$q(s^{\prime},a^{\prime})$$
      <d-footnote>
        For Q-Learning, the next action $$a^{\prime}$$ is the action with the largest Q-value in that state:
        $$\max_{a^{\prime}} q(s^{\prime}, a^{\prime})$$.
      </d-footnote>. We can represent the sample as:
    </p>

    <d-math block="">
      q(s,a) = r + \gamma q{(s^\prime,a^\prime)}
    </d-math>

    <p>
      The important thing to realize is that the left side of the equation is an estimate (current Q-value), and the right side
      of the equation is a combination of information gathered from the environment (the sampled reward) and another estimate
      (next Q-value). Since the right side of the equation contains more information about the true Q-value than the left side,
      we want to move the value of the left side closer to that of the right side. We accomplish this by minimizing the squared
      Temporal Difference error ($$\delta^2_{TD}$$), where $$\delta_{TD}$$ is defined as:
    </p>

    <d-math block="">
      \delta_{TD} = r + \gamma q(s^\prime,a^\prime) - q(s,a)
    </d-math>

    <p>
      The way we do this in a tabular environment, where $$\alpha$$ is the learning rate, is with the following update rule:
    </p>

    <d-math block="">
      q(s,a) \leftarrow \alpha(r_{t+1} + \gamma q(s^\prime,a^\prime)) + (1 - \alpha) q(s,a)
    </d-math>

    <p>
      Updating in this manner is called bootstrapping because we are using one Q-value to update another Q-value.
    </p>
  </div>

  

  <p>
    We will use the Central Limit Theorem (CLT) as the foundation to understand when Q-values are normally
    distributed. Since Q-values are sample sums, then they should look more and more normally distributed as the sample size
    increases <d-cite key="lecam1986clt"></d-cite>.
    However, the first nuance that we will point out is that rewards must be sampled from distributions with finite variance.
    Thus, if rewards are sampled distributions such as Cauchy or Lévy, then we cannot assume Q-values are normally distributed.
  </p>

  

  <p>
    Otherwise, Q-values are approximately normally distributed when the number of <b><i>effective timesteps</i></b>
    $$\widetilde{N}$$ is large
    <d-footnote>
      We can think of effective timesteps as the number of <b>full</b> samples.
    </d-footnote>.
    This metric is comprised of three factors:
  </p>

  <ul>
    <li>
      $$N$$ - <b>Number of timesteps</b>: As $$N$$ increases, so does $$\widetilde{N}$$.
    </li>

    <li>
      $$\xi$$ - <b>Sparsity</b>: We define sparsity as the number of timesteps,
      on average, a reward of zero is deterministically received in between receiving non-zero rewards
      <d-footnote>
        In the Google Colab notebook, we ran simulations to show that $$\xi$$ reduces the effective number of timesteps by $$\frac{1}{\xi + 1}$$:
        <a href="https://colab.research.google.com/github/brandinho/bayesian-perspective-q-learning/blob/main/Sparsity.ipynb">
          Experiment in a <span>Notebook</span>
        </a>
      </d-footnote>.
      When sparsity is present, we lose samples (since they are always zero).
      <!-- As sparsity increases, we essentially lose samples since they are always zero. -->
      Therefore, as $$\xi$$ increases, $$\widetilde{N}$$ decreases.
    </li>

    <li>
      $$\gamma$$ - <b>Discount Factor</b>:
      As $$\gamma$$ gets smaller, the agent places more weight on immediate rewards relative to distant ones, which means
      that we cannot treat distant rewards as full samples. Therefore, as $$\gamma$$ increases, so does $$\widetilde{N}$$.
    </li>

    <div><h4>Discount Factor and Mixture Distributions</h4></div>
    <div>
      <p>
        We will define the total return as the sum of discounted future
        rewards, where the discount factor $$\gamma$$ can take on any value between $$0$$ (myopic) and $$1$$ (far-sighted).
        It helps to think of the resulting distribution $$G_t$$ as a weighted mixture distribution.
      </p>

      <d-math block="">
        G_t = r_{t+1} + \gamma r_{t+2} + \gamma^2 r_{t+3} + ... + \gamma^{N-1} r_{t+N}
      </d-math>

      <p>
        When we set $$\gamma \lt 1$$, the mixture weights for the underlying distributions change from equal weight
        to time-weighted, where immediate timesteps have a higher weight. When $$\gamma = 0$$, then this is
        equivalent to sampling from only one timestep and CLT would not hold. Use the slider
        to see the effect $$\gamma$$ has on the mixture weights, and ultimately the mixture distribution.
      </p>

      <div>
        <div>
          <p>
              $$$$<br>
              $$$$
          </p>
          

          <p>
              $$$$<br>
              $$$$
          </p>
          

          <p>
              $$$$<br>
              $$$$
          </p>

          
          
        </div>

        
      </div>

      <p><label for="barGammaMixture">$$\gamma$$ = <span></span></label></p>
    </div>
  </ul>

  We combine the factors above to formally define the number of effective timesteps:

  <d-math block="">
    \widetilde{N} = \frac{1}{\xi + 1}\sum_{i=0}^{N-1}\gamma^{i}
  </d-math>

  <p>
    Below we visually demonstrate how each factor affects the normality of Q-values
    <d-footnote>
      We scale the Q-values by $$\widetilde{N}$$ because otherwise the distribution of Q-values
      moves farther and farther to the right as the number of effective timesteps increases, which distorts the visual.
    </d-footnote>:
  </p>

  <p>
    <label for="skew">Skew-Normal</label>
    
    <label for="bernoulli">Bernoulli</label>
  </p>

  

  

  <figcaption>
    Select whether the underlying distribution follows a skew-normal or a Bernoulli distribution.
    In the Google Colab notebook we also include three statistical tests of normality for the Q-value distribution.
    </figcaption>
 …</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://brandinho.github.io/bayesian-perspective-q-learning/">https://brandinho.github.io/bayesian-perspective-q-learning/</a></em></p>]]>
            </description>
            <link>https://brandinho.github.io/bayesian-perspective-q-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915662</guid>
            <pubDate>Wed, 28 Oct 2020 05:49:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Theory of Software Architecture]]>
            </title>
            <description>
<![CDATA[
Score 490 | Comments 238 (<a href="https://news.ycombinator.com/item?id=24915497">thread link</a>) | @nreece
<br/>
October 27, 2020 | https://danuker.go.ro/the-grand-unified-theory-of-software-architecture.html | <a href="https://web.archive.org/web/*/https://danuker.go.ro/the-grand-unified-theory-of-software-architecture.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
    <section id="content">
        <article>
            
            <div>
                
                <p>Take <strong>Uncle Bob's</strong> Clean Architecture and map its correspondences with <strong>Gary Bernhardt's</strong> thin imperative shell around a functional core, and you get an understanding of how to cheaply maintain and scale software!</p>
<p>This is what <a href="https://rhodesmill.org/brandon/">Mr. Brandon Rhodes</a> did. It's not every day that I find such clear insight.</p>
<p>I am honored to have found his <a href="https://rhodesmill.org/brandon/talks/#clean-architecture-python">presentation</a> and <a href="https://rhodesmill.org/brandon/slides/2014-07-pyohio/clean-architecture/">slides</a> explaining  <a href="https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html">Uncle Bob's Clean Architecture</a> and Gary Bernhardt's PyCon talks of <a href="https://archive.org/details/pyvideo_422___units-need-testing-too">2011</a>, <a href="https://pycon-2012-notes.readthedocs.io/en/latest/fast_tests_slow_tests.html">2012</a>, and <a href="https://www.destroyallsoftware.com/talks/boundaries">2013</a>.</p>
<p>Mr. Rhodes offers such a distilled view, that he can show you these crucial concepts in 3 slides of code. I will go ahead and summarize what he said and add a tiny bit of my insight.</p>
<p>Copyright of all Python code on this page belongs to <a href="https://rhodesmill.org/brandon/">Mr. Brandon Rhodes</a>, and copyright of the diagram belongs to <a href="https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html">Robert C. Martin (Uncle Bob)</a>. I use these under (hopefully) fair use (nonprofit and educational).</p>


<p>First of all, we need to be on the same page, in order to be able to understand each other. Here are the words I'll use:</p>
<ul>
<li>Function: I use "function" or "pure function" to refer to a Python "function" that only uses its parameters for input, returns a result as output, and does not cause any other side-effects (such as I/O). <ul>
<li>A pure function returns the same output given the same inputs.</li>
<li>A pure function may be called any number of times without changing the system state - it should have no influence on DB, UI, other functions or classes.</li>
<li>This is very similar to a mathematical function: takes you from <em>x</em> to <em>y</em> and nothing else happens.</li>
<li>Sadly we can't have only pure functions; software has a <strong>purpose</strong> of causing side-effects.</li>
</ul>
</li>
<li>Procedure, Routine, or Subroutine: A piece of code that executes, that may or may not have side effects. This is a "function" in Python, but might not be a "pure function".</li>
<li>Tests: automated unit tests. By "unit" I mean not necessarily just a class, but a behavior. If you want, see more details in <a href="https://danuker.go.ro/tdd-revisited-pytest-updated-2020-09-03.html#update-2020-09-03-keep-coupling-low">the coupling chapter of my previous post</a>.</li>
</ul>

<div><pre><span></span><code><span>import</span> <span>requests</span>                      <span># Listing 1</span>
<span>from</span> <span>urllib</span> <span>import</span> <span>urlencode</span>

<span>def</span> <span>find_definition</span><span>(</span><span>word</span><span>):</span>
    <span>q</span> <span>=</span> <span>'define '</span> <span>+</span> <span>word</span>
    <span>url</span> <span>=</span> <span>'http://api.duckduckgo.com/?'</span>
    <span>url</span> <span>+=</span> <span>urlencode</span><span>({</span><span>'q'</span><span>:</span> <span>q</span><span>,</span> <span>'format'</span><span>:</span> <span>'json'</span><span>})</span>
    <span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span>     <span># I/O</span>
    <span>data</span> <span>=</span> <span>response</span><span>.</span><span>json</span><span>()</span>           <span># I/O</span>
    <span>definition</span> <span>=</span> <span>data</span><span>[</span><span>u</span><span>'Definition'</span><span>]</span>
    <span>if</span> <span>definition</span> <span>==</span> <span>u</span><span>''</span><span>:</span>
        <span>raise</span> <span>ValueError</span><span>(</span><span>'that is not a word'</span><span>)</span>
    <span>return</span> <span>definition</span>
</code></pre></div>
<p>Here, we have a piece of code that prepares a URL, then gets some data over the network (I/O), then validates the result (a word definition) and returns it.</p>
<p>This is a bit much: a procedure should ideally do one thing only. While this small-ish procedure is quite readable still, it is a metaphor for a more developed system - where it could be arbitrarily long.</p>
<p>The current knee-jerk reaction is to <em>hide</em> the I/O operations somewhere far away. Here is the same code after extracting the I/O lines:</p>

<div><pre><span></span><code><span>def</span> <span>find_definition</span><span>(</span><span>word</span><span>):</span>           <span># Listing 2</span>
    <span>q</span> <span>=</span> <span>'define '</span> <span>+</span> <span>word</span>
    <span>url</span> <span>=</span> <span>'http://api.duckduckgo.com/?'</span>
    <span>url</span> <span>+=</span> <span>urlencode</span><span>({</span><span>'q'</span><span>:</span> <span>q</span><span>,</span> <span>'format'</span><span>:</span> <span>'json'</span><span>})</span>
    <span>data</span> <span>=</span> <span>call_json_api</span><span>(</span><span>url</span><span>)</span>
    <span>definition</span> <span>=</span> <span>data</span><span>[</span><span>u</span><span>'Definition'</span><span>]</span>
    <span>if</span> <span>definition</span> <span>==</span> <span>u</span><span>''</span><span>:</span>
        <span>raise</span> <span>ValueError</span><span>(</span><span>'that is not a word'</span><span>)</span>
    <span>return</span> <span>definition</span>

<span>def</span> <span>call_json_api</span><span>(</span><span>url</span><span>):</span>
    <span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span>     <span># I/O</span>
    <span>data</span> <span>=</span> <span>response</span><span>.</span><span>json</span><span>()</span>           <span># I/O</span>
    <span>return</span> <span>data</span>
</code></pre></div>
<p>In Listing #2, the I/O is extracted from the top-level procedure. </p>
<p>The problem is, the code is still <strong>coupled</strong> - <code>call_json_api</code> is called whenever you want to test anything - even the building of the URL or the parsing of the result.</p>
<p><strong>Coupling kills software.</strong></p>
<p>A good rule of thumb to spot coupling is this: Can you test a piece of code without having to mock or dependency inject like Frankenstein?</p>
<p>Here, we can't test <code>find_definition</code> without somehow replacing <code>call_json_api</code> from inside it, in order to avoid making HTTP requests.</p>
<p>Let's find out what a better solution looks like.</p>

<div><pre><span></span><code><span>def</span> <span>find_definition</span><span>(</span><span>word</span><span>):</span>           <span># Listing 3</span>
    <span>url</span> <span>=</span> <span>build_url</span><span>(</span><span>word</span><span>)</span>
    <span>data</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span><span>.</span><span>json</span><span>()</span>  <span># I/O</span>
    <span>return</span> <span>pluck_definition</span><span>(</span><span>data</span><span>)</span>

<span>def</span> <span>build_url</span><span>(</span><span>word</span><span>):</span>
    <span>q</span> <span>=</span> <span>'define '</span> <span>+</span> <span>word</span>
    <span>url</span> <span>=</span> <span>'http://api.duckduckgo.com/?'</span>
    <span>url</span> <span>+=</span> <span>urlencode</span><span>({</span><span>'q'</span><span>:</span> <span>q</span><span>,</span> <span>'format'</span><span>:</span> <span>'json'</span><span>})</span>
    <span>return</span> <span>url</span>

<span>def</span> <span>pluck_definition</span><span>(</span><span>data</span><span>):</span>
    <span>definition</span> <span>=</span> <span>data</span><span>[</span><span>u</span><span>'Definition'</span><span>]</span>
    <span>if</span> <span>definition</span> <span>==</span> <span>u</span><span>''</span><span>:</span>
        <span>raise</span> <span>ValueError</span><span>(</span><span>'that is not a word'</span><span>)</span>
    <span>return</span> <span>definition</span>
</code></pre></div>
<p>Here, the procedure at the top (aka. the <span><strong>imperative shell</strong></span> of the program) is handling the I/O, and everything else is moved to <span><strong>pure functions</strong></span> (<code>build_url</code>, <code>pluck_definition</code>). The <span><strong>pure functions</strong></span> are easily testable by just calling them on made-up data structures; no Frankenstein needed.</p>
<p>This separation into an <span><strong>imperative shell</strong></span> and <span><strong>functional core</strong></span> is an encouraged idea by Functional Programming.</p>
<p>Ideally, though, in a real system, you wouldn't test elements as small as these routines, but integrate more of the system. See <a href="https://danuker.go.ro/tdd-revisited-pytest-updated-2020-09-03.html#update-2020-09-03-keep-coupling-low">the coupling chapter of my previous post</a> to understand the trade-offs.</p>

<p>Look at <a href="https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html">Uncle Bob's Clean Architecture chart</a> (Copyright Robert C. Martin aka. Uncle Bob) :
<img alt="The Clean Architecture" src="https://danuker.go.ro/images/CleanArchitecture.jpg"></p>
<p>Uncle Bob's <span><strong>Use Cases</strong></span> and <span><strong>Entities</strong></span> (red and yellow circles of the chart) map to the <span><strong>pure functions</strong></span> we saw earlier - <code>build_url</code> and <code>pluck_definition</code> from Listing 3, and the <span><strong>plain objects</strong></span> they receive as parameters and send as outputs. <em>(updated 2020-10-28)</em></p>
<p>Uncle Bob's <span><strong>Interface Adapters</strong></span> (green circle) map to the top-level <span><strong>imperative shell</strong></span>  from earlier - <code>find_definition</code> from Listing 3, handling only I/O to the outside (Web, DB, UI, other frameworks).</p>
<p><a href="https://www.reddit.com/r/programming/comments/jj7ave/the_grand_unified_theory_of_software_architecture/gabst6z/?context=3">Update 2020-10-28</a>: A "Model" object in today's MVC frameworks is a poisoned apple: it is not a <a href="https://khanlou.com/2014/12/pure-objects/">"pure" object</a> or <a href="http://xunitpatterns.com/Humble%20Object.html">"humble" object</a>, but one that can produce side effects like saving or loading from the database. Their "save" and "read" methods litter your code with untestable side-effects all over. Avoid them, or confine them to the periphery of your system and reduce their influence accordingly (they are actually a hidden <span><strong>Interface Adapter</strong></span>) due to interacting with the DB.</p>
<p>Notice the arrows on the left side of the circles, pointing inwards to more and more abstract parts. These are procedure or function calls. Our code is called by the outside. <strong>This has some exceptions. Whatever you do, the database won't call your app. But the web can, a user can through a UI, the OS can through STDIN, and a timer can, at regular intervals (such as in a game).</strong> <em>(updated 2020-10-28)</em></p>
<p>The top-level procedure:</p>
<ol>
<li>gets the input, </li>
<li>adapts it to simple objects acceptable to the system,</li>
<li>pushes it through the functional core,</li>
<li>gets the returned value from the functional core,</li>
<li>adapts it for the output device,</li>
<li>and pushes it out to the output device.</li>
</ol>
<p>This lets us easily test the functional core. Ideally, most of a production system should be pure-functional.</p>

<p>If you reduce the <span><strong>imperative shell</strong></span> and move code into the <span><strong>functional core</strong></span>, each test can verify almost the entire (now-functional) stack, but stopping short of actually performing external actions.</p>
<p>You can then test the imperative shell using <strong>fewer integration tests</strong>: you only need to check that it is <strong>correctly connected</strong> to the functional core.</p>
<p>Having two users for the system - the real user and the unit tests - and listening to both, lets you guide your architecture so as to <strong>minimize coupling</strong> and build a more <strong>flexible system</strong>.</p>
<p>Having a flexible system lets you implement new features and change existing ones <strong>quickly and cheaply</strong>, in order to <strong>stay competitive as a business</strong>.</p>
<p>Comments are much appreciated. I am yet to apply these insights, and I may be missing something!</p>
<p><strong>Edit 2020-10-28:</strong> I have tried out this methodology in some small TDD Katas, and together with TDD, it works great. But I am not employed right now, so I can't say I've <em>really</em> tried it.</p>
            </div>
            <!-- /.entry-content -->


        </article>
    </section>

        </div>
        
    </div>
</div></div>]]>
            </description>
            <link>https://danuker.go.ro/the-grand-unified-theory-of-software-architecture.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915497</guid>
            <pubDate>Wed, 28 Oct 2020 05:19:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DDoS attack against TinyCert announced]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24915478">thread link</a>) | @shdon
<br/>
October 27, 2020 | https://www.tinycert.org/ddos | <a href="https://web.archive.org/web/*/https://www.tinycert.org/ddos">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Posted by admin on 28 October 2020 at 06:15 CET. Latest update on 28 October 2020 at 17:02 CET.</p>
<p>A greedy bunch of bastards calling themselves "Voodoo Bear" sent an <a href="#mail">email</a> to my private email address announcing a DDoS attack aimed at TinyCert to take place, starting Monday 2 November 2020. They seem to be under the impression that there is a large company with deep pockets behind TinyCert, which I suppose is flattering. TinyCert is just a pet project of mine, that I find useful for myself and figured others might find it useful too.</p>
<h3>Ransom demands</h3>
<p>As you can see from the <a href="#mail">email below</a>, they are demanding a "small" $1000 ransom to call off the attack, increasing their demands by $1000 per day they are not met. TinyCert has been up for 6 years now and costs me about $200 per year to run ($1200 thusfar) and the total amount of <a href="https://www.tinycert.org/donate">donations</a> in that time has been $75, as I guess not enough people found it useful enough to consider donating. Thus, even if I <i>could</i> pay the ransom, I would not want to. If the site goes down, so be it, the version I use privately will be unaffected anyway.</p>
<h3>What can I do about it?</h3>
<p>Realistically, nothing. I could change the IP address by moving to another host or hosting provider, so that the attack goes to the wrong place. That would probably not be effective, at least not for very long. Besides, I would much rather the moronic dipshits waste their time and effort by attacking my little pet project rather than going after somebody who might actually pay them. Heck, if anything, they're saving me money if I have to shut down the site.</p>
<h4>Cloudflare?</h4>
<p>Using Cloudflare or similar services is not an option. The dumb idiots indicate they will attack the network directly (most likely the IP address of the server TinyCert is running on, rather than the actual network of my hosting provider). Since it is a very lightweight server, as TinyCert requires very little in terms of server resources, it won't hold up against a proper DDoS attack for any significant length of time. If anything, it will be interesting to see how well it holds up. For Cloudflare's protection to be effective, the IP address would first have to be changed (which in itself is easily done - I guess the criminals overestimate how much work it is to migrate a small website), but the Cloudflare SSL proxy is not suitable in the free tier. This is because the free tier does not allow the use of a custom certificate and TinyCert uses <abbr title="HTTP Public Key Pinning">HPKP</abbr>. There is also no way I could afford the higher tier that allows that.</p>
<p><strong>Update:</strong> Cloudflare CEO Matthew Prince has <a href="https://twitter.com/eastdakota/status/1321320999678136325">offered Cloudflare's assistance</a> at no cost if needed. I hope it will not be necessary, but kudos to him and Cloudflare for their work and the kind offer.</p><h4>Open source?</h4>
<p>It has been suggested that I open-source the TinyCert codebase and allow people to have their own local versions, which of course wouldn't be affected. This too is not an option. Parts of the codebase are licensed to me personally and providing the source to them would be a breach of that license. Swapping that out for open source code would be possible, but time consuming and labour intensive and not something I am willing to do.</p>
<h3 id="mail">The actual email received</h3>
<p>Here is a copy of the email, for anybody who is interested.</p>
<div>
	<p>
		From: Robert Clark &lt;robertclark@coronaxy.com&gt;<br>
		Subject: If www.tinycert.org is important to you, you must read this<br>
		Date: Wed, 28 Oct 2020 02:13:37 +0000
	</p>
	<div><p>
		PLEASE FORWARD THIS EMAIL TO SOMEONE IN YOUR COMPANY WHO IS ALLOWED TO MAKE IMPORTANT DECISIONS!</p><p>
		==========================================</p><p>
		We are the Voodoo Bear and we have chosen www.tinycert.org as target for our next DDoS attack.<br>
		Please perform a google search for "Voodoo Bear" to have a look at some of our previous work.</p><p>
		Your network will be subject to a DDoS attack starting at 2020 November 2nd (Monday).</p><p>
		THIS IS NOT A HOAX, and to prove it right now we will start a small attack on www.tinycert.org that will last for 30 minutes.<br>
		It will not be heavy attack, and will not cause you any damage so don't worry, at this moment.</p><p>
		This means that your website, e-mail and other connected services will be unavailable for everyone.</p><p>
		We will refrain from attacking your servers for a small fee.<br>
		The current fee is $1000(USD) in bitcoins (BTC). The fee will increase by 1000 USD for each day after deadline that passed without payment.</p><p>
		Please send Bitcoin to the following Bitcoin address (cAsE-SeNsitIve):</p><p>
		[address removed]</p><p>
		You can easily buy bitcoins via several websites or even offline from a Bitcoin-ATM. We suggest you coinmama.com or https://buy.coingate.com/ for buying bitcoins.</p><p>
		Once you have paid we will automatically get informed that it was your payment. Please note that you have to make payment before the deadline or the attack WILL start!</p><p>
		If you decide not to pay, we will start the attack on the indicated date and uphold it until you do, there's no counter measure to this, you will only end up wasting more money trying to find a solution (Cloudflare, Sucuri, Imperva and similar services are useless, because we will hit your network directly).</p><p>
		We will completely destroy your reputation and make sure your services will remain offline until you pay.<br>
		We will also download your database and do as much damage as possible.</p><p>
		Do not reply to this email, don't try to reason or negotiate, we will not read any replies.</p><p>
		Once you have paid we won't start the attack and you will never hear from us again.</p><p>
		Please note that Bitcoin is anonymous and no one will find out that you have complied.</p><p>
		-- Voodoo Bear team
	</p></div>
</div>
<p>I literally laughed out loud at the first sentence, as it indicates how clueless these numbskulls are. Maybe I'll forward the email to my budgerigars, as they are the only other living beings in here, though I'm not sure they're qualified to make any decisions.</p>
<p><strong>Update:</strong> some users have reported receiving similar emails. On the one hand, that is a good thing, as it reduces the likelihood of (persistent) follow-through on the part of these scumbags. On the other hand, the more widespread this is, the more likely it is that somebody will give in and pay up. If you receive a threat like this, do not comply. It will only encourage them that their actions are successful and marks you as being susceptible to caving in to pressure.</p>
<p>So, Mr. "Clark" or "Voodoo Bear", whatever you hilariously pitiable imbeciles call yourselves, you can just fuck off. I have not for a nanosecond considered giving in to your demands, even if I could. You wanna waste your time to take down my pet project? Be my guest. My taking the time and effort to Write this page is the only thing you have "achieved" as you're not getting a penny from me. And thank you for thinking TinyCert something worthy of extortion - that means I must've done something right in creating it.</p>
<p>Well, there you go. It's been fun while it lasted. This is why we can't have nice things.</p>
				</div></div>]]>
            </description>
            <link>https://www.tinycert.org/ddos</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915478</guid>
            <pubDate>Wed, 28 Oct 2020 05:15:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[X266 Open Source Video Codec for Versatile Video Coding (VVC) Update]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24915382">thread link</a>) | @ponderingfish
<br/>
October 27, 2020 | https://ottverse.com/x266-vvc-multicoreware-opensource-encoder/ | <a href="https://web.archive.org/web/*/https://ottverse.com/x266-vvc-multicoreware-opensource-encoder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/x266-featured-image.png?resize=678%2C381&amp;ssl=1" alt="x266 multicoreware vvc" title="x266-featured-image" data-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/x266-featured-image.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p><strong>MulticoreWare is a software development company that works on video compression, ML, heterogeneous computing, and championed the open-source x265 encoder in the past. They are now driving the x266 project to create an open-source VVC (Versatile Video Coding) encoder and use their experience from their UHDKit product to make it the premier open-source VVC encoder.</strong></p>




<h2><span id="Who_is_MulticoreWare"></span><strong>Who is MulticoreWare?</strong><span></span></h2>



<p><a href="https://multicorewareinc.com/" target="_blank" aria-label="MulticoreWare (opens in a new tab)" rel="noreferrer noopener">MulticoreWare</a> is a multi-faceted company with expertise in different verticals such as high-performance Video Compression, AI &amp; Video Analytics, ADAS (Automated Driver Assistance), etc. A common thread through these verticals is their ability to design and write high-performance code for various computing platforms. MulticoreWare’s background and experience are cool, in my opinion, and how they’ve nurtured and built a strong team in a very complex niche is admirable.</p>



<p>With teams in the US, India, China, and Germany, MulticoreWare is well-placed to don the role of a thought-leader in the open-source video codec world.</p>



<p>Let’s see why and what their plans are!</p>



<h2><span id="The_Road_To_x266_%E2%80%93_An_Open_Source_VVC_Encoder"></span><strong>The Road To x266 – An Open Source VVC Encoder</strong><span></span></h2>



<p>MPEG announced three new video codecs – VVC (Versatile Video Coding), EVC (Essential Video Coding), and LCEVC (Low Complexity Enhancement Video Coding). Of these three, VVC or H.266 is touted as the successor to H.265 (HEVC) and promises 50% more compression efficiency over HEVC but comes at a much higher complexity. Here’s a <a href="https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/">brief explanation of all three</a> on OTTVerse.</p>



<p>But, first, let’s take a look at HEVC and the x265 encoder.</p>



<h3><span id="x265_and_HEVC"></span><strong>x265 and HEVC</strong><span></span></h3>



<p>MulticoreWare announced the <a href="https://x265.com/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">x265 project</a> back in 2013, and it was a success. x265 allowed video compression teams worldwide to get their hands on an efficient, standards-compliant HEVC encoder. x265 was made available under the open-source <a href="http://www.gnu.org/licenses/old-licenses/gpl-2.0.html" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">GNU GPL v2 license</a> and also offered by MulticoreWare under Commercial License Agreements.</p>



<p>But, having a good encoder clearly wasn’t enough. Because, fast-forward 7 years, and unfortunately, HEVC is still embroiled in patent-wars that seem destined to give it a “death by a thousand cuts.”&nbsp;</p>



<p>HEVC’s situation is rather unfortunate considering that HEVC had interesting features such as the use of quadtree-decomposition, large block sizes, the concept of TU, PU, and CUs, the Sample Adaptive Offset filter, new picture types, and several innovations which made it possible to compress 4K videos quite efficiently (in comparison to H.264/AVC).</p>



<h3><span id="The_x266_Project"></span><strong>The x266 Project</strong><span></span></h3>



<p>Riding on the back of their x265 success, MulticoreWare has decided to pioneer the x266 project along the x265 project lines they worked on earlier. x266 will be an open-source project with the MulticoreWare video compression team’s full attention and the backing of an industry-consortium.</p>



<p>As with any new codec, there are always early adopters (both programmers and companies) willing to give it a try, evaluate, file tickets, and contribute code. But, to get the ball rolling, you need a reliable encoder that is not only standards-compliant but also reasonably fast and with enough presets and knobs to make the early-adoption both valuable and exciting (in a geeky-sense!)</p>



<p>I spoke to <a href="https://www.linkedin.com/in/shivakumarasu/" target="_blank" aria-label="Shivakumar Narayanan (opens in a new tab)" rel="noreferrer noopener">Shivakumar Narayanan</a>, Senior Director – Marketing and Product Management at MulticoreWare, about the consortium, and this is what he had to say –</p>



<blockquote><p><em>Similar to when we did this for x265 consortium, to get key consortium members on board and invest in the development of this codec. These members will be founding partners with benefits when the codec (rather encoder is ready to release for the open-source world). Consortium members being strategic, will also play an important role in the shaping of this codec as well as prioritization of functionalities as it would pertain to their and their customers’ interests.</em></p></blockquote>



<p>Industry involvement bodes well for the open-source community because <strong>video encoder implementation is both an art and a science.</strong></p>



<p>It helps to have a proficient team that understands and implements concepts such as wavefront parallelism, multi-threading, intrinsics, etc. to make codec implementations practical and useful. And, of course, people with “golden eyes” to spot issues with video quality as they occur.&nbsp;</p>



<p>MulticoreWare has such a team, and I feel they’ll bring their experience from x265 to the x266 development.</p>



<h3><span id="Expertise_from_UHDKit"></span><strong>Expertise from UHDKit</strong><span></span></h3>



<p>Another product in MulticoreWare’s portfolio is <a href="https://x265.com/uhdkit/" target="_blank" rel="noopener">UHDKit</a>. It is an extended encoding library built on top of the x264 (AVC) encoder and x265 (HEVC) encoder libraries. It has a better performance and feature-set than the vanilla x264, x265, and svt-av1 encoders. UHDKit comes in-built with powerful features such as a “control system for video compression” that dynamically adjusts settings to achieve better video quality based on the computing platform’s spec. </p>



<p>Additional features include fast ABR encoding (to get the bitrate ladder faster!) and high-performance live encoding, all this on software, without any requirement for additional hardware accelerators. It can be used as a standalone encoding library or can be invoked via the FFmpeg framework, which makes it seamlessly integrate into any software encoding/ transcoding pipeline.</p>



<p>I am sure some of this expertise from building UHDKit will rub off on the x266 encoder development.</p>



<h2><span id="How_Do_I_Get_my_hands_on_x266"></span><strong>How Do I Get my hands on x266?</strong><span></span></h2>



<p>Currently, MulticoreWare is working closely with x266 Consortium members and after a few months, it will be available to them.</p>



<p>Upon enquiring about the open-source implementation, here’s what MCW had to say –</p>



<blockquote><p><em>For the larger open source community, it will be made available when we have reached critical mass required for its first release. As we near readiness, we will update here on how you can get hold of it.</em></p></blockquote>



<p>If you have any questions for the MulticoreWare team, please get in touch with Shivakumar Narayanan at <a aria-label="x266@multicorewareinc.com (opens in a new tab)" href="mailto:x266@multicorewareinc.com" target="_blank" rel="noreferrer noopener">x266@multicorewareinc.com</a>.</p>



<p>Also, many thanks to <a aria-label="Praveen Kumar Karadugattu (opens in a new tab)" href="https://www.linkedin.com/in/praveenkpk/" target="_blank" rel="noreferrer noopener">Praveen Kumar Karadugattu</a>, Video Architect at MulticoreWare for kicking off this discussion between MulticoreWare and OTTVerse.com. </p>





	</div></div>]]>
            </description>
            <link>https://ottverse.com/x266-vvc-multicoreware-opensource-encoder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915382</guid>
            <pubDate>Wed, 28 Oct 2020 04:54:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What a Yarn Workspace Is, and the Problem It Solves]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24914835">thread link</a>) | @taphangum
<br/>
October 27, 2020 | https://planflow.dev/blog/what-is-a-yarn-workspace | <a href="https://web.archive.org/web/*/https://planflow.dev/blog/what-is-a-yarn-workspace">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>What Is A Yarn Workspace?</h2><p>Before I start to use a new technology, I first try to make sure that I really understand what it is. </p><p>This means getting the definition of what it is to be as crystal clear as possible for me, in all areas that compose the technology.</p><p>This is what we will first do with Yarn Workspaces before we dive into the way we can use them for our projects.</p><p><strong>We can briefly state that a Yarn Workspace is a method of combining multiple project NPM dependencies into a single workspace, so that all projects share the same dependencies. This is commonly referred to as a ‘</strong><a target="_blank" title="monorepo" href="https://www.perforce.com/blog/vcs/what-monorepo"><strong>monorepo</strong></a><strong>’.</strong></p><p>To get an even better understanding of what a Yarn Workspace is, it's best to take a look at the broader picture of the problem it solves and why that problem exists in the first place.</p><h2>The Multi-Megabyte Problem that a Yarn Workspace solves</h2><p>While the emergence of open source packages within the NPM ecosystem has lead to <a target="_blank" title="https://flaviocopes.com/node-modules-size/" href="https://flaviocopes.com/node-modules-size/">tremendous benefits</a> and time-saved on project code, the fact that so many node modules are now needed for even the simplest of projects has led to a lot of bloat in overall project size. </p><p>The average node js project, specifically the dependencies located within it, <a target="_blank" title="https://forum.freecodecamp.org/t/node-modules-is-huge-is-this-normal/137282/12" href="https://forum.freecodecamp.org/t/node-modules-is-huge-is-this-normal/137282/12">have a total estimated size of 76MB</a>.</p><p>For a single, web based project for example, this is huge.</p><p>When working on more complex projects, with dependencies from a variety of frameworks, this size can swell even more. I’m sure we’re all familiar with the infamous Godzilla 500+ MB /node_modules folder.</p><p>Imagine now, with these large individual file sizes on each project, that we had a multi-project setup with each project that needed to have its own dependencies, such as what you might find in a standard MERN or MEVN stack. With a separate /client and /server folder structure, each with their own package.json and subsequent package dependencies.</p><p>Each of these projects would have to be loading in their own dependencies, and sometimes, as shown in the drawing above, having the same duplicate dependencies loaded in for each folder, causing massive unnecessary bloat. Not to mention the issues that would arise from dealing with out-of-date code and the potential conflicts in the overall codebase.</p><p>These issues are what are commonly referred to as ‘<a target="_blank" title="https://blog.appsignal.com/2020/04/09/ride-down-the-javascript-dependency-hell.html" href="https://blog.appsignal.com/2020/04/09/ride-down-the-javascript-dependency-hell.html">dependency hell’</a>. </p><p><strong>And it’s not a new issue. Infact, its been around for a long time. </strong></p><p>Fortunately, there are now solutions to this problem. That solution as we have stated above is the monorepo. </p><p>One of the most prominent (within the NPM ecosystem) of which is the <em><strong>Yarn Workspace</strong></em>.</p><p><strong>Whose benefits alongside the obvious bloat reduction mentioned above, include:</strong></p><p>-	Better code-quality and optimization due to packages being linked together. Leading to more up to date code in general. </p><p>-	All your dependencies installed together at one time, leading to better ability for Yarn to optimize them.</p><p>-	Yarn gets to make a single lock file rather than multiple, giving you fewer conflicts and making code review easier.</p><p>So now that we have a clearer overall picture of what a Yarn Workspace is in general. Let’s now take a look at what it actually looks like and how we can go about setting it up within a project.</p><h2><strong>How Do You Set Up A Yarn Workspace? And What Does It Looks Like?</strong></h2><p>Setting up a Yarn Workspace is as easy as running a few commands and making some edits to a few simple pages.</p><h3><strong>The general steps are:</strong></h3><p><strong>1. Create your main project directory with a command like this:</strong></p><p>$ mkdir my-monorepo-workspace</p><p><strong>2. Navigate to the newly created project directory root and create your package.json.</strong></p><p>$ cd my-monorepo-workspace</p><p>$ touch package.json</p><p><strong>3. Replace the contents of your package.json with the following:</strong></p><p>{</p><p>   "private": true,</p><p>   "name": "my-monorepo-workspace",</p><p>   "workspaces": [],</p><p>   "scripts": {}</p><p>}</p><p>This makes the workspace project that we have created private, as we don’t want to upload it to NPM. It also creates the spaces where we will set our workspace project names and our scripts.</p><p><strong>4. Create two project directories within your main directory root, like this:</strong></p><p>$ mkdir project-1 project-2</p><p>Feel free to name these however you want.</p><p><strong>5. Add your project names to the workspace package.json that lives within your root directory:</strong></p><p> {</p><p>   "private": true,</p><p>   "name": "my-monorepo-workspace",</p><p>   "workspaces": [“project-1”, “project-2”],</p><p>   "scripts": {}</p><p>}</p><p>Once set up, these two of our projects will be able to share the same installed NPM packages. </p><p>The above steps have now given us our basic Workspace structure. </p><p>Now we can get started with fully activating our Workspace. Let’s add some real code to it before we do that, to demonstrate how it all works.</p><p>We’ll do this by creating a front end in project-1 and a backend in project-2.</p><p><strong>6. For our front-end in project-1, we’ll use React, which we can install with the following command:</strong></p><p>$ yarn create react-app project-1</p><p><strong>7. For our backend in project-2, we’ll use an </strong><a target="_blank" title="https://expressjs.com/" href="https://expressjs.com/"><strong>Express.js</strong></a><strong> server package. Which we can install by first adding Express Generator to our global package.json like so:</strong></p><p>$ yarn global add express-generator --prefix /usr/local</p><p><strong>Note</strong><strong>:</strong> Notice here that we use ‘yarn global add’ instead of the usual ‘yarn add’, now that we have multiple projects, we need to specify the scope of our installed packages for clarity.</p><p><strong>8. Generate and install the Express package for our server in ‘project 2’ like this:</strong></p><p>$ express --view=pug project-2</p><p>Now that we have set up our react app frontend and our express app backend we can now install all of our dependencies.</p><p><strong>9. Install all of the dependencies like so:</strong></p><p>$ yarn install</p><p>This command generates a yarn.lock file, which contains a note of all of your dependencies. This is generated automatically and should not be deleted.</p><p>Our packages our now installed and should be available to both of our projects within the workspace. </p><p>As a final step, let us now set up some scripts that can run our projects for us concurrently, which is wise to do within a shared workspace, as the core concept is about bringing these two together.</p><p><strong>10. We can set up the two projects to run concurrently by first setting the command within our root package.json like this:</strong></p><p>$ yarn add -W concurrently</p><p>This adds the ‘concurrently’ start script that you’ll see below that runs the two project start scripts concurrently. </p><p>To tell our package.json how we want those scripts to run, add the following:</p><p>{</p><p>   "private": true,</p><p>   "name": "my-monorepo-workspace",</p><p>   "workspaces": [“project-1”, “project-2”],</p><p>   "scripts": {</p><p>   	"project-1": "yarn workspace project-1 start",</p><p>   	"project-2": "yarn workspace project-2 start",</p><p>   	"start": "concurrently --kill-others-on-fail \"yarn project-2\"  \"yarn project-1\"</p><p>   }</p><p>}</p><p>The actual scripts that are necessary to run the projects are within the installations within the project directories.</p><p>Last but not least, change the port name within our project-2 express app directory to port 4000, just to ensure that we don’t get conflicts by running the same port 3000 when we run our two app projects.</p><p><strong>11. We can do that like this, within our server/bin/www on line 15:</strong></p><p>var port = normalizePort(process.env.PORT || '4000');</p><p>Now to run our project, all we need to do is go to our root directory and run:</p><p>$ yarn start</p><p><strong>That’s it, we’re done. </strong></p><p>This has fully set up our Yarn Workspace, and has it running!</p><p><em><strong>If you’d like to read some more on the topic of Yarn Workspaces, as well as monorepo's in general. Here are some good resources:</strong></em></p><p>Creating Yarn Workspaces with GatsbyJS - <a target="_blank" title="https://www.gatsbyjs.com/blog/2019-05-22-setting-up-yarn-workspaces-for-theme-development/" href="https://www.gatsbyjs.com/blog/2019-05-22-setting-up-yarn-workspaces-for-theme-development/">https://www.gatsbyjs.com/blog/2019-05-22-setting-up-yarn-workspaces-for-theme-development/</a></p><p>Yarn Workspaces: Organize Your Project’s Codebase Like A Pro - <a target="_blank" title="https://www.smashingmagazine.com/2019/07/yarn-workspaces-organize-project-codebase-pro/" href="https://www.smashingmagazine.com/2019/07/yarn-workspaces-organize-project-codebase-pro/">https://www.smashingmagazine.com/2019/07/yarn-workspaces-organize-project-codebase-pro/</a></p><p>Ride Down Into JavaScript Dependency Hell - <a target="_blank" title="https://blog.appsignal.com/2020/04/09/ride-down-the-javascript-dependency-hell.html" href="https://blog.appsignal.com/2020/04/09/ride-down-the-javascript-dependency-hell.html">https://blog.appsignal.com/2020/04/09/ride-down-the-javascript-dependency-hell.html</a></p><p>What Is a Monorepo? - <a target="_blank" title="https://www.perforce.com/blog/vcs/what-monorepo" href="https://www.perforce.com/blog/vcs/what-monorepo">https://www.perforce.com/blog/vcs/what-monorepo</a></p><p><strong>Bonus: </strong><a target="_blank" title="https://stackoverflow.com/questions/64110406/how-could-i-change-the-name-of-my-yarn-workspace-package" href="https://stackoverflow.com/questions/64110406/how-could-i-change-the-name-of-my-yarn-workspace-package"><strong>How Do You Modify A Yarn Workspace?</strong></a></p><p>This is a post on StackOverflow that will help in modifying a Yarn workspace that has already been setup when that is necessary for you to do.</p></div></div>]]>
            </description>
            <link>https://planflow.dev/blog/what-is-a-yarn-workspace</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914835</guid>
            <pubDate>Wed, 28 Oct 2020 03:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Note on Branching Within a Shader]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24914672">thread link</a>) | @underanalyzer
<br/>
October 27, 2020 | https://www.peterstefek.me/shader-branch.html | <a href="https://web.archive.org/web/*/https://www.peterstefek.me/shader-branch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 <div>
  
  <p><label>Posted on <strong>26 October 2020</strong></label></p><p>An <a href="https://www.google.com/search?q=three+weeks&amp;oq=three+weeks">eternity</a> ago, I published a <a href="https://www.peterstefek.me/focused-render.html">blog post</a> about a shader I wrote. In that post, I casually repeated a piece of gpu folklore I picked up as a wee opengl enthusiast almost a decade ago,   </p>
<p>
"Using if statements inside a shader will cause performance degradation."  
</p>

<p>People on the internet seemed a little skeptical about this statement, and I realized my advice might be outdated. So this post is a quick follow up about the cost of branching on more modern gpus.  </p>
<p>Before we talk about branching, what is a gpu? A GPU or graphics processing unit, is a special piece of hardware initially developed to crunch numbers for graphics calculations. It accomplishes this goal quickly through a large amount of parallelization.   </p>
<p>GPUs can run many threads at the same time in parallel. These threads are generally executed in groups called warps (CUDA), invocations (Vulkan) and waves (I will use the term warp, but they are all interchangeable). On recent Nvidia hardware (Ampere/ Volta / Pascal) these warps contain 32 threads. Pascal for example can theoretically run up to four independent instructions per warp over 56 warps of 32 threads which comes out to a mind blowing 7168 instructions per cycle. </p>
<p>Each warp can only execute one instruction at a time. However that instruction can be executed for each of the threads in the warp. This means the GPU can execute 32 copies of the same instruction in parallel for each thread in the warp at once.   </p>
<p>However, taking both sides of a branch will cause the threads inside a warp to "diverge". This means some threads will need to execute one side of the branch and some will need to execute the other. Unfortunately, both instructions can not be executed simultaneously for threads in the same warp. So these divergent instructions must be executed sequentially.   </p>
<p>
    <img src="https://www.peterstefek.me/images/shader-branch/pascal-divergence.png" width="65%"> 
</p>

<p>The above image is taken from the Volta whitepaper.  </p>
<p>Consider the <a href="https://www.shadertoy.com/view/WdyyWV">following fragment shader</a>:<br>
<code>
void mainImage( out vec4 fragColor, in vec2 fragCoord )
{  <br>
  </code></p><p><code>
  // TUNE THIS AMOUNT TO YOUR GPU STRENGTH<br>
  int workAmount = 2000;<br>
  float incr = 1. / float(workAmount);<br>
  float outColor = 0.0;  
<p>// USE THIS VARIABLE TO TOGGLE BRANCHING<br>
  bool branch = true;  </p>
<p>if (mod(fragCoord.x, 2.) &lt; 1. &amp;&amp; branch) {
    </p><div><p>
      for (int i = 0; i &lt; workAmount; i++) {
        </p><p>
          outColor += incr;
          </p><p>
      }<br>
      fragColor = vec4(0.0,outColor,0.0,1.0);
      </p></div>
  } else {
    <div><p>
      for (int i = 0; i &lt; workAmount; i++) {
        </p><p>
          outColor += incr;
          </p><p>
      }<br>
      fragColor = vec4(outColor,0.0,0.0,1.0);
      </p></div>
  }
  </code></p><p><code>
}
</code></p>
<p>In fragment shaders like the one above, each warp is composed of a set of spatially close pixels. Each warp in this shader should diverge because each horizontally adjacent pixel takes a different side of the branch. Let's say the cost of each inner loop is n cycles. Since each side of the branch is executed in series, each warp must take at least 2n cycles, even though each thread uses only one side of the branch. These effects scale with the number of threads in the distinct divergent paths taken (up to 32x in Nvidia hardware). Here's another shader which should have roughly four branches per warp. <a href="https://www.shadertoy.com/view/wsVyzG">This shader</a> will take at least 4n cycles.  </p>
<p>However, let's look a <a href="https://www.shadertoy.com/view/tsVyzG">second shader</a>:   </p>
<p><code>
void mainImage( out vec4 fragColor, in vec2 fragCoord )
{
  </code></p><p><code>
  // USE THIS VARIABLE TO TOGGLE BRANCHING<br>
  int workAmount = 2000;<br>
  float incr = 1. / float(workAmount);<br>
  float outColor = 0.0;  
<p>// USE THIS VARIABLE TO TOGGLE BRANCHING<br>
  bool branch = true;  </p>
<p>if (fragCoord.x &lt; iResolution.x / 2.0 &amp;&amp; branch) {
    </p><div><p>
      for (int i = 0; i &lt; workAmount; i++) {
        </p><p>
          outColor += incr;
          </p><p>
      }<br>
      fragColor = vec4(0.0,outColor,0.0,1.0);
    </p></div>
  } else {
    <div><p>
        for (int i = 0; i &lt; workAmount; i++) {
          </p><p>
          outColor += incr;
          </p><p>
      }<br>
      fragColor = vec4(outColor,0.0,0.0,1.0);
      </p></div>
  }
  </code></p><p><code>
}
</code></p>
<p>This shader should run roughly twice as fast as the other shader even though roughly the same number of pixels take each branch. This is because most of the warps do not diverge (with the exception of a few around half way across the screen).   </p>
<p><strong>Nvidia Specifics</strong><br>
As far as I can tell, there are roughly two different ways of nvidia graphics cards handle divergence with in a warp.</p>
<p><strong>Thread Masking (Pre Volta)</strong><br>
On pre volta Nvidia card, divergence was handled by something called thread masking.   </p>
<p>Basically when a conditional is hit, a thread mask is generated.  We can think of this mask as a 32 entry array. Each entry specifies whether the corresponding thread takes the first side of the branch or not. The first side is then executed for each of those threads. After the first side of the branch is then executed, the mask is reversed and the other side of the branch is executed.   </p>
<p>This thread mask strategy exists in part because there is only one program counter per warp on pre volta gpus. So essential every thread in the warp must be at the same place in the program. The only way we know which threads to execute, is by using the mask.</p>
<p>
    <img src="https://www.peterstefek.me/images/shader-branch/pascal-divergence.png" width="65%"> 
</p>

<p>The above image is taken from the Volta whitepaper.</p>
<p>It's worth noting that only the threads which need to execute the branch actually are assigned to computational cores. So if no threads execute one side of the branch, no work is done.</p>
<p><strong>Independent Thread Scheduling (Volta and Beyond)</strong><br>
One big change in the Volta architecture and beyond is the introduction of "Independent Thread Scheduling".   </p>
<p>In Independent thread scheduling, each thread has its own program counter. This allows each warp to track the execution of every thread at a fine grain level. However, we can still only execute only one instruction at a time. So the actual runtime of a branch does not change.  </p>
<p>So if Independent Thread Scheduling does not speed up branching, what does it do? Independent Thread Scheduling enables both sides of a branch to execute concurrently but not in parallel.   </p>
<p>
    <img src="https://www.peterstefek.me/images/shader-branch/volta-divergence.png" width="65%"> 
</p>

<p>The above image is taken from the Volta whitepaper.</p>
<p>The reason for this shift is because before Volta, branches were places where deceptive deadlocks could occur. <br>
<code>
leader_id = 0<br>
If (threadIdx.x == leader_id) {<br>
  </code></p><p><code>
    // Do some inital work
  </code></p><p><code>
} else {
  <p>
    // Wait for leader to finish it's work<br>
    // then do my work
  </p>
}<br>
</code></p>
<p>In the above compute shader pseudo code, we have 31 "follower" threads waiting for the "leader thread" to finish (using in-warp shared local memory) before executing their own instructions. </p>
<p>On a Pascal GPU or below, if the else side of the branch is executed first, a deadlock will occur. The leader will never get a chance to start it's work because its followers will be waiting for it. </p>
<p>Independent Thread Scheduling gets around these locking problems by interlacing the two diverging paths. </p>
<p><strong>Article TLDR</strong><br>
Branch divergence in warp makes all parts of the branch execute in sequence which slows down the shader. Branching divergence between warps does not affect runtime.  </p>
<p><strong>Further Reading</strong><br>
Branch execution on gpus is surprisingly deep, and there are many edge cases I didn't address and I also didn't touch gpu vendors other than Nvidia. Here are some good sources if you want to learn more:  </p>
<p><a href="https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf">The Volta Whitepaper</a> (Most of this post can be found between figures 20 and 22)<br>
<a href="http://taylorlloyd.ca/gpu,/pascal,/cuda/2017/01/07/gpu-pipelines.html">Understanding the Pascal GPU Instruction Pipeline</a><br>
<a href="https://aschrein.github.io/jekyll/update/2019/06/13/whatsup-with-my-branches-on-gpu.html#figure-8-divergent-threads-execution-time">What's up with My Branch on GPU</a> (this post covers some diabolical edge cases, including some around texture sampling)  </p>
<p>Have questions / comments / corrections?<br>
Get in touch: <a href="mailto:pstefek.dev@gmail.com">pstefek.dev@gmail.com</a>   </p>
 </div>
</div></div>]]>
            </description>
            <link>https://www.peterstefek.me/shader-branch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914672</guid>
            <pubDate>Wed, 28 Oct 2020 03:10:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making a Real-Time NYC Subway Map with Real Weird NYC Subway Data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24914667">thread link</a>) | @underanalyzer
<br/>
October 27, 2020 | https://www.patrickweaver.net/blog/making-a-real-time-nyc-subway-map-with-real-weird-nyc-subway-data/ | <a href="https://web.archive.org/web/*/https://www.patrickweaver.net/blog/making-a-real-time-nyc-subway-map-with-real-weird-nyc-subway-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <h3>
        <a href="">
            Making a Real-Time NYC Subway Map with Real Weird NYC Subway Data
        </a>
      </h3>
      
            
      <p>Earlier this week the NYC MTA released a new <a href="https://map.mta.info/">digital-first map</a>. The <a href="https://www.curbed.com/2020/10/first-look-new-yorks-digital-subway-map-comes-alive-today.html">Curbed exclusive</a> that announced its release accurately portrays it as a strange child of both the 1972 map design by Massimo Vignelli and the current <a href="https://new.mta.info/map/5256">“paper” map</a>. One feature of the new map (though it's harder than it should be to notice at first) is real-time visualizations of each train in the system.</p>
<p>I've been working on a similar concept, starting in February 2020, on which progress stalled once I stopped riding the subway regularly in March. But, when I started my batch at <a href="https://www.recurse.com/">Recurse Center</a> I decided to pick up the project again. My inspiration for the map was the large TV screens that the MTA has installed in stations over the last few years, which frustratingly display the “paper” version of the map.</p>
<figure>
<p><img src="https://www.patrickweaver.net/images/blog/nyc-subway/tv-screen-map.jpg" alt="A photograph of a TV in a subway station with the “paper” map displayed.">
</p>
<figcaption>Subway station TV (This is not a good photo, but it’s hard to take a picture of a screen underground)</figcaption>
</figure>
<p>Over the past few weeks at RC the subway map has been my main focus, which is longer than I expected the project to take (and though I have a prototype, I wouldn’t say I’m close to “done”). A big factor in the time the project has taken is some of the quirks in working with MTA data, which based on some of the bugs I've seen in the "official" version I'd say the team working on that version had to grapple with as well.  I'm not sure I will ever finish this project to a state that would look great on a subway station tv, or be useful, but I do want to point out <a href="https://www.theweekendest.com/trains">The Weekendest</a> by <a href="https://sunny.ng/">Sunny Ng</a> (who also made <a href="https://www.goodservice.io/">goodservice.io</a>), which is a great take on the concept, and handles some of the challenges of this kind of project much better than the MTA map does.</p>
<p>For a long time the NYC Subway was almost <a href="https://www.theatlantic.com/technology/archive/2015/11/why-dont-we-know-where-all-the-trains-are/415152/">completely lacking in real-time data</a>. For many years the only line that had even countdown clocks in stations was the L, which seems to be the line the MTA tries out new technology on, likely because it never shares tracks with any other line. Over the last 5 years the MTA has slowly installed countdown clocks in every station, and made the data that powers the countdown clocks available on their website, in apps, and as data online.</p>
<p>Inspired and frustrated by the “paper” maps on the tv screens, I first became interested in working with MTA data in 2018, but I initially started working with bus data, I think for two reasons: the first was because at the time the API key for working with bus data was easier to obtain than for subway data, the second because my morning commute at the time usually started with the bus (The MTA, earlier this year, has fortunately updated the system for obtaining an API key for subway data). I made a small prototype of an iPhone app that would show real-time bus data, but got distracted by learning the Swift programming language and abandoned the project without building functionality beyond what the MTA already provided <a href="https://bustime.mta.info/">on their bustime website</a>.</p>
<p>That MTA Bustime website was the other inspiration for what became my map idea. Though you could only view one route at a time (and the functionality is not available on phone-size devices), the Bustime website showed, in addition to countdowns for each stop, the physical location of each bus on a map. This leads us to the first weird thing about working with NYC Subway data, unlike real-time bus data, the subway data does not contain the latitude and longitude data for each train that would make it easy to show them on a map.</p>
<h3>Real-Time Transit Data</h3>
<p>Transit data for most transit systems is available in formats called <a href="https://developers.google.com/transit/gtfs">GTFS</a> (General Transit Feed Specification) and <a href="https://developers.google.com/transit/gtfs-realtime">GTFS Realtime</a>, which were developed by Google (makes you wonder what the “G” originally stood for), but are now widely used. A GTFS file is, “a collection of at least six, and up to 13 CSV files (with extension .txt) contained within a .zip file.” and “The GTFS Realtime data exchange format is based on Protocol Buffers” (which are <a href="https://developers.google.com/protocol-buffers">“Google's language-neutral, platform-neutral, extensible mechanism for serializing structured data”</a>).</p>
<p>The GTFS Realtime feeds are available through 9 different API endpoints from the MTA. These 9 endpoints roughly correspond to the line colors, with Shuttles combined with trains they share tracks or stations with, and the 1/2/3 and 4/5/6 sharing one endpoint. This list of separate endpoints is another challenge with working with the entirety of the MTA data.</p>
<p>I have exclusively worked with the NYC MTA’s GTFS Realtime feeds through the <a href="https://www.npmjs.com/package/gtfs-realtime-bindings">npm module</a> maintained by Google. It is very possible that some of the challenges I’ve encountered are due to trying to squeeze the “extensible mechanism for serializing structured data” into JSON. Each API response is mostly composed of an array of "Feed Entity" objects like <a href="https://www.patrickweaver.net/notes/nyc-subway-feed-entity/">these</a>, but there are a few quirks to working with this data (some maybe because of the JSON conversion).</p>
<ul>
<li>Each item in the array has an <code>id</code> property, but unfortunately these ids do not consistently refer to the same train between each update, it's best to ignore it.</li>
<li>The array consists of pairs of objects that either have a <code>tripUpdate</code> property or a <code>vehicle</code> property. Each of these have a sub-property called <code>tripId</code> that allows you to unite the pairs, but there are also some that don't have a corresponding item (usually these represent trips that recently ended or haven't yet begun).</li>
<li>The data mixes together HH:MM:SS timestamps for data about when a train's trip started, and <a href="https://en.wikipedia.org/wiki/Unix_time">Unix timestamps</a> for data about the current time (according to the API) and when a train will arrive at a station (the API provides both arrival and departure times but as far as I have seen they are always identical).</li>
<li><code>tripUpdate</code> items show information about the stops a train will make in the future (stopTimeUpdates) and vehicle items show information about the current status of the train, but the first <code>stopTimeUpdate</code> is usually in the past.</li>
</ul>
<p>I had never heard of Protocol Buffers before starting this project, so I was excited to learn more about them while reading through <a href="https://dataintensive.net/">Designing Data Intensive Applications</a> with fellow Recursers.  In the book Martin Kleppmann notes that a, "curious detail of Protocol Buffers is that it does not have a list or array datatype, but instead has a repeated marker for fields (which is a third option alongside required and optional)." This could be the reason for the strange organization of the <code>tripUpdate</code> and <code>vehicle</code> properties.</p>
<h3>Calculating Train Locations</h3>
<p>The subway real-time API doesn’t have latitude and longitude data because it is designed to feed data to countdown clock style applications that show when the train will be at a specific station. One of the earliest features that I built into the real-time map was a way to translate these station-by-station countdown clocks into an approximation of the location of each train. My first attempt at this was to just show a list of stations and display an icon for a train between the names of the station it had been at previously and the station it was approaching.</p>
<figure>
<p><img src="https://www.patrickweaver.net/images/blog/nyc-subway/prototype-diagram.png" alt="An early prototype diagram of G train positions.">
</p>
<figcaption>A first prototype, still available at: <a href="https://nyc-subway-g.glitch.me/">nyc-subway-g.glitch.me</a></figcaption>
</figure>
<p>The next step was plotting the stations on a map. To start off, as with the diagram version, I just placed each train at the midpoint between the station it was travelling from and the station it was travelling towards.</p>
<p>A goal I had for the project was not just to show real-time train locations, but to animate them as they moved around the map. To determine how long I should expect a train to take to travel between each station I logged updates from the MTA API for a few hours and noted both the average time for a pair of stations, and the longest time I had seen for the pair. I'm still experimenting a little bit with what values to use as the baseline, but from looking at the logged numbers there does seem to be an expected amount of time for most stations.</p>
<figure>
<div>
<pre><code>G: {
   G22: { N: { avg: 60, max: 71 }, S: null },
   G24: { N: { avg: 123, max: 180 }, S: { avg: 60, max: 106 } },
   G26: { N: { avg: 75, max: 90 }, S: { avg: 108, max: 180 } },
   G28: { N: { avg: 128, max: 180 }, S: { avg: 78, max: 90 } },
   G29: { N: { avg: 60, max: 76 }, S: { avg: 139, max: 180 } },
   G30: { N: { avg: 51, max: 74 }, S: { avg: 70, max: 90 } },
   G31: { N: { avg: 60, max: 90 }, S: { avg: 58, max: 69 } },
   G32: { N: { avg: 66, max: 87 }, S: { avg: 53, max: 84 } },
   G33: { N: { avg: 50, max: 66 }, S: { avg: 67, max: 84 } },
   G34: { N: { avg: 58, max: 90 }, S: { avg: 54, max: 66 } },
   G35: { N: { avg: 68, max: 86 }, S: { avg: 50, max: 81 } },
   G36: { N: { avg: 81, max: 161 }, S: { avg: 59, max: 71 } },
   A42: { N: { avg: 70, max: 177 }, S: { avg: 87, max: 157 } },
   F20: { N: { avg: 68, max: 90 }, S: { avg: 86, max: 165 } },
   F21: { N: { avg: 72, max: 120 }, S: { avg: 76, max: 120 } },
   F22: { N: { avg: 62, max: 90 }, S: { avg: 84, max: 120 } },
   F23: { N: { avg: 90, max: 120 }, S: { avg: 88, max: 150 } },
   F24: { N: { avg: 101, max: 120 }, S: { avg: 67, max: 84 } },
   F25: { N: { avg: 139, max: 180 }, S: { avg: 71, max: 90 } },
   F26: { N: { avg: 120, max: 120 }, S: { avg: 109, max: 150 } },
   F27: { N: null, S: { avg: 81, max: 120 } },
 }
</code></pre>
</div>
<figcaption>Average and max wait times in seconds for stops on the G line.</figcaption>
</figure>
<figure>
<table>
<thead>
<tr>
<th>Trip Id</th>
<th>Trip Start Time</th>
<th>Trip Date</th>
<th>Route</th>
<th>Stop1 Arrival</th>
<th>Stop1 Id</th>
<th>Stop2 Arrival</th>
<th>Stop2 Id</th>
<th>Seconds</th>
</tr>
</thead>
<tbody>
<tr>
<td>073476_G..N</td>
<td>12:14:46</td>
<td>20200818</td>
<td>G</td>
<td>1597768631</td>
<td>G33N</td>
<td>1597768692</td>
<td>G32N</td>
<td>61</td>
</tr>
<tr>
<td>074600_G..N</td>
<td>12:26:00</td>
<td>20200818</td>
<td>G</td>
<td>1597769103</td>
<td>G33N</td>
<td>1597769172</td>
<td>G32N</td>
<td>69</td>
</tr>
<tr>
<td>075000_G..N</td>
<td>12:30:00</td>
<td>20200818</td>
<td>G</td>
<td>1597769531</td>
<td>G33N</td>
<td>1597769596</td>
<td>G32N</td>
<td>65</td>
</tr>
<tr>
<td>076501_G..N</td>
<td>12:45:01</td>
<td>20200818</td>
<td>G</td>
<td>1597770333</td>
<td>G33N</td>
<td>1597770396</td>
<td>G32N</td>
<td>63</td>
</tr>
<tr>
<td>077700_G..N</td>
<td>12:57:00</td>
<td>20200818</td>
<td>G</td>
<td>1597771043</td>
<td>G33N</td>
<td>1597771104</td>
<td>G32N</td>
<td>61</td>
</tr>
<tr>
<td>078403_G..N</td>
<td>13:04:02</td>
<td>20200818</td>
<td>G</td>
<td>1597771443</td>
<td>G33N</td>
<td>1597771524</td>
<td>G32N</td>
<td>81</td>
</tr>
<tr>
<td>079600_G..N</td>
<td>13:16:00</td>
<td>20200818</td>
<td>G</td>
<td>1597772051</td>
<td>G33N</td>
<td>1597772112</td>
<td>G32N</td>
<td>61</td>
</tr>
<tr>
<td>080550_G..N</td>
<td>13:25:30</td>
<td>20200818</td>
<td>G</td>
<td>1597772711</td>
<td>G33N</td>
<td>1597772776</td>
<td>G32N</td>
<td>65</td>
</tr>
</tbody>
</table>
<figcaption>Logged travel Times between the Bedford - Nostrand stop and the Myrtle - Willoughby stop on the G train</figcaption>
</figure>
<h3>Secret Stations</h3>
<p>One thing I discovered while …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.patrickweaver.net/blog/making-a-real-time-nyc-subway-map-with-real-weird-nyc-subway-data/">https://www.patrickweaver.net/blog/making-a-real-time-nyc-subway-map-with-real-weird-nyc-subway-data/</a></em></p>]]>
            </description>
            <link>https://www.patrickweaver.net/blog/making-a-real-time-nyc-subway-map-with-real-weird-nyc-subway-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914667</guid>
            <pubDate>Wed, 28 Oct 2020 03:09:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Dual-Boot Ubuntu 20.04 and Windows 10 with Encryption]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 150 (<a href="https://news.ycombinator.com/item?id=24914573">thread link</a>) | @Fiveplus
<br/>
October 27, 2020 | https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html | <a href="https://web.archive.org/web/*/https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><img src="https://www.mikekasberg.com/images/posts/dual-boot-encryption-full.jpg" alt="Image for "></p>
  <p><span>08 Apr 2020</span></p><p>When you run the Ubuntu installer, there’s an option to dual-boot Ubuntu with an
existing Windows installation. There’s also an option to encrypt your Ubuntu
installation, but <em>only if you erase everything and install ubuntu</em>. There’s no
automatic way to install Ubuntu alongside Windows 10 with encryption. And while
there are plenty of tutorials for dual-booting Ubuntu and Windows, many of them
are outdated – often referencing an MBR partition table – and almost none of
them seem to address encrypting your Ubuntu partition.</p>

<blockquote>
  <p>Dual-booting with encrypted storage should not be this hard in 2020.</p>

  <p>–Me, while figuring out how to do this.</p>
</blockquote>

<p>In reality, once you figure it out, it’s not that hard. The tricky thing is that
this isn’t well-documented <strong>anywhere</strong>! So I’m hoping to fix that with this
tutorial blog post. Honestly, if you know enough about Ubuntu to set up a
dual-boot with Windows, it’s only a little bit harder to do it with encryption.
I prepared this tutorial on a Dell Latitude e7450, and I fine-tuned it when I
tested it on my Dell Precision 5510. So it should work with almost no
modification on most Dell systems, and with only minor modifications
(particularly around BIOS setup) on most other types of computers.</p>

<h2 id="references">References</h2>

<p>To write this guide, I compiled information from several sources. Here are some
of the most useful references I found:</p>

<ul>
  <li><a href="https://gist.github.com/luispabon/db2c9e5f6cc73bb37812a19a40e137bc">XPS 15 9560 Dual-Boot with Encryption Notes</a>,
by <a href="https://gist.github.com/luispabon">luispabon</a>. I followed these notes pretty
closely, but modified some partition sizes and names based on other guides.</li>
  <li><a href="https://gist.github.com/mdziekon/221bdb597cf32b46c50ffab96dbec08a">XPS 15 9570 Dual-Boot with Encryption Notes</a>,
by <a href="https://gist.github.com/mdziekon">mdziekon</a>, upon which the above is based.</li>
  <li><a href="https://help.ubuntu.com/community/Full_Disk_Encryption_Howto_2019">Full Disk Encryption HowTo 2019</a>,
from the Ubuntu Community Wiki. This is a great resource, but deals with
encryption without dual-booting.</li>
  <li><a href="https://help.ubuntu.com/community/ManualFullSystemEncryption">Manual Full System Encryption</a>,
from the Ubuntu Community Wiki. This is longer, and isn’t focused on
dual-booting, but provides great details on the way certain things work.</li>
</ul>

<p>It is worth noting that this method doesn’t encrypt <code>/boot</code>. While there are
valid reasons for encrypting /boot, the graphical installer does not encrypt it
when you do a graphical install with LUKS. As such, I’m matching that precedent,
and keeping the simplicity of an unencrypted /boot partition. Thus, the guide
I’ve compiled below is just about the <strong>simplest way to have a LUKS encryption
with dual-boot.</strong></p>

<h2 id="why-encryption-is-important">Why encryption is important</h2>

<p>I began using encrypted storage on all my personal computers 5 or 6 years ago
after noticing that all the companies I’d worked for required it, and had good
reason to. Laptops get lost and stolen all the time. They’re high-value items
that are small and easy to carry. And when a thief gets your laptop, there’s
tons of valuable information on it that they can use or sell. Even if you use a
password to log in, it’s easy for an attacker to gain access to your data if
your disk isn’t encrypted – for example, by using a live USB stick. And once
they have that data, they might get access to online accounts, bank statements,
emails, and tons of other data. For me, an encrypted hard disk isn’t optional
anymore – its a necessity.</p>

<h2 id="an-overview">An Overview</h2>

<p>So what are we going to do? This tutorial will help you set up a system to
<strong>dual-boot Ubuntu 20.04 and Windows 10</strong>. (I haven’t tested it, but it should
work with most other modern versions (~16.04+) of Ubuntu or Windows.) The system
will use a GPT hard disk with UEFI (your BIOS must support UEFI). The Ubuntu
partition will be encrypted with LUKS.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> The Windows partition can optionally
be encrypted with BitLocker. I’m going to keep the Ubuntu installation as close
to a “default” installation as possible – no fancy tricks like a separate
<code>/home</code> partition, but it should be somewhat easy to add that yourself if you
really want to.</p>

<p>I’m going to start with a blank hard disk, installing both Windows 10 and Ubuntu
from scratch. If you already have Windows installed and you want to keep it, you
should be able to shrink your windows partition and join us in phase 3 (though
you might want to skim phases 1 and 2 to understand what we did).</p>

<p>To give you a broad overview of where we’re headed, here’s what we’re going to
do:</p>

<ol>
  <li>Prepare the installation media and computer</li>
  <li>Install Windows 10</li>
  <li>Create an encrypted partition for Ubuntu</li>
  <li>Install Ubuntu</li>
</ol>

<p>Of course, as with any new OS installation, you should back up any important
data before proceeding. <strong>The instructions below will erase all the data on your
hard disk.</strong> Proceed at your own risk; I’m not responsible for any damage or
data loss.</p>



<p>Since we’re installing both Windows 10 and Ubuntu from scratch, we’ll need a USB
stick for each. If you don’t already have a computer running Ubuntu or Windows,
making the installation media will be a little harder – but there are tutorials
for that and I’ll let you figure it out on your own.</p>

<ol>
  <li>Create a Windows Installer USB stick.  The easiest way is to use the <a href="https://www.microsoft.com/software-download/">Windows
10 Media Creation Tool</a> from a
computer that’s already running Windows.</li>
  <li>Create an Ubuntu 20.04 USB stick. The easiest way is to <a href="https://ubuntu.com/download/desktop">download the
ISO</a> and use the Startup Disk Creator on a
computer that’s already running Ubuntu.</li>
</ol>

<p>Great! We’ve got our USB sticks ready to go! One final thing before we get
started – we need to make sure our BIOS is set up correctly. In particular, we
want to make sure we’re using UEFI to boot our OS.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<p><img src="https://www.mikekasberg.com/images/dual-boot-encryption/dell-bios.jpg" alt="The Dell BIOS"></p>

<ol start="3">
  <li>Ensure your computer is running the latest BIOS available. This is important
because an out-of-date BIOS can have bugs, and those bugs sometimes affect
things like UEFI, non-Windows operating systems, or other components we’ll be
touching.</li>
  <li>Edit your BIOS settings. The following names are probably specific to Dell
BIOS, but other manufacturers will have similar settings.
    <ol>
      <li>Under <code>General</code> and <code>Boot Sequence</code>, make sure your <code>Boot
List Option</code> is set to <code>UEFI</code>.</li>
      <li>Under <code>General</code> and <code>Advanced Boot Options</code>, I disabled
<code>Legacy Option ROMs</code>. It’s important that both OSes install in UEFI mode.
(You can probably enable this when installation is complete if you care).</li>
      <li>Under <code>Security</code>, <code>TPM Security</code> must be enabled if you
want to easily set up BitLocker in Windows.</li>
      <li>I disabled <code>Secure Boot</code>. I’m not sure if this is absolutely required, and
you can try leaving it on or re-enabling it when you’re done if you want.</li>
    </ol>
  </li>
</ol>

<p>Now that our BIOS is configured for UEFI, we’re going to set up our hard disk.</p>

<div>
<p><b>For this tutorial, your BIOS must support UEFI!</b></p>
<p>Most modern computers support this, but if yours doesn't this tutorial won't
work for you. You should consider:</p>

<ul>
  <li>Installing only Linux with encryption using the graphical installer.</li>
  <li>OR Installing only Windows with encryption.</li>
  <li>OR Dual-booting Linux and Windows without encryption using Ubuntu's graphical installer.</li>
  <li>OR Finding another tutorial or figuring out how to do this with an MBR disk.</li>
</ul>
</div>

<ol start="5">
  <li><strong>Completely erase</strong> your hard disk and set it up for UEFI by doing the
following.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>
    <ol>
      <li>Boot your Ubuntu USB stick and use <code>Try without installing</code>.</li>
      <li>Open a terminal. Make it fullscreen while you’re at it.</li>
      <li>Figure out what your primary hard disk is called. It will probably be
either <code>/dev/sda</code> or <code>/dev/nvme0n1</code>. Importantly, it’s <strong>not</strong> <code>/dev/sda1</code> or
<code>/dev/nvme0n1p1</code> – those are partitions of the disk. One way to figure out what
yours is called is to run <code>lsblk</code> and look at the disk size. Throughout the rest
of this guide, I’m going to refer to <code>/dev/sda</code>. <strong>If yours is not
<code>/dev/sda</code>, replace <code>/dev/sda</code> with your own (perhaps <code>/dev/sdb</code> or
<code>/dev/nvme0n1</code>) for the rest of this guide.</strong></li>
      <li>
        <p>Run the following commands. This will initialize the drive as a GPT drive
and create a 550M EFI system partition formatted as FAT32.</p>

        <div><div><pre><code>$ sudo su
# sgdisk --zap-all /dev/sda
# sgdisk --new=1:0:+550M /dev/sda
# sgdisk --change-name=1:EFI /dev/sda
# sgdisk --typecode=1:ef00 /dev/sda
# mkfs.fat -F 32 /dev/sda1
</code></pre></div>        </div>
      </li>
    </ol>
  </li>
</ol>

<p>OK, phase 1’s complete. We have our installation media ready to go and the
computer’s BIOS and hard drive is set up correctly. Next, we’ll install Windows.</p>

<h2 id="phase-2-install-windows">Phase 2: Install Windows</h2>

<p>In this phase, we’re going to install Windows. Note that when we do this, we’re
going to leave some unallocated space to install Linux later. This is a good
approach because the Windows installer will mess with our partitions a little
bit, and its easier to let it do so before finalizing our Linux partitions.</p>

<p><img src="https://www.mikekasberg.com/images/dual-boot-encryption/windows-installer.jpg" alt="The Windows installer"></p>

<ol>
  <li>Boot from your Windows Installer USB stick.</li>
  <li>Choose a <code>Custom (advanced)</code> install to get to the Windows partitioning tool.</li>
  <li>Create a new partition. The size of this partition should be the amount of
disk space you want to use for Windows. In this example, I did 80G since the SSD
on my computer is relatively small. If unsure, do about half of your hard
disk.</li>
  <li>Windows will warn you that it is going to create an extra system partition.
This is good.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup></li>
  <li>Install Windows onto the partition you just made. There’s no need to format
any partitions – the Windows installer will take care of that for you.</li>
  <li>When the Windows installation is finished, log in and enable BitLocker on
drive <code>C:</code>. This will automatically create yet another partition on your disk
(a Windows recovery partition) - which is why we’re doing it before
partitioning for Ubuntu.</li>
</ol>

<p>At this point, you can start using Windows. But I’d avoid doing too much setup
or personalization yet so you don’t have to do it again if something goes wrong
below. If you want to double check your partitions, this is what you’ll be left
with after installing Windows and enabling BitLocker:</p>

<div><div><pre><code>ubuntu@ubuntu:~$ sudo sgdisk --print /dev/sda
Disk /dev/sda: 500118192 sectors, 238.5 GiB

Number  Start (sector)    End (sector)  Size       Code  Name
   1            2048         1128447   550.0 MiB   EF00  EFI
   2         1128448         1161215   16.0 MiB    0C01  Microsoft reserved ...
   3         1161216       167825076   79.5 GiB    0700  Basic data partition
   4       167825408       168900607   525.0 MiB   2700
</code></pre></div></div>

<h2 id="phase-3-partition-the-drive-for-ubuntu">Phase 3: Partition the drive for Ubuntu</h2>

<p>This is the trickiest phase since this is where we need to manually set up our
encrypted disks for Ubuntu. We’re going to make it work very similar to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html">https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html</a></em></p>]]>
            </description>
            <link>https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914573</guid>
            <pubDate>Wed, 28 Oct 2020 02:56:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Do Great Work]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24914528">thread link</a>) | @StokoeKeagan
<br/>
October 27, 2020 | https://www.keaganstokoe.com/post/how-to-do-great-work | <a href="https://web.archive.org/web/*/https://www.keaganstokoe.com/post/how-to-do-great-work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.19.2"><div dir="ltr"><div><p id="viewer-foo"><span>Nobody sets out to be average. Nobody wants to reach the end of the road feeling that they haven’t fulfilled their potential. We all want to do great work. </span></p><p id="viewer-4evni"><span>Great work is a form of wizardry. People who do great work are wizards. <strong>The path to wizardry can be summed up in one sentence: surround yourself with wizards. </strong></span></p><p id="viewer-7mio7"><span>It seems naively simple, but when you get to the end of this essay you’ll understand why on the quest to do great work, the only thing that matters is whether you’ve been surrounded by wizards or not. </span></p><p id="viewer-84pdq"><span>Great work doesn’t come from moments of magic. It comes from making incremental improvements over a long enough time for them to compound. Steph Smith wrote an </span><a href="https://blog.stephsmith.io/how-to-be-great/" target="_blank" rel="noopener"><span><u>essay</u></span></a><span> about this where she arrives at the conclusion that great is just good, but repeatable. The image below summarises the argument. <strong> </strong></span></p><div id="viewer-s8ii"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.keaganstokoe.com/post/how-to-do-great-work" data-pin-media="https://static.wixstatic.com/media/6a534b_37e47edcee264562b335c6763c11b58d~mv2.png/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/6a534b_37e47edcee264562b335c6763c11b58d~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-749s7"><span>If great work is just good work done repeatedly, two questions need to be answered: </span></p><ol><li id="viewer-f1qj8"><p><span>How do you do good work? </span></p></li><li id="viewer-e2eh6"><p><span>How do you do it consistently? </span></p></li></ol><p id="viewer-64o4s"><span><strong>The answer to both is simple: surround yourself with wizards. </strong></span></p><h3 id="viewer-id1h"><strong>THE GOOD WORK PART</strong></h3><p id="viewer-5isde"><span>When I was 13 years old I made the challenging jump from junior to senior cricket. The players were physically and mentally stronger, and far more mature. The coaching was more intense, the fitness requirements whizzed up a notch, and everything seemed to shift from 0 to 60 extremely quickly.</span></p><p id="viewer-7skt"><span>One of the players on the team was phenomenal. In my first game for the side, he walked in to bat and hit 5 fours off his first 5 balls. He was retired and he walked off the field as if nothing had happened. It was magic. That was my first encounter with a wizard. </span></p><p id="viewer-3gk1g"><span>Wizards do work that is not only brilliant in its own right but work that makes everyone around them better. Our team was filled with an unrivalled sense of confidence. It's what makes wizards valuable. It's why we want to be wizards. </span></p><p id="viewer-c3is3"><span>That season was a phenomenal experience. Even though we were on the same team, and logically we were playing at the same level, it seemed like the skills required were completely different. You couldn’t compare my abilities with his. I improved more in that season than in any other.</span></p><p id="viewer-aao0e"><span>It leads me to wonder how one person on one team helped me produce good work for years to come. <strong>The best explanation I’ve come across is tacit knowledge.</strong> Tacit knowledge is the knowledge and skills we pick up from the people around us and i<!-- -->t plays a disproportionately large role in doing good work. </span></p><p id="viewer-1ugo0"><span>Tacit knowledge is challenging to wrap your head around. This anecdote from an </span><a href="https://commoncog.com/blog/the-tacit-knowledge-series/" target="_blank" rel="noopener"><span><u>essay series</u></span></a><span> on the topic provides context:</span></p><blockquote id="viewer-1mt6r"><span>“Gallwey (a tennis coach) relays the story of teaching a student without explicit instruction: “I was going to skip entirely my usual explanations to beginning players about the proper grip, stroke and footwork for the basic forehand. Instead, I was going to hit ten forehands myself, and I wanted him to watch carefully, not thinking about what I was doing, but simply trying to grasp a visual image of the forehand. He was to repeat the image in his mind several times and then just let his body imitate.” 

It worked. Gallwey concluded: “I was beginning to learn what all good pros and students of tennis must learn: <strong>that images are better than words, showing better than telling, too much instruction worse than none, and that trying often produces negative results.”</strong></span></blockquote><p id="viewer-7j54h"><span>Tacit knowledge is knowledge that cannot be captured through words alone. It’s what’s on display when you ask someone how they did something and they tell you that "it just felt right.” </span></p><p id="viewer-2rjc9"><span><strong>Tacit knowledge is a catalyst that transforms average people with average skills into people with the intuition and know-how to produce good work. It’s not to say that you can’t do good work without it, but you’re far more likely to succeed with it and as a result of it. </strong></span></p><p id="viewer-6i9ji"><span>When learning a new skill, your tacit knowledge resources start at zero. Over time they increase and the quality of your work increases with them. Time spent with wizards reduces the effort required to develop tacit knowledge and produce good work. Why? Because when learning, images are better than words, showing better than telling, and too much instruction worse than none. When you question and imitate wizards, you learn extremely quickly. You place yourself on the shortest path to doing good work. </span></p><p id="viewer-c09e3"><span>It happens because stress elicits growth. Place your body under stress and it’ll overshoot and overprepare in response. It’s how you get stronger and more capable. Do it often enough and good work becomes your default. </span></p><p id="viewer-81jj0"><span>In theory, it’s simple: place yourself under sufficient stress to elicit desired growth. In practice, it’s more complicated. Imagine I went to the gym every day and pushed myself as hard as I could. I’d see growth, but would it be the most growth I’m capable of? Probably not. My biological and nutritional knowledge would let me down, and it would be far tougher to remain motivated when in pursuit of this goal by myself. </span></p><p id="viewer-2rdj8"><span>Intellectual and career growth works in the same way. I can push myself to read more books and learn new skills. I’ll grow, but will I reach the levels I’m capable of without the right environment? Probably not. <!-- -->To get a more accurate picture of the type of growth you’re capable of, you need to be in an environment that fosters and values growth. </span></p><p id="viewer-5dmef"><span>Tobi Lutke, CEO of Shopify, began an apprenticeship at the age of 16. In </span><a href="https://tobi.lutke.com/blogs/news/11280301-the-apprentice-programmer" target="_blank" rel="noopener"><span><u>an essay</u></span></a><span> he wrote about the experience, he says the following: </span></p><div id="viewer-2bd6n"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.keaganstokoe.com/post/how-to-do-great-work" data-pin-media="https://static.wixstatic.com/media/6a534b_00186cf1173d477c92d7e2e3f6bca549~mv2.png/v1/fit/w_1000%2Ch_628%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/6a534b_00186cf1173d477c92d7e2e3f6bca549~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-5n3p7"><span>That is an enormous statement. It comes from someone the CEO of a $120 billion-dollar company. For him to attribute a move to the basement as the most important thing to happen in professional life shows the importance of environment.</span></p><p id="viewer-f4mn5"><span><strong>Let’s recap: </strong></span></p><ul><li id="viewer-3rsa1"><p><span>Great work is just good work, done repeatably. </span></p></li><li id="viewer-5dhso"><p><span>Tacit knowledge is the catalyst that transforms average work into good work. </span></p></li><li id="viewer-28srk"><p><span>You acquire tacit knowledge by placing yourself in an environment where the people around you are better than you. Stress leads to growth. Growth leads to good work. </span></p></li></ul><h3 id="viewer-97c3t"><strong>CONSISTENCY, CONSISTENCY, CONSISTENCY</strong></h3><p id="viewer-2kgkg"><span>Environment plays an important role in doing good work, but it’s unlikely that it’s the only way to produce good work.<!-- --> It’s simply one that is effective for most people. </span></p><p id="viewer-2sqvq"><span>It’s not uncommon for people to produce good work, but it is uncommon for them to sustain it over a long period of time. To maintain consistency, environment is non-negotiable. </span></p><p id="viewer-fn7ld"><span>There’s a part of Paul Graham’s </span><a href="http://www.paulgraham.com/cities.html" target="_blank" rel="noopener"><span><u>Cities and Ambition</u></span></a><span> that reads:</span></p><div id="viewer-4lk0i"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.keaganstokoe.com/post/how-to-do-great-work" data-pin-media="https://static.wixstatic.com/media/6a534b_4eacac09732c4246b4dedb7368117a59~mv2.png/v1/fit/w_1000%2Ch_566%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/6a534b_4eacac09732c4246b4dedb7368117a59~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-5dpv9"><span>I thought about this for days. If I am trying to do good work on a consistent basis and my environment isn’t suitable, I don’t stand much of a chance. I’m gritty and stubborn, but if 15th century Milanese Leonardo couldn’t do it, I don’t fancy my odds. </span></p><p id="viewer-34jca"><span>Even if I did manage to win the battle against my environment, it would require plenty of energy and determination which would be better spent on trying to improve the quality of my work. If environment is so powerful, using it as a tailwind seems a more effective strategy.</span></p><p id="viewer-7tjq4"><span>People are the critical component of any good environment, for two reasons: </span></p><ol><li id="viewer-eo2p1"><p><span><strong>Your habits and behaviour align with theirs.</strong></span></p></li><li id="viewer-4e80f"><p><span><strong>Your interests and motivation </strong></span><strong>fluctuate</strong><span><strong> with theirs.</strong></span></p></li></ol><p id="viewer-1s5qb"><span>I suspect that in pursuit of greatness, motivation and passion are two ingredients you’re likely to need. Not because you can’t produce great work in areas that you’re not passionate about -  I doubt that people in the portable toilet industry are passionate about shit, yet successful companies continue to emerge from the near </span><a href="https://www.prnewswire.com/news-releases/portable-toilet-rental-market-worth-24-70-billion-by-2025--cagr-7-30-grand-view-research-inc-300914775.html" target="_blank" rel="noopener"><span><u>$25 billion market</u></span></a><span> - but that doing great work requires time. </span></p><p id="viewer-doqc5"><span>The correct environment for you is the one where the people around you care about the things that you do. When the people around you care about the things you wish to care about, it becomes easy to do the same. </span></p><p id="viewer-9sqco"><span>In neuroscience, long-term potentiation is the persistent strengthening of synapses based on recent patterns of activity. In the context of your environment, the people you’re surrounded by determine the behaviours and beliefs that get strengthened. </span></p><p id="viewer-64dpg"><span>Put a lot of cynical people in one place and they become more cynical. Put a lot of ambitious people in one place and they become more ambitious. Put a lot of wizards in one place and they become more wizardly. <strong>If you want to learn to produce magic, surround yourself with wizards. By spending time around them, you can’t help but develop the same traits. </strong></span></p><p id="viewer-ejfpo"><span>The pursuit of greatness is an uphill battle. Being surrounded by people that motivate and inspire you reduces the friction associated with getting to the top.  </span></p><h3 id="viewer-f3m6d"><span><strong>GET OUT OF YOUR OWN WAY</strong></span></h3><p id="viewer-5devi"><a href="https://en.wikipedia.org/wiki/Joseph_Tussman" target="_blank" rel="noopener"><span><u>Joseph Tussman</u></span></a><span> has a fantastic saying: </span></p><blockquote id="viewer-897kv"><span>“What the pupil must learn, if he learns anything at all, is that the world will do most of the work for you, provided you cooperate with it by identifying how it really works and aligning with those realities. If we do not let the world teach us, it teaches us a lesson.”</span></blockquote><p id="viewer-611ii"><span>Placing yourself in the correct environment is like finding yourself in a riptide - you can’t help but get pulled along with it. <!-- -->The riptide represents a leverage point: a place where little effort produces large output. </span></p><p id="viewer-emsei"><span>Most of us understand this or at least have an intuition about it, but we struggle to identify leverage points. Developing tacit knowledge will help you navigate the sea you’re in and find the riptides heading in the direction you want to go. Your effort will </span>compound<span> to the point where it becomes near impossible to not do great work. </span></p><p id="viewer-2p84u"><span>This is an essay about how to become a wizard. It's about doing work that isn't only great in </span>its<span> own right, but work that inspires the people around you to be as good as they can be.</span></p><p id="viewer-3fdej"><span>Surrounding yourself with wizards is the first step of this </span>journe<span>y. The time you spend around them will transform you from an average person with average skills, into someone with the intuition and know-how to produce good work on a consistent basis. Great work is just good work, but repeatable. </span></p><p id="viewer-590bb"><span>You won’t get your wizard hat straight away, but each day that you spend surrounded by wizards and the magic that they produce will take you closer than you were before.</span></p><p id="viewer-6ltik"><em>Thank …</em></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.keaganstokoe.com/post/how-to-do-great-work">https://www.keaganstokoe.com/post/how-to-do-great-work</a></em></p>]]>
            </description>
            <link>https://www.keaganstokoe.com/post/how-to-do-great-work</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914528</guid>
            <pubDate>Wed, 28 Oct 2020 02:50:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When is no-code useful?]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 81 (<a href="https://news.ycombinator.com/item?id=24914062">thread link</a>) | @thesephist
<br/>
October 27, 2020 | https://linus.coffee/note/no-code/ | <a href="https://web.archive.org/web/*/https://linus.coffee/note/no-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>To talk about what no-code is good for, we need to first take a digression on what makes no-code fundamentally different from “yes-code” software.</p>
<h2 id="the-grain-of-abstractions">The grain of abstractions</h2>
<p>Software – yes-code software – has been around for a while. One of the things we’ve learned as an industry is how to write software <em>that gracefully evolves</em>. We’re not perfect – sad, legacy systems still proliferate – but we as a technical industry have learned how to build and evolve software systems against changing requirements and constraints that span years and decades.</p>
<p>When we first solve a problem with software, we write some code against the constraints of that particular day. We don’t necessarily know how the problem is going to change. Maybe there will be different customers or stakeholders tomorrow, or maybe the product will expand to serve a related, but different, problem space. We need to be able to change software to accommodate changing circumstances without rewriting it, and that is fundamentally what <em>software engineering</em> is: how to change software systems. <em>Change</em> is the name of the game.</p>
<p>We’ve gotten decent at change. We’ve built tools like Git and patterns like continuous integration and code autoformatting to make it easier to change code and remain stable. We’ve learned how to operate large software teams, especially in open source. We’ve also learned to use better abstractions. Abstractions are conceptual wrappers that isolate different parts of a codebase – say, a data source from a user interface – so that one part may change while another doesn’t. In general we have started to figure out how to make the DNA of software systems resilient against the changing tides of time.</p>
<p>No-code seems to reject a lot of those learnings, for better or worse. I haven’t seen any no-code company or product that allows source control (and I’ve seen many no-code companies, but you’re welcome to prove me wrong.) I have yet to find no-code products that allow for natural construction of abstraction between layers of a no-code workflow. No-code software is also scarily ill-prepared for large scale development: we have software systems being worked on by tens of thousands of engineers – what does it look like for a team of 1000 engineers to be working on a set of thousands of no-code workflows? Chaos.</p>
<blockquote>
<p>Traditional software has learned the abstractions and patterns that make software resilient and adaptable to change and scale. No-code software is not ready for changing constraints nor development scale.</p>
</blockquote>
<p>Despite these limitations, I think no-code has a few niches where making tradeoffs in adaptability and scale allows no-code tools to be much, much better. So, given this, <em>when is no-code useful?</em></p>
<h2 id="1-transitionary-ephemeral-software">1. Transitionary, ephemeral software</h2>
<p>The obvious answer, and one I had before our conversation, was <em>transitionary</em> software, software with <em>a defined lifetime</em>. If your software system has a finite, pre-defined lifetime and team, it doesn’t need to worry about changing constraints or team growth. It just needs to worry about solving a problem well, now.</p>
<p>Lots of software has predictably finite lifetime: a product prototype for an early-stage company, a game or app used as a part of an interactive online ad, a quick sketch or solution to patch a particularly urgent problem in a product, an app built for an event or a conference or a recruiting cycle or a quarterly goal tracker… all of these are projects with a pre-defined, maximum lifetime. They don’t need to last or grow or change – they just need to work now, and by giving up some of the adaptability of software abstractions of code, no-code software benefits from way faster prototyping speed. This is a plus.</p>
<p>I think we see lots of finite-time software in transitions. Transitions from having no product to having a product, in a prototype. Transitions in the process of brainstorming a solution and trying multiple designs. Software with a finite shelf life is a good fit for no-code tools.</p>
<h2 id="2-high-churn-code">2. High-churn code</h2>
<p>There’s another category of software for which long-term maintainability matters little – code with high churn.</p>
<p>By high churn, I mean that requirements are changing almost daily, and very little of the code written today will exist in a month or a quarter’s time. If the code you write today doesn’t have to last and evolve, because something new is going to take its place tomorrow, what matters is the speed to build, not resilience to change.</p>
<p>There’s lots of high-churn code in businesses. Marketing websites and landing pages, data pipelines for analytics, e-commerce storefronts, marketing campaigns, payment portals – requirements for these kinds of solutions change quickly enough that code is constantly being rewritten, and if code needs to <em>be replaced</em> more than it needs to <em>last</em>, no-code tools are a great fit.</p>
<h2 id="avoiding-the-same-mistakes">Avoiding the same mistakes</h2>
<p>I think “no-code” is a misnomer. It leads us to think that no-code software is the start of a trend in which general software will involve less coding, and software engineering will become easier. This is not the case. Software engineering is not about building solutions, it’s about evolving them. But change resiliency over time is not the focus of no-code tools, and I think that’s ok.</p>
<p>I think no-code tools are instead an extension of a different trend: <a href="https://thesephist.com/posts/text/">reifying workflows</a>. Business processes and workflows used to be documented in Word docs strewn about the office or on a shared folder, or even just passed down by oral tradition in companies. Now, we have tools that allow us to build these workflows, talk about them, edit them, and share them more concretely. This is a huge boon for more repeatable business processes and for getting things done quickly! I think this is the true win of no-code tools: concretizing workflows.</p>
<p>If no-code wants to be a serious competitor against “traditional” software – though I don’t think it should try – no-code needs to learn from the mistakes of early software. No-code tools need to understand that products and software systems need to live on for decades against changing teams and requirements, and against products and companies and standards that die out and get replaced. This requires a cultural shift, a tooling shift, and a new class of abstractions in our toolbelt as no-code engineers. Anytime we try to introduce more tooling and abstraction to no-code, I think no-code gets just a little more “code” in it. And perhaps that’ll bring us right back to where we started, discovering that code is good.</p>
<p>After all, the world is complex. And when we build software against the complexity of the world, that <a href="https://thesephist.com/posts/complexity-conservation/">complexity needs to go somewhere</a>. Software is complex, but only as much as the world it attempts to make sense of.</p>
<p>It feels like we’re getting off the edge of a discovery phase of no-code, and into a time when we’re starting to understand what problems no-code tools are great for. I think it’s important that no-code tool builders focus on those strengths, or risk falling into the trap of repeating the software industry’s mistakes from the ground up.</p>

        <hr>
        <p>
            
            Next:
            <a href="https://linus.coffee/note/scannability/"><em>Scannability is king</em></a>
            
        </p>
    </article></div>]]>
            </description>
            <link>https://linus.coffee/note/no-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914062</guid>
            <pubDate>Wed, 28 Oct 2020 01:36:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ench – a minimalistic editor x3 faster than Medium]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24914041">thread link</a>) | @hewmax
<br/>
October 27, 2020 | https://ench.app/ench/the-internet-today-is-it-really-a-genius-product-of-humanity-TfHQUH | <a href="https://web.archive.org/web/*/https://ench.app/ench/the-internet-today-is-it-really-a-genius-product-of-humanity-TfHQUH">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://ench.app/ench/the-internet-today-is-it-really-a-genius-product-of-humanity-TfHQUH</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914041</guid>
            <pubDate>Wed, 28 Oct 2020 01:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Audio Visualizations]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24914012">thread link</a>) | @parisianka
<br/>
October 27, 2020 | https://www.hiteshsahu.com/AudioAnalysis | <a href="https://web.archive.org/web/*/https://www.hiteshsahu.com/AudioAnalysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.hiteshsahu.com/AudioAnalysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914012</guid>
            <pubDate>Wed, 28 Oct 2020 01:28:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OfferMarket launched today on Product Hunt, and we failed miserably]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24913859">thread link</a>) | @dwshorowitz
<br/>
October 27, 2020 | https://www.offermarket.us/blog/try-to-find-us-on-product-hunt | <a href="https://web.archive.org/web/*/https://www.offermarket.us/blog/try-to-find-us-on-product-hunt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog-post-838853946992034243">
	
	  <p><a href="https://www.offermarket.us/blog/try-to-find-us-on-product-hunt" data-back-to-blog-link="">Back to Blog</a></p>
	
	  
	
	  <div>
	    	

<h2>OfferMarket launched today on Product Hunt, and we failed miserably.</h2>

<div><p>
We tried launching on Product Hunt today, if that's what you'll call it. We half-assed it. We put together our launch post and asked a few friends to upvote.&nbsp;<span>6 hours in and we have 3 referrals to our site from Product Hunt.</span></p><p>

One person we asked for an upvote replied "I just like sold my soul to give you an upvote", here's what they were referring to in the sign up with Twitter authentication flow:
</p></div>

<div>
<div>
<p><a><img src="https://www.offermarket.us/uploads/1/3/1/0/131040874/published/twitter-authorize-an-application-copy.jpg?1603845762" alt="Picture"></a></p>
</div>
</div>



<p>
Then we tried to have some people find us on Product Hunt, but they couldn't because their search doesn't work...<br>
</p>

<div>
<div>
<p><a><img src="https://www.offermarket.us/uploads/1/3/1/0/131040874/published/producthunt-offermarket-search-no-results.png?1603845954" alt="Picture"></a></p>
</div>
</div>



<div><p>
So that's when we realized we probably were not going to be raising much awareness on Product Hunt this time around. It also made it clear that Product Hunt either has some bugs or performance issues, or the only people whose product launches percolate to the top of the daily rankings do one or both of the following:</p><ul>
<li>know a lot of people already on Product Hunt and build a following on Product Hunt before launch</li>

<li>coerce a lot of friends, family and others for upvotes</li>
</ul><p>
Which doesn't lend much credibility to the platform as a utility for finding valuable tools.</p><p>

Moving on then. We'll try again next time. We hope you enjoyed our post-mortem and how not to launch on Product Hunt.
</p></div>




	  </div>
	
	
	  	

	
	  
	
	  
	
	  <p><a href="https://www.offermarket.us/blog/try-to-find-us-on-product-hunt">
	    <span>read more</span>
	  </a>
	</p></div></div>]]>
            </description>
            <link>https://www.offermarket.us/blog/try-to-find-us-on-product-hunt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24913859</guid>
            <pubDate>Wed, 28 Oct 2020 01:05:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GitHub Actions for ML in R]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24913691">thread link</a>) | @ishcheklein
<br/>
October 27, 2020 | https://loppsided.blog/posts/2020-10-26-tidymodels-dvc-mashup/ | <a href="https://web.archive.org/web/*/https://loppsided.blog/posts/2020-10-26-tidymodels-dvc-mashup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I had a few goals in my first few days of vacation:</p>
<ol type="1">
<li>Figure out GitHub Actions.</li>
<li>Try out <a href="https://tidymodels.org/"><code>tidymodels</code></a> , after being inspired by a R in Pharma talk on the <code>stacks</code> package.</li>
<li>Investigate this whole MLOps thing, and by investigate I meant <em>try it</em>, I did NOT go on vacation to read more Gartner Garbage ™️ .</li>
</ol>
<p>As luck would have it, <a href="https://twitter.com/DrElleOBrien">@DrElleOBrien</a> happened to reach out about trying <a href="https://twitter.com/DrElleOBrien">DVC</a> with R. DVC is a framework for MLOps that can use GitHub actions, so I had the perfect excuse to knock out all three goals with one sample project.</p>
<p>If you don’t want the rambling story, here is the project: <a href="https://github.com/slopp/tidydvc">https://github.com/slopp/tidydvc</a>.</p>
<h2 id="background">Background</h2>
<h3 id="dvc">DVC</h3>
<p><a href="https://dvc.org/">DVC</a>, and its close companion <a href="https://cml.dev/">CML</a>, provide tools for model management - think Git for data and models. The core idea is that a DVC pipeline tracks the input (files, data, hyper-parameters) to an experiment and the output of an experiment (model, metrics, etc). DVC can be used locally, but the real magic is that DVC can be combined with something like GitHub and GitHub actions to automate the experiment management. Just like a software engineer could create a PR to propose a change to code, a data scientist could create a PR to propose a change to a model. But, unlike in software engineering where the goal of a PR is to review and automatically test code changes, in ModelOps the goal of the PR would be to train a model and explain the outcome!</p>
<p>DVC is primarily built around Python, but I wanted to see if it could be used with R. In many ways it shares some of the principles of the <code>drake</code> (now <code>targets</code>) package, but with some added Git ✨.</p>
<h3 id="tidymodels">Tidymodels</h3>
<p><a href="https://tidymodels.org/">Tidymodels</a> is an opinionated workflow for model construction in R<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>. It is kind of like scikit learn in the sense that many different algorithms are presented with a consistent interface.</p>
<p>A few interesting bits about tidymodels:</p>
<ol type="1">
<li>There is a concept of a <code>workflow</code> that allows you to track a model’s pre-processing steps and the model itself in one easy-to-use object. This turns out to be super helpful, though a bit at odds with DVC (or drake)’s concept of a pipeline… more to come.</li>
<li>There are easy ways to <code>tune</code> hyper-parameters. Again, very helpful, but potentially at odds with external ModelOps-y things that want to control those elements.</li>
<li>There is experimental support for <a href="https://github.com/tidymodels/stacks">ensembles</a>, which is what I wanted to try!</li>
</ol>
<p><img src="https://loppsided.blog/posts/2020-10-26-tidymodels-dvc-mashup/images/paste-5761E6A6.png" title="The Delightful stacks Logo" alt="The Delightful stacks Logo"><br>
</p>
<h3 id="mashup">Mashup</h3>
<p>Aside from learning the individual pieces, I wanted to see if it was possible to glue these different ecosystems together. As I hinted at above, however, there were some surface level concerns. It wasn’t clear to me if I could define clean boundaries between the concepts <code>tidymodels</code> wanted to control and what DVC expected to own. But the goal of PRs with beautiful <code>ggplots</code>was enticing. (Famous last words).</p>
<p>Final note, I also enjoy using R Markdown as a framework for data exploration and model creation. I find R Markdown encourages “thinking while coding”. I definitely wanted R Markdown to play a role.</p>
<p>If you are interested in this type of mashup but want to play mostly in R, I highly recommend this article by David Neuzerling: <a href="https://mdneuzerling.com/post/machine-learning-pipelines-with-tidymodels-and-targets/">Machine Learning Pipelines with Tidymodels and Targets</a>.</p>
<h2 id="unstacking-stacks">Unstacking Stacks</h2>
<div><p>I began by creating an R Markdown document that roughly followed the outline of this <a href="https://stacks.tidymodels.org/articles/basics.html">stacks tutorial</a>. To spice things up, I decided to use the Ames Housing data, so my goal was to create an ensemble that predicted housing prices. You can follow the <a href="https://github.com/slopp/tidydvc/blob/main/fit_model.Rmd">code here</a>. Because one of my goals was to try tidymodels, here are some notes for future me on what I learned.</p></div>
<h3 id="dont-skip-eda">Don’t skip EDA</h3>
<p>I didn’t want to just copy code from Max’s <a href="https://www.tidymodels.org/learn/models/parsnip-ranger-glmnet/">parsnip regression tutorial</a> so instead I opted to write my own formula regressing on different predictors<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a>. I thought I could do this without any EDA. MISTAKE. I lost at least 2 hours fighting models that wouldn’t converge because my data was either incomplete or my pre-processing was non-sensical. I still am not happy with the results, but I did learn a valuable tactic. <em>When defining a recipe that will be used further down the line in a workflow, it is still a good idea (though not required) to prep and juice the recipe.</em> Essentially, this optional juicing allows you to SEE how the recipe is applied to your training dataset and troubleshoot any errors in a friendly space, as opposed to an unfriendly space (which is what I call a stack trace from the middle of a cross validation optimization routine that has failed because of a <code>NA</code>).</p>
<div data-layout="l-body">
<pre><code>
# First define the recipe
housing_rec &lt;- recipe(SalePrice ~ ...) %&gt;% 
  update_role(PID, new_role = "ID") %&gt;% 
  step_dummy(all_nominal()) %&gt;%  
  step_meanimpute(all_numeric()) %&gt;% 
  step_zv(all_predictors()) %&gt;% 
  step_nzv(all_predictors())

# Check it!
housing_rec %&gt;% 
  prep() %&gt;% 
  juice()

# Then do the rest of your workflow magic
housing_wflow &lt;- 
  workflow() %&gt;% 
  add_recipe(housing_rec)</code></pre>
</div>
<p><em>Tune</em></p>
<p>Tuning is easy. Getting the model out of the tune to actually use… a little less intuitive. As with all things, I should have started by reading <a href="https://juliasilge.com/blog/sf-trees-random-tuning/">Julia Silge’s advice</a>. Essentially there are a couple things you (future me) need to know:</p>
<ol type="1">
<li>You create a model spec and stick it in a workflow:</li>
</ol>
<div data-layout="l-body">
<pre><code>
# PS - for those who learned penalized regression through glmnet
# penalty = lambda 
# mixture = alpha
model_spec &lt;- linear_reg(penalty = tune("penalty"), mixture = tune("mixture"))

# the workflow ties your model to your pre-processing
model_wflow &lt;- 
  workflow() %&gt;% 
  add_recipe(preprocess_data) %&gt;% 
  add_model(model_spec)</code></pre>
</div>
<ol start="2" type="1">
<li>You can tune the model<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> using a grid:</li>
</ol>
<div data-layout="l-body">
<pre><code>
tune_results &lt;- 
  tune_grid(
    model_wflow,
    resamples = folds,  
    metrics = metric,  # think rmse
    control = control_grid() # controls what metadata is saved 
  )</code></pre>
</div>
<ol start="3" type="1">
<li>You can look at the tuned results:</li>
</ol>
<div data-layout="l-body">
<pre><code>
# hint use the n function argument to see more. This is where you can find the actual tune parameters
show_best(tune_results)</code></pre>
</div>
<ol start="4" type="1">
<li>BUT, at this point, <em>you have to finalize the actual best model</em>. Or in the case of an ensemble, you have to finalize <em>many</em> models. Finalize means take the tuned parameters and fit the model on ALL the training data. (The parameters come from a model fit on a cross validation fold). To do this:</li>
</ol>
<div data-layout="l-body">
<pre><code>
# select_best was counterintuitive to me... I found it hard to pull the data
# for all models; and it doesn't give you the best model, just the best
# tune parameters 
tuned_params &lt;- select_best(tune_results)

# use this object for future predictions
model_wflow_fit &lt;- finalize_workflow(model_wflow, tuned_params)

# final tip: to inspect the actual model 
model_wflow_fit %&gt;% 
  pull_workflow_fit() %&gt;% 
  broom::tidy() # linear models OR
  vip::vip() # trees</code></pre>
</div>
<p>At different points of this process it can be easy to forget what is trained and what is still a placeholder. The print methods are really good, use them.</p>
<h3 id="stacks">Stacks</h3>
<p>My final goal was to fit an ensemble model. Unfortunately, I hit an error using the <code>stacks</code> package. I suspect this error was due to the fact that the package is experimental and I had some stale dependencies. This left me between a rock and, well, another rock. I could have tried to nuke my environment and fight with <code>remotes</code> to install a bunch of development tidymodels packages. (This was made harder by the WIP change to <code>main</code> from <code>master</code> 👏). Or I could try to push forward by working around the error with my own ensemble code. I went for the latter path, and refreshed a lot of my statistical thinking along the way. (Recall <code>%*%</code> is how to do matrix multiplication in R). But I also killed 5 hours of vacation. 🤷 I will spare you and my future self the details in the hope that the error is fixed, but a few conceptual tips:</p>
<ol type="1">
<li>The <code>stacks()</code> object starts with candidate models (from <code>tune_grid</code>) or a single model but with multiple fits (from <code>fit_resamples</code>). The magic this function does is align the different models based on the resample they used. In other words, if one candidate was fit on resample 1, it is matched with another candidate fit on resample 1. The same matching occurs within tuning configurations from a single model.<br>
</li>
<li>Under the hood, the ensemble is fit with glmnet, but buried in quite a few layers of tidymodels abstraction. <code>cv.glmnet</code> works as an alternative, but with a nasty side affect. You have to do all the work manually to get a final fitted object that glues all the prior models, workflows, and the ensemble together.<br>
</li>
<li>When those nice print methods I mentioned earlier fail, try <code>attributes</code> to see “all the stuff” tidymodels is carrying around.</li>
</ol>
<h2 id="the-mashup">The Mashup</h2>
<h3 id="adding-dvc">Adding DVC</h3>
<p><br>
Once I had a functional R Markdown document that was fitting models, it was time to try this ModelOps thing. Now ModelOps can consist of a lot of things, but in this case I was interested in trying out the training side of model operations - tracking experiments and enabling collaboration. I’ll save the monitoring side - deploying models to production and watching them overtime - for another vacation.</p>
<div><p>DVC is oriented around pipelines. Unfortunately, this appeared to clash a bit with my R Markdown workflow. For one, the R Markdown document “drove” all the modeling code, and this code was not amenable to being managed by an external pipeline. Another problem was that the tidymodels packages, especially <code>tune</code> and <code>stacks,</code> handled the parameters and “experiments” that DVC wanted to control.</p><p>

I decided to mostly ignore the first challenge. If my data was large, or the pre-processing intense, I think I would have benefited from breaking the R Markdown document into child documents that could each be a stage in a pipeline. In this case, I didn’t care for the extra overhead in saving intermediate results, and things were fast enough that I didn’t mind re-running steps from scratch. As I mentioned, I am advocate for using R Markdown instead of .R files even in the multi-stage approach. You an see an example of this <a href="https://github.com/sol-eng/bike_predict">“split it up” approach here</a>.</p></div>
<p>For the second problem, I decided to go with a hyper-hyper-parameter strategy. Essentially, I allowed <code>tune</code> and tidymodels to handle the hyper-parameter optimization within a model, but I used DVC to handle “parameters” that would …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://loppsided.blog/posts/2020-10-26-tidymodels-dvc-mashup/">https://loppsided.blog/posts/2020-10-26-tidymodels-dvc-mashup/</a></em></p>]]>
            </description>
            <link>https://loppsided.blog/posts/2020-10-26-tidymodels-dvc-mashup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24913691</guid>
            <pubDate>Wed, 28 Oct 2020 00:37:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sega Saturn Homebrew with Game Basic]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24913598">thread link</a>) | @lostgame
<br/>
October 27, 2020 | https://flybacklabs.com/sega-saturn-homebrew-with-game-basic/ | <a href="https://web.archive.org/web/*/https://flybacklabs.com/sega-saturn-homebrew-with-game-basic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6">
		<!-- .entry-header -->

	
	<div>
		
	
<figure><img data-attachment-id="123" data-permalink="https://flybacklabs.com/sega-saturn-homebrew-with-game-basic/game-basic-for-sega-saturn-2/" data-orig-file="https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn.jpg" data-orig-size="2560,1920" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone SE (2nd generation)&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1602104707&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;500&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Game BASIC for Sega Saturn" data-image-description="" data-medium-file="https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-300x225.jpg" data-large-file="https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-1024x768.jpg" loading="lazy" width="1024" height="768" src="https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-1024x768.jpg" alt="Sega Saturn for Game BASIC - Complete in Box" srcset="https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-1024x768.jpg 1024w, https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-300x225.jpg 300w, https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-768x576.jpg 768w, https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-1536x1152.jpg 1536w, https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-2048x1536.jpg 2048w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"><figcaption>Game BASIC for Sega Saturn – Complete in Box</figcaption></figure>



<h2>Part 1: Introduction</h2>



<h3>Summary</h3>



<p>Game BASIC for Sega Saturn is a homebrew development kit that allows you to program games for the Sega Saturn using the BASIC programming language.&nbsp; If you’re familiar with the PlayStation’s Net Yaroze platform, think of this as the Saturn’s answer to it – just cheaper and easier to get started with.</p>



<p>Game BASIC’s use of the BASIC language makes for a very low barrier to entry in terms of programming skill.&nbsp; Though the Saturn is notoriously difficult to program for, Game BASIC makes it easy to get started and is surprisingly powerful, allowing very easy sprite manipulation and straightforward 3D polygon implementation.&nbsp; It even includes an adapter cable that allows you to communicate with the Saturn from your PC to transfer or save programs and streamline development.  For example, here’s a Pilotwings-esque demo, but in Game BASIC:</p>



<figure><p>
<iframe title="Game Basic for Sega Saturn - GBSS CD - Jump Multi Controller" width="525" height="394" src="https://www.youtube.com/embed/jMPksluhvlE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p><figcaption>“Jump” demo, provided with Game BASIC (video courtesy <a href="https://www.satakore.com/sega-saturn-game-basic,,GBSSCD_G_JUMP_A,,GBSS-CD-Jump-Multi-Controller-Version-Bits-Laboratory.html" target="_blank" rel="noreferrer noopener">Satakore.com</a>)</figcaption></figure>



<p>The caveat?&nbsp; Game BASIC was released only in Japan, so this means a complete setup can be difficult to obtain and all documentation is in Japanese!&nbsp; Moreover, the supporting software that allows you to use your PC for streamlined development was intended for the Windows 95 era and flat out does not install on modern systems. Oh, and the adapter cable that allows you to connect your Saturn to your PC is a 25-pin serial connection!</p>



<p>Who in the world still has both Game BASIC and a Windows 95 PC with a physical serial port? Nobody!&nbsp; (Well, unless you’re <a href="https://www.youtube.com/watch?v=O_QU8eaMymo" target="_blank" rel="noreferrer noopener">Modern Vintage Gamer</a>) But if you’re a brave experimenter who’s not afraid to tinker a bit, there are still multiple options to get everything working, even today!&nbsp; You can even do a lot just via emulation.&nbsp; So, let’s head to the Lab and get started…</p>



<h3>What You’ll Need</h3>



<p>There are several options for working with Game BASIC, ranging from quite simple but clunky to work with, to quite powerful and streamlined.&nbsp; Here are the three options:</p>



<h4>The Simple Saturn-only setup</h4>



<h5>Required Tools</h5>



<ul><li>A copy of the <a href="https://archive.org/details/game-basic-for-sega-saturn" target="_blank" rel="noreferrer noopener">Game BASIC for Sega Saturn disc</a></li><li>The ability to play Japanese Saturn games (A Japanese or modded console, a Pro Action Replay/<a href="https://ppcenter.webou.net/pskai/" target="_blank" rel="noreferrer noopener">Pseudo Saturn Kai</a> cartridge, or a Saturn emulator)</li><li>Any Saturn controller</li><li>Plenty of room in the Saturn’s internal memory (if you want to save your programs)</li></ul>



<p>For this option, you’ll run Game BASIC on the Saturn with no PC connection, using only standard Saturn accessories.&nbsp; This is a reasonable choice if you just want to write “Hello, World!”-style programs or play around with the neat games and demos that come with the kit.&nbsp; Theoretically, you can write even the most complex programs this way, but you’ll run into limitations on the size of games you can save to the Saturn’s internal memory.&nbsp; Plus, programming with a virtual keyboard is an absolute pain.&nbsp; Start here if you don’t have the necessary hardware for the other options, or if you just want to poke around a bit and see what this is all about.</p>



<h4>The Enhanced Saturn-only setup</h4>



<h5>Required Tools</h5>



<ul><li>All of the tools from Option 1, PLUS</li><li>Some kind of external expanded memory, such as:<ul><li>A direct-save memory cartridge (e.g., the official Saturn Backup Memory)</li></ul><ul><li>A Sega Saturn Floppy Disk Drive and some 3.5″ floppy disks</li></ul></li><li>A Sega Saturn keyboard OR the NetLink keyboard adapter with a PS/2 keyboard</li><li>Fun peripherals, like the Stunner light gun, 3D Control Pad, multi-tap, and Shuttle Mouse</li></ul>



<p>One of the great things about Game BASIC is how easy it makes it to access the Saturn’s peripherals, including the internal backup RAM, external memory cartridges, and even the Saturn Floppy Disk Drive.&nbsp; With a setup like this, you’ll have plenty of space to save your programs and you can use a real keyboard for text entry.&nbsp; You can even start experimenting with different forms of input, like analog controls and light guns!&nbsp; But without access to the tools a PC provides, it will be difficult to make nice-looking sprites, textures, and 3D models.&nbsp; So, this will still limit what you’re capable of.&nbsp; Regardless, this is a great option for the sheer fun factor of “Hey look! I’m programming with my Saturn!” or if you have no ability to connect your Saturn to a PC.</p>



<p>You can even go this route with a Saturn emulator, giving you easy access to improved keyboard, mouse, and storage options.&nbsp; I’ve confirmed that Mednafen successfully emulates Game BASIC and allows for keyboard and mouse pass-through input, meaning you can do a whole lot of Saturn development with very little barrier to entry.</p>



<h4>The Full Saturn plus PC Setup</h4>



<h5>Required Tools</h5>



<ul><li>A complete Game BASIC for Sega Saturn kit, including:<ul><li>A copy of the <a rel="noreferrer noopener" href="https://archive.org/details/game-basic-for-sega-saturn" target="_blank">Game BASIC for Sega Saturn disc</a></li></ul><ul><li>A copy of the <a rel="noreferrer noopener" href="https://archive.org/details/game-basic-for-sega-saturn" target="_blank">Windows 95 Tools disc</a></li></ul><ul><li>The special Saturn-to-PC serial cable adapter</li></ul></li><li>A modern PC with a USB port, capable of running a Virtual Machine (I use VirtualBox)</li><li>A copy of Windows XP SP3 32-bit to install on a VM</li><li>A <a href="https://www.amazon.com/USB-Serial-Adapter-Prolific-PL-2303/dp/B003WOWBBW" target="_blank" rel="noreferrer noopener">USB-to-Serial adapter</a> (Must support RS232 with a DB25 connector)</li><li>The ability to play Japanese Saturn games on original hardware (Japanese or modded console, or a Pro Action Replay/Pseudo Saturn Kai cartridge)</li><li>A Saturn controller</li><li>Optionally, any fun Saturn accessories you may want to experiment with (I especially recommend a keyboard or keyboard adapter)</li></ul>



<p>This is the Cadillac option!&nbsp; This is the setup I use, is how Game BASIC was really intended to be used (well, except nobody expected it to be run on a VM, I suppose), and is what the rest of this guide will focus on.&nbsp; With this setup, writing a game is as simple as writing BASIC in a text editor and hitting a couple of buttons to send it to your Saturn, where it immediately shows up on your TV and responds to controller and keyboard input!&nbsp; Seriously, it’s super cool once you get it working…</p>



<p>The Simple and Enhanced Saturn-only setups are extremely straightforward.&nbsp; You just boot Game BASIC like any other Saturn game and get started, so there’s not much configuration to discuss.&nbsp; Regardless of the setup you choose, continue on to Part 2 for a few test programs.&nbsp; But if you want the Full setup, it’s quite a project to get going, so read on to Part 3 for the complete How-To!</p>


<nav role="navigation"><!-- .nav-links --></nav><!-- .mpp-post-navigation -->	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://flybacklabs.com/sega-saturn-homebrew-with-game-basic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24913598</guid>
            <pubDate>Wed, 28 Oct 2020 00:22:52 GMT</pubDate>
        </item>
    </channel>
</rss>
